2019-08-16 21:24:05.124243: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-16 21:24:05.675270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-08-16 21:24:05.675426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 21:24:06.109387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 21:24:06.109459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 21:24:06.109474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 21:24:06.109944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:58,  1.48it/s]Loading train:   1%|          | 2/266 [00:01<02:38,  1.66it/s]Loading train:   1%|          | 3/266 [00:01<02:25,  1.80it/s]Loading train:   2%|▏         | 4/266 [00:02<02:20,  1.87it/s]Loading train:   2%|▏         | 5/266 [00:02<02:18,  1.88it/s]Loading train:   2%|▏         | 6/266 [00:03<02:12,  1.96it/s]Loading train:   3%|▎         | 7/266 [00:03<02:11,  1.97it/s]Loading train:   3%|▎         | 8/266 [00:03<02:06,  2.04it/s]Loading train:   3%|▎         | 9/266 [00:04<02:10,  1.96it/s]Loading train:   4%|▍         | 10/266 [00:05<02:09,  1.98it/s]Loading train:   4%|▍         | 11/266 [00:05<02:19,  1.82it/s]Loading train:   5%|▍         | 12/266 [00:06<02:14,  1.89it/s]Loading train:   5%|▍         | 13/266 [00:06<02:07,  1.98it/s]Loading train:   5%|▌         | 14/266 [00:07<02:06,  2.00it/s]Loading train:   6%|▌         | 15/266 [00:07<02:04,  2.01it/s]Loading train:   6%|▌         | 16/266 [00:08<02:04,  2.00it/s]Loading train:   6%|▋         | 17/266 [00:08<01:57,  2.11it/s]Loading train:   7%|▋         | 18/266 [00:08<01:50,  2.24it/s]Loading train:   7%|▋         | 19/266 [00:09<01:50,  2.23it/s]Loading train:   8%|▊         | 20/266 [00:09<01:55,  2.13it/s]Loading train:   8%|▊         | 21/266 [00:10<01:52,  2.18it/s]Loading train:   8%|▊         | 22/266 [00:10<01:51,  2.20it/s]Loading train:   9%|▊         | 23/266 [00:11<02:08,  1.88it/s]Loading train:   9%|▉         | 24/266 [00:11<02:08,  1.89it/s]Loading train:   9%|▉         | 25/266 [00:12<02:16,  1.77it/s]Loading train:  10%|▉         | 26/266 [00:13<02:09,  1.86it/s]Loading train:  10%|█         | 27/266 [00:13<02:12,  1.80it/s]Loading train:  11%|█         | 28/266 [00:14<02:19,  1.71it/s]Loading train:  11%|█         | 29/266 [00:14<02:20,  1.68it/s]Loading train:  11%|█▏        | 30/266 [00:15<02:46,  1.42it/s]Loading train:  12%|█▏        | 31/266 [00:16<02:41,  1.45it/s]Loading train:  12%|█▏        | 32/266 [00:17<02:51,  1.36it/s]Loading train:  12%|█▏        | 33/266 [00:18<03:01,  1.28it/s]Loading train:  13%|█▎        | 34/266 [00:18<02:40,  1.45it/s]Loading train:  13%|█▎        | 35/266 [00:19<02:28,  1.55it/s]Loading train:  14%|█▎        | 36/266 [00:19<02:26,  1.57it/s]Loading train:  14%|█▍        | 37/266 [00:20<02:33,  1.49it/s]Loading train:  14%|█▍        | 38/266 [00:21<02:16,  1.66it/s]Loading train:  15%|█▍        | 39/266 [00:21<02:14,  1.69it/s]Loading train:  15%|█▌        | 40/266 [00:22<02:22,  1.59it/s]Loading train:  15%|█▌        | 41/266 [00:23<02:20,  1.60it/s]Loading train:  16%|█▌        | 42/266 [00:23<02:16,  1.64it/s]Loading train:  16%|█▌        | 43/266 [00:24<02:35,  1.44it/s]Loading train:  17%|█▋        | 44/266 [00:24<02:13,  1.67it/s]Loading train:  17%|█▋        | 45/266 [00:25<02:23,  1.54it/s]Loading train:  17%|█▋        | 46/266 [00:26<02:23,  1.53it/s]Loading train:  18%|█▊        | 47/266 [00:27<02:38,  1.38it/s]Loading train:  18%|█▊        | 48/266 [00:27<02:27,  1.47it/s]Loading train:  18%|█▊        | 49/266 [00:28<02:19,  1.55it/s]Loading train:  19%|█▉        | 50/266 [00:28<02:14,  1.61it/s]Loading train:  19%|█▉        | 51/266 [00:29<02:13,  1.61it/s]Loading train:  20%|█▉        | 52/266 [00:30<02:25,  1.47it/s]Loading train:  20%|█▉        | 53/266 [00:31<02:31,  1.41it/s]Loading train:  20%|██        | 54/266 [00:31<02:40,  1.32it/s]Loading train:  21%|██        | 55/266 [00:32<02:53,  1.21it/s]Loading train:  21%|██        | 56/266 [00:34<03:11,  1.09it/s]Loading train:  21%|██▏       | 57/266 [00:35<03:18,  1.05it/s]Loading train:  22%|██▏       | 58/266 [00:35<02:59,  1.16it/s]Loading train:  22%|██▏       | 59/266 [00:36<02:43,  1.27it/s]Loading train:  23%|██▎       | 60/266 [00:37<02:50,  1.21it/s]Loading train:  23%|██▎       | 61/266 [00:38<03:08,  1.09it/s]Loading train:  23%|██▎       | 62/266 [00:39<03:14,  1.05it/s]Loading train:  24%|██▎       | 63/266 [00:40<03:23,  1.00s/it]Loading train:  24%|██▍       | 64/266 [00:41<03:25,  1.02s/it]Loading train:  24%|██▍       | 65/266 [00:42<03:28,  1.04s/it]Loading train:  25%|██▍       | 66/266 [00:43<02:58,  1.12it/s]Loading train:  25%|██▌       | 67/266 [00:44<02:59,  1.11it/s]Loading train:  26%|██▌       | 68/266 [00:45<03:11,  1.03it/s]Loading train:  26%|██▌       | 69/266 [00:46<03:22,  1.03s/it]Loading train:  26%|██▋       | 70/266 [00:47<03:26,  1.05s/it]Loading train:  27%|██▋       | 71/266 [00:48<03:27,  1.07s/it]Loading train:  27%|██▋       | 72/266 [00:49<03:12,  1.01it/s]Loading train:  27%|██▋       | 73/266 [00:50<02:49,  1.14it/s]Loading train:  28%|██▊       | 74/266 [00:51<02:51,  1.12it/s]Loading train:  28%|██▊       | 75/266 [00:52<03:06,  1.02it/s]Loading train:  29%|██▊       | 76/266 [00:53<03:11,  1.01s/it]Loading train:  29%|██▉       | 77/266 [00:54<03:08,  1.00it/s]Loading train:  29%|██▉       | 78/266 [00:55<02:57,  1.06it/s]Loading train:  30%|██▉       | 79/266 [00:55<02:51,  1.09it/s]Loading train:  30%|███       | 80/266 [00:56<02:36,  1.19it/s]Loading train:  30%|███       | 81/266 [00:57<02:41,  1.14it/s]Loading train:  31%|███       | 82/266 [00:58<02:27,  1.24it/s]Loading train:  31%|███       | 83/266 [00:58<02:16,  1.34it/s]Loading train:  32%|███▏      | 84/266 [00:59<02:17,  1.32it/s]Loading train:  32%|███▏      | 85/266 [01:00<02:24,  1.25it/s]Loading train:  32%|███▏      | 86/266 [01:01<02:36,  1.15it/s]Loading train:  33%|███▎      | 87/266 [01:02<02:29,  1.20it/s]Loading train:  33%|███▎      | 88/266 [01:03<02:22,  1.25it/s]Loading train:  33%|███▎      | 89/266 [01:04<02:34,  1.15it/s]Loading train:  34%|███▍      | 90/266 [01:05<02:46,  1.06it/s]Loading train:  34%|███▍      | 91/266 [01:06<02:56,  1.01s/it]Loading train:  35%|███▍      | 92/266 [01:07<02:43,  1.06it/s]Loading train:  35%|███▍      | 93/266 [01:07<02:36,  1.10it/s]Loading train:  35%|███▌      | 94/266 [01:08<02:42,  1.06it/s]Loading train:  36%|███▌      | 95/266 [01:09<02:42,  1.05it/s]Loading train:  36%|███▌      | 96/266 [01:10<02:42,  1.05it/s]Loading train:  36%|███▋      | 97/266 [01:11<02:39,  1.06it/s]Loading train:  37%|███▋      | 98/266 [01:12<02:24,  1.16it/s]Loading train:  37%|███▋      | 99/266 [01:13<02:12,  1.26it/s]Loading train:  38%|███▊      | 100/266 [01:14<02:20,  1.18it/s]Loading train:  38%|███▊      | 101/266 [01:15<02:30,  1.09it/s]Loading train:  38%|███▊      | 102/266 [01:16<02:42,  1.01it/s]Loading train:  39%|███▊      | 103/266 [01:17<02:40,  1.01it/s]Loading train:  39%|███▉      | 104/266 [01:18<02:44,  1.01s/it]Loading train:  39%|███▉      | 105/266 [01:19<02:44,  1.02s/it]Loading train:  40%|███▉      | 106/266 [01:20<02:27,  1.08it/s]Loading train:  40%|████      | 107/266 [01:20<02:11,  1.21it/s]Loading train:  41%|████      | 108/266 [01:21<02:13,  1.19it/s]Loading train:  41%|████      | 109/266 [01:22<02:17,  1.14it/s]Loading train:  41%|████▏     | 110/266 [01:23<02:30,  1.04it/s]Loading train:  42%|████▏     | 111/266 [01:24<02:37,  1.02s/it]Loading train:  42%|████▏     | 112/266 [01:26<02:41,  1.05s/it]Loading train:  42%|████▏     | 113/266 [01:27<02:40,  1.05s/it]Loading train:  43%|████▎     | 114/266 [01:28<02:43,  1.08s/it]Loading train:  43%|████▎     | 115/266 [01:29<02:32,  1.01s/it]Loading train:  44%|████▎     | 116/266 [01:30<02:32,  1.02s/it]Loading train:  44%|████▍     | 117/266 [01:31<02:28,  1.00it/s]Loading train:  44%|████▍     | 118/266 [01:31<02:12,  1.11it/s]Loading train:  45%|████▍     | 119/266 [01:32<02:12,  1.11it/s]Loading train:  45%|████▌     | 120/266 [01:33<02:03,  1.18it/s]Loading train:  45%|████▌     | 121/266 [01:34<02:06,  1.14it/s]Loading train:  46%|████▌     | 122/266 [01:35<02:02,  1.18it/s]Loading train:  46%|████▌     | 123/266 [01:35<02:02,  1.16it/s]Loading train:  47%|████▋     | 124/266 [01:37<02:14,  1.06it/s]Loading train:  47%|████▋     | 125/266 [01:38<02:17,  1.02it/s]Loading train:  47%|████▋     | 126/266 [01:39<02:21,  1.01s/it]Loading train:  48%|████▊     | 127/266 [01:40<02:19,  1.00s/it]Loading train:  48%|████▊     | 128/266 [01:41<02:14,  1.03it/s]Loading train:  48%|████▊     | 129/266 [01:42<02:21,  1.03s/it]Loading train:  49%|████▉     | 130/266 [01:43<02:29,  1.10s/it]Loading train:  49%|████▉     | 131/266 [01:44<02:18,  1.03s/it]Loading train:  50%|████▉     | 132/266 [01:45<02:12,  1.01it/s]Loading train:  50%|█████     | 133/266 [01:46<02:26,  1.10s/it]Loading train:  50%|█████     | 134/266 [01:47<02:17,  1.04s/it]Loading train:  51%|█████     | 135/266 [01:48<02:25,  1.11s/it]Loading train:  51%|█████     | 136/266 [01:49<02:24,  1.11s/it]Loading train:  52%|█████▏    | 137/266 [01:50<01:59,  1.08it/s]Loading train:  52%|█████▏    | 138/266 [01:51<02:00,  1.06it/s]Loading train:  52%|█████▏    | 139/266 [01:52<01:59,  1.06it/s]Loading train:  53%|█████▎    | 140/266 [01:53<02:02,  1.03it/s]Loading train:  53%|█████▎    | 141/266 [01:54<02:05,  1.01s/it]Loading train:  53%|█████▎    | 142/266 [01:55<02:09,  1.04s/it]Loading train:  54%|█████▍    | 143/266 [01:56<02:11,  1.07s/it]Loading train:  54%|█████▍    | 144/266 [01:58<02:17,  1.12s/it]Loading train:  55%|█████▍    | 145/266 [01:59<02:12,  1.09s/it]Loading train:  55%|█████▍    | 146/266 [01:59<02:03,  1.03s/it]Loading train:  55%|█████▌    | 147/266 [02:00<01:59,  1.01s/it]Loading train:  56%|█████▌    | 148/266 [02:01<02:03,  1.05s/it]Loading train:  56%|█████▌    | 149/266 [02:02<02:00,  1.03s/it]Loading train:  56%|█████▋    | 150/266 [02:04<02:02,  1.06s/it]Loading train:  57%|█████▋    | 151/266 [02:05<02:07,  1.11s/it]Loading train:  57%|█████▋    | 152/266 [02:06<02:04,  1.09s/it]Loading train:  58%|█████▊    | 153/266 [02:07<02:02,  1.08s/it]Loading train:  58%|█████▊    | 154/266 [02:08<02:01,  1.09s/it]Loading train:  58%|█████▊    | 155/266 [02:09<02:00,  1.08s/it]Loading train:  59%|█████▊    | 156/266 [02:10<02:02,  1.11s/it]Loading train:  59%|█████▉    | 157/266 [02:11<02:00,  1.11s/it]Loading train:  59%|█████▉    | 158/266 [02:12<01:55,  1.07s/it]Loading train:  60%|█████▉    | 159/266 [02:13<01:49,  1.03s/it]Loading train:  60%|██████    | 160/266 [02:14<01:44,  1.01it/s]Loading train:  61%|██████    | 161/266 [02:15<01:40,  1.05it/s]Loading train:  61%|██████    | 162/266 [02:16<01:41,  1.02it/s]Loading train:  61%|██████▏   | 163/266 [02:17<01:44,  1.01s/it]Loading train:  62%|██████▏   | 164/266 [02:18<01:45,  1.03s/it]Loading train:  62%|██████▏   | 165/266 [02:19<01:44,  1.03s/it]Loading train:  62%|██████▏   | 166/266 [02:21<01:48,  1.09s/it]Loading train:  63%|██████▎   | 167/266 [02:21<01:41,  1.03s/it]Loading train:  63%|██████▎   | 168/266 [02:22<01:25,  1.15it/s]Loading train:  64%|██████▎   | 169/266 [02:23<01:30,  1.07it/s]Loading train:  64%|██████▍   | 170/266 [02:24<01:25,  1.12it/s]Loading train:  64%|██████▍   | 171/266 [02:25<01:30,  1.05it/s]Loading train:  65%|██████▍   | 172/266 [02:26<01:25,  1.11it/s]Loading train:  65%|██████▌   | 173/266 [02:26<01:15,  1.23it/s]Loading train:  65%|██████▌   | 174/266 [02:27<01:21,  1.13it/s]Loading train:  66%|██████▌   | 175/266 [02:28<01:20,  1.13it/s]Loading train:  66%|██████▌   | 176/266 [02:29<01:19,  1.14it/s]Loading train:  67%|██████▋   | 177/266 [02:30<01:24,  1.05it/s]Loading train:  67%|██████▋   | 178/266 [02:31<01:25,  1.02it/s]Loading train:  67%|██████▋   | 179/266 [02:32<01:29,  1.03s/it]Loading train:  68%|██████▊   | 180/266 [02:33<01:27,  1.02s/it]Loading train:  68%|██████▊   | 181/266 [02:34<01:28,  1.05s/it]Loading train:  68%|██████▊   | 182/266 [02:36<01:29,  1.07s/it]Loading train:  69%|██████▉   | 183/266 [02:37<01:27,  1.06s/it]Loading train:  69%|██████▉   | 184/266 [02:38<01:25,  1.04s/it]Loading train:  70%|██████▉   | 185/266 [02:38<01:17,  1.04it/s]Loading train:  70%|██████▉   | 186/266 [02:39<01:03,  1.26it/s]Loading train:  70%|███████   | 187/266 [02:40<01:07,  1.17it/s]Loading train:  71%|███████   | 188/266 [02:41<01:12,  1.08it/s]Loading train:  71%|███████   | 189/266 [02:42<01:14,  1.03it/s]Loading train:  71%|███████▏  | 190/266 [02:43<01:15,  1.00it/s]Loading train:  72%|███████▏  | 191/266 [02:44<01:18,  1.05s/it]Loading train:  72%|███████▏  | 192/266 [02:45<01:17,  1.05s/it]Loading train:  73%|███████▎  | 193/266 [02:46<01:11,  1.02it/s]Loading train:  73%|███████▎  | 194/266 [02:47<01:14,  1.04s/it]Loading train:  73%|███████▎  | 195/266 [02:48<01:08,  1.03it/s]Loading train:  74%|███████▎  | 196/266 [02:49<01:08,  1.03it/s]Loading train:  74%|███████▍  | 197/266 [02:50<01:10,  1.02s/it]Loading train:  74%|███████▍  | 198/266 [02:51<01:10,  1.03s/it]Loading train:  75%|███████▍  | 199/266 [02:52<01:08,  1.02s/it]Loading train:  75%|███████▌  | 200/266 [02:53<01:02,  1.05it/s]Loading train:  76%|███████▌  | 201/266 [02:54<01:01,  1.07it/s]Loading train:  76%|███████▌  | 202/266 [02:55<01:02,  1.03it/s]Loading train:  76%|███████▋  | 203/266 [02:56<00:58,  1.07it/s]Loading train:  77%|███████▋  | 204/266 [02:57<00:54,  1.14it/s]Loading train:  77%|███████▋  | 205/266 [02:57<00:52,  1.17it/s]Loading train:  77%|███████▋  | 206/266 [02:58<00:52,  1.14it/s]Loading train:  78%|███████▊  | 207/266 [02:59<00:45,  1.31it/s]Loading train:  78%|███████▊  | 208/266 [03:00<00:47,  1.22it/s]Loading train:  79%|███████▊  | 209/266 [03:01<00:47,  1.19it/s]Loading train:  79%|███████▉  | 210/266 [03:01<00:42,  1.32it/s]Loading train:  79%|███████▉  | 211/266 [03:02<00:42,  1.28it/s]Loading train:  80%|███████▉  | 212/266 [03:03<00:42,  1.27it/s]Loading train:  80%|████████  | 213/266 [03:04<00:46,  1.15it/s]Loading train:  80%|████████  | 214/266 [03:05<00:48,  1.08it/s]Loading train:  81%|████████  | 215/266 [03:06<00:48,  1.05it/s]Loading train:  81%|████████  | 216/266 [03:07<00:46,  1.08it/s]Loading train:  82%|████████▏ | 217/266 [03:08<00:43,  1.14it/s]Loading train:  82%|████████▏ | 218/266 [03:08<00:40,  1.17it/s]Loading train:  82%|████████▏ | 219/266 [03:09<00:42,  1.10it/s]Loading train:  83%|████████▎ | 220/266 [03:10<00:42,  1.09it/s]Loading train:  83%|████████▎ | 221/266 [03:11<00:42,  1.07it/s]Loading train:  83%|████████▎ | 222/266 [03:12<00:41,  1.05it/s]Loading train:  84%|████████▍ | 223/266 [03:14<00:43,  1.01s/it]Loading train:  84%|████████▍ | 224/266 [03:15<00:43,  1.03s/it]Loading train:  85%|████████▍ | 225/266 [03:16<00:42,  1.03s/it]Loading train:  85%|████████▍ | 226/266 [03:17<00:40,  1.02s/it]Loading train:  85%|████████▌ | 227/266 [03:18<00:42,  1.09s/it]Loading train:  86%|████████▌ | 228/266 [03:19<00:43,  1.15s/it]Loading train:  86%|████████▌ | 229/266 [03:20<00:41,  1.11s/it]Loading train:  86%|████████▋ | 230/266 [03:21<00:39,  1.10s/it]Loading train:  87%|████████▋ | 231/266 [03:22<00:38,  1.09s/it]Loading train:  87%|████████▋ | 232/266 [03:23<00:35,  1.05s/it]Loading train:  88%|████████▊ | 233/266 [03:24<00:32,  1.02it/s]Loading train:  88%|████████▊ | 234/266 [03:25<00:34,  1.08s/it]Loading train:  88%|████████▊ | 235/266 [03:27<00:34,  1.12s/it]Loading train:  89%|████████▊ | 236/266 [03:28<00:34,  1.15s/it]Loading train:  89%|████████▉ | 237/266 [03:29<00:32,  1.11s/it]Loading train:  89%|████████▉ | 238/266 [03:30<00:33,  1.20s/it]Loading train:  90%|████████▉ | 239/266 [03:31<00:32,  1.20s/it]Loading train:  90%|█████████ | 240/266 [03:33<00:31,  1.20s/it]Loading train:  91%|█████████ | 241/266 [03:34<00:30,  1.20s/it]Loading train:  91%|█████████ | 242/266 [03:35<00:28,  1.21s/it]Loading train:  91%|█████████▏| 243/266 [03:36<00:25,  1.10s/it]Loading train:  92%|█████████▏| 244/266 [03:37<00:21,  1.02it/s]Loading train:  92%|█████████▏| 245/266 [03:37<00:19,  1.06it/s]Loading train:  92%|█████████▏| 246/266 [03:38<00:16,  1.21it/s]Loading train:  93%|█████████▎| 247/266 [03:39<00:15,  1.25it/s]Loading train:  93%|█████████▎| 248/266 [03:40<00:15,  1.18it/s]Loading train:  94%|█████████▎| 249/266 [03:41<00:13,  1.22it/s]Loading train:  94%|█████████▍| 250/266 [03:42<00:14,  1.13it/s]Loading train:  94%|█████████▍| 251/266 [03:43<00:14,  1.01it/s]Loading train:  95%|█████████▍| 252/266 [03:44<00:13,  1.01it/s]Loading train:  95%|█████████▌| 253/266 [03:45<00:13,  1.01s/it]Loading train:  95%|█████████▌| 254/266 [03:46<00:12,  1.01s/it]Loading train:  96%|█████████▌| 255/266 [03:47<00:11,  1.07s/it]Loading train:  96%|█████████▌| 256/266 [03:48<00:10,  1.08s/it]Loading train:  97%|█████████▋| 257/266 [03:49<00:09,  1.03s/it]Loading train:  97%|█████████▋| 258/266 [03:50<00:08,  1.05s/it]Loading train:  97%|█████████▋| 259/266 [03:51<00:07,  1.08s/it]Loading train:  98%|█████████▊| 260/266 [03:52<00:06,  1.10s/it]Loading train:  98%|█████████▊| 261/266 [03:53<00:05,  1.01s/it]Loading train:  98%|█████████▊| 262/266 [03:54<00:03,  1.04it/s]Loading train:  99%|█████████▉| 263/266 [03:55<00:02,  1.05it/s]Loading train:  99%|█████████▉| 264/266 [03:56<00:01,  1.07it/s]Loading train: 100%|█████████▉| 265/266 [03:57<00:00,  1.12it/s]Loading train: 100%|██████████| 266/266 [03:57<00:00,  1.19it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:27,  9.78it/s]concatenating: train:   1%|          | 2/266 [00:00<00:28,  9.20it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:24, 10.56it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:21, 12.21it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:24, 10.51it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:27,  9.42it/s]concatenating: train:   4%|▍         | 11/266 [00:01<00:28,  9.06it/s]concatenating: train:   5%|▍         | 12/266 [00:01<00:29,  8.74it/s]concatenating: train:   5%|▍         | 13/266 [00:01<00:28,  8.89it/s]concatenating: train:   5%|▌         | 14/266 [00:01<00:28,  8.90it/s]concatenating: train:   6%|▋         | 17/266 [00:01<00:22, 10.93it/s]concatenating: train:   8%|▊         | 21/266 [00:01<00:17, 13.64it/s]concatenating: train:   9%|▉         | 25/266 [00:01<00:15, 15.72it/s]concatenating: train:  11%|█         | 28/266 [00:02<00:16, 14.59it/s]concatenating: train:  11%|█▏        | 30/266 [00:02<00:22, 10.65it/s]concatenating: train:  12%|█▏        | 32/266 [00:02<00:21, 11.13it/s]concatenating: train:  13%|█▎        | 35/266 [00:02<00:17, 13.48it/s]concatenating: train:  15%|█▍        | 39/266 [00:02<00:13, 16.40it/s]concatenating: train:  16%|█▌        | 42/266 [00:03<00:15, 14.57it/s]concatenating: train:  17%|█▋        | 44/266 [00:03<00:17, 13.01it/s]concatenating: train:  17%|█▋        | 46/266 [00:03<00:21, 10.18it/s]concatenating: train:  18%|█▊        | 49/266 [00:03<00:17, 12.32it/s]concatenating: train:  20%|█▉        | 52/266 [00:03<00:14, 14.88it/s]concatenating: train:  21%|██        | 55/266 [00:03<00:13, 15.77it/s]concatenating: train:  21%|██▏       | 57/266 [00:04<00:17, 12.08it/s]concatenating: train:  22%|██▏       | 59/266 [00:04<00:17, 11.82it/s]concatenating: train:  23%|██▎       | 61/266 [00:04<00:17, 11.80it/s]concatenating: train:  24%|██▎       | 63/266 [00:04<00:15, 12.92it/s]concatenating: train:  25%|██▌       | 67/266 [00:04<00:12, 15.68it/s]concatenating: train:  26%|██▋       | 70/266 [00:04<00:12, 15.29it/s]concatenating: train:  27%|██▋       | 72/266 [00:05<00:15, 12.89it/s]concatenating: train:  28%|██▊       | 74/266 [00:05<00:14, 13.33it/s]concatenating: train:  29%|██▊       | 76/266 [00:05<00:14, 13.33it/s]concatenating: train:  29%|██▉       | 78/266 [00:05<00:15, 12.03it/s]concatenating: train:  30%|███       | 81/266 [00:05<00:12, 14.58it/s]concatenating: train:  32%|███▏      | 85/266 [00:05<00:10, 17.54it/s]concatenating: train:  33%|███▎      | 88/266 [00:06<00:10, 17.28it/s]concatenating: train:  34%|███▍      | 91/266 [00:06<00:11, 15.60it/s]concatenating: train:  35%|███▍      | 93/266 [00:06<00:15, 11.28it/s]concatenating: train:  36%|███▌      | 95/266 [00:06<00:15, 10.93it/s]concatenating: train:  36%|███▋      | 97/266 [00:06<00:13, 12.10it/s]concatenating: train:  38%|███▊      | 100/266 [00:07<00:12, 13.69it/s]concatenating: train:  38%|███▊      | 102/266 [00:07<00:12, 12.70it/s]concatenating: train:  39%|███▉      | 104/266 [00:07<00:13, 12.18it/s]concatenating: train:  40%|███▉      | 106/266 [00:07<00:13, 11.92it/s]concatenating: train:  41%|████      | 108/266 [00:07<00:13, 11.35it/s]concatenating: train:  41%|████▏     | 110/266 [00:07<00:12, 12.09it/s]concatenating: train:  43%|████▎     | 114/266 [00:08<00:10, 14.81it/s]concatenating: train:  44%|████▍     | 117/266 [00:08<00:10, 14.79it/s]concatenating: train:  45%|████▍     | 119/266 [00:08<00:13, 11.19it/s]concatenating: train:  45%|████▌     | 121/266 [00:08<00:13, 10.95it/s]concatenating: train:  46%|████▌     | 123/266 [00:08<00:13, 10.45it/s]concatenating: train:  47%|████▋     | 125/266 [00:09<00:13, 10.84it/s]concatenating: train:  48%|████▊     | 128/266 [00:09<00:10, 13.20it/s]concatenating: train:  52%|█████▏    | 138/266 [00:09<00:07, 17.66it/s]concatenating: train:  53%|█████▎    | 142/266 [00:09<00:08, 15.22it/s]concatenating: train:  55%|█████▍    | 145/266 [00:10<00:08, 13.74it/s]concatenating: train:  56%|█████▌    | 148/266 [00:10<00:09, 12.23it/s]concatenating: train:  57%|█████▋    | 151/266 [00:10<00:07, 14.70it/s]concatenating: train:  58%|█████▊    | 154/266 [00:10<00:06, 16.22it/s]concatenating: train:  59%|█████▉    | 157/266 [00:10<00:07, 14.30it/s]concatenating: train:  60%|█████▉    | 159/266 [00:10<00:07, 13.48it/s]concatenating: train:  61%|██████    | 161/266 [00:11<00:09, 11.07it/s]concatenating: train:  61%|██████▏   | 163/266 [00:11<00:09, 10.66it/s]concatenating: train:  65%|██████▍   | 172/266 [00:11<00:06, 14.44it/s]concatenating: train:  66%|██████▌   | 176/266 [00:11<00:05, 17.57it/s]concatenating: train:  68%|██████▊   | 180/266 [00:11<00:04, 19.88it/s]concatenating: train:  69%|██████▉   | 184/266 [00:12<00:06, 13.64it/s]concatenating: train:  70%|███████   | 187/266 [00:12<00:06, 11.98it/s]concatenating: train:  82%|████████▏ | 217/266 [00:12<00:02, 16.79it/s]concatenating: train:  85%|████████▌ | 227/266 [00:13<00:02, 14.46it/s]concatenating: train:  90%|█████████ | 240/266 [00:13<00:01, 19.71it/s]concatenating: train: 100%|█████████▉| 265/266 [00:13<00:00, 27.24it/s]concatenating: train: 100%|██████████| 266/266 [00:13<00:00, 19.15it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.03s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.04s/it]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.02it/s]Loading test:  80%|████████  | 4/5 [00:03<00:00,  1.06it/s]Loading test: 100%|██████████| 5/5 [00:04<00:00,  1.02it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 11.32it/s]concatenating: validation:  60%|██████    | 3/5 [00:00<00:00,  9.41it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  9.37it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  8.66it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<03:45,  1.18it/s]Loading trainS:   1%|          | 2/266 [00:01<03:38,  1.21it/s]Loading trainS:   1%|          | 3/266 [00:02<03:40,  1.19it/s]Loading trainS:   2%|▏         | 4/266 [00:03<03:43,  1.17it/s]Loading trainS:   2%|▏         | 5/266 [00:04<03:46,  1.15it/s]Loading trainS:   2%|▏         | 6/266 [00:05<03:54,  1.11it/s]Loading trainS:   3%|▎         | 7/266 [00:06<03:56,  1.10it/s]Loading trainS:   3%|▎         | 8/266 [00:07<04:11,  1.03it/s]Loading trainS:   3%|▎         | 9/266 [00:08<04:18,  1.01s/it]Loading trainS:   4%|▍         | 10/266 [00:09<04:34,  1.07s/it]Loading trainS:   4%|▍         | 11/266 [00:10<04:54,  1.16s/it]Loading trainS:   5%|▍         | 12/266 [00:11<04:40,  1.10s/it]Loading trainS:   5%|▍         | 13/266 [00:13<04:42,  1.12s/it]Loading trainS:   5%|▌         | 14/266 [00:14<04:49,  1.15s/it]Loading trainS:   6%|▌         | 15/266 [00:15<04:48,  1.15s/it]Loading trainS:   6%|▌         | 16/266 [00:16<04:28,  1.07s/it]Loading trainS:   6%|▋         | 17/266 [00:17<04:21,  1.05s/it]Loading trainS:   7%|▋         | 18/266 [00:18<04:27,  1.08s/it]Loading trainS:   7%|▋         | 19/266 [00:19<04:21,  1.06s/it]Loading trainS:   8%|▊         | 20/266 [00:20<04:27,  1.09s/it]Loading trainS:   8%|▊         | 21/266 [00:21<04:17,  1.05s/it]Loading trainS:   8%|▊         | 22/266 [00:22<04:26,  1.09s/it]Loading trainS:   9%|▊         | 23/266 [00:23<04:04,  1.01s/it]Loading trainS:   9%|▉         | 24/266 [00:24<04:10,  1.04s/it]Loading trainS:   9%|▉         | 25/266 [00:26<04:27,  1.11s/it]Loading trainS:  10%|▉         | 26/266 [00:27<04:35,  1.15s/it]Loading trainS:  10%|█         | 27/266 [00:28<04:49,  1.21s/it]Loading trainS:  11%|█         | 28/266 [00:30<05:07,  1.29s/it]Loading trainS:  11%|█         | 29/266 [00:31<05:05,  1.29s/it]Loading trainS:  11%|█▏        | 30/266 [00:32<05:22,  1.36s/it]Loading trainS:  12%|█▏        | 31/266 [00:34<05:05,  1.30s/it]Loading trainS:  12%|█▏        | 32/266 [00:35<05:02,  1.29s/it]Loading trainS:  12%|█▏        | 33/266 [00:36<04:51,  1.25s/it]Loading trainS:  13%|█▎        | 34/266 [00:37<03:59,  1.03s/it]Loading trainS:  13%|█▎        | 35/266 [00:37<03:33,  1.08it/s]Loading trainS:  14%|█▎        | 36/266 [00:38<03:30,  1.09it/s]Loading trainS:  14%|█▍        | 37/266 [00:39<03:40,  1.04it/s]Loading trainS:  14%|█▍        | 38/266 [00:40<03:38,  1.04it/s]Loading trainS:  15%|█▍        | 39/266 [00:41<03:16,  1.15it/s]Loading trainS:  15%|█▌        | 40/266 [00:41<03:00,  1.25it/s]Loading trainS:  15%|█▌        | 41/266 [00:42<03:03,  1.23it/s]Loading trainS:  16%|█▌        | 42/266 [00:43<03:00,  1.24it/s]Loading trainS:  16%|█▌        | 43/266 [00:44<02:42,  1.38it/s]Loading trainS:  17%|█▋        | 44/266 [00:44<02:51,  1.29it/s]Loading trainS:  17%|█▋        | 45/266 [00:46<03:08,  1.17it/s]Loading trainS:  17%|█▋        | 46/266 [00:47<03:18,  1.11it/s]Loading trainS:  18%|█▊        | 47/266 [00:47<02:52,  1.27it/s]Loading trainS:  18%|█▊        | 48/266 [00:48<02:29,  1.46it/s]Loading trainS:  18%|█▊        | 49/266 [00:49<02:49,  1.28it/s]Loading trainS:  19%|█▉        | 50/266 [00:50<03:11,  1.13it/s]Loading trainS:  19%|█▉        | 51/266 [00:51<03:22,  1.06it/s]Loading trainS:  20%|█▉        | 52/266 [00:52<03:24,  1.05it/s]Loading trainS:  20%|█▉        | 53/266 [00:53<03:22,  1.05it/s]Loading trainS:  20%|██        | 54/266 [00:54<03:16,  1.08it/s]Loading trainS:  21%|██        | 55/266 [00:54<03:17,  1.07it/s]Loading trainS:  21%|██        | 56/266 [00:55<03:10,  1.10it/s]Loading trainS:  21%|██▏       | 57/266 [00:56<03:17,  1.06it/s]Loading trainS:  22%|██▏       | 58/266 [00:57<03:19,  1.04it/s]Loading trainS:  22%|██▏       | 59/266 [00:58<02:57,  1.16it/s]Loading trainS:  23%|██▎       | 60/266 [00:59<02:53,  1.19it/s]Loading trainS:  23%|██▎       | 61/266 [01:00<03:06,  1.10it/s]Loading trainS:  23%|██▎       | 62/266 [01:01<03:19,  1.02it/s]Loading trainS:  24%|██▎       | 63/266 [01:02<03:27,  1.02s/it]Loading trainS:  24%|██▍       | 64/266 [01:03<03:35,  1.07s/it]Loading trainS:  24%|██▍       | 65/266 [01:04<03:15,  1.03it/s]Loading trainS:  25%|██▍       | 66/266 [01:05<02:57,  1.12it/s]Loading trainS:  25%|██▌       | 67/266 [01:06<03:12,  1.03it/s]Loading trainS:  26%|██▌       | 68/266 [01:07<03:11,  1.04it/s]Loading trainS:  26%|██▌       | 69/266 [01:08<03:33,  1.08s/it]Loading trainS:  26%|██▋       | 70/266 [01:09<03:30,  1.07s/it]Loading trainS:  27%|██▋       | 71/266 [01:10<03:03,  1.06it/s]Loading trainS:  27%|██▋       | 72/266 [01:11<02:55,  1.10it/s]Loading trainS:  27%|██▋       | 73/266 [01:11<02:34,  1.25it/s]Loading trainS:  28%|██▊       | 74/266 [01:12<02:45,  1.16it/s]Loading trainS:  28%|██▊       | 75/266 [01:13<02:58,  1.07it/s]Loading trainS:  29%|██▊       | 76/266 [01:14<02:55,  1.08it/s]Loading trainS:  29%|██▉       | 77/266 [01:15<03:06,  1.01it/s]Loading trainS:  29%|██▉       | 78/266 [01:17<03:17,  1.05s/it]Loading trainS:  30%|██▉       | 79/266 [01:18<03:11,  1.03s/it]Loading trainS:  30%|███       | 80/266 [01:18<03:04,  1.01it/s]Loading trainS:  30%|███       | 81/266 [01:20<03:10,  1.03s/it]Loading trainS:  31%|███       | 82/266 [01:21<03:04,  1.00s/it]Loading trainS:  31%|███       | 83/266 [01:22<03:06,  1.02s/it]Loading trainS:  32%|███▏      | 84/266 [01:22<02:45,  1.10it/s]Loading trainS:  32%|███▏      | 85/266 [01:23<02:44,  1.10it/s]Loading trainS:  32%|███▏      | 86/266 [01:24<02:26,  1.22it/s]Loading trainS:  33%|███▎      | 87/266 [01:24<02:08,  1.40it/s]Loading trainS:  33%|███▎      | 88/266 [01:25<02:12,  1.34it/s]Loading trainS:  33%|███▎      | 89/266 [01:26<02:16,  1.30it/s]Loading trainS:  34%|███▍      | 90/266 [01:27<02:10,  1.35it/s]Loading trainS:  34%|███▍      | 91/266 [01:27<02:19,  1.26it/s]Loading trainS:  35%|███▍      | 92/266 [01:28<02:20,  1.24it/s]Loading trainS:  35%|███▍      | 93/266 [01:29<02:09,  1.33it/s]Loading trainS:  35%|███▌      | 94/266 [01:30<02:06,  1.36it/s]Loading trainS:  36%|███▌      | 95/266 [01:30<02:01,  1.41it/s]Loading trainS:  36%|███▌      | 96/266 [01:31<01:55,  1.47it/s]Loading trainS:  36%|███▋      | 97/266 [01:32<02:07,  1.33it/s]Loading trainS:  37%|███▋      | 98/266 [01:32<02:01,  1.38it/s]Loading trainS:  37%|███▋      | 99/266 [01:33<01:46,  1.56it/s]Loading trainS:  38%|███▊      | 100/266 [01:33<01:42,  1.61it/s]Loading trainS:  38%|███▊      | 101/266 [01:34<01:57,  1.40it/s]Loading trainS:  38%|███▊      | 102/266 [01:35<02:08,  1.28it/s]Loading trainS:  39%|███▊      | 103/266 [01:36<02:22,  1.14it/s]Loading trainS:  39%|███▉      | 104/266 [01:38<02:41,  1.00it/s]Loading trainS:  39%|███▉      | 105/266 [01:39<02:49,  1.05s/it]Loading trainS:  40%|███▉      | 106/266 [01:40<02:51,  1.07s/it]Loading trainS:  40%|████      | 107/266 [01:41<02:38,  1.00it/s]Loading trainS:  41%|████      | 108/266 [01:41<02:18,  1.14it/s]Loading trainS:  41%|████      | 109/266 [01:42<02:13,  1.18it/s]Loading trainS:  41%|████▏     | 110/266 [01:43<02:07,  1.23it/s]Loading trainS:  42%|████▏     | 111/266 [01:43<01:49,  1.42it/s]Loading trainS:  42%|████▏     | 112/266 [01:44<01:38,  1.56it/s]Loading trainS:  42%|████▏     | 113/266 [01:45<01:37,  1.57it/s]Loading trainS:  43%|████▎     | 114/266 [01:45<01:48,  1.39it/s]Loading trainS:  43%|████▎     | 115/266 [01:46<01:46,  1.42it/s]Loading trainS:  44%|████▎     | 116/266 [01:47<01:35,  1.56it/s]Loading trainS:  44%|████▍     | 117/266 [01:47<01:46,  1.39it/s]Loading trainS:  44%|████▍     | 118/266 [01:48<01:52,  1.32it/s]Loading trainS:  45%|████▍     | 119/266 [01:49<01:42,  1.44it/s]Loading trainS:  45%|████▌     | 120/266 [01:50<01:51,  1.31it/s]Loading trainS:  45%|████▌     | 121/266 [01:51<02:10,  1.11it/s]Loading trainS:  46%|████▌     | 122/266 [01:52<02:02,  1.18it/s]Loading trainS:  46%|████▌     | 123/266 [01:53<02:17,  1.04it/s]Loading trainS:  47%|████▋     | 124/266 [01:54<02:23,  1.01s/it]Loading trainS:  47%|████▋     | 125/266 [01:55<02:36,  1.11s/it]Loading trainS:  47%|████▋     | 126/266 [01:56<02:29,  1.07s/it]Loading trainS:  48%|████▊     | 127/266 [01:57<02:18,  1.01it/s]Loading trainS:  48%|████▊     | 128/266 [01:58<02:13,  1.04it/s]Loading trainS:  48%|████▊     | 129/266 [01:59<02:01,  1.13it/s]Loading trainS:  49%|████▉     | 130/266 [01:59<01:44,  1.31it/s]Loading trainS:  49%|████▉     | 131/266 [02:00<01:50,  1.22it/s]Loading trainS:  50%|████▉     | 132/266 [02:01<02:00,  1.11it/s]Loading trainS:  50%|█████     | 133/266 [02:02<01:51,  1.19it/s]Loading trainS:  50%|█████     | 134/266 [02:03<01:55,  1.14it/s]Loading trainS:  51%|█████     | 135/266 [02:04<01:59,  1.09it/s]Loading trainS:  51%|█████     | 136/266 [02:05<01:48,  1.19it/s]Loading trainS:  52%|█████▏    | 137/266 [02:05<01:45,  1.22it/s]Loading trainS:  52%|█████▏    | 138/266 [02:06<01:30,  1.41it/s]Loading trainS:  52%|█████▏    | 139/266 [02:07<01:40,  1.26it/s]Loading trainS:  53%|█████▎    | 140/266 [02:08<01:43,  1.22it/s]Loading trainS:  53%|█████▎    | 141/266 [02:09<01:43,  1.20it/s]Loading trainS:  53%|█████▎    | 142/266 [02:09<01:32,  1.34it/s]Loading trainS:  54%|█████▍    | 143/266 [02:10<01:24,  1.46it/s]Loading trainS:  54%|█████▍    | 144/266 [02:10<01:21,  1.49it/s]Loading trainS:  55%|█████▍    | 145/266 [02:11<01:26,  1.41it/s]Loading trainS:  55%|█████▍    | 146/266 [02:12<01:18,  1.54it/s]Loading trainS:  55%|█████▌    | 147/266 [02:12<01:23,  1.42it/s]Loading trainS:  56%|█████▌    | 148/266 [02:13<01:31,  1.30it/s]Loading trainS:  56%|█████▌    | 149/266 [02:14<01:23,  1.40it/s]Loading trainS:  56%|█████▋    | 150/266 [02:15<01:32,  1.25it/s]Loading trainS:  57%|█████▋    | 151/266 [02:16<01:37,  1.17it/s]Loading trainS:  57%|█████▋    | 152/266 [02:17<01:36,  1.19it/s]Loading trainS:  58%|█████▊    | 153/266 [02:18<01:34,  1.20it/s]Loading trainS:  58%|█████▊    | 154/266 [02:18<01:34,  1.19it/s]Loading trainS:  58%|█████▊    | 155/266 [02:19<01:38,  1.13it/s]Loading trainS:  59%|█████▊    | 156/266 [02:20<01:39,  1.11it/s]Loading trainS:  59%|█████▉    | 157/266 [02:21<01:42,  1.06it/s]Loading trainS:  59%|█████▉    | 158/266 [02:22<01:43,  1.04it/s]Loading trainS:  60%|█████▉    | 159/266 [02:24<01:47,  1.01s/it]Loading trainS:  60%|██████    | 160/266 [02:25<01:49,  1.04s/it]Loading trainS:  61%|██████    | 161/266 [02:26<01:43,  1.01it/s]Loading trainS:  61%|██████    | 162/266 [02:27<01:48,  1.04s/it]Loading trainS:  61%|██████▏   | 163/266 [02:27<01:38,  1.05it/s]Loading trainS:  62%|██████▏   | 164/266 [02:28<01:32,  1.10it/s]Loading trainS:  62%|██████▏   | 165/266 [02:29<01:31,  1.10it/s]Loading trainS:  62%|██████▏   | 166/266 [02:30<01:27,  1.14it/s]Loading trainS:  63%|██████▎   | 167/266 [02:31<01:29,  1.10it/s]Loading trainS:  63%|██████▎   | 168/266 [02:32<01:22,  1.19it/s]Loading trainS:  64%|██████▎   | 169/266 [02:32<01:22,  1.18it/s]Loading trainS:  64%|██████▍   | 170/266 [02:33<01:18,  1.23it/s]Loading trainS:  64%|██████▍   | 171/266 [02:34<01:17,  1.23it/s]Loading trainS:  65%|██████▍   | 172/266 [02:35<01:20,  1.16it/s]Loading trainS:  65%|██████▌   | 173/266 [02:36<01:28,  1.05it/s]Loading trainS:  65%|██████▌   | 174/266 [02:37<01:31,  1.01it/s]Loading trainS:  66%|██████▌   | 175/266 [02:38<01:32,  1.02s/it]Loading trainS:  66%|██████▌   | 176/266 [02:39<01:33,  1.04s/it]Loading trainS:  67%|██████▋   | 177/266 [02:40<01:29,  1.01s/it]Loading trainS:  67%|██████▋   | 178/266 [02:41<01:19,  1.11it/s]Loading trainS:  67%|██████▋   | 179/266 [02:42<01:19,  1.10it/s]Loading trainS:  68%|██████▊   | 180/266 [02:43<01:14,  1.15it/s]Loading trainS:  68%|██████▊   | 181/266 [02:44<01:15,  1.13it/s]Loading trainS:  68%|██████▊   | 182/266 [02:45<01:18,  1.07it/s]Loading trainS:  69%|██████▉   | 183/266 [02:45<01:13,  1.13it/s]Loading trainS:  69%|██████▉   | 184/266 [02:46<01:08,  1.20it/s]Loading trainS:  70%|██████▉   | 185/266 [02:47<01:03,  1.27it/s]Loading trainS:  70%|██████▉   | 186/266 [02:48<01:02,  1.28it/s]Loading trainS:  70%|███████   | 187/266 [02:49<01:10,  1.12it/s]Loading trainS:  71%|███████   | 188/266 [02:50<01:13,  1.06it/s]Loading trainS:  71%|███████   | 189/266 [02:51<01:16,  1.01it/s]Loading trainS:  71%|███████▏  | 190/266 [02:52<01:16,  1.01s/it]Loading trainS:  72%|███████▏  | 191/266 [02:53<01:14,  1.01it/s]Loading trainS:  72%|███████▏  | 192/266 [02:54<01:14,  1.00s/it]Loading trainS:  73%|███████▎  | 193/266 [02:55<01:08,  1.06it/s]Loading trainS:  73%|███████▎  | 194/266 [02:56<01:10,  1.02it/s]Loading trainS:  73%|███████▎  | 195/266 [02:57<01:08,  1.04it/s]Loading trainS:  74%|███████▎  | 196/266 [02:58<01:10,  1.01s/it]Loading trainS:  74%|███████▍  | 197/266 [02:59<01:12,  1.05s/it]Loading trainS:  74%|███████▍  | 198/266 [03:00<01:10,  1.04s/it]Loading trainS:  75%|███████▍  | 199/266 [03:01<01:08,  1.03s/it]Loading trainS:  75%|███████▌  | 200/266 [03:02<01:09,  1.05s/it]Loading trainS:  76%|███████▌  | 201/266 [03:03<01:06,  1.03s/it]Loading trainS:  76%|███████▌  | 202/266 [03:04<01:03,  1.01it/s]Loading trainS:  76%|███████▋  | 203/266 [03:05<01:05,  1.03s/it]Loading trainS:  77%|███████▋  | 204/266 [03:06<01:04,  1.04s/it]Loading trainS:  77%|███████▋  | 205/266 [03:07<01:02,  1.03s/it]Loading trainS:  77%|███████▋  | 206/266 [03:08<01:00,  1.00s/it]Loading trainS:  78%|███████▊  | 207/266 [03:09<00:59,  1.01s/it]Loading trainS:  78%|███████▊  | 208/266 [03:10<01:03,  1.09s/it]Loading trainS:  79%|███████▊  | 209/266 [03:11<00:57,  1.01s/it]Loading trainS:  79%|███████▉  | 210/266 [03:12<00:57,  1.03s/it]Loading trainS:  79%|███████▉  | 211/266 [03:13<00:53,  1.02it/s]Loading trainS:  80%|███████▉  | 212/266 [03:14<00:52,  1.03it/s]Loading trainS:  80%|████████  | 213/266 [03:15<00:52,  1.02it/s]Loading trainS:  80%|████████  | 214/266 [03:16<00:51,  1.02it/s]Loading trainS:  81%|████████  | 215/266 [03:17<00:48,  1.05it/s]Loading trainS:  81%|████████  | 216/266 [03:17<00:40,  1.24it/s]Loading trainS:  82%|████████▏ | 217/266 [03:18<00:42,  1.17it/s]Loading trainS:  82%|████████▏ | 218/266 [03:19<00:38,  1.23it/s]Loading trainS:  82%|████████▏ | 219/266 [03:20<00:34,  1.34it/s]Loading trainS:  83%|████████▎ | 220/266 [03:21<00:34,  1.33it/s]Loading trainS:  83%|████████▎ | 221/266 [03:21<00:33,  1.35it/s]Loading trainS:  83%|████████▎ | 222/266 [03:22<00:37,  1.18it/s]Loading trainS:  84%|████████▍ | 223/266 [03:23<00:39,  1.10it/s]Loading trainS:  84%|████████▍ | 224/266 [03:24<00:39,  1.08it/s]Loading trainS:  85%|████████▍ | 225/266 [03:25<00:38,  1.06it/s]Loading trainS:  85%|████████▍ | 226/266 [03:26<00:33,  1.19it/s]Loading trainS:  85%|████████▌ | 227/266 [03:27<00:29,  1.31it/s]Loading trainS:  86%|████████▌ | 228/266 [03:27<00:30,  1.23it/s]Loading trainS:  86%|████████▌ | 229/266 [03:28<00:28,  1.30it/s]Loading trainS:  86%|████████▋ | 230/266 [03:29<00:26,  1.36it/s]Loading trainS:  87%|████████▋ | 231/266 [03:30<00:30,  1.15it/s]Loading trainS:  87%|████████▋ | 232/266 [03:31<00:33,  1.02it/s]Loading trainS:  88%|████████▊ | 233/266 [03:32<00:28,  1.14it/s]Loading trainS:  88%|████████▊ | 234/266 [03:33<00:27,  1.18it/s]Loading trainS:  88%|████████▊ | 235/266 [03:33<00:23,  1.34it/s]Loading trainS:  89%|████████▊ | 236/266 [03:34<00:22,  1.33it/s]Loading trainS:  89%|████████▉ | 237/266 [03:35<00:22,  1.31it/s]Loading trainS:  89%|████████▉ | 238/266 [03:35<00:21,  1.30it/s]Loading trainS:  90%|████████▉ | 239/266 [03:36<00:19,  1.40it/s]Loading trainS:  90%|█████████ | 240/266 [03:37<00:20,  1.28it/s]Loading trainS:  91%|█████████ | 241/266 [03:38<00:20,  1.23it/s]Loading trainS:  91%|█████████ | 242/266 [03:39<00:18,  1.28it/s]Loading trainS:  91%|█████████▏| 243/266 [03:39<00:17,  1.32it/s]Loading trainS:  92%|█████████▏| 244/266 [03:40<00:14,  1.51it/s]Loading trainS:  92%|█████████▏| 245/266 [03:40<00:13,  1.60it/s]Loading trainS:  92%|█████████▏| 246/266 [03:41<00:11,  1.78it/s]Loading trainS:  93%|█████████▎| 247/266 [03:41<00:12,  1.57it/s]Loading trainS:  93%|█████████▎| 248/266 [03:42<00:11,  1.60it/s]Loading trainS:  94%|█████████▎| 249/266 [03:43<00:10,  1.59it/s]Loading trainS:  94%|█████████▍| 250/266 [03:43<00:09,  1.77it/s]Loading trainS:  94%|█████████▍| 251/266 [03:44<00:09,  1.63it/s]Loading trainS:  95%|█████████▍| 252/266 [03:45<00:09,  1.53it/s]Loading trainS:  95%|█████████▌| 253/266 [03:45<00:07,  1.66it/s]Loading trainS:  95%|█████████▌| 254/266 [03:46<00:07,  1.59it/s]Loading trainS:  96%|█████████▌| 255/266 [03:46<00:06,  1.58it/s]Loading trainS:  96%|█████████▌| 256/266 [03:47<00:06,  1.46it/s]Loading trainS:  97%|█████████▋| 257/266 [03:48<00:06,  1.29it/s]Loading trainS:  97%|█████████▋| 258/266 [03:49<00:06,  1.27it/s]Loading trainS:  97%|█████████▋| 259/266 [03:49<00:04,  1.48it/s]Loading trainS:  98%|█████████▊| 260/266 [03:50<00:04,  1.42it/s]Loading trainS:  98%|█████████▊| 261/266 [03:51<00:03,  1.53it/s]Loading trainS:  98%|█████████▊| 262/266 [03:51<00:02,  1.59it/s]Loading trainS:  99%|█████████▉| 263/266 [03:52<00:01,  1.52it/s]Loading trainS:  99%|█████████▉| 264/266 [03:53<00:01,  1.48it/s]Loading trainS: 100%|█████████▉| 265/266 [03:53<00:00,  1.68it/s]Loading trainS: 100%|██████████| 266/266 [03:54<00:00,  1.55it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.72it/s]Loading testS:  40%|████      | 2/5 [00:01<00:01,  1.51it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.59it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.53it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.79it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:09,  4.54it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.87it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  5.07it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.66it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.32it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  4.65it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.79it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:04,  5.42it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.59it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  3.95it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.12it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.70it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.40it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.14it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.72it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.07it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.05it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:05<00:00,  7.47it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  6.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  6.03it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.94it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 40s - loss: 0.3444 - acc: 0.9224 - mDice: 0.6510 - val_loss: 0.6416 - val_acc: 0.9882 - val_mDice: 0.6361

Epoch 00001: val_mDice improved from -inf to 0.63610, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 35s - loss: 0.0824 - acc: 0.9912 - mDice: 0.8529 - val_loss: 0.7783 - val_acc: 0.9899 - val_mDice: 0.7566

Epoch 00002: val_mDice improved from 0.63610 to 0.75661, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 35s - loss: 0.0689 - acc: 0.9925 - mDice: 0.8754 - val_loss: 0.4248 - val_acc: 0.9922 - val_mDice: 0.7956

Epoch 00003: val_mDice improved from 0.75661 to 0.79562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 35s - loss: 0.0619 - acc: 0.9931 - mDice: 0.8873 - val_loss: 0.7112 - val_acc: 0.9914 - val_mDice: 0.7866

Epoch 00004: val_mDice did not improve from 0.79562
Epoch 5/300
 - 35s - loss: 0.0565 - acc: 0.9936 - mDice: 0.8964 - val_loss: 0.3079 - val_acc: 0.9933 - val_mDice: 0.8123

Epoch 00005: val_mDice improved from 0.79562 to 0.81234, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 35s - loss: 0.0540 - acc: 0.9938 - mDice: 0.9008 - val_loss: 0.7518 - val_acc: 0.9921 - val_mDice: 0.7918

Epoch 00006: val_mDice did not improve from 0.81234
Epoch 7/300
 - 45s - loss: 0.0503 - acc: 0.9941 - mDice: 0.9072 - val_loss: 0.6430 - val_acc: 0.9925 - val_mDice: 0.8029

Epoch 00007: val_mDice did not improve from 0.81234
Epoch 8/300
 - 51s - loss: 0.0490 - acc: 0.9943 - mDice: 0.9096 - val_loss: 0.6500 - val_acc: 0.9931 - val_mDice: 0.8141

Epoch 00008: val_mDice improved from 0.81234 to 0.81413, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 52s - loss: 0.0464 - acc: 0.9945 - mDice: 0.9141 - val_loss: 0.2897 - val_acc: 0.9936 - val_mDice: 0.8152

Epoch 00009: val_mDice improved from 0.81413 to 0.81518, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 52s - loss: 0.0445 - acc: 0.9947 - mDice: 0.9175 - val_loss: 0.7628 - val_acc: 0.9907 - val_mDice: 0.7728

Epoch 00010: val_mDice did not improve from 0.81518
Epoch 11/300
 - 54s - loss: 0.0428 - acc: 0.9948 - mDice: 0.9205 - val_loss: 0.5481 - val_acc: 0.9934 - val_mDice: 0.8158

Epoch 00011: val_mDice improved from 0.81518 to 0.81578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 38s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9219 - val_loss: 0.5521 - val_acc: 0.9931 - val_mDice: 0.8048

Epoch 00012: val_mDice did not improve from 0.81578
Epoch 13/300
 - 38s - loss: 0.0405 - acc: 0.9950 - mDice: 0.9247 - val_loss: 0.6920 - val_acc: 0.9921 - val_mDice: 0.8003

Epoch 00013: val_mDice did not improve from 0.81578
Epoch 14/300
 - 38s - loss: 0.0394 - acc: 0.9951 - mDice: 0.9266 - val_loss: 0.6594 - val_acc: 0.9930 - val_mDice: 0.8109

Epoch 00014: val_mDice did not improve from 0.81578
Epoch 15/300
 - 38s - loss: 0.0386 - acc: 0.9952 - mDice: 0.9280 - val_loss: 0.2919 - val_acc: 0.9937 - val_mDice: 0.8205

Epoch 00015: val_mDice improved from 0.81578 to 0.82048, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 38s - loss: 0.0382 - acc: 0.9952 - mDice: 0.9288 - val_loss: 0.2981 - val_acc: 0.9931 - val_mDice: 0.7997

Epoch 00016: val_mDice did not improve from 0.82048
Epoch 17/300
 - 38s - loss: 0.0372 - acc: 0.9954 - mDice: 0.9305 - val_loss: 0.2899 - val_acc: 0.9939 - val_mDice: 0.8244

Epoch 00017: val_mDice improved from 0.82048 to 0.82444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 38s - loss: 0.0362 - acc: 0.9954 - mDice: 0.9324 - val_loss: 0.7404 - val_acc: 0.9914 - val_mDice: 0.7838

Epoch 00018: val_mDice did not improve from 0.82444
Epoch 19/300
 - 38s - loss: 0.0355 - acc: 0.9955 - mDice: 0.9336 - val_loss: 0.6646 - val_acc: 0.9925 - val_mDice: 0.8057

Epoch 00019: val_mDice did not improve from 0.82444
Epoch 20/300
 - 38s - loss: 0.0349 - acc: 0.9956 - mDice: 0.9346 - val_loss: 0.2766 - val_acc: 0.9934 - val_mDice: 0.8178

Epoch 00020: val_mDice did not improve from 0.82444
Epoch 21/300
 - 38s - loss: 0.0351 - acc: 0.9956 - mDice: 0.9344 - val_loss: 0.2578 - val_acc: 0.9937 - val_mDice: 0.8211

Epoch 00021: val_mDice did not improve from 0.82444
Epoch 22/300
 - 38s - loss: 0.0345 - acc: 0.9956 - mDice: 0.9354 - val_loss: 0.2992 - val_acc: 0.9917 - val_mDice: 0.7562

Epoch 00022: val_mDice did not improve from 0.82444
Epoch 23/300
 - 38s - loss: 0.0337 - acc: 0.9957 - mDice: 0.9369 - val_loss: 0.5826 - val_acc: 0.9936 - val_mDice: 0.8204

Epoch 00023: val_mDice did not improve from 0.82444
Epoch 24/300
 - 38s - loss: 0.0333 - acc: 0.9957 - mDice: 0.9375 - val_loss: 0.2054 - val_acc: 0.9933 - val_mDice: 0.8157

Epoch 00024: val_mDice did not improve from 0.82444
Epoch 25/300
 - 38s - loss: 0.0330 - acc: 0.9958 - mDice: 0.9381 - val_loss: 0.3286 - val_acc: 0.9932 - val_mDice: 0.8190

Epoch 00025: val_mDice did not improve from 0.82444
Epoch 26/300
 - 37s - loss: 0.0327 - acc: 0.9958 - mDice: 0.9388 - val_loss: 0.6496 - val_acc: 0.9933 - val_mDice: 0.8173

Epoch 00026: val_mDice did not improve from 0.82444
Epoch 27/300
 - 37s - loss: 0.0323 - acc: 0.9958 - mDice: 0.9395 - val_loss: 0.2918 - val_acc: 0.9912 - val_mDice: 0.7339

Epoch 00027: val_mDice did not improve from 0.82444
Epoch 28/300
 - 38s - loss: 0.0320 - acc: 0.9959 - mDice: 0.9400 - val_loss: 0.1812 - val_acc: 0.9935 - val_mDice: 0.8201

Epoch 00028: val_mDice did not improve from 0.82444
Epoch 29/300
 - 37s - loss: 0.0319 - acc: 0.9959 - mDice: 0.9401 - val_loss: 0.2714 - val_acc: 0.9900 - val_mDice: 0.6897

Epoch 00029: val_mDice did not improve from 0.82444
Epoch 30/300
 - 37s - loss: 0.0315 - acc: 0.9959 - mDice: 0.9408 - val_loss: 0.6835 - val_acc: 0.9920 - val_mDice: 0.8007

Epoch 00030: val_mDice did not improve from 0.82444
Epoch 31/300
 - 37s - loss: 0.0312 - acc: 0.9959 - mDice: 0.9414 - val_loss: 0.6940 - val_acc: 0.9926 - val_mDice: 0.8052

Epoch 00031: val_mDice did not improve from 0.82444
Epoch 32/300
 - 37s - loss: 0.0306 - acc: 0.9960 - mDice: 0.9425 - val_loss: 0.1764 - val_acc: 0.9934 - val_mDice: 0.8113

Epoch 00032: val_mDice did not improve from 0.82444
Epoch 33/300
 - 37s - loss: 0.0311 - acc: 0.9959 - mDice: 0.9416 - val_loss: 0.5811 - val_acc: 0.9937 - val_mDice: 0.8209

Epoch 00033: val_mDice did not improve from 0.82444
Epoch 34/300
 - 37s - loss: 0.0305 - acc: 0.9960 - mDice: 0.9426 - val_loss: 0.5508 - val_acc: 0.9936 - val_mDice: 0.8196

Epoch 00034: val_mDice did not improve from 0.82444
Epoch 35/300
 - 38s - loss: 0.0303 - acc: 0.9960 - mDice: 0.9431 - val_loss: 0.6024 - val_acc: 0.9935 - val_mDice: 0.8218

Epoch 00035: val_mDice did not improve from 0.82444
Epoch 36/300
 - 37s - loss: 0.0301 - acc: 0.9960 - mDice: 0.9433 - val_loss: 0.6578 - val_acc: 0.9923 - val_mDice: 0.8055

Epoch 00036: val_mDice did not improve from 0.82444
Epoch 37/300
 - 37s - loss: 0.0297 - acc: 0.9961 - mDice: 0.9442 - val_loss: 0.7387 - val_acc: 0.9914 - val_mDice: 0.7861

Epoch 00037: val_mDice did not improve from 0.82444
Epoch 38/300
 - 37s - loss: 0.0297 - acc: 0.9961 - mDice: 0.9441 - val_loss: 0.6822 - val_acc: 0.9927 - val_mDice: 0.8108

Epoch 00038: val_mDice did not improve from 0.82444
Epoch 39/300
 - 37s - loss: 0.0293 - acc: 0.9961 - mDice: 0.9448 - val_loss: 0.0877 - val_acc: 0.9932 - val_mDice: 0.8172

Epoch 00039: val_mDice did not improve from 0.82444
Epoch 40/300
 - 37s - loss: 0.0294 - acc: 0.9961 - mDice: 0.9447 - val_loss: 0.1363 - val_acc: 0.9930 - val_mDice: 0.7955

Epoch 00040: val_mDice did not improve from 0.82444
Epoch 41/300
 - 37s - loss: 0.0288 - acc: 0.9962 - mDice: 0.9459 - val_loss: 0.7470 - val_acc: 0.9912 - val_mDice: 0.7922

Epoch 00041: val_mDice did not improve from 0.82444
Epoch 42/300
 - 37s - loss: 0.0287 - acc: 0.9962 - mDice: 0.9460 - val_loss: 0.0930 - val_acc: 0.9940 - val_mDice: 0.8198

Epoch 00042: val_mDice did not improve from 0.82444
Epoch 43/300
 - 37s - loss: 0.0288 - acc: 0.9961 - mDice: 0.9457 - val_loss: 0.0959 - val_acc: 0.9937 - val_mDice: 0.8185

Epoch 00043: val_mDice did not improve from 0.82444
Epoch 44/300
 - 37s - loss: 0.0286 - acc: 0.9962 - mDice: 0.9462 - val_loss: 0.0702 - val_acc: 0.9932 - val_mDice: 0.8192

Epoch 00044: val_mDice did not improve from 0.82444
Epoch 45/300
 - 37s - loss: 0.0286 - acc: 0.9962 - mDice: 0.9462 - val_loss: 0.3943 - val_acc: 0.9937 - val_mDice: 0.8186

Epoch 00045: val_mDice did not improve from 0.82444
Epoch 46/300
 - 37s - loss: 0.0282 - acc: 0.9962 - mDice: 0.9469 - val_loss: 0.1832 - val_acc: 0.9909 - val_mDice: 0.7235

Epoch 00046: val_mDice did not improve from 0.82444
Epoch 47/300
 - 37s - loss: 0.0283 - acc: 0.9962 - mDice: 0.9467 - val_loss: 0.5467 - val_acc: 0.9937 - val_mDice: 0.8224

Epoch 00047: val_mDice did not improve from 0.82444
Epoch 48/300
 - 37s - loss: 0.0280 - acc: 0.9963 - mDice: 0.9473 - val_loss: 0.0628 - val_acc: 0.9934 - val_mDice: 0.8168

Epoch 00048: val_mDice did not improve from 0.82444
Epoch 49/300
 - 37s - loss: 0.0280 - acc: 0.9962 - mDice: 0.9472 - val_loss: 0.6010 - val_acc: 0.9928 - val_mDice: 0.8135

Epoch 00049: val_mDice did not improve from 0.82444
Epoch 50/300
 - 37s - loss: 0.0278 - acc: 0.9963 - mDice: 0.9477 - val_loss: 0.3537 - val_acc: 0.9923 - val_mDice: 0.7738

Epoch 00050: val_mDice did not improve from 0.82444
Epoch 51/300
 - 37s - loss: 0.0275 - acc: 0.9963 - mDice: 0.9482 - val_loss: 0.6671 - val_acc: 0.9921 - val_mDice: 0.8037

Epoch 00051: val_mDice did not improve from 0.82444
Epoch 52/300
 - 37s - loss: 0.0277 - acc: 0.9963 - mDice: 0.9479 - val_loss: 0.0500 - val_acc: 0.9934 - val_mDice: 0.8118

Epoch 00052: val_mDice did not improve from 0.82444
Epoch 53/300
 - 37s - loss: 0.0273 - acc: 0.9963 - mDice: 0.9485 - val_loss: 0.0845 - val_acc: 0.9939 - val_mDice: 0.8207

Epoch 00053: val_mDice did not improve from 0.82444
Epoch 54/300
 - 37s - loss: 0.0277 - acc: 0.9963 - mDice: 0.9478 - val_loss: 0.6214 - val_acc: 0.9922 - val_mDice: 0.8028

Epoch 00054: val_mDice did not improve from 0.82444
Epoch 55/300
 - 37s - loss: 0.0273 - acc: 0.9963 - mDice: 0.9486 - val_loss: 0.6799 - val_acc: 0.9931 - val_mDice: 0.8166

Epoch 00055: val_mDice did not improve from 0.82444
Epoch 56/300
 - 37s - loss: 0.0272 - acc: 0.9963 - mDice: 0.9488 - val_loss: 0.5964 - val_acc: 0.9938 - val_mDice: 0.8198

Epoch 00056: val_mDice did not improve from 0.82444
Epoch 57/300
 - 37s - loss: 0.0269 - acc: 0.9964 - mDice: 0.9493 - val_loss: 0.5875 - val_acc: 0.9939 - val_mDice: 0.8245

Epoch 00057: val_mDice improved from 0.82444 to 0.82452, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 58/300
 - 37s - loss: 0.0268 - acc: 0.9964 - mDice: 0.9496 - val_loss: 0.5917 - val_acc: 0.9933 - val_mDice: 0.8178

Epoch 00058: val_mDice did not improve from 0.82452
Epoch 59/300
 - 37s - loss: 0.0268 - acc: 0.9964 - mDice: 0.9496 - val_loss: 0.8238 - val_acc: 0.9888 - val_mDice: 0.7529

Epoch 00059: val_mDice did not improve from 0.82452
Epoch 60/300
 - 38s - loss: 0.0268 - acc: 0.9964 - mDice: 0.9494 - val_loss: 0.6938 - val_acc: 0.9933 - val_mDice: 0.8179

Epoch 00060: val_mDice did not improve from 0.82452
Epoch 61/300
 - 37s - loss: 0.0270 - acc: 0.9963 - mDice: 0.9492 - val_loss: 0.6070 - val_acc: 0.9937 - val_mDice: 0.8214

Epoch 00061: val_mDice did not improve from 0.82452
Epoch 62/300
 - 37s - loss: 0.0268 - acc: 0.9964 - mDice: 0.9495 - val_loss: 0.6868 - val_acc: 0.9934 - val_mDice: 0.8134

Epoch 00062: val_mDice did not improve from 0.82452
Epoch 63/300
 - 37s - loss: 0.0263 - acc: 0.9964 - mDice: 0.9505 - val_loss: 0.6601 - val_acc: 0.9917 - val_mDice: 0.7504

Epoch 00063: val_mDice did not improve from 0.82452
Epoch 64/300
 - 37s - loss: 0.0265 - acc: 0.9964 - mDice: 0.9501 - val_loss: 0.0433 - val_acc: 0.9936 - val_mDice: 0.8214

Epoch 00064: val_mDice did not improve from 0.82452
Epoch 65/300
 - 38s - loss: 0.0262 - acc: 0.9964 - mDice: 0.9507 - val_loss: 0.6060 - val_acc: 0.9928 - val_mDice: 0.8139

Epoch 00065: val_mDice did not improve from 0.82452
Epoch 66/300
 - 37s - loss: 0.0263 - acc: 0.9964 - mDice: 0.9505 - val_loss: 0.0545 - val_acc: 0.9934 - val_mDice: 0.8053

Epoch 00066: val_mDice did not improve from 0.82452
Epoch 67/300
 - 37s - loss: 0.0261 - acc: 0.9964 - mDice: 0.9509 - val_loss: 0.3318 - val_acc: 0.9934 - val_mDice: 0.8149

Epoch 00067: val_mDice did not improve from 0.82452
Epoch 68/300
 - 37s - loss: 0.0260 - acc: 0.9964 - mDice: 0.9510 - val_loss: 0.5273 - val_acc: 0.9934 - val_mDice: 0.8158

Epoch 00068: val_mDice did not improve from 0.82452
Epoch 69/300
 - 37s - loss: 0.0260 - acc: 0.9964 - mDice: 0.9510 - val_loss: 0.7205 - val_acc: 0.9926 - val_mDice: 0.8104

Epoch 00069: val_mDice did not improve from 0.82452
Epoch 70/300
 - 37s - loss: 0.0259 - acc: 0.9964 - mDice: 0.9511 - val_loss: 0.5558 - val_acc: 0.9926 - val_mDice: 0.8119

Epoch 00070: val_mDice did not improve from 0.82452
Epoch 71/300
 - 37s - loss: 0.0260 - acc: 0.9964 - mDice: 0.9510 - val_loss: 0.0444 - val_acc: 0.9931 - val_mDice: 0.8198

Epoch 00071: val_mDice did not improve from 0.82452
Epoch 72/300
 - 37s - loss: 0.0259 - acc: 0.9964 - mDice: 0.9512 - val_loss: 0.7335 - val_acc: 0.9928 - val_mDice: 0.7938

Epoch 00072: val_mDice did not improve from 0.82452
Epoch 73/300
 - 37s - loss: 0.0257 - acc: 0.9965 - mDice: 0.9515 - val_loss: 0.6318 - val_acc: 0.9928 - val_mDice: 0.7896

Epoch 00073: val_mDice did not improve from 0.82452
Epoch 74/300
 - 37s - loss: 0.0257 - acc: 0.9965 - mDice: 0.9515 - val_loss: 0.0469 - val_acc: 0.9936 - val_mDice: 0.8170

Epoch 00074: val_mDice did not improve from 0.82452
Epoch 75/300
 - 37s - loss: 0.0257 - acc: 0.9965 - mDice: 0.9515 - val_loss: 0.2405 - val_acc: 0.9937 - val_mDice: 0.8205

Epoch 00075: val_mDice did not improve from 0.82452
Epoch 76/300
 - 37s - loss: 0.0256 - acc: 0.9965 - mDice: 0.9518 - val_loss: 0.7656 - val_acc: 0.9919 - val_mDice: 0.8011

Epoch 00076: val_mDice did not improve from 0.82452
Epoch 77/300
 - 37s - loss: 0.0253 - acc: 0.9965 - mDice: 0.9522 - val_loss: 0.6797 - val_acc: 0.9929 - val_mDice: 0.8148

Epoch 00077: val_mDice did not improve from 0.82452
Epoch 78/300
 - 37s - loss: 0.0255 - acc: 0.9965 - mDice: 0.9519 - val_loss: 0.6009 - val_acc: 0.9936 - val_mDice: 0.8195

Epoch 00078: val_mDice did not improve from 0.82452
Epoch 79/300
 - 37s - loss: 0.0252 - acc: 0.9965 - mDice: 0.9525 - val_loss: 0.5434 - val_acc: 0.9936 - val_mDice: 0.8206

Epoch 00079: val_mDice did not improve from 0.82452
Epoch 80/300
 - 37s - loss: 0.0253 - acc: 0.9965 - mDice: 0.9523 - val_loss: 0.7622 - val_acc: 0.9914 - val_mDice: 0.7956

Epoch 00080: val_mDice did not improve from 0.82452
Epoch 81/300
 - 37s - loss: 0.0253 - acc: 0.9965 - mDice: 0.9523 - val_loss: 0.5466 - val_acc: 0.9935 - val_mDice: 0.8256

Epoch 00081: val_mDice improved from 0.82452 to 0.82564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 82/300
 - 36s - loss: 0.0251 - acc: 0.9965 - mDice: 0.9527 - val_loss: 0.0445 - val_acc: 0.9936 - val_mDice: 0.8179

Epoch 00082: val_mDice did not improve from 0.82564
Epoch 83/300
 - 36s - loss: 0.0252 - acc: 0.9965 - mDice: 0.9524 - val_loss: 0.6216 - val_acc: 0.9934 - val_mDice: 0.8205

Epoch 00083: val_mDice did not improve from 0.82564
Epoch 84/300
 - 35s - loss: 0.0250 - acc: 0.9965 - mDice: 0.9527 - val_loss: 0.6071 - val_acc: 0.9932 - val_mDice: 0.8041

Epoch 00084: val_mDice did not improve from 0.82564
Epoch 85/300
 - 36s - loss: 0.0250 - acc: 0.9965 - mDice: 0.9527 - val_loss: 0.7708 - val_acc: 0.9917 - val_mDice: 0.8015

Epoch 00085: val_mDice did not improve from 0.82564
Epoch 86/300
 - 35s - loss: 0.0252 - acc: 0.9965 - mDice: 0.9525 - val_loss: 0.6052 - val_acc: 0.9936 - val_mDice: 0.8229

Epoch 00086: val_mDice did not improve from 0.82564
Epoch 87/300
 - 35s - loss: 0.0249 - acc: 0.9965 - mDice: 0.9529 - val_loss: 0.7004 - val_acc: 0.9927 - val_mDice: 0.8103

Epoch 00087: val_mDice did not improve from 0.82564
Epoch 88/300
 - 35s - loss: 0.0248 - acc: 0.9965 - mDice: 0.9532 - val_loss: 0.6206 - val_acc: 0.9936 - val_mDice: 0.8214

Epoch 00088: val_mDice did not improve from 0.82564
Epoch 89/300
 - 35s - loss: 0.0248 - acc: 0.9966 - mDice: 0.9533 - val_loss: 0.6178 - val_acc: 0.9934 - val_mDice: 0.8153

Epoch 00089: val_mDice did not improve from 0.82564
Epoch 90/300
 - 35s - loss: 0.0250 - acc: 0.9965 - mDice: 0.9529 - val_loss: 0.0710 - val_acc: 0.9925 - val_mDice: 0.7800

Epoch 00090: val_mDice did not improve from 0.82564
Epoch 91/300
 - 36s - loss: 0.0250 - acc: 0.9965 - mDice: 0.9529 - val_loss: 0.6805 - val_acc: 0.9926 - val_mDice: 0.8099

Epoch 00091: val_mDice did not improve from 0.82564
Epoch 92/300
 - 35s - loss: 0.0246 - acc: 0.9965 - mDice: 0.9535 - val_loss: 0.6521 - val_acc: 0.9926 - val_mDice: 0.8136

Epoch 00092: val_mDice did not improve from 0.82564
Epoch 93/300
 - 35s - loss: 0.0248 - acc: 0.9966 - mDice: 0.9532 - val_loss: 0.6896 - val_acc: 0.9930 - val_mDice: 0.8152

Epoch 00093: val_mDice did not improve from 0.82564
Epoch 94/300
 - 36s - loss: 0.0245 - acc: 0.9966 - mDice: 0.9538 - val_loss: 0.7113 - val_acc: 0.9932 - val_mDice: 0.8184

Epoch 00094: val_mDice did not improve from 0.82564
Epoch 95/300
 - 36s - loss: 0.0247 - acc: 0.9966 - mDice: 0.9533 - val_loss: 0.6529 - val_acc: 0.9937 - val_mDice: 0.8232

Epoch 00095: val_mDice did not improve from 0.82564
Epoch 96/300
 - 36s - loss: 0.0246 - acc: 0.9966 - mDice: 0.9535 - val_loss: 0.0440 - val_acc: 0.9938 - val_mDice: 0.8202

Epoch 00096: val_mDice did not improve from 0.82564
Epoch 97/300
 - 37s - loss: 0.0244 - acc: 0.9966 - mDice: 0.9539 - val_loss: 0.0546 - val_acc: 0.9931 - val_mDice: 0.8017

Epoch 00097: val_mDice did not improve from 0.82564
Epoch 98/300
 - 38s - loss: 0.0243 - acc: 0.9966 - mDice: 0.9541 - val_loss: 0.6117 - val_acc: 0.9931 - val_mDice: 0.8186

Epoch 00098: val_mDice did not improve from 0.82564
Epoch 99/300
 - 36s - loss: 0.0245 - acc: 0.9966 - mDice: 0.9537 - val_loss: 0.5824 - val_acc: 0.9935 - val_mDice: 0.8217

Epoch 00099: val_mDice did not improve from 0.82564
Epoch 100/300
 - 36s - loss: 0.0244 - acc: 0.9966 - mDice: 0.9539 - val_loss: 0.0416 - val_acc: 0.9937 - val_mDice: 0.8229

Epoch 00100: val_mDice did not improve from 0.82564
Epoch 101/300
 - 35s - loss: 0.0242 - acc: 0.9966 - mDice: 0.9544 - val_loss: 0.5841 - val_acc: 0.9936 - val_mDice: 0.8128

Epoch 00101: val_mDice did not improve from 0.82564
Epoch 102/300
 - 35s - loss: 0.0244 - acc: 0.9966 - mDice: 0.9539 - val_loss: 0.5523 - val_acc: 0.9932 - val_mDice: 0.7987

Epoch 00102: val_mDice did not improve from 0.82564
Epoch 103/300
 - 35s - loss: 0.0243 - acc: 0.9966 - mDice: 0.9541 - val_loss: 0.7465 - val_acc: 0.9921 - val_mDice: 0.8031

Epoch 00103: val_mDice did not improve from 0.82564
Epoch 104/300
 - 35s - loss: 0.0242 - acc: 0.9966 - mDice: 0.9543 - val_loss: 0.6144 - val_acc: 0.9932 - val_mDice: 0.8194

Epoch 00104: val_mDice did not improve from 0.82564
Epoch 105/300
 - 35s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9548 - val_loss: 0.0728 - val_acc: 0.9925 - val_mDice: 0.7769

Epoch 00105: val_mDice did not improve from 0.82564
Epoch 106/300
 - 35s - loss: 0.0241 - acc: 0.9966 - mDice: 0.9545 - val_loss: 0.6007 - val_acc: 0.9934 - val_mDice: 0.8207

Epoch 00106: val_mDice did not improve from 0.82564
Epoch 107/300
 - 36s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9550 - val_loss: 0.6369 - val_acc: 0.9927 - val_mDice: 0.7950

Epoch 00107: val_mDice did not improve from 0.82564
Epoch 108/300
 - 36s - loss: 0.0240 - acc: 0.9966 - mDice: 0.9547 - val_loss: 0.0579 - val_acc: 0.9930 - val_mDice: 0.7978

Epoch 00108: val_mDice did not improve from 0.82564
Epoch 109/300
 - 36s - loss: 0.0241 - acc: 0.9966 - mDice: 0.9545 - val_loss: 0.6458 - val_acc: 0.9933 - val_mDice: 0.8092

Epoch 00109: val_mDice did not improve from 0.82564
Epoch 110/300
 - 37s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9549 - val_loss: 0.6111 - val_acc: 0.9936 - val_mDice: 0.8235

Epoch 00110: val_mDice did not improve from 0.82564
Epoch 111/300
 - 37s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9550 - val_loss: 0.0664 - val_acc: 0.9926 - val_mDice: 0.7855

Epoch 00111: val_mDice did not improve from 0.82564
Epoch 112/300
 - 37s - loss: 0.0240 - acc: 0.9966 - mDice: 0.9547 - val_loss: 0.6459 - val_acc: 0.9930 - val_mDice: 0.7942

Epoch 00112: val_mDice did not improve from 0.82564
Epoch 113/300
 - 37s - loss: 0.0240 - acc: 0.9966 - mDice: 0.9548 - val_loss: 0.7462 - val_acc: 0.9916 - val_mDice: 0.7987

Epoch 00113: val_mDice did not improve from 0.82564
Epoch 114/300
 - 37s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9549 - val_loss: 0.0723 - val_acc: 0.9924 - val_mDice: 0.7782

Epoch 00114: val_mDice did not improve from 0.82564
Epoch 115/300
 - 37s - loss: 0.0238 - acc: 0.9966 - mDice: 0.9551 - val_loss: 0.6769 - val_acc: 0.9931 - val_mDice: 0.8127

Epoch 00115: val_mDice did not improve from 0.82564
Epoch 116/300
 - 37s - loss: 0.0236 - acc: 0.9966 - mDice: 0.9554 - val_loss: 0.7669 - val_acc: 0.9911 - val_mDice: 0.7900

Epoch 00116: val_mDice did not improve from 0.82564
Epoch 117/300
 - 37s - loss: 0.0237 - acc: 0.9966 - mDice: 0.9552 - val_loss: 0.7475 - val_acc: 0.9920 - val_mDice: 0.7949

Epoch 00117: val_mDice did not improve from 0.82564
Epoch 118/300
 - 37s - loss: 0.0239 - acc: 0.9966 - mDice: 0.9550 - val_loss: 0.6082 - val_acc: 0.9934 - val_mDice: 0.8192

Epoch 00118: val_mDice did not improve from 0.82564
Epoch 119/300
 - 37s - loss: 0.0235 - acc: 0.9966 - mDice: 0.9555 - val_loss: 0.6550 - val_acc: 0.9935 - val_mDice: 0.8211

Epoch 00119: val_mDice did not improve from 0.82564
Epoch 120/300
 - 37s - loss: 0.0236 - acc: 0.9966 - mDice: 0.9555 - val_loss: 0.6650 - val_acc: 0.9935 - val_mDice: 0.8202

Epoch 00120: val_mDice did not improve from 0.82564
Epoch 121/300
 - 37s - loss: 0.0235 - acc: 0.9967 - mDice: 0.9557 - val_loss: 0.5739 - val_acc: 0.9936 - val_mDice: 0.8122

Epoch 00121: val_mDice did not improve from 0.82564
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
{'val_loss': [0.6416425360366702, 0.7783477999037132, 0.424793399637565, 0.7111522022169083, 0.30787614244036376, 0.7518392794299871, 0.6429993700003251, 0.650032656500116, 0.28968677355442196, 0.7628497608238831, 0.5481484855990857, 0.5521188590209931, 0.692030992358923, 0.659438040223904, 0.29193499486427754, 0.29812933586072177, 0.2898706628475338, 0.7403800740139559, 0.6646197328809649, 0.27663783088792115, 0.2577602941310033, 0.2992279869504273, 0.5825693984515965, 0.20540503307711333, 0.32860496547073126, 0.6495612270664424, 0.29183078662026674, 0.18117829435504973, 0.2713996797101572, 0.6834644970949739, 0.6940018980531022, 0.1764427290763706, 0.5810549865709618, 0.5507558251265436, 0.6023746818536893, 0.6577590806409717, 0.738709868164733, 0.6822407187428325, 0.08770437492057681, 0.13628722866997123, 0.746976172667928, 0.09303316008299589, 0.09586559992749244, 0.07017366786021739, 0.39426059927791357, 0.18323188635986298, 0.5467493882169947, 0.06283656600862741, 0.6009503466775641, 0.35372694104444236, 0.6670919132884592, 0.049980776268057525, 0.08451332699041814, 0.6214049974223599, 0.6798594403080642, 0.5964416491333395, 0.5874541238881648, 0.5917207847815007, 0.8237501070834696, 0.6937545835971832, 0.6069641194771975, 0.6867884749080986, 0.6600638567470014, 0.0432938999729231, 0.6059671972179785, 0.05451273708604276, 0.33175372215919197, 0.5272887861356139, 0.7205447730375454, 0.5558077449677512, 0.04443008406087756, 0.73354532266967, 0.6318206123542041, 0.04686968005262315, 0.24047296959906816, 0.7656242697266862, 0.6797273746924475, 0.6008964992361143, 0.5433656551176682, 0.7622499978169799, 0.5465677403844893, 0.04450520663522184, 0.6215596190886572, 0.6070629899622872, 0.7708189914701506, 0.6052496740594506, 0.7004268968012184, 0.6205923618981615, 0.6178270200034603, 0.07097756688017398, 0.6805323956068605, 0.6521118294913322, 0.6896046745823696, 0.7113001354737207, 0.6529299657559022, 0.043966860859654844, 0.054636725573800504, 0.6117036020150408, 0.5823516232194379, 0.04157493414822966, 0.5841381390346214, 0.5523233760613948, 0.7465375046012923, 0.6143914025742561, 0.07279256894253194, 0.6006760937161744, 0.6368625359609723, 0.05791167251300067, 0.6458412051433697, 0.6111057231901214, 0.0663741995813325, 0.6459324007155374, 0.7462022014660761, 0.07225975696928799, 0.6769398299511522, 0.7669398922007531, 0.7474538407986984, 0.6082476860610768, 0.6549841349478811, 0.664960794034414, 0.5739178060321137], 'val_acc': [0.988161027431488, 0.989877924323082, 0.9921770207583904, 0.9913745764642954, 0.9932994972914457, 0.99210393615067, 0.9925379697233438, 0.9930974524468184, 0.9936424847692251, 0.9907212946563959, 0.9933763351291418, 0.9931321237236261, 0.9921390954405069, 0.9929764829576015, 0.9937011022120714, 0.9930727668106556, 0.993891678750515, 0.9913952723145485, 0.9925070311874151, 0.9933523871004581, 0.9936933815479279, 0.991737250238657, 0.993630763143301, 0.9932503700256348, 0.9932331591844559, 0.993269570171833, 0.9911852367222309, 0.9934993125498295, 0.9900463037192822, 0.9920019172132015, 0.9925928376615047, 0.9933828227221966, 0.9936876464635134, 0.9936372637748718, 0.9935484528541565, 0.9922840353101492, 0.9914314486086369, 0.992695864289999, 0.993197238072753, 0.9929510429501534, 0.9912343919277191, 0.9939730018377304, 0.9937153328210115, 0.9932373967021704, 0.9936881437897682, 0.9909305479377508, 0.993671428412199, 0.9933646153658628, 0.9928432758897543, 0.9923137109726667, 0.992142841219902, 0.9934322107583284, 0.993885699659586, 0.9922062214463949, 0.9930967073887587, 0.9937906563282013, 0.9938522782176733, 0.993310222402215, 0.9887716379016638, 0.9932758137583733, 0.9936826452612877, 0.9933808129280806, 0.9916831310838461, 0.9935636576265097, 0.9928138498216867, 0.993411498144269, 0.9934381935745478, 0.9934319742023945, 0.9925756268203259, 0.9925801195204258, 0.9931456055492163, 0.9928340520709753, 0.9928397815674543, 0.9936038348823786, 0.9937001056969166, 0.9918527510017157, 0.9928729701787233, 0.9936375133693218, 0.9935726579278708, 0.9914187267422676, 0.9935324843972921, 0.9935980830341578, 0.9934406839311123, 0.9931570794433355, 0.9917242787778378, 0.9935726448893547, 0.9926519598811865, 0.9936093185096979, 0.9934050254523754, 0.9925422016531229, 0.9926217868924141, 0.9926162865012884, 0.9930146504193544, 0.9931645672768354, 0.9936781730502844, 0.9938188306987286, 0.9931431096047163, 0.9931161683052778, 0.9935339875519276, 0.993673674762249, 0.9935601651668549, 0.993184270337224, 0.9920642711222172, 0.9932181853801012, 0.992469372227788, 0.9933651071041822, 0.992747001349926, 0.9930356070399284, 0.9932538531720638, 0.9936472363770008, 0.9925865978002548, 0.9930166490375996, 0.9915920831263065, 0.9924237187951803, 0.993097972124815, 0.9911154098808765, 0.9919542744755745, 0.9933720976114273, 0.9935402162373066, 0.9934611450880766, 0.9935599155724049], 'val_mDice': [0.6360960239544511, 0.7566075306385756, 0.7956209219992161, 0.7865543104708195, 0.8123395312577486, 0.7918000593781471, 0.8028823509812355, 0.8141293283551931, 0.8151817694306374, 0.77280193567276, 0.8157815877348185, 0.8047760743647814, 0.8003358077257872, 0.8108589705079794, 0.8204788342118263, 0.799687821418047, 0.8244415931403637, 0.7837854977697134, 0.8056688960641623, 0.8177947998046875, 0.8211476355791092, 0.7562217023223639, 0.8204331528395414, 0.8157100342214108, 0.8189888205379248, 0.8173016086220741, 0.7339393440634012, 0.8201010897755623, 0.6897491496056318, 0.8007378038018942, 0.8052132837474346, 0.8113177586346865, 0.8208643551915884, 0.8195653278380632, 0.8217890560626984, 0.8054721914231777, 0.786052756011486, 0.8107586298137903, 0.8172165788710117, 0.7955494802445173, 0.7922449894249439, 0.8197635412216187, 0.8185330033302307, 0.8191566541790962, 0.8185599930584431, 0.7234784588217735, 0.8223646320402622, 0.8168481569737196, 0.8135218825191259, 0.773821696639061, 0.80367686226964, 0.8117576781660318, 0.820683566853404, 0.8028136286884546, 0.8165736496448517, 0.8197644725441933, 0.8245156612247229, 0.8177525736391544, 0.7529491279274225, 0.8178751915693283, 0.8214007131755352, 0.8133702352643013, 0.750359296798706, 0.8213839679956436, 0.8139149285852909, 0.8052830118685961, 0.814873743802309, 0.8157988823950291, 0.8104009367525578, 0.8118967153131962, 0.8197984471917152, 0.7938316185027361, 0.7896250020712614, 0.8169696945697069, 0.8205072022974491, 0.8011205028742552, 0.8147592283785343, 0.8195113390684128, 0.8205799106508493, 0.7956377882510424, 0.8256354555487633, 0.8178680762648582, 0.8204878214746714, 0.8040828350931406, 0.8014504332095385, 0.8228873834013939, 0.8102553058415651, 0.8213700354099274, 0.8152611367404461, 0.7800199743360281, 0.8099064044654369, 0.8135852590203285, 0.8152483962476254, 0.8183962386101484, 0.823231153190136, 0.8202245552092791, 0.8016939647495747, 0.818629888817668, 0.8216610830277205, 0.8229405526071787, 0.8128177747130394, 0.7986890617758036, 0.8031018543988466, 0.8193673193454742, 0.7768523413687944, 0.8206971734762192, 0.7949970476329327, 0.7977519743144512, 0.809202678501606, 0.8235086034983397, 0.7855164539068937, 0.7941586244851351, 0.7986861281096935, 0.7781649194657803, 0.812659515067935, 0.7900497876107693, 0.7948676683008671, 0.8191864285618067, 0.8210798539221287, 0.8201966341584921, 0.8121623564511538], 'loss': [0.3444394809912933, 0.08240498864939505, 0.06889948291063268, 0.06187711724609161, 0.056516297296619285, 0.054009050150104654, 0.05033847519616515, 0.04895213747855206, 0.04640040688534377, 0.04450891775839646, 0.042810526570326655, 0.042038646050856214, 0.04047753100134229, 0.03939200585972692, 0.0386182271540113, 0.03818286377064467, 0.03723650539288042, 0.036181306034504875, 0.03552259016681198, 0.03494835534158229, 0.03507689277318916, 0.03448516128391488, 0.03369853120572901, 0.03332734276295276, 0.03303252951464608, 0.032651500445734866, 0.0322582085580205, 0.031953992868956616, 0.03191099287964775, 0.031527749855606704, 0.03119095504081345, 0.03060877558756743, 0.031080896709171878, 0.03053198590185621, 0.030290336884273406, 0.03014092584218182, 0.02966297930274239, 0.02972126019177425, 0.029342083403031502, 0.029411998562159, 0.028750268320658072, 0.02871714292635787, 0.028842363070704816, 0.028609559430319963, 0.028560875399176483, 0.02819574894120611, 0.02833624260676015, 0.02799115299813227, 0.02802278181819103, 0.02778607910555027, 0.027470006938039932, 0.02766719745738042, 0.02731095017927843, 0.027730643399734106, 0.027255752505315808, 0.027150942677047884, 0.026893845580036085, 0.02675139706114817, 0.026752000233993597, 0.026840818439735497, 0.02697456751827705, 0.026781475315576193, 0.026254841119035397, 0.026472613682243913, 0.02615429550314962, 0.02627570139408887, 0.026060101613480276, 0.025977799844633442, 0.025972391809933593, 0.0259136094737582, 0.025967885313880862, 0.025901263956929717, 0.025730588002578575, 0.025688606200420967, 0.025692147665800042, 0.02556210745957458, 0.025328799682712948, 0.025486188384204276, 0.02516669900729721, 0.025276571339959534, 0.02529284095129125, 0.025057541330698697, 0.02523654708739418, 0.025047160524485818, 0.025048946781057756, 0.025197060702993393, 0.024945724131397715, 0.024822506703461478, 0.024757838248037928, 0.024958622564061866, 0.024981773558511087, 0.024644976640857026, 0.024789533672106172, 0.024488057703796032, 0.02472883858266221, 0.024629478366960906, 0.024444083818124674, 0.024328947850666742, 0.024511102978904045, 0.024406608411388916, 0.024166998787684295, 0.024407515764769686, 0.024318320426730256, 0.024212357622954445, 0.023923019793625145, 0.024085974390020668, 0.02385633720354023, 0.023974293255573632, 0.024080104541812152, 0.023912732817809992, 0.02385163047930166, 0.024016483750813677, 0.02395313251575305, 0.023912844407718757, 0.023762527308978102, 0.023620058263770945, 0.023733959720144637, 0.023854599845785775, 0.023541786272844412, 0.023585500069671535, 0.02348009791461948], 'acc': [0.9223795711848743, 0.9912438692151289, 0.9924636214220165, 0.9931300152355029, 0.993595321619983, 0.9938286482713025, 0.9941420070839992, 0.9942909694997721, 0.9944985223533911, 0.9946606038989846, 0.9948298096504447, 0.994885991872278, 0.9950281562422354, 0.9951382702037102, 0.9952080661831963, 0.9952392034709585, 0.9953519051895194, 0.9954208441834368, 0.9955035873208434, 0.9955563501598694, 0.9955540560562464, 0.9956196734087246, 0.995693406660382, 0.9957217761375243, 0.9957589364445166, 0.9957784706532117, 0.9958183140210107, 0.9958504003709487, 0.995875070288135, 0.9958972494486138, 0.995912951065492, 0.9959914868850527, 0.9959493501684704, 0.9959866826758923, 0.9960285024636296, 0.9960146698370563, 0.9960911708785583, 0.9960787353289035, 0.9961164838707903, 0.9961252253936727, 0.9961575797602207, 0.9961664452707364, 0.9961419898873355, 0.9961822936312447, 0.996204107331526, 0.9962221390488838, 0.9962125821535742, 0.9962553257267415, 0.9962382024694877, 0.9962723594419879, 0.9962965580898252, 0.9962963558966321, 0.9963204107440223, 0.9962973269668899, 0.9963173585111454, 0.9963383908067913, 0.9963566171966447, 0.9963742144863766, 0.9963783028303878, 0.9963567967792691, 0.9963392600844764, 0.9963628030742961, 0.9964081151526717, 0.9963959383122442, 0.9963977505718359, 0.9963996107741434, 0.9964292240818715, 0.996426943454563, 0.9964448297786923, 0.9964359656324283, 0.9964335585036621, 0.9964416455180993, 0.9964576964596084, 0.9964580560057397, 0.9964666031054313, 0.9964560389214032, 0.9964997181150574, 0.9964879969762733, 0.9965083242169072, 0.9964986209934759, 0.9964889797223103, 0.9965248386508374, 0.9965136442240403, 0.9965227050718647, 0.9965314012974331, 0.9964981235055623, 0.9965377610167713, 0.9965365508146453, 0.9965526994836722, 0.9965315540797816, 0.9965244614733101, 0.9965412340139808, 0.9965572087651445, 0.9965548337828591, 0.9965620362912374, 0.9965528415112846, 0.9965532899415354, 0.9965831522356, 0.996569411083147, 0.9965806297409946, 0.9965830968899138, 0.9965780143941669, 0.9965863988778172, 0.9965811029563068, 0.9966142217124313, 0.9966163439895822, 0.9966139885361801, 0.996618871546462, 0.996619140837297, 0.996600190874618, 0.9966200548028841, 0.9966001959022668, 0.9966226289797787, 0.9966011623188332, 0.996625723829942, 0.9966214763947836, 0.9966314986730765, 0.9966225912308629, 0.9966282936647765, 0.9966326987298784, 0.996658336836466], 'mDice': [0.6510329629104458, 0.8528932740052042, 0.8753562209372655, 0.8872549713205015, 0.896435089971153, 0.9007964252913138, 0.9071861691102066, 0.9096286567755799, 0.9141299596117586, 0.9174775763146343, 0.9204851497032646, 0.9218679017426176, 0.9246610802017993, 0.9265996936833774, 0.9279877181334045, 0.9287705936054603, 0.9304786390982343, 0.9323807499322019, 0.9335554598778594, 0.9345956049107281, 0.9343545099951269, 0.9354343548931283, 0.9368555183622277, 0.9375353731510184, 0.9380613209562212, 0.938762669289335, 0.9394735122123108, 0.9400247216044617, 0.9401013296670139, 0.940808220574204, 0.9414340073436038, 0.9424845658349177, 0.9416198536980452, 0.9426275674191809, 0.9430670350066347, 0.9433496867417873, 0.9442108662214043, 0.9441064628308778, 0.9447960454896586, 0.9446695653406381, 0.9458931130967906, 0.9459552389827217, 0.9457271696729805, 0.9461526160208594, 0.9462403550898141, 0.9469133228655683, 0.9466569128249239, 0.947288098686509, 0.9472364371587718, 0.9476700900489339, 0.9482491994424884, 0.947883520854036, 0.9485356053769194, 0.947766602032412, 0.9486479062893893, 0.9488287337831577, 0.9493134628400939, 0.9495762628629203, 0.9495704855752127, 0.949416553993542, 0.9491712388724168, 0.949526427417346, 0.9505011622908778, 0.9500913717293277, 0.9506896823017913, 0.9504579063130544, 0.9508524186951616, 0.9510102075152077, 0.9510111613765029, 0.9511292561416054, 0.9510263806022639, 0.9511539494726762, 0.9514696647152192, 0.9515478076094934, 0.9515427065474571, 0.9517872789062052, 0.9522120566737629, 0.9519190893808114, 0.9525174839066977, 0.9523127687798708, 0.9522834353930612, 0.9527209085482982, 0.9523840852491224, 0.9527386526578365, 0.9527321527737476, 0.9524636852196926, 0.9529243470955715, 0.9531559728642602, 0.9532726712034072, 0.9529034422224264, 0.9528566219394764, 0.953493806838546, 0.9532139519511081, 0.9537825296741476, 0.9533243231329059, 0.9535137503712493, 0.9538656195323337, 0.954076274375931, 0.9537361697396072, 0.9539241904066708, 0.9543800874358619, 0.9539248023463055, 0.9540960515599446, 0.9542927272895688, 0.9548358614330883, 0.9545259411789003, 0.9549579877976384, 0.9547373284594971, 0.954535975873962, 0.9548565722847007, 0.9549657745451078, 0.954658846572895, 0.9547776773552924, 0.9548588742137274, 0.9551292593379157, 0.9554042340959283, 0.9551866884789456, 0.9549613527558026, 0.9555452326261805, 0.9554657024817557, 0.955658816690158]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.15it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.46it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.83it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.23it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.50it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:33,  2.83it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:31,  2.88it/s]predicting train subjects:   1%|          | 3/266 [00:00<01:28,  2.98it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:29,  2.94it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:29,  2.92it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:28,  2.93it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:26,  3.00it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:27,  2.96it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:27,  2.94it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:24,  3.03it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:23,  3.05it/s]predicting train subjects:   5%|▍         | 12/266 [00:03<01:20,  3.15it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:22,  3.06it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:20,  3.12it/s]predicting train subjects:   6%|▌         | 15/266 [00:04<01:19,  3.15it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:19,  3.15it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:17,  3.20it/s]predicting train subjects:   7%|▋         | 18/266 [00:05<01:16,  3.22it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:17,  3.20it/s]predicting train subjects:   8%|▊         | 20/266 [00:06<01:17,  3.17it/s]predicting train subjects:   8%|▊         | 21/266 [00:06<01:20,  3.05it/s]predicting train subjects:   8%|▊         | 22/266 [00:07<01:21,  2.99it/s]predicting train subjects:   9%|▊         | 23/266 [00:07<01:18,  3.09it/s]predicting train subjects:   9%|▉         | 24/266 [00:07<01:19,  3.05it/s]predicting train subjects:   9%|▉         | 25/266 [00:08<01:16,  3.14it/s]predicting train subjects:  10%|▉         | 26/266 [00:08<01:14,  3.24it/s]predicting train subjects:  10%|█         | 27/266 [00:08<01:12,  3.30it/s]predicting train subjects:  11%|█         | 28/266 [00:09<01:11,  3.31it/s]predicting train subjects:  11%|█         | 29/266 [00:09<01:11,  3.30it/s]predicting train subjects:  11%|█▏        | 30/266 [00:09<01:10,  3.35it/s]predicting train subjects:  12%|█▏        | 31/266 [00:09<01:09,  3.39it/s]predicting train subjects:  12%|█▏        | 32/266 [00:10<01:08,  3.42it/s]predicting train subjects:  12%|█▏        | 33/266 [00:10<01:07,  3.45it/s]predicting train subjects:  13%|█▎        | 34/266 [00:10<01:07,  3.44it/s]predicting train subjects:  13%|█▎        | 35/266 [00:11<01:09,  3.32it/s]predicting train subjects:  14%|█▎        | 36/266 [00:11<01:08,  3.36it/s]predicting train subjects:  14%|█▍        | 37/266 [00:11<01:10,  3.25it/s]predicting train subjects:  14%|█▍        | 38/266 [00:11<01:08,  3.31it/s]predicting train subjects:  15%|█▍        | 39/266 [00:12<01:07,  3.37it/s]predicting train subjects:  15%|█▌        | 40/266 [00:12<01:08,  3.31it/s]predicting train subjects:  15%|█▌        | 41/266 [00:12<01:07,  3.32it/s]predicting train subjects:  16%|█▌        | 42/266 [00:13<01:03,  3.50it/s]predicting train subjects:  16%|█▌        | 43/266 [00:13<01:03,  3.49it/s]predicting train subjects:  17%|█▋        | 44/266 [00:13<01:03,  3.50it/s]predicting train subjects:  17%|█▋        | 45/266 [00:13<01:00,  3.64it/s]predicting train subjects:  17%|█▋        | 46/266 [00:14<01:01,  3.59it/s]predicting train subjects:  18%|█▊        | 47/266 [00:14<00:58,  3.72it/s]predicting train subjects:  18%|█▊        | 48/266 [00:14<00:57,  3.82it/s]predicting train subjects:  18%|█▊        | 49/266 [00:14<00:56,  3.81it/s]predicting train subjects:  19%|█▉        | 50/266 [00:15<00:55,  3.91it/s]predicting train subjects:  19%|█▉        | 51/266 [00:15<00:55,  3.91it/s]predicting train subjects:  20%|█▉        | 52/266 [00:15<00:53,  4.00it/s]predicting train subjects:  20%|█▉        | 53/266 [00:15<00:53,  4.00it/s]predicting train subjects:  20%|██        | 54/266 [00:16<00:52,  4.01it/s]predicting train subjects:  21%|██        | 55/266 [00:16<00:52,  3.98it/s]predicting train subjects:  21%|██        | 56/266 [00:16<00:51,  4.05it/s]predicting train subjects:  21%|██▏       | 57/266 [00:16<00:51,  4.06it/s]predicting train subjects:  22%|██▏       | 58/266 [00:17<00:52,  3.99it/s]predicting train subjects:  22%|██▏       | 59/266 [00:17<00:50,  4.08it/s]predicting train subjects:  23%|██▎       | 60/266 [00:17<00:50,  4.12it/s]predicting train subjects:  23%|██▎       | 61/266 [00:17<00:49,  4.14it/s]predicting train subjects:  23%|██▎       | 62/266 [00:18<00:48,  4.23it/s]predicting train subjects:  24%|██▎       | 63/266 [00:18<00:47,  4.26it/s]predicting train subjects:  24%|██▍       | 64/266 [00:18<00:47,  4.30it/s]predicting train subjects:  24%|██▍       | 65/266 [00:18<00:46,  4.34it/s]predicting train subjects:  25%|██▍       | 66/266 [00:19<00:45,  4.37it/s]predicting train subjects:  25%|██▌       | 67/266 [00:19<00:45,  4.38it/s]predicting train subjects:  26%|██▌       | 68/266 [00:19<00:44,  4.40it/s]predicting train subjects:  26%|██▌       | 69/266 [00:19<00:45,  4.35it/s]predicting train subjects:  26%|██▋       | 70/266 [00:19<00:44,  4.36it/s]predicting train subjects:  27%|██▋       | 71/266 [00:20<00:45,  4.33it/s]predicting train subjects:  27%|██▋       | 72/266 [00:20<00:45,  4.30it/s]predicting train subjects:  27%|██▋       | 73/266 [00:20<00:46,  4.17it/s]predicting train subjects:  28%|██▊       | 74/266 [00:20<00:45,  4.21it/s]predicting train subjects:  28%|██▊       | 75/266 [00:21<00:45,  4.17it/s]predicting train subjects:  29%|██▊       | 76/266 [00:21<00:46,  4.09it/s]predicting train subjects:  29%|██▉       | 77/266 [00:21<00:48,  3.93it/s]predicting train subjects:  29%|██▉       | 78/266 [00:22<00:51,  3.69it/s]predicting train subjects:  30%|██▉       | 79/266 [00:22<00:52,  3.59it/s]predicting train subjects:  30%|███       | 80/266 [00:22<00:54,  3.39it/s]predicting train subjects:  30%|███       | 81/266 [00:22<00:55,  3.31it/s]predicting train subjects:  31%|███       | 82/266 [00:23<00:56,  3.27it/s]predicting train subjects:  31%|███       | 83/266 [00:23<00:55,  3.28it/s]predicting train subjects:  32%|███▏      | 84/266 [00:23<00:54,  3.32it/s]predicting train subjects:  32%|███▏      | 85/266 [00:24<00:54,  3.30it/s]predicting train subjects:  32%|███▏      | 86/266 [00:24<00:54,  3.32it/s]predicting train subjects:  33%|███▎      | 87/266 [00:24<00:55,  3.24it/s]predicting train subjects:  33%|███▎      | 88/266 [00:25<00:55,  3.23it/s]predicting train subjects:  33%|███▎      | 89/266 [00:25<00:54,  3.26it/s]predicting train subjects:  34%|███▍      | 90/266 [00:25<00:53,  3.27it/s]predicting train subjects:  34%|███▍      | 91/266 [00:26<00:53,  3.28it/s]predicting train subjects:  35%|███▍      | 92/266 [00:26<00:53,  3.25it/s]predicting train subjects:  35%|███▍      | 93/266 [00:26<00:52,  3.28it/s]predicting train subjects:  35%|███▌      | 94/266 [00:26<00:52,  3.27it/s]predicting train subjects:  36%|███▌      | 95/266 [00:27<00:52,  3.25it/s]predicting train subjects:  36%|███▌      | 96/266 [00:27<00:53,  3.17it/s]predicting train subjects:  36%|███▋      | 97/266 [00:27<00:54,  3.11it/s]predicting train subjects:  37%|███▋      | 98/266 [00:28<00:56,  3.00it/s]predicting train subjects:  37%|███▋      | 99/266 [00:28<00:53,  3.11it/s]predicting train subjects:  38%|███▊      | 100/266 [00:28<00:50,  3.31it/s]predicting train subjects:  38%|███▊      | 101/266 [00:29<00:48,  3.38it/s]predicting train subjects:  38%|███▊      | 102/266 [00:29<00:46,  3.53it/s]predicting train subjects:  39%|███▊      | 103/266 [00:29<00:44,  3.63it/s]predicting train subjects:  39%|███▉      | 104/266 [00:29<00:44,  3.67it/s]predicting train subjects:  39%|███▉      | 105/266 [00:30<00:42,  3.77it/s]predicting train subjects:  40%|███▉      | 106/266 [00:30<00:44,  3.63it/s]predicting train subjects:  40%|████      | 107/266 [00:30<00:42,  3.72it/s]predicting train subjects:  41%|████      | 108/266 [00:30<00:43,  3.64it/s]predicting train subjects:  41%|████      | 109/266 [00:31<00:43,  3.58it/s]predicting train subjects:  41%|████▏     | 110/266 [00:31<00:42,  3.64it/s]predicting train subjects:  42%|████▏     | 111/266 [00:31<00:43,  3.60it/s]predicting train subjects:  42%|████▏     | 112/266 [00:32<00:43,  3.54it/s]predicting train subjects:  42%|████▏     | 113/266 [00:32<00:43,  3.50it/s]predicting train subjects:  43%|████▎     | 114/266 [00:32<00:41,  3.63it/s]predicting train subjects:  43%|████▎     | 115/266 [00:32<00:42,  3.56it/s]predicting train subjects:  44%|████▎     | 116/266 [00:33<00:42,  3.52it/s]predicting train subjects:  44%|████▍     | 117/266 [00:33<00:40,  3.64it/s]predicting train subjects:  44%|████▍     | 118/266 [00:33<00:39,  3.78it/s]predicting train subjects:  45%|████▍     | 119/266 [00:34<00:42,  3.48it/s]predicting train subjects:  45%|████▌     | 120/266 [00:34<00:42,  3.41it/s]predicting train subjects:  45%|████▌     | 121/266 [00:34<00:43,  3.33it/s]predicting train subjects:  46%|████▌     | 122/266 [00:35<00:44,  3.26it/s]predicting train subjects:  46%|████▌     | 123/266 [00:35<00:43,  3.32it/s]predicting train subjects:  47%|████▋     | 124/266 [00:35<00:42,  3.35it/s]predicting train subjects:  47%|████▋     | 125/266 [00:35<00:41,  3.38it/s]predicting train subjects:  47%|████▋     | 126/266 [00:36<00:41,  3.41it/s]predicting train subjects:  48%|████▊     | 127/266 [00:36<00:42,  3.29it/s]predicting train subjects:  48%|████▊     | 128/266 [00:36<00:42,  3.28it/s]predicting train subjects:  48%|████▊     | 129/266 [00:37<00:42,  3.24it/s]predicting train subjects:  49%|████▉     | 130/266 [00:37<00:41,  3.25it/s]predicting train subjects:  49%|████▉     | 131/266 [00:37<00:42,  3.19it/s]predicting train subjects:  50%|████▉     | 132/266 [00:38<00:42,  3.14it/s]predicting train subjects:  50%|█████     | 133/266 [00:38<00:42,  3.12it/s]predicting train subjects:  50%|█████     | 134/266 [00:38<00:42,  3.10it/s]predicting train subjects:  51%|█████     | 135/266 [00:39<00:42,  3.08it/s]predicting train subjects:  51%|█████     | 136/266 [00:39<00:42,  3.09it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:39<00:40,  3.16it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:39<00:38,  3.30it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:40<00:37,  3.39it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:40<00:37,  3.38it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:40<00:37,  3.36it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:41<00:36,  3.41it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:41<00:35,  3.49it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:41<00:36,  3.33it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:42<00:35,  3.42it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:42<00:34,  3.46it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:42<00:35,  3.39it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:42<00:34,  3.38it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:43<00:35,  3.33it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:43<00:34,  3.40it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:43<00:33,  3.42it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:44<00:32,  3.47it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:44<00:32,  3.52it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:44<00:31,  3.55it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:44<00:30,  3.63it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:45<00:29,  3.74it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:45<00:28,  3.89it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:45<00:26,  4.14it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:45<00:25,  4.16it/s]predicting train subjects:  60%|██████    | 160/266 [00:46<00:24,  4.26it/s]predicting train subjects:  61%|██████    | 161/266 [00:46<00:23,  4.43it/s]predicting train subjects:  61%|██████    | 162/266 [00:46<00:22,  4.54it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:46<00:22,  4.57it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:46<00:22,  4.50it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:47<00:22,  4.56it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:47<00:21,  4.58it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:47<00:22,  4.47it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:47<00:21,  4.58it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:47<00:21,  4.41it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:48<00:21,  4.55it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:48<00:21,  4.47it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:48<00:20,  4.58it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:48<00:21,  4.31it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:49<00:22,  4.06it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:49<00:22,  4.02it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:49<00:22,  4.03it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:49<00:22,  3.87it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:50<00:23,  3.78it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:50<00:22,  3.80it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:50<00:22,  3.84it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:51<00:22,  3.84it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:51<00:21,  3.92it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:51<00:20,  3.98it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:51<00:21,  3.84it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:52<00:21,  3.76it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:52<00:21,  3.71it/s]predicting train subjects:  70%|███████   | 187/266 [00:52<00:20,  3.82it/s]predicting train subjects:  71%|███████   | 188/266 [00:52<00:20,  3.90it/s]predicting train subjects:  71%|███████   | 189/266 [00:53<00:19,  4.00it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:53<00:18,  4.00it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:53<00:19,  3.82it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:53<00:20,  3.67it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:54<00:19,  3.73it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:54<00:21,  3.39it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:54<00:20,  3.53it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:55<00:19,  3.67it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:55<00:18,  3.80it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:55<00:18,  3.72it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:55<00:17,  3.83it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:56<00:17,  3.73it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:56<00:16,  3.86it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:56<00:16,  3.91it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:56<00:16,  3.75it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:57<00:16,  3.80it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:57<00:16,  3.78it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:57<00:15,  3.80it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:57<00:15,  3.87it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:58<00:14,  3.93it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:58<00:14,  3.94it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:58<00:14,  3.74it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:58<00:14,  3.83it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:59<00:14,  3.67it/s]predicting train subjects:  80%|████████  | 213/266 [00:59<00:13,  3.88it/s]predicting train subjects:  80%|████████  | 214/266 [00:59<00:12,  4.08it/s]predicting train subjects:  81%|████████  | 215/266 [00:59<00:12,  4.19it/s]predicting train subjects:  81%|████████  | 216/266 [01:00<00:11,  4.28it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:00<00:11,  4.26it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:00<00:11,  4.31it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:00<00:10,  4.40it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:01<00:10,  4.41it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:01<00:10,  4.47it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:01<00:10,  4.39it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:01<00:09,  4.45it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:01<00:09,  4.43it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:02<00:09,  4.44it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:02<00:09,  4.44it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:02<00:08,  4.51it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:02<00:08,  4.52it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:03<00:08,  4.48it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:03<00:08,  4.47it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:03<00:07,  4.40it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:03<00:07,  4.30it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:03<00:07,  4.34it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:04<00:07,  4.36it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:04<00:07,  4.36it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:04<00:06,  4.38it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:04<00:06,  4.38it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:05<00:06,  4.34it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:05<00:06,  4.35it/s]predicting train subjects:  90%|█████████ | 240/266 [01:05<00:06,  4.31it/s]predicting train subjects:  91%|█████████ | 241/266 [01:05<00:06,  4.08it/s]predicting train subjects:  91%|█████████ | 242/266 [01:06<00:05,  4.17it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:06<00:05,  4.27it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:06<00:05,  4.32it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:06<00:04,  4.35it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:06<00:04,  4.38it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:07<00:04,  4.39it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:07<00:04,  4.39it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:07<00:04,  4.04it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:08<00:04,  3.72it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:08<00:04,  3.51it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:08<00:04,  3.49it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:08<00:03,  3.52it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:09<00:03,  3.55it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:09<00:03,  3.41it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:09<00:02,  3.43it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:10<00:02,  3.43it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:10<00:02,  3.36it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:10<00:02,  3.38it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:10<00:01,  3.42it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:11<00:01,  3.32it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:11<00:01,  3.40it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:11<00:00,  3.44it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:12<00:00,  3.34it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:12<00:00,  3.28it/s]predicting train subjects: 100%|██████████| 266/266 [01:12<00:00,  3.26it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:01,  3.74it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  3.82it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  3.95it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  4.09it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:01<00:00,  4.03it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:20,  3.28it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:20,  3.28it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<01:18,  3.35it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:16,  3.45it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:17,  3.38it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:01<01:20,  3.25it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:02<01:21,  3.16it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:23,  3.10it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:02<01:24,  3.05it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:03<01:22,  3.12it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:03<01:23,  3.07it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:03<01:20,  3.14it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:04<01:22,  3.07it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:04<01:20,  3.14it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:04<01:21,  3.07it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:05<01:22,  3.04it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:05<01:21,  3.06it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:05<01:20,  3.08it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:06<01:21,  3.04it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:06<01:22,  3.00it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:06<01:22,  2.98it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:07<01:22,  2.97it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:07<01:22,  2.95it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:07<01:22,  2.94it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:08<01:21,  2.97it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:08<01:17,  3.12it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:08<01:16,  3.11it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:09<01:14,  3.19it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:09<01:12,  3.28it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:09<01:11,  3.31it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:09<01:12,  3.24it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:10<01:13,  3.19it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:10<01:11,  3.24it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:10<01:10,  3.29it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:11<01:09,  3.32it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:11<01:10,  3.25it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:11<01:11,  3.19it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:12<01:10,  3.24it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:12<01:11,  3.18it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:12<01:10,  3.23it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:12<01:07,  3.31it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:13<01:05,  3.42it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:13<01:03,  3.53it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:13<00:59,  3.70it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:13<00:57,  3.87it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:14<00:54,  4.00it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:14<00:56,  3.90it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:14<00:54,  4.01it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:14<00:53,  4.07it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:15<00:53,  4.07it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:15<00:52,  4.09it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:15<00:51,  4.14it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:15<00:50,  4.21it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:16<00:50,  4.24it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:16<00:49,  4.25it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:16<00:51,  4.04it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:16<00:53,  3.87it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:17<00:54,  3.79it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:17<00:54,  3.80it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:17<00:53,  3.84it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:17<00:53,  3.80it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:18<00:53,  3.78it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:18<00:51,  3.95it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:18<00:50,  4.04it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:18<00:48,  4.14it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:19<00:47,  4.18it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:19<00:47,  4.16it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:19<00:47,  4.14it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:19<00:49,  4.00it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:20<00:47,  4.10it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:20<00:46,  4.22it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:20<00:46,  4.20it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:20<00:46,  4.11it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:21<00:45,  4.18it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:21<00:45,  4.22it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:21<00:44,  4.28it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:21<00:44,  4.29it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:22<00:48,  3.88it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:22<00:49,  3.76it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:22<00:51,  3.62it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:23<00:54,  3.42it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:23<00:54,  3.40it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:23<00:56,  3.23it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:24<00:57,  3.17it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:24<00:56,  3.20it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:24<00:57,  3.15it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:24<00:57,  3.11it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:25<00:56,  3.14it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:25<00:54,  3.23it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:25<00:53,  3.28it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:26<00:53,  3.29it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:26<00:54,  3.19it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:26<00:53,  3.24it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:27<00:52,  3.27it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:27<00:53,  3.20it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:27<00:52,  3.26it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:28<00:52,  3.23it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:28<00:50,  3.32it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:28<00:47,  3.55it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:28<00:44,  3.70it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:29<00:45,  3.61it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:29<00:43,  3.74it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:29<00:44,  3.69it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:29<00:42,  3.79it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:30<00:42,  3.81it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:30<00:42,  3.73it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:30<00:43,  3.68it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:30<00:41,  3.78it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:31<00:41,  3.80it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:31<00:41,  3.80it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:31<00:42,  3.68it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:32<00:42,  3.61it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:32<00:43,  3.55it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:32<00:43,  3.52it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:32<00:42,  3.54it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:33<00:42,  3.51it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:33<00:41,  3.55it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:33<00:40,  3.65it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:34<00:41,  3.56it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:34<00:42,  3.46it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:34<00:42,  3.44it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:34<00:43,  3.35it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:35<00:42,  3.36it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:35<00:41,  3.40it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:35<00:41,  3.37it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:36<00:41,  3.37it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:36<00:42,  3.29it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:36<00:43,  3.21it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:37<00:42,  3.25it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:37<00:42,  3.17it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:37<00:42,  3.17it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:38<00:41,  3.25it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:38<00:40,  3.30it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:38<00:39,  3.34it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:38<00:39,  3.32it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:39<00:40,  3.23it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:39<00:38,  3.34it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:39<00:37,  3.37it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:40<00:38,  3.34it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:40<00:37,  3.37it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:40<00:37,  3.36it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:40<00:35,  3.46it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:41<00:35,  3.44it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:41<00:34,  3.50it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:41<00:35,  3.40it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:42<00:34,  3.49it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:42<00:34,  3.45it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:42<00:35,  3.31it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:43<00:35,  3.27it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:43<00:34,  3.31it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:43<00:34,  3.33it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:43<00:34,  3.29it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:44<00:34,  3.26it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:44<00:33,  3.32it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:44<00:30,  3.67it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:44<00:27,  4.00it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:45<00:25,  4.20it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:45<00:25,  4.32it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:45<00:23,  4.46it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:45<00:23,  4.57it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:46<00:22,  4.62it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:46<00:22,  4.67it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:46<00:22,  4.62it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:46<00:21,  4.66it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:46<00:21,  4.64it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:47<00:21,  4.65it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:47<00:21,  4.62it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:47<00:21,  4.60it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:47<00:20,  4.70it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:47<00:20,  4.76it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:48<00:20,  4.68it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:48<00:20,  4.57it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:48<00:22,  4.17it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:48<00:22,  4.11it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:49<00:23,  3.91it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:49<00:23,  3.80it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:49<00:23,  3.73it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:50<00:24,  3.66it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:50<00:24,  3.61it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:50<00:24,  3.58it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:50<00:23,  3.58it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:51<00:23,  3.61it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:51<00:21,  3.80it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:51<00:21,  3.84it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:51<00:20,  3.91it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:52<00:21,  3.79it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:52<00:21,  3.72it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:52<00:21,  3.67it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:53<00:21,  3.65it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:53<00:20,  3.70it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:53<00:20,  3.72it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:53<00:19,  3.74it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:54<00:20,  3.63it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:54<00:20,  3.44it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:54<00:19,  3.60it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:54<00:19,  3.62it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:55<00:19,  3.57it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:55<00:18,  3.70it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:55<00:17,  3.82it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:55<00:16,  3.91it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:56<00:16,  3.91it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:56<00:16,  3.83it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:56<00:16,  3.83it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:57<00:16,  3.86it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:57<00:16,  3.80it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:57<00:15,  3.81it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:57<00:15,  3.69it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:58<00:15,  3.63it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:58<00:15,  3.57it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:58<00:15,  3.63it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:58<00:14,  3.73it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:59<00:14,  3.64it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:59<00:14,  3.77it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:59<00:13,  3.72it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:00<00:13,  3.77it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:00<00:12,  3.98it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:00<00:12,  4.01it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:00<00:12,  3.92it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:00<00:11,  3.99it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:01<00:11,  4.03it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:01<00:10,  4.14it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:01<00:10,  4.18it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:01<00:10,  4.25it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:02<00:09,  4.29it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:02<00:09,  4.33it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:02<00:09,  4.26it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:02<00:09,  4.30it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:03<00:08,  4.27it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:03<00:08,  4.31it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:03<00:08,  4.28it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:03<00:08,  4.19it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:04<00:08,  4.24it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:04<00:07,  4.26it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:04<00:07,  4.10it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:04<00:07,  3.94it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:05<00:07,  3.87it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:05<00:07,  3.81it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:05<00:07,  3.91it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:05<00:06,  4.02it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:06<00:06,  4.11it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:06<00:06,  4.17it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:06<00:05,  4.20it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:06<00:05,  4.23it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:07<00:05,  4.04it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:07<00:05,  3.89it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:07<00:04,  4.02it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:07<00:04,  4.09it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:07<00:04,  4.13it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:08<00:04,  3.73it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:08<00:04,  3.55it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:08<00:04,  3.52it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:09<00:04,  3.36it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:09<00:04,  3.22it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:09<00:03,  3.24it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:10<00:03,  3.28it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:10<00:02,  3.34it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:10<00:02,  3.37it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:11<00:02,  3.41it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:11<00:02,  3.43it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:11<00:01,  3.43it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:11<00:01,  3.45it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:12<00:01,  3.48it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:12<00:00,  3.48it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:12<00:00,  3.40it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:13<00:00,  3.38it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:13<00:00,  3.38it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 77.90it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:03, 68.10it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 68.05it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 67.86it/s]saving BB  train1-THALAMUS:  11%|█         | 29/266 [00:00<00:03, 68.70it/s]saving BB  train1-THALAMUS:  14%|█▍        | 37/266 [00:00<00:03, 70.84it/s]saving BB  train1-THALAMUS:  17%|█▋        | 45/266 [00:00<00:03, 72.81it/s]saving BB  train1-THALAMUS:  20%|█▉        | 53/266 [00:00<00:02, 74.79it/s]saving BB  train1-THALAMUS:  23%|██▎       | 62/266 [00:00<00:02, 76.80it/s]saving BB  train1-THALAMUS:  27%|██▋       | 71/266 [00:00<00:02, 79.82it/s]saving BB  train1-THALAMUS:  30%|███       | 80/266 [00:01<00:02, 81.35it/s]saving BB  train1-THALAMUS:  33%|███▎      | 88/266 [00:01<00:02, 79.56it/s]saving BB  train1-THALAMUS:  36%|███▌      | 96/266 [00:01<00:02, 78.20it/s]saving BB  train1-THALAMUS:  39%|███▉      | 104/266 [00:01<00:02, 75.87it/s]saving BB  train1-THALAMUS:  42%|████▏     | 112/266 [00:01<00:02, 75.91it/s]saving BB  train1-THALAMUS:  45%|████▌     | 120/266 [00:01<00:01, 75.72it/s]saving BB  train1-THALAMUS:  48%|████▊     | 128/266 [00:01<00:01, 74.72it/s]saving BB  train1-THALAMUS:  51%|█████     | 136/266 [00:01<00:01, 74.45it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 144/266 [00:01<00:01, 72.71it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 152/266 [00:02<00:01, 72.41it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:02<00:01, 74.79it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 170/266 [00:02<00:01, 77.49it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 179/266 [00:02<00:01, 78.49it/s]saving BB  train1-THALAMUS:  71%|███████   | 188/266 [00:02<00:00, 80.17it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 197/266 [00:02<00:00, 79.97it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 206/266 [00:02<00:00, 79.63it/s]saving BB  train1-THALAMUS:  81%|████████  | 215/266 [00:02<00:00, 80.00it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 224/266 [00:02<00:00, 80.58it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 233/266 [00:03<00:00, 78.15it/s]saving BB  train1-THALAMUS:  91%|█████████ | 242/266 [00:03<00:00, 80.35it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 251/266 [00:03<00:00, 80.75it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:03<00:00, 78.70it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 76.95it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 75.04it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 70.59it/s]saving BB  train1-THALAMUS Sagittal:   6%|▌         | 15/266 [00:00<00:03, 69.48it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 22/266 [00:00<00:03, 69.35it/s]saving BB  train1-THALAMUS Sagittal:  11%|█▏        | 30/266 [00:00<00:03, 70.55it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 38/266 [00:00<00:03, 71.47it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 46/266 [00:00<00:03, 72.46it/s]saving BB  train1-THALAMUS Sagittal:  21%|██        | 55/266 [00:00<00:02, 74.72it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▍       | 64/266 [00:00<00:02, 76.86it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 73/266 [00:00<00:02, 79.54it/s]saving BB  train1-THALAMUS Sagittal:  31%|███       | 82/266 [00:01<00:02, 79.56it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▍      | 90/266 [00:01<00:02, 77.55it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 98/266 [00:01<00:02, 76.50it/s]saving BB  train1-THALAMUS Sagittal:  40%|███▉      | 106/266 [00:01<00:02, 77.38it/s]saving BB  train1-THALAMUS Sagittal:  43%|████▎     | 114/266 [00:01<00:01, 77.42it/s]saving BB  train1-THALAMUS Sagittal:  46%|████▌     | 122/266 [00:01<00:01, 76.74it/s]saving BB  train1-THALAMUS Sagittal:  49%|████▉     | 130/266 [00:01<00:01, 76.19it/s]saving BB  train1-THALAMUS Sagittal:  52%|█████▏    | 138/266 [00:01<00:01, 75.41it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 146/266 [00:01<00:01, 74.15it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:02<00:01, 73.22it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████▏   | 163/266 [00:02<00:01, 77.05it/s]saving BB  train1-THALAMUS Sagittal:  65%|██████▍   | 172/266 [00:02<00:01, 79.99it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 181/266 [00:02<00:01, 81.59it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████▏  | 190/266 [00:02<00:00, 82.52it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▍  | 199/266 [00:02<00:00, 80.37it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 208/266 [00:02<00:00, 79.97it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 217/266 [00:02<00:00, 80.05it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 226/266 [00:02<00:00, 80.40it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 235/266 [00:03<00:00, 81.58it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 244/266 [00:03<00:00, 83.29it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 253/266 [00:03<00:00, 82.32it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 262/266 [00:03<00:00, 80.25it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 77.91it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:42,  1.75s/it]Loading train:   1%|          | 2/266 [00:03<07:15,  1.65s/it]Loading train:   1%|          | 3/266 [00:04<06:38,  1.51s/it]Loading train:   2%|▏         | 4/266 [00:05<06:06,  1.40s/it]Loading train:   2%|▏         | 5/266 [00:07<06:20,  1.46s/it]Loading train:   2%|▏         | 6/266 [00:08<05:53,  1.36s/it]Loading train:   3%|▎         | 7/266 [00:09<05:16,  1.22s/it]Loading train:   3%|▎         | 8/266 [00:10<04:55,  1.15s/it]Loading train:   3%|▎         | 9/266 [00:11<04:44,  1.11s/it]Loading train:   4%|▍         | 10/266 [00:11<04:25,  1.04s/it]Loading train:   4%|▍         | 11/266 [00:12<04:12,  1.01it/s]Loading train:   5%|▍         | 12/266 [00:13<04:01,  1.05it/s]Loading train:   5%|▍         | 13/266 [00:14<03:52,  1.09it/s]Loading train:   5%|▌         | 14/266 [00:15<03:48,  1.10it/s]Loading train:   6%|▌         | 15/266 [00:16<03:45,  1.11it/s]Loading train:   6%|▌         | 16/266 [00:17<03:39,  1.14it/s]Loading train:   6%|▋         | 17/266 [00:18<03:43,  1.11it/s]Loading train:   7%|▋         | 18/266 [00:18<03:40,  1.12it/s]Loading train:   7%|▋         | 19/266 [00:19<03:40,  1.12it/s]Loading train:   8%|▊         | 20/266 [00:20<03:39,  1.12it/s]Loading train:   8%|▊         | 21/266 [00:21<03:36,  1.13it/s]Loading train:   8%|▊         | 22/266 [00:22<03:39,  1.11it/s]Loading train:   9%|▊         | 23/266 [00:23<03:33,  1.14it/s]Loading train:   9%|▉         | 24/266 [00:24<03:27,  1.16it/s]Loading train:   9%|▉         | 25/266 [00:25<03:24,  1.18it/s]Loading train:  10%|▉         | 26/266 [00:25<03:19,  1.20it/s]Loading train:  10%|█         | 27/266 [00:26<03:17,  1.21it/s]Loading train:  11%|█         | 28/266 [00:27<03:15,  1.22it/s]Loading train:  11%|█         | 29/266 [00:28<03:18,  1.19it/s]Loading train:  11%|█▏        | 30/266 [00:29<03:25,  1.15it/s]Loading train:  12%|█▏        | 31/266 [00:30<03:23,  1.16it/s]Loading train:  12%|█▏        | 32/266 [00:30<03:15,  1.20it/s]Loading train:  12%|█▏        | 33/266 [00:31<03:15,  1.19it/s]Loading train:  13%|█▎        | 34/266 [00:32<03:30,  1.10it/s]Loading train:  13%|█▎        | 35/266 [00:33<03:26,  1.12it/s]Loading train:  14%|█▎        | 36/266 [00:34<03:17,  1.16it/s]Loading train:  14%|█▍        | 37/266 [00:35<03:19,  1.15it/s]Loading train:  14%|█▍        | 38/266 [00:36<03:24,  1.11it/s]Loading train:  15%|█▍        | 39/266 [00:37<03:19,  1.14it/s]Loading train:  15%|█▌        | 40/266 [00:37<03:14,  1.16it/s]Loading train:  15%|█▌        | 41/266 [00:38<03:09,  1.19it/s]Loading train:  16%|█▌        | 42/266 [00:39<03:02,  1.23it/s]Loading train:  16%|█▌        | 43/266 [00:40<02:54,  1.28it/s]Loading train:  17%|█▋        | 44/266 [00:40<02:45,  1.34it/s]Loading train:  17%|█▋        | 45/266 [00:41<02:40,  1.38it/s]Loading train:  17%|█▋        | 46/266 [00:42<02:34,  1.42it/s]Loading train:  18%|█▊        | 47/266 [00:42<02:32,  1.44it/s]Loading train:  18%|█▊        | 48/266 [00:43<02:29,  1.46it/s]Loading train:  18%|█▊        | 49/266 [00:44<02:28,  1.46it/s]Loading train:  19%|█▉        | 50/266 [00:44<02:25,  1.48it/s]Loading train:  19%|█▉        | 51/266 [00:45<02:22,  1.51it/s]Loading train:  20%|█▉        | 52/266 [00:46<02:21,  1.51it/s]Loading train:  20%|█▉        | 53/266 [00:46<02:23,  1.49it/s]Loading train:  20%|██        | 54/266 [00:47<02:20,  1.51it/s]Loading train:  21%|██        | 55/266 [00:48<02:20,  1.51it/s]Loading train:  21%|██        | 56/266 [00:48<02:18,  1.52it/s]Loading train:  21%|██▏       | 57/266 [00:49<02:15,  1.54it/s]Loading train:  22%|██▏       | 58/266 [00:50<02:16,  1.53it/s]Loading train:  22%|██▏       | 59/266 [00:50<02:22,  1.45it/s]Loading train:  23%|██▎       | 60/266 [00:51<02:26,  1.41it/s]Loading train:  23%|██▎       | 61/266 [00:52<02:25,  1.40it/s]Loading train:  23%|██▎       | 62/266 [00:53<02:24,  1.41it/s]Loading train:  24%|██▎       | 63/266 [00:53<02:23,  1.42it/s]Loading train:  24%|██▍       | 64/266 [00:54<02:20,  1.44it/s]Loading train:  24%|██▍       | 65/266 [00:55<02:20,  1.43it/s]Loading train:  25%|██▍       | 66/266 [00:55<02:15,  1.48it/s]Loading train:  25%|██▌       | 67/266 [00:56<02:09,  1.54it/s]Loading train:  26%|██▌       | 68/266 [00:56<02:05,  1.58it/s]Loading train:  26%|██▌       | 69/266 [00:57<02:02,  1.61it/s]Loading train:  26%|██▋       | 70/266 [00:58<02:00,  1.63it/s]Loading train:  27%|██▋       | 71/266 [00:58<02:00,  1.62it/s]Loading train:  27%|██▋       | 72/266 [00:59<02:01,  1.60it/s]Loading train:  27%|██▋       | 73/266 [01:00<02:01,  1.59it/s]Loading train:  28%|██▊       | 74/266 [01:00<02:08,  1.49it/s]Loading train:  28%|██▊       | 75/266 [01:01<02:09,  1.48it/s]Loading train:  29%|██▊       | 76/266 [01:02<02:07,  1.49it/s]Loading train:  29%|██▉       | 77/266 [01:02<02:07,  1.48it/s]Loading train:  29%|██▉       | 78/266 [01:03<02:21,  1.33it/s]Loading train:  30%|██▉       | 79/266 [01:04<02:32,  1.23it/s]Loading train:  30%|███       | 80/266 [01:05<02:33,  1.21it/s]Loading train:  30%|███       | 81/266 [01:06<02:36,  1.18it/s]Loading train:  31%|███       | 82/266 [01:07<02:42,  1.14it/s]Loading train:  31%|███       | 83/266 [01:08<02:39,  1.15it/s]Loading train:  32%|███▏      | 84/266 [01:09<02:38,  1.15it/s]Loading train:  32%|███▏      | 85/266 [01:10<02:36,  1.16it/s]Loading train:  32%|███▏      | 86/266 [01:10<02:34,  1.16it/s]Loading train:  33%|███▎      | 87/266 [01:11<02:37,  1.14it/s]Loading train:  33%|███▎      | 88/266 [01:12<02:35,  1.14it/s]Loading train:  33%|███▎      | 89/266 [01:13<02:34,  1.14it/s]Loading train:  34%|███▍      | 90/266 [01:14<02:33,  1.14it/s]Loading train:  34%|███▍      | 91/266 [01:15<02:32,  1.15it/s]Loading train:  35%|███▍      | 92/266 [01:16<02:33,  1.14it/s]Loading train:  35%|███▍      | 93/266 [01:17<02:32,  1.14it/s]Loading train:  35%|███▌      | 94/266 [01:18<02:36,  1.10it/s]Loading train:  36%|███▌      | 95/266 [01:18<02:33,  1.11it/s]Loading train:  36%|███▌      | 96/266 [01:20<02:51,  1.01s/it]Loading train:  36%|███▋      | 97/266 [01:21<03:09,  1.12s/it]Loading train:  37%|███▋      | 98/266 [01:22<03:02,  1.09s/it]Loading train:  37%|███▋      | 99/266 [01:23<02:48,  1.01s/it]Loading train:  38%|███▊      | 100/266 [01:24<02:48,  1.02s/it]Loading train:  38%|███▊      | 101/266 [01:25<02:32,  1.08it/s]Loading train:  38%|███▊      | 102/266 [01:25<02:20,  1.17it/s]Loading train:  39%|███▊      | 103/266 [01:26<02:09,  1.25it/s]Loading train:  39%|███▉      | 104/266 [01:27<02:02,  1.32it/s]Loading train:  39%|███▉      | 105/266 [01:27<02:01,  1.32it/s]Loading train:  40%|███▉      | 106/266 [01:28<02:00,  1.32it/s]Loading train:  40%|████      | 107/266 [01:29<01:58,  1.34it/s]Loading train:  41%|████      | 108/266 [01:30<01:58,  1.33it/s]Loading train:  41%|████      | 109/266 [01:30<01:56,  1.34it/s]Loading train:  41%|████▏     | 110/266 [01:31<01:55,  1.35it/s]Loading train:  42%|████▏     | 111/266 [01:32<01:56,  1.34it/s]Loading train:  42%|████▏     | 112/266 [01:33<01:54,  1.34it/s]Loading train:  42%|████▏     | 113/266 [01:33<01:52,  1.37it/s]Loading train:  43%|████▎     | 114/266 [01:34<01:49,  1.38it/s]Loading train:  43%|████▎     | 115/266 [01:35<01:50,  1.36it/s]Loading train:  44%|████▎     | 116/266 [01:35<01:48,  1.38it/s]Loading train:  44%|████▍     | 117/266 [01:36<01:45,  1.41it/s]Loading train:  44%|████▍     | 118/266 [01:37<01:48,  1.36it/s]Loading train:  45%|████▍     | 119/266 [01:38<01:52,  1.30it/s]Loading train:  45%|████▌     | 120/266 [01:39<01:52,  1.30it/s]Loading train:  45%|████▌     | 121/266 [01:39<01:52,  1.29it/s]Loading train:  46%|████▌     | 122/266 [01:40<01:53,  1.27it/s]Loading train:  46%|████▌     | 123/266 [01:41<01:58,  1.21it/s]Loading train:  47%|████▋     | 124/266 [01:42<02:00,  1.18it/s]Loading train:  47%|████▋     | 125/266 [01:43<02:00,  1.17it/s]Loading train:  47%|████▋     | 126/266 [01:44<01:59,  1.17it/s]Loading train:  48%|████▊     | 127/266 [01:45<01:58,  1.17it/s]Loading train:  48%|████▊     | 128/266 [01:45<01:59,  1.15it/s]Loading train:  48%|████▊     | 129/266 [01:46<01:57,  1.16it/s]Loading train:  49%|████▉     | 130/266 [01:47<01:56,  1.17it/s]Loading train:  49%|████▉     | 131/266 [01:48<01:54,  1.18it/s]Loading train:  50%|████▉     | 132/266 [01:49<01:53,  1.18it/s]Loading train:  50%|█████     | 133/266 [01:50<01:54,  1.16it/s]Loading train:  50%|█████     | 134/266 [01:51<01:53,  1.17it/s]Loading train:  51%|█████     | 135/266 [01:51<01:51,  1.17it/s]Loading train:  51%|█████     | 136/266 [01:52<01:51,  1.17it/s]Loading train:  52%|█████▏    | 137/266 [01:53<01:47,  1.20it/s]Loading train:  52%|█████▏    | 138/266 [01:54<01:46,  1.21it/s]Loading train:  52%|█████▏    | 139/266 [01:55<01:42,  1.24it/s]Loading train:  53%|█████▎    | 140/266 [01:55<01:39,  1.27it/s]Loading train:  53%|█████▎    | 141/266 [01:56<01:39,  1.25it/s]Loading train:  53%|█████▎    | 142/266 [01:57<01:39,  1.24it/s]Loading train:  54%|█████▍    | 143/266 [01:58<01:37,  1.27it/s]Loading train:  54%|█████▍    | 144/266 [01:58<01:34,  1.29it/s]Loading train:  55%|█████▍    | 145/266 [01:59<01:35,  1.27it/s]Loading train:  55%|█████▍    | 146/266 [02:00<01:35,  1.25it/s]Loading train:  55%|█████▌    | 147/266 [02:01<01:34,  1.26it/s]Loading train:  56%|█████▌    | 148/266 [02:02<01:34,  1.25it/s]Loading train:  56%|█████▌    | 149/266 [02:03<01:35,  1.22it/s]Loading train:  56%|█████▋    | 150/266 [02:03<01:34,  1.23it/s]Loading train:  57%|█████▋    | 151/266 [02:04<01:33,  1.23it/s]Loading train:  57%|█████▋    | 152/266 [02:05<01:31,  1.25it/s]Loading train:  58%|█████▊    | 153/266 [02:06<01:29,  1.26it/s]Loading train:  58%|█████▊    | 154/266 [02:07<01:29,  1.25it/s]Loading train:  58%|█████▊    | 155/266 [02:07<01:22,  1.34it/s]Loading train:  59%|█████▊    | 156/266 [02:08<01:15,  1.45it/s]Loading train:  59%|█████▉    | 157/266 [02:08<01:13,  1.48it/s]Loading train:  59%|█████▉    | 158/266 [02:09<01:11,  1.52it/s]Loading train:  60%|█████▉    | 159/266 [02:10<01:08,  1.57it/s]Loading train:  60%|██████    | 160/266 [02:10<01:07,  1.58it/s]Loading train:  61%|██████    | 161/266 [02:11<01:05,  1.61it/s]Loading train:  61%|██████    | 162/266 [02:12<01:07,  1.55it/s]Loading train:  61%|██████▏   | 163/266 [02:12<01:05,  1.57it/s]Loading train:  62%|██████▏   | 164/266 [02:13<01:04,  1.59it/s]Loading train:  62%|██████▏   | 165/266 [02:13<01:04,  1.56it/s]Loading train:  62%|██████▏   | 166/266 [02:14<01:03,  1.56it/s]Loading train:  63%|██████▎   | 167/266 [02:15<01:02,  1.60it/s]Loading train:  63%|██████▎   | 168/266 [02:15<01:00,  1.62it/s]Loading train:  64%|██████▎   | 169/266 [02:16<01:01,  1.57it/s]Loading train:  64%|██████▍   | 170/266 [02:17<01:01,  1.56it/s]Loading train:  64%|██████▍   | 171/266 [02:17<01:01,  1.55it/s]Loading train:  65%|██████▍   | 172/266 [02:18<00:58,  1.60it/s]Loading train:  65%|██████▌   | 173/266 [02:19<01:00,  1.54it/s]Loading train:  65%|██████▌   | 174/266 [02:19<00:59,  1.54it/s]Loading train:  66%|██████▌   | 175/266 [02:20<00:58,  1.55it/s]Loading train:  66%|██████▌   | 176/266 [02:20<00:59,  1.52it/s]Loading train:  67%|██████▋   | 177/266 [02:21<00:58,  1.53it/s]Loading train:  67%|██████▋   | 178/266 [02:22<00:56,  1.56it/s]Loading train:  67%|██████▋   | 179/266 [02:22<00:56,  1.53it/s]Loading train:  68%|██████▊   | 180/266 [02:23<00:57,  1.49it/s]Loading train:  68%|██████▊   | 181/266 [02:24<00:56,  1.51it/s]Loading train:  68%|██████▊   | 182/266 [02:24<00:55,  1.51it/s]Loading train:  69%|██████▉   | 183/266 [02:25<00:56,  1.48it/s]Loading train:  69%|██████▉   | 184/266 [02:26<00:55,  1.47it/s]Loading train:  70%|██████▉   | 185/266 [02:26<00:53,  1.50it/s]Loading train:  70%|██████▉   | 186/266 [02:27<00:56,  1.42it/s]Loading train:  70%|███████   | 187/266 [02:28<00:56,  1.40it/s]Loading train:  71%|███████   | 188/266 [02:29<00:54,  1.42it/s]Loading train:  71%|███████   | 189/266 [02:29<00:53,  1.44it/s]Loading train:  71%|███████▏  | 190/266 [02:30<00:51,  1.47it/s]Loading train:  72%|███████▏  | 191/266 [02:31<01:00,  1.24it/s]Loading train:  72%|███████▏  | 192/266 [02:32<01:02,  1.18it/s]Loading train:  73%|███████▎  | 193/266 [02:33<01:05,  1.11it/s]Loading train:  73%|███████▎  | 194/266 [02:34<01:16,  1.06s/it]Loading train:  73%|███████▎  | 195/266 [02:35<01:10,  1.01it/s]Loading train:  74%|███████▎  | 196/266 [02:36<01:03,  1.10it/s]Loading train:  74%|███████▍  | 197/266 [02:37<00:59,  1.16it/s]Loading train:  74%|███████▍  | 198/266 [02:38<00:57,  1.19it/s]Loading train:  75%|███████▍  | 199/266 [02:38<00:53,  1.25it/s]Loading train:  75%|███████▌  | 200/266 [02:39<00:50,  1.30it/s]Loading train:  76%|███████▌  | 201/266 [02:40<00:49,  1.32it/s]Loading train:  76%|███████▌  | 202/266 [02:40<00:48,  1.32it/s]Loading train:  76%|███████▋  | 203/266 [02:41<00:49,  1.27it/s]Loading train:  77%|███████▋  | 204/266 [02:42<00:48,  1.27it/s]Loading train:  77%|███████▋  | 205/266 [02:43<00:48,  1.26it/s]Loading train:  77%|███████▋  | 206/266 [02:44<00:47,  1.25it/s]Loading train:  78%|███████▊  | 207/266 [02:45<00:47,  1.23it/s]Loading train:  78%|███████▊  | 208/266 [02:45<00:45,  1.28it/s]Loading train:  79%|███████▊  | 209/266 [02:46<00:44,  1.29it/s]Loading train:  79%|███████▉  | 210/266 [02:47<00:43,  1.30it/s]Loading train:  79%|███████▉  | 211/266 [02:48<00:42,  1.29it/s]Loading train:  80%|███████▉  | 212/266 [02:48<00:42,  1.26it/s]Loading train:  80%|████████  | 213/266 [02:49<00:41,  1.29it/s]Loading train:  80%|████████  | 214/266 [02:50<00:38,  1.34it/s]Loading train:  81%|████████  | 215/266 [02:51<00:37,  1.37it/s]Loading train:  81%|████████  | 216/266 [02:51<00:36,  1.39it/s]Loading train:  82%|████████▏ | 217/266 [02:52<00:34,  1.43it/s]Loading train:  82%|████████▏ | 218/266 [02:53<00:34,  1.41it/s]Loading train:  82%|████████▏ | 219/266 [02:53<00:33,  1.41it/s]Loading train:  83%|████████▎ | 220/266 [02:54<00:33,  1.38it/s]Loading train:  83%|████████▎ | 221/266 [02:55<00:32,  1.40it/s]Loading train:  83%|████████▎ | 222/266 [02:55<00:31,  1.41it/s]Loading train:  84%|████████▍ | 223/266 [02:56<00:30,  1.43it/s]Loading train:  84%|████████▍ | 224/266 [02:57<00:29,  1.41it/s]Loading train:  85%|████████▍ | 225/266 [02:58<00:29,  1.40it/s]Loading train:  85%|████████▍ | 226/266 [02:58<00:29,  1.38it/s]Loading train:  85%|████████▌ | 227/266 [02:59<00:27,  1.40it/s]Loading train:  86%|████████▌ | 228/266 [03:00<00:27,  1.37it/s]Loading train:  86%|████████▌ | 229/266 [03:01<00:27,  1.35it/s]Loading train:  86%|████████▋ | 230/266 [03:01<00:27,  1.33it/s]Loading train:  87%|████████▋ | 231/266 [03:02<00:26,  1.32it/s]Loading train:  87%|████████▋ | 232/266 [03:03<00:25,  1.33it/s]Loading train:  88%|████████▊ | 233/266 [03:04<00:24,  1.33it/s]Loading train:  88%|████████▊ | 234/266 [03:04<00:24,  1.33it/s]Loading train:  88%|████████▊ | 235/266 [03:05<00:22,  1.37it/s]Loading train:  89%|████████▊ | 236/266 [03:06<00:21,  1.38it/s]Loading train:  89%|████████▉ | 237/266 [03:07<00:21,  1.34it/s]Loading train:  89%|████████▉ | 238/266 [03:07<00:20,  1.35it/s]Loading train:  90%|████████▉ | 239/266 [03:08<00:19,  1.39it/s]Loading train:  90%|█████████ | 240/266 [03:09<00:18,  1.43it/s]Loading train:  91%|█████████ | 241/266 [03:09<00:17,  1.47it/s]Loading train:  91%|█████████ | 242/266 [03:10<00:16,  1.50it/s]Loading train:  91%|█████████▏| 243/266 [03:11<00:15,  1.50it/s]Loading train:  92%|█████████▏| 244/266 [03:11<00:14,  1.50it/s]Loading train:  92%|█████████▏| 245/266 [03:12<00:13,  1.51it/s]Loading train:  92%|█████████▏| 246/266 [03:13<00:13,  1.47it/s]Loading train:  93%|█████████▎| 247/266 [03:13<00:12,  1.52it/s]Loading train:  93%|█████████▎| 248/266 [03:14<00:11,  1.54it/s]Loading train:  94%|█████████▎| 249/266 [03:15<00:12,  1.36it/s]Loading train:  94%|█████████▍| 250/266 [03:16<00:12,  1.28it/s]Loading train:  94%|█████████▍| 251/266 [03:17<00:12,  1.20it/s]Loading train:  95%|█████████▍| 252/266 [03:17<00:11,  1.23it/s]Loading train:  95%|█████████▌| 253/266 [03:18<00:11,  1.17it/s]Loading train:  95%|█████████▌| 254/266 [03:19<00:10,  1.15it/s]Loading train:  96%|█████████▌| 255/266 [03:20<00:09,  1.14it/s]Loading train:  96%|█████████▌| 256/266 [03:21<00:08,  1.11it/s]Loading train:  97%|█████████▋| 257/266 [03:22<00:08,  1.10it/s]Loading train:  97%|█████████▋| 258/266 [03:23<00:07,  1.09it/s]Loading train:  97%|█████████▋| 259/266 [03:24<00:06,  1.11it/s]Loading train:  98%|█████████▊| 260/266 [03:25<00:05,  1.09it/s]Loading train:  98%|█████████▊| 261/266 [03:26<00:04,  1.11it/s]Loading train:  98%|█████████▊| 262/266 [03:26<00:03,  1.13it/s]Loading train:  99%|█████████▉| 263/266 [03:27<00:02,  1.14it/s]Loading train:  99%|█████████▉| 264/266 [03:28<00:01,  1.13it/s]Loading train: 100%|█████████▉| 265/266 [03:29<00:00,  1.15it/s]Loading train: 100%|██████████| 266/266 [03:30<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 16/266 [00:00<00:01, 152.88it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:01, 153.17it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:01, 149.76it/s]concatenating: train:  25%|██▍       | 66/266 [00:00<00:01, 159.44it/s]concatenating: train:  32%|███▏      | 85/266 [00:00<00:01, 167.34it/s]concatenating: train:  39%|███▉      | 105/266 [00:00<00:00, 173.40it/s]concatenating: train:  45%|████▌     | 121/266 [00:00<00:00, 164.58it/s]concatenating: train:  52%|█████▏    | 138/266 [00:00<00:00, 164.20it/s]concatenating: train:  59%|█████▉    | 157/266 [00:00<00:00, 170.23it/s]concatenating: train:  65%|██████▌   | 174/266 [00:01<00:00, 164.26it/s]concatenating: train:  72%|███████▏  | 191/266 [00:01<00:00, 161.04it/s]concatenating: train:  79%|███████▉  | 210/266 [00:01<00:00, 168.36it/s]concatenating: train:  89%|████████▉ | 238/266 [00:01<00:00, 190.27it/s]concatenating: train:  98%|█████████▊| 262/266 [00:01<00:00, 201.98it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 180.63it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.18s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.18s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.16s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.11s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 507.40it/s]2019-08-16 22:54:39.815984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 22:54:39.816096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 22:54:39.816113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 22:54:39.816123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 22:54:39.816523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.61it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.73it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.39it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.18it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.98it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.78it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.97it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.38it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.48it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.57it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 11.10it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.20it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.71it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.71it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 11.06it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.21it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.66it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.28it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33981455e-02 3.28583785e-02 7.68347990e-02 9.54711013e-03
 2.76315107e-02 7.22900590e-03 8.42963668e-02 1.14202279e-01
 8.96713305e-02 1.36241955e-02 2.90732091e-01 1.89722815e-01
 2.51972551e-04]
Train on 9969 samples, validate on 179 samples
Epoch 1/300
 - 14s - loss: 2.2015 - acc: 0.6781 - mDice: 0.1803 - val_loss: 0.9773 - val_acc: 0.9143 - val_mDice: 0.3996

Epoch 00001: val_mDice improved from -inf to 0.39962, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 0.7158 - acc: 0.8963 - mDice: 0.4756 - val_loss: 0.6243 - val_acc: 0.9247 - val_mDice: 0.5323

Epoch 00002: val_mDice improved from 0.39962 to 0.53230, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.5432 - acc: 0.9041 - mDice: 0.5655 - val_loss: 0.5785 - val_acc: 0.9299 - val_mDice: 0.5551

Epoch 00003: val_mDice improved from 0.53230 to 0.55505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.4718 - acc: 0.9095 - mDice: 0.6093 - val_loss: 0.5525 - val_acc: 0.9354 - val_mDice: 0.5660

Epoch 00004: val_mDice improved from 0.55505 to 0.56602, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.4234 - acc: 0.9152 - mDice: 0.6408 - val_loss: 0.5071 - val_acc: 0.9366 - val_mDice: 0.5917

Epoch 00005: val_mDice improved from 0.56602 to 0.59172, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.3905 - acc: 0.9202 - mDice: 0.6631 - val_loss: 0.5270 - val_acc: 0.9371 - val_mDice: 0.5834

Epoch 00006: val_mDice did not improve from 0.59172
Epoch 7/300
 - 10s - loss: 0.3673 - acc: 0.9249 - mDice: 0.6792 - val_loss: 0.4731 - val_acc: 0.9413 - val_mDice: 0.6148

Epoch 00007: val_mDice improved from 0.59172 to 0.61485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.3474 - acc: 0.9279 - mDice: 0.6934 - val_loss: 0.4879 - val_acc: 0.9411 - val_mDice: 0.6082

Epoch 00008: val_mDice did not improve from 0.61485
Epoch 9/300
 - 9s - loss: 0.3335 - acc: 0.9300 - mDice: 0.7035 - val_loss: 0.4790 - val_acc: 0.9426 - val_mDice: 0.6111

Epoch 00009: val_mDice did not improve from 0.61485
Epoch 10/300
 - 10s - loss: 0.3206 - acc: 0.9322 - mDice: 0.7130 - val_loss: 0.4704 - val_acc: 0.9441 - val_mDice: 0.6178

Epoch 00010: val_mDice improved from 0.61485 to 0.61778, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.3129 - acc: 0.9343 - mDice: 0.7218 - val_loss: 1.0337 - val_acc: 0.9378 - val_mDice: 0.5327

Epoch 00011: val_mDice did not improve from 0.61778
Epoch 12/300
 - 9s - loss: 0.3070 - acc: 0.9362 - mDice: 0.7235 - val_loss: 0.4797 - val_acc: 0.9474 - val_mDice: 0.6131

Epoch 00012: val_mDice did not improve from 0.61778
Epoch 13/300
 - 9s - loss: 0.3005 - acc: 0.9391 - mDice: 0.7329 - val_loss: 0.5845 - val_acc: 0.9444 - val_mDice: 0.6001

Epoch 00013: val_mDice did not improve from 0.61778
Epoch 14/300
 - 10s - loss: 0.2831 - acc: 0.9428 - mDice: 0.7410 - val_loss: 0.4901 - val_acc: 0.9482 - val_mDice: 0.6108

Epoch 00014: val_mDice did not improve from 0.61778
Epoch 15/300
 - 10s - loss: 0.2768 - acc: 0.9448 - mDice: 0.7458 - val_loss: 0.4750 - val_acc: 0.9485 - val_mDice: 0.6145

Epoch 00015: val_mDice did not improve from 0.61778
Epoch 16/300
 - 10s - loss: 0.2715 - acc: 0.9461 - mDice: 0.7498 - val_loss: 0.4882 - val_acc: 0.9467 - val_mDice: 0.6056

Epoch 00016: val_mDice did not improve from 0.61778
Epoch 17/300
 - 10s - loss: 0.2665 - acc: 0.9471 - mDice: 0.7539 - val_loss: 0.4942 - val_acc: 0.9491 - val_mDice: 0.6142

Epoch 00017: val_mDice did not improve from 0.61778
Epoch 18/300
 - 10s - loss: 0.2629 - acc: 0.9477 - mDice: 0.7565 - val_loss: 0.4834 - val_acc: 0.9472 - val_mDice: 0.6073

Epoch 00018: val_mDice did not improve from 0.61778
Epoch 19/300
 - 10s - loss: 0.2574 - acc: 0.9486 - mDice: 0.7609 - val_loss: 0.5041 - val_acc: 0.9445 - val_mDice: 0.6022

Epoch 00019: val_mDice did not improve from 0.61778
Epoch 20/300
 - 10s - loss: 0.2530 - acc: 0.9491 - mDice: 0.7643 - val_loss: 0.5081 - val_acc: 0.9448 - val_mDice: 0.5960

Epoch 00020: val_mDice did not improve from 0.61778
Epoch 21/300
 - 10s - loss: 0.2663 - acc: 0.9484 - mDice: 0.7548 - val_loss: 0.5573 - val_acc: 0.9474 - val_mDice: 0.5909

Epoch 00021: val_mDice did not improve from 0.61778
Epoch 22/300
 - 10s - loss: 0.2491 - acc: 0.9501 - mDice: 0.7674 - val_loss: 0.5049 - val_acc: 0.9455 - val_mDice: 0.6062

Epoch 00022: val_mDice did not improve from 0.61778
Epoch 23/300
 - 10s - loss: 0.2427 - acc: 0.9509 - mDice: 0.7726 - val_loss: 0.4628 - val_acc: 0.9485 - val_mDice: 0.6180

Epoch 00023: val_mDice improved from 0.61778 to 0.61795, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 10s - loss: 0.2417 - acc: 0.9513 - mDice: 0.7735 - val_loss: 0.7783 - val_acc: 0.9392 - val_mDice: 0.5710

Epoch 00024: val_mDice did not improve from 0.61795
Epoch 25/300
 - 10s - loss: 0.2404 - acc: 0.9518 - mDice: 0.7765 - val_loss: 0.5374 - val_acc: 0.9474 - val_mDice: 0.5873

Epoch 00025: val_mDice did not improve from 0.61795
Epoch 26/300
 - 10s - loss: 0.2348 - acc: 0.9523 - mDice: 0.7790 - val_loss: 0.4810 - val_acc: 0.9488 - val_mDice: 0.6135

Epoch 00026: val_mDice did not improve from 0.61795
Epoch 27/300
 - 11s - loss: 0.2337 - acc: 0.9527 - mDice: 0.7799 - val_loss: 0.5877 - val_acc: 0.9460 - val_mDice: 0.5710

Epoch 00027: val_mDice did not improve from 0.61795
Epoch 28/300
 - 12s - loss: 0.2315 - acc: 0.9531 - mDice: 0.7819 - val_loss: 0.5022 - val_acc: 0.9495 - val_mDice: 0.6081

Epoch 00028: val_mDice did not improve from 0.61795
Epoch 29/300
 - 13s - loss: 0.2286 - acc: 0.9533 - mDice: 0.7841 - val_loss: 0.4726 - val_acc: 0.9504 - val_mDice: 0.6190

Epoch 00029: val_mDice improved from 0.61795 to 0.61904, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 12s - loss: 0.2275 - acc: 0.9536 - mDice: 0.7850 - val_loss: 0.5146 - val_acc: 0.9495 - val_mDice: 0.6055

Epoch 00030: val_mDice did not improve from 0.61904
Epoch 31/300
 - 13s - loss: 0.2242 - acc: 0.9539 - mDice: 0.7877 - val_loss: 0.4644 - val_acc: 0.9513 - val_mDice: 0.6233

Epoch 00031: val_mDice improved from 0.61904 to 0.62334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 13s - loss: 0.2235 - acc: 0.9540 - mDice: 0.7883 - val_loss: 0.7021 - val_acc: 0.9497 - val_mDice: 0.6156

Epoch 00032: val_mDice did not improve from 0.62334
Epoch 33/300
 - 13s - loss: 0.2208 - acc: 0.9543 - mDice: 0.7905 - val_loss: 0.4617 - val_acc: 0.9472 - val_mDice: 0.6216

Epoch 00033: val_mDice did not improve from 0.62334
Epoch 34/300
 - 13s - loss: 0.2193 - acc: 0.9546 - mDice: 0.7917 - val_loss: 0.4923 - val_acc: 0.9485 - val_mDice: 0.6129

Epoch 00034: val_mDice did not improve from 0.62334
Epoch 35/300
 - 12s - loss: 0.2175 - acc: 0.9549 - mDice: 0.7931 - val_loss: 0.5176 - val_acc: 0.9481 - val_mDice: 0.6159

Epoch 00035: val_mDice did not improve from 0.62334
Epoch 36/300
 - 11s - loss: 0.2160 - acc: 0.9550 - mDice: 0.7944 - val_loss: 0.5328 - val_acc: 0.9487 - val_mDice: 0.6164

Epoch 00036: val_mDice did not improve from 0.62334
Epoch 37/300
 - 12s - loss: 0.2153 - acc: 0.9551 - mDice: 0.7950 - val_loss: 0.4826 - val_acc: 0.9516 - val_mDice: 0.6140

Epoch 00037: val_mDice did not improve from 0.62334
Epoch 38/300
 - 12s - loss: 0.2138 - acc: 0.9554 - mDice: 0.7964 - val_loss: 0.5064 - val_acc: 0.9505 - val_mDice: 0.6031

Epoch 00038: val_mDice did not improve from 0.62334
Epoch 39/300
 - 12s - loss: 0.2127 - acc: 0.9555 - mDice: 0.7973 - val_loss: 0.5026 - val_acc: 0.9517 - val_mDice: 0.6162

Epoch 00039: val_mDice did not improve from 0.62334
Epoch 40/300
 - 12s - loss: 0.2092 - acc: 0.9557 - mDice: 0.8001 - val_loss: 0.4773 - val_acc: 0.9524 - val_mDice: 0.6172

Epoch 00040: val_mDice did not improve from 0.62334
Epoch 41/300
 - 13s - loss: 0.2106 - acc: 0.9559 - mDice: 0.8006 - val_loss: 0.6157 - val_acc: 0.9488 - val_mDice: 0.5985

Epoch 00041: val_mDice did not improve from 0.62334
Epoch 42/300
 - 13s - loss: 0.2130 - acc: 0.9555 - mDice: 0.7970 - val_loss: 0.4697 - val_acc: 0.9501 - val_mDice: 0.6269

Epoch 00042: val_mDice improved from 0.62334 to 0.62685, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 12s - loss: 0.2067 - acc: 0.9563 - mDice: 0.8023 - val_loss: 0.6984 - val_acc: 0.9520 - val_mDice: 0.6214

Epoch 00043: val_mDice did not improve from 0.62685
Epoch 44/300
 - 12s - loss: 0.2087 - acc: 0.9561 - mDice: 0.8009 - val_loss: 0.7156 - val_acc: 0.9512 - val_mDice: 0.6119

Epoch 00044: val_mDice did not improve from 0.62685
Epoch 45/300
 - 12s - loss: 0.2074 - acc: 0.9563 - mDice: 0.8018 - val_loss: 0.4524 - val_acc: 0.9513 - val_mDice: 0.6270

Epoch 00045: val_mDice improved from 0.62685 to 0.62699, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 12s - loss: 0.2039 - acc: 0.9564 - mDice: 0.8046 - val_loss: 0.4981 - val_acc: 0.9508 - val_mDice: 0.6110

Epoch 00046: val_mDice did not improve from 0.62699
Epoch 47/300
 - 12s - loss: 0.2030 - acc: 0.9567 - mDice: 0.8053 - val_loss: 0.7021 - val_acc: 0.9493 - val_mDice: 0.6185

Epoch 00047: val_mDice did not improve from 0.62699
Epoch 48/300
 - 12s - loss: 0.2010 - acc: 0.9568 - mDice: 0.8070 - val_loss: 0.4981 - val_acc: 0.9490 - val_mDice: 0.6110

Epoch 00048: val_mDice did not improve from 0.62699
Epoch 49/300
 - 12s - loss: 0.1999 - acc: 0.9569 - mDice: 0.8080 - val_loss: 0.7103 - val_acc: 0.9502 - val_mDice: 0.6130

Epoch 00049: val_mDice did not improve from 0.62699
Epoch 50/300
 - 12s - loss: 0.1982 - acc: 0.9571 - mDice: 0.8094 - val_loss: 0.7112 - val_acc: 0.9514 - val_mDice: 0.6131

Epoch 00050: val_mDice did not improve from 0.62699
Epoch 51/300
 - 12s - loss: 0.1984 - acc: 0.9571 - mDice: 0.8092 - val_loss: 0.7156 - val_acc: 0.9491 - val_mDice: 0.5981

Epoch 00051: val_mDice did not improve from 0.62699
Epoch 52/300
 - 12s - loss: 0.2031 - acc: 0.9571 - mDice: 0.8087 - val_loss: 0.7279 - val_acc: 0.9513 - val_mDice: 0.6058

Epoch 00052: val_mDice did not improve from 0.62699
Epoch 53/300
 - 12s - loss: 0.2097 - acc: 0.9560 - mDice: 0.8000 - val_loss: 0.6373 - val_acc: 0.9523 - val_mDice: 0.6104

Epoch 00053: val_mDice did not improve from 0.62699
Epoch 54/300
 - 12s - loss: 0.1973 - acc: 0.9573 - mDice: 0.8102 - val_loss: 0.7278 - val_acc: 0.9504 - val_mDice: 0.6042

Epoch 00054: val_mDice did not improve from 0.62699
Epoch 55/300
 - 12s - loss: 0.1958 - acc: 0.9576 - mDice: 0.8115 - val_loss: 0.4958 - val_acc: 0.9522 - val_mDice: 0.6101

Epoch 00055: val_mDice did not improve from 0.62699
Epoch 56/300
 - 13s - loss: 0.1972 - acc: 0.9575 - mDice: 0.8121 - val_loss: 0.7698 - val_acc: 0.9494 - val_mDice: 0.5848

Epoch 00056: val_mDice did not improve from 0.62699
Epoch 57/300
 - 13s - loss: 0.1946 - acc: 0.9576 - mDice: 0.8124 - val_loss: 0.7312 - val_acc: 0.9505 - val_mDice: 0.6028

Epoch 00057: val_mDice did not improve from 0.62699
Epoch 58/300
 - 13s - loss: 0.1936 - acc: 0.9578 - mDice: 0.8134 - val_loss: 0.7133 - val_acc: 0.9498 - val_mDice: 0.6122

Epoch 00058: val_mDice did not improve from 0.62699
Epoch 59/300
 - 12s - loss: 0.1911 - acc: 0.9580 - mDice: 0.8154 - val_loss: 0.5630 - val_acc: 0.9513 - val_mDice: 0.6086

Epoch 00059: val_mDice did not improve from 0.62699
Epoch 60/300
 - 12s - loss: 0.1904 - acc: 0.9581 - mDice: 0.8161 - val_loss: 0.4984 - val_acc: 0.9505 - val_mDice: 0.6050

Epoch 00060: val_mDice did not improve from 0.62699
Epoch 61/300
 - 12s - loss: 0.1907 - acc: 0.9581 - mDice: 0.8158 - val_loss: 0.7036 - val_acc: 0.9506 - val_mDice: 0.6182

Epoch 00061: val_mDice did not improve from 0.62699
Epoch 62/300
 - 12s - loss: 0.1897 - acc: 0.9581 - mDice: 0.8167 - val_loss: 0.7297 - val_acc: 0.9514 - val_mDice: 0.6033

Epoch 00062: val_mDice did not improve from 0.62699
Epoch 63/300
 - 12s - loss: 0.1911 - acc: 0.9580 - mDice: 0.8155 - val_loss: 0.7076 - val_acc: 0.9519 - val_mDice: 0.6165

Epoch 00063: val_mDice did not improve from 0.62699
Epoch 64/300
 - 12s - loss: 0.1875 - acc: 0.9583 - mDice: 0.8186 - val_loss: 0.4672 - val_acc: 0.9514 - val_mDice: 0.6243

Epoch 00064: val_mDice did not improve from 0.62699
Epoch 65/300
 - 12s - loss: 0.1941 - acc: 0.9578 - mDice: 0.8133 - val_loss: 0.7013 - val_acc: 0.9530 - val_mDice: 0.6200

Epoch 00065: val_mDice did not improve from 0.62699
Epoch 66/300
 - 12s - loss: 0.1897 - acc: 0.9582 - mDice: 0.8168 - val_loss: 0.4856 - val_acc: 0.9502 - val_mDice: 0.6128

Epoch 00066: val_mDice did not improve from 0.62699
Epoch 67/300
 - 12s - loss: 0.1886 - acc: 0.9583 - mDice: 0.8176 - val_loss: 0.7335 - val_acc: 0.9471 - val_mDice: 0.6001

Epoch 00067: val_mDice did not improve from 0.62699
Epoch 68/300
 - 13s - loss: 0.1885 - acc: 0.9584 - mDice: 0.8178 - val_loss: 0.4933 - val_acc: 0.9518 - val_mDice: 0.6148

Epoch 00068: val_mDice did not improve from 0.62699
Epoch 69/300
 - 13s - loss: 0.1861 - acc: 0.9586 - mDice: 0.8198 - val_loss: 0.7055 - val_acc: 0.9526 - val_mDice: 0.6167

Epoch 00069: val_mDice did not improve from 0.62699
Epoch 70/300
 - 13s - loss: 0.1864 - acc: 0.9586 - mDice: 0.8195 - val_loss: 0.7134 - val_acc: 0.9464 - val_mDice: 0.6121

Epoch 00070: val_mDice did not improve from 0.62699
Epoch 71/300
 - 13s - loss: 0.1855 - acc: 0.9586 - mDice: 0.8203 - val_loss: 0.5618 - val_acc: 0.9526 - val_mDice: 0.6238

Epoch 00071: val_mDice did not improve from 0.62699
Epoch 72/300
 - 13s - loss: 0.1857 - acc: 0.9587 - mDice: 0.8202 - val_loss: 0.5530 - val_acc: 0.9481 - val_mDice: 0.5863

Epoch 00072: val_mDice did not improve from 0.62699
Epoch 73/300
 - 12s - loss: 0.1842 - acc: 0.9588 - mDice: 0.8214 - val_loss: 0.5034 - val_acc: 0.9510 - val_mDice: 0.6062

Epoch 00073: val_mDice did not improve from 0.62699
Epoch 74/300
 - 13s - loss: 0.1858 - acc: 0.9588 - mDice: 0.8201 - val_loss: 0.7209 - val_acc: 0.9470 - val_mDice: 0.6070

Epoch 00074: val_mDice did not improve from 0.62699
Epoch 75/300
 - 12s - loss: 0.1834 - acc: 0.9589 - mDice: 0.8221 - val_loss: 0.7256 - val_acc: 0.9466 - val_mDice: 0.6064

Epoch 00075: val_mDice did not improve from 0.62699
Epoch 76/300
 - 12s - loss: 0.1840 - acc: 0.9589 - mDice: 0.8216 - val_loss: 0.7042 - val_acc: 0.9506 - val_mDice: 0.6179

Epoch 00076: val_mDice did not improve from 0.62699
Epoch 77/300
 - 12s - loss: 0.1824 - acc: 0.9590 - mDice: 0.8230 - val_loss: 0.5355 - val_acc: 0.9493 - val_mDice: 0.6058

Epoch 00077: val_mDice did not improve from 0.62699
Epoch 78/300
 - 12s - loss: 0.1830 - acc: 0.9590 - mDice: 0.8225 - val_loss: 0.7010 - val_acc: 0.9523 - val_mDice: 0.6205

Epoch 00078: val_mDice did not improve from 0.62699
Epoch 79/300
 - 12s - loss: 0.1833 - acc: 0.9590 - mDice: 0.8223 - val_loss: 0.4754 - val_acc: 0.9511 - val_mDice: 0.6165

Epoch 00079: val_mDice did not improve from 0.62699
Epoch 80/300
 - 12s - loss: 0.1845 - acc: 0.9591 - mDice: 0.8229 - val_loss: 0.4807 - val_acc: 0.9517 - val_mDice: 0.6161

Epoch 00080: val_mDice did not improve from 0.62699
Epoch 81/300
 - 12s - loss: 0.1820 - acc: 0.9591 - mDice: 0.8235 - val_loss: 0.6404 - val_acc: 0.9529 - val_mDice: 0.6172

Epoch 00081: val_mDice did not improve from 0.62699
Epoch 82/300
 - 12s - loss: 0.1808 - acc: 0.9592 - mDice: 0.8244 - val_loss: 0.7022 - val_acc: 0.9521 - val_mDice: 0.6192

Epoch 00082: val_mDice did not improve from 0.62699
Epoch 83/300
 - 12s - loss: 0.1807 - acc: 0.9593 - mDice: 0.8246 - val_loss: 0.7465 - val_acc: 0.9480 - val_mDice: 0.5903

Epoch 00083: val_mDice did not improve from 0.62699
Epoch 84/300
 - 12s - loss: 0.1857 - acc: 0.9590 - mDice: 0.8205 - val_loss: 0.7249 - val_acc: 0.9478 - val_mDice: 0.6055

Epoch 00084: val_mDice did not improve from 0.62699
Epoch 85/300
 - 12s - loss: 0.1800 - acc: 0.9594 - mDice: 0.8251 - val_loss: 0.7084 - val_acc: 0.9514 - val_mDice: 0.6152

Epoch 00085: val_mDice did not improve from 0.62699
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
{'val_loss': [0.9773070812225342, 0.6242977507287564, 0.5785006491165587, 0.552450709835777, 0.5070758536874249, 0.5269690195941392, 0.4730588687198788, 0.48793217722930055, 0.4789697780955437, 0.47040114888931783, 1.0336899104731043, 0.4797005819874769, 0.584542529210032, 0.4901283000434577, 0.4750354621330453, 0.488163893116253, 0.49416098248359214, 0.48339840420131575, 0.5041249091398783, 0.5080691775796133, 0.557269551900512, 0.5048708602702817, 0.46275414135203013, 0.7782801143283951, 0.5373521510449202, 0.48099385859580013, 0.5877099077128831, 0.5022424655919634, 0.47257603646656654, 0.5145607061226275, 0.46440120615772695, 0.7020953417490314, 0.46167765998973526, 0.49230465476073365, 0.5175589209828297, 0.5327714162165892, 0.48263921784289054, 0.5064415275717581, 0.5026480801944626, 0.4772700694020234, 0.6157218387673021, 0.4696713356332406, 0.6984289012141733, 0.7156181844919087, 0.4523616251665787, 0.49808574821695933, 0.7021059493778804, 0.4980769773435326, 0.7102819587931287, 0.7111903831945451, 0.715606072761493, 0.7278991857720487, 0.6373015482332454, 0.7278340432230986, 0.49584588192028706, 0.7697691411279434, 0.7312358754307198, 0.7132535250493268, 0.5629686460148688, 0.4983973809460688, 0.703552628362645, 0.7296560513240665, 0.7075994594137096, 0.46720033218074775, 0.701307342705114, 0.48563258940947124, 0.7334993428358153, 0.4933312731748187, 0.7055022480101559, 0.7134095770020724, 0.5618227250749173, 0.5530342373102071, 0.50335526532967, 0.7209381620977178, 0.725569440332871, 0.7041751089708765, 0.5354642398530545, 0.7009509721947782, 0.4754404212509454, 0.48069463445487637, 0.6404246491426863, 0.7022304261862898, 0.7465160009581283, 0.724894568906816, 0.7083657720235473], 'val_acc': [0.9142864796036448, 0.924671807102651, 0.9299233109591394, 0.9353896945548457, 0.936641793011287, 0.9370740995060798, 0.941333124757479, 0.9411016299737899, 0.9425698775152921, 0.9440982608155831, 0.9377864759061589, 0.9473890851995799, 0.9443885917104157, 0.9481590303628804, 0.9485325050753588, 0.9467483052994285, 0.9490645557808477, 0.947170393426991, 0.944490924560824, 0.9447914615023736, 0.9473545428094917, 0.9454718978045373, 0.948480047660167, 0.9391664995827489, 0.9473865505037361, 0.9487780735479386, 0.9460077971719497, 0.9495045129813295, 0.950358862650461, 0.9494827905846708, 0.9512861540863634, 0.9496605576083647, 0.9472368928973235, 0.9484711056315033, 0.9480580064837493, 0.9486578566402031, 0.9515688009768225, 0.9505200379387626, 0.9516596031588549, 0.9524065279427854, 0.9487588811853078, 0.9501082111337331, 0.9519742367653873, 0.9511518435105265, 0.9512643967260862, 0.9507988624732587, 0.949319070943907, 0.9490159446966715, 0.9501862176303757, 0.9513692739289566, 0.9491348945894721, 0.9512733444155261, 0.9522850323655752, 0.9504381854440913, 0.9521801581595863, 0.9493919937304278, 0.9504675998368077, 0.9497526344640295, 0.9512874137755879, 0.9504957352270628, 0.9506005997764332, 0.9513935733107881, 0.9519153959924282, 0.9514383460556328, 0.952953942328192, 0.9501644839121642, 0.9471000303103271, 0.9518476238463844, 0.952623953033426, 0.9464490303780113, 0.9525817582727144, 0.9480874152156894, 0.9510265152547612, 0.9470309794948087, 0.9465820632833343, 0.9506044447755014, 0.9492500111377439, 0.952324677446035, 0.9510687210040385, 0.9517325116269415, 0.9529040625641466, 0.9521443424278131, 0.9480145067476028, 0.9478226643700839, 0.9514421784012012], 'val_mDice': [0.39961644307861116, 0.532297056480493, 0.555052600093394, 0.5660236111566341, 0.5917181902091596, 0.5833690695922468, 0.614845958501933, 0.6081561975638959, 0.6110670193613574, 0.6177812281933577, 0.5327077547931138, 0.6131097787585338, 0.6001289317061781, 0.6107956197674714, 0.6145418149798942, 0.6056379272951095, 0.6141939033343139, 0.607342722695633, 0.6022280108329304, 0.5959657051043803, 0.5908553490425621, 0.6062438874271329, 0.6179539651178115, 0.5710021583727618, 0.5873327078765997, 0.613459971363984, 0.5710404119012076, 0.608100097605636, 0.6190357691082875, 0.6055479429287618, 0.6233447943319822, 0.6156413318724606, 0.6215880909445566, 0.6129282849461006, 0.615888335185344, 0.6163736035703947, 0.61403560505233, 0.6031073261905648, 0.6161968851222672, 0.6171881433305794, 0.5985439739413767, 0.6268521480720136, 0.621428738093243, 0.6119016681969499, 0.6269891082241549, 0.6109923453970328, 0.6184906496681981, 0.6109724174664674, 0.613025562057282, 0.6130666616242691, 0.5980978804593645, 0.605770255600274, 0.6104168432384895, 0.6041871901996975, 0.6100505460573974, 0.5847847238599255, 0.6027531174308095, 0.612185618064923, 0.6085768585098522, 0.6050300931131374, 0.618188109477805, 0.6032740780095148, 0.6164592984002396, 0.624339554562915, 0.6200413560734115, 0.6128407357125308, 0.6000710392797459, 0.6148301169858964, 0.6167417874549355, 0.6121024289610666, 0.6237632305928449, 0.5862929208318615, 0.6062231293603695, 0.6070181411071862, 0.6064151239128752, 0.6178546711053262, 0.6058014251666362, 0.6205016594359328, 0.6164997023577131, 0.6160556640704917, 0.6171543854574918, 0.6191911850561643, 0.5902643213724957, 0.6055136146492133, 0.6152106410298268], 'loss': [2.2014522062331867, 0.7158416201470668, 0.5432025570187362, 0.4717915489042471, 0.42336155992116764, 0.39051824581217703, 0.367267897183109, 0.3473791876711211, 0.33350638703987107, 0.3205765437513025, 0.3129296598815669, 0.30702371174993315, 0.300516789805412, 0.28309260296933997, 0.2767747101991582, 0.2714643273911776, 0.26646088963107867, 0.26293114255801736, 0.25736933942125245, 0.25298420341242783, 0.2663018054694419, 0.249111140715417, 0.24267386762790208, 0.24166224904082606, 0.24044513051578495, 0.23483043122087083, 0.23371275271691605, 0.23146951504254223, 0.22864361800165947, 0.2274895649112231, 0.22422608277726908, 0.2234625738737803, 0.22078950160400404, 0.21934257950403946, 0.21754735723931568, 0.21603067089064643, 0.21534676025039107, 0.2137605679158952, 0.21271926597058205, 0.2092050279824446, 0.2106320408470641, 0.21302448925647685, 0.20666148325291783, 0.20865478262055637, 0.20740597644215997, 0.20388485432382644, 0.20304465844998545, 0.20103559219343323, 0.1998939894708519, 0.19817011696439243, 0.198432840921836, 0.20313038547606557, 0.20974134678843745, 0.197268988412856, 0.19578435021084617, 0.19715568920723928, 0.19461412241142245, 0.19355693183131556, 0.19110660005033117, 0.1903925764353228, 0.19069780076305826, 0.1897449933193502, 0.19114049249856974, 0.1874982922976301, 0.1941093479107801, 0.18972284049737392, 0.1885634217213599, 0.18846939301458496, 0.18607835997034666, 0.18643967121651184, 0.1854998553193241, 0.18565318486296864, 0.18422846333476411, 0.1858160697056018, 0.18340965966748335, 0.18403926041967136, 0.18240261481762268, 0.18298153902101044, 0.18325909560686224, 0.18450647440080073, 0.18196116902187506, 0.18076521739975024, 0.18065954146915889, 0.18566328625984424, 0.17998710506831], 'acc': [0.678051431259098, 0.8963207624623213, 0.904079593702357, 0.9094643946910815, 0.9151786060794352, 0.9202287394778756, 0.9248631829148323, 0.9279257696040093, 0.9300276130357135, 0.9321896268809878, 0.9342851804173068, 0.9361574691484417, 0.9390609507898424, 0.9428124382355015, 0.9447841429342082, 0.9461111504678347, 0.9470979087521839, 0.9477244844969016, 0.9485946489451869, 0.9491301484638428, 0.948394717507932, 0.9500937565289717, 0.9509332666653952, 0.9513236918866975, 0.9517956440409778, 0.952335114757208, 0.9526701712634645, 0.9530520117716943, 0.9533393714442059, 0.9536260009732717, 0.9538735135685705, 0.9540296321420328, 0.9542894094288559, 0.9545670108661715, 0.954852465246826, 0.9549944108533864, 0.9551293539276261, 0.9553562006855671, 0.9554558704078514, 0.9557300022677034, 0.9558906194104009, 0.955511030856412, 0.9562879357633075, 0.9560934470151633, 0.9562719750935293, 0.956427448622644, 0.9566553061842404, 0.9568356726494605, 0.9568743465573106, 0.9570603618555819, 0.9570758861361326, 0.9570527387330209, 0.9559701459854318, 0.9572697331343578, 0.9575621921041089, 0.9575462334671905, 0.9575871097992507, 0.9578456270777242, 0.9579531947233598, 0.958068225116856, 0.9580500142327258, 0.9580911006787821, 0.9579942106172235, 0.9583293605333872, 0.9578252768837014, 0.9581743703884351, 0.9583273844920306, 0.9584041784132289, 0.9585924930194158, 0.9585689769930557, 0.9586257233771796, 0.9587258958436264, 0.9587647314774307, 0.9587560950400347, 0.9588953543539236, 0.9588689903687279, 0.9589901093985111, 0.9590164499280923, 0.9590184257243101, 0.9591168281677817, 0.9590859413087183, 0.9592389114248153, 0.9592584742444104, 0.9590415044287188, 0.9593665494592609], 'mDice': [0.18026213364821192, 0.47559367742231373, 0.5655386316607668, 0.6092871703407042, 0.6408374185176607, 0.6631125233240096, 0.6792457524531225, 0.6934218702518136, 0.703465462125571, 0.7129775181805816, 0.7218196428172482, 0.7235015266720564, 0.7328797069520478, 0.7409895609584827, 0.7458134621623909, 0.7498491395798116, 0.7538984691992675, 0.7565216518342883, 0.7608676783143368, 0.7643215479182556, 0.7548235264163113, 0.7674239986231507, 0.7725619233734379, 0.7735291811513236, 0.7765215569171949, 0.7789550172563947, 0.7799040342491744, 0.7818789587107928, 0.7841051173898925, 0.7849960504485559, 0.7876924781577376, 0.788287840285097, 0.7904608687446641, 0.7916666819848631, 0.7931402291250942, 0.7944438628607976, 0.7949744300218556, 0.7963993718791766, 0.7972662728042538, 0.8000544438882056, 0.8006142457433876, 0.7970291698501538, 0.8022961681567626, 0.8009461643093387, 0.801782153622295, 0.8045524608432404, 0.8052826370778229, 0.8070231255120338, 0.8079532779067865, 0.8094344430515551, 0.8091834068944072, 0.8086916647723666, 0.8000342181410758, 0.8102321143565989, 0.8114584021659658, 0.8121176598267924, 0.8124440534146646, 0.813364633311837, 0.8154499634408295, 0.816097454628192, 0.8158318476435867, 0.8166666935267235, 0.8154543646181439, 0.8185605095673832, 0.8132705261695587, 0.8167606943623928, 0.8176406805488264, 0.8177682394631732, 0.8198140838617594, 0.8194842919063061, 0.8202861172347672, 0.8202005354819296, 0.8214453729993423, 0.82013773415318, 0.8221255789813312, 0.8215620456147019, 0.822993488964196, 0.8224507444289206, 0.8222676952165758, 0.8229403419974862, 0.8235169180251014, 0.824446909453233, 0.8245787459709351, 0.8204592323396495, 0.8250545331809738]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:04<00:17,  4.36s/it]predicting test subjects:  40%|████      | 2/5 [00:08<00:12,  4.17s/it]predicting test subjects:  60%|██████    | 3/5 [00:11<00:08,  4.01s/it]predicting test subjects:  80%|████████  | 4/5 [00:15<00:03,  3.85s/it]predicting test subjects: 100%|██████████| 5/5 [00:18<00:00,  3.78s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:04<18:13,  4.13s/it]predicting train subjects:   1%|          | 2/266 [00:08<18:30,  4.21s/it]predicting train subjects:   1%|          | 3/266 [00:12<17:31,  4.00s/it]predicting train subjects:   2%|▏         | 4/266 [00:15<16:08,  3.70s/it]predicting train subjects:   2%|▏         | 5/266 [00:19<16:39,  3.83s/it]predicting train subjects:   2%|▏         | 6/266 [00:23<17:03,  3.94s/it]predicting train subjects:   3%|▎         | 7/266 [00:27<17:00,  3.94s/it]predicting train subjects:   3%|▎         | 8/266 [00:31<17:19,  4.03s/it]predicting train subjects:   3%|▎         | 9/266 [00:35<17:18,  4.04s/it]predicting train subjects:   4%|▍         | 10/266 [00:39<17:02,  3.99s/it]predicting train subjects:   4%|▍         | 11/266 [00:43<17:09,  4.04s/it]predicting train subjects:   5%|▍         | 12/266 [00:47<17:16,  4.08s/it]predicting train subjects:   5%|▍         | 13/266 [00:51<17:07,  4.06s/it]predicting train subjects:   5%|▌         | 14/266 [00:55<17:08,  4.08s/it]predicting train subjects:   6%|▌         | 15/266 [00:59<16:56,  4.05s/it]predicting train subjects:   6%|▌         | 16/266 [01:04<16:56,  4.07s/it]predicting train subjects:   6%|▋         | 17/266 [01:08<16:47,  4.05s/it]predicting train subjects:   7%|▋         | 18/266 [01:12<16:56,  4.10s/it]predicting train subjects:   7%|▋         | 19/266 [01:16<17:01,  4.14s/it]predicting train subjects:   8%|▊         | 20/266 [01:20<16:32,  4.03s/it]predicting train subjects:   8%|▊         | 21/266 [01:24<16:37,  4.07s/it]predicting train subjects:   8%|▊         | 22/266 [01:28<16:43,  4.11s/it]predicting train subjects:   9%|▊         | 23/266 [01:32<16:31,  4.08s/it]predicting train subjects:   9%|▉         | 24/266 [01:36<16:12,  4.02s/it]predicting train subjects:   9%|▉         | 25/266 [01:40<15:33,  3.87s/it]predicting train subjects:  10%|▉         | 26/266 [01:43<14:36,  3.65s/it]predicting train subjects:  10%|█         | 27/266 [01:46<13:52,  3.48s/it]predicting train subjects:  11%|█         | 28/266 [01:49<13:34,  3.42s/it]predicting train subjects:  11%|█         | 29/266 [01:52<13:26,  3.40s/it]predicting train subjects:  11%|█▏        | 30/266 [01:56<13:07,  3.34s/it]predicting train subjects:  12%|█▏        | 31/266 [01:59<12:48,  3.27s/it]predicting train subjects:  12%|█▏        | 32/266 [02:02<12:51,  3.30s/it]predicting train subjects:  12%|█▏        | 33/266 [02:05<12:37,  3.25s/it]predicting train subjects:  13%|█▎        | 34/266 [02:08<12:19,  3.19s/it]predicting train subjects:  13%|█▎        | 35/266 [02:11<12:08,  3.15s/it]predicting train subjects:  14%|█▎        | 36/266 [02:15<12:10,  3.18s/it]predicting train subjects:  14%|█▍        | 37/266 [02:18<12:00,  3.15s/it]predicting train subjects:  14%|█▍        | 38/266 [02:21<11:58,  3.15s/it]predicting train subjects:  15%|█▍        | 39/266 [02:24<11:44,  3.10s/it]predicting train subjects:  15%|█▌        | 40/266 [02:27<11:48,  3.13s/it]predicting train subjects:  15%|█▌        | 41/266 [02:30<11:46,  3.14s/it]predicting train subjects:  16%|█▌        | 42/266 [02:33<11:06,  2.97s/it]predicting train subjects:  16%|█▌        | 43/266 [02:35<10:37,  2.86s/it]predicting train subjects:  17%|█▋        | 44/266 [02:38<10:20,  2.80s/it]predicting train subjects:  17%|█▋        | 45/266 [02:41<10:12,  2.77s/it]predicting train subjects:  17%|█▋        | 46/266 [02:43<09:57,  2.72s/it]predicting train subjects:  18%|█▊        | 47/266 [02:46<10:02,  2.75s/it]predicting train subjects:  18%|█▊        | 48/266 [02:49<09:57,  2.74s/it]predicting train subjects:  18%|█▊        | 49/266 [02:51<09:41,  2.68s/it]predicting train subjects:  19%|█▉        | 50/266 [02:54<09:31,  2.64s/it]predicting train subjects:  19%|█▉        | 51/266 [02:57<09:39,  2.70s/it]predicting train subjects:  20%|█▉        | 52/266 [02:59<09:30,  2.67s/it]predicting train subjects:  20%|█▉        | 53/266 [03:02<09:35,  2.70s/it]predicting train subjects:  20%|██        | 54/266 [03:05<09:32,  2.70s/it]predicting train subjects:  21%|██        | 55/266 [03:08<09:28,  2.69s/it]predicting train subjects:  21%|██        | 56/266 [03:10<09:22,  2.68s/it]predicting train subjects:  21%|██▏       | 57/266 [03:13<09:14,  2.65s/it]predicting train subjects:  22%|██▏       | 58/266 [03:16<09:26,  2.72s/it]predicting train subjects:  22%|██▏       | 59/266 [03:18<09:17,  2.69s/it]predicting train subjects:  23%|██▎       | 60/266 [03:21<09:05,  2.65s/it]predicting train subjects:  23%|██▎       | 61/266 [03:23<08:52,  2.60s/it]predicting train subjects:  23%|██▎       | 62/266 [03:26<08:30,  2.50s/it]predicting train subjects:  24%|██▎       | 63/266 [03:28<08:33,  2.53s/it]predicting train subjects:  24%|██▍       | 64/266 [03:31<08:20,  2.48s/it]predicting train subjects:  24%|██▍       | 65/266 [03:33<08:21,  2.49s/it]predicting train subjects:  25%|██▍       | 66/266 [03:36<08:23,  2.52s/it]predicting train subjects:  25%|██▌       | 67/266 [03:38<08:23,  2.53s/it]predicting train subjects:  26%|██▌       | 68/266 [03:41<08:11,  2.48s/it]predicting train subjects:  26%|██▌       | 69/266 [03:43<08:05,  2.47s/it]predicting train subjects:  26%|██▋       | 70/266 [03:45<08:04,  2.47s/it]predicting train subjects:  27%|██▋       | 71/266 [03:48<08:00,  2.46s/it]predicting train subjects:  27%|██▋       | 72/266 [03:51<08:06,  2.51s/it]predicting train subjects:  27%|██▋       | 73/266 [03:53<08:04,  2.51s/it]predicting train subjects:  28%|██▊       | 74/266 [03:55<07:54,  2.47s/it]predicting train subjects:  28%|██▊       | 75/266 [03:58<07:51,  2.47s/it]predicting train subjects:  29%|██▊       | 76/266 [04:00<07:49,  2.47s/it]predicting train subjects:  29%|██▉       | 77/266 [04:03<07:47,  2.47s/it]predicting train subjects:  29%|██▉       | 78/266 [04:06<08:25,  2.69s/it]predicting train subjects:  30%|██▉       | 79/266 [04:09<08:53,  2.85s/it]predicting train subjects:  30%|███       | 80/266 [04:12<08:25,  2.72s/it]predicting train subjects:  30%|███       | 81/266 [04:14<07:59,  2.59s/it]predicting train subjects:  31%|███       | 82/266 [04:17<07:54,  2.58s/it]predicting train subjects:  31%|███       | 83/266 [04:19<07:47,  2.56s/it]predicting train subjects:  32%|███▏      | 84/266 [04:22<07:46,  2.56s/it]predicting train subjects:  32%|███▏      | 85/266 [04:24<07:39,  2.54s/it]predicting train subjects:  32%|███▏      | 86/266 [04:27<07:32,  2.51s/it]predicting train subjects:  33%|███▎      | 87/266 [04:29<07:30,  2.52s/it]predicting train subjects:  33%|███▎      | 88/266 [04:32<07:37,  2.57s/it]predicting train subjects:  33%|███▎      | 89/266 [04:34<07:38,  2.59s/it]predicting train subjects:  34%|███▍      | 90/266 [04:37<07:36,  2.60s/it]predicting train subjects:  34%|███▍      | 91/266 [04:40<07:29,  2.57s/it]predicting train subjects:  35%|███▍      | 92/266 [04:42<07:26,  2.57s/it]predicting train subjects:  35%|███▍      | 93/266 [04:45<07:20,  2.55s/it]predicting train subjects:  35%|███▌      | 94/266 [04:47<07:15,  2.53s/it]predicting train subjects:  36%|███▌      | 95/266 [04:50<07:17,  2.56s/it]predicting train subjects:  36%|███▌      | 96/266 [04:52<07:05,  2.50s/it]predicting train subjects:  36%|███▋      | 97/266 [04:55<07:07,  2.53s/it]predicting train subjects:  37%|███▋      | 98/266 [04:57<06:58,  2.49s/it]predicting train subjects:  37%|███▋      | 99/266 [04:59<06:27,  2.32s/it]predicting train subjects:  38%|███▊      | 100/266 [05:01<06:13,  2.25s/it]predicting train subjects:  38%|███▊      | 101/266 [05:03<06:12,  2.26s/it]predicting train subjects:  38%|███▊      | 102/266 [05:06<06:06,  2.23s/it]predicting train subjects:  39%|███▊      | 103/266 [05:08<06:06,  2.25s/it]predicting train subjects:  39%|███▉      | 104/266 [05:10<06:05,  2.26s/it]predicting train subjects:  39%|███▉      | 105/266 [05:12<06:00,  2.24s/it]predicting train subjects:  40%|███▉      | 106/266 [05:15<05:58,  2.24s/it]predicting train subjects:  40%|████      | 107/266 [05:17<05:52,  2.21s/it]predicting train subjects:  41%|████      | 108/266 [05:19<05:56,  2.26s/it]predicting train subjects:  41%|████      | 109/266 [05:21<05:57,  2.27s/it]predicting train subjects:  41%|████▏     | 110/266 [05:23<05:48,  2.23s/it]predicting train subjects:  42%|████▏     | 111/266 [05:26<05:51,  2.26s/it]predicting train subjects:  42%|████▏     | 112/266 [05:28<05:47,  2.26s/it]predicting train subjects:  42%|████▏     | 113/266 [05:30<05:40,  2.23s/it]predicting train subjects:  43%|████▎     | 114/266 [05:32<05:40,  2.24s/it]predicting train subjects:  43%|████▎     | 115/266 [05:35<05:37,  2.24s/it]predicting train subjects:  44%|████▎     | 116/266 [05:37<05:36,  2.24s/it]predicting train subjects:  44%|████▍     | 117/266 [05:39<05:33,  2.24s/it]predicting train subjects:  44%|████▍     | 118/266 [05:41<05:26,  2.21s/it]predicting train subjects:  45%|████▍     | 119/266 [05:44<05:36,  2.29s/it]predicting train subjects:  45%|████▌     | 120/266 [05:46<05:49,  2.39s/it]predicting train subjects:  45%|████▌     | 121/266 [05:49<06:06,  2.53s/it]predicting train subjects:  46%|████▌     | 122/266 [05:52<06:20,  2.64s/it]predicting train subjects:  46%|████▌     | 123/266 [05:55<06:14,  2.62s/it]predicting train subjects:  47%|████▋     | 124/266 [05:57<06:10,  2.61s/it]predicting train subjects:  47%|████▋     | 125/266 [06:00<06:19,  2.69s/it]predicting train subjects:  47%|████▋     | 126/266 [06:03<06:13,  2.67s/it]predicting train subjects:  48%|████▊     | 127/266 [06:05<06:08,  2.65s/it]predicting train subjects:  48%|████▊     | 128/266 [06:08<06:04,  2.64s/it]predicting train subjects:  48%|████▊     | 129/266 [06:11<06:01,  2.64s/it]predicting train subjects:  49%|████▉     | 130/266 [06:13<05:53,  2.60s/it]predicting train subjects:  49%|████▉     | 131/266 [06:16<05:56,  2.64s/it]predicting train subjects:  50%|████▉     | 132/266 [06:19<05:54,  2.64s/it]predicting train subjects:  50%|█████     | 133/266 [06:21<05:50,  2.63s/it]predicting train subjects:  50%|█████     | 134/266 [06:24<05:45,  2.62s/it]predicting train subjects:  51%|█████     | 135/266 [06:26<05:44,  2.63s/it]predicting train subjects:  51%|█████     | 136/266 [06:29<05:37,  2.60s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:32<05:34,  2.59s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:34<05:22,  2.52s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:36<05:09,  2.44s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:39<05:03,  2.41s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:41<04:55,  2.37s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:43<04:54,  2.38s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:46<05:01,  2.45s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:48<05:04,  2.50s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:51<05:02,  2.50s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:53<04:54,  2.46s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:56<04:49,  2.43s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:58<04:44,  2.41s/it]predicting train subjects:  56%|█████▌    | 149/266 [07:01<04:50,  2.49s/it]predicting train subjects:  56%|█████▋    | 150/266 [07:03<04:44,  2.45s/it]predicting train subjects:  57%|█████▋    | 151/266 [07:06<04:45,  2.49s/it]predicting train subjects:  57%|█████▋    | 152/266 [07:08<04:39,  2.45s/it]predicting train subjects:  58%|█████▊    | 153/266 [07:10<04:32,  2.42s/it]predicting train subjects:  58%|█████▊    | 154/266 [07:13<04:29,  2.40s/it]predicting train subjects:  58%|█████▊    | 155/266 [07:14<04:03,  2.19s/it]predicting train subjects:  59%|█████▊    | 156/266 [07:16<03:47,  2.07s/it]predicting train subjects:  59%|█████▉    | 157/266 [07:18<03:37,  2.00s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:20<03:30,  1.95s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:22<03:22,  1.89s/it]predicting train subjects:  60%|██████    | 160/266 [07:23<03:20,  1.90s/it]predicting train subjects:  61%|██████    | 161/266 [07:25<03:13,  1.84s/it]predicting train subjects:  61%|██████    | 162/266 [07:28<03:26,  1.99s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:29<03:21,  1.96s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:31<03:14,  1.91s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:33<03:12,  1.91s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:35<03:19,  1.99s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:37<03:13,  1.95s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:39<03:14,  1.98s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:41<03:06,  1.93s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:43<03:04,  1.92s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:45<03:03,  1.94s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:47<03:04,  1.97s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:49<03:04,  1.98s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:51<03:00,  1.97s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:53<03:01,  1.99s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:55<03:03,  2.04s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:57<03:01,  2.04s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:59<03:01,  2.06s/it]predicting train subjects:  67%|██████▋   | 179/266 [08:01<03:02,  2.09s/it]predicting train subjects:  68%|██████▊   | 180/266 [08:03<03:00,  2.10s/it]predicting train subjects:  68%|██████▊   | 181/266 [08:06<02:58,  2.10s/it]predicting train subjects:  68%|██████▊   | 182/266 [08:08<02:52,  2.06s/it]predicting train subjects:  69%|██████▉   | 183/266 [08:10<02:55,  2.11s/it]predicting train subjects:  69%|██████▉   | 184/266 [08:12<02:51,  2.10s/it]predicting train subjects:  70%|██████▉   | 185/266 [08:14<02:53,  2.14s/it]predicting train subjects:  70%|██████▉   | 186/266 [08:16<02:51,  2.14s/it]predicting train subjects:  70%|███████   | 187/266 [08:18<02:48,  2.13s/it]predicting train subjects:  71%|███████   | 188/266 [08:21<02:46,  2.14s/it]predicting train subjects:  71%|███████   | 189/266 [08:22<02:40,  2.09s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:24<02:35,  2.05s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:27<02:36,  2.08s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:29<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:31<02:35,  2.13s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:33<02:40,  2.23s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:36<02:36,  2.21s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:38<02:31,  2.16s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:40<02:31,  2.20s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:42<02:30,  2.22s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:44<02:26,  2.19s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:46<02:24,  2.19s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:49<02:27,  2.27s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:51<02:25,  2.28s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:53<02:21,  2.25s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:56<02:20,  2.26s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:58<02:16,  2.24s/it]predicting train subjects:  77%|███████▋  | 206/266 [09:00<02:13,  2.22s/it]predicting train subjects:  78%|███████▊  | 207/266 [09:02<02:09,  2.19s/it]predicting train subjects:  78%|███████▊  | 208/266 [09:04<02:06,  2.18s/it]predicting train subjects:  79%|███████▊  | 209/266 [09:07<02:05,  2.20s/it]predicting train subjects:  79%|███████▉  | 210/266 [09:09<02:02,  2.19s/it]predicting train subjects:  79%|███████▉  | 211/266 [09:11<02:00,  2.19s/it]predicting train subjects:  80%|███████▉  | 212/266 [09:13<01:58,  2.20s/it]predicting train subjects:  80%|████████  | 213/266 [09:15<01:53,  2.14s/it]predicting train subjects:  80%|████████  | 214/266 [09:17<01:47,  2.06s/it]predicting train subjects:  81%|████████  | 215/266 [09:19<01:44,  2.05s/it]predicting train subjects:  81%|████████  | 216/266 [09:21<01:39,  1.99s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:23<01:36,  1.97s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:25<01:32,  1.92s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:27<01:30,  1.93s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:28<01:26,  1.88s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:30<01:23,  1.86s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:32<01:23,  1.90s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:34<01:19,  1.86s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:36<01:22,  1.96s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:38<01:19,  1.94s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:40<01:17,  1.94s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:42<01:16,  1.95s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:44<01:14,  1.96s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:46<01:13,  2.00s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:48<01:11,  1.99s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:50<01:09,  2.00s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:52<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:54<01:06,  2.01s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:56<01:03,  1.98s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:58<01:00,  1.96s/it]predicting train subjects:  89%|████████▊ | 236/266 [10:00<00:59,  2.00s/it]predicting train subjects:  89%|████████▉ | 237/266 [10:02<01:00,  2.08s/it]predicting train subjects:  89%|████████▉ | 238/266 [10:04<00:58,  2.09s/it]predicting train subjects:  90%|████████▉ | 239/266 [10:06<00:54,  2.03s/it]predicting train subjects:  90%|█████████ | 240/266 [10:08<00:52,  2.00s/it]predicting train subjects:  91%|█████████ | 241/266 [10:10<00:48,  1.96s/it]predicting train subjects:  91%|█████████ | 242/266 [10:12<00:48,  2.04s/it]predicting train subjects:  91%|█████████▏| 243/266 [10:14<00:46,  2.02s/it]predicting train subjects:  92%|█████████▏| 244/266 [10:16<00:45,  2.05s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:18<00:42,  2.02s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:20<00:40,  2.04s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:23<00:39,  2.07s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:24<00:36,  2.02s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:27<00:37,  2.20s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:30<00:36,  2.30s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:32<00:35,  2.37s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:35<00:34,  2.45s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:37<00:32,  2.50s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:40<00:29,  2.50s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:42<00:27,  2.53s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:45<00:25,  2.52s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:47<00:22,  2.52s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:50<00:20,  2.52s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:53<00:17,  2.52s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:55<00:14,  2.50s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:57<00:12,  2.49s/it]predicting train subjects:  98%|█████████▊| 262/266 [11:00<00:09,  2.48s/it]predicting train subjects:  99%|█████████▉| 263/266 [11:03<00:07,  2.53s/it]predicting train subjects:  99%|█████████▉| 264/266 [11:05<00:05,  2.51s/it]predicting train subjects: 100%|█████████▉| 265/266 [11:07<00:02,  2.47s/it]predicting train subjects: 100%|██████████| 266/266 [11:10<00:00,  2.46s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:29,  1.78it/s]Loading train:   1%|          | 2/266 [00:00<02:17,  1.92it/s]Loading train:   1%|          | 3/266 [00:01<02:05,  2.09it/s]Loading train:   2%|▏         | 4/266 [00:01<01:55,  2.27it/s]Loading train:   2%|▏         | 5/266 [00:02<01:52,  2.31it/s]Loading train:   2%|▏         | 6/266 [00:02<01:50,  2.35it/s]Loading train:   3%|▎         | 7/266 [00:03<01:55,  2.23it/s]Loading train:   3%|▎         | 8/266 [00:03<01:56,  2.21it/s]Loading train:   3%|▎         | 9/266 [00:04<02:01,  2.11it/s]Loading train:   4%|▍         | 10/266 [00:04<01:58,  2.16it/s]Loading train:   4%|▍         | 11/266 [00:04<01:52,  2.26it/s]Loading train:   5%|▍         | 12/266 [00:05<01:48,  2.34it/s]Loading train:   5%|▍         | 13/266 [00:05<01:45,  2.39it/s]Loading train:   5%|▌         | 14/266 [00:06<01:43,  2.43it/s]Loading train:   6%|▌         | 15/266 [00:06<01:41,  2.46it/s]Loading train:   6%|▌         | 16/266 [00:06<01:41,  2.47it/s]Loading train:   6%|▋         | 17/266 [00:07<01:39,  2.49it/s]Loading train:   7%|▋         | 18/266 [00:07<01:39,  2.50it/s]Loading train:   7%|▋         | 19/266 [00:08<01:38,  2.51it/s]Loading train:   8%|▊         | 20/266 [00:08<01:37,  2.52it/s]Loading train:   8%|▊         | 21/266 [00:08<01:37,  2.51it/s]Loading train:   8%|▊         | 22/266 [00:09<01:37,  2.50it/s]Loading train:   9%|▊         | 23/266 [00:09<01:39,  2.45it/s]Loading train:   9%|▉         | 24/266 [00:10<01:44,  2.32it/s]Loading train:   9%|▉         | 25/266 [00:10<01:41,  2.37it/s]Loading train:  10%|▉         | 26/266 [00:10<01:38,  2.45it/s]Loading train:  10%|█         | 27/266 [00:11<01:35,  2.50it/s]Loading train:  11%|█         | 28/266 [00:11<01:37,  2.43it/s]Loading train:  11%|█         | 29/266 [00:12<01:40,  2.37it/s]Loading train:  11%|█▏        | 30/266 [00:12<01:39,  2.37it/s]Loading train:  12%|█▏        | 31/266 [00:12<01:35,  2.45it/s]Loading train:  12%|█▏        | 32/266 [00:13<01:32,  2.52it/s]Loading train:  12%|█▏        | 33/266 [00:13<01:30,  2.57it/s]Loading train:  13%|█▎        | 34/266 [00:14<01:30,  2.57it/s]Loading train:  13%|█▎        | 35/266 [00:14<01:34,  2.44it/s]Loading train:  14%|█▎        | 36/266 [00:15<01:43,  2.23it/s]Loading train:  14%|█▍        | 37/266 [00:15<01:44,  2.18it/s]Loading train:  14%|█▍        | 38/266 [00:16<01:41,  2.24it/s]Loading train:  15%|█▍        | 39/266 [00:16<01:43,  2.20it/s]Loading train:  15%|█▌        | 40/266 [00:17<01:47,  2.10it/s]Loading train:  15%|█▌        | 41/266 [00:17<01:50,  2.04it/s]Loading train:  16%|█▌        | 42/266 [00:17<01:45,  2.12it/s]Loading train:  16%|█▌        | 43/266 [00:18<01:41,  2.20it/s]Loading train:  17%|█▋        | 44/266 [00:18<01:35,  2.32it/s]Loading train:  17%|█▋        | 45/266 [00:19<01:28,  2.49it/s]Loading train:  17%|█▋        | 46/266 [00:19<01:24,  2.61it/s]Loading train:  18%|█▊        | 47/266 [00:19<01:23,  2.63it/s]Loading train:  18%|█▊        | 48/266 [00:20<01:19,  2.73it/s]Loading train:  18%|█▊        | 49/266 [00:20<01:20,  2.71it/s]Loading train:  19%|█▉        | 50/266 [00:20<01:22,  2.63it/s]Loading train:  19%|█▉        | 51/266 [00:21<01:27,  2.45it/s]Loading train:  20%|█▉        | 52/266 [00:21<01:29,  2.38it/s]Loading train:  20%|█▉        | 53/266 [00:22<01:32,  2.30it/s]Loading train:  20%|██        | 54/266 [00:22<01:30,  2.36it/s]Loading train:  21%|██        | 55/266 [00:23<01:33,  2.26it/s]Loading train:  21%|██        | 56/266 [00:23<01:34,  2.23it/s]Loading train:  21%|██▏       | 57/266 [00:24<01:35,  2.19it/s]Loading train:  22%|██▏       | 58/266 [00:24<01:31,  2.28it/s]Loading train:  22%|██▏       | 59/266 [00:24<01:27,  2.37it/s]Loading train:  23%|██▎       | 60/266 [00:25<01:29,  2.29it/s]Loading train:  23%|██▎       | 61/266 [00:25<01:29,  2.28it/s]Loading train:  23%|██▎       | 62/266 [00:26<01:31,  2.24it/s]Loading train:  24%|██▎       | 63/266 [00:26<01:26,  2.33it/s]Loading train:  24%|██▍       | 64/266 [00:27<01:28,  2.28it/s]Loading train:  24%|██▍       | 65/266 [00:27<01:24,  2.38it/s]Loading train:  25%|██▍       | 66/266 [00:27<01:21,  2.44it/s]Loading train:  25%|██▌       | 67/266 [00:28<01:19,  2.49it/s]Loading train:  26%|██▌       | 68/266 [00:28<01:18,  2.54it/s]Loading train:  26%|██▌       | 69/266 [00:29<01:16,  2.57it/s]Loading train:  26%|██▋       | 70/266 [00:29<01:15,  2.58it/s]Loading train:  27%|██▋       | 71/266 [00:29<01:14,  2.60it/s]Loading train:  27%|██▋       | 72/266 [00:30<01:13,  2.64it/s]Loading train:  27%|██▋       | 73/266 [00:30<01:10,  2.72it/s]Loading train:  28%|██▊       | 74/266 [00:30<01:09,  2.78it/s]Loading train:  28%|██▊       | 75/266 [00:31<01:12,  2.64it/s]Loading train:  29%|██▊       | 76/266 [00:31<01:12,  2.61it/s]Loading train:  29%|██▉       | 77/266 [00:32<01:12,  2.62it/s]Loading train:  29%|██▉       | 78/266 [00:32<01:18,  2.39it/s]Loading train:  30%|██▉       | 79/266 [00:32<01:20,  2.34it/s]Loading train:  30%|███       | 80/266 [00:33<01:21,  2.27it/s]Loading train:  30%|███       | 81/266 [00:33<01:20,  2.29it/s]Loading train:  31%|███       | 82/266 [00:34<01:18,  2.34it/s]Loading train:  31%|███       | 83/266 [00:34<01:18,  2.33it/s]Loading train:  32%|███▏      | 84/266 [00:35<01:19,  2.28it/s]Loading train:  32%|███▏      | 85/266 [00:35<01:17,  2.34it/s]Loading train:  32%|███▏      | 86/266 [00:36<01:22,  2.19it/s]Loading train:  33%|███▎      | 87/266 [00:36<01:19,  2.26it/s]Loading train:  33%|███▎      | 88/266 [00:37<01:23,  2.13it/s]Loading train:  33%|███▎      | 89/266 [00:37<01:20,  2.20it/s]Loading train:  34%|███▍      | 90/266 [00:37<01:20,  2.18it/s]Loading train:  34%|███▍      | 91/266 [00:38<01:22,  2.13it/s]Loading train:  35%|███▍      | 92/266 [00:38<01:18,  2.20it/s]Loading train:  35%|███▍      | 93/266 [00:39<01:17,  2.24it/s]Loading train:  35%|███▌      | 94/266 [00:39<01:16,  2.25it/s]Loading train:  36%|███▌      | 95/266 [00:40<01:17,  2.20it/s]Loading train:  36%|███▌      | 96/266 [00:40<01:21,  2.08it/s]Loading train:  36%|███▋      | 97/266 [00:41<01:21,  2.07it/s]Loading train:  37%|███▋      | 98/266 [00:41<01:22,  2.03it/s]Loading train:  37%|███▋      | 99/266 [00:42<01:19,  2.09it/s]Loading train:  38%|███▊      | 100/266 [00:42<01:16,  2.18it/s]Loading train:  38%|███▊      | 101/266 [00:43<01:15,  2.18it/s]Loading train:  38%|███▊      | 102/266 [00:43<01:13,  2.23it/s]Loading train:  39%|███▊      | 103/266 [00:43<01:12,  2.26it/s]Loading train:  39%|███▉      | 104/266 [00:44<01:11,  2.26it/s]Loading train:  39%|███▉      | 105/266 [00:44<01:07,  2.37it/s]Loading train:  40%|███▉      | 106/266 [00:45<01:04,  2.48it/s]Loading train:  40%|████      | 107/266 [00:45<01:02,  2.55it/s]Loading train:  41%|████      | 108/266 [00:45<01:00,  2.61it/s]Loading train:  41%|████      | 109/266 [00:46<00:59,  2.66it/s]Loading train:  41%|████▏     | 110/266 [00:46<01:00,  2.60it/s]Loading train:  42%|████▏     | 111/266 [00:46<00:58,  2.64it/s]Loading train:  42%|████▏     | 112/266 [00:47<00:59,  2.57it/s]Loading train:  42%|████▏     | 113/266 [00:47<00:59,  2.55it/s]Loading train:  43%|████▎     | 114/266 [00:48<00:58,  2.60it/s]Loading train:  43%|████▎     | 115/266 [00:48<00:57,  2.65it/s]Loading train:  44%|████▎     | 116/266 [00:48<00:55,  2.68it/s]Loading train:  44%|████▍     | 117/266 [00:49<00:55,  2.70it/s]Loading train:  44%|████▍     | 118/266 [00:49<00:54,  2.70it/s]Loading train:  45%|████▍     | 119/266 [00:49<00:55,  2.65it/s]Loading train:  45%|████▌     | 120/266 [00:50<00:59,  2.44it/s]Loading train:  45%|████▌     | 121/266 [00:51<01:04,  2.23it/s]Loading train:  46%|████▌     | 122/266 [00:51<01:03,  2.25it/s]Loading train:  46%|████▌     | 123/266 [00:51<01:01,  2.33it/s]Loading train:  47%|████▋     | 124/266 [00:52<01:01,  2.30it/s]Loading train:  47%|████▋     | 125/266 [00:52<01:01,  2.29it/s]Loading train:  47%|████▋     | 126/266 [00:53<01:01,  2.27it/s]Loading train:  48%|████▊     | 127/266 [00:53<01:01,  2.27it/s]Loading train:  48%|████▊     | 128/266 [00:54<01:05,  2.11it/s]Loading train:  48%|████▊     | 129/266 [00:54<01:03,  2.16it/s]Loading train:  49%|████▉     | 130/266 [00:54<01:00,  2.26it/s]Loading train:  49%|████▉     | 131/266 [00:55<00:57,  2.35it/s]Loading train:  50%|████▉     | 132/266 [00:55<00:55,  2.42it/s]Loading train:  50%|█████     | 133/266 [00:56<00:54,  2.43it/s]Loading train:  50%|█████     | 134/266 [00:56<00:53,  2.46it/s]Loading train:  51%|█████     | 135/266 [00:56<00:52,  2.50it/s]Loading train:  51%|█████     | 136/266 [00:57<00:51,  2.53it/s]Loading train:  52%|█████▏    | 137/266 [00:57<00:50,  2.54it/s]Loading train:  52%|█████▏    | 138/266 [00:58<00:50,  2.54it/s]Loading train:  52%|█████▏    | 139/266 [00:58<00:50,  2.53it/s]Loading train:  53%|█████▎    | 140/266 [00:58<00:49,  2.57it/s]Loading train:  53%|█████▎    | 141/266 [00:59<00:48,  2.58it/s]Loading train:  53%|█████▎    | 142/266 [00:59<00:47,  2.61it/s]Loading train:  54%|█████▍    | 143/266 [01:00<00:47,  2.62it/s]Loading train:  54%|█████▍    | 144/266 [01:00<00:46,  2.65it/s]Loading train:  55%|█████▍    | 145/266 [01:00<00:45,  2.68it/s]Loading train:  55%|█████▍    | 146/266 [01:01<00:44,  2.69it/s]Loading train:  55%|█████▌    | 147/266 [01:01<00:44,  2.70it/s]Loading train:  56%|█████▌    | 148/266 [01:01<00:43,  2.70it/s]Loading train:  56%|█████▌    | 149/266 [01:02<00:44,  2.61it/s]Loading train:  56%|█████▋    | 150/266 [01:02<00:43,  2.66it/s]Loading train:  57%|█████▋    | 151/266 [01:03<00:43,  2.67it/s]Loading train:  57%|█████▋    | 152/266 [01:03<00:42,  2.68it/s]Loading train:  58%|█████▊    | 153/266 [01:03<00:43,  2.58it/s]Loading train:  58%|█████▊    | 154/266 [01:04<00:42,  2.63it/s]Loading train:  58%|█████▊    | 155/266 [01:04<00:40,  2.75it/s]Loading train:  59%|█████▊    | 156/266 [01:04<00:38,  2.85it/s]Loading train:  59%|█████▉    | 157/266 [01:05<00:37,  2.93it/s]Loading train:  59%|█████▉    | 158/266 [01:05<00:37,  2.90it/s]Loading train:  60%|█████▉    | 159/266 [01:05<00:36,  2.97it/s]Loading train:  60%|██████    | 160/266 [01:06<00:34,  3.04it/s]Loading train:  61%|██████    | 161/266 [01:06<00:35,  2.98it/s]Loading train:  61%|██████    | 162/266 [01:06<00:34,  3.04it/s]Loading train:  61%|██████▏   | 163/266 [01:07<00:33,  3.03it/s]Loading train:  62%|██████▏   | 164/266 [01:07<00:34,  2.97it/s]Loading train:  62%|██████▏   | 165/266 [01:07<00:33,  3.03it/s]Loading train:  62%|██████▏   | 166/266 [01:08<00:32,  3.08it/s]Loading train:  63%|██████▎   | 167/266 [01:08<00:31,  3.11it/s]Loading train:  63%|██████▎   | 168/266 [01:08<00:31,  3.11it/s]Loading train:  64%|██████▎   | 169/266 [01:09<00:31,  3.03it/s]Loading train:  64%|██████▍   | 170/266 [01:09<00:31,  3.05it/s]Loading train:  64%|██████▍   | 171/266 [01:09<00:30,  3.08it/s]Loading train:  65%|██████▍   | 172/266 [01:10<00:30,  3.08it/s]Loading train:  65%|██████▌   | 173/266 [01:10<00:32,  2.86it/s]Loading train:  65%|██████▌   | 174/266 [01:10<00:32,  2.86it/s]Loading train:  66%|██████▌   | 175/266 [01:11<00:31,  2.90it/s]Loading train:  66%|██████▌   | 176/266 [01:11<00:31,  2.85it/s]Loading train:  67%|██████▋   | 177/266 [01:11<00:30,  2.89it/s]Loading train:  67%|██████▋   | 178/266 [01:12<00:31,  2.79it/s]Loading train:  67%|██████▋   | 179/266 [01:12<00:30,  2.86it/s]Loading train:  68%|██████▊   | 180/266 [01:12<00:29,  2.89it/s]Loading train:  68%|██████▊   | 181/266 [01:13<00:29,  2.89it/s]Loading train:  68%|██████▊   | 182/266 [01:13<00:29,  2.81it/s]Loading train:  69%|██████▉   | 183/266 [01:13<00:29,  2.82it/s]Loading train:  69%|██████▉   | 184/266 [01:14<00:28,  2.85it/s]Loading train:  70%|██████▉   | 185/266 [01:14<00:28,  2.89it/s]Loading train:  70%|██████▉   | 186/266 [01:14<00:27,  2.91it/s]Loading train:  70%|███████   | 187/266 [01:15<00:27,  2.84it/s]Loading train:  71%|███████   | 188/266 [01:15<00:27,  2.86it/s]Loading train:  71%|███████   | 189/266 [01:16<00:26,  2.90it/s]Loading train:  71%|███████▏  | 190/266 [01:16<00:26,  2.85it/s]Loading train:  72%|███████▏  | 191/266 [01:16<00:26,  2.80it/s]Loading train:  72%|███████▏  | 192/266 [01:17<00:26,  2.79it/s]Loading train:  73%|███████▎  | 193/266 [01:17<00:26,  2.75it/s]Loading train:  73%|███████▎  | 194/266 [01:17<00:27,  2.58it/s]Loading train:  73%|███████▎  | 195/266 [01:18<00:27,  2.60it/s]Loading train:  74%|███████▎  | 196/266 [01:18<00:26,  2.69it/s]Loading train:  74%|███████▍  | 197/266 [01:18<00:24,  2.78it/s]Loading train:  74%|███████▍  | 198/266 [01:19<00:24,  2.73it/s]Loading train:  75%|███████▍  | 199/266 [01:19<00:23,  2.81it/s]Loading train:  75%|███████▌  | 200/266 [01:20<00:23,  2.85it/s]Loading train:  76%|███████▌  | 201/266 [01:20<00:23,  2.81it/s]Loading train:  76%|███████▌  | 202/266 [01:20<00:22,  2.87it/s]Loading train:  76%|███████▋  | 203/266 [01:21<00:21,  2.88it/s]Loading train:  77%|███████▋  | 204/266 [01:21<00:22,  2.77it/s]Loading train:  77%|███████▋  | 205/266 [01:21<00:21,  2.84it/s]Loading train:  77%|███████▋  | 206/266 [01:22<00:20,  2.89it/s]Loading train:  78%|███████▊  | 207/266 [01:22<00:20,  2.92it/s]Loading train:  78%|███████▊  | 208/266 [01:22<00:20,  2.82it/s]Loading train:  79%|███████▊  | 209/266 [01:23<00:20,  2.79it/s]Loading train:  79%|███████▉  | 210/266 [01:23<00:19,  2.84it/s]Loading train:  79%|███████▉  | 211/266 [01:23<00:19,  2.79it/s]Loading train:  80%|███████▉  | 212/266 [01:24<00:18,  2.85it/s]Loading train:  80%|████████  | 213/266 [01:24<00:18,  2.94it/s]Loading train:  80%|████████  | 214/266 [01:24<00:17,  3.04it/s]Loading train:  81%|████████  | 215/266 [01:25<00:16,  3.08it/s]Loading train:  81%|████████  | 216/266 [01:25<00:16,  3.03it/s]Loading train:  82%|████████▏ | 217/266 [01:25<00:16,  2.93it/s]Loading train:  82%|████████▏ | 218/266 [01:26<00:16,  2.93it/s]Loading train:  82%|████████▏ | 219/266 [01:26<00:15,  3.01it/s]Loading train:  83%|████████▎ | 220/266 [01:26<00:15,  2.97it/s]Loading train:  83%|████████▎ | 221/266 [01:27<00:14,  3.03it/s]Loading train:  83%|████████▎ | 222/266 [01:27<00:14,  3.00it/s]Loading train:  84%|████████▍ | 223/266 [01:27<00:14,  3.05it/s]Loading train:  84%|████████▍ | 224/266 [01:28<00:13,  3.10it/s]Loading train:  85%|████████▍ | 225/266 [01:28<00:13,  3.12it/s]Loading train:  85%|████████▍ | 226/266 [01:28<00:12,  3.09it/s]Loading train:  85%|████████▌ | 227/266 [01:29<00:12,  3.06it/s]Loading train:  86%|████████▌ | 228/266 [01:29<00:12,  3.01it/s]Loading train:  86%|████████▌ | 229/266 [01:29<00:12,  3.06it/s]Loading train:  86%|████████▋ | 230/266 [01:30<00:11,  3.09it/s]Loading train:  87%|████████▋ | 231/266 [01:30<00:11,  2.93it/s]Loading train:  87%|████████▋ | 232/266 [01:30<00:11,  2.94it/s]Loading train:  88%|████████▊ | 233/266 [01:31<00:11,  2.99it/s]Loading train:  88%|████████▊ | 234/266 [01:31<00:10,  2.99it/s]Loading train:  88%|████████▊ | 235/266 [01:31<00:10,  2.93it/s]Loading train:  89%|████████▊ | 236/266 [01:32<00:10,  2.95it/s]Loading train:  89%|████████▉ | 237/266 [01:32<00:09,  2.90it/s]Loading train:  89%|████████▉ | 238/266 [01:32<00:09,  2.94it/s]Loading train:  90%|████████▉ | 239/266 [01:33<00:09,  2.99it/s]Loading train:  90%|█████████ | 240/266 [01:33<00:08,  2.92it/s]Loading train:  91%|█████████ | 241/266 [01:33<00:08,  2.94it/s]Loading train:  91%|█████████ | 242/266 [01:34<00:08,  2.96it/s]Loading train:  91%|█████████▏| 243/266 [01:34<00:07,  2.96it/s]Loading train:  92%|█████████▏| 244/266 [01:34<00:07,  2.95it/s]Loading train:  92%|█████████▏| 245/266 [01:35<00:07,  2.94it/s]Loading train:  92%|█████████▏| 246/266 [01:35<00:06,  2.94it/s]Loading train:  93%|█████████▎| 247/266 [01:35<00:06,  2.94it/s]Loading train:  93%|█████████▎| 248/266 [01:36<00:06,  2.91it/s]Loading train:  94%|█████████▎| 249/266 [01:36<00:06,  2.77it/s]Loading train:  94%|█████████▍| 250/266 [01:37<00:05,  2.70it/s]Loading train:  94%|█████████▍| 251/266 [01:37<00:05,  2.62it/s]Loading train:  95%|█████████▍| 252/266 [01:38<00:05,  2.36it/s]Loading train:  95%|█████████▌| 253/266 [01:38<00:05,  2.36it/s]Loading train:  95%|█████████▌| 254/266 [01:38<00:04,  2.43it/s]Loading train:  96%|█████████▌| 255/266 [01:39<00:04,  2.49it/s]Loading train:  96%|█████████▌| 256/266 [01:39<00:03,  2.54it/s]Loading train:  97%|█████████▋| 257/266 [01:39<00:03,  2.56it/s]Loading train:  97%|█████████▋| 258/266 [01:40<00:03,  2.53it/s]Loading train:  97%|█████████▋| 259/266 [01:40<00:02,  2.49it/s]Loading train:  98%|█████████▊| 260/266 [01:41<00:02,  2.50it/s]Loading train:  98%|█████████▊| 261/266 [01:41<00:01,  2.55it/s]Loading train:  98%|█████████▊| 262/266 [01:41<00:01,  2.56it/s]Loading train:  99%|█████████▉| 263/266 [01:42<00:01,  2.57it/s]Loading train:  99%|█████████▉| 264/266 [01:42<00:00,  2.44it/s]Loading train: 100%|█████████▉| 265/266 [01:43<00:00,  2.42it/s]Loading train: 100%|██████████| 266/266 [01:43<00:00,  2.46it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 22/266 [00:00<00:01, 215.71it/s]concatenating: train:  18%|█▊        | 49/266 [00:00<00:00, 229.09it/s]concatenating: train:  29%|██▉       | 78/266 [00:00<00:00, 241.70it/s]concatenating: train:  41%|████      | 109/266 [00:00<00:00, 258.56it/s]concatenating: train:  54%|█████▍    | 144/266 [00:00<00:00, 279.62it/s]concatenating: train:  66%|██████▌   | 175/266 [00:00<00:00, 287.17it/s]concatenating: train:  82%|████████▏ | 217/266 [00:00<00:00, 315.97it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 332.92it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:02,  1.96it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.10it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.28it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  2.48it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  2.48it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 734.97it/s]2019-08-16 23:24:46.718048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 23:24:46.718145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 23:24:46.718162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 23:24:46.718172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 23:24:46.718574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.78it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  6.85it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.55it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.39it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.24it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.76it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.00it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.37it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.12it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.46it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.52it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.39it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.40it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.54it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.76it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.37it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.95it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 57s - loss: 0.1213 - acc: 0.9792 - mDice: 0.8429 - val_loss: 0.0564 - val_acc: 0.9950 - val_mDice: 0.8960

Epoch 00001: val_mDice improved from -inf to 0.89600, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 52s - loss: 0.0453 - acc: 0.9948 - mDice: 0.9166 - val_loss: 0.0569 - val_acc: 0.9950 - val_mDice: 0.8954

Epoch 00002: val_mDice did not improve from 0.89600
Epoch 3/300
 - 53s - loss: 0.0389 - acc: 0.9954 - mDice: 0.9277 - val_loss: 0.0554 - val_acc: 0.9951 - val_mDice: 0.8981

Epoch 00003: val_mDice improved from 0.89600 to 0.89810, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 55s - loss: 0.0356 - acc: 0.9957 - mDice: 0.9335 - val_loss: 0.0572 - val_acc: 0.9949 - val_mDice: 0.8953

Epoch 00004: val_mDice did not improve from 0.89810
Epoch 5/300
 - 56s - loss: 0.0334 - acc: 0.9959 - mDice: 0.9374 - val_loss: 0.0576 - val_acc: 0.9949 - val_mDice: 0.8946

Epoch 00005: val_mDice did not improve from 0.89810
Epoch 6/300
 - 56s - loss: 0.0317 - acc: 0.9961 - mDice: 0.9406 - val_loss: 0.0595 - val_acc: 0.9947 - val_mDice: 0.8913

Epoch 00006: val_mDice did not improve from 0.89810
Epoch 7/300
 - 57s - loss: 0.0304 - acc: 0.9962 - mDice: 0.9429 - val_loss: 0.0581 - val_acc: 0.9949 - val_mDice: 0.8938

Epoch 00007: val_mDice did not improve from 0.89810
Epoch 8/300
 - 57s - loss: 0.0294 - acc: 0.9963 - mDice: 0.9447 - val_loss: 0.0583 - val_acc: 0.9951 - val_mDice: 0.8935

Epoch 00008: val_mDice did not improve from 0.89810
Epoch 9/300
 - 56s - loss: 0.0286 - acc: 0.9963 - mDice: 0.9462 - val_loss: 0.0588 - val_acc: 0.9949 - val_mDice: 0.8926

Epoch 00009: val_mDice did not improve from 0.89810
Epoch 10/300
 - 57s - loss: 0.0278 - acc: 0.9964 - mDice: 0.9476 - val_loss: 0.0569 - val_acc: 0.9950 - val_mDice: 0.8957

Epoch 00010: val_mDice did not improve from 0.89810
Epoch 11/300
 - 56s - loss: 0.0270 - acc: 0.9965 - mDice: 0.9491 - val_loss: 0.0556 - val_acc: 0.9950 - val_mDice: 0.8981

Epoch 00011: val_mDice did not improve from 0.89810
Epoch 12/300
 - 57s - loss: 0.0266 - acc: 0.9965 - mDice: 0.9498 - val_loss: 0.0593 - val_acc: 0.9949 - val_mDice: 0.8918

Epoch 00012: val_mDice did not improve from 0.89810
Epoch 13/300
 - 56s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0611 - val_acc: 0.9950 - val_mDice: 0.8885

Epoch 00013: val_mDice did not improve from 0.89810
Epoch 14/300
 - 57s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9515 - val_loss: 0.0604 - val_acc: 0.9948 - val_mDice: 0.8901

Epoch 00014: val_mDice did not improve from 0.89810
Epoch 15/300
 - 56s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9524 - val_loss: 0.0587 - val_acc: 0.9950 - val_mDice: 0.8928

Epoch 00015: val_mDice did not improve from 0.89810
Epoch 16/300
 - 57s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9529 - val_loss: 0.0573 - val_acc: 0.9949 - val_mDice: 0.8952

Epoch 00016: val_mDice did not improve from 0.89810
Epoch 17/300
 - 56s - loss: 0.0245 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0587 - val_acc: 0.9947 - val_mDice: 0.8930

Epoch 00017: val_mDice did not improve from 0.89810
Epoch 18/300
 - 57s - loss: 0.0241 - acc: 0.9968 - mDice: 0.9543 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8942

Epoch 00018: val_mDice did not improve from 0.89810
Epoch 19/300
 - 57s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9548 - val_loss: 0.0610 - val_acc: 0.9948 - val_mDice: 0.8889

Epoch 00019: val_mDice did not improve from 0.89810
Epoch 20/300
 - 56s - loss: 0.0237 - acc: 0.9968 - mDice: 0.9551 - val_loss: 0.0583 - val_acc: 0.9949 - val_mDice: 0.8936

Epoch 00020: val_mDice did not improve from 0.89810
Epoch 21/300
 - 57s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9555 - val_loss: 0.0576 - val_acc: 0.9950 - val_mDice: 0.8947

Epoch 00021: val_mDice did not improve from 0.89810
Epoch 22/300
 - 56s - loss: 0.0231 - acc: 0.9969 - mDice: 0.9562 - val_loss: 0.0596 - val_acc: 0.9950 - val_mDice: 0.8915

Epoch 00022: val_mDice did not improve from 0.89810
Epoch 23/300
 - 57s - loss: 0.0231 - acc: 0.9969 - mDice: 0.9563 - val_loss: 0.0594 - val_acc: 0.9949 - val_mDice: 0.8919

Epoch 00023: val_mDice did not improve from 0.89810
Epoch 24/300
 - 57s - loss: 0.0229 - acc: 0.9969 - mDice: 0.9567 - val_loss: 0.0610 - val_acc: 0.9947 - val_mDice: 0.8890

Epoch 00024: val_mDice did not improve from 0.89810
Epoch 25/300
 - 57s - loss: 0.0225 - acc: 0.9969 - mDice: 0.9574 - val_loss: 0.0609 - val_acc: 0.9949 - val_mDice: 0.8889

Epoch 00025: val_mDice did not improve from 0.89810
Epoch 26/300
 - 56s - loss: 0.0224 - acc: 0.9969 - mDice: 0.9575 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8943

Epoch 00026: val_mDice did not improve from 0.89810
Epoch 27/300
 - 57s - loss: 0.0222 - acc: 0.9970 - mDice: 0.9579 - val_loss: 0.0586 - val_acc: 0.9948 - val_mDice: 0.8931

Epoch 00027: val_mDice did not improve from 0.89810
Epoch 28/300
 - 57s - loss: 0.0221 - acc: 0.9970 - mDice: 0.9580 - val_loss: 0.0606 - val_acc: 0.9947 - val_mDice: 0.8898

Epoch 00028: val_mDice did not improve from 0.89810
Epoch 29/300
 - 56s - loss: 0.0220 - acc: 0.9970 - mDice: 0.9584 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8943

Epoch 00029: val_mDice did not improve from 0.89810
Epoch 30/300
 - 55s - loss: 0.0219 - acc: 0.9970 - mDice: 0.9585 - val_loss: 0.0583 - val_acc: 0.9950 - val_mDice: 0.8936

Epoch 00030: val_mDice did not improve from 0.89810
Epoch 31/300
 - 54s - loss: 0.0217 - acc: 0.9970 - mDice: 0.9589 - val_loss: 0.0596 - val_acc: 0.9950 - val_mDice: 0.8914

Epoch 00031: val_mDice did not improve from 0.89810
Epoch 32/300
 - 54s - loss: 0.0215 - acc: 0.9970 - mDice: 0.9592 - val_loss: 0.0664 - val_acc: 0.9947 - val_mDice: 0.8797

Epoch 00032: val_mDice did not improve from 0.89810
Epoch 33/300
 - 54s - loss: 0.0213 - acc: 0.9970 - mDice: 0.9596 - val_loss: 0.0595 - val_acc: 0.9948 - val_mDice: 0.8916

Epoch 00033: val_mDice did not improve from 0.89810
Epoch 34/300
 - 54s - loss: 0.0214 - acc: 0.9970 - mDice: 0.9595 - val_loss: 0.0619 - val_acc: 0.9946 - val_mDice: 0.8876

Epoch 00034: val_mDice did not improve from 0.89810
Epoch 35/300
 - 55s - loss: 0.0212 - acc: 0.9971 - mDice: 0.9598 - val_loss: 0.0581 - val_acc: 0.9949 - val_mDice: 0.8938

Epoch 00035: val_mDice did not improve from 0.89810
Epoch 36/300
 - 55s - loss: 0.0212 - acc: 0.9971 - mDice: 0.9598 - val_loss: 0.0602 - val_acc: 0.9947 - val_mDice: 0.8903

Epoch 00036: val_mDice did not improve from 0.89810
Epoch 37/300
 - 56s - loss: 0.0210 - acc: 0.9971 - mDice: 0.9602 - val_loss: 0.0588 - val_acc: 0.9949 - val_mDice: 0.8928

Epoch 00037: val_mDice did not improve from 0.89810
Epoch 38/300
 - 56s - loss: 0.0209 - acc: 0.9971 - mDice: 0.9604 - val_loss: 0.0570 - val_acc: 0.9951 - val_mDice: 0.8958

Epoch 00038: val_mDice did not improve from 0.89810
Epoch 39/300
 - 57s - loss: 0.0209 - acc: 0.9971 - mDice: 0.9604 - val_loss: 0.0589 - val_acc: 0.9947 - val_mDice: 0.8924

Epoch 00039: val_mDice did not improve from 0.89810
Epoch 40/300
 - 56s - loss: 0.0208 - acc: 0.9971 - mDice: 0.9606 - val_loss: 0.0596 - val_acc: 0.9948 - val_mDice: 0.8916

Epoch 00040: val_mDice did not improve from 0.89810
Epoch 41/300
 - 57s - loss: 0.0208 - acc: 0.9971 - mDice: 0.9606 - val_loss: 0.0616 - val_acc: 0.9948 - val_mDice: 0.8880

Epoch 00041: val_mDice did not improve from 0.89810
Epoch 42/300
 - 57s - loss: 0.0207 - acc: 0.9971 - mDice: 0.9607 - val_loss: 0.0596 - val_acc: 0.9949 - val_mDice: 0.8914

Epoch 00042: val_mDice did not improve from 0.89810
Epoch 43/300
 - 57s - loss: 0.0205 - acc: 0.9971 - mDice: 0.9611 - val_loss: 0.0607 - val_acc: 0.9950 - val_mDice: 0.8895

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:04,  1.00s/it]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.25it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.53it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  1.80it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.94it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:56,  2.28it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:56,  2.27it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:44,  2.52it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:35,  2.73it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:40,  2.59it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:39,  2.61it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:40,  2.57it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:40,  2.57it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:39,  2.59it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:37,  2.61it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:37,  2.61it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:36,  2.62it/s]predicting train subjects:   5%|▍         | 13/266 [00:05<01:38,  2.58it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:36,  2.62it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:32,  2.70it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:30,  2.75it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:31,  2.72it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:33,  2.67it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:32,  2.66it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:32,  2.65it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:33,  2.63it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:30,  2.69it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:31,  2.67it/s]predicting train subjects:   9%|▉         | 24/266 [00:09<01:30,  2.67it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:28,  2.72it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:28,  2.71it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:25,  2.78it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:23,  2.86it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:22,  2.88it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:21,  2.91it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:19,  2.94it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:18,  2.97it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:17,  2.99it/s]predicting train subjects:  13%|█▎        | 34/266 [00:12<01:17,  2.98it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:20,  2.88it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:20,  2.84it/s]predicting train subjects:  14%|█▍        | 37/266 [00:13<01:18,  2.90it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:18,  2.91it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:18,  2.88it/s]predicting train subjects:  15%|█▌        | 40/266 [00:14<01:19,  2.85it/s]predicting train subjects:  15%|█▌        | 41/266 [00:14<01:17,  2.90it/s]predicting train subjects:  16%|█▌        | 42/266 [00:15<01:15,  2.96it/s]predicting train subjects:  16%|█▌        | 43/266 [00:15<01:12,  3.08it/s]predicting train subjects:  17%|█▋        | 44/266 [00:15<01:11,  3.10it/s]predicting train subjects:  17%|█▋        | 45/266 [00:16<01:09,  3.19it/s]predicting train subjects:  17%|█▋        | 46/266 [00:16<01:06,  3.29it/s]predicting train subjects:  18%|█▊        | 47/266 [00:16<01:05,  3.36it/s]predicting train subjects:  18%|█▊        | 48/266 [00:17<01:05,  3.32it/s]predicting train subjects:  18%|█▊        | 49/266 [00:17<01:05,  3.34it/s]predicting train subjects:  19%|█▉        | 50/266 [00:17<01:05,  3.27it/s]predicting train subjects:  19%|█▉        | 51/266 [00:17<01:06,  3.23it/s]predicting train subjects:  20%|█▉        | 52/266 [00:18<01:06,  3.21it/s]predicting train subjects:  20%|█▉        | 53/266 [00:18<01:06,  3.19it/s]predicting train subjects:  20%|██        | 54/266 [00:18<01:06,  3.19it/s]predicting train subjects:  21%|██        | 55/266 [00:19<01:04,  3.29it/s]predicting train subjects:  21%|██        | 56/266 [00:19<01:02,  3.38it/s]predicting train subjects:  21%|██▏       | 57/266 [00:19<01:00,  3.44it/s]predicting train subjects:  22%|██▏       | 58/266 [00:20<01:00,  3.42it/s]predicting train subjects:  22%|██▏       | 59/266 [00:20<01:00,  3.44it/s]predicting train subjects:  23%|██▎       | 60/266 [00:20<00:58,  3.55it/s]predicting train subjects:  23%|██▎       | 61/266 [00:20<00:58,  3.53it/s]predicting train subjects:  23%|██▎       | 62/266 [00:21<00:56,  3.62it/s]predicting train subjects:  24%|██▎       | 63/266 [00:21<00:56,  3.57it/s]predicting train subjects:  24%|██▍       | 64/266 [00:21<00:56,  3.56it/s]predicting train subjects:  24%|██▍       | 65/266 [00:21<00:55,  3.63it/s]predicting train subjects:  25%|██▍       | 66/266 [00:22<00:54,  3.69it/s]predicting train subjects:  25%|██▌       | 67/266 [00:22<00:53,  3.71it/s]predicting train subjects:  26%|██▌       | 68/266 [00:22<00:53,  3.71it/s]predicting train subjects:  26%|██▌       | 69/266 [00:23<00:53,  3.71it/s]predicting train subjects:  26%|██▋       | 70/266 [00:23<00:54,  3.58it/s]predicting train subjects:  27%|██▋       | 71/266 [00:23<00:54,  3.60it/s]predicting train subjects:  27%|██▋       | 72/266 [00:23<00:55,  3.50it/s]predicting train subjects:  27%|██▋       | 73/266 [00:24<00:54,  3.53it/s]predicting train subjects:  28%|██▊       | 74/266 [00:24<00:53,  3.62it/s]predicting train subjects:  28%|██▊       | 75/266 [00:24<00:54,  3.49it/s]predicting train subjects:  29%|██▊       | 76/266 [00:25<00:53,  3.53it/s]predicting train subjects:  29%|██▉       | 77/266 [00:25<00:52,  3.62it/s]predicting train subjects:  29%|██▉       | 78/266 [00:25<00:58,  3.24it/s]predicting train subjects:  30%|██▉       | 79/266 [00:26<01:00,  3.08it/s]predicting train subjects:  30%|███       | 80/266 [00:26<01:00,  3.05it/s]predicting train subjects:  30%|███       | 81/266 [00:26<01:03,  2.93it/s]predicting train subjects:  31%|███       | 82/266 [00:27<01:04,  2.85it/s]predicting train subjects:  31%|███       | 83/266 [00:27<01:03,  2.86it/s]predicting train subjects:  32%|███▏      | 84/266 [00:27<01:03,  2.86it/s]predicting train subjects:  32%|███▏      | 85/266 [00:28<01:03,  2.86it/s]predicting train subjects:  32%|███▏      | 86/266 [00:28<01:03,  2.86it/s]predicting train subjects:  33%|███▎      | 87/266 [00:28<01:02,  2.88it/s]predicting train subjects:  33%|███▎      | 88/266 [00:29<01:01,  2.91it/s]predicting train subjects:  33%|███▎      | 89/266 [00:29<00:59,  2.95it/s]predicting train subjects:  34%|███▍      | 90/266 [00:29<01:00,  2.93it/s]predicting train subjects:  34%|███▍      | 91/266 [00:30<01:00,  2.91it/s]predicting train subjects:  35%|███▍      | 92/266 [00:30<00:59,  2.91it/s]predicting train subjects:  35%|███▍      | 93/266 [00:30<00:59,  2.91it/s]predicting train subjects:  35%|███▌      | 94/266 [00:31<01:00,  2.85it/s]predicting train subjects:  36%|███▌      | 95/266 [00:31<00:59,  2.88it/s]predicting train subjects:  36%|███▌      | 96/266 [00:31<01:00,  2.83it/s]predicting train subjects:  36%|███▋      | 97/266 [00:32<01:02,  2.72it/s]predicting train subjects:  37%|███▋      | 98/266 [00:32<01:02,  2.67it/s]predicting train subjects:  37%|███▋      | 99/266 [00:33<00:57,  2.90it/s]predicting train subjects:  38%|███▊      | 100/266 [00:33<00:55,  2.99it/s]predicting train subjects:  38%|███▊      | 101/266 [00:33<00:52,  3.11it/s]predicting train subjects:  38%|███▊      | 102/266 [00:33<00:51,  3.20it/s]predicting train subjects:  39%|███▊      | 103/266 [00:34<00:50,  3.23it/s]predicting train subjects:  39%|███▉      | 104/266 [00:34<00:49,  3.28it/s]predicting train subjects:  39%|███▉      | 105/266 [00:34<00:50,  3.20it/s]predicting train subjects:  40%|███▉      | 106/266 [00:35<00:50,  3.14it/s]predicting train subjects:  40%|████      | 107/266 [00:35<00:49,  3.20it/s]predicting train subjects:  41%|████      | 108/266 [00:35<00:49,  3.22it/s]predicting train subjects:  41%|████      | 109/266 [00:36<00:48,  3.26it/s]predicting train subjects:  41%|████▏     | 110/266 [00:36<00:47,  3.29it/s]predicting train subjects:  42%|████▏     | 111/266 [00:36<00:46,  3.31it/s]predicting train subjects:  42%|████▏     | 112/266 [00:36<00:46,  3.33it/s]predicting train subjects:  42%|████▏     | 113/266 [00:37<00:47,  3.24it/s]predicting train subjects:  43%|████▎     | 114/266 [00:37<00:47,  3.17it/s]predicting train subjects:  43%|████▎     | 115/266 [00:37<00:46,  3.24it/s]predicting train subjects:  44%|████▎     | 116/266 [00:38<00:45,  3.29it/s]predicting train subjects:  44%|████▍     | 117/266 [00:38<00:44,  3.32it/s]predicting train subjects:  44%|████▍     | 118/266 [00:38<00:45,  3.25it/s]predicting train subjects:  45%|████▍     | 119/266 [00:39<00:46,  3.13it/s]predicting train subjects:  45%|████▌     | 120/266 [00:39<00:47,  3.09it/s]predicting train subjects:  45%|████▌     | 121/266 [00:39<00:47,  3.08it/s]predicting train subjects:  46%|████▌     | 122/266 [00:40<00:47,  3.06it/s]predicting train subjects:  46%|████▌     | 123/266 [00:40<00:46,  3.05it/s]predicting train subjects:  47%|████▋     | 124/266 [00:40<00:46,  3.03it/s]predicting train subjects:  47%|████▋     | 125/266 [00:41<00:47,  2.95it/s]predicting train subjects:  47%|████▋     | 126/266 [00:41<00:47,  2.96it/s]predicting train subjects:  48%|████▊     | 127/266 [00:41<00:46,  2.96it/s]predicting train subjects:  48%|████▊     | 128/266 [00:42<00:47,  2.90it/s]predicting train subjects:  48%|████▊     | 129/266 [00:42<00:47,  2.91it/s]predicting train subjects:  49%|████▉     | 130/266 [00:42<00:47,  2.88it/s]predicting train subjects:  49%|████▉     | 131/266 [00:43<00:46,  2.88it/s]predicting train subjects:  50%|████▉     | 132/266 [00:43<00:45,  2.91it/s]predicting train subjects:  50%|█████     | 133/266 [00:44<00:47,  2.81it/s]predicting train subjects:  50%|█████     | 134/266 [00:44<00:46,  2.86it/s]predicting train subjects:  51%|█████     | 135/266 [00:44<00:46,  2.81it/s]predicting train subjects:  51%|█████     | 136/266 [00:45<00:48,  2.69it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:45<00:46,  2.75it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:45<00:45,  2.84it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:46<00:44,  2.88it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:46<00:43,  2.88it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:46<00:42,  2.94it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:47<00:42,  2.92it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:47<00:41,  2.94it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:47<00:42,  2.85it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:48<00:43,  2.76it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:48<00:43,  2.76it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:48<00:42,  2.83it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:49<00:41,  2.83it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:49<00:40,  2.90it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:49<00:40,  2.87it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:50<00:39,  2.94it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:50<00:37,  3.00it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:50<00:37,  3.02it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:51<00:38,  2.94it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:51<00:35,  3.11it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:51<00:32,  3.36it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:52<00:31,  3.49it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:52<00:30,  3.57it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:52<00:29,  3.68it/s]predicting train subjects:  60%|██████    | 160/266 [00:52<00:28,  3.78it/s]predicting train subjects:  61%|██████    | 161/266 [00:53<00:27,  3.80it/s]predicting train subjects:  61%|██████    | 162/266 [00:53<00:29,  3.52it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:53<00:28,  3.57it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:54<00:29,  3.46it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:54<00:28,  3.50it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:54<00:28,  3.56it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:54<00:27,  3.66it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:55<00:27,  3.57it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:55<00:27,  3.53it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:55<00:27,  3.50it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:55<00:25,  3.67it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:56<00:25,  3.74it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:56<00:25,  3.65it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:56<00:25,  3.61it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:57<00:25,  3.61it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:57<00:25,  3.58it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:57<00:25,  3.50it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:57<00:24,  3.53it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:58<00:25,  3.35it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:58<00:26,  3.25it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:58<00:26,  3.26it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:59<00:25,  3.33it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:59<00:25,  3.27it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:59<00:25,  3.23it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:00<00:24,  3.34it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:00<00:23,  3.35it/s]predicting train subjects:  70%|███████   | 187/266 [01:00<00:22,  3.44it/s]predicting train subjects:  71%|███████   | 188/266 [01:00<00:22,  3.48it/s]predicting train subjects:  71%|███████   | 189/266 [01:01<00:22,  3.47it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:01<00:21,  3.49it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:01<00:22,  3.36it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:02<00:23,  3.17it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:02<00:22,  3.20it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:02<00:23,  3.00it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:03<00:22,  3.10it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:03<00:21,  3.24it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:03<00:21,  3.27it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:04<00:20,  3.35it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:04<00:19,  3.41it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:04<00:19,  3.46it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:04<00:19,  3.30it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:05<00:19,  3.23it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:05<00:19,  3.18it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:05<00:19,  3.19it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:06<00:19,  3.14it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:06<00:18,  3.25it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:06<00:17,  3.33it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:07<00:17,  3.38it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:07<00:16,  3.41it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:07<00:16,  3.37it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:07<00:16,  3.38it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:08<00:15,  3.40it/s]predicting train subjects:  80%|████████  | 213/266 [01:08<00:15,  3.47it/s]predicting train subjects:  80%|████████  | 214/266 [01:08<00:14,  3.60it/s]predicting train subjects:  81%|████████  | 215/266 [01:09<00:13,  3.68it/s]predicting train subjects:  81%|████████  | 216/266 [01:09<00:13,  3.72it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:09<00:12,  3.80it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:09<00:12,  3.77it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:10<00:12,  3.78it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:10<00:12,  3.57it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:10<00:12,  3.55it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:10<00:12,  3.64it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:11<00:11,  3.75it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:11<00:11,  3.81it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:11<00:10,  3.81it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:11<00:10,  3.87it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:12<00:10,  3.89it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:12<00:10,  3.78it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:12<00:09,  3.82it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:12<00:09,  3.86it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:13<00:09,  3.72it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:13<00:09,  3.72it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:13<00:08,  3.73it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:14<00:08,  3.61it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:14<00:08,  3.58it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:14<00:08,  3.52it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:14<00:08,  3.57it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:15<00:07,  3.60it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:15<00:07,  3.66it/s]predicting train subjects:  90%|█████████ | 240/266 [01:15<00:07,  3.47it/s]predicting train subjects:  91%|█████████ | 241/266 [01:16<00:07,  3.38it/s]predicting train subjects:  91%|█████████ | 242/266 [01:16<00:06,  3.47it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:16<00:06,  3.41it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:17<00:06,  3.23it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:17<00:06,  3.31it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:17<00:05,  3.44it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:17<00:05,  3.50it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:18<00:05,  3.43it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:18<00:05,  3.18it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:18<00:05,  3.08it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:19<00:05,  2.95it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:19<00:04,  2.90it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:19<00:04,  2.93it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:20<00:04,  2.95it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:20<00:03,  3.02it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:20<00:03,  3.01it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:21<00:03,  3.00it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:21<00:02,  2.97it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:21<00:02,  2.93it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:22<00:02,  2.95it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:22<00:01,  2.98it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:23<00:01,  2.89it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:23<00:01,  2.90it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:23<00:00,  2.73it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:24<00:00,  2.74it/s]predicting train subjects: 100%|██████████| 266/266 [01:24<00:00,  2.75it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 67.46it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:03, 66.49it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 65.56it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 64.67it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 65.07it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 67.01it/s]saving BB  train1-THALAMUS:  17%|█▋        | 44/266 [00:00<00:03, 68.86it/s]saving BB  train1-THALAMUS:  20%|█▉        | 52/266 [00:00<00:02, 71.77it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:00<00:02, 75.00it/s]saving BB  train1-THALAMUS:  26%|██▋       | 70/266 [00:00<00:02, 77.96it/s]saving BB  train1-THALAMUS:  30%|██▉       | 79/266 [00:01<00:02, 79.10it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:02, 76.08it/s]saving BB  train1-THALAMUS:  36%|███▌      | 95/266 [00:01<00:02, 74.06it/s]saving BB  train1-THALAMUS:  39%|███▊      | 103/266 [00:01<00:02, 73.09it/s]saving BB  train1-THALAMUS:  42%|████▏     | 111/266 [00:01<00:02, 74.09it/s]saving BB  train1-THALAMUS:  45%|████▍     | 119/266 [00:01<00:01, 73.89it/s]saving BB  train1-THALAMUS:  48%|████▊     | 127/266 [00:01<00:01, 71.86it/s]saving BB  train1-THALAMUS:  51%|█████     | 135/266 [00:01<00:01, 70.19it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 143/266 [00:01<00:01, 70.15it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 151/266 [00:02<00:01, 70.93it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 159/266 [00:02<00:01, 72.78it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 168/266 [00:02<00:01, 75.88it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 177/266 [00:02<00:01, 78.13it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:02<00:00, 80.88it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 195/266 [00:02<00:00, 77.42it/s]saving BB  train1-THALAMUS:  76%|███████▋  | 203/266 [00:02<00:00, 74.13it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 211/266 [00:02<00:00, 74.84it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 220/266 [00:02<00:00, 76.98it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 229/266 [00:03<00:00, 78.05it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 79.50it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 80.42it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 256/266 [00:03<00:00, 77.17it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 264/266 [00:03<00:00, 75.30it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 74.51it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:17,  1.65s/it]Loading train:   1%|          | 2/266 [00:03<07:08,  1.62s/it]Loading train:   1%|          | 3/266 [00:04<06:47,  1.55s/it]Loading train:   2%|▏         | 4/266 [00:05<06:20,  1.45s/it]Loading train:   2%|▏         | 5/266 [00:07<06:23,  1.47s/it]Loading train:   2%|▏         | 6/266 [00:08<06:13,  1.43s/it]Loading train:   3%|▎         | 7/266 [00:09<05:46,  1.34s/it]Loading train:   3%|▎         | 8/266 [00:10<05:27,  1.27s/it]Loading train:   3%|▎         | 9/266 [00:12<05:15,  1.23s/it]Loading train:   4%|▍         | 10/266 [00:13<05:00,  1.17s/it]Loading train:   4%|▍         | 11/266 [00:14<04:56,  1.16s/it]Loading train:   5%|▍         | 12/266 [00:15<04:56,  1.17s/it]Loading train:   5%|▍         | 13/266 [00:16<04:48,  1.14s/it]Loading train:   5%|▌         | 14/266 [00:17<04:48,  1.15s/it]Loading train:   6%|▌         | 15/266 [00:18<04:44,  1.14s/it]Loading train:   6%|▌         | 16/266 [00:19<04:50,  1.16s/it]Loading train:   6%|▋         | 17/266 [00:21<04:48,  1.16s/it]Loading train:   7%|▋         | 18/266 [00:22<04:48,  1.16s/it]Loading train:   7%|▋         | 19/266 [00:23<04:42,  1.14s/it]Loading train:   8%|▊         | 20/266 [00:24<04:41,  1.14s/it]Loading train:   8%|▊         | 21/266 [00:25<04:32,  1.11s/it]Loading train:   8%|▊         | 22/266 [00:26<04:26,  1.09s/it]Loading train:   9%|▊         | 23/266 [00:27<04:24,  1.09s/it]Loading train:   9%|▉         | 24/266 [00:28<04:30,  1.12s/it]Loading train:   9%|▉         | 25/266 [00:29<04:13,  1.05s/it]Loading train:  10%|▉         | 26/266 [00:30<04:02,  1.01s/it]Loading train:  10%|█         | 27/266 [00:31<03:54,  1.02it/s]Loading train:  11%|█         | 28/266 [00:32<03:49,  1.04it/s]Loading train:  11%|█         | 29/266 [00:33<03:46,  1.05it/s]Loading train:  11%|█▏        | 30/266 [00:34<03:40,  1.07it/s]Loading train:  12%|█▏        | 31/266 [00:35<03:36,  1.08it/s]Loading train:  12%|█▏        | 32/266 [00:36<03:34,  1.09it/s]Loading train:  12%|█▏        | 33/266 [00:37<03:31,  1.10it/s]Loading train:  13%|█▎        | 34/266 [00:38<03:35,  1.08it/s]Loading train:  13%|█▎        | 35/266 [00:38<03:33,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:39<03:30,  1.09it/s]Loading train:  14%|█▍        | 37/266 [00:40<03:29,  1.09it/s]Loading train:  14%|█▍        | 38/266 [00:41<03:33,  1.07it/s]Loading train:  15%|█▍        | 39/266 [00:42<03:32,  1.07it/s]Loading train:  15%|█▌        | 40/266 [00:43<03:28,  1.08it/s]Loading train:  15%|█▌        | 41/266 [00:44<03:26,  1.09it/s]Loading train:  16%|█▌        | 42/266 [00:45<03:28,  1.07it/s]Loading train:  16%|█▌        | 43/266 [00:46<03:20,  1.11it/s]Loading train:  17%|█▋        | 44/266 [00:47<03:14,  1.14it/s]Loading train:  17%|█▋        | 45/266 [00:47<03:15,  1.13it/s]Loading train:  17%|█▋        | 46/266 [00:48<03:13,  1.14it/s]Loading train:  18%|█▊        | 47/266 [00:49<03:09,  1.15it/s]Loading train:  18%|█▊        | 48/266 [00:50<03:09,  1.15it/s]Loading train:  18%|█▊        | 49/266 [00:51<03:07,  1.16it/s]Loading train:  19%|█▉        | 50/266 [00:52<03:11,  1.13it/s]Loading train:  19%|█▉        | 51/266 [00:53<03:08,  1.14it/s]Loading train:  20%|█▉        | 52/266 [00:54<03:11,  1.12it/s]Loading train:  20%|█▉        | 53/266 [00:55<03:10,  1.12it/s]Loading train:  20%|██        | 54/266 [00:55<03:10,  1.12it/s]Loading train:  21%|██        | 55/266 [00:56<03:06,  1.13it/s]Loading train:  21%|██        | 56/266 [00:57<03:05,  1.13it/s]Loading train:  21%|██▏       | 57/266 [00:58<03:01,  1.15it/s]Loading train:  22%|██▏       | 58/266 [00:59<03:04,  1.13it/s]Loading train:  22%|██▏       | 59/266 [01:00<03:03,  1.13it/s]Loading train:  23%|██▎       | 60/266 [01:01<03:09,  1.09it/s]Loading train:  23%|██▎       | 61/266 [01:02<03:07,  1.09it/s]Loading train:  23%|██▎       | 62/266 [01:03<03:02,  1.12it/s]Loading train:  24%|██▎       | 63/266 [01:03<02:52,  1.18it/s]Loading train:  24%|██▍       | 64/266 [01:04<02:45,  1.22it/s]Loading train:  24%|██▍       | 65/266 [01:05<02:42,  1.23it/s]Loading train:  25%|██▍       | 66/266 [01:06<02:39,  1.25it/s]Loading train:  25%|██▌       | 67/266 [01:06<02:37,  1.26it/s]Loading train:  26%|██▌       | 68/266 [01:07<02:40,  1.23it/s]Loading train:  26%|██▌       | 69/266 [01:08<02:37,  1.25it/s]Loading train:  26%|██▋       | 70/266 [01:09<02:36,  1.25it/s]Loading train:  27%|██▋       | 71/266 [01:10<02:34,  1.26it/s]Loading train:  27%|██▋       | 72/266 [01:10<02:34,  1.25it/s]Loading train:  27%|██▋       | 73/266 [01:11<02:32,  1.27it/s]Loading train:  28%|██▊       | 74/266 [01:12<02:31,  1.27it/s]Loading train:  28%|██▊       | 75/266 [01:13<02:34,  1.23it/s]Loading train:  29%|██▊       | 76/266 [01:14<02:33,  1.24it/s]Loading train:  29%|██▉       | 77/266 [01:14<02:29,  1.26it/s]Loading train:  29%|██▉       | 78/266 [01:16<02:49,  1.11it/s]Loading train:  30%|██▉       | 79/266 [01:16<02:47,  1.12it/s]Loading train:  30%|███       | 80/266 [01:17<02:48,  1.10it/s]Loading train:  30%|███       | 81/266 [01:18<02:45,  1.12it/s]Loading train:  31%|███       | 82/266 [01:19<02:43,  1.13it/s]Loading train:  31%|███       | 83/266 [01:20<02:42,  1.12it/s]Loading train:  32%|███▏      | 84/266 [01:21<02:42,  1.12it/s]Loading train:  32%|███▏      | 85/266 [01:22<02:46,  1.08it/s]Loading train:  32%|███▏      | 86/266 [01:23<02:44,  1.09it/s]Loading train:  33%|███▎      | 87/266 [01:24<02:42,  1.10it/s]Loading train:  33%|███▎      | 88/266 [01:25<02:44,  1.08it/s]Loading train:  33%|███▎      | 89/266 [01:26<02:45,  1.07it/s]Loading train:  34%|███▍      | 90/266 [01:27<02:47,  1.05it/s]Loading train:  34%|███▍      | 91/266 [01:27<02:43,  1.07it/s]Loading train:  35%|███▍      | 92/266 [01:29<02:49,  1.02it/s]Loading train:  35%|███▍      | 93/266 [01:30<02:55,  1.01s/it]Loading train:  35%|███▌      | 94/266 [01:31<02:56,  1.03s/it]Loading train:  36%|███▌      | 95/266 [01:32<02:58,  1.04s/it]Loading train:  36%|███▌      | 96/266 [01:33<03:23,  1.20s/it]Loading train:  36%|███▋      | 97/266 [01:35<03:36,  1.28s/it]Loading train:  37%|███▋      | 98/266 [01:36<03:45,  1.34s/it]Loading train:  37%|███▋      | 99/266 [01:37<03:33,  1.28s/it]Loading train:  38%|███▊      | 100/266 [01:39<03:30,  1.27s/it]Loading train:  38%|███▊      | 101/266 [01:40<03:11,  1.16s/it]Loading train:  38%|███▊      | 102/266 [01:41<03:01,  1.10s/it]Loading train:  39%|███▊      | 103/266 [01:42<02:53,  1.07s/it]Loading train:  39%|███▉      | 104/266 [01:42<02:43,  1.01s/it]Loading train:  39%|███▉      | 105/266 [01:43<02:37,  1.02it/s]Loading train:  40%|███▉      | 106/266 [01:44<02:32,  1.05it/s]Loading train:  40%|████      | 107/266 [01:45<02:26,  1.09it/s]Loading train:  41%|████      | 108/266 [01:46<02:23,  1.10it/s]Loading train:  41%|████      | 109/266 [01:47<02:21,  1.11it/s]Loading train:  41%|████▏     | 110/266 [01:48<02:20,  1.11it/s]Loading train:  42%|████▏     | 111/266 [01:49<02:17,  1.12it/s]Loading train:  42%|████▏     | 112/266 [01:49<02:16,  1.13it/s]Loading train:  42%|████▏     | 113/266 [01:50<02:15,  1.13it/s]Loading train:  43%|████▎     | 114/266 [01:51<02:16,  1.11it/s]Loading train:  43%|████▎     | 115/266 [01:52<02:13,  1.13it/s]Loading train:  44%|████▎     | 116/266 [01:53<02:12,  1.13it/s]Loading train:  44%|████▍     | 117/266 [01:54<02:11,  1.13it/s]Loading train:  44%|████▍     | 118/266 [01:55<02:11,  1.13it/s]Loading train:  45%|████▍     | 119/266 [01:56<02:15,  1.08it/s]Loading train:  45%|████▌     | 120/266 [01:57<02:18,  1.06it/s]Loading train:  45%|████▌     | 121/266 [01:58<02:17,  1.05it/s]Loading train:  46%|████▌     | 122/266 [01:59<02:16,  1.05it/s]Loading train:  46%|████▌     | 123/266 [02:00<02:17,  1.04it/s]Loading train:  47%|████▋     | 124/266 [02:01<02:18,  1.03it/s]Loading train:  47%|████▋     | 125/266 [02:02<02:18,  1.02it/s]Loading train:  47%|████▋     | 126/266 [02:03<02:19,  1.00it/s]Loading train:  48%|████▊     | 127/266 [02:04<02:19,  1.00s/it]Loading train:  48%|████▊     | 128/266 [02:05<02:19,  1.01s/it]Loading train:  48%|████▊     | 129/266 [02:06<02:18,  1.01s/it]Loading train:  49%|████▉     | 130/266 [02:07<02:15,  1.00it/s]Loading train:  49%|████▉     | 131/266 [02:08<02:14,  1.01it/s]Loading train:  50%|████▉     | 132/266 [02:09<02:12,  1.01it/s]Loading train:  50%|█████     | 133/266 [02:10<02:11,  1.01it/s]Loading train:  50%|█████     | 134/266 [02:11<02:11,  1.01it/s]Loading train:  51%|█████     | 135/266 [02:12<02:09,  1.01it/s]Loading train:  51%|█████     | 136/266 [02:13<02:06,  1.03it/s]Loading train:  52%|█████▏    | 137/266 [02:14<02:04,  1.03it/s]Loading train:  52%|█████▏    | 138/266 [02:14<02:01,  1.05it/s]Loading train:  52%|█████▏    | 139/266 [02:15<01:58,  1.07it/s]Loading train:  53%|█████▎    | 140/266 [02:16<01:59,  1.05it/s]Loading train:  53%|█████▎    | 141/266 [02:17<01:58,  1.06it/s]Loading train:  53%|█████▎    | 142/266 [02:18<01:55,  1.08it/s]Loading train:  54%|█████▍    | 143/266 [02:19<01:54,  1.07it/s]Loading train:  54%|█████▍    | 144/266 [02:20<01:55,  1.05it/s]Loading train:  55%|█████▍    | 145/266 [02:21<01:58,  1.02it/s]Loading train:  55%|█████▍    | 146/266 [02:22<01:58,  1.02it/s]Loading train:  55%|█████▌    | 147/266 [02:23<02:00,  1.01s/it]Loading train:  56%|█████▌    | 148/266 [02:24<02:01,  1.03s/it]Loading train:  56%|█████▌    | 149/266 [02:25<02:00,  1.03s/it]Loading train:  56%|█████▋    | 150/266 [02:26<01:59,  1.03s/it]Loading train:  57%|█████▋    | 151/266 [02:27<01:59,  1.04s/it]Loading train:  57%|█████▋    | 152/266 [02:28<01:57,  1.03s/it]Loading train:  58%|█████▊    | 153/266 [02:29<01:54,  1.01s/it]Loading train:  58%|█████▊    | 154/266 [02:30<01:54,  1.03s/it]Loading train:  58%|█████▊    | 155/266 [02:31<01:48,  1.02it/s]Loading train:  59%|█████▊    | 156/266 [02:32<01:44,  1.05it/s]Loading train:  59%|█████▉    | 157/266 [02:33<01:38,  1.11it/s]Loading train:  59%|█████▉    | 158/266 [02:34<01:35,  1.13it/s]Loading train:  60%|█████▉    | 159/266 [02:35<01:30,  1.18it/s]Loading train:  60%|██████    | 160/266 [02:35<01:26,  1.23it/s]Loading train:  61%|██████    | 161/266 [02:36<01:22,  1.28it/s]Loading train:  61%|██████    | 162/266 [02:37<01:18,  1.32it/s]Loading train:  61%|██████▏   | 163/266 [02:38<01:19,  1.30it/s]Loading train:  62%|██████▏   | 164/266 [02:38<01:20,  1.26it/s]Loading train:  62%|██████▏   | 165/266 [02:39<01:18,  1.28it/s]Loading train:  62%|██████▏   | 166/266 [02:40<01:16,  1.31it/s]Loading train:  63%|██████▎   | 167/266 [02:41<01:15,  1.31it/s]Loading train:  63%|██████▎   | 168/266 [02:41<01:15,  1.29it/s]Loading train:  64%|██████▎   | 169/266 [02:42<01:18,  1.24it/s]Loading train:  64%|██████▍   | 170/266 [02:43<01:19,  1.21it/s]Loading train:  64%|██████▍   | 171/266 [02:44<01:19,  1.19it/s]Loading train:  65%|██████▍   | 172/266 [02:45<01:20,  1.17it/s]Loading train:  65%|██████▌   | 173/266 [02:46<01:19,  1.16it/s]Loading train:  65%|██████▌   | 174/266 [02:47<01:18,  1.18it/s]Loading train:  66%|██████▌   | 175/266 [02:47<01:16,  1.19it/s]Loading train:  66%|██████▌   | 176/266 [02:48<01:13,  1.23it/s]Loading train:  67%|██████▋   | 177/266 [02:49<01:10,  1.25it/s]Loading train:  67%|██████▋   | 178/266 [02:50<01:09,  1.26it/s]Loading train:  67%|██████▋   | 179/266 [02:51<01:07,  1.28it/s]Loading train:  68%|██████▊   | 180/266 [02:51<01:09,  1.24it/s]Loading train:  68%|██████▊   | 181/266 [02:52<01:08,  1.23it/s]Loading train:  68%|██████▊   | 182/266 [02:53<01:07,  1.25it/s]Loading train:  69%|██████▉   | 183/266 [02:54<01:06,  1.24it/s]Loading train:  69%|██████▉   | 184/266 [02:55<01:05,  1.25it/s]Loading train:  70%|██████▉   | 185/266 [02:55<01:04,  1.26it/s]Loading train:  70%|██████▉   | 186/266 [02:56<01:03,  1.27it/s]Loading train:  70%|███████   | 187/266 [02:57<01:00,  1.30it/s]Loading train:  71%|███████   | 188/266 [02:58<01:00,  1.29it/s]Loading train:  71%|███████   | 189/266 [02:58<00:59,  1.29it/s]Loading train:  71%|███████▏  | 190/266 [02:59<00:59,  1.27it/s]Loading train:  72%|███████▏  | 191/266 [03:00<01:09,  1.09it/s]Loading train:  72%|███████▏  | 192/266 [03:02<01:13,  1.01it/s]Loading train:  73%|███████▎  | 193/266 [03:03<01:19,  1.09s/it]Loading train:  73%|███████▎  | 194/266 [03:04<01:28,  1.23s/it]Loading train:  73%|███████▎  | 195/266 [03:05<01:20,  1.14s/it]Loading train:  74%|███████▎  | 196/266 [03:06<01:13,  1.05s/it]Loading train:  74%|███████▍  | 197/266 [03:07<01:08,  1.01it/s]Loading train:  74%|███████▍  | 198/266 [03:08<01:05,  1.04it/s]Loading train:  75%|███████▍  | 199/266 [03:09<01:01,  1.09it/s]Loading train:  75%|███████▌  | 200/266 [03:10<01:01,  1.08it/s]Loading train:  76%|███████▌  | 201/266 [03:11<00:59,  1.10it/s]Loading train:  76%|███████▌  | 202/266 [03:11<00:56,  1.14it/s]Loading train:  76%|███████▋  | 203/266 [03:12<00:54,  1.15it/s]Loading train:  77%|███████▋  | 204/266 [03:13<00:53,  1.16it/s]Loading train:  77%|███████▋  | 205/266 [03:14<00:51,  1.18it/s]Loading train:  77%|███████▋  | 206/266 [03:15<00:50,  1.18it/s]Loading train:  78%|███████▊  | 207/266 [03:16<00:49,  1.20it/s]Loading train:  78%|███████▊  | 208/266 [03:16<00:47,  1.22it/s]Loading train:  79%|███████▊  | 209/266 [03:17<00:47,  1.20it/s]Loading train:  79%|███████▉  | 210/266 [03:18<00:46,  1.21it/s]Loading train:  79%|███████▉  | 211/266 [03:19<00:44,  1.25it/s]Loading train:  80%|███████▉  | 212/266 [03:20<00:42,  1.26it/s]Loading train:  80%|████████  | 213/266 [03:20<00:41,  1.28it/s]Loading train:  80%|████████  | 214/266 [03:21<00:40,  1.28it/s]Loading train:  81%|████████  | 215/266 [03:22<00:38,  1.31it/s]Loading train:  81%|████████  | 216/266 [03:23<00:38,  1.32it/s]Loading train:  82%|████████▏ | 217/266 [03:23<00:36,  1.33it/s]Loading train:  82%|████████▏ | 218/266 [03:24<00:36,  1.31it/s]Loading train:  82%|████████▏ | 219/266 [03:25<00:35,  1.31it/s]Loading train:  83%|████████▎ | 220/266 [03:26<00:34,  1.34it/s]Loading train:  83%|████████▎ | 221/266 [03:26<00:33,  1.34it/s]Loading train:  83%|████████▎ | 222/266 [03:27<00:32,  1.34it/s]Loading train:  84%|████████▍ | 223/266 [03:28<00:31,  1.36it/s]Loading train:  84%|████████▍ | 224/266 [03:29<00:31,  1.35it/s]Loading train:  85%|████████▍ | 225/266 [03:29<00:30,  1.34it/s]Loading train:  85%|████████▍ | 226/266 [03:30<00:30,  1.30it/s]Loading train:  85%|████████▌ | 227/266 [03:31<00:29,  1.31it/s]Loading train:  86%|████████▌ | 228/266 [03:32<00:29,  1.28it/s]Loading train:  86%|████████▌ | 229/266 [03:33<00:29,  1.26it/s]Loading train:  86%|████████▋ | 230/266 [03:33<00:28,  1.27it/s]Loading train:  87%|████████▋ | 231/266 [03:34<00:27,  1.27it/s]Loading train:  87%|████████▋ | 232/266 [03:35<00:26,  1.30it/s]Loading train:  88%|████████▊ | 233/266 [03:36<00:24,  1.33it/s]Loading train:  88%|████████▊ | 234/266 [03:36<00:24,  1.32it/s]Loading train:  88%|████████▊ | 235/266 [03:37<00:23,  1.33it/s]Loading train:  89%|████████▊ | 236/266 [03:38<00:22,  1.34it/s]Loading train:  89%|████████▉ | 237/266 [03:39<00:21,  1.33it/s]Loading train:  89%|████████▉ | 238/266 [03:39<00:21,  1.32it/s]Loading train:  90%|████████▉ | 239/266 [03:40<00:20,  1.33it/s]Loading train:  90%|█████████ | 240/266 [03:41<00:19,  1.35it/s]Loading train:  91%|█████████ | 241/266 [03:42<00:18,  1.34it/s]Loading train:  91%|█████████ | 242/266 [03:42<00:17,  1.34it/s]Loading train:  91%|█████████▏| 243/266 [03:43<00:17,  1.32it/s]Loading train:  92%|█████████▏| 244/266 [03:44<00:16,  1.31it/s]Loading train:  92%|█████████▏| 245/266 [03:45<00:15,  1.35it/s]Loading train:  92%|█████████▏| 246/266 [03:45<00:15,  1.30it/s]Loading train:  93%|█████████▎| 247/266 [03:46<00:14,  1.32it/s]Loading train:  93%|█████████▎| 248/266 [03:47<00:13,  1.30it/s]Loading train:  94%|█████████▎| 249/266 [03:48<00:13,  1.21it/s]Loading train:  94%|█████████▍| 250/266 [03:49<00:13,  1.20it/s]Loading train:  94%|█████████▍| 251/266 [03:50<00:13,  1.15it/s]Loading train:  95%|█████████▍| 252/266 [03:50<00:12,  1.16it/s]Loading train:  95%|█████████▌| 253/266 [03:51<00:11,  1.17it/s]Loading train:  95%|█████████▌| 254/266 [03:52<00:10,  1.15it/s]Loading train:  96%|█████████▌| 255/266 [03:53<00:09,  1.12it/s]Loading train:  96%|█████████▌| 256/266 [03:54<00:08,  1.12it/s]Loading train:  97%|█████████▋| 257/266 [03:55<00:08,  1.09it/s]Loading train:  97%|█████████▋| 258/266 [03:56<00:07,  1.08it/s]Loading train:  97%|█████████▋| 259/266 [03:57<00:06,  1.08it/s]Loading train:  98%|█████████▊| 260/266 [03:58<00:05,  1.03it/s]Loading train:  98%|█████████▊| 261/266 [03:59<00:04,  1.02it/s]Loading train:  98%|█████████▊| 262/266 [04:00<00:03,  1.01it/s]Loading train:  99%|█████████▉| 263/266 [04:01<00:02,  1.02it/s]Loading train:  99%|█████████▉| 264/266 [04:02<00:01,  1.01it/s]Loading train: 100%|█████████▉| 265/266 [04:03<00:00,  1.05it/s]Loading train: 100%|██████████| 266/266 [04:04<00:00,  1.05it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:03, 79.11it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:02, 91.93it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:01, 111.06it/s]concatenating: train:  26%|██▌       | 69/266 [00:00<00:01, 131.51it/s]concatenating: train:  36%|███▋      | 97/266 [00:00<00:01, 156.28it/s]concatenating: train:  47%|████▋     | 126/266 [00:00<00:00, 181.07it/s]concatenating: train:  57%|█████▋    | 152/266 [00:00<00:00, 198.99it/s]concatenating: train:  68%|██████▊   | 182/266 [00:00<00:00, 220.48it/s]concatenating: train:  80%|███████▉  | 212/266 [00:00<00:00, 237.82it/s]concatenating: train:  90%|████████▉ | 239/266 [00:01<00:00, 244.73it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 239.03it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.28s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.31s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.26s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.23s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 98.74it/s]2019-08-17 00:11:04.838118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 00:11:04.838208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 00:11:04.838223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 00:11:04.838233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 00:11:04.838624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.31it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.35it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.09it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.84it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.49it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.26it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.28it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.94it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.92it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.12it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.28it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.09it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.00it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.29it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.11it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.47it/s]
Epoch 00043: val_mDice did not improve from 0.89810
Restoring model weights from the end of the best epoch
Epoch 00043: early stopping
{'val_loss': [0.056379896402359006, 0.056913791224360466, 0.05542847365140915, 0.05715281702578068, 0.057563158124685286, 0.059542295336723325, 0.058067485317587854, 0.058250556513667104, 0.058803070709109305, 0.056933750957250596, 0.055595054477453235, 0.05928451679646969, 0.061125198379158974, 0.06043062694370747, 0.05872226618230343, 0.05725379399955273, 0.05870064944028854, 0.05801413208246231, 0.061044170334935186, 0.05832956805825233, 0.05760882496833801, 0.059563760086894034, 0.059366425126791, 0.06100776456296444, 0.06085887104272843, 0.058023056387901305, 0.05856351740658283, 0.060566657781600954, 0.05795444957911968, 0.05830267108976841, 0.05963027887046337, 0.06641932353377342, 0.059503945708274844, 0.06194042675197124, 0.058136085793375966, 0.060195745155215266, 0.05881824232637882, 0.0570450846105814, 0.058883486315608025, 0.05959844030439854, 0.061596359685063364, 0.059632394835352896, 0.0607285525649786], 'val_acc': [0.9949790358543396, 0.9950414299964905, 0.9950626134872437, 0.994949322938919, 0.9948652565479279, 0.9946661829948426, 0.9948789000511169, 0.9950882017612457, 0.9948779165744781, 0.9949663698673248, 0.9949819684028626, 0.9948947370052338, 0.9950126707553864, 0.9948040843009949, 0.9949554085731507, 0.9949466407299041, 0.9947205126285553, 0.9948888897895813, 0.9948467314243317, 0.9948886454105377, 0.9950034081935882, 0.9949807584285736, 0.9949110627174378, 0.99474196434021, 0.9949364066123962, 0.9948723196983338, 0.9948289453983307, 0.9946637332439423, 0.9949410319328308, 0.9949736952781677, 0.994958084821701, 0.994685423374176, 0.9948050618171692, 0.9945852816104889, 0.9948986351490021, 0.9947063863277436, 0.9948603749275208, 0.9950626194477081, 0.9947470724582672, 0.9947987377643586, 0.9948365092277527, 0.9949159324169159, 0.9949912309646607], 'val_mDice': [0.8959964275360107, 0.8954399883747101, 0.8980996608734131, 0.8952933549880981, 0.894636482000351, 0.8912517547607421, 0.893760746717453, 0.8934523344039917, 0.8926285684108735, 0.895700889825821, 0.8980533838272095, 0.8918038189411164, 0.8885293483734131, 0.8900962769985199, 0.8927918314933777, 0.8951597154140473, 0.8930009245872498, 0.8941844224929809, 0.8888749539852142, 0.8935505628585816, 0.894743698835373, 0.8915341556072235, 0.8919429242610931, 0.8889956593513488, 0.8889208436012268, 0.8942554533481598, 0.8930574417114258, 0.8898209750652313, 0.8942907691001892, 0.8936433494091034, 0.8913790166378022, 0.8796910285949707, 0.8916112184524536, 0.8875724077224731, 0.893823790550232, 0.8902786374092102, 0.8927856087684631, 0.8958398878574372, 0.8924249529838562, 0.8915616273880005, 0.8880470991134644, 0.8913972795009613, 0.8894603073596954], 'loss': [0.12128660074990334, 0.04528057885886316, 0.038907765995949486, 0.03559025957904628, 0.03342349118303758, 0.03168487890555991, 0.030389690122798026, 0.029416121961078054, 0.028590465134155005, 0.027774126487719365, 0.027001771927010327, 0.02662141681843295, 0.026130484185606272, 0.02564831629139119, 0.025210770964409525, 0.024919568153075132, 0.02453445593910031, 0.02413626519172684, 0.023912055007190947, 0.023715839390921967, 0.02351546222047543, 0.023148545213878276, 0.023063618216843162, 0.02286502411712484, 0.022467496752947666, 0.022438755515549805, 0.022196922785425045, 0.022142146661088036, 0.02195505062362093, 0.021898167163379074, 0.0216945177579394, 0.02154332989828196, 0.021310551147002175, 0.02135472458767596, 0.02119931117763438, 0.021201331007086408, 0.021014016947027876, 0.02090806413148926, 0.020866578390463953, 0.02079312819089723, 0.020804944378657455, 0.02073681322809752, 0.020538190727616257], 'acc': [0.9792045440884075, 0.9948308946691312, 0.9954055973318701, 0.9956971502987293, 0.9958912795109734, 0.9960500271701053, 0.9961696042825237, 0.9962574427298302, 0.9963351779715502, 0.9964304472824493, 0.9964883533045296, 0.9965238617488535, 0.9965658976077846, 0.9966181379024437, 0.9966503253945559, 0.9966859571180761, 0.9967233022765365, 0.9967566351949856, 0.9967844567230056, 0.9968115765999789, 0.996809469742863, 0.9968739792107727, 0.9968712587135417, 0.9968849972977142, 0.9969305015689636, 0.99692325795941, 0.9969612041819529, 0.9969835257966381, 0.9969791810126721, 0.9969741374165842, 0.997019013439927, 0.9970209945878292, 0.9970474717794825, 0.9970443550275403, 0.997054892254271, 0.9970681044702451, 0.9970832786133432, 0.9970848693568918, 0.9970995695528699, 0.9971002490931004, 0.9970991335106155, 0.9971158720759771, 0.9971124248246175], 'mDice': [0.8428943949174633, 0.9165969294750682, 0.9276550361107208, 0.9335473389573925, 0.9374271211216261, 0.940556229110716, 0.9428950644478212, 0.9446618934363786, 0.9461628451102688, 0.9476445930629492, 0.9490621610269987, 0.9497586097919013, 0.9506632560113961, 0.9515481055790228, 0.9523531654795407, 0.9528904681710579, 0.9536037974880325, 0.9543407494693757, 0.9547541184296208, 0.9551168397618979, 0.9554949512979874, 0.9561678052510795, 0.9563299895576646, 0.9567013252977092, 0.9574399423095776, 0.957493497737799, 0.9579474961689083, 0.9580443985495327, 0.9584006765956438, 0.958508871678614, 0.9588803464152335, 0.9591694724015852, 0.9596021911609542, 0.9595193518730002, 0.9598116338003844, 0.959806986339743, 0.9601572878547228, 0.9603584811001442, 0.9604358104607912, 0.960574974527985, 0.9605530203080924, 0.9606793480559714, 0.9610547300328455]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34708927e-02 3.28960824e-02 7.69229643e-02 9.55806511e-03
 2.76632169e-02 7.23730094e-03 8.42715092e-02 1.14333322e-01
 8.97742253e-02 1.36398288e-02 2.91065696e-01 1.88903300e-01
 2.63596016e-04]
Train on 16787 samples, validate on 307 samples
Epoch 1/300
 - 18s - loss: 1.1372 - acc: 0.8172 - mDice: 0.4198 - val_loss: 1.5060 - val_acc: 0.9339 - val_mDice: 0.5033

Epoch 00001: val_mDice improved from -inf to 0.50331, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.4425 - acc: 0.9199 - mDice: 0.6377 - val_loss: 1.0665 - val_acc: 0.9465 - val_mDice: 0.5787

Epoch 00002: val_mDice improved from 0.50331 to 0.57866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.3932 - acc: 0.9359 - mDice: 0.6736 - val_loss: 0.9457 - val_acc: 0.9484 - val_mDice: 0.5788

Epoch 00003: val_mDice improved from 0.57866 to 0.57878, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.3753 - acc: 0.9411 - mDice: 0.6822 - val_loss: 1.1436 - val_acc: 0.9463 - val_mDice: 0.5532

Epoch 00004: val_mDice did not improve from 0.57878
Epoch 5/300
 - 13s - loss: 0.3180 - acc: 0.9460 - mDice: 0.7190 - val_loss: 0.9795 - val_acc: 0.9496 - val_mDice: 0.5996

Epoch 00005: val_mDice improved from 0.57878 to 0.59957, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.3085 - acc: 0.9473 - mDice: 0.7290 - val_loss: 1.0145 - val_acc: 0.9469 - val_mDice: 0.5943

Epoch 00006: val_mDice did not improve from 0.59957
Epoch 7/300
 - 13s - loss: 0.3133 - acc: 0.9468 - mDice: 0.7273 - val_loss: 1.1464 - val_acc: 0.9446 - val_mDice: 0.5127

Epoch 00007: val_mDice did not improve from 0.59957
Epoch 8/300
 - 14s - loss: 0.2855 - acc: 0.9491 - mDice: 0.7407 - val_loss: 1.1009 - val_acc: 0.9432 - val_mDice: 0.5599

Epoch 00008: val_mDice did not improve from 0.59957
Epoch 9/300
 - 13s - loss: 0.2898 - acc: 0.9489 - mDice: 0.7440 - val_loss: 1.1788 - val_acc: 0.9506 - val_mDice: 0.5816

Epoch 00009: val_mDice did not improve from 0.59957
Epoch 10/300
 - 13s - loss: 0.2738 - acc: 0.9509 - mDice: 0.7590 - val_loss: 0.9678 - val_acc: 0.9474 - val_mDice: 0.5758

Epoch 00010: val_mDice did not improve from 0.59957
Epoch 11/300
 - 13s - loss: 0.2556 - acc: 0.9519 - mDice: 0.7657 - val_loss: 3.0020 - val_acc: 0.9203 - val_mDice: 0.3104

Epoch 00011: val_mDice did not improve from 0.59957
Epoch 12/300
 - 13s - loss: 0.2862 - acc: 0.9498 - mDice: 0.7464 - val_loss: 0.9676 - val_acc: 0.9495 - val_mDice: 0.5998

Epoch 00012: val_mDice improved from 0.59957 to 0.59981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 14s - loss: 0.2558 - acc: 0.9526 - mDice: 0.7693 - val_loss: 1.0856 - val_acc: 0.9490 - val_mDice: 0.5755

Epoch 00013: val_mDice did not improve from 0.59981
Epoch 14/300
 - 13s - loss: 0.2321 - acc: 0.9539 - mDice: 0.7820 - val_loss: 0.9892 - val_acc: 0.9491 - val_mDice: 0.6042

Epoch 00014: val_mDice improved from 0.59981 to 0.60424, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 13s - loss: 0.2189 - acc: 0.9550 - mDice: 0.7924 - val_loss: 0.9387 - val_acc: 0.9501 - val_mDice: 0.6088

Epoch 00015: val_mDice improved from 0.60424 to 0.60875, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 13s - loss: 0.2128 - acc: 0.9557 - mDice: 0.7976 - val_loss: 1.0245 - val_acc: 0.9495 - val_mDice: 0.5958

Epoch 00016: val_mDice did not improve from 0.60875
Epoch 17/300
 - 13s - loss: 0.2156 - acc: 0.9559 - mDice: 0.7987 - val_loss: 0.9149 - val_acc: 0.9500 - val_mDice: 0.6064

Epoch 00017: val_mDice did not improve from 0.60875
Epoch 18/300
 - 14s - loss: 0.2203 - acc: 0.9554 - mDice: 0.7947 - val_loss: 1.0925 - val_acc: 0.9458 - val_mDice: 0.5794

Epoch 00018: val_mDice did not improve from 0.60875
Epoch 19/300
 - 13s - loss: 0.2167 - acc: 0.9555 - mDice: 0.7968 - val_loss: 1.0390 - val_acc: 0.9513 - val_mDice: 0.5985

Epoch 00019: val_mDice did not improve from 0.60875
Epoch 20/300
 - 13s - loss: 0.2389 - acc: 0.9543 - mDice: 0.7831 - val_loss: 0.8840 - val_acc: 0.9515 - val_mDice: 0.6026

Epoch 00020: val_mDice did not improve from 0.60875
Epoch 21/300
 - 13s - loss: 0.2385 - acc: 0.9527 - mDice: 0.7794 - val_loss: 0.9375 - val_acc: 0.9486 - val_mDice: 0.5877

Epoch 00021: val_mDice did not improve from 0.60875
Epoch 22/300
 - 14s - loss: 0.2149 - acc: 0.9559 - mDice: 0.7995 - val_loss: 0.7526 - val_acc: 0.9508 - val_mDice: 0.6028

Epoch 00022: val_mDice did not improve from 0.60875
Epoch 23/300
 - 14s - loss: 0.2216 - acc: 0.9555 - mDice: 0.7942 - val_loss: 0.9739 - val_acc: 0.9478 - val_mDice: 0.6022

Epoch 00023: val_mDice did not improve from 0.60875
Epoch 24/300
 - 14s - loss: 0.2012 - acc: 0.9569 - mDice: 0.8073 - val_loss: 0.9129 - val_acc: 0.9507 - val_mDice: 0.5992

Epoch 00024: val_mDice did not improve from 0.60875
Epoch 25/300
 - 14s - loss: 0.2066 - acc: 0.9572 - mDice: 0.8090 - val_loss: 2.0918 - val_acc: 0.9433 - val_mDice: 0.4767

Epoch 00025: val_mDice did not improve from 0.60875
Epoch 26/300
 - 14s - loss: 0.2300 - acc: 0.9554 - mDice: 0.7937 - val_loss: 0.9182 - val_acc: 0.9466 - val_mDice: 0.5901

Epoch 00026: val_mDice did not improve from 0.60875
Epoch 27/300
 - 13s - loss: 0.2061 - acc: 0.9567 - mDice: 0.8041 - val_loss: 0.8882 - val_acc: 0.9480 - val_mDice: 0.6078

Epoch 00027: val_mDice did not improve from 0.60875
Epoch 28/300
 - 13s - loss: 0.2007 - acc: 0.9576 - mDice: 0.8124 - val_loss: 1.0520 - val_acc: 0.9482 - val_mDice: 0.5566

Epoch 00028: val_mDice did not improve from 0.60875
Epoch 29/300
 - 14s - loss: 0.1962 - acc: 0.9574 - mDice: 0.8118 - val_loss: 0.8581 - val_acc: 0.9507 - val_mDice: 0.5921

Epoch 00029: val_mDice did not improve from 0.60875
Epoch 30/300
 - 14s - loss: 0.2074 - acc: 0.9560 - mDice: 0.8046 - val_loss: 0.8388 - val_acc: 0.9504 - val_mDice: 0.6073

Epoch 00030: val_mDice did not improve from 0.60875
Epoch 31/300
 - 13s - loss: 0.2001 - acc: 0.9574 - mDice: 0.8118 - val_loss: 0.9016 - val_acc: 0.9482 - val_mDice: 0.5962

Epoch 00031: val_mDice did not improve from 0.60875
Epoch 32/300
 - 13s - loss: 0.2036 - acc: 0.9572 - mDice: 0.8105 - val_loss: 0.8174 - val_acc: 0.9518 - val_mDice: 0.5988

Epoch 00032: val_mDice did not improve from 0.60875
Epoch 33/300
 - 13s - loss: 0.2098 - acc: 0.9567 - mDice: 0.8054 - val_loss: 1.1082 - val_acc: 0.9491 - val_mDice: 0.5474

Epoch 00033: val_mDice did not improve from 0.60875
Epoch 34/300
 - 13s - loss: 0.2347 - acc: 0.9550 - mDice: 0.7922 - val_loss: 0.8872 - val_acc: 0.9482 - val_mDice: 0.5944

Epoch 00034: val_mDice did not improve from 0.60875
Epoch 35/300
 - 13s - loss: 0.1973 - acc: 0.9573 - mDice: 0.8109 - val_loss: 0.8098 - val_acc: 0.9516 - val_mDice: 0.6042

Epoch 00035: val_mDice did not improve from 0.60875
Epoch 36/300
 - 14s - loss: 0.1958 - acc: 0.9579 - mDice: 0.8176 - val_loss: 0.8069 - val_acc: 0.9503 - val_mDice: 0.6089

Epoch 00036: val_mDice improved from 0.60875 to 0.60885, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 14s - loss: 0.2612 - acc: 0.9524 - mDice: 0.7736 - val_loss: 0.8132 - val_acc: 0.9504 - val_mDice: 0.6017

Epoch 00037: val_mDice did not improve from 0.60885
Epoch 38/300
 - 13s - loss: 0.2096 - acc: 0.9568 - mDice: 0.8063 - val_loss: 0.8124 - val_acc: 0.9509 - val_mDice: 0.6100

Epoch 00038: val_mDice improved from 0.60885 to 0.61001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 13s - loss: 0.1930 - acc: 0.9577 - mDice: 0.8151 - val_loss: 1.1266 - val_acc: 0.9495 - val_mDice: 0.5448

Epoch 00039: val_mDice did not improve from 0.61001
Epoch 40/300
 - 13s - loss: 0.2184 - acc: 0.9555 - mDice: 0.7963 - val_loss: 1.0720 - val_acc: 0.9494 - val_mDice: 0.5438

Epoch 00040: val_mDice did not improve from 0.61001
Epoch 41/300
 - 14s - loss: 0.1973 - acc: 0.9574 - mDice: 0.8110 - val_loss: 0.7967 - val_acc: 0.9504 - val_mDice: 0.6078

Epoch 00041: val_mDice did not improve from 0.61001
Epoch 42/300
 - 14s - loss: 0.1851 - acc: 0.9585 - mDice: 0.8212 - val_loss: 0.7798 - val_acc: 0.9505 - val_mDice: 0.6142

Epoch 00042: val_mDice improved from 0.61001 to 0.61416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 14s - loss: 0.1810 - acc: 0.9590 - mDice: 0.8249 - val_loss: 0.7972 - val_acc: 0.9508 - val_mDice: 0.6055

Epoch 00043: val_mDice did not improve from 0.61416
Epoch 44/300
 - 13s - loss: 0.2092 - acc: 0.9561 - mDice: 0.8040 - val_loss: 1.0072 - val_acc: 0.9518 - val_mDice: 0.5687

Epoch 00044: val_mDice did not improve from 0.61416
Epoch 45/300
 - 13s - loss: 0.2103 - acc: 0.9563 - mDice: 0.8044 - val_loss: 1.4938 - val_acc: 0.9473 - val_mDice: 0.5634

Epoch 00045: val_mDice did not improve from 0.61416
Epoch 46/300
 - 13s - loss: 0.1907 - acc: 0.9577 - mDice: 0.8163 - val_loss: 0.7969 - val_acc: 0.9514 - val_mDice: 0.6094

Epoch 00046: val_mDice did not improve from 0.61416
Epoch 47/300
 - 13s - loss: 0.1792 - acc: 0.9589 - mDice: 0.8261 - val_loss: 0.8178 - val_acc: 0.9505 - val_mDice: 0.6023

Epoch 00047: val_mDice did not improve from 0.61416
Epoch 48/300
 - 14s - loss: 0.1763 - acc: 0.9593 - mDice: 0.8291 - val_loss: 0.8309 - val_acc: 0.9525 - val_mDice: 0.6082

Epoch 00048: val_mDice did not improve from 0.61416
Epoch 49/300
 - 13s - loss: 0.1757 - acc: 0.9597 - mDice: 0.8312 - val_loss: 0.7272 - val_acc: 0.9511 - val_mDice: 0.6122

Epoch 00049: val_mDice did not improve from 0.61416
Epoch 50/300
 - 13s - loss: 0.1851 - acc: 0.9592 - mDice: 0.8272 - val_loss: 0.7540 - val_acc: 0.9492 - val_mDice: 0.6124

Epoch 00050: val_mDice did not improve from 0.61416
Epoch 51/300
 - 13s - loss: 0.1723 - acc: 0.9600 - mDice: 0.8339 - val_loss: 0.7558 - val_acc: 0.9506 - val_mDice: 0.6144

Epoch 00051: val_mDice improved from 0.61416 to 0.61442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 52/300
 - 13s - loss: 0.1749 - acc: 0.9597 - mDice: 0.8313 - val_loss: 0.7710 - val_acc: 0.9527 - val_mDice: 0.5982

Epoch 00052: val_mDice did not improve from 0.61442
Epoch 53/300
 - 13s - loss: 0.1805 - acc: 0.9594 - mDice: 0.8278 - val_loss: 0.7417 - val_acc: 0.9513 - val_mDice: 0.6153

Epoch 00053: val_mDice improved from 0.61442 to 0.61534, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 13s - loss: 0.1766 - acc: 0.9599 - mDice: 0.8318 - val_loss: 0.6747 - val_acc: 0.9507 - val_mDice: 0.6034

Epoch 00054: val_mDice did not improve from 0.61534
Epoch 55/300
 - 13s - loss: 0.1848 - acc: 0.9598 - mDice: 0.8301 - val_loss: 0.7019 - val_acc: 0.9514 - val_mDice: 0.6178

Epoch 00055: val_mDice improved from 0.61534 to 0.61779, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 56/300
 - 13s - loss: 0.1915 - acc: 0.9587 - mDice: 0.8201 - val_loss: 0.7222 - val_acc: 0.9501 - val_mDice: 0.6071

Epoch 00056: val_mDice did not improve from 0.61779
Epoch 57/300
 - 13s - loss: 0.2247 - acc: 0.9555 - mDice: 0.8003 - val_loss: 0.7395 - val_acc: 0.9509 - val_mDice: 0.6107

Epoch 00057: val_mDice did not improve from 0.61779
Epoch 58/300
 - 13s - loss: 0.1928 - acc: 0.9582 - mDice: 0.8196 - val_loss: 0.6827 - val_acc: 0.9516 - val_mDice: 0.6122

Epoch 00058: val_mDice did not improve from 0.61779
Epoch 59/300
 - 13s - loss: 0.1921 - acc: 0.9591 - mDice: 0.8237 - val_loss: 0.7231 - val_acc: 0.9520 - val_mDice: 0.6022

Epoch 00059: val_mDice did not improve from 0.61779
Epoch 60/300
 - 13s - loss: 0.1782 - acc: 0.9598 - mDice: 0.8309 - val_loss: 0.5832 - val_acc: 0.9521 - val_mDice: 0.6112

Epoch 00060: val_mDice did not improve from 0.61779
Epoch 61/300
 - 14s - loss: 0.1898 - acc: 0.9593 - mDice: 0.8272 - val_loss: 0.6788 - val_acc: 0.9509 - val_mDice: 0.6114

Epoch 00061: val_mDice did not improve from 0.61779
Epoch 62/300
 - 13s - loss: 0.1891 - acc: 0.9587 - mDice: 0.8212 - val_loss: 0.7567 - val_acc: 0.9501 - val_mDice: 0.6135

Epoch 00062: val_mDice did not improve from 0.61779
Epoch 63/300
 - 14s - loss: 0.1711 - acc: 0.9604 - mDice: 0.8365 - val_loss: 0.7362 - val_acc: 0.9523 - val_mDice: 0.6078

Epoch 00063: val_mDice did not improve from 0.61779
Epoch 64/300
 - 13s - loss: 0.1738 - acc: 0.9602 - mDice: 0.8357 - val_loss: 1.5391 - val_acc: 0.9445 - val_mDice: 0.5137

Epoch 00064: val_mDice did not improve from 0.61779
Epoch 65/300
 - 13s - loss: 0.1773 - acc: 0.9597 - mDice: 0.8283 - val_loss: 0.7737 - val_acc: 0.9515 - val_mDice: 0.6069

Epoch 00065: val_mDice did not improve from 0.61779
Epoch 66/300
 - 13s - loss: 0.1684 - acc: 0.9606 - mDice: 0.8375 - val_loss: 0.7445 - val_acc: 0.9496 - val_mDice: 0.6075

Epoch 00066: val_mDice did not improve from 0.61779
Epoch 67/300
 - 14s - loss: 0.1660 - acc: 0.9610 - mDice: 0.8409 - val_loss: 0.7868 - val_acc: 0.9509 - val_mDice: 0.6105

Epoch 00067: val_mDice did not improve from 0.61779
Epoch 68/300
 - 14s - loss: 0.1603 - acc: 0.9611 - mDice: 0.8428 - val_loss: 0.7588 - val_acc: 0.9535 - val_mDice: 0.6042

Epoch 00068: val_mDice did not improve from 0.61779
Epoch 69/300
 - 14s - loss: 0.1634 - acc: 0.9610 - mDice: 0.8418 - val_loss: 0.7063 - val_acc: 0.9521 - val_mDice: 0.6182

Epoch 00069: val_mDice improved from 0.61779 to 0.61822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 13s - loss: 0.1594 - acc: 0.9611 - mDice: 0.8436 - val_loss: 0.7525 - val_acc: 0.9523 - val_mDice: 0.6142

Epoch 00070: val_mDice did not improve from 0.61822
Epoch 71/300
 - 14s - loss: 0.1588 - acc: 0.9613 - mDice: 0.8442 - val_loss: 0.7337 - val_acc: 0.9511 - val_mDice: 0.6146

Epoch 00071: val_mDice did not improve from 0.61822
Epoch 72/300
 - 14s - loss: 0.1675 - acc: 0.9608 - mDice: 0.8409 - val_loss: 0.8893 - val_acc: 0.9486 - val_mDice: 0.5455

Epoch 00072: val_mDice did not improve from 0.61822
Epoch 73/300
 - 14s - loss: 0.1835 - acc: 0.9595 - mDice: 0.8291 - val_loss: 0.6859 - val_acc: 0.9519 - val_mDice: 0.6119

Epoch 00073: val_mDice did not improve from 0.61822
Epoch 74/300
 - 14s - loss: 0.1698 - acc: 0.9606 - mDice: 0.8379 - val_loss: 0.6693 - val_acc: 0.9513 - val_mDice: 0.6061

Epoch 00074: val_mDice did not improve from 0.61822
Epoch 75/300
 - 13s - loss: 0.1702 - acc: 0.9610 - mDice: 0.8409 - val_loss: 0.6854 - val_acc: 0.9523 - val_mDice: 0.6148

Epoch 00075: val_mDice did not improve from 0.61822
Epoch 76/300
 - 14s - loss: 0.1558 - acc: 0.9615 - mDice: 0.8468 - val_loss: 0.6739 - val_acc: 0.9530 - val_mDice: 0.6075

Epoch 00076: val_mDice did not improve from 0.61822
Epoch 77/300
 - 14s - loss: 0.1626 - acc: 0.9614 - mDice: 0.8455 - val_loss: 0.6696 - val_acc: 0.9511 - val_mDice: 0.6082

Epoch 00077: val_mDice did not improve from 0.61822
Epoch 78/300
 - 14s - loss: 0.1814 - acc: 0.9594 - mDice: 0.8299 - val_loss: 0.7012 - val_acc: 0.9499 - val_mDice: 0.6002

Epoch 00078: val_mDice did not improve from 0.61822
Epoch 79/300
 - 14s - loss: 0.1749 - acc: 0.9605 - mDice: 0.8367 - val_loss: 0.7039 - val_acc: 0.9496 - val_mDice: 0.6139

Epoch 00079: val_mDice did not improve from 0.61822
Epoch 80/300
 - 14s - loss: 0.1624 - acc: 0.9611 - mDice: 0.8411 - val_loss: 0.7092 - val_acc: 0.9524 - val_mDice: 0.6097

Epoch 00080: val_mDice did not improve from 0.61822
Epoch 81/300
 - 14s - loss: 0.1924 - acc: 0.9591 - mDice: 0.8260 - val_loss: 0.7347 - val_acc: 0.9512 - val_mDice: 0.6022

Epoch 00081: val_mDice did not improve from 0.61822
Epoch 82/300
 - 13s - loss: 0.1733 - acc: 0.9602 - mDice: 0.8365 - val_loss: 0.7003 - val_acc: 0.9528 - val_mDice: 0.6017

Epoch 00082: val_mDice did not improve from 0.61822
Epoch 83/300
 - 14s - loss: 0.1611 - acc: 0.9610 - mDice: 0.8426 - val_loss: 0.6799 - val_acc: 0.9524 - val_mDice: 0.6093

Epoch 00083: val_mDice did not improve from 0.61822
Epoch 84/300
 - 14s - loss: 0.1576 - acc: 0.9614 - mDice: 0.8454 - val_loss: 0.6758 - val_acc: 0.9527 - val_mDice: 0.6110

Epoch 00084: val_mDice did not improve from 0.61822
Epoch 85/300
 - 14s - loss: 0.1762 - acc: 0.9604 - mDice: 0.8345 - val_loss: 0.6980 - val_acc: 0.9517 - val_mDice: 0.6043

Epoch 00085: val_mDice did not improve from 0.61822
Epoch 86/300
 - 13s - loss: 0.1658 - acc: 0.9606 - mDice: 0.8387 - val_loss: 0.7455 - val_acc: 0.9518 - val_mDice: 0.6135

Epoch 00086: val_mDice did not improve from 0.61822
Epoch 87/300
 - 14s - loss: 0.1886 - acc: 0.9581 - mDice: 0.8234 - val_loss: 0.7688 - val_acc: 0.9522 - val_mDice: 0.5859

Epoch 00087: val_mDice did not improve from 0.61822
Epoch 88/300
 - 14s - loss: 0.1771 - acc: 0.9599 - mDice: 0.8312 - val_loss: 0.7550 - val_acc: 0.9497 - val_mDice: 0.6009

Epoch 00088: val_mDice did not improve from 0.61822
Epoch 89/300
 - 14s - loss: 0.1630 - acc: 0.9609 - mDice: 0.8407 - val_loss: 0.7154 - val_acc: 0.9516 - val_mDice: 0.6040

Epoch 00089: val_mDice did not improve from 0.61822
Epoch 90/300
 - 14s - loss: 0.1713 - acc: 0.9613 - mDice: 0.8438 - val_loss: 0.6732 - val_acc: 0.9513 - val_mDice: 0.6056

Epoch 00090: val_mDice did not improve from 0.61822
Epoch 91/300
 - 13s - loss: 0.1609 - acc: 0.9616 - mDice: 0.8473 - val_loss: 0.6349 - val_acc: 0.9522 - val_mDice: 0.6110

Epoch 00091: val_mDice did not improve from 0.61822
Epoch 92/300
 - 13s - loss: 0.1564 - acc: 0.9619 - mDice: 0.8497 - val_loss: 0.6619 - val_acc: 0.9516 - val_mDice: 0.6090

Epoch 00092: val_mDice did not improve from 0.61822
Epoch 93/300
 - 13s - loss: 0.1523 - acc: 0.9620 - mDice: 0.8501 - val_loss: 0.7023 - val_acc: 0.9533 - val_mDice: 0.5903

Epoch 00093: val_mDice did not improve from 0.61822
Epoch 94/300
 - 13s - loss: 0.1648 - acc: 0.9615 - mDice: 0.8438 - val_loss: 0.6676 - val_acc: 0.9527 - val_mDice: 0.6103

Epoch 00094: val_mDice did not improve from 0.61822
Epoch 95/300
 - 13s - loss: 0.1529 - acc: 0.9620 - mDice: 0.8497 - val_loss: 0.6998 - val_acc: 0.9517 - val_mDice: 0.6080

Epoch 00095: val_mDice did not improve from 0.61822
Epoch 96/300
 - 14s - loss: 0.1572 - acc: 0.9620 - mDice: 0.8506 - val_loss: 0.7482 - val_acc: 0.9501 - val_mDice: 0.6013

Epoch 00096: val_mDice did not improve from 0.61822
Epoch 97/300
 - 14s - loss: 0.1530 - acc: 0.9619 - mDice: 0.8496 - val_loss: 0.6798 - val_acc: 0.9511 - val_mDice: 0.6189

Epoch 00097: val_mDice improved from 0.61822 to 0.61888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 98/300
 - 14s - loss: 0.1720 - acc: 0.9605 - mDice: 0.8357 - val_loss: 0.7431 - val_acc: 0.9517 - val_mDice: 0.6106

Epoch 00098: val_mDice did not improve from 0.61888
Epoch 99/300
 - 13s - loss: 0.1710 - acc: 0.9605 - mDice: 0.8374 - val_loss: 0.7604 - val_acc: 0.9511 - val_mDice: 0.6117

Epoch 00099: val_mDice did not improve from 0.61888
Epoch 100/300
 - 13s - loss: 0.1581 - acc: 0.9616 - mDice: 0.8466 - val_loss: 0.8943 - val_acc: 0.9520 - val_mDice: 0.6020

Epoch 00100: val_mDice did not improve from 0.61888
Epoch 101/300
 - 14s - loss: 0.1543 - acc: 0.9620 - mDice: 0.8512 - val_loss: 0.7056 - val_acc: 0.9530 - val_mDice: 0.6107

Epoch 00101: val_mDice did not improve from 0.61888
Epoch 102/300
 - 14s - loss: 0.1633 - acc: 0.9607 - mDice: 0.8416 - val_loss: 0.9885 - val_acc: 0.9508 - val_mDice: 0.5554

Epoch 00102: val_mDice did not improve from 0.61888
Epoch 103/300
 - 14s - loss: 0.1656 - acc: 0.9608 - mDice: 0.8395 - val_loss: 0.8413 - val_acc: 0.9505 - val_mDice: 0.6066

Epoch 00103: val_mDice did not improve from 0.61888
Epoch 104/300
 - 14s - loss: 0.1592 - acc: 0.9614 - mDice: 0.8441 - val_loss: 0.6774 - val_acc: 0.9519 - val_mDice: 0.6064

Epoch 00104: val_mDice did not improve from 0.61888
Epoch 105/300
 - 14s - loss: 0.1789 - acc: 0.9606 - mDice: 0.8362 - val_loss: 0.6722 - val_acc: 0.9522 - val_mDice: 0.6083

Epoch 00105: val_mDice did not improve from 0.61888
Epoch 106/300
 - 14s - loss: 0.1630 - acc: 0.9612 - mDice: 0.8436 - val_loss: 0.8375 - val_acc: 0.9498 - val_mDice: 0.5889

Epoch 00106: val_mDice did not improve from 0.61888
Epoch 107/300
 - 14s - loss: 0.1955 - acc: 0.9583 - mDice: 0.8230 - val_loss: 0.7708 - val_acc: 0.9504 - val_mDice: 0.6046

Epoch 00107: val_mDice did not improve from 0.61888
Epoch 108/300
 - 14s - loss: 0.1662 - acc: 0.9607 - mDice: 0.8406 - val_loss: 0.8173 - val_acc: 0.9524 - val_mDice: 0.6058

Epoch 00108: val_mDice did not improve from 0.61888
Epoch 109/300
 - 14s - loss: 0.1562 - acc: 0.9614 - mDice: 0.8468 - val_loss: 0.8232 - val_acc: 0.9516 - val_mDice: 0.5844

Epoch 00109: val_mDice did not improve from 0.61888
Epoch 110/300
 - 14s - loss: 0.1551 - acc: 0.9616 - mDice: 0.8475 - val_loss: 0.7341 - val_acc: 0.9524 - val_mDice: 0.6069

Epoch 00110: val_mDice did not improve from 0.61888
Epoch 111/300
 - 14s - loss: 0.1626 - acc: 0.9611 - mDice: 0.8428 - val_loss: 0.9055 - val_acc: 0.9481 - val_mDice: 0.5802

Epoch 00111: val_mDice did not improve from 0.61888
Epoch 112/300
 - 14s - loss: 0.1584 - acc: 0.9614 - mDice: 0.8447 - val_loss: 0.7158 - val_acc: 0.9513 - val_mDice: 0.6066

Epoch 00112: val_mDice did not improve from 0.61888
Epoch 113/300
 - 13s - loss: 0.1513 - acc: 0.9620 - mDice: 0.8508 - val_loss: 0.6897 - val_acc: 0.9516 - val_mDice: 0.6106

Epoch 00113: val_mDice did not improve from 0.61888
Epoch 114/300
 - 13s - loss: 0.1502 - acc: 0.9622 - mDice: 0.8528 - val_loss: 0.6990 - val_acc: 0.9529 - val_mDice: 0.6019

Epoch 00114: val_mDice did not improve from 0.61888
Epoch 115/300
 - 13s - loss: 0.1528 - acc: 0.9623 - mDice: 0.8525 - val_loss: 0.7179 - val_acc: 0.9516 - val_mDice: 0.5975

Epoch 00115: val_mDice did not improve from 0.61888
Epoch 116/300
 - 13s - loss: 0.1469 - acc: 0.9625 - mDice: 0.8549 - val_loss: 0.7046 - val_acc: 0.9520 - val_mDice: 0.6095

Epoch 00116: val_mDice did not improve from 0.61888
Epoch 117/300
 - 14s - loss: 0.1530 - acc: 0.9621 - mDice: 0.8508 - val_loss: 0.6718 - val_acc: 0.9527 - val_mDice: 0.6085

Epoch 00117: val_mDice did not improve from 0.61888
Epoch 118/300
 - 14s - loss: 0.1620 - acc: 0.9613 - mDice: 0.8451 - val_loss: 0.9147 - val_acc: 0.9502 - val_mDice: 0.5690

Epoch 00118: val_mDice did not improve from 0.61888
Epoch 119/300
 - 14s - loss: 0.1612 - acc: 0.9616 - mDice: 0.8474 - val_loss: 0.6996 - val_acc: 0.9502 - val_mDice: 0.5963

Epoch 00119: val_mDice did not improve from 0.61888
Epoch 120/300
 - 13s - loss: 0.1716 - acc: 0.9609 - mDice: 0.8414 - val_loss: 1.0401 - val_acc: 0.9319 - val_mDice: 0.5115

Epoch 00120: val_mDice did not improve from 0.61888
Epoch 121/300
 - 13s - loss: 0.1823 - acc: 0.9601 - mDice: 0.8326 - val_loss: 0.7842 - val_acc: 0.9503 - val_mDice: 0.6049

Epoch 00121: val_mDice did not improve from 0.61888
Epoch 122/300
 - 13s - loss: 0.1697 - acc: 0.9614 - mDice: 0.8439 - val_loss: 0.6911 - val_acc: 0.9527 - val_mDice: 0.6016

Epoch 00122: val_mDice did not improve from 0.61888
Epoch 123/300
 - 13s - loss: 0.1774 - acc: 0.9600 - mDice: 0.8337 - val_loss: 0.7557 - val_acc: 0.9518 - val_mDice: 0.6054

Epoch 00123: val_mDice did not improve from 0.61888
Epoch 124/300
 - 13s - loss: 0.1564 - acc: 0.9616 - mDice: 0.8464 - val_loss: 0.7165 - val_acc: 0.9526 - val_mDice: 0.6108

Epoch 00124: val_mDice did not improve from 0.61888
Epoch 125/300
 - 13s - loss: 0.1518 - acc: 0.9621 - mDice: 0.8507 - val_loss: 0.6770 - val_acc: 0.9520 - val_mDice: 0.6136

Epoch 00125: val_mDice did not improve from 0.61888
Epoch 126/300
 - 14s - loss: 0.1524 - acc: 0.9623 - mDice: 0.8529 - val_loss: 0.6791 - val_acc: 0.9524 - val_mDice: 0.6064

Epoch 00126: val_mDice did not improve from 0.61888
Epoch 127/300
 - 13s - loss: 0.1471 - acc: 0.9626 - mDice: 0.8548 - val_loss: 0.6695 - val_acc: 0.9512 - val_mDice: 0.6086

Epoch 00127: val_mDice did not improve from 0.61888
Epoch 128/300
 - 13s - loss: 0.1540 - acc: 0.9622 - mDice: 0.8526 - val_loss: 0.9739 - val_acc: 0.9500 - val_mDice: 0.5629

Epoch 00128: val_mDice did not improve from 0.61888
Epoch 129/300
 - 13s - loss: 0.1653 - acc: 0.9613 - mDice: 0.8420 - val_loss: 0.7036 - val_acc: 0.9511 - val_mDice: 0.6033

Epoch 00129: val_mDice did not improve from 0.61888
Epoch 130/300
 - 13s - loss: 0.1591 - acc: 0.9617 - mDice: 0.8495 - val_loss: 0.7092 - val_acc: 0.9512 - val_mDice: 0.6114

Epoch 00130: val_mDice did not improve from 0.61888
Epoch 131/300
 - 13s - loss: 0.1660 - acc: 0.9615 - mDice: 0.8460 - val_loss: 1.5492 - val_acc: 0.9440 - val_mDice: 0.4914

Epoch 00131: val_mDice did not improve from 0.61888
Epoch 132/300
 - 13s - loss: 0.1845 - acc: 0.9599 - mDice: 0.8298 - val_loss: 0.7488 - val_acc: 0.9506 - val_mDice: 0.6016

Epoch 00132: val_mDice did not improve from 0.61888
Epoch 133/300
 - 14s - loss: 0.1641 - acc: 0.9615 - mDice: 0.8454 - val_loss: 0.7421 - val_acc: 0.9515 - val_mDice: 0.5996

Epoch 00133: val_mDice did not improve from 0.61888
Epoch 134/300
 - 13s - loss: 0.1692 - acc: 0.9616 - mDice: 0.8458 - val_loss: 0.7504 - val_acc: 0.9503 - val_mDice: 0.5988

Epoch 00134: val_mDice did not improve from 0.61888
Epoch 135/300
 - 13s - loss: 0.1855 - acc: 0.9590 - mDice: 0.8278 - val_loss: 0.7397 - val_acc: 0.9503 - val_mDice: 0.6070

Epoch 00135: val_mDice did not improve from 0.61888
Epoch 136/300
 - 13s - loss: 0.1765 - acc: 0.9599 - mDice: 0.8324 - val_loss: 0.7991 - val_acc: 0.9493 - val_mDice: 0.6085

Epoch 00136: val_mDice did not improve from 0.61888
Epoch 137/300
 - 13s - loss: 0.1565 - acc: 0.9615 - mDice: 0.8465 - val_loss: 0.6916 - val_acc: 0.9508 - val_mDice: 0.6075

Epoch 00137: val_mDice did not improve from 0.61888
Restoring model weights from the end of the best epoch
Epoch 00137: early stopping
{'val_loss': [1.5059752400224293, 1.0664545817949873, 0.9457496495899238, 1.143605022942981, 0.9794929182878923, 1.0145471829933141, 1.1464114612399172, 1.1008615237493857, 1.1788150173056786, 0.9678020281201465, 3.001954771408429, 0.9676060742586365, 1.085624485916734, 0.9892061851700277, 0.9386531467934773, 1.0245133521890795, 0.9148692339173358, 1.0925261325867246, 1.0390374229474642, 0.8839983198464111, 0.9375079136329676, 0.7525609803510411, 0.9739108677795734, 0.9129417235765861, 2.091755247659714, 0.9182006505102599, 0.8881631786737846, 1.0519743769487262, 0.8580830982531321, 0.8388101559508507, 0.9015716904537685, 0.8173501870142909, 1.1082016256810787, 0.8871899307356595, 0.8098241644107558, 0.8069143512738256, 0.8132002217761857, 0.8123867298182137, 1.1265661312625153, 1.072036980223578, 0.7967291936423957, 0.7798468938479595, 0.7971969262396473, 1.0072499934935804, 1.493795236663632, 0.7969062229321136, 0.817823319171073, 0.8309146715297762, 0.7271533876366258, 0.7540433255391323, 0.755771939839913, 0.771016885286822, 0.7417162450983004, 0.6746635893268772, 0.7018931750754192, 0.7221521065367161, 0.7395105800721855, 0.6826587290251294, 0.7231305462917986, 0.5832247207918074, 0.6788008277113352, 0.7566941953249009, 0.7362455378137893, 1.539083102821139, 0.773690179427206, 0.7444964099784628, 0.7867711038853524, 0.7587592733799441, 0.7062509289005292, 0.7524989354105648, 0.7336698487061243, 0.8893435418799956, 0.6858616706214432, 0.6693031318024626, 0.6854278781126687, 0.6739441818445435, 0.6695586881730766, 0.7011638357507289, 0.7039337618343217, 0.7091934521734132, 0.7346673411732776, 0.7002928501619966, 0.6799072269896342, 0.6757607537682747, 0.6979767443302788, 0.7455071742837515, 0.7687900794445498, 0.754996827836922, 0.7154181281207828, 0.6732043309398117, 0.634907907111637, 0.6618615891723757, 0.7022841829042094, 0.6676437757690877, 0.699849040578165, 0.7482436126528811, 0.6798179908761761, 0.7430873398672098, 0.7603905511601352, 0.894330729490771, 0.7055986682832823, 0.9884893620441325, 0.8413079841129166, 0.6774025580782067, 0.6722338640340376, 0.837539544128828, 0.7708011496727164, 0.8172899540938461, 0.8231857541329698, 0.7340616220760035, 0.9055200473493396, 0.7157684121924037, 0.6897429841349102, 0.6990201807177416, 0.7178975071891511, 0.7045947458922669, 0.6718414245288613, 0.914692564002854, 0.6996140000486218, 1.0400755005473035, 0.78417558875845, 0.6911079124441364, 0.7557086655293691, 0.7164639145232955, 0.6769652430708323, 0.6790519554762576, 0.6695415884353438, 0.973891230476019, 0.7035893858061552, 0.7092248677042485, 1.5491764353230255, 0.7488186703054447, 0.7420510599201587, 0.7504009816079652, 0.7396868824570497, 0.7991087890991558, 0.6916084621550594], 'val_acc': [0.9338615897812362, 0.9464668033565683, 0.9484021290894051, 0.9462592997846075, 0.9495988338700335, 0.9469052764802491, 0.9446058174297942, 0.9432473116666564, 0.9505945576130373, 0.9473737689881837, 0.9203389869450747, 0.9494983621839591, 0.9490207208484314, 0.9490846475094848, 0.9500699466525149, 0.9494918262531392, 0.9500373207785019, 0.9458495042611411, 0.9512614328232184, 0.9514689371717869, 0.9485613375610948, 0.9508307797512713, 0.9477744106361066, 0.9506689508108829, 0.9433360295885937, 0.946632531644467, 0.9479780001050098, 0.9481594065501557, 0.9506559065188182, 0.9504014317686472, 0.9481502680126153, 0.9518043142576559, 0.9490990122288757, 0.9482337855749099, 0.9515720345686624, 0.9503335622700495, 0.9503779358894895, 0.9509443147563003, 0.9494800953989309, 0.949447450303876, 0.9503518306082933, 0.9505306134783096, 0.9508438102585485, 0.9517586487512247, 0.9472967772608083, 0.9514010696147086, 0.9505058307601109, 0.9525038163126097, 0.9511139697671325, 0.9491681740027685, 0.9506167557806456, 0.9527073817066727, 0.9513384276570249, 0.9507407272289164, 0.9514284840624185, 0.9500816982809807, 0.9509312665811968, 0.9516437997258835, 0.9520457419976349, 0.9520653266860142, 0.9509182042330018, 0.9501169376342227, 0.9523276389615932, 0.9444805426395677, 0.9515015548914185, 0.949558371829676, 0.9509247434644047, 0.9534851831023002, 0.9521318703210315, 0.9523224151095661, 0.951090467092657, 0.9485926767902187, 0.9518969769586569, 0.9513462579988113, 0.9522910784044173, 0.9529644897395703, 0.9510656835978505, 0.9498794253563648, 0.9495897011570511, 0.9524098498813492, 0.9511596391566025, 0.9527674247465227, 0.9523654803391, 0.952721741960569, 0.9517025258331423, 0.9518382333777238, 0.9521501439013776, 0.9497149668221365, 0.9516163949857706, 0.9513423378770437, 0.9522075686082001, 0.9515994400853831, 0.9533364083557253, 0.9526904273887411, 0.9516790367493023, 0.9500869145610822, 0.9510695874108553, 0.9516725219810436, 0.9511491939765234, 0.9519687613369199, 0.9530075501153058, 0.9508098855080744, 0.9504523248159924, 0.9518995817010488, 0.952216712193691, 0.949828518912536, 0.9504444936975982, 0.9524372577278932, 0.951566814599674, 0.9524411627058097, 0.9480732648302755, 0.9512627361651741, 0.9516020457985347, 0.9529227280461439, 0.9515785555497831, 0.9519961522922453, 0.9527204436665637, 0.9502239285540504, 0.9501691322761561, 0.9318570853832878, 0.950345308462261, 0.9527491589322541, 0.9517717091579002, 0.952561238883761, 0.9520013920647313, 0.9524307305339105, 0.9512249025537447, 0.9500125304883776, 0.9511178867824691, 0.9511596327495886, 0.9439559248837275, 0.9506232672483215, 0.9515185243532013, 0.9502774581847051, 0.9503192018220014, 0.9492621419872446, 0.9507746583864044], 'val_mDice': [0.5033126131962099, 0.5786599841587706, 0.5787797728947786, 0.5532141984576899, 0.5995716918563222, 0.5943396578782545, 0.5126948218052473, 0.5599107824824143, 0.5816363356400779, 0.5757995550232524, 0.3104455804252081, 0.5998052857597799, 0.5755066791312702, 0.6042394721061477, 0.6087512922646169, 0.5958177181573566, 0.6064151135494732, 0.5793535706954205, 0.5985410720692396, 0.6025616781428117, 0.5876926225685918, 0.6028356517662055, 0.6021613868177907, 0.599158519278326, 0.47673268135673447, 0.5901487263872103, 0.6078306596714045, 0.556631769972826, 0.5920629713939145, 0.6073026346704082, 0.5962143534800517, 0.5987905553187144, 0.5473971438718541, 0.5943989793766982, 0.6042154569190954, 0.6088513660120265, 0.6017387978465627, 0.6100078075881501, 0.5448073958340995, 0.5438108378444898, 0.6078134111404807, 0.614162548478535, 0.6055133122623161, 0.5686961381850879, 0.563429563218297, 0.6093881285540056, 0.6022671313064495, 0.6082002011883142, 0.6121774650988827, 0.6123791121504594, 0.6144150138532299, 0.5981940627583463, 0.6153413696087144, 0.603402415806191, 0.6177903483667281, 0.6071214763757072, 0.6106775644256548, 0.6122011827723599, 0.6022067742258408, 0.6111900512772197, 0.6113799688093825, 0.6135373215042419, 0.6078426583582105, 0.5136993871061344, 0.6069440366245248, 0.6074970497807385, 0.6105461687043746, 0.604156131100771, 0.618215672259222, 0.6141941426291528, 0.6145896996319876, 0.5455348795516484, 0.6118532934192725, 0.6060548547521865, 0.6147994756310304, 0.6074628804716303, 0.6081948377895822, 0.6002482810218481, 0.6139327241077486, 0.6097403965671987, 0.6022457281667557, 0.6016507514961767, 0.6092939715868876, 0.6110142046154905, 0.6042926788378616, 0.6134977920241775, 0.5859254222448175, 0.6009233520648378, 0.6039522367890572, 0.6055979182403717, 0.6110245663587744, 0.6089717997693084, 0.5902873108023929, 0.6102800081917829, 0.6079820782334486, 0.6013227299292624, 0.6188758835196495, 0.6106057694418423, 0.6116871470737146, 0.6019895885637218, 0.6107384196515969, 0.5553733856456676, 0.6066107847257624, 0.6064280737980181, 0.6083193165568653, 0.5889072391031619, 0.6046102157875847, 0.6057836194962555, 0.5843758976226521, 0.6068870319654188, 0.5801642712824507, 0.606614779110646, 0.6106168023441048, 0.6018890420320756, 0.597531479034051, 0.6094554291874268, 0.6085064943139639, 0.5690478224319433, 0.5962626132689393, 0.5115016410521653, 0.6049044671246983, 0.601577081247339, 0.6054406888321867, 0.610759086785565, 0.6135546468465258, 0.606351267097439, 0.6086483985331237, 0.5628883503256092, 0.6033421603398526, 0.6113545328669905, 0.4914048300018528, 0.601561439590656, 0.5995931322974568, 0.5988097731812769, 0.6070446924637117, 0.6084514073420814, 0.6075161066913449], 'loss': [1.1372381276077956, 0.44252452177956525, 0.39322888150978963, 0.3753321518184047, 0.31799735316974864, 0.3084932523223396, 0.31330758051817714, 0.2855305186851587, 0.2898024642468209, 0.2737710743941921, 0.25559575756580255, 0.2861605307919817, 0.25582991610823475, 0.23210364307021203, 0.21890279882101332, 0.21280463064463234, 0.2155555308649835, 0.2203471892755056, 0.21665090066848208, 0.23891213119417018, 0.23854252767405218, 0.21493524678955553, 0.2215893733666184, 0.2011790229779312, 0.20661609927829783, 0.22995296103422996, 0.20610624360127114, 0.20069322410054194, 0.1961596925598291, 0.20737994163775733, 0.20010271413675504, 0.2035912331982594, 0.20984463928148747, 0.23466283237503774, 0.1973342216908914, 0.19575128638578185, 0.26121328511029746, 0.2096084279019361, 0.1930201005809976, 0.21838094776958653, 0.1973496189665722, 0.18514477319506356, 0.18102543624735448, 0.20921507651919355, 0.21028955611967023, 0.19070877347217177, 0.1792359920791683, 0.1762586042472262, 0.1756658472758546, 0.18513159312109442, 0.17228881868376175, 0.17486640593045774, 0.1804617446233498, 0.17660535023290122, 0.18479860137677387, 0.19145680229453793, 0.2246790948755697, 0.1928086439332336, 0.19213145043160126, 0.17815473232962656, 0.18977026060838728, 0.18911365999668162, 0.1710941127395519, 0.1737979062635221, 0.17731039859046033, 0.16836323184801438, 0.1660211566497665, 0.1603367046341047, 0.1633684894510198, 0.15939417855837734, 0.15875175952744497, 0.16749377851653227, 0.18351457668112736, 0.1697953407622551, 0.17020106869779406, 0.15576375372827234, 0.16263529184129188, 0.1813958916981125, 0.1748818468559688, 0.1624204827074341, 0.19241599988030544, 0.1733235605702389, 0.16114209398299734, 0.15755950962694007, 0.1762451072011389, 0.16578767819750292, 0.18864040118630224, 0.17706206673492716, 0.16303575595118144, 0.1713419708114799, 0.16089523727673546, 0.15638485123294243, 0.15233337765471563, 0.1648379693599698, 0.15290634848753082, 0.1571575440672785, 0.1529649173857635, 0.17196834273958117, 0.17099373848845734, 0.15812469771472623, 0.154292164290861, 0.16333545221231846, 0.16564011495322292, 0.15916899859624742, 0.17889004113306745, 0.16298558037099387, 0.19548670584143413, 0.16616017740372288, 0.15617007279971973, 0.15508038110823788, 0.1625983061215333, 0.15841774219852212, 0.15131582895739548, 0.15017582685183178, 0.15284124821603792, 0.14688694626740903, 0.1530304142072741, 0.1619663922033053, 0.16120205491793663, 0.1715685930013188, 0.1822579786995435, 0.16967440232551992, 0.17742927032925357, 0.1564464072152673, 0.1518469191353111, 0.15236222611016456, 0.14711636898256567, 0.1539708283409905, 0.16528920032443048, 0.15911010532458117, 0.16602913922143536, 0.18450883038347768, 0.16405677282519768, 0.1692280889892476, 0.18550394778063606, 0.17648923234000927, 0.15654161109985104], 'acc': [0.8171578359028367, 0.9199244910889401, 0.9359033551516936, 0.941064311070163, 0.9459665634686506, 0.9472780334890553, 0.9467886820006783, 0.9490926933876561, 0.9489474212597117, 0.9509190045793792, 0.9518791868765216, 0.9497629512291593, 0.9525643141080647, 0.9539124146250323, 0.9549850796534035, 0.955682447776549, 0.9559248334962246, 0.9553725214692489, 0.9555430700107606, 0.9542772797445462, 0.9527131181316577, 0.9559140215893204, 0.9554927118618336, 0.9568987880027506, 0.9572294278064449, 0.9554404226317758, 0.9566663791959066, 0.9576464414156278, 0.9573755124812968, 0.955995501760091, 0.9573675426333573, 0.9572378767213465, 0.956725160506921, 0.9550003053256184, 0.957329475624733, 0.9579451259574235, 0.9523752438252995, 0.9568464238044155, 0.957722026510563, 0.9554845496542566, 0.9574244622499072, 0.9585328294521163, 0.9589560005651617, 0.9561310619952006, 0.9562785058029499, 0.9577379927297456, 0.9588971456599689, 0.9593102945539774, 0.9596530357693634, 0.9591571205551546, 0.9599628895547794, 0.9597461378658877, 0.9593835145052203, 0.9598803846151668, 0.9597949691850461, 0.9586531159570576, 0.9554714462581992, 0.9582385377836474, 0.9590937552041917, 0.9597586683550379, 0.9593234202374211, 0.9586691051915083, 0.960361811426885, 0.9602357771516364, 0.9596663541249013, 0.9605937892815309, 0.9609749591136807, 0.961052402316931, 0.960967154974252, 0.9610996807730062, 0.961309897045343, 0.9607738125364726, 0.9594732279567897, 0.9605603081130311, 0.9610339553557705, 0.9614810871560968, 0.961436840750345, 0.9594401731140001, 0.9605181138795406, 0.9610521174168838, 0.9591482896372199, 0.960238353001139, 0.9609934081626192, 0.961357317676267, 0.960444341359474, 0.9605833380809029, 0.9581236678698849, 0.9598906957500281, 0.9609135265481573, 0.961316671995379, 0.9616489617935476, 0.9619077180476798, 0.9620438027127671, 0.9614872443297496, 0.9619989840960342, 0.9619595556323919, 0.9619487929018938, 0.9604779925114588, 0.9604737204097044, 0.9616129468471147, 0.9620250448821562, 0.9606961296009053, 0.9608001846323247, 0.9613526880602644, 0.9606186845513206, 0.9612144323686906, 0.9582578929566908, 0.9607093749978298, 0.961442948584262, 0.9616240685973335, 0.9611163660151584, 0.9613779140511498, 0.9619734695159836, 0.9622121781648686, 0.9622951371181059, 0.9625173571772038, 0.9621476453376184, 0.9612542410174368, 0.9616120174520955, 0.9609461287798262, 0.9601400013214823, 0.9613826400635602, 0.9599646801121106, 0.9616176011400864, 0.9621217500718232, 0.9623482625174993, 0.962556900947979, 0.9622408901486892, 0.9612655775922118, 0.9616978871195314, 0.9614979599716197, 0.959863484754396, 0.9614982221759565, 0.9616219445813609, 0.9589915859547992, 0.9598759693585861, 0.9614919691349415], 'mDice': [0.41978258624528203, 0.6377129508519163, 0.6736292299814134, 0.6821890721271681, 0.719013651770691, 0.7290426911915464, 0.72730253613314, 0.7406796842374987, 0.7439717624316287, 0.7590282805205855, 0.7657034322277689, 0.7464288509345831, 0.7692913910776933, 0.7820272542398228, 0.792401278811455, 0.7975835119512626, 0.7986507001162896, 0.7947157181281461, 0.7968376863384116, 0.78310399133027, 0.7794383468782453, 0.7994886699757923, 0.7941777369190215, 0.8073167686856666, 0.8089527165747004, 0.7936789464189303, 0.8040931209377701, 0.8124493578457879, 0.8118436196621998, 0.8046186060528236, 0.8117590573486339, 0.8104704872182932, 0.8053768270422053, 0.792244659680497, 0.810889778490425, 0.8176306849431557, 0.7735598311036809, 0.806278098898547, 0.8151087471831936, 0.7962817809861121, 0.8109864969665983, 0.8212249147364373, 0.8248736068633894, 0.8039888405292834, 0.8044388978712936, 0.8163010665032083, 0.8261344259133353, 0.8290666102858846, 0.8311976306795072, 0.827216419599435, 0.8338544112103418, 0.8313211555413352, 0.8277625047110273, 0.8318083836137982, 0.83006400113848, 0.8200584260179067, 0.8002505070359169, 0.8195916587248193, 0.8237239857799934, 0.8308829311646493, 0.8272224417953925, 0.8212305248163579, 0.8365258284753306, 0.8356864220860134, 0.8282783962229191, 0.8374957284777105, 0.8409304734692932, 0.842781479528962, 0.8418465099752557, 0.843575858367507, 0.8442316975127439, 0.8409441133355586, 0.8291184992413002, 0.8378652309003691, 0.8409367783106395, 0.846766334076539, 0.8455495675494816, 0.8298665389534886, 0.8367406689347366, 0.8410955751468435, 0.8260166504018507, 0.8364814872496563, 0.8425621711782427, 0.8453673103648612, 0.8345270803894034, 0.838684172260191, 0.823353525539418, 0.8312094380020875, 0.8406974912229456, 0.8437944998826081, 0.8473186974813196, 0.8496622474018739, 0.8501066020667436, 0.8437975707627638, 0.849676431670484, 0.8506020982163072, 0.8495560082598483, 0.8357124830887246, 0.8374197968471154, 0.8466275259084582, 0.8511860016565862, 0.841569525195523, 0.8395041696487163, 0.8440870483522227, 0.8362020581575433, 0.8435968680443414, 0.8229985903364243, 0.8406373898609616, 0.8467695169830334, 0.8475162603625478, 0.8427711129011005, 0.8446911468559545, 0.8508313372114285, 0.8528020578775141, 0.8525006071646474, 0.854933799445796, 0.8508406435817706, 0.8451459875497098, 0.8473991900265249, 0.841352571396928, 0.8325940347551526, 0.8439452089646691, 0.8337183737119966, 0.846418810812494, 0.8507410571056345, 0.8529403802927719, 0.8548003736087392, 0.8525679515579397, 0.8419598889349471, 0.8494540338626447, 0.8459744447145537, 0.8297836453427352, 0.8453934798752238, 0.8458000238807957, 0.8277660292284396, 0.8323870059589877, 0.846465726563281]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.81s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:07,  2.63s/it]predicting test subjects:  60%|██████    | 3/5 [00:06<00:04,  2.41s/it]predicting test subjects:  80%|████████  | 4/5 [00:08<00:02,  2.24s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.26s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:12,  2.76s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:00,  2.73s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:15,  2.57s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:34,  2.42s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:44,  2.47s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:13,  2.59s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:28,  2.66s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:35,  2.70s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:45,  2.74s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:45,  2.76s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:43,  2.76s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<11:56,  2.82s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:51,  2.81s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:51,  2.82s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<11:49,  2.83s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:49,  2.84s/it]predicting train subjects:   6%|▋         | 17/266 [00:46<11:43,  2.82s/it]predicting train subjects:   7%|▋         | 18/266 [00:49<11:35,  2.80s/it]predicting train subjects:   7%|▋         | 19/266 [00:51<11:27,  2.78s/it]predicting train subjects:   8%|▊         | 20/266 [00:54<11:26,  2.79s/it]predicting train subjects:   8%|▊         | 21/266 [00:57<11:20,  2.78s/it]predicting train subjects:   8%|▊         | 22/266 [01:00<11:19,  2.79s/it]predicting train subjects:   9%|▊         | 23/266 [01:02<11:16,  2.78s/it]predicting train subjects:   9%|▉         | 24/266 [01:05<11:05,  2.75s/it]predicting train subjects:   9%|▉         | 25/266 [01:08<10:50,  2.70s/it]predicting train subjects:  10%|▉         | 26/266 [01:10<10:36,  2.65s/it]predicting train subjects:  10%|█         | 27/266 [01:13<10:23,  2.61s/it]predicting train subjects:  11%|█         | 28/266 [01:15<10:16,  2.59s/it]predicting train subjects:  11%|█         | 29/266 [01:18<10:15,  2.60s/it]predicting train subjects:  11%|█▏        | 30/266 [01:20<10:09,  2.58s/it]predicting train subjects:  12%|█▏        | 31/266 [01:23<10:02,  2.57s/it]predicting train subjects:  12%|█▏        | 32/266 [01:25<09:54,  2.54s/it]predicting train subjects:  12%|█▏        | 33/266 [01:28<09:57,  2.56s/it]predicting train subjects:  13%|█▎        | 34/266 [01:31<09:56,  2.57s/it]predicting train subjects:  13%|█▎        | 35/266 [01:33<10:01,  2.60s/it]predicting train subjects:  14%|█▎        | 36/266 [01:36<10:00,  2.61s/it]predicting train subjects:  14%|█▍        | 37/266 [01:39<09:58,  2.61s/it]predicting train subjects:  14%|█▍        | 38/266 [01:41<09:57,  2.62s/it]predicting train subjects:  15%|█▍        | 39/266 [01:44<09:48,  2.59s/it]predicting train subjects:  15%|█▌        | 40/266 [01:46<09:43,  2.58s/it]predicting train subjects:  15%|█▌        | 41/266 [01:49<09:37,  2.57s/it]predicting train subjects:  16%|█▌        | 42/266 [01:51<09:07,  2.44s/it]predicting train subjects:  16%|█▌        | 43/266 [01:53<08:52,  2.39s/it]predicting train subjects:  17%|█▋        | 44/266 [01:55<08:35,  2.32s/it]predicting train subjects:  17%|█▋        | 45/266 [01:58<08:26,  2.29s/it]predicting train subjects:  17%|█▋        | 46/266 [02:00<08:12,  2.24s/it]predicting train subjects:  18%|█▊        | 47/266 [02:02<08:05,  2.22s/it]predicting train subjects:  18%|█▊        | 48/266 [02:04<07:54,  2.18s/it]predicting train subjects:  18%|█▊        | 49/266 [02:06<07:45,  2.15s/it]predicting train subjects:  19%|█▉        | 50/266 [02:08<07:44,  2.15s/it]predicting train subjects:  19%|█▉        | 51/266 [02:10<07:43,  2.15s/it]predicting train subjects:  20%|█▉        | 52/266 [02:13<07:46,  2.18s/it]predicting train subjects:  20%|█▉        | 53/266 [02:15<07:42,  2.17s/it]predicting train subjects:  20%|██        | 54/266 [02:17<07:39,  2.17s/it]predicting train subjects:  21%|██        | 55/266 [02:19<07:37,  2.17s/it]predicting train subjects:  21%|██        | 56/266 [02:21<07:34,  2.16s/it]predicting train subjects:  21%|██▏       | 57/266 [02:23<07:31,  2.16s/it]predicting train subjects:  22%|██▏       | 58/266 [02:25<07:27,  2.15s/it]predicting train subjects:  22%|██▏       | 59/266 [02:28<07:23,  2.14s/it]predicting train subjects:  23%|██▎       | 60/266 [02:30<07:14,  2.11s/it]predicting train subjects:  23%|██▎       | 61/266 [02:32<07:10,  2.10s/it]predicting train subjects:  23%|██▎       | 62/266 [02:34<06:59,  2.06s/it]predicting train subjects:  24%|██▎       | 63/266 [02:36<06:51,  2.03s/it]predicting train subjects:  24%|██▍       | 64/266 [02:38<06:43,  2.00s/it]predicting train subjects:  24%|██▍       | 65/266 [02:40<06:40,  1.99s/it]predicting train subjects:  25%|██▍       | 66/266 [02:42<06:36,  1.98s/it]predicting train subjects:  25%|██▌       | 67/266 [02:43<06:33,  1.98s/it]predicting train subjects:  26%|██▌       | 68/266 [02:45<06:30,  1.97s/it]predicting train subjects:  26%|██▌       | 69/266 [02:47<06:27,  1.97s/it]predicting train subjects:  26%|██▋       | 70/266 [02:49<06:27,  1.98s/it]predicting train subjects:  27%|██▋       | 71/266 [02:51<06:23,  1.97s/it]predicting train subjects:  27%|██▋       | 72/266 [02:53<06:23,  1.98s/it]predicting train subjects:  27%|██▋       | 73/266 [02:55<06:22,  1.98s/it]predicting train subjects:  28%|██▊       | 74/266 [02:57<06:24,  2.00s/it]predicting train subjects:  28%|██▊       | 75/266 [02:59<06:18,  1.98s/it]predicting train subjects:  29%|██▊       | 76/266 [03:01<06:15,  1.98s/it]predicting train subjects:  29%|██▉       | 77/266 [03:03<06:11,  1.97s/it]predicting train subjects:  29%|██▉       | 78/266 [03:06<06:42,  2.14s/it]predicting train subjects:  30%|██▉       | 79/266 [03:08<07:06,  2.28s/it]predicting train subjects:  30%|███       | 80/266 [03:11<07:19,  2.36s/it]predicting train subjects:  30%|███       | 81/266 [03:14<07:29,  2.43s/it]predicting train subjects:  31%|███       | 82/266 [03:16<07:37,  2.49s/it]predicting train subjects:  31%|███       | 83/266 [03:19<07:37,  2.50s/it]predicting train subjects:  32%|███▏      | 84/266 [03:21<07:36,  2.51s/it]predicting train subjects:  32%|███▏      | 85/266 [03:24<07:36,  2.52s/it]predicting train subjects:  32%|███▏      | 86/266 [03:26<07:36,  2.54s/it]predicting train subjects:  33%|███▎      | 87/266 [03:29<07:36,  2.55s/it]predicting train subjects:  33%|███▎      | 88/266 [03:31<07:35,  2.56s/it]predicting train subjects:  33%|███▎      | 89/266 [03:34<07:33,  2.56s/it]predicting train subjects:  34%|███▍      | 90/266 [03:37<07:32,  2.57s/it]predicting train subjects:  34%|███▍      | 91/266 [03:39<07:30,  2.57s/it]predicting train subjects:  35%|███▍      | 92/266 [03:42<07:25,  2.56s/it]predicting train subjects:  35%|███▍      | 93/266 [03:44<07:26,  2.58s/it]predicting train subjects:  35%|███▌      | 94/266 [03:47<07:21,  2.57s/it]predicting train subjects:  36%|███▌      | 95/266 [03:50<07:22,  2.59s/it]predicting train subjects:  36%|███▌      | 96/266 [03:52<07:06,  2.51s/it]predicting train subjects:  36%|███▋      | 97/266 [03:55<07:18,  2.59s/it]predicting train subjects:  37%|███▋      | 98/266 [03:57<07:14,  2.59s/it]predicting train subjects:  37%|███▋      | 99/266 [03:59<06:37,  2.38s/it]predicting train subjects:  38%|███▊      | 100/266 [04:01<06:16,  2.27s/it]predicting train subjects:  38%|███▊      | 101/266 [04:03<06:18,  2.30s/it]predicting train subjects:  38%|███▊      | 102/266 [04:06<06:17,  2.30s/it]predicting train subjects:  39%|███▊      | 103/266 [04:08<06:13,  2.29s/it]predicting train subjects:  39%|███▉      | 104/266 [04:10<06:16,  2.33s/it]predicting train subjects:  39%|███▉      | 105/266 [04:13<06:13,  2.32s/it]predicting train subjects:  40%|███▉      | 106/266 [04:15<06:11,  2.32s/it]predicting train subjects:  40%|████      | 107/266 [04:17<06:03,  2.29s/it]predicting train subjects:  41%|████      | 108/266 [04:20<06:05,  2.31s/it]predicting train subjects:  41%|████      | 109/266 [04:22<06:07,  2.34s/it]predicting train subjects:  41%|████▏     | 110/266 [04:24<06:05,  2.34s/it]predicting train subjects:  42%|████▏     | 111/266 [04:27<06:00,  2.32s/it]predicting train subjects:  42%|████▏     | 112/266 [04:29<05:59,  2.34s/it]predicting train subjects:  42%|████▏     | 113/266 [04:31<05:57,  2.33s/it]predicting train subjects:  43%|████▎     | 114/266 [04:34<05:51,  2.31s/it]predicting train subjects:  43%|████▎     | 115/266 [04:36<05:50,  2.32s/it]predicting train subjects:  44%|████▎     | 116/266 [04:38<05:50,  2.33s/it]predicting train subjects:  44%|████▍     | 117/266 [04:41<05:49,  2.35s/it]predicting train subjects:  44%|████▍     | 118/266 [04:43<05:46,  2.34s/it]predicting train subjects:  45%|████▍     | 119/266 [04:46<05:59,  2.45s/it]predicting train subjects:  45%|████▌     | 120/266 [04:48<06:04,  2.50s/it]predicting train subjects:  45%|████▌     | 121/266 [04:51<06:06,  2.53s/it]predicting train subjects:  46%|████▌     | 122/266 [04:54<06:07,  2.55s/it]predicting train subjects:  46%|████▌     | 123/266 [04:56<06:08,  2.58s/it]predicting train subjects:  47%|████▋     | 124/266 [04:59<06:07,  2.59s/it]predicting train subjects:  47%|████▋     | 125/266 [05:01<06:06,  2.60s/it]predicting train subjects:  47%|████▋     | 126/266 [05:04<06:08,  2.63s/it]predicting train subjects:  48%|████▊     | 127/266 [05:07<06:08,  2.65s/it]predicting train subjects:  48%|████▊     | 128/266 [05:10<06:05,  2.65s/it]predicting train subjects:  48%|████▊     | 129/266 [05:12<06:00,  2.63s/it]predicting train subjects:  49%|████▉     | 130/266 [05:15<05:55,  2.62s/it]predicting train subjects:  49%|████▉     | 131/266 [05:17<05:51,  2.60s/it]predicting train subjects:  50%|████▉     | 132/266 [05:20<05:46,  2.59s/it]predicting train subjects:  50%|█████     | 133/266 [05:23<05:47,  2.61s/it]predicting train subjects:  50%|█████     | 134/266 [05:25<05:44,  2.61s/it]predicting train subjects:  51%|█████     | 135/266 [05:28<05:43,  2.62s/it]predicting train subjects:  51%|█████     | 136/266 [05:31<05:47,  2.67s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:33<05:45,  2.68s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:36<05:42,  2.68s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:38<05:34,  2.63s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:41<05:27,  2.60s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:44<05:23,  2.59s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:46<05:18,  2.57s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:49<05:15,  2.57s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:51<05:11,  2.55s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:54<05:07,  2.54s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:56<05:02,  2.52s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:59<04:58,  2.51s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:01<04:57,  2.52s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:04<04:56,  2.53s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:06<04:55,  2.55s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:09<04:54,  2.56s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:11<04:50,  2.55s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:14<04:48,  2.55s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:17<04:45,  2.55s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:18<04:23,  2.38s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:21<04:09,  2.27s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:22<03:56,  2.17s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:24<03:47,  2.10s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:26<03:39,  2.05s/it]predicting train subjects:  60%|██████    | 160/266 [06:28<03:34,  2.02s/it]predicting train subjects:  61%|██████    | 161/266 [06:30<03:31,  2.01s/it]predicting train subjects:  61%|██████    | 162/266 [06:32<03:28,  2.00s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:34<03:24,  1.99s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:36<03:19,  1.95s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:38<03:17,  1.96s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:40<03:14,  1.95s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:42<03:12,  1.94s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:44<03:09,  1.94s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:46<03:05,  1.91s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:48<03:03,  1.91s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:49<03:01,  1.91s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:51<02:58,  1.90s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:54<03:03,  1.97s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:56<03:05,  2.01s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:58<03:06,  2.05s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:00<03:06,  2.08s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:02<03:06,  2.09s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:04<03:04,  2.10s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:06<03:03,  2.11s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:08<03:04,  2.14s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:11<03:03,  2.16s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:13<02:58,  2.13s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:15<02:55,  2.11s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:17<02:54,  2.13s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:19<02:52,  2.12s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:21<02:50,  2.13s/it]predicting train subjects:  70%|███████   | 187/266 [07:23<02:46,  2.11s/it]predicting train subjects:  71%|███████   | 188/266 [07:25<02:43,  2.10s/it]predicting train subjects:  71%|███████   | 189/266 [07:28<02:43,  2.12s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:30<02:39,  2.10s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:32<02:40,  2.13s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:34<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:36<02:32,  2.08s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:38<02:40,  2.23s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:41<02:38,  2.23s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:43<02:35,  2.22s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:45<02:33,  2.23s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:47<02:30,  2.22s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:50<02:28,  2.22s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:52<02:26,  2.21s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:54<02:25,  2.23s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:56<02:21,  2.21s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:58<02:18,  2.20s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:01<02:17,  2.22s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:03<02:14,  2.21s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:05<02:11,  2.20s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:07<02:08,  2.17s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:09<02:06,  2.19s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:11<02:04,  2.19s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:14<02:02,  2.19s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:16<02:01,  2.20s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:18<01:58,  2.19s/it]predicting train subjects:  80%|████████  | 213/266 [08:20<01:52,  2.12s/it]predicting train subjects:  80%|████████  | 214/266 [08:22<01:47,  2.06s/it]predicting train subjects:  81%|████████  | 215/266 [08:24<01:42,  2.01s/it]predicting train subjects:  81%|████████  | 216/266 [08:26<01:38,  1.97s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:28<01:36,  1.97s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:30<01:34,  1.96s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:32<01:31,  1.95s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:34<01:29,  1.95s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:35<01:28,  1.96s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:37<01:26,  1.96s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:39<01:24,  1.97s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:41<01:22,  1.96s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:43<01:20,  1.96s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:45<01:18,  1.96s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:47<01:16,  1.95s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:49<01:14,  1.96s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:51<01:13,  1.98s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:53<01:10,  1.95s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:55<01:08,  1.97s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:57<01:07,  1.97s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:59<01:05,  1.98s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:01<01:03,  1.97s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:03<01:01,  2.00s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:05<01:00,  2.00s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:07<00:57,  1.98s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:09<00:55,  1.98s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:11<00:53,  1.98s/it]predicting train subjects:  90%|█████████ | 240/266 [09:13<00:51,  1.99s/it]predicting train subjects:  91%|█████████ | 241/266 [09:15<00:49,  1.99s/it]predicting train subjects:  91%|█████████ | 242/266 [09:17<00:47,  2.00s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:19<00:45,  2.00s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:21<00:44,  2.00s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:23<00:41,  1.99s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:25<00:39,  1.99s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:27<00:37,  1.97s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:29<00:35,  1.96s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:31<00:36,  2.14s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:34<00:35,  2.24s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:36<00:34,  2.33s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:39<00:33,  2.42s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:42<00:31,  2.45s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:44<00:29,  2.48s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:47<00:27,  2.51s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:49<00:25,  2.52s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:52<00:22,  2.53s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:54<00:20,  2.52s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:57<00:17,  2.50s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:59<00:15,  2.54s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:02<00:12,  2.57s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:05<00:10,  2.59s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:07<00:07,  2.57s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:10<00:05,  2.57s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:12<00:02,  2.58s/it]predicting train subjects: 100%|██████████| 266/266 [10:15<00:00,  2.57s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:38,  1.73s/it]Loading train:   1%|          | 2/266 [00:03<07:23,  1.68s/it]Loading train:   1%|          | 3/266 [00:04<06:47,  1.55s/it]Loading train:   2%|▏         | 4/266 [00:05<06:18,  1.44s/it]Loading train:   2%|▏         | 5/266 [00:07<06:21,  1.46s/it]Loading train:   2%|▏         | 6/266 [00:08<05:38,  1.30s/it]Loading train:   3%|▎         | 7/266 [00:09<05:03,  1.17s/it]Loading train:   3%|▎         | 8/266 [00:09<04:41,  1.09s/it]Loading train:   3%|▎         | 9/266 [00:10<04:26,  1.04s/it]Loading train:   4%|▍         | 10/266 [00:11<04:19,  1.01s/it]Loading train:   4%|▍         | 11/266 [00:12<04:16,  1.00s/it]Loading train:   5%|▍         | 12/266 [00:13<04:12,  1.00it/s]Loading train:   5%|▍         | 13/266 [00:14<04:11,  1.01it/s]Loading train:   5%|▌         | 14/266 [00:15<04:06,  1.02it/s]Loading train:   6%|▌         | 15/266 [00:16<04:02,  1.03it/s]Loading train:   6%|▌         | 16/266 [00:17<03:58,  1.05it/s]Loading train:   6%|▋         | 17/266 [00:18<03:55,  1.06it/s]Loading train:   7%|▋         | 18/266 [00:19<03:52,  1.07it/s]Loading train:   7%|▋         | 19/266 [00:20<03:44,  1.10it/s]Loading train:   8%|▊         | 20/266 [00:21<03:41,  1.11it/s]Loading train:   8%|▊         | 21/266 [00:22<03:46,  1.08it/s]Loading train:   8%|▊         | 22/266 [00:23<03:49,  1.06it/s]Loading train:   9%|▊         | 23/266 [00:24<03:48,  1.06it/s]Loading train:   9%|▉         | 24/266 [00:24<03:45,  1.07it/s]Loading train:   9%|▉         | 25/266 [00:25<03:39,  1.10it/s]Loading train:  10%|▉         | 26/266 [00:26<03:44,  1.07it/s]Loading train:  10%|█         | 27/266 [00:27<03:39,  1.09it/s]Loading train:  11%|█         | 28/266 [00:28<03:30,  1.13it/s]Loading train:  11%|█         | 29/266 [00:29<03:26,  1.15it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:26,  1.14it/s]Loading train:  12%|█▏        | 31/266 [00:31<03:26,  1.14it/s]Loading train:  12%|█▏        | 32/266 [00:31<03:22,  1.16it/s]Loading train:  12%|█▏        | 33/266 [00:32<03:17,  1.18it/s]Loading train:  13%|█▎        | 34/266 [00:33<03:12,  1.21it/s]Loading train:  13%|█▎        | 35/266 [00:34<03:07,  1.23it/s]Loading train:  14%|█▎        | 36/266 [00:35<03:10,  1.21it/s]Loading train:  14%|█▍        | 37/266 [00:35<03:09,  1.21it/s]Loading train:  14%|█▍        | 38/266 [00:36<03:11,  1.19it/s]Loading train:  15%|█▍        | 39/266 [00:37<03:10,  1.19it/s]Loading train:  15%|█▌        | 40/266 [00:38<03:10,  1.19it/s]Loading train:  15%|█▌        | 41/266 [00:39<03:16,  1.15it/s]Loading train:  16%|█▌        | 42/266 [00:40<03:32,  1.05it/s]Loading train:  16%|█▌        | 43/266 [00:41<03:19,  1.12it/s]Loading train:  17%|█▋        | 44/266 [00:42<03:09,  1.17it/s]Loading train:  17%|█▋        | 45/266 [00:42<03:01,  1.22it/s]Loading train:  17%|█▋        | 46/266 [00:43<02:56,  1.25it/s]Loading train:  18%|█▊        | 47/266 [00:44<02:49,  1.30it/s]Loading train:  18%|█▊        | 48/266 [00:45<02:49,  1.28it/s]Loading train:  18%|█▊        | 49/266 [00:45<02:44,  1.32it/s]Loading train:  19%|█▉        | 50/266 [00:46<02:39,  1.35it/s]Loading train:  19%|█▉        | 51/266 [00:47<02:35,  1.38it/s]Loading train:  20%|█▉        | 52/266 [00:47<02:36,  1.37it/s]Loading train:  20%|█▉        | 53/266 [00:48<02:37,  1.35it/s]Loading train:  20%|██        | 54/266 [00:49<02:36,  1.36it/s]Loading train:  21%|██        | 55/266 [00:50<02:36,  1.35it/s]Loading train:  21%|██        | 56/266 [00:50<02:32,  1.38it/s]Loading train:  21%|██▏       | 57/266 [00:51<02:31,  1.38it/s]Loading train:  22%|██▏       | 58/266 [00:52<02:33,  1.35it/s]Loading train:  22%|██▏       | 59/266 [00:53<02:33,  1.35it/s]Loading train:  23%|██▎       | 60/266 [00:53<02:39,  1.29it/s]Loading train:  23%|██▎       | 61/266 [00:54<02:32,  1.35it/s]Loading train:  23%|██▎       | 62/266 [00:55<02:28,  1.37it/s]Loading train:  24%|██▎       | 63/266 [00:56<02:28,  1.37it/s]Loading train:  24%|██▍       | 64/266 [00:56<02:25,  1.39it/s]Loading train:  24%|██▍       | 65/266 [00:57<02:19,  1.44it/s]Loading train:  25%|██▍       | 66/266 [00:58<02:19,  1.43it/s]Loading train:  25%|██▌       | 67/266 [00:58<02:19,  1.43it/s]Loading train:  26%|██▌       | 68/266 [00:59<02:20,  1.41it/s]Loading train:  26%|██▌       | 69/266 [01:00<02:19,  1.41it/s]Loading train:  26%|██▋       | 70/266 [01:00<02:18,  1.42it/s]Loading train:  27%|██▋       | 71/266 [01:01<02:13,  1.46it/s]Loading train:  27%|██▋       | 72/266 [01:02<02:13,  1.45it/s]Loading train:  27%|██▋       | 73/266 [01:03<02:16,  1.42it/s]Loading train:  28%|██▊       | 74/266 [01:03<02:17,  1.40it/s]Loading train:  28%|██▊       | 75/266 [01:04<02:16,  1.40it/s]Loading train:  29%|██▊       | 76/266 [01:05<02:15,  1.41it/s]Loading train:  29%|██▉       | 77/266 [01:05<02:12,  1.43it/s]Loading train:  29%|██▉       | 78/266 [01:06<02:22,  1.32it/s]Loading train:  30%|██▉       | 79/266 [01:07<02:23,  1.30it/s]Loading train:  30%|███       | 80/266 [01:08<02:26,  1.27it/s]Loading train:  30%|███       | 81/266 [01:09<02:27,  1.25it/s]Loading train:  31%|███       | 82/266 [01:10<02:33,  1.20it/s]Loading train:  31%|███       | 83/266 [01:11<02:36,  1.17it/s]Loading train:  32%|███▏      | 84/266 [01:11<02:35,  1.17it/s]Loading train:  32%|███▏      | 85/266 [01:12<02:34,  1.17it/s]Loading train:  32%|███▏      | 86/266 [01:13<02:36,  1.15it/s]Loading train:  33%|███▎      | 87/266 [01:14<02:36,  1.14it/s]Loading train:  33%|███▎      | 88/266 [01:15<02:33,  1.16it/s]Loading train:  33%|███▎      | 89/266 [01:16<02:33,  1.15it/s]Loading train:  34%|███▍      | 90/266 [01:17<02:32,  1.15it/s]Loading train:  34%|███▍      | 91/266 [01:18<02:33,  1.14it/s]Loading train:  35%|███▍      | 92/266 [01:18<02:32,  1.14it/s]Loading train:  35%|███▍      | 93/266 [01:19<02:30,  1.15it/s]Loading train:  35%|███▌      | 94/266 [01:20<02:30,  1.14it/s]Loading train:  36%|███▌      | 95/266 [01:21<02:29,  1.14it/s]Loading train:  36%|███▌      | 96/266 [01:22<02:46,  1.02it/s]Loading train:  36%|███▋      | 97/266 [01:24<03:11,  1.13s/it]Loading train:  37%|███▋      | 98/266 [01:25<03:13,  1.15s/it]Loading train:  37%|███▋      | 99/266 [01:26<03:06,  1.11s/it]Loading train:  38%|███▊      | 100/266 [01:27<03:11,  1.15s/it]Loading train:  38%|███▊      | 101/266 [01:28<03:01,  1.10s/it]Loading train:  38%|███▊      | 102/266 [01:29<02:44,  1.00s/it]Loading train:  39%|███▊      | 103/266 [01:30<02:31,  1.07it/s]Loading train:  39%|███▉      | 104/266 [01:31<02:24,  1.12it/s]Loading train:  39%|███▉      | 105/266 [01:31<02:20,  1.15it/s]Loading train:  40%|███▉      | 106/266 [01:32<02:16,  1.17it/s]Loading train:  40%|████      | 107/266 [01:33<02:11,  1.21it/s]Loading train:  41%|████      | 108/266 [01:34<02:08,  1.23it/s]Loading train:  41%|████      | 109/266 [01:35<02:07,  1.23it/s]Loading train:  41%|████▏     | 110/266 [01:35<02:02,  1.27it/s]Loading train:  42%|████▏     | 111/266 [01:36<02:00,  1.29it/s]Loading train:  42%|████▏     | 112/266 [01:37<01:55,  1.33it/s]Loading train:  42%|████▏     | 113/266 [01:37<01:54,  1.34it/s]Loading train:  43%|████▎     | 114/266 [01:38<01:54,  1.33it/s]Loading train:  43%|████▎     | 115/266 [01:39<01:56,  1.30it/s]Loading train:  44%|████▎     | 116/266 [01:40<01:55,  1.30it/s]Loading train:  44%|████▍     | 117/266 [01:41<01:53,  1.31it/s]Loading train:  44%|████▍     | 118/266 [01:41<01:52,  1.31it/s]Loading train:  45%|████▍     | 119/266 [01:42<01:57,  1.25it/s]Loading train:  45%|████▌     | 120/266 [01:43<02:03,  1.19it/s]Loading train:  45%|████▌     | 121/266 [01:44<02:01,  1.20it/s]Loading train:  46%|████▌     | 122/266 [01:45<01:58,  1.22it/s]Loading train:  46%|████▌     | 123/266 [01:46<01:58,  1.21it/s]Loading train:  47%|████▋     | 124/266 [01:47<02:02,  1.16it/s]Loading train:  47%|████▋     | 125/266 [01:47<02:00,  1.17it/s]Loading train:  47%|████▋     | 126/266 [01:48<01:59,  1.17it/s]Loading train:  48%|████▊     | 127/266 [01:49<01:58,  1.18it/s]Loading train:  48%|████▊     | 128/266 [01:50<01:57,  1.17it/s]Loading train:  48%|████▊     | 129/266 [01:51<01:57,  1.16it/s]Loading train:  49%|████▉     | 130/266 [01:52<01:55,  1.18it/s]Loading train:  49%|████▉     | 131/266 [01:52<01:55,  1.17it/s]Loading train:  50%|████▉     | 132/266 [01:53<01:55,  1.16it/s]Loading train:  50%|█████     | 133/266 [01:54<01:58,  1.12it/s]Loading train:  50%|█████     | 134/266 [01:55<01:59,  1.10it/s]Loading train:  51%|█████     | 135/266 [01:56<01:54,  1.14it/s]Loading train:  51%|█████     | 136/266 [01:57<01:52,  1.15it/s]Loading train:  52%|█████▏    | 137/266 [01:58<01:54,  1.12it/s]Loading train:  52%|█████▏    | 138/266 [01:59<01:52,  1.14it/s]Loading train:  52%|█████▏    | 139/266 [02:00<01:50,  1.14it/s]Loading train:  53%|█████▎    | 140/266 [02:00<01:49,  1.15it/s]Loading train:  53%|█████▎    | 141/266 [02:01<01:52,  1.12it/s]Loading train:  53%|█████▎    | 142/266 [02:02<01:49,  1.13it/s]Loading train:  54%|█████▍    | 143/266 [02:03<01:49,  1.13it/s]Loading train:  54%|█████▍    | 144/266 [02:04<01:49,  1.12it/s]Loading train:  55%|█████▍    | 145/266 [02:05<01:49,  1.11it/s]Loading train:  55%|█████▍    | 146/266 [02:06<01:46,  1.12it/s]Loading train:  55%|█████▌    | 147/266 [02:07<01:47,  1.11it/s]Loading train:  56%|█████▌    | 148/266 [02:08<01:43,  1.14it/s]Loading train:  56%|█████▌    | 149/266 [02:08<01:42,  1.14it/s]Loading train:  56%|█████▋    | 150/266 [02:09<01:42,  1.13it/s]Loading train:  57%|█████▋    | 151/266 [02:10<01:41,  1.13it/s]Loading train:  57%|█████▋    | 152/266 [02:11<01:40,  1.14it/s]Loading train:  58%|█████▊    | 153/266 [02:12<01:38,  1.14it/s]Loading train:  58%|█████▊    | 154/266 [02:13<01:39,  1.13it/s]Loading train:  58%|█████▊    | 155/266 [02:14<01:35,  1.16it/s]Loading train:  59%|█████▊    | 156/266 [02:14<01:30,  1.22it/s]Loading train:  59%|█████▉    | 157/266 [02:15<01:24,  1.29it/s]Loading train:  59%|█████▉    | 158/266 [02:16<01:19,  1.35it/s]Loading train:  60%|█████▉    | 159/266 [02:16<01:17,  1.38it/s]Loading train:  60%|██████    | 160/266 [02:17<01:14,  1.43it/s]Loading train:  61%|██████    | 161/266 [02:18<01:10,  1.49it/s]Loading train:  61%|██████    | 162/266 [02:18<01:08,  1.51it/s]Loading train:  61%|██████▏   | 163/266 [02:19<01:09,  1.48it/s]Loading train:  62%|██████▏   | 164/266 [02:20<01:08,  1.48it/s]Loading train:  62%|██████▏   | 165/266 [02:20<01:07,  1.49it/s]Loading train:  62%|██████▏   | 166/266 [02:21<01:10,  1.42it/s]Loading train:  63%|██████▎   | 167/266 [02:22<01:11,  1.39it/s]Loading train:  63%|██████▎   | 168/266 [02:23<01:09,  1.41it/s]Loading train:  64%|██████▎   | 169/266 [02:23<01:09,  1.40it/s]Loading train:  64%|██████▍   | 170/266 [02:24<01:09,  1.39it/s]Loading train:  64%|██████▍   | 171/266 [02:25<01:09,  1.37it/s]Loading train:  65%|██████▍   | 172/266 [02:25<01:06,  1.41it/s]Loading train:  65%|██████▌   | 173/266 [02:26<01:07,  1.38it/s]Loading train:  65%|██████▌   | 174/266 [02:27<01:07,  1.36it/s]Loading train:  66%|██████▌   | 175/266 [02:28<01:07,  1.35it/s]Loading train:  66%|██████▌   | 176/266 [02:28<01:05,  1.38it/s]Loading train:  67%|██████▋   | 177/266 [02:29<01:04,  1.38it/s]Loading train:  67%|██████▋   | 178/266 [02:30<01:03,  1.39it/s]Loading train:  67%|██████▋   | 179/266 [02:30<01:00,  1.43it/s]Loading train:  68%|██████▊   | 180/266 [02:31<01:01,  1.40it/s]Loading train:  68%|██████▊   | 181/266 [02:32<01:02,  1.37it/s]Loading train:  68%|██████▊   | 182/266 [02:33<01:01,  1.36it/s]Loading train:  69%|██████▉   | 183/266 [02:33<00:59,  1.39it/s]Loading train:  69%|██████▉   | 184/266 [02:34<01:01,  1.34it/s]Loading train:  70%|██████▉   | 185/266 [02:35<01:00,  1.34it/s]Loading train:  70%|██████▉   | 186/266 [02:36<00:58,  1.36it/s]Loading train:  70%|███████   | 187/266 [02:36<00:56,  1.39it/s]Loading train:  71%|███████   | 188/266 [02:37<00:56,  1.38it/s]Loading train:  71%|███████   | 189/266 [02:38<00:54,  1.42it/s]Loading train:  71%|███████▏  | 190/266 [02:38<00:53,  1.42it/s]Loading train:  72%|███████▏  | 191/266 [02:40<01:07,  1.12it/s]Loading train:  72%|███████▏  | 192/266 [02:41<01:12,  1.02it/s]Loading train:  73%|███████▎  | 193/266 [02:42<01:15,  1.03s/it]Loading train:  73%|███████▎  | 194/266 [02:44<01:22,  1.15s/it]Loading train:  73%|███████▎  | 195/266 [02:44<01:15,  1.07s/it]Loading train:  74%|███████▎  | 196/266 [02:45<01:10,  1.00s/it]Loading train:  74%|███████▍  | 197/266 [02:46<01:06,  1.04it/s]Loading train:  74%|███████▍  | 198/266 [02:47<01:02,  1.09it/s]Loading train:  75%|███████▍  | 199/266 [02:48<00:59,  1.12it/s]Loading train:  75%|███████▌  | 200/266 [02:49<00:56,  1.17it/s]Loading train:  76%|███████▌  | 201/266 [02:49<00:55,  1.18it/s]Loading train:  76%|███████▌  | 202/266 [02:50<00:53,  1.20it/s]Loading train:  76%|███████▋  | 203/266 [02:51<00:52,  1.20it/s]Loading train:  77%|███████▋  | 204/266 [02:52<00:51,  1.20it/s]Loading train:  77%|███████▋  | 205/266 [02:53<00:50,  1.20it/s]Loading train:  77%|███████▋  | 206/266 [02:54<00:49,  1.22it/s]Loading train:  78%|███████▊  | 207/266 [02:54<00:48,  1.22it/s]Loading train:  78%|███████▊  | 208/266 [02:55<00:46,  1.25it/s]Loading train:  79%|███████▊  | 209/266 [02:56<00:44,  1.28it/s]Loading train:  79%|███████▉  | 210/266 [02:57<00:42,  1.32it/s]Loading train:  79%|███████▉  | 211/266 [02:57<00:42,  1.29it/s]Loading train:  80%|███████▉  | 212/266 [02:58<00:41,  1.31it/s]Loading train:  80%|████████  | 213/266 [02:59<00:42,  1.24it/s]Loading train:  80%|████████  | 214/266 [03:00<00:42,  1.22it/s]Loading train:  81%|████████  | 215/266 [03:01<00:42,  1.20it/s]Loading train:  81%|████████  | 216/266 [03:02<00:41,  1.22it/s]Loading train:  82%|████████▏ | 217/266 [03:02<00:38,  1.27it/s]Loading train:  82%|████████▏ | 218/266 [03:03<00:35,  1.34it/s]Loading train:  82%|████████▏ | 219/266 [03:04<00:33,  1.38it/s]Loading train:  83%|████████▎ | 220/266 [03:04<00:33,  1.36it/s]Loading train:  83%|████████▎ | 221/266 [03:05<00:32,  1.38it/s]Loading train:  83%|████████▎ | 222/266 [03:06<00:30,  1.43it/s]Loading train:  84%|████████▍ | 223/266 [03:06<00:31,  1.38it/s]Loading train:  84%|████████▍ | 224/266 [03:07<00:30,  1.38it/s]Loading train:  85%|████████▍ | 225/266 [03:08<00:28,  1.42it/s]Loading train:  85%|████████▍ | 226/266 [03:08<00:27,  1.44it/s]Loading train:  85%|████████▌ | 227/266 [03:09<00:26,  1.47it/s]Loading train:  86%|████████▌ | 228/266 [03:10<00:25,  1.47it/s]Loading train:  86%|████████▌ | 229/266 [03:10<00:25,  1.47it/s]Loading train:  86%|████████▋ | 230/266 [03:11<00:24,  1.45it/s]Loading train:  87%|████████▋ | 231/266 [03:12<00:24,  1.43it/s]Loading train:  87%|████████▋ | 232/266 [03:13<00:23,  1.45it/s]Loading train:  88%|████████▊ | 233/266 [03:13<00:22,  1.48it/s]Loading train:  88%|████████▊ | 234/266 [03:14<00:21,  1.49it/s]Loading train:  88%|████████▊ | 235/266 [03:15<00:20,  1.51it/s]Loading train:  89%|████████▊ | 236/266 [03:15<00:19,  1.50it/s]Loading train:  89%|████████▉ | 237/266 [03:16<00:19,  1.48it/s]Loading train:  89%|████████▉ | 238/266 [03:17<00:19,  1.47it/s]Loading train:  90%|████████▉ | 239/266 [03:17<00:18,  1.48it/s]Loading train:  90%|█████████ | 240/266 [03:18<00:17,  1.47it/s]Loading train:  91%|█████████ | 241/266 [03:19<00:17,  1.45it/s]Loading train:  91%|█████████ | 242/266 [03:19<00:16,  1.45it/s]Loading train:  91%|█████████▏| 243/266 [03:20<00:16,  1.40it/s]Loading train:  92%|█████████▏| 244/266 [03:21<00:15,  1.41it/s]Loading train:  92%|█████████▏| 245/266 [03:22<00:15,  1.39it/s]Loading train:  92%|█████████▏| 246/266 [03:22<00:14,  1.38it/s]Loading train:  93%|█████████▎| 247/266 [03:23<00:13,  1.36it/s]Loading train:  93%|█████████▎| 248/266 [03:24<00:13,  1.33it/s]Loading train:  94%|█████████▎| 249/266 [03:25<00:13,  1.26it/s]Loading train:  94%|█████████▍| 250/266 [03:26<00:13,  1.20it/s]Loading train:  94%|█████████▍| 251/266 [03:26<00:12,  1.21it/s]Loading train:  95%|█████████▍| 252/266 [03:27<00:11,  1.18it/s]Loading train:  95%|█████████▌| 253/266 [03:28<00:11,  1.16it/s]Loading train:  95%|█████████▌| 254/266 [03:29<00:10,  1.14it/s]Loading train:  96%|█████████▌| 255/266 [03:30<00:09,  1.13it/s]Loading train:  96%|█████████▌| 256/266 [03:31<00:08,  1.12it/s]Loading train:  97%|█████████▋| 257/266 [03:32<00:08,  1.10it/s]Loading train:  97%|█████████▋| 258/266 [03:33<00:07,  1.13it/s]Loading train:  97%|█████████▋| 259/266 [03:34<00:06,  1.14it/s]Loading train:  98%|█████████▊| 260/266 [03:35<00:05,  1.14it/s]Loading train:  98%|█████████▊| 261/266 [03:35<00:04,  1.16it/s]Loading train:  98%|█████████▊| 262/266 [03:36<00:03,  1.17it/s]Loading train:  99%|█████████▉| 263/266 [03:37<00:02,  1.20it/s]Loading train:  99%|█████████▉| 264/266 [03:38<00:01,  1.20it/s]Loading train: 100%|█████████▉| 265/266 [03:39<00:00,  1.23it/s]Loading train: 100%|██████████| 266/266 [03:39<00:00,  1.24it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:01, 136.75it/s]concatenating: train:  11%|█         | 29/266 [00:00<00:01, 139.78it/s]concatenating: train:  17%|█▋        | 44/266 [00:00<00:01, 141.42it/s]concatenating: train:  22%|██▏       | 59/266 [00:00<00:01, 142.11it/s]concatenating: train:  27%|██▋       | 73/266 [00:00<00:01, 140.81it/s]concatenating: train:  33%|███▎      | 87/266 [00:00<00:01, 140.10it/s]concatenating: train:  39%|███▊      | 103/266 [00:00<00:01, 145.18it/s]concatenating: train:  46%|████▌     | 122/266 [00:00<00:00, 155.77it/s]concatenating: train:  52%|█████▏    | 139/266 [00:00<00:00, 157.59it/s]concatenating: train:  58%|█████▊    | 155/266 [00:01<00:00, 151.69it/s]concatenating: train:  65%|██████▍   | 172/266 [00:01<00:00, 154.89it/s]concatenating: train:  71%|███████▏  | 190/266 [00:01<00:00, 159.55it/s]concatenating: train:  77%|███████▋  | 206/266 [00:01<00:00, 145.83it/s]concatenating: train:  84%|████████▍ | 223/266 [00:01<00:00, 150.38it/s]concatenating: train:  91%|█████████ | 241/266 [00:01<00:00, 155.67it/s]concatenating: train:  97%|█████████▋| 258/266 [00:01<00:00, 157.61it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 154.49it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.25s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.22s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.17s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.12s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.20s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 655.91it/s]2019-08-17 00:56:40.234337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 00:56:40.234434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 00:56:40.234451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 00:56:40.234460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 00:56:40.234868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.33it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.38it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.06it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.80it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.46it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.31it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.40it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.79it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  7.95it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.90it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.36it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.47it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.32it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.29it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.21it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.20it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.60it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 26, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 13, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 13, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 13, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 26, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 26, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 52, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 52, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34310672e-02 3.28754414e-02 7.68746981e-02 9.55206780e-03
 2.76458593e-02 7.23275981e-03 8.43556305e-02 1.14261583e-01
 8.97178954e-02 1.36312704e-02 2.90883063e-01 1.89296061e-01
 2.42602716e-04]
Train on 10312 samples, validate on 190 samples
Epoch 1/300
 - 23s - loss: 1.2956 - acc: 0.8104 - mDice: 0.3994 - val_loss: 0.4872 - val_acc: 0.9484 - val_mDice: 0.6036

Epoch 00001: val_mDice improved from -inf to 0.60361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 0.4137 - acc: 0.9404 - mDice: 0.6479 - val_loss: 0.5342 - val_acc: 0.9478 - val_mDice: 0.5903

Epoch 00002: val_mDice did not improve from 0.60361
Epoch 3/300
 - 18s - loss: 0.3359 - acc: 0.9469 - mDice: 0.7009 - val_loss: 0.5292 - val_acc: 0.9481 - val_mDice: 0.5859

Epoch 00003: val_mDice did not improve from 0.60361
Epoch 4/300
 - 17s - loss: 0.2971 - acc: 0.9504 - mDice: 0.7304 - val_loss: 0.5350 - val_acc: 0.9448 - val_mDice: 0.5907

Epoch 00004: val_mDice did not improve from 0.60361
Epoch 5/300
 - 17s - loss: 0.2861 - acc: 0.9518 - mDice: 0.7417 - val_loss: 0.4380 - val_acc: 0.9511 - val_mDice: 0.6354

Epoch 00005: val_mDice improved from 0.60361 to 0.63540, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 18s - loss: 0.2583 - acc: 0.9539 - mDice: 0.7597 - val_loss: 0.4786 - val_acc: 0.9498 - val_mDice: 0.6145

Epoch 00006: val_mDice did not improve from 0.63540
Epoch 7/300
 - 17s - loss: 0.2736 - acc: 0.9529 - mDice: 0.7516 - val_loss: 1.1197 - val_acc: 0.9424 - val_mDice: 0.4849

Epoch 00007: val_mDice did not improve from 0.63540
Epoch 8/300
 - 17s - loss: 0.2851 - acc: 0.9516 - mDice: 0.7405 - val_loss: 0.4392 - val_acc: 0.9523 - val_mDice: 0.6371

Epoch 00008: val_mDice improved from 0.63540 to 0.63708, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 18s - loss: 0.2414 - acc: 0.9558 - mDice: 0.7751 - val_loss: 0.4679 - val_acc: 0.9505 - val_mDice: 0.6192

Epoch 00009: val_mDice did not improve from 0.63708
Epoch 10/300
 - 18s - loss: 0.2411 - acc: 0.9558 - mDice: 0.7741 - val_loss: 0.4526 - val_acc: 0.9544 - val_mDice: 0.6300

Epoch 00010: val_mDice did not improve from 0.63708
Epoch 11/300
 - 18s - loss: 0.2190 - acc: 0.9577 - mDice: 0.7915 - val_loss: 0.4335 - val_acc: 0.9557 - val_mDice: 0.6435

Epoch 00011: val_mDice improved from 0.63708 to 0.64345, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 18s - loss: 0.2185 - acc: 0.9583 - mDice: 0.7957 - val_loss: 0.4565 - val_acc: 0.9510 - val_mDice: 0.6265

Epoch 00012: val_mDice did not improve from 0.64345
Epoch 13/300
 - 18s - loss: 0.2070 - acc: 0.9589 - mDice: 0.8017 - val_loss: 0.4451 - val_acc: 0.9544 - val_mDice: 0.6363

Epoch 00013: val_mDice did not improve from 0.64345
Epoch 14/300
 - 19s - loss: 0.2018 - acc: 0.9595 - mDice: 0.8061 - val_loss: 0.4681 - val_acc: 0.9522 - val_mDice: 0.6209

Epoch 00014: val_mDice did not improve from 0.64345
Epoch 15/300
 - 18s - loss: 0.1994 - acc: 0.9598 - mDice: 0.8083 - val_loss: 0.4662 - val_acc: 0.9537 - val_mDice: 0.6246

Epoch 00015: val_mDice did not improve from 0.64345
Epoch 16/300
 - 18s - loss: 0.1935 - acc: 0.9603 - mDice: 0.8133 - val_loss: 0.5406 - val_acc: 0.9530 - val_mDice: 0.5902

Epoch 00016: val_mDice did not improve from 0.64345
Epoch 17/300
 - 19s - loss: 0.1910 - acc: 0.9606 - mDice: 0.8154 - val_loss: 0.4540 - val_acc: 0.9518 - val_mDice: 0.6297

Epoch 00017: val_mDice did not improve from 0.64345
Epoch 18/300
 - 19s - loss: 0.1876 - acc: 0.9611 - mDice: 0.8195 - val_loss: 0.4870 - val_acc: 0.9502 - val_mDice: 0.6152

Epoch 00018: val_mDice did not improve from 0.64345
Epoch 19/300
 - 19s - loss: 0.1947 - acc: 0.9603 - mDice: 0.8125 - val_loss: 2.3188 - val_acc: 0.9330 - val_mDice: 0.3107

Epoch 00019: val_mDice did not improve from 0.64345
Epoch 20/300
 - 18s - loss: 0.2548 - acc: 0.9543 - mDice: 0.7664 - val_loss: 0.4969 - val_acc: 0.9461 - val_mDice: 0.6040

Epoch 00020: val_mDice did not improve from 0.64345
Epoch 21/300
 - 18s - loss: 0.2096 - acc: 0.9587 - mDice: 0.7998 - val_loss: 0.4520 - val_acc: 0.9540 - val_mDice: 0.6313

Epoch 00021: val_mDice did not improve from 0.64345
Epoch 22/300
 - 19s - loss: 0.1903 - acc: 0.9606 - mDice: 0.8159 - val_loss: 0.4438 - val_acc: 0.9534 - val_mDice: 0.6347

Epoch 00022: val_mDice did not improve from 0.64345
Epoch 23/300
 - 19s - loss: 0.1870 - acc: 0.9612 - mDice: 0.8206 - val_loss: 0.4834 - val_acc: 0.9506 - val_mDice: 0.6116

Epoch 00023: val_mDice did not improve from 0.64345
Epoch 24/300
 - 19s - loss: 0.2101 - acc: 0.9590 - mDice: 0.7994 - val_loss: 0.4508 - val_acc: 0.9518 - val_mDice: 0.6303

Epoch 00024: val_mDice did not improve from 0.64345
Epoch 25/300
 - 19s - loss: 0.1931 - acc: 0.9609 - mDice: 0.8174 - val_loss: 0.6100 - val_acc: 0.9460 - val_mDice: 0.5555

Epoch 00025: val_mDice did not improve from 0.64345
Epoch 26/300
 - 19s - loss: 0.2337 - acc: 0.9567 - mDice: 0.7814 - val_loss: 0.4427 - val_acc: 0.9539 - val_mDice: 0.6354

Epoch 00026: val_mDice did not improve from 0.64345
Epoch 27/300
 - 19s - loss: 0.1890 - acc: 0.9608 - mDice: 0.8171 - val_loss: 0.4367 - val_acc: 0.9546 - val_mDice: 0.6404

Epoch 00027: val_mDice did not improve from 0.64345
Epoch 28/300
 - 19s - loss: 0.1813 - acc: 0.9616 - mDice: 0.8237 - val_loss: 0.4443 - val_acc: 0.9548 - val_mDice: 0.6349

Epoch 00028: val_mDice did not improve from 0.64345
Epoch 29/300
 - 19s - loss: 0.1760 - acc: 0.9620 - mDice: 0.8284 - val_loss: 0.4423 - val_acc: 0.9550 - val_mDice: 0.6390

Epoch 00029: val_mDice did not improve from 0.64345
Epoch 30/300
 - 19s - loss: 0.1728 - acc: 0.9623 - mDice: 0.8312 - val_loss: 0.4436 - val_acc: 0.9544 - val_mDice: 0.6372

Epoch 00030: val_mDice did not improve from 0.64345
Epoch 31/300
 - 19s - loss: 0.1717 - acc: 0.9625 - mDice: 0.8323 - val_loss: 0.4443 - val_acc: 0.9537 - val_mDice: 0.6349

Epoch 00031: val_mDice did not improve from 0.64345
Epoch 32/300
 - 19s - loss: 0.1727 - acc: 0.9625 - mDice: 0.8315 - val_loss: 0.4742 - val_acc: 0.9506 - val_mDice: 0.6184

Epoch 00032: val_mDice did not improve from 0.64345
Epoch 33/300
 - 19s - loss: 0.1661 - acc: 0.9631 - mDice: 0.8371 - val_loss: 0.4495 - val_acc: 0.9548 - val_mDice: 0.6344

Epoch 00033: val_mDice did not improve from 0.64345
Epoch 34/300
 - 19s - loss: 0.2059 - acc: 0.9599 - mDice: 0.8091 - val_loss: 0.4561 - val_acc: 0.9534 - val_mDice: 0.6285

Epoch 00034: val_mDice did not improve from 0.64345
Epoch 35/300
 - 19s - loss: 0.1772 - acc: 0.9619 - mDice: 0.8274 - val_loss: 0.4807 - val_acc: 0.9510 - val_mDice: 0.6163

Epoch 00035: val_mDice did not improve from 0.64345
Epoch 36/300
 - 19s - loss: 0.1677 - acc: 0.9628 - mDice: 0.8356 - val_loss: 0.4626 - val_acc: 0.9537 - val_mDice: 0.6286

Epoch 00036: val_mDice did not improve from 0.64345
Epoch 37/300
 - 19s - loss: 0.1683 - acc: 0.9631 - mDice: 0.8372 - val_loss: 0.4963 - val_acc: 0.9527 - val_mDice: 0.6123

Epoch 00037: val_mDice did not improve from 0.64345
Epoch 38/300
 - 19s - loss: 0.1756 - acc: 0.9625 - mDice: 0.8300 - val_loss: 0.4607 - val_acc: 0.9523 - val_mDice: 0.6243

Epoch 00038: val_mDice did not improve from 0.64345
Epoch 39/300
 - 20s - loss: 0.1662 - acc: 0.9632 - mDice: 0.8373 - val_loss: 0.4598 - val_acc: 0.9545 - val_mDice: 0.6290

Epoch 00039: val_mDice did not improve from 0.64345
Epoch 40/300
 - 20s - loss: 0.1633 - acc: 0.9635 - mDice: 0.8400 - val_loss: 2.3777 - val_acc: 0.9344 - val_mDice: 0.3968

Epoch 00040: val_mDice did not improve from 0.64345
Epoch 41/300
 - 19s - loss: 0.2250 - acc: 0.9578 - mDice: 0.7907 - val_loss: 0.4630 - val_acc: 0.9531 - val_mDice: 0.6246

Epoch 00041: val_mDice did not improve from 0.64345
Epoch 42/300
 - 19s - loss: 0.1752 - acc: 0.9624 - mDice: 0.8293 - val_loss: 0.4387 - val_acc: 0.9540 - val_mDice: 0.6395

Epoch 00042: val_mDice did not improve from 0.64345
Epoch 43/300
 - 19s - loss: 0.1675 - acc: 0.9631 - mDice: 0.8360 - val_loss: 0.4652 - val_acc: 0.9504 - val_mDice: 0.6214

Epoch 00043: val_mDice did not improve from 0.64345
Epoch 44/300
 - 19s - loss: 0.1634 - acc: 0.9635 - mDice: 0.8396 - val_loss: 0.4532 - val_acc: 0.9520 - val_mDice: 0.6287

Epoch 00044: val_mDice did not improve from 0.64345
Epoch 45/300
 - 19s - loss: 0.1620 - acc: 0.9637 - mDice: 0.8416 - val_loss: 0.4772 - val_acc: 0.9503 - val_mDice: 0.6160

Epoch 00045: val_mDice did not improve from 0.64345
Epoch 46/300
 - 19s - loss: 0.1594 - acc: 0.9637 - mDice: 0.8432 - val_loss: 0.4480 - val_acc: 0.9522 - val_mDice: 0.6312

Epoch 00046: val_mDice did not improve from 0.64345
Epoch 47/300
 - 19s - loss: 0.1579 - acc: 0.9640 - mDice: 0.8450 - val_loss: 0.4848 - val_acc: 0.9474 - val_mDice: 0.6103

Epoch 00047: val_mDice did not improve from 0.64345
Epoch 48/300
 - 19s - loss: 0.1662 - acc: 0.9629 - mDice: 0.8372 - val_loss: 0.4582 - val_acc: 0.9529 - val_mDice: 0.6266

Epoch 00048: val_mDice did not improve from 0.64345
Epoch 49/300
 - 19s - loss: 0.1574 - acc: 0.9640 - mDice: 0.8454 - val_loss: 0.4725 - val_acc: 0.9504 - val_mDice: 0.6157

Epoch 00049: val_mDice did not improve from 0.64345
Epoch 50/300
 - 19s - loss: 0.1556 - acc: 0.9641 - mDice: 0.8466 - val_loss: 0.4478 - val_acc: 0.9519 - val_mDice: 0.6319

Epoch 00050: val_mDice did not improve from 0.64345
Epoch 51/300
 - 19s - loss: 0.1538 - acc: 0.9643 - mDice: 0.8482 - val_loss: 0.4476 - val_acc: 0.9536 - val_mDice: 0.6325

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:13,  3.31s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:09,  3.02s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.80s/it]predicting test subjects:  80%|████████  | 4/5 [00:10<00:02,  2.60s/it]predicting test subjects: 100%|██████████| 5/5 [00:12<00:00,  2.65s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:12,  3.22s/it]predicting train subjects:   1%|          | 2/266 [00:06<13:53,  3.16s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:53,  2.94s/it]predicting train subjects:   2%|▏         | 4/266 [00:10<11:52,  2.72s/it]predicting train subjects:   2%|▏         | 5/266 [00:13<12:07,  2.79s/it]predicting train subjects:   2%|▏         | 6/266 [00:16<12:26,  2.87s/it]predicting train subjects:   3%|▎         | 7/266 [00:19<12:29,  2.89s/it]predicting train subjects:   3%|▎         | 8/266 [00:22<12:46,  2.97s/it]predicting train subjects:   3%|▎         | 9/266 [00:26<13:12,  3.08s/it]predicting train subjects:   4%|▍         | 10/266 [00:29<13:22,  3.13s/it]predicting train subjects:   4%|▍         | 11/266 [00:32<13:17,  3.13s/it]predicting train subjects:   5%|▍         | 12/266 [00:35<13:06,  3.10s/it]predicting train subjects:   5%|▍         | 13/266 [00:38<13:02,  3.09s/it]predicting train subjects:   5%|▌         | 14/266 [00:41<13:06,  3.12s/it]predicting train subjects:   6%|▌         | 15/266 [00:45<12:55,  3.09s/it]predicting train subjects:   6%|▌         | 16/266 [00:48<12:51,  3.09s/it]predicting train subjects:   6%|▋         | 17/266 [00:50<12:33,  3.03s/it]predicting train subjects:   7%|▋         | 18/266 [00:54<12:38,  3.06s/it]predicting train subjects:   7%|▋         | 19/266 [00:57<12:39,  3.07s/it]predicting train subjects:   8%|▊         | 20/266 [01:00<12:47,  3.12s/it]predicting train subjects:   8%|▊         | 21/266 [01:03<12:39,  3.10s/it]predicting train subjects:   8%|▊         | 22/266 [01:06<12:19,  3.03s/it]predicting train subjects:   9%|▊         | 23/266 [01:09<12:12,  3.01s/it]predicting train subjects:   9%|▉         | 24/266 [01:12<12:00,  2.98s/it]predicting train subjects:   9%|▉         | 25/266 [01:14<11:40,  2.91s/it]predicting train subjects:  10%|▉         | 26/266 [01:17<11:30,  2.88s/it]predicting train subjects:  10%|█         | 27/266 [01:20<11:31,  2.89s/it]predicting train subjects:  11%|█         | 28/266 [01:23<11:21,  2.86s/it]predicting train subjects:  11%|█         | 29/266 [01:26<11:23,  2.89s/it]predicting train subjects:  11%|█▏        | 30/266 [01:29<11:13,  2.86s/it]predicting train subjects:  12%|█▏        | 31/266 [01:31<11:02,  2.82s/it]predicting train subjects:  12%|█▏        | 32/266 [01:34<10:46,  2.76s/it]predicting train subjects:  12%|█▏        | 33/266 [01:37<10:39,  2.74s/it]predicting train subjects:  13%|█▎        | 34/266 [01:39<10:30,  2.72s/it]predicting train subjects:  13%|█▎        | 35/266 [01:42<10:20,  2.69s/it]predicting train subjects:  14%|█▎        | 36/266 [01:45<10:11,  2.66s/it]predicting train subjects:  14%|█▍        | 37/266 [01:47<10:00,  2.62s/it]predicting train subjects:  14%|█▍        | 38/266 [01:50<10:09,  2.67s/it]predicting train subjects:  15%|█▍        | 39/266 [01:53<10:03,  2.66s/it]predicting train subjects:  15%|█▌        | 40/266 [01:55<09:58,  2.65s/it]predicting train subjects:  15%|█▌        | 41/266 [01:58<09:52,  2.63s/it]predicting train subjects:  16%|█▌        | 42/266 [02:00<09:13,  2.47s/it]predicting train subjects:  16%|█▌        | 43/266 [02:02<08:50,  2.38s/it]predicting train subjects:  17%|█▋        | 44/266 [02:04<08:34,  2.32s/it]predicting train subjects:  17%|█▋        | 45/266 [02:06<08:21,  2.27s/it]predicting train subjects:  17%|█▋        | 46/266 [02:09<08:07,  2.21s/it]predicting train subjects:  18%|█▊        | 47/266 [02:11<08:04,  2.21s/it]predicting train subjects:  18%|█▊        | 48/266 [02:13<08:00,  2.20s/it]predicting train subjects:  18%|█▊        | 49/266 [02:15<07:59,  2.21s/it]predicting train subjects:  19%|█▉        | 50/266 [02:17<07:54,  2.20s/it]predicting train subjects:  19%|█▉        | 51/266 [02:19<07:49,  2.18s/it]predicting train subjects:  20%|█▉        | 52/266 [02:22<07:45,  2.18s/it]predicting train subjects:  20%|█▉        | 53/266 [02:24<07:43,  2.18s/it]predicting train subjects:  20%|██        | 54/266 [02:26<07:40,  2.17s/it]predicting train subjects:  21%|██        | 55/266 [02:28<07:40,  2.18s/it]predicting train subjects:  21%|██        | 56/266 [02:30<07:43,  2.21s/it]predicting train subjects:  21%|██▏       | 57/266 [02:33<07:40,  2.21s/it]predicting train subjects:  22%|██▏       | 58/266 [02:35<07:37,  2.20s/it]predicting train subjects:  22%|██▏       | 59/266 [02:37<07:35,  2.20s/it]predicting train subjects:  23%|██▎       | 60/266 [02:39<07:24,  2.16s/it]predicting train subjects:  23%|██▎       | 61/266 [02:41<07:12,  2.11s/it]predicting train subjects:  23%|██▎       | 62/266 [02:43<07:02,  2.07s/it]predicting train subjects:  24%|██▎       | 63/266 [02:45<06:53,  2.04s/it]predicting train subjects:  24%|██▍       | 64/266 [02:47<06:46,  2.01s/it]predicting train subjects:  24%|██▍       | 65/266 [02:49<06:41,  2.00s/it]predicting train subjects:  25%|██▍       | 66/266 [02:51<06:35,  1.98s/it]predicting train subjects:  25%|██▌       | 67/266 [02:53<06:31,  1.97s/it]predicting train subjects:  26%|██▌       | 68/266 [02:55<06:31,  1.98s/it]predicting train subjects:  26%|██▌       | 69/266 [02:57<06:26,  1.96s/it]predicting train subjects:  26%|██▋       | 70/266 [02:59<06:29,  1.99s/it]predicting train subjects:  27%|██▋       | 71/266 [03:01<06:29,  2.00s/it]predicting train subjects:  27%|██▋       | 72/266 [03:03<06:24,  1.98s/it]predicting train subjects:  27%|██▋       | 73/266 [03:05<06:20,  1.97s/it]predicting train subjects:  28%|██▊       | 74/266 [03:07<06:21,  1.99s/it]predicting train subjects:  28%|██▊       | 75/266 [03:09<06:14,  1.96s/it]predicting train subjects:  29%|██▊       | 76/266 [03:11<06:12,  1.96s/it]predicting train subjects:  29%|██▉       | 77/266 [03:13<06:11,  1.96s/it]predicting train subjects:  29%|██▉       | 78/266 [03:15<06:46,  2.16s/it]predicting train subjects:  30%|██▉       | 79/266 [03:18<07:07,  2.28s/it]predicting train subjects:  30%|███       | 80/266 [03:20<07:21,  2.37s/it]predicting train subjects:  30%|███       | 81/266 [03:23<07:32,  2.44s/it]predicting train subjects:  31%|███       | 82/266 [03:26<07:37,  2.48s/it]predicting train subjects:  31%|███       | 83/266 [03:28<07:38,  2.51s/it]predicting train subjects:  32%|███▏      | 84/266 [03:31<07:43,  2.55s/it]predicting train subjects:  32%|███▏      | 85/266 [03:33<07:43,  2.56s/it]predicting train subjects:  32%|███▏      | 86/266 [03:36<07:41,  2.56s/it]predicting train subjects:  33%|███▎      | 87/266 [03:39<07:44,  2.59s/it]predicting train subjects:  33%|███▎      | 88/266 [03:41<07:40,  2.59s/it]predicting train subjects:  33%|███▎      | 89/266 [03:44<07:40,  2.60s/it]predicting train subjects:  34%|███▍      | 90/266 [03:46<07:38,  2.60s/it]predicting train subjects:  34%|███▍      | 91/266 [03:49<07:33,  2.59s/it]predicting train subjects:  35%|███▍      | 92/266 [03:51<07:29,  2.58s/it]predicting train subjects:  35%|███▍      | 93/266 [03:54<07:23,  2.56s/it]predicting train subjects:  35%|███▌      | 94/266 [03:57<07:21,  2.57s/it]predicting train subjects:  36%|███▌      | 95/266 [03:59<07:15,  2.55s/it]predicting train subjects:  36%|███▌      | 96/266 [04:01<06:57,  2.45s/it]predicting train subjects:  36%|███▋      | 97/266 [04:04<07:02,  2.50s/it]predicting train subjects:  37%|███▋      | 98/266 [04:06<07:00,  2.50s/it]predicting train subjects:  37%|███▋      | 99/266 [04:08<06:24,  2.30s/it]predicting train subjects:  38%|███▊      | 100/266 [04:10<06:10,  2.23s/it]predicting train subjects:  38%|███▊      | 101/266 [04:13<06:10,  2.25s/it]predicting train subjects:  38%|███▊      | 102/266 [04:15<06:04,  2.22s/it]predicting train subjects:  39%|███▊      | 103/266 [04:17<06:01,  2.22s/it]predicting train subjects:  39%|███▉      | 104/266 [04:19<06:05,  2.25s/it]predicting train subjects:  39%|███▉      | 105/266 [04:22<06:04,  2.26s/it]predicting train subjects:  40%|███▉      | 106/266 [04:24<06:02,  2.26s/it]predicting train subjects:  40%|████      | 107/266 [04:26<06:01,  2.27s/it]predicting train subjects:  41%|████      | 108/266 [04:28<06:00,  2.28s/it]predicting train subjects:  41%|████      | 109/266 [04:31<05:56,  2.27s/it]predicting train subjects:  41%|████▏     | 110/266 [04:33<05:54,  2.28s/it]predicting train subjects:  42%|████▏     | 111/266 [04:35<05:51,  2.27s/it]predicting train subjects:  42%|████▏     | 112/266 [04:37<05:47,  2.26s/it]predicting train subjects:  42%|████▏     | 113/266 [04:40<05:45,  2.25s/it]predicting train subjects:  43%|████▎     | 114/266 [04:42<05:42,  2.25s/it]predicting train subjects:  43%|████▎     | 115/266 [04:44<05:38,  2.24s/it]predicting train subjects:  44%|████▎     | 116/266 [04:46<05:35,  2.24s/it]predicting train subjects:  44%|████▍     | 117/266 [04:49<05:35,  2.25s/it]predicting train subjects:  44%|████▍     | 118/266 [04:51<05:35,  2.26s/it]predicting train subjects:  45%|████▍     | 119/266 [04:54<05:50,  2.38s/it]predicting train subjects:  45%|████▌     | 120/266 [04:56<05:56,  2.44s/it]predicting train subjects:  45%|████▌     | 121/266 [04:59<06:00,  2.48s/it]predicting train subjects:  46%|████▌     | 122/266 [05:01<06:04,  2.53s/it]predicting train subjects:  46%|████▌     | 123/266 [05:04<06:09,  2.58s/it]predicting train subjects:  47%|████▋     | 124/266 [05:07<06:08,  2.60s/it]predicting train subjects:  47%|████▋     | 125/266 [05:09<06:04,  2.58s/it]predicting train subjects:  47%|████▋     | 126/266 [05:12<05:59,  2.57s/it]predicting train subjects:  48%|████▊     | 127/266 [05:14<05:58,  2.58s/it]predicting train subjects:  48%|████▊     | 128/266 [05:17<05:57,  2.59s/it]predicting train subjects:  48%|████▊     | 129/266 [05:20<05:54,  2.59s/it]predicting train subjects:  49%|████▉     | 130/266 [05:22<05:52,  2.59s/it]predicting train subjects:  49%|████▉     | 131/266 [05:25<05:50,  2.59s/it]predicting train subjects:  50%|████▉     | 132/266 [05:27<05:46,  2.59s/it]predicting train subjects:  50%|█████     | 133/266 [05:30<05:43,  2.59s/it]predicting train subjects:  50%|█████     | 134/266 [05:33<05:43,  2.61s/it]predicting train subjects:  51%|█████     | 135/266 [05:35<05:42,  2.61s/it]predicting train subjects:  51%|█████     | 136/266 [05:38<05:38,  2.60s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:40<05:31,  2.57s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:43<05:26,  2.55s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:45<05:20,  2.53s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:48<05:18,  2.52s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:50<05:16,  2.53s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:53<05:13,  2.52s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:55<05:09,  2.51s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:58<05:08,  2.53s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:00<05:04,  2.52s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:03<05:00,  2.51s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:06<05:01,  2.53s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:08<04:57,  2.52s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:11<04:53,  2.51s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:13<04:51,  2.51s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:16<04:50,  2.53s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:18<04:48,  2.53s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:21<04:44,  2.52s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:23<04:43,  2.53s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:25<04:17,  2.32s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:27<03:58,  2.17s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:29<03:44,  2.06s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:31<03:36,  2.01s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:32<03:29,  1.96s/it]predicting train subjects:  60%|██████    | 160/266 [06:34<03:23,  1.92s/it]predicting train subjects:  61%|██████    | 161/266 [06:36<03:18,  1.90s/it]predicting train subjects:  61%|██████    | 162/266 [06:38<03:14,  1.87s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:40<03:13,  1.88s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:42<03:08,  1.85s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:43<03:05,  1.84s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:45<03:03,  1.84s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:47<03:02,  1.85s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:49<03:01,  1.85s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:51<02:59,  1.85s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:53<02:57,  1.85s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:54<02:55,  1.85s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:56<02:55,  1.87s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:58<02:58,  1.92s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:00<02:59,  1.96s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:02<02:59,  1.98s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:05<02:59,  2.00s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:07<02:57,  2.00s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:09<02:57,  2.01s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:11<02:54,  2.00s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:13<02:54,  2.02s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:15<02:53,  2.05s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:17<02:49,  2.02s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:19<02:46,  2.01s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:21<02:44,  2.01s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:23<02:40,  1.99s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:25<02:39,  1.99s/it]predicting train subjects:  70%|███████   | 187/266 [07:27<02:38,  2.01s/it]predicting train subjects:  71%|███████   | 188/266 [07:29<02:36,  2.00s/it]predicting train subjects:  71%|███████   | 189/266 [07:31<02:35,  2.01s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:33<02:32,  2.00s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:35<02:35,  2.08s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:37<02:30,  2.03s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:39<02:27,  2.02s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:41<02:36,  2.18s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:44<02:34,  2.17s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:46<02:33,  2.19s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:48<02:30,  2.18s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:50<02:28,  2.18s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:52<02:28,  2.22s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:55<02:26,  2.21s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:57<02:23,  2.21s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:59<02:21,  2.21s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:01<02:18,  2.19s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:03<02:15,  2.19s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:06<02:12,  2.18s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:08<02:10,  2.17s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:10<02:08,  2.17s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:12<02:06,  2.18s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:14<02:03,  2.17s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:16<02:01,  2.16s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:19<01:59,  2.17s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:21<01:56,  2.17s/it]predicting train subjects:  80%|████████  | 213/266 [08:23<01:53,  2.14s/it]predicting train subjects:  80%|████████  | 214/266 [08:25<01:47,  2.07s/it]predicting train subjects:  81%|████████  | 215/266 [08:27<01:43,  2.03s/it]predicting train subjects:  81%|████████  | 216/266 [08:29<01:39,  2.00s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:31<01:38,  2.00s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:32<01:35,  1.98s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:34<01:33,  1.99s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:36<01:30,  1.97s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:38<01:29,  1.98s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:40<01:27,  2.00s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:42<01:25,  1.98s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:44<01:22,  1.96s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:46<01:20,  1.95s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:48<01:17,  1.95s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:50<01:14,  1.92s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:52<01:13,  1.93s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:54<01:12,  1.95s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:56<01:11,  1.97s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:58<01:09,  1.98s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:00<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:02<01:05,  1.98s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:04<01:03,  1.98s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:06<01:00,  1.97s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:08<00:58,  1.96s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:10<00:56,  1.95s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:12<00:54,  1.96s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:14<00:52,  1.96s/it]predicting train subjects:  90%|█████████ | 240/266 [09:16<00:50,  1.94s/it]predicting train subjects:  91%|█████████ | 241/266 [09:18<00:48,  1.95s/it]predicting train subjects:  91%|█████████ | 242/266 [09:20<00:46,  1.95s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:21<00:44,  1.96s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:23<00:43,  1.96s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:25<00:41,  1.97s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:27<00:39,  1.95s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:29<00:36,  1.95s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:31<00:35,  1.95s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:34<00:36,  2.13s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:36<00:36,  2.25s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:39<00:34,  2.32s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:41<00:33,  2.36s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:44<00:31,  2.42s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:46<00:29,  2.45s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:49<00:27,  2.48s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:51<00:24,  2.49s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:54<00:22,  2.50s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:56<00:19,  2.49s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:59<00:17,  2.51s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:02<00:15,  2.52s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:04<00:12,  2.51s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:07<00:10,  2.51s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:09<00:07,  2.50s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:11<00:04,  2.50s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:14<00:02,  2.50s/it]predicting train subjects: 100%|██████████| 266/266 [10:16<00:00,  2.48s/it]

Epoch 00051: val_mDice did not improve from 0.64345
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [0.48722803435827555, 0.5342356374389247, 0.5292352171320664, 0.53502083765833, 0.43797321696030467, 0.4786370208388881, 1.1197176763885899, 0.4391622809987319, 0.4678790945755808, 0.4525885660397379, 0.4335176003606696, 0.4564889277282514, 0.4451103947664562, 0.4681354761123657, 0.46623750579984563, 0.5405502585988295, 0.4540187136123055, 0.4870352603887257, 2.318762697671589, 0.49685645574017573, 0.4519745676141036, 0.44376940946829946, 0.4833702884222332, 0.4507502772306141, 0.6100422175307023, 0.44270651434597214, 0.4366930597706845, 0.44430486152046605, 0.4422749798548849, 0.4436028050748925, 0.4443327470829612, 0.47415578679034587, 0.44946033860507767, 0.45609210039439957, 0.48074297999080856, 0.462550130329634, 0.4962717294692993, 0.4607224354618474, 0.45984055023444326, 2.377669312452015, 0.4629692262724826, 0.43873843864390727, 0.46517165240488556, 0.4532308468693181, 0.4771953507473594, 0.4480167407738535, 0.48479535077747543, 0.4581565354999743, 0.47246171769342926, 0.44776463508605957, 0.44757900426262304], 'val_acc': [0.9484311718689767, 0.947815455888447, 0.9481359563375774, 0.9447549016852128, 0.9511470951532063, 0.9497553800281725, 0.9424004680231998, 0.9522833510449058, 0.9505000490891305, 0.9543931923414531, 0.9556981576116461, 0.9509868402230112, 0.9543546344104566, 0.9522435884726675, 0.9537461400032043, 0.9530304042916549, 0.9518110156059265, 0.9501951901536239, 0.9329983748887715, 0.9460911844906054, 0.954037744747965, 0.9534183928841039, 0.9505723463861566, 0.9517712624449479, 0.9459743029192874, 0.953918435071644, 0.9546450313768888, 0.9547980584596333, 0.9550028913899472, 0.9544245130137393, 0.9536967371639452, 0.9506048779738577, 0.9547932273463199, 0.9533858644334894, 0.9509699721085397, 0.9537437369948939, 0.9527436463456405, 0.9523291525087858, 0.9544570508756136, 0.934374401443883, 0.9530810086350692, 0.9540196751293383, 0.9503711085570486, 0.9520038178092555, 0.9503229291815507, 0.9522423838314257, 0.947396130938279, 0.9529014794450057, 0.9504253362354479, 0.9518869299637643, 0.9536328849039579], 'val_mDice': [0.6036069581383153, 0.5903071227826571, 0.5859095313047108, 0.5907114744186401, 0.6353994325587624, 0.6145487490453219, 0.4848761966353969, 0.6370782852172852, 0.6192014217376709, 0.6299814738725361, 0.6434515840128848, 0.6264900690630862, 0.6362928277567813, 0.6208708850960982, 0.624559157773068, 0.5901650002128199, 0.6297059435593454, 0.6152127008689078, 0.3106536849548942, 0.6039617751774035, 0.6312778341142755, 0.6347283846453616, 0.6116111560871726, 0.6302726237397445, 0.5554808660557395, 0.6354096061304996, 0.640415608882904, 0.6348870302501478, 0.6389975422307065, 0.6372488360655936, 0.6349047642005118, 0.618355111071938, 0.6344261890963504, 0.628491809493617, 0.6162934867959273, 0.6285907030105591, 0.6122644073084781, 0.6243264800623843, 0.6290387668107685, 0.39683541812394796, 0.6246198917690077, 0.639496878573769, 0.62141762281719, 0.6287403577252438, 0.6160192458253158, 0.6311675466989216, 0.6102511067139474, 0.626579645432924, 0.6157333286185014, 0.6319059259013126, 0.6324769666320399], 'loss': [1.2956239102455975, 0.41373317989270014, 0.33588248943292975, 0.29713004795708703, 0.2860578652138947, 0.2583355676553294, 0.2736473680814169, 0.2850709308612199, 0.2414252475435832, 0.24111939574786173, 0.21897913245057948, 0.2185358759868367, 0.20697378833063634, 0.2018479461918236, 0.19935168501038805, 0.19352912350830132, 0.19096666814064314, 0.18758710587933325, 0.19466031379737625, 0.2547662189220208, 0.20959977551288989, 0.19028166153224704, 0.18697362983291513, 0.21011193179293508, 0.19310016476363523, 0.23373489269713638, 0.18904770611618452, 0.1813023283043002, 0.17600756290291428, 0.17282920683928477, 0.17165294917310459, 0.17266816778514532, 0.16610576082642362, 0.20587214026701275, 0.17720334043999436, 0.16774791810600864, 0.16829062632412944, 0.17560801568352224, 0.16621529996175466, 0.16330278289697261, 0.2250240671082094, 0.1752043226697678, 0.16748656000713677, 0.16342939289909542, 0.1619651762377023, 0.15942961479269135, 0.15789986840218792, 0.1661909848070126, 0.15744369033409053, 0.15560188609456443, 0.1537852577974946], 'acc': [0.8104271724678525, 0.940357569787186, 0.9469177930206176, 0.9503562571097937, 0.9517727744981612, 0.9539336987342643, 0.9529305183327965, 0.9516137478377488, 0.9557837363219798, 0.9558122438502182, 0.9576942964498159, 0.9582786504916205, 0.9588775050279427, 0.95948073003207, 0.959822049336992, 0.9603007739948801, 0.9606410938353387, 0.9610621357745585, 0.9602553029338735, 0.9543198406973765, 0.9587065338787873, 0.9606357230591719, 0.9612197192650234, 0.9589766986130558, 0.9608877687906461, 0.956722579289537, 0.9607588048009932, 0.961558397862225, 0.9620012203975645, 0.9623291099529289, 0.9625401289496337, 0.9624880010809799, 0.9630683621549162, 0.9599212902150845, 0.961867125449114, 0.9628498357127487, 0.9630705805898545, 0.9625296058397685, 0.9632006585366787, 0.9635092517009902, 0.9577571487038333, 0.9624202440675605, 0.9630620338779905, 0.9634999722542922, 0.9637076640841201, 0.9637411645533411, 0.964010131715156, 0.9628501916412608, 0.9639745216507427, 0.9641442493216948, 0.9643442588804118], 'mDice': [0.39935253970498397, 0.6479237876699543, 0.7008851363364812, 0.730394449353773, 0.7417144016922677, 0.7596762493611122, 0.7516342323010424, 0.7404943017117084, 0.7750636644609405, 0.7740656017124237, 0.7915248662418317, 0.7956722356997505, 0.8017328545809532, 0.8060510377952348, 0.8083249769694496, 0.8133359032952573, 0.8154416075503761, 0.8194665328835775, 0.8124955527952608, 0.7663945077670647, 0.7997825138900888, 0.8159332711327622, 0.8206356883719506, 0.7994443512268081, 0.8174394049253272, 0.7813781174788464, 0.8170530141047306, 0.8237360574021831, 0.8283887945861202, 0.8312020143790242, 0.8323173310356237, 0.8315261993022554, 0.8371488490684538, 0.8090751154927712, 0.8273524833197183, 0.8356384531969798, 0.8371856358390709, 0.8299844250187012, 0.8372585879244298, 0.8399974346808262, 0.790676849886278, 0.8292988351697234, 0.8360188478319288, 0.8396293377233532, 0.8415853040476378, 0.8431656505476143, 0.8449526811242566, 0.8371864815753407, 0.8454142884402611, 0.846618533666232, 0.8482370281677268]}
