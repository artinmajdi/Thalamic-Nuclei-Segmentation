2019-07-10 20:16:52.609234: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-10 20:16:55.999607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-10 20:16:55.999691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:16:56.398840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:16:56.398914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:16:56.398927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:16:56.399391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:10,  1.94s/it]Loading train:   1%|          | 2/285 [00:03<08:11,  1.74s/it]Loading train:   1%|          | 3/285 [00:04<07:35,  1.61s/it]Loading train:   1%|▏         | 4/285 [00:05<07:05,  1.52s/it]Loading train:   2%|▏         | 5/285 [00:07<07:31,  1.61s/it]Loading train:   2%|▏         | 6/285 [00:08<06:50,  1.47s/it]Loading train:   2%|▏         | 7/285 [00:10<06:52,  1.48s/it]Loading train:   3%|▎         | 8/285 [00:11<06:34,  1.43s/it]Loading train:   3%|▎         | 9/285 [00:13<07:20,  1.60s/it]Loading train:   4%|▎         | 10/285 [00:14<06:47,  1.48s/it]Loading train:   4%|▍         | 11/285 [00:15<06:02,  1.32s/it]Loading train:   4%|▍         | 12/285 [00:16<05:49,  1.28s/it]Loading train:   5%|▍         | 13/285 [00:17<05:21,  1.18s/it]Loading train:   5%|▍         | 14/285 [00:19<05:19,  1.18s/it]Loading train:   5%|▌         | 15/285 [00:20<05:15,  1.17s/it]Loading train:   6%|▌         | 16/285 [00:21<05:13,  1.17s/it]Loading train:   6%|▌         | 17/285 [00:22<04:56,  1.11s/it]Loading train:   6%|▋         | 18/285 [00:23<04:55,  1.11s/it]Loading train:   7%|▋         | 19/285 [00:24<04:52,  1.10s/it]Loading train:   7%|▋         | 20/285 [00:25<04:53,  1.11s/it]Loading train:   7%|▋         | 21/285 [00:26<05:04,  1.15s/it]Loading train:   8%|▊         | 22/285 [00:27<04:50,  1.10s/it]Loading train:   8%|▊         | 23/285 [00:29<04:54,  1.12s/it]Loading train:   8%|▊         | 24/285 [00:30<04:49,  1.11s/it]Loading train:   9%|▉         | 25/285 [00:31<04:54,  1.13s/it]Loading train:   9%|▉         | 26/285 [00:32<04:52,  1.13s/it]Loading train:   9%|▉         | 27/285 [00:33<04:38,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:34<04:42,  1.10s/it]Loading train:  10%|█         | 29/285 [00:35<04:36,  1.08s/it]Loading train:  11%|█         | 30/285 [00:36<04:43,  1.11s/it]Loading train:  11%|█         | 31/285 [00:37<04:46,  1.13s/it]Loading train:  11%|█         | 32/285 [00:38<04:30,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:34,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:37,  1.11s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:37,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:30,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:43,  1.14s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:49,  1.17s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:39,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:47,  1.17s/it]Loading train:  14%|█▍        | 41/285 [00:49<05:02,  1.24s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:42,  1.16s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:40,  1.16s/it]Loading train:  15%|█▌        | 44/285 [00:53<05:19,  1.33s/it]Loading train:  16%|█▌        | 45/285 [00:54<05:03,  1.27s/it]Loading train:  16%|█▌        | 46/285 [00:55<05:00,  1.26s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:40,  1.18s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:58,  1.26s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:53,  1.24s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:50,  1.23s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:54,  1.26s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:34,  1.18s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:35,  1.19s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:37,  1.20s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:18,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:30,  1.18s/it]Loading train:  20%|██        | 57/285 [01:08<04:14,  1.12s/it]Loading train:  20%|██        | 58/285 [01:09<04:13,  1.12s/it]Loading train:  21%|██        | 59/285 [01:10<04:15,  1.13s/it]Loading train:  21%|██        | 60/285 [01:12<05:20,  1.42s/it]Loading train:  21%|██▏       | 61/285 [01:14<05:26,  1.46s/it]Loading train:  22%|██▏       | 62/285 [01:16<05:29,  1.48s/it]Loading train:  22%|██▏       | 63/285 [01:17<05:49,  1.57s/it]Loading train:  22%|██▏       | 64/285 [01:20<06:27,  1.75s/it]Loading train:  23%|██▎       | 65/285 [01:22<06:58,  1.90s/it]Loading train:  23%|██▎       | 66/285 [01:24<06:51,  1.88s/it]Loading train:  24%|██▎       | 67/285 [01:25<06:18,  1.74s/it]Loading train:  24%|██▍       | 68/285 [01:26<05:51,  1.62s/it]Loading train:  24%|██▍       | 69/285 [01:28<05:55,  1.65s/it]Loading train:  25%|██▍       | 70/285 [01:29<05:34,  1.55s/it]Loading train:  25%|██▍       | 71/285 [01:31<05:20,  1.50s/it]Loading train:  25%|██▌       | 72/285 [01:32<05:30,  1.55s/it]Loading train:  26%|██▌       | 73/285 [01:34<05:39,  1.60s/it]Loading train:  26%|██▌       | 74/285 [01:36<05:24,  1.54s/it]Loading train:  26%|██▋       | 75/285 [01:37<05:10,  1.48s/it]Loading train:  27%|██▋       | 76/285 [01:38<04:55,  1.41s/it]Loading train:  27%|██▋       | 77/285 [01:40<05:04,  1.47s/it]Loading train:  27%|██▋       | 78/285 [01:41<04:31,  1.31s/it]Loading train:  28%|██▊       | 79/285 [01:42<04:26,  1.29s/it]Loading train:  28%|██▊       | 80/285 [01:43<04:14,  1.24s/it]Loading train:  28%|██▊       | 81/285 [01:44<04:03,  1.20s/it]Loading train:  29%|██▉       | 82/285 [01:45<03:56,  1.17s/it]Loading train:  29%|██▉       | 83/285 [01:46<03:54,  1.16s/it]Loading train:  29%|██▉       | 84/285 [01:48<03:52,  1.16s/it]Loading train:  30%|██▉       | 85/285 [01:49<04:31,  1.36s/it]Loading train:  30%|███       | 86/285 [01:51<04:25,  1.34s/it]Loading train:  31%|███       | 87/285 [01:52<04:35,  1.39s/it]Loading train:  31%|███       | 88/285 [01:54<04:34,  1.39s/it]Loading train:  31%|███       | 89/285 [01:55<04:29,  1.38s/it]Loading train:  32%|███▏      | 90/285 [01:56<04:23,  1.35s/it]Loading train:  32%|███▏      | 91/285 [01:57<04:02,  1.25s/it]Loading train:  32%|███▏      | 92/285 [01:58<03:58,  1.24s/it]Loading train:  33%|███▎      | 93/285 [01:59<03:45,  1.18s/it]Loading train:  33%|███▎      | 94/285 [02:01<03:47,  1.19s/it]Loading train:  33%|███▎      | 95/285 [02:02<03:51,  1.22s/it]Loading train:  34%|███▎      | 96/285 [02:03<03:42,  1.18s/it]Loading train:  34%|███▍      | 97/285 [02:04<03:56,  1.26s/it]Loading train:  34%|███▍      | 98/285 [02:06<03:46,  1.21s/it]Loading train:  35%|███▍      | 99/285 [02:07<03:43,  1.20s/it]Loading train:  35%|███▌      | 100/285 [02:08<03:51,  1.25s/it]Loading train:  35%|███▌      | 101/285 [02:09<03:54,  1.28s/it]Loading train:  36%|███▌      | 102/285 [02:11<04:05,  1.34s/it]Loading train:  36%|███▌      | 103/285 [02:12<03:46,  1.25s/it]Loading train:  36%|███▋      | 104/285 [02:13<03:55,  1.30s/it]Loading train:  37%|███▋      | 105/285 [02:15<04:12,  1.40s/it]Loading train:  37%|███▋      | 106/285 [02:16<04:12,  1.41s/it]Loading train:  38%|███▊      | 107/285 [02:18<04:03,  1.37s/it]Loading train:  38%|███▊      | 108/285 [02:19<03:43,  1.26s/it]Loading train:  38%|███▊      | 109/285 [02:20<03:31,  1.20s/it]Loading train:  39%|███▊      | 110/285 [02:21<03:32,  1.22s/it]Loading train:  39%|███▉      | 111/285 [02:23<03:46,  1.30s/it]Loading train:  39%|███▉      | 112/285 [02:24<03:49,  1.33s/it]Loading train:  40%|███▉      | 113/285 [02:25<03:48,  1.33s/it]Loading train:  40%|████      | 114/285 [02:26<03:35,  1.26s/it]Loading train:  40%|████      | 115/285 [02:28<03:30,  1.24s/it]Loading train:  41%|████      | 116/285 [02:29<03:34,  1.27s/it]Loading train:  41%|████      | 117/285 [02:30<03:24,  1.22s/it]Loading train:  41%|████▏     | 118/285 [02:31<03:28,  1.25s/it]Loading train:  42%|████▏     | 119/285 [02:33<03:34,  1.29s/it]Loading train:  42%|████▏     | 120/285 [02:34<03:27,  1.26s/it]Loading train:  42%|████▏     | 121/285 [02:36<03:49,  1.40s/it]Loading train:  43%|████▎     | 122/285 [02:37<03:53,  1.43s/it]Loading train:  43%|████▎     | 123/285 [02:38<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [02:40<03:34,  1.33s/it]Loading train:  44%|████▍     | 125/285 [02:41<03:27,  1.30s/it]Loading train:  44%|████▍     | 126/285 [02:42<03:26,  1.30s/it]Loading train:  45%|████▍     | 127/285 [02:43<03:10,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:44<03:03,  1.17s/it]Loading train:  45%|████▌     | 129/285 [02:45<02:48,  1.08s/it]Loading train:  46%|████▌     | 130/285 [02:46<02:43,  1.06s/it]Loading train:  46%|████▌     | 131/285 [02:47<02:46,  1.08s/it]Loading train:  46%|████▋     | 132/285 [02:48<02:46,  1.09s/it]Loading train:  47%|████▋     | 133/285 [02:49<02:40,  1.06s/it]Loading train:  47%|████▋     | 134/285 [02:51<02:47,  1.11s/it]Loading train:  47%|████▋     | 135/285 [02:51<02:37,  1.05s/it]Loading train:  48%|████▊     | 136/285 [02:52<02:31,  1.02s/it]Loading train:  48%|████▊     | 137/285 [02:53<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:55<02:48,  1.15s/it]Loading train:  49%|████▉     | 139/285 [02:56<02:49,  1.16s/it]Loading train:  49%|████▉     | 140/285 [02:57<02:48,  1.16s/it]Loading train:  49%|████▉     | 141/285 [02:58<02:43,  1.13s/it]Loading train:  50%|████▉     | 142/285 [02:59<02:35,  1.09s/it]Loading train:  50%|█████     | 143/285 [03:00<02:34,  1.09s/it]Loading train:  51%|█████     | 144/285 [03:01<02:29,  1.06s/it]Loading train:  51%|█████     | 145/285 [03:02<02:25,  1.04s/it]Loading train:  51%|█████     | 146/285 [03:03<02:25,  1.05s/it]Loading train:  52%|█████▏    | 147/285 [03:04<02:17,  1.00it/s]Loading train:  52%|█████▏    | 148/285 [03:06<02:32,  1.11s/it]Loading train:  52%|█████▏    | 149/285 [03:07<02:28,  1.09s/it]Loading train:  53%|█████▎    | 150/285 [03:08<02:25,  1.08s/it]Loading train:  53%|█████▎    | 151/285 [03:09<02:25,  1.09s/it]Loading train:  53%|█████▎    | 152/285 [03:10<02:19,  1.05s/it]Loading train:  54%|█████▎    | 153/285 [03:11<02:10,  1.01it/s]Loading train:  54%|█████▍    | 154/285 [03:12<02:16,  1.04s/it]Loading train:  54%|█████▍    | 155/285 [03:13<02:10,  1.00s/it]Loading train:  55%|█████▍    | 156/285 [03:14<02:15,  1.05s/it]Loading train:  55%|█████▌    | 157/285 [03:15<02:17,  1.08s/it]Loading train:  55%|█████▌    | 158/285 [03:16<02:06,  1.00it/s]Loading train:  56%|█████▌    | 159/285 [03:17<02:08,  1.02s/it]Loading train:  56%|█████▌    | 160/285 [03:18<02:02,  1.02it/s]Loading train:  56%|█████▋    | 161/285 [03:19<02:12,  1.07s/it]Loading train:  57%|█████▋    | 162/285 [03:20<02:02,  1.00it/s]Loading train:  57%|█████▋    | 163/285 [03:21<02:10,  1.07s/it]Loading train:  58%|█████▊    | 164/285 [03:22<02:12,  1.10s/it]Loading train:  58%|█████▊    | 165/285 [03:23<02:11,  1.09s/it]Loading train:  58%|█████▊    | 166/285 [03:24<02:08,  1.08s/it]Loading train:  59%|█████▊    | 167/285 [03:25<02:03,  1.05s/it]Loading train:  59%|█████▉    | 168/285 [03:26<01:56,  1.00it/s]Loading train:  59%|█████▉    | 169/285 [03:27<01:51,  1.04it/s]Loading train:  60%|█████▉    | 170/285 [03:28<01:51,  1.03it/s]Loading train:  60%|██████    | 171/285 [03:29<01:47,  1.06it/s]Loading train:  60%|██████    | 172/285 [03:30<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:31<01:53,  1.01s/it]Loading train:  61%|██████    | 174/285 [03:32<01:54,  1.03s/it]Loading train:  61%|██████▏   | 175/285 [03:33<01:55,  1.05s/it]Loading train:  62%|██████▏   | 176/285 [03:35<02:04,  1.15s/it]Loading train:  62%|██████▏   | 177/285 [03:36<01:56,  1.08s/it]Loading train:  62%|██████▏   | 178/285 [03:37<01:55,  1.08s/it]Loading train:  63%|██████▎   | 179/285 [03:38<01:50,  1.04s/it]Loading train:  63%|██████▎   | 180/285 [03:39<01:50,  1.05s/it]Loading train:  64%|██████▎   | 181/285 [03:40<01:57,  1.13s/it]Loading train:  64%|██████▍   | 182/285 [03:41<01:55,  1.12s/it]Loading train:  64%|██████▍   | 183/285 [03:42<01:47,  1.05s/it]Loading train:  65%|██████▍   | 184/285 [03:43<01:43,  1.02s/it]Loading train:  65%|██████▍   | 185/285 [03:44<01:43,  1.04s/it]Loading train:  65%|██████▌   | 186/285 [03:46<01:54,  1.16s/it]Loading train:  66%|██████▌   | 187/285 [03:47<02:04,  1.27s/it]Loading train:  66%|██████▌   | 188/285 [03:49<02:15,  1.40s/it]Loading train:  66%|██████▋   | 189/285 [03:50<02:14,  1.40s/it]Loading train:  67%|██████▋   | 190/285 [03:52<02:15,  1.43s/it]Loading train:  67%|██████▋   | 191/285 [03:53<02:12,  1.41s/it]Loading train:  67%|██████▋   | 192/285 [03:54<02:02,  1.32s/it]Loading train:  68%|██████▊   | 193/285 [03:55<01:56,  1.27s/it]Loading train:  68%|██████▊   | 194/285 [03:57<01:58,  1.30s/it]Loading train:  68%|██████▊   | 195/285 [03:58<01:48,  1.21s/it]Loading train:  69%|██████▉   | 196/285 [03:59<01:53,  1.27s/it]Loading train:  69%|██████▉   | 197/285 [04:00<01:49,  1.24s/it]Loading train:  69%|██████▉   | 198/285 [04:01<01:46,  1.22s/it]Loading train:  70%|██████▉   | 199/285 [04:02<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [04:03<01:34,  1.11s/it]Loading train:  71%|███████   | 201/285 [04:05<01:36,  1.15s/it]Loading train:  71%|███████   | 202/285 [04:06<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [04:07<01:31,  1.11s/it]Loading train:  72%|███████▏  | 204/285 [04:08<01:30,  1.11s/it]Loading train:  72%|███████▏  | 205/285 [04:09<01:29,  1.12s/it]Loading train:  72%|███████▏  | 206/285 [04:10<01:28,  1.12s/it]Loading train:  73%|███████▎  | 207/285 [04:11<01:31,  1.18s/it]Loading train:  73%|███████▎  | 208/285 [04:13<01:30,  1.17s/it]Loading train:  73%|███████▎  | 209/285 [04:14<01:30,  1.19s/it]Loading train:  74%|███████▎  | 210/285 [04:15<01:24,  1.12s/it]Loading train:  74%|███████▍  | 211/285 [04:16<01:19,  1.08s/it]Loading train:  74%|███████▍  | 212/285 [04:17<01:16,  1.05s/it]Loading train:  75%|███████▍  | 213/285 [04:18<01:14,  1.03s/it]Loading train:  75%|███████▌  | 214/285 [04:19<01:12,  1.02s/it]Loading train:  75%|███████▌  | 215/285 [04:20<01:18,  1.12s/it]Loading train:  76%|███████▌  | 216/285 [04:21<01:15,  1.09s/it]Loading train:  76%|███████▌  | 217/285 [04:22<01:16,  1.12s/it]Loading train:  76%|███████▋  | 218/285 [04:24<01:19,  1.19s/it]Loading train:  77%|███████▋  | 219/285 [04:25<01:20,  1.22s/it]Loading train:  77%|███████▋  | 220/285 [04:26<01:17,  1.19s/it]Loading train:  78%|███████▊  | 221/285 [04:27<01:10,  1.10s/it]Loading train:  78%|███████▊  | 222/285 [04:29<01:18,  1.24s/it]Loading train:  78%|███████▊  | 223/285 [04:30<01:14,  1.20s/it]Loading train:  79%|███████▊  | 224/285 [04:31<01:11,  1.17s/it]Loading train:  79%|███████▉  | 225/285 [04:32<01:07,  1.13s/it]Loading train:  79%|███████▉  | 226/285 [04:33<01:09,  1.18s/it]Loading train:  80%|███████▉  | 227/285 [04:35<01:15,  1.30s/it]Loading train:  80%|████████  | 228/285 [04:36<01:10,  1.24s/it]Loading train:  80%|████████  | 229/285 [04:37<01:10,  1.25s/it]Loading train:  81%|████████  | 230/285 [04:38<01:06,  1.20s/it]Loading train:  81%|████████  | 231/285 [04:39<01:02,  1.17s/it]Loading train:  81%|████████▏ | 232/285 [04:40<01:03,  1.20s/it]Loading train:  82%|████████▏ | 233/285 [04:42<01:00,  1.17s/it]Loading train:  82%|████████▏ | 234/285 [04:43<01:05,  1.28s/it]Loading train:  82%|████████▏ | 235/285 [04:44<01:04,  1.29s/it]Loading train:  83%|████████▎ | 236/285 [04:46<01:02,  1.28s/it]Loading train:  83%|████████▎ | 237/285 [04:47<01:02,  1.30s/it]Loading train:  84%|████████▎ | 238/285 [04:48<01:01,  1.30s/it]Loading train:  84%|████████▍ | 239/285 [04:49<00:56,  1.23s/it]Loading train:  84%|████████▍ | 240/285 [04:51<00:58,  1.30s/it]Loading train:  85%|████████▍ | 241/285 [04:52<00:53,  1.22s/it]Loading train:  85%|████████▍ | 242/285 [04:53<00:52,  1.22s/it]Loading train:  85%|████████▌ | 243/285 [04:54<00:50,  1.20s/it]Loading train:  86%|████████▌ | 244/285 [04:56<00:52,  1.28s/it]Loading train:  86%|████████▌ | 245/285 [04:57<00:46,  1.17s/it]Loading train:  86%|████████▋ | 246/285 [04:58<00:45,  1.16s/it]Loading train:  87%|████████▋ | 247/285 [04:59<00:42,  1.13s/it]Loading train:  87%|████████▋ | 248/285 [05:00<00:41,  1.13s/it]Loading train:  87%|████████▋ | 249/285 [05:01<00:37,  1.05s/it]Loading train:  88%|████████▊ | 250/285 [05:02<00:36,  1.05s/it]Loading train:  88%|████████▊ | 251/285 [05:03<00:34,  1.00s/it]Loading train:  88%|████████▊ | 252/285 [05:04<00:32,  1.01it/s]Loading train:  89%|████████▉ | 253/285 [05:05<00:37,  1.17s/it]Loading train:  89%|████████▉ | 254/285 [05:07<00:38,  1.23s/it]Loading train:  89%|████████▉ | 255/285 [05:08<00:39,  1.31s/it]Loading train:  90%|████████▉ | 256/285 [05:09<00:35,  1.23s/it]Loading train:  90%|█████████ | 257/285 [05:10<00:34,  1.23s/it]Loading train:  91%|█████████ | 258/285 [05:12<00:35,  1.30s/it]Loading train:  91%|█████████ | 259/285 [05:13<00:33,  1.28s/it]Loading train:  91%|█████████ | 260/285 [05:14<00:28,  1.15s/it]Loading train:  92%|█████████▏| 261/285 [05:15<00:27,  1.13s/it]Loading train:  92%|█████████▏| 262/285 [05:16<00:25,  1.13s/it]Loading train:  92%|█████████▏| 263/285 [05:17<00:24,  1.13s/it]Loading train:  93%|█████████▎| 264/285 [05:19<00:25,  1.21s/it]Loading train:  93%|█████████▎| 265/285 [05:20<00:25,  1.27s/it]Loading train:  93%|█████████▎| 266/285 [05:21<00:22,  1.17s/it]Loading train:  94%|█████████▎| 267/285 [05:22<00:20,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [05:23<00:20,  1.18s/it]Loading train:  94%|█████████▍| 269/285 [05:24<00:18,  1.14s/it]Loading train:  95%|█████████▍| 270/285 [05:25<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [05:26<00:15,  1.09s/it]Loading train:  95%|█████████▌| 272/285 [05:28<00:14,  1.09s/it]Loading train:  96%|█████████▌| 273/285 [05:29<00:12,  1.05s/it]Loading train:  96%|█████████▌| 274/285 [05:29<00:10,  1.00it/s]Loading train:  96%|█████████▋| 275/285 [05:31<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [05:32<00:10,  1.14s/it]Loading train:  97%|█████████▋| 277/285 [05:33<00:08,  1.11s/it]Loading train:  98%|█████████▊| 278/285 [05:34<00:07,  1.12s/it]Loading train:  98%|█████████▊| 279/285 [05:35<00:06,  1.12s/it]Loading train:  98%|█████████▊| 280/285 [05:36<00:05,  1.11s/it]Loading train:  99%|█████████▊| 281/285 [05:37<00:04,  1.02s/it]Loading train:  99%|█████████▉| 282/285 [05:38<00:02,  1.02it/s]Loading train:  99%|█████████▉| 283/285 [05:39<00:02,  1.08s/it]Loading train: 100%|█████████▉| 284/285 [05:41<00:01,  1.11s/it]Loading train: 100%|██████████| 285/285 [05:42<00:00,  1.18s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:17, 16.63it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:15, 18.08it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:14, 19.73it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:12, 22.33it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:10, 26.27it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:08, 29.76it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:07, 32.55it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:07, 35.43it/s]concatenating: train:  14%|█▍        | 40/285 [00:01<00:05, 41.48it/s]concatenating: train:  16%|█▋        | 47/285 [00:01<00:05, 46.13it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:04, 50.07it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:04, 52.76it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:03, 55.88it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:03, 55.17it/s]concatenating: train:  30%|██▉       | 85/285 [00:01<00:03, 64.37it/s]concatenating: train:  34%|███▍      | 97/285 [00:01<00:02, 74.76it/s]concatenating: train:  38%|███▊      | 109/285 [00:01<00:02, 81.62it/s]concatenating: train:  42%|████▏     | 119/285 [00:02<00:02, 80.46it/s]concatenating: train:  46%|████▋     | 132/285 [00:02<00:01, 90.09it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:01, 98.33it/s]concatenating: train:  55%|█████▍    | 156/285 [00:02<00:01, 94.35it/s]concatenating: train:  59%|█████▊    | 167/285 [00:02<00:01, 84.79it/s]concatenating: train:  63%|██████▎   | 180/285 [00:02<00:01, 92.33it/s]concatenating: train:  67%|██████▋   | 190/285 [00:02<00:01, 83.93it/s]concatenating: train:  71%|███████   | 201/285 [00:02<00:00, 89.48it/s]concatenating: train:  74%|███████▍  | 211/285 [00:03<00:00, 74.34it/s]concatenating: train:  77%|███████▋  | 220/285 [00:03<00:00, 70.27it/s]concatenating: train:  80%|████████  | 229/285 [00:03<00:00, 73.06it/s]concatenating: train:  83%|████████▎ | 237/285 [00:03<00:00, 73.27it/s]concatenating: train:  86%|████████▌ | 245/285 [00:03<00:00, 68.36it/s]concatenating: train:  89%|████████▉ | 253/285 [00:03<00:00, 69.18it/s]concatenating: train:  92%|█████████▏| 262/285 [00:03<00:00, 72.27it/s]concatenating: train:  95%|█████████▍| 270/285 [00:04<00:00, 62.55it/s]concatenating: train:  98%|█████████▊| 279/285 [00:04<00:00, 66.94it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 67.40it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.73s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 48.26it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.49it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:01<00:14,  2.79it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:14,  2.70it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:02<00:09,  3.66it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:02<00:09,  3.80it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:06,  4.77it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:06,  4.85it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.42it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:03<00:03,  6.98it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:03,  6.06it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  7.76it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:04,  3.78it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:05<00:05,  2.88it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  3.64it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:06<00:03,  3.38it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:02,  4.42it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  5.33it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  4.53it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:00,  5.11it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:08<00:01,  1.98it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:08<00:00,  5.30it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 127,968
Trainable params: 29,488
Non-trainable params: 98,480
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 17s - loss: 3.0251 - acc: 0.5835 - mDice: 0.0738 - val_loss: 2.2833 - val_acc: 0.8782 - val_mDice: 0.2097

Epoch 00001: val_mDice improved from -inf to 0.20972, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 7s - loss: 1.1945 - acc: 0.8760 - mDice: 0.3095 - val_loss: 1.3784 - val_acc: 0.9131 - val_mDice: 0.4423

Epoch 00002: val_mDice improved from 0.20972 to 0.44231, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 7s - loss: 0.7515 - acc: 0.8845 - mDice: 0.4550 - val_loss: 1.1735 - val_acc: 0.9173 - val_mDice: 0.5221

Epoch 00003: val_mDice improved from 0.44231 to 0.52210, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 7s - loss: 0.6268 - acc: 0.8878 - mDice: 0.5175 - val_loss: 1.1057 - val_acc: 0.9160 - val_mDice: 0.5415

Epoch 00004: val_mDice improved from 0.52210 to 0.54150, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 7s - loss: 0.5723 - acc: 0.8897 - mDice: 0.5480 - val_loss: 1.0356 - val_acc: 0.9188 - val_mDice: 0.5491

Epoch 00005: val_mDice improved from 0.54150 to 0.54908, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.5332 - acc: 0.8917 - mDice: 0.5711 - val_loss: 0.9905 - val_acc: 0.9207 - val_mDice: 0.5681

Epoch 00006: val_mDice improved from 0.54908 to 0.56806, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 7s - loss: 0.5098 - acc: 0.8940 - mDice: 0.5852 - val_loss: 0.9390 - val_acc: 0.9219 - val_mDice: 0.5712

Epoch 00007: val_mDice improved from 0.56806 to 0.57119, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 7s - loss: 0.4855 - acc: 0.8965 - mDice: 0.6003 - val_loss: 0.9083 - val_acc: 0.9240 - val_mDice: 0.5859

Epoch 00008: val_mDice improved from 0.57119 to 0.58594, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 8s - loss: 0.4715 - acc: 0.8987 - mDice: 0.6090 - val_loss: 0.9011 - val_acc: 0.9234 - val_mDice: 0.5789

Epoch 00009: val_mDice did not improve from 0.58594
Epoch 10/300
 - 8s - loss: 0.4583 - acc: 0.9015 - mDice: 0.6174 - val_loss: 0.9283 - val_acc: 0.9286 - val_mDice: 0.5671

Epoch 00010: val_mDice did not improve from 0.58594
Epoch 11/300
 - 7s - loss: 0.4462 - acc: 0.9051 - mDice: 0.6253 - val_loss: 0.8928 - val_acc: 0.9301 - val_mDice: 0.5794

Epoch 00011: val_mDice did not improve from 0.58594
Epoch 12/300
 - 8s - loss: 0.4359 - acc: 0.9087 - mDice: 0.6319 - val_loss: 0.9555 - val_acc: 0.9280 - val_mDice: 0.5730

Epoch 00012: val_mDice did not improve from 0.58594
Epoch 13/300
 - 7s - loss: 0.4309 - acc: 0.9112 - mDice: 0.6352 - val_loss: 0.8851 - val_acc: 0.9308 - val_mDice: 0.5667

Epoch 00013: val_mDice did not improve from 0.58594
Epoch 14/300
 - 7s - loss: 0.4217 - acc: 0.9126 - mDice: 0.6413 - val_loss: 0.9059 - val_acc: 0.9313 - val_mDice: 0.5795

Epoch 00014: val_mDice did not improve from 0.58594
Epoch 15/300
 - 7s - loss: 0.4173 - acc: 0.9137 - mDice: 0.6442 - val_loss: 0.9159 - val_acc: 0.9307 - val_mDice: 0.5512

Epoch 00015: val_mDice did not improve from 0.58594
Epoch 16/300
 - 8s - loss: 0.4128 - acc: 0.9145 - mDice: 0.6473 - val_loss: 0.8896 - val_acc: 0.9329 - val_mDice: 0.5887

Epoch 00016: val_mDice improved from 0.58594 to 0.58875, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 7s - loss: 0.4041 - acc: 0.9167 - mDice: 0.6530 - val_loss: 0.8202 - val_acc: 0.9327 - val_mDice: 0.5841

Epoch 00017: val_mDice did not improve from 0.58875
Epoch 18/300
 - 7s - loss: 0.4023 - acc: 0.9181 - mDice: 0.6542 - val_loss: 0.8687 - val_acc: 0.9345 - val_mDice: 0.5799

Epoch 00018: val_mDice did not improve from 0.58875
Epoch 19/300
 - 8s - loss: 0.3961 - acc: 0.9216 - mDice: 0.6584 - val_loss: 0.8303 - val_acc: 0.9460 - val_mDice: 0.5749

Epoch 00019: val_mDice did not improve from 0.58875
Epoch 20/300
 - 8s - loss: 0.3924 - acc: 0.9255 - mDice: 0.6608 - val_loss: 0.8206 - val_acc: 0.9455 - val_mDice: 0.5705

Epoch 00020: val_mDice did not improve from 0.58875
Epoch 21/300
 - 7s - loss: 0.3887 - acc: 0.9288 - mDice: 0.6634 - val_loss: 0.7940 - val_acc: 0.9456 - val_mDice: 0.5689

Epoch 00021: val_mDice did not improve from 0.58875
Epoch 22/300
 - 7s - loss: 0.3851 - acc: 0.9308 - mDice: 0.6658 - val_loss: 0.8787 - val_acc: 0.9408 - val_mDice: 0.5800

Epoch 00022: val_mDice did not improve from 0.58875
Epoch 23/300
 - 7s - loss: 0.3847 - acc: 0.9314 - mDice: 0.6660 - val_loss: 0.7858 - val_acc: 0.9453 - val_mDice: 0.5740

Epoch 00023: val_mDice did not improve from 0.58875
Epoch 24/300
 - 8s - loss: 0.3804 - acc: 0.9324 - mDice: 0.6688 - val_loss: 0.8129 - val_acc: 0.9449 - val_mDice: 0.5794

Epoch 00024: val_mDice did not improve from 0.58875
Epoch 25/300
 - 7s - loss: 0.3743 - acc: 0.9332 - mDice: 0.6731 - val_loss: 0.7586 - val_acc: 0.9424 - val_mDice: 0.5806

Epoch 00025: val_mDice did not improve from 0.58875
Epoch 26/300
 - 7s - loss: 0.3740 - acc: 0.9332 - mDice: 0.6732 - val_loss: 0.7863 - val_acc: 0.9424 - val_mDice: 0.5730

Epoch 00026: val_mDice did not improve from 0.58875
Epoch 27/300
 - 7s - loss: 0.3710 - acc: 0.9336 - mDice: 0.6754 - val_loss: 0.8016 - val_acc: 0.9430 - val_mDice: 0.5616

Epoch 00027: val_mDice did not improve from 0.58875
Epoch 28/300
 - 7s - loss: 0.3684 - acc: 0.9336 - mDice: 0.6770 - val_loss: 0.7146 - val_acc: 0.9420 - val_mDice: 0.5742

Epoch 00028: val_mDice did not improve from 0.58875
Epoch 29/300
 - 7s - loss: 0.3651 - acc: 0.9338 - mDice: 0.6794 - val_loss: 0.7992 - val_acc: 0.9450 - val_mDice: 0.5656

Epoch 00029: val_mDice did not improve from 0.58875
Epoch 30/300
 - 8s - loss: 0.3632 - acc: 0.9337 - mDice: 0.6806 - val_loss: 0.7363 - val_acc: 0.9425 - val_mDice: 0.5872

Epoch 00030: val_mDice did not improve from 0.58875
Epoch 31/300
 - 7s - loss: 0.3615 - acc: 0.9340 - mDice: 0.6819 - val_loss: 0.7397 - val_acc: 0.9448 - val_mDice: 0.5736

Epoch 00031: val_mDice did not improve from 0.58875
Epoch 32/300
 - 7s - loss: 0.3591 - acc: 0.9342 - mDice: 0.6836 - val_loss: 0.7129 - val_acc: 0.9453 - val_mDice: 0.5823

Epoch 00032: val_mDice did not improve from 0.58875
Epoch 33/300
 - 7s - loss: 0.3574 - acc: 0.9344 - mDice: 0.6848 - val_loss: 0.7277 - val_acc: 0.9425 - val_mDice: 0.5656

Epoch 00033: val_mDice did not improve from 0.58875
Epoch 34/300
 - 7s - loss: 0.3546 - acc: 0.9346 - mDice: 0.6870 - val_loss: 0.7640 - val_acc: 0.9429 - val_mDice: 0.5583

Epoch 00034: val_mDice did not improve from 0.58875
Epoch 35/300
 - 8s - loss: 0.3540 - acc: 0.9345 - mDice: 0.6873 - val_loss: 0.7137 - val_acc: 0.9445 - val_mDice: 0.5738

Epoch 00035: val_mDice did not improve from 0.58875
Epoch 36/300
 - 8s - loss: 0.3515 - acc: 0.9348 - mDice: 0.6891 - val_loss: 0.7040 - val_acc: 0.9433 - val_mDice: 0.5780

Epoch 00036: val_mDice did not improve from 0.58875
Epoch 37/300
 - 7s - loss: 0.3480 - acc: 0.9350 - mDice: 0.6915 - val_loss: 0.7040 - val_acc: 0.9387 - val_mDice: 0.5725

Epoch 00037: val_mDice did not improve from 0.58875
Epoch 38/300
 - 7s - loss: 0.3476 - acc: 0.9351 - mDice: 0.6918 - val_loss: 0.7352 - val_acc: 0.9432 - val_mDice: 0.5716

Epoch 00038: val_mDice did not improve from 0.58875
Epoch 39/300
 - 7s - loss: 0.3452 - acc: 0.9353 - mDice: 0.6935 - val_loss: 0.7072 - val_acc: 0.9428 - val_mDice: 0.5790

Epoch 00039: val_mDice did not improve from 0.58875
Epoch 40/300
 - 7s - loss: 0.3447 - acc: 0.9354 - mDice: 0.6939 - val_loss: 0.6707 - val_acc: 0.9426 - val_mDice: 0.5796

Epoch 00040: val_mDice did not improve from 0.58875
Epoch 41/300
 - 8s - loss: 0.3440 - acc: 0.9355 - mDice: 0.6944 - val_loss: 0.6768 - val_acc: 0.9436 - val_mDice: 0.5767

Epoch 00041: val_mDice did not improve from 0.58875
Epoch 42/300
 - 7s - loss: 0.3433 - acc: 0.9355 - mDice: 0.6949 - val_loss: 0.6718 - val_acc: 0.9437 - val_mDice: 0.5678

Epoch 00042: val_mDice did not improve from 0.58875
Epoch 43/300
 - 7s - loss: 0.3401 - acc: 0.9356 - mDice: 0.6973 - val_loss: 0.7378 - val_acc: 0.9406 - val_mDice: 0.5631

Epoch 00043: val_mDice did not improve from 0.58875
Epoch 44/300
 - 7s - loss: 0.3404 - acc: 0.9357 - mDice: 0.6970 - val_loss: 0.6484 - val_acc: 0.9443 - val_mDice: 0.5707

Epoch 00044: val_mDice did not improve from 0.58875
Epoch 45/300
 - 7s - loss: 0.3363 - acc: 0.9358 - mDice: 0.6999 - val_loss: 0.6566 - val_acc: 0.9435 - val_mDice: 0.5756

Epoch 00045: val_mDice did not improve from 0.58875
Epoch 46/300
 - 7s - loss: 0.3375 - acc: 0.9358 - mDice: 0.6991 - val_loss: 0.6964 - val_acc: 0.9428 - val_mDice: 0.5701

Epoch 00046: val_mDice did not improve from 0.58875
Epoch 47/300
 - 8s - loss: 0.3361 - acc: 0.9361 - mDice: 0.7003 - val_loss: 0.6292 - val_acc: 0.9458 - val_mDice: 0.5785

Epoch 00047: val_mDice did not improve from 0.58875
Epoch 48/300
 - 7s - loss: 0.3344 - acc: 0.9360 - mDice: 0.7013 - val_loss: 0.7731 - val_acc: 0.9373 - val_mDice: 0.5627

Epoch 00048: val_mDice did not improve from 0.58875
Epoch 49/300
 - 7s - loss: 0.3328 - acc: 0.9363 - mDice: 0.7025 - val_loss: 0.6947 - val_acc: 0.9431 - val_mDice: 0.5565

Epoch 00049: val_mDice did not improve from 0.58875
Epoch 50/300
 - 7s - loss: 0.3323 - acc: 0.9362 - mDice: 0.7029 - val_loss: 0.6372 - val_acc: 0.9446 - val_mDice: 0.5754

Epoch 00050: val_mDice did not improve from 0.58875
Epoch 51/300
 - 7s - loss: 0.3316 - acc: 0.9365 - mDice: 0.7035 - val_loss: 0.6908 - val_acc: 0.9450 - val_mDice: 0.5756

Epoch 00051: val_mDice did not improve from 0.58875
Epoch 52/300
 - 7s - loss: 0.3291 - acc: 0.9368 - mDice: 0.7053 - val_loss: 0.6625 - val_acc: 0.9403 - val_mDice: 0.5646

Epoch 00052: val_mDice did not improve from 0.58875
Epoch 53/300
 - 8s - loss: 0.3290 - acc: 0.9366 - mDice: 0.7053 - val_loss: 0.6849 - val_acc: 0.9388 - val_mDice: 0.5707

Epoch 00053: val_mDice did not improve from 0.58875
Epoch 54/300
 - 8s - loss: 0.3311 - acc: 0.9364 - mDice: 0.7037 - val_loss: 0.7095 - val_acc: 0.9369 - val_mDice: 0.5545

Epoch 00054: val_mDice did not improve from 0.58875
Epoch 55/300
 - 7s - loss: 0.3282 - acc: 0.9369 - mDice: 0.7058 - val_loss: 0.6410 - val_acc: 0.9442 - val_mDice: 0.5522

Epoch 00055: val_mDice did not improve from 0.58875
Epoch 56/300
 - 8s - loss: 0.3262 - acc: 0.9371 - mDice: 0.7074 - val_loss: 0.6159 - val_acc: 0.9417 - val_mDice: 0.5699

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.09s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.87s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.69s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:24,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:41,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:39,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:28,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:05,  1.52s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:25,  1.60s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:33,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:05,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:37,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:53,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:35,  1.68s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:43,  1.71s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:53,  1.75s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:01,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:41,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:24,  1.68s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:35,  1.73s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:17,  1.67s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:21,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:06,  1.63s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:24,  1.71s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:38,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:17,  1.70s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:20,  1.71s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:23,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:34,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:39,  1.81s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:11,  1.71s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:19,  1.75s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:24,  1.78s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<07:01,  1.69s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<07:06,  1.72s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:55,  1.69s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:55,  1.70s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:43,  1.65s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:29,  1.60s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:40,  1.66s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:59,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:40,  1.67s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:55,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:33,  1.65s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:36,  1.67s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<06:48,  1.73s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:44,  1.72s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<06:59,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<06:39,  1.71s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:52,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:36,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:35<06:40,  1.75s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:25,  1.69s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:42,  1.77s/it]predicting train subjects:  21%|██        | 59/285 [01:40<06:53,  1.83s/it]predicting train subjects:  21%|██        | 60/285 [01:42<07:01,  1.87s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:34,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<06:36,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<06:21,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:22,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<06:16,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 68/285 [01:56<06:03,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:04,  1.69s/it]predicting train subjects:  25%|██▍       | 70/285 [01:59<06:07,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:01<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:04<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:06<06:01,  1.71s/it]predicting train subjects:  26%|██▋       | 75/285 [02:08<06:08,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<06:13,  1.79s/it]predicting train subjects:  27%|██▋       | 77/285 [02:11<05:56,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:13<05:42,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:16<05:51,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:18<05:45,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:45,  1.70s/it]predicting train subjects:  29%|██▉       | 83/285 [02:21<05:39,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:32,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:40,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:49,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:52,  1.78s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:37,  1.71s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:35,  1.71s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:38,  1.73s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:32,  1.72s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:22,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:31,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:36,  1.79s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:28,  1.76s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:22,  1.73s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:23,  1.75s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:14,  1.72s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:57<04:58,  1.65s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<05:04,  1.69s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<04:57,  1.66s/it]predicting train subjects:  38%|███▊      | 107/285 [03:03<04:59,  1.68s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:50,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:06<04:52,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:08<05:04,  1.74s/it]predicting train subjects:  39%|███▉      | 111/285 [03:09<04:58,  1.72s/it]predicting train subjects:  39%|███▉      | 112/285 [03:11<04:52,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:13<05:00,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:15<04:54,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:16<04:53,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:18<04:53,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:20<04:42,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<04:36,  1.65s/it]predicting train subjects:  42%|████▏     | 119/285 [03:23<04:41,  1.69s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:30,  1.64s/it]predicting train subjects:  42%|████▏     | 121/285 [03:26<04:21,  1.60s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:13,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:29<04:03,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:01,  1.50s/it]predicting train subjects:  44%|████▍     | 125/285 [03:32<03:58,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<03:53,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<03:45,  1.43s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<03:49,  1.46s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:50,  1.48s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:40<03:40,  1.43s/it]predicting train subjects:  46%|████▋     | 132/285 [03:42<03:45,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:43<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:43,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:46<03:35,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:49<03:36,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:51<03:29,  1.42s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:33,  1.46s/it]predicting train subjects:  49%|████▉     | 140/285 [03:54<03:33,  1.47s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:32,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:30,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:26,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:29,  1.48s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:25,  1.48s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:04<03:20,  1.45s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:07<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:15,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:10<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:11,  1.44s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<03:06,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:07,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:17<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:07,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:20<03:03,  1.44s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<02:59,  1.43s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:23<02:56,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:27<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:30<02:52,  1.44s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:33<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:34<02:46,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:36<02:43,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:37<02:41,  1.40s/it]predicting train subjects:  60%|██████    | 171/285 [04:38<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:40<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:41<02:38,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:43<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:44<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:46<02:43,  1.50s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:47<02:40,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:49<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:50<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:52<02:40,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:53<02:40,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:55<02:40,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:56<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:58<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:59<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:01<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:03<02:37,  1.61s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:04<02:40,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:06<02:28,  1.54s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:07<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:09<02:24,  1.54s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:10<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:12<02:17,  1.49s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:13<02:13,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:14<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:16<02:17,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:18<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:20<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:21<02:14,  1.57s/it]predicting train subjects:  70%|███████   | 200/285 [05:22<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:24<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:26<02:11,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:27<02:08,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:29<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:30<01:58,  1.48s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:31<01:53,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:33<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:35<02:05,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:37<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:38<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:39<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:41<01:51,  1.53s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:43<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:44<01:45,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:46<01:49,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:47<01:42,  1.48s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:49<01:46,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:51<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:52<01:48,  1.65s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:53<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:55<01:35,  1.49s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:56<01:35,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:58<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:59<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:01<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:02<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:04<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:06<01:35,  1.68s/it]predicting train subjects:  80%|████████  | 229/285 [06:08<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:09<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:10<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:12<01:21,  1.54s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:13<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:15<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:17<01:16,  1.52s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:18<01:21,  1.66s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:20<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:22<01:22,  1.75s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:24<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:25<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:26<01:07,  1.53s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:28<01:03,  1.47s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:29<01:00,  1.44s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:31<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:32<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:34<01:01,  1.56s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:36<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:37<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:39<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:40<00:52,  1.50s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:42<00:48,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:43<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:45<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:47<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:48<00:48,  1.62s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:50<00:45,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [06:51<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [06:53<00:43,  1.61s/it]predicting train subjects:  91%|█████████ | 259/285 [06:54<00:41,  1.60s/it]predicting train subjects:  91%|█████████ | 260/285 [06:56<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:57<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:59<00:33,  1.47s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:00<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:02<00:32,  1.55s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:04<00:32,  1.61s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:05<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:06<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:08<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:10<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:11<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:12<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:14<00:19,  1.49s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:15<00:17,  1.44s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:17<00:15,  1.40s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:18<00:15,  1.50s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:20<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:21<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:23<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:24<00:08,  1.48s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:26<00:07,  1.44s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:27<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:29<00:04,  1.43s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:30<00:03,  1.53s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:32<00:01,  1.58s/it]predicting train subjects: 100%|██████████| 285/285 [07:34<00:00,  1.64s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:30,  1.80s/it]Loading train:   1%|          | 2/285 [00:03<07:48,  1.65s/it]Loading train:   1%|          | 3/285 [00:04<07:44,  1.65s/it]Loading train:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]Loading train:   2%|▏         | 5/285 [00:07<07:38,  1.64s/it]Loading train:   2%|▏         | 6/285 [00:09<07:08,  1.54s/it]Loading train:   2%|▏         | 7/285 [00:10<07:23,  1.60s/it]Loading train:   3%|▎         | 8/285 [00:12<07:02,  1.53s/it]Loading train:   3%|▎         | 9/285 [00:14<07:33,  1.64s/it]Loading train:   4%|▎         | 10/285 [00:15<07:00,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:23,  1.40s/it]Loading train:   4%|▍         | 12/285 [00:18<06:27,  1.42s/it]Loading train:   5%|▍         | 13/285 [00:19<05:55,  1.31s/it]Loading train:   5%|▍         | 14/285 [00:20<05:44,  1.27s/it]Loading train:   5%|▌         | 15/285 [00:21<05:42,  1.27s/it]Loading train:   6%|▌         | 16/285 [00:22<05:34,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:23<05:20,  1.20s/it]Loading train:   6%|▋         | 18/285 [00:25<05:27,  1.23s/it]Loading train:   7%|▋         | 19/285 [00:26<05:18,  1.20s/it]Loading train:   7%|▋         | 20/285 [00:27<05:32,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:28<05:32,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:30<05:15,  1.20s/it]Loading train:   8%|▊         | 23/285 [00:31<05:11,  1.19s/it]Loading train:   8%|▊         | 24/285 [00:32<04:55,  1.13s/it]Loading train:   9%|▉         | 25/285 [00:33<05:06,  1.18s/it]Loading train:   9%|▉         | 26/285 [00:34<05:05,  1.18s/it]Loading train:   9%|▉         | 27/285 [00:35<04:56,  1.15s/it]Loading train:  10%|▉         | 28/285 [00:36<04:53,  1.14s/it]Loading train:  10%|█         | 29/285 [00:37<04:42,  1.11s/it]Loading train:  11%|█         | 30/285 [00:39<05:10,  1.22s/it]Loading train:  11%|█         | 31/285 [00:40<05:27,  1.29s/it]Loading train:  11%|█         | 32/285 [00:41<05:12,  1.24s/it]Loading train:  12%|█▏        | 33/285 [00:43<05:25,  1.29s/it]Loading train:  12%|█▏        | 34/285 [00:44<05:25,  1.30s/it]Loading train:  12%|█▏        | 35/285 [00:46<05:48,  1.40s/it]Loading train:  13%|█▎        | 36/285 [00:47<05:44,  1.38s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:54,  1.43s/it]Loading train:  13%|█▎        | 38/285 [00:50<06:01,  1.47s/it]Loading train:  14%|█▎        | 39/285 [00:51<05:42,  1.39s/it]Loading train:  14%|█▍        | 40/285 [00:53<05:30,  1.35s/it]Loading train:  14%|█▍        | 41/285 [00:54<05:19,  1.31s/it]Loading train:  15%|█▍        | 42/285 [00:55<05:03,  1.25s/it]Loading train:  15%|█▌        | 43/285 [00:56<05:05,  1.26s/it]Loading train:  15%|█▌        | 44/285 [00:58<05:09,  1.28s/it]Loading train:  16%|█▌        | 45/285 [00:59<05:10,  1.29s/it]Loading train:  16%|█▌        | 46/285 [01:01<05:38,  1.42s/it]Loading train:  16%|█▋        | 47/285 [01:02<05:23,  1.36s/it]Loading train:  17%|█▋        | 48/285 [01:03<05:24,  1.37s/it]Loading train:  17%|█▋        | 49/285 [01:05<05:30,  1.40s/it]Loading train:  18%|█▊        | 50/285 [01:06<05:22,  1.37s/it]Loading train:  18%|█▊        | 51/285 [01:07<05:12,  1.34s/it]Loading train:  18%|█▊        | 52/285 [01:09<05:06,  1.31s/it]Loading train:  19%|█▊        | 53/285 [01:10<05:02,  1.30s/it]Loading train:  19%|█▉        | 54/285 [01:11<05:06,  1.33s/it]Loading train:  19%|█▉        | 55/285 [01:13<05:02,  1.31s/it]Loading train:  20%|█▉        | 56/285 [01:14<04:59,  1.31s/it]Loading train:  20%|██        | 57/285 [01:15<04:53,  1.29s/it]Loading train:  20%|██        | 58/285 [01:16<04:47,  1.27s/it]Loading train:  21%|██        | 59/285 [01:18<04:57,  1.32s/it]Loading train:  21%|██        | 60/285 [01:19<05:03,  1.35s/it]Loading train:  21%|██▏       | 61/285 [01:20<04:52,  1.30s/it]Loading train:  22%|██▏       | 62/285 [01:22<05:12,  1.40s/it]Loading train:  22%|██▏       | 63/285 [01:23<04:53,  1.32s/it]Loading train:  22%|██▏       | 64/285 [01:25<05:12,  1.41s/it]Loading train:  23%|██▎       | 65/285 [01:26<05:30,  1.50s/it]
Epoch 00056: val_mDice did not improve from 0.58875
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [2.2832526025317965, 1.3784117698669434, 1.1734752314431327, 1.1057289100828624, 1.0356233914693196, 0.9905121894109816, 0.9390093088150024, 0.9082643531617665, 0.9011133965991792, 0.9282505909601847, 0.8927961587905884, 0.9554702951794579, 0.8850595213118053, 0.905946243376959, 0.9159498101189023, 0.8896199294498989, 0.820170141401745, 0.8686966555459159, 0.8302647953941709, 0.8205581165495373, 0.7940045311337426, 0.8786551782063076, 0.7858143363680158, 0.812943384760902, 0.7586188202812558, 0.7862545138313657, 0.8015983785901751, 0.7145838794254121, 0.7991956642695835, 0.736318514460609, 0.739748165720985, 0.7128771316437494, 0.7276530549639747, 0.764034180414109, 0.7136785700207665, 0.7039618832724435, 0.7040143183299473, 0.7351691211972918, 0.7072099844614664, 0.6707217068899245, 0.6768428087234497, 0.6717788037799653, 0.7377816949571881, 0.6484355302084059, 0.6566048974082583, 0.6963668437231154, 0.6291636512393043, 0.7731261480422247, 0.6947074731191, 0.637166386558896, 0.6908246562594459, 0.6625430697486514, 0.6848717757633754, 0.7094871770767939, 0.6409989765712193, 0.6159117165065947], 'val_acc': [0.878168523311615, 0.913118132523128, 0.917330577259972, 0.9159592702275231, 0.9188118321555001, 0.9207028349240621, 0.9218566587993077, 0.9240361679167974, 0.923415754522596, 0.9285622778392973, 0.9301144849686396, 0.9280448868161156, 0.9308493648256574, 0.931256856237139, 0.9306547613370986, 0.9328594292913165, 0.932731222538721, 0.9344597203390939, 0.946041654972803, 0.9455128425643557, 0.9455792194321042, 0.9408402017184666, 0.945251811118353, 0.944903830687205, 0.9424221487272353, 0.942403861454555, 0.9429922047115508, 0.9419528472991217, 0.9450389430636451, 0.9425137270064581, 0.9447870793796721, 0.945318219207582, 0.942534327507019, 0.942859445299421, 0.9445146379016695, 0.9433264703977675, 0.9386767205737886, 0.9432463333720252, 0.9427884788740248, 0.9425869754382542, 0.943560004234314, 0.9437087944575718, 0.9405563445318312, 0.9443315040497553, 0.9434844227064223, 0.9428319874263945, 0.9458104173342387, 0.9372962486176264, 0.9430860905420213, 0.9445855958121163, 0.944993135474977, 0.9403044865244911, 0.9388118272735959, 0.9369001587231954, 0.9441987417993092, 0.9416895508766174], 'val_mDice': [0.20972344421205066, 0.4423118733933994, 0.522095324737685, 0.5414959305808658, 0.5490800564487776, 0.56806060139622, 0.5711933495033354, 0.585941647135076, 0.5788621058066686, 0.5670607976970219, 0.5793629045642558, 0.5729548106236118, 0.5666501791704268, 0.5794981185879026, 0.5512065216898918, 0.5887478304406008, 0.5840973854064941, 0.5799034825038343, 0.5749199028526034, 0.5705015705454917, 0.5689219773880073, 0.580043569561981, 0.5739930043263095, 0.5794440720762525, 0.5806186092751366, 0.5729929212303388, 0.5616058803030423, 0.5741879904554004, 0.5656263629595438, 0.5871702629540648, 0.5735730663651512, 0.5822526526947817, 0.5655646959231013, 0.5582822921375433, 0.5737878800857634, 0.5779652721470311, 0.5725119011033148, 0.5715854675287292, 0.579011199020204, 0.5795560761221817, 0.5767161631513209, 0.5678067320869082, 0.5631447219777674, 0.5707247147247905, 0.5756336180936723, 0.5701340896387895, 0.5785275541600727, 0.5627165498832861, 0.5564772123027415, 0.575408718415669, 0.5755706940378461, 0.5646045463425773, 0.5706884797130313, 0.554548923280977, 0.5522184559986705, 0.5698907474676768], 'loss': [3.0250884827240045, 1.1945124257845021, 0.7514551852005443, 0.626806220958659, 0.5722625561939031, 0.5331552698533154, 0.5097555549463739, 0.48551841428658166, 0.47146219773537995, 0.45827936773381067, 0.4462162427918769, 0.43585190200520685, 0.43092902700221214, 0.42171657869690343, 0.41730584434881957, 0.41275883008226255, 0.40413423699291084, 0.4023136502059641, 0.39613380800075837, 0.3924272540322567, 0.38868147774263917, 0.3850533785688089, 0.38465654096186036, 0.3804362954685677, 0.37432489566130056, 0.3740445644910197, 0.37104716185708025, 0.3684427476133803, 0.365082586733206, 0.363236546303832, 0.3614932335719268, 0.35906961391329284, 0.3574333966571241, 0.354603893906941, 0.35397961578871073, 0.35151034752160154, 0.3480422306157317, 0.34760205753051365, 0.3452340678854303, 0.34470738205395846, 0.34400892468553207, 0.34334424026604904, 0.34009502333139485, 0.3404456843225763, 0.3363479172962811, 0.337541352135151, 0.33610434690858443, 0.33443630044460754, 0.33283377340103315, 0.332313575598921, 0.33164655093009565, 0.3290944733336088, 0.328991437592625, 0.33114554841485766, 0.3282344662341075, 0.3261550475642335], 'acc': [0.5835341420882879, 0.8760421982569021, 0.8845462160393616, 0.8878091607154485, 0.8896528207453684, 0.8917198010163889, 0.8940089425531361, 0.8964502639753961, 0.898708170161717, 0.9015259385246842, 0.9050984295756228, 0.9087301726191402, 0.9112264290811102, 0.9126056181871985, 0.9136772203679854, 0.914470228416648, 0.9166712770922602, 0.9181052906471386, 0.9215543487753647, 0.9255242870220312, 0.9287821743928193, 0.9308146018501143, 0.9313897718600922, 0.9323596043901129, 0.9332414327707506, 0.9331778275247298, 0.9335580760512895, 0.933609009398094, 0.9337887313753418, 0.9337356889755803, 0.9339896716638546, 0.9342405796280848, 0.9344116827989788, 0.9346208995032544, 0.9345345594576381, 0.9348069029390318, 0.9350152391332042, 0.9350938618309539, 0.9352647748001743, 0.9353890496112028, 0.9355023777942242, 0.9355350943551212, 0.9356151595955895, 0.9356870807180153, 0.9358142020501496, 0.9357911202405169, 0.9360940258857348, 0.9359634522875081, 0.936268718216905, 0.9362220285668271, 0.936473627908165, 0.9367776876105401, 0.9365557721062434, 0.9364421588390439, 0.9368508398153659, 0.9371466520137357], 'mDice': [0.07375771387067057, 0.3094505018091211, 0.45501204355847336, 0.5174662297875614, 0.5479627149009005, 0.5710576619282839, 0.5851625333132026, 0.6003120196837783, 0.6090448133996486, 0.6174134136809074, 0.6253048274842029, 0.6318699734068938, 0.6351923213911489, 0.641252658949529, 0.6442085494074905, 0.6472798622663435, 0.6529570076193036, 0.6541867612160674, 0.6584495402081109, 0.660766345148765, 0.6633503271224803, 0.6657852053941044, 0.6660182993375706, 0.668822955322192, 0.6730967217243681, 0.6731950792706447, 0.675432686392503, 0.6770138326972718, 0.6794162446050164, 0.6806224172391574, 0.6819109631821165, 0.6836467589375047, 0.6848437269229937, 0.6869507637790616, 0.687283444156393, 0.6891024443646813, 0.6914988717454602, 0.6918167602540166, 0.6934838731187328, 0.6938883895609267, 0.6944423554971862, 0.6948993790464546, 0.6972883855397931, 0.696961951262693, 0.6999182045540185, 0.6991258970983736, 0.7002698816797144, 0.7013347823771067, 0.7024893348493259, 0.7028850929595061, 0.7034964846902807, 0.7052953425965053, 0.7052714252301855, 0.7037246165901612, 0.7058492844702767, 0.7073667691304133]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label valuesLoading train:  23%|██▎       | 66/285 [01:28<05:30,  1.51s/it]Loading train:  24%|██▎       | 67/285 [01:29<05:03,  1.39s/it]Loading train:  24%|██▍       | 68/285 [01:30<04:47,  1.33s/it]Loading train:  24%|██▍       | 69/285 [01:32<04:44,  1.32s/it]Loading train:  25%|██▍       | 70/285 [01:33<05:18,  1.48s/it]Loading train:  25%|██▍       | 71/285 [01:35<05:06,  1.43s/it]Loading train:  25%|██▌       | 72/285 [01:36<04:53,  1.38s/it]Loading train:  26%|██▌       | 73/285 [01:37<04:40,  1.32s/it]Loading train:  26%|██▌       | 74/285 [01:38<04:23,  1.25s/it]Loading train:  26%|██▋       | 75/285 [01:40<04:39,  1.33s/it]Loading train:  27%|██▋       | 76/285 [01:41<04:42,  1.35s/it]Loading train:  27%|██▋       | 77/285 [01:42<04:31,  1.31s/it]Loading train:  27%|██▋       | 78/285 [01:44<04:19,  1.25s/it]Loading train:  28%|██▊       | 79/285 [01:45<04:22,  1.27s/it]Loading train:  28%|██▊       | 80/285 [01:46<04:26,  1.30s/it]Loading train:  28%|██▊       | 81/285 [01:47<04:22,  1.29s/it]Loading train:  29%|██▉       | 82/285 [01:49<04:25,  1.31s/it]Loading train:  29%|██▉       | 83/285 [01:50<04:12,  1.25s/it]Loading train:  29%|██▉       | 84/285 [01:51<04:18,  1.28s/it]Loading train:  30%|██▉       | 85/285 [01:53<04:16,  1.28s/it]Loading train:  30%|███       | 86/285 [01:54<04:18,  1.30s/it]Loading train:  31%|███       | 87/285 [01:55<04:16,  1.30s/it]Loading train:  31%|███       | 88/285 [01:56<04:15,  1.30s/it]Loading train:  31%|███       | 89/285 [01:58<04:18,  1.32s/it]Loading train:  32%|███▏      | 90/285 [01:59<04:23,  1.35s/it]Loading train:  32%|███▏      | 91/285 [02:01<04:15,  1.31s/it]Loading train:  32%|███▏      | 92/285 [02:02<04:13,  1.31s/it]Loading train:  33%|███▎      | 93/285 [02:03<04:18,  1.35s/it]Loading train:  33%|███▎      | 94/285 [02:04<04:07,  1.29s/it]Loading train:  33%|███▎      | 95/285 [02:06<04:19,  1.37s/it]Loading train:  34%|███▎      | 96/285 [02:08<04:30,  1.43s/it]Loading train:  34%|███▍      | 97/285 [02:09<04:27,  1.42s/it]Loading train:  34%|███▍      | 98/285 [02:10<04:26,  1.42s/it]Loading train:  35%|███▍      | 99/285 [02:12<04:30,  1.45s/it]Loading train:  35%|███▌      | 100/285 [02:13<04:22,  1.42s/it]Loading train:  35%|███▌      | 101/285 [02:14<04:09,  1.35s/it]Loading train:  36%|███▌      | 102/285 [02:16<04:13,  1.39s/it]Loading train:  36%|███▌      | 103/285 [02:17<04:05,  1.35s/it]Loading train:  36%|███▋      | 104/285 [02:18<03:52,  1.29s/it]Loading train:  37%|███▋      | 105/285 [02:19<03:46,  1.26s/it]Loading train:  37%|███▋      | 106/285 [02:21<03:40,  1.23s/it]Loading train:  38%|███▊      | 107/285 [02:22<03:49,  1.29s/it]Loading train:  38%|███▊      | 108/285 [02:23<03:39,  1.24s/it]Loading train:  38%|███▊      | 109/285 [02:24<03:39,  1.25s/it]Loading train:  39%|███▊      | 110/285 [02:26<03:43,  1.28s/it]Loading train:  39%|███▉      | 111/285 [02:27<03:52,  1.34s/it]Loading train:  39%|███▉      | 112/285 [02:29<04:05,  1.42s/it]Loading train:  40%|███▉      | 113/285 [02:30<03:57,  1.38s/it]Loading train:  40%|████      | 114/285 [02:32<03:56,  1.38s/it]Loading train:  40%|████      | 115/285 [02:33<04:04,  1.44s/it]Loading train:  41%|████      | 116/285 [02:34<03:59,  1.41s/it]Loading train:  41%|████      | 117/285 [02:36<03:55,  1.40s/it]Loading train:  41%|████▏     | 118/285 [02:37<03:42,  1.33s/it]Loading train:  42%|████▏     | 119/285 [02:39<03:49,  1.38s/it]Loading train:  42%|████▏     | 120/285 [02:40<03:47,  1.38s/it]Loading train:  42%|████▏     | 121/285 [02:41<03:48,  1.39s/it]Loading train:  43%|████▎     | 122/285 [02:43<03:45,  1.38s/it]Loading train:  43%|████▎     | 123/285 [02:44<03:44,  1.38s/it]Loading train:  44%|████▎     | 124/285 [02:45<03:26,  1.28s/it]Loading train:  44%|████▍     | 125/285 [02:46<03:11,  1.19s/it]Loading train:  44%|████▍     | 126/285 [02:47<03:10,  1.20s/it]Loading train:  45%|████▍     | 127/285 [02:48<03:02,  1.15s/it]Loading train:  45%|████▍     | 128/285 [02:49<02:58,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:51<03:00,  1.16s/it]Loading train:  46%|████▌     | 130/285 [02:52<02:57,  1.14s/it]Loading train:  46%|████▌     | 131/285 [02:53<02:55,  1.14s/it]Loading train:  46%|████▋     | 132/285 [02:54<02:55,  1.15s/it]Loading train:  47%|████▋     | 133/285 [02:55<02:53,  1.14s/it]Loading train:  47%|████▋     | 134/285 [02:56<02:53,  1.15s/it]Loading train:  47%|████▋     | 135/285 [02:57<02:46,  1.11s/it]Loading train:  48%|████▊     | 136/285 [02:58<02:43,  1.10s/it]Loading train:  48%|████▊     | 137/285 [03:00<02:50,  1.15s/it]Loading train:  48%|████▊     | 138/285 [03:01<02:52,  1.17s/it]Loading train:  49%|████▉     | 139/285 [03:02<03:00,  1.23s/it]Loading train:  49%|████▉     | 140/285 [03:04<02:59,  1.24s/it]Loading train:  49%|████▉     | 141/285 [03:05<02:49,  1.18s/it]Loading train:  50%|████▉     | 142/285 [03:06<02:49,  1.19s/it]Loading train:  50%|█████     | 143/285 [03:07<02:48,  1.19s/it]Loading train:  51%|█████     | 144/285 [03:08<02:46,  1.18s/it]Loading train:  51%|█████     | 145/285 [03:09<02:38,  1.13s/it]Loading train:  51%|█████     | 146/285 [03:11<02:45,  1.19s/it]Loading train:  52%|█████▏    | 147/285 [03:12<02:45,  1.20s/it]Loading train:  52%|█████▏    | 148/285 [03:13<02:42,  1.18s/it]Loading train:  52%|█████▏    | 149/285 [03:14<02:40,  1.18s/it]Loading train:  53%|█████▎    | 150/285 [03:15<02:38,  1.17s/it]Loading train:  53%|█████▎    | 151/285 [03:16<02:37,  1.17s/it]Loading train:  53%|█████▎    | 152/285 [03:18<02:33,  1.15s/it]Loading train:  54%|█████▎    | 153/285 [03:19<02:29,  1.13s/it]Loading train:  54%|█████▍    | 154/285 [03:20<02:30,  1.15s/it]Loading train:  54%|█████▍    | 155/285 [03:21<02:32,  1.18s/it]Loading train:  55%|█████▍    | 156/285 [03:22<02:35,  1.20s/it]Loading train:  55%|█████▌    | 157/285 [03:23<02:23,  1.12s/it]Loading train:  55%|█████▌    | 158/285 [03:25<02:34,  1.22s/it]Loading train:  56%|█████▌    | 159/285 [03:26<02:30,  1.19s/it]Loading train:  56%|█████▌    | 160/285 [03:27<02:21,  1.13s/it]Loading train:  56%|█████▋    | 161/285 [03:28<02:22,  1.15s/it]Loading train:  57%|█████▋    | 162/285 [03:29<02:17,  1.12s/it]Loading train:  57%|█████▋    | 163/285 [03:30<02:20,  1.15s/it]Loading train:  58%|█████▊    | 164/285 [03:32<02:25,  1.20s/it]Loading train:  58%|█████▊    | 165/285 [03:33<02:18,  1.15s/it]Loading train:  58%|█████▊    | 166/285 [03:34<02:21,  1.19s/it]Loading train:  59%|█████▊    | 167/285 [03:35<02:23,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:36<02:20,  1.20s/it]Loading train:  59%|█████▉    | 169/285 [03:38<02:21,  1.22s/it]Loading train:  60%|█████▉    | 170/285 [03:39<02:18,  1.21s/it]Loading train:  60%|██████    | 171/285 [03:40<02:10,  1.15s/it]Loading train:  60%|██████    | 172/285 [03:41<02:16,  1.20s/it]Loading train:  61%|██████    | 173/285 [03:42<02:14,  1.20s/it]Loading train:  61%|██████    | 174/285 [03:43<02:10,  1.18s/it]Loading train:  61%|██████▏   | 175/285 [03:45<02:08,  1.17s/it]Loading train:  62%|██████▏   | 176/285 [03:46<02:08,  1.18s/it]Loading train:  62%|██████▏   | 177/285 [03:47<02:03,  1.15s/it]Loading train:  62%|██████▏   | 178/285 [03:48<02:03,  1.15s/it]Loading train:  63%|██████▎   | 179/285 [03:49<02:02,  1.16s/it]Loading train:  63%|██████▎   | 180/285 [03:50<02:06,  1.20s/it]Loading train:  64%|██████▎   | 181/285 [03:52<02:04,  1.20s/it]Loading train:  64%|██████▍   | 182/285 [03:53<02:03,  1.20s/it]Loading train:  64%|██████▍   | 183/285 [03:54<02:05,  1.23s/it]Loading train:  65%|██████▍   | 184/285 [03:55<02:04,  1.23s/it]Loading train:  65%|██████▍   | 185/285 [03:57<01:59,  1.20s/it]Loading train:  65%|██████▌   | 186/285 [03:58<02:11,  1.33s/it]Loading train:  66%|██████▌   | 187/285 [04:00<02:11,  1.35s/it]Loading train:  66%|██████▌   | 188/285 [04:01<02:10,  1.34s/it]Loading train:  66%|██████▋   | 189/285 [04:02<01:58,  1.23s/it]Loading train:  67%|██████▋   | 190/285 [04:03<01:52,  1.19s/it]Loading train:  67%|██████▋   | 191/285 [04:04<01:48,  1.16s/it]Loading train:  67%|██████▋   | 192/285 [04:05<01:47,  1.16s/it]Loading train:  68%|██████▊   | 193/285 [04:06<01:49,  1.20s/it]Loading train:  68%|██████▊   | 194/285 [04:08<01:46,  1.17s/it]Loading train:  68%|██████▊   | 195/285 [04:09<01:45,  1.18s/it]Loading train:  69%|██████▉   | 196/285 [04:10<01:51,  1.25s/it]Loading train:  69%|██████▉   | 197/285 [04:11<01:46,  1.21s/it]Loading train:  69%|██████▉   | 198/285 [04:13<01:48,  1.25s/it]Loading train:  70%|██████▉   | 199/285 [04:14<01:39,  1.16s/it]Loading train:  70%|███████   | 200/285 [04:15<01:37,  1.15s/it]Loading train:  71%|███████   | 201/285 [04:16<01:38,  1.17s/it]Loading train:  71%|███████   | 202/285 [04:17<01:36,  1.17s/it]Loading train:  71%|███████   | 203/285 [04:18<01:34,  1.15s/it]Loading train:  72%|███████▏  | 204/285 [04:19<01:33,  1.16s/it]Loading train:  72%|███████▏  | 205/285 [04:21<01:34,  1.19s/it]Loading train:  72%|███████▏  | 206/285 [04:22<01:35,  1.20s/it]Loading train:  73%|███████▎  | 207/285 [04:24<01:45,  1.35s/it]Loading train:  73%|███████▎  | 208/285 [04:25<01:45,  1.37s/it]Loading train:  73%|███████▎  | 209/285 [04:26<01:39,  1.31s/it]Loading train:  74%|███████▎  | 210/285 [04:28<01:39,  1.33s/it]Loading train:  74%|███████▍  | 211/285 [04:29<01:42,  1.38s/it]Loading train:  74%|███████▍  | 212/285 [04:31<01:49,  1.50s/it]Loading train:  75%|███████▍  | 213/285 [04:32<01:42,  1.42s/it]Loading train:  75%|███████▌  | 214/285 [04:33<01:36,  1.35s/it]Loading train:  75%|███████▌  | 215/285 [04:35<01:40,  1.43s/it]Loading train:  76%|███████▌  | 216/285 [04:36<01:34,  1.37s/it]Loading train:  76%|███████▌  | 217/285 [04:37<01:33,  1.37s/it]Loading train:  76%|███████▋  | 218/285 [04:39<01:35,  1.43s/it]Loading train:  77%|███████▋  | 219/285 [04:40<01:33,  1.42s/it]Loading train:  77%|███████▋  | 220/285 [04:42<01:26,  1.33s/it]Loading train:  78%|███████▊  | 221/285 [04:43<01:22,  1.29s/it]Loading train:  78%|███████▊  | 222/285 [04:44<01:28,  1.41s/it]Loading train:  78%|███████▊  | 223/285 [04:46<01:23,  1.35s/it]Loading train:  79%|███████▊  | 224/285 [04:47<01:21,  1.33s/it]Loading train:  79%|███████▉  | 225/285 [04:48<01:16,  1.27s/it]Loading train:  79%|███████▉  | 226/285 [04:49<01:15,  1.27s/it]Loading train:  80%|███████▉  | 227/285 [04:51<01:16,  1.32s/it]Loading train:  80%|████████  | 228/285 [04:52<01:19,  1.40s/it]Loading train:  80%|████████  | 229/285 [04:54<01:21,  1.45s/it]Loading train:  81%|████████  | 230/285 [04:55<01:16,  1.40s/it]Loading train:  81%|████████  | 231/285 [04:56<01:11,  1.32s/it]Loading train:  81%|████████▏ | 232/285 [04:57<01:06,  1.26s/it]Loading train:  82%|████████▏ | 233/285 [04:59<01:05,  1.27s/it]Loading train:  82%|████████▏ | 234/285 [05:00<01:04,  1.27s/it]Loading train:  82%|████████▏ | 235/285 [05:01<01:03,  1.28s/it]Loading train:  83%|████████▎ | 236/285 [05:03<01:11,  1.47s/it]Loading train:  83%|████████▎ | 237/285 [05:05<01:14,  1.54s/it]Loading train:  84%|████████▎ | 238/285 [05:06<01:10,  1.50s/it]Loading train:  84%|████████▍ | 239/285 [05:07<01:03,  1.38s/it]Loading train:  84%|████████▍ | 240/285 [05:09<00:59,  1.32s/it]Loading train:  85%|████████▍ | 241/285 [05:10<00:56,  1.28s/it]Loading train:  85%|████████▍ | 242/285 [05:11<00:55,  1.30s/it]Loading train:  85%|████████▌ | 243/285 [05:12<00:51,  1.22s/it]Loading train:  86%|████████▌ | 244/285 [05:14<00:52,  1.27s/it]Loading train:  86%|████████▌ | 245/285 [05:15<00:49,  1.23s/it]Loading train:  86%|████████▋ | 246/285 [05:16<00:49,  1.28s/it]Loading train:  87%|████████▋ | 247/285 [05:18<00:50,  1.34s/it]Loading train:  87%|████████▋ | 248/285 [05:19<00:49,  1.34s/it]Loading train:  87%|████████▋ | 249/285 [05:20<00:45,  1.27s/it]Loading train:  88%|████████▊ | 250/285 [05:21<00:42,  1.20s/it]Loading train:  88%|████████▊ | 251/285 [05:22<00:39,  1.17s/it]Loading train:  88%|████████▊ | 252/285 [05:24<00:39,  1.21s/it]Loading train:  89%|████████▉ | 253/285 [05:25<00:41,  1.30s/it]Loading train:  89%|████████▉ | 254/285 [05:26<00:40,  1.32s/it]Loading train:  89%|████████▉ | 255/285 [05:28<00:38,  1.27s/it]Loading train:  90%|████████▉ | 256/285 [05:29<00:34,  1.18s/it]Loading train:  90%|█████████ | 257/285 [05:30<00:32,  1.16s/it]Loading train:  91%|█████████ | 258/285 [05:31<00:34,  1.26s/it]Loading train:  91%|█████████ | 259/285 [05:32<00:32,  1.25s/it]Loading train:  91%|█████████ | 260/285 [05:33<00:30,  1.22s/it]Loading train:  92%|█████████▏| 261/285 [05:35<00:27,  1.17s/it]Loading train:  92%|█████████▏| 262/285 [05:36<00:26,  1.14s/it]Loading train:  92%|█████████▏| 263/285 [05:37<00:26,  1.23s/it]Loading train:  93%|█████████▎| 264/285 [05:39<00:27,  1.31s/it]Loading train:  93%|█████████▎| 265/285 [05:40<00:28,  1.41s/it]Loading train:  93%|█████████▎| 266/285 [05:42<00:26,  1.38s/it]Loading train:  94%|█████████▎| 267/285 [05:43<00:23,  1.29s/it]Loading train:  94%|█████████▍| 268/285 [05:44<00:22,  1.30s/it]Loading train:  94%|█████████▍| 269/285 [05:45<00:20,  1.31s/it]Loading train:  95%|█████████▍| 270/285 [05:46<00:19,  1.28s/it]Loading train:  95%|█████████▌| 271/285 [05:48<00:18,  1.34s/it]Loading train:  95%|█████████▌| 272/285 [05:49<00:16,  1.30s/it]Loading train:  96%|█████████▌| 273/285 [05:50<00:15,  1.29s/it]Loading train:  96%|█████████▌| 274/285 [05:52<00:13,  1.24s/it]Loading train:  96%|█████████▋| 275/285 [05:53<00:12,  1.28s/it]Loading train:  97%|█████████▋| 276/285 [05:54<00:11,  1.30s/it]Loading train:  97%|█████████▋| 277/285 [05:56<00:10,  1.30s/it]Loading train:  98%|█████████▊| 278/285 [05:57<00:08,  1.28s/it]Loading train:  98%|█████████▊| 279/285 [05:58<00:07,  1.26s/it]Loading train:  98%|█████████▊| 280/285 [05:59<00:06,  1.26s/it]Loading train:  99%|█████████▊| 281/285 [06:00<00:04,  1.21s/it]Loading train:  99%|█████████▉| 282/285 [06:02<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [06:03<00:02,  1.29s/it]Loading train: 100%|█████████▉| 284/285 [06:04<00:01,  1.34s/it]Loading train: 100%|██████████| 285/285 [06:06<00:00,  1.34s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.12it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 47.06it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:05, 52.14it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:05, 46.39it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:05, 46.88it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:05, 45.19it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:05, 48.33it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:05, 47.16it/s]concatenating: train:  18%|█▊        | 52/285 [00:01<00:04, 50.91it/s]concatenating: train:  20%|██        | 58/285 [00:01<00:05, 44.35it/s]concatenating: train:  22%|██▏       | 64/285 [00:01<00:04, 47.20it/s]concatenating: train:  24%|██▍       | 69/285 [00:01<00:04, 46.93it/s]concatenating: train:  27%|██▋       | 76/285 [00:01<00:04, 50.72it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:03, 53.19it/s]concatenating: train:  31%|███       | 88/285 [00:01<00:04, 49.11it/s]concatenating: train:  33%|███▎      | 94/285 [00:01<00:03, 48.42it/s]concatenating: train:  35%|███▌      | 101/285 [00:02<00:03, 51.82it/s]concatenating: train:  38%|███▊      | 108/285 [00:02<00:03, 54.74it/s]concatenating: train:  40%|████      | 114/285 [00:02<00:03, 54.39it/s]concatenating: train:  42%|████▏     | 121/285 [00:02<00:02, 56.59it/s]concatenating: train:  45%|████▍     | 128/285 [00:02<00:02, 53.88it/s]concatenating: train:  47%|████▋     | 134/285 [00:02<00:02, 53.85it/s]concatenating: train:  49%|████▉     | 141/285 [00:02<00:02, 56.18it/s]concatenating: train:  52%|█████▏    | 148/285 [00:02<00:02, 57.94it/s]concatenating: train:  56%|█████▌    | 160/285 [00:02<00:01, 68.52it/s]concatenating: train:  59%|█████▉    | 169/285 [00:03<00:01, 71.77it/s]concatenating: train:  63%|██████▎   | 179/285 [00:03<00:01, 77.60it/s]concatenating: train:  67%|██████▋   | 190/285 [00:03<00:01, 84.43it/s]concatenating: train:  71%|███████   | 201/285 [00:03<00:00, 89.77it/s]concatenating: train:  74%|███████▍  | 211/285 [00:03<00:00, 91.70it/s]concatenating: train:  78%|███████▊  | 223/285 [00:03<00:00, 97.61it/s]concatenating: train:  82%|████████▏ | 234/285 [00:03<00:00, 92.02it/s]concatenating: train:  86%|████████▌ | 245/285 [00:03<00:00, 96.65it/s]concatenating: train:  91%|█████████ | 258/285 [00:03<00:00, 102.74it/s]concatenating: train:  95%|█████████▌| 271/285 [00:03<00:00, 108.56it/s]concatenating: train: 100%|█████████▉| 284/285 [00:04<00:00, 112.98it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 69.26it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.74s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.72s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 23.49it/s]2019-07-10 20:44:42.284398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:44:42.284556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:44:42.284576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:44:42.284589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:44:42.285180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.88it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.72it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.93it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.41it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.95it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.41it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.10it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.04it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.54it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.18it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.80it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.69it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:02,  6.97it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:03,  3.97it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:03,  4.18it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.45it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  3.95it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  3.78it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  4.71it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  3.69it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.56it/s] min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 225,773
Trainable params: 51,073
Non-trainable params: 174,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 2.2084 - acc: 0.7199 - mDice: 0.1712 - val_loss: 1.5167 - val_acc: 0.9189 - val_mDice: 0.2886

Epoch 00001: val_mDice improved from -inf to 0.28859, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.8708 - acc: 0.9000 - mDice: 0.4055 - val_loss: 0.7687 - val_acc: 0.9257 - val_mDice: 0.4608

Epoch 00002: val_mDice improved from 0.28859 to 0.46084, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6669 - acc: 0.9091 - mDice: 0.4978 - val_loss: 0.5960 - val_acc: 0.9355 - val_mDice: 0.5374

Epoch 00003: val_mDice improved from 0.46084 to 0.53745, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.5749 - acc: 0.9192 - mDice: 0.5477 - val_loss: 0.5733 - val_acc: 0.9403 - val_mDice: 0.5530

Epoch 00004: val_mDice improved from 0.53745 to 0.55297, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5230 - acc: 0.9272 - mDice: 0.5778 - val_loss: 0.5510 - val_acc: 0.9427 - val_mDice: 0.5656

Epoch 00005: val_mDice improved from 0.55297 to 0.56562, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.4839 - acc: 0.9320 - mDice: 0.6017 - val_loss: 0.5495 - val_acc: 0.9387 - val_mDice: 0.5689

Epoch 00006: val_mDice improved from 0.56562 to 0.56894, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.4637 - acc: 0.9351 - mDice: 0.6145 - val_loss: 0.5452 - val_acc: 0.9401 - val_mDice: 0.5648

Epoch 00007: val_mDice did not improve from 0.56894
Epoch 8/300
 - 11s - loss: 0.4393 - acc: 0.9380 - mDice: 0.6303 - val_loss: 0.5320 - val_acc: 0.9444 - val_mDice: 0.5807

Epoch 00008: val_mDice improved from 0.56894 to 0.58068, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4213 - acc: 0.9401 - mDice: 0.6417 - val_loss: 0.5019 - val_acc: 0.9455 - val_mDice: 0.5950

Epoch 00009: val_mDice improved from 0.58068 to 0.59500, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.4076 - acc: 0.9415 - mDice: 0.6507 - val_loss: 0.4906 - val_acc: 0.9455 - val_mDice: 0.6008

Epoch 00010: val_mDice improved from 0.59500 to 0.60081, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 11s - loss: 0.3978 - acc: 0.9426 - mDice: 0.6575 - val_loss: 0.5148 - val_acc: 0.9443 - val_mDice: 0.5889

Epoch 00011: val_mDice did not improve from 0.60081
Epoch 12/300
 - 11s - loss: 0.3891 - acc: 0.9434 - mDice: 0.6633 - val_loss: 0.5084 - val_acc: 0.9467 - val_mDice: 0.5932

Epoch 00012: val_mDice did not improve from 0.60081
Epoch 13/300
 - 11s - loss: 0.3784 - acc: 0.9441 - mDice: 0.6705 - val_loss: 0.5133 - val_acc: 0.9455 - val_mDice: 0.5883

Epoch 00013: val_mDice did not improve from 0.60081
Epoch 14/300
 - 12s - loss: 0.3726 - acc: 0.9448 - mDice: 0.6747 - val_loss: 0.4860 - val_acc: 0.9459 - val_mDice: 0.6015

Epoch 00014: val_mDice improved from 0.60081 to 0.60154, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 12s - loss: 0.3637 - acc: 0.9455 - mDice: 0.6809 - val_loss: 0.5323 - val_acc: 0.9415 - val_mDice: 0.5778

Epoch 00015: val_mDice did not improve from 0.60154
Epoch 16/300
 - 11s - loss: 0.3589 - acc: 0.9460 - mDice: 0.6843 - val_loss: 0.5118 - val_acc: 0.9478 - val_mDice: 0.5910

Epoch 00016: val_mDice did not improve from 0.60154
Epoch 17/300
 - 11s - loss: 0.3538 - acc: 0.9465 - mDice: 0.6879 - val_loss: 0.5379 - val_acc: 0.9473 - val_mDice: 0.5799

Epoch 00017: val_mDice did not improve from 0.60154
Epoch 18/300
 - 12s - loss: 0.3494 - acc: 0.9468 - mDice: 0.6910 - val_loss: 0.5143 - val_acc: 0.9444 - val_mDice: 0.5876

Epoch 00018: val_mDice did not improve from 0.60154
Epoch 19/300
 - 11s - loss: 0.3437 - acc: 0.9472 - mDice: 0.6950 - val_loss: 0.4877 - val_acc: 0.9455 - val_mDice: 0.6040

Epoch 00019: val_mDice improved from 0.60154 to 0.60399, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 11s - loss: 0.3381 - acc: 0.9477 - mDice: 0.6991 - val_loss: 0.4985 - val_acc: 0.9457 - val_mDice: 0.5974

Epoch 00020: val_mDice did not improve from 0.60399
Epoch 21/300
 - 11s - loss: 0.3349 - acc: 0.9480 - mDice: 0.7014 - val_loss: 0.4922 - val_acc: 0.9457 - val_mDice: 0.6012

Epoch 00021: val_mDice did not improve from 0.60399
Epoch 22/300
 - 12s - loss: 0.3299 - acc: 0.9483 - mDice: 0.7050 - val_loss: 0.5183 - val_acc: 0.9468 - val_mDice: 0.5885

Epoch 00022: val_mDice did not improve from 0.60399
Epoch 23/300
 - 11s - loss: 0.3289 - acc: 0.9485 - mDice: 0.7058 - val_loss: 0.4878 - val_acc: 0.9464 - val_mDice: 0.6042

Epoch 00023: val_mDice improved from 0.60399 to 0.60420, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 11s - loss: 0.3239 - acc: 0.9487 - mDice: 0.7094 - val_loss: 0.5396 - val_acc: 0.9458 - val_mDice: 0.5764

Epoch 00024: val_mDice did not improve from 0.60420
Epoch 25/300
 - 11s - loss: 0.3220 - acc: 0.9490 - mDice: 0.7109 - val_loss: 0.4930 - val_acc: 0.9488 - val_mDice: 0.6010

Epoch 00025: val_mDice did not improve from 0.60420
Epoch 26/300
 - 12s - loss: 0.3186 - acc: 0.9493 - mDice: 0.7134 - val_loss: 0.5249 - val_acc: 0.9460 - val_mDice: 0.5822

Epoch 00026: val_mDice did not improve from 0.60420
Epoch 27/300
 - 11s - loss: 0.3152 - acc: 0.9495 - mDice: 0.7159 - val_loss: 0.4976 - val_acc: 0.9481 - val_mDice: 0.5956

Epoch 00027: val_mDice did not improve from 0.60420
Epoch 28/300
 - 11s - loss: 0.3119 - acc: 0.9496 - mDice: 0.7184 - val_loss: 0.5179 - val_acc: 0.9468 - val_mDice: 0.5893

Epoch 00028: val_mDice did not improve from 0.60420
Epoch 29/300
 - 12s - loss: 0.3099 - acc: 0.9498 - mDice: 0.7199 - val_loss: 0.5235 - val_acc: 0.9471 - val_mDice: 0.5841

Epoch 00029: val_mDice did not improve from 0.60420
Epoch 30/300
 - 11s - loss: 0.3094 - acc: 0.9500 - mDice: 0.7204 - val_loss: 0.4822 - val_acc: 0.9463 - val_mDice: 0.6045

Epoch 00030: val_mDice improved from 0.60420 to 0.60446, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 11s - loss: 0.3045 - acc: 0.9502 - mDice: 0.7239 - val_loss: 0.4845 - val_acc: 0.9481 - val_mDice: 0.6067

Epoch 00031: val_mDice improved from 0.60446 to 0.60673, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 11s - loss: 0.3018 - acc: 0.9504 - mDice: 0.7260 - val_loss: 0.5000 - val_acc: 0.9490 - val_mDice: 0.5974

Epoch 00032: val_mDice did not improve from 0.60673
Epoch 33/300
 - 12s - loss: 0.3026 - acc: 0.9504 - mDice: 0.7255 - val_loss: 0.5089 - val_acc: 0.9459 - val_mDice: 0.5932

Epoch 00033: val_mDice did not improve from 0.60673
Epoch 34/300
 - 11s - loss: 0.3003 - acc: 0.9507 - mDice: 0.7271 - val_loss: 0.5124 - val_acc: 0.9474 - val_mDice: 0.5910

Epoch 00034: val_mDice did not improve from 0.60673
Epoch 35/300
 - 11s - loss: 0.2971 - acc: 0.9508 - mDice: 0.7295 - val_loss: 0.5151 - val_acc: 0.9491 - val_mDice: 0.5927

Epoch 00035: val_mDice did not improve from 0.60673
Epoch 36/300
 - 12s - loss: 0.2960 - acc: 0.9509 - mDice: 0.7304 - val_loss: 0.5017 - val_acc: 0.9467 - val_mDice: 0.5977

Epoch 00036: val_mDice did not improve from 0.60673
Epoch 37/300
 - 11s - loss: 0.2935 - acc: 0.9511 - mDice: 0.7323 - val_loss: 0.5187 - val_acc: 0.9446 - val_mDice: 0.5882

Epoch 00037: val_mDice did not improve from 0.60673
Epoch 38/300
 - 11s - loss: 0.2932 - acc: 0.9511 - mDice: 0.7325 - val_loss: 0.5030 - val_acc: 0.9461 - val_mDice: 0.5952

Epoch 00038: val_mDice did not improve from 0.60673
Epoch 39/300
 - 12s - loss: 0.2896 - acc: 0.9514 - mDice: 0.7352 - val_loss: 0.4972 - val_acc: 0.9487 - val_mDice: 0.6022

Epoch 00039: val_mDice did not improve from 0.60673
Epoch 40/300
 - 11s - loss: 0.2887 - acc: 0.9515 - mDice: 0.7359 - val_loss: 0.5040 - val_acc: 0.9454 - val_mDice: 0.5995

Epoch 00040: val_mDice did not improve from 0.60673
Epoch 41/300
 - 11s - loss: 0.2864 - acc: 0.9517 - mDice: 0.7377 - val_loss: 0.5355 - val_acc: 0.9504 - val_mDice: 0.5913

Epoch 00041: val_mDice did not improve from 0.60673
Epoch 42/300
 - 12s - loss: 0.2870 - acc: 0.9516 - mDice: 0.7372 - val_loss: 0.5118 - val_acc: 0.9475 - val_mDice: 0.5967

Epoch 00042: val_mDice did not improve from 0.60673
Epoch 43/300
 - 11s - loss: 0.2856 - acc: 0.9518 - mDice: 0.7384 - val_loss: 0.5211 - val_acc: 0.9463 - val_mDice: 0.5889

Epoch 00043: val_mDice did not improve from 0.60673
Epoch 44/300
 - 12s - loss: 0.2832 - acc: 0.9518 - mDice: 0.7401 - val_loss: 0.5254 - val_acc: 0.9486 - val_mDice: 0.5885

Epoch 00044: val_mDice did not improve from 0.60673
Epoch 45/300
 - 11s - loss: 0.2830 - acc: 0.9519 - mDice: 0.7404 - val_loss: 0.5100 - val_acc: 0.9468 - val_mDice: 0.6010

Epoch 00045: val_mDice did not improve from 0.60673
Epoch 46/300
 - 12s - loss: 0.2813 - acc: 0.9520 - mDice: 0.7416 - val_loss: 0.5469 - val_acc: 0.9478 - val_mDice: 0.5825

Epoch 00046: val_mDice did not improve from 0.60673
Epoch 47/300
 - 11s - loss: 0.2808 - acc: 0.9519 - mDice: 0.7420 - val_loss: 0.5334 - val_acc: 0.9478 - val_mDice: 0.5883

Epoch 00047: val_mDice did not improve from 0.60673
Epoch 48/300
 - 12s - loss: 0.2778 - acc: 0.9522 - mDice: 0.7444 - val_loss: 0.5510 - val_acc: 0.9505 - val_mDice: 0.5832

Epoch 00048: val_mDice did not improve from 0.60673
Epoch 49/300
 - 11s - loss: 0.2786 - acc: 0.9522 - mDice: 0.7437 - val_loss: 0.5501 - val_acc: 0.9498 - val_mDice: 0.5875

Epoch 00049: val_mDice did not improve from 0.60673
Epoch 50/300
 - 11s - loss: 0.2790 - acc: 0.9521 - mDice: 0.7435 - val_loss: 0.5637 - val_acc: 0.9483 - val_mDice: 0.5804

Epoch 00050: val_mDice did not improve from 0.60673
Epoch 51/300
 - 12s - loss: 0.2756 - acc: 0.9525 - mDice: 0.7461 - val_loss: 0.5206 - val_acc: 0.9484 - val_mDice: 0.5902

Epoch 00051: val_mDice did not improve from 0.60673
Epoch 52/300
 - 11s - loss: 0.2755 - acc: 0.9526 - mDice: 0.7461 - val_loss: 0.5019 - val_acc: 0.9488 - val_mDice: 0.6031

Epoch 00052: val_mDice did not improve from 0.60673
Epoch 53/300
 - 11s - loss: 0.2750 - acc: 0.9526 - mDice: 0.7465 - val_loss: 0.5392 - val_acc: 0.9508 - val_mDice: 0.5825

Epoch 00053: val_mDice did not improve from 0.60673
Epoch 54/300
 - 12s - loss: 0.2742 - acc: 0.9526 - mDice: 0.7472 - val_loss: 0.5302 - val_acc: 0.9487 - val_mDice: 0.5953

Epoch 00054: val_mDice did not improve from 0.60673
Epoch 55/300
 - 11s - loss: 0.2737 - acc: 0.9527 - mDice: 0.7476 - val_loss: 0.5113 - val_acc: 0.9497 - val_mDice: 0.5983

Epoch 00055: val_mDice did not improve from 0.60673
Epoch 56/300
 - 12s - loss: 0.2711 - acc: 0.9530 - mDice: 0.7496 - val_loss: 0.5240 - val_acc: 0.9497 - val_mDice: 0.5895

Epoch 00056: val_mDice did not improve from 0.60673
Epoch 57/300
 - 11s - loss: 0.2714 - acc: 0.9529 - mDice: 0.7493 - val_loss: 0.5393 - val_acc: 0.9516 - val_mDice: 0.5860

Epoch 00057: val_mDice did not improve from 0.60673
Epoch 58/300
 - 12s - loss: 0.2695 - acc: 0.9530 - mDice: 0.7508 - val_loss: 0.4924 - val_acc: 0.9491 - val_mDice: 0.6039

Epoch 00058: val_mDice did not improve from 0.60673
Epoch 59/300
 - 11s - loss: 0.2695 - acc: 0.9530 - mDice: 0.7508 - val_loss: 0.5130 - val_acc: 0.9479 - val_mDice: 0.5940

Epoch 00059: val_mDice did not improve from 0.60673
Epoch 60/300
 - 11s - loss: 0.2677 - acc: 0.9531 - mDice: 0.7522 - val_loss: 0.5298 - val_acc: 0.9503 - val_mDice: 0.5872

Epoch 00060: val_mDice did not improve from 0.60673
Epoch 61/300
 - 12s - loss: 0.2665 - acc: 0.9532 - mDice: 0.7532 - val_loss: 0.5296 - val_acc: 0.9478 - val_mDice: 0.5888

Epoch 00061: val_mDice did not improve from 0.60673
Epoch 62/300
 - 11s - loss: 0.2687 - acc: 0.9532 - mDice: 0.7515 - val_loss: 0.5132 - val_acc: 0.9510 - val_mDice: 0.5984

Epoch 00062: val_mDice did not improve from 0.60673
Epoch 63/300
 - 12s - loss: 0.2662 - acc: 0.9534 - mDice: 0.7534 - val_loss: 0.5444 - val_acc: 0.9500 - val_mDice: 0.5802

Epoch 00063: val_mDice did not improve from 0.60673
Epoch 64/300
 - 12s - loss: 0.2635 - acc: 0.9534 - mDice: 0.7554 - val_loss: 0.5135 - val_acc: 0.9496 - val_mDice: 0.6003

Epoch 00064: val_mDice did not improve from 0.60673
Epoch 65/300
 - 11s - loss: 0.2636 - acc: 0.9535 - mDice: 0.7554 - val_loss: 0.5013 - val_acc: 0.9497 - val_mDice: 0.6018

Epoch 00065: val_mDice did not improve from 0.60673
Epoch 66/300
 - 12s - loss: 0.2640 - acc: 0.9535 - mDice: 0.7551 - val_loss: 0.5249 - val_acc: 0.9514 - val_mDice: 0.5972

Epoch 00066: val_mDice did not improve from 0.60673
Epoch 67/300
 - 12s - loss: 0.2630 - acc: 0.9536 - mDice: 0.7560 - val_loss: 0.5394 - val_acc: 0.9496 - val_mDice: 0.5904

Epoch 00067: val_mDice did not improve from 0.60673
Epoch 68/300
 - 11s - loss: 0.2623 - acc: 0.9535 - mDice: 0.7565 - val_loss: 0.5033 - val_acc: 0.9489 - val_mDice: 0.5977

Epoch 00068: val_mDice did not improve from 0.60673
Epoch 69/300
 - 12s - loss: 0.2618 - acc: 0.9537 - mDice: 0.7568 - val_loss: 0.4989 - val_acc: 0.9474 - val_mDice: 0.5978

Epoch 00069: val_mDice did not improve from 0.60673
Epoch 70/300
 - 11s - loss: 0.2608 - acc: 0.9537 - mDice: 0.7576 - val_loss: 0.5049 - val_acc: 0.9511 - val_mDice: 0.5980

Epoch 00070: val_mDice did not improve from 0.60673
Epoch 71/300
 - 12s - loss: 0.2619 - acc: 0.9538 - mDice: 0.7570 - val_loss: 0.4850 - val_acc: 0.9462 - val_mDice: 0.6079

Epoch 00071: val_mDice improved from 0.60673 to 0.60795, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 12s - loss: 0.2616 - acc: 0.9537 - mDice: 0.7570 - val_loss: 0.5345 - val_acc: 0.9489 - val_mDice: 0.5875

Epoch 00072: val_mDice did not improve from 0.60795
Epoch 73/300
 - 12s - loss: 0.2587 - acc: 0.9539 - mDice: 0.7592 - val_loss: 0.5151 - val_acc: 0.9494 - val_mDice: 0.5978

Epoch 00073: val_mDice did not improve from 0.60795
Epoch 74/300
 - 12s - loss: 0.2590 - acc: 0.9539 - mDice: 0.7591 - val_loss: 0.5614 - val_acc: 0.9484 - val_mDice: 0.5813

Epoch 00074: val_mDice did not improve from 0.60795
Epoch 75/300
 - 12s - loss: 0.2593 - acc: 0.9539 - mDice: 0.7589 - val_loss: 0.5530 - val_acc: 0.9471 - val_mDice: 0.5835

Epoch 00075: val_mDice did not improve from 0.60795
Epoch 76/300
 - 12s - loss: 0.2571 - acc: 0.9541 - mDice: 0.7606 - val_loss: 0.5281 - val_acc: 0.9493 - val_mDice: 0.5942

Epoch 00076: val_mDice did not improve from 0.60795
Epoch 77/300
 - 12s - loss: 0.2573 - acc: 0.9539 - mDice: 0.7604 - val_loss: 0.5308 - val_acc: 0.9518 - val_mDice: 0.5956

Epoch 00077: val_mDice did not improve from 0.60795
Epoch 78/300
 - 12s - loss: 0.2561 - acc: 0.9542 - mDice: 0.7614 - val_loss: 0.5360 - val_acc: 0.9494 - val_mDice: 0.5925

Epoch 00078: val_mDice did not improve from 0.60795
Epoch 79/300
 - 12s - loss: 0.2566 - acc: 0.9541 - mDice: 0.7610 - val_loss: 0.5092 - val_acc: 0.9485 - val_mDice: 0.5982

Epoch 00079: val_mDice did not improve from 0.60795
Epoch 80/300
 - 12s - loss: 0.2569 - acc: 0.9541 - mDice: 0.7608 - val_loss: 0.5176 - val_acc: 0.9455 - val_mDice: 0.5925

Epoch 00080: val_mDice did not improve from 0.60795
Epoch 81/300
 - 11s - loss: 0.2562 - acc: 0.9541 - mDice: 0.7613 - val_loss: 0.5094 - val_acc: 0.9507 - val_mDice: 0.5960

Epoch 00081: val_mDice did not improve from 0.60795
Epoch 82/300
 - 12s - loss: 0.2570 - acc: 0.9542 - mDice: 0.7610 - val_loss: 0.5300 - val_acc: 0.9505 - val_mDice: 0.5856

Epoch 00082: val_mDice did not improve from 0.60795
Epoch 83/300
 - 12s - loss: 0.2549 - acc: 0.9542 - mDice: 0.7625 - val_loss: 0.5042 - val_acc: 0.9500 - val_mDice: 0.6029

Epoch 00083: val_mDice did not improve from 0.60795
Epoch 84/300
 - 12s - loss: 0.2531 - acc: 0.9544 - mDice: 0.7638 - val_loss: 0.5041 - val_acc: 0.9481 - val_mDice: 0.5984

Epoch 00084: val_mDice did not improve from 0.60795
Epoch 85/300
 - 12s - loss: 0.2533 - acc: 0.9544 - mDice: 0.7638 - val_loss: 0.5130 - val_acc: 0.9480 - val_mDice: 0.6001

Epoch 00085: val_mDice did not improve from 0.60795
Epoch 86/300
 - 12s - loss: 0.2522 - acc: 0.9544 - mDice: 0.7645 - val_loss: 0.4909 - val_acc: 0.9509 - val_mDice: 0.6102

Epoch 00086: val_mDice improved from 0.60795 to 0.61019, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 87/300
 - 11s - loss: 0.2594 - acc: 0.9544 - mDice: 0.7641 - val_loss: 0.5132 - val_acc: 0.9505 - val_mDice: 0.6053

Epoch 00087: val_mDice did not improve from 0.61019
Epoch 88/300
 - 12s - loss: 0.2523 - acc: 0.9544 - mDice: 0.7645 - val_loss: 0.5327 - val_acc: 0.9493 - val_mDice: 0.5915

Epoch 00088: val_mDice did not improve from 0.61019
Epoch 89/300
 - 12s - loss: 0.2527 - acc: 0.9545 - mDice: 0.7642 - val_loss: 0.4908 - val_acc: 0.9503 - val_mDice: 0.6118

Epoch 00089: val_mDice improved from 0.61019 to 0.61184, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 90/300
 - 11s - loss: 0.2525 - acc: 0.9544 - mDice: 0.7643 - val_loss: 0.5263 - val_acc: 0.9489 - val_mDice: 0.5935

Epoch 00090: val_mDice did not improve from 0.61184
Epoch 91/300
 - 12s - loss: 0.2515 - acc: 0.9545 - mDice: 0.7651 - val_loss: 0.5105 - val_acc: 0.9505 - val_mDice: 0.5988

Epoch 00091: val_mDice did not improve from 0.61184
Epoch 92/300
 - 11s - loss: 0.2504 - acc: 0.9545 - mDice: 0.7659 - val_loss: 0.5175 - val_acc: 0.9494 - val_mDice: 0.6004

Epoch 00092: val_mDice did not improve from 0.61184
Epoch 93/300
 - 12s - loss: 0.2510 - acc: 0.9545 - mDice: 0.7656 - val_loss: 0.5064 - val_acc: 0.9509 - val_mDice: 0.6010

Epoch 00093: val_mDice did not improve from 0.61184
Epoch 94/300
 - 12s - loss: 0.2501 - acc: 0.9547 - mDice: 0.7663 - val_loss: 0.5087 - val_acc: 0.9515 - val_mDice: 0.6007

Epoch 00094: val_mDice did not improve from 0.61184
Epoch 95/300
 - 12s - loss: 0.2478 - acc: 0.9548 - mDice: 0.7680 - val_loss: 0.5003 - val_acc: 0.9524 - val_mDice: 0.6032

Epoch 00095: val_mDice did not improve from 0.61184
Epoch 96/300
 - 12s - loss: 0.2491 - acc: 0.9547 - mDice: 0.7670 - val_loss: 0.5387 - val_acc: 0.9486 - val_mDice: 0.5875

Epoch 00096: val_mDice did not improve from 0.61184
Epoch 97/300
 - 12s - loss: 0.2492 - acc: 0.9547 - mDice: 0.7669 - val_loss: 0.5197 - val_acc: 0.9514 - val_mDice: 0.5966

Epoch 00097: val_mDice did not improve from 0.61184
Epoch 98/300
 - 12s - loss: 0.2478 - acc: 0.9548 - mDice: 0.7681 - val_loss: 0.5316 - val_acc: 0.9505 - val_mDice: 0.5976

Epoch 00098: val_mDice did not improve from 0.61184
Epoch 99/300
 - 12s - loss: 0.2484 - acc: 0.9548 - mDice: 0.7676 - val_loss: 0.5174 - val_acc: 0.9508 - val_mDice: 0.5974

Epoch 00099: val_mDice did not improve from 0.61184
Epoch 100/300
 - 12s - loss: 0.2471 - acc: 0.9549 - mDice: 0.7686 - val_loss: 0.4959 - val_acc: 0.9499 - val_mDice: 0.6060

Epoch 00100: val_mDice did not improve from 0.61184
Epoch 101/300
 - 11s - loss: 0.2502 - acc: 0.9548 - mDice: 0.7671 - val_loss: 0.5552 - val_acc: 0.9468 - val_mDice: 0.5740

Epoch 00101: val_mDice did not improve from 0.61184
Epoch 102/300
 - 12s - loss: 0.3814 - acc: 0.9444 - mDice: 0.6717 - val_loss: 0.4999 - val_acc: 0.9463 - val_mDice: 0.5996

Epoch 00102: val_mDice did not improve from 0.61184
Epoch 103/300
 - 11s - loss: 0.2897 - acc: 0.9516 - mDice: 0.7351 - val_loss: 0.5088 - val_acc: 0.9488 - val_mDice: 0.5986

Epoch 00103: val_mDice did not improve from 0.61184
Epoch 104/300
 - 13s - loss: 0.2723 - acc: 0.9529 - mDice: 0.7486 - val_loss: 0.5159 - val_acc: 0.9513 - val_mDice: 0.5966

Epoch 00104: val_mDice did not improve from 0.61184
Epoch 105/300
 - 12s - loss: 0.2639 - acc: 0.9535 - mDice: 0.7551 - val_loss: 0.5229 - val_acc: 0.9526 - val_mDice: 0.5954

Epoch 00105: val_mDice did not improve from 0.61184
Epoch 106/300
 - 12s - loss: 0.2596 - acc: 0.9539 - mDice: 0.7586 - val_loss: 0.4846 - val_acc: 0.9530 - val_mDice: 0.6111

Epoch 00106: val_mDice did not improve from 0.61184
Epoch 107/300
 - 12s - loss: 0.2558 - acc: 0.9542 - mDice: 0.7617 - val_loss: 0.5078 - val_acc: 0.9518 - val_mDice: 0.5983

Epoch 00107: val_mDice did not improve from 0.61184
Epoch 108/300
 - 12s - loss: 0.2541 - acc: 0.9543 - mDice: 0.7631 - val_loss: 0.5102 - val_acc: 0.9506 - val_mDice: 0.5959

Epoch 00108: val_mDice did not improve from 0.61184
Epoch 109/300
 - 12s - loss: 0.2517 - acc: 0.9545 - mDice: 0.7649 - val_loss: 0.5210 - val_acc: 0.9501 - val_mDice: 0.5966

Epoch 00109: val_mDice did not improve from 0.61184
Epoch 110/300
 - 11s - loss: 0.2505 - acc: 0.9545 - mDice: 0.7658 - val_loss: 0.5201 - val_acc: 0.9526 - val_mDice: 0.5996

Epoch 00110: val_mDice did not improve from 0.61184
Epoch 111/300
 - 12s - loss: 0.2489 - acc: 0.9547 - mDice: 0.7672 - val_loss: 0.5453 - val_acc: 0.9522 - val_mDice: 0.5931

Epoch 00111: val_mDice did not improve from 0.61184
Epoch 112/300
 - 11s - loss: 0.2480 - acc: 0.9548 - mDice: 0.7679 - val_loss: 0.5489 - val_acc: 0.9521 - val_mDice: 0.5887

Epoch 00112: val_mDice did not improve from 0.61184
Epoch 113/300
 - 11s - loss: 0.2479 - acc: 0.9548 - mDice: 0.7680 - val_loss: 0.5151 - val_acc: 0.9517 - val_mDice: 0.5961

Epoch 00113: val_mDice did not improve from 0.61184
Epoch 114/300
 - 11s - loss: 0.2460 - acc: 0.9549 - mDice: 0.7696 - val_loss: 0.5034 - val_acc: 0.9507 - val_mDice: 0.6044

Epoch 00114: val_mDice did not improve from 0.61184
Epoch 115/300
 - 11s - loss: 0.2453 - acc: 0.9549 - mDice: 0.7701 - val_loss: 0.5061 - val_acc: 0.9514 - val_mDice: 0.6008

Epoch 00115: val_mDice did not improve from 0.61184
Epoch 116/300
 - 12s - loss: 0.2448 - acc: 0.9550 - mDice: 0.7705 - val_loss: 0.5041 - val_acc: 0.9518 - val_mDice: 0.6076

Epoch 00116: val_mDice did not improve from 0.61184
Epoch 117/300
 - 11s - loss: 0.2439 - acc: 0.9550 - mDice: 0.7712 - val_loss: 0.5091 - val_acc: 0.9534 - val_mDice: 0.6012

Epoch 00117: val_mDice did not improve from 0.61184
Epoch 118/300
 - 11s - loss: 0.2444 - acc: 0.9550 - mDice: 0.7708 - val_loss: 0.5283 - val_acc: 0.9521 - val_mDice: 0.5930

Epoch 00118: val_mDice did not improve from 0.61184
Epoch 119/300
 - 11s - loss: 0.2479 - acc: 0.9549 - mDice: 0.7681 - val_loss: 0.4999 - val_acc: 0.9514 - val_mDice: 0.6011

Epoch 00119: val_mDice did not improve from 0.61184
Epoch 120/300
 - 11s - loss: 0.2433 - acc: 0.9552 - mDice: 0.7717 - val_loss: 0.5016 - val_acc: 0.9488 - val_mDice: 0.6000

Epoch 00120: val_mDice did not improve from 0.61184
Epoch 121/300
 - 11s - loss: 0.2443 - acc: 0.9551 - mDice: 0.7710 - val_loss: 0.5103 - val_acc: 0.9515 - val_mDice: 0.5998

Epoch 00121: val_mDice did not improve from 0.61184
Epoch 122/300
 - 11s - loss: 0.2430 - acc: 0.9551 - mDice: 0.7719 - val_loss: 0.4934 - val_acc: 0.9525 - val_mDice: 0.6067

Epoch 00122: val_mDice did not improve from 0.61184
Epoch 123/300
 - 12s - loss: 0.2425 - acc: 0.9552 - mDice: 0.7724 - val_loss: 0.5171 - val_acc: 0.9506 - val_mDice: 0.5966

Epoch 00123: val_mDice did not improve from 0.61184
Epoch 124/300
 - 12s - loss: 0.2435 - acc: 0.9551 - mDice: 0.7716 - val_loss: 0.4932 - val_acc: 0.9520 - val_mDice: 0.6066

Epoch 00124: val_mDice did not improve from 0.61184
Epoch 125/300
 - 11s - loss: 0.2419 - acc: 0.9552 - mDice: 0.7728 - val_loss: 0.4907 - val_acc: 0.9516 - val_mDice: 0.6092

Epoch 00125: val_mDice did not improve from 0.61184
Epoch 126/300
 - 11s - loss: 0.2419 - acc: 0.9551 - mDice: 0.7728 - val_loss: 0.5272 - val_acc: 0.9524 - val_mDice: 0.5974

Epoch 00126: val_mDice did not improve from 0.61184
Epoch 127/300
 - 11s - loss: 0.2417 - acc: 0.9552 - mDice: 0.7730 - val_loss: 0.5039 - val_acc: 0.9509 - val_mDice: 0.6035

Epoch 00127: val_mDice did not improve from 0.61184
Epoch 128/300
 - 11s - loss: 0.2419 - acc: 0.9552 - mDice: 0.7729 - val_loss: 0.5267 - val_acc: 0.9511 - val_mDice: 0.5952

Epoch 00128: val_mDice did not improve from 0.61184
Epoch 129/300
 - 11s - loss: 0.2420 - acc: 0.9551 - mDice: 0.7728 - val_loss: 0.5221 - val_acc: 0.9527 - val_mDice: 0.5992

Epoch 00129: val_mDice did not improve from 0.61184
Restoring model weights from the end of the best epoch
Epoch 00129: early stopping
{'val_loss': [1.5166510663219004, 0.7686663559695196, 0.5960325219111735, 0.5733163130349953, 0.5510137191031899, 0.5494738357693123, 0.5452295438537385, 0.5319914591379006, 0.501917118799753, 0.4905971814800241, 0.514790762070171, 0.5083968286407726, 0.5132812291550237, 0.48596887015763607, 0.5323383428530986, 0.511768071012124, 0.5378942186605997, 0.5142630668325797, 0.48771882390176785, 0.4984549157446323, 0.4922454500331559, 0.5183249845185094, 0.4877588405955437, 0.5395612213864672, 0.492985286193187, 0.5249103167869525, 0.4975551003850372, 0.5179089514236876, 0.523473345700589, 0.4821987748146057, 0.48445982806509436, 0.4999638109899766, 0.5089065742226286, 0.5123968220955832, 0.5150621546713333, 0.5016512987333969, 0.5187473350397035, 0.5029756786437009, 0.49715956829113667, 0.5039678861975004, 0.5354787061334322, 0.5117991476751572, 0.5210579157541584, 0.5254439391903372, 0.5100120069594357, 0.5468848880442827, 0.5334401293839822, 0.5509785736739302, 0.5500729340414762, 0.5636745508156675, 0.5205613111650478, 0.501938093307964, 0.5392493002907524, 0.5302404338421103, 0.5112628657058631, 0.5239702952640682, 0.5392868781888951, 0.4924476829321025, 0.5130297891254532, 0.5298435901130378, 0.5295621562936452, 0.5132310610243728, 0.5444350925237773, 0.5134679954811181, 0.5012603245633941, 0.5249315896513742, 0.5394048754063399, 0.5033405263330684, 0.49894601273137096, 0.5048727702828093, 0.4849838864203938, 0.5345078979790544, 0.5151178896760141, 0.5613575371284059, 0.5529693261871125, 0.5280693899319825, 0.5307857490784629, 0.5360434148564684, 0.5092175499686982, 0.5175664208454793, 0.5094360033227079, 0.5300434474838512, 0.5042025640024154, 0.5041356855930563, 0.51297204021635, 0.49093902510637677, 0.5131873055543313, 0.5327452191427433, 0.4908117249025313, 0.5262563638180994, 0.5104928889088125, 0.5174589510070545, 0.5063985189912039, 0.5086997394455212, 0.5002943723561377, 0.5386693317796931, 0.5196906065141689, 0.5315559256676189, 0.5173946049626313, 0.49594769864108973, 0.5551650950362562, 0.49987902787810595, 0.5087552190492939, 0.5158742136795428, 0.5229340978174902, 0.48458123972962025, 0.5078354074968306, 0.5102416929585973, 0.5209523286233401, 0.5201472310380563, 0.5452969690274926, 0.5488789807484803, 0.5150975465108563, 0.5033906135479165, 0.5061486706387397, 0.5040585455281774, 0.5091001501296486, 0.5282700967522307, 0.4998897280772971, 0.5015954838118739, 0.510303943183835, 0.4934058845376169, 0.5170863986681293, 0.49318565070296133, 0.49074542489131734, 0.5271782825113008, 0.5038561078423228, 0.5267171743195816, 0.5220535807103418], 'val_acc': [0.9188725302339266, 0.9256512232998896, 0.9355124844519119, 0.9403283978973687, 0.942714694158991, 0.9387437444825412, 0.9400867023947519, 0.9444047092725445, 0.9455204166513581, 0.9454584181641733, 0.944317936564291, 0.9466567319198693, 0.9454956104635527, 0.9459108723608475, 0.9414874764794078, 0.9477682380036935, 0.9472909802831085, 0.9443882134373628, 0.9454852852075459, 0.9457021921706599, 0.9457414676357248, 0.9468468004764792, 0.9463612836832441, 0.9457972362720767, 0.9488219402355855, 0.946032791830308, 0.9480513014606924, 0.9467724175426547, 0.9470596033767615, 0.9463488669368808, 0.9480946866493651, 0.9490451013575719, 0.9459439139792373, 0.9474252762075243, 0.949102922191833, 0.9466753049269735, 0.9445803408516186, 0.9461422885596419, 0.9487021109245343, 0.9454356778267375, 0.9504479396276634, 0.9475037818514435, 0.9462538574660957, 0.9486380529137297, 0.946840623903541, 0.9478178403896993, 0.9478364370388692, 0.9505305633198615, 0.9498053915673794, 0.9482599606727089, 0.9483818784772351, 0.9488364051840159, 0.9507681464349758, 0.9486670017908405, 0.9497330761488589, 0.9496648877692622, 0.9515615152247126, 0.9491359797935912, 0.947859147740476, 0.9502702565166538, 0.94778066707057, 0.9509892160666056, 0.9500429810092436, 0.9496028896150642, 0.9496524936660042, 0.9513610894453592, 0.9496173772065999, 0.9488632365977964, 0.9474438915039574, 0.9510821833290868, 0.9462352701405573, 0.9489045975594547, 0.9493880564940043, 0.948365349676356, 0.9470513413072298, 0.9492764752670373, 0.9518114997687952, 0.9494314406837165, 0.9485409642731011, 0.9455017936962277, 0.9506607148900378, 0.9504789090689334, 0.9500057973675222, 0.9481442780468051, 0.9480058534185314, 0.9509334331118194, 0.9504665229573596, 0.9493012578127771, 0.9503322243690491, 0.9488508514851831, 0.9505346900257985, 0.9494066235073452, 0.9508507837796344, 0.9515160675155384, 0.9524106486549591, 0.9485595402770868, 0.951447872143218, 0.95048510162524, 0.9508384183132449, 0.9498962896496224, 0.9467765449145653, 0.946276579489255, 0.9488074836118261, 0.9512846536476519, 0.9526069227543623, 0.9529747157123502, 0.951803245357961, 0.9505801470586042, 0.9501256050344286, 0.9526461948895587, 0.9521586085830986, 0.9520594121357582, 0.9517268072293458, 0.9506586550334313, 0.9513941673593148, 0.9518404533077218, 0.9533879070974595, 0.9520862875038019, 0.9514189562318045, 0.9488426223813489, 0.9514726939814051, 0.9525284054559037, 0.9506173343631809, 0.9520036471622616, 0.9515594387187638, 0.9523962060166471, 0.950867324235053, 0.9510821836620735, 0.9526937084491026], 'val_mDice': [0.28858892428142396, 0.46084014413743046, 0.5374459421168493, 0.5529664621672816, 0.5656174574484373, 0.5689363313120837, 0.5648424462233176, 0.5806794273120731, 0.5950023998095336, 0.600805511687721, 0.5888609173577591, 0.5931929536371924, 0.5883230643565428, 0.6015380807429053, 0.5778435079079101, 0.5910015226076435, 0.5799370521273692, 0.5875552489770858, 0.6039856342630013, 0.5973606675696772, 0.6012132440865373, 0.5884743053153907, 0.6041996305881265, 0.5764354643874994, 0.6009986047638195, 0.5822121577555907, 0.5955915517647173, 0.5892614712262286, 0.5840913470230955, 0.6044632133158891, 0.6067294808073417, 0.5973743413413704, 0.5931969314980108, 0.5909591000839318, 0.5927302274624062, 0.5976912052937726, 0.5881792872977656, 0.5951584141347661, 0.602248804529286, 0.5994827437667207, 0.5913004099323763, 0.5967083273653212, 0.5889191284525994, 0.5884767074824712, 0.600976412855713, 0.582548177775058, 0.5883404895580014, 0.5832006085518352, 0.587547755774173, 0.5804239474861316, 0.5902035948950485, 0.6030934716070164, 0.5824977589053149, 0.595284653442532, 0.5982597250512193, 0.5894608717390944, 0.5859891302758755, 0.6039304946387947, 0.5939877079851801, 0.5871725342127198, 0.5888497449832255, 0.5984420320175213, 0.5801644431812137, 0.600345131405239, 0.601778729001903, 0.5971872486881704, 0.5903879563901677, 0.5977192804134092, 0.5978107798698894, 0.5980446312014617, 0.6079477910888927, 0.5874957052689025, 0.597841627770962, 0.5812781083517234, 0.5834905894774964, 0.5941702586978508, 0.595608590368452, 0.5925462186003531, 0.598247766494751, 0.5925428727485614, 0.5959851412133798, 0.5855851353213773, 0.6029108955873458, 0.5983587436835859, 0.6000869820237825, 0.6101852488917345, 0.6052734242471237, 0.5914848982954825, 0.6118421884222404, 0.5934743541579007, 0.5988250990819665, 0.6004483679819373, 0.6010193538399382, 0.600652226855635, 0.6032013083969414, 0.5875187179895752, 0.5966039489767405, 0.5975959617332374, 0.5974378689041351, 0.6059935878774974, 0.573977715809252, 0.5995689474004607, 0.5986232041646649, 0.5965541461326557, 0.5953793482407511, 0.6110581665731675, 0.5982742076479522, 0.5958990261541398, 0.5966365147569326, 0.5996049749118656, 0.5931461829712937, 0.5887367905185209, 0.5960855274227078, 0.604423482324824, 0.60075534355707, 0.6075791739884702, 0.6012310215880751, 0.5930246937208336, 0.6010814092678731, 0.599952472321814, 0.5997618393525065, 0.6066819429397583, 0.5966284035304406, 0.6065729476886088, 0.6092060484699697, 0.5973786175583994, 0.6035100704464833, 0.5952323119067613, 0.5992030684508425], 'loss': [2.208418233625367, 0.8708452916886771, 0.6668874792112296, 0.5749334856566699, 0.5229917874744493, 0.4838712302390984, 0.4636863860392011, 0.4392539447646315, 0.42130924615132304, 0.40759859126927345, 0.3978240435146557, 0.38913935476136063, 0.3784167232658081, 0.3725698489011435, 0.3636945492204164, 0.3588570384400504, 0.35375072852724176, 0.34944579559216266, 0.343732958833712, 0.33809705964750625, 0.33494716149374754, 0.32987021969285485, 0.3289265806612889, 0.32388487794541965, 0.3219685537477742, 0.31861793030114044, 0.31516163604048225, 0.3118997124582651, 0.30989615867278275, 0.3094020159303879, 0.3044530238375335, 0.30178190304604396, 0.30262200972670456, 0.30034398140032614, 0.2971430521185093, 0.29602156704881405, 0.29347371034753084, 0.29317496800648607, 0.28956109337294833, 0.28867366481636303, 0.28638472437637835, 0.2869798927244541, 0.2856195363144126, 0.28316124386013763, 0.28295797399819844, 0.28130444960262796, 0.2807858222746056, 0.27778501960974256, 0.2785637045414981, 0.278982992558157, 0.2755524573791755, 0.2755055824398871, 0.2750111251223822, 0.2741725423400824, 0.2736663649180351, 0.27114876429698714, 0.2713567928842363, 0.26945544224270784, 0.2694843419220419, 0.26771233163753316, 0.26648716236484005, 0.268673100227897, 0.2662243855073557, 0.26347996135675, 0.2636356788174752, 0.26403902625344194, 0.26295996607112815, 0.2622825226199555, 0.26178347124142376, 0.2608075367148734, 0.2618780649748446, 0.2616447538427977, 0.2587253007177343, 0.25899930663776516, 0.25925907752825655, 0.2571109103277406, 0.2572779537893109, 0.25607004231581026, 0.2566487380936413, 0.2568853737955928, 0.2562149320657811, 0.2570320156603089, 0.25490779339143976, 0.2530824677317395, 0.25326907577438557, 0.252214777510051, 0.2593888122397475, 0.25225271926285375, 0.25265511024245624, 0.2525477971291011, 0.2515311413932279, 0.2504063196905129, 0.25098500772762855, 0.2500871290315776, 0.24783051311466586, 0.24908882158948253, 0.24918421770673088, 0.24780256126637384, 0.24838877869443782, 0.24706588642337238, 0.25015985772900706, 0.38142444016685295, 0.2896772040455217, 0.2722773375717502, 0.2639311554206495, 0.25963964958504115, 0.25577230064036977, 0.25405022644943404, 0.2517059073026621, 0.25051470452531166, 0.2489252718833334, 0.24800228385986062, 0.247906791201981, 0.2459960577786407, 0.24530437080408, 0.24476706107602478, 0.24386650196451953, 0.2444452773423556, 0.24792612433907488, 0.2432665912141585, 0.24431107508646663, 0.24301936989399053, 0.24251202743827735, 0.24345439941423028, 0.24190542803621065, 0.24194488740260808, 0.24168473001684954, 0.2418511974143473, 0.24198370773959385], 'acc': [0.7199194992583897, 0.8999649803432386, 0.909128567412959, 0.9191894673955745, 0.927156069940825, 0.9319539923117601, 0.935054749940243, 0.9380401213388155, 0.9401419275947454, 0.9414918099143889, 0.9425988426350552, 0.9434044124754054, 0.9441310841886185, 0.9448335082479944, 0.9455154655701805, 0.9460462813841986, 0.9465190688351337, 0.9467924331490312, 0.9472475953399729, 0.9477414295802052, 0.9480282492506745, 0.9483406074484295, 0.948453907593683, 0.948692060894621, 0.9489505810906675, 0.9492506510707186, 0.9494842739933931, 0.9496212787867359, 0.9498280139441039, 0.9499924296965546, 0.9502343334512029, 0.9504250757679051, 0.9503935540555434, 0.950653566088229, 0.9507988833224135, 0.9509414500332133, 0.9511020982338838, 0.9511047148391589, 0.9514184860347967, 0.9514876120549246, 0.9516610516116846, 0.9516036898071395, 0.9517612969730552, 0.9518275049983088, 0.9519012835893059, 0.9520120030556828, 0.9519463182859097, 0.9522362202673746, 0.952179764465766, 0.9521246136523599, 0.9524941342983699, 0.9526082371796705, 0.952597017739049, 0.9526322254732825, 0.9527110016285597, 0.9529750812294553, 0.9528556619131463, 0.953049745845883, 0.9530210831210632, 0.9531400202276478, 0.9531943407539683, 0.9531633461893569, 0.9533761411306353, 0.953449982932876, 0.9535154028270222, 0.9535410042993578, 0.9535649512388187, 0.9535152987161043, 0.9536661831461704, 0.9537343446137527, 0.953792571992268, 0.9536987735317343, 0.9538708633537951, 0.9539460120335636, 0.9538983774077404, 0.9540590471311382, 0.9539431135032855, 0.9541709126421624, 0.9541158874818789, 0.9541138325938147, 0.9541000563798013, 0.954175970336982, 0.9542064453403607, 0.9543707227922461, 0.9543552734410216, 0.9544474211895325, 0.9544014161458028, 0.9543801869489575, 0.9544601715323283, 0.9543816803957433, 0.9545371525201017, 0.9545418261494826, 0.9545155996967521, 0.954674095543542, 0.954772188833457, 0.9547220341657139, 0.9546828370300502, 0.9548072515213895, 0.9547688003608549, 0.9548716474433824, 0.954812410791795, 0.9444391715793423, 0.9515621780109109, 0.9528933436767604, 0.9534586028078595, 0.9538956390903066, 0.9542031015460836, 0.9543318874104519, 0.9544985402637393, 0.9544907256341644, 0.9546850742899536, 0.95476322610435, 0.954798553625708, 0.9549487084418131, 0.9548971662171545, 0.9550316131431146, 0.955030442014589, 0.9550120533827402, 0.9548509416773158, 0.9551739540535616, 0.9551021493790774, 0.9551254114413351, 0.9551808434882901, 0.955127626584445, 0.9552089606655377, 0.9550817232656295, 0.9551723647543524, 0.9551627530614559, 0.955113285280353], 'mDice': [0.171207142869131, 0.40553785035094825, 0.49779997252864805, 0.5477057335800182, 0.5778318644641214, 0.6016901732237729, 0.6145400073129519, 0.6302716896123768, 0.6417332230151319, 0.6506881065458509, 0.6575414770393939, 0.6633002484366107, 0.670521963630183, 0.6747172172536622, 0.6809057131337416, 0.6843215863849205, 0.687896228941637, 0.6910266565812984, 0.6950262257634837, 0.699100730527714, 0.7014272763126459, 0.7049749698405704, 0.7058492352692275, 0.7094367290723493, 0.7108566177338662, 0.7133822815947125, 0.715934940065137, 0.7184314061357762, 0.7199258135915627, 0.7204094003322149, 0.7238505566135081, 0.7260226971553462, 0.7254919555833751, 0.7271435025938001, 0.729480548164929, 0.7304492126485828, 0.7322667420582407, 0.7325134435566635, 0.7352118896351201, 0.73592525825126, 0.7376796300683521, 0.7372360836478543, 0.7383670464955827, 0.7401119461279537, 0.7403587068901636, 0.7416002685828547, 0.7419567450537712, 0.7443582371431565, 0.7436589454489138, 0.7434636834309087, 0.7460506977413508, 0.7461405629088732, 0.746508464568594, 0.7471642320396711, 0.7476283766872632, 0.7495635283856174, 0.7493472922134617, 0.7507891514437514, 0.7507889788366728, 0.7522126150757105, 0.7531587944643137, 0.7514843240970296, 0.7534341143598277, 0.7554344013556501, 0.7554217367661518, 0.7551032704768387, 0.7559562258799347, 0.7565162857336765, 0.7568476588291954, 0.7576315744881095, 0.7569529547046507, 0.7570461240100949, 0.7592415839334659, 0.7591421493653684, 0.7588897907852731, 0.7606082052831575, 0.7604402611344074, 0.7614215239480744, 0.7609981501175813, 0.760765512500815, 0.7612757602033257, 0.7609704404697654, 0.7624824768635619, 0.7638496214038087, 0.7637535624271398, 0.7644875696051985, 0.7641425481659869, 0.7644502521989575, 0.7642499929672687, 0.7642689798173156, 0.765065652327784, 0.765899722712874, 0.7655950453044945, 0.7662637183481972, 0.7680042282012246, 0.7669961495919136, 0.7669276567684735, 0.7680569539551355, 0.767647381039475, 0.768582505991786, 0.7670616481430254, 0.6717454962861297, 0.7350929543431967, 0.7485617819801602, 0.7550911258348784, 0.7585653117211918, 0.7616798245960718, 0.7630605190240846, 0.76488826173069, 0.7657716597134846, 0.7671582987187612, 0.7679005515425431, 0.7680025057435315, 0.7695840766023339, 0.7701451647132967, 0.7705241003546033, 0.7712404674275055, 0.7707934580164261, 0.7680537475037761, 0.7717250656097336, 0.7709554857460024, 0.7719036374604492, 0.7723702823704777, 0.7715955925600687, 0.7727840498092226, 0.772806448566648, 0.7730005915586572, 0.7728704040778059, 0.772753330527759]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:51,  1.87s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:11,  1.74s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:07,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:44,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:55,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:31,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:47,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:38,  1.66s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:11,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:32,  1.86s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:13,  1.80s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:29,  1.87s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:04,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:10,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:24,  1.87s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:36,  1.92s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:05,  1.81s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:06,  1.82s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:49,  1.76s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:52,  1.78s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:06,  1.84s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:45,  1.77s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:51,  1.80s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:28,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:48,  1.80s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:09,  1.89s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:40,  1.78s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:38,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:36,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:52,  1.85s/it]predicting train subjects:  11%|█         | 31/285 [00:55<07:58,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:38,  1.81s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:35,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:35,  1.81s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:50,  1.88s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:35,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:40,  1.86s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:48,  1.90s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:25,  1.81s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:26,  1.82s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:17,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<07:05,  1.75s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:12,  1.79s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:20<07:11,  1.80s/it]predicting train subjects:  16%|█▌        | 46/285 [01:22<07:25,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<07:05,  1.79s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<07:09,  1.81s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<07:25,  1.89s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<07:19,  1.87s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<07:28,  1.92s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:35<07:01,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:37<07:10,  1.86s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:48,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:40<06:48,  1.78s/it]predicting train subjects:  20%|██        | 57/285 [01:42<06:34,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:44<06:36,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:46<06:55,  1.84s/it]predicting train subjects:  21%|██        | 60/285 [01:48<07:04,  1.89s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<06:42,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:53<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:55<06:29,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:57<06:28,  1.77s/it]predicting train subjects:  23%|██▎       | 66/285 [01:58<06:24,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:23,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [02:02<06:16,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:04<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:16,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:07<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:09<06:10,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:12,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:12<06:13,  1.77s/it]predicting train subjects:  26%|██▋       | 75/285 [02:14<06:15,  1.79s/it]predicting train subjects:  27%|██▋       | 76/285 [02:16<06:15,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<06:11,  1.79s/it]predicting train subjects:  27%|██▋       | 78/285 [02:19<05:59,  1.74s/it]predicting train subjects:  28%|██▊       | 79/285 [02:21<06:00,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:23<06:07,  1.79s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<06:02,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<06:02,  1.79s/it]predicting train subjects:  29%|██▉       | 83/285 [02:28<05:54,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:30<05:49,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:56,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:36<05:57,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:37<05:48,  1.77s/it]predicting train subjects:  31%|███       | 89/285 [02:39<05:53,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:41<05:53,  1.81s/it]predicting train subjects:  32%|███▏      | 91/285 [02:43<05:48,  1.79s/it]predicting train subjects:  32%|███▏      | 92/285 [02:45<05:53,  1.83s/it]predicting train subjects:  33%|███▎      | 93/285 [02:46<05:45,  1.80s/it]predicting train subjects:  33%|███▎      | 94/285 [02:48<05:46,  1.81s/it]predicting train subjects:  33%|███▎      | 95/285 [02:50<05:52,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:52<05:49,  1.85s/it]predicting train subjects:  34%|███▍      | 97/285 [02:54<05:48,  1.85s/it]predicting train subjects:  34%|███▍      | 98/285 [02:56<05:44,  1.84s/it]predicting train subjects:  35%|███▍      | 99/285 [02:57<05:41,  1.84s/it]predicting train subjects:  35%|███▌      | 100/285 [02:59<05:39,  1.84s/it]predicting train subjects:  35%|███▌      | 101/285 [03:01<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:03<05:33,  1.82s/it]predicting train subjects:  36%|███▌      | 103/285 [03:05<05:24,  1.78s/it]predicting train subjects:  36%|███▋      | 104/285 [03:06<05:24,  1.79s/it]predicting train subjects:  37%|███▋      | 105/285 [03:08<05:27,  1.82s/it]predicting train subjects:  37%|███▋      | 106/285 [03:10<05:23,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:12<05:20,  1.80s/it]predicting train subjects:  38%|███▊      | 108/285 [03:14<05:17,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:15<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:17<05:16,  1.81s/it]predicting train subjects:  39%|███▉      | 111/285 [03:19<05:13,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:21<05:15,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:17,  1.85s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:14,  1.84s/it]predicting train subjects:  40%|████      | 115/285 [03:26<05:13,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:28<05:15,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:30<05:04,  1.81s/it]predicting train subjects:  41%|████▏     | 118/285 [03:32<04:56,  1.77s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<04:59,  1.80s/it]predicting train subjects:  42%|████▏     | 120/285 [03:35<04:52,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:37<04:44,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:38<04:31,  1.67s/it]predicting train subjects:  43%|████▎     | 123/285 [03:40<04:22,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:25,  1.65s/it]predicting train subjects:  44%|████▍     | 125/285 [03:43<04:23,  1.65s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:18,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<04:11,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:48<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:50<04:05,  1.57s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<04:00,  1.55s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<03:53,  1.51s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<03:55,  1.54s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<03:52,  1.53s/it]predicting train subjects:  47%|████▋     | 134/285 [03:57<03:49,  1.52s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<03:43,  1.49s/it]predicting train subjects:  48%|████▊     | 136/285 [04:00<03:39,  1.47s/it]predicting train subjects:  48%|████▊     | 137/285 [04:02<03:44,  1.52s/it]predicting train subjects:  48%|████▊     | 138/285 [04:03<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 139/285 [04:05<03:43,  1.53s/it]predicting train subjects:  49%|████▉     | 140/285 [04:06<03:49,  1.58s/it]predicting train subjects:  49%|████▉     | 141/285 [04:08<03:43,  1.55s/it]predicting train subjects:  50%|████▉     | 142/285 [04:09<03:42,  1.55s/it]predicting train subjects:  50%|█████     | 143/285 [04:11<03:37,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:13<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:14<03:37,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:16<03:42,  1.60s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:17<03:36,  1.57s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:19<03:38,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:21<03:37,  1.60s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:22<03:36,  1.60s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:34,  1.60s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:25<03:32,  1.60s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:23,  1.54s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:28<03:27,  1.58s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:26,  1.59s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:33<03:21,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:35<03:18,  1.57s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:12,  1.53s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:38<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:14,  1.57s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<03:10,  1.57s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<03:07,  1.55s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<03:05,  1.54s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<03:05,  1.56s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<03:08,  1.60s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:50<03:03,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<03:00,  1.55s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:53<02:54,  1.52s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:52,  1.51s/it]predicting train subjects:  60%|██████    | 172/285 [04:56<02:51,  1.52s/it]predicting train subjects:  61%|██████    | 173/285 [04:58<02:50,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [04:59<02:47,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:01<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:03<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:04<02:47,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:06<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:07<02:39,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:09<02:46,  1.59s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:10<02:48,  1.62s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:12<02:51,  1.66s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:14<02:45,  1.62s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:15<02:40,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:17<02:32,  1.53s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:18<02:41,  1.63s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:20<02:45,  1.69s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:22<02:46,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:35,  1.62s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:25<02:28,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:28<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:30<02:25,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:31<02:22,  1.56s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:33<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:35<02:25,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:36<02:29,  1.70s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:38<02:30,  1.74s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:40<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:41<02:13,  1.57s/it]predicting train subjects:  71%|███████   | 201/285 [05:43<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:45<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:46<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:48<02:10,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:49<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:51<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:53<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:55<02:11,  1.71s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:56<02:12,  1.74s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:58<02:06,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:59<01:59,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:01<02:00,  1.65s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:03<02:00,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:04<01:54,  1.61s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:06<01:57,  1.68s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:08<01:51,  1.62s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:09<01:55,  1.69s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:11<01:57,  1.75s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:13<01:56,  1.76s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:15<01:49,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:16<01:44,  1.63s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:18<01:43,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:19<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:21<01:35,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:22<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:24<01:35,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:26<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [06:28<01:38,  1.73s/it]predicting train subjects:  80%|████████  | 229/285 [06:29<01:37,  1.73s/it]predicting train subjects:  81%|████████  | 230/285 [06:31<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:32<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:34<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:36<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:37<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:39<01:18,  1.56s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:40<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:42<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:44<01:21,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:46<01:17,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:47<01:12,  1.61s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:49<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:50<01:04,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:51<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:53<01:03,  1.56s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:55<00:59,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:56<01:02,  1.60s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:58<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:00<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:01<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:02<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:04<00:49,  1.45s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:05<00:46,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:07<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:09<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:10<00:48,  1.60s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:12<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:42,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:42,  1.56s/it]predicting train subjects:  91%|█████████ | 259/285 [07:16<00:41,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [07:18<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:19<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:21<00:34,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:22<00:32,  1.46s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:24<00:32,  1.57s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:26<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:27<00:29,  1.55s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:29<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:30<00:26,  1.59s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:32<00:25,  1.60s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:33<00:22,  1.53s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:35<00:21,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:36<00:19,  1.53s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:38<00:17,  1.50s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:39<00:16,  1.47s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:41<00:15,  1.56s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:43<00:14,  1.62s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:44<00:12,  1.53s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:45<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:47<00:09,  1.52s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:48<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:50<00:05,  1.46s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:51<00:04,  1.44s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:53<00:03,  1.54s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:55<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:57<00:00,  1.66s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:34,  1.60s/it]Loading train:   1%|          | 2/285 [00:02<06:55,  1.47s/it]Loading train:   1%|          | 3/285 [00:04<06:41,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:05<06:13,  1.33s/it]Loading train:   2%|▏         | 5/285 [00:06<06:32,  1.40s/it]Loading train:   2%|▏         | 6/285 [00:08<06:55,  1.49s/it]Loading train:   2%|▏         | 7/285 [00:09<06:54,  1.49s/it]Loading train:   3%|▎         | 8/285 [00:11<06:37,  1.44s/it]Loading train:   3%|▎         | 9/285 [00:12<06:53,  1.50s/it]Loading train:   4%|▎         | 10/285 [00:13<06:16,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:14<05:16,  1.16s/it]Loading train:   4%|▍         | 12/285 [00:15<04:48,  1.06s/it]Loading train:   5%|▍         | 13/285 [00:16<04:18,  1.05it/s]Loading train:   5%|▍         | 14/285 [00:17<04:19,  1.04it/s]Loading train:   5%|▌         | 15/285 [00:18<04:13,  1.06it/s]Loading train:   6%|▌         | 16/285 [00:18<04:06,  1.09it/s]Loading train:   6%|▌         | 17/285 [00:19<03:49,  1.17it/s]Loading train:   6%|▋         | 18/285 [00:20<03:46,  1.18it/s]Loading train:   7%|▋         | 19/285 [00:21<03:45,  1.18it/s]Loading train:   7%|▋         | 20/285 [00:22<03:47,  1.16it/s]Loading train:   7%|▋         | 21/285 [00:23<03:55,  1.12it/s]Loading train:   8%|▊         | 22/285 [00:23<03:43,  1.17it/s]Loading train:   8%|▊         | 23/285 [00:24<03:32,  1.23it/s]Loading train:   8%|▊         | 24/285 [00:25<03:22,  1.29it/s]Loading train:   9%|▉         | 25/285 [00:26<03:30,  1.23it/s]Loading train:   9%|▉         | 26/285 [00:27<03:37,  1.19it/s]Loading train:   9%|▉         | 27/285 [00:28<03:52,  1.11it/s]Loading train:  10%|▉         | 28/285 [00:29<04:01,  1.06it/s]Loading train:  10%|█         | 29/285 [00:30<04:05,  1.04it/s]Loading train:  11%|█         | 30/285 [00:31<04:07,  1.03it/s]Loading train:  11%|█         | 31/285 [00:32<04:07,  1.03it/s]Loading train:  11%|█         | 32/285 [00:33<04:00,  1.05it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:54,  1.07it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:44,  1.12it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:56,  1.06it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:48,  1.09it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:43,  1.11it/s]Loading train:  13%|█▎        | 38/285 [00:38<03:45,  1.09it/s]Loading train:  14%|█▎        | 39/285 [00:39<03:30,  1.17it/s]Loading train:  14%|█▍        | 40/285 [00:40<03:33,  1.15it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:22,  1.21it/s]Loading train:  15%|█▍        | 42/285 [00:41<03:15,  1.25it/s]Loading train:  15%|█▌        | 43/285 [00:42<03:18,  1.22it/s]Loading train:  15%|█▌        | 44/285 [00:43<03:25,  1.17it/s]Loading train:  16%|█▌        | 45/285 [00:44<03:18,  1.21it/s]Loading train:  16%|█▌        | 46/285 [00:45<03:23,  1.17it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:14,  1.23it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:20,  1.18it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:20,  1.18it/s]Loading train:  18%|█▊        | 50/285 [00:48<03:17,  1.19it/s]Loading train:  18%|█▊        | 51/285 [00:49<03:20,  1.17it/s]Loading train:  18%|█▊        | 52/285 [00:50<03:14,  1.20it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:08,  1.23it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:11,  1.21it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:01,  1.27it/s]Loading train:  20%|█▉        | 56/285 [00:53<03:01,  1.26it/s]Loading train:  20%|██        | 57/285 [00:53<02:58,  1.28it/s]Loading train:  20%|██        | 58/285 [00:54<02:59,  1.27it/s]Loading train:  21%|██        | 59/285 [00:55<03:05,  1.22it/s]Loading train:  21%|██        | 60/285 [00:56<03:09,  1.18it/s]Loading train:  21%|██▏       | 61/285 [00:57<03:16,  1.14it/s]Loading train:  22%|██▏       | 62/285 [00:58<03:27,  1.08it/s]Loading train:  22%|██▏       | 63/285 [00:59<03:32,  1.05it/s]Loading train:  22%|██▏       | 64/285 [01:00<03:41,  1.00s/it]Loading train:  23%|██▎       | 65/285 [01:02<04:10,  1.14s/it]Loading train:  23%|██▎       | 66/285 [01:03<04:13,  1.16s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:58,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:42,  1.03s/it]Loading train:  24%|██▍       | 69/285 [01:05<03:29,  1.03it/s]Loading train:  25%|██▍       | 70/285 [01:06<03:21,  1.06it/s]Loading train:  25%|██▍       | 71/285 [01:07<03:23,  1.05it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:11,  1.11it/s]Loading train:  26%|██▌       | 73/285 [01:09<03:20,  1.06it/s]Loading train:  26%|██▌       | 74/285 [01:10<03:17,  1.07it/s]Loading train:  26%|██▋       | 75/285 [01:11<03:15,  1.08it/s]Loading train:  27%|██▋       | 76/285 [01:12<03:07,  1.11it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:54,  1.19it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:48,  1.23it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:53,  1.19it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:56,  1.16it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:54,  1.17it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:57,  1.14it/s]Loading train:  29%|██▉       | 83/285 [01:18<02:56,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:19<02:51,  1.17it/s]Loading train:  30%|██▉       | 85/285 [01:19<02:56,  1.14it/s]Loading train:  30%|███       | 86/285 [01:20<02:58,  1.11it/s]Loading train:  31%|███       | 87/285 [01:21<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:22<02:47,  1.17it/s]Loading train:  31%|███       | 89/285 [01:23<02:48,  1.17it/s]Loading train:  32%|███▏      | 90/285 [01:24<02:49,  1.15it/s]Loading train:  32%|███▏      | 91/285 [01:25<02:51,  1.13it/s]Loading train:  32%|███▏      | 92/285 [01:26<02:51,  1.13it/s]Loading train:  33%|███▎      | 93/285 [01:26<02:43,  1.17it/s]Loading train:  33%|███▎      | 94/285 [01:27<02:43,  1.17it/s]Loading train:  33%|███▎      | 95/285 [01:28<02:41,  1.17it/s]Loading train:  34%|███▎      | 96/285 [01:29<02:36,  1.21it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:33,  1.23it/s]Loading train:  34%|███▍      | 98/285 [01:30<02:28,  1.26it/s]Loading train:  35%|███▍      | 99/285 [01:31<02:27,  1.26it/s]Loading train:  35%|███▌      | 100/285 [01:32<02:35,  1.19it/s]Loading train:  35%|███▌      | 101/285 [01:33<02:33,  1.20it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:40,  1.14it/s]Loading train:  36%|███▌      | 103/285 [01:35<02:31,  1.20it/s]Loading train:  36%|███▋      | 104/285 [01:36<02:36,  1.15it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:38,  1.13it/s]Loading train:  37%|███▋      | 106/285 [01:37<02:33,  1.17it/s]Loading train:  38%|███▊      | 107/285 [01:38<02:33,  1.16it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:30,  1.17it/s]Loading train:  38%|███▊      | 109/285 [01:40<02:31,  1.17it/s]Loading train:  39%|███▊      | 110/285 [01:41<02:29,  1.17it/s]Loading train:  39%|███▉      | 111/285 [01:41<02:20,  1.24it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:25,  1.19it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:24,  1.19it/s]Loading train:  40%|████      | 114/285 [01:44<02:28,  1.15it/s]Loading train:  40%|████      | 115/285 [01:45<02:26,  1.16it/s]Loading train:  41%|████      | 116/285 [01:46<02:29,  1.13it/s]Loading train:  41%|████      | 117/285 [01:47<02:18,  1.21it/s]Loading train:  41%|████▏     | 118/285 [01:47<02:13,  1.25it/s]Loading train:  42%|████▏     | 119/285 [01:48<02:20,  1.18it/s]Loading train:  42%|████▏     | 120/285 [01:49<02:13,  1.24it/s]Loading train:  42%|████▏     | 121/285 [01:50<02:32,  1.07it/s]Loading train:  43%|████▎     | 122/285 [01:51<02:43,  1.01s/it]Loading train:  43%|████▎     | 123/285 [01:53<02:51,  1.06s/it]Loading train:  44%|████▎     | 124/285 [01:53<02:40,  1.00it/s]Loading train:  44%|████▍     | 125/285 [01:54<02:25,  1.10it/s]Loading train:  44%|████▍     | 126/285 [01:55<02:14,  1.18it/s]Loading train:  45%|████▍     | 127/285 [01:56<02:05,  1.26it/s]Loading train:  45%|████▍     | 128/285 [01:56<02:07,  1.23it/s]Loading train:  45%|████▌     | 129/285 [01:57<01:59,  1.31it/s]Loading train:  46%|████▌     | 130/285 [01:58<01:53,  1.36it/s]Loading train:  46%|████▌     | 131/285 [01:58<01:49,  1.41it/s]Loading train:  46%|████▋     | 132/285 [01:59<01:49,  1.39it/s]Loading train:  47%|████▋     | 133/285 [02:00<01:45,  1.45it/s]Loading train:  47%|████▋     | 134/285 [02:00<01:42,  1.47it/s]Loading train:  47%|████▋     | 135/285 [02:01<01:44,  1.44it/s]Loading train:  48%|████▊     | 136/285 [02:02<01:47,  1.38it/s]Loading train:  48%|████▊     | 137/285 [02:03<01:59,  1.23it/s]Loading train:  48%|████▊     | 138/285 [02:04<01:56,  1.27it/s]Loading train:  49%|████▉     | 139/285 [02:04<01:53,  1.28it/s]Loading train:  49%|████▉     | 140/285 [02:05<01:58,  1.22it/s]Loading train:  49%|████▉     | 141/285 [02:06<01:58,  1.22it/s]Loading train:  50%|████▉     | 142/285 [02:07<01:57,  1.22it/s]Loading train:  50%|█████     | 143/285 [02:08<01:55,  1.23it/s]Loading train:  51%|█████     | 144/285 [02:09<01:53,  1.24it/s]Loading train:  51%|█████     | 145/285 [02:09<01:54,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:10<01:51,  1.25it/s]Loading train:  52%|█████▏    | 147/285 [02:11<01:51,  1.24it/s]Loading train:  52%|█████▏    | 148/285 [02:12<01:51,  1.23it/s]Loading train:  52%|█████▏    | 149/285 [02:13<01:48,  1.26it/s]Loading train:  53%|█████▎    | 150/285 [02:13<01:45,  1.28it/s]Loading train:  53%|█████▎    | 151/285 [02:14<01:50,  1.21it/s]Loading train:  53%|█████▎    | 152/285 [02:15<01:45,  1.26it/s]Loading train:  54%|█████▎    | 153/285 [02:16<01:46,  1.24it/s]Loading train:  54%|█████▍    | 154/285 [02:17<01:47,  1.22it/s]Loading train:  54%|█████▍    | 155/285 [02:17<01:44,  1.24it/s]Loading train:  55%|█████▍    | 156/285 [02:18<01:45,  1.23it/s]Loading train:  55%|█████▌    | 157/285 [02:19<01:42,  1.25it/s]Loading train:  55%|█████▌    | 158/285 [02:20<01:42,  1.24it/s]Loading train:  56%|█████▌    | 159/285 [02:21<01:39,  1.27it/s]Loading train:  56%|█████▌    | 160/285 [02:21<01:34,  1.32it/s]Loading train:  56%|█████▋    | 161/285 [02:22<01:40,  1.23it/s]Loading train:  57%|█████▋    | 162/285 [02:23<01:39,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [02:24<01:41,  1.20it/s]Loading train:  58%|█████▊    | 164/285 [02:25<01:38,  1.23it/s]Loading train:  58%|█████▊    | 165/285 [02:25<01:35,  1.25it/s]Loading train:  58%|█████▊    | 166/285 [02:26<01:34,  1.26it/s]Loading train:  59%|█████▊    | 167/285 [02:27<01:33,  1.26it/s]Loading train:  59%|█████▉    | 168/285 [02:28<01:33,  1.25it/s]Loading train:  59%|█████▉    | 169/285 [02:29<01:34,  1.23it/s]Loading train:  60%|█████▉    | 170/285 [02:29<01:28,  1.29it/s]Loading train:  60%|██████    | 171/285 [02:30<01:27,  1.30it/s]Loading train:  60%|██████    | 172/285 [02:31<01:30,  1.25it/s]Loading train:  61%|██████    | 173/285 [02:32<01:27,  1.28it/s]Loading train:  61%|██████    | 174/285 [02:33<01:30,  1.22it/s]Loading train:  61%|██████▏   | 175/285 [02:34<01:33,  1.18it/s]Loading train:  62%|██████▏   | 176/285 [02:34<01:36,  1.14it/s]Loading train:  62%|██████▏   | 177/285 [02:35<01:36,  1.12it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:29,  1.19it/s]Loading train:  63%|██████▎   | 179/285 [02:37<01:26,  1.23it/s]Loading train:  63%|██████▎   | 180/285 [02:38<01:30,  1.16it/s]Loading train:  64%|██████▎   | 181/285 [02:39<01:29,  1.16it/s]Loading train:  64%|██████▍   | 182/285 [02:40<01:27,  1.18it/s]Loading train:  64%|██████▍   | 183/285 [02:40<01:22,  1.23it/s]Loading train:  65%|██████▍   | 184/285 [02:41<01:21,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [02:42<01:17,  1.30it/s]Loading train:  65%|██████▌   | 186/285 [02:43<01:20,  1.23it/s]Loading train:  66%|██████▌   | 187/285 [02:44<01:22,  1.18it/s]Loading train:  66%|██████▌   | 188/285 [02:45<01:25,  1.13it/s]Loading train:  66%|██████▋   | 189/285 [02:45<01:24,  1.13it/s]Loading train:  67%|██████▋   | 190/285 [02:46<01:27,  1.08it/s]Loading train:  67%|██████▋   | 191/285 [02:47<01:27,  1.08it/s]Loading train:  67%|██████▋   | 192/285 [02:48<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [02:49<01:21,  1.13it/s]Loading train:  68%|██████▊   | 194/285 [02:50<01:20,  1.13it/s]Loading train:  68%|██████▊   | 195/285 [02:51<01:13,  1.22it/s]Loading train:  69%|██████▉   | 196/285 [02:52<01:15,  1.17it/s]Loading train:  69%|██████▉   | 197/285 [02:53<01:16,  1.15it/s]Loading train:  69%|██████▉   | 198/285 [02:53<01:18,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [02:54<01:12,  1.18it/s]Loading train:  70%|███████   | 200/285 [02:55<01:10,  1.20it/s]Loading train:  71%|███████   | 201/285 [02:56<01:10,  1.19it/s]Loading train:  71%|███████   | 202/285 [02:57<01:08,  1.21it/s]Loading train:  71%|███████   | 203/285 [02:57<01:05,  1.24it/s]Loading train:  72%|███████▏  | 204/285 [02:58<01:03,  1.27it/s]Loading train:  72%|███████▏  | 205/285 [02:59<01:03,  1.26it/s]Loading train:  72%|███████▏  | 206/285 [03:00<01:04,  1.23it/s]Loading train:  73%|███████▎  | 207/285 [03:01<01:04,  1.20it/s]Loading train:  73%|███████▎  | 208/285 [03:02<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:03<01:10,  1.07it/s]Loading train:  74%|███████▎  | 210/285 [03:04<01:11,  1.05it/s]Loading train:  74%|███████▍  | 211/285 [03:04<01:05,  1.13it/s]Loading train:  74%|███████▍  | 212/285 [03:05<01:06,  1.10it/s]Loading train:  75%|███████▍  | 213/285 [03:06<01:04,  1.12it/s]Loading train:  75%|███████▌  | 214/285 [03:07<00:58,  1.21it/s]Loading train:  75%|███████▌  | 215/285 [03:08<01:00,  1.16it/s]Loading train:  76%|███████▌  | 216/285 [03:09<00:56,  1.22it/s]Loading train:  76%|███████▌  | 217/285 [03:10<00:57,  1.18it/s]Loading train:  76%|███████▋  | 218/285 [03:10<00:57,  1.16it/s]Loading train:  77%|███████▋  | 219/285 [03:11<00:59,  1.11it/s]Loading train:  77%|███████▋  | 220/285 [03:12<00:53,  1.20it/s]Loading train:  78%|███████▊  | 221/285 [03:13<00:50,  1.26it/s]Loading train:  78%|███████▊  | 222/285 [03:14<00:51,  1.22it/s]Loading train:  78%|███████▊  | 223/285 [03:14<00:48,  1.29it/s]Loading train:  79%|███████▊  | 224/285 [03:15<00:47,  1.30it/s]Loading train:  79%|███████▉  | 225/285 [03:16<00:44,  1.34it/s]Loading train:  79%|███████▉  | 226/285 [03:17<00:46,  1.27it/s]Loading train:  80%|███████▉  | 227/285 [03:18<00:47,  1.23it/s]Loading train:  80%|████████  | 228/285 [03:19<00:49,  1.16it/s]Loading train:  80%|████████  | 229/285 [03:19<00:46,  1.20it/s]Loading train:  81%|████████  | 230/285 [03:20<00:43,  1.26it/s]Loading train:  81%|████████  | 231/285 [03:21<00:41,  1.31it/s]Loading train:  81%|████████▏ | 232/285 [03:22<00:41,  1.28it/s]Loading train:  82%|████████▏ | 233/285 [03:22<00:39,  1.32it/s]Loading train:  82%|████████▏ | 234/285 [03:23<00:41,  1.24it/s]Loading train:  82%|████████▏ | 235/285 [03:24<00:39,  1.26it/s]Loading train:  83%|████████▎ | 236/285 [03:25<00:41,  1.18it/s]Loading train:  83%|████████▎ | 237/285 [03:26<00:41,  1.17it/s]Loading train:  84%|████████▎ | 238/285 [03:27<00:40,  1.17it/s]Loading train:  84%|████████▍ | 239/285 [03:27<00:38,  1.19it/s]Loading train:  84%|████████▍ | 240/285 [03:28<00:35,  1.27it/s]Loading train:  85%|████████▍ | 241/285 [03:29<00:35,  1.25it/s]Loading train:  85%|████████▍ | 242/285 [03:30<00:32,  1.33it/s]Loading train:  85%|████████▌ | 243/285 [03:30<00:32,  1.29it/s]Loading train:  86%|████████▌ | 244/285 [03:31<00:32,  1.25it/s]Loading train:  86%|████████▌ | 245/285 [03:32<00:30,  1.30it/s]Loading train:  86%|████████▋ | 246/285 [03:33<00:31,  1.24it/s]Loading train:  87%|████████▋ | 247/285 [03:34<00:31,  1.21it/s]Loading train:  87%|████████▋ | 248/285 [03:35<00:31,  1.18it/s]Loading train:  87%|████████▋ | 249/285 [03:35<00:29,  1.22it/s]Loading train:  88%|████████▊ | 250/285 [03:36<00:30,  1.16it/s]Loading train:  88%|████████▊ | 251/285 [03:37<00:27,  1.23it/s]Loading train:  88%|████████▊ | 252/285 [03:38<00:26,  1.24it/s]Loading train:  89%|████████▉ | 253/285 [03:39<00:27,  1.17it/s]Loading train:  89%|████████▉ | 254/285 [03:40<00:27,  1.14it/s]Loading train:  89%|████████▉ | 255/285 [03:41<00:26,  1.15it/s]Loading train:  90%|████████▉ | 256/285 [03:41<00:24,  1.17it/s]Loading train:  90%|█████████ | 257/285 [03:42<00:22,  1.23it/s]Loading train:  91%|█████████ | 258/285 [03:43<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [03:44<00:21,  1.20it/s]Loading train:  91%|█████████ | 260/285 [03:45<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [03:45<00:18,  1.29it/s]Loading train:  92%|█████████▏| 262/285 [03:46<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [03:47<00:16,  1.29it/s]Loading train:  93%|█████████▎| 264/285 [03:48<00:17,  1.19it/s]Loading train:  93%|█████████▎| 265/285 [03:49<00:16,  1.20it/s]Loading train:  93%|█████████▎| 266/285 [03:49<00:15,  1.24it/s]Loading train:  94%|█████████▎| 267/285 [03:50<00:14,  1.27it/s]Loading train:  94%|█████████▍| 268/285 [03:51<00:13,  1.25it/s]Loading train:  94%|█████████▍| 269/285 [03:52<00:13,  1.21it/s]Loading train:  95%|█████████▍| 270/285 [03:53<00:11,  1.27it/s]Loading train:  95%|█████████▌| 271/285 [03:53<00:10,  1.30it/s]Loading train:  95%|█████████▌| 272/285 [03:54<00:10,  1.23it/s]Loading train:  96%|█████████▌| 273/285 [03:55<00:09,  1.25it/s]Loading train:  96%|█████████▌| 274/285 [03:56<00:08,  1.29it/s]Loading train:  96%|█████████▋| 275/285 [03:57<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [03:58<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [03:58<00:06,  1.17it/s]Loading train:  98%|█████████▊| 278/285 [03:59<00:05,  1.23it/s]Loading train:  98%|█████████▊| 279/285 [04:00<00:04,  1.20it/s]Loading train:  98%|█████████▊| 280/285 [04:01<00:03,  1.26it/s]Loading train:  99%|█████████▊| 281/285 [04:01<00:03,  1.31it/s]Loading train:  99%|█████████▉| 282/285 [04:02<00:02,  1.35it/s]Loading train:  99%|█████████▉| 283/285 [04:03<00:01,  1.27it/s]Loading train: 100%|█████████▉| 284/285 [04:04<00:00,  1.23it/s]Loading train: 100%|██████████| 285/285 [04:05<00:00,  1.16it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:00, 284.96it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:00, 297.02it/s]concatenating: train:  34%|███▎      | 96/285 [00:00<00:00, 306.65it/s]concatenating: train:  46%|████▌     | 131/285 [00:00<00:00, 316.28it/s]concatenating: train:  57%|█████▋    | 163/285 [00:00<00:00, 317.06it/s]concatenating: train:  69%|██████▉   | 197/285 [00:00<00:00, 322.18it/s]concatenating: train:  81%|████████  | 230/285 [00:00<00:00, 322.77it/s]concatenating: train:  92%|█████████▏| 263/285 [00:00<00:00, 322.45it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 323.76it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 440.41it/s]2019-07-10 21:22:37.225830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:22:37.225937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:22:37.225952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:22:37.225961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:22:37.226450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.03it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:05,  6.69it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.33it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:04,  7.28it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  8.12it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.13it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.13it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.69it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  7.89it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.89it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.37it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.59it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.99it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.87it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.24it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.17it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.99it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.52it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 225,773
Trainable params: 51,073
Non-trainable params: 174,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 14s - loss: 2.9671 - acc: 0.5914 - mDice: 0.0946 - val_loss: 1.8994 - val_acc: 0.8901 - val_mDice: 0.2319

Epoch 00001: val_mDice improved from -inf to 0.23186, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.1736 - acc: 0.8896 - mDice: 0.3098 - val_loss: 1.4842 - val_acc: 0.9043 - val_mDice: 0.3270

Epoch 00002: val_mDice improved from 0.23186 to 0.32695, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8434 - acc: 0.9053 - mDice: 0.4183 - val_loss: 1.0964 - val_acc: 0.9108 - val_mDice: 0.4292

Epoch 00003: val_mDice improved from 0.32695 to 0.42919, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7070 - acc: 0.9127 - mDice: 0.4767 - val_loss: 0.9088 - val_acc: 0.9251 - val_mDice: 0.4965

Epoch 00004: val_mDice improved from 0.42919 to 0.49645, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6120 - acc: 0.9197 - mDice: 0.5249 - val_loss: 0.8071 - val_acc: 0.9296 - val_mDice: 0.5333

Epoch 00005: val_mDice improved from 0.49645 to 0.53332, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5467 - acc: 0.9252 - mDice: 0.5621 - val_loss: 0.8717 - val_acc: 0.9341 - val_mDice: 0.5294

Epoch 00006: val_mDice did not improve from 0.53332
Epoch 7/300
 - 9s - loss: 0.5083 - acc: 0.9284 - mDice: 0.5851 - val_loss: 0.8292 - val_acc: 0.9368 - val_mDice: 0.5585

Epoch 00007: val_mDice improved from 0.53332 to 0.55848, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.4818 - acc: 0.9305 - mDice: 0.6014 - val_loss: 0.7984 - val_acc: 0.9336 - val_mDice: 0.5657

Epoch 00008: val_mDice improved from 0.55848 to 0.56568, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4597 - acc: 0.9322 - mDice: 0.6153 - val_loss: 0.8293 - val_acc: 0.9320 - val_mDice: 0.5507

Epoch 00009: val_mDice did not improve from 0.56568
Epoch 10/300
 - 9s - loss: 0.4458 - acc: 0.9332 - mDice: 0.6245 - val_loss: 0.8189 - val_acc: 0.9354 - val_mDice: 0.5639

Epoch 00010: val_mDice did not improve from 0.56568
Epoch 11/300
 - 9s - loss: 0.4309 - acc: 0.9345 - mDice: 0.6340 - val_loss: 0.8128 - val_acc: 0.9357 - val_mDice: 0.5624

Epoch 00011: val_mDice did not improve from 0.56568
Epoch 12/300
 - 9s - loss: 0.4225 - acc: 0.9350 - mDice: 0.6397 - val_loss: 0.8122 - val_acc: 0.9382 - val_mDice: 0.5634

Epoch 00012: val_mDice did not improve from 0.56568
Epoch 13/300
 - 9s - loss: 0.4124 - acc: 0.9359 - mDice: 0.6464 - val_loss: 0.8351 - val_acc: 0.9280 - val_mDice: 0.5438

Epoch 00013: val_mDice did not improve from 0.56568
Epoch 14/300
 - 9s - loss: 0.4043 - acc: 0.9366 - mDice: 0.6520 - val_loss: 0.8079 - val_acc: 0.9398 - val_mDice: 0.5592

Epoch 00014: val_mDice did not improve from 0.56568
Epoch 15/300
 - 9s - loss: 0.3969 - acc: 0.9369 - mDice: 0.6567 - val_loss: 0.8179 - val_acc: 0.9353 - val_mDice: 0.5555

Epoch 00015: val_mDice did not improve from 0.56568
Epoch 16/300
 - 9s - loss: 0.3911 - acc: 0.9377 - mDice: 0.6609 - val_loss: 0.7930 - val_acc: 0.9380 - val_mDice: 0.5689

Epoch 00016: val_mDice improved from 0.56568 to 0.56891, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 9s - loss: 0.3845 - acc: 0.9381 - mDice: 0.6655 - val_loss: 0.7913 - val_acc: 0.9351 - val_mDice: 0.5669

Epoch 00017: val_mDice did not improve from 0.56891
Epoch 18/300
 - 9s - loss: 0.3796 - acc: 0.9385 - mDice: 0.6689 - val_loss: 0.7934 - val_acc: 0.9406 - val_mDice: 0.5625

Epoch 00018: val_mDice did not improve from 0.56891
Epoch 19/300
 - 9s - loss: 0.3751 - acc: 0.9388 - mDice: 0.6720 - val_loss: 0.7649 - val_acc: 0.9409 - val_mDice: 0.5773

Epoch 00019: val_mDice improved from 0.56891 to 0.57733, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.3683 - acc: 0.9394 - mDice: 0.6768 - val_loss: 0.7779 - val_acc: 0.9388 - val_mDice: 0.5697

Epoch 00020: val_mDice did not improve from 0.57733
Epoch 21/300
 - 9s - loss: 0.3663 - acc: 0.9395 - mDice: 0.6782 - val_loss: 0.7854 - val_acc: 0.9398 - val_mDice: 0.5640

Epoch 00021: val_mDice did not improve from 0.57733
Epoch 22/300
 - 9s - loss: 0.3621 - acc: 0.9399 - mDice: 0.6812 - val_loss: 0.7731 - val_acc: 0.9377 - val_mDice: 0.5700

Epoch 00022: val_mDice did not improve from 0.57733
Epoch 23/300
 - 9s - loss: 0.3566 - acc: 0.9402 - mDice: 0.6852 - val_loss: 0.7642 - val_acc: 0.9363 - val_mDice: 0.5737

Epoch 00023: val_mDice did not improve from 0.57733
Epoch 24/300
 - 9s - loss: 0.3547 - acc: 0.9403 - mDice: 0.6864 - val_loss: 0.7641 - val_acc: 0.9390 - val_mDice: 0.5691

Epoch 00024: val_mDice did not improve from 0.57733
Epoch 25/300
 - 9s - loss: 0.3513 - acc: 0.9406 - mDice: 0.6890 - val_loss: 0.7669 - val_acc: 0.9370 - val_mDice: 0.5722

Epoch 00025: val_mDice did not improve from 0.57733
Epoch 26/300
 - 9s - loss: 0.3499 - acc: 0.9409 - mDice: 0.6900 - val_loss: 0.7592 - val_acc: 0.9399 - val_mDice: 0.5713

Epoch 00026: val_mDice did not improve from 0.57733
Epoch 27/300
 - 9s - loss: 0.3443 - acc: 0.9412 - mDice: 0.6939 - val_loss: 0.7454 - val_acc: 0.9386 - val_mDice: 0.5794

Epoch 00027: val_mDice improved from 0.57733 to 0.57945, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 9s - loss: 0.3433 - acc: 0.9411 - mDice: 0.6947 - val_loss: 0.7491 - val_acc: 0.9372 - val_mDice: 0.5706

Epoch 00028: val_mDice did not improve from 0.57945
Epoch 29/300
 - 9s - loss: 0.3389 - acc: 0.9416 - mDice: 0.6978 - val_loss: 0.7418 - val_acc: 0.9391 - val_mDice: 0.5774

Epoch 00029: val_mDice did not improve from 0.57945
Epoch 30/300
 - 9s - loss: 0.3379 - acc: 0.9417 - mDice: 0.6985 - val_loss: 0.7460 - val_acc: 0.9356 - val_mDice: 0.5751

Epoch 00030: val_mDice did not improve from 0.57945
Epoch 31/300
 - 9s - loss: 0.3344 - acc: 0.9420 - mDice: 0.7011 - val_loss: 0.7351 - val_acc: 0.9397 - val_mDice: 0.5757

Epoch 00031: val_mDice did not improve from 0.57945
Epoch 32/300
 - 9s - loss: 0.3333 - acc: 0.9420 - mDice: 0.7020 - val_loss: 0.7321 - val_acc: 0.9387 - val_mDice: 0.5739

Epoch 00032: val_mDice did not improve from 0.57945
Epoch 33/300
 - 9s - loss: 0.3304 - acc: 0.9423 - mDice: 0.7040 - val_loss: 0.7351 - val_acc: 0.9385 - val_mDice: 0.5749

Epoch 00033: val_mDice did not improve from 0.57945
Epoch 34/300
 - 9s - loss: 0.3290 - acc: 0.9423 - mDice: 0.7051 - val_loss: 0.7256 - val_acc: 0.9381 - val_mDice: 0.5701

Epoch 00034: val_mDice did not improve from 0.57945
Epoch 35/300
 - 9s - loss: 0.3273 - acc: 0.9425 - mDice: 0.7064 - val_loss: 0.7418 - val_acc: 0.9370 - val_mDice: 0.5718

Epoch 00035: val_mDice did not improve from 0.57945
Epoch 36/300
 - 9s - loss: 0.3242 - acc: 0.9427 - mDice: 0.7086 - val_loss: 0.7346 - val_acc: 0.9373 - val_mDice: 0.5682

Epoch 00036: val_mDice did not improve from 0.57945
Epoch 37/300
 - 9s - loss: 0.3223 - acc: 0.9429 - mDice: 0.7099 - val_loss: 0.7205 - val_acc: 0.9385 - val_mDice: 0.5779

Epoch 00037: val_mDice did not improve from 0.57945
Epoch 38/300
 - 9s - loss: 0.3212 - acc: 0.9430 - mDice: 0.7109 - val_loss: 0.7399 - val_acc: 0.9405 - val_mDice: 0.5623

Epoch 00038: val_mDice did not improve from 0.57945
Epoch 39/300
 - 9s - loss: 0.3197 - acc: 0.9431 - mDice: 0.7120 - val_loss: 0.7111 - val_acc: 0.9412 - val_mDice: 0.5773

Epoch 00039: val_mDice did not improve from 0.57945
Epoch 40/300
 - 9s - loss: 0.3190 - acc: 0.9433 - mDice: 0.7125 - val_loss: 0.7061 - val_acc: 0.9400 - val_mDice: 0.5770

Epoch 00040: val_mDice did not improve from 0.57945
Epoch 41/300
 - 9s - loss: 0.3175 - acc: 0.9434 - mDice: 0.7135 - val_loss: 0.7105 - val_acc: 0.9410 - val_mDice: 0.5769

Epoch 00041: val_mDice did not improve from 0.57945
Epoch 42/300
 - 9s - loss: 0.3153 - acc: 0.9434 - mDice: 0.7152 - val_loss: 0.7145 - val_acc: 0.9413 - val_mDice: 0.5743

Epoch 00042: val_mDice did not improve from 0.57945
Epoch 43/300
 - 9s - loss: 0.3123 - acc: 0.9437 - mDice: 0.7175 - val_loss: 0.7043 - val_acc: 0.9354 - val_mDice: 0.5735

Epoch 00043: val_mDice did not improve from 0.57945
Epoch 44/300
 - 9s - loss: 0.3127 - acc: 0.9435 - mDice: 0.7171 - val_loss: 0.6686 - val_acc: 0.9380 - val_mDice: 0.5830

Epoch 00044: val_mDice improved from 0.57945 to 0.58297, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 9s - loss: 0.3104 - acc: 0.9439 - mDice: 0.7189 - val_loss: 0.7026 - val_acc: 0.9383 - val_mDice: 0.5763

Epoch 00045: val_mDice did not improve from 0.58297
Epoch 46/300
 - 9s - loss: 0.3113 - acc: 0.9438 - mDice: 0.7183 - val_loss: 0.6952 - val_acc: 0.9382 - val_mDice: 0.5783

Epoch 00046: val_mDice did not improve from 0.58297
Epoch 47/300
 - 9s - loss: 0.3082 - acc: 0.9439 - mDice: 0.7205 - val_loss: 0.7073 - val_acc: 0.9406 - val_mDice: 0.5673

Epoch 00047: val_mDice did not improve from 0.58297
Epoch 48/300
 - 9s - loss: 0.3065 - acc: 0.9441 - mDice: 0.7218 - val_loss: 0.6845 - val_acc: 0.9412 - val_mDice: 0.5789

Epoch 00048: val_mDice did not improve from 0.58297
Epoch 49/300
 - 9s - loss: 0.3079 - acc: 0.9441 - mDice: 0.7208 - val_loss: 0.7020 - val_acc: 0.9411 - val_mDice: 0.5658

Epoch 00049: val_mDice did not improve from 0.58297
Epoch 50/300
 - 9s - loss: 0.3051 - acc: 0.9445 - mDice: 0.7229 - val_loss: 0.6845 - val_acc: 0.9387 - val_mDice: 0.5757

Epoch 00050: val_mDice did not improve from 0.58297
Epoch 51/300
 - 9s - loss: 0.3050 - acc: 0.9445 - mDice: 0.7229 - val_loss: 0.6799 - val_acc: 0.9392 - val_mDice: 0.5770

Epoch 00051: val_mDice did not improve from 0.58297
Epoch 52/300
 - 9s - loss: 0.3032 - acc: 0.9444 - mDice: 0.7243 - val_loss: 0.6666 - val_acc: 0.9404 - val_mDice: 0.5830

Epoch 00052: val_mDice improved from 0.58297 to 0.58302, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 53/300
 - 9s - loss: 0.3001 - acc: 0.9449 - mDice: 0.7266 - val_loss: 0.6727 - val_acc: 0.9432 - val_mDice: 0.5807

Epoch 00053: val_mDice did not improve from 0.58302
Epoch 54/300
 - 9s - loss: 0.2998 - acc: 0.9449 - mDice: 0.7269 - val_loss: 0.6715 - val_acc: 0.9402 - val_mDice: 0.5784

Epoch 00054: val_mDice did not improve from 0.58302
Epoch 55/300
 - 9s - loss: 0.2998 - acc: 0.9448 - mDice: 0.7269 - val_loss: 0.6801 - val_acc: 0.9415 - val_mDice: 0.5719

Epoch 00055: val_mDice did not improve from 0.58302
Epoch 56/300
 - 9s - loss: 0.2986 - acc: 0.9450 - mDice: 0.7278 - val_loss: 0.6658 - val_acc: 0.9392 - val_mDice: 0.5778

Epoch 00056: val_mDice did not improve from 0.58302
Epoch 57/300
 - 9s - loss: 0.2977 - acc: 0.9450 - mDice: 0.7284 - val_loss: 0.6810 - val_acc: 0.9395 - val_mDice: 0.5804

Epoch 00057: val_mDice did not improve from 0.58302
Epoch 58/300
 - 9s - loss: 0.2962 - acc: 0.9452 - mDice: 0.7297 - val_loss: 0.6608 - val_acc: 0.9403 - val_mDice: 0.5780

Epoch 00058: val_mDice did not improve from 0.58302
Epoch 59/300
 - 9s - loss: 0.2953 - acc: 0.9452 - mDice: 0.7302 - val_loss: 0.6684 - val_acc: 0.9407 - val_mDice: 0.5812

Epoch 00059: val_mDice did not improve from 0.58302
Epoch 60/300
 - 9s - loss: 0.2965 - acc: 0.9452 - mDice: 0.7295 - val_loss: 0.6786 - val_acc: 0.9430 - val_mDice: 0.5774

Epoch 00060: val_mDice did not improve from 0.58302
Epoch 61/300
 - 9s - loss: 0.2948 - acc: 0.9453 - mDice: 0.7306 - val_loss: 0.6819 - val_acc: 0.9388 - val_mDice: 0.5794

Epoch 00061: val_mDice did not improve from 0.58302
Epoch 62/300
 - 9s - loss: 0.2939 - acc: 0.9453 - mDice: 0.7314 - val_loss: 0.6675 - val_acc: 0.9394 - val_mDice: 0.5776

Epoch 00062: val_mDice did not improve from 0.58302
Epoch 63/300
 - 9s - loss: 0.2927 - acc: 0.9455 - mDice: 0.7323 - val_loss: 0.6602 - val_acc: 0.9409 - val_mDice: 0.5746

Epoch 00063: val_mDice did not improve from 0.58302
Epoch 64/300
 - 9s - loss: 0.2935 - acc: 0.9454 - mDice: 0.7317 - val_loss: 0.6558 - val_acc: 0.9410 - val_mDice: 0.5800

Epoch 00064: val_mDice did not improve from 0.58302
Epoch 65/300
 - 9s - loss: 0.2916 - acc: 0.9455 - mDice: 0.7332 - val_loss: 0.6478 - val_acc: 0.9405 - val_mDice: 0.5789

Epoch 00065: val_mDice did not improve from 0.58302
Epoch 66/300
 - 9s - loss: 0.2915 - acc: 0.9456 - mDice: 0.7332 - val_loss: 0.6554 - val_acc: 0.9433 - val_mDice: 0.5744

Epoch 00066: val_mDice did not improve from 0.58302
Epoch 67/300
 - 9s - loss: 0.2892 - acc: 0.9459 - mDice: 0.7350 - val_loss: 0.6437 - val_acc: 0.9415 - val_mDice: 0.5801

Epoch 00067: val_mDice did not improve from 0.58302
Epoch 68/300
 - 9s - loss: 0.2888 - acc: 0.9460 - mDice: 0.7352 - val_loss: 0.6498 - val_acc: 0.9394 - val_mDice: 0.5758

Epoch 00068: val_mDice did not improve from 0.58302
Epoch 69/300
 - 9s - loss: 0.2884 - acc: 0.9460 - mDice: 0.7356 - val_loss: 0.6671 - val_acc: 0.9416 - val_mDice: 0.5778

Epoch 00069: val_mDice did not improve from 0.58302
Epoch 70/300
 - 9s - loss: 0.2877 - acc: 0.9460 - mDice: 0.7361 - val_loss: 0.6519 - val_acc: 0.9409 - val_mDice: 0.5767

Epoch 00070: val_mDice did not improve from 0.58302
Epoch 71/300
 - 9s - loss: 0.2854 - acc: 0.9462 - mDice: 0.7379 - val_loss: 0.6466 - val_acc: 0.9413 - val_mDice: 0.5769

Epoch 00071: val_mDice did not improve from 0.58302
Epoch 72/300
 - 9s - loss: 0.2870 - acc: 0.9462 - mDice: 0.7367 - val_loss: 0.6555 - val_acc: 0.9391 - val_mDice: 0.5757

Epoch 00072: val_mDice did not improve from 0.58302
Epoch 73/300
 - 9s - loss: 0.2881 - acc: 0.9463 - mDice: 0.7359 - val_loss: 0.6449 - val_acc: 0.9424 - val_mDice: 0.5744

Epoch 00073: val_mDice did not improve from 0.58302
Epoch 74/300
 - 9s - loss: 0.2848 - acc: 0.9463 - mDice: 0.7384 - val_loss: 0.6312 - val_acc: 0.9419 - val_mDice: 0.5867

Epoch 00074: val_mDice improved from 0.58302 to 0.58669, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 75/300
 - 9s - loss: 0.2844 - acc: 0.9464 - mDice: 0.7387 - val_loss: 0.6511 - val_acc: 0.9411 - val_mDice: 0.5758

Epoch 00075: val_mDice did not improve from 0.58669
Epoch 76/300
 - 9s - loss: 0.2849 - acc: 0.9463 - mDice: 0.7383 - val_loss: 0.6398 - val_acc: 0.9405 - val_mDice: 0.5769

Epoch 00076: val_mDice did not improve from 0.58669
Epoch 77/300
 - 9s - loss: 0.2833 - acc: 0.9465 - mDice: 0.7395 - val_loss: 0.6485 - val_acc: 0.9388 - val_mDice: 0.5705

Epoch 00077: val_mDice did not improve from 0.58669
Epoch 78/300
 - 10s - loss: 0.2829 - acc: 0.9466 - mDice: 0.7399 - val_loss: 0.6466 - val_acc: 0.9408 - val_mDice: 0.5722

Epoch 00078: val_mDice did not improve from 0.58669
Epoch 79/300
 - 9s - loss: 0.2822 - acc: 0.9467 - mDice: 0.7405 - val_loss: 0.6387 - val_acc: 0.9394 - val_mDice: 0.5807

Epoch 00079: val_mDice did not improve from 0.58669
Epoch 80/300
 - 9s - loss: 0.2824 - acc: 0.9466 - mDice: 0.7403 - val_loss: 0.6664 - val_acc: 0.9363 - val_mDice: 0.5681

Epoch 00080: val_mDice did not improve from 0.58669
Epoch 81/300
 - 9s - loss: 0.2824 - acc: 0.9466 - mDice: 0.7402 - val_loss: 0.6483 - val_acc: 0.9378 - val_mDice: 0.5862

Epoch 00081: val_mDice did not improve from 0.58669
Epoch 82/300
 - 9s - loss: 0.2823 - acc: 0.9468 - mDice: 0.7403 - val_loss: 0.6400 - val_acc: 0.9381 - val_mDice: 0.5747

Epoch 00082: val_mDice did not improve from 0.58669
Epoch 83/300
 - 9s - loss: 0.2800 - acc: 0.9469 - mDice: 0.7421 - val_loss: 0.6249 - val_acc: 0.9384 - val_mDice: 0.5853

Epoch 00083: val_mDice did not improve from 0.58669
Epoch 84/300
 - 9s - loss: 0.2796 - acc: 0.9469 - mDice: 0.7425 - val_loss: 0.6304 - val_acc: 0.9397 - val_mDice: 0.5820

Epoch 00084: val_mDice did not improve from 0.58669
Epoch 85/300
 - 9s - loss: 0.2806 - acc: 0.9468 - mDice: 0.7416 - val_loss: 0.6372 - val_acc: 0.9420 - val_mDice: 0.5759

Epoch 00085: val_mDice did not improve from 0.58669
Epoch 86/300
 - 9s - loss: 0.2786 - acc: 0.9470 - mDice: 0.7432 - val_loss: 0.6458 - val_acc: 0.9421 - val_mDice: 0.5834

Epoch 00086: val_mDice did not improve from 0.58669
Epoch 87/300
 - 9s - loss: 0.2820 - acc: 0.9471 - mDice: 0.7440 - val_loss: 0.6473 - val_acc: 0.9380 - val_mDice: 0.5726

Epoch 00087: val_mDice did not improve from 0.58669
Epoch 88/300
 - 9s - loss: 0.2790 - acc: 0.9471 - mDice: 0.7428 - val_loss: 0.6426 - val_acc: 0.9427 - val_mDice: 0.5747

Epoch 00088: val_mDice did not improve from 0.58669
Epoch 89/300
 - 9s - loss: 0.2776 - acc: 0.9471 - mDice: 0.7440 - val_loss: 0.6395 - val_acc: 0.9385 - val_mDice: 0.5749

Epoch 00089: val_mDice did not improve from 0.58669
Epoch 90/300
 - 9s - loss: 0.2774 - acc: 0.9472 - mDice: 0.7441 - val_loss: 0.6551 - val_acc: 0.9405 - val_mDice: 0.5663

Epoch 00090: val_mDice did not improve from 0.58669
Epoch 91/300
 - 9s - loss: 0.2783 - acc: 0.9471 - mDice: 0.7435 - val_loss: 0.6810 - val_acc: 0.9400 - val_mDice: 0.5725

Epoch 00091: val_mDice did not improve from 0.58669
Epoch 92/300
 - 9s - loss: 0.2937 - acc: 0.9455 - mDice: 0.7318 - val_loss: 0.6397 - val_acc: 0.9392 - val_mDice: 0.5760

Epoch 00092: val_mDice did not improve from 0.58669
Epoch 93/300
 - 9s - loss: 0.2769 - acc: 0.9472 - mDice: 0.7445 - val_loss: 0.6363 - val_acc: 0.9400 - val_mDice: 0.5795

Epoch 00093: val_mDice did not improve from 0.58669
Epoch 94/300
 - 9s - loss: 0.2746 - acc: 0.9474 - mDice: 0.7464 - val_loss: 0.6701 - val_acc: 0.9362 - val_mDice: 0.5781

Epoch 00094: val_mDice did not improve from 0.58669
Epoch 95/300
 - 9s - loss: 0.2746 - acc: 0.9474 - mDice: 0.7464 - val_loss: 0.6372 - val_acc: 0.9408 - val_mDice: 0.5764

Epoch 00095: val_mDice did not improve from 0.58669
Epoch 96/300
 - 9s - loss: 0.2748 - acc: 0.9474 - mDice: 0.7461 - val_loss: 0.6318 - val_acc: 0.9412 - val_mDice: 0.5801

Epoch 00096: val_mDice did not improve from 0.58669
Epoch 97/300
 - 9s - loss: 0.2751 - acc: 0.9474 - mDice: 0.7460 - val_loss: 0.6382 - val_acc: 0.9403 - val_mDice: 0.5752

Epoch 00097: val_mDice did not improve from 0.58669
Epoch 98/300
 - 9s - loss: 0.2745 - acc: 0.9474 - mDice: 0.7464 - val_loss: 0.6423 - val_acc: 0.9371 - val_mDice: 0.5735

Epoch 00098: val_mDice did not improve from 0.58669
Epoch 99/300
 - 9s - loss: 0.2743 - acc: 0.9474 - mDice: 0.7465 - val_loss: 0.6346 - val_acc: 0.9384 - val_mDice: 0.5779

Epoch 00099: val_mDice did not improve from 0.58669
Epoch 100/300
 - 9s - loss: 0.2732 - acc: 0.9475 - mDice: 0.7474 - val_loss: 0.6868 - val_acc: 0.9376 - val_mDice: 0.5749

Epoch 00100: val_mDice did not improve from 0.58669
Epoch 101/300
 - 9s - loss: 0.2721 - acc: 0.9476 - mDice: 0.7482 - val_loss: 0.6355 - val_acc: 0.9433 - val_mDice: 0.5786

Epoch 00101: val_mDice did not improve from 0.58669
Epoch 102/300
 - 9s - loss: 0.2717 - acc: 0.9477 - mDice: 0.7486 - val_loss: 0.6585 - val_acc: 0.9395 - val_mDice: 0.5771

Epoch 00102: val_mDice did not improve from 0.58669
Epoch 103/300
 - 9s - loss: 0.2721 - acc: 0.9477 - mDice: 0.7482 - val_loss: 0.6681 - val_acc: 0.9414 - val_mDice: 0.5719

Epoch 00103: val_mDice did not improve from 0.58669
Epoch 104/300
 - 9s - loss: 0.2714 - acc: 0.9478 - mDice: 0.7489 - val_loss: 0.6817 - val_acc: 0.9410 - val_mDice: 0.5771

Epoch 00104: val_mDice did not improve from 0.58669
Epoch 105/300
 - 9s - loss: 0.2711 - acc: 0.9478 - mDice: 0.7490 - val_loss: 0.6901 - val_acc: 0.9373 - val_mDice: 0.5750

Epoch 00105: val_mDice did not improve from 0.58669
Epoch 106/300
 - 9s - loss: 0.2716 - acc: 0.9477 - mDice: 0.7488 - val_loss: 0.6817 - val_acc: 0.9384 - val_mDice: 0.5748

Epoch 00106: val_mDice did not improve from 0.58669
Epoch 107/300
 - 9s - loss: 0.2724 - acc: 0.9477 - mDice: 0.7481 - val_loss: 0.6436 - val_acc: 0.9410 - val_mDice: 0.5727

Epoch 00107: val_mDice did not improve from 0.58669
Epoch 108/300
 - 9s - loss: 0.2690 - acc: 0.9480 - mDice: 0.7508 - val_loss: 0.6451 - val_acc: 0.9385 - val_mDice: 0.5713

Epoch 00108: val_mDice did not improve from 0.58669
Epoch 109/300
 - 9s - loss: 0.2696 - acc: 0.9479 - mDice: 0.7502 - val_loss: 0.6311 - val_acc: 0.9428 - val_mDice: 0.5803

Epoch 00109: val_mDice did not improve from 0.58669
Epoch 110/300
 - 10s - loss: 0.2693 - acc: 0.9479 - mDice: 0.7505 - val_loss: 0.6454 - val_acc: 0.9402 - val_mDice: 0.5773

Epoch 00110: val_mDice did not improve from 0.58669
Epoch 111/300
 - 9s - loss: 0.2707 - acc: 0.9478 - mDice: 0.7494 - val_loss: 0.6578 - val_acc: 0.9382 - val_mDice: 0.5845

Epoch 00111: val_mDice did not improve from 0.58669
Epoch 112/300
 - 9s - loss: 0.2688 - acc: 0.9480 - mDice: 0.7508 - val_loss: 0.6707 - val_acc: 0.9379 - val_mDice: 0.5724

Epoch 00112: val_mDice did not improve from 0.58669
Epoch 113/300
 - 9s - loss: 0.2685 - acc: 0.9480 - mDice: 0.7511 - val_loss: 0.6916 - val_acc: 0.9389 - val_mDice: 0.5733

Epoch 00113: val_mDice did not improve from 0.58669
Epoch 114/300
 - 9s - loss: 0.2686 - acc: 0.9481 - mDice: 0.7511 - val_loss: 0.6746 - val_acc: 0.9408 - val_mDice: 0.5694

Epoch 00114: val_mDice did not improve from 0.58669
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
{'val_loss': [1.89940233872487, 1.484220000413748, 1.0963827394522154, 0.9088022227470691, 0.8070597281822791, 0.8717135832859919, 0.8292270302772522, 0.7983649395979368, 0.8293273586493272, 0.8189139572473673, 0.8128493611629193, 0.8122457197079291, 0.8350518414607415, 0.807932755121818, 0.8178749474195334, 0.7930224102277023, 0.7913362131668971, 0.7934001477865072, 0.7649126121631036, 0.7778926720985999, 0.7854127471263592, 0.7730593429161952, 0.7641687163939843, 0.7640778468205378, 0.7668557831874261, 0.7591888583623446, 0.74540026142047, 0.7490698076211489, 0.7418151188355225, 0.7459780218509527, 0.735112903209833, 0.7320897808441749, 0.7351193542663867, 0.7255755617068365, 0.741806277861962, 0.7346098193755517, 0.720459562081557, 0.739856651196113, 0.7110834729212981, 0.7060998334334447, 0.7104700654745102, 0.7145286339979905, 0.7042972353788522, 0.6686364939579597, 0.7025991162428489, 0.695242763711856, 0.7073461092435397, 0.6844846709416463, 0.7020035431935236, 0.6845145546472989, 0.679892510175705, 0.6666454191391284, 0.6726723313331604, 0.6714963706640097, 0.6801412953780248, 0.6657677911795102, 0.68099078306785, 0.6607882838982803, 0.6683696393783276, 0.678596820968848, 0.6819135489372107, 0.6674925616154304, 0.6601837369111868, 0.6557835856309304, 0.6477664491304984, 0.6553894602335416, 0.6437271787570074, 0.6498444951497592, 0.6671117761960397, 0.6519111406344634, 0.6465889914677694, 0.6555121369086779, 0.6448586285114288, 0.6312372982501984, 0.6510572330309794, 0.6398110802357013, 0.6485322599227612, 0.6465557538546048, 0.6386819539161829, 0.6663669416537652, 0.6483289037759488, 0.6400450926560622, 0.6248687631808795, 0.6303776663083297, 0.637189690883343, 0.6457789987325668, 0.6473384774648226, 0.6425834848330572, 0.6394994499591681, 0.6550881908490107, 0.6810333155668699, 0.6397048028615805, 0.6362863251796136, 0.6700714161762824, 0.6372393392599546, 0.6317888463918979, 0.6382426241269479, 0.6423326959976783, 0.6346488044812129, 0.6867532821801993, 0.635491729928897, 0.6584921376063273, 0.6681350011091965, 0.6817417293787003, 0.6900619291342222, 0.681715482702622, 0.6436351400155288, 0.6450714881603534, 0.631120658837832, 0.6453885046335367, 0.6578378895154366, 0.6707141812031086, 0.6916333161867582, 0.6746005713939667], 'val_acc': [0.890051795886113, 0.9043107193249923, 0.91080808868775, 0.9250693229528574, 0.9296112266870645, 0.9340536984113547, 0.9368088680964249, 0.9335521688828101, 0.931996579353626, 0.9353527266245621, 0.9356994193333846, 0.938158759704003, 0.9280256124643179, 0.9398160118323106, 0.9353226675437047, 0.9380362263092628, 0.9351354264296018, 0.940576468522732, 0.9408792509482458, 0.9388244358392862, 0.9397975045901078, 0.937747292793714, 0.9362911444443923, 0.9390070530084463, 0.9369961069180415, 0.9399339052347037, 0.9386071310593531, 0.937241100347959, 0.9391248936836536, 0.9355908150856311, 0.9397327831158271, 0.9387366221501277, 0.9385077747014853, 0.9381494797193087, 0.9370261843387897, 0.93725729905642, 0.9384846756091485, 0.9405440871532147, 0.9412051553909595, 0.939966238462008, 0.9409994414219489, 0.941327691078186, 0.9354243668226095, 0.9380292800756601, 0.9382835351503812, 0.9381679754990798, 0.9405695314590747, 0.9411913110659673, 0.9410549218838031, 0.9386834593919607, 0.9391873341340286, 0.9403938490610856, 0.9431513524972476, 0.9401673720433161, 0.9414548094456012, 0.9392312146150149, 0.9394970444532541, 0.9402805818961217, 0.9406758753152994, 0.9429756884391491, 0.9387643268475165, 0.9394115003255697, 0.940893115905615, 0.9409878689509171, 0.9404793588014749, 0.9432946489407465, 0.9414802010242755, 0.939374559200727, 0.9415703576344711, 0.9409093169065622, 0.941267552284094, 0.9391433940483973, 0.9424070761753962, 0.9418870027248676, 0.9410618451925424, 0.9405487065131848, 0.9387851563783792, 0.9408122507425455, 0.9393838025056399, 0.9363119464654189, 0.9378259227826045, 0.9381495072291448, 0.938426884321066, 0.9396889118047861, 0.9419633081326118, 0.94211123081354, 0.9379830566736368, 0.9427399474840897, 0.9384892766292279, 0.9404631830178775, 0.9399870358980619, 0.9391734439593095, 0.9399639368057251, 0.9361755481133094, 0.9408099009440496, 0.9412398361242734, 0.940287518959779, 0.9370862383108872, 0.9383644874279315, 0.9376017084488502, 0.9432946695731237, 0.939503972346966, 0.9413507603682004, 0.9409671081946447, 0.9372712006935706, 0.9383505857907809, 0.9410457015037537, 0.9384522713147677, 0.9428439507117639, 0.9402482417913584, 0.9381795410926526, 0.9378536664522611, 0.938886835024907, 0.9407752523055444], 'val_mDice': [0.23186050412746576, 0.32695409197073716, 0.42918994564276475, 0.49645346517746264, 0.5333166328760294, 0.5293646747103105, 0.5584824641163533, 0.5656785323069646, 0.5506519629405096, 0.5639456991965954, 0.5623523008364898, 0.5634472719751872, 0.5438311294867442, 0.5591920419381216, 0.5555206809479457, 0.5689133932957282, 0.5669324793494664, 0.5625040496771152, 0.5773339735773894, 0.5697384448005602, 0.5639852262460269, 0.5700496389315679, 0.5736762789579538, 0.5691148306314762, 0.5722207220701071, 0.5713253244757652, 0.5794475485499089, 0.5705530689312861, 0.577387429200686, 0.5751029986601609, 0.5756503034096497, 0.5738922764475529, 0.5749144038328757, 0.5700569513898629, 0.5718099916210542, 0.5682208778766485, 0.5778614041896967, 0.5622503362022914, 0.5772981706720132, 0.5770066403425657, 0.5769234758156997, 0.5743467756188833, 0.573538200213359, 0.5829718021246103, 0.576305397427999, 0.5783462524414062, 0.5672691988830383, 0.5788627547713426, 0.5657641658416162, 0.5757234646723821, 0.5769715360724009, 0.583018591770759, 0.5806727609955348, 0.5784215680681742, 0.5719058462060415, 0.5777820953382895, 0.5804298439851174, 0.5779619692609861, 0.5811695960851816, 0.5773909871394818, 0.5794343014176075, 0.577615520128837, 0.5745610136252183, 0.580027067890534, 0.5789471506499327, 0.5743783941635718, 0.5801322975983987, 0.5757541914398854, 0.5778042083749404, 0.576722224171345, 0.5768880288188274, 0.5756862324017745, 0.5743541316344187, 0.5866871854433646, 0.5758088036225393, 0.5768740893556521, 0.5705182197002264, 0.5721671993915851, 0.5806984523167977, 0.5680738068543948, 0.5861819724623973, 0.574679668706197, 0.58529416930217, 0.5820132941007614, 0.5758519046581708, 0.583384069112631, 0.5725638132828933, 0.5747213028371334, 0.5748903006315231, 0.5662737958706342, 0.5725354139621441, 0.5759848104073451, 0.5795001450639504, 0.578093175131541, 0.5764071666277372, 0.5800527804172956, 0.5751693684321183, 0.5735006338128676, 0.5779405454030404, 0.5749463840172842, 0.5786303671506735, 0.5770826935768127, 0.5718738436698914, 0.5771299686569434, 0.5749884431178753, 0.5748083637310908, 0.5726812292750065, 0.5713232663961557, 0.5803357626383121, 0.5773489360625927, 0.5844969703600957, 0.5724252479580733, 0.5733326616195532, 0.5694073163546048], 'loss': [2.967142301116781, 1.1736368085695326, 0.8434272290408518, 0.7069583289475719, 0.6119545025380458, 0.5467370118281724, 0.50828097238319, 0.4818408561513662, 0.4597185612670348, 0.445819037809678, 0.4309095447984534, 0.4224733015185494, 0.4123586765665262, 0.4042921614093907, 0.39685759905089774, 0.3910871313873345, 0.38446659707807584, 0.37962545243277496, 0.3751098496424891, 0.3682616725103624, 0.36630364517262753, 0.3620737832179426, 0.3565609738124887, 0.3546827802889617, 0.35127581861431856, 0.3499476137162794, 0.3442637051513997, 0.34325962058184917, 0.3389365601575892, 0.3379113570186888, 0.33436145344519763, 0.33325433291039275, 0.33041107918155666, 0.3290278359548111, 0.32725802430596, 0.3242182946481092, 0.3223257945146352, 0.3211528156792712, 0.3196600811607688, 0.3189903192086753, 0.31749148738732763, 0.3153031910932406, 0.3122939584764906, 0.31269620028158224, 0.3104072515346418, 0.311307300580644, 0.3082221874636191, 0.3065438917600547, 0.30786371577394017, 0.30505646103798084, 0.3050019318938948, 0.30318213462895555, 0.3001444149333965, 0.29982636886406877, 0.29979229412603936, 0.2986169060520236, 0.29773571137395566, 0.2961804983218548, 0.29531290043459096, 0.296508392435724, 0.2948335941307529, 0.2939353371242596, 0.2927059416735534, 0.2935310770123359, 0.2915962101414251, 0.2915103588169773, 0.28923047782309896, 0.28884320452370943, 0.28841688300282886, 0.287745001960766, 0.28536801982781307, 0.2869690338601972, 0.2881244629866125, 0.2848030841104287, 0.28440796448869327, 0.28492323877922915, 0.28334908593484837, 0.28285979835417374, 0.28222922303959597, 0.2823897711352032, 0.2823745893627298, 0.2822584352386203, 0.2800448440756732, 0.279559323623437, 0.2805568912306758, 0.27855271367330586, 0.28196958491561, 0.27898448227703665, 0.27755575925510306, 0.27744111677635686, 0.2782953826113292, 0.29365962320760225, 0.27691287285758487, 0.27455322814528643, 0.2745709103581695, 0.27481915318228206, 0.2751117613849237, 0.2744660753528977, 0.27428398834134143, 0.27321183597108134, 0.2721362477377157, 0.2716831928561405, 0.27207574082027774, 0.27136416204584973, 0.2711202869014657, 0.27157923587186744, 0.27240070335090816, 0.26897823236684104, 0.2695767263760154, 0.2692819905931919, 0.27069890283630155, 0.26883394592232474, 0.26847773763698746, 0.2685760718523043], 'acc': [0.5913694756673973, 0.8896117831336323, 0.9053422203255702, 0.9127278125814919, 0.9196908977829221, 0.9251657839763827, 0.9283764066263438, 0.9304738896948312, 0.9321934480701416, 0.9332406274904945, 0.9344938747295537, 0.9350207322617688, 0.9359044348205201, 0.936589276236515, 0.9369221717506759, 0.937655518517375, 0.9381085560570934, 0.9384776101355996, 0.9388203759326669, 0.9393559718862029, 0.939514237384476, 0.9399250624453154, 0.9402369207246578, 0.9403274839933449, 0.9406208726441323, 0.9408552322035444, 0.9411542330744257, 0.9411096503008317, 0.941619458595875, 0.9416773030978446, 0.9419721339413637, 0.9420016613996502, 0.9422889603005556, 0.9423332547037669, 0.9424924308453541, 0.9426871466590483, 0.9428816637264608, 0.9430484226255039, 0.943117857853403, 0.9432536246239408, 0.943415016708235, 0.9434198096406907, 0.9436998511772363, 0.9434610210275953, 0.943873595654893, 0.9437960696200609, 0.9438718185206681, 0.9441117620452748, 0.9441155526873964, 0.944481060644099, 0.9444530399250476, 0.9444498932362703, 0.9448937278034436, 0.9448585667359942, 0.9447900155896048, 0.945009475917292, 0.9450051708161188, 0.9451506928490347, 0.9451750608307623, 0.9452257381366823, 0.9453379379903699, 0.9453487576598844, 0.9454869624599368, 0.9453566496820563, 0.9454891811236897, 0.9455977030415207, 0.9458545969936072, 0.9459660505991212, 0.9460053532741216, 0.946024201117043, 0.9461566397187939, 0.9461834641836737, 0.9462517232051868, 0.9462858419526957, 0.9464392146423911, 0.9463069043145852, 0.946528447044849, 0.9465891230615382, 0.946679442420081, 0.9466374094807485, 0.9465596406351846, 0.9467541750953018, 0.9469282730450481, 0.9468903629462965, 0.9468174909936274, 0.9470228721193311, 0.9471208832365752, 0.9471463341175559, 0.9471102194032754, 0.9472101623090906, 0.9471014613134663, 0.9455123027125419, 0.9472148805639571, 0.9473722208517016, 0.9473998189841009, 0.9474000827441365, 0.9474315664529207, 0.9474001757874102, 0.9473769585441798, 0.9474761963088519, 0.9476037146057203, 0.9476768729553269, 0.947686560625829, 0.9477520941984364, 0.9477765263473703, 0.9477101257946134, 0.9477361992838461, 0.948016423075487, 0.9479046214784543, 0.9478865301522186, 0.9477987855296287, 0.9479530596605561, 0.9480419399981722, 0.948081554642443], 'mDice': [0.09464005977094014, 0.3098341545242451, 0.41832097807427915, 0.47667863343041905, 0.5248569812456269, 0.5621390085559835, 0.585087426746836, 0.6013616128325363, 0.6152933122794434, 0.6244501348660132, 0.6340493647570453, 0.6397261695757153, 0.6464145611784373, 0.6519733572164541, 0.6567413572355641, 0.6609450583032255, 0.6655327829830455, 0.6688792404406825, 0.6720029163941086, 0.6767847131706523, 0.6781520280002019, 0.6811922629644958, 0.6851567861713476, 0.6864156113563181, 0.689029848444762, 0.6899701757953471, 0.693947228565874, 0.6946734857770291, 0.697841482635003, 0.6985283360197174, 0.7011201004255063, 0.7020023269516114, 0.7040131493686893, 0.7051017283843605, 0.7063680572680394, 0.7085658737316481, 0.7099443711247665, 0.7109027642897219, 0.7119748900926807, 0.7124757508416683, 0.7135458241515655, 0.7152101166472822, 0.717500586258159, 0.7171049383879917, 0.7188638059853034, 0.7183224373414355, 0.7204802746780682, 0.7217794355734417, 0.720789374157829, 0.7228820505786907, 0.7229390824774496, 0.7242633560910322, 0.7266274857408918, 0.7269463330345115, 0.7269063258450332, 0.7278310282802292, 0.7284393212699168, 0.7296884611261338, 0.7302397861369012, 0.7294583085453358, 0.7306395227988466, 0.7314448062040858, 0.7323297662103043, 0.731716763365261, 0.7331907303309315, 0.7332176519288993, 0.7349636411354638, 0.735204118419307, 0.7356058217541798, 0.7361342515176286, 0.7379431979612023, 0.7367102589970485, 0.7359141814008384, 0.7383863491281134, 0.7386794963259434, 0.738264520554418, 0.7394950779493825, 0.7398731183502206, 0.740462476280599, 0.7402718373960228, 0.7402400554056527, 0.7403382373331087, 0.7420687982212142, 0.7424667254811799, 0.7416261562306777, 0.7432381360170026, 0.7440097773854587, 0.7428472005803131, 0.743970238485207, 0.7441488654479587, 0.7435189042211865, 0.7318446851574846, 0.7445486902443013, 0.7463502113882668, 0.7463530717130892, 0.7461496029218536, 0.7459714243049871, 0.74640755470659, 0.7465473223049175, 0.7473614667819279, 0.7482454560729374, 0.7486110989660242, 0.7482243561661135, 0.748912173466171, 0.7490294386537315, 0.748790424984671, 0.7481074088901476, 0.7507557370758778, 0.7502465529777375, 0.7505097547811435, 0.7494309754935862, 0.7508288595516568, 0.7510885996516424, 0.7510811451076637]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.11s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.76s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:29,  1.79s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:46,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:43,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:16,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:30,  1.61s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:31,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:35,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:53,  1.72s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:06,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:36,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:00,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<08:02,  1.77s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:05,  1.79s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:20,  1.85s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:16,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:53,  1.77s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:51,  1.77s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:37,  1.72s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:32,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:46,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:24,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:29,  1.72s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:24,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:46,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.73s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:26,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:26,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:35,  1.79s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:46,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:27,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:19,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:24,  1.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:40,  1.84s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:09,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:01,  1.71s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<07:00,  1.72s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:44,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:50,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:00,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:50,  1.71s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<07:07,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:51,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:59,  1.78s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<07:00,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:57,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:48,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<07:01,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:43,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [01:37<06:44,  1.77s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:30,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:31,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:40,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:44<06:46,  1.81s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:32,  1.75s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:31,  1.76s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:27,  1.74s/it]predicting train subjects:  22%|██▏       | 64/285 [01:51<06:15,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:17,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:17,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:13,  1.71s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<06:08,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:07,  1.70s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:12,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:01,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<05:57,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<05:56,  1.70s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:55,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:45,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:46,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:45,  1.69s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:43,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:43,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:33,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:22,  1.61s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:29,  1.65s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:39,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:35,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:26,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:33,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:23,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:30,  1.71s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:19,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:24,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:19,  1.68s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:15,  1.67s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:18,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:21,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:26,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:16,  1.73s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<05:08,  1.70s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<05:06,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<04:58,  1.67s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<04:53,  1.66s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<04:53,  1.67s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<04:57,  1.70s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<04:47,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:47,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<04:53,  1.71s/it]predicting train subjects:  40%|████      | 114/285 [03:16<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:17<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:57,  1.76s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:46,  1.71s/it]predicting train subjects:  41%|████▏     | 118/285 [03:22<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:34,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<04:27,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:28<04:13,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:05,  1.52s/it]predicting train subjects:  44%|████▎     | 124/285 [03:31<04:07,  1.54s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<04:00,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:34<03:52,  1.46s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<03:44,  1.42s/it]predicting train subjects:  45%|████▍     | 128/285 [03:37<03:48,  1.46s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:46,  1.45s/it]predicting train subjects:  46%|████▌     | 130/285 [03:40<03:42,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<03:37,  1.41s/it]predicting train subjects:  46%|████▋     | 132/285 [03:43<03:41,  1.45s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:37,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:30,  1.39s/it]predicting train subjects:  47%|████▋     | 135/285 [03:47<03:24,  1.37s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:21,  1.35s/it]predicting train subjects:  48%|████▊     | 137/285 [03:50<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 138/285 [03:51<03:23,  1.38s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:27,  1.42s/it]predicting train subjects:  49%|████▉     | 140/285 [03:54<03:29,  1.44s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:25,  1.43s/it]predicting train subjects:  50%|████▉     | 142/285 [03:57<03:23,  1.42s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [04:00<03:22,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:19,  1.42s/it]predicting train subjects:  51%|█████     | 146/285 [04:03<03:21,  1.45s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:04<03:16,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:17,  1.44s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:07<03:10,  1.40s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:05,  1.37s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:09<03:07,  1.40s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:02,  1.37s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<02:57,  1.35s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:03,  1.40s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:03,  1.41s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:17<03:07,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:04,  1.44s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:19<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:22<02:54,  1.40s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:27<02:56,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:29<02:51,  1.43s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:32<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:34<02:43,  1.40s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:35<02:39,  1.38s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:36<02:40,  1.39s/it]predicting train subjects:  60%|██████    | 171/285 [04:38<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:39<02:37,  1.39s/it]predicting train subjects:  61%|██████    | 173/285 [04:41<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:42<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:44<02:37,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:45<02:40,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:46<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:48<02:29,  1.40s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:49<02:26,  1.38s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:51<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:52<02:34,  1.49s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:54<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:55<02:28,  1.45s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:57<02:23,  1.42s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:58<02:18,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:00<02:26,  1.48s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:01<02:31,  1.55s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:03<02:34,  1.59s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:04<02:25,  1.51s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:06<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:07<02:21,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:09<02:21,  1.52s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:10<02:13,  1.45s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:11<02:08,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:13<02:04,  1.38s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:14<02:11,  1.48s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:16<02:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:18<02:17,  1.58s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:19<02:08,  1.49s/it]predicting train subjects:  70%|███████   | 200/285 [05:20<02:02,  1.44s/it]predicting train subjects:  71%|███████   | 201/285 [05:22<02:06,  1.50s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:05,  1.52s/it]predicting train subjects:  71%|███████   | 203/285 [05:25<02:04,  1.52s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:26<01:58,  1.46s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:28<01:54,  1.43s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:29<01:49,  1.39s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:31<01:56,  1.50s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:33<02:00,  1.56s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:34<02:01,  1.60s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:36<01:52,  1.50s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:37<01:47,  1.46s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:38<01:48,  1.48s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:40<01:47,  1.49s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:41<01:41,  1.43s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:43<01:47,  1.53s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:44<01:40,  1.46s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:46<01:44,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:48<01:46,  1.60s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:49<01:47,  1.63s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:51<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:52<01:35,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:54<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:55<01:28,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:56<01:25,  1.40s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:58<01:22,  1.37s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:59<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:01<01:30,  1.56s/it]predicting train subjects:  80%|████████  | 228/285 [06:03<01:31,  1.60s/it]predicting train subjects:  80%|████████  | 229/285 [06:04<01:29,  1.59s/it]predicting train subjects:  81%|████████  | 230/285 [06:06<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [06:07<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:09<01:19,  1.49s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:10<01:13,  1.41s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:11<01:16,  1.49s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:13<01:11,  1.43s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:14<01:13,  1.51s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:16<01:15,  1.56s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:18<01:15,  1.61s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:13,  1.60s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:09,  1.53s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:04,  1.48s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:23<01:01,  1.43s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:25<00:59,  1.41s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:26<01:01,  1.49s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:28<00:56,  1.42s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:29<00:59,  1.51s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:31<00:59,  1.56s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:33<00:57,  1.55s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:34<00:52,  1.46s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:35<00:49,  1.42s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:36<00:46,  1.38s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:38<00:44,  1.34s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:39<00:46,  1.46s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:41<00:47,  1.53s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:43<00:46,  1.56s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:44<00:42,  1.48s/it]predicting train subjects:  90%|█████████ | 257/285 [06:45<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [06:47<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [06:49<00:39,  1.52s/it]predicting train subjects:  91%|█████████ | 260/285 [06:50<00:36,  1.45s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:51<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:53<00:31,  1.39s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:54<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:56<00:30,  1.47s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:57<00:30,  1.53s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:00<00:25,  1.41s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:02<00:25,  1.49s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:03<00:24,  1.50s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:04<00:21,  1.43s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:06<00:19,  1.40s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:07<00:18,  1.46s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:09<00:16,  1.41s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:10<00:15,  1.37s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:12<00:14,  1.48s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:13<00:13,  1.54s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:15<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:16<00:10,  1.45s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:18<00:08,  1.48s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:19<00:07,  1.43s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:20<00:05,  1.41s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:21<00:04,  1.37s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:23<00:02,  1.47s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:25<00:01,  1.56s/it]predicting train subjects: 100%|██████████| 285/285 [07:27<00:00,  1.61s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:46,  1.64s/it]Loading train:   1%|          | 2/285 [00:02<06:56,  1.47s/it]Loading train:   1%|          | 3/285 [00:04<06:40,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:05<06:14,  1.33s/it]Loading train:   2%|▏         | 5/285 [00:06<06:29,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:07<06:06,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:24,  1.38s/it]Loading train:   3%|▎         | 8/285 [00:10<06:20,  1.38s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:03,  1.32s/it]Loading train:   4%|▍         | 11/285 [00:14<05:13,  1.15s/it]Loading train:   4%|▍         | 12/285 [00:15<05:03,  1.11s/it]Loading train:   5%|▍         | 13/285 [00:15<04:38,  1.02s/it]Loading train:   5%|▍         | 14/285 [00:17<04:48,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:17<04:32,  1.01s/it]Loading train:   6%|▌         | 16/285 [00:19<04:34,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:19<04:08,  1.08it/s]Loading train:   6%|▋         | 18/285 [00:20<03:59,  1.11it/s]Loading train:   7%|▋         | 19/285 [00:21<03:46,  1.18it/s]Loading train:   7%|▋         | 20/285 [00:22<03:40,  1.20it/s]Loading train:   7%|▋         | 21/285 [00:23<03:47,  1.16it/s]Loading train:   8%|▊         | 22/285 [00:23<03:28,  1.26it/s]Loading train:   8%|▊         | 23/285 [00:24<03:37,  1.20it/s]Loading train:   8%|▊         | 24/285 [00:25<03:55,  1.11it/s]Loading train:   9%|▉         | 25/285 [00:26<04:18,  1.01it/s]Loading train:   9%|▉         | 26/285 [00:28<04:40,  1.08s/it]Loading train:   9%|▉         | 27/285 [00:29<04:27,  1.03s/it]Loading train:  10%|▉         | 28/285 [00:30<04:32,  1.06s/it]Loading train:  10%|█         | 29/285 [00:31<04:27,  1.05s/it]Loading train:  11%|█         | 30/285 [00:32<04:31,  1.07s/it]Loading train:  11%|█         | 31/285 [00:33<04:43,  1.12s/it]Loading train:  11%|█         | 32/285 [00:34<04:26,  1.05s/it]Loading train:  12%|█▏        | 33/285 [00:35<04:41,  1.12s/it]Loading train:  12%|█▏        | 34/285 [00:36<04:50,  1.16s/it]Loading train:  12%|█▏        | 35/285 [00:37<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:38<04:25,  1.07s/it]Loading train:  13%|█▎        | 37/285 [00:40<04:26,  1.07s/it]Loading train:  13%|█▎        | 38/285 [00:41<04:38,  1.13s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:27,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:43<04:24,  1.08s/it]Loading train:  14%|█▍        | 41/285 [00:44<04:33,  1.12s/it]Loading train:  15%|█▍        | 42/285 [00:45<04:25,  1.09s/it]Loading train:  15%|█▌        | 43/285 [00:46<04:27,  1.11s/it]Loading train:  15%|█▌        | 44/285 [00:47<04:24,  1.10s/it]Loading train:  16%|█▌        | 45/285 [00:48<04:14,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:49<04:16,  1.08s/it]Loading train:  16%|█▋        | 47/285 [00:50<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [00:52<04:18,  1.09s/it]Loading train:  17%|█▋        | 49/285 [00:53<04:23,  1.12s/it]Loading train:  18%|█▊        | 50/285 [00:54<04:19,  1.11s/it]Loading train:  18%|█▊        | 51/285 [00:55<04:17,  1.10s/it]Loading train:  18%|█▊        | 52/285 [00:56<03:58,  1.02s/it]Loading train:  19%|█▊        | 53/285 [00:57<04:02,  1.05s/it]Loading train:  19%|█▉        | 54/285 [00:58<04:19,  1.12s/it]Loading train:  19%|█▉        | 55/285 [00:59<04:10,  1.09s/it]Loading train:  20%|█▉        | 56/285 [01:00<04:03,  1.07s/it]Loading train:  20%|██        | 57/285 [01:01<04:01,  1.06s/it]Loading train:  20%|██        | 58/285 [01:02<04:02,  1.07s/it]Loading train:  21%|██        | 59/285 [01:03<04:09,  1.10s/it]Loading train:  21%|██        | 60/285 [01:05<04:08,  1.11s/it]Loading train:  21%|██▏       | 61/285 [01:06<04:00,  1.07s/it]Loading train:  22%|██▏       | 62/285 [01:07<03:57,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:08<03:57,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:09<04:22,  1.19s/it]Loading train:  23%|██▎       | 65/285 [01:11<04:50,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:55,  1.35s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:40,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:14<04:21,  1.21s/it]Loading train:  24%|██▍       | 69/285 [01:16<04:15,  1.19s/it]Loading train:  25%|██▍       | 70/285 [01:17<04:09,  1.16s/it]Loading train:  25%|██▍       | 71/285 [01:18<04:24,  1.24s/it]Loading train:  25%|██▌       | 72/285 [01:19<04:28,  1.26s/it]Loading train:  26%|██▌       | 73/285 [01:21<04:21,  1.23s/it]Loading train:  26%|██▌       | 74/285 [01:22<04:03,  1.16s/it]Loading train:  26%|██▋       | 75/285 [01:23<03:56,  1.13s/it]Loading train:  27%|██▋       | 76/285 [01:24<03:57,  1.13s/it]Loading train:  27%|██▋       | 77/285 [01:25<03:51,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:26<03:51,  1.12s/it]Loading train:  28%|██▊       | 79/285 [01:27<03:52,  1.13s/it]Loading train:  28%|██▊       | 80/285 [01:28<03:52,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:29<03:38,  1.07s/it]Loading train:  29%|██▉       | 82/285 [01:30<03:32,  1.05s/it]Loading train:  29%|██▉       | 83/285 [01:31<03:31,  1.05s/it]Loading train:  29%|██▉       | 84/285 [01:32<03:34,  1.07s/it]Loading train:  30%|██▉       | 85/285 [01:33<03:23,  1.02s/it]Loading train:  30%|███       | 86/285 [01:34<03:29,  1.05s/it]Loading train:  31%|███       | 87/285 [01:35<03:25,  1.04s/it]Loading train:  31%|███       | 88/285 [01:36<03:19,  1.01s/it]Loading train:  31%|███       | 89/285 [01:37<03:26,  1.05s/it]Loading train:  32%|███▏      | 90/285 [01:39<03:30,  1.08s/it]Loading train:  32%|███▏      | 91/285 [01:40<03:27,  1.07s/it]Loading train:  32%|███▏      | 92/285 [01:41<03:40,  1.14s/it]Loading train:  33%|███▎      | 93/285 [01:42<03:31,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:43<03:28,  1.09s/it]Loading train:  33%|███▎      | 95/285 [01:44<03:36,  1.14s/it]Loading train:  34%|███▎      | 96/285 [01:45<03:40,  1.16s/it]Loading train:  34%|███▍      | 97/285 [01:47<03:36,  1.15s/it]Loading train:  34%|███▍      | 98/285 [01:48<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:49<03:17,  1.06s/it]Loading train:  35%|███▌      | 100/285 [01:50<03:19,  1.08s/it]Loading train:  35%|███▌      | 101/285 [01:51<03:19,  1.08s/it]Loading train:  36%|███▌      | 102/285 [01:52<03:20,  1.10s/it]Loading train:  36%|███▌      | 103/285 [01:53<03:13,  1.06s/it]Loading train:  36%|███▋      | 104/285 [01:54<03:06,  1.03s/it]Loading train:  37%|███▋      | 105/285 [01:55<03:16,  1.09s/it]Loading train:  37%|███▋      | 106/285 [01:56<03:17,  1.10s/it]Loading train:  38%|███▊      | 107/285 [01:57<03:20,  1.13s/it]Loading train:  38%|███▊      | 108/285 [01:58<03:09,  1.07s/it]Loading train:  38%|███▊      | 109/285 [02:00<03:17,  1.12s/it]Loading train:  39%|███▊      | 110/285 [02:01<03:21,  1.15s/it]Loading train:  39%|███▉      | 111/285 [02:02<03:10,  1.10s/it]Loading train:  39%|███▉      | 112/285 [02:03<03:09,  1.10s/it]Loading train:  40%|███▉      | 113/285 [02:04<03:12,  1.12s/it]Loading train:  40%|████      | 114/285 [02:05<03:15,  1.15s/it]Loading train:  40%|████      | 115/285 [02:06<03:10,  1.12s/it]Loading train:  41%|████      | 116/285 [02:08<03:15,  1.16s/it]Loading train:  41%|████      | 117/285 [02:08<03:00,  1.08s/it]Loading train:  41%|████▏     | 118/285 [02:09<02:52,  1.03s/it]Loading train:  42%|████▏     | 119/285 [02:11<03:41,  1.33s/it]Loading train:  42%|████▏     | 120/285 [02:12<03:20,  1.22s/it]Loading train:  42%|████▏     | 121/285 [02:14<03:23,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:15<03:19,  1.22s/it]Loading train:  43%|████▎     | 123/285 [02:16<03:22,  1.25s/it]Loading train:  44%|████▎     | 124/285 [02:17<03:09,  1.18s/it]Loading train:  44%|████▍     | 125/285 [02:18<02:51,  1.07s/it]Loading train:  44%|████▍     | 126/285 [02:19<02:46,  1.05s/it]Loading train:  45%|████▍     | 127/285 [02:20<02:33,  1.03it/s]Loading train:  45%|████▍     | 128/285 [02:21<02:34,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:22<02:22,  1.09it/s]Loading train:  46%|████▌     | 130/285 [02:22<02:18,  1.12it/s]Loading train:  46%|████▌     | 131/285 [02:23<02:17,  1.12it/s]Loading train:  46%|████▋     | 132/285 [02:24<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:25<02:25,  1.05it/s]Loading train:  47%|████▋     | 134/285 [02:26<02:22,  1.06it/s]Loading train:  47%|████▋     | 135/285 [02:27<02:22,  1.05it/s]Loading train:  48%|████▊     | 136/285 [02:28<02:13,  1.12it/s]Loading train:  48%|████▊     | 137/285 [02:29<02:12,  1.12it/s]Loading train:  48%|████▊     | 138/285 [02:30<02:18,  1.06it/s]Loading train:  49%|████▉     | 139/285 [02:31<02:14,  1.08it/s]Loading train:  49%|████▉     | 140/285 [02:32<02:11,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:33<02:11,  1.09it/s]Loading train:  50%|████▉     | 142/285 [02:34<02:16,  1.05it/s]Loading train:  50%|█████     | 143/285 [02:35<02:18,  1.02it/s]Loading train:  51%|█████     | 144/285 [02:36<02:33,  1.09s/it]Loading train:  51%|█████     | 145/285 [02:37<02:25,  1.04s/it]Loading train:  51%|█████     | 146/285 [02:38<02:24,  1.04s/it]Loading train:  52%|█████▏    | 147/285 [02:39<02:19,  1.01s/it]Loading train:  52%|█████▏    | 148/285 [02:40<02:18,  1.01s/it]Loading train:  52%|█████▏    | 149/285 [02:41<02:17,  1.01s/it]Loading train:  53%|█████▎    | 150/285 [02:42<02:12,  1.02it/s]Loading train:  53%|█████▎    | 151/285 [02:43<02:08,  1.04it/s]Loading train:  53%|█████▎    | 152/285 [02:44<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [02:45<02:06,  1.04it/s]Loading train:  54%|█████▍    | 154/285 [02:46<02:05,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [02:47<02:04,  1.04it/s]Loading train:  55%|█████▍    | 156/285 [02:48<02:01,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [02:48<01:56,  1.10it/s]Loading train:  55%|█████▌    | 158/285 [02:49<01:52,  1.13it/s]Loading train:  56%|█████▌    | 159/285 [02:50<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [02:51<01:50,  1.13it/s]Loading train:  56%|█████▋    | 161/285 [02:52<01:55,  1.07it/s]Loading train:  57%|█████▋    | 162/285 [02:53<01:55,  1.07it/s]Loading train:  57%|█████▋    | 163/285 [02:54<01:58,  1.03it/s]Loading train:  58%|█████▊    | 164/285 [02:55<01:51,  1.09it/s]Loading train:  58%|█████▊    | 165/285 [02:56<01:50,  1.08it/s]Loading train:  58%|█████▊    | 166/285 [02:57<01:51,  1.07it/s]Loading train:  59%|█████▊    | 167/285 [02:58<01:51,  1.06it/s]Loading train:  59%|█████▉    | 168/285 [02:59<01:47,  1.09it/s]Loading train:  59%|█████▉    | 169/285 [02:59<01:46,  1.09it/s]Loading train:  60%|█████▉    | 170/285 [03:00<01:40,  1.14it/s]Loading train:  60%|██████    | 171/285 [03:01<01:47,  1.06it/s]Loading train:  60%|██████    | 172/285 [03:02<01:49,  1.03it/s]Loading train:  61%|██████    | 173/285 [03:04<01:56,  1.04s/it]Loading train:  61%|██████    | 174/285 [03:04<01:49,  1.01it/s]Loading train:  61%|██████▏   | 175/285 [03:06<01:51,  1.01s/it]Loading train:  62%|██████▏   | 176/285 [03:06<01:48,  1.01it/s]Loading train:  62%|██████▏   | 177/285 [03:07<01:44,  1.03it/s]Loading train:  62%|██████▏   | 178/285 [03:08<01:39,  1.08it/s]Loading train:  63%|██████▎   | 179/285 [03:09<01:36,  1.10it/s]Loading train:  63%|██████▎   | 180/285 [03:10<01:43,  1.01it/s]Loading train:  64%|██████▎   | 181/285 [03:11<01:40,  1.03it/s]Loading train:  64%|██████▍   | 182/285 [03:12<01:40,  1.03it/s]Loading train:  64%|██████▍   | 183/285 [03:13<01:34,  1.07it/s]Loading train:  65%|██████▍   | 184/285 [03:14<01:36,  1.05it/s]Loading train:  65%|██████▍   | 185/285 [03:15<01:34,  1.06it/s]Loading train:  65%|██████▌   | 186/285 [03:16<01:37,  1.02it/s]Loading train:  66%|██████▌   | 187/285 [03:17<01:40,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [03:18<01:42,  1.05s/it]Loading train:  66%|██████▋   | 189/285 [03:19<01:36,  1.01s/it]Loading train:  67%|██████▋   | 190/285 [03:20<01:37,  1.03s/it]Loading train:  67%|██████▋   | 191/285 [03:21<01:35,  1.01s/it]Loading train:  67%|██████▋   | 192/285 [03:22<01:33,  1.00s/it]Loading train:  68%|██████▊   | 193/285 [03:23<01:31,  1.00it/s]Loading train:  68%|██████▊   | 194/285 [03:24<01:27,  1.04it/s]Loading train:  68%|██████▊   | 195/285 [03:25<01:23,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [03:26<01:28,  1.01it/s]Loading train:  69%|██████▉   | 197/285 [03:27<01:28,  1.01s/it]Loading train:  69%|██████▉   | 198/285 [03:28<01:28,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:29<01:20,  1.06it/s]Loading train:  70%|███████   | 200/285 [03:30<01:21,  1.04it/s]Loading train:  71%|███████   | 201/285 [03:31<01:21,  1.02it/s]Loading train:  71%|███████   | 202/285 [03:32<01:21,  1.02it/s]Loading train:  71%|███████   | 203/285 [03:33<01:17,  1.06it/s]Loading train:  72%|███████▏  | 204/285 [03:34<01:17,  1.05it/s]Loading train:  72%|███████▏  | 205/285 [03:35<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:36<01:14,  1.06it/s]Loading train:  73%|███████▎  | 207/285 [03:37<01:17,  1.01it/s]Loading train:  73%|███████▎  | 208/285 [03:38<01:17,  1.00s/it]Loading train:  73%|███████▎  | 209/285 [03:39<01:19,  1.05s/it]Loading train:  74%|███████▎  | 210/285 [03:40<01:15,  1.00s/it]Loading train:  74%|███████▍  | 211/285 [03:41<01:13,  1.00it/s]Loading train:  74%|███████▍  | 212/285 [03:42<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:43<01:10,  1.02it/s]Loading train:  75%|███████▌  | 214/285 [03:44<01:08,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [03:45<01:12,  1.03s/it]Loading train:  76%|███████▌  | 216/285 [03:46<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [03:47<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [03:48<01:10,  1.06s/it]Loading train:  77%|███████▋  | 219/285 [03:49<01:11,  1.09s/it]Loading train:  77%|███████▋  | 220/285 [03:50<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [03:51<00:59,  1.07it/s]Loading train:  78%|███████▊  | 222/285 [03:52<01:00,  1.04it/s]Loading train:  78%|███████▊  | 223/285 [03:53<00:58,  1.06it/s]Loading train:  79%|███████▊  | 224/285 [03:54<00:58,  1.04it/s]Loading train:  79%|███████▉  | 225/285 [03:54<00:53,  1.13it/s]Loading train:  79%|███████▉  | 226/285 [03:56<00:58,  1.01it/s]Loading train:  80%|███████▉  | 227/285 [03:57<00:57,  1.00it/s]Loading train:  80%|████████  | 228/285 [03:58<01:01,  1.09s/it]Loading train:  80%|████████  | 229/285 [03:59<01:03,  1.13s/it]Loading train:  81%|████████  | 230/285 [04:00<00:59,  1.09s/it]Loading train:  81%|████████  | 231/285 [04:01<00:55,  1.03s/it]Loading train:  81%|████████▏ | 232/285 [04:02<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [04:03<00:50,  1.04it/s]Loading train:  82%|████████▏ | 234/285 [04:04<00:53,  1.05s/it]Loading train:  82%|████████▏ | 235/285 [04:05<00:51,  1.03s/it]Loading train:  83%|████████▎ | 236/285 [04:06<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:07<00:53,  1.12s/it]Loading train:  84%|████████▎ | 238/285 [04:09<00:53,  1.15s/it]Loading train:  84%|████████▍ | 239/285 [04:10<00:52,  1.14s/it]Loading train:  84%|████████▍ | 240/285 [04:11<00:48,  1.08s/it]Loading train:  85%|████████▍ | 241/285 [04:12<00:44,  1.02s/it]Loading train:  85%|████████▍ | 242/285 [04:13<00:42,  1.00it/s]Loading train:  85%|████████▌ | 243/285 [04:13<00:38,  1.08it/s]Loading train:  86%|████████▌ | 244/285 [04:15<00:44,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:16<00:39,  1.01it/s]Loading train:  86%|████████▋ | 246/285 [04:17<00:38,  1.00it/s]Loading train:  87%|████████▋ | 247/285 [04:18<00:38,  1.01s/it]Loading train:  87%|████████▋ | 248/285 [04:18<00:34,  1.06it/s]Loading train:  87%|████████▋ | 249/285 [04:19<00:33,  1.09it/s]Loading train:  88%|████████▊ | 250/285 [04:20<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [04:21<00:31,  1.08it/s]Loading train:  88%|████████▊ | 252/285 [04:22<00:30,  1.10it/s]Loading train:  89%|████████▉ | 253/285 [04:23<00:32,  1.02s/it]Loading train:  89%|████████▉ | 254/285 [04:24<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [04:25<00:30,  1.01s/it]Loading train:  90%|████████▉ | 256/285 [04:26<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [04:27<00:27,  1.02it/s]Loading train:  91%|█████████ | 258/285 [04:28<00:28,  1.05s/it]Loading train:  91%|█████████ | 259/285 [04:29<00:27,  1.04s/it]Loading train:  91%|█████████ | 260/285 [04:30<00:24,  1.04it/s]Loading train:  92%|█████████▏| 261/285 [04:31<00:23,  1.01it/s]Loading train:  92%|█████████▏| 262/285 [04:32<00:22,  1.04it/s]Loading train:  92%|█████████▏| 263/285 [04:33<00:21,  1.03it/s]Loading train:  93%|█████████▎| 264/285 [04:34<00:22,  1.08s/it]Loading train:  93%|█████████▎| 265/285 [04:36<00:21,  1.08s/it]Loading train:  93%|█████████▎| 266/285 [04:37<00:20,  1.07s/it]Loading train:  94%|█████████▎| 267/285 [04:38<00:18,  1.02s/it]Loading train:  94%|█████████▍| 268/285 [04:39<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [04:40<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:40<00:14,  1.04it/s]Loading train:  95%|█████████▌| 271/285 [04:41<00:12,  1.10it/s]Loading train:  95%|█████████▌| 272/285 [04:42<00:11,  1.10it/s]Loading train:  96%|█████████▌| 273/285 [04:43<00:11,  1.06it/s]Loading train:  96%|█████████▌| 274/285 [04:44<00:10,  1.09it/s]Loading train:  96%|█████████▋| 275/285 [04:45<00:09,  1.07it/s]Loading train:  97%|█████████▋| 276/285 [04:46<00:08,  1.04it/s]Loading train:  97%|█████████▋| 277/285 [04:47<00:07,  1.03it/s]Loading train:  98%|█████████▊| 278/285 [04:48<00:06,  1.02it/s]Loading train:  98%|█████████▊| 279/285 [04:49<00:05,  1.03it/s]Loading train:  98%|█████████▊| 280/285 [04:50<00:04,  1.05it/s]Loading train:  99%|█████████▊| 281/285 [04:51<00:03,  1.08it/s]Loading train:  99%|█████████▉| 282/285 [04:52<00:02,  1.03it/s]Loading train:  99%|█████████▉| 283/285 [04:53<00:02,  1.02s/it]Loading train: 100%|█████████▉| 284/285 [04:54<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:55<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 61.80it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:03, 77.76it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 101.61it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:01, 118.88it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:01, 120.65it/s]concatenating: train:  41%|████      | 116/285 [00:00<00:01, 128.99it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:01, 130.29it/s]concatenating: train:  53%|█████▎    | 151/285 [00:00<00:00, 138.17it/s]concatenating: train:  59%|█████▊    | 167/285 [00:01<00:00, 140.47it/s]concatenating: train:  64%|██████▍   | 183/285 [00:01<00:00, 136.69it/s]concatenating: train:  72%|███████▏  | 204/285 [00:01<00:00, 152.67it/s]concatenating: train:  80%|███████▉  | 227/285 [00:01<00:00, 169.60it/s]concatenating: train:  93%|█████████▎| 265/285 [00:01<00:00, 202.87it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 192.91it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.23s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 84.96it/s]2019-07-10 21:53:02.814005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:53:02.814093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:53:02.814109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:53:02.814117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:53:02.814551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.35it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.27it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.93it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.64it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.30it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.91it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.94it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.72it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.61it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.20it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.51it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.38it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.18it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.51it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.15it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.83it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.25it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 129,458
Trainable params: 30,958
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 13s - loss: 3.2908 - acc: 0.4069 - mDice: 0.0577 - val_loss: 2.6049 - val_acc: 0.8095 - val_mDice: 0.1495

Epoch 00001: val_mDice improved from -inf to 0.14953, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 7s - loss: 1.5166 - acc: 0.8499 - mDice: 0.2214 - val_loss: 1.8659 - val_acc: 0.8592 - val_mDice: 0.2653

Epoch 00002: val_mDice improved from 0.14953 to 0.26525, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 7s - loss: 1.0606 - acc: 0.8738 - mDice: 0.3352 - val_loss: 1.6829 - val_acc: 0.8825 - val_mDice: 0.3190

Epoch 00003: val_mDice improved from 0.26525 to 0.31899, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.8792 - acc: 0.8799 - mDice: 0.4003 - val_loss: 1.3210 - val_acc: 0.9061 - val_mDice: 0.4377

Epoch 00004: val_mDice improved from 0.31899 to 0.43772, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.7886 - acc: 0.8839 - mDice: 0.4385 - val_loss: 1.2386 - val_acc: 0.9126 - val_mDice: 0.4740

Epoch 00005: val_mDice improved from 0.43772 to 0.47399, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 7s - loss: 0.7258 - acc: 0.8873 - mDice: 0.4676 - val_loss: 1.1499 - val_acc: 0.9162 - val_mDice: 0.4872

Epoch 00006: val_mDice improved from 0.47399 to 0.48718, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 7s - loss: 0.6897 - acc: 0.8901 - mDice: 0.4853 - val_loss: 1.1105 - val_acc: 0.9179 - val_mDice: 0.4991

Epoch 00007: val_mDice improved from 0.48718 to 0.49907, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 7s - loss: 0.6596 - acc: 0.8925 - mDice: 0.5002 - val_loss: 1.1743 - val_acc: 0.9178 - val_mDice: 0.4804

Epoch 00008: val_mDice did not improve from 0.49907
Epoch 9/300
 - 7s - loss: 0.6326 - acc: 0.8958 - mDice: 0.5142 - val_loss: 1.1236 - val_acc: 0.9214 - val_mDice: 0.5057

Epoch 00009: val_mDice improved from 0.49907 to 0.50573, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 7s - loss: 0.6115 - acc: 0.8984 - mDice: 0.5254 - val_loss: 1.0931 - val_acc: 0.9273 - val_mDice: 0.5040

Epoch 00010: val_mDice did not improve from 0.50573
Epoch 11/300
 - 7s - loss: 0.5947 - acc: 0.9012 - mDice: 0.5347 - val_loss: 1.0937 - val_acc: 0.9313 - val_mDice: 0.5068

Epoch 00011: val_mDice improved from 0.50573 to 0.50680, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 8s - loss: 0.5765 - acc: 0.9048 - mDice: 0.5450 - val_loss: 1.0733 - val_acc: 0.9308 - val_mDice: 0.5095

Epoch 00012: val_mDice improved from 0.50680 to 0.50952, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 8s - loss: 0.5603 - acc: 0.9085 - mDice: 0.5540 - val_loss: 1.0186 - val_acc: 0.9353 - val_mDice: 0.5212

Epoch 00013: val_mDice improved from 0.50952 to 0.52121, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.5475 - acc: 0.9119 - mDice: 0.5615 - val_loss: 1.0232 - val_acc: 0.9242 - val_mDice: 0.5141

Epoch 00014: val_mDice did not improve from 0.52121
Epoch 15/300
 - 7s - loss: 0.5361 - acc: 0.9140 - mDice: 0.5679 - val_loss: 1.1141 - val_acc: 0.9206 - val_mDice: 0.5021

Epoch 00015: val_mDice did not improve from 0.52121
Epoch 16/300
 - 7s - loss: 0.5243 - acc: 0.9159 - mDice: 0.5751 - val_loss: 1.0996 - val_acc: 0.9313 - val_mDice: 0.5154

Epoch 00016: val_mDice did not improve from 0.52121
Epoch 17/300
 - 7s - loss: 0.5157 - acc: 0.9168 - mDice: 0.5802 - val_loss: 0.9382 - val_acc: 0.9319 - val_mDice: 0.5272

Epoch 00017: val_mDice improved from 0.52121 to 0.52724, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 7s - loss: 0.5084 - acc: 0.9180 - mDice: 0.5847 - val_loss: 1.0160 - val_acc: 0.9246 - val_mDice: 0.5224

Epoch 00018: val_mDice did not improve from 0.52724
Epoch 19/300
 - 8s - loss: 0.4998 - acc: 0.9190 - mDice: 0.5899 - val_loss: 0.9744 - val_acc: 0.9377 - val_mDice: 0.5338

Epoch 00019: val_mDice improved from 0.52724 to 0.53384, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 8s - loss: 0.4942 - acc: 0.9198 - mDice: 0.5932 - val_loss: 0.9276 - val_acc: 0.9291 - val_mDice: 0.5242

Epoch 00020: val_mDice did not improve from 0.53384
Epoch 21/300
 - 7s - loss: 0.4874 - acc: 0.9206 - mDice: 0.5975 - val_loss: 0.8845 - val_acc: 0.9327 - val_mDice: 0.5297

Epoch 00021: val_mDice did not improve from 0.53384
Epoch 22/300
 - 7s - loss: 0.4832 - acc: 0.9212 - mDice: 0.6002 - val_loss: 0.8692 - val_acc: 0.9376 - val_mDice: 0.5272

Epoch 00022: val_mDice did not improve from 0.53384
Epoch 23/300
 - 7s - loss: 0.4752 - acc: 0.9220 - mDice: 0.6052 - val_loss: 0.8822 - val_acc: 0.9323 - val_mDice: 0.5297

Epoch 00023: val_mDice did not improve from 0.53384
Epoch 24/300
 - 7s - loss: 0.4709 - acc: 0.9227 - mDice: 0.6077 - val_loss: 0.8803 - val_acc: 0.9298 - val_mDice: 0.5369

Epoch 00024: val_mDice improved from 0.53384 to 0.53693, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 7s - loss: 0.4672 - acc: 0.9232 - mDice: 0.6103 - val_loss: 0.9508 - val_acc: 0.9269 - val_mDice: 0.5168

Epoch 00025: val_mDice did not improve from 0.53693
Epoch 26/300
 - 7s - loss: 0.4623 - acc: 0.9236 - mDice: 0.6133 - val_loss: 0.9835 - val_acc: 0.9199 - val_mDice: 0.5175

Epoch 00026: val_mDice did not improve from 0.53693
Epoch 27/300
 - 8s - loss: 0.4604 - acc: 0.9238 - mDice: 0.6147 - val_loss: 0.9166 - val_acc: 0.9289 - val_mDice: 0.5265

Epoch 00027: val_mDice did not improve from 0.53693
Epoch 28/300
 - 8s - loss: 0.4535 - acc: 0.9246 - mDice: 0.6190 - val_loss: 0.8282 - val_acc: 0.9359 - val_mDice: 0.5401

Epoch 00028: val_mDice improved from 0.53693 to 0.54005, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 7s - loss: 0.4478 - acc: 0.9250 - mDice: 0.6227 - val_loss: 0.9120 - val_acc: 0.9301 - val_mDice: 0.5301

Epoch 00029: val_mDice did not improve from 0.54005
Epoch 30/300
 - 7s - loss: 0.4475 - acc: 0.9253 - mDice: 0.6231 - val_loss: 0.8507 - val_acc: 0.9324 - val_mDice: 0.5339

Epoch 00030: val_mDice did not improve from 0.54005
Epoch 31/300
 - 7s - loss: 0.4450 - acc: 0.9255 - mDice: 0.6246 - val_loss: 0.8222 - val_acc: 0.9389 - val_mDice: 0.5455

Epoch 00031: val_mDice improved from 0.54005 to 0.54546, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 7s - loss: 0.4400 - acc: 0.9261 - mDice: 0.6281 - val_loss: 0.8299 - val_acc: 0.9340 - val_mDice: 0.5353

Epoch 00032: val_mDice did not improve from 0.54546
Epoch 33/300
 - 7s - loss: 0.4363 - acc: 0.9267 - mDice: 0.6303 - val_loss: 0.9099 - val_acc: 0.9296 - val_mDice: 0.5255

Epoch 00033: val_mDice did not improve from 0.54546
Epoch 34/300
 - 7s - loss: 0.4343 - acc: 0.9267 - mDice: 0.6315 - val_loss: 0.8561 - val_acc: 0.9342 - val_mDice: 0.5346

Epoch 00034: val_mDice did not improve from 0.54546
Epoch 35/300
 - 7s - loss: 0.4306 - acc: 0.9272 - mDice: 0.6341 - val_loss: 0.8271 - val_acc: 0.9344 - val_mDice: 0.5362

Epoch 00035: val_mDice did not improve from 0.54546
Epoch 36/300
 - 7s - loss: 0.4289 - acc: 0.9273 - mDice: 0.6353 - val_loss: 0.7853 - val_acc: 0.9364 - val_mDice: 0.5365

Epoch 00036: val_mDice did not improve from 0.54546
Epoch 37/300
 - 8s - loss: 0.4263 - acc: 0.9276 - mDice: 0.6369 - val_loss: 0.8906 - val_acc: 0.9329 - val_mDice: 0.5296

Epoch 00037: val_mDice did not improve from 0.54546
Epoch 38/300
 - 8s - loss: 0.4224 - acc: 0.9281 - mDice: 0.6395 - val_loss: 0.8383 - val_acc: 0.9395 - val_mDice: 0.5392

Epoch 00038: val_mDice did not improve from 0.54546
Epoch 39/300
 - 8s - loss: 0.4237 - acc: 0.9280 - mDice: 0.6386 - val_loss: 0.8037 - val_acc: 0.9377 - val_mDice: 0.5419

Epoch 00039: val_mDice did not improve from 0.54546
Epoch 40/300
 - 7s - loss: 0.4197 - acc: 0.9283 - mDice: 0.6415 - val_loss: 1.0080 - val_acc: 0.9246 - val_mDice: 0.5160

Epoch 00040: val_mDice did not improve from 0.54546
Epoch 41/300
 - 7s - loss: 0.4145 - acc: 0.9290 - mDice: 0.6447 - val_loss: 0.7336 - val_acc: 0.9387 - val_mDice: 0.5387

Epoch 00041: val_mDice did not improve from 0.54546
Epoch 42/300
 - 7s - loss: 0.4148 - acc: 0.9288 - mDice: 0.6447 - val_loss: 0.7960 - val_acc: 0.9342 - val_mDice: 0.5347

Epoch 00042: val_mDice did not improve from 0.54546
Epoch 43/300
 - 7s - loss: 0.4133 - acc: 0.9292 - mDice: 0.6456 - val_loss: 0.8818 - val_acc: 0.9209 - val_mDice: 0.5118

Epoch 00043: val_mDice did not improve from 0.54546
Epoch 44/300
 - 7s - loss: 0.4116 - acc: 0.9295 - mDice: 0.6469 - val_loss: 0.7828 - val_acc: 0.9366 - val_mDice: 0.5315

Epoch 00044: val_mDice did not improve from 0.54546
Epoch 45/300
 - 7s - loss: 0.4089 - acc: 0.9293 - mDice: 0.6487 - val_loss: 0.7655 - val_acc: 0.9366 - val_mDice: 0.5447

Epoch 00045: val_mDice did not improve from 0.54546
Epoch 46/300
 - 7s - loss: 0.4074 - acc: 0.9297 - mDice: 0.6497 - val_loss: 0.8289 - val_acc: 0.9264 - val_mDice: 0.5285

Epoch 00046: val_mDice did not improve from 0.54546
Epoch 47/300
 - 7s - loss: 0.4055 - acc: 0.9298 - mDice: 0.6509 - val_loss: 0.7910 - val_acc: 0.9364 - val_mDice: 0.5267

Epoch 00047: val_mDice did not improve from 0.54546
Epoch 48/300
 - 7s - loss: 0.4057 - acc: 0.9299 - mDice: 0.6508 - val_loss: 0.8016 - val_acc: 0.9424 - val_mDice: 0.5432

Epoch 00048: val_mDice did not improve from 0.54546
Epoch 49/300
 - 7s - loss: 0.4024 - acc: 0.9302 - mDice: 0.6530 - val_loss: 0.7157 - val_acc: 0.9376 - val_mDice: 0.5428

Epoch 00049: val_mDice did not improve from 0.54546
Epoch 50/300
 - 7s - loss: 0.3985 - acc: 0.9304 - mDice: 0.6557 - val_loss: 0.7800 - val_acc: 0.9327 - val_mDice: 0.5303

Epoch 00050: val_mDice did not improve from 0.54546
Epoch 51/300
 - 7s - loss: 0.3993 - acc: 0.9306 - mDice: 0.6553 - val_loss: 0.7688 - val_acc: 0.9383 - val_mDice: 0.5418

Epoch 00051: val_mDice did not improve from 0.54546
Epoch 52/300
 - 8s - loss: 0.3972 - acc: 0.9307 - mDice: 0.6565 - val_loss: 0.7959 - val_acc: 0.9331 - val_mDice: 0.5384

Epoch 00052: val_mDice did not improve from 0.54546
Epoch 53/300
 - 8s - loss: 0.3945 - acc: 0.9309 - mDice: 0.6584 - val_loss: 0.7094 - val_acc: 0.9400 - val_mDice: 0.5442

Epoch 00053: val_mDice did not improve from 0.54546
Epoch 54/300
 - 7s - loss: 0.3952 - acc: 0.9309 - mDice: 0.6580 - val_loss: 0.8310 - val_acc: 0.9311 - val_mDice: 0.5366

Epoch 00054: val_mDice did not improve from 0.54546
Epoch 55/300
 - 7s - loss: 0.3943 - acc: 0.9312 - mDice: 0.6587 - val_loss: 0.6783 - val_acc: 0.9407 - val_mDice: 0.5450

Epoch 00055: val_mDice did not improve from 0.54546
Epoch 56/300
 - 7s - loss: 0.3928 - acc: 0.9313 - mDice: 0.6598 - val_loss: 0.6964 - val_acc: 0.9413 - val_mDice: 0.5518

Epoch 00056: val_mDice improved from 0.54546 to 0.55185, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 57/300
 - 7s - loss: 0.3915 - acc: 0.9315 - mDice: 0.6607 - val_loss: 0.6550 - val_acc: 0.9418 - val_mDice: 0.5494

Epoch 00057: val_mDice did not improve from 0.55185
Epoch 58/300
 - 7s - loss: 0.3888 - acc: 0.9317 - mDice: 0.6624 - val_loss: 0.7558 - val_acc: 0.9405 - val_mDice: 0.5431

Epoch 00058: val_mDice did not improve from 0.55185
Epoch 59/300
 - 7s - loss: 0.3861 - acc: 0.9320 - mDice: 0.6643 - val_loss: 0.7227 - val_acc: 0.9383 - val_mDice: 0.5513

Epoch 00059: val_mDice did not improve from 0.55185
Epoch 60/300
 - 7s - loss: 0.3855 - acc: 0.9321 - mDice: 0.6647 - val_loss: 0.6412 - val_acc: 0.9426 - val_mDice: 0.5501

Epoch 00060: val_mDice did not improve from 0.55185
Epoch 61/300
 - 7s - loss: 0.3858 - acc: 0.9321 - mDice: 0.6646 - val_loss: 0.7914 - val_acc: 0.9244 - val_mDice: 0.5151

Epoch 00061: val_mDice did not improve from 0.55185
Epoch 62/300
 - 7s - loss: 0.3852 - acc: 0.9324 - mDice: 0.6650 - val_loss: 0.7271 - val_acc: 0.9325 - val_mDice: 0.5371

Epoch 00062: val_mDice did not improve from 0.55185
Epoch 63/300
 - 7s - loss: 0.3829 - acc: 0.9326 - mDice: 0.6666 - val_loss: 0.6721 - val_acc: 0.9414 - val_mDice: 0.5601

Epoch 00063: val_mDice improved from 0.55185 to 0.56007, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 64/300
 - 7s - loss: 0.3796 - acc: 0.9328 - mDice: 0.6688 - val_loss: 0.6871 - val_acc: 0.9411 - val_mDice: 0.5420

Epoch 00064: val_mDice did not improve from 0.56007
Epoch 65/300
 - 8s - loss: 0.3800 - acc: 0.9328 - mDice: 0.6685 - val_loss: 0.6972 - val_acc: 0.9428 - val_mDice: 0.5478

Epoch 00065: val_mDice did not improve from 0.56007
Epoch 66/300
 - 8s - loss: 0.3808 - acc: 0.9328 - mDice: 0.6680 - val_loss: 0.6513 - val_acc: 0.9429 - val_mDice: 0.5588

Epoch 00066: val_mDice did not improve from 0.56007
Epoch 67/300
 - 8s - loss: 0.3812 - acc: 0.9330 - mDice: 0.6679 - val_loss: 0.7620 - val_acc: 0.9321 - val_mDice: 0.5310

Epoch 00067: val_mDice did not improve from 0.56007
Epoch 68/300
 - 8s - loss: 0.3773 - acc: 0.9333 - mDice: 0.6704 - val_loss: 0.7629 - val_acc: 0.9373 - val_mDice: 0.5524

Epoch 00068: val_mDice did not improve from 0.56007
Epoch 69/300
 - 7s - loss: 0.3800 - acc: 0.9332 - mDice: 0.6687 - val_loss: 0.7646 - val_acc: 0.9291 - val_mDice: 0.5283

Epoch 00069: val_mDice did not improve from 0.56007
Epoch 70/300
 - 7s - loss: 0.3765 - acc: 0.9333 - mDice: 0.6711 - val_loss: 0.7344 - val_acc: 0.9367 - val_mDice: 0.5275

Epoch 00070: val_mDice did not improve from 0.56007
Epoch 71/300
 - 7s - loss: 0.3740 - acc: 0.9335 - mDice: 0.6727 - val_loss: 0.7330 - val_acc: 0.9387 - val_mDice: 0.5475

Epoch 00071: val_mDice did not improve from 0.56007
Epoch 72/300
 - 7s - loss: 0.3719 - acc: 0.9337 - mDice: 0.6744 - val_loss: 0.7421 - val_acc: 0.9355 - val_mDice: 0.5448

Epoch 00072: val_mDice did not improve from 0.56007
Epoch 73/300
 - 7s - loss: 0.3724 - acc: 0.9336 - mDice: 0.6739 - val_loss: 0.6317 - val_acc: 0.9418 - val_mDice: 0.5616

Epoch 00073: val_mDice improved from 0.56007 to 0.56161, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 7s - loss: 0.3725 - acc: 0.9338 - mDice: 0.6738 - val_loss: 0.7182 - val_acc: 0.9418 - val_mDice: 0.5531

Epoch 00074: val_mDice did not improve from 0.56161
Epoch 75/300
 - 8s - loss: 0.3725 - acc: 0.9338 - mDice: 0.6738 - val_loss: 0.6742 - val_acc: 0.9325 - val_mDice: 0.5379

Epoch 00075: val_mDice did not improve from 0.56161
Epoch 76/300
 - 7s - loss: 0.3717 - acc: 0.9338 - mDice: 0.6743 - val_loss: 0.7161 - val_acc: 0.9418 - val_mDice: 0.5426

Epoch 00076: val_mDice did not improve from 0.56161
Epoch 77/300
 - 7s - loss: 0.3687 - acc: 0.9341 - mDice: 0.6765 - val_loss: 0.7647 - val_acc: 0.9349 - val_mDice: 0.5435

Epoch 00077: val_mDice did not improve from 0.56161
Epoch 78/300
 - 7s - loss: 0.3675 - acc: 0.9342 - mDice: 0.6774 - val_loss: 0.8414 - val_acc: 0.9316 - val_mDice: 0.5325

Epoch 00078: val_mDice did not improve from 0.56161
Epoch 79/300
 - 7s - loss: 0.3686 - acc: 0.9341 - mDice: 0.6765 - val_loss: 0.6083 - val_acc: 0.9436 - val_mDice: 0.5482

Epoch 00079: val_mDice did not improve from 0.56161
Epoch 80/300
 - 8s - loss: 0.3658 - acc: 0.9346 - mDice: 0.6784 - val_loss: 0.7444 - val_acc: 0.9261 - val_mDice: 0.5164

Epoch 00080: val_mDice did not improve from 0.56161
Epoch 81/300
 - 8s - loss: 0.3680 - acc: 0.9342 - mDice: 0.6770 - val_loss: 0.6673 - val_acc: 0.9408 - val_mDice: 0.5546

Epoch 00081: val_mDice did not improve from 0.56161
Epoch 82/300
 - 8s - loss: 0.3657 - acc: 0.9346 - mDice: 0.6786 - val_loss: 0.7144 - val_acc: 0.9365 - val_mDice: 0.5410

Epoch 00082: val_mDice did not improve from 0.56161
Epoch 83/300
 - 7s - loss: 0.3643 - acc: 0.9348 - mDice: 0.6797 - val_loss: 0.7217 - val_acc: 0.9393 - val_mDice: 0.5500

Epoch 00083: val_mDice did not improve from 0.56161
Epoch 84/300
 - 7s - loss: 0.3645 - acc: 0.9347 - mDice: 0.6795 - val_loss: 0.6894 - val_acc: 0.9415 - val_mDice: 0.5600

Epoch 00084: val_mDice did not improve from 0.56161
Epoch 85/300
 - 8s - loss: 0.3629 - acc: 0.9349 - mDice: 0.6807 - val_loss: 0.7034 - val_acc: 0.9426 - val_mDice: 0.5594

Epoch 00085: val_mDice did not improve from 0.56161
Epoch 86/300
 - 8s - loss: 0.3597 - acc: 0.9351 - mDice: 0.6829 - val_loss: 0.6999 - val_acc: 0.9353 - val_mDice: 0.5368

Epoch 00086: val_mDice did not improve from 0.56161
Epoch 87/300
 - 7s - loss: 0.3613 - acc: 0.9350 - mDice: 0.6817 - val_loss: 0.6862 - val_acc: 0.9406 - val_mDice: 0.5518

Epoch 00087: val_mDice did not improve from 0.56161
Epoch 88/300
 - 8s - loss: 0.3622 - acc: 0.9349 - mDice: 0.6811 - val_loss: 0.6982 - val_acc: 0.9380 - val_mDice: 0.5394

Epoch 00088: val_mDice did not improve from 0.56161
Epoch 89/300
 - 7s - loss: 0.3606 - acc: 0.9352 - mDice: 0.6822 - val_loss: 0.6797 - val_acc: 0.9351 - val_mDice: 0.5495

Epoch 00089: val_mDice did not improve from 0.56161
Epoch 90/300
 - 7s - loss: 0.3585 - acc: 0.9354 - mDice: 0.6837 - val_loss: 0.6623 - val_acc: 0.9404 - val_mDice: 0.5351

Epoch 00090: val_mDice did not improve from 0.56161
Epoch 91/300
 - 8s - loss: 0.3582 - acc: 0.9355 - mDice: 0.6840 - val_loss: 0.6792 - val_acc: 0.9363 - val_mDice: 0.5447

Epoch 00091: val_mDice did not improve from 0.56161
Epoch 92/300
 - 8s - loss: 0.3591 - acc: 0.9353 - mDice: 0.6833 - val_loss: 0.6421 - val_acc: 0.9334 - val_mDice: 0.5378

Epoch 00092: val_mDice did not improve from 0.56161
Epoch 93/300
 - 7s - loss: 0.3593 - acc: 0.9354 - mDice: 0.6832 - val_loss: 0.6459 - val_acc: 0.9414 - val_mDice: 0.5431

Epoch 00093: val_mDice did not improve from 0.56161
Epoch 94/300
 - 8s - loss: 0.3578 - acc: 0.9355 - mDice: 0.6843 - val_loss: 0.6813 - val_acc: 0.9439 - val_mDice: 0.5520

Epoch 00094: val_mDice did not improve from 0.56161
Epoch 95/300
 - 8s - loss: 0.3576 - acc: 0.9354 - mDice: 0.6844 - val_loss: 0.6937 - val_acc: 0.9394 - val_mDice: 0.5400

Epoch 00095: val_mDice did not improve from 0.56161
Epoch 96/300
 - 8s - loss: 0.3567 - acc: 0.9356 - mDice: 0.6850 - val_loss: 0.6700 - val_acc: 0.9397 - val_mDice: 0.5450

Epoch 00096: val_mDice did not improve from 0.56161
Epoch 97/300
 - 8s - loss: 0.3552 - acc: 0.9355 - mDice: 0.6860 - val_loss: 0.5566 - val_acc: 0.9431 - val_mDice: 0.5495

Epoch 00097: val_mDice did not improve from 0.56161
Epoch 98/300
 - 8s - loss: 0.3545 - acc: 0.9360 - mDice: 0.6866 - val_loss: 0.7153 - val_acc: 0.9299 - val_mDice: 0.5329

Epoch 00098: val_mDice did not improve from 0.56161
Epoch 99/300
 - 8s - loss: 0.3541 - acc: 0.9359 - mDice: 0.6870 - val_loss: 0.7038 - val_acc: 0.9366 - val_mDice: 0.5291

Epoch 00099: val_mDice did not improve from 0.56161
Epoch 100/300
 - 8s - loss: 0.3535 - acc: 0.9359 - mDice: 0.6874 - val_loss: 0.5948 - val_acc: 0.9446 - val_mDice: 0.5597

Epoch 00100: val_mDice did not improve from 0.56161
Epoch 101/300
 - 8s - loss: 0.3523 - acc: 0.9361 - mDice: 0.6882 - val_loss: 0.5992 - val_acc: 0.9436 - val_mDice: 0.5618

Epoch 00101: val_mDice improved from 0.56161 to 0.56182, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 102/300
 - 8s - loss: 0.3513 - acc: 0.9362 - mDice: 0.6889 - val_loss: 0.6794 - val_acc: 0.9401 - val_mDice: 0.5490

Epoch 00102: val_mDice did not improve from 0.56182
Epoch 103/300
 - 8s - loss: 0.3525 - acc: 0.9361 - mDice: 0.6881 - val_loss: 0.6274 - val_acc: 0.9397 - val_mDice: 0.5476

Epoch 00103: val_mDice did not improve from 0.56182
Epoch 104/300
 - 8s - loss: 0.3516 - acc: 0.9362 - mDice: 0.6887 - val_loss: 0.6590 - val_acc: 0.9380 - val_mDice: 0.5408

Epoch 00104: val_mDice did not improve from 0.56182
Epoch 105/300
 - 8s - loss: 0.3504 - acc: 0.9362 - mDice: 0.6895 - val_loss: 0.6793 - val_acc: 0.9424 - val_mDice: 0.5492

Epoch 00105: val_mDice did not improve from 0.56182
Epoch 106/300
 - 8s - loss: 0.3498 - acc: 0.9363 - mDice: 0.6900 - val_loss: 0.6000 - val_acc: 0.9427 - val_mDice: 0.5539

Epoch 00106: val_mDice did not improve from 0.56182
Epoch 107/300
 - 8s - loss: 0.3505 - acc: 0.9363 - mDice: 0.6896 - val_loss: 0.6194 - val_acc: 0.9423 - val_mDice: 0.5438

Epoch 00107: val_mDice did not improve from 0.56182
Epoch 108/300
 - 8s - loss: 0.3476 - acc: 0.9366 - mDice: 0.6916 - val_loss: 0.6410 - val_acc: 0.9399 - val_mDice: 0.5364

Epoch 00108: val_mDice did not improve from 0.56182
Epoch 109/300
 - 8s - loss: 0.3485 - acc: 0.9365 - mDice: 0.6909 - val_loss: 0.6834 - val_acc: 0.9388 - val_mDice: 0.5395

Epoch 00109: val_mDice did not improve from 0.56182
Epoch 110/300
 - 8s - loss: 0.3481 - acc: 0.9364 - mDice: 0.6913 - val_loss: 0.7585 - val_acc: 0.9314 - val_mDice: 0.5296

Epoch 00110: val_mDice did not improve from 0.56182
Epoch 111/300
 - 8s - loss: 0.3470 - acc: 0.9365 - mDice: 0.6919 - val_loss: 0.6811 - val_acc: 0.9429 - val_mDice: 0.5464

Epoch 00111: val_mDice did not improve from 0.56182
Epoch 112/300
 - 8s - loss: 0.3468 - acc: 0.9367 - mDice: 0.6921 - val_loss: 0.6828 - val_acc: 0.9277 - val_mDice: 0.5303

Epoch 00112: val_mDice did not improve from 0.56182
Epoch 113/300
 - 8s - loss: 0.3475 - acc: 0.9367 - mDice: 0.6916 - val_loss: 0.7159 - val_acc: 0.9343 - val_mDice: 0.5341

Epoch 00113: val_mDice did not improve from 0.56182
Epoch 114/300
 - 8s - loss: 0.3456 - acc: 0.9366 - mDice: 0.6930 - val_loss: 0.6282 - val_acc: 0.9403 - val_mDice: 0.5573

Epoch 00114: val_mDice did not improve from 0.56182
Epoch 115/300
 - 8s - loss: 0.3457 - acc: 0.9369 - mDice: 0.6930 - val_loss: 0.6908 - val_acc: 0.9429 - val_mDice: 0.5622

Epoch 00115: val_mDice improved from 0.56182 to 0.56216, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 116/300
 - 8s - loss: 0.3452 - acc: 0.9367 - mDice: 0.6933 - val_loss: 0.7450 - val_acc: 0.9402 - val_mDice: 0.5364

Epoch 00116: val_mDice did not improve from 0.56216
Epoch 117/300
 - 8s - loss: 0.3443 - acc: 0.9370 - mDice: 0.6940 - val_loss: 0.6071 - val_acc: 0.9416 - val_mDice: 0.5543

Epoch 00117: val_mDice did not improve from 0.56216
Epoch 118/300
 - 8s - loss: 0.3429 - acc: 0.9369 - mDice: 0.6950 - val_loss: 0.7304 - val_acc: 0.9353 - val_mDice: 0.5305

Epoch 00118: val_mDice did not improve from 0.56216
Epoch 119/300
 - 8s - loss: 0.3419 - acc: 0.9371 - mDice: 0.6957 - val_loss: 0.7012 - val_acc: 0.9355 - val_mDice: 0.5379

Epoch 00119: val_mDice did not improve from 0.56216
Epoch 120/300
 - 8s - loss: 0.3414 - acc: 0.9372 - mDice: 0.6960 - val_loss: 0.6823 - val_acc: 0.9441 - val_mDice: 0.5471

Epoch 00120: val_mDice did not improve from 0.56216
Epoch 121/300
 - 8s - loss: 0.3432 - acc: 0.9370 - mDice: 0.6948 - val_loss: 0.6142 - val_acc: 0.9432 - val_mDice: 0.5497

Epoch 00121: val_mDice did not improve from 0.56216
Epoch 122/300
 - 8s - loss: 0.3425 - acc: 0.9370 - mDice: 0.6953 - val_loss: 0.7016 - val_acc: 0.9353 - val_mDice: 0.5352

Epoch 00122: val_mDice did not improve from 0.56216
Epoch 123/300
 - 8s - loss: 0.3434 - acc: 0.9371 - mDice: 0.6947 - val_loss: 0.6127 - val_acc: 0.9423 - val_mDice: 0.5402

Epoch 00123: val_mDice did not improve from 0.56216
Epoch 124/300
 - 8s - loss: 0.3423 - acc: 0.9372 - mDice: 0.6954 - val_loss: 0.7588 - val_acc: 0.9347 - val_mDice: 0.5462

Epoch 00124: val_mDice did not improve from 0.56216
Epoch 125/300
 - 8s - loss: 0.3401 - acc: 0.9374 - mDice: 0.6970 - val_loss: 0.6753 - val_acc: 0.9417 - val_mDice: 0.5507

Epoch 00125: val_mDice did not improve from 0.56216
Epoch 126/300
 - 8s - loss: 0.3409 - acc: 0.9373 - mDice: 0.6964 - val_loss: 0.7631 - val_acc: 0.9314 - val_mDice: 0.5331

Epoch 00126: val_mDice did not improve from 0.56216
Epoch 127/300
 - 8s - loss: 0.3388 - acc: 0.9376 - mDice: 0.6980 - val_loss: 0.6046 - val_acc: 0.9401 - val_mDice: 0.5514

Epoch 00127: val_mDice did not improve from 0.56216
Epoch 128/300
 - 7s - loss: 0.3398 - acc: 0.9375 - mDice: 0.6973 - val_loss: 0.6720 - val_acc: 0.9428 - val_mDice: 0.5416

Epoch 00128: val_mDice did not improve from 0.56216
Epoch 129/300
 - 8s - loss: 0.3394 - acc: 0.9374 - mDice: 0.6975 - val_loss: 0.6849 - val_acc: 0.9386 - val_mDice: 0.5345

Epoch 00129: val_mDice did not improve from 0.56216
Epoch 130/300
 - 8s - loss: 0.3391 - acc: 0.9376 - mDice: 0.6977 - val_loss: 0.6023 - val_acc: 0.9429 - val_mDice: 0.5570

Epoch 00130: val_mDice did not improve from 0.56216
Epoch 131/300
 - 7s - loss: 0.3386 - acc: 0.9374 - mDice: 0.6981 - val_loss: 0.6996 - val_acc: 0.9369 - val_mDice: 0.5382

Epoch 00131: val_mDice did not improve from 0.56216
Epoch 132/300
 - 8s - loss: 0.3376 - acc: 0.9376 - mDice: 0.6989 - val_loss: 0.6086 - val_acc: 0.9433 - val_mDice: 0.5500

Epoch 00132: val_mDice did not improve from 0.56216
Epoch 133/300
 - 8s - loss: 0.3366 - acc: 0.9378 - mDice: 0.6995 - val_loss: 0.6267 - val_acc: 0.9423 - val_mDice: 0.5410

Epoch 00133: val_mDice did not improve from 0.56216
Epoch 134/300
 - 8s - loss: 0.3373 - acc: 0.9375 - mDice: 0.6990 - val_loss: 0.7078 - val_acc: 0.9339 - val_mDice: 0.5411

Epoch 00134: val_mDice did not improve from 0.56216
Epoch 135/300
 - 7s - loss: 0.3370 - acc: 0.9378 - mDice: 0.6993 - val_loss: 0.5734 - val_acc: 0.9417 - val_mDice: 0.5390

Epoch 00135: val_mDice did not improve from 0.56216
Epoch 136/300
 - 7s - loss: 0.3365 - acc: 0.9378 - mDice: 0.6996 - val_loss: 0.5638 - val_acc: 0.9417 - val_mDice: 0.5424

Epoch 00136: val_mDice did not improve from 0.56216
Epoch 137/300
 - 7s - loss: 0.3353 - acc: 0.9380 - mDice: 0.7005 - val_loss: 0.6231 - val_acc: 0.9375 - val_mDice: 0.5472

Epoch 00137: val_mDice did not improve from 0.56216
Epoch 138/300
 - 7s - loss: 0.3351 - acc: 0.9380 - mDice: 0.7007 - val_loss: 0.6207 - val_acc: 0.9429 - val_mDice: 0.5461

Epoch 00138: val_mDice did not improve from 0.56216
Epoch 139/300
 - 7s - loss: 0.3338 - acc: 0.9380 - mDice: 0.7016 - val_loss: 0.6899 - val_acc: 0.9382 - val_mDice: 0.5458

Epoch 00139: val_mDice did not improve from 0.56216
Epoch 140/300
 - 7s - loss: 0.3346 - acc: 0.9379 - mDice: 0.7010 - val_loss: 0.6788 - val_acc: 0.9421 - val_mDice: 0.5504

Epoch 00140: val_mDice did not improve from 0.56216
Epoch 141/300
 - 7s - loss: 0.3342 - acc: 0.9381 - mDice: 0.7014 - val_loss: 0.7135 - val_acc: 0.9416 - val_mDice: 0.5459

Epoch 00141: val_mDice did not improve from 0.56216
Epoch 142/300
 - 8s - loss: 0.3349 - acc: 0.9380 - mDice: 0.7009 - val_loss: 0.6197 - val_acc: 0.9420 - val_mDice: 0.5477

Epoch 00142: val_mDice did not improve from 0.56216
Epoch 143/300
 - 8s - loss: 0.3357 - acc: 0.9380 - mDice: 0.7002 - val_loss: 0.6120 - val_acc: 0.9443 - val_mDice: 0.5454

Epoch 00143: val_mDice did not improve from 0.56216
Epoch 144/300
 - 7s - loss: 0.3324 - acc: 0.9384 - mDice: 0.7027 - val_loss: 0.6627 - val_acc: 0.9414 - val_mDice: 0.5574

Epoch 00144: val_mDice did not improve from 0.56216
Epoch 145/300
 - 7s - loss: 0.3338 - acc: 0.9382 - mDice: 0.7017 - val_loss: 0.7162 - val_acc: 0.9373 - val_mDice: 0.5370

Epoch 00145: val_mDice did not improve from 0.56216
Epoch 146/300
 - 7s - loss: 0.3323 - acc: 0.9383 - mDice: 0.7027 - val_loss: 0.5828 - val_acc: 0.9449 - val_mDice: 0.5490

Epoch 00146: val_mDice did not improve from 0.56216
Epoch 147/300
 - 7s - loss: 0.3334 - acc: 0.9381 - mDice: 0.7019 - val_loss: 0.6444 - val_acc: 0.9428 - val_mDice: 0.5515

Epoch 00147: val_mDice did not improve from 0.56216
Epoch 148/300
 - 7s - loss: 0.3320 - acc: 0.9384 - mDice: 0.7030 - val_loss: 0.6200 - val_acc: 0.9431 - val_mDice: 0.5275

Epoch 00148: val_mDice did not improve from 0.56216
Epoch 149/300
 - 7s - loss: 0.3354 - acc: 0.9380 - mDice: 0.7006 - val_loss: 0.6517 - val_acc: 0.9418 - val_mDice: 0.5550

Epoch 00149: val_mDice did not improve from 0.56216
Epoch 150/300
 - 7s - loss: 0.3309 - acc: 0.9384 - mDice: 0.7038 - val_loss: 0.7366 - val_acc: 0.9291 - val_mDice: 0.5239

Epoch 00150: val_mDice did not improve from 0.56216
Epoch 151/300
 - 7s - loss: 0.3320 - acc: 0.9383 - mDice: 0.7030 - val_loss: 0.7205 - val_acc: 0.9403 - val_mDice: 0.5463

Epoch 00151: val_mDice did not improve from 0.56216
Epoch 152/300
 - 7s - loss: 0.3302 - acc: 0.9384 - mDice: 0.7042 - val_loss: 0.5559 - val_acc: 0.9437 - val_mDice: 0.5463

Epoch 00152: val_mDice did not improve from 0.56216
Epoch 153/300
 - 8s - loss: 0.3288 - acc: 0.9386 - mDice: 0.7053 - val_loss: 0.7332 - val_acc: 0.9363 - val_mDice: 0.5538

Epoch 00153: val_mDice did not improve from 0.56216
Epoch 154/300
 - 8s - loss: 0.3304 - acc: 0.9382 - mDice: 0.7040 - val_loss: 0.6982 - val_acc: 0.9431 - val_mDice: 0.5634

Epoch 00154: val_mDice improved from 0.56216 to 0.56342, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 155/300
 - 8s - loss: 0.3305 - acc: 0.9385 - mDice: 0.7040 - val_loss: 0.7230 - val_acc: 0.9361 - val_mDice: 0.5336

Epoch 00155: val_mDice did not improve from 0.56342
Epoch 156/300
 - 8s - loss: 0.3312 - acc: 0.9383 - mDice: 0.7036 - val_loss: 0.6076 - val_acc: 0.9403 - val_mDice: 0.5541

Epoch 00156: val_mDice did not improve from 0.56342
Epoch 157/300
 - 8s - loss: 0.3301 - acc: 0.9385 - mDice: 0.7043 - val_loss: 0.6791 - val_acc: 0.9404 - val_mDice: 0.5248

Epoch 00157: val_mDice did not improve from 0.56342
Epoch 158/300
 - 8s - loss: 0.3281 - acc: 0.9387 - mDice: 0.7059 - val_loss: 0.5589 - val_acc: 0.9435 - val_mDice: 0.5459

Epoch 00158: val_mDice did not improve from 0.56342
Epoch 159/300
 - 8s - loss: 0.3293 - acc: 0.9384 - mDice: 0.7049 - val_loss: 0.7012 - val_acc: 0.9394 - val_mDice: 0.5403

Epoch 00159: val_mDice did not improve from 0.56342
Epoch 160/300
 - 8s - loss: 0.3298 - acc: 0.9384 - mDice: 0.7046 - val_loss: 0.6778 - val_acc: 0.9379 - val_mDice: 0.5424

Epoch 00160: val_mDice did not improve from 0.56342
Epoch 161/300
 - 8s - loss: 0.3279 - acc: 0.9385 - mDice: 0.7060 - val_loss: 0.5937 - val_acc: 0.9440 - val_mDice: 0.5473

Epoch 00161: val_mDice did not improve from 0.56342
Epoch 162/300
 - 8s - loss: 0.3278 - acc: 0.9388 - mDice: 0.7061 - val_loss: 0.7398 - val_acc: 0.9357 - val_mDice: 0.5201

Epoch 00162: val_mDice did not improve from 0.56342
Epoch 163/300
 - 7s - loss: 0.3275 - acc: 0.9386 - mDice: 0.7063 - val_loss: 0.6645 - val_acc: 0.9448 - val_mDice: 0.5433

Epoch 00163: val_mDice did not improve from 0.56342
Epoch 164/300
 - 7s - loss: 0.3275 - acc: 0.9388 - mDice: 0.7063 - val_loss: 0.6106 - val_acc: 0.9417 - val_mDice: 0.5533

Epoch 00164: val_mDice did not improve from 0.56342
Epoch 165/300
 - 8s - loss: 0.3269 - acc: 0.9388 - mDice: 0.7068 - val_loss: 0.7271 - val_acc: 0.9390 - val_mDice: 0.5443

Epoch 00165: val_mDice did not improve from 0.56342
Epoch 166/300
 - 8s - loss: 0.3275 - acc: 0.9388 - mDice: 0.7063 - val_loss: 0.7158 - val_acc: 0.9369 - val_mDice: 0.5371

Epoch 00166: val_mDice did not improve from 0.56342
Epoch 167/300
 - 7s - loss: 0.3273 - acc: 0.9389 - mDice: 0.7065 - val_loss: 0.5581 - val_acc: 0.9436 - val_mDice: 0.5451

Epoch 00167: val_mDice did not improve from 0.56342
Epoch 168/300
 - 8s - loss: 0.3253 - acc: 0.9391 - mDice: 0.7080 - val_loss: 0.5269 - val_acc: 0.9432 - val_mDice: 0.5660

Epoch 00168: val_mDice improved from 0.56342 to 0.56600, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 169/300
 - 7s - loss: 0.3263 - acc: 0.9388 - mDice: 0.7072 - val_loss: 0.6069 - val_acc: 0.9429 - val_mDice: 0.5548

Epoch 00169: val_mDice did not improve from 0.56600
Epoch 170/300
 - 8s - loss: 0.3241 - acc: 0.9391 - mDice: 0.7087 - val_loss: 0.6222 - val_acc: 0.9409 - val_mDice: 0.5456

Epoch 00170: val_mDice did not improve from 0.56600
Epoch 171/300
 - 7s - loss: 0.3242 - acc: 0.9389 - mDice: 0.7087 - val_loss: 0.6109 - val_acc: 0.9435 - val_mDice: 0.5496

Epoch 00171: val_mDice did not improve from 0.56600
Epoch 172/300
 - 8s - loss: 0.3239 - acc: 0.9391 - mDice: 0.7089 - val_loss: 0.5567 - val_acc: 0.9419 - val_mDice: 0.5446

Epoch 00172: val_mDice did not improve from 0.56600
Epoch 173/300
 - 8s - loss: 0.3249 - acc: 0.9390 - mDice: 0.7082 - val_loss: 0.6561 - val_acc: 0.9438 - val_mDice: 0.5441

Epoch 00173: val_mDice did not improve from 0.56600
Epoch 174/300
 - 8s - loss: 0.3244 - acc: 0.9389 - mDice: 0.7086 - val_loss: 0.6435 - val_acc: 0.9349 - val_mDice: 0.5454

Epoch 00174: val_mDice did not improve from 0.56600
Epoch 175/300
 - 8s - loss: 0.3238 - acc: 0.9393 - mDice: 0.7091 - val_loss: 0.6753 - val_acc: 0.9374 - val_mDice: 0.5371

Epoch 00175: val_mDice did not improve from 0.56600
Epoch 176/300
 - 8s - loss: 0.3222 - acc: 0.9393 - mDice: 0.7101 - val_loss: 0.6738 - val_acc: 0.9434 - val_mDice: 0.5533

Epoch 00176: val_mDice did not improve from 0.56600
Epoch 177/300
 - 8s - loss: 0.3240 - acc: 0.9391 - mDice: 0.7089 - val_loss: 0.6238 - val_acc: 0.9427 - val_mDice: 0.5488

Epoch 00177: val_mDice did not improve from 0.56600
Epoch 178/300
 - 8s - loss: 0.3229 - acc: 0.9392 - mDice: 0.7097 - val_loss: 0.7007 - val_acc: 0.9407 - val_mDice: 0.5431

Epoch 00178: val_mDice did not improve from 0.56600
Epoch 179/300
 - 7s - loss: 0.3233 - acc: 0.9392 - mDice: 0.7094 - val_loss: 0.6239 - val_acc: 0.9447 - val_mDice: 0.5434

Epoch 00179: val_mDice did not improve from 0.56600
Epoch 180/300
 - 7s - loss: 0.3232 - acc: 0.9392 - mDice: 0.7094 - val_loss: 0.7194 - val_acc: 0.9383 - val_mDice: 0.5386

Epoch 00180: val_mDice did not improve from 0.56600
Epoch 181/300
 - 8s - loss: 0.3225 - acc: 0.9395 - mDice: 0.7100 - val_loss: 0.6565 - val_acc: 0.9413 - val_mDice: 0.5423

Epoch 00181: val_mDice did not improve from 0.56600
Epoch 182/300
 - 7s - loss: 0.3241 - acc: 0.9391 - mDice: 0.7088 - val_loss: 0.7968 - val_acc: 0.9330 - val_mDice: 0.5372

Epoch 00182: val_mDice did not improve from 0.56600
Epoch 183/300
 - 7s - loss: 0.3241 - acc: 0.9393 - mDice: 0.7088 - val_loss: 0.6967 - val_acc: 0.9414 - val_mDice: 0.5407

Epoch 00183: val_mDice did not improve from 0.56600
Epoch 184/300
 - 7s - loss: 0.3225 - acc: 0.9393 - mDice: 0.7100 - val_loss: 0.7057 - val_acc: 0.9369 - val_mDice: 0.5356

Epoch 00184: val_mDice did not improve from 0.56600
Epoch 185/300
 - 7s - loss: 0.3247 - acc: 0.9391 - mDice: 0.7084 - val_loss: 0.5463 - val_acc: 0.9465 - val_mDice: 0.5524

Epoch 00185: val_mDice did not improve from 0.56600
Epoch 186/300
 - 7s - loss: 0.3221 - acc: 0.9394 - mDice: 0.7103 - val_loss: 0.6583 - val_acc: 0.9440 - val_mDice: 0.5625

Epoch 00186: val_mDice did not improve from 0.56600
Epoch 187/300
 - 7s - loss: 0.3213 - acc: 0.9393 - mDice: 0.7109 - val_loss: 0.6576 - val_acc: 0.9422 - val_mDice: 0.5480

Epoch 00187: val_mDice did not improve from 0.56600
Epoch 188/300
 - 7s - loss: 0.3216 - acc: 0.9394 - mDice: 0.7107 - val_loss: 0.6660 - val_acc: 0.9432 - val_mDice: 0.5551

Epoch 00188: val_mDice did not improve from 0.56600
Epoch 189/300
 - 8s - loss: 0.3209 - acc: 0.9395 - mDice: 0.7113 - val_loss: 0.6206 - val_acc: 0.9424 - val_mDice: 0.5552

Epoch 00189: val_mDice did not improve from 0.56600
Epoch 190/300
 - 8s - loss: 0.3198 - acc: 0.9394 - mDice: 0.7120 - val_loss: 0.5518 - val_acc: 0.9451 - val_mDice: 0.5647

Epoch 00190: val_mDice did not improve from 0.56600
Epoch 191/300
 - 7s - loss: 0.3196 - acc: 0.9395 - mDice: 0.7123 - val_loss: 0.5555 - val_acc: 0.9442 - val_mDice: 0.5466

Epoch 00191: val_mDice did not improve from 0.56600
Epoch 192/300
 - 7s - loss: 0.3190 - acc: 0.9395 - mDice: 0.7126 - val_loss: 0.7544 - val_acc: 0.9400 - val_mDice: 0.5366

Epoch 00192: val_mDice did not improve from 0.56600
Epoch 193/300
 - 7s - loss: 0.3208 - acc: 0.9395 - mDice: 0.7113 - val_loss: 0.7325 - val_acc: 0.9351 - val_mDice: 0.5400

Epoch 00193: val_mDice did not improve from 0.56600
Epoch 194/300
 - 8s - loss: 0.3194 - acc: 0.9395 - mDice: 0.7123 - val_loss: 0.6135 - val_acc: 0.9432 - val_mDice: 0.5529

Epoch 00194: val_mDice did not improve from 0.56600
Epoch 195/300
 - 8s - loss: 0.3189 - acc: 0.9396 - mDice: 0.7127 - val_loss: 0.6866 - val_acc: 0.9410 - val_mDice: 0.5463

Epoch 00195: val_mDice did not improve from 0.56600
Epoch 196/300
 - 7s - loss: 0.3206 - acc: 0.9396 - mDice: 0.7114 - val_loss: 0.6347 - val_acc: 0.9429 - val_mDice: 0.5504

Epoch 00196: val_mDice did not improve from 0.56600
Epoch 197/300
 - 7s - loss: 0.3185 - acc: 0.9397 - mDice: 0.7130 - val_loss: 0.6373 - val_acc: 0.9456 - val_mDice: 0.5413

Epoch 00197: val_mDice did not improve from 0.56600
Epoch 198/300
 - 7s - loss: 0.3176 - acc: 0.9397 - mDice: 0.7136 - val_loss: 0.7865 - val_acc: 0.9392 - val_mDice: 0.5339

Epoch 00198: val_mDice did not improve from 0.56600
Epoch 199/300
 - 7s - loss: 0.3181 - acc: 0.9397 - mDice: 0.7133 - val_loss: 0.7154 - val_acc: 0.9389 - val_mDice: 0.5399

Epoch 00199: val_mDice did not improve from 0.56600
Epoch 200/300
 - 7s - loss: 0.3201 - acc: 0.9395 - mDice: 0.7118 - val_loss: 0.8087 - val_acc: 0.9347 - val_mDice: 0.5427

Epoch 00200: val_mDice did not improve from 0.56600
Epoch 201/300
 - 7s - loss: 0.3175 - acc: 0.9397 - mDice: 0.7138 - val_loss: 0.6088 - val_acc: 0.9346 - val_mDice: 0.5191

Epoch 00201: val_mDice did not improve from 0.56600
Epoch 202/300
 - 7s - loss: 0.3210 - acc: 0.9395 - mDice: 0.7111 - val_loss: 0.6871 - val_acc: 0.9409 - val_mDice: 0.5496

Epoch 00202: val_mDice did not improve from 0.56600
Epoch 203/300
 - 8s - loss: 0.3172 - acc: 0.9398 - mDice: 0.7140 - val_loss: 0.6306 - val_acc: 0.9444 - val_mDice: 0.5478

Epoch 00203: val_mDice did not improve from 0.56600
Epoch 204/300
 - 8s - loss: 0.3180 - acc: 0.9398 - mDice: 0.7133 - val_loss: 0.7219 - val_acc: 0.9406 - val_mDice: 0.5370

Epoch 00204: val_mDice did not improve from 0.56600
Epoch 205/300
 - 7s - loss: 0.3174 - acc: 0.9399 - mDice: 0.7138 - val_loss: 0.7151 - val_acc: 0.9424 - val_mDice: 0.5300

Epoch 00205: val_mDice did not improve from 0.56600
Epoch 206/300
 - 8s - loss: 0.3179 - acc: 0.9399 - mDice: 0.7135 - val_loss: 0.7062 - val_acc: 0.9388 - val_mDice: 0.5392

Epoch 00206: val_mDice did not improve from 0.56600
Epoch 207/300
 - 8s - loss: 0.3164 - acc: 0.9398 - mDice: 0.7146 - val_loss: 0.7335 - val_acc: 0.9398 - val_mDice: 0.5461

Epoch 00207: val_mDice did not improve from 0.56600
Epoch 208/300
 - 7s - loss: 0.3163 - acc: 0.9399 - mDice: 0.7147 - val_loss: 0.8020 - val_acc: 0.9311 - val_mDice: 0.5162

Epoch 00208: val_mDice did not improve from 0.56600
Restoring model weights from the end of the best epoch
Epoch 00208: early stopping
{'val_loss': [2.6048548108055476, 1.8659262430100214, 1.6828596478416806, 1.3210195359729586, 1.2385691347576322, 1.1499351092747279, 1.1104981331598192, 1.1743240924108596, 1.1235991546085902, 1.093101251692999, 1.0937074025472004, 1.0732686065492176, 1.018588701883952, 1.023195016951788, 1.1140704041435605, 1.0996312413896834, 0.9382157779875255, 1.0160243397667295, 0.9744029499235607, 0.9276158128465924, 0.8845284552801222, 0.8691661244346982, 0.8822452908470517, 0.8803028606233143, 0.9508457865033831, 0.983535403297061, 0.9166324933369955, 0.8282300290607271, 0.9119688896905809, 0.8507206099373954, 0.8221921239580426, 0.8299001512073335, 0.9098826817103794, 0.8561257407778785, 0.8271225407010033, 0.7852577936081659, 0.8906270776476178, 0.8382919175284249, 0.8036866869245257, 1.0080438568478538, 0.7336022172655378, 0.7959893544514974, 0.8818483579726446, 0.7828118687584287, 0.7655304613567534, 0.8288898127419608, 0.7910052481151763, 0.8015570072900682, 0.7156545548211961, 0.7800008569444928, 0.7688495772225517, 0.7958966323307582, 0.7093957605816069, 0.8309765543256488, 0.6782739162445068, 0.6963929108210972, 0.6550109499976748, 0.7557635307312012, 0.7226725532895043, 0.6412316731044224, 0.7913632619948614, 0.7271200248173305, 0.672132514771961, 0.6871237527756464, 0.6972048169090634, 0.6512757596515474, 0.7619855744498116, 0.7629494439987909, 0.7646258899143764, 0.7343808696383521, 0.7329515048435756, 0.742085820152646, 0.6316633565085275, 0.7181506270454043, 0.6742374897003174, 0.7160790988377163, 0.7647275470551991, 0.8413846379234677, 0.608346700668335, 0.7443846975054059, 0.6672982147761753, 0.7144173213413784, 0.7216832183656239, 0.689352308000837, 0.7034230345771426, 0.6998807589213053, 0.6862468265351795, 0.6982140086946034, 0.6797289280664354, 0.6622602485475086, 0.6791802815028599, 0.642118113381522, 0.6458845138549805, 0.6813204174950009, 0.6937094643002465, 0.6700105894179571, 0.5566045613515944, 0.7152515252431234, 0.7038284142812093, 0.5948178768157959, 0.5992453665960402, 0.6794399306887672, 0.6273793492998395, 0.6589995679401216, 0.6793179852621896, 0.60004532904852, 0.6193874449956984, 0.6409861133212135, 0.6833603949773879, 0.7584935597011021, 0.68113264583406, 0.6828478972117106, 0.7158537932804653, 0.6281873044513521, 0.6907665615990048, 0.7449977170853388, 0.607144071942284, 0.7303672177450997, 0.7012221586136591, 0.6823096502394903, 0.6142194384620303, 0.7016213280814034, 0.6127075524557204, 0.7588426839737665, 0.6753247011275518, 0.7631097748166039, 0.604584398723784, 0.6719768842061361, 0.6848666327340263, 0.6022572857992989, 0.6995635032653809, 0.6086099488394601, 0.626653580438523, 0.7077844029381162, 0.5734324625560215, 0.563751532917931, 0.6231231462387812, 0.620737632115682, 0.6898614224933443, 0.6788070428939093, 0.713507958820888, 0.619719459896996, 0.6120398952847436, 0.6627043315342495, 0.7161677451360793, 0.5828404142743066, 0.6443867002214704, 0.6200390486490159, 0.6516680376870292, 0.7366240138099307, 0.7204740047454834, 0.5558826894987197, 0.7331956454685756, 0.6981961954207647, 0.7229545911153158, 0.6076129164014544, 0.6791411581493559, 0.5589035295304798, 0.701165619350615, 0.6778243496304467, 0.5936977806545439, 0.7398134413219634, 0.6644684019542876, 0.6105767431713286, 0.7270511559077671, 0.7158015682583764, 0.5580531387102037, 0.5268559285572597, 0.6069480578104655, 0.6222108545757475, 0.6109087126595634, 0.5567302647091094, 0.656141996383667, 0.6435305391039167, 0.6753030050368536, 0.67376785051255, 0.6238303411574591, 0.7006974447341192, 0.6238551821027484, 0.7194035847981771, 0.6565493061428979, 0.7968076183682397, 0.696706147420974, 0.7056549617222377, 0.5463450834864662, 0.6582590057736352, 0.6575967357272193, 0.665992021560669, 0.6206373941330683, 0.5518079087847755, 0.5555321999958583, 0.7543567589351109, 0.7324512345450265, 0.6134836673736572, 0.6865716207595098, 0.6346573943183536, 0.6372807252974737, 0.7865353879474458, 0.715421858287993, 0.8086950211297899, 0.6088069563820249, 0.6871150334676107, 0.630560352688744, 0.7219408012571789, 0.7151359262920561, 0.7062061741238549, 0.7334666025070917, 0.8019889422825405], 'val_acc': [0.8095421478861854, 0.8592124780019125, 0.882520630246117, 0.9061034690766108, 0.9125549509411767, 0.9161561188243684, 0.9179464039348421, 0.9178204877035958, 0.9214400138173785, 0.9272756207556951, 0.931266032514118, 0.9308104344776699, 0.9353044856162298, 0.9241987126214164, 0.9205815139270964, 0.9313346970648992, 0.9319322307904562, 0.9246107935905457, 0.9376740086646307, 0.9290727944601149, 0.9326854603631156, 0.9376442432403564, 0.9323305714698065, 0.9297825325103033, 0.9268681378591628, 0.9199130308060419, 0.9288758976118905, 0.9358814330328078, 0.9301007475171771, 0.9323740573156447, 0.9388667401813325, 0.9340407678059169, 0.9296131219182696, 0.9342468097096398, 0.9344390829404196, 0.9363530476888021, 0.9329418312935602, 0.9395146284784589, 0.9377243859427316, 0.924560424827394, 0.9386561399414426, 0.9342284741855803, 0.9208768066905794, 0.9365636621202741, 0.936614005338578, 0.926396491981688, 0.9364422815186637, 0.9423832694689432, 0.9376396763892401, 0.9326831414586022, 0.9382989974248976, 0.9330700692676362, 0.9400091483479455, 0.9311034764562335, 0.9406799532118297, 0.9413438410986037, 0.9418475400833857, 0.9405311601502555, 0.9382554775192624, 0.9425892716362363, 0.924377285298847, 0.9324542085329691, 0.9413896657171703, 0.9411171901793707, 0.9428365627924601, 0.9429097743261428, 0.9320924991653079, 0.9372893798918951, 0.9291392167409261, 0.9367421922229585, 0.938672159399305, 0.9354922033491588, 0.9418269225529262, 0.9417765537897745, 0.9325000047683716, 0.9418269339061919, 0.9349244322095599, 0.9315819683529082, 0.94358743088586, 0.9261286883127122, 0.9407737993058705, 0.9365155867167881, 0.9393314804349627, 0.9414789648283095, 0.9425984649431138, 0.9353113287971133, 0.9405815175601414, 0.9380265616235279, 0.9351259242920649, 0.9404006458464123, 0.9362866140547252, 0.9333516416095552, 0.9414491738591876, 0.9438873699733189, 0.9393932961282276, 0.9396726148469108, 0.9430540544646127, 0.9299015800158182, 0.9366117261704945, 0.9446360128266471, 0.9435942996115911, 0.9400503834088644, 0.939681799638839, 0.9379876255989075, 0.9424473586536589, 0.9427449759982881, 0.9422801931699117, 0.9399083994683766, 0.938768330074492, 0.9314331724530175, 0.9429303805033366, 0.9276991969063169, 0.9343063405581883, 0.9402747438067481, 0.942898378485725, 0.9401625650269645, 0.9416415010179792, 0.9352724580537706, 0.9354807706106276, 0.9440567663737706, 0.9431867883318946, 0.9353067704609462, 0.9422825007211595, 0.934700105871473, 0.9417284698713393, 0.9313667728787377, 0.940059517111097, 0.9427747215543475, 0.9385988854226612, 0.9429074838047936, 0.9369276620092846, 0.9432509314446222, 0.9422985116640726, 0.9338782287779308, 0.9416506375585284, 0.9417376489866347, 0.9374541980879647, 0.9429280899819874, 0.938207433337257, 0.9420558583168757, 0.941584274882362, 0.9420490066210429, 0.9442880153656006, 0.9413850875127883, 0.9372618822824388, 0.9448534590857369, 0.9427792884054638, 0.9431112834385463, 0.9417994476500011, 0.9291414987473261, 0.9403319387208848, 0.9437385598818461, 0.9363415780521575, 0.9431272801898775, 0.9361240835416884, 0.9403021789732433, 0.940412095614842, 0.9435165070352101, 0.9393887150855291, 0.9378914889835176, 0.9440155795642308, 0.9356982452528817, 0.9448374339512416, 0.9416895622298831, 0.9390063910257249, 0.9368933268955776, 0.9436195010230655, 0.9432051437241691, 0.9429257994606381, 0.9408562126613799, 0.9434775624956403, 0.9418704140753973, 0.9438369983718509, 0.9348512064842951, 0.937369480019524, 0.9433928728103638, 0.9427083106268019, 0.9406639025324867, 0.9446703309104556, 0.9383149970145452, 0.9412660087857928, 0.9330128374553862, 0.9414011154856, 0.9368704301970345, 0.9465109847840809, 0.94401787008558, 0.9422184342429751, 0.9431547749610174, 0.9423580765724182, 0.945114464986892, 0.9442147697721209, 0.939956491901761, 0.9350618237540835, 0.9432211376371837, 0.9409638359433129, 0.942948716027396, 0.9456066773051307, 0.9392078518867493, 0.9388851012502398, 0.9346657253447033, 0.9345604351588658, 0.9408768245152065, 0.9444116126923334, 0.9406387607256571, 0.9424107188270205, 0.938784366562253, 0.9397664751325335, 0.9310759873617263], 'val_mDice': [0.14953291238773436, 0.26525335134716616, 0.31898764263661133, 0.43772021645591375, 0.47398990357205983, 0.48717553949072245, 0.49907406987178893, 0.4804105999923888, 0.5057297015473956, 0.5040178937571389, 0.5068030504598504, 0.5095170732764971, 0.5212106477646601, 0.5141088653888021, 0.50209085625552, 0.5154328051777113, 0.5272371517050833, 0.5224151460542565, 0.533836580103352, 0.5241619029215404, 0.529687765453543, 0.5271884710306213, 0.5296567930352121, 0.5369269564038232, 0.516762849653051, 0.5174631453340962, 0.5264952173900037, 0.540051239409617, 0.5301305818415823, 0.5338967731665998, 0.5454631651796046, 0.5352701266251859, 0.5255340234864325, 0.5346444800850891, 0.5362441695871807, 0.5365390742108935, 0.5295686280088765, 0.5391707509046509, 0.5419406309014275, 0.5159648945998578, 0.5386643251847654, 0.5346865852673849, 0.5117585208444368, 0.5314611100724765, 0.5447159214388757, 0.5285496715278852, 0.5266669183259919, 0.5432305591447013, 0.5428301874725592, 0.5302778173770223, 0.5418272756394886, 0.5384372669671263, 0.5441540435311341, 0.5365620070979709, 0.5450383964039031, 0.5518485272214526, 0.5493965423887684, 0.5431344023063069, 0.5512596237517539, 0.5500863765676817, 0.5150714708226067, 0.5371435268649033, 0.5600741005369595, 0.5420434567190352, 0.5478117966226169, 0.5588372438436463, 0.53103095328524, 0.5523710249080545, 0.5282872537417072, 0.527503276509898, 0.5474714102844397, 0.5448435495297114, 0.5616100909454482, 0.5530685640516735, 0.5379259208483356, 0.5425514504313469, 0.5434840837759631, 0.5324574428654852, 0.5481978424248242, 0.516371717587823, 0.5546025442225593, 0.540975000177111, 0.5499886611387843, 0.5600319462163108, 0.5594046978013856, 0.5368076502567246, 0.5517675514732089, 0.5394254921092874, 0.549460103114446, 0.5351060153472991, 0.5447099114812556, 0.5377976500562259, 0.5431186136390481, 0.5519530755423364, 0.5399575011716002, 0.5449676114533629, 0.5495134556577319, 0.5328767927629607, 0.5291155225464276, 0.5597096126349199, 0.5618189073034695, 0.5490370431826228, 0.5476321368699982, 0.5408169128710315, 0.5492038709067163, 0.5539337579338324, 0.5437563116706553, 0.5364393598976589, 0.5394831970334053, 0.5295929603633427, 0.5463849524302142, 0.5302866633449282, 0.5341057209741502, 0.5573426729866436, 0.5621599377620787, 0.5363708867558411, 0.5542555625240008, 0.5304655523172447, 0.5379347501411325, 0.5471331054965655, 0.5496792748925232, 0.535213328188374, 0.5402149331002009, 0.5462441875466278, 0.5506995157116935, 0.5330573430373555, 0.5514490849205426, 0.5416261174139523, 0.5344701414661748, 0.5569722964650109, 0.538235657804069, 0.5499526666743415, 0.5409876945472899, 0.5411486453598454, 0.5389635475973288, 0.5423579819145656, 0.5472315404386747, 0.5461160780063697, 0.5457974266083467, 0.5504118303457896, 0.5458582061387244, 0.5476548249522845, 0.5453511417976448, 0.5573962894933564, 0.5369502483379274, 0.5490291026376543, 0.5515144804403895, 0.5275278614745254, 0.555024904864175, 0.5238516208316598, 0.546343842787402, 0.5463302630398955, 0.5538185806501479, 0.563421928811641, 0.5336213665349143, 0.5540569048552286, 0.5247501713179407, 0.5458990560755843, 0.540289856493473, 0.542422658453385, 0.5473127263997283, 0.5201193417112032, 0.5433199629187584, 0.5533187861243883, 0.5442946991395383, 0.5371408874080295, 0.5451319705517519, 0.5659987158363774, 0.5548134683853104, 0.5455614250330698, 0.5495672094680014, 0.5445694696335566, 0.5441277083896455, 0.545382997464566, 0.5371287677969251, 0.5533419368522507, 0.5488217002933934, 0.5430622831696555, 0.5433573763640154, 0.5385526000034242, 0.5423462515076002, 0.5371892225174677, 0.5407288299784774, 0.5356470690596671, 0.5523862845840908, 0.5625123544817879, 0.5479658104124523, 0.5550916931104093, 0.5552385894670373, 0.5647244144763265, 0.5465769611653828, 0.5366005046027047, 0.5399870794443857, 0.5528808534145355, 0.5462510789788905, 0.5504371985083535, 0.5412702019370738, 0.5338603930459136, 0.539877060623396, 0.542735208712873, 0.5190951602444762, 0.549583467344443, 0.5478261177028928, 0.5370427043665023, 0.5299718520116239, 0.5392282693868592, 0.546124262823945, 0.5161628471243949], 'loss': [3.290789448872499, 1.5166356473707248, 1.060582255567915, 0.8792342286659661, 0.7885678126583537, 0.7258016713349972, 0.6897187989549138, 0.6596499550473559, 0.6325613023551278, 0.6115291924726671, 0.5946604345652416, 0.5765190816968996, 0.5603115502317586, 0.5474820558060013, 0.5361373251358255, 0.5242650907279118, 0.5157485331888256, 0.5083784135476872, 0.49975212830464827, 0.4942336116702152, 0.48743255946340647, 0.4832143922037809, 0.4751989136478541, 0.4708892796766742, 0.4671684223688106, 0.46232273321471645, 0.46039768998876157, 0.45352688810373515, 0.4477569872424716, 0.4475003388809611, 0.44495507987427624, 0.43998294968767754, 0.43627560201329213, 0.43433233041259534, 0.4305669006720797, 0.42888751675426695, 0.42626561635556837, 0.42243567797428433, 0.42367204287182236, 0.4197328114167146, 0.41454641368431877, 0.41477809994349896, 0.41329356883793456, 0.41160516521593776, 0.4088787994151265, 0.4074065948189948, 0.40546691773345483, 0.40569050212758617, 0.40243193239450503, 0.39851493152989254, 0.3993306288099574, 0.3972141456633881, 0.39453377833089687, 0.3952216622467236, 0.3942753879038474, 0.3928435390708486, 0.39145221921872236, 0.3888074880577545, 0.3860517290600559, 0.38552533092125546, 0.38581717884768085, 0.38522425973624513, 0.38289895547431446, 0.37964021106986195, 0.38002935246693187, 0.380801103639998, 0.38116070868905993, 0.3773034334538965, 0.38000734332257297, 0.3764520319976259, 0.37398854404233983, 0.3718612541841224, 0.37240949353547553, 0.37252295049992235, 0.3725323592028407, 0.3717188825089278, 0.3686942057685859, 0.3674711519028149, 0.36862937834006826, 0.3658420387802727, 0.36800814957340167, 0.36569175794103, 0.3642793396993802, 0.3644714363512562, 0.362876555082861, 0.35966650580587656, 0.3612973814482217, 0.362180683001264, 0.36056486960318773, 0.35849500683224084, 0.3581642106775836, 0.3591462150173011, 0.35932745247165754, 0.35775978869272146, 0.3576089271017644, 0.3567437126281658, 0.35519497954066326, 0.35454664374905465, 0.3540615170751667, 0.3534908363624692, 0.35230638678877807, 0.351278048502082, 0.35247765860393004, 0.35164807681428784, 0.3504188641753527, 0.3497689936646887, 0.35046196792289797, 0.3475708459093319, 0.3485274110165363, 0.3480969890190821, 0.34704071727473773, 0.34684548393848524, 0.3475358599133636, 0.34564216657596813, 0.3456870137047901, 0.34517951417985115, 0.34429366083670976, 0.3428756222574151, 0.34190478219401294, 0.341406841906183, 0.34322014683722896, 0.34245049754089074, 0.3434356644086027, 0.3422876043840941, 0.3400673502806595, 0.34089300500098646, 0.33880824973892565, 0.33978065459374773, 0.339434383598991, 0.3390629007932605, 0.3386444035053529, 0.33758150659615027, 0.33664277919873536, 0.3373229542873902, 0.3370420453760788, 0.33650607098176205, 0.3352556155381553, 0.33507290710620574, 0.33382721314523084, 0.33455082423681926, 0.3341738480994852, 0.3348637532298451, 0.3356963703116172, 0.3324074472378094, 0.33375764131569, 0.3323458916526873, 0.33343005761237005, 0.3320246755226467, 0.3353797037097698, 0.33085193507285715, 0.3319682182030616, 0.33023468982582727, 0.328794721799111, 0.330426100535914, 0.33052147669509035, 0.3311967210593149, 0.3301413991627308, 0.3280564874887512, 0.32926527881452244, 0.3297809588212785, 0.3278546521940373, 0.3278095631590693, 0.32746117807248204, 0.32745908294106485, 0.32690073735616976, 0.32747538309922813, 0.32734172755476365, 0.3252696642382471, 0.326294839227041, 0.32411557755443615, 0.32420637553795834, 0.32387105814059713, 0.32491044036243977, 0.3243990095681668, 0.32375748677016547, 0.322247299915659, 0.3239829858270527, 0.32292427867507345, 0.32334333862186465, 0.32323477436909215, 0.3225154994321003, 0.32410821517423466, 0.3241244836397798, 0.3225167822879198, 0.3246885082936365, 0.3221230626462488, 0.32130464257613894, 0.3216143785321416, 0.32086009283573247, 0.31983172331031906, 0.31956585286232186, 0.31898088544371594, 0.320841529775222, 0.3193746465397451, 0.31889661169819733, 0.320605852136452, 0.31846959708236605, 0.31763962146770247, 0.31808521912717075, 0.3200594773923636, 0.317478124618944, 0.3210416724910758, 0.31723434840159676, 0.31804767425680336, 0.31742450701769825, 0.3178775080865533, 0.3163590466778518, 0.3162826807404245], 'acc': [0.40686537552476276, 0.8498669482045075, 0.8737533104679408, 0.8799331454452072, 0.8838851935996332, 0.8872743748690045, 0.8900672072662837, 0.8925405925860496, 0.8957792024564624, 0.8984478571889762, 0.9011725407472253, 0.9048236366386516, 0.9085473483505565, 0.9119116235887106, 0.9139791525281278, 0.9158695094130829, 0.9168063925828046, 0.9180001587864979, 0.9189791938852707, 0.9198140476005993, 0.9205920670748171, 0.9212041745784312, 0.9219976721849656, 0.9227048970496055, 0.9232314540881607, 0.9235632552538898, 0.9238439566693325, 0.9245640205031579, 0.9250321147275012, 0.9252547973931031, 0.9254761793054044, 0.9261375039396476, 0.9266651980744085, 0.9267089917799033, 0.9272075351754985, 0.9273468904787574, 0.9275964505184771, 0.9280694325879886, 0.9280039288874925, 0.9283025204066667, 0.9289713528589727, 0.9288325326300688, 0.9291661105474021, 0.9294799956853436, 0.9293213183419746, 0.9296906978173456, 0.9297829935586083, 0.9298818404674071, 0.9301869907038093, 0.930418941587158, 0.9305530150708422, 0.9307231877221063, 0.9308680153224012, 0.9308610606083227, 0.9311679956861054, 0.9313497344767723, 0.9315222446367372, 0.9317463156642403, 0.931974398037223, 0.9321115991962147, 0.9321473072162133, 0.932368621181288, 0.9325564726598234, 0.9327519990608645, 0.9327747073733372, 0.9328121543620073, 0.9330179626964203, 0.933273204436577, 0.9331514826394561, 0.933326382098778, 0.9335296685603259, 0.933695095741889, 0.9335596764595586, 0.9337664844788911, 0.9338025638012383, 0.9338312252123553, 0.9341493478188148, 0.9342323797319536, 0.9341341965525325, 0.9345815078771388, 0.9341883943883904, 0.934571868908619, 0.9348092162358593, 0.9346584404436453, 0.9348917116037747, 0.9351237042804709, 0.9349762890893691, 0.9348893929750491, 0.9352444776777176, 0.9354022297988812, 0.9354938970426615, 0.9353230295094861, 0.9353805205967699, 0.9354611544887615, 0.935423663109742, 0.9356328358603324, 0.935459257746469, 0.9360230553579947, 0.9359458395918601, 0.935861401953678, 0.9360702752331582, 0.936173897201394, 0.9360626522506941, 0.9362131513587675, 0.9362005948307934, 0.9363242595301948, 0.9363397168979861, 0.9366337690528979, 0.9365446953523451, 0.9363981771381783, 0.9365418444875809, 0.936723674736387, 0.9366656264427748, 0.936588511534548, 0.9368554292006462, 0.9367153320511067, 0.9369547683447571, 0.9369255023607519, 0.9370997740005698, 0.9372149621886464, 0.9370241163897105, 0.937046896257634, 0.9371051979083327, 0.9372033778127733, 0.9374009657508264, 0.9373001658964736, 0.9375565832052384, 0.9375387934652946, 0.9374380134446831, 0.9375925475010781, 0.9374344232157289, 0.9376337455834455, 0.93776696207943, 0.9375348271536694, 0.9377524123178963, 0.9377776716563061, 0.938007205741953, 0.9379930248926066, 0.937957667904551, 0.9379217509637799, 0.9380749378196072, 0.938015641367732, 0.9379682543536522, 0.9383856290242151, 0.9381586565593545, 0.9382585065889294, 0.9381340049539018, 0.9383514490986183, 0.9379649660434248, 0.9384453654840821, 0.9382904864975499, 0.9384332486883119, 0.9386394975708012, 0.9382429789871707, 0.9385361038284861, 0.938302000662438, 0.9384534501353738, 0.9387167296199089, 0.9384118833361689, 0.9383721659471701, 0.9385436355941255, 0.938827724074821, 0.9386310158884545, 0.9387743357796647, 0.9387972760297026, 0.9387898832956031, 0.9388552720730121, 0.9390766603973805, 0.9388265403245073, 0.9390808492468022, 0.9389473394159868, 0.9391220263692945, 0.9390304542493333, 0.9389422166340609, 0.9392541297511234, 0.9392576788072529, 0.9390668114968662, 0.9391740265783373, 0.9392272760717768, 0.9392354092962001, 0.9394501680373594, 0.9391076177192006, 0.9392864294931887, 0.939289932527224, 0.9391318329363768, 0.939434916889918, 0.9393205214194854, 0.939430492563654, 0.9394732196022602, 0.9394361684380732, 0.9394598959014897, 0.9395367825033579, 0.939496809424567, 0.9395211896892686, 0.9396264300839116, 0.9395684578617759, 0.9396599614829347, 0.939699192497113, 0.9397037119586872, 0.9394744009624126, 0.9396502522919388, 0.9394693710175649, 0.9397948216858778, 0.9397857149648878, 0.9398692264270985, 0.9398836867989018, 0.9398013121915825, 0.9398861656948301], 'mDice': [0.05766400780743525, 0.2213729091271606, 0.33516078989745246, 0.40034811513281887, 0.438486160623193, 0.46763330209064463, 0.4852587218249674, 0.5002025988075759, 0.5142265763245085, 0.5253821822037374, 0.5347306760078637, 0.5449593540719876, 0.5539694565188708, 0.5615322391651765, 0.5679045288186324, 0.5750962074882657, 0.5801727378071906, 0.5846664717782548, 0.5898902393936398, 0.5931843961965194, 0.5975136346662575, 0.6002082183500327, 0.6052337507418362, 0.6077247043669005, 0.6102873681252096, 0.6133418799549807, 0.6147286908714349, 0.6189995039077032, 0.6227417299346196, 0.623107425918785, 0.624611334336937, 0.6281087632259239, 0.6303164063562703, 0.6315220054091805, 0.6341201570053792, 0.6352821438096956, 0.6368953638943675, 0.6394937828323941, 0.6385911915926017, 0.6415050563748824, 0.6447333838982414, 0.6447061385427203, 0.6456194875533121, 0.6469319973558227, 0.648658051951809, 0.6496560514513321, 0.6509414342572654, 0.6508327751277337, 0.6530242903351623, 0.6557108330915079, 0.6552657581878715, 0.6565341413974853, 0.6584341260585708, 0.6579677203681994, 0.6586637242993615, 0.6597918142627975, 0.6607272431458355, 0.6623759663631306, 0.6642649905953261, 0.664688037233314, 0.6645789896681149, 0.6650033009886535, 0.666596429045085, 0.6687709686957, 0.6685353543042722, 0.6679895556177595, 0.6679408384330107, 0.6703949510327235, 0.6686660661756223, 0.6710523175945028, 0.6727393849727527, 0.6743511624112855, 0.6738717719174222, 0.6737605538675269, 0.6737941082488693, 0.6743013494870141, 0.6764641238449395, 0.677350423343843, 0.676537062750861, 0.6784339673904778, 0.6769880855591375, 0.6786172709323456, 0.6797319350271113, 0.6795190547343185, 0.6807091701736289, 0.6828672216304906, 0.6817386321693297, 0.6811267807806805, 0.6822356097565374, 0.6837141157483604, 0.6839573687157559, 0.6833260467752501, 0.6832260084515343, 0.6842987135653094, 0.6844072097272158, 0.6850104016308061, 0.6859998408024863, 0.686594329887855, 0.6869690349871008, 0.6873738105089788, 0.6881834100684104, 0.6888996669959765, 0.6880641226274834, 0.6887318590644791, 0.6895372121233413, 0.6899790767991798, 0.6896048116734521, 0.6915736602109729, 0.6908772091702825, 0.6912922187303794, 0.6919403723583806, 0.6920759823250132, 0.6916212328417535, 0.6929978973056071, 0.6930469775765256, 0.6933119997183942, 0.6940072362354456, 0.6950001971487689, 0.6956601129783379, 0.6960363392887811, 0.6947664569654698, 0.6952753243520813, 0.6947468122535987, 0.6954189417838866, 0.6969596325880029, 0.696427401306773, 0.6979714689030453, 0.6973296801364097, 0.6975481333887965, 0.6977314518576806, 0.698088693853194, 0.698866434391004, 0.6995425797368328, 0.6990355513149634, 0.6992743672583634, 0.6996104992582822, 0.7005063048879007, 0.7006952348462369, 0.7015904168850979, 0.7010444883714643, 0.701380745808881, 0.7009101899483311, 0.700209640792415, 0.7026727078207798, 0.7016817287302946, 0.7027073473927601, 0.7019462441120254, 0.7030146275960298, 0.7006478226780087, 0.7037917564709062, 0.7030185308211889, 0.7042200576139824, 0.7052683356250897, 0.7040153066041452, 0.7039844694913456, 0.7035632768485366, 0.7043308585003113, 0.705881983127947, 0.7049048332917982, 0.7046470119356995, 0.7059854972631412, 0.7060605618267453, 0.7062875525050938, 0.7063082299159859, 0.7068037495393387, 0.7063247663841005, 0.7065019079295339, 0.7079585782935078, 0.7072256565185924, 0.7086779292043013, 0.7087010370643929, 0.7089016603922509, 0.7081569665103881, 0.7085910791695313, 0.7090618070642314, 0.710140059098633, 0.7089081688011821, 0.7096967017901111, 0.7093736404901022, 0.7094481111561055, 0.7100374897091242, 0.7088422813189381, 0.7088223337345737, 0.7099895208746523, 0.7084067914558095, 0.7103011377611118, 0.710897998759713, 0.7107207596198613, 0.7112638377628506, 0.7119624666770529, 0.7122607755941395, 0.712589675092688, 0.7113353508341995, 0.7122880874490012, 0.7126572267246633, 0.7114269211960133, 0.7130313158173173, 0.7136105472282658, 0.7133228936153087, 0.711799749444164, 0.7138033153373243, 0.7110861648317245, 0.7139718454996928, 0.7132718855644757, 0.713809824642566, 0.7135098998616007, 0.7146367641090082, 0.714678043227033]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.02s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.82s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.66s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:56,  1.68s/it]predicting train subjects:   1%|          | 2/285 [00:02<07:19,  1.55s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:16,  1.55s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<06:51,  1.46s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:16,  1.56s/it]predicting train subjects:   2%|▏         | 6/285 [00:08<07:00,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:18,  1.58s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:02,  1.53s/it]predicting train subjects:   3%|▎         | 9/285 [00:13<07:27,  1.62s/it]predicting train subjects:   4%|▎         | 10/285 [00:15<07:40,  1.67s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:20,  1.61s/it]predicting train subjects:   4%|▍         | 12/285 [00:18<07:36,  1.67s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:12,  1.59s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:26,  1.65s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:42,  1.71s/it]predicting train subjects:   6%|▌         | 16/285 [00:25<07:49,  1.74s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:21,  1.65s/it]predicting train subjects:   6%|▋         | 18/285 [00:28<07:23,  1.66s/it]predicting train subjects:   7%|▋         | 19/285 [00:30<07:02,  1.59s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:11,  1.63s/it]predicting train subjects:   7%|▋         | 21/285 [00:33<07:26,  1.69s/it]predicting train subjects:   8%|▊         | 22/285 [00:35<06:59,  1.59s/it]predicting train subjects:   8%|▊         | 23/285 [00:36<07:01,  1.61s/it]predicting train subjects:   8%|▊         | 24/285 [00:38<06:40,  1.54s/it]predicting train subjects:   9%|▉         | 25/285 [00:40<06:55,  1.60s/it]predicting train subjects:   9%|▉         | 26/285 [00:41<07:07,  1.65s/it]predicting train subjects:   9%|▉         | 27/285 [00:43<06:44,  1.57s/it]predicting train subjects:  10%|▉         | 28/285 [00:44<06:52,  1.61s/it]predicting train subjects:  10%|█         | 29/285 [00:46<06:55,  1.62s/it]predicting train subjects:  11%|█         | 30/285 [00:48<07:02,  1.66s/it]predicting train subjects:  11%|█         | 31/285 [00:50<07:13,  1.71s/it]predicting train subjects:  11%|█         | 32/285 [00:51<06:47,  1.61s/it]predicting train subjects:  12%|█▏        | 33/285 [00:53<06:48,  1.62s/it]predicting train subjects:  12%|█▏        | 34/285 [00:54<06:49,  1.63s/it]predicting train subjects:  12%|█▏        | 35/285 [00:56<06:56,  1.66s/it]predicting train subjects:  13%|█▎        | 36/285 [00:57<06:33,  1.58s/it]predicting train subjects:  13%|█▎        | 37/285 [00:59<06:36,  1.60s/it]predicting train subjects:  13%|█▎        | 38/285 [01:01<06:44,  1.64s/it]predicting train subjects:  14%|█▎        | 39/285 [01:02<06:30,  1.59s/it]predicting train subjects:  14%|█▍        | 40/285 [01:04<06:41,  1.64s/it]predicting train subjects:  14%|█▍        | 41/285 [01:06<06:28,  1.59s/it]predicting train subjects:  15%|█▍        | 42/285 [01:07<06:17,  1.55s/it]predicting train subjects:  15%|█▌        | 43/285 [01:09<06:27,  1.60s/it]predicting train subjects:  15%|█▌        | 44/285 [01:10<06:37,  1.65s/it]predicting train subjects:  16%|█▌        | 45/285 [01:12<06:20,  1.58s/it]predicting train subjects:  16%|█▌        | 46/285 [01:14<06:31,  1.64s/it]predicting train subjects:  16%|█▋        | 47/285 [01:15<06:19,  1.59s/it]predicting train subjects:  17%|█▋        | 48/285 [01:17<06:26,  1.63s/it]predicting train subjects:  17%|█▋        | 49/285 [01:19<06:35,  1.67s/it]predicting train subjects:  18%|█▊        | 50/285 [01:20<06:36,  1.69s/it]predicting train subjects:  18%|█▊        | 51/285 [01:22<06:45,  1.73s/it]predicting train subjects:  18%|█▊        | 52/285 [01:24<06:19,  1.63s/it]predicting train subjects:  19%|█▊        | 53/285 [01:25<06:17,  1.63s/it]predicting train subjects:  19%|█▉        | 54/285 [01:27<06:23,  1.66s/it]predicting train subjects:  19%|█▉        | 55/285 [01:28<06:02,  1.58s/it]predicting train subjects:  20%|█▉        | 56/285 [01:30<06:05,  1.60s/it]predicting train subjects:  20%|██        | 57/285 [01:31<05:51,  1.54s/it]predicting train subjects:  20%|██        | 58/285 [01:33<05:55,  1.57s/it]predicting train subjects:  21%|██        | 59/285 [01:35<06:04,  1.61s/it]predicting train subjects:  21%|██        | 60/285 [01:37<06:14,  1.66s/it]predicting train subjects:  21%|██▏       | 61/285 [01:38<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 62/285 [01:40<06:02,  1.63s/it]predicting train subjects:  22%|██▏       | 63/285 [01:41<06:04,  1.64s/it]predicting train subjects:  22%|██▏       | 64/285 [01:43<05:53,  1.60s/it]predicting train subjects:  23%|██▎       | 65/285 [01:45<05:58,  1.63s/it]predicting train subjects:  23%|██▎       | 66/285 [01:46<05:56,  1.63s/it]predicting train subjects:  24%|██▎       | 67/285 [01:48<05:59,  1.65s/it]predicting train subjects:  24%|██▍       | 68/285 [01:49<05:46,  1.59s/it]predicting train subjects:  24%|██▍       | 69/285 [01:51<05:46,  1.60s/it]predicting train subjects:  25%|██▍       | 70/285 [01:53<05:46,  1.61s/it]predicting train subjects:  25%|██▍       | 71/285 [01:54<05:52,  1.65s/it]predicting train subjects:  25%|██▌       | 72/285 [01:56<05:38,  1.59s/it]predicting train subjects:  26%|██▌       | 73/285 [01:57<05:38,  1.60s/it]predicting train subjects:  26%|██▌       | 74/285 [01:59<05:38,  1.60s/it]predicting train subjects:  26%|██▋       | 75/285 [02:01<05:38,  1.61s/it]predicting train subjects:  27%|██▋       | 76/285 [02:02<05:44,  1.65s/it]predicting train subjects:  27%|██▋       | 77/285 [02:04<05:31,  1.60s/it]predicting train subjects:  27%|██▋       | 78/285 [02:05<05:23,  1.56s/it]predicting train subjects:  28%|██▊       | 79/285 [02:07<05:24,  1.58s/it]predicting train subjects:  28%|██▊       | 80/285 [02:09<05:25,  1.59s/it]predicting train subjects:  28%|██▊       | 81/285 [02:10<05:18,  1.56s/it]predicting train subjects:  29%|██▉       | 82/285 [02:12<05:21,  1.58s/it]predicting train subjects:  29%|██▉       | 83/285 [02:13<05:11,  1.54s/it]predicting train subjects:  29%|██▉       | 84/285 [02:15<05:05,  1.52s/it]predicting train subjects:  30%|██▉       | 85/285 [02:16<05:10,  1.55s/it]predicting train subjects:  30%|███       | 86/285 [02:18<05:17,  1.59s/it]predicting train subjects:  31%|███       | 87/285 [02:20<05:20,  1.62s/it]predicting train subjects:  31%|███       | 88/285 [02:21<05:12,  1.58s/it]predicting train subjects:  31%|███       | 89/285 [02:23<05:13,  1.60s/it]predicting train subjects:  32%|███▏      | 90/285 [02:24<05:17,  1.63s/it]predicting train subjects:  32%|███▏      | 91/285 [02:26<05:06,  1.58s/it]predicting train subjects:  32%|███▏      | 92/285 [02:28<05:13,  1.63s/it]predicting train subjects:  33%|███▎      | 93/285 [02:29<05:06,  1.59s/it]predicting train subjects:  33%|███▎      | 94/285 [02:31<05:04,  1.59s/it]predicting train subjects:  33%|███▎      | 95/285 [02:32<05:09,  1.63s/it]predicting train subjects:  34%|███▎      | 96/285 [02:34<05:08,  1.63s/it]predicting train subjects:  34%|███▍      | 97/285 [02:36<05:13,  1.67s/it]predicting train subjects:  34%|███▍      | 98/285 [02:37<05:08,  1.65s/it]predicting train subjects:  35%|███▍      | 99/285 [02:39<05:02,  1.63s/it]predicting train subjects:  35%|███▌      | 100/285 [02:41<05:03,  1.64s/it]predicting train subjects:  35%|███▌      | 101/285 [02:42<04:50,  1.58s/it]predicting train subjects:  36%|███▌      | 102/285 [02:44<04:57,  1.62s/it]predicting train subjects:  36%|███▌      | 103/285 [02:45<04:45,  1.57s/it]predicting train subjects:  36%|███▋      | 104/285 [02:47<04:46,  1.58s/it]predicting train subjects:  37%|███▋      | 105/285 [02:49<04:51,  1.62s/it]predicting train subjects:  37%|███▋      | 106/285 [02:50<04:45,  1.59s/it]predicting train subjects:  38%|███▊      | 107/285 [02:52<04:48,  1.62s/it]predicting train subjects:  38%|███▊      | 108/285 [02:53<04:39,  1.58s/it]predicting train subjects:  38%|███▊      | 109/285 [02:55<04:37,  1.58s/it]predicting train subjects:  39%|███▊      | 110/285 [02:57<04:40,  1.60s/it]predicting train subjects:  39%|███▉      | 111/285 [02:58<04:31,  1.56s/it]predicting train subjects:  39%|███▉      | 112/285 [03:00<04:29,  1.56s/it]predicting train subjects:  40%|███▉      | 113/285 [03:01<04:31,  1.58s/it]predicting train subjects:  40%|████      | 114/285 [03:03<04:27,  1.57s/it]predicting train subjects:  40%|████      | 115/285 [03:04<04:27,  1.57s/it]predicting train subjects:  41%|████      | 116/285 [03:06<04:33,  1.62s/it]predicting train subjects:  41%|████      | 117/285 [03:08<04:25,  1.58s/it]predicting train subjects:  41%|████▏     | 118/285 [03:09<04:20,  1.56s/it]predicting train subjects:  42%|████▏     | 119/285 [03:11<04:24,  1.59s/it]predicting train subjects:  42%|████▏     | 120/285 [03:12<04:17,  1.56s/it]predicting train subjects:  42%|████▏     | 121/285 [03:14<04:09,  1.52s/it]predicting train subjects:  43%|████▎     | 122/285 [03:15<03:58,  1.47s/it]predicting train subjects:  43%|████▎     | 123/285 [03:16<03:50,  1.42s/it]predicting train subjects:  44%|████▎     | 124/285 [03:18<03:49,  1.43s/it]predicting train subjects:  44%|████▍     | 125/285 [03:19<03:41,  1.38s/it]predicting train subjects:  44%|████▍     | 126/285 [03:20<03:36,  1.36s/it]predicting train subjects:  45%|████▍     | 127/285 [03:22<03:32,  1.35s/it]predicting train subjects:  45%|████▍     | 128/285 [03:23<03:37,  1.39s/it]predicting train subjects:  45%|████▌     | 129/285 [03:24<03:32,  1.36s/it]predicting train subjects:  46%|████▌     | 130/285 [03:26<03:26,  1.33s/it]predicting train subjects:  46%|████▌     | 131/285 [03:27<03:22,  1.32s/it]predicting train subjects:  46%|████▋     | 132/285 [03:28<03:29,  1.37s/it]predicting train subjects:  47%|████▋     | 133/285 [03:30<03:24,  1.35s/it]predicting train subjects:  47%|████▋     | 134/285 [03:31<03:19,  1.32s/it]predicting train subjects:  47%|████▋     | 135/285 [03:32<03:16,  1.31s/it]predicting train subjects:  48%|████▊     | 136/285 [03:34<03:12,  1.29s/it]predicting train subjects:  48%|████▊     | 137/285 [03:35<03:18,  1.34s/it]predicting train subjects:  48%|████▊     | 138/285 [03:36<03:14,  1.32s/it]predicting train subjects:  49%|████▉     | 139/285 [03:38<03:18,  1.36s/it]predicting train subjects:  49%|████▉     | 140/285 [03:39<03:19,  1.37s/it]predicting train subjects:  49%|████▉     | 141/285 [03:40<03:13,  1.34s/it]predicting train subjects:  50%|████▉     | 142/285 [03:42<03:12,  1.35s/it]predicting train subjects:  50%|█████     | 143/285 [03:43<03:08,  1.33s/it]predicting train subjects:  51%|█████     | 144/285 [03:45<03:13,  1.37s/it]predicting train subjects:  51%|█████     | 145/285 [03:46<03:09,  1.35s/it]predicting train subjects:  51%|█████     | 146/285 [03:47<03:14,  1.40s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:49<03:09,  1.37s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:50<03:12,  1.40s/it]predicting train subjects:  52%|█████▏    | 149/285 [03:51<03:06,  1.37s/it]predicting train subjects:  53%|█████▎    | 150/285 [03:53<03:01,  1.34s/it]predicting train subjects:  53%|█████▎    | 151/285 [03:54<03:04,  1.38s/it]predicting train subjects:  53%|█████▎    | 152/285 [03:55<03:00,  1.36s/it]predicting train subjects:  54%|█████▎    | 153/285 [03:57<02:57,  1.35s/it]predicting train subjects:  54%|█████▍    | 154/285 [03:58<03:01,  1.38s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:00<02:57,  1.37s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:01<02:59,  1.39s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:02<02:55,  1.37s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:04<02:51,  1.35s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:05<02:47,  1.33s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:06<02:46,  1.33s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:08<02:50,  1.37s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:09<02:46,  1.36s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:10<02:48,  1.38s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:12<02:43,  1.36s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:13<02:40,  1.34s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:15<02:43,  1.38s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:16<02:47,  1.42s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:17<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:19<02:38,  1.37s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:20<02:35,  1.35s/it]predicting train subjects:  60%|██████    | 171/285 [04:21<02:32,  1.34s/it]predicting train subjects:  60%|██████    | 172/285 [04:23<02:29,  1.33s/it]predicting train subjects:  61%|██████    | 173/285 [04:24<02:28,  1.32s/it]predicting train subjects:  61%|██████    | 174/285 [04:25<02:25,  1.31s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:27<02:31,  1.37s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:28<02:35,  1.42s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:30<02:30,  1.39s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:31<02:25,  1.36s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:32<02:21,  1.34s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:34<02:31,  1.45s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:35<02:31,  1.46s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:37<02:31,  1.47s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:38<02:23,  1.41s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:39<02:18,  1.37s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:41<02:13,  1.34s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:42<02:21,  1.43s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:44<02:26,  1.49s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:46<02:30,  1.55s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:47<02:20,  1.46s/it]predicting train subjects:  67%|██████▋   | 190/285 [04:48<02:14,  1.42s/it]predicting train subjects:  67%|██████▋   | 191/285 [04:50<02:15,  1.44s/it]predicting train subjects:  67%|██████▋   | 192/285 [04:51<02:16,  1.47s/it]predicting train subjects:  68%|██████▊   | 193/285 [04:52<02:07,  1.38s/it]predicting train subjects:  68%|██████▊   | 194/285 [04:54<02:02,  1.35s/it]predicting train subjects:  68%|██████▊   | 195/285 [04:55<01:59,  1.33s/it]predicting train subjects:  69%|██████▉   | 196/285 [04:57<02:09,  1.45s/it]predicting train subjects:  69%|██████▉   | 197/285 [04:58<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:00<02:18,  1.60s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:01<02:06,  1.48s/it]predicting train subjects:  70%|███████   | 200/285 [05:03<02:01,  1.42s/it]predicting train subjects:  71%|███████   | 201/285 [05:04<02:05,  1.49s/it]predicting train subjects:  71%|███████   | 202/285 [05:06<02:03,  1.49s/it]predicting train subjects:  71%|███████   | 203/285 [05:07<02:02,  1.50s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:09<01:55,  1.42s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:10<01:51,  1.39s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:11<01:46,  1.34s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:13<01:51,  1.44s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:14<01:55,  1.51s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:16<01:59,  1.57s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:17<01:50,  1.47s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:19<01:44,  1.41s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:20<01:43,  1.42s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:22<01:44,  1.45s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:23<01:37,  1.38s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:24<01:41,  1.45s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:26<01:34,  1.37s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:27<01:38,  1.45s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:29<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:31<01:43,  1.56s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:32<01:35,  1.47s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:33<01:32,  1.44s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:35<01:32,  1.46s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:36<01:27,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:37<01:25,  1.40s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:39<01:21,  1.36s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:40<01:26,  1.46s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:42<01:28,  1.52s/it]predicting train subjects:  80%|████████  | 228/285 [05:44<01:28,  1.56s/it]predicting train subjects:  80%|████████  | 229/285 [05:45<01:26,  1.54s/it]predicting train subjects:  81%|████████  | 230/285 [05:46<01:19,  1.45s/it]predicting train subjects:  81%|████████  | 231/285 [05:48<01:15,  1.40s/it]predicting train subjects:  81%|████████▏ | 232/285 [05:49<01:16,  1.44s/it]predicting train subjects:  82%|████████▏ | 233/285 [05:51<01:12,  1.39s/it]predicting train subjects:  82%|████████▏ | 234/285 [05:52<01:15,  1.48s/it]predicting train subjects:  82%|████████▏ | 235/285 [05:54<01:10,  1.42s/it]predicting train subjects:  83%|████████▎ | 236/285 [05:55<01:13,  1.51s/it]predicting train subjects:  83%|████████▎ | 237/285 [05:57<01:15,  1.57s/it]predicting train subjects:  84%|████████▎ | 238/285 [05:59<01:15,  1.62s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:00<01:12,  1.58s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:01<01:06,  1.48s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:03<01:02,  1.43s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:04<00:59,  1.38s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:05<00:55,  1.33s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:07<00:58,  1.42s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:08<00:54,  1.37s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:10<00:57,  1.47s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:11<00:57,  1.53s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:13<00:56,  1.54s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:14<00:52,  1.45s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:16<00:49,  1.41s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:17<00:46,  1.36s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:18<00:43,  1.31s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:20<00:46,  1.45s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:21<00:47,  1.53s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:23<00:45,  1.52s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:24<00:41,  1.44s/it]predicting train subjects:  90%|█████████ | 257/285 [06:26<00:39,  1.41s/it]predicting train subjects:  91%|█████████ | 258/285 [06:27<00:40,  1.49s/it]predicting train subjects:  91%|█████████ | 259/285 [06:29<00:38,  1.50s/it]predicting train subjects:  91%|█████████ | 260/285 [06:30<00:35,  1.42s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:31<00:33,  1.38s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:33<00:31,  1.35s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:34<00:29,  1.32s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:36<00:29,  1.43s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:37<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:38<00:27,  1.43s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:40<00:25,  1.40s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:42<00:26,  1.55s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:43<00:24,  1.53s/it]predicting train subjects:  95%|█████████▍| 270/285 [06:44<00:21,  1.46s/it]predicting train subjects:  95%|█████████▌| 271/285 [06:46<00:19,  1.40s/it]predicting train subjects:  95%|█████████▌| 272/285 [06:47<00:18,  1.43s/it]predicting train subjects:  96%|█████████▌| 273/285 [06:49<00:16,  1.38s/it]predicting train subjects:  96%|█████████▌| 274/285 [06:50<00:14,  1.33s/it]predicting train subjects:  96%|█████████▋| 275/285 [06:51<00:14,  1.45s/it]predicting train subjects:  97%|█████████▋| 276/285 [06:53<00:13,  1.51s/it]predicting train subjects:  97%|█████████▋| 277/285 [06:54<00:11,  1.41s/it]predicting train subjects:  98%|█████████▊| 278/285 [06:56<00:09,  1.39s/it]predicting train subjects:  98%|█████████▊| 279/285 [06:57<00:08,  1.43s/it]predicting train subjects:  98%|█████████▊| 280/285 [06:58<00:06,  1.37s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:00<00:05,  1.35s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:01<00:03,  1.32s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:03<00:02,  1.42s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:04<00:01,  1.52s/it]predicting train subjects: 100%|██████████| 285/285 [07:06<00:00,  1.62s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:10,  1.73s/it]Loading train:   1%|          | 2/285 [00:03<07:33,  1.60s/it]Loading train:   1%|          | 3/285 [00:04<07:31,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:05<06:50,  1.46s/it]Loading train:   2%|▏         | 5/285 [00:07<06:57,  1.49s/it]Loading train:   2%|▏         | 6/285 [00:08<06:37,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<06:50,  1.48s/it]Loading train:   3%|▎         | 8/285 [00:11<06:42,  1.45s/it]Loading train:   3%|▎         | 9/285 [00:13<06:59,  1.52s/it]Loading train:   4%|▎         | 10/285 [00:14<06:21,  1.39s/it]Loading train:   4%|▍         | 11/285 [00:15<05:37,  1.23s/it]Loading train:   4%|▍         | 12/285 [00:16<05:15,  1.15s/it]Loading train:   5%|▍         | 13/285 [00:17<05:01,  1.11s/it]Loading train:   5%|▍         | 14/285 [00:18<05:00,  1.11s/it]Loading train:   5%|▌         | 15/285 [00:19<05:02,  1.12s/it]Loading train:   6%|▌         | 16/285 [00:20<05:04,  1.13s/it]Loading train:   6%|▌         | 17/285 [00:21<04:47,  1.07s/it]Loading train:   6%|▋         | 18/285 [00:22<04:42,  1.06s/it]Loading train:   7%|▋         | 19/285 [00:23<04:36,  1.04s/it]Loading train:   7%|▋         | 20/285 [00:24<04:30,  1.02s/it]Loading train:   7%|▋         | 21/285 [00:25<04:48,  1.09s/it]Loading train:   8%|▊         | 22/285 [00:26<04:32,  1.04s/it]Loading train:   8%|▊         | 23/285 [00:27<04:36,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:28<04:31,  1.04s/it]Loading train:   9%|▉         | 25/285 [00:29<04:41,  1.08s/it]Loading train:   9%|▉         | 26/285 [00:31<04:46,  1.11s/it]Loading train:   9%|▉         | 27/285 [00:32<04:35,  1.07s/it]Loading train:  10%|▉         | 28/285 [00:33<04:39,  1.09s/it]Loading train:  10%|█         | 29/285 [00:34<04:54,  1.15s/it]Loading train:  11%|█         | 30/285 [00:35<05:06,  1.20s/it]Loading train:  11%|█         | 31/285 [00:37<05:28,  1.29s/it]Loading train:  11%|█         | 32/285 [00:38<05:14,  1.24s/it]Loading train:  12%|█▏        | 33/285 [00:39<05:25,  1.29s/it]Loading train:  12%|█▏        | 34/285 [00:41<05:19,  1.27s/it]Loading train:  12%|█▏        | 35/285 [00:42<05:16,  1.27s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:57,  1.20s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:46,  1.16s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:55,  1.20s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:41,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:33,  1.11s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:11,  1.03s/it]Loading train:  15%|█▍        | 42/285 [00:49<03:55,  1.03it/s]Loading train:  15%|█▌        | 43/285 [00:50<03:52,  1.04it/s]Loading train:  15%|█▌        | 44/285 [00:51<04:00,  1.00it/s]Loading train:  16%|█▌        | 45/285 [00:52<03:59,  1.00it/s]Loading train:  16%|█▌        | 46/285 [00:53<04:24,  1.11s/it]Loading train:  16%|█▋        | 47/285 [00:54<04:20,  1.09s/it]Loading train:  17%|█▋        | 48/285 [00:56<04:22,  1.11s/it]Loading train:  17%|█▋        | 49/285 [00:57<04:30,  1.15s/it]Loading train:  18%|█▊        | 50/285 [00:58<04:22,  1.12s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:27,  1.14s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:24,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:01<04:17,  1.11s/it]Loading train:  19%|█▉        | 54/285 [01:03<04:32,  1.18s/it]Loading train:  19%|█▉        | 55/285 [01:04<04:17,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:05<04:16,  1.12s/it]Loading train:  20%|██        | 57/285 [01:06<04:03,  1.07s/it]Loading train:  20%|██        | 58/285 [01:07<04:03,  1.07s/it]Loading train:  21%|██        | 59/285 [01:08<04:09,  1.10s/it]Loading train:  21%|██        | 60/285 [01:09<04:10,  1.11s/it]Loading train:  21%|██▏       | 61/285 [01:10<03:55,  1.05s/it]Loading train:  22%|██▏       | 62/285 [01:11<03:59,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:12<03:56,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:20,  1.18s/it]Loading train:  23%|██▎       | 65/285 [01:15<04:50,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:17<04:55,  1.35s/it]Loading train:  24%|██▎       | 67/285 [01:18<04:30,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:20,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:18,  1.20s/it]Loading train:  25%|██▍       | 70/285 [01:21<04:12,  1.18s/it]Loading train:  25%|██▍       | 71/285 [01:22<04:06,  1.15s/it]Loading train:  25%|██▌       | 72/285 [01:23<03:51,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:24<03:58,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:25<03:51,  1.10s/it]Loading train:  26%|██▋       | 75/285 [01:26<03:55,  1.12s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:48,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:28<03:39,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:29<03:34,  1.04s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:33,  1.03s/it]Loading train:  28%|██▊       | 80/285 [01:32<03:52,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:33<04:03,  1.20s/it]Loading train:  29%|██▉       | 82/285 [01:34<04:01,  1.19s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:54,  1.16s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:42,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:38<03:41,  1.11s/it]Loading train:  30%|███       | 86/285 [01:39<03:36,  1.09s/it]Loading train:  31%|███       | 87/285 [01:40<03:29,  1.06s/it]Loading train:  31%|███       | 88/285 [01:41<03:20,  1.02s/it]Loading train:  31%|███       | 89/285 [01:42<03:24,  1.04s/it]Loading train:  32%|███▏      | 90/285 [01:43<03:19,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:44<03:16,  1.02s/it]Loading train:  32%|███▏      | 92/285 [01:45<03:16,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:46<03:13,  1.01s/it]Loading train:  33%|███▎      | 94/285 [01:47<03:15,  1.02s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:11,  1.01s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:16,  1.04s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:16,  1.05s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:25,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:19,  1.07s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:18,  1.07s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:14,  1.05s/it]Loading train:  36%|███▌      | 102/285 [01:55<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:56<03:05,  1.02s/it]Loading train:  36%|███▋      | 104/285 [01:57<03:11,  1.06s/it]Loading train:  37%|███▋      | 105/285 [01:58<03:13,  1.08s/it]Loading train:  37%|███▋      | 106/285 [01:59<03:09,  1.06s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:11,  1.07s/it]Loading train:  38%|███▊      | 108/285 [02:01<03:03,  1.04s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:05,  1.05s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:08,  1.08s/it]Loading train:  39%|███▉      | 111/285 [02:05<03:07,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:06<03:18,  1.15s/it]Loading train:  40%|███▉      | 113/285 [02:07<03:15,  1.14s/it]Loading train:  40%|████      | 114/285 [02:08<03:02,  1.07s/it]Loading train:  40%|████      | 115/285 [02:09<03:07,  1.10s/it]Loading train:  41%|████      | 116/285 [02:10<03:06,  1.10s/it]Loading train:  41%|████      | 117/285 [02:11<03:05,  1.10s/it]Loading train:  41%|████▏     | 118/285 [02:13<03:00,  1.08s/it]Loading train:  42%|████▏     | 119/285 [02:14<02:57,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:15<02:50,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:06,  1.13s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:18<03:11,  1.18s/it]Loading train:  44%|████▎     | 124/285 [02:19<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:48,  1.05s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:41,  1.01s/it]Loading train:  45%|████▍     | 127/285 [02:22<02:31,  1.04it/s]Loading train:  45%|████▍     | 128/285 [02:23<02:25,  1.08it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:20,  1.11it/s]Loading train:  46%|████▌     | 130/285 [02:24<02:17,  1.13it/s]Loading train:  46%|████▌     | 131/285 [02:25<02:15,  1.14it/s]Loading train:  46%|████▋     | 132/285 [02:26<02:13,  1.15it/s]Loading train:  47%|████▋     | 133/285 [02:27<02:15,  1.13it/s]Loading train:  47%|████▋     | 134/285 [02:28<02:13,  1.13it/s]Loading train:  47%|████▋     | 135/285 [02:29<02:08,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:08,  1.16it/s]Loading train:  48%|████▊     | 137/285 [02:31<02:07,  1.16it/s]Loading train:  48%|████▊     | 138/285 [02:31<02:08,  1.14it/s]Loading train:  49%|████▉     | 139/285 [02:32<02:08,  1.14it/s]Loading train:  49%|████▉     | 140/285 [02:33<02:09,  1.12it/s]Loading train:  49%|████▉     | 141/285 [02:34<02:05,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:35<02:04,  1.15it/s]Loading train:  50%|█████     | 143/285 [02:36<02:02,  1.16it/s]Loading train:  51%|█████     | 144/285 [02:37<02:02,  1.15it/s]Loading train:  51%|█████     | 145/285 [02:38<02:01,  1.15it/s]Loading train:  51%|█████     | 146/285 [02:38<02:01,  1.15it/s]Loading train:  52%|█████▏    | 147/285 [02:39<02:01,  1.14it/s]Loading train:  52%|█████▏    | 148/285 [02:40<02:02,  1.12it/s]Loading train:  52%|█████▏    | 149/285 [02:41<02:04,  1.09it/s]Loading train:  53%|█████▎    | 150/285 [02:42<01:58,  1.13it/s]Loading train:  53%|█████▎    | 151/285 [02:43<02:01,  1.10it/s]Loading train:  53%|█████▎    | 152/285 [02:44<01:59,  1.11it/s]Loading train:  54%|█████▎    | 153/285 [02:45<01:57,  1.13it/s]Loading train:  54%|█████▍    | 154/285 [02:46<01:53,  1.16it/s]Loading train:  54%|█████▍    | 155/285 [02:46<01:55,  1.12it/s]Loading train:  55%|█████▍    | 156/285 [02:47<01:56,  1.10it/s]Loading train:  55%|█████▌    | 157/285 [02:48<01:54,  1.12it/s]Loading train:  55%|█████▌    | 158/285 [02:49<01:55,  1.10it/s]Loading train:  56%|█████▌    | 159/285 [02:50<01:53,  1.11it/s]Loading train:  56%|█████▌    | 160/285 [02:51<01:53,  1.10it/s]Loading train:  56%|█████▋    | 161/285 [02:52<01:55,  1.07it/s]Loading train:  57%|█████▋    | 162/285 [02:53<01:54,  1.08it/s]Loading train:  57%|█████▋    | 163/285 [02:54<01:51,  1.09it/s]Loading train:  58%|█████▊    | 164/285 [02:55<01:47,  1.12it/s]Loading train:  58%|█████▊    | 165/285 [02:56<01:44,  1.15it/s]Loading train:  58%|█████▊    | 166/285 [02:57<01:49,  1.09it/s]Loading train:  59%|█████▊    | 167/285 [02:57<01:48,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [02:58<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [02:59<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [03:00<01:38,  1.17it/s]Loading train:  60%|██████    | 171/285 [03:01<01:48,  1.05it/s]Loading train:  60%|██████    | 172/285 [03:02<01:48,  1.04it/s]Loading train:  61%|██████    | 173/285 [03:03<01:47,  1.05it/s]Loading train:  61%|██████    | 174/285 [03:04<01:41,  1.10it/s]Loading train:  61%|██████▏   | 175/285 [03:05<01:43,  1.06it/s]Loading train:  62%|██████▏   | 176/285 [03:06<01:39,  1.10it/s]Loading train:  62%|██████▏   | 177/285 [03:07<01:40,  1.08it/s]Loading train:  62%|██████▏   | 178/285 [03:08<01:47,  1.00s/it]Loading train:  63%|██████▎   | 179/285 [03:09<01:44,  1.01it/s]Loading train:  63%|██████▎   | 180/285 [03:10<01:43,  1.02it/s]Loading train:  64%|██████▎   | 181/285 [03:11<01:42,  1.01it/s]Loading train:  64%|██████▍   | 182/285 [03:12<01:40,  1.02it/s]Loading train:  64%|██████▍   | 183/285 [03:13<01:35,  1.07it/s]Loading train:  65%|██████▍   | 184/285 [03:13<01:29,  1.13it/s]Loading train:  65%|██████▍   | 185/285 [03:14<01:25,  1.16it/s]Loading train:  65%|██████▌   | 186/285 [03:15<01:30,  1.09it/s]Loading train:  66%|██████▌   | 187/285 [03:16<01:37,  1.00it/s]Loading train:  66%|██████▌   | 188/285 [03:18<01:40,  1.03s/it]Loading train:  66%|██████▋   | 189/285 [03:18<01:35,  1.01it/s]Loading train:  67%|██████▋   | 190/285 [03:19<01:28,  1.08it/s]Loading train:  67%|██████▋   | 191/285 [03:20<01:26,  1.08it/s]Loading train:  67%|██████▋   | 192/285 [03:21<01:25,  1.09it/s]Loading train:  68%|██████▊   | 193/285 [03:22<01:26,  1.06it/s]Loading train:  68%|██████▊   | 194/285 [03:23<01:25,  1.07it/s]Loading train:  68%|██████▊   | 195/285 [03:24<01:23,  1.08it/s]Loading train:  69%|██████▉   | 196/285 [03:25<01:30,  1.01s/it]Loading train:  69%|██████▉   | 197/285 [03:26<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [03:27<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [03:28<01:24,  1.02it/s]Loading train:  70%|███████   | 200/285 [03:29<01:20,  1.06it/s]Loading train:  71%|███████   | 201/285 [03:30<01:24,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:31<01:23,  1.01s/it]Loading train:  71%|███████   | 203/285 [03:32<01:21,  1.01it/s]Loading train:  72%|███████▏  | 204/285 [03:33<01:17,  1.05it/s]Loading train:  72%|███████▏  | 205/285 [03:34<01:13,  1.09it/s]Loading train:  72%|███████▏  | 206/285 [03:35<01:09,  1.14it/s]Loading train:  73%|███████▎  | 207/285 [03:36<01:13,  1.06it/s]Loading train:  73%|███████▎  | 208/285 [03:37<01:14,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [03:38<01:13,  1.03it/s]Loading train:  74%|███████▎  | 210/285 [03:38<01:09,  1.08it/s]Loading train:  74%|███████▍  | 211/285 [03:39<01:06,  1.11it/s]Loading train:  74%|███████▍  | 212/285 [03:40<01:06,  1.09it/s]Loading train:  75%|███████▍  | 213/285 [03:41<01:07,  1.07it/s]Loading train:  75%|███████▌  | 214/285 [03:42<01:05,  1.09it/s]Loading train:  75%|███████▌  | 215/285 [03:43<01:09,  1.01it/s]Loading train:  76%|███████▌  | 216/285 [03:44<01:06,  1.03it/s]Loading train:  76%|███████▌  | 217/285 [03:45<01:06,  1.02it/s]Loading train:  76%|███████▋  | 218/285 [03:46<01:06,  1.00it/s]Loading train:  77%|███████▋  | 219/285 [03:47<01:07,  1.03s/it]Loading train:  77%|███████▋  | 220/285 [03:48<01:03,  1.03it/s]Loading train:  78%|███████▊  | 221/285 [03:49<01:00,  1.06it/s]Loading train:  78%|███████▊  | 222/285 [03:50<01:03,  1.01s/it]Loading train:  78%|███████▊  | 223/285 [03:51<01:00,  1.03it/s]Loading train:  79%|███████▊  | 224/285 [03:52<00:55,  1.10it/s]Loading train:  79%|███████▉  | 225/285 [03:53<00:54,  1.11it/s]Loading train:  79%|███████▉  | 226/285 [03:54<00:57,  1.03it/s]Loading train:  80%|███████▉  | 227/285 [03:55<00:58,  1.00s/it]Loading train:  80%|████████  | 228/285 [03:56<00:57,  1.02s/it]Loading train:  80%|████████  | 229/285 [03:57<00:55,  1.02it/s]Loading train:  81%|████████  | 230/285 [03:58<00:54,  1.01it/s]Loading train:  81%|████████  | 231/285 [03:59<00:50,  1.07it/s]Loading train:  81%|████████▏ | 232/285 [04:00<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [04:01<00:47,  1.09it/s]Loading train:  82%|████████▏ | 234/285 [04:02<00:49,  1.02it/s]Loading train:  82%|████████▏ | 235/285 [04:03<00:46,  1.07it/s]Loading train:  83%|████████▎ | 236/285 [04:04<00:47,  1.04it/s]Loading train:  83%|████████▎ | 237/285 [04:05<00:48,  1.01s/it]Loading train:  84%|████████▎ | 238/285 [04:06<00:47,  1.01s/it]Loading train:  84%|████████▍ | 239/285 [04:07<00:45,  1.01it/s]Loading train:  84%|████████▍ | 240/285 [04:08<00:44,  1.01it/s]Loading train:  85%|████████▍ | 241/285 [04:08<00:40,  1.07it/s]Loading train:  85%|████████▍ | 242/285 [04:09<00:39,  1.09it/s]Loading train:  85%|████████▌ | 243/285 [04:10<00:38,  1.09it/s]Loading train:  86%|████████▌ | 244/285 [04:11<00:39,  1.04it/s]Loading train:  86%|████████▌ | 245/285 [04:12<00:37,  1.06it/s]Loading train:  86%|████████▋ | 246/285 [04:13<00:38,  1.01it/s]Loading train:  87%|████████▋ | 247/285 [04:14<00:37,  1.01it/s]Loading train:  87%|████████▋ | 248/285 [04:15<00:36,  1.02it/s]Loading train:  87%|████████▋ | 249/285 [04:16<00:33,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [04:17<00:33,  1.04it/s]Loading train:  88%|████████▊ | 251/285 [04:18<00:31,  1.07it/s]Loading train:  88%|████████▊ | 252/285 [04:19<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:20<00:34,  1.07s/it]Loading train:  89%|████████▉ | 254/285 [04:22<00:34,  1.13s/it]Loading train:  89%|████████▉ | 255/285 [04:23<00:31,  1.07s/it]Loading train:  90%|████████▉ | 256/285 [04:23<00:30,  1.04s/it]Loading train:  90%|█████████ | 257/285 [04:25<00:29,  1.04s/it]Loading train:  91%|█████████ | 258/285 [04:26<00:27,  1.03s/it]Loading train:  91%|█████████ | 259/285 [04:27<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [04:27<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [04:28<00:22,  1.06it/s]Loading train:  92%|█████████▏| 262/285 [04:29<00:20,  1.10it/s]Loading train:  92%|█████████▏| 263/285 [04:30<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:31<00:20,  1.01it/s]Loading train:  93%|█████████▎| 265/285 [04:32<00:20,  1.01s/it]Loading train:  93%|█████████▎| 266/285 [04:33<00:18,  1.05it/s]Loading train:  94%|█████████▎| 267/285 [04:34<00:16,  1.08it/s]Loading train:  94%|█████████▍| 268/285 [04:35<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [04:36<00:15,  1.03it/s]Loading train:  95%|█████████▍| 270/285 [04:37<00:13,  1.10it/s]Loading train:  95%|█████████▌| 271/285 [04:38<00:13,  1.05it/s]Loading train:  95%|█████████▌| 272/285 [04:39<00:12,  1.04it/s]Loading train:  96%|█████████▌| 273/285 [04:40<00:11,  1.06it/s]Loading train:  96%|█████████▌| 274/285 [04:41<00:10,  1.03it/s]Loading train:  96%|█████████▋| 275/285 [04:42<00:10,  1.03s/it]Loading train:  97%|█████████▋| 276/285 [04:43<00:09,  1.07s/it]Loading train:  97%|█████████▋| 277/285 [04:44<00:08,  1.04s/it]Loading train:  98%|█████████▊| 278/285 [04:45<00:06,  1.00it/s]Loading train:  98%|█████████▊| 279/285 [04:46<00:05,  1.03it/s]Loading train:  98%|█████████▊| 280/285 [04:47<00:04,  1.03it/s]Loading train:  99%|█████████▊| 281/285 [04:48<00:03,  1.05it/s]Loading train:  99%|█████████▉| 282/285 [04:49<00:02,  1.04it/s]Loading train:  99%|█████████▉| 283/285 [04:50<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [04:51<00:01,  1.06s/it]Loading train: 100%|██████████| 285/285 [04:52<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:01, 188.49it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:01, 207.51it/s]concatenating: train:  26%|██▋       | 75/285 [00:00<00:00, 223.98it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:00, 235.59it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 176.97it/s]concatenating: train:  49%|████▉     | 140/285 [00:00<00:00, 159.17it/s]concatenating: train:  58%|█████▊    | 164/285 [00:00<00:00, 175.50it/s]concatenating: train:  66%|██████▌   | 188/285 [00:00<00:00, 189.11it/s]concatenating: train:  73%|███████▎  | 208/285 [00:01<00:00, 165.70it/s]concatenating: train:  79%|███████▉  | 226/285 [00:01<00:00, 163.60it/s]concatenating: train:  86%|████████▌ | 244/285 [00:01<00:00, 145.63it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 157.83it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 187.94it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 90.23it/s]2019-07-10 22:32:01.644619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:32:01.644702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:32:01.644717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:32:01.644726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:32:01.645119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.07it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.16it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.02it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.71it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.20it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.32it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.56it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  7.90it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.79it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.29it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.62it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.96it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.82it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.92it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.22it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.01it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.42it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 227,713
Trainable params: 52,993
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 16s - loss: 2.1698 - acc: 0.6856 - mDice: 0.1754 - val_loss: 0.9456 - val_acc: 0.9147 - val_mDice: 0.3783

Epoch 00001: val_mDice improved from -inf to 0.37833, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.8601 - acc: 0.8934 - mDice: 0.4082 - val_loss: 0.6641 - val_acc: 0.9186 - val_mDice: 0.5050

Epoch 00002: val_mDice improved from 0.37833 to 0.50497, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.6827 - acc: 0.8972 - mDice: 0.4900 - val_loss: 0.6363 - val_acc: 0.9233 - val_mDice: 0.5209

Epoch 00003: val_mDice improved from 0.50497 to 0.52086, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5989 - acc: 0.8991 - mDice: 0.5343 - val_loss: 0.6174 - val_acc: 0.9257 - val_mDice: 0.5340

Epoch 00004: val_mDice improved from 0.52086 to 0.53405, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5490 - acc: 0.9005 - mDice: 0.5630 - val_loss: 0.5712 - val_acc: 0.9252 - val_mDice: 0.5571

Epoch 00005: val_mDice improved from 0.53405 to 0.55713, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.5152 - acc: 0.9021 - mDice: 0.5833 - val_loss: 0.5663 - val_acc: 0.9280 - val_mDice: 0.5671

Epoch 00006: val_mDice improved from 0.55713 to 0.56708, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4810 - acc: 0.9050 - mDice: 0.6040 - val_loss: 0.5281 - val_acc: 0.9305 - val_mDice: 0.5800

Epoch 00007: val_mDice improved from 0.56708 to 0.58004, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4618 - acc: 0.9095 - mDice: 0.6162 - val_loss: 0.5226 - val_acc: 0.9334 - val_mDice: 0.5844

Epoch 00008: val_mDice improved from 0.58004 to 0.58436, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4422 - acc: 0.9155 - mDice: 0.6285 - val_loss: 0.5482 - val_acc: 0.9364 - val_mDice: 0.5726

Epoch 00009: val_mDice did not improve from 0.58436
Epoch 10/300
 - 12s - loss: 0.4274 - acc: 0.9212 - mDice: 0.6378 - val_loss: 0.5028 - val_acc: 0.9382 - val_mDice: 0.5969

Epoch 00010: val_mDice improved from 0.58436 to 0.59687, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 11s - loss: 0.4150 - acc: 0.9262 - mDice: 0.6458 - val_loss: 0.5187 - val_acc: 0.9350 - val_mDice: 0.5843

Epoch 00011: val_mDice did not improve from 0.59687
Epoch 12/300
 - 11s - loss: 0.4037 - acc: 0.9312 - mDice: 0.6534 - val_loss: 0.5460 - val_acc: 0.9418 - val_mDice: 0.5753

Epoch 00012: val_mDice did not improve from 0.59687
Epoch 13/300
 - 11s - loss: 0.3953 - acc: 0.9363 - mDice: 0.6590 - val_loss: 0.5297 - val_acc: 0.9472 - val_mDice: 0.5858

Epoch 00013: val_mDice did not improve from 0.59687
Epoch 14/300
 - 11s - loss: 0.3846 - acc: 0.9406 - mDice: 0.6662 - val_loss: 0.5629 - val_acc: 0.9373 - val_mDice: 0.5633

Epoch 00014: val_mDice did not improve from 0.59687
Epoch 15/300
 - 11s - loss: 0.3813 - acc: 0.9422 - mDice: 0.6684 - val_loss: 0.5165 - val_acc: 0.9429 - val_mDice: 0.5896

Epoch 00015: val_mDice did not improve from 0.59687
Epoch 16/300
 - 11s - loss: 0.3734 - acc: 0.9432 - mDice: 0.6736 - val_loss: 0.5217 - val_acc: 0.9449 - val_mDice: 0.5931

Epoch 00016: val_mDice did not improve from 0.59687
Epoch 17/300
 - 11s - loss: 0.3657 - acc: 0.9441 - mDice: 0.6792 - val_loss: 0.5082 - val_acc: 0.9443 - val_mDice: 0.5942

Epoch 00017: val_mDice did not improve from 0.59687
Epoch 18/300
 - 12s - loss: 0.3595 - acc: 0.9447 - mDice: 0.6834 - val_loss: 0.5213 - val_acc: 0.9463 - val_mDice: 0.5917

Epoch 00018: val_mDice did not improve from 0.59687
Epoch 19/300
 - 11s - loss: 0.3549 - acc: 0.9452 - mDice: 0.6867 - val_loss: 0.5327 - val_acc: 0.9391 - val_mDice: 0.5808

Epoch 00019: val_mDice did not improve from 0.59687
Epoch 20/300
 - 11s - loss: 0.3500 - acc: 0.9455 - mDice: 0.6902 - val_loss: 0.5400 - val_acc: 0.9361 - val_mDice: 0.5759

Epoch 00020: val_mDice did not improve from 0.59687
Epoch 21/300
 - 11s - loss: 0.3470 - acc: 0.9459 - mDice: 0.6923 - val_loss: 0.5222 - val_acc: 0.9455 - val_mDice: 0.5913

Epoch 00021: val_mDice did not improve from 0.59687
Epoch 22/300
 - 11s - loss: 0.3421 - acc: 0.9464 - mDice: 0.6957 - val_loss: 0.5084 - val_acc: 0.9459 - val_mDice: 0.5992

Epoch 00022: val_mDice improved from 0.59687 to 0.59917, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 11s - loss: 0.3384 - acc: 0.9467 - mDice: 0.6985 - val_loss: 0.4905 - val_acc: 0.9463 - val_mDice: 0.6035

Epoch 00023: val_mDice improved from 0.59917 to 0.60354, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 11s - loss: 0.3343 - acc: 0.9470 - mDice: 0.7014 - val_loss: 0.5106 - val_acc: 0.9462 - val_mDice: 0.5985

Epoch 00024: val_mDice did not improve from 0.60354
Epoch 25/300
 - 11s - loss: 0.3327 - acc: 0.9472 - mDice: 0.7028 - val_loss: 0.5091 - val_acc: 0.9493 - val_mDice: 0.5991

Epoch 00025: val_mDice did not improve from 0.60354
Epoch 26/300
 - 12s - loss: 0.3287 - acc: 0.9476 - mDice: 0.7056 - val_loss: 0.5137 - val_acc: 0.9471 - val_mDice: 0.5956

Epoch 00026: val_mDice did not improve from 0.60354
Epoch 27/300
 - 12s - loss: 0.3249 - acc: 0.9479 - mDice: 0.7085 - val_loss: 0.5023 - val_acc: 0.9463 - val_mDice: 0.6035

Epoch 00027: val_mDice improved from 0.60354 to 0.60354, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 11s - loss: 0.3214 - acc: 0.9482 - mDice: 0.7109 - val_loss: 0.4873 - val_acc: 0.9470 - val_mDice: 0.6101

Epoch 00028: val_mDice improved from 0.60354 to 0.61009, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 11s - loss: 0.3213 - acc: 0.9484 - mDice: 0.7119 - val_loss: 0.5875 - val_acc: 0.9444 - val_mDice: 0.5521

Epoch 00029: val_mDice did not improve from 0.61009
Epoch 30/300
 - 11s - loss: 0.3948 - acc: 0.9422 - mDice: 0.6622 - val_loss: 0.4880 - val_acc: 0.9502 - val_mDice: 0.6112

Epoch 00030: val_mDice improved from 0.61009 to 0.61118, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 11s - loss: 0.3331 - acc: 0.9475 - mDice: 0.7024 - val_loss: 0.4763 - val_acc: 0.9502 - val_mDice: 0.6184

Epoch 00031: val_mDice improved from 0.61118 to 0.61845, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 12s - loss: 0.3213 - acc: 0.9483 - mDice: 0.7110 - val_loss: 0.4959 - val_acc: 0.9461 - val_mDice: 0.6049

Epoch 00032: val_mDice did not improve from 0.61845
Epoch 33/300
 - 11s - loss: 0.3202 - acc: 0.9484 - mDice: 0.7119 - val_loss: 0.5135 - val_acc: 0.9488 - val_mDice: 0.6007

Epoch 00033: val_mDice did not improve from 0.61845
Epoch 34/300
 - 12s - loss: 0.3135 - acc: 0.9488 - mDice: 0.7167 - val_loss: 0.5141 - val_acc: 0.9480 - val_mDice: 0.6010

Epoch 00034: val_mDice did not improve from 0.61845
Epoch 35/300
 - 12s - loss: 0.3116 - acc: 0.9491 - mDice: 0.7183 - val_loss: 0.5061 - val_acc: 0.9456 - val_mDice: 0.6006

Epoch 00035: val_mDice did not improve from 0.61845
Epoch 36/300
 - 11s - loss: 0.3076 - acc: 0.9493 - mDice: 0.7213 - val_loss: 0.4951 - val_acc: 0.9494 - val_mDice: 0.6109

Epoch 00036: val_mDice did not improve from 0.61845
Epoch 37/300
 - 11s - loss: 0.3068 - acc: 0.9493 - mDice: 0.7219 - val_loss: 0.5049 - val_acc: 0.9486 - val_mDice: 0.6039

Epoch 00037: val_mDice did not improve from 0.61845
Epoch 38/300
 - 11s - loss: 0.3053 - acc: 0.9494 - mDice: 0.7230 - val_loss: 0.5462 - val_acc: 0.9444 - val_mDice: 0.5846

Epoch 00038: val_mDice did not improve from 0.61845
Epoch 39/300
 - 11s - loss: 0.3031 - acc: 0.9497 - mDice: 0.7249 - val_loss: 0.4879 - val_acc: 0.9484 - val_mDice: 0.6108

Epoch 00039: val_mDice did not improve from 0.61845
Epoch 40/300
 - 12s - loss: 0.3038 - acc: 0.9497 - mDice: 0.7244 - val_loss: 0.5312 - val_acc: 0.9475 - val_mDice: 0.5923

Epoch 00040: val_mDice did not improve from 0.61845
Epoch 41/300
 - 11s - loss: 0.3005 - acc: 0.9499 - mDice: 0.7268 - val_loss: 0.5056 - val_acc: 0.9481 - val_mDice: 0.6041

Epoch 00041: val_mDice did not improve from 0.61845
Epoch 42/300
 - 11s - loss: 0.2964 - acc: 0.9501 - mDice: 0.7298 - val_loss: 0.5425 - val_acc: 0.9479 - val_mDice: 0.5820

Epoch 00042: val_mDice did not improve from 0.61845
Epoch 43/300
 - 11s - loss: 0.2971 - acc: 0.9501 - mDice: 0.7293 - val_loss: 0.5200 - val_acc: 0.9508 - val_mDice: 0.5993

Epoch 00043: val_mDice did not improve from 0.61845
Epoch 44/300
 - 11s - loss: 0.2948 - acc: 0.9504 - mDice: 0.7309 - val_loss: 0.5146 - val_acc: 0.9493 - val_mDice: 0.6028

Epoch 00044: val_mDice did not improve from 0.61845
Epoch 45/300
 - 11s - loss: 0.2939 - acc: 0.9503 - mDice: 0.7316 - val_loss: 0.5295 - val_acc: 0.9464 - val_mDice: 0.5895

Epoch 00045: val_mDice did not improve from 0.61845
Epoch 46/300
 - 12s - loss: 0.2922 - acc: 0.9505 - mDice: 0.7329 - val_loss: 0.5178 - val_acc: 0.9489 - val_mDice: 0.6010

Epoch 00046: val_mDice did not improve from 0.61845
Epoch 47/300
 - 12s - loss: 0.2912 - acc: 0.9506 - mDice: 0.7338 - val_loss: 0.5587 - val_acc: 0.9486 - val_mDice: 0.5889

Epoch 00047: val_mDice did not improve from 0.61845
Epoch 48/300
 - 11s - loss: 0.2932 - acc: 0.9504 - mDice: 0.7325 - val_loss: 0.5289 - val_acc: 0.9468 - val_mDice: 0.6017

Epoch 00048: val_mDice did not improve from 0.61845
Epoch 49/300
 - 11s - loss: 0.2922 - acc: 0.9505 - mDice: 0.7331 - val_loss: 0.5322 - val_acc: 0.9448 - val_mDice: 0.5864

Epoch 00049: val_mDice did not improve from 0.61845
Epoch 50/300
 - 11s - loss: 0.2873 - acc: 0.9508 - mDice: 0.7368 - val_loss: 0.5182 - val_acc: 0.9478 - val_mDice: 0.5967

Epoch 00050: val_mDice did not improve from 0.61845
Epoch 51/300
 - 11s - loss: 0.2855 - acc: 0.9508 - mDice: 0.7382 - val_loss: 0.5491 - val_acc: 0.9492 - val_mDice: 0.5842

Epoch 00051: val_mDice did not improve from 0.61845
Epoch 52/300
 - 11s - loss: 0.2847 - acc: 0.9509 - mDice: 0.7388 - val_loss: 0.4930 - val_acc: 0.9493 - val_mDice: 0.6133

Epoch 00052: val_mDice did not improve from 0.61845
Epoch 53/300
 - 11s - loss: 0.2841 - acc: 0.9510 - mDice: 0.7393 - val_loss: 0.4934 - val_acc: 0.9494 - val_mDice: 0.6092

Epoch 00053: val_mDice did not improve from 0.61845
Epoch 54/300
 - 12s - loss: 0.2834 - acc: 0.9510 - mDice: 0.7399 - val_loss: 0.4883 - val_acc: 0.9500 - val_mDice: 0.6134

Epoch 00054: val_mDice did not improve from 0.61845
Epoch 55/300
 - 12s - loss: 0.2840 - acc: 0.9510 - mDice: 0.7394 - val_loss: 0.5075 - val_acc: 0.9469 - val_mDice: 0.6015

Epoch 00055: val_mDice did not improve from 0.61845
Epoch 56/300
 - 11s - loss: 0.2816 - acc: 0.9511 - mDice: 0.7413 - val_loss: 0.4951 - val_acc: 0.9521 - val_mDice: 0.6082

Epoch 00056: val_mDice did not improve from 0.61845
Epoch 57/300
 - 11s - loss: 0.2825 - acc: 0.9511 - mDice: 0.7408 - val_loss: 0.5202 - val_acc: 0.9443 - val_mDice: 0.5929

Epoch 00057: val_mDice did not improve from 0.61845
Epoch 58/300
 - 11s - loss: 0.2802 - acc: 0.9512 - mDice: 0.7424 - val_loss: 0.5480 - val_acc: 0.9468 - val_mDice: 0.5853

Epoch 00058: val_mDice did not improve from 0.61845
Epoch 59/300
 - 11s - loss: 0.2772 - acc: 0.9514 - mDice: 0.7446 - val_loss: 0.5349 - val_acc: 0.9472 - val_mDice: 0.5869

Epoch 00059: val_mDice did not improve from 0.61845
Epoch 60/300
 - 12s - loss: 0.2775 - acc: 0.9514 - mDice: 0.7445 - val_loss: 0.5214 - val_acc: 0.9514 - val_mDice: 0.5969

Epoch 00060: val_mDice did not improve from 0.61845
Epoch 61/300
 - 11s - loss: 0.2777 - acc: 0.9515 - mDice: 0.7443 - val_loss: 0.4807 - val_acc: 0.9476 - val_mDice: 0.6138

Epoch 00061: val_mDice did not improve from 0.61845
Epoch 62/300
 - 11s - loss: 0.2749 - acc: 0.9517 - mDice: 0.7464 - val_loss: 0.5750 - val_acc: 0.9498 - val_mDice: 0.5841

Epoch 00062: val_mDice did not improve from 0.61845
Epoch 63/300
 - 11s - loss: 0.2781 - acc: 0.9516 - mDice: 0.7440 - val_loss: 0.5250 - val_acc: 0.9496 - val_mDice: 0.5983

Epoch 00063: val_mDice did not improve from 0.61845
Epoch 64/300
 - 11s - loss: 0.2744 - acc: 0.9518 - mDice: 0.7469 - val_loss: 0.5090 - val_acc: 0.9518 - val_mDice: 0.6033

Epoch 00064: val_mDice did not improve from 0.61845
Epoch 65/300
 - 11s - loss: 0.2741 - acc: 0.9519 - mDice: 0.7471 - val_loss: 0.5141 - val_acc: 0.9512 - val_mDice: 0.6015

Epoch 00065: val_mDice did not improve from 0.61845
Epoch 66/300
 - 12s - loss: 0.2726 - acc: 0.9521 - mDice: 0.7483 - val_loss: 0.5036 - val_acc: 0.9508 - val_mDice: 0.6047

Epoch 00066: val_mDice did not improve from 0.61845
Epoch 67/300
 - 11s - loss: 0.2731 - acc: 0.9521 - mDice: 0.7479 - val_loss: 0.4955 - val_acc: 0.9505 - val_mDice: 0.6086

Epoch 00067: val_mDice did not improve from 0.61845
Epoch 68/300
 - 11s - loss: 0.2715 - acc: 0.9522 - mDice: 0.7490 - val_loss: 0.5122 - val_acc: 0.9466 - val_mDice: 0.5985

Epoch 00068: val_mDice did not improve from 0.61845
Epoch 69/300
 - 12s - loss: 0.2701 - acc: 0.9524 - mDice: 0.7502 - val_loss: 0.5117 - val_acc: 0.9478 - val_mDice: 0.5981

Epoch 00069: val_mDice did not improve from 0.61845
Epoch 70/300
 - 12s - loss: 0.2694 - acc: 0.9525 - mDice: 0.7508 - val_loss: 0.5143 - val_acc: 0.9480 - val_mDice: 0.5981

Epoch 00070: val_mDice did not improve from 0.61845
Epoch 71/300
 - 12s - loss: 0.2698 - acc: 0.9524 - mDice: 0.7505 - val_loss: 0.5399 - val_acc: 0.9481 - val_mDice: 0.5855

Epoch 00071: val_mDice did not improve from 0.61845
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
{'val_loss': [0.9455654667742426, 0.6641462218828041, 0.6362670823182474, 0.6174001930146243, 0.5712023107699176, 0.5663183264892194, 0.5280938657968404, 0.5226354692235339, 0.5482384675707896, 0.5027592571754029, 0.5186906004085221, 0.5460179641260116, 0.5296632028158816, 0.5628632453566823, 0.5164938262721014, 0.5217141422479512, 0.5082269830410707, 0.5212608885498686, 0.5326755333213167, 0.5399540336438398, 0.5221582624499358, 0.5083745541519293, 0.490490614035942, 0.5105768795119984, 0.5090880683680487, 0.513720270974676, 0.5023075348838082, 0.487268204129608, 0.5874991213809179, 0.4880479321133491, 0.47634818334153245, 0.49587781569145245, 0.5135184389918876, 0.5140795208222373, 0.5061229001210389, 0.4950893577916662, 0.5049097228316621, 0.5462324369553081, 0.48787944643191117, 0.5311832684378385, 0.5055808914440304, 0.542474536589404, 0.5199929086189696, 0.5146232756822469, 0.5294555135945368, 0.5177710579094275, 0.5587228676460309, 0.5289183472121894, 0.5321525435207942, 0.5182034210119834, 0.5490838199354416, 0.4929807169477367, 0.49342494204057663, 0.48830062084357834, 0.5074534386229914, 0.49507545725593355, 0.5201660977395554, 0.5479769393718442, 0.5349408038501633, 0.5214067381187524, 0.48072029092458374, 0.5749895902319327, 0.5249533443477566, 0.5089698883408275, 0.5140808254646856, 0.5035871247339515, 0.4955394491137073, 0.5122332796038196, 0.5117016115002126, 0.5143318386051242, 0.5398705085562594], 'val_acc': [0.9146825900956905, 0.9185770533604329, 0.9233248660018324, 0.9256636180691213, 0.9252318277039342, 0.9279837701573718, 0.9304527074265081, 0.9334484745004323, 0.9364194537008275, 0.9382210490423873, 0.9349670243662829, 0.9417932606276187, 0.9471980320008774, 0.9372934066383533, 0.942888247900169, 0.9449212471200101, 0.9443468771167307, 0.9462724504524103, 0.9390660531028023, 0.9360827001113465, 0.9455266068767569, 0.9459232774526714, 0.9463137571372133, 0.9462001143887057, 0.949346714179609, 0.947140188523511, 0.9462931092890947, 0.9469562965398394, 0.9444047352455182, 0.9501710727228133, 0.9501752147461449, 0.9460699758050162, 0.9488054074388642, 0.9479934606472207, 0.9455637855236757, 0.9494272906687007, 0.9485905443489885, 0.9444274672582829, 0.9484417814782212, 0.9475120515796726, 0.9480678159431373, 0.9478839699116499, 0.9508197860344828, 0.9493178042619588, 0.9463695447538152, 0.9489397020313327, 0.9486380475859403, 0.9468447153128725, 0.944751826411519, 0.9478446947795719, 0.9491607846494493, 0.9492888540529006, 0.949396292923549, 0.9500471100460883, 0.9468819142719886, 0.9520511707114108, 0.9442518473337482, 0.9467682998273625, 0.9472083549259761, 0.9514024231020964, 0.9476484509819713, 0.9497619917272856, 0.9496318031955697, 0.9518259780366993, 0.9512040641720735, 0.9507970866544286, 0.9504665093048991, 0.9466257355066651, 0.9478157695445268, 0.9479727948178126, 0.9481153374943654], 'val_mDice': [0.3783344370026828, 0.5049668818545741, 0.5208592481453326, 0.5340467338455456, 0.5571250356109448, 0.5670841945616226, 0.5800438693115831, 0.5843637089489558, 0.572558243847426, 0.5968666749293577, 0.5842592110180987, 0.5752565234733027, 0.5857853986031516, 0.5632524137390392, 0.5895761760919453, 0.5930740167308786, 0.5941978852842107, 0.5917002169113585, 0.580783898270996, 0.5758839342847216, 0.5913170243108739, 0.5991679203576882, 0.6035435595991891, 0.5984886448476567, 0.5991006147262105, 0.5955614311069084, 0.6035439109003078, 0.6100915697033845, 0.5520811690298538, 0.6111802595287728, 0.6184462521995246, 0.6048621075779366, 0.6007241603382473, 0.6009793268235702, 0.6006118964882536, 0.6108921683034417, 0.6039458493280677, 0.5846174808853831, 0.6107671687056898, 0.5922509944638726, 0.6041193268152588, 0.58203118040575, 0.5993470526274356, 0.6028165657427058, 0.5895464979736499, 0.6010097937876951, 0.5889047956999454, 0.601669268235148, 0.5864189130633903, 0.5966970327846165, 0.5842111843258309, 0.6132704582294273, 0.609200094665229, 0.6133885090577536, 0.6014781540998534, 0.6081664325804684, 0.5928718927186295, 0.5853245518061035, 0.5868941951730398, 0.5969046261057508, 0.6137858848998, 0.5841303341215549, 0.5982848405838013, 0.6033484875822867, 0.6015208589964073, 0.6047193424661732, 0.608632416032546, 0.5984576131378472, 0.5980618316368018, 0.5981486433045158, 0.5855126434198304], 'loss': [2.1697847527178875, 0.860082941668582, 0.6826783637745721, 0.5988711875304762, 0.5490389986434512, 0.51519643424169, 0.4809678854145559, 0.4617745799586817, 0.44221834084689116, 0.42738228235477965, 0.41502433859128773, 0.4037006612641704, 0.3953226985744931, 0.3845532237006379, 0.3813154696801423, 0.37337595717650235, 0.3656854852356362, 0.35949365653527354, 0.3549498612211587, 0.3500284201117436, 0.3470247380971506, 0.34209844164875336, 0.3383618247229175, 0.33433516113776657, 0.3327494937281133, 0.32871270735671165, 0.32485966611405837, 0.32140581672484175, 0.32133130988656067, 0.3947652839191157, 0.3330977176874592, 0.32131459869646856, 0.3202258523146407, 0.31351714252282914, 0.31157032500963233, 0.30756215669284115, 0.30682893047002424, 0.30529361535089933, 0.30308457562869023, 0.3037677001709006, 0.3004711161907134, 0.29637953696002384, 0.2970666829507781, 0.2948223907770554, 0.2938574313189, 0.2922358055723356, 0.29122041439082935, 0.29319518212107076, 0.2921948067247007, 0.28734325889466955, 0.2855149369637539, 0.2846805631309337, 0.2840887460549032, 0.2833732305158815, 0.28400066034783855, 0.28159683551782355, 0.28251267692783183, 0.280185586202379, 0.27722353444666353, 0.2774589402221411, 0.27771281572275386, 0.27488878140307466, 0.27811439477289096, 0.27443173472206484, 0.2741407125508186, 0.272561336964747, 0.2730646980389239, 0.2715470022358839, 0.2701019331278037, 0.26939199960872595, 0.2698323767914062], 'acc': [0.6856035349083994, 0.8934039507489547, 0.8972338228065733, 0.899101704350939, 0.9004701174498189, 0.9021454262458176, 0.9050228140347794, 0.9095072094427138, 0.9155193212102307, 0.921208655471915, 0.9262401648586037, 0.9312328373702171, 0.9363379837329023, 0.9405841422551052, 0.9421781821582295, 0.9432326207707101, 0.9440550886430964, 0.944748650360819, 0.9452439360022318, 0.9455282785950789, 0.9458986633120393, 0.9463901582655515, 0.9467301334789925, 0.947027084848329, 0.9472440315853711, 0.9476314149490597, 0.9479319105694467, 0.9481888776393986, 0.9483728332071807, 0.9421754602117026, 0.947494030524674, 0.94828670863122, 0.948424898086761, 0.9488291441241833, 0.9490636769582955, 0.949310654749454, 0.9492860994374828, 0.9493817161010064, 0.9496714300621336, 0.9496639616238409, 0.9498647527006234, 0.9501061315312117, 0.9500833696467471, 0.9503505313281536, 0.9503084170546292, 0.9504963572680655, 0.9506041141975862, 0.9503766927484866, 0.9505006876927264, 0.9507556800248609, 0.9508161464097693, 0.9509404608577589, 0.9509560116417338, 0.9510490642245264, 0.95097387588191, 0.9511425242101462, 0.9511432095223487, 0.9511637716087912, 0.9513877107065933, 0.9514036831315076, 0.9514762750735931, 0.9516841562366533, 0.9516048991019855, 0.9518405592108492, 0.9518831572165956, 0.9520858647185638, 0.9520649747984594, 0.9522361194773844, 0.9523526001980307, 0.9524819097885878, 0.9523844643327628], 'mDice': [0.1754357333102148, 0.40815404627221996, 0.4900379754133418, 0.5342687171214897, 0.5629640311387414, 0.5833135247587619, 0.6039740211121832, 0.616201253051845, 0.6285433569515941, 0.6378074025518267, 0.6457761786425661, 0.6534368169703104, 0.6589654662284344, 0.6661622184604921, 0.6684222613847773, 0.6736186954893452, 0.6791638194505091, 0.683388590504288, 0.686704380928019, 0.6901654169473908, 0.6922599616266791, 0.6957274754123616, 0.6985093185236937, 0.701398053198337, 0.7027655585867459, 0.7055959944845538, 0.7084607835636895, 0.7109079944640098, 0.7119383711576215, 0.662217048464839, 0.7023580833773657, 0.7109724672120755, 0.711878405096588, 0.7166985087934633, 0.7182921213519631, 0.7212754924419003, 0.7218624699655282, 0.7230064474700758, 0.7248554587961509, 0.7243676600025913, 0.7267557797456098, 0.7297981021892634, 0.729258424699076, 0.7309357891265333, 0.7316255941317495, 0.7329311121082093, 0.7337554631705352, 0.7324509256533123, 0.7330524720213822, 0.7368383536079884, 0.7381796604615334, 0.7388057188266802, 0.7393252428700791, 0.7398647966613944, 0.7394442016941667, 0.7412522698557654, 0.7407575661330615, 0.7423942575371089, 0.7446112343314608, 0.7444891936248842, 0.7443008568511408, 0.7464421228816855, 0.7440367625381789, 0.7469156455269086, 0.7471139004116101, 0.7482549129024024, 0.7479022747875201, 0.7490319454048617, 0.7501976686679397, 0.7508217769863493, 0.7504786465053861]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.06s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:39,  2.04s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:49,  1.87s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:29,  1.81s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:57,  1.70s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:09,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:51,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:08,  1.76s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:54,  1.71s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:38,  1.88s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:02,  1.97s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:31,  1.87s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:54,  1.96s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:28,  1.87s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:29,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:38,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:47,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:26,  1.89s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:30,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:12,  1.85s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:21,  1.89s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:37,  1.96s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:13,  1.88s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:12,  1.88s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:01,  1.84s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:22,  1.93s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:29,  1.97s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:16,  1.92s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:11,  1.91s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:58,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:13,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:16,  1.96s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:03,  1.91s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:54,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:06,  1.95s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:40,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:55,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:30,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:34,  1.86s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:30,  1.85s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:14,  1.79s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:19,  1.82s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:34,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:20,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:37,  1.91s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:20,  1.85s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:17,  1.85s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:38,  1.94s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:30,  1.92s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:46,  2.00s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:20,  1.89s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:22,  1.91s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:39,  1.99s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:23,  1.93s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:17,  1.91s/it]predicting train subjects:  20%|██        | 57/285 [01:46<07:00,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:48<06:54,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:13,  1.92s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:17,  1.95s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:58,  1.87s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<06:48,  1.83s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<06:55,  1.87s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:45,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:48,  1.86s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:51,  1.88s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:58,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:45,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:43,  1.87s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:43,  1.88s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:44,  1.89s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:33,  1.85s/it]predicting train subjects:  26%|██▌       | 73/285 [02:16<06:35,  1.86s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:34,  1.87s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:26,  1.84s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:22,  1.83s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:25<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<06:09,  1.79s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:10,  1.81s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:03,  1.78s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:04,  1.79s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<05:58,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:51,  1.75s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<05:57,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:01,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:08,  1.86s/it]predicting train subjects:  31%|███       | 88/285 [02:43<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:45<06:05,  1.87s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<06:13,  1.92s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<06:09,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<06:12,  1.93s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<06:02,  1.89s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<06:00,  1.89s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<05:56,  1.87s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<05:56,  1.89s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<06:02,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<06:04,  1.95s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<06:01,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<06:02,  1.96s/it]predicting train subjects:  35%|███▌      | 101/285 [03:08<05:45,  1.88s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:12<05:32,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:14<05:31,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:28,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:22,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:22,  1.82s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:25,  1.85s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:26,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:26<05:18,  1.83s/it]predicting train subjects:  39%|███▉      | 112/285 [03:28<05:24,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:30<05:25,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:22,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:13,  1.85s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:37<04:59,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<04:51,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<04:53,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:43<04:57,  1.80s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:52,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:42,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [03:48<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:33,  1.70s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:20,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:13,  1.59s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:06,  1.56s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:09,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:07,  1.59s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:04,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [04:00<04:00,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:10,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:04,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [04:05<04:03,  1.61s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<03:54,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:08<03:48,  1.53s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:11<03:50,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:13<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:16<03:49,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:19<03:44,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:21<03:49,  1.62s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:45,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:47,  1.64s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:41,  1.61s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:40,  1.61s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:39,  1.61s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:31<03:35,  1.60s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:37,  1.62s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:34,  1.61s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:30,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:33,  1.63s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:32,  1.63s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:32,  1.65s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:26,  1.61s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:17,  1.56s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:47<03:10,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:16,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:50<03:10,  1.55s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:53<03:06,  1.54s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<03:02,  1.52s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:56<03:04,  1.55s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:58<03:07,  1.59s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:59<03:03,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:01<03:08,  1.63s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:02<03:03,  1.60s/it]predicting train subjects:  60%|██████    | 171/285 [05:04<03:04,  1.62s/it]predicting train subjects:  60%|██████    | 172/285 [05:06<03:03,  1.62s/it]predicting train subjects:  61%|██████    | 173/285 [05:07<02:57,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:09<02:54,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:11<02:57,  1.61s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:12<03:00,  1.66s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:14<02:53,  1.61s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:15<02:53,  1.62s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:17<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:19<02:54,  1.66s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:59,  1.72s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:22<03:00,  1.75s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:49,  1.66s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:25<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:27<02:34,  1.55s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:29<02:46,  1.68s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:31<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:33<02:56,  1.82s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:34<02:45,  1.73s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:36<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:37<02:39,  1.69s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:39<02:38,  1.71s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:41<02:30,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:42<02:23,  1.58s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:43<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:45<02:25,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:47<02:29,  1.70s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:49<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:51<02:23,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:52<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:54<02:22,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:56<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:57<02:17,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:59<02:10,  1.61s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:00<02:07,  1.59s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:02<02:02,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:04<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:06<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:08<02:18,  1.82s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:09<02:05,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:10<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:12<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:14<01:56,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:15<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:17<01:58,  1.69s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:19<01:54,  1.66s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:21<02:00,  1.77s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:22<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:24<01:59,  1.82s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:26<01:52,  1.73s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:27<01:45,  1.65s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:29<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:30<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:32<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:33<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:35<01:36,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:37<01:37,  1.69s/it]predicting train subjects:  80%|████████  | 228/285 [06:39<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:41<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [06:42<01:29,  1.62s/it]predicting train subjects:  81%|████████  | 231/285 [06:44<01:26,  1.60s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:45<01:26,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:47<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:49<01:26,  1.69s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:50<01:20,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:52<01:21,  1.66s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:54<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:55<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:57<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:59<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:00<01:13,  1.66s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:02<01:09,  1.63s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:03<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:05<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:07<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:09<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:10<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:12<01:04,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:14<01:01,  1.70s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:15<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:17<00:54,  1.61s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:18<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:20<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:22<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:24<00:52,  1.75s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:25<00:47,  1.64s/it]predicting train subjects:  90%|█████████ | 257/285 [07:27<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:29<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:30<00:43,  1.67s/it]predicting train subjects:  91%|█████████ | 260/285 [07:32<00:41,  1.66s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:33<00:38,  1.60s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:35<00:36,  1.59s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:36<00:34,  1.56s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:38<00:35,  1.71s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:40<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:42<00:32,  1.71s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:43<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:45<00:29,  1.72s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:47<00:28,  1.75s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:49<00:25,  1.68s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:50<00:22,  1.63s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:52<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:54<00:20,  1.67s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:55<00:18,  1.64s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:57<00:17,  1.76s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:59<00:15,  1.77s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:00<00:13,  1.67s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:02<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:04<00:10,  1.69s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:05<00:08,  1.64s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:07<00:06,  1.60s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:08<00:04,  1.60s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:10<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:12<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [08:14<00:00,  1.82s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:26,  1.57s/it]Loading train:   1%|          | 2/285 [00:02<06:51,  1.45s/it]Loading train:   1%|          | 3/285 [00:04<06:55,  1.47s/it]Loading train:   1%|▏         | 4/285 [00:05<06:44,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:07<07:09,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<06:39,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<06:44,  1.46s/it]Loading train:   3%|▎         | 8/285 [00:11<06:41,  1.45s/it]Loading train:   3%|▎         | 9/285 [00:13<07:08,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:31,  1.42s/it]Loading train:   4%|▍         | 11/285 [00:15<06:11,  1.36s/it]Loading train:   4%|▍         | 12/285 [00:16<05:56,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:17<05:24,  1.19s/it]Loading train:   5%|▍         | 14/285 [00:18<05:17,  1.17s/it]Loading train:   5%|▌         | 15/285 [00:20<05:15,  1.17s/it]Loading train:   6%|▌         | 16/285 [00:21<05:22,  1.20s/it]Loading train:   6%|▌         | 17/285 [00:22<05:07,  1.15s/it]Loading train:   6%|▋         | 18/285 [00:23<05:03,  1.14s/it]Loading train:   7%|▋         | 19/285 [00:24<05:13,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:25<04:52,  1.10s/it]Loading train:   7%|▋         | 21/285 [00:26<04:51,  1.10s/it]Loading train:   8%|▊         | 22/285 [00:27<04:34,  1.04s/it]Loading train:   8%|▊         | 23/285 [00:28<04:26,  1.02s/it]Loading train:   8%|▊         | 24/285 [00:29<04:09,  1.04it/s]Loading train:   9%|▉         | 25/285 [00:30<04:26,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:31<04:20,  1.00s/it]Loading train:   9%|▉         | 27/285 [00:32<04:17,  1.00it/s]Loading train:  10%|▉         | 28/285 [00:33<04:12,  1.02it/s]Loading train:  10%|█         | 29/285 [00:34<04:15,  1.00it/s]Loading train:  11%|█         | 30/285 [00:35<04:30,  1.06s/it]Loading train:  11%|█         | 31/285 [00:36<04:24,  1.04s/it]Loading train:  11%|█         | 32/285 [00:37<04:16,  1.01s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:15,  1.01s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:12,  1.01s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:13,  1.01s/it]Loading train:  13%|█▎        | 36/285 [00:41<04:05,  1.02it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:18,  1.04s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:15,  1.04s/it]Loading train:  14%|█▎        | 39/285 [00:44<04:17,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:45<04:18,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:46<04:03,  1.00it/s]Loading train:  15%|█▍        | 42/285 [00:47<03:58,  1.02it/s]Loading train:  15%|█▌        | 43/285 [00:49<04:13,  1.05s/it]Loading train:  15%|█▌        | 44/285 [00:50<04:36,  1.15s/it]Loading train:  16%|█▌        | 45/285 [00:51<04:18,  1.08s/it]Loading train:  16%|█▌        | 46/285 [00:52<04:07,  1.04s/it]Loading train:  16%|█▋        | 47/285 [00:53<04:24,  1.11s/it]Loading train:  17%|█▋        | 48/285 [00:54<04:27,  1.13s/it]Loading train:  17%|█▋        | 49/285 [00:55<04:29,  1.14s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:31,  1.15s/it]Loading train:  18%|█▊        | 51/285 [00:58<04:55,  1.26s/it]Loading train:  18%|█▊        | 52/285 [00:59<04:24,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:00<04:17,  1.11s/it]Loading train:  19%|█▉        | 54/285 [01:01<04:20,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:02<04:09,  1.09s/it]Loading train:  20%|█▉        | 56/285 [01:03<04:06,  1.07s/it]Loading train:  20%|██        | 57/285 [01:04<04:07,  1.09s/it]Loading train:  20%|██        | 58/285 [01:05<03:59,  1.06s/it]Loading train:  21%|██        | 59/285 [01:06<03:56,  1.05s/it]Loading train:  21%|██        | 60/285 [01:07<03:58,  1.06s/it]Loading train:  21%|██▏       | 61/285 [01:08<03:59,  1.07s/it]Loading train:  22%|██▏       | 62/285 [01:10<03:57,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:11<03:56,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:12<04:08,  1.12s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:34,  1.25s/it]Loading train:  23%|██▎       | 66/285 [01:15<05:04,  1.39s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:52,  1.34s/it]Loading train:  24%|██▍       | 68/285 [01:17<04:39,  1.29s/it]Loading train:  24%|██▍       | 69/285 [01:19<04:27,  1.24s/it]Loading train:  25%|██▍       | 70/285 [01:20<04:11,  1.17s/it]Loading train:  25%|██▍       | 71/285 [01:21<03:53,  1.09s/it]Loading train:  25%|██▌       | 72/285 [01:22<03:47,  1.07s/it]Loading train:  26%|██▌       | 73/285 [01:23<04:11,  1.19s/it]Loading train:  26%|██▌       | 74/285 [01:24<03:55,  1.11s/it]Loading train:  26%|██▋       | 75/285 [01:25<03:44,  1.07s/it]Loading train:  27%|██▋       | 76/285 [01:26<03:53,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:27<03:38,  1.05s/it]Loading train:  27%|██▋       | 78/285 [01:28<03:25,  1.01it/s]Loading train:  28%|██▊       | 79/285 [01:29<03:32,  1.03s/it]Loading train:  28%|██▊       | 80/285 [01:30<03:43,  1.09s/it]Loading train:  28%|██▊       | 81/285 [01:31<03:29,  1.03s/it]Loading train:  29%|██▉       | 82/285 [01:32<03:44,  1.11s/it]Loading train:  29%|██▉       | 83/285 [01:33<03:22,  1.00s/it]Loading train:  29%|██▉       | 84/285 [01:34<03:19,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:36<03:45,  1.13s/it]Loading train:  30%|███       | 86/285 [01:37<04:01,  1.22s/it]Loading train:  31%|███       | 87/285 [01:38<04:03,  1.23s/it]Loading train:  31%|███       | 88/285 [01:39<03:54,  1.19s/it]Loading train:  31%|███       | 89/285 [01:40<03:45,  1.15s/it]Loading train:  32%|███▏      | 90/285 [01:41<03:35,  1.10s/it]Loading train:  32%|███▏      | 91/285 [01:42<03:23,  1.05s/it]Loading train:  32%|███▏      | 92/285 [01:43<03:20,  1.04s/it]Loading train:  33%|███▎      | 93/285 [01:44<03:05,  1.03it/s]Loading train:  33%|███▎      | 94/285 [01:45<03:07,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:46<03:14,  1.02s/it]Loading train:  34%|███▎      | 96/285 [01:48<03:32,  1.12s/it]Loading train:  34%|███▍      | 97/285 [01:49<03:30,  1.12s/it]Loading train:  34%|███▍      | 98/285 [01:50<03:27,  1.11s/it]Loading train:  35%|███▍      | 99/285 [01:51<03:30,  1.13s/it]Loading train:  35%|███▌      | 100/285 [01:52<03:30,  1.14s/it]Loading train:  35%|███▌      | 101/285 [01:53<03:24,  1.11s/it]Loading train:  36%|███▌      | 102/285 [01:55<03:34,  1.17s/it]Loading train:  36%|███▌      | 103/285 [01:55<03:16,  1.08s/it]Loading train:  36%|███▋      | 104/285 [01:57<03:19,  1.10s/it]Loading train:  37%|███▋      | 105/285 [01:58<03:23,  1.13s/it]Loading train:  37%|███▋      | 106/285 [01:59<03:08,  1.05s/it]Loading train:  38%|███▊      | 107/285 [02:00<03:12,  1.08s/it]Loading train:  38%|███▊      | 108/285 [02:01<03:03,  1.04s/it]Loading train:  38%|███▊      | 109/285 [02:02<03:03,  1.04s/it]Loading train:  39%|███▊      | 110/285 [02:03<03:07,  1.07s/it]Loading train:  39%|███▉      | 111/285 [02:04<02:52,  1.01it/s]Loading train:  39%|███▉      | 112/285 [02:05<03:03,  1.06s/it]Loading train:  40%|███▉      | 113/285 [02:06<02:58,  1.04s/it]Loading train:  40%|████      | 114/285 [02:07<03:07,  1.10s/it]Loading train:  40%|████      | 115/285 [02:08<02:57,  1.04s/it]Loading train:  41%|████      | 116/285 [02:09<03:02,  1.08s/it]Loading train:  41%|████      | 117/285 [02:10<02:49,  1.01s/it]Loading train:  41%|████▏     | 118/285 [02:11<02:46,  1.00it/s]Loading train:  42%|████▏     | 119/285 [02:12<02:48,  1.02s/it]Loading train:  42%|████▏     | 120/285 [02:13<02:44,  1.00it/s]Loading train:  42%|████▏     | 121/285 [02:15<03:05,  1.13s/it]Loading train:  43%|████▎     | 122/285 [02:16<03:12,  1.18s/it]Loading train:  43%|████▎     | 123/285 [02:17<03:20,  1.24s/it]Loading train:  44%|████▎     | 124/285 [02:18<03:07,  1.17s/it]Loading train:  44%|████▍     | 125/285 [02:19<03:03,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:21<03:07,  1.18s/it]Loading train:  45%|████▍     | 127/285 [02:21<02:48,  1.07s/it]Loading train:  45%|████▍     | 128/285 [02:22<02:41,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:23<02:42,  1.04s/it]Loading train:  46%|████▌     | 130/285 [02:25<02:50,  1.10s/it]Loading train:  46%|████▌     | 131/285 [02:26<02:40,  1.04s/it]Loading train:  46%|████▋     | 132/285 [02:27<02:51,  1.12s/it]Loading train:  47%|████▋     | 133/285 [02:28<02:38,  1.04s/it]Loading train:  47%|████▋     | 134/285 [02:29<02:32,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:29<02:23,  1.04it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:31<02:26,  1.01it/s]Loading train:  48%|████▊     | 138/285 [02:32<02:25,  1.01it/s]Loading train:  49%|████▉     | 139/285 [02:34<02:32,  1.04s/it]Loading train:  49%|████▉     | 140/285 [02:35<02:29,  1.03s/it]Loading train:  49%|████▉     | 141/285 [02:36<02:27,  1.03s/it]Loading train:  50%|████▉     | 142/285 [02:37<02:30,  1.05s/it]Loading train:  50%|█████     | 143/285 [02:38<02:45,  1.17s/it]Loading train:  51%|█████     | 144/285 [02:39<02:29,  1.06s/it]Loading train:  51%|█████     | 145/285 [02:40<02:29,  1.07s/it]Loading train:  51%|█████     | 146/285 [02:41<02:22,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [02:42<02:26,  1.06s/it]Loading train:  52%|█████▏    | 148/285 [02:43<02:16,  1.00it/s]Loading train:  52%|█████▏    | 149/285 [02:44<02:08,  1.06it/s]Loading train:  53%|█████▎    | 150/285 [02:45<02:05,  1.07it/s]Loading train:  53%|█████▎    | 151/285 [02:46<02:10,  1.03it/s]Loading train:  53%|█████▎    | 152/285 [02:47<02:13,  1.01s/it]Loading train:  54%|█████▎    | 153/285 [02:48<02:11,  1.01it/s]Loading train:  54%|█████▍    | 154/285 [02:49<02:14,  1.03s/it]Loading train:  54%|█████▍    | 155/285 [02:50<02:14,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [02:51<02:20,  1.09s/it]Loading train:  55%|█████▌    | 157/285 [02:52<02:09,  1.01s/it]Loading train:  55%|█████▌    | 158/285 [02:53<02:07,  1.00s/it]Loading train:  56%|█████▌    | 159/285 [02:54<02:08,  1.02s/it]Loading train:  56%|█████▌    | 160/285 [02:55<02:02,  1.02it/s]Loading train:  56%|█████▋    | 161/285 [02:56<02:11,  1.06s/it]Loading train:  57%|█████▋    | 162/285 [02:57<02:06,  1.03s/it]Loading train:  57%|█████▋    | 163/285 [02:58<02:06,  1.04s/it]Loading train:  58%|█████▊    | 164/285 [02:59<02:00,  1.00it/s]Loading train:  58%|█████▊    | 165/285 [03:00<01:53,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [03:01<01:51,  1.07it/s]Loading train:  59%|█████▊    | 167/285 [03:02<01:46,  1.11it/s]Loading train:  59%|█████▉    | 168/285 [03:03<01:49,  1.07it/s]Loading train:  59%|█████▉    | 169/285 [03:04<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [03:04<01:43,  1.11it/s]Loading train:  60%|██████    | 171/285 [03:06<01:49,  1.04it/s]Loading train:  60%|██████    | 172/285 [03:06<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:07<01:40,  1.11it/s]Loading train:  61%|██████    | 174/285 [03:08<01:43,  1.07it/s]Loading train:  61%|██████▏   | 175/285 [03:09<01:47,  1.02it/s]Loading train:  62%|██████▏   | 176/285 [03:10<01:44,  1.04it/s]Loading train:  62%|██████▏   | 177/285 [03:11<01:51,  1.03s/it]Loading train:  62%|██████▏   | 178/285 [03:12<01:46,  1.00it/s]Loading train:  63%|██████▎   | 179/285 [03:13<01:49,  1.03s/it]Loading train:  63%|██████▎   | 180/285 [03:15<02:01,  1.15s/it]Loading train:  64%|██████▎   | 181/285 [03:16<01:48,  1.04s/it]Loading train:  64%|██████▍   | 182/285 [03:17<01:44,  1.02s/it]Loading train:  64%|██████▍   | 183/285 [03:18<01:38,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:18<01:37,  1.04it/s]Loading train:  65%|██████▍   | 185/285 [03:20<01:39,  1.00it/s]Loading train:  65%|██████▌   | 186/285 [03:21<01:50,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [03:22<01:50,  1.12s/it]Loading train:  66%|██████▌   | 188/285 [03:23<01:47,  1.11s/it]Loading train:  66%|██████▋   | 189/285 [03:24<01:38,  1.03s/it]Loading train:  67%|██████▋   | 190/285 [03:25<01:38,  1.04s/it]Loading train:  67%|██████▋   | 191/285 [03:26<01:37,  1.04s/it]Loading train:  67%|██████▋   | 192/285 [03:27<01:29,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [03:28<01:33,  1.02s/it]Loading train:  68%|██████▊   | 194/285 [03:29<01:35,  1.05s/it]Loading train:  68%|██████▊   | 195/285 [03:30<01:33,  1.03s/it]Loading train:  69%|██████▉   | 196/285 [03:31<01:32,  1.04s/it]Loading train:  69%|██████▉   | 197/285 [03:32<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [03:33<01:30,  1.04s/it]Loading train:  70%|██████▉   | 199/285 [03:34<01:26,  1.01s/it]Loading train:  70%|███████   | 200/285 [03:35<01:28,  1.04s/it]Loading train:  71%|███████   | 201/285 [03:37<01:32,  1.10s/it]Loading train:  71%|███████   | 202/285 [03:37<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:38<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:39<01:16,  1.06it/s]Loading train:  72%|███████▏  | 205/285 [03:40<01:23,  1.04s/it]Loading train:  72%|███████▏  | 206/285 [03:41<01:14,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:42<01:19,  1.02s/it]Loading train:  73%|███████▎  | 208/285 [03:44<01:21,  1.06s/it]Loading train:  73%|███████▎  | 209/285 [03:44<01:17,  1.02s/it]Loading train:  74%|███████▎  | 210/285 [03:46<01:18,  1.04s/it]Loading train:  74%|███████▍  | 211/285 [03:47<01:15,  1.02s/it]Loading train:  74%|███████▍  | 212/285 [03:48<01:14,  1.02s/it]Loading train:  75%|███████▍  | 213/285 [03:49<01:16,  1.06s/it]Loading train:  75%|███████▌  | 214/285 [03:50<01:12,  1.02s/it]Loading train:  75%|███████▌  | 215/285 [03:51<01:13,  1.04s/it]Loading train:  76%|███████▌  | 216/285 [03:52<01:11,  1.04s/it]Loading train:  76%|███████▌  | 217/285 [03:53<01:11,  1.06s/it]Loading train:  76%|███████▋  | 218/285 [03:54<01:11,  1.07s/it]Loading train:  77%|███████▋  | 219/285 [03:55<01:12,  1.10s/it]Loading train:  77%|███████▋  | 220/285 [03:56<01:05,  1.00s/it]Loading train:  78%|███████▊  | 221/285 [03:57<01:05,  1.03s/it]Loading train:  78%|███████▊  | 222/285 [03:58<01:06,  1.06s/it]Loading train:  78%|███████▊  | 223/285 [03:59<00:58,  1.06it/s]Loading train:  79%|███████▊  | 224/285 [04:00<00:58,  1.05it/s]Loading train:  79%|███████▉  | 225/285 [04:01<00:55,  1.08it/s]Loading train:  79%|███████▉  | 226/285 [04:02<00:59,  1.01s/it]Loading train:  80%|███████▉  | 227/285 [04:03<00:59,  1.03s/it]Loading train:  80%|████████  | 228/285 [04:04<01:03,  1.11s/it]Loading train:  80%|████████  | 229/285 [04:05<00:57,  1.03s/it]Loading train:  81%|████████  | 230/285 [04:06<00:56,  1.02s/it]Loading train:  81%|████████  | 231/285 [04:07<00:54,  1.01s/it]Loading train:  81%|████████▏ | 232/285 [04:08<00:56,  1.06s/it]Loading train:  82%|████████▏ | 233/285 [04:09<00:52,  1.00s/it]Loading train:  82%|████████▏ | 234/285 [04:10<00:53,  1.05s/it]Loading train:  82%|████████▏ | 235/285 [04:11<00:49,  1.01it/s]Loading train:  83%|████████▎ | 236/285 [04:12<00:52,  1.07s/it]Loading train:  83%|████████▎ | 237/285 [04:13<00:50,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [04:14<00:47,  1.02s/it]Loading train:  84%|████████▍ | 239/285 [04:15<00:47,  1.02s/it]Loading train:  84%|████████▍ | 240/285 [04:16<00:42,  1.06it/s]Loading train:  85%|████████▍ | 241/285 [04:17<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:18<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [04:19<00:43,  1.03s/it]Loading train:  86%|████████▌ | 244/285 [04:21<00:47,  1.16s/it]Loading train:  86%|████████▌ | 245/285 [04:22<00:46,  1.17s/it]Loading train:  86%|████████▋ | 246/285 [04:23<00:47,  1.22s/it]Loading train:  87%|████████▋ | 247/285 [04:24<00:44,  1.16s/it]Loading train:  87%|████████▋ | 248/285 [04:26<00:44,  1.19s/it]Loading train:  87%|████████▋ | 249/285 [04:26<00:40,  1.12s/it]Loading train:  88%|████████▊ | 250/285 [04:28<00:38,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [04:28<00:35,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:29<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:31<00:33,  1.06s/it]Loading train:  89%|████████▉ | 254/285 [04:32<00:35,  1.13s/it]Loading train:  89%|████████▉ | 255/285 [04:33<00:31,  1.06s/it]Loading train:  90%|████████▉ | 256/285 [04:34<00:28,  1.00it/s]Loading train:  90%|█████████ | 257/285 [04:35<00:28,  1.01s/it]Loading train:  91%|█████████ | 258/285 [04:36<00:28,  1.06s/it]Loading train:  91%|█████████ | 259/285 [04:37<00:29,  1.12s/it]Loading train:  91%|█████████ | 260/285 [04:39<00:30,  1.24s/it]Loading train:  92%|█████████▏| 261/285 [04:40<00:30,  1.26s/it]Loading train:  92%|█████████▏| 262/285 [04:41<00:26,  1.17s/it]Loading train:  92%|█████████▏| 263/285 [04:42<00:26,  1.19s/it]Loading train:  93%|█████████▎| 264/285 [04:43<00:24,  1.19s/it]Loading train:  93%|█████████▎| 265/285 [04:45<00:24,  1.22s/it]Loading train:  93%|█████████▎| 266/285 [04:46<00:22,  1.17s/it]Loading train:  94%|█████████▎| 267/285 [04:47<00:20,  1.15s/it]Loading train:  94%|█████████▍| 268/285 [04:48<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [04:49<00:18,  1.18s/it]Loading train:  95%|█████████▍| 270/285 [04:50<00:16,  1.08s/it]Loading train:  95%|█████████▌| 271/285 [04:51<00:15,  1.08s/it]Loading train:  95%|█████████▌| 272/285 [04:52<00:13,  1.08s/it]Loading train:  96%|█████████▌| 273/285 [04:53<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [04:54<00:11,  1.04s/it]Loading train:  96%|█████████▋| 275/285 [04:55<00:10,  1.10s/it]Loading train:  97%|█████████▋| 276/285 [04:57<00:10,  1.22s/it]Loading train:  97%|█████████▋| 277/285 [04:58<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [04:59<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:59<00:05,  1.01it/s]Loading train:  98%|█████████▊| 280/285 [05:00<00:04,  1.06it/s]Loading train:  99%|█████████▊| 281/285 [05:01<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [05:02<00:02,  1.15it/s]Loading train:  99%|█████████▉| 283/285 [05:03<00:01,  1.04it/s]Loading train: 100%|█████████▉| 284/285 [05:04<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [05:05<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 39.73it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:07, 37.27it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:06, 40.58it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:06, 42.67it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:05, 46.62it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:04, 51.30it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:03, 61.56it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:03, 74.35it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:02, 82.70it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:02, 74.84it/s]concatenating: train:  32%|███▏      | 91/285 [00:01<00:03, 63.44it/s]concatenating: train:  35%|███▍      | 99/285 [00:01<00:02, 63.15it/s]concatenating: train:  40%|███▉      | 113/285 [00:01<00:02, 75.56it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:01, 93.51it/s]concatenating: train:  55%|█████▌    | 158/285 [00:01<00:01, 114.47it/s]concatenating: train:  66%|██████▋   | 189/285 [00:01<00:00, 140.85it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 170.57it/s]concatenating: train:  90%|████████▉ | 256/285 [00:02<00:00, 199.30it/s]concatenating: train:  99%|█████████▉| 283/285 [00:02<00:00, 206.12it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 126.96it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.76s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.62s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 43.21it/s]2019-07-10 22:59:43.626781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:59:43.626885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:59:43.626901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:59:43.626910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:59:43.627325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.05it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:05,  6.71it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.57it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  7.69it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.00it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.71it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.79it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.33it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.23it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.05it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.03it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.78it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.37it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.34it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.04it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.51it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.83it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.88it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 227,713
Trainable params: 52,993
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 3.1829 - acc: 0.3861 - mDice: 0.0714 - val_loss: 2.3335 - val_acc: 0.8919 - val_mDice: 0.1635

Epoch 00001: val_mDice improved from -inf to 0.16351, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.3502 - acc: 0.8737 - mDice: 0.2624 - val_loss: 1.7435 - val_acc: 0.8471 - val_mDice: 0.2602

Epoch 00002: val_mDice improved from 0.16351 to 0.26022, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.9299 - acc: 0.8941 - mDice: 0.3854 - val_loss: 1.4045 - val_acc: 0.8827 - val_mDice: 0.3504

Epoch 00003: val_mDice improved from 0.26022 to 0.35036, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7784 - acc: 0.9040 - mDice: 0.4477 - val_loss: 1.3323 - val_acc: 0.8930 - val_mDice: 0.3680

Epoch 00004: val_mDice improved from 0.35036 to 0.36799, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6986 - acc: 0.9096 - mDice: 0.4850 - val_loss: 0.9698 - val_acc: 0.9202 - val_mDice: 0.4699

Epoch 00005: val_mDice improved from 0.36799 to 0.46992, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.6457 - acc: 0.9136 - mDice: 0.5113 - val_loss: 0.9138 - val_acc: 0.9178 - val_mDice: 0.4876

Epoch 00006: val_mDice improved from 0.46992 to 0.48762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.6062 - acc: 0.9169 - mDice: 0.5320 - val_loss: 0.8916 - val_acc: 0.9266 - val_mDice: 0.5015

Epoch 00007: val_mDice improved from 0.48762 to 0.50154, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.5708 - acc: 0.9198 - mDice: 0.5512 - val_loss: 0.8876 - val_acc: 0.9293 - val_mDice: 0.4974

Epoch 00008: val_mDice did not improve from 0.50154
Epoch 9/300
 - 10s - loss: 0.5477 - acc: 0.9218 - mDice: 0.5639 - val_loss: 0.8336 - val_acc: 0.9321 - val_mDice: 0.5283

Epoch 00009: val_mDice improved from 0.50154 to 0.52830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.5205 - acc: 0.9241 - mDice: 0.5796 - val_loss: 0.8126 - val_acc: 0.9347 - val_mDice: 0.5377

Epoch 00010: val_mDice improved from 0.52830 to 0.53769, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.5048 - acc: 0.9256 - mDice: 0.5887 - val_loss: 0.8123 - val_acc: 0.9341 - val_mDice: 0.5326

Epoch 00011: val_mDice did not improve from 0.53769
Epoch 12/300
 - 9s - loss: 0.4906 - acc: 0.9269 - mDice: 0.5974 - val_loss: 0.8288 - val_acc: 0.9330 - val_mDice: 0.5334

Epoch 00012: val_mDice did not improve from 0.53769
Epoch 13/300
 - 10s - loss: 0.4760 - acc: 0.9282 - mDice: 0.6063 - val_loss: 0.8071 - val_acc: 0.9331 - val_mDice: 0.5336

Epoch 00013: val_mDice did not improve from 0.53769
Epoch 14/300
 - 10s - loss: 0.4658 - acc: 0.9292 - mDice: 0.6125 - val_loss: 0.8194 - val_acc: 0.9292 - val_mDice: 0.5295

Epoch 00014: val_mDice did not improve from 0.53769
Epoch 15/300
 - 9s - loss: 0.4577 - acc: 0.9300 - mDice: 0.6176 - val_loss: 0.8118 - val_acc: 0.9367 - val_mDice: 0.5389

Epoch 00015: val_mDice improved from 0.53769 to 0.53886, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.4462 - acc: 0.9310 - mDice: 0.6248 - val_loss: 0.8084 - val_acc: 0.9276 - val_mDice: 0.5323

Epoch 00016: val_mDice did not improve from 0.53886
Epoch 17/300
 - 9s - loss: 0.4369 - acc: 0.9320 - mDice: 0.6309 - val_loss: 0.7669 - val_acc: 0.9356 - val_mDice: 0.5579

Epoch 00017: val_mDice improved from 0.53886 to 0.55790, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 10s - loss: 0.4310 - acc: 0.9326 - mDice: 0.6345 - val_loss: 0.7629 - val_acc: 0.9331 - val_mDice: 0.5495

Epoch 00018: val_mDice did not improve from 0.55790
Epoch 19/300
 - 10s - loss: 0.4241 - acc: 0.9333 - mDice: 0.6392 - val_loss: 0.7474 - val_acc: 0.9376 - val_mDice: 0.5622

Epoch 00019: val_mDice improved from 0.55790 to 0.56219, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.4184 - acc: 0.9338 - mDice: 0.6430 - val_loss: 0.8153 - val_acc: 0.9293 - val_mDice: 0.5312

Epoch 00020: val_mDice did not improve from 0.56219
Epoch 21/300
 - 9s - loss: 0.4101 - acc: 0.9345 - mDice: 0.6482 - val_loss: 0.7662 - val_acc: 0.9311 - val_mDice: 0.5472

Epoch 00021: val_mDice did not improve from 0.56219
Epoch 22/300
 - 9s - loss: 0.4060 - acc: 0.9350 - mDice: 0.6511 - val_loss: 0.7867 - val_acc: 0.9321 - val_mDice: 0.5491

Epoch 00022: val_mDice did not improve from 0.56219
Epoch 23/300
 - 9s - loss: 0.4016 - acc: 0.9354 - mDice: 0.6540 - val_loss: 0.7814 - val_acc: 0.9366 - val_mDice: 0.5477

Epoch 00023: val_mDice did not improve from 0.56219
Epoch 24/300
 - 10s - loss: 0.3963 - acc: 0.9356 - mDice: 0.6575 - val_loss: 0.7645 - val_acc: 0.9296 - val_mDice: 0.5427

Epoch 00024: val_mDice did not improve from 0.56219
Epoch 25/300
 - 10s - loss: 0.3934 - acc: 0.9361 - mDice: 0.6595 - val_loss: 0.7504 - val_acc: 0.9373 - val_mDice: 0.5529

Epoch 00025: val_mDice did not improve from 0.56219
Epoch 26/300
 - 9s - loss: 0.3883 - acc: 0.9365 - mDice: 0.6629 - val_loss: 0.7968 - val_acc: 0.9295 - val_mDice: 0.5319

Epoch 00026: val_mDice did not improve from 0.56219
Epoch 27/300
 - 9s - loss: 0.3848 - acc: 0.9367 - mDice: 0.6654 - val_loss: 0.7560 - val_acc: 0.9365 - val_mDice: 0.5468

Epoch 00027: val_mDice did not improve from 0.56219
Epoch 28/300
 - 9s - loss: 0.3803 - acc: 0.9371 - mDice: 0.6685 - val_loss: 0.7575 - val_acc: 0.9373 - val_mDice: 0.5514

Epoch 00028: val_mDice did not improve from 0.56219
Epoch 29/300
 - 10s - loss: 0.3774 - acc: 0.9374 - mDice: 0.6704 - val_loss: 0.7761 - val_acc: 0.9333 - val_mDice: 0.5406

Epoch 00029: val_mDice did not improve from 0.56219
Epoch 30/300
 - 10s - loss: 0.3727 - acc: 0.9378 - mDice: 0.6738 - val_loss: 0.7754 - val_acc: 0.9338 - val_mDice: 0.5434

Epoch 00030: val_mDice did not improve from 0.56219
Epoch 31/300
 - 9s - loss: 0.3744 - acc: 0.9377 - mDice: 0.6725 - val_loss: 0.7044 - val_acc: 0.9368 - val_mDice: 0.5551

Epoch 00031: val_mDice did not improve from 0.56219
Epoch 32/300
 - 9s - loss: 0.3688 - acc: 0.9381 - mDice: 0.6764 - val_loss: 0.7338 - val_acc: 0.9326 - val_mDice: 0.5549

Epoch 00032: val_mDice did not improve from 0.56219
Epoch 33/300
 - 9s - loss: 0.3654 - acc: 0.9384 - mDice: 0.6788 - val_loss: 0.7527 - val_acc: 0.9337 - val_mDice: 0.5464

Epoch 00033: val_mDice did not improve from 0.56219
Epoch 34/300
 - 10s - loss: 0.3650 - acc: 0.9386 - mDice: 0.6792 - val_loss: 0.7161 - val_acc: 0.9357 - val_mDice: 0.5535

Epoch 00034: val_mDice did not improve from 0.56219
Epoch 35/300
 - 10s - loss: 0.3624 - acc: 0.9388 - mDice: 0.6810 - val_loss: 0.7311 - val_acc: 0.9295 - val_mDice: 0.5432

Epoch 00035: val_mDice did not improve from 0.56219
Epoch 36/300
 - 10s - loss: 0.3574 - acc: 0.9392 - mDice: 0.6844 - val_loss: 0.7297 - val_acc: 0.9340 - val_mDice: 0.5519

Epoch 00036: val_mDice did not improve from 0.56219
Epoch 37/300
 - 10s - loss: 0.3566 - acc: 0.9392 - mDice: 0.6850 - val_loss: 0.7417 - val_acc: 0.9287 - val_mDice: 0.5348

Epoch 00037: val_mDice did not improve from 0.56219
Epoch 38/300
 - 10s - loss: 0.3538 - acc: 0.9395 - mDice: 0.6870 - val_loss: 0.7257 - val_acc: 0.9379 - val_mDice: 0.5513

Epoch 00038: val_mDice did not improve from 0.56219
Epoch 39/300
 - 10s - loss: 0.3507 - acc: 0.9396 - mDice: 0.6892 - val_loss: 0.7230 - val_acc: 0.9315 - val_mDice: 0.5477

Epoch 00039: val_mDice did not improve from 0.56219
Epoch 40/300
 - 10s - loss: 0.3479 - acc: 0.9398 - mDice: 0.6912 - val_loss: 0.7515 - val_acc: 0.9379 - val_mDice: 0.5493

Epoch 00040: val_mDice did not improve from 0.56219
Epoch 41/300
 - 10s - loss: 0.3455 - acc: 0.9401 - mDice: 0.6929 - val_loss: 0.7057 - val_acc: 0.9385 - val_mDice: 0.5526

Epoch 00041: val_mDice did not improve from 0.56219
Epoch 42/300
 - 10s - loss: 0.3444 - acc: 0.9403 - mDice: 0.6938 - val_loss: 0.7123 - val_acc: 0.9340 - val_mDice: 0.5616

Epoch 00042: val_mDice did not improve from 0.56219
Epoch 43/300
 - 11s - loss: 0.3434 - acc: 0.9403 - mDice: 0.6946 - val_loss: 0.6873 - val_acc: 0.9372 - val_mDice: 0.5563

Epoch 00043: val_mDice did not improve from 0.56219
Epoch 44/300
 - 10s - loss: 0.3388 - acc: 0.9408 - mDice: 0.6978 - val_loss: 0.6978 - val_acc: 0.9304 - val_mDice: 0.5464

Epoch 00044: val_mDice did not improve from 0.56219
Epoch 45/300
 - 9s - loss: 0.3387 - acc: 0.9408 - mDice: 0.6978 - val_loss: 0.7148 - val_acc: 0.9321 - val_mDice: 0.5407

Epoch 00045: val_mDice did not improve from 0.56219
Epoch 46/300
 - 9s - loss: 0.3373 - acc: 0.9410 - mDice: 0.6989 - val_loss: 0.6811 - val_acc: 0.9340 - val_mDice: 0.5533

Epoch 00046: val_mDice did not improve from 0.56219
Epoch 47/300
 - 9s - loss: 0.3351 - acc: 0.9414 - mDice: 0.7005 - val_loss: 0.6917 - val_acc: 0.9375 - val_mDice: 0.5466

Epoch 00047: val_mDice did not improve from 0.56219
Epoch 48/300
 - 9s - loss: 0.3317 - acc: 0.9414 - mDice: 0.7029 - val_loss: 0.6655 - val_acc: 0.9403 - val_mDice: 0.5579

Epoch 00048: val_mDice did not improve from 0.56219
Epoch 49/300
 - 10s - loss: 0.3318 - acc: 0.9415 - mDice: 0.7028 - val_loss: 0.6808 - val_acc: 0.9373 - val_mDice: 0.5472

Epoch 00049: val_mDice did not improve from 0.56219
Epoch 50/300
 - 9s - loss: 0.3303 - acc: 0.9415 - mDice: 0.7039 - val_loss: 0.6756 - val_acc: 0.9341 - val_mDice: 0.5490

Epoch 00050: val_mDice did not improve from 0.56219
Epoch 51/300
 - 9s - loss: 0.3278 - acc: 0.9418 - mDice: 0.7057 - val_loss: 0.6880 - val_acc: 0.9360 - val_mDice: 0.5562

Epoch 00051: val_mDice did not improve from 0.56219
Epoch 52/300
 - 9s - loss: 0.3306 - acc: 0.9416 - mDice: 0.7036 - val_loss: 0.6837 - val_acc: 0.9397 - val_mDice: 0.5510

Epoch 00052: val_mDice did not improve from 0.56219
Epoch 53/300
 - 10s - loss: 0.3262 - acc: 0.9421 - mDice: 0.7069 - val_loss: 0.6541 - val_acc: 0.9343 - val_mDice: 0.5497

Epoch 00053: val_mDice did not improve from 0.56219
Epoch 54/300
 - 10s - loss: 0.3257 - acc: 0.9420 - mDice: 0.7073 - val_loss: 0.6407 - val_acc: 0.9350 - val_mDice: 0.5586

Epoch 00054: val_mDice did not improve from 0.56219
Epoch 55/300
 - 9s - loss: 0.3237 - acc: 0.9422 - mDice: 0.7088 - val_loss: 0.6498 - val_acc: 0.9363 - val_mDice: 0.5595

Epoch 00055: val_mDice did not improve from 0.56219
Epoch 56/300
 - 9s - loss: 0.3215 - acc: 0.9424 - mDice: 0.7104 - val_loss: 0.6643 - val_acc: 0.9417 - val_mDice: 0.5622

Epoch 00056: val_mDice improved from 0.56219 to 0.56225, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 57/300
 - 10s - loss: 0.3230 - acc: 0.9423 - mDice: 0.7092 - val_loss: 0.6271 - val_acc: 0.9371 - val_mDice: 0.5595

Epoch 00057: val_mDice did not improve from 0.56225
Epoch 58/300
 - 10s - loss: 0.3182 - acc: 0.9427 - mDice: 0.7128 - val_loss: 0.6387 - val_acc: 0.9403 - val_mDice: 0.5558

Epoch 00058: val_mDice did not improve from 0.56225
Epoch 59/300
 - 9s - loss: 0.3194 - acc: 0.9426 - mDice: 0.7120 - val_loss: 0.6479 - val_acc: 0.9360 - val_mDice: 0.5465

Epoch 00059: val_mDice did not improve from 0.56225
Epoch 60/300
 - 9s - loss: 0.3191 - acc: 0.9426 - mDice: 0.7121 - val_loss: 0.6114 - val_acc: 0.9382 - val_mDice: 0.5661

Epoch 00060: val_mDice improved from 0.56225 to 0.56608, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 61/300
 - 10s - loss: 0.3159 - acc: 0.9429 - mDice: 0.7145 - val_loss: 0.6346 - val_acc: 0.9317 - val_mDice: 0.5525

Epoch 00061: val_mDice did not improve from 0.56608
Epoch 62/300
 - 10s - loss: 0.3153 - acc: 0.9428 - mDice: 0.7149 - val_loss: 0.6338 - val_acc: 0.9357 - val_mDice: 0.5563

Epoch 00062: val_mDice did not improve from 0.56608
Epoch 63/300
 - 9s - loss: 0.3142 - acc: 0.9430 - mDice: 0.7158 - val_loss: 0.6216 - val_acc: 0.9370 - val_mDice: 0.5594

Epoch 00063: val_mDice did not improve from 0.56608
Epoch 64/300
 - 9s - loss: 0.3125 - acc: 0.9431 - mDice: 0.7170 - val_loss: 0.6178 - val_acc: 0.9401 - val_mDice: 0.5608

Epoch 00064: val_mDice did not improve from 0.56608
Epoch 65/300
 - 10s - loss: 0.3107 - acc: 0.9432 - mDice: 0.7182 - val_loss: 0.6145 - val_acc: 0.9365 - val_mDice: 0.5665

Epoch 00065: val_mDice improved from 0.56608 to 0.56650, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 66/300
 - 10s - loss: 0.3104 - acc: 0.9433 - mDice: 0.7186 - val_loss: 0.6224 - val_acc: 0.9376 - val_mDice: 0.5587

Epoch 00066: val_mDice did not improve from 0.56650
Epoch 67/300
 - 9s - loss: 0.3107 - acc: 0.9432 - mDice: 0.7184 - val_loss: 0.6499 - val_acc: 0.9358 - val_mDice: 0.5474

Epoch 00067: val_mDice did not improve from 0.56650
Epoch 68/300
 - 9s - loss: 0.3084 - acc: 0.9433 - mDice: 0.7201 - val_loss: 0.6188 - val_acc: 0.9376 - val_mDice: 0.5605

Epoch 00068: val_mDice did not improve from 0.56650
Epoch 69/300
 - 9s - loss: 0.3099 - acc: 0.9434 - mDice: 0.7190 - val_loss: 0.6359 - val_acc: 0.9354 - val_mDice: 0.5493

Epoch 00069: val_mDice did not improve from 0.56650
Epoch 70/300
 - 10s - loss: 0.3061 - acc: 0.9437 - mDice: 0.7219 - val_loss: 0.6207 - val_acc: 0.9369 - val_mDice: 0.5613

Epoch 00070: val_mDice did not improve from 0.56650
Epoch 71/300
 - 9s - loss: 0.3060 - acc: 0.9437 - mDice: 0.7219 - val_loss: 0.6186 - val_acc: 0.9371 - val_mDice: 0.5592

Epoch 00071: val_mDice did not improve from 0.56650
Epoch 72/300
 - 9s - loss: 0.3071 - acc: 0.9437 - mDice: 0.7211 - val_loss: 0.6193 - val_acc: 0.9395 - val_mDice: 0.5582

Epoch 00072: val_mDice did not improve from 0.56650
Epoch 73/300
 - 10s - loss: 0.3061 - acc: 0.9437 - mDice: 0.7218 - val_loss: 0.6104 - val_acc: 0.9381 - val_mDice: 0.5622

Epoch 00073: val_mDice did not improve from 0.56650
Epoch 74/300
 - 9s - loss: 0.3051 - acc: 0.9437 - mDice: 0.7226 - val_loss: 0.6249 - val_acc: 0.9381 - val_mDice: 0.5579

Epoch 00074: val_mDice did not improve from 0.56650
Epoch 75/300
 - 10s - loss: 0.3048 - acc: 0.9438 - mDice: 0.7229 - val_loss: 0.6367 - val_acc: 0.9390 - val_mDice: 0.5476

Epoch 00075: val_mDice did not improve from 0.56650
Epoch 76/300
 - 9s - loss: 0.3032 - acc: 0.9440 - mDice: 0.7240 - val_loss: 0.5945 - val_acc: 0.9366 - val_mDice: 0.5667

Epoch 00076: val_mDice improved from 0.56650 to 0.56671, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 77/300
 - 9s - loss: 0.3007 - acc: 0.9441 - mDice: 0.7260 - val_loss: 0.6381 - val_acc: 0.9361 - val_mDice: 0.5475

Epoch 00077: val_mDice did not improve from 0.56671
Epoch 78/300
 - 10s - loss: 0.2998 - acc: 0.9442 - mDice: 0.7266 - val_loss: 0.6100 - val_acc: 0.9390 - val_mDice: 0.5641

Epoch 00078: val_mDice did not improve from 0.56671
Epoch 79/300
 - 9s - loss: 0.2993 - acc: 0.9442 - mDice: 0.7270 - val_loss: 0.6030 - val_acc: 0.9377 - val_mDice: 0.5667

Epoch 00079: val_mDice did not improve from 0.56671
Epoch 80/300
 - 10s - loss: 0.3003 - acc: 0.9441 - mDice: 0.7262 - val_loss: 0.6296 - val_acc: 0.9345 - val_mDice: 0.5518

Epoch 00080: val_mDice did not improve from 0.56671
Epoch 81/300
 - 9s - loss: 0.3025 - acc: 0.9441 - mDice: 0.7246 - val_loss: 0.6260 - val_acc: 0.9369 - val_mDice: 0.5539

Epoch 00081: val_mDice did not improve from 0.56671
Epoch 82/300
 - 10s - loss: 0.2992 - acc: 0.9443 - mDice: 0.7270 - val_loss: 0.6276 - val_acc: 0.9348 - val_mDice: 0.5545

Epoch 00082: val_mDice did not improve from 0.56671
Epoch 83/300
 - 9s - loss: 0.2994 - acc: 0.9442 - mDice: 0.7268 - val_loss: 0.6464 - val_acc: 0.9372 - val_mDice: 0.5523

Epoch 00083: val_mDice did not improve from 0.56671
Epoch 84/300
 - 10s - loss: 0.2964 - acc: 0.9445 - mDice: 0.7292 - val_loss: 0.6141 - val_acc: 0.9383 - val_mDice: 0.5617

Epoch 00084: val_mDice did not improve from 0.56671
Epoch 85/300
 - 10s - loss: 0.2967 - acc: 0.9446 - mDice: 0.7291 - val_loss: 0.6330 - val_acc: 0.9382 - val_mDice: 0.5591

Epoch 00085: val_mDice did not improve from 0.56671
Epoch 86/300
 - 9s - loss: 0.2963 - acc: 0.9445 - mDice: 0.7293 - val_loss: 0.6264 - val_acc: 0.9360 - val_mDice: 0.5530

Epoch 00086: val_mDice did not improve from 0.56671
Epoch 87/300
 - 10s - loss: 0.2950 - acc: 0.9447 - mDice: 0.7302 - val_loss: 0.6169 - val_acc: 0.9374 - val_mDice: 0.5585

Epoch 00087: val_mDice did not improve from 0.56671
Epoch 88/300
 - 9s - loss: 0.2935 - acc: 0.9448 - mDice: 0.7315 - val_loss: 0.6392 - val_acc: 0.9393 - val_mDice: 0.5515

Epoch 00088: val_mDice did not improve from 0.56671
Epoch 89/300
 - 10s - loss: 0.2926 - acc: 0.9449 - mDice: 0.7321 - val_loss: 0.6441 - val_acc: 0.9370 - val_mDice: 0.5499

Epoch 00089: val_mDice did not improve from 0.56671
Epoch 90/300
 - 9s - loss: 0.2929 - acc: 0.9447 - mDice: 0.7319 - val_loss: 0.6291 - val_acc: 0.9409 - val_mDice: 0.5533

Epoch 00090: val_mDice did not improve from 0.56671
Epoch 91/300
 - 10s - loss: 0.2944 - acc: 0.9447 - mDice: 0.7308 - val_loss: 0.6443 - val_acc: 0.9401 - val_mDice: 0.5502

Epoch 00091: val_mDice did not improve from 0.56671
Epoch 92/300
 - 10s - loss: 0.2920 - acc: 0.9450 - mDice: 0.7325 - val_loss: 0.6241 - val_acc: 0.9385 - val_mDice: 0.5616

Epoch 00092: val_mDice did not improve from 0.56671
Epoch 93/300
 - 10s - loss: 0.2909 - acc: 0.9450 - mDice: 0.7334 - val_loss: 0.6342 - val_acc: 0.9358 - val_mDice: 0.5527

Epoch 00093: val_mDice did not improve from 0.56671
Epoch 94/300
 - 10s - loss: 0.2907 - acc: 0.9450 - mDice: 0.7336 - val_loss: 0.6630 - val_acc: 0.9342 - val_mDice: 0.5340

Epoch 00094: val_mDice did not improve from 0.56671
Epoch 95/300
 - 10s - loss: 0.2920 - acc: 0.9449 - mDice: 0.7326 - val_loss: 0.6616 - val_acc: 0.9401 - val_mDice: 0.5638

Epoch 00095: val_mDice did not improve from 0.56671
Epoch 96/300
 - 10s - loss: 0.2920 - acc: 0.9449 - mDice: 0.7326 - val_loss: 0.6460 - val_acc: 0.9342 - val_mDice: 0.5485

Epoch 00096: val_mDice did not improve from 0.56671
Epoch 97/300
 - 9s - loss: 0.2914 - acc: 0.9450 - mDice: 0.7330 - val_loss: 0.6695 - val_acc: 0.9378 - val_mDice: 0.5597

Epoch 00097: val_mDice did not improve from 0.56671
Epoch 98/300
 - 10s - loss: 0.2889 - acc: 0.9452 - mDice: 0.7350 - val_loss: 0.6605 - val_acc: 0.9390 - val_mDice: 0.5650

Epoch 00098: val_mDice did not improve from 0.56671
Epoch 99/300
 - 9s - loss: 0.2898 - acc: 0.9451 - mDice: 0.7343 - val_loss: 0.6800 - val_acc: 0.9373 - val_mDice: 0.5482

Epoch 00099: val_mDice did not improve from 0.56671
Epoch 100/300
 - 10s - loss: 0.2879 - acc: 0.9452 - mDice: 0.7358 - val_loss: 0.6466 - val_acc: 0.9395 - val_mDice: 0.5580

Epoch 00100: val_mDice did not improve from 0.56671
Epoch 101/300
 - 9s - loss: 0.2879 - acc: 0.9452 - mDice: 0.7358 - val_loss: 0.6649 - val_acc: 0.9400 - val_mDice: 0.5611

Epoch 00101: val_mDice did not improve from 0.56671
Epoch 102/300
 - 10s - loss: 0.2892 - acc: 0.9453 - mDice: 0.7347 - val_loss: 0.6670 - val_acc: 0.9374 - val_mDice: 0.5599

Epoch 00102: val_mDice did not improve from 0.56671
Epoch 103/300
 - 10s - loss: 0.2875 - acc: 0.9453 - mDice: 0.7360 - val_loss: 0.6755 - val_acc: 0.9400 - val_mDice: 0.5571

Epoch 00103: val_mDice did not improve from 0.56671
Epoch 104/300
 - 9s - loss: 0.2858 - acc: 0.9454 - mDice: 0.7373 - val_loss: 0.6215 - val_acc: 0.9328 - val_mDice: 0.5567

Epoch 00104: val_mDice did not improve from 0.56671
Epoch 105/300
 - 10s - loss: 0.2861 - acc: 0.9456 - mDice: 0.7371 - val_loss: 0.6500 - val_acc: 0.9364 - val_mDice: 0.5437

Epoch 00105: val_mDice did not improve from 0.56671
Epoch 106/300
 - 9s - loss: 0.2861 - acc: 0.9454 - mDice: 0.7371 - val_loss: 0.6416 - val_acc: 0.9370 - val_mDice: 0.5443

Epoch 00106: val_mDice did not improve from 0.56671
Epoch 107/300
 - 10s - loss: 0.2843 - acc: 0.9455 - mDice: 0.7385 - val_loss: 0.6613 - val_acc: 0.9402 - val_mDice: 0.5536

Epoch 00107: val_mDice did not improve from 0.56671
Epoch 108/300
 - 9s - loss: 0.2842 - acc: 0.9456 - mDice: 0.7385 - val_loss: 0.6267 - val_acc: 0.9395 - val_mDice: 0.5659

Epoch 00108: val_mDice did not improve from 0.56671
Epoch 109/300
 - 9s - loss: 0.2842 - acc: 0.9456 - mDice: 0.7386 - val_loss: 0.6243 - val_acc: 0.9362 - val_mDice: 0.5545

Epoch 00109: val_mDice did not improve from 0.56671
Epoch 110/300
 - 10s - loss: 0.2825 - acc: 0.9458 - mDice: 0.7399 - val_loss: 0.6227 - val_acc: 0.9402 - val_mDice: 0.5607

Epoch 00110: val_mDice did not improve from 0.56671
Epoch 111/300
 - 9s - loss: 0.2826 - acc: 0.9457 - mDice: 0.7398 - val_loss: 0.6214 - val_acc: 0.9379 - val_mDice: 0.5588

Epoch 00111: val_mDice did not improve from 0.56671
Epoch 112/300
 - 10s - loss: 0.2822 - acc: 0.9459 - mDice: 0.7401 - val_loss: 0.6174 - val_acc: 0.9371 - val_mDice: 0.5589

Epoch 00112: val_mDice did not improve from 0.56671
Epoch 113/300
 - 10s - loss: 0.2819 - acc: 0.9460 - mDice: 0.7403 - val_loss: 0.6302 - val_acc: 0.9347 - val_mDice: 0.5506

Epoch 00113: val_mDice did not improve from 0.56671
Epoch 114/300
 - 9s - loss: 0.2825 - acc: 0.9459 - mDice: 0.7399 - val_loss: 0.6646 - val_acc: 0.9371 - val_mDice: 0.5533

Epoch 00114: val_mDice did not improve from 0.56671
Epoch 115/300
 - 10s - loss: 0.2815 - acc: 0.9460 - mDice: 0.7407 - val_loss: 0.6075 - val_acc: 0.9384 - val_mDice: 0.5648

Epoch 00115: val_mDice did not improve from 0.56671
Epoch 116/300
 - 9s - loss: 0.2818 - acc: 0.9459 - mDice: 0.7405 - val_loss: 0.6414 - val_acc: 0.9357 - val_mDice: 0.5469

Epoch 00116: val_mDice did not improve from 0.56671
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [2.333507294838245, 1.7434773995326116, 1.4044751479075506, 1.3323476314544678, 0.9697748376772954, 0.913828962124311, 0.8916197075293615, 0.8875787533246554, 0.8336283495792975, 0.8126362699728745, 0.8123200306525598, 0.8288294306168189, 0.8070821807934687, 0.8193515585019038, 0.8117659687995911, 0.8084130516419044, 0.766939463523718, 0.7628976702690125, 0.7473986584406632, 0.8153155148029327, 0.7661953224585607, 0.7867490924321688, 0.7814013270231394, 0.7645043111764468, 0.750354833327807, 0.7968017206742213, 0.7559709869898282, 0.7575020423302283, 0.7760820434643672, 0.7753545687748835, 0.7044166830869821, 0.733801238811933, 0.7526956773721255, 0.7161345344323379, 0.7310899541928217, 0.7297116472170904, 0.7417307129273047, 0.7257063388824463, 0.7230307597380418, 0.7514678423221295, 0.7056737014880547, 0.7123105296721826, 0.6872842976680169, 0.6977785115058606, 0.7147732583376077, 0.6810857218045455, 0.691657121364887, 0.6654767692089081, 0.6808268198600183, 0.675586081468142, 0.6879777793700879, 0.6837148322508886, 0.6540939028446491, 0.640681422673739, 0.6497957339653602, 0.6643326878547668, 0.6270541342405173, 0.6386818633629725, 0.6479270251897665, 0.6114136003530942, 0.6345688861150008, 0.6338354028188266, 0.6215753371898944, 0.6177947131487039, 0.6145123037008139, 0.6224498702929571, 0.6498617484019353, 0.618845657660411, 0.6359333602281717, 0.6207266381153693, 0.6185784500378829, 0.6192624316765711, 0.610383696280993, 0.6248873357589428, 0.6367064668582036, 0.5944965573457571, 0.6381052847091968, 0.6100433193720304, 0.6030305830331949, 0.6295928083933316, 0.6260093725644625, 0.6275939780932206, 0.6463717887034783, 0.6141424477100372, 0.632954132098418, 0.6264062707240765, 0.6168891306106861, 0.6392366404716785, 0.6441005881016071, 0.6290794290029086, 0.6442808508872986, 0.6240696631945096, 0.634229994737185, 0.6629685988793006, 0.6616498759159675, 0.6459653239983779, 0.6694518167238969, 0.6605100035667419, 0.6800182094940772, 0.6465778763477619, 0.6648798286914825, 0.6669791913949527, 0.675455595438297, 0.6215046208638412, 0.6499998179765848, 0.6416038779112009, 0.6612900931101579, 0.6266816992026109, 0.6243388033830203, 0.6226711846314944, 0.6214270202013162, 0.6173729736071366, 0.6301744855367221, 0.6646040265376751, 0.6075325562403753, 0.641381385234686], 'val_acc': [0.8918500359241779, 0.8471361925968757, 0.8826553065043229, 0.8929502734771142, 0.9202293088802924, 0.917811570259241, 0.9266272072608654, 0.9293384597851679, 0.9321260039622967, 0.9346985794030703, 0.9341369546376742, 0.9329835245242486, 0.9330759736207815, 0.9292159607777228, 0.9366563535653628, 0.927567931321951, 0.9356393218040466, 0.9330967779342945, 0.937620208813594, 0.9292922432606037, 0.9311344279692724, 0.9320612801955297, 0.9365777648412265, 0.9295765299063462, 0.9373381802668939, 0.9294563623575064, 0.9365291870557345, 0.9373405300653898, 0.933283996123534, 0.9338456759086022, 0.9368227536861713, 0.932611380632107, 0.933651538995596, 0.9357456473203806, 0.9295280392353351, 0.9340259570341843, 0.928693576500966, 0.93790681545551, 0.9315435588359833, 0.9378536458198841, 0.9384869428781363, 0.9340329284851367, 0.9371532889512869, 0.9304317533969879, 0.9320983061423669, 0.9339589384885935, 0.9375393046782567, 0.9402505778349363, 0.9372873787696545, 0.9341184221781217, 0.9359744695516733, 0.9397143240158374, 0.9342894577063047, 0.9349967653934772, 0.9363350455577557, 0.9416928497644571, 0.9371140140753526, 0.9402552017798791, 0.9359999069800744, 0.938177241728856, 0.9317215062104739, 0.9357017232821538, 0.9369544959985293, 0.9401303827762604, 0.9364644930912898, 0.937620188181217, 0.9358473511842581, 0.9375693133244147, 0.9353527174546168, 0.9369313693963565, 0.9370585083961487, 0.9394947382119986, 0.9381032929970667, 0.9381472009878892, 0.9389608020965869, 0.9365662244650034, 0.9361455348821787, 0.9390278298121232, 0.93772419828635, 0.9344674486380357, 0.9368782501954299, 0.9347910720568436, 0.9371694899522341, 0.9383390385370988, 0.9381587551190302, 0.9360253558709071, 0.9373936584362617, 0.9393074833429776, 0.9369706786595858, 0.9409463061736181, 0.9401072538816012, 0.9385309035961444, 0.9357849657535553, 0.9341554091526911, 0.9401442179313073, 0.934224749986942, 0.9377888968357673, 0.9390024061386402, 0.9373312615431272, 0.93951088648576, 0.9400471723996676, 0.937372856415235, 0.9399962769104884, 0.9328425618318411, 0.9364182398869441, 0.9370146026978126, 0.9402389801465548, 0.9395432839026818, 0.9362056163641123, 0.9401904321633853, 0.9379276312314547, 0.9370724214957311, 0.9347494680147904, 0.9370631438035232, 0.9384083885412949, 0.9356809189686408], 'val_mDice': [0.1635102818791683, 0.2602151408791542, 0.35035952581809116, 0.367990795809489, 0.4699212507559703, 0.487622975729979, 0.5015356609454522, 0.49744956424603093, 0.5283005283429072, 0.5376883791043208, 0.5325658436004932, 0.5333924196087397, 0.533591859615766, 0.5294711658587823, 0.5388619664769906, 0.5323060515981454, 0.5578972559708816, 0.5494549572467804, 0.5621939765719267, 0.5312498945456284, 0.5471860399613013, 0.5490837962581561, 0.5477016763045237, 0.5427284664832629, 0.5529347130885491, 0.5318704213087375, 0.5467978990994967, 0.5514028439154992, 0.540566762479452, 0.543421168739979, 0.5550722600175784, 0.5548654508132201, 0.5463984700349661, 0.5534713428754073, 0.5432246568111273, 0.5518670821419129, 0.5347710142915065, 0.5513447087544662, 0.547685964176288, 0.5492560404997605, 0.5526302772072645, 0.5616499993663567, 0.5562502558414752, 0.5463767452881887, 0.5407216044572684, 0.5532694241175284, 0.5466151707447492, 0.5579144307054006, 0.5472089315836246, 0.5489686910922711, 0.5562418813888843, 0.5510053588793828, 0.5497039762827066, 0.5586138614095174, 0.5595352351665497, 0.5622451356970347, 0.5595482668051353, 0.5558129858512145, 0.546468158180897, 0.5660789522987145, 0.5524716893067727, 0.5562979223636481, 0.5594073339150503, 0.5607894148964149, 0.5664952276990964, 0.558660208605803, 0.5473913997411728, 0.5604751637348762, 0.5492582601996568, 0.5612525911285327, 0.5592247843742371, 0.5581833863487611, 0.5621575965331151, 0.5579325516636555, 0.5475980473252443, 0.5667098548549873, 0.5474846070775619, 0.5640779687808111, 0.5666834517167165, 0.5518059822229239, 0.5538707043115909, 0.5545256705238268, 0.5522684999383413, 0.5616881535030328, 0.5591441470269973, 0.5529667494388727, 0.5584535186107342, 0.5515194956499797, 0.549881424754858, 0.553344894773685, 0.5502102375030518, 0.5616239733420886, 0.5527436847870166, 0.5339958335344608, 0.563795923613585, 0.5485369929900537, 0.5597481423845658, 0.5649739435085883, 0.5482012351545004, 0.5579837523400784, 0.5610827958354583, 0.5598605384047215, 0.5570557309457889, 0.5567447182077628, 0.5437427306404481, 0.5442676303478388, 0.5535637856676028, 0.5659440119679158, 0.5545382270446191, 0.5607013650811635, 0.5588257673841256, 0.5589424022115194, 0.550564645574643, 0.5532531996185963, 0.5648087051052314, 0.5468976033421663], 'loss': [3.1828808025670408, 1.3502209858734713, 0.9298597429496362, 0.7783961175695883, 0.6986182071258251, 0.6457367664354046, 0.6061821273307041, 0.5707521532598395, 0.5477235284687617, 0.5205473011186244, 0.5047873491116427, 0.49057639713801, 0.4759905568064551, 0.46580722535282093, 0.45765349562181534, 0.4462240988298128, 0.4368801431402799, 0.43104265001518727, 0.4240725666523683, 0.4183573952973862, 0.4100768194392765, 0.406049933431224, 0.40155950900231474, 0.39628877946396635, 0.39335300046876714, 0.38831905307809794, 0.38484265656035005, 0.38030733760845875, 0.37742629869611105, 0.3727072346675531, 0.37443771538375586, 0.3688340940280208, 0.3653872376750187, 0.3650392347141615, 0.3623532053400293, 0.3574104798567929, 0.35663475513865034, 0.3538436852543268, 0.35069294752235136, 0.3478586810311081, 0.3454878046664762, 0.34441839320286055, 0.3434063719914846, 0.3388441622499103, 0.33865538410437696, 0.3373373590837839, 0.33508101432490345, 0.3317102189297321, 0.331806703150014, 0.33031430836644304, 0.32777489913210245, 0.3306059860703823, 0.32618009372356904, 0.32570760438420904, 0.32365262332486344, 0.3214948878020672, 0.3229900971116873, 0.31818580246495, 0.3194094351805038, 0.31914395798641215, 0.31593422975793467, 0.31533488916546, 0.31416903079012315, 0.31247642647842966, 0.3107421109594565, 0.3104303415676088, 0.3107295416630162, 0.3084120340978573, 0.30987463828977113, 0.30607963863866394, 0.30595241900817566, 0.30709106671428654, 0.3060620239956687, 0.30513326566586313, 0.30484878913531455, 0.3032223385115628, 0.30069282649573303, 0.2997693901328949, 0.2993261438503176, 0.3002673326565047, 0.30246973089941814, 0.2992498414697632, 0.2994427730745136, 0.29639009728836724, 0.29666225218986175, 0.29628732102081956, 0.2950071581865846, 0.2934698374890582, 0.29261499769483384, 0.29287206276221917, 0.294434855905701, 0.29196961093936186, 0.2909245057392085, 0.29073066182003726, 0.2919850816484154, 0.2920229453794479, 0.291383584462265, 0.28885092587584466, 0.2897727842960016, 0.2878646896431436, 0.28785769929582866, 0.28920286589582217, 0.2875049407165736, 0.2857563721620211, 0.28613290452356877, 0.286144269427437, 0.28430548156362107, 0.2841899815761635, 0.2842123458814898, 0.28250898873081487, 0.28259573796738074, 0.28223834543070714, 0.2819334651412839, 0.28251627744766855, 0.2814968318904248, 0.2817934527161772], 'acc': [0.3860651200781004, 0.8736806021760907, 0.8941470574246422, 0.9040164837183728, 0.9096031456396917, 0.9136060204033613, 0.9168943175583059, 0.9197659226269956, 0.9218129680065017, 0.9240872760073215, 0.9255505826962914, 0.9268875609494812, 0.9282116804144473, 0.9292019757465453, 0.9300343316001315, 0.9310172652666127, 0.931983212065589, 0.9325626162731547, 0.9332967838831606, 0.9337562697241362, 0.934541049252508, 0.9350000710314977, 0.9353627651960089, 0.935604880362499, 0.9360588215807537, 0.9364682525151727, 0.936704710880395, 0.9371113216515277, 0.9374420939694139, 0.9377795105478283, 0.9377187918739368, 0.9380944335437575, 0.9384488341037192, 0.938563653219563, 0.9388325658438665, 0.9391915625799387, 0.9391852406506431, 0.9395001594962905, 0.9396308476135738, 0.9398346362403758, 0.9401320368614978, 0.940272833097578, 0.9403043398170644, 0.9407603679784691, 0.9408239493464166, 0.9409857674915061, 0.9413573740703488, 0.9414432349871701, 0.941521422807816, 0.9415170603557936, 0.941843371554889, 0.9416357115616077, 0.9420500590848954, 0.9420204412604042, 0.9421588437952789, 0.9424094031803241, 0.9422869423675239, 0.9426727338458607, 0.9426378613961619, 0.9426035463595581, 0.942905782746244, 0.9428159497897475, 0.9430282482645295, 0.9431345488140529, 0.943151088341635, 0.9432648396531583, 0.9432331833860965, 0.9433390438957957, 0.9433607673673604, 0.943658063571787, 0.943721843482625, 0.9436968166560119, 0.9437028023794899, 0.9437476055412992, 0.9438235793047304, 0.9440376921948126, 0.94411905474475, 0.9442230565438222, 0.9442100418534192, 0.944142533708606, 0.9441026733786398, 0.9442653758910863, 0.944179781257452, 0.9445479298433914, 0.9445730451562138, 0.9445484361777851, 0.944698166690013, 0.9447830347769443, 0.944884128998448, 0.9447496694897546, 0.9447432407745299, 0.9449942691744138, 0.9449798787507604, 0.9449659994109623, 0.9449160743505106, 0.9449429250748562, 0.9449980392685172, 0.9451985172951429, 0.9450939634865878, 0.9452108191375219, 0.9452411027881675, 0.9453358975028922, 0.945342194514005, 0.9454127181327223, 0.9455507419310097, 0.9453996374665795, 0.9454960095028172, 0.9455891900877006, 0.9456192473253509, 0.9458435592886202, 0.9457262846186275, 0.9458797655234882, 0.9459518598012793, 0.9458990736574108, 0.9459727424532134, 0.945940173019686], 'mDice': [0.0714006786302789, 0.26239423660909644, 0.38536803893670046, 0.44770808591181244, 0.4850199937320202, 0.5113110444229775, 0.5320184555790757, 0.5511983891348332, 0.5638697255881392, 0.5795954336795069, 0.5887482867715412, 0.5974078035152323, 0.6063081933422347, 0.6125241017952887, 0.6176203013697773, 0.6248122392012538, 0.6308570177278252, 0.6345415772860048, 0.6391750688395861, 0.6429606039486918, 0.6482399833396958, 0.651055046264881, 0.6539863319862244, 0.6575116082265964, 0.6595312929412904, 0.662888760640592, 0.6654360245693041, 0.6684833655528429, 0.6704298111825788, 0.6737561141676122, 0.6725209139264796, 0.6763909250555538, 0.6787924939588044, 0.6791979854346355, 0.6809862545965167, 0.6844070673120821, 0.685018795536836, 0.6869832005523221, 0.6892015719275232, 0.6912108326842179, 0.6929236866776314, 0.6937537822876867, 0.6945684304495068, 0.697775981291671, 0.6978486557733767, 0.6988648159866963, 0.7004785109168762, 0.7028576748667745, 0.7028352557529902, 0.7038897763733977, 0.7057282510888232, 0.7036431200728803, 0.7069459044932219, 0.7073080458017026, 0.7087979273284635, 0.7103697687873957, 0.709224333152289, 0.7127648997458542, 0.7119643638948228, 0.7121159513201384, 0.7144873219860949, 0.7148757288841417, 0.7157614495408366, 0.7170460223491963, 0.7182396015018859, 0.7186080678619934, 0.7183914844767475, 0.7200565733483475, 0.7190284904250247, 0.7218653164116162, 0.721949126973733, 0.7211213163384914, 0.7218103457242594, 0.7226315297830218, 0.7228721733255096, 0.7240426466549211, 0.7259617683237289, 0.7266328207166567, 0.7269946435693334, 0.7262499866962301, 0.724620390672762, 0.727037542043088, 0.7268437042696322, 0.729194191343657, 0.7290914482838617, 0.7292569739774817, 0.730212082922662, 0.7314501034425192, 0.7320852179671525, 0.7319372510388913, 0.7307865458540532, 0.7325315534392374, 0.7334363185467782, 0.7335645237235492, 0.7325580942282254, 0.7325892591568791, 0.7330152495567247, 0.7349922885965577, 0.7343454866361807, 0.7357548071726171, 0.7357562002985721, 0.7347333942305764, 0.7359905811865853, 0.7373400902952598, 0.7370547027503456, 0.737070497002734, 0.7384793659005451, 0.7385148101986241, 0.7386064993480931, 0.7398605395053834, 0.7397784021610287, 0.7401395477371705, 0.7403360783784446, 0.7398729366998023, 0.7406886746047179, 0.7404835258123456]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.07s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.74s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:15,  1.74s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:38,  1.62s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:33,  1.61s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:13,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:12,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:33,  1.63s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:52,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:05,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:30,  1.65s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:40,  1.69s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:28,  1.65s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:45,  1.72s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:54,  1.76s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:40,  1.72s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:24,  1.67s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:29,  1.70s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:46,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:35,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:15,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.75s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:44,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:17,  1.70s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:24,  1.73s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:26,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:33,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:34,  1.79s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:18,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:13,  1.72s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:12,  1.72s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:18,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:14,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:17,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:31,  1.83s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<07:06,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:06,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:56,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:39,  1.64s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:41,  1.66s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:02,  1.75s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:48,  1.70s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:55,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<07:01,  1.78s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:09,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:09,  1.83s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:11,  1.85s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:50,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:54,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<07:06,  1.85s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:49,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:43,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:29,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:26,  1.70s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:34,  1.74s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:37,  1.76s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:24,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:33,  1.76s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:28,  1.75s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:18,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:23,  1.75s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:27,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:18,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:12,  1.73s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:20,  1.78s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:06,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<06:01,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:01,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:01,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<05:55,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:40,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:31,  1.60s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:47,  1.70s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:36,  1.65s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:28,  1.63s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:37,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:40,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:36,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:27,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:34,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:27,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:30,  1.74s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:20,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:21,  1.71s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:24,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:18,  1.71s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:17,  1.72s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:08,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:03,  1.67s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<05:17,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<05:10,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<05:01,  1.69s/it]predicting train subjects:  38%|███▊      | 107/285 [03:03<05:09,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<05:03,  1.71s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<05:01,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:08<05:08,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<04:54,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:55,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<05:00,  1.75s/it]predicting train subjects:  40%|████      | 114/285 [03:15<04:59,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:17<04:54,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:49,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:20<04:41,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:22<04:36,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:45,  1.72s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<04:29,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:18,  1.57s/it]predicting train subjects:  43%|████▎     | 122/285 [03:28<04:07,  1.52s/it]predicting train subjects:  43%|████▎     | 123/285 [03:29<04:03,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:31<04:10,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:32<04:00,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:34<03:56,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<03:50,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:37<03:56,  1.50s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:47,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:40<03:42,  1.44s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<03:37,  1.41s/it]predicting train subjects:  46%|████▋     | 132/285 [03:43<03:39,  1.44s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:36,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:35,  1.42s/it]predicting train subjects:  47%|████▋     | 135/285 [03:47<03:30,  1.40s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:50<03:35,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:51<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:53<03:37,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:54<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [03:56<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [03:57<03:30,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [03:59<03:25,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [04:00<03:29,  1.48s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:31,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:03<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:06<03:33,  1.56s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:09<03:21,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:12<03:22,  1.52s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:14<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:15<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:19<03:24,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:15,  1.53s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:22<03:19,  1.57s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:23<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<03:12,  1.54s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:26<03:08,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<03:05,  1.51s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:29<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:31<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:32<03:01,  1.51s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<03:00,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<03:00,  1.53s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:37<02:53,  1.49s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:39<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:42<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:46,  1.49s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:46,  1.51s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:48<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:53<02:41,  1.52s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:55<02:49,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:49,  1.63s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:58<02:52,  1.67s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:00<02:42,  1.59s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:01<02:34,  1.53s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:25,  1.46s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:04<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:06<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:08<02:47,  1.73s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:09<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:11<02:29,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:12<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:14<02:28,  1.60s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:15<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:17<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:18<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:20<02:19,  1.57s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:22<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:24<02:27,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:25<02:16,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:26<02:08,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:28<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:30<02:14,  1.63s/it]predicting train subjects:  71%|███████   | 203/285 [05:31<02:14,  1.64s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:33<02:05,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:34<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:36<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:37<02:04,  1.60s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:39<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:41<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:43<02:00,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:44<01:57,  1.58s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<01:55,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:47<01:54,  1.60s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:50<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:52<01:43,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:55<01:48,  1.62s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:57<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:58<01:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:00<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:01<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:03<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:04<01:31,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:06<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:07<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:09<01:33,  1.61s/it]predicting train subjects:  80%|████████  | 228/285 [06:11<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [06:13<01:33,  1.67s/it]predicting train subjects:  81%|████████  | 230/285 [06:14<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:15<01:22,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:17<01:22,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:18<01:19,  1.53s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:20<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:22<01:17,  1.56s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:23<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:25<01:19,  1.65s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:27<01:21,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:29<01:19,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:30<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:31<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:33<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:34<01:00,  1.44s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:36<01:02,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:37<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:39<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:41<01:01,  1.62s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:42<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:44<00:55,  1.53s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:45<00:53,  1.53s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:47<00:50,  1.49s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:48<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:50<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:52<00:51,  1.66s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:53<00:50,  1.67s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:55<00:46,  1.61s/it]predicting train subjects:  90%|█████████ | 257/285 [06:56<00:44,  1.57s/it]predicting train subjects:  91%|█████████ | 258/285 [06:58<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:00<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:01<00:39,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:03<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:04<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:05<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:07<00:32,  1.54s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:09<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:10<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:11<00:26,  1.46s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:13<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:15<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:16<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:18<00:21,  1.53s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:19<00:20,  1.57s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:21<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:22<00:16,  1.52s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:24<00:16,  1.62s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:26<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:27<00:12,  1.60s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:29<00:10,  1.56s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:31<00:09,  1.59s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:32<00:07,  1.53s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:33<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:35<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:37<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:39<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 285/285 [07:40<00:00,  1.71s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:43,  1.84s/it]Loading train:   1%|          | 2/285 [00:03<08:20,  1.77s/it]Loading train:   1%|          | 3/285 [00:04<07:47,  1.66s/it]Loading train:   1%|▏         | 4/285 [00:06<07:31,  1.61s/it]Loading train:   2%|▏         | 5/285 [00:08<07:55,  1.70s/it]Loading train:   2%|▏         | 6/285 [00:09<07:32,  1.62s/it]Loading train:   2%|▏         | 7/285 [00:11<08:05,  1.75s/it]Loading train:   3%|▎         | 8/285 [00:13<07:32,  1.63s/it]Loading train:   3%|▎         | 9/285 [00:14<07:41,  1.67s/it]Loading train:   4%|▎         | 10/285 [00:16<07:22,  1.61s/it]Loading train:   4%|▍         | 11/285 [00:17<06:27,  1.42s/it]Loading train:   4%|▍         | 12/285 [00:18<05:53,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:19<05:28,  1.21s/it]Loading train:   5%|▍         | 14/285 [00:20<05:40,  1.26s/it]Loading train:   5%|▌         | 15/285 [00:22<06:00,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:23<05:46,  1.29s/it]Loading train:   6%|▌         | 17/285 [00:24<05:22,  1.20s/it]Loading train:   6%|▋         | 18/285 [00:25<05:19,  1.20s/it]Loading train:   7%|▋         | 19/285 [00:26<05:10,  1.17s/it]Loading train:   7%|▋         | 20/285 [00:27<04:49,  1.09s/it]Loading train:   7%|▋         | 21/285 [00:28<04:52,  1.11s/it]Loading train:   8%|▊         | 22/285 [00:29<04:44,  1.08s/it]Loading train:   8%|▊         | 23/285 [00:30<04:41,  1.08s/it]Loading train:   8%|▊         | 24/285 [00:31<04:26,  1.02s/it]Loading train:   9%|▉         | 25/285 [00:33<05:02,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:34<04:59,  1.16s/it]Loading train:   9%|▉         | 27/285 [00:35<04:50,  1.13s/it]Loading train:  10%|▉         | 28/285 [00:36<05:12,  1.21s/it]Loading train:  10%|█         | 29/285 [00:37<05:07,  1.20s/it]Loading train:  11%|█         | 30/285 [00:39<05:02,  1.19s/it]Loading train:  11%|█         | 31/285 [00:40<05:14,  1.24s/it]Loading train:  11%|█         | 32/285 [00:41<04:46,  1.13s/it]Loading train:  12%|█▏        | 33/285 [00:42<05:13,  1.25s/it]Loading train:  12%|█▏        | 34/285 [00:44<05:25,  1.30s/it]Loading train:  12%|█▏        | 35/285 [00:45<05:34,  1.34s/it]Loading train:  13%|█▎        | 36/285 [00:46<05:19,  1.28s/it]Loading train:  13%|█▎        | 37/285 [00:48<05:16,  1.28s/it]Loading train:  13%|█▎        | 38/285 [00:49<05:11,  1.26s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:39,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:24,  1.08s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:27,  1.10s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:02,  1.00it/s]Loading train:  15%|█▌        | 43/285 [00:54<04:27,  1.10s/it]Loading train:  15%|█▌        | 44/285 [00:55<04:25,  1.10s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:10,  1.04s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:09,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:58<03:51,  1.03it/s]Loading train:  17%|█▋        | 48/285 [00:59<04:30,  1.14s/it]Loading train:  17%|█▋        | 49/285 [01:01<04:38,  1.18s/it]Loading train:  18%|█▊        | 50/285 [01:02<04:39,  1.19s/it]Loading train:  18%|█▊        | 51/285 [01:03<04:58,  1.27s/it]Loading train:  18%|█▊        | 52/285 [01:04<04:45,  1.22s/it]Loading train:  19%|█▊        | 53/285 [01:05<04:22,  1.13s/it]Loading train:  19%|█▉        | 54/285 [01:07<04:46,  1.24s/it]Loading train:  19%|█▉        | 55/285 [01:08<04:17,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:09<04:17,  1.12s/it]Loading train:  20%|██        | 57/285 [01:10<04:06,  1.08s/it]Loading train:  20%|██        | 58/285 [01:11<04:23,  1.16s/it]Loading train:  21%|██        | 59/285 [01:13<04:44,  1.26s/it]Loading train:  21%|██        | 60/285 [01:14<04:28,  1.19s/it]Loading train:  21%|██▏       | 61/285 [01:15<04:14,  1.14s/it]Loading train:  22%|██▏       | 62/285 [01:16<04:43,  1.27s/it]Loading train:  22%|██▏       | 63/285 [01:17<04:19,  1.17s/it]Loading train:  22%|██▏       | 64/285 [01:19<04:40,  1.27s/it]Loading train:  23%|██▎       | 65/285 [01:20<05:17,  1.44s/it]Loading train:  23%|██▎       | 66/285 [01:22<05:09,  1.41s/it]Loading train:  24%|██▎       | 67/285 [01:23<04:57,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:24<04:34,  1.26s/it]Loading train:  24%|██▍       | 69/285 [01:25<04:24,  1.22s/it]Loading train:  25%|██▍       | 70/285 [01:27<04:30,  1.26s/it]Loading train:  25%|██▍       | 71/285 [01:28<04:12,  1.18s/it]Loading train:  25%|██▌       | 72/285 [01:29<04:00,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:29<03:42,  1.05s/it]Loading train:  26%|██▌       | 74/285 [01:30<03:30,  1.00it/s]Loading train:  26%|██▋       | 75/285 [01:31<03:37,  1.04s/it]Loading train:  27%|██▋       | 76/285 [01:33<03:43,  1.07s/it]Loading train:  27%|██▋       | 77/285 [01:33<03:28,  1.00s/it]Loading train:  27%|██▋       | 78/285 [01:34<03:30,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:36<03:36,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:37<03:34,  1.05s/it]Loading train:  28%|██▊       | 81/285 [01:38<03:24,  1.00s/it]Loading train:  29%|██▉       | 82/285 [01:39<03:22,  1.00it/s]Loading train:  29%|██▉       | 83/285 [01:40<03:39,  1.09s/it]Loading train:  29%|██▉       | 84/285 [01:41<03:30,  1.05s/it]Loading train:  30%|██▉       | 85/285 [01:42<03:28,  1.04s/it]Loading train:  30%|███       | 86/285 [01:43<03:39,  1.10s/it]Loading train:  31%|███       | 87/285 [01:44<03:53,  1.18s/it]Loading train:  31%|███       | 88/285 [01:45<03:34,  1.09s/it]Loading train:  31%|███       | 89/285 [01:46<03:39,  1.12s/it]Loading train:  32%|███▏      | 90/285 [01:48<03:50,  1.18s/it]Loading train:  32%|███▏      | 91/285 [01:49<03:28,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:50<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:51<03:29,  1.09s/it]Loading train:  33%|███▎      | 94/285 [01:52<03:42,  1.17s/it]Loading train:  33%|███▎      | 95/285 [01:54<03:48,  1.20s/it]Loading train:  34%|███▎      | 96/285 [01:55<03:33,  1.13s/it]Loading train:  34%|███▍      | 97/285 [01:56<03:46,  1.21s/it]Loading train:  34%|███▍      | 98/285 [01:57<03:53,  1.25s/it]Loading train:  35%|███▍      | 99/285 [01:58<03:29,  1.13s/it]Loading train:  35%|███▌      | 100/285 [01:59<03:34,  1.16s/it]Loading train:  35%|███▌      | 101/285 [02:00<03:26,  1.12s/it]Loading train:  36%|███▌      | 102/285 [02:02<03:36,  1.19s/it]Loading train:  36%|███▌      | 103/285 [02:03<03:22,  1.12s/it]Loading train:  36%|███▋      | 104/285 [02:04<03:29,  1.16s/it]Loading train:  37%|███▋      | 105/285 [02:05<03:32,  1.18s/it]Loading train:  37%|███▋      | 106/285 [02:06<03:30,  1.18s/it]Loading train:  38%|███▊      | 107/285 [02:07<03:22,  1.14s/it]Loading train:  38%|███▊      | 108/285 [02:08<03:17,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:09<03:12,  1.09s/it]Loading train:  39%|███▊      | 110/285 [02:11<03:27,  1.19s/it]Loading train:  39%|███▉      | 111/285 [02:12<03:01,  1.04s/it]Loading train:  39%|███▉      | 112/285 [02:13<03:12,  1.11s/it]Loading train:  40%|███▉      | 113/285 [02:14<03:10,  1.11s/it]Loading train:  40%|████      | 114/285 [02:15<02:59,  1.05s/it]Loading train:  40%|████      | 115/285 [02:16<03:06,  1.10s/it]Loading train:  41%|████      | 116/285 [02:17<03:00,  1.07s/it]Loading train:  41%|████      | 117/285 [02:18<03:09,  1.13s/it]Loading train:  41%|████▏     | 118/285 [02:19<03:04,  1.10s/it]Loading train:  42%|████▏     | 119/285 [02:21<03:08,  1.13s/it]Loading train:  42%|████▏     | 120/285 [02:22<03:06,  1.13s/it]Loading train:  42%|████▏     | 121/285 [02:23<03:21,  1.23s/it]Loading train:  43%|████▎     | 122/285 [02:24<03:17,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:26<03:27,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:27<03:06,  1.16s/it]Loading train:  44%|████▍     | 125/285 [02:28<03:03,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:29<03:04,  1.16s/it]Loading train:  45%|████▍     | 127/285 [02:30<02:48,  1.07s/it]Loading train:  45%|████▍     | 128/285 [02:31<02:58,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:32<02:46,  1.07s/it]Loading train:  46%|████▌     | 130/285 [02:33<02:32,  1.01it/s]Loading train:  46%|████▌     | 131/285 [02:34<02:31,  1.02it/s]Loading train:  46%|████▋     | 132/285 [02:35<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:36<02:24,  1.05it/s]Loading train:  47%|████▋     | 134/285 [02:36<02:17,  1.10it/s]Loading train:  47%|████▋     | 135/285 [02:37<02:14,  1.12it/s]Loading train:  48%|████▊     | 136/285 [02:38<02:07,  1.17it/s]Loading train:  48%|████▊     | 137/285 [02:40<02:41,  1.09s/it]Loading train:  48%|████▊     | 138/285 [02:41<02:32,  1.04s/it]Loading train:  49%|████▉     | 139/285 [02:42<02:23,  1.02it/s]Loading train:  49%|████▉     | 140/285 [02:42<02:17,  1.05it/s]Loading train:  49%|████▉     | 141/285 [02:43<02:09,  1.11it/s]Loading train:  50%|████▉     | 142/285 [02:44<02:20,  1.02it/s]Loading train:  50%|█████     | 143/285 [02:45<02:18,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:47<02:28,  1.05s/it]Loading train:  51%|█████     | 145/285 [02:48<02:25,  1.04s/it]Loading train:  51%|█████     | 146/285 [02:49<02:23,  1.03s/it]Loading train:  52%|█████▏    | 147/285 [02:49<02:16,  1.01it/s]Loading train:  52%|█████▏    | 148/285 [02:50<02:11,  1.04it/s]Loading train:  52%|█████▏    | 149/285 [02:51<02:12,  1.03it/s]Loading train:  53%|█████▎    | 150/285 [02:52<02:17,  1.02s/it]Loading train:  53%|█████▎    | 151/285 [02:54<02:19,  1.04s/it]Loading train:  53%|█████▎    | 152/285 [02:55<02:15,  1.02s/it]Loading train:  54%|█████▎    | 153/285 [02:55<02:11,  1.00it/s]Loading train:  54%|█████▍    | 154/285 [02:56<02:10,  1.00it/s]Loading train:  54%|█████▍    | 155/285 [02:57<02:04,  1.04it/s]Loading train:  55%|█████▍    | 156/285 [02:58<02:01,  1.06it/s]Loading train:  55%|█████▌    | 157/285 [02:59<01:56,  1.10it/s]Loading train:  55%|█████▌    | 158/285 [03:00<01:52,  1.13it/s]Loading train:  56%|█████▌    | 159/285 [03:01<01:48,  1.16it/s]Loading train:  56%|█████▌    | 160/285 [03:02<01:46,  1.18it/s]Loading train:  56%|█████▋    | 161/285 [03:03<01:58,  1.04it/s]Loading train:  57%|█████▋    | 162/285 [03:04<02:00,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [03:05<01:58,  1.03it/s]Loading train:  58%|█████▊    | 164/285 [03:06<01:53,  1.06it/s]Loading train:  58%|█████▊    | 165/285 [03:07<01:55,  1.04it/s]Loading train:  58%|█████▊    | 166/285 [03:08<01:56,  1.02it/s]Loading train:  59%|█████▊    | 167/285 [03:09<02:01,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [03:10<02:04,  1.07s/it]Loading train:  59%|█████▉    | 169/285 [03:11<01:55,  1.00it/s]Loading train:  60%|█████▉    | 170/285 [03:12<01:48,  1.06it/s]Loading train:  60%|██████    | 171/285 [03:13<01:55,  1.01s/it]Loading train:  60%|██████    | 172/285 [03:14<01:55,  1.02s/it]Loading train:  61%|██████    | 173/285 [03:15<01:55,  1.03s/it]Loading train:  61%|██████    | 174/285 [03:16<01:47,  1.04it/s]Loading train:  61%|██████▏   | 175/285 [03:17<01:55,  1.05s/it]Loading train:  62%|██████▏   | 176/285 [03:18<01:54,  1.05s/it]Loading train:  62%|██████▏   | 177/285 [03:19<01:49,  1.01s/it]Loading train:  62%|██████▏   | 178/285 [03:20<01:56,  1.09s/it]Loading train:  63%|██████▎   | 179/285 [03:21<01:53,  1.07s/it]Loading train:  63%|██████▎   | 180/285 [03:22<01:54,  1.09s/it]Loading train:  64%|██████▎   | 181/285 [03:23<01:44,  1.00s/it]Loading train:  64%|██████▍   | 182/285 [03:24<01:43,  1.00s/it]Loading train:  64%|██████▍   | 183/285 [03:25<01:36,  1.05it/s]Loading train:  65%|██████▍   | 184/285 [03:26<01:37,  1.04it/s]Loading train:  65%|██████▍   | 185/285 [03:27<01:37,  1.02it/s]Loading train:  65%|██████▌   | 186/285 [03:28<01:40,  1.02s/it]Loading train:  66%|██████▌   | 187/285 [03:29<01:49,  1.11s/it]Loading train:  66%|██████▌   | 188/285 [03:31<01:51,  1.15s/it]Loading train:  66%|██████▋   | 189/285 [03:32<01:43,  1.08s/it]Loading train:  67%|██████▋   | 190/285 [03:32<01:37,  1.02s/it]Loading train:  67%|██████▋   | 191/285 [03:33<01:35,  1.02s/it]Loading train:  67%|██████▋   | 192/285 [03:35<01:36,  1.03s/it]Loading train:  68%|██████▊   | 193/285 [03:36<01:35,  1.04s/it]Loading train:  68%|██████▊   | 194/285 [03:36<01:31,  1.00s/it]Loading train:  68%|██████▊   | 195/285 [03:38<01:30,  1.01s/it]Loading train:  69%|██████▉   | 196/285 [03:39<01:35,  1.07s/it]Loading train:  69%|██████▉   | 197/285 [03:40<01:35,  1.08s/it]Loading train:  69%|██████▉   | 198/285 [03:41<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [03:41<01:19,  1.08it/s]Loading train:  70%|███████   | 200/285 [03:42<01:20,  1.06it/s]Loading train:  71%|███████   | 201/285 [03:44<01:25,  1.02s/it]Loading train:  71%|███████   | 202/285 [03:45<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:45<01:18,  1.04it/s]Loading train:  72%|███████▏  | 204/285 [03:47<01:21,  1.01s/it]Loading train:  72%|███████▏  | 205/285 [03:48<01:21,  1.02s/it]Loading train:  72%|███████▏  | 206/285 [03:49<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [03:50<01:26,  1.11s/it]Loading train:  73%|███████▎  | 208/285 [03:51<01:21,  1.06s/it]Loading train:  73%|███████▎  | 209/285 [03:52<01:26,  1.13s/it]Loading train:  74%|███████▎  | 210/285 [03:53<01:24,  1.12s/it]Loading train:  74%|███████▍  | 211/285 [03:54<01:19,  1.07s/it]Loading train:  74%|███████▍  | 212/285 [03:55<01:13,  1.01s/it]Loading train:  75%|███████▍  | 213/285 [03:56<01:09,  1.04it/s]Loading train:  75%|███████▌  | 214/285 [03:57<01:09,  1.02it/s]Loading train:  75%|███████▌  | 215/285 [03:59<01:19,  1.13s/it]Loading train:  76%|███████▌  | 216/285 [04:00<01:18,  1.14s/it]Loading train:  76%|███████▌  | 217/285 [04:01<01:18,  1.15s/it]Loading train:  76%|███████▋  | 218/285 [04:02<01:15,  1.12s/it]Loading train:  77%|███████▋  | 219/285 [04:03<01:19,  1.20s/it]Loading train:  77%|███████▋  | 220/285 [04:05<01:17,  1.19s/it]Loading train:  78%|███████▊  | 221/285 [04:05<01:11,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [04:07<01:09,  1.10s/it]Loading train:  78%|███████▊  | 223/285 [04:07<01:03,  1.02s/it]Loading train:  79%|███████▊  | 224/285 [04:08<01:02,  1.03s/it]Loading train:  79%|███████▉  | 225/285 [04:09<01:00,  1.01s/it]Loading train:  79%|███████▉  | 226/285 [04:10<01:00,  1.03s/it]Loading train:  80%|███████▉  | 227/285 [04:12<01:02,  1.07s/it]Loading train:  80%|████████  | 228/285 [04:13<01:00,  1.05s/it]Loading train:  80%|████████  | 229/285 [04:14<00:57,  1.03s/it]Loading train:  81%|████████  | 230/285 [04:14<00:49,  1.11it/s]Loading train:  81%|████████  | 231/285 [04:15<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [04:16<00:52,  1.02it/s]Loading train:  82%|████████▏ | 233/285 [04:17<00:53,  1.03s/it]Loading train:  82%|████████▏ | 234/285 [04:19<01:01,  1.21s/it]Loading train:  82%|████████▏ | 235/285 [04:20<00:54,  1.09s/it]Loading train:  83%|████████▎ | 236/285 [04:21<00:58,  1.19s/it]Loading train:  83%|████████▎ | 237/285 [04:23<01:01,  1.28s/it]Loading train:  84%|████████▎ | 238/285 [04:24<00:56,  1.20s/it]Loading train:  84%|████████▍ | 239/285 [04:25<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [04:26<00:51,  1.14s/it]Loading train:  85%|████████▍ | 241/285 [04:27<00:50,  1.16s/it]Loading train:  85%|████████▍ | 242/285 [04:28<00:46,  1.09s/it]Loading train:  85%|████████▌ | 243/285 [04:29<00:42,  1.00s/it]Loading train:  86%|████████▌ | 244/285 [04:30<00:42,  1.05s/it]Loading train:  86%|████████▌ | 245/285 [04:31<00:40,  1.02s/it]Loading train:  86%|████████▋ | 246/285 [04:32<00:42,  1.08s/it]Loading train:  87%|████████▋ | 247/285 [04:33<00:39,  1.04s/it]Loading train:  87%|████████▋ | 248/285 [04:34<00:35,  1.03it/s]Loading train:  87%|████████▋ | 249/285 [04:35<00:34,  1.05it/s]Loading train:  88%|████████▊ | 250/285 [04:36<00:35,  1.01s/it]Loading train:  88%|████████▊ | 251/285 [04:37<00:34,  1.02s/it]Loading train:  88%|████████▊ | 252/285 [04:38<00:32,  1.03it/s]Loading train:  89%|████████▉ | 253/285 [04:39<00:34,  1.07s/it]Loading train:  89%|████████▉ | 254/285 [04:40<00:33,  1.07s/it]Loading train:  89%|████████▉ | 255/285 [04:41<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [04:42<00:27,  1.05it/s]Loading train:  90%|█████████ | 257/285 [04:43<00:27,  1.01it/s]Loading train:  91%|█████████ | 258/285 [04:45<00:30,  1.13s/it]Loading train:  91%|█████████ | 259/285 [04:46<00:29,  1.12s/it]Loading train:  91%|█████████ | 260/285 [04:46<00:25,  1.02s/it]Loading train:  92%|█████████▏| 261/285 [04:47<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [04:48<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [04:49<00:21,  1.00it/s]Loading train:  93%|█████████▎| 264/285 [04:51<00:22,  1.06s/it]Loading train:  93%|█████████▎| 265/285 [04:52<00:21,  1.07s/it]Loading train:  93%|█████████▎| 266/285 [04:53<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [04:54<00:18,  1.04s/it]Loading train:  94%|█████████▍| 268/285 [04:55<00:17,  1.01s/it]Loading train:  94%|█████████▍| 269/285 [04:56<00:16,  1.04s/it]Loading train:  95%|█████████▍| 270/285 [04:57<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [04:58<00:14,  1.04s/it]Loading train:  95%|█████████▌| 272/285 [04:59<00:12,  1.00it/s]Loading train:  96%|█████████▌| 273/285 [05:00<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [05:01<00:10,  1.00it/s]Loading train:  96%|█████████▋| 275/285 [05:02<00:10,  1.03s/it]Loading train:  97%|█████████▋| 276/285 [05:03<00:10,  1.15s/it]Loading train:  97%|█████████▋| 277/285 [05:04<00:09,  1.14s/it]Loading train:  98%|█████████▊| 278/285 [05:06<00:08,  1.24s/it]Loading train:  98%|█████████▊| 279/285 [05:07<00:07,  1.31s/it]Loading train:  98%|█████████▊| 280/285 [05:08<00:06,  1.22s/it]Loading train:  99%|█████████▊| 281/285 [05:10<00:04,  1.20s/it]Loading train:  99%|█████████▉| 282/285 [05:11<00:03,  1.20s/it]Loading train:  99%|█████████▉| 283/285 [05:12<00:02,  1.22s/it]Loading train: 100%|█████████▉| 284/285 [05:13<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [05:15<00:00,  1.36s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:10, 25.99it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:10, 27.56it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:08, 32.18it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:06, 40.01it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:04, 50.24it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:04, 57.01it/s]concatenating: train:  19%|█▉        | 55/285 [00:01<00:06, 36.70it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:06, 33.42it/s]concatenating: train:  24%|██▎       | 67/285 [00:01<00:05, 38.02it/s]concatenating: train:  28%|██▊       | 79/285 [00:01<00:04, 47.80it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:03, 58.67it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:02, 69.72it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:03, 55.40it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:03, 47.84it/s]concatenating: train:  46%|████▌     | 131/285 [00:02<00:02, 51.46it/s]concatenating: train:  48%|████▊     | 138/285 [00:02<00:02, 54.34it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 56.56it/s]concatenating: train:  53%|█████▎    | 152/285 [00:02<00:02, 58.22it/s]concatenating: train:  56%|█████▋    | 161/285 [00:02<00:02, 58.43it/s]concatenating: train:  59%|█████▉    | 168/285 [00:03<00:02, 47.71it/s]concatenating: train:  68%|██████▊   | 193/285 [00:03<00:01, 62.97it/s]concatenating: train:  78%|███████▊  | 223/285 [00:03<00:00, 82.44it/s]concatenating: train:  84%|████████▍ | 240/285 [00:03<00:00, 83.10it/s]concatenating: train:  89%|████████▉ | 255/285 [00:03<00:00, 93.91it/s]concatenating: train:  95%|█████████▍| 270/285 [00:03<00:00, 101.47it/s]concatenating: train: 100%|█████████▉| 284/285 [00:03<00:00, 105.60it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 74.57it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.80s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.85s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 54.43it/s]2019-07-10 23:32:16.509015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:32:16.509157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:32:16.509173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:32:16.509182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:32:16.509636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.71it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.99it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.28it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.92it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:01<00:04,  7.90it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.13it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.04it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.76it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.36it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.71it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.72it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.44it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.75it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.76it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  9.35it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.55it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.71it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 130,948
Trainable params: 32,428
Non-trainable params: 98,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 13s - loss: 2.7794 - acc: 0.6786 - mDice: 0.0916 - val_loss: 3.0495 - val_acc: 0.8985 - val_mDice: 0.1719

Epoch 00001: val_mDice improved from -inf to 0.17195, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 8s - loss: 1.1669 - acc: 0.8776 - mDice: 0.3199 - val_loss: 1.6131 - val_acc: 0.9131 - val_mDice: 0.3583

Epoch 00002: val_mDice improved from 0.17195 to 0.35828, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 0.6952 - acc: 0.8937 - mDice: 0.4823 - val_loss: 1.3037 - val_acc: 0.9251 - val_mDice: 0.4426

Epoch 00003: val_mDice improved from 0.35828 to 0.44255, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.5754 - acc: 0.9051 - mDice: 0.5457 - val_loss: 0.9988 - val_acc: 0.9426 - val_mDice: 0.5793

Epoch 00004: val_mDice improved from 0.44255 to 0.57931, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.5194 - acc: 0.9164 - mDice: 0.5786 - val_loss: 1.0168 - val_acc: 0.9420 - val_mDice: 0.5451

Epoch 00005: val_mDice did not improve from 0.57931
Epoch 6/300
 - 8s - loss: 0.4877 - acc: 0.9214 - mDice: 0.5980 - val_loss: 0.9644 - val_acc: 0.9438 - val_mDice: 0.5592

Epoch 00006: val_mDice did not improve from 0.57931
Epoch 7/300
 - 8s - loss: 0.4639 - acc: 0.9245 - mDice: 0.6128 - val_loss: 0.9496 - val_acc: 0.9437 - val_mDice: 0.5621

Epoch 00007: val_mDice did not improve from 0.57931
Epoch 8/300
 - 8s - loss: 0.4453 - acc: 0.9266 - mDice: 0.6248 - val_loss: 0.9096 - val_acc: 0.9457 - val_mDice: 0.5919

Epoch 00008: val_mDice improved from 0.57931 to 0.59192, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 8s - loss: 0.4346 - acc: 0.9279 - mDice: 0.6320 - val_loss: 0.9106 - val_acc: 0.9453 - val_mDice: 0.5735

Epoch 00009: val_mDice did not improve from 0.59192
Epoch 10/300
 - 8s - loss: 0.4246 - acc: 0.9290 - mDice: 0.6385 - val_loss: 0.9000 - val_acc: 0.9449 - val_mDice: 0.5867

Epoch 00010: val_mDice did not improve from 0.59192
Epoch 11/300
 - 8s - loss: 0.4160 - acc: 0.9295 - mDice: 0.6442 - val_loss: 0.8524 - val_acc: 0.9468 - val_mDice: 0.5951

Epoch 00011: val_mDice improved from 0.59192 to 0.59506, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 8s - loss: 0.4073 - acc: 0.9306 - mDice: 0.6500 - val_loss: 0.8594 - val_acc: 0.9464 - val_mDice: 0.5816

Epoch 00012: val_mDice did not improve from 0.59506
Epoch 13/300
 - 9s - loss: 0.4021 - acc: 0.9311 - mDice: 0.6536 - val_loss: 0.8866 - val_acc: 0.9459 - val_mDice: 0.5878

Epoch 00013: val_mDice did not improve from 0.59506
Epoch 14/300
 - 8s - loss: 0.3953 - acc: 0.9316 - mDice: 0.6582 - val_loss: 0.8609 - val_acc: 0.9457 - val_mDice: 0.5926

Epoch 00014: val_mDice did not improve from 0.59506
Epoch 15/300
 - 8s - loss: 0.3918 - acc: 0.9320 - mDice: 0.6606 - val_loss: 0.8648 - val_acc: 0.9480 - val_mDice: 0.5870

Epoch 00015: val_mDice did not improve from 0.59506
Epoch 16/300
 - 8s - loss: 0.3842 - acc: 0.9328 - mDice: 0.6658 - val_loss: 0.8444 - val_acc: 0.9439 - val_mDice: 0.5771

Epoch 00016: val_mDice did not improve from 0.59506
Epoch 17/300
 - 8s - loss: 0.3801 - acc: 0.9332 - mDice: 0.6687 - val_loss: 0.8071 - val_acc: 0.9482 - val_mDice: 0.5890

Epoch 00017: val_mDice did not improve from 0.59506
Epoch 18/300
 - 8s - loss: 0.3772 - acc: 0.9335 - mDice: 0.6708 - val_loss: 0.8287 - val_acc: 0.9449 - val_mDice: 0.5860

Epoch 00018: val_mDice did not improve from 0.59506
Epoch 19/300
 - 8s - loss: 0.3747 - acc: 0.9336 - mDice: 0.6726 - val_loss: 0.8100 - val_acc: 0.9470 - val_mDice: 0.5765

Epoch 00019: val_mDice did not improve from 0.59506
Epoch 20/300
 - 8s - loss: 0.3685 - acc: 0.9343 - mDice: 0.6769 - val_loss: 0.8023 - val_acc: 0.9467 - val_mDice: 0.5855

Epoch 00020: val_mDice did not improve from 0.59506
Epoch 21/300
 - 8s - loss: 0.3658 - acc: 0.9345 - mDice: 0.6789 - val_loss: 0.8327 - val_acc: 0.9411 - val_mDice: 0.5813

Epoch 00021: val_mDice did not improve from 0.59506
Epoch 22/300
 - 9s - loss: 0.3645 - acc: 0.9345 - mDice: 0.6796 - val_loss: 0.8368 - val_acc: 0.9450 - val_mDice: 0.5631

Epoch 00022: val_mDice did not improve from 0.59506
Epoch 23/300
 - 8s - loss: 0.3622 - acc: 0.9347 - mDice: 0.6814 - val_loss: 0.7835 - val_acc: 0.9474 - val_mDice: 0.5855

Epoch 00023: val_mDice did not improve from 0.59506
Epoch 24/300
 - 8s - loss: 0.3580 - acc: 0.9351 - mDice: 0.6844 - val_loss: 0.7925 - val_acc: 0.9472 - val_mDice: 0.5701

Epoch 00024: val_mDice did not improve from 0.59506
Epoch 25/300
 - 8s - loss: 0.3552 - acc: 0.9354 - mDice: 0.6863 - val_loss: 0.7935 - val_acc: 0.9437 - val_mDice: 0.5790

Epoch 00025: val_mDice did not improve from 0.59506
Epoch 26/300
 - 8s - loss: 0.3538 - acc: 0.9355 - mDice: 0.6873 - val_loss: 0.7663 - val_acc: 0.9453 - val_mDice: 0.5884

Epoch 00026: val_mDice did not improve from 0.59506
Epoch 27/300
 - 8s - loss: 0.3500 - acc: 0.9358 - mDice: 0.6900 - val_loss: 0.7892 - val_acc: 0.9470 - val_mDice: 0.5739

Epoch 00027: val_mDice did not improve from 0.59506
Epoch 28/300
 - 8s - loss: 0.3483 - acc: 0.9360 - mDice: 0.6912 - val_loss: 0.7588 - val_acc: 0.9473 - val_mDice: 0.5901

Epoch 00028: val_mDice did not improve from 0.59506
Epoch 29/300
 - 8s - loss: 0.3475 - acc: 0.9359 - mDice: 0.6919 - val_loss: 0.7332 - val_acc: 0.9475 - val_mDice: 0.5808

Epoch 00029: val_mDice did not improve from 0.59506
Epoch 30/300
 - 8s - loss: 0.3472 - acc: 0.9361 - mDice: 0.6921 - val_loss: 0.7935 - val_acc: 0.9462 - val_mDice: 0.5874

Epoch 00030: val_mDice did not improve from 0.59506
Epoch 31/300
 - 9s - loss: 0.3447 - acc: 0.9364 - mDice: 0.6939 - val_loss: 0.7547 - val_acc: 0.9455 - val_mDice: 0.5837

Epoch 00031: val_mDice did not improve from 0.59506
Epoch 32/300
 - 8s - loss: 0.3417 - acc: 0.9366 - mDice: 0.6960 - val_loss: 0.7032 - val_acc: 0.9465 - val_mDice: 0.5726

Epoch 00032: val_mDice did not improve from 0.59506
Epoch 33/300
 - 8s - loss: 0.3411 - acc: 0.9366 - mDice: 0.6965 - val_loss: 0.7539 - val_acc: 0.9465 - val_mDice: 0.5808

Epoch 00033: val_mDice did not improve from 0.59506
Epoch 34/300
 - 8s - loss: 0.3390 - acc: 0.9369 - mDice: 0.6980 - val_loss: 0.7049 - val_acc: 0.9451 - val_mDice: 0.5836

Epoch 00034: val_mDice did not improve from 0.59506
Epoch 35/300
 - 8s - loss: 0.3375 - acc: 0.9369 - mDice: 0.6991 - val_loss: 0.7840 - val_acc: 0.9471 - val_mDice: 0.5765

Epoch 00035: val_mDice did not improve from 0.59506
Epoch 36/300
 - 8s - loss: 0.3346 - acc: 0.9373 - mDice: 0.7012 - val_loss: 0.7280 - val_acc: 0.9435 - val_mDice: 0.5712

Epoch 00036: val_mDice did not improve from 0.59506
Epoch 37/300
 - 8s - loss: 0.3337 - acc: 0.9372 - mDice: 0.7018 - val_loss: 0.7731 - val_acc: 0.9391 - val_mDice: 0.5724

Epoch 00037: val_mDice did not improve from 0.59506
Epoch 38/300
 - 8s - loss: 0.3320 - acc: 0.9375 - mDice: 0.7031 - val_loss: 0.7162 - val_acc: 0.9466 - val_mDice: 0.5761

Epoch 00038: val_mDice did not improve from 0.59506
Epoch 39/300
 - 8s - loss: 0.3309 - acc: 0.9375 - mDice: 0.7039 - val_loss: 0.6754 - val_acc: 0.9468 - val_mDice: 0.5825

Epoch 00039: val_mDice did not improve from 0.59506
Epoch 40/300
 - 8s - loss: 0.3306 - acc: 0.9377 - mDice: 0.7041 - val_loss: 0.6928 - val_acc: 0.9472 - val_mDice: 0.5884

Epoch 00040: val_mDice did not improve from 0.59506
Epoch 41/300
 - 8s - loss: 0.3293 - acc: 0.9377 - mDice: 0.7051 - val_loss: 0.7396 - val_acc: 0.9478 - val_mDice: 0.5807

Epoch 00041: val_mDice did not improve from 0.59506
Epoch 42/300
 - 8s - loss: 0.3286 - acc: 0.9377 - mDice: 0.7056 - val_loss: 0.6874 - val_acc: 0.9469 - val_mDice: 0.5713

Epoch 00042: val_mDice did not improve from 0.59506
Epoch 43/300
 - 8s - loss: 0.3268 - acc: 0.9380 - mDice: 0.7069 - val_loss: 0.6802 - val_acc: 0.9440 - val_mDice: 0.5860

Epoch 00043: val_mDice did not improve from 0.59506
Epoch 44/300
 - 8s - loss: 0.3242 - acc: 0.9381 - mDice: 0.7088 - val_loss: 0.7192 - val_acc: 0.9461 - val_mDice: 0.5711

Epoch 00044: val_mDice did not improve from 0.59506
Epoch 45/300
 - 8s - loss: 0.3250 - acc: 0.9383 - mDice: 0.7083 - val_loss: 0.6736 - val_acc: 0.9456 - val_mDice: 0.5736

Epoch 00045: val_mDice did not improve from 0.59506
Epoch 46/300
 - 8s - loss: 0.3259 - acc: 0.9381 - mDice: 0.7076 - val_loss: 0.6770 - val_acc: 0.9446 - val_mDice: 0.5770

Epoch 00046: val_mDice did not improve from 0.59506
Epoch 47/300
 - 9s - loss: 0.3222 - acc: 0.9384 - mDice: 0.7102 - val_loss: 0.7120 - val_acc: 0.9475 - val_mDice: 0.5768

Epoch 00047: val_mDice did not improve from 0.59506
Epoch 48/300
 - 8s - loss: 0.3207 - acc: 0.9385 - mDice: 0.7114 - val_loss: 0.7318 - val_acc: 0.9467 - val_mDice: 0.5693

Epoch 00048: val_mDice did not improve from 0.59506
Epoch 49/300
 - 8s - loss: 0.3201 - acc: 0.9385 - mDice: 0.7118 - val_loss: 0.7288 - val_acc: 0.9412 - val_mDice: 0.5693

Epoch 00049: val_mDice did not improve from 0.59506
Epoch 50/300
 - 8s - loss: 0.3205 - acc: 0.9387 - mDice: 0.7115 - val_loss: 0.6251 - val_acc: 0.9408 - val_mDice: 0.5755

Epoch 00050: val_mDice did not improve from 0.59506
Epoch 51/300
 - 8s - loss: 0.3189 - acc: 0.9387 - mDice: 0.7128 - val_loss: 0.6679 - val_acc: 0.9432 - val_mDice: 0.5745

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.45s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.18s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:46,  2.06s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:54,  1.89s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:39,  1.84s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:59,  1.71s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:22,  1.80s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:58,  1.72s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:26,  1.82s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:07,  1.76s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:29,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:52,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:18,  1.82s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:33,  1.88s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:11,  1.81s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:32,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:47,  1.95s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:40,  1.93s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:09,  1.83s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:31,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:01,  1.81s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:04,  1.83s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:38,  1.96s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:28,  1.94s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:37,  1.98s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:12,  1.89s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:32,  1.97s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:48,  2.04s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:29,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:20,  1.95s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:18,  1.95s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:16,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:28,  2.00s/it]predicting train subjects:  11%|█         | 32/285 [01:00<07:58,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:52,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<07:38,  1.84s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:19,  1.77s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:30,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:38,  1.86s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:16,  1.77s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:24,  1.81s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:04,  1.74s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<06:55,  1.71s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:06,  1.76s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:16,  1.81s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<06:51,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:04,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<06:43,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<06:51,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:12,  1.83s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:09,  1.83s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:03,  1.82s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:05,  1.83s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:15,  1.88s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<06:55,  1.81s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<06:55,  1.82s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:30,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:39,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:51,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:05,  1.89s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:34,  1.78s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:29,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:31,  1.78s/it]predicting train subjects:  23%|██▎       | 66/285 [02:00<06:27,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [02:02<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<06:16,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:07<06:26,  1.80s/it]predicting train subjects:  25%|██▍       | 71/285 [02:09<06:31,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:11<06:19,  1.78s/it]predicting train subjects:  26%|██▌       | 73/285 [02:13<06:19,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:15<06:15,  1.78s/it]predicting train subjects:  26%|██▋       | 75/285 [02:16<06:16,  1.79s/it]predicting train subjects:  27%|██▋       | 76/285 [02:18<06:12,  1.78s/it]predicting train subjects:  27%|██▋       | 77/285 [02:20<05:59,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:21<05:50,  1.69s/it]predicting train subjects:  28%|██▊       | 79/285 [02:23<06:01,  1.75s/it]predicting train subjects:  28%|██▊       | 80/285 [02:25<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:27<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:28<05:47,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:30<05:43,  1.70s/it]predicting train subjects:  29%|██▉       | 84/285 [02:32<05:32,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:33<05:37,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:35<05:50,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:37<05:53,  1.78s/it]predicting train subjects:  31%|███       | 88/285 [02:39<05:47,  1.76s/it]predicting train subjects:  31%|███       | 89/285 [02:41<05:41,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:42<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 91/285 [02:44<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:46<05:34,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:47<05:30,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:49<05:30,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:51<05:41,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [02:53<05:42,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [02:55<05:41,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [02:57<05:39,  1.82s/it]predicting train subjects:  35%|███▍      | 99/285 [02:58<05:32,  1.79s/it]predicting train subjects:  35%|███▌      | 100/285 [03:00<05:32,  1.80s/it]predicting train subjects:  35%|███▌      | 101/285 [03:02<05:21,  1.75s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:20,  1.75s/it]predicting train subjects:  36%|███▌      | 103/285 [03:05<05:13,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:07<05:16,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:18,  1.77s/it]predicting train subjects:  37%|███▋      | 106/285 [03:10<05:10,  1.74s/it]predicting train subjects:  38%|███▊      | 107/285 [03:12<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:14<05:05,  1.73s/it]predicting train subjects:  38%|███▊      | 109/285 [03:16<05:09,  1.76s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:17,  1.81s/it]predicting train subjects:  39%|███▉      | 111/285 [03:19<05:08,  1.77s/it]predicting train subjects:  39%|███▉      | 112/285 [03:21<05:09,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:06,  1.78s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:02,  1.77s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:09,  1.82s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:30<04:54,  1.75s/it]predicting train subjects:  41%|████▏     | 118/285 [03:32<04:43,  1.70s/it]predicting train subjects:  42%|████▏     | 119/285 [03:33<04:48,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:35<04:45,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:37<04:37,  1.69s/it]predicting train subjects:  43%|████▎     | 122/285 [03:38<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:40<04:17,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [03:41<04:15,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:43<04:13,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:44<04:03,  1.53s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:47<04:01,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:49<04:00,  1.54s/it]predicting train subjects:  46%|████▌     | 130/285 [03:50<03:52,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:52<03:45,  1.47s/it]predicting train subjects:  46%|████▋     | 132/285 [03:53<03:52,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [03:55<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [03:56<03:37,  1.44s/it]predicting train subjects:  47%|████▋     | 135/285 [03:57<03:29,  1.40s/it]predicting train subjects:  48%|████▊     | 136/285 [03:59<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [04:00<03:34,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [04:02<03:29,  1.43s/it]predicting train subjects:  49%|████▉     | 139/285 [04:03<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [04:05<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [04:06<03:36,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:08<03:31,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:09<03:31,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:11<03:36,  1.53s/it]predicting train subjects:  51%|█████     | 145/285 [04:13<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:14<03:30,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:16<03:28,  1.51s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:17<03:30,  1.54s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:19<03:27,  1.52s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:20<03:25,  1.52s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:22<03:23,  1.52s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:23<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:25<03:15,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:26<03:18,  1.52s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:28<03:15,  1.50s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:29<03:20,  1.55s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:31<03:13,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:32<03:08,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:33<03:02,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:35<03:01,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:37<03:08,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:38<03:06,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:40<03:10,  1.56s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:41<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:43<03:04,  1.54s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:44<03:01,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:46<02:59,  1.52s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:47<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:49<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:50<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [04:52<02:51,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [04:53<02:46,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [04:55<02:44,  1.47s/it]predicting train subjects:  61%|██████    | 174/285 [04:56<02:42,  1.46s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:58<02:47,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:59<02:50,  1.56s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:01<02:45,  1.53s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:02<02:38,  1.48s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:04<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:05<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:07<02:44,  1.58s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:46,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:10<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:11<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:13<02:25,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:15<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:16<02:42,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:18<02:45,  1.70s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:20<02:33,  1.60s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:21<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:23<02:23,  1.53s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:24<02:30,  1.61s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:26<02:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:27<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:28<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:30<02:17,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:32<02:24,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:34<02:28,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:35<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:37<02:11,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:38<02:15,  1.61s/it]predicting train subjects:  71%|███████   | 202/285 [05:40<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:42<02:10,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:43<02:04,  1.53s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:44<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:46<01:53,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:48<02:01,  1.56s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:49<02:04,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:51<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:52<01:57,  1.57s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:54<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:56<01:54,  1.57s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:57<01:53,  1.57s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:58<01:45,  1.49s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:00<01:47,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:01<01:40,  1.45s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:03<01:45,  1.56s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:05<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:07<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:08<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:10<01:39,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:11<01:37,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:12<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:14<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:15<01:27,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:33,  1.59s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:19<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:21<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [06:23<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:24<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:25<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:27<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:17,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:30<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:15,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:18,  1.60s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:20,  1.68s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:37<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:39<01:19,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:40<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:42<01:09,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:43<01:05,  1.52s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:44<01:02,  1.49s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:46<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:47<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:49<01:01,  1.59s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:51<01:01,  1.62s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:53<01:00,  1.64s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:54<00:56,  1.58s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:56<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:57<00:50,  1.49s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:58<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:00<00:50,  1.57s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:02<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:04<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:05<00:44,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [07:06<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [07:08<00:43,  1.60s/it]predicting train subjects:  91%|█████████ | 259/285 [07:10<00:42,  1.63s/it]predicting train subjects:  91%|█████████ | 260/285 [07:11<00:38,  1.53s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:13<00:35,  1.48s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:14<00:33,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:15<00:31,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:17<00:32,  1.55s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:19<00:32,  1.64s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:20<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:22<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:24<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:25<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:27<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:28<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:29<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:31<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:32<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:34<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:36<00:14,  1.64s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:37<00:12,  1.57s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:39<00:10,  1.55s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:40<00:09,  1.55s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:42<00:07,  1.54s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:43<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:45<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:47<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:48<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [07:50<00:00,  1.70s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:44,  1.85s/it]Loading train:   1%|          | 2/285 [00:03<08:18,  1.76s/it]Loading train:   1%|          | 3/285 [00:04<07:58,  1.70s/it]Loading train:   1%|▏         | 4/285 [00:06<07:25,  1.58s/it]Loading train:   2%|▏         | 5/285 [00:07<07:33,  1.62s/it]Loading train:   2%|▏         | 6/285 [00:09<07:13,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:11<07:23,  1.60s/it]Loading train:   3%|▎         | 8/285 [00:12<07:00,  1.52s/it]Loading train:   3%|▎         | 9/285 [00:14<07:22,  1.60s/it]Loading train:   4%|▎         | 10/285 [00:15<07:04,  1.54s/it]Loading train:   4%|▍         | 11/285 [00:16<06:12,  1.36s/it]Loading train:   4%|▍         | 12/285 [00:18<06:20,  1.39s/it]Loading train:   5%|▍         | 13/285 [00:19<06:34,  1.45s/it]Loading train:   5%|▍         | 14/285 [00:20<06:19,  1.40s/it]Loading train:   5%|▌         | 15/285 [00:22<06:11,  1.38s/it]Loading train:   6%|▌         | 16/285 [00:23<06:01,  1.34s/it]Loading train:   6%|▌         | 17/285 [00:24<05:32,  1.24s/it]Loading train:   6%|▋         | 18/285 [00:25<05:14,  1.18s/it]Loading train:   7%|▋         | 19/285 [00:26<04:50,  1.09s/it]Loading train:   7%|▋         | 20/285 [00:27<04:45,  1.08s/it]Loading train:   7%|▋         | 21/285 [00:28<04:59,  1.14s/it]Loading train:   8%|▊         | 22/285 [00:29<04:57,  1.13s/it]Loading train:   8%|▊         | 23/285 [00:31<05:21,  1.23s/it]Loading train:   8%|▊         | 24/285 [00:32<05:29,  1.26s/it]Loading train:   9%|▉         | 25/285 [00:33<05:33,  1.28s/it]Loading train:   9%|▉         | 26/285 [00:35<05:28,  1.27s/it]Loading train:   9%|▉         | 27/285 [00:36<05:03,  1.18s/it]Loading train:  10%|▉         | 28/285 [00:37<05:04,  1.19s/it]Loading train:  10%|█         | 29/285 [00:38<04:57,  1.16s/it]Loading train:  11%|█         | 30/285 [00:39<05:01,  1.18s/it]Loading train:  11%|█         | 31/285 [00:40<05:08,  1.21s/it]Loading train:  11%|█         | 32/285 [00:42<05:05,  1.21s/it]Loading train:  12%|█▏        | 33/285 [00:43<05:07,  1.22s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:56,  1.18s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:47,  1.15s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:39,  1.12s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:37,  1.12s/it]Loading train:  13%|█▎        | 38/285 [00:49<04:53,  1.19s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:43,  1.15s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:53,  1.20s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:51,  1.19s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:30,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:54<04:34,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:56<04:55,  1.23s/it]Loading train:  16%|█▌        | 45/285 [00:57<04:51,  1.21s/it]Loading train:  16%|█▌        | 46/285 [00:59<05:25,  1.36s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:53,  1.23s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:40,  1.18s/it]Loading train:  17%|█▋        | 49/285 [01:02<04:31,  1.15s/it]Loading train:  18%|█▊        | 50/285 [01:03<04:26,  1.13s/it]Loading train:  18%|█▊        | 51/285 [01:04<04:34,  1.17s/it]Loading train:  18%|█▊        | 52/285 [01:05<04:38,  1.20s/it]Loading train:  19%|█▊        | 53/285 [01:07<04:50,  1.25s/it]Loading train:  19%|█▉        | 54/285 [01:08<04:50,  1.26s/it]Loading train:  19%|█▉        | 55/285 [01:09<04:32,  1.18s/it]Loading train:  20%|█▉        | 56/285 [01:10<04:25,  1.16s/it]Loading train:  20%|██        | 57/285 [01:11<04:07,  1.09s/it]Loading train:  20%|██        | 58/285 [01:12<03:56,  1.04s/it]Loading train:  21%|██        | 59/285 [01:13<04:13,  1.12s/it]Loading train:  21%|██        | 60/285 [01:14<04:19,  1.15s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:20,  1.16s/it]Loading train:  22%|██▏       | 62/285 [01:17<04:17,  1.15s/it]Loading train:  22%|██▏       | 63/285 [01:18<04:28,  1.21s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:46,  1.30s/it]Loading train:  23%|██▎       | 65/285 [01:21<05:13,  1.43s/it]Loading train:  23%|██▎       | 66/285 [01:23<05:16,  1.45s/it]Loading train:  24%|██▎       | 67/285 [01:24<05:19,  1.47s/it]Loading train:  24%|██▍       | 68/285 [01:25<04:47,  1.32s/it]Loading train:  24%|██▍       | 69/285 [01:26<04:29,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:28<04:28,  1.25s/it]Loading train:  25%|██▍       | 71/285 [01:29<04:14,  1.19s/it]Loading train:  25%|██▌       | 72/285 [01:30<03:58,  1.12s/it]Loading train:  26%|██▌       | 73/285 [01:31<04:03,  1.15s/it]Loading train:  26%|██▌       | 74/285 [01:32<04:04,  1.16s/it]Loading train:  26%|██▋       | 75/285 [01:33<04:00,  1.14s/it]Loading train:  27%|██▋       | 76/285 [01:34<03:55,  1.13s/it]Loading train:  27%|██▋       | 77/285 [01:35<03:53,  1.12s/it]Loading train:  27%|██▋       | 78/285 [01:37<03:59,  1.16s/it]Loading train:  28%|██▊       | 79/285 [01:38<04:02,  1.18s/it]Loading train:  28%|██▊       | 80/285 [01:39<04:12,  1.23s/it]Loading train:  28%|██▊       | 81/285 [01:40<04:07,  1.21s/it]Loading train:  29%|██▉       | 82/285 [01:42<04:17,  1.27s/it]Loading train:  29%|██▉       | 83/285 [01:43<04:06,  1.22s/it]Loading train:  29%|██▉       | 84/285 [01:44<03:58,  1.19s/it]Loading train:  30%|██▉       | 85/285 [01:45<03:51,  1.16s/it]Loading train:  30%|███       | 86/285 [01:46<03:53,  1.17s/it]Loading train:  31%|███       | 87/285 [01:47<03:44,  1.13s/it]Loading train:  31%|███       | 88/285 [01:48<03:25,  1.04s/it]Loading train:  31%|███       | 89/285 [01:49<03:18,  1.01s/it]Loading train:  32%|███▏      | 90/285 [01:50<03:19,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:51<03:11,  1.01it/s]Loading train:  32%|███▏      | 92/285 [01:52<03:12,  1.00it/s]Loading train:  33%|███▎      | 93/285 [01:53<03:04,  1.04it/s]Loading train:  33%|███▎      | 94/285 [01:54<03:16,  1.03s/it]Loading train:  33%|███▎      | 95/285 [01:55<03:20,  1.06s/it]Loading train:  34%|███▎      | 96/285 [01:56<03:20,  1.06s/it]Loading train:  34%|███▍      | 97/285 [01:57<03:23,  1.08s/it]Loading train:  34%|███▍      | 98/285 [01:59<03:30,  1.13s/it]Loading train:  35%|███▍      | 99/285 [02:00<03:30,  1.13s/it]Loading train:  35%|███▌      | 100/285 [02:01<03:20,  1.08s/it]Loading train:  35%|███▌      | 101/285 [02:02<03:17,  1.07s/it]Loading train:  36%|███▌      | 102/285 [02:03<03:25,  1.12s/it]Loading train:  36%|███▌      | 103/285 [02:04<03:13,  1.07s/it]Loading train:  36%|███▋      | 104/285 [02:05<03:30,  1.17s/it]Loading train:  37%|███▋      | 105/285 [02:07<03:39,  1.22s/it]Loading train:  37%|███▋      | 106/285 [02:08<03:51,  1.29s/it]Loading train:  38%|███▊      | 107/285 [02:09<03:47,  1.28s/it]Loading train:  38%|███▊      | 108/285 [02:10<03:32,  1.20s/it]Loading train:  38%|███▊      | 109/285 [02:12<03:27,  1.18s/it]Loading train:  39%|███▊      | 110/285 [02:13<03:35,  1.23s/it]Loading train:  39%|███▉      | 111/285 [02:14<03:20,  1.15s/it]Loading train:  39%|███▉      | 112/285 [02:15<03:31,  1.22s/it]Loading train:  40%|███▉      | 113/285 [02:17<03:30,  1.22s/it]Loading train:  40%|████      | 114/285 [02:18<03:31,  1.24s/it]Loading train:  40%|████      | 115/285 [02:19<03:37,  1.28s/it]Loading train:  41%|████      | 116/285 [02:20<03:27,  1.23s/it]Loading train:  41%|████      | 117/285 [02:21<03:23,  1.21s/it]Loading train:  41%|████▏     | 118/285 [02:23<03:23,  1.22s/it]Loading train:  42%|████▏     | 119/285 [02:24<03:34,  1.29s/it]Loading train:  42%|████▏     | 120/285 [02:25<03:27,  1.26s/it]Loading train:  42%|████▏     | 121/285 [02:27<03:30,  1.28s/it]Loading train:  43%|████▎     | 122/285 [02:28<03:33,  1.31s/it]Loading train:  43%|████▎     | 123/285 [02:30<03:50,  1.42s/it]Loading train:  44%|████▎     | 124/285 [02:31<03:46,  1.40s/it]Loading train:  44%|████▍     | 125/285 [02:32<03:42,  1.39s/it]Loading train:  44%|████▍     | 126/285 [02:33<03:22,  1.27s/it]Loading train:  45%|████▍     | 127/285 [02:34<03:02,  1.15s/it]Loading train:  45%|████▍     | 128/285 [02:35<02:58,  1.14s/it]Loading train:  45%|████▌     | 129/285 [02:36<02:49,  1.09s/it]Loading train:  46%|████▌     | 130/285 [02:38<02:55,  1.13s/it]Loading train:  46%|████▌     | 131/285 [02:39<02:48,  1.10s/it]Loading train:  46%|████▋     | 132/285 [02:40<02:41,  1.05s/it]Loading train:  47%|████▋     | 133/285 [02:41<02:34,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:42<02:32,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:43<02:33,  1.02s/it]Loading train:  48%|████▊     | 136/285 [02:44<02:28,  1.00it/s]Loading train:  48%|████▊     | 137/285 [02:45<02:37,  1.06s/it]Loading train:  48%|████▊     | 138/285 [02:46<02:29,  1.02s/it]Loading train:  49%|████▉     | 139/285 [02:47<02:31,  1.04s/it]Loading train:  49%|████▉     | 140/285 [02:48<02:31,  1.05s/it]Loading train:  49%|████▉     | 141/285 [02:49<02:29,  1.04s/it]Loading train:  50%|████▉     | 142/285 [02:50<02:23,  1.00s/it]Loading train:  50%|█████     | 143/285 [02:51<02:23,  1.01s/it]Loading train:  51%|█████     | 144/285 [02:52<02:26,  1.04s/it]Loading train:  51%|█████     | 145/285 [02:53<02:21,  1.01s/it]Loading train:  51%|█████     | 146/285 [02:54<02:33,  1.10s/it]Loading train:  52%|█████▏    | 147/285 [02:55<02:27,  1.07s/it]Loading train:  52%|█████▏    | 148/285 [02:56<02:18,  1.01s/it]Loading train:  52%|█████▏    | 149/285 [02:57<02:23,  1.05s/it]Loading train:  53%|█████▎    | 150/285 [02:58<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:59<02:16,  1.02s/it]Loading train:  53%|█████▎    | 152/285 [03:00<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [03:01<02:17,  1.04s/it]Loading train:  54%|█████▍    | 154/285 [03:02<02:20,  1.07s/it]Loading train:  54%|█████▍    | 155/285 [03:03<02:13,  1.03s/it]Loading train:  55%|█████▍    | 156/285 [03:04<02:13,  1.04s/it]Loading train:  55%|█████▌    | 157/285 [03:05<02:08,  1.01s/it]Loading train:  55%|█████▌    | 158/285 [03:06<02:04,  1.02it/s]Loading train:  56%|█████▌    | 159/285 [03:07<02:06,  1.00s/it]Loading train:  56%|█████▌    | 160/285 [03:08<02:03,  1.02it/s]Loading train:  56%|█████▋    | 161/285 [03:09<02:05,  1.01s/it]Loading train:  57%|█████▋    | 162/285 [03:10<02:02,  1.01it/s]Loading train:  57%|█████▋    | 163/285 [03:11<02:01,  1.00it/s]Loading train:  58%|█████▊    | 164/285 [03:12<01:58,  1.02it/s]Loading train:  58%|█████▊    | 165/285 [03:13<01:54,  1.05it/s]Loading train:  58%|█████▊    | 166/285 [03:14<02:00,  1.01s/it]Loading train:  59%|█████▊    | 167/285 [03:15<01:58,  1.00s/it]Loading train:  59%|█████▉    | 168/285 [03:16<02:07,  1.09s/it]Loading train:  59%|█████▉    | 169/285 [03:17<02:02,  1.06s/it]Loading train:  60%|█████▉    | 170/285 [03:18<01:58,  1.03s/it]Loading train:  60%|██████    | 171/285 [03:19<01:53,  1.00it/s]Loading train:  60%|██████    | 172/285 [03:20<01:48,  1.04it/s]Loading train:  61%|██████    | 173/285 [03:21<01:51,  1.00it/s]Loading train:  61%|██████    | 174/285 [03:22<01:45,  1.05it/s]Loading train:  61%|██████▏   | 175/285 [03:23<01:54,  1.05s/it]Loading train:  62%|██████▏   | 176/285 [03:24<01:52,  1.03s/it]Loading train:  62%|██████▏   | 177/285 [03:25<01:44,  1.04it/s]Loading train:  62%|██████▏   | 178/285 [03:26<01:42,  1.05it/s]Loading train:  63%|██████▎   | 179/285 [03:27<01:47,  1.02s/it]Loading train:  63%|██████▎   | 180/285 [03:29<02:04,  1.18s/it]Loading train:  64%|██████▎   | 181/285 [03:30<02:09,  1.25s/it]Loading train:  64%|██████▍   | 182/285 [03:31<02:04,  1.21s/it]Loading train:  64%|██████▍   | 183/285 [03:32<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [03:33<01:51,  1.10s/it]Loading train:  65%|██████▍   | 185/285 [03:35<01:54,  1.14s/it]Loading train:  65%|██████▌   | 186/285 [03:36<01:55,  1.17s/it]Loading train:  66%|██████▌   | 187/285 [03:37<01:53,  1.16s/it]Loading train:  66%|██████▌   | 188/285 [03:38<01:49,  1.13s/it]Loading train:  66%|██████▋   | 189/285 [03:39<01:43,  1.08s/it]Loading train:  67%|██████▋   | 190/285 [03:40<01:37,  1.02s/it]Loading train:  67%|██████▋   | 191/285 [03:41<01:37,  1.03s/it]Loading train:  67%|██████▋   | 192/285 [03:42<01:42,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [03:43<01:40,  1.09s/it]Loading train:  68%|██████▊   | 194/285 [03:44<01:40,  1.10s/it]Loading train:  68%|██████▊   | 195/285 [03:45<01:34,  1.05s/it]Loading train:  69%|██████▉   | 196/285 [03:47<01:36,  1.08s/it]Loading train:  69%|██████▉   | 197/285 [03:48<01:43,  1.18s/it]Loading train:  69%|██████▉   | 198/285 [03:49<01:42,  1.18s/it]Loading train:  70%|██████▉   | 199/285 [03:50<01:36,  1.12s/it]Loading train:  70%|███████   | 200/285 [03:51<01:29,  1.06s/it]Loading train:  71%|███████   | 201/285 [03:52<01:36,  1.15s/it]Loading train:  71%|███████   | 202/285 [03:53<01:30,  1.09s/it]Loading train:  71%|███████   | 203/285 [03:54<01:27,  1.06s/it]Loading train:  72%|███████▏  | 204/285 [03:55<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:56<01:16,  1.05it/s]Loading train:  72%|███████▏  | 206/285 [03:57<01:13,  1.08it/s]Loading train:  73%|███████▎  | 207/285 [03:58<01:20,  1.03s/it]Loading train:  73%|███████▎  | 208/285 [04:00<01:26,  1.13s/it]Loading train:  73%|███████▎  | 209/285 [04:01<01:24,  1.11s/it]Loading train:  74%|███████▎  | 210/285 [04:02<01:22,  1.10s/it]Loading train:  74%|███████▍  | 211/285 [04:03<01:21,  1.10s/it]Loading train:  74%|███████▍  | 212/285 [04:04<01:16,  1.05s/it]Loading train:  75%|███████▍  | 213/285 [04:05<01:17,  1.07s/it]Loading train:  75%|███████▌  | 214/285 [04:06<01:11,  1.01s/it]Loading train:  75%|███████▌  | 215/285 [04:07<01:15,  1.08s/it]Loading train:  76%|███████▌  | 216/285 [04:08<01:10,  1.02s/it]Loading train:  76%|███████▌  | 217/285 [04:09<01:12,  1.06s/it]Loading train:  76%|███████▋  | 218/285 [04:10<01:12,  1.09s/it]Loading train:  77%|███████▋  | 219/285 [04:11<01:16,  1.17s/it]Loading train:  77%|███████▋  | 220/285 [04:13<01:15,  1.16s/it]Loading train:  78%|███████▊  | 221/285 [04:14<01:11,  1.12s/it]Loading train:  78%|███████▊  | 222/285 [04:15<01:11,  1.14s/it]Loading train:  78%|███████▊  | 223/285 [04:16<01:04,  1.04s/it]Loading train:  79%|███████▊  | 224/285 [04:17<01:01,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [04:18<01:01,  1.02s/it]Loading train:  79%|███████▉  | 226/285 [04:19<01:03,  1.07s/it]Loading train:  80%|███████▉  | 227/285 [04:20<01:02,  1.08s/it]Loading train:  80%|████████  | 228/285 [04:21<01:00,  1.06s/it]Loading train:  80%|████████  | 229/285 [04:22<00:59,  1.06s/it]Loading train:  81%|████████  | 230/285 [04:23<00:58,  1.06s/it]Loading train:  81%|████████  | 231/285 [04:24<00:57,  1.07s/it]Loading train:  81%|████████▏ | 232/285 [04:25<00:59,  1.12s/it]Loading train:  82%|████████▏ | 233/285 [04:26<00:58,  1.12s/it]Loading train:  82%|████████▏ | 234/285 [04:28<00:59,  1.16s/it]Loading train:  82%|████████▏ | 235/285 [04:29<00:55,  1.12s/it]Loading train:  83%|████████▎ | 236/285 [04:30<01:02,  1.27s/it]Loading train:  83%|████████▎ | 237/285 [04:32<01:02,  1.31s/it]Loading train:  84%|████████▎ | 238/285 [04:33<01:00,  1.30s/it]Loading train:  84%|████████▍ | 239/285 [04:34<00:59,  1.29s/it]Loading train:  84%|████████▍ | 240/285 [04:36<00:56,  1.26s/it]Loading train:  85%|████████▍ | 241/285 [04:37<00:53,  1.23s/it]Loading train:  85%|████████▍ | 242/285 [04:38<00:51,  1.19s/it]Loading train:  85%|████████▌ | 243/285 [04:39<00:49,  1.17s/it]Loading train:  86%|████████▌ | 244/285 [04:40<00:48,  1.19s/it]Loading train:  86%|████████▌ | 245/285 [04:41<00:44,  1.12s/it]Loading train:  86%|████████▋ | 246/285 [04:42<00:42,  1.10s/it]Loading train:  87%|████████▋ | 247/285 [04:43<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:44<00:39,  1.08s/it]Loading train:  87%|████████▋ | 249/285 [04:45<00:36,  1.02s/it]Loading train:  88%|████████▊ | 250/285 [04:46<00:35,  1.02s/it]Loading train:  88%|████████▊ | 251/285 [04:47<00:34,  1.02s/it]Loading train:  88%|████████▊ | 252/285 [04:48<00:33,  1.01s/it]Loading train:  89%|████████▉ | 253/285 [04:49<00:34,  1.08s/it]Loading train:  89%|████████▉ | 254/285 [04:51<00:34,  1.10s/it]Loading train:  89%|████████▉ | 255/285 [04:52<00:32,  1.07s/it]Loading train:  90%|████████▉ | 256/285 [04:52<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [04:53<00:26,  1.04it/s]Loading train:  91%|█████████ | 258/285 [04:54<00:27,  1.03s/it]Loading train:  91%|█████████ | 259/285 [04:55<00:25,  1.01it/s]Loading train:  91%|█████████ | 260/285 [04:56<00:25,  1.02s/it]Loading train:  92%|█████████▏| 261/285 [04:57<00:24,  1.01s/it]Loading train:  92%|█████████▏| 262/285 [04:58<00:21,  1.05it/s]Loading train:  92%|█████████▏| 263/285 [04:59<00:19,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [05:00<00:20,  1.05it/s]Loading train:  93%|█████████▎| 265/285 [05:01<00:20,  1.03s/it]Loading train:  93%|█████████▎| 266/285 [05:02<00:18,  1.01it/s]Loading train:  94%|█████████▎| 267/285 [05:03<00:17,  1.05it/s]Loading train:  94%|█████████▍| 268/285 [05:04<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [05:05<00:15,  1.02it/s]Loading train:  95%|█████████▍| 270/285 [05:06<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [05:07<00:13,  1.03it/s]Loading train:  95%|█████████▌| 272/285 [05:08<00:12,  1.02it/s]Loading train:  96%|█████████▌| 273/285 [05:09<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [05:10<00:11,  1.05s/it]Loading train:  96%|█████████▋| 275/285 [05:12<00:11,  1.12s/it]Loading train:  97%|█████████▋| 276/285 [05:13<00:10,  1.18s/it]Loading train:  97%|█████████▋| 277/285 [05:14<00:08,  1.10s/it]Loading train:  98%|█████████▊| 278/285 [05:15<00:07,  1.12s/it]Loading train:  98%|█████████▊| 279/285 [05:16<00:06,  1.13s/it]Loading train:  98%|█████████▊| 280/285 [05:17<00:05,  1.10s/it]Loading train:  99%|█████████▊| 281/285 [05:18<00:04,  1.14s/it]Loading train:  99%|█████████▉| 282/285 [05:19<00:03,  1.08s/it]Loading train:  99%|█████████▉| 283/285 [05:21<00:02,  1.14s/it]Loading train: 100%|█████████▉| 284/285 [05:22<00:01,  1.12s/it]Loading train: 100%|██████████| 285/285 [05:23<00:00,  1.10s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:03, 78.97it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:02, 88.79it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:02, 102.29it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:01, 122.06it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:01, 144.49it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:01, 166.49it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:01, 130.46it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 117.70it/s]concatenating: train:  58%|█████▊    | 164/285 [00:01<00:01, 91.02it/s] concatenating: train:  62%|██████▏   | 177/285 [00:01<00:01, 98.22it/s]concatenating: train:  67%|██████▋   | 192/285 [00:01<00:00, 109.56it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 116.96it/s]concatenating: train:  80%|███████▉  | 227/285 [00:01<00:00, 133.43it/s]concatenating: train:  90%|████████▉ | 256/285 [00:01<00:00, 157.19it/s]concatenating: train:  96%|█████████▋| 275/285 [00:01<00:00, 142.30it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 135.37it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.49s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.45s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 184.83it/s]2019-07-10 23:53:17.783052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:53:17.783154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:53:17.783169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:53:17.783178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:53:17.783624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.68it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.77it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.47it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.28it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.88it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.52it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.63it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.83it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  7.71it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.38it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.81it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.23it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.44it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.50it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.95it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.18it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.61it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.74it/s]
Epoch 00051: val_mDice did not improve from 0.59506
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [3.049515951247442, 1.6131243478684199, 1.3037226654234386, 0.9988294839859009, 1.016785053979783, 0.9644138472420829, 0.9496266955421084, 0.9096269834609259, 0.9105538129806519, 0.8999538989294142, 0.8524258079982939, 0.8593757322856358, 0.88663041023981, 0.8609016225451515, 0.8647538820902506, 0.8443871736526489, 0.8071272940862746, 0.8286991005852109, 0.809993238676162, 0.8023060446693784, 0.8327177081789289, 0.8367742129734584, 0.7834838685535249, 0.7924704324631464, 0.7935494525091988, 0.7663462105251494, 0.7892335596538725, 0.7587579318455288, 0.7331751130876087, 0.7935072524206979, 0.7547324555260795, 0.7031591676530384, 0.7539244719914028, 0.7048668691090175, 0.7840450547990345, 0.7279922905422392, 0.7730542705172584, 0.7162017595200312, 0.6753572679701305, 0.6927509648459298, 0.7395756471724737, 0.6874075900940668, 0.6801804758253551, 0.7192292383738926, 0.6736386276426769, 0.6770365919385638, 0.7120174226306734, 0.7318165075211298, 0.7288000413349697, 0.6250568571544829, 0.6678658439999535], 'val_acc': [0.898459235827128, 0.9131364368257069, 0.9251121765091306, 0.9425938583555675, 0.942007805619921, 0.943798079377129, 0.9437225205557687, 0.9456913840203058, 0.9453251163164774, 0.9448763841674441, 0.9468361082531157, 0.9464285600753057, 0.9458859704789662, 0.9457165769168309, 0.9480380302383786, 0.9439331633704049, 0.9481776782444545, 0.9448649173691159, 0.9469940634000868, 0.9466850019636608, 0.9411400982311794, 0.945029752595084, 0.9473992955116999, 0.9472115664255052, 0.9437019058636257, 0.9453365490550086, 0.9470032226471674, 0.9472802451678685, 0.9474748458181109, 0.9462156607991173, 0.9454624369030907, 0.9464674932616097, 0.9464514369056338, 0.9451373361405873, 0.9471336972145807, 0.9435324952715919, 0.9390682322638375, 0.9465774013882592, 0.9468017447562445, 0.9471520242236909, 0.947811348097665, 0.9468612472216288, 0.9440361800647917, 0.9460851578485399, 0.945620426109859, 0.9445558701242719, 0.9475274937493461, 0.9466506469817388, 0.9412408613023304, 0.9408402073950994, 0.943200565519787], 'val_mDice': [0.17194644171035006, 0.3582800217859802, 0.4425535533754599, 0.5793091851685729, 0.5451272754442125, 0.559166669845581, 0.5621011305068221, 0.5919222766090007, 0.5735336215723128, 0.5866579489693755, 0.5950554713961624, 0.5816427781468346, 0.5877653665485836, 0.5926276069311869, 0.5870321462196963, 0.5771013696988424, 0.5890144413071019, 0.5859527158595267, 0.5765022177781377, 0.5854519995905104, 0.58132004737854, 0.5630810748608339, 0.5855332050649893, 0.5701183795574165, 0.5790464713105133, 0.5884141613330159, 0.5738548989452067, 0.5900999745797544, 0.5807981466253599, 0.5873537161165759, 0.5836701405545076, 0.5726060865535623, 0.5807864181697369, 0.5835808480069751, 0.5765467497209708, 0.5711817265976042, 0.5724424372116724, 0.5760950061182181, 0.5825332862635454, 0.5884324872777575, 0.5807458877208687, 0.5712587287028631, 0.5859585989798818, 0.5711419195646331, 0.5735734820011116, 0.5770407343904177, 0.5768137162639981, 0.5693475902080536, 0.5693480808820043, 0.5755258172395683, 0.5744950806810742], 'loss': [2.779412238060543, 1.16686064063503, 0.6952142809566698, 0.5753780823464519, 0.5193937329030667, 0.48768707411193146, 0.4639052601018714, 0.4453484616701098, 0.43461632247097076, 0.4246134242904377, 0.4160000207866803, 0.4073050933201832, 0.40212164982127757, 0.3953417817452796, 0.3918187584529062, 0.38421531649299595, 0.38008878335388313, 0.37721501015872194, 0.3746963601673594, 0.3685209363417426, 0.36575234653358174, 0.3644803145475555, 0.3621915718517208, 0.35795446352414456, 0.3552115109986323, 0.3538498353275555, 0.3500477779295395, 0.3483191555994702, 0.34746763633008587, 0.3471961194537659, 0.34471889926974936, 0.3417027556174565, 0.34110681595130304, 0.33902653569726554, 0.3374564671920907, 0.3346483805390114, 0.3337376326558124, 0.3320158103745591, 0.3309377961152317, 0.3305743433203292, 0.32926004818806376, 0.32855649572566037, 0.3268296455047667, 0.32418284601551134, 0.3249735156878907, 0.32591957378438013, 0.32222670927451297, 0.3206590664094874, 0.3201175460080915, 0.32046699162528813, 0.31885474454306306], 'acc': [0.6785686724168017, 0.8775785607319014, 0.8937360752012681, 0.905140046717598, 0.9163554228521943, 0.9213794235873365, 0.9245419131438581, 0.92658242698761, 0.9278571129373808, 0.9289681990412773, 0.9295389902874388, 0.930586081709916, 0.9310661780367657, 0.9316341901115077, 0.9320396964596442, 0.9327546389939032, 0.9331806536375362, 0.9335137028466168, 0.9336226092544115, 0.9342974912276819, 0.9344918160900942, 0.934489745762345, 0.9347411611761826, 0.9351187913730835, 0.9354489207359691, 0.9355159564378612, 0.9358291000282923, 0.9359744587844567, 0.9359413011468902, 0.936091129757293, 0.9364201919936435, 0.936569024309019, 0.9366431047812073, 0.936855474406868, 0.9369443624677377, 0.9373264650239498, 0.9372476120203797, 0.9374681585483614, 0.9374649642473106, 0.9377191568675795, 0.9377386470463365, 0.9376772202943501, 0.9380390700609992, 0.9380682409441675, 0.9382739142344731, 0.9380651607962962, 0.9384232137229417, 0.9385476918585479, 0.9385066796341958, 0.9386853330255314, 0.9387193972351511], 'mDice': [0.09159895638228382, 0.31986976395527567, 0.48226755898835827, 0.5457450403559523, 0.5786024820650615, 0.5980041247469533, 0.6128160689914528, 0.6248020226150574, 0.6319636891107465, 0.6385094610647772, 0.6442200506103505, 0.6500337864246262, 0.6536394831002138, 0.6581819332448049, 0.6606226713413307, 0.6657740748271056, 0.6686721719458127, 0.6708309332345845, 0.672566617686601, 0.6769159015074893, 0.6789222554892089, 0.679635498768244, 0.6814011744228383, 0.6843849690130089, 0.6863320147184501, 0.6873137377603264, 0.6900037363450238, 0.6912440893873902, 0.6918615918870098, 0.692137796501445, 0.6938566487948283, 0.6960208896085754, 0.6964551129505678, 0.6980446569373067, 0.6991139308138116, 0.7011965240888888, 0.7018066031040657, 0.7030783623704014, 0.7039400575155005, 0.7041213721444847, 0.705123902045166, 0.7056226153260645, 0.7069334193118992, 0.7088089129220136, 0.7082763550275549, 0.7076029082081877, 0.7102381359388632, 0.7114309018256234, 0.7117931841999574, 0.7115139771178897, 0.7128144710399936]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 229,653
Trainable params: 54,913
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 16s - loss: 2.2243 - acc: 0.6653 - mDice: 0.1842 - val_loss: 0.8989 - val_acc: 0.9223 - val_mDice: 0.4116

Epoch 00001: val_mDice improved from -inf to 0.41164, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.7275 - acc: 0.9144 - mDice: 0.4700 - val_loss: 0.5999 - val_acc: 0.9465 - val_mDice: 0.5397

Epoch 00002: val_mDice improved from 0.41164 to 0.53969, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.5537 - acc: 0.9301 - mDice: 0.5591 - val_loss: 0.5503 - val_acc: 0.9490 - val_mDice: 0.5680

Epoch 00003: val_mDice improved from 0.53969 to 0.56801, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.4881 - acc: 0.9371 - mDice: 0.5984 - val_loss: 0.5075 - val_acc: 0.9486 - val_mDice: 0.5916

Epoch 00004: val_mDice improved from 0.56801 to 0.59161, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.4454 - acc: 0.9406 - mDice: 0.6252 - val_loss: 0.5166 - val_acc: 0.9516 - val_mDice: 0.5902

Epoch 00005: val_mDice did not improve from 0.59161
Epoch 6/300
 - 12s - loss: 0.4184 - acc: 0.9429 - mDice: 0.6431 - val_loss: 0.4754 - val_acc: 0.9507 - val_mDice: 0.6120

Epoch 00006: val_mDice improved from 0.59161 to 0.61198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.3969 - acc: 0.9447 - mDice: 0.6575 - val_loss: 0.4882 - val_acc: 0.9505 - val_mDice: 0.6065

Epoch 00007: val_mDice did not improve from 0.61198
Epoch 8/300
 - 12s - loss: 0.3811 - acc: 0.9458 - mDice: 0.6685 - val_loss: 0.5044 - val_acc: 0.9517 - val_mDice: 0.5987

Epoch 00008: val_mDice did not improve from 0.61198
Epoch 9/300
 - 12s - loss: 0.3692 - acc: 0.9466 - mDice: 0.6766 - val_loss: 0.4699 - val_acc: 0.9524 - val_mDice: 0.6164

Epoch 00009: val_mDice improved from 0.61198 to 0.61638, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.3618 - acc: 0.9472 - mDice: 0.6820 - val_loss: 0.5167 - val_acc: 0.9517 - val_mDice: 0.5955

Epoch 00010: val_mDice did not improve from 0.61638
Epoch 11/300
 - 12s - loss: 0.3504 - acc: 0.9478 - mDice: 0.6901 - val_loss: 0.4942 - val_acc: 0.9527 - val_mDice: 0.6046

Epoch 00011: val_mDice did not improve from 0.61638
Epoch 12/300
 - 12s - loss: 0.3434 - acc: 0.9485 - mDice: 0.6952 - val_loss: 0.4823 - val_acc: 0.9523 - val_mDice: 0.6128

Epoch 00012: val_mDice did not improve from 0.61638
Epoch 13/300
 - 12s - loss: 0.3372 - acc: 0.9490 - mDice: 0.6997 - val_loss: 0.4675 - val_acc: 0.9549 - val_mDice: 0.6227

Epoch 00013: val_mDice improved from 0.61638 to 0.62268, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 12s - loss: 0.3322 - acc: 0.9493 - mDice: 0.7034 - val_loss: 0.5079 - val_acc: 0.9518 - val_mDice: 0.5963

Epoch 00014: val_mDice did not improve from 0.62268
Epoch 15/300
 - 12s - loss: 0.3250 - acc: 0.9496 - mDice: 0.7085 - val_loss: 0.4772 - val_acc: 0.9531 - val_mDice: 0.6170

Epoch 00015: val_mDice did not improve from 0.62268
Epoch 16/300
 - 12s - loss: 0.3210 - acc: 0.9499 - mDice: 0.7115 - val_loss: 0.4929 - val_acc: 0.9525 - val_mDice: 0.6063

Epoch 00016: val_mDice did not improve from 0.62268
Epoch 17/300
 - 12s - loss: 0.3167 - acc: 0.9502 - mDice: 0.7147 - val_loss: 0.4627 - val_acc: 0.9531 - val_mDice: 0.6230

Epoch 00017: val_mDice improved from 0.62268 to 0.62301, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 12s - loss: 0.3118 - acc: 0.9505 - mDice: 0.7184 - val_loss: 0.4887 - val_acc: 0.9540 - val_mDice: 0.6113

Epoch 00018: val_mDice did not improve from 0.62301
Epoch 19/300
 - 12s - loss: 0.3078 - acc: 0.9508 - mDice: 0.7214 - val_loss: 0.5061 - val_acc: 0.9540 - val_mDice: 0.6014

Epoch 00019: val_mDice did not improve from 0.62301
Epoch 20/300
 - 12s - loss: 0.3044 - acc: 0.9509 - mDice: 0.7238 - val_loss: 0.4807 - val_acc: 0.9497 - val_mDice: 0.6101

Epoch 00020: val_mDice did not improve from 0.62301
Epoch 21/300
 - 12s - loss: 0.3011 - acc: 0.9512 - mDice: 0.7265 - val_loss: 0.5336 - val_acc: 0.9516 - val_mDice: 0.5834

Epoch 00021: val_mDice did not improve from 0.62301
Epoch 22/300
 - 12s - loss: 0.2996 - acc: 0.9512 - mDice: 0.7276 - val_loss: 0.4785 - val_acc: 0.9549 - val_mDice: 0.6209

Epoch 00022: val_mDice did not improve from 0.62301
Epoch 23/300
 - 12s - loss: 0.2958 - acc: 0.9515 - mDice: 0.7305 - val_loss: 0.4756 - val_acc: 0.9530 - val_mDice: 0.6159

Epoch 00023: val_mDice did not improve from 0.62301
Epoch 24/300
 - 12s - loss: 0.2938 - acc: 0.9517 - mDice: 0.7320 - val_loss: 0.4801 - val_acc: 0.9537 - val_mDice: 0.6154

Epoch 00024: val_mDice did not improve from 0.62301
Epoch 25/300
 - 13s - loss: 0.2914 - acc: 0.9519 - mDice: 0.7338 - val_loss: 0.5034 - val_acc: 0.9531 - val_mDice: 0.6030

Epoch 00025: val_mDice did not improve from 0.62301
Epoch 26/300
 - 12s - loss: 0.2879 - acc: 0.9520 - mDice: 0.7365 - val_loss: 0.4818 - val_acc: 0.9540 - val_mDice: 0.6156

Epoch 00026: val_mDice did not improve from 0.62301
Epoch 27/300
 - 12s - loss: 0.2875 - acc: 0.9521 - mDice: 0.7370 - val_loss: 0.5016 - val_acc: 0.9503 - val_mDice: 0.6027

Epoch 00027: val_mDice did not improve from 0.62301
Epoch 28/300
 - 12s - loss: 0.2854 - acc: 0.9522 - mDice: 0.7385 - val_loss: 0.5034 - val_acc: 0.9541 - val_mDice: 0.6033

Epoch 00028: val_mDice did not improve from 0.62301
Epoch 29/300
 - 12s - loss: 0.2833 - acc: 0.9524 - mDice: 0.7402 - val_loss: 0.4878 - val_acc: 0.9506 - val_mDice: 0.6101

Epoch 00029: val_mDice did not improve from 0.62301
Epoch 30/300
 - 12s - loss: 0.2797 - acc: 0.9526 - mDice: 0.7428 - val_loss: 0.4972 - val_acc: 0.9531 - val_mDice: 0.6076

Epoch 00030: val_mDice did not improve from 0.62301
Epoch 31/300
 - 12s - loss: 0.2796 - acc: 0.9525 - mDice: 0.7429 - val_loss: 0.4836 - val_acc: 0.9522 - val_mDice: 0.6142

Epoch 00031: val_mDice did not improve from 0.62301
Epoch 32/300
 - 12s - loss: 0.2764 - acc: 0.9528 - mDice: 0.7455 - val_loss: 0.4714 - val_acc: 0.9506 - val_mDice: 0.6196

Epoch 00032: val_mDice did not improve from 0.62301
Epoch 33/300
 - 12s - loss: 0.2749 - acc: 0.9529 - mDice: 0.7466 - val_loss: 0.4737 - val_acc: 0.9526 - val_mDice: 0.6195

Epoch 00033: val_mDice did not improve from 0.62301
Epoch 34/300
 - 12s - loss: 0.2738 - acc: 0.9531 - mDice: 0.7475 - val_loss: 0.4768 - val_acc: 0.9537 - val_mDice: 0.6179

Epoch 00034: val_mDice did not improve from 0.62301
Epoch 35/300
 - 12s - loss: 0.2727 - acc: 0.9531 - mDice: 0.7484 - val_loss: 0.4921 - val_acc: 0.9529 - val_mDice: 0.6142

Epoch 00035: val_mDice did not improve from 0.62301
Epoch 36/300
 - 12s - loss: 0.2706 - acc: 0.9533 - mDice: 0.7499 - val_loss: 0.4983 - val_acc: 0.9539 - val_mDice: 0.6112

Epoch 00036: val_mDice did not improve from 0.62301
Epoch 37/300
 - 13s - loss: 0.2699 - acc: 0.9533 - mDice: 0.7505 - val_loss: 0.5111 - val_acc: 0.9534 - val_mDice: 0.6055

Epoch 00037: val_mDice did not improve from 0.62301
Epoch 38/300
 - 12s - loss: 0.2685 - acc: 0.9534 - mDice: 0.7516 - val_loss: 0.5297 - val_acc: 0.9525 - val_mDice: 0.5922

Epoch 00038: val_mDice did not improve from 0.62301
Epoch 39/300
 - 12s - loss: 0.2676 - acc: 0.9534 - mDice: 0.7523 - val_loss: 0.5162 - val_acc: 0.9533 - val_mDice: 0.6002

Epoch 00039: val_mDice did not improve from 0.62301
Epoch 40/300
 - 12s - loss: 0.2645 - acc: 0.9536 - mDice: 0.7548 - val_loss: 0.5243 - val_acc: 0.9542 - val_mDice: 0.5971

Epoch 00040: val_mDice did not improve from 0.62301
Epoch 41/300
 - 12s - loss: 0.2639 - acc: 0.9536 - mDice: 0.7553 - val_loss: 0.4727 - val_acc: 0.9522 - val_mDice: 0.6165

Epoch 00041: val_mDice did not improve from 0.62301
Epoch 42/300
 - 12s - loss: 0.2644 - acc: 0.9536 - mDice: 0.7549 - val_loss: 0.5394 - val_acc: 0.9516 - val_mDice: 0.5893

Epoch 00042: val_mDice did not improve from 0.62301
Epoch 43/300
 - 13s - loss: 0.2621 - acc: 0.9538 - mDice: 0.7568 - val_loss: 0.4653 - val_acc: 0.9528 - val_mDice: 0.6242

Epoch 00043: val_mDice improved from 0.62301 to 0.62418, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 12s - loss: 0.2706 - acc: 0.9530 - mDice: 0.7504 - val_loss: 0.4974 - val_acc: 0.9475 - val_mDice: 0.6041

Epoch 00044: val_mDice did not improve from 0.62418
Epoch 45/300
 - 12s - loss: 0.2689 - acc: 0.9532 - mDice: 0.7513 - val_loss: 0.4934 - val_acc: 0.9541 - val_mDice: 0.6109

Epoch 00045: val_mDice did not improve from 0.62418
Epoch 46/300
 - 12s - loss: 0.2608 - acc: 0.9539 - mDice: 0.7577 - val_loss: 0.4920 - val_acc: 0.9536 - val_mDice: 0.6144

Epoch 00046: val_mDice did not improve from 0.62418
Epoch 47/300
 - 13s - loss: 0.2585 - acc: 0.9540 - mDice: 0.7596 - val_loss: 0.4794 - val_acc: 0.9549 - val_mDice: 0.6199

Epoch 00047: val_mDice did not improve from 0.62418
Epoch 48/300
 - 12s - loss: 0.2577 - acc: 0.9540 - mDice: 0.7602 - val_loss: 0.5102 - val_acc: 0.9534 - val_mDice: 0.6061

Epoch 00048: val_mDice did not improve from 0.62418
Epoch 49/300
 - 12s - loss: 0.2573 - acc: 0.9541 - mDice: 0.7606 - val_loss: 0.5208 - val_acc: 0.9538 - val_mDice: 0.6053

Epoch 00049: val_mDice did not improve from 0.62418
Epoch 50/300
 - 12s - loss: 0.2569 - acc: 0.9542 - mDice: 0.7609 - val_loss: 0.4998 - val_acc: 0.9527 - val_mDice: 0.6080

Epoch 00050: val_mDice did not improve from 0.62418
Epoch 51/300
 - 12s - loss: 0.2566 - acc: 0.9542 - mDice: 0.7612 - val_loss: 0.5042 - val_acc: 0.9526 - val_mDice: 0.6163

Epoch 00051: val_mDice did not improve from 0.62418
Epoch 52/300
 - 12s - loss: 0.2553 - acc: 0.9543 - mDice: 0.7622 - val_loss: 0.4876 - val_acc: 0.9528 - val_mDice: 0.6130

Epoch 00052: val_mDice did not improve from 0.62418
Epoch 53/300
 - 12s - loss: 0.2547 - acc: 0.9544 - mDice: 0.7627 - val_loss: 0.5226 - val_acc: 0.9537 - val_mDice: 0.6040

Epoch 00053: val_mDice did not improve from 0.62418
Epoch 54/300
 - 12s - loss: 0.2544 - acc: 0.9544 - mDice: 0.7629 - val_loss: 0.4783 - val_acc: 0.9525 - val_mDice: 0.6172

Epoch 00054: val_mDice did not improve from 0.62418
Epoch 55/300
 - 12s - loss: 0.2532 - acc: 0.9544 - mDice: 0.7638 - val_loss: 0.5057 - val_acc: 0.9530 - val_mDice: 0.6091

Epoch 00055: val_mDice did not improve from 0.62418
Epoch 56/300
 - 12s - loss: 0.2525 - acc: 0.9545 - mDice: 0.7644 - val_loss: 0.5238 - val_acc: 0.9521 - val_mDice: 0.5992

Epoch 00056: val_mDice did not improve from 0.62418
Epoch 57/300
 - 12s - loss: 0.2503 - acc: 0.9547 - mDice: 0.7661 - val_loss: 0.4873 - val_acc: 0.9534 - val_mDice: 0.6149

Epoch 00057: val_mDice did not improve from 0.62418
Epoch 58/300
 - 12s - loss: 0.2511 - acc: 0.9547 - mDice: 0.7656 - val_loss: 0.4915 - val_acc: 0.9536 - val_mDice: 0.6164

Epoch 00058: val_mDice did not improve from 0.62418
Epoch 59/300
 - 12s - loss: 0.2510 - acc: 0.9548 - mDice: 0.7656 - val_loss: 0.5527 - val_acc: 0.9516 - val_mDice: 0.5855

Epoch 00059: val_mDice did not improve from 0.62418
Epoch 60/300
 - 12s - loss: 0.2513 - acc: 0.9547 - mDice: 0.7653 - val_loss: 0.5185 - val_acc: 0.9540 - val_mDice: 0.5967

Epoch 00060: val_mDice did not improve from 0.62418
Epoch 61/300
 - 12s - loss: 0.2497 - acc: 0.9548 - mDice: 0.7666 - val_loss: 0.5071 - val_acc: 0.9527 - val_mDice: 0.6074

Epoch 00061: val_mDice did not improve from 0.62418
Epoch 62/300
 - 12s - loss: 0.2474 - acc: 0.9550 - mDice: 0.7685 - val_loss: 0.5159 - val_acc: 0.9517 - val_mDice: 0.6015

Epoch 00062: val_mDice did not improve from 0.62418
Epoch 63/300
 - 12s - loss: 0.2474 - acc: 0.9550 - mDice: 0.7685 - val_loss: 0.4779 - val_acc: 0.9534 - val_mDice: 0.6183

Epoch 00063: val_mDice did not improve from 0.62418
Epoch 64/300
 - 12s - loss: 0.2478 - acc: 0.9550 - mDice: 0.7682 - val_loss: 0.4870 - val_acc: 0.9524 - val_mDice: 0.6152

Epoch 00064: val_mDice did not improve from 0.62418
Epoch 65/300
 - 12s - loss: 0.2474 - acc: 0.9550 - mDice: 0.7685 - val_loss: 0.5050 - val_acc: 0.9548 - val_mDice: 0.6087

Epoch 00065: val_mDice did not improve from 0.62418
Epoch 66/300
 - 12s - loss: 0.2473 - acc: 0.9550 - mDice: 0.7686 - val_loss: 0.5260 - val_acc: 0.9530 - val_mDice: 0.6059

Epoch 00066: val_mDice did not improve from 0.62418
Epoch 67/300
 - 12s - loss: 0.2457 - acc: 0.9551 - mDice: 0.7699 - val_loss: 0.4961 - val_acc: 0.9543 - val_mDice: 0.6113

Epoch 00067: val_mDice did not improve from 0.62418
Epoch 68/300
 - 13s - loss: 0.2443 - acc: 0.9553 - mDice: 0.7709 - val_loss: 0.5232 - val_acc: 0.9537 - val_mDice: 0.6036

Epoch 00068: val_mDice did not improve from 0.62418
Epoch 69/300
 - 12s - loss: 0.2448 - acc: 0.9552 - mDice: 0.7705 - val_loss: 0.5139 - val_acc: 0.9537 - val_mDice: 0.6035

Epoch 00069: val_mDice did not improve from 0.62418
Epoch 70/300
 - 12s - loss: 0.2444 - acc: 0.9552 - mDice: 0.7709 - val_loss: 0.4912 - val_acc: 0.9535 - val_mDice: 0.6179

Epoch 00070: val_mDice did not improve from 0.62418
Epoch 71/300
 - 12s - loss: 0.2436 - acc: 0.9553 - mDice: 0.7716 - val_loss: 0.5473 - val_acc: 0.9540 - val_mDice: 0.5966

Epoch 00071: val_mDice did not improve from 0.62418
Epoch 72/300
 - 12s - loss: 0.2439 - acc: 0.9553 - mDice: 0.7712 - val_loss: 0.5103 - val_acc: 0.9549 - val_mDice: 0.6098

Epoch 00072: val_mDice did not improve from 0.62418
Epoch 73/300
 - 13s - loss: 0.2423 - acc: 0.9554 - mDice: 0.7726 - val_loss: 0.5279 - val_acc: 0.9546 - val_mDice: 0.5978

Epoch 00073: val_mDice did not improve from 0.62418
Epoch 74/300
 - 12s - loss: 0.2426 - acc: 0.9554 - mDice: 0.7724 - val_loss: 0.5046 - val_acc: 0.9537 - val_mDice: 0.6035

Epoch 00074: val_mDice did not improve from 0.62418
Epoch 75/300
 - 12s - loss: 0.2426 - acc: 0.9555 - mDice: 0.7724 - val_loss: 0.4818 - val_acc: 0.9538 - val_mDice: 0.6157

Epoch 00075: val_mDice did not improve from 0.62418
Epoch 76/300
 - 12s - loss: 0.2423 - acc: 0.9555 - mDice: 0.7728 - val_loss: 0.5118 - val_acc: 0.9532 - val_mDice: 0.6071

Epoch 00076: val_mDice did not improve from 0.62418
Epoch 77/300
 - 12s - loss: 0.2414 - acc: 0.9555 - mDice: 0.7734 - val_loss: 0.5007 - val_acc: 0.9547 - val_mDice: 0.6096

Epoch 00077: val_mDice did not improve from 0.62418
Epoch 78/300
 - 13s - loss: 0.2409 - acc: 0.9555 - mDice: 0.7737 - val_loss: 0.4804 - val_acc: 0.9544 - val_mDice: 0.6157

Epoch 00078: val_mDice did not improve from 0.62418
Epoch 79/300
 - 12s - loss: 0.2418 - acc: 0.9556 - mDice: 0.7730 - val_loss: 0.4903 - val_acc: 0.9545 - val_mDice: 0.6133

Epoch 00079: val_mDice did not improve from 0.62418
Epoch 80/300
 - 12s - loss: 0.2400 - acc: 0.9556 - mDice: 0.7745 - val_loss: 0.5209 - val_acc: 0.9559 - val_mDice: 0.6059

Epoch 00080: val_mDice did not improve from 0.62418
Epoch 81/300
 - 12s - loss: 0.2400 - acc: 0.9557 - mDice: 0.7744 - val_loss: 0.5093 - val_acc: 0.9535 - val_mDice: 0.6052

Epoch 00081: val_mDice did not improve from 0.62418
Epoch 82/300
 - 12s - loss: 0.2383 - acc: 0.9558 - mDice: 0.7758 - val_loss: 0.5115 - val_acc: 0.9528 - val_mDice: 0.6032

Epoch 00082: val_mDice did not improve from 0.62418
Epoch 83/300
 - 13s - loss: 0.2381 - acc: 0.9558 - mDice: 0.7760 - val_loss: 0.5130 - val_acc: 0.9535 - val_mDice: 0.6039

Epoch 00083: val_mDice did not improve from 0.62418
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [0.8989055602910132, 0.5999134229548151, 0.5502695138228006, 0.5075043556410507, 0.5165796076785253, 0.47541494542659996, 0.4881943820575096, 0.5044463040442441, 0.4699187495189006, 0.5167174822125356, 0.49422626089117383, 0.4822930573751141, 0.4674659930793933, 0.50793785622666, 0.47722369532345393, 0.49287953256894756, 0.462745909917288, 0.4887217699482454, 0.5060625352673025, 0.4806662628104567, 0.533629507325881, 0.4785184440666071, 0.4755553656450197, 0.4801304799884391, 0.5034210448824493, 0.48183459576281756, 0.5015944079313864, 0.5034209103557651, 0.48781044789532707, 0.4972443930263626, 0.4836214900682758, 0.4714307015834574, 0.47371809775602886, 0.4767926645012541, 0.4920736880941764, 0.4983411178242561, 0.5110602042528504, 0.529682117467486, 0.5161899088481285, 0.5242632334458761, 0.4727485036716781, 0.5393721128309239, 0.4653404558171107, 0.4974219575940564, 0.49338400330623433, 0.49203543822858586, 0.4794081459498272, 0.5102064739392457, 0.5207576258888458, 0.4997626026915438, 0.504210179744486, 0.4875779151916504, 0.5226054614482645, 0.47825814692001767, 0.5057297182482714, 0.5237563951721405, 0.4873373428536527, 0.4914657606758885, 0.5526879066861542, 0.5185072292162719, 0.5070620375638567, 0.5159105861653163, 0.47788675603919856, 0.48703075587416494, 0.5050498753286606, 0.5259587664843938, 0.4960563385952784, 0.5232463255940869, 0.5138723533912744, 0.49124765229624745, 0.5472737514106921, 0.510272557509012, 0.5278874582418517, 0.5045658416588213, 0.48177167923090847, 0.5118351358941148, 0.500702768064744, 0.4803879577354346, 0.4902964720512902, 0.5208529367127233, 0.5092955454767749, 0.5115229893663076, 0.5130366979364577], 'val_acc': [0.9222856307162919, 0.9465306930701826, 0.9489913592791425, 0.948602935122378, 0.9515574041691572, 0.9506566058324036, 0.9505305376798747, 0.9517102807593745, 0.9524086007858787, 0.9517102794274271, 0.9527143726135765, 0.952323872949824, 0.9548795839261742, 0.9517784631452081, 0.9530883298239894, 0.9524767968241729, 0.9531482448125018, 0.9539911953430602, 0.9539788128943417, 0.9496917658012006, 0.9515904308031391, 0.9548754635469874, 0.9530325278889533, 0.9537411968135301, 0.9530511385235707, 0.9540428455981462, 0.950295029405775, 0.9540634794608175, 0.9506462655919891, 0.9530655858236984, 0.9522205631160203, 0.9506483277795035, 0.9526110707714571, 0.9537122679156298, 0.9528527865862714, 0.9538548432248931, 0.9534250967329441, 0.9524850315887835, 0.9532742916538729, 0.9541833127677107, 0.9521627396178645, 0.9515739023352469, 0.9528403854902896, 0.9475244610003253, 0.9540924210122178, 0.9535634973861652, 0.9549333333303143, 0.9534395526907298, 0.9537784034313437, 0.9526957759644066, 0.9526234685375704, 0.9527598269824875, 0.9536502860777871, 0.9525449525710591, 0.9530056668393438, 0.9520532585389121, 0.9534188758727559, 0.9535841798649154, 0.9516069865759524, 0.9539705518237706, 0.9526523821180759, 0.9517454075413709, 0.95343750582061, 0.9523858904172589, 0.9547907546911826, 0.9529912055537687, 0.9542825065511565, 0.9537040011842823, 0.9536502834138924, 0.9534911842985526, 0.9540097766748353, 0.9549270898270208, 0.954567629864762, 0.9537143447545654, 0.9538072923708228, 0.9532164022243222, 0.9546957169165159, 0.9543940531474918, 0.9544601876642451, 0.9559208634179398, 0.9534560628443457, 0.9528424679900015, 0.9534560891503062], 'val_mDice': [0.41163659462049684, 0.5396859694126598, 0.5680061507158439, 0.5916117409754066, 0.59020749017513, 0.6119791262642631, 0.6065029555192872, 0.5987186804830029, 0.6163849207942046, 0.5954991599034997, 0.6045579314231873, 0.6127808057396106, 0.6226790920316174, 0.5963067295831009, 0.6170320314402021, 0.6063305399271363, 0.623006201656171, 0.6113198619315078, 0.6013860432795306, 0.6100892258090014, 0.5833625350584531, 0.6208934950428968, 0.6158756190838095, 0.6154041197046888, 0.6030008060306145, 0.6155594933632366, 0.6026741958863242, 0.60333743574899, 0.6100714206695557, 0.6075851800721451, 0.6142090422481132, 0.6195797946865998, 0.6194793858341665, 0.6179429545748834, 0.6141624347457673, 0.6112352303286505, 0.605518163915453, 0.5922497550868455, 0.600162384896305, 0.5970821890085103, 0.6165084925443767, 0.5892560315531725, 0.6241756054942168, 0.6040921207912807, 0.6109008605919737, 0.6144439165152651, 0.6199066705543902, 0.6061058427368462, 0.6053156939298747, 0.6080070524242337, 0.6163127865205263, 0.6129711460134837, 0.6039507102699919, 0.6171523126143983, 0.6091383122865048, 0.5992036824785797, 0.6148719994049499, 0.6163573025325157, 0.5854645424714967, 0.5967447441383447, 0.6074305626267161, 0.6015423453053949, 0.6182535280728473, 0.6151555836533701, 0.608659204491024, 0.6058574022527513, 0.6112899380689226, 0.6035959327687098, 0.6035222521041359, 0.6179462697918855, 0.5965854448979128, 0.6098096080998469, 0.5978339111338781, 0.603519779010858, 0.6156734591089813, 0.6071241121718337, 0.6096188802292893, 0.615668630133794, 0.613331882314309, 0.6058621140165702, 0.6051736330852828, 0.6031554670973197, 0.6039305329322815], 'loss': [2.2243333472112745, 0.7274523281069416, 0.5537224008616172, 0.48811024503701134, 0.44544647814115856, 0.4183556462196436, 0.39691700461441753, 0.381055705923315, 0.3691988732471204, 0.36177483738608157, 0.3503820396564955, 0.3433900700857629, 0.3372465143045448, 0.33221939548117213, 0.3250237880536891, 0.32101094313069345, 0.31669542658115407, 0.3118039200728732, 0.30779311627865386, 0.3043782079289937, 0.3011124378653447, 0.29964013592550603, 0.2957885525018962, 0.29376853119248586, 0.2914298396569946, 0.2878644600292286, 0.2874732452630023, 0.28541738761938007, 0.2832564990960411, 0.2797425623296763, 0.27955789167009326, 0.2763648388851417, 0.2749075465950011, 0.2737836370598769, 0.27268366510685893, 0.27059980616623536, 0.2699388541006508, 0.26852578297886387, 0.2676369150907059, 0.2644871714542221, 0.2638541157436776, 0.2643540621665716, 0.26213168361485506, 0.27058570153747896, 0.2689301638303645, 0.26076501133453484, 0.2585180875594226, 0.25765278990781226, 0.25730422655486, 0.2569035886874172, 0.2565625514474987, 0.25526627201405777, 0.254700555700303, 0.25444543869217123, 0.25316243439492403, 0.2525309202862386, 0.2503119391311027, 0.25106206877313014, 0.25102823263231133, 0.2512845753378471, 0.24968777772816858, 0.24738934962527825, 0.24737134821910586, 0.24780666644011218, 0.24743918216629074, 0.24725683716074404, 0.24574895831346708, 0.24433824290936304, 0.2448463388163503, 0.2443558829690719, 0.2435750266587083, 0.2439406335509672, 0.24232943376569757, 0.242597572445824, 0.24258096047777683, 0.24231850229137558, 0.24141271827001598, 0.240919608524387, 0.2418130515080886, 0.23996619429049956, 0.24004944923279703, 0.23827122632623285, 0.2381443572238499], 'acc': [0.6653284366304926, 0.9144090873166293, 0.9300709001853454, 0.9370778068972337, 0.9405912764938131, 0.9429146442354378, 0.9446818210591574, 0.9457875796895577, 0.9466233422511946, 0.9471694266028046, 0.9478438719867667, 0.9485289722049647, 0.9489539445508092, 0.9492704096939509, 0.9496165670234974, 0.9499318452937353, 0.9501826527117254, 0.9504573044093383, 0.9507771745615486, 0.9508600160808229, 0.9511842972916343, 0.9512369495404, 0.9515078544395953, 0.9516601865311463, 0.9518510494140763, 0.9520396560107524, 0.9521279975444843, 0.9522207099513209, 0.9523553992530553, 0.952621551823703, 0.9525442089911647, 0.952823191415341, 0.9529366500756429, 0.953060804998996, 0.953059594188145, 0.9532658668406083, 0.953337753473508, 0.9533617406861142, 0.9533504009389662, 0.9536343599370827, 0.953625700051901, 0.953642152251842, 0.9537958752179898, 0.9530230986059806, 0.9532427443741752, 0.9538632695220809, 0.9540334287522619, 0.9540404175226546, 0.9541039052699608, 0.9541520634109656, 0.9541741370680831, 0.9542571598165117, 0.9543715856003999, 0.9544149536393345, 0.9544478240410985, 0.9544974559467931, 0.9546592712798387, 0.9547493862505865, 0.9547876557567061, 0.9546909348311933, 0.9548220145216072, 0.9550011761242655, 0.9550308888725034, 0.9550022256380203, 0.9550361860863855, 0.9549893339496638, 0.9551208178810444, 0.9553047536660965, 0.9552257989500935, 0.9551692204299845, 0.955292528399935, 0.9552852794934602, 0.9554231259650274, 0.955438857906739, 0.9554621633325849, 0.955537069980683, 0.9554723725489792, 0.9555390854883243, 0.9555630945288066, 0.9555803738052786, 0.9557012855490467, 0.9557581852674549, 0.9557865843567205], 'mDice': [0.18415397910621262, 0.47000597916386444, 0.5590769449263823, 0.5984494351891415, 0.6251952201963918, 0.6431296365751004, 0.657548798331053, 0.668456931940306, 0.6766162084459278, 0.6819580132181781, 0.6900591821291628, 0.6952167720188536, 0.6997391741024267, 0.7033747509799553, 0.70846096090382, 0.7115171738202247, 0.7147082276615947, 0.7184447167154867, 0.7214430269998413, 0.723837563219715, 0.7264713851151582, 0.7275585519105974, 0.7304649494629359, 0.7320099532763285, 0.7338301793668441, 0.7365307242780345, 0.7369764400303711, 0.7384921015623667, 0.7402373187442366, 0.7428326960528289, 0.7428859031724356, 0.7454748507464324, 0.7465730073320717, 0.7475472778174412, 0.7483507587651166, 0.7499278135746629, 0.7505051048744297, 0.7516069985618974, 0.7523232955219997, 0.7548033652057069, 0.7552609544915511, 0.7548991158555116, 0.7567802006548692, 0.7503600506719944, 0.7512919689814163, 0.7577281244491533, 0.7595963476530172, 0.7601973460745263, 0.760555644621225, 0.7609045094871344, 0.7611874763005102, 0.7622136231614292, 0.7626539443833955, 0.7629192183073696, 0.763822875552159, 0.7643640321633712, 0.7661385112166904, 0.7656016186310649, 0.7655950494889282, 0.7653256941903852, 0.7666231649424877, 0.7684684233282147, 0.7684606276957741, 0.7681835706856871, 0.7684893989724003, 0.7685813443748125, 0.7698800756380608, 0.7709362070958188, 0.7705291962157432, 0.7708648129925152, 0.7715601608920841, 0.7712430761346214, 0.7725529904381381, 0.7723613529188182, 0.7723660545926696, 0.7727526411122795, 0.7734123342703724, 0.7737431841039182, 0.7730293021853418, 0.7744560628329206, 0.7744406393414314, 0.7758230320879216, 0.7759953046129404]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:49,  1.87s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:09,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:58,  1.70s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:31,  1.61s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:55,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:26,  1.60s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:03,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:03,  1.75s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:25,  1.83s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:41,  1.90s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:20,  1.83s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:43,  1.92s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:17,  1.84s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:34,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<09:01,  2.01s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:27,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:05,  1.83s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:19,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:19,  1.91s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:10,  1.89s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:25,  1.95s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:09,  1.90s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:15,  1.93s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:09,  1.91s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:23,  1.97s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:37,  2.04s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:09,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<08:04,  1.92s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:14,  1.98s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:50,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<08:05,  1.96s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:28,  2.06s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:58,  1.95s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<07:53,  1.93s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:28,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:17,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:15,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:29,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:15,  1.81s/it]predicting train subjects:  16%|█▌        | 46/285 [01:26<07:45,  1.95s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:25,  1.87s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:25,  1.88s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<07:46,  1.98s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:38,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<07:55,  2.03s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:22,  1.90s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:33,  1.95s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:41,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:23,  1.93s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:22,  1.93s/it]predicting train subjects:  20%|██        | 57/285 [01:47<07:04,  1.86s/it]predicting train subjects:  20%|██        | 58/285 [01:49<07:08,  1.89s/it]predicting train subjects:  21%|██        | 59/285 [01:51<07:19,  1.95s/it]predicting train subjects:  21%|██        | 60/285 [01:53<07:30,  2.00s/it]predicting train subjects:  21%|██▏       | 61/285 [01:55<07:03,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<07:01,  1.89s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<07:06,  1.92s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<07:02,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<07:03,  1.93s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<07:05,  1.95s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:50,  1.89s/it]predicting train subjects:  24%|██▍       | 69/285 [02:10<06:38,  1.85s/it]predicting train subjects:  25%|██▍       | 70/285 [02:12<06:44,  1.88s/it]predicting train subjects:  25%|██▍       | 71/285 [02:14<06:43,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:37,  1.87s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:44,  1.91s/it]predicting train subjects:  26%|██▌       | 74/285 [02:19<06:43,  1.91s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:46,  1.94s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:42,  1.93s/it]predicting train subjects:  27%|██▋       | 77/285 [02:25<06:32,  1.89s/it]predicting train subjects:  27%|██▋       | 78/285 [02:27<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:29<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:31<06:23,  1.87s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:12,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:06,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:36<05:55,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<05:47,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<05:49,  1.75s/it]predicting train subjects:  30%|███       | 86/285 [02:41<05:59,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:10,  1.87s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:03,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:47<06:01,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:49<06:02,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<05:53,  1.82s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<05:58,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:54<05:52,  1.83s/it]predicting train subjects:  33%|███▎      | 94/285 [02:56<05:50,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:58<05:58,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<05:57,  1.89s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<05:59,  1.91s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<05:56,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<05:47,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:35,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:45,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:39,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:40,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:39,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:31,  1.85s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:37,  1.90s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:27,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:32,  1.89s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:38,  1.93s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:30,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:29,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:24,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:21,  1.88s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:27,  1.94s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:20,  1.91s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:17,  1.90s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:22,  1.95s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:20,  1.94s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<05:08,  1.88s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:52,  1.79s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:35,  1.70s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:38,  1.73s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:31,  1.70s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:24,  1.66s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:21,  1.66s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:13,  1.63s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:05,  1.60s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:09,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:06,  1.62s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<04:05,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<03:56,  1.58s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:57,  1.59s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<03:57,  1.61s/it]predicting train subjects:  48%|████▊     | 138/285 [04:14<03:54,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:58,  1.63s/it]predicting train subjects:  49%|████▉     | 140/285 [04:18<04:01,  1.66s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<03:53,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:21<03:52,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:24<03:54,  1.67s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:45,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:28<03:48,  1.64s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:29<03:48,  1.66s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:31<03:54,  1.71s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:33<03:49,  1.68s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:42,  1.65s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:36<03:42,  1.66s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:38<03:37,  1.64s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:39<03:30,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:41<03:33,  1.63s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:42<03:30,  1.62s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:44<03:38,  1.69s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:46<03:34,  1.68s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:47<03:28,  1.64s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:49<03:19,  1.59s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:51<03:17,  1.58s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:52<03:21,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:54<03:22,  1.64s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:56<03:22,  1.66s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:57<03:19,  1.65s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:59<03:17,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:01<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:02<03:16,  1.66s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:04<03:08,  1.61s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:05<03:09,  1.63s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:07<03:04,  1.60s/it]predicting train subjects:  60%|██████    | 171/285 [05:09<03:02,  1.60s/it]predicting train subjects:  60%|██████    | 172/285 [05:10<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:12<03:00,  1.61s/it]predicting train subjects:  61%|██████    | 174/285 [05:13<02:54,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:15<03:00,  1.64s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:17<03:02,  1.67s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:18<02:59,  1.66s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:20<02:50,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:21<02:47,  1.58s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:23<02:54,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:25<02:55,  1.69s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:27<02:55,  1.70s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:28<02:52,  1.69s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:30<02:50,  1.68s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:32<02:43,  1.63s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:34<02:53,  1.75s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:36<02:59,  1.83s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:38<03:04,  1.90s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:39<02:52,  1.80s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:41<02:43,  1.72s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:43<02:41,  1.72s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:44<02:42,  1.75s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:46<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:47<02:30,  1.65s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:49<02:25,  1.62s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:51<02:35,  1.74s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:53<02:36,  1.77s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:55<02:35,  1.79s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:56<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:58<02:24,  1.70s/it]predicting train subjects:  71%|███████   | 201/285 [06:00<02:31,  1.81s/it]predicting train subjects:  71%|███████   | 202/285 [06:02<02:32,  1.84s/it]predicting train subjects:  71%|███████   | 203/285 [06:04<02:36,  1.91s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:06<02:28,  1.84s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:07<02:19,  1.74s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:09<02:14,  1.70s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:11<02:20,  1.81s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:13<02:22,  1.85s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:15<02:19,  1.83s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:16<02:09,  1.72s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:17<02:01,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:19<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:21<02:06,  1.76s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:23<02:03,  1.74s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:25<02:06,  1.80s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:26<01:57,  1.70s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:28<02:03,  1.82s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:30<02:06,  1.88s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:32<02:05,  1.90s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:34<01:56,  1.79s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:35<01:50,  1.73s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:37<01:47,  1.71s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:39<01:42,  1.65s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:40<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:42<01:34,  1.58s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:44<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:46<01:42,  1.76s/it]predicting train subjects:  80%|████████  | 228/285 [06:48<01:44,  1.83s/it]predicting train subjects:  80%|████████  | 229/285 [06:49<01:42,  1.83s/it]predicting train subjects:  81%|████████  | 230/285 [06:51<01:35,  1.73s/it]predicting train subjects:  81%|████████  | 231/285 [06:52<01:29,  1.66s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:54<01:31,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:56<01:27,  1.68s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:58<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:59<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:01<01:28,  1.80s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:03<01:27,  1.82s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:05<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:07<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:08<01:16,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:10<01:12,  1.65s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:11<01:08,  1.60s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:13<01:05,  1.57s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:14<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:16<01:03,  1.58s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:18<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:20<01:07,  1.77s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:22<01:05,  1.76s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:23<01:01,  1.72s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:25<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:26<00:54,  1.60s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:28<00:51,  1.57s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:30<00:53,  1.67s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:31<00:53,  1.71s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:33<00:51,  1.71s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:35<00:48,  1.67s/it]predicting train subjects:  90%|█████████ | 257/285 [07:36<00:46,  1.65s/it]predicting train subjects:  91%|█████████ | 258/285 [07:38<00:48,  1.80s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:46,  1.80s/it]predicting train subjects:  91%|█████████ | 260/285 [07:42<00:41,  1.68s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:39,  1.64s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:45<00:36,  1.59s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:35,  1.60s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:48<00:35,  1.71s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:50<00:35,  1.76s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:52<00:33,  1.76s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:53<00:31,  1.73s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:55<00:30,  1.77s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:57<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:58<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:00<00:22,  1.62s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:02<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:03<00:20,  1.67s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:05<00:17,  1.58s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:07<00:17,  1.71s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:09<00:15,  1.78s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:10<00:13,  1.69s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:12<00:11,  1.64s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:13<00:09,  1.66s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:15<00:08,  1.60s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:16<00:06,  1.57s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:18<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:20<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:22<00:01,  1.70s/it]predicting train subjects: 100%|██████████| 285/285 [08:24<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:07,  1.93s/it]Loading train:   1%|          | 2/285 [00:03<08:09,  1.73s/it]Loading train:   1%|          | 3/285 [00:04<08:11,  1.74s/it]Loading train:   1%|▏         | 4/285 [00:06<07:47,  1.66s/it]Loading train:   2%|▏         | 5/285 [00:08<07:44,  1.66s/it]Loading train:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]Loading train:   2%|▏         | 7/285 [00:10<07:11,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:12<07:00,  1.52s/it]Loading train:   3%|▎         | 9/285 [00:14<07:23,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:57,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:16<05:57,  1.30s/it]Loading train:   4%|▍         | 12/285 [00:17<05:36,  1.23s/it]Loading train:   5%|▍         | 13/285 [00:18<04:55,  1.09s/it]Loading train:   5%|▍         | 14/285 [00:18<04:34,  1.01s/it]Loading train:   5%|▌         | 15/285 [00:19<04:22,  1.03it/s]Loading train:   6%|▌         | 16/285 [00:20<04:07,  1.09it/s]Loading train:   6%|▌         | 17/285 [00:21<04:09,  1.07it/s]Loading train:   6%|▋         | 18/285 [00:22<04:22,  1.02it/s]Loading train:   7%|▋         | 19/285 [00:23<04:42,  1.06s/it]Loading train:   7%|▋         | 20/285 [00:25<05:11,  1.17s/it]Loading train:   7%|▋         | 21/285 [00:26<05:25,  1.23s/it]Loading train:   8%|▊         | 22/285 [00:28<05:46,  1.32s/it]Loading train:   8%|▊         | 23/285 [00:29<06:05,  1.40s/it]Loading train:   8%|▊         | 24/285 [00:31<06:00,  1.38s/it]Loading train:   9%|▉         | 25/285 [00:32<05:55,  1.37s/it]Loading train:   9%|▉         | 26/285 [00:34<06:07,  1.42s/it]Loading train:   9%|▉         | 27/285 [00:34<05:26,  1.26s/it]Loading train:  10%|▉         | 28/285 [00:36<05:48,  1.36s/it]Loading train:  10%|█         | 29/285 [00:37<05:25,  1.27s/it]Loading train:  11%|█         | 30/285 [00:39<05:33,  1.31s/it]Loading train:  11%|█         | 31/285 [00:40<05:53,  1.39s/it]Loading train:  11%|█         | 32/285 [00:41<05:37,  1.33s/it]Loading train:  12%|█▏        | 33/285 [00:43<05:50,  1.39s/it]Loading train:  12%|█▏        | 34/285 [00:45<06:15,  1.50s/it]Loading train:  12%|█▏        | 35/285 [00:46<06:07,  1.47s/it]Loading train:  13%|█▎        | 36/285 [00:47<05:45,  1.39s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:52,  1.42s/it]Loading train:  13%|█▎        | 38/285 [00:50<05:52,  1.43s/it]Loading train:  14%|█▎        | 39/285 [00:51<05:46,  1.41s/it]Loading train:  14%|█▍        | 40/285 [00:53<06:01,  1.48s/it]Loading train:  14%|█▍        | 41/285 [00:54<05:49,  1.43s/it]Loading train:  15%|█▍        | 42/285 [00:56<05:32,  1.37s/it]Loading train:  15%|█▌        | 43/285 [00:57<05:22,  1.33s/it]Loading train:  15%|█▌        | 44/285 [00:58<05:29,  1.37s/it]Loading train:  16%|█▌        | 45/285 [01:00<06:02,  1.51s/it]Loading train:  16%|█▌        | 46/285 [01:02<05:51,  1.47s/it]Loading train:  16%|█▋        | 47/285 [01:03<05:45,  1.45s/it]Loading train:  17%|█▋        | 48/285 [01:04<05:37,  1.42s/it]Loading train:  17%|█▋        | 49/285 [01:06<05:55,  1.51s/it]Loading train:  18%|█▊        | 50/285 [01:08<06:05,  1.55s/it]Loading train:  18%|█▊        | 51/285 [01:09<05:47,  1.49s/it]Loading train:  18%|█▊        | 52/285 [01:10<05:41,  1.47s/it]Loading train:  19%|█▊        | 53/285 [01:12<05:39,  1.46s/it]Loading train:  19%|█▉        | 54/285 [01:14<06:10,  1.61s/it]Loading train:  19%|█▉        | 55/285 [01:15<05:51,  1.53s/it]Loading train:  20%|█▉        | 56/285 [01:17<05:55,  1.55s/it]Loading train:  20%|██        | 57/285 [01:18<05:45,  1.52s/it]Loading train:  20%|██        | 58/285 [01:20<05:46,  1.53s/it]Loading train:  21%|██        | 59/285 [01:21<05:30,  1.46s/it]Loading train:  21%|██        | 60/285 [01:23<05:26,  1.45s/it]Loading train:  21%|██▏       | 61/285 [01:24<05:13,  1.40s/it]Loading train:  22%|██▏       | 62/285 [01:25<05:25,  1.46s/it]Loading train:  22%|██▏       | 63/285 [01:27<05:19,  1.44s/it]Loading train:  22%|██▏       | 64/285 [01:29<05:36,  1.52s/it]Loading train:  23%|██▎       | 65/285 [01:30<05:58,  1.63s/it]Loading train:  23%|██▎       | 66/285 [01:32<06:05,  1.67s/it]Loading train:  24%|██▎       | 67/285 [01:33<05:31,  1.52s/it]Loading train:  24%|██▍       | 68/285 [01:34<04:56,  1.37s/it]Loading train:  24%|██▍       | 69/285 [01:36<04:43,  1.31s/it]Loading train:  25%|██▍       | 70/285 [01:37<04:45,  1.33s/it]Loading train:  25%|██▍       | 71/285 [01:38<04:54,  1.38s/it]Loading train:  25%|██▌       | 72/285 [01:40<04:55,  1.39s/it]Loading train:  26%|██▌       | 73/285 [01:41<05:01,  1.42s/it]Loading train:  26%|██▌       | 74/285 [01:43<04:52,  1.39s/it]Loading train:  26%|██▋       | 75/285 [01:44<04:54,  1.40s/it]Loading train:  27%|██▋       | 76/285 [01:45<04:35,  1.32s/it]Loading train:  27%|██▋       | 77/285 [01:46<04:23,  1.27s/it]Loading train:  27%|██▋       | 78/285 [01:48<04:21,  1.26s/it]Loading train:  28%|██▊       | 79/285 [01:49<04:30,  1.31s/it]Loading train:  28%|██▊       | 80/285 [01:50<04:27,  1.31s/it]Loading train:  28%|██▊       | 81/285 [01:52<04:22,  1.29s/it]Loading train:  29%|██▉       | 82/285 [01:53<04:21,  1.29s/it]Loading train:  29%|██▉       | 83/285 [01:54<04:27,  1.33s/it]Loading train:  29%|██▉       | 84/285 [01:56<04:23,  1.31s/it]Loading train:  30%|██▉       | 85/285 [01:57<04:21,  1.31s/it]Loading train:  30%|███       | 86/285 [01:58<04:31,  1.37s/it]Loading train:  31%|███       | 87/285 [02:00<04:28,  1.36s/it]Loading train:  31%|███       | 88/285 [02:01<04:24,  1.34s/it]Loading train:  31%|███       | 89/285 [02:02<04:15,  1.31s/it]Loading train:  32%|███▏      | 90/285 [02:04<04:36,  1.42s/it]Loading train:  32%|███▏      | 91/285 [02:06<05:10,  1.60s/it]Loading train:  32%|███▏      | 92/285 [02:07<04:54,  1.53s/it]Loading train:  33%|███▎      | 93/285 [02:09<04:47,  1.50s/it]Loading train:  33%|███▎      | 94/285 [02:10<05:03,  1.59s/it]Loading train:  33%|███▎      | 95/285 [02:12<05:01,  1.59s/it]Loading train:  34%|███▎      | 96/285 [02:14<05:01,  1.60s/it]Loading train:  34%|███▍      | 97/285 [02:15<04:39,  1.49s/it]Loading train:  34%|███▍      | 98/285 [02:16<04:37,  1.48s/it]Loading train:  35%|███▍      | 99/285 [02:18<04:37,  1.49s/it]Loading train:  35%|███▌      | 100/285 [02:19<04:16,  1.39s/it]Loading train:  35%|███▌      | 101/285 [02:20<04:04,  1.33s/it]Loading train:  36%|███▌      | 102/285 [02:22<04:19,  1.42s/it]Loading train:  36%|███▌      | 103/285 [02:23<03:56,  1.30s/it]Loading train:  36%|███▋      | 104/285 [02:24<03:56,  1.31s/it]Loading train:  37%|███▋      | 105/285 [02:25<03:54,  1.30s/it]Loading train:  37%|███▋      | 106/285 [02:27<04:02,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:28<03:57,  1.34s/it]Loading train:  38%|███▊      | 108/285 [02:29<03:49,  1.30s/it]Loading train:  38%|███▊      | 109/285 [02:31<03:58,  1.36s/it]Loading train:  39%|███▊      | 110/285 [02:32<04:00,  1.37s/it]Loading train:  39%|███▉      | 111/285 [02:34<03:55,  1.35s/it]Loading train:  39%|███▉      | 112/285 [02:35<04:09,  1.44s/it]Loading train:  40%|███▉      | 113/285 [02:37<04:10,  1.46s/it]Loading train:  40%|████      | 114/285 [02:38<03:49,  1.34s/it]Loading train:  40%|████      | 115/285 [02:39<03:31,  1.24s/it]Loading train:  41%|████      | 116/285 [02:40<03:32,  1.26s/it]Loading train:  41%|████      | 117/285 [02:41<03:29,  1.25s/it]Loading train:  41%|████▏     | 118/285 [02:43<03:28,  1.25s/it]Loading train:  42%|████▏     | 119/285 [02:44<03:20,  1.21s/it]Loading train:  42%|████▏     | 120/285 [02:45<03:08,  1.14s/it]Loading train:  42%|████▏     | 121/285 [02:46<03:20,  1.22s/it]Loading train:  43%|████▎     | 122/285 [02:47<03:20,  1.23s/it]Loading train:  43%|████▎     | 123/285 [02:49<03:25,  1.27s/it]Loading train:  44%|████▎     | 124/285 [02:50<03:27,  1.29s/it]Loading train:  44%|████▍     | 125/285 [02:52<03:34,  1.34s/it]Loading train:  44%|████▍     | 126/285 [02:53<03:29,  1.32s/it]Loading train:  45%|████▍     | 127/285 [02:54<03:15,  1.24s/it]Loading train:  45%|████▍     | 128/285 [02:55<03:19,  1.27s/it]Loading train:  45%|████▌     | 129/285 [02:56<03:17,  1.27s/it]Loading train:  46%|████▌     | 130/285 [02:58<03:17,  1.28s/it]Loading train:  46%|████▌     | 131/285 [02:59<03:05,  1.21s/it]Loading train:  46%|████▋     | 132/285 [03:00<03:08,  1.23s/it]Loading train:  47%|████▋     | 133/285 [03:02<03:24,  1.34s/it]Loading train:  47%|████▋     | 134/285 [03:03<03:20,  1.33s/it]Loading train:  47%|████▋     | 135/285 [03:04<03:10,  1.27s/it]Loading train:  48%|████▊     | 136/285 [03:05<03:01,  1.22s/it]Loading train:  48%|████▊     | 137/285 [03:07<03:07,  1.27s/it]Loading train:  48%|████▊     | 138/285 [03:08<02:53,  1.18s/it]Loading train:  49%|████▉     | 139/285 [03:09<02:54,  1.20s/it]Loading train:  49%|████▉     | 140/285 [03:10<03:05,  1.28s/it]Loading train:  49%|████▉     | 141/285 [03:11<02:58,  1.24s/it]Loading train:  50%|████▉     | 142/285 [03:13<03:00,  1.26s/it]Loading train:  50%|█████     | 143/285 [03:14<03:05,  1.30s/it]Loading train:  51%|█████     | 144/285 [03:16<03:09,  1.35s/it]Loading train:  51%|█████     | 145/285 [03:17<03:08,  1.35s/it]Loading train:  51%|█████     | 146/285 [03:19<03:15,  1.41s/it]Loading train:  52%|█████▏    | 147/285 [03:20<03:13,  1.40s/it]Loading train:  52%|█████▏    | 148/285 [03:21<03:08,  1.37s/it]Loading train:  52%|█████▏    | 149/285 [03:23<03:03,  1.35s/it]Loading train:  53%|█████▎    | 150/285 [03:24<02:58,  1.32s/it]Loading train:  53%|█████▎    | 151/285 [03:25<03:04,  1.38s/it]Loading train:  53%|█████▎    | 152/285 [03:26<02:45,  1.25s/it]Loading train:  54%|█████▎    | 153/285 [03:27<02:30,  1.14s/it]Loading train:  54%|█████▍    | 154/285 [03:28<02:34,  1.18s/it]Loading train:  54%|█████▍    | 155/285 [03:30<02:48,  1.30s/it]Loading train:  55%|█████▍    | 156/285 [03:32<03:03,  1.42s/it]Loading train:  55%|█████▌    | 157/285 [03:33<02:51,  1.34s/it]Loading train:  55%|█████▌    | 158/285 [03:34<02:49,  1.34s/it]Loading train:  56%|█████▌    | 159/285 [03:35<02:37,  1.25s/it]Loading train:  56%|█████▌    | 160/285 [03:36<02:36,  1.25s/it]Loading train:  56%|█████▋    | 161/285 [03:38<02:44,  1.33s/it]Loading train:  57%|█████▋    | 162/285 [03:39<02:45,  1.35s/it]Loading train:  57%|█████▋    | 163/285 [03:41<03:00,  1.48s/it]Loading train:  58%|█████▊    | 164/285 [03:42<02:48,  1.40s/it]Loading train:  58%|█████▊    | 165/285 [03:44<02:43,  1.36s/it]Loading train:  58%|█████▊    | 166/285 [03:45<02:48,  1.41s/it]Loading train:  59%|█████▊    | 167/285 [03:46<02:40,  1.36s/it]Loading train:  59%|█████▉    | 168/285 [03:48<02:34,  1.32s/it]Loading train:  59%|█████▉    | 169/285 [03:49<02:38,  1.36s/it]Loading train:  60%|█████▉    | 170/285 [03:51<02:40,  1.39s/it]Loading train:  60%|██████    | 171/285 [03:52<02:37,  1.38s/it]Loading train:  60%|██████    | 172/285 [03:53<02:28,  1.32s/it]Loading train:  61%|██████    | 173/285 [03:54<02:20,  1.25s/it]Loading train:  61%|██████    | 174/285 [03:55<02:07,  1.15s/it]Loading train:  61%|██████▏   | 175/285 [03:56<02:01,  1.11s/it]Loading train:  62%|██████▏   | 176/285 [03:57<02:00,  1.10s/it]Loading train:  62%|██████▏   | 177/285 [03:58<01:55,  1.07s/it]Loading train:  62%|██████▏   | 178/285 [03:59<01:49,  1.03s/it]Loading train:  63%|██████▎   | 179/285 [04:00<01:55,  1.09s/it]Loading train:  63%|██████▎   | 180/285 [04:02<02:14,  1.29s/it]Loading train:  64%|██████▎   | 181/285 [04:03<02:17,  1.32s/it]Loading train:  64%|██████▍   | 182/285 [04:05<02:16,  1.33s/it]Loading train:  64%|██████▍   | 183/285 [04:06<02:07,  1.25s/it]Loading train:  65%|██████▍   | 184/285 [04:07<02:03,  1.22s/it]Loading train:  65%|██████▍   | 185/285 [04:08<02:02,  1.22s/it]Loading train:  65%|██████▌   | 186/285 [04:10<02:09,  1.31s/it]Loading train:  66%|██████▌   | 187/285 [04:11<02:03,  1.26s/it]Loading train:  66%|██████▌   | 188/285 [04:13<02:13,  1.37s/it]Loading train:  66%|██████▋   | 189/285 [04:14<02:06,  1.32s/it]Loading train:  67%|██████▋   | 190/285 [04:15<02:04,  1.31s/it]Loading train:  67%|██████▋   | 191/285 [04:16<02:03,  1.32s/it]Loading train:  67%|██████▋   | 192/285 [04:18<02:04,  1.34s/it]Loading train:  68%|██████▊   | 193/285 [04:19<01:56,  1.27s/it]Loading train:  68%|██████▊   | 194/285 [04:20<01:54,  1.26s/it]Loading train:  68%|██████▊   | 195/285 [04:22<01:57,  1.30s/it]Loading train:  69%|██████▉   | 196/285 [04:23<01:58,  1.33s/it]Loading train:  69%|██████▉   | 197/285 [04:24<01:53,  1.29s/it]Loading train:  69%|██████▉   | 198/285 [04:25<01:52,  1.29s/it]Loading train:  70%|██████▉   | 199/285 [04:26<01:42,  1.20s/it]Loading train:  70%|███████   | 200/285 [04:28<01:51,  1.31s/it]Loading train:  71%|███████   | 201/285 [04:29<01:51,  1.32s/it]Loading train:  71%|███████   | 202/285 [04:31<01:52,  1.36s/it]Loading train:  71%|███████   | 203/285 [04:32<01:51,  1.35s/it]Loading train:  72%|███████▏  | 204/285 [04:33<01:45,  1.31s/it]Loading train:  72%|███████▏  | 205/285 [04:35<01:44,  1.30s/it]Loading train:  72%|███████▏  | 206/285 [04:36<01:34,  1.19s/it]Loading train:  73%|███████▎  | 207/285 [04:37<01:36,  1.23s/it]Loading train:  73%|███████▎  | 208/285 [04:38<01:40,  1.31s/it]Loading train:  73%|███████▎  | 209/285 [04:40<01:50,  1.46s/it]Loading train:  74%|███████▎  | 210/285 [04:42<01:47,  1.43s/it]Loading train:  74%|███████▍  | 211/285 [04:43<01:45,  1.42s/it]Loading train:  74%|███████▍  | 212/285 [04:44<01:44,  1.44s/it]Loading train:  75%|███████▍  | 213/285 [04:46<01:43,  1.43s/it]Loading train:  75%|███████▌  | 214/285 [04:47<01:33,  1.31s/it]Loading train:  75%|███████▌  | 215/285 [04:48<01:34,  1.35s/it]Loading train:  76%|███████▌  | 216/285 [04:49<01:26,  1.26s/it]Loading train:  76%|███████▌  | 217/285 [04:51<01:28,  1.30s/it]Loading train:  76%|███████▋  | 218/285 [04:52<01:23,  1.25s/it]Loading train:  77%|███████▋  | 219/285 [04:53<01:26,  1.30s/it]Loading train:  77%|███████▋  | 220/285 [04:55<01:23,  1.29s/it]Loading train:  78%|███████▊  | 221/285 [04:55<01:13,  1.15s/it]Loading train:  78%|███████▊  | 222/285 [04:57<01:14,  1.19s/it]Loading train:  78%|███████▊  | 223/285 [04:58<01:12,  1.18s/it]Loading train:  79%|███████▊  | 224/285 [05:00<01:26,  1.42s/it]Loading train:  79%|███████▉  | 225/285 [05:01<01:21,  1.36s/it]Loading train:  79%|███████▉  | 226/285 [05:02<01:19,  1.35s/it]Loading train:  80%|███████▉  | 227/285 [05:04<01:15,  1.30s/it]Loading train:  80%|████████  | 228/285 [05:05<01:16,  1.33s/it]Loading train:  80%|████████  | 229/285 [05:06<01:10,  1.26s/it]Loading train:  81%|████████  | 230/285 [05:08<01:17,  1.42s/it]Loading train:  81%|████████  | 231/285 [05:09<01:14,  1.38s/it]Loading train:  81%|████████▏ | 232/285 [05:10<01:10,  1.32s/it]Loading train:  82%|████████▏ | 233/285 [05:11<01:02,  1.21s/it]Loading train:  82%|████████▏ | 234/285 [05:12<01:00,  1.18s/it]Loading train:  82%|████████▏ | 235/285 [05:13<00:56,  1.12s/it]Loading train:  83%|████████▎ | 236/285 [05:15<00:57,  1.17s/it]Loading train:  83%|████████▎ | 237/285 [05:16<01:01,  1.29s/it]Loading train:  84%|████████▎ | 238/285 [05:18<01:04,  1.38s/it]Loading train:  84%|████████▍ | 239/285 [05:19<01:01,  1.33s/it]Loading train:  84%|████████▍ | 240/285 [05:20<01:02,  1.39s/it]Loading train:  85%|████████▍ | 241/285 [05:22<01:02,  1.43s/it]Loading train:  85%|████████▍ | 242/285 [05:23<00:59,  1.37s/it]Loading train:  85%|████████▌ | 243/285 [05:25<01:00,  1.44s/it]Loading train:  86%|████████▌ | 244/285 [05:26<00:57,  1.41s/it]Loading train:  86%|████████▌ | 245/285 [05:27<00:48,  1.22s/it]Loading train:  86%|████████▋ | 246/285 [05:28<00:49,  1.27s/it]Loading train:  87%|████████▋ | 247/285 [05:30<00:56,  1.49s/it]Loading train:  87%|████████▋ | 248/285 [05:32<00:53,  1.46s/it]Loading train:  87%|████████▋ | 249/285 [05:33<00:50,  1.42s/it]Loading train:  88%|████████▊ | 250/285 [05:35<00:50,  1.44s/it]Loading train:  88%|████████▊ | 251/285 [05:36<00:46,  1.37s/it]Loading train:  88%|████████▊ | 252/285 [05:37<00:42,  1.28s/it]Loading train:  89%|████████▉ | 253/285 [05:39<00:44,  1.40s/it]Loading train:  89%|████████▉ | 254/285 [05:40<00:46,  1.52s/it]Loading train:  89%|████████▉ | 255/285 [05:42<00:45,  1.50s/it]Loading train:  90%|████████▉ | 256/285 [05:43<00:40,  1.40s/it]Loading train:  90%|█████████ | 257/285 [05:44<00:36,  1.30s/it]Loading train:  91%|█████████ | 258/285 [05:46<00:37,  1.41s/it]Loading train:  91%|█████████ | 259/285 [05:47<00:35,  1.35s/it]Loading train:  91%|█████████ | 260/285 [05:48<00:29,  1.19s/it]Loading train:  92%|█████████▏| 261/285 [05:49<00:27,  1.14s/it]Loading train:  92%|█████████▏| 262/285 [05:50<00:30,  1.33s/it]Loading train:  92%|█████████▏| 263/285 [05:52<00:29,  1.32s/it]Loading train:  93%|█████████▎| 264/285 [05:53<00:28,  1.36s/it]Loading train:  93%|█████████▎| 265/285 [05:55<00:29,  1.47s/it]Loading train:  93%|█████████▎| 266/285 [05:57<00:28,  1.50s/it]Loading train:  94%|█████████▎| 267/285 [05:58<00:26,  1.45s/it]Loading train:  94%|█████████▍| 268/285 [05:59<00:24,  1.42s/it]Loading train:  94%|█████████▍| 269/285 [06:01<00:22,  1.39s/it]Loading train:  95%|█████████▍| 270/285 [06:02<00:21,  1.42s/it]Loading train:  95%|█████████▌| 271/285 [06:04<00:20,  1.43s/it]Loading train:  95%|█████████▌| 272/285 [06:05<00:19,  1.49s/it]Loading train:  96%|█████████▌| 273/285 [06:06<00:16,  1.34s/it]Loading train:  96%|█████████▌| 274/285 [06:07<00:14,  1.29s/it]Loading train:  96%|█████████▋| 275/285 [06:09<00:12,  1.28s/it]Loading train:  97%|█████████▋| 276/285 [06:10<00:12,  1.39s/it]Loading train:  97%|█████████▋| 277/285 [06:11<00:10,  1.36s/it]Loading train:  98%|█████████▊| 278/285 [06:13<00:09,  1.35s/it]Loading train:  98%|█████████▊| 279/285 [06:14<00:08,  1.40s/it]Loading train:  98%|█████████▊| 280/285 [06:16<00:06,  1.34s/it]Loading train:  99%|█████████▊| 281/285 [06:17<00:05,  1.42s/it]Loading train:  99%|█████████▉| 282/285 [06:18<00:03,  1.31s/it]Loading train:  99%|█████████▉| 283/285 [06:19<00:02,  1.29s/it]Loading train: 100%|█████████▉| 284/285 [06:21<00:01,  1.38s/it]Loading train: 100%|██████████| 285/285 [06:22<00:00,  1.34s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:04, 59.24it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:04, 57.42it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:04, 58.86it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:03, 69.00it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 64.61it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:03, 62.66it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:03, 62.61it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:03, 62.58it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:03, 62.56it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:03, 62.54it/s]concatenating: train:  28%|██▊       | 80/285 [00:01<00:03, 62.53it/s]concatenating: train:  31%|███       | 87/285 [00:01<00:03, 62.52it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:02, 71.20it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:02, 81.77it/s]concatenating: train:  43%|████▎     | 122/285 [00:01<00:01, 86.07it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:01, 89.84it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 81.75it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:01, 85.59it/s]concatenating: train:  58%|█████▊    | 164/285 [00:02<00:01, 88.52it/s]concatenating: train:  62%|██████▏   | 177/285 [00:02<00:01, 97.02it/s]concatenating: train:  67%|██████▋   | 190/285 [00:02<00:00, 104.00it/s]concatenating: train:  71%|███████   | 203/285 [00:02<00:00, 106.29it/s]concatenating: train:  75%|███████▌  | 214/285 [00:02<00:00, 96.16it/s] concatenating: train:  79%|███████▉  | 226/285 [00:02<00:00, 101.41it/s]concatenating: train:  83%|████████▎ | 237/285 [00:02<00:00, 101.31it/s]concatenating: train:  87%|████████▋ | 248/285 [00:02<00:00, 100.34it/s]concatenating: train:  91%|█████████ | 259/285 [00:03<00:00, 85.00it/s] concatenating: train:  94%|█████████▍| 269/285 [00:03<00:00, 77.43it/s]concatenating: train:  99%|█████████▊| 281/285 [00:03<00:00, 83.75it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 82.72it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.95s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.85s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.71s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 137.69it/s]2019-07-11 00:25:29.928392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:25:29.928495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:25:29.928510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:25:29.928519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:25:29.928970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.07it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.89it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.17it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.66it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.69it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.08it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.04it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.92it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.12it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.06it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.56it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  7.63it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.94it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.78it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.83it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.37it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.17it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.10it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 229,653
Trainable params: 54,913
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2.8102 - acc: 0.5405 - mDice: 0.0973 - val_loss: 1.7310 - val_acc: 0.8955 - val_mDice: 0.2473

Epoch 00001: val_mDice improved from -inf to 0.24728, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.1080 - acc: 0.8846 - mDice: 0.3213 - val_loss: 1.3983 - val_acc: 0.9076 - val_mDice: 0.3244

Epoch 00002: val_mDice improved from 0.24728 to 0.32437, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.8502 - acc: 0.8937 - mDice: 0.4131 - val_loss: 1.1897 - val_acc: 0.9089 - val_mDice: 0.3841

Epoch 00003: val_mDice improved from 0.32437 to 0.38412, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.7469 - acc: 0.9000 - mDice: 0.4595 - val_loss: 1.0135 - val_acc: 0.9222 - val_mDice: 0.4476

Epoch 00004: val_mDice improved from 0.38412 to 0.44762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.6777 - acc: 0.9066 - mDice: 0.4938 - val_loss: 0.9742 - val_acc: 0.9187 - val_mDice: 0.4607

Epoch 00005: val_mDice improved from 0.44762 to 0.46073, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.6232 - acc: 0.9126 - mDice: 0.5216 - val_loss: 0.9153 - val_acc: 0.9195 - val_mDice: 0.4905

Epoch 00006: val_mDice improved from 0.46073 to 0.49054, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5836 - acc: 0.9169 - mDice: 0.5431 - val_loss: 0.8818 - val_acc: 0.9211 - val_mDice: 0.4964

Epoch 00007: val_mDice improved from 0.49054 to 0.49642, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.5504 - acc: 0.9205 - mDice: 0.5612 - val_loss: 0.8460 - val_acc: 0.9212 - val_mDice: 0.5132

Epoch 00008: val_mDice improved from 0.49642 to 0.51324, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.5204 - acc: 0.9238 - mDice: 0.5783 - val_loss: 0.8435 - val_acc: 0.9194 - val_mDice: 0.5120

Epoch 00009: val_mDice did not improve from 0.51324
Epoch 10/300
 - 10s - loss: 0.5019 - acc: 0.9260 - mDice: 0.5893 - val_loss: 0.8291 - val_acc: 0.9269 - val_mDice: 0.5214

Epoch 00010: val_mDice improved from 0.51324 to 0.52142, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.4876 - acc: 0.9275 - mDice: 0.5980 - val_loss: 0.8395 - val_acc: 0.9201 - val_mDice: 0.5205

Epoch 00011: val_mDice did not improve from 0.52142
Epoch 12/300
 - 10s - loss: 0.4712 - acc: 0.9291 - mDice: 0.6081 - val_loss: 0.7926 - val_acc: 0.9272 - val_mDice: 0.5381

Epoch 00012: val_mDice improved from 0.52142 to 0.53809, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 10s - loss: 0.4604 - acc: 0.9303 - mDice: 0.6149 - val_loss: 0.8096 - val_acc: 0.9223 - val_mDice: 0.5271

Epoch 00013: val_mDice did not improve from 0.53809
Epoch 14/300
 - 10s - loss: 0.4516 - acc: 0.9311 - mDice: 0.6205 - val_loss: 0.7957 - val_acc: 0.9236 - val_mDice: 0.5376

Epoch 00014: val_mDice did not improve from 0.53809
Epoch 15/300
 - 10s - loss: 0.4405 - acc: 0.9320 - mDice: 0.6277 - val_loss: 0.7685 - val_acc: 0.9322 - val_mDice: 0.5554

Epoch 00015: val_mDice improved from 0.53809 to 0.55535, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.4324 - acc: 0.9328 - mDice: 0.6328 - val_loss: 0.8373 - val_acc: 0.9308 - val_mDice: 0.5354

Epoch 00016: val_mDice did not improve from 0.55535
Epoch 17/300
 - 10s - loss: 0.4239 - acc: 0.9338 - mDice: 0.6385 - val_loss: 0.8054 - val_acc: 0.9318 - val_mDice: 0.5527

Epoch 00017: val_mDice did not improve from 0.55535
Epoch 18/300
 - 10s - loss: 0.4182 - acc: 0.9342 - mDice: 0.6424 - val_loss: 0.7866 - val_acc: 0.9207 - val_mDice: 0.5326

Epoch 00018: val_mDice did not improve from 0.55535
Epoch 19/300
 - 10s - loss: 0.4118 - acc: 0.9349 - mDice: 0.6466 - val_loss: 0.7686 - val_acc: 0.9322 - val_mDice: 0.5545

Epoch 00019: val_mDice did not improve from 0.55535
Epoch 20/300
 - 10s - loss: 0.4068 - acc: 0.9353 - mDice: 0.6501 - val_loss: 0.7698 - val_acc: 0.9341 - val_mDice: 0.5597

Epoch 00020: val_mDice improved from 0.55535 to 0.55974, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 9s - loss: 0.3996 - acc: 0.9358 - mDice: 0.6548 - val_loss: 0.8151 - val_acc: 0.9261 - val_mDice: 0.5439

Epoch 00021: val_mDice did not improve from 0.55974
Epoch 22/300
 - 10s - loss: 0.3956 - acc: 0.9363 - mDice: 0.6575 - val_loss: 0.7860 - val_acc: 0.9264 - val_mDice: 0.5443

Epoch 00022: val_mDice did not improve from 0.55974
Epoch 23/300
 - 10s - loss: 0.3923 - acc: 0.9367 - mDice: 0.6598 - val_loss: 0.7950 - val_acc: 0.9189 - val_mDice: 0.5324

Epoch 00023: val_mDice did not improve from 0.55974
Epoch 24/300
 - 9s - loss: 0.3845 - acc: 0.9373 - mDice: 0.6653 - val_loss: 0.8032 - val_acc: 0.9286 - val_mDice: 0.5469

Epoch 00024: val_mDice did not improve from 0.55974
Epoch 25/300
 - 10s - loss: 0.3818 - acc: 0.9374 - mDice: 0.6670 - val_loss: 0.7370 - val_acc: 0.9348 - val_mDice: 0.5656

Epoch 00025: val_mDice improved from 0.55974 to 0.56559, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 10s - loss: 0.3798 - acc: 0.9375 - mDice: 0.6684 - val_loss: 0.8089 - val_acc: 0.9355 - val_mDice: 0.5567

Epoch 00026: val_mDice did not improve from 0.56559
Epoch 27/300
 - 10s - loss: 0.3745 - acc: 0.9382 - mDice: 0.6721 - val_loss: 0.7630 - val_acc: 0.9307 - val_mDice: 0.5545

Epoch 00027: val_mDice did not improve from 0.56559
Epoch 28/300
 - 10s - loss: 0.3730 - acc: 0.9384 - mDice: 0.6731 - val_loss: 0.7824 - val_acc: 0.9308 - val_mDice: 0.5502

Epoch 00028: val_mDice did not improve from 0.56559
Epoch 29/300
 - 9s - loss: 0.3672 - acc: 0.9389 - mDice: 0.6773 - val_loss: 0.7558 - val_acc: 0.9360 - val_mDice: 0.5653

Epoch 00029: val_mDice did not improve from 0.56559
Epoch 30/300
 - 10s - loss: 0.3662 - acc: 0.9388 - mDice: 0.6779 - val_loss: 0.8078 - val_acc: 0.9282 - val_mDice: 0.5431

Epoch 00030: val_mDice did not improve from 0.56559
Epoch 31/300
 - 10s - loss: 0.3616 - acc: 0.9393 - mDice: 0.6812 - val_loss: 0.7407 - val_acc: 0.9369 - val_mDice: 0.5520

Epoch 00031: val_mDice did not improve from 0.56559
Epoch 32/300
 - 10s - loss: 0.3607 - acc: 0.9393 - mDice: 0.6818 - val_loss: 0.7302 - val_acc: 0.9352 - val_mDice: 0.5608

Epoch 00032: val_mDice did not improve from 0.56559
Epoch 33/300
 - 10s - loss: 0.3594 - acc: 0.9395 - mDice: 0.6828 - val_loss: 0.7762 - val_acc: 0.9327 - val_mDice: 0.5546

Epoch 00033: val_mDice did not improve from 0.56559
Epoch 34/300
 - 9s - loss: 0.3557 - acc: 0.9398 - mDice: 0.6855 - val_loss: 0.7835 - val_acc: 0.9296 - val_mDice: 0.5514

Epoch 00034: val_mDice did not improve from 0.56559
Epoch 35/300
 - 10s - loss: 0.3532 - acc: 0.9400 - mDice: 0.6873 - val_loss: 0.7246 - val_acc: 0.9367 - val_mDice: 0.5658

Epoch 00035: val_mDice improved from 0.56559 to 0.56584, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 10s - loss: 0.3514 - acc: 0.9401 - mDice: 0.6886 - val_loss: 0.8122 - val_acc: 0.9374 - val_mDice: 0.5434

Epoch 00036: val_mDice did not improve from 0.56584
Epoch 37/300
 - 10s - loss: 0.3477 - acc: 0.9405 - mDice: 0.6912 - val_loss: 0.7813 - val_acc: 0.9371 - val_mDice: 0.5485

Epoch 00037: val_mDice did not improve from 0.56584
Epoch 38/300
 - 10s - loss: 0.3468 - acc: 0.9405 - mDice: 0.6918 - val_loss: 0.7058 - val_acc: 0.9329 - val_mDice: 0.5616

Epoch 00038: val_mDice did not improve from 0.56584
Epoch 39/300
 - 10s - loss: 0.3444 - acc: 0.9406 - mDice: 0.6935 - val_loss: 0.7684 - val_acc: 0.9310 - val_mDice: 0.5466

Epoch 00039: val_mDice did not improve from 0.56584
Epoch 40/300
 - 10s - loss: 0.3437 - acc: 0.9408 - mDice: 0.6941 - val_loss: 0.7430 - val_acc: 0.9307 - val_mDice: 0.5586

Epoch 00040: val_mDice did not improve from 0.56584
Epoch 41/300
 - 10s - loss: 0.3412 - acc: 0.9410 - mDice: 0.6959 - val_loss: 0.7429 - val_acc: 0.9330 - val_mDice: 0.5595

Epoch 00041: val_mDice did not improve from 0.56584
Epoch 42/300
 - 9s - loss: 0.3392 - acc: 0.9411 - mDice: 0.6973 - val_loss: 0.7414 - val_acc: 0.9324 - val_mDice: 0.5518

Epoch 00042: val_mDice did not improve from 0.56584
Epoch 43/300
 - 10s - loss: 0.3379 - acc: 0.9413 - mDice: 0.6983 - val_loss: 0.7744 - val_acc: 0.9295 - val_mDice: 0.5440

Epoch 00043: val_mDice did not improve from 0.56584
Epoch 44/300
 - 10s - loss: 0.3343 - acc: 0.9416 - mDice: 0.7011 - val_loss: 0.8004 - val_acc: 0.9266 - val_mDice: 0.5353

Epoch 00044: val_mDice did not improve from 0.56584
Epoch 45/300
 - 10s - loss: 0.3350 - acc: 0.9416 - mDice: 0.7005 - val_loss: 0.7867 - val_acc: 0.9255 - val_mDice: 0.5369

Epoch 00045: val_mDice did not improve from 0.56584
Epoch 46/300
 - 10s - loss: 0.3317 - acc: 0.9419 - mDice: 0.7029 - val_loss: 0.7475 - val_acc: 0.9317 - val_mDice: 0.5503

Epoch 00046: val_mDice did not improve from 0.56584
Epoch 47/300
 - 10s - loss: 0.3288 - acc: 0.9419 - mDice: 0.7050 - val_loss: 0.7127 - val_acc: 0.9339 - val_mDice: 0.5604

Epoch 00047: val_mDice did not improve from 0.56584
Epoch 48/300
 - 10s - loss: 0.3284 - acc: 0.9420 - mDice: 0.7054 - val_loss: 0.7017 - val_acc: 0.9364 - val_mDice: 0.5649

Epoch 00048: val_mDice did not improve from 0.56584
Epoch 49/300
 - 10s - loss: 0.3275 - acc: 0.9423 - mDice: 0.7061 - val_loss: 0.7096 - val_acc: 0.9365 - val_mDice: 0.5585

Epoch 00049: val_mDice did not improve from 0.56584
Epoch 50/300
 - 10s - loss: 0.3267 - acc: 0.9423 - mDice: 0.7066 - val_loss: 0.7151 - val_acc: 0.9333 - val_mDice: 0.5581

Epoch 00050: val_mDice did not improve from 0.56584
Epoch 51/300
 - 10s - loss: 0.3238 - acc: 0.9424 - mDice: 0.7087 - val_loss: 0.7146 - val_acc: 0.9375 - val_mDice: 0.5522

Epoch 00051: val_mDice did not improve from 0.56584
Epoch 52/300
 - 9s - loss: 0.3232 - acc: 0.9425 - mDice: 0.7092 - val_loss: 0.7468 - val_acc: 0.9283 - val_mDice: 0.5340

Epoch 00052: val_mDice did not improve from 0.56584
Epoch 53/300
 - 9s - loss: 0.3237 - acc: 0.9425 - mDice: 0.7088 - val_loss: 0.7274 - val_acc: 0.9368 - val_mDice: 0.5531

Epoch 00053: val_mDice did not improve from 0.56584
Epoch 54/300
 - 10s - loss: 0.3204 - acc: 0.9428 - mDice: 0.7111 - val_loss: 0.7205 - val_acc: 0.9349 - val_mDice: 0.5458

Epoch 00054: val_mDice did not improve from 0.56584
Epoch 55/300
 - 10s - loss: 0.3193 - acc: 0.9429 - mDice: 0.7120 - val_loss: 0.7078 - val_acc: 0.9383 - val_mDice: 0.5485

Epoch 00055: val_mDice did not improve from 0.56584
Epoch 56/300
 - 10s - loss: 0.3199 - acc: 0.9427 - mDice: 0.7116 - val_loss: 0.6852 - val_acc: 0.9355 - val_mDice: 0.5604

Epoch 00056: val_mDice did not improve from 0.56584
Epoch 57/300
 - 10s - loss: 0.3190 - acc: 0.9428 - mDice: 0.7124 - val_loss: 0.7167 - val_acc: 0.9251 - val_mDice: 0.5351

Epoch 00057: val_mDice did not improve from 0.56584
Epoch 58/300
 - 10s - loss: 0.3171 - acc: 0.9430 - mDice: 0.7138 - val_loss: 0.7138 - val_acc: 0.9259 - val_mDice: 0.5418

Epoch 00058: val_mDice did not improve from 0.56584
Epoch 59/300
 - 10s - loss: 0.3149 - acc: 0.9432 - mDice: 0.7154 - val_loss: 0.6772 - val_acc: 0.9350 - val_mDice: 0.5643

Epoch 00059: val_mDice did not improve from 0.56584
Epoch 60/300
 - 10s - loss: 0.3160 - acc: 0.9431 - mDice: 0.7146 - val_loss: 0.6775 - val_acc: 0.9360 - val_mDice: 0.5604

Epoch 00060: val_mDice did not improve from 0.56584
Epoch 61/300
 - 10s - loss: 0.3121 - acc: 0.9434 - mDice: 0.7174 - val_loss: 0.6859 - val_acc: 0.9363 - val_mDice: 0.5499

Epoch 00061: val_mDice did not improve from 0.56584
Epoch 62/300
 - 10s - loss: 0.3120 - acc: 0.9436 - mDice: 0.7175 - val_loss: 0.7062 - val_acc: 0.9297 - val_mDice: 0.5507

Epoch 00062: val_mDice did not improve from 0.56584
Epoch 63/300
 - 10s - loss: 0.3116 - acc: 0.9435 - mDice: 0.7179 - val_loss: 0.6848 - val_acc: 0.9364 - val_mDice: 0.5534

Epoch 00063: val_mDice did not improve from 0.56584
Epoch 64/300
 - 10s - loss: 0.3088 - acc: 0.9436 - mDice: 0.7199 - val_loss: 0.6761 - val_acc: 0.9302 - val_mDice: 0.5558

Epoch 00064: val_mDice did not improve from 0.56584
Epoch 65/300
 - 10s - loss: 0.3106 - acc: 0.9437 - mDice: 0.7186 - val_loss: 0.6970 - val_acc: 0.9330 - val_mDice: 0.5511

Epoch 00065: val_mDice did not improve from 0.56584
Epoch 66/300
 - 10s - loss: 0.3086 - acc: 0.9437 - mDice: 0.7200 - val_loss: 0.6760 - val_acc: 0.9339 - val_mDice: 0.5571

Epoch 00066: val_mDice did not improve from 0.56584
Epoch 67/300
 - 10s - loss: 0.3081 - acc: 0.9439 - mDice: 0.7205 - val_loss: 0.6742 - val_acc: 0.9341 - val_mDice: 0.5594

Epoch 00067: val_mDice did not improve from 0.56584
Epoch 68/300
 - 9s - loss: 0.3074 - acc: 0.9439 - mDice: 0.7209 - val_loss: 0.6921 - val_acc: 0.9321 - val_mDice: 0.5483

Epoch 00068: val_mDice did not improve from 0.56584
Epoch 69/300
 - 10s - loss: 0.3079 - acc: 0.9439 - mDice: 0.7207 - val_loss: 0.6712 - val_acc: 0.9379 - val_mDice: 0.5569

Epoch 00069: val_mDice did not improve from 0.56584
Epoch 70/300
 - 10s - loss: 0.3059 - acc: 0.9440 - mDice: 0.7221 - val_loss: 0.6773 - val_acc: 0.9388 - val_mDice: 0.5550

Epoch 00070: val_mDice did not improve from 0.56584
Epoch 71/300
 - 10s - loss: 0.3045 - acc: 0.9443 - mDice: 0.7232 - val_loss: 0.6677 - val_acc: 0.9375 - val_mDice: 0.5618

Epoch 00071: val_mDice did not improve from 0.56584
Epoch 72/300
 - 10s - loss: 0.3043 - acc: 0.9441 - mDice: 0.7232 - val_loss: 0.6806 - val_acc: 0.9341 - val_mDice: 0.5545

Epoch 00072: val_mDice did not improve from 0.56584
Epoch 73/300
 - 10s - loss: 0.3033 - acc: 0.9443 - mDice: 0.7241 - val_loss: 0.7460 - val_acc: 0.9274 - val_mDice: 0.5286

Epoch 00073: val_mDice did not improve from 0.56584
Epoch 74/300
 - 10s - loss: 0.3016 - acc: 0.9444 - mDice: 0.7254 - val_loss: 0.6999 - val_acc: 0.9329 - val_mDice: 0.5435

Epoch 00074: val_mDice did not improve from 0.56584
Epoch 75/300
 - 10s - loss: 0.3005 - acc: 0.9443 - mDice: 0.7262 - val_loss: 0.6753 - val_acc: 0.9341 - val_mDice: 0.5556

Epoch 00075: val_mDice did not improve from 0.56584
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [1.7309655868090117, 1.398250373510214, 1.1897073777822347, 1.0134632931305811, 0.9741591834104978, 0.9152510945613568, 0.8818032787396357, 0.8459822283341334, 0.8435156964338743, 0.8291318416595459, 0.8395216396221747, 0.7926176832272456, 0.8096471703969516, 0.7957055339446435, 0.7684637583219088, 0.8373267283806434, 0.8053657825176532, 0.786559134721756, 0.7686428863268632, 0.7698317032593948, 0.8150956493157607, 0.7860475549331079, 0.7950414235775287, 0.803180048098931, 0.7369757546828344, 0.8089335102301377, 0.7629725933074951, 0.7824302567885473, 0.7557832919634305, 0.8077539045077103, 0.7406795941866361, 0.7302237153053284, 0.7762011931492732, 0.7834632625946631, 0.7245910305243272, 0.8122422144963191, 0.7812795959986173, 0.7058459566189692, 0.7683969346376566, 0.7430117588776809, 0.7428705210869129, 0.7413535484900842, 0.7743861675262451, 0.800404443190648, 0.786744645008674, 0.7475192432220166, 0.7127497838093684, 0.7017490955499502, 0.7096403126533215, 0.715054438664363, 0.7146449089050293, 0.7467534863031827, 0.7274477848639855, 0.7205296112940862, 0.7078432303208572, 0.6851773330798516, 0.7167264566971705, 0.7138164501923782, 0.6772001293989328, 0.6775397750047537, 0.685870844584245, 0.7061972916126251, 0.684751726113833, 0.6760564698622777, 0.696950220144712, 0.6759951435602628, 0.6742374094632956, 0.6920529558108404, 0.6711939802536597, 0.6772867670426002, 0.6676767285053546, 0.6805661274836614, 0.7459609921161945, 0.6998807650346023, 0.6753453726951892], 'val_acc': [0.8954765911285694, 0.907565197119346, 0.9089358105109289, 0.9222471117973328, 0.9186644760461954, 0.9194896633808429, 0.921130705338258, 0.921211641568404, 0.9194387908165271, 0.9269161270214961, 0.9201229879489312, 0.927228161921868, 0.9222610271894015, 0.9236455445106213, 0.9321745290206029, 0.9308385642675253, 0.931844046482673, 0.9206707752667941, 0.9321745657003843, 0.9341161319842706, 0.9261025557151208, 0.9264191824656266, 0.9188678906514094, 0.928589573273292, 0.934751760501128, 0.9354567367296952, 0.9306721641467168, 0.9307923225256113, 0.9359606091792767, 0.9281573685315939, 0.9368574092021356, 0.9351840042150937, 0.9326552977928748, 0.9296251099843246, 0.9367141356834998, 0.9373543652204367, 0.9371232436253474, 0.9329280646947714, 0.9310050102380606, 0.930713775066229, 0.9330321068947132, 0.9323733219733605, 0.9294910155809842, 0.9265786638626685, 0.9255454952900226, 0.9317284684914809, 0.9338988363742828, 0.9363535367525541, 0.9365245997905731, 0.9332655255611126, 0.9374537834754357, 0.9283468654522529, 0.9367533945120298, 0.934895043189709, 0.9382720085290762, 0.9354983086769397, 0.9251202115645776, 0.9258714134876544, 0.9349990991445688, 0.935962940637882, 0.9363257976678702, 0.929699047253682, 0.9364182834441845, 0.9301844583107874, 0.93303438104116, 0.9338757624992957, 0.9341277067477887, 0.932139896429502, 0.937867535994603, 0.9387920773946322, 0.9375138489099649, 0.9340745027248676, 0.9273506953166082, 0.9329165105636303, 0.9341022830743057], 'val_mDice': [0.24727622247659242, 0.32436683028936386, 0.3841160054390247, 0.4476201958381213, 0.4607251275044221, 0.4905449306735626, 0.4964222793395703, 0.5132449269294739, 0.511993272946431, 0.5214220755375348, 0.5205007493495941, 0.5380893962887617, 0.5271420146410282, 0.5375987726908463, 0.5553522694569367, 0.5354383014715635, 0.5526734693692281, 0.5326371341943741, 0.5545068417604153, 0.5597425252199173, 0.543865000972381, 0.5443160786078527, 0.5323876480643566, 0.5469403948921424, 0.565591845374841, 0.556708523287223, 0.5545475414166083, 0.5501881482509466, 0.5652976465912966, 0.5431259211439353, 0.5519871012522624, 0.5608185764688712, 0.5545780257536814, 0.5513505672033017, 0.5658366364928392, 0.5433814938251789, 0.5485242335842206, 0.5616106797869389, 0.5465550743616544, 0.5585705718168845, 0.559495937365752, 0.551767521752761, 0.5439835259547601, 0.535337878534427, 0.5368950149187675, 0.5503251220171268, 0.5604082426199546, 0.5649442380437484, 0.5584738678657092, 0.5580796765593382, 0.552191074937582, 0.5340240695155584, 0.5531324153909316, 0.5457773904960889, 0.5484626155633193, 0.5603753213699048, 0.53508988653238, 0.5417501089664606, 0.5643071486399724, 0.5604245708538935, 0.5499184011266782, 0.5507421126732459, 0.5533637559184661, 0.5558065542807946, 0.5510684045461508, 0.5571159926744608, 0.5594427001017791, 0.5483209381882961, 0.5568949660429587, 0.5550017488690523, 0.5617884999284377, 0.5545491341214913, 0.5285733703237313, 0.5434727204533724, 0.555628700611683], 'loss': [2.8102232138301177, 1.1079932947467968, 0.850186365942316, 0.7469417992348844, 0.677712917168466, 0.6232442865289908, 0.5835791609059244, 0.55037472484561, 0.5203879505167761, 0.5019164997075939, 0.4876205051537865, 0.4711700006790358, 0.4603817597351797, 0.4516484465594003, 0.4404710448311559, 0.43240548518160704, 0.42385752431901963, 0.41818450071500984, 0.41182221674142944, 0.40676574011982713, 0.3996209226789855, 0.395637048944868, 0.39230165165596254, 0.38447081848647796, 0.3818244342323292, 0.37978569521605393, 0.3744625774002005, 0.37302196103082114, 0.36719243187894685, 0.36622416654559264, 0.36164107120291045, 0.3606982827846232, 0.3594446766066461, 0.35566094791461517, 0.3531512428443722, 0.35138190458327284, 0.3476997697379749, 0.34675311877324466, 0.34441203536125803, 0.34374037219250453, 0.34118796727110473, 0.3392346462815997, 0.3378724998695807, 0.33427440441810236, 0.33501937550052907, 0.3316984561320151, 0.3288160878623817, 0.3283921434910526, 0.3274662191936212, 0.32672051948110503, 0.32382990516200666, 0.32321002436532953, 0.3237054185691184, 0.3204330954177457, 0.3193100671931781, 0.3198655067961847, 0.31896716303230815, 0.3170544599256513, 0.3148539713648735, 0.31599170440931795, 0.3120518942072989, 0.31199342228439936, 0.3115625517659441, 0.3088369288809964, 0.3105518386821998, 0.3086379602789208, 0.3080664287850963, 0.3074072526272599, 0.3078823116562699, 0.30594215194732405, 0.304514654239781, 0.3043392798364751, 0.3033268777089267, 0.30163745276879356, 0.30047470757214334], 'acc': [0.5405155473727917, 0.8846464899427764, 0.8936936639776356, 0.8999559494893423, 0.9066205416549827, 0.9125587284691404, 0.9169327389827835, 0.9204827077019581, 0.9238277176841867, 0.9260307081311014, 0.9275157362522262, 0.9290688917787051, 0.9302688180482289, 0.9311194187774876, 0.9319558099089519, 0.9328451888934829, 0.9337514809584536, 0.9342404553879894, 0.9348896196503531, 0.9353313716665291, 0.9358244716247092, 0.9362640236286641, 0.9366879943364179, 0.937328495212359, 0.9374375492183197, 0.9374976056831235, 0.9381613398042429, 0.9383929944023, 0.9388765977073901, 0.9387687176210375, 0.9392501526539433, 0.9392968678149001, 0.9395289366385775, 0.9397809589347814, 0.9400320747599417, 0.9400859478928776, 0.9404685496129552, 0.9404671093002188, 0.9406341331906395, 0.9407558006344494, 0.9410452023924997, 0.9411024201854089, 0.9412871620910783, 0.9415945422492168, 0.9415552344454574, 0.9418576705843873, 0.9419371474990873, 0.9420428112634355, 0.9423072252240138, 0.9422599168366022, 0.9424228626435218, 0.9425211854661775, 0.9425443528785395, 0.9427764471536147, 0.9428929905879105, 0.9427168961381776, 0.9428315161504308, 0.9430214858556447, 0.9432162222228543, 0.943088858398929, 0.9433649371418579, 0.9435759711659154, 0.9435417850134306, 0.9436270898034693, 0.9436966791524996, 0.9437219803924547, 0.9438839479696813, 0.9438878310943765, 0.9439332088915765, 0.9439931784203426, 0.9442769919639692, 0.944120475119642, 0.9442760180274817, 0.9444178558853756, 0.9443122444145796], 'mDice': [0.09731607000034893, 0.32129806041563613, 0.41313439773631516, 0.45948703588292045, 0.4938342438229641, 0.5216479184145331, 0.5430981943190213, 0.5611918907285144, 0.5782854938588436, 0.589289266608204, 0.5980436255722307, 0.6081325956390516, 0.6148704856642385, 0.6204904796759888, 0.6276995180102387, 0.6328412140250195, 0.6384767858808159, 0.642381936556341, 0.6466332018007094, 0.6500826652756061, 0.6547699010065425, 0.6574833135064827, 0.6597696920388038, 0.6652510956041071, 0.6669950047773288, 0.6683500896056046, 0.672104593661508, 0.6731134499448543, 0.6773156279799881, 0.6779234179445137, 0.6811805757816171, 0.6818484112333132, 0.6828013039444422, 0.685476684827575, 0.6873179778152976, 0.6886290993174207, 0.691220309174084, 0.6917573665985485, 0.6935314258438057, 0.6940942661003423, 0.6958529217749144, 0.6973413481083918, 0.6982827885480953, 0.7010586998190682, 0.7004602432888636, 0.7028590154902891, 0.7049904472161888, 0.7054213125536629, 0.7060653272616647, 0.7066482439874933, 0.7086578237057216, 0.7092038823550537, 0.7087841116886214, 0.7111304949913739, 0.7120213162181102, 0.7116364274508266, 0.7124114784875127, 0.71382448582107, 0.7153560894337965, 0.7146319420665522, 0.7173900743708513, 0.7175286601283042, 0.7178584259780891, 0.7198593262309883, 0.7185866806127373, 0.7199984218244633, 0.7204779219299755, 0.7209389458214523, 0.7206759646866118, 0.7221184938384698, 0.7231872284598184, 0.723221628755856, 0.7241252882832653, 0.7253682086369455, 0.7262157344580642]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.77s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:26,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:43,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:41,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:15,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:16,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:33,  1.63s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:34,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:57,  1.73s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:43,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:06,  1.78s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:47,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:56,  1.76s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:03,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:02,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:39,  1.72s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:44,  1.74s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:23,  1.67s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:22,  1.67s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:41,  1.75s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:23,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:25,  1.70s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:22,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:37,  1.76s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:44,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:21,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:27,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:28,  1.75s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:38,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:39,  1.81s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:16,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:08,  1.70s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:16,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:24,  1.78s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:17,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:15,  1.76s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:57,  1.70s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:00,  1.71s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:48,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:43,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:40,  1.65s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:43,  1.68s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:52,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:32,  1.65s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:42,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:03,  1.80s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:02,  1.80s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:06,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:44,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:50,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:58,  1.81s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:40,  1.75s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:32,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:33,  1.73s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:44,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:52,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:29,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:23,  1.72s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:23,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:09,  1.67s/it]predicting train subjects:  23%|██▎       | 65/285 [01:51<06:21,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:22,  1.75s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:24,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:07,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:11,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:08,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:06,  1.71s/it]predicting train subjects:  25%|██▌       | 72/285 [02:03<05:55,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<05:55,  1.68s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:10<06:04,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:50,  1.69s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:47,  1.69s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:37,  1.66s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:29,  1.63s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:26,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:33,  1.67s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:38,  1.70s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:41,  1.72s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:25,  1.65s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:29,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:34,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:33,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:22,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:28,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:26,  1.73s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:27,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:25,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:32,  1.80s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:14,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:15,  1.73s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:01,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<04:58,  1.65s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<04:58,  1.66s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<04:50,  1.62s/it]predicting train subjects:  38%|███▊      | 107/285 [03:03<04:52,  1.64s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:45,  1.61s/it]predicting train subjects:  38%|███▊      | 109/285 [03:06<04:48,  1.64s/it]predicting train subjects:  39%|███▊      | 110/285 [03:08<04:54,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:09<04:46,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:11<04:43,  1.64s/it]predicting train subjects:  40%|███▉      | 113/285 [03:13<04:52,  1.70s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:54,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:16<04:53,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:18<04:47,  1.70s/it]predicting train subjects:  41%|████      | 117/285 [03:19<04:37,  1.65s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<04:31,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:23<04:34,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:32,  1.65s/it]predicting train subjects:  42%|████▏     | 121/285 [03:26<04:24,  1.62s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:29<04:12,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:32<04:08,  1.55s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<04:02,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<03:52,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<03:45,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:42<03:47,  1.48s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:40,  1.45s/it]predicting train subjects:  47%|████▋     | 134/285 [03:45<03:31,  1.40s/it]predicting train subjects:  47%|████▋     | 135/285 [03:46<03:29,  1.40s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:49<03:39,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:51<03:33,  1.46s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:38,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:54<03:37,  1.50s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [03:57<03:32,  1.49s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:00<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:37,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:03<03:33,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:06<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:09<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:12<03:17,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:13<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:15<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:16<03:06,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:18<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:19<03:00,  1.41s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:20<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:22<02:59,  1.43s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:23<02:56,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:25<03:02,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:26<02:57,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:28<03:01,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:29<02:54,  1.44s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:31<02:52,  1.44s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:32<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:34<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:35<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:37<02:49,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:38<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:40<02:47,  1.47s/it]predicting train subjects:  60%|██████    | 172/285 [04:41<02:45,  1.46s/it]predicting train subjects:  61%|██████    | 173/285 [04:42<02:40,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:44<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:45<02:38,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:47<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:48<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:49<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:51<02:27,  1.40s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:53<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:54<02:41,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:56<02:40,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:57<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:59<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:00<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:02<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:03<02:35,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:05<02:37,  1.62s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:07<02:32,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:08<02:25,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:10<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:11<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:12<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:14<02:13,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:15<02:06,  1.41s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:17<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:19<02:20,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:20<02:23,  1.65s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:22<02:14,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:23<02:08,  1.51s/it]predicting train subjects:  71%|███████   | 201/285 [05:25<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:27<02:10,  1.57s/it]predicting train subjects:  71%|███████   | 203/285 [05:28<02:07,  1.56s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:29<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:31<01:56,  1.46s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:32<01:52,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:34<02:02,  1.57s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:36<02:05,  1.62s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:38<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:39<01:56,  1.55s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:40<01:50,  1.50s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:42<01:52,  1.54s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:43<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:45<01:46,  1.50s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:46<01:49,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:48<01:41,  1.48s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:50<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:51<01:46,  1.59s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:53<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:54<01:42,  1.58s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:56<01:38,  1.54s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:57<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:59<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:00<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:01<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:03<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:05<01:35,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [06:07<01:37,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:09<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:10<01:25,  1.56s/it]predicting train subjects:  81%|████████  | 231/285 [06:11<01:22,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:13<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:14<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:16<01:21,  1.59s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:17<01:15,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:19<01:18,  1.60s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:21<01:17,  1.62s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:23<01:16,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:24<01:15,  1.65s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:26<01:09,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:27<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:28<01:03,  1.47s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:30<01:00,  1.43s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:31<01:01,  1.49s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:33<00:56,  1.41s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:34<00:58,  1.51s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:36<00:59,  1.55s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:38<00:58,  1.58s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:39<00:53,  1.49s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:40<00:50,  1.44s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:42<00:46,  1.38s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:43<00:44,  1.35s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:45<00:47,  1.48s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:46<00:47,  1.55s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:48<00:46,  1.56s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:49<00:42,  1.47s/it]predicting train subjects:  90%|█████████ | 257/285 [06:51<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [06:52<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [06:54<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [06:55<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:57<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:58<00:33,  1.47s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:00<00:31,  1.45s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:01<00:32,  1.55s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:03<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:04<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:06<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:07<00:26,  1.53s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:09<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:10<00:22,  1.47s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:12<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:13<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:15<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:16<00:15,  1.44s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:18<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:20<00:14,  1.60s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:21<00:12,  1.52s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:22<00:10,  1.51s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:24<00:09,  1.53s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:25<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:27<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:28<00:04,  1.40s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:30<00:02,  1.49s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:32<00:01,  1.56s/it]predicting train subjects: 100%|██████████| 285/285 [07:33<00:00,  1.62s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:17,  1.75s/it]Loading train:   1%|          | 2/285 [00:03<07:37,  1.62s/it]Loading train:   1%|          | 3/285 [00:04<07:20,  1.56s/it]Loading train:   1%|▏         | 4/285 [00:05<06:32,  1.40s/it]Loading train:   2%|▏         | 5/285 [00:07<06:40,  1.43s/it]Loading train:   2%|▏         | 6/285 [00:08<06:24,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:34,  1.42s/it]Loading train:   3%|▎         | 8/285 [00:10<06:09,  1.33s/it]Loading train:   3%|▎         | 9/285 [00:12<06:18,  1.37s/it]Loading train:   4%|▎         | 10/285 [00:13<05:48,  1.27s/it]Loading train:   4%|▍         | 11/285 [00:14<05:04,  1.11s/it]Loading train:   4%|▍         | 12/285 [00:15<04:50,  1.06s/it]Loading train:   5%|▍         | 13/285 [00:16<04:36,  1.02s/it]Loading train:   5%|▍         | 14/285 [00:17<04:48,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:51,  1.08s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.03s/it]Loading train:   6%|▌         | 17/285 [00:20<04:32,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:21<04:39,  1.05s/it]Loading train:   7%|▋         | 19/285 [00:22<04:40,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:23<04:44,  1.07s/it]Loading train:   7%|▋         | 21/285 [00:24<05:00,  1.14s/it]Loading train:   8%|▊         | 22/285 [00:25<04:54,  1.12s/it]Loading train:   8%|▊         | 23/285 [00:27<05:00,  1.15s/it]Loading train:   8%|▊         | 24/285 [00:27<04:38,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:28<04:32,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:30<04:54,  1.14s/it]Loading train:   9%|▉         | 27/285 [00:31<04:30,  1.05s/it]Loading train:  10%|▉         | 28/285 [00:32<04:27,  1.04s/it]Loading train:  10%|█         | 29/285 [00:33<04:39,  1.09s/it]Loading train:  11%|█         | 30/285 [00:34<04:40,  1.10s/it]Loading train:  11%|█         | 31/285 [00:35<04:45,  1.12s/it]Loading train:  11%|█         | 32/285 [00:36<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:34,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:35,  1.10s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:25,  1.06s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:08,  1.00it/s]Loading train:  13%|█▎        | 37/285 [00:41<04:21,  1.05s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:17,  1.04s/it]Loading train:  14%|█▎        | 39/285 [00:43<04:06,  1.00s/it]Loading train:  14%|█▍        | 40/285 [00:44<04:11,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:45<04:09,  1.02s/it]Loading train:  15%|█▍        | 42/285 [00:46<03:58,  1.02it/s]Loading train:  15%|█▌        | 43/285 [00:48<04:18,  1.07s/it]Loading train:  15%|█▌        | 44/285 [00:49<04:27,  1.11s/it]Loading train:  16%|█▌        | 45/285 [00:50<04:00,  1.00s/it]Loading train:  16%|█▌        | 46/285 [00:51<04:07,  1.04s/it]Loading train:  16%|█▋        | 47/285 [00:51<03:53,  1.02it/s]Loading train:  17%|█▋        | 48/285 [00:53<04:00,  1.01s/it]Loading train:  17%|█▋        | 49/285 [00:54<04:13,  1.07s/it]Loading train:  18%|█▊        | 50/285 [00:55<04:11,  1.07s/it]Loading train:  18%|█▊        | 51/285 [00:56<04:14,  1.09s/it]Loading train:  18%|█▊        | 52/285 [00:57<03:47,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:58<03:48,  1.01it/s]Loading train:  19%|█▉        | 54/285 [00:59<03:56,  1.02s/it]Loading train:  19%|█▉        | 55/285 [01:00<03:40,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:01<04:01,  1.06s/it]Loading train:  20%|██        | 57/285 [01:02<03:44,  1.02it/s]Loading train:  20%|██        | 58/285 [01:03<04:05,  1.08s/it]Loading train:  21%|██        | 59/285 [01:04<04:05,  1.09s/it]Loading train:  21%|██        | 60/285 [01:05<04:13,  1.13s/it]Loading train:  21%|██▏       | 61/285 [01:06<03:51,  1.04s/it]Loading train:  22%|██▏       | 62/285 [01:07<03:42,  1.00it/s]Loading train:  22%|██▏       | 63/285 [01:08<03:40,  1.01it/s]Loading train:  22%|██▏       | 64/285 [01:09<04:09,  1.13s/it]Loading train:  23%|██▎       | 65/285 [01:11<04:31,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:41,  1.28s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:18,  1.18s/it]Loading train:  24%|██▍       | 68/285 [01:14<04:01,  1.11s/it]Loading train:  24%|██▍       | 69/285 [01:15<04:05,  1.14s/it]Loading train:  25%|██▍       | 70/285 [01:16<03:51,  1.08s/it]Loading train:  25%|██▍       | 71/285 [01:17<03:51,  1.08s/it]Loading train:  25%|██▌       | 72/285 [01:18<03:34,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:19<03:37,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:20<03:32,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:22<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:23<03:35,  1.03s/it]Loading train:  27%|██▋       | 77/285 [01:23<03:22,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:24<03:07,  1.11it/s]Loading train:  28%|██▊       | 79/285 [01:25<03:08,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:26<03:08,  1.09it/s]Loading train:  28%|██▊       | 81/285 [01:27<02:56,  1.16it/s]Loading train:  29%|██▉       | 82/285 [01:28<02:54,  1.16it/s]Loading train:  29%|██▉       | 83/285 [01:29<03:01,  1.11it/s]Loading train:  29%|██▉       | 84/285 [01:29<03:03,  1.10it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:03,  1.09it/s]Loading train:  30%|███       | 86/285 [01:31<03:12,  1.03it/s]Loading train:  31%|███       | 87/285 [01:32<03:12,  1.03it/s]Loading train:  31%|███       | 88/285 [01:34<03:17,  1.00s/it]Loading train:  31%|███       | 89/285 [01:35<03:31,  1.08s/it]Loading train:  32%|███▏      | 90/285 [01:36<03:30,  1.08s/it]Loading train:  32%|███▏      | 91/285 [01:37<03:11,  1.01it/s]Loading train:  32%|███▏      | 92/285 [01:38<03:21,  1.05s/it]Loading train:  33%|███▎      | 93/285 [01:39<03:19,  1.04s/it]Loading train:  33%|███▎      | 94/285 [01:40<03:13,  1.01s/it]Loading train:  33%|███▎      | 95/285 [01:41<03:21,  1.06s/it]Loading train:  34%|███▎      | 96/285 [01:42<03:10,  1.01s/it]Loading train:  34%|███▍      | 97/285 [01:43<03:09,  1.01s/it]Loading train:  34%|███▍      | 98/285 [01:44<03:10,  1.02s/it]Loading train:  35%|███▍      | 99/285 [01:45<02:58,  1.04it/s]Loading train:  35%|███▌      | 100/285 [01:46<02:57,  1.04it/s]Loading train:  35%|███▌      | 101/285 [01:47<02:47,  1.10it/s]Loading train:  36%|███▌      | 102/285 [01:48<03:20,  1.10s/it]Loading train:  36%|███▌      | 103/285 [01:49<03:16,  1.08s/it]Loading train:  36%|███▋      | 104/285 [01:50<03:17,  1.09s/it]Loading train:  37%|███▋      | 105/285 [01:51<03:15,  1.09s/it]Loading train:  37%|███▋      | 106/285 [01:52<02:57,  1.01it/s]Loading train:  38%|███▊      | 107/285 [01:53<02:53,  1.03it/s]Loading train:  38%|███▊      | 108/285 [01:54<02:44,  1.08it/s]Loading train:  38%|███▊      | 109/285 [01:55<02:48,  1.05it/s]Loading train:  39%|███▊      | 110/285 [01:56<02:59,  1.02s/it]Loading train:  39%|███▉      | 111/285 [01:57<02:58,  1.03s/it]Loading train:  39%|███▉      | 112/285 [01:58<02:53,  1.00s/it]Loading train:  40%|███▉      | 113/285 [01:59<02:47,  1.03it/s]Loading train:  40%|████      | 114/285 [02:00<02:48,  1.02it/s]Loading train:  40%|████      | 115/285 [02:01<02:46,  1.02it/s]Loading train:  41%|████      | 116/285 [02:02<02:56,  1.05s/it]Loading train:  41%|████      | 117/285 [02:03<02:45,  1.01it/s]Loading train:  41%|████▏     | 118/285 [02:04<02:42,  1.03it/s]Loading train:  42%|████▏     | 119/285 [02:05<02:55,  1.06s/it]Loading train:  42%|████▏     | 120/285 [02:06<02:49,  1.03s/it]Loading train:  42%|████▏     | 121/285 [02:07<03:02,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:09<03:05,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:10<03:12,  1.19s/it]Loading train:  44%|████▎     | 124/285 [02:11<03:01,  1.12s/it]Loading train:  44%|████▍     | 125/285 [02:12<02:48,  1.05s/it]Loading train:  44%|████▍     | 126/285 [02:12<02:32,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:13<02:25,  1.08it/s]Loading train:  45%|████▍     | 128/285 [02:14<02:23,  1.09it/s]Loading train:  45%|████▌     | 129/285 [02:15<02:32,  1.03it/s]Loading train:  46%|████▌     | 130/285 [02:16<02:14,  1.15it/s]Loading train:  46%|████▌     | 131/285 [02:17<02:05,  1.23it/s]Loading train:  46%|████▋     | 132/285 [02:17<02:05,  1.22it/s]Loading train:  47%|████▋     | 133/285 [02:18<02:05,  1.21it/s]Loading train:  47%|████▋     | 134/285 [02:19<02:05,  1.21it/s]Loading train:  47%|████▋     | 135/285 [02:20<01:56,  1.29it/s]Loading train:  48%|████▊     | 136/285 [02:21<01:53,  1.31it/s]Loading train:  48%|████▊     | 137/285 [02:21<02:00,  1.23it/s]Loading train:  48%|████▊     | 138/285 [02:22<02:06,  1.17it/s]Loading train:  49%|████▉     | 139/285 [02:23<02:11,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:24<02:08,  1.13it/s]Loading train:  49%|████▉     | 141/285 [02:25<02:06,  1.14it/s]Loading train:  50%|████▉     | 142/285 [02:26<01:59,  1.20it/s]Loading train:  50%|█████     | 143/285 [02:27<01:51,  1.28it/s]Loading train:  51%|█████     | 144/285 [02:28<02:06,  1.11it/s]Loading train:  51%|█████     | 145/285 [02:28<02:01,  1.15it/s]Loading train:  51%|█████     | 146/285 [02:30<02:08,  1.08it/s]Loading train:  52%|█████▏    | 147/285 [02:30<02:03,  1.12it/s]Loading train:  52%|█████▏    | 148/285 [02:31<01:55,  1.19it/s]Loading train:  52%|█████▏    | 149/285 [02:32<01:50,  1.23it/s]Loading train:  53%|█████▎    | 150/285 [02:33<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:34<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:35<01:56,  1.14it/s]Loading train:  54%|█████▎    | 153/285 [02:35<01:55,  1.14it/s]Loading train:  54%|█████▍    | 154/285 [02:36<01:59,  1.09it/s]Loading train:  54%|█████▍    | 155/285 [02:37<01:54,  1.14it/s]Loading train:  55%|█████▍    | 156/285 [02:38<01:48,  1.19it/s]Loading train:  55%|█████▌    | 157/285 [02:39<01:42,  1.25it/s]Loading train:  55%|█████▌    | 158/285 [02:39<01:36,  1.31it/s]Loading train:  56%|█████▌    | 159/285 [02:40<01:35,  1.31it/s]Loading train:  56%|█████▌    | 160/285 [02:41<01:34,  1.33it/s]Loading train:  56%|█████▋    | 161/285 [02:42<01:35,  1.30it/s]Loading train:  57%|█████▋    | 162/285 [02:42<01:31,  1.35it/s]Loading train:  57%|█████▋    | 163/285 [02:43<01:32,  1.32it/s]Loading train:  58%|█████▊    | 164/285 [02:44<01:29,  1.35it/s]Loading train:  58%|█████▊    | 165/285 [02:45<01:33,  1.29it/s]Loading train:  58%|█████▊    | 166/285 [02:46<01:45,  1.13it/s]Loading train:  59%|█████▊    | 167/285 [02:47<01:40,  1.17it/s]Loading train:  59%|█████▉    | 168/285 [02:48<01:42,  1.14it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:40,  1.15it/s]Loading train:  60%|█████▉    | 170/285 [02:49<01:31,  1.26it/s]Loading train:  60%|██████    | 171/285 [02:50<01:30,  1.25it/s]Loading train:  60%|██████    | 172/285 [02:51<01:32,  1.22it/s]Loading train:  61%|██████    | 173/285 [02:51<01:28,  1.26it/s]Loading train:  61%|██████    | 174/285 [02:52<01:23,  1.33it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:33,  1.16it/s]Loading train:  62%|██████▏   | 177/285 [02:55<01:30,  1.19it/s]Loading train:  62%|██████▏   | 178/285 [02:56<01:28,  1.21it/s]Loading train:  63%|██████▎   | 179/285 [02:56<01:21,  1.31it/s]Loading train:  63%|██████▎   | 180/285 [02:57<01:30,  1.16it/s]Loading train:  64%|██████▎   | 181/285 [02:58<01:32,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [02:59<01:32,  1.11it/s]Loading train:  64%|██████▍   | 183/285 [03:00<01:34,  1.08it/s]Loading train:  65%|██████▍   | 184/285 [03:01<01:39,  1.01it/s]Loading train:  65%|██████▍   | 185/285 [03:02<01:38,  1.01it/s]Loading train:  65%|██████▌   | 186/285 [03:04<01:45,  1.07s/it]Loading train:  66%|██████▌   | 187/285 [03:04<01:39,  1.01s/it]Loading train:  66%|██████▌   | 188/285 [03:05<01:38,  1.02s/it]Loading train:  66%|██████▋   | 189/285 [03:06<01:29,  1.07it/s]Loading train:  67%|██████▋   | 190/285 [03:07<01:26,  1.10it/s]Loading train:  67%|██████▋   | 191/285 [03:08<01:34,  1.01s/it]Loading train:  67%|██████▋   | 192/285 [03:10<01:40,  1.08s/it]Loading train:  68%|██████▊   | 193/285 [03:11<01:37,  1.06s/it]Loading train:  68%|██████▊   | 194/285 [03:11<01:33,  1.03s/it]Loading train:  68%|██████▊   | 195/285 [03:12<01:30,  1.01s/it]Loading train:  69%|██████▉   | 196/285 [03:13<01:30,  1.01s/it]Loading train:  69%|██████▉   | 197/285 [03:15<01:32,  1.05s/it]Loading train:  69%|██████▉   | 198/285 [03:16<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [03:16<01:24,  1.02it/s]Loading train:  70%|███████   | 200/285 [03:17<01:24,  1.01it/s]Loading train:  71%|███████   | 201/285 [03:19<01:26,  1.03s/it]Loading train:  71%|███████   | 202/285 [03:20<01:24,  1.01s/it]Loading train:  71%|███████   | 203/285 [03:21<01:21,  1.01it/s]Loading train:  72%|███████▏  | 204/285 [03:21<01:13,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [03:22<01:18,  1.02it/s]Loading train:  72%|███████▏  | 206/285 [03:23<01:17,  1.02it/s]Loading train:  73%|███████▎  | 207/285 [03:24<01:16,  1.02it/s]Loading train:  73%|███████▎  | 208/285 [03:25<01:12,  1.06it/s]Loading train:  73%|███████▎  | 209/285 [03:26<01:11,  1.06it/s]Loading train:  74%|███████▎  | 210/285 [03:27<01:08,  1.10it/s]Loading train:  74%|███████▍  | 211/285 [03:28<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:29<01:09,  1.05it/s]Loading train:  75%|███████▍  | 213/285 [03:30<01:08,  1.04it/s]Loading train:  75%|███████▌  | 214/285 [03:31<01:10,  1.01it/s]Loading train:  75%|███████▌  | 215/285 [03:32<01:13,  1.05s/it]Loading train:  76%|███████▌  | 216/285 [03:33<01:07,  1.03it/s]Loading train:  76%|███████▌  | 217/285 [03:34<01:07,  1.00it/s]Loading train:  76%|███████▋  | 218/285 [03:35<01:07,  1.00s/it]Loading train:  77%|███████▋  | 219/285 [03:36<01:06,  1.00s/it]Loading train:  77%|███████▋  | 220/285 [03:37<01:02,  1.04it/s]Loading train:  78%|███████▊  | 221/285 [03:38<01:03,  1.01it/s]Loading train:  78%|███████▊  | 222/285 [03:39<01:01,  1.02it/s]Loading train:  78%|███████▊  | 223/285 [03:40<00:55,  1.12it/s]Loading train:  79%|███████▊  | 224/285 [03:41<00:54,  1.12it/s]Loading train:  79%|███████▉  | 225/285 [03:41<00:51,  1.16it/s]Loading train:  79%|███████▉  | 226/285 [03:42<00:54,  1.08it/s]Loading train:  80%|███████▉  | 227/285 [03:43<00:55,  1.04it/s]Loading train:  80%|████████  | 228/285 [03:45<00:59,  1.04s/it]Loading train:  80%|████████  | 229/285 [03:46<01:01,  1.09s/it]Loading train:  81%|████████  | 230/285 [03:47<00:55,  1.01s/it]Loading train:  81%|████████  | 231/285 [03:48<00:52,  1.04it/s]Loading train:  81%|████████▏ | 232/285 [03:49<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [03:49<00:49,  1.06it/s]Loading train:  82%|████████▏ | 234/285 [03:51<00:54,  1.07s/it]Loading train:  82%|████████▏ | 235/285 [03:52<00:48,  1.03it/s]Loading train:  83%|████████▎ | 236/285 [03:53<00:48,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [03:53<00:45,  1.07it/s]Loading train:  84%|████████▎ | 238/285 [03:54<00:43,  1.08it/s]Loading train:  84%|████████▍ | 239/285 [03:55<00:42,  1.09it/s]Loading train:  84%|████████▍ | 240/285 [03:56<00:38,  1.18it/s]Loading train:  85%|████████▍ | 241/285 [03:57<00:35,  1.24it/s]Loading train:  85%|████████▍ | 242/285 [03:57<00:32,  1.31it/s]Loading train:  85%|████████▌ | 243/285 [03:58<00:31,  1.33it/s]Loading train:  86%|████████▌ | 244/285 [03:59<00:33,  1.23it/s]Loading train:  86%|████████▌ | 245/285 [04:00<00:32,  1.25it/s]Loading train:  86%|████████▋ | 246/285 [04:01<00:31,  1.23it/s]Loading train:  87%|████████▋ | 247/285 [04:02<00:35,  1.07it/s]Loading train:  87%|████████▋ | 248/285 [04:03<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [04:04<00:33,  1.08it/s]Loading train:  88%|████████▊ | 250/285 [04:05<00:33,  1.04it/s]Loading train:  88%|████████▊ | 251/285 [04:06<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [04:07<00:32,  1.02it/s]Loading train:  89%|████████▉ | 253/285 [04:08<00:33,  1.04s/it]Loading train:  89%|████████▉ | 254/285 [04:09<00:34,  1.13s/it]Loading train:  89%|████████▉ | 255/285 [04:10<00:32,  1.08s/it]Loading train:  90%|████████▉ | 256/285 [04:11<00:28,  1.04it/s]Loading train:  90%|█████████ | 257/285 [04:12<00:27,  1.01it/s]Loading train:  91%|█████████ | 258/285 [04:13<00:27,  1.00s/it]Loading train:  91%|█████████ | 259/285 [04:14<00:25,  1.03it/s]Loading train:  91%|█████████ | 260/285 [04:15<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [04:16<00:23,  1.01it/s]Loading train:  92%|█████████▏| 262/285 [04:17<00:22,  1.03it/s]Loading train:  92%|█████████▏| 263/285 [04:18<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [04:19<00:23,  1.12s/it]Loading train:  93%|█████████▎| 265/285 [04:20<00:22,  1.15s/it]Loading train:  93%|█████████▎| 266/285 [04:21<00:19,  1.02s/it]Loading train:  94%|█████████▎| 267/285 [04:22<00:18,  1.02s/it]Loading train:  94%|█████████▍| 268/285 [04:23<00:17,  1.06s/it]Loading train:  94%|█████████▍| 269/285 [04:24<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:25<00:14,  1.04it/s]Loading train:  95%|█████████▌| 271/285 [04:26<00:14,  1.01s/it]Loading train:  95%|█████████▌| 272/285 [04:27<00:13,  1.07s/it]Loading train:  96%|█████████▌| 273/285 [04:28<00:11,  1.02it/s]Loading train:  96%|█████████▌| 274/285 [04:29<00:11,  1.00s/it]Loading train:  96%|█████████▋| 275/285 [04:30<00:10,  1.03s/it]Loading train:  97%|█████████▋| 276/285 [04:31<00:09,  1.06s/it]Loading train:  97%|█████████▋| 277/285 [04:32<00:08,  1.00s/it]Loading train:  98%|█████████▊| 278/285 [04:33<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:35<00:06,  1.07s/it]Loading train:  98%|█████████▊| 280/285 [04:35<00:04,  1.02it/s]Loading train:  99%|█████████▊| 281/285 [04:36<00:03,  1.06it/s]Loading train:  99%|█████████▉| 282/285 [04:37<00:02,  1.01it/s]Loading train:  99%|█████████▉| 283/285 [04:38<00:02,  1.05s/it]Loading train: 100%|█████████▉| 284/285 [04:40<00:01,  1.19s/it]Loading train: 100%|██████████| 285/285 [04:41<00:00,  1.14s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:01, 184.88it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:01, 184.92it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:01, 167.51it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:01, 191.54it/s]concatenating: train:  38%|███▊      | 107/285 [00:00<00:00, 206.16it/s]concatenating: train:  47%|████▋     | 134/285 [00:00<00:00, 220.41it/s]concatenating: train:  55%|█████▍    | 156/285 [00:01<00:01, 110.51it/s]concatenating: train:  62%|██████▏   | 177/285 [00:01<00:00, 127.88it/s]concatenating: train:  71%|███████   | 201/285 [00:01<00:00, 148.73it/s]concatenating: train:  82%|████████▏ | 235/285 [00:01<00:00, 178.87it/s]concatenating: train:  94%|█████████▍| 269/285 [00:01<00:00, 207.77it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 190.39it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.51s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 506.01it/s]2019-07-11 00:50:59.734056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:50:59.734161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:50:59.734176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:50:59.734185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:50:59.734617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.59it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.37it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.41it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.98it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.47it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.42it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.06it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.73it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.85it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.58it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.97it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.04it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.72it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.10it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.85it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.63it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.08it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.90it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.23it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 13)   598         dropout_6[0][0]                  
==================================================================================================
Total params: 132,438
Trainable params: 33,898
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 13s - loss: 3.0515 - acc: 0.4058 - mDice: 0.0735 - val_loss: 5.5428 - val_acc: 0.9048 - val_mDice: 0.0325

Epoch 00001: val_mDice improved from -inf to 0.03245, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.4682 - acc: 0.8705 - mDice: 0.2419 - val_loss: 2.0025 - val_acc: 0.9083 - val_mDice: 0.2597

Epoch 00002: val_mDice improved from 0.03245 to 0.25971, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 0.9646 - acc: 0.8802 - mDice: 0.3685 - val_loss: 1.2776 - val_acc: 0.9130 - val_mDice: 0.4307

Epoch 00003: val_mDice improved from 0.25971 to 0.43068, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7680 - acc: 0.8862 - mDice: 0.4483 - val_loss: 1.2055 - val_acc: 0.9148 - val_mDice: 0.4504

Epoch 00004: val_mDice improved from 0.43068 to 0.45039, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.6621 - acc: 0.8913 - mDice: 0.4999 - val_loss: 1.1179 - val_acc: 0.9188 - val_mDice: 0.4983

Epoch 00005: val_mDice improved from 0.45039 to 0.49828, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5991 - acc: 0.8952 - mDice: 0.5338 - val_loss: 1.0498 - val_acc: 0.9186 - val_mDice: 0.5313

Epoch 00006: val_mDice improved from 0.49828 to 0.53126, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.5544 - acc: 0.8980 - mDice: 0.5593 - val_loss: 1.0635 - val_acc: 0.9257 - val_mDice: 0.5405

Epoch 00007: val_mDice improved from 0.53126 to 0.54050, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 8s - loss: 0.5171 - acc: 0.9024 - mDice: 0.5810 - val_loss: 1.0129 - val_acc: 0.9330 - val_mDice: 0.5640

Epoch 00008: val_mDice improved from 0.54050 to 0.56404, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4886 - acc: 0.9069 - mDice: 0.5982 - val_loss: 0.9803 - val_acc: 0.9325 - val_mDice: 0.5649

Epoch 00009: val_mDice improved from 0.56404 to 0.56486, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 8s - loss: 0.4707 - acc: 0.9107 - mDice: 0.6094 - val_loss: 0.9932 - val_acc: 0.9392 - val_mDice: 0.5732

Epoch 00010: val_mDice improved from 0.56486 to 0.57325, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4522 - acc: 0.9154 - mDice: 0.6213 - val_loss: 0.9742 - val_acc: 0.9436 - val_mDice: 0.5781

Epoch 00011: val_mDice improved from 0.57325 to 0.57814, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4414 - acc: 0.9195 - mDice: 0.6282 - val_loss: 0.9769 - val_acc: 0.9450 - val_mDice: 0.5725

Epoch 00012: val_mDice did not improve from 0.57814
Epoch 13/300
 - 8s - loss: 0.4302 - acc: 0.9231 - mDice: 0.6355 - val_loss: 0.9466 - val_acc: 0.9409 - val_mDice: 0.5730

Epoch 00013: val_mDice did not improve from 0.57814
Epoch 14/300
 - 8s - loss: 0.4205 - acc: 0.9255 - mDice: 0.6418 - val_loss: 0.9859 - val_acc: 0.9362 - val_mDice: 0.5493

Epoch 00014: val_mDice did not improve from 0.57814
Epoch 15/300
 - 9s - loss: 0.4157 - acc: 0.9266 - mDice: 0.6449 - val_loss: 0.9210 - val_acc: 0.9426 - val_mDice: 0.5706

Epoch 00015: val_mDice did not improve from 0.57814
Epoch 16/300
 - 8s - loss: 0.4072 - acc: 0.9281 - mDice: 0.6506 - val_loss: 0.8941 - val_acc: 0.9455 - val_mDice: 0.5750

Epoch 00016: val_mDice did not improve from 0.57814
Epoch 17/300
 - 9s - loss: 0.4022 - acc: 0.9293 - mDice: 0.6539 - val_loss: 0.9064 - val_acc: 0.9443 - val_mDice: 0.5730

Epoch 00017: val_mDice did not improve from 0.57814
Epoch 18/300
 - 8s - loss: 0.3984 - acc: 0.9299 - mDice: 0.6564 - val_loss: 0.8854 - val_acc: 0.9408 - val_mDice: 0.5796

Epoch 00018: val_mDice improved from 0.57814 to 0.57962, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 8s - loss: 0.3934 - acc: 0.9307 - mDice: 0.6599 - val_loss: 0.9102 - val_acc: 0.9384 - val_mDice: 0.5599

Epoch 00019: val_mDice did not improve from 0.57962
Epoch 20/300
 - 9s - loss: 0.3881 - acc: 0.9313 - mDice: 0.6635 - val_loss: 0.8608 - val_acc: 0.9459 - val_mDice: 0.5654

Epoch 00020: val_mDice did not improve from 0.57962
Epoch 21/300
 - 8s - loss: 0.3850 - acc: 0.9318 - mDice: 0.6655 - val_loss: 0.8542 - val_acc: 0.9453 - val_mDice: 0.5684

Epoch 00021: val_mDice did not improve from 0.57962
Epoch 22/300
 - 8s - loss: 0.3807 - acc: 0.9326 - mDice: 0.6684 - val_loss: 0.8416 - val_acc: 0.9427 - val_mDice: 0.5765

Epoch 00022: val_mDice did not improve from 0.57962
Epoch 23/300
 - 9s - loss: 0.3790 - acc: 0.9328 - mDice: 0.6698 - val_loss: 0.8259 - val_acc: 0.9412 - val_mDice: 0.5742

Epoch 00023: val_mDice did not improve from 0.57962
Epoch 24/300
 - 8s - loss: 0.3751 - acc: 0.9334 - mDice: 0.6723 - val_loss: 0.7972 - val_acc: 0.9465 - val_mDice: 0.5709

Epoch 00024: val_mDice did not improve from 0.57962
Epoch 25/300
 - 9s - loss: 0.3732 - acc: 0.9335 - mDice: 0.6737 - val_loss: 0.8437 - val_acc: 0.9437 - val_mDice: 0.5551

Epoch 00025: val_mDice did not improve from 0.57962
Epoch 26/300
 - 9s - loss: 0.3705 - acc: 0.9339 - mDice: 0.6756 - val_loss: 0.7898 - val_acc: 0.9457 - val_mDice: 0.5642

Epoch 00026: val_mDice did not improve from 0.57962
Epoch 27/300
 - 8s - loss: 0.3649 - acc: 0.9343 - mDice: 0.6795 - val_loss: 0.7907 - val_acc: 0.9440 - val_mDice: 0.5628

Epoch 00027: val_mDice did not improve from 0.57962
Epoch 28/300
 - 9s - loss: 0.3631 - acc: 0.9345 - mDice: 0.6807 - val_loss: 0.7753 - val_acc: 0.9386 - val_mDice: 0.5609

Epoch 00028: val_mDice did not improve from 0.57962
Epoch 29/300
 - 8s - loss: 0.3600 - acc: 0.9347 - mDice: 0.6829 - val_loss: 0.8186 - val_acc: 0.9448 - val_mDice: 0.5429

Epoch 00029: val_mDice did not improve from 0.57962
Epoch 30/300
 - 8s - loss: 0.3578 - acc: 0.9351 - mDice: 0.6844 - val_loss: 0.7561 - val_acc: 0.9427 - val_mDice: 0.5693

Epoch 00030: val_mDice did not improve from 0.57962
Epoch 31/300
 - 9s - loss: 0.3570 - acc: 0.9353 - mDice: 0.6850 - val_loss: 0.7833 - val_acc: 0.9374 - val_mDice: 0.5604

Epoch 00031: val_mDice did not improve from 0.57962
Epoch 32/300
 - 8s - loss: 0.3550 - acc: 0.9355 - mDice: 0.6864 - val_loss: 0.7170 - val_acc: 0.9437 - val_mDice: 0.5762

Epoch 00032: val_mDice did not improve from 0.57962
Epoch 33/300
 - 9s - loss: 0.3540 - acc: 0.9355 - mDice: 0.6872 - val_loss: 0.8285 - val_acc: 0.9352 - val_mDice: 0.5588

Epoch 00033: val_mDice did not improve from 0.57962
Epoch 34/300
 - 9s - loss: 0.3511 - acc: 0.9357 - mDice: 0.6891 - val_loss: 0.7251 - val_acc: 0.9433 - val_mDice: 0.5709

Epoch 00034: val_mDice did not improve from 0.57962
Epoch 35/300
 - 8s - loss: 0.3472 - acc: 0.9361 - mDice: 0.6920 - val_loss: 0.7114 - val_acc: 0.9422 - val_mDice: 0.5713

Epoch 00035: val_mDice did not improve from 0.57962
Epoch 36/300
 - 9s - loss: 0.3461 - acc: 0.9364 - mDice: 0.6928 - val_loss: 0.7128 - val_acc: 0.9451 - val_mDice: 0.5660

Epoch 00036: val_mDice did not improve from 0.57962
Epoch 37/300
 - 8s - loss: 0.3460 - acc: 0.9363 - mDice: 0.6928 - val_loss: 0.6896 - val_acc: 0.9458 - val_mDice: 0.5725

Epoch 00037: val_mDice did not improve from 0.57962
Epoch 38/300
 - 9s - loss: 0.3436 - acc: 0.9366 - mDice: 0.6946 - val_loss: 0.6989 - val_acc: 0.9452 - val_mDice: 0.5629

Epoch 00038: val_mDice did not improve from 0.57962
Epoch 39/300
 - 9s - loss: 0.3416 - acc: 0.9367 - mDice: 0.6961 - val_loss: 0.7085 - val_acc: 0.9413 - val_mDice: 0.5585

Epoch 00039: val_mDice did not improve from 0.57962
Epoch 40/300
 - 8s - loss: 0.3404 - acc: 0.9370 - mDice: 0.6970 - val_loss: 0.7385 - val_acc: 0.9443 - val_mDice: 0.5578

Epoch 00040: val_mDice did not improve from 0.57962
Epoch 41/300
 - 9s - loss: 0.3399 - acc: 0.9370 - mDice: 0.6974 - val_loss: 0.7101 - val_acc: 0.9458 - val_mDice: 0.5638

Epoch 00041: val_mDice did not improve from 0.57962
Epoch 42/300
 - 9s - loss: 0.3379 - acc: 0.9372 - mDice: 0.6988 - val_loss: 0.7294 - val_acc: 0.9451 - val_mDice: 0.5471

Epoch 00042: val_mDice did not improve from 0.57962
Epoch 43/300
 - 8s - loss: 0.3355 - acc: 0.9374 - mDice: 0.7005 - val_loss: 0.6956 - val_acc: 0.9441 - val_mDice: 0.5533

Epoch 00043: val_mDice did not improve from 0.57962
Epoch 44/300
 - 8s - loss: 0.3355 - acc: 0.9375 - mDice: 0.7005 - val_loss: 0.7014 - val_acc: 0.9433 - val_mDice: 0.5641

Epoch 00044: val_mDice did not improve from 0.57962
Epoch 45/300
 - 9s - loss: 0.3335 - acc: 0.9375 - mDice: 0.7019 - val_loss: 0.6673 - val_acc: 0.9448 - val_mDice: 0.5573

Epoch 00045: val_mDice did not improve from 0.57962
Epoch 46/300
 - 8s - loss: 0.3318 - acc: 0.9378 - mDice: 0.7032 - val_loss: 0.6966 - val_acc: 0.9430 - val_mDice: 0.5552

Epoch 00046: val_mDice did not improve from 0.57962
Epoch 47/300
 - 9s - loss: 0.3338 - acc: 0.9376 - mDice: 0.7018 - val_loss: 0.7363 - val_acc: 0.9430 - val_mDice: 0.5546

Epoch 00047: val_mDice did not improve from 0.57962
Epoch 48/300
 - 9s - loss: 0.3295 - acc: 0.9379 - mDice: 0.7048 - val_loss: 0.6603 - val_acc: 0.9423 - val_mDice: 0.5708

Epoch 00048: val_mDice did not improve from 0.57962
Epoch 49/300
 - 8s - loss: 0.3292 - acc: 0.9380 - mDice: 0.7051 - val_loss: 0.6437 - val_acc: 0.9445 - val_mDice: 0.5730

Epoch 00049: val_mDice did not improve from 0.57962
Epoch 50/300
 - 8s - loss: 0.3287 - acc: 0.9381 - mDice: 0.7055 - val_loss: 0.7345 - val_acc: 0.9392 - val_mDice: 0.5427

Epoch 00050: val_mDice did not improve from 0.57962
Epoch 51/300
 - 9s - loss: 0.3281 - acc: 0.9381 - mDice: 0.7059 - val_loss: 0.6532 - val_acc: 0.9439 - val_mDice: 0.5535

Epoch 00051: val_mDice did not improve from 0.57962
Epoch 52/300
 - 8s - loss: 0.3244 - acc: 0.9384 - mDice: 0.7086 - val_loss: 0.6238 - val_acc: 0.9422 - val_mDice: 0.5690

Epoch 00052: val_mDice did not improve from 0.57962
Epoch 53/300
 - 8s - loss: 0.3273 - acc: 0.9381 - mDice: 0.7066 - val_loss: 0.6897 - val_acc: 0.9433 - val_mDice: 0.5501

Epoch 00053: val_mDice did not improve from 0.57962
Epoch 54/300
 - 8s - loss: 0.3240 - acc: 0.9385 - mDice: 0.7089 - val_loss: 0.6624 - val_acc: 0.9407 - val_mDice: 0.5573

Epoch 00054: val_mDice did not improve from 0.57962
Epoch 55/300
 - 9s - loss: 0.3237 - acc: 0.9385 - mDice: 0.7092 - val_loss: 0.6388 - val_acc: 0.9446 - val_mDice: 0.5642

Epoch 00055: val_mDice did not improve from 0.57962
Epoch 56/300
 - 9s - loss: 0.3228 - acc: 0.9387 - mDice: 0.7099 - val_loss: 0.7132 - val_acc: 0.9420 - val_mDice: 0.5535

Epoch 00056: val_mDice did not improve from 0.57962
Epoch 57/300
 - 8s - loss: 0.3211 - acc: 0.9387 - mDice: 0.7110 - val_loss: 0.6274 - val_acc: 0.9447 - val_mDice: 0.5563

Epoch 00057: val_mDice did not improve from 0.57962
Epoch 58/300
 - 8s - loss: 0.3224 - acc: 0.9387 - mDice: 0.7101 - val_loss: 0.6445 - val_acc: 0.9457 - val_mDice: 0.5608

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.46s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.25s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:54,  2.09s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:00,  1.91s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:55,  1.90s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:08,  1.74s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:25,  1.81s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:51,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<07:59,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:44,  1.68s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:20,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:46,  1.91s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:23,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:39,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:29,  1.87s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:37,  1.91s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:41,  1.93s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<09:07,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:41,  1.95s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:39,  1.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:07,  1.83s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:16,  1.87s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:23,  1.91s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<07:56,  1.81s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:46,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:19,  1.92s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:21,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:56,  1.85s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:01,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:56,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:55<07:59,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:15,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:52,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:50,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:55,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:10,  1.96s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:41,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:45,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:58,  1.94s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:49,  1.91s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<08:02,  1.97s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:35,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:27,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:39,  1.90s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:51,  1.95s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:20,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:23,  1.86s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:12,  1.82s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:21,  1.86s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:43,  1.96s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:33,  1.93s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:42,  1.98s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:26,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:40,  1.99s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:50,  2.04s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:31,  1.97s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:30,  1.97s/it]predicting train subjects:  20%|██        | 57/285 [01:47<07:08,  1.88s/it]predicting train subjects:  20%|██        | 58/285 [01:49<07:13,  1.91s/it]predicting train subjects:  21%|██        | 59/285 [01:51<07:31,  2.00s/it]predicting train subjects:  21%|██        | 60/285 [01:53<07:35,  2.03s/it]predicting train subjects:  21%|██▏       | 61/285 [01:55<07:13,  1.93s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<07:09,  1.93s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<07:08,  1.93s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<06:53,  1.87s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:55,  1.90s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<06:58,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:39,  1.84s/it]predicting train subjects:  24%|██▍       | 69/285 [02:10<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:12<06:44,  1.88s/it]predicting train subjects:  25%|██▍       | 71/285 [02:14<06:55,  1.94s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:37,  1.87s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:36,  1.87s/it]predicting train subjects:  26%|██▌       | 74/285 [02:19<06:28,  1.84s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:44,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:46,  1.94s/it]predicting train subjects:  27%|██▋       | 77/285 [02:25<06:27,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:27<06:17,  1.82s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:12,  1.81s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<06:16,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:21,  1.87s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:21,  1.88s/it]predicting train subjects:  29%|██▉       | 83/285 [02:36<06:01,  1.79s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<05:46,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<05:44,  1.72s/it]predicting train subjects:  30%|███       | 86/285 [02:41<06:04,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:03,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:05,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:47<06:12,  1.90s/it]predicting train subjects:  32%|███▏      | 90/285 [02:49<06:18,  1.94s/it]predicting train subjects:  32%|███▏      | 91/285 [02:51<06:11,  1.91s/it]predicting train subjects:  32%|███▏      | 92/285 [02:53<06:10,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [02:54<06:01,  1.88s/it]predicting train subjects:  33%|███▎      | 94/285 [02:56<06:01,  1.89s/it]predicting train subjects:  33%|███▎      | 95/285 [02:58<05:59,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<05:50,  1.86s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<05:55,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<05:58,  1.92s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<06:09,  1.99s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<06:03,  1.96s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:52,  1.91s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:52,  1.93s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:34,  1.84s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:40,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:38,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:34,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:35,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:23<05:17,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:14,  1.78s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:26,  1.87s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:29,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:30,  1.91s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:33,  1.94s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:32,  1.95s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:21,  1.89s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:17,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:11,  1.85s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<04:54,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<04:58,  1.80s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<04:46,  1.74s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<04:42,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:49<04:16,  1.58s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:52<04:06,  1.54s/it]predicting train subjects:  44%|████▍     | 126/285 [03:54<04:10,  1.58s/it]predicting train subjects:  45%|████▍     | 127/285 [03:55<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:57<04:09,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<03:58,  1.53s/it]predicting train subjects:  46%|████▌     | 130/285 [04:00<03:57,  1.53s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<03:48,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<03:57,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<03:48,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<03:48,  1.51s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<03:37,  1.45s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<03:32,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<03:42,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:32,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [04:13<03:45,  1.54s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:48,  1.58s/it]predicting train subjects:  49%|████▉     | 141/285 [04:16<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:42,  1.56s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:37,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:21<03:39,  1.55s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:36,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:32,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:36,  1.58s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:31,  1.55s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:29,  1.55s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:30,  1.57s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:29,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:23,  1.54s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:28,  1.59s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:22,  1.56s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:41<03:17,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:13,  1.52s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:08,  1.49s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<03:07,  1.51s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:07,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:04,  1.51s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:00,  1.49s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<02:53,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<03:05,  1.57s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<02:56,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<02:56,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<02:46,  1.46s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [05:05<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:08<02:47,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:48,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:48,  1.56s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:44,  1.55s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:55,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:54,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:23<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:24<02:37,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:26<02:43,  1.65s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:30<02:52,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:31<02:39,  1.66s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:35<02:36,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:36<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:38<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:39<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:41<02:12,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:42<02:21,  1.60s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:44<02:29,  1.69s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:46<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:49<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:51<02:20,  1.68s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:54<02:17,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:10,  1.61s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:57<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:59<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:00<02:02,  1.57s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:02<02:03,  1.60s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:04<02:09,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:06<02:05,  1.67s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:07<01:57,  1.59s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:09<01:58,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:10<01:56,  1.62s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:12<01:50,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:14<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:15<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:17<01:48,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:18<01:51,  1.66s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:20<01:52,  1.70s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:22<01:45,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:23<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:25<01:42,  1.62s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:26<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:31,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:29<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:40,  1.76s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [06:38<01:30,  1.65s/it]predicting train subjects:  81%|████████  | 231/285 [06:39<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:41<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:42<01:19,  1.53s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:44<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:45<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:47<01:22,  1.69s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:49<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:51<01:21,  1.73s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:53<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:54<01:13,  1.64s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:55<01:09,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:57<01:05,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:58<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:00<01:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:01<01:00,  1.52s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:03<01:04,  1.64s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:05<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:07<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:08<00:56,  1.56s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:09<00:52,  1.51s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:11<00:49,  1.46s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:12<00:46,  1.41s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:14<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:16<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:17<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:19<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:20<00:43,  1.56s/it]predicting train subjects:  91%|█████████ | 258/285 [07:22<00:43,  1.63s/it]predicting train subjects:  91%|█████████ | 259/285 [07:24<00:43,  1.67s/it]predicting train subjects:  91%|█████████ | 260/285 [07:25<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:27<00:37,  1.56s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:28<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:30<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:32<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:33<00:33,  1.67s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:35<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:36<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:38<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:40<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:41<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:42<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:44<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:46<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:47<00:16,  1.48s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:49<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:51<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:52<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:54<00:10,  1.52s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:55<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:57<00:07,  1.52s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:58<00:05,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:03<00:01,  1.68s/it]predicting train subjects: 100%|██████████| 285/285 [08:05<00:00,  1.74s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:41,  2.05s/it]Loading train:   1%|          | 2/285 [00:03<08:48,  1.87s/it]Loading train:   1%|          | 3/285 [00:05<08:36,  1.83s/it]Loading train:   1%|▏         | 4/285 [00:06<07:59,  1.71s/it]Loading train:   2%|▏         | 5/285 [00:08<08:14,  1.77s/it]Loading train:   2%|▏         | 6/285 [00:09<07:42,  1.66s/it]Loading train:   2%|▏         | 7/285 [00:11<07:37,  1.64s/it]Loading train:   3%|▎         | 8/285 [00:13<07:50,  1.70s/it]Loading train:   3%|▎         | 9/285 [00:15<08:02,  1.75s/it]Loading train:   4%|▎         | 10/285 [00:16<07:25,  1.62s/it]Loading train:   4%|▍         | 11/285 [00:17<06:55,  1.52s/it]Loading train:   4%|▍         | 12/285 [00:19<06:38,  1.46s/it]Loading train:   5%|▍         | 13/285 [00:20<05:55,  1.31s/it]Loading train:   5%|▍         | 14/285 [00:21<05:39,  1.25s/it]Loading train:   5%|▌         | 15/285 [00:22<05:37,  1.25s/it]Loading train:   6%|▌         | 16/285 [00:24<06:13,  1.39s/it]Loading train:   6%|▌         | 17/285 [00:25<05:37,  1.26s/it]Loading train:   6%|▋         | 18/285 [00:26<05:25,  1.22s/it]Loading train:   7%|▋         | 19/285 [00:27<05:16,  1.19s/it]Loading train:   7%|▋         | 20/285 [00:28<05:33,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:30<05:47,  1.32s/it]Loading train:   8%|▊         | 22/285 [00:31<05:19,  1.22s/it]Loading train:   8%|▊         | 23/285 [00:32<04:58,  1.14s/it]Loading train:   8%|▊         | 24/285 [00:33<05:17,  1.22s/it]Loading train:   9%|▉         | 25/285 [00:35<05:38,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:36<05:43,  1.33s/it]Loading train:   9%|▉         | 27/285 [00:37<05:28,  1.27s/it]Loading train:  10%|▉         | 28/285 [00:38<05:10,  1.21s/it]Loading train:  10%|█         | 29/285 [00:40<05:18,  1.25s/it]Loading train:  11%|█         | 30/285 [00:41<05:30,  1.30s/it]Loading train:  11%|█         | 31/285 [00:42<05:29,  1.30s/it]Loading train:  11%|█         | 32/285 [00:43<05:13,  1.24s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:15,  1.25s/it]Loading train:  12%|█▏        | 34/285 [00:46<05:33,  1.33s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:32,  1.33s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:33,  1.34s/it]Loading train:  13%|█▎        | 37/285 [00:50<05:22,  1.30s/it]Loading train:  13%|█▎        | 38/285 [00:51<05:11,  1.26s/it]Loading train:  14%|█▎        | 39/285 [00:52<04:47,  1.17s/it]Loading train:  14%|█▍        | 40/285 [00:53<04:40,  1.15s/it]Loading train:  14%|█▍        | 41/285 [00:55<04:54,  1.21s/it]Loading train:  15%|█▍        | 42/285 [00:56<04:54,  1.21s/it]Loading train:  15%|█▌        | 43/285 [00:57<05:21,  1.33s/it]Loading train:  15%|█▌        | 44/285 [00:59<05:28,  1.36s/it]Loading train:  16%|█▌        | 45/285 [01:00<05:13,  1.31s/it]Loading train:  16%|█▌        | 46/285 [01:02<05:24,  1.36s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:54,  1.24s/it]Loading train:  17%|█▋        | 48/285 [01:04<04:48,  1.22s/it]Loading train:  17%|█▋        | 49/285 [01:05<04:55,  1.25s/it]Loading train:  18%|█▊        | 50/285 [01:06<04:53,  1.25s/it]Loading train:  18%|█▊        | 51/285 [01:08<05:05,  1.31s/it]Loading train:  18%|█▊        | 52/285 [01:09<04:54,  1.27s/it]Loading train:  19%|█▊        | 53/285 [01:10<04:43,  1.22s/it]Loading train:  19%|█▉        | 54/285 [01:11<04:41,  1.22s/it]Loading train:  19%|█▉        | 55/285 [01:12<04:33,  1.19s/it]Loading train:  20%|█▉        | 56/285 [01:14<04:41,  1.23s/it]Loading train:  20%|██        | 57/285 [01:15<04:38,  1.22s/it]Loading train:  20%|██        | 58/285 [01:16<04:18,  1.14s/it]Loading train:  21%|██        | 59/285 [01:17<04:45,  1.26s/it]Loading train:  21%|██        | 60/285 [01:19<04:57,  1.32s/it]Loading train:  21%|██▏       | 61/285 [01:20<04:36,  1.23s/it]Loading train:  22%|██▏       | 62/285 [01:21<05:02,  1.36s/it]Loading train:  22%|██▏       | 63/285 [01:23<05:06,  1.38s/it]Loading train:  22%|██▏       | 64/285 [01:25<05:24,  1.47s/it]Loading train:  23%|██▎       | 65/285 [01:26<05:47,  1.58s/it]
Epoch 00058: val_mDice did not improve from 0.57962
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [5.542791411990211, 2.0025223777407692, 1.2776382650647844, 1.2054617404937744, 1.1179311616080148, 1.0498353640238445, 1.0634914693378268, 1.0128944601331438, 0.9803089868454706, 0.9932011649722144, 0.9741937319437662, 0.9768794207345872, 0.9465749717894054, 0.9859309082939511, 0.9210401546387446, 0.894145959899539, 0.9064204522541591, 0.8853826238995507, 0.9101508458455404, 0.8607669330778576, 0.8541610978898548, 0.8415781827200026, 0.8258841605413527, 0.79716842515128, 0.8436938808077857, 0.7898484525226411, 0.7907221884954543, 0.7753382750919887, 0.8185870420365107, 0.7561194556100028, 0.7833271253676641, 0.7170404763448806, 0.8285307657150995, 0.7251049053101313, 0.7114196504865374, 0.7128241175696963, 0.6896218742643084, 0.6988553319658551, 0.7085368519737607, 0.7385078838893345, 0.7100876967112223, 0.7293869881402879, 0.6955582073756627, 0.7013741447812035, 0.6673416410173688, 0.6966125397455125, 0.7362758432115827, 0.6602986710412162, 0.643666114125933, 0.7345468316759381, 0.6532200291043236, 0.6238288254964919, 0.6896607535226005, 0.6624116329919725, 0.6388411408378964, 0.7131602423531669, 0.6273851848783947, 0.6445182164510092], 'val_acc': [0.9048031256312415, 0.908253224123092, 0.9130311523165021, 0.9148489038149515, 0.918750007947286, 0.918580603031885, 0.9256891012191772, 0.9329761976287478, 0.9324908540362403, 0.9392010257357642, 0.9436011938821702, 0.9450137132690066, 0.9408585258892604, 0.9362019442376637, 0.9426144730477106, 0.9455311440286183, 0.9443131798789615, 0.940847050575983, 0.9384409331140064, 0.9458836884725661, 0.9453045044626508, 0.9426968608583722, 0.9412454139618647, 0.9464789231618246, 0.943740827696664, 0.9457303086916605, 0.9439606212434315, 0.9385554052534557, 0.9448466017132714, 0.9426533892041161, 0.9374129914102101, 0.9436767385119483, 0.9351899992851984, 0.9433058642205738, 0.9421703560011727, 0.9451167384783427, 0.9457669428416661, 0.9451671129181272, 0.9412637523242405, 0.9442834314845857, 0.9458173087665013, 0.94507782799857, 0.9441460541316441, 0.9432852353368487, 0.9448466215814862, 0.942953280040196, 0.9430403056598845, 0.9422550314948672, 0.9444894904182071, 0.9392444973900205, 0.9439239700635275, 0.9422138021105811, 0.943315014952705, 0.9406753891990298, 0.9445558332261585, 0.9419642630077544, 0.9447275428544908, 0.9456684844834464], 'val_mDice': [0.03245400924580671, 0.259706121470247, 0.43068296355860575, 0.45039444736071993, 0.4982801950758412, 0.531261896448476, 0.5404952464713937, 0.564038410782814, 0.5648564949986481, 0.5732471430230708, 0.5781378118055207, 0.5725089900550389, 0.5729637676406474, 0.549319751560688, 0.5705874257144474, 0.5749799960425922, 0.5730493982278165, 0.57961658973779, 0.5599060101168496, 0.5653802940533275, 0.568447973046984, 0.5765357973674933, 0.5741774943612871, 0.5709356025216126, 0.5551413153963429, 0.5642381583650907, 0.5627687346367609, 0.5609272787613528, 0.5428955682686397, 0.5693137954388346, 0.5604043673901331, 0.5762474598983923, 0.5587853902862185, 0.570907864897024, 0.5713474736327216, 0.5660288280674389, 0.5724606549456006, 0.5628620694790568, 0.5585120559803077, 0.5577575782580035, 0.5638335379106658, 0.5471284251127925, 0.5533231026714757, 0.5640539447111743, 0.5573117383534, 0.5551692160467306, 0.5546269175552186, 0.5708271747543698, 0.5729565638161841, 0.5427141918667725, 0.5534662774630955, 0.5689956040254661, 0.5500933866770494, 0.557331388017961, 0.5641577069958051, 0.5534568817487785, 0.5562730843112582, 0.560760460793972], 'loss': [3.0515074579615065, 1.4682330537766235, 0.9645734108296438, 0.7680305648061474, 0.6621297464817504, 0.5991046690908681, 0.5543972057185698, 0.5170774575095198, 0.48859586241917735, 0.4706707172525258, 0.4521786710396423, 0.441370481289442, 0.43021424758496346, 0.4204530151611536, 0.41568815769638107, 0.40722478511063653, 0.40222654669919594, 0.398377475048826, 0.39344189114508105, 0.38809679201257374, 0.3849753088888599, 0.38069193977277266, 0.37898287422422133, 0.3751494774980216, 0.37316526044810094, 0.37046974368216745, 0.3648762709664223, 0.3631097156348338, 0.360013150849369, 0.3577849821120943, 0.35695308375064405, 0.35504666250612044, 0.35403958057791873, 0.3511359281845122, 0.3471880774231851, 0.3461357764375447, 0.3460484841252789, 0.3436281159247234, 0.3416032394290499, 0.3403702475890411, 0.33985691485847147, 0.33785397255032285, 0.3354506971164087, 0.3354705918701669, 0.3334671410092596, 0.33178841937868403, 0.3337514296372272, 0.3294998503947088, 0.3292413107664433, 0.32866493627035437, 0.3281084562464902, 0.3243686271375697, 0.32729609469492266, 0.32400683356843657, 0.3236575165775348, 0.32276659508144, 0.3211453599129565, 0.3224292451909725], 'acc': [0.40579103417974666, 0.870526816290147, 0.8802184140450099, 0.886231411231927, 0.8913018728281598, 0.8951572700114018, 0.8979636846145775, 0.9024414546875359, 0.9068739481208549, 0.9106532269092292, 0.9154011351376893, 0.9195094131678774, 0.9230948326811524, 0.9255083436701186, 0.9266116980162341, 0.9281431630854204, 0.9292699641544326, 0.9298909286186832, 0.9306672306701538, 0.9313341582903909, 0.931794308963391, 0.932623255073576, 0.9328048070294792, 0.933373374242141, 0.9334777629235266, 0.9338876518505442, 0.9343427669250461, 0.9345126185707672, 0.9347321694127531, 0.9350870717851923, 0.935264984169102, 0.9354766831247247, 0.935488408003006, 0.9356625666962163, 0.9360880246391319, 0.9363795931982309, 0.9363287097115679, 0.9365736601645487, 0.9367314586180677, 0.9370169141560546, 0.937047038690557, 0.9372434207118497, 0.9374043222725771, 0.9374553469970826, 0.937502668316203, 0.9377764417460044, 0.9375542223924659, 0.9379414905811381, 0.9379620931960724, 0.9381077739804932, 0.9380678936238691, 0.9383983741336093, 0.9381156518598593, 0.9384923346681082, 0.9385017645779615, 0.9386913345134485, 0.9387134624649064, 0.9386534497575629], 'mDice': [0.07346628880886322, 0.24193968116972794, 0.3685162555672701, 0.4482735449325057, 0.4998939656236853, 0.5338322610461645, 0.55931433721018, 0.5810094100789618, 0.5982242853098667, 0.6094135969664657, 0.6213156865675923, 0.6282132601540328, 0.6354505350899095, 0.641786227537438, 0.6448734170764955, 0.650616341067436, 0.6539102953616103, 0.6564420061762309, 0.6599102082430846, 0.6634728426714497, 0.6655373043330942, 0.6684408165113715, 0.6697589872153205, 0.6723463713996369, 0.6736930026377422, 0.6755809741188433, 0.6795166913130528, 0.6806588548328781, 0.6828859263769987, 0.6844357667641302, 0.6850087513509044, 0.6864146352021111, 0.6871739909762428, 0.6891425349061053, 0.6919633397160639, 0.6927680415019655, 0.6927913989500433, 0.6945871159431446, 0.696055232892497, 0.6969592713863836, 0.6973620529967235, 0.6988264147155612, 0.7005333049876028, 0.700495412015538, 0.7019377984314817, 0.703151639058959, 0.7018337432924944, 0.7048290299385619, 0.7050734503273333, 0.705467499058578, 0.7059190171932884, 0.7085967196741614, 0.7065863134499251, 0.7088545955673036, 0.7091671571994486, 0.709887115544429, 0.7110046458906214, 0.7101226424996233]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label valuesLoading train:  23%|██▎       | 66/285 [01:28<05:43,  1.57s/it]Loading train:  24%|██▎       | 67/285 [01:29<05:05,  1.40s/it]Loading train:  24%|██▍       | 68/285 [01:30<04:33,  1.26s/it]Loading train:  24%|██▍       | 69/285 [01:31<04:40,  1.30s/it]Loading train:  25%|██▍       | 70/285 [01:32<04:33,  1.27s/it]Loading train:  25%|██▍       | 71/285 [01:33<04:13,  1.19s/it]Loading train:  25%|██▌       | 72/285 [01:35<04:08,  1.16s/it]Loading train:  26%|██▌       | 73/285 [01:36<04:07,  1.17s/it]Loading train:  26%|██▌       | 74/285 [01:37<04:17,  1.22s/it]Loading train:  26%|██▋       | 75/285 [01:38<04:21,  1.24s/it]Loading train:  27%|██▋       | 76/285 [01:40<04:13,  1.21s/it]Loading train:  27%|██▋       | 77/285 [01:41<03:58,  1.15s/it]Loading train:  27%|██▋       | 78/285 [01:42<04:13,  1.22s/it]Loading train:  28%|██▊       | 79/285 [01:43<04:31,  1.32s/it]Loading train:  28%|██▊       | 80/285 [01:45<04:29,  1.31s/it]Loading train:  28%|██▊       | 81/285 [01:46<04:34,  1.35s/it]Loading train:  29%|██▉       | 82/285 [01:48<04:47,  1.42s/it]Loading train:  29%|██▉       | 83/285 [01:49<04:45,  1.41s/it]Loading train:  29%|██▉       | 84/285 [01:51<04:42,  1.40s/it]Loading train:  30%|██▉       | 85/285 [01:52<04:45,  1.43s/it]Loading train:  30%|███       | 86/285 [01:53<04:41,  1.41s/it]Loading train:  31%|███       | 87/285 [01:55<04:19,  1.31s/it]Loading train:  31%|███       | 88/285 [01:56<04:01,  1.23s/it]Loading train:  31%|███       | 89/285 [01:57<03:49,  1.17s/it]Loading train:  32%|███▏      | 90/285 [01:58<03:41,  1.14s/it]Loading train:  32%|███▏      | 91/285 [01:59<03:34,  1.11s/it]Loading train:  32%|███▏      | 92/285 [02:00<03:38,  1.13s/it]Loading train:  33%|███▎      | 93/285 [02:01<03:48,  1.19s/it]Loading train:  33%|███▎      | 94/285 [02:03<04:02,  1.27s/it]Loading train:  33%|███▎      | 95/285 [02:04<03:52,  1.22s/it]Loading train:  34%|███▎      | 96/285 [02:05<03:50,  1.22s/it]Loading train:  34%|███▍      | 97/285 [02:07<04:08,  1.32s/it]Loading train:  34%|███▍      | 98/285 [02:08<03:54,  1.25s/it]Loading train:  35%|███▍      | 99/285 [02:09<03:39,  1.18s/it]Loading train:  35%|███▌      | 100/285 [02:10<03:36,  1.17s/it]Loading train:  35%|███▌      | 101/285 [02:11<03:31,  1.15s/it]Loading train:  36%|███▌      | 102/285 [02:12<03:36,  1.18s/it]Loading train:  36%|███▌      | 103/285 [02:14<03:44,  1.24s/it]Loading train:  36%|███▋      | 104/285 [02:15<03:43,  1.24s/it]Loading train:  37%|███▋      | 105/285 [02:16<03:43,  1.24s/it]Loading train:  37%|███▋      | 106/285 [02:17<03:38,  1.22s/it]Loading train:  38%|███▊      | 107/285 [02:19<03:49,  1.29s/it]Loading train:  38%|███▊      | 108/285 [02:20<03:55,  1.33s/it]Loading train:  38%|███▊      | 109/285 [02:21<03:44,  1.27s/it]Loading train:  39%|███▊      | 110/285 [02:23<03:55,  1.34s/it]Loading train:  39%|███▉      | 111/285 [02:24<03:55,  1.36s/it]Loading train:  39%|███▉      | 112/285 [02:25<03:44,  1.30s/it]Loading train:  40%|███▉      | 113/285 [02:27<03:48,  1.33s/it]Loading train:  40%|████      | 114/285 [02:28<03:55,  1.38s/it]Loading train:  40%|████      | 115/285 [02:29<03:46,  1.33s/it]Loading train:  41%|████      | 116/285 [02:31<03:52,  1.38s/it]Loading train:  41%|████      | 117/285 [02:32<03:43,  1.33s/it]Loading train:  41%|████▏     | 118/285 [02:33<03:27,  1.24s/it]Loading train:  42%|████▏     | 119/285 [02:34<03:23,  1.23s/it]Loading train:  42%|████▏     | 120/285 [02:35<03:10,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:37<03:32,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:38<03:33,  1.31s/it]Loading train:  43%|████▎     | 123/285 [02:40<03:33,  1.32s/it]Loading train:  44%|████▎     | 124/285 [02:40<03:08,  1.17s/it]Loading train:  44%|████▍     | 125/285 [02:41<03:00,  1.13s/it]Loading train:  44%|████▍     | 126/285 [02:42<02:52,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:44<02:53,  1.09s/it]Loading train:  45%|████▍     | 128/285 [02:45<02:45,  1.05s/it]Loading train:  45%|████▌     | 129/285 [02:45<02:36,  1.01s/it]Loading train:  46%|████▌     | 130/285 [02:46<02:29,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:47<02:31,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:49<02:45,  1.08s/it]Loading train:  47%|████▋     | 133/285 [02:50<02:36,  1.03s/it]Loading train:  47%|████▋     | 134/285 [02:51<02:38,  1.05s/it]Loading train:  47%|████▋     | 135/285 [02:52<02:35,  1.04s/it]Loading train:  48%|████▊     | 136/285 [02:53<02:28,  1.01it/s]Loading train:  48%|████▊     | 137/285 [02:54<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:55<02:25,  1.01it/s]Loading train:  49%|████▉     | 139/285 [02:56<02:37,  1.08s/it]Loading train:  49%|████▉     | 140/285 [02:57<02:31,  1.05s/it]Loading train:  49%|████▉     | 141/285 [02:58<02:24,  1.01s/it]Loading train:  50%|████▉     | 142/285 [02:59<02:24,  1.01s/it]Loading train:  50%|█████     | 143/285 [03:00<02:21,  1.00it/s]Loading train:  51%|█████     | 144/285 [03:01<02:21,  1.00s/it]Loading train:  51%|█████     | 145/285 [03:02<02:30,  1.07s/it]Loading train:  51%|█████     | 146/285 [03:03<02:28,  1.07s/it]Loading train:  52%|█████▏    | 147/285 [03:04<02:25,  1.05s/it]Loading train:  52%|█████▏    | 148/285 [03:05<02:21,  1.04s/it]Loading train:  52%|█████▏    | 149/285 [03:06<02:15,  1.01it/s]Loading train:  53%|█████▎    | 150/285 [03:07<02:31,  1.12s/it]Loading train:  53%|█████▎    | 151/285 [03:08<02:21,  1.06s/it]Loading train:  53%|█████▎    | 152/285 [03:09<02:10,  1.02it/s]Loading train:  54%|█████▎    | 153/285 [03:10<01:59,  1.10it/s]Loading train:  54%|█████▍    | 154/285 [03:11<01:56,  1.12it/s]Loading train:  54%|█████▍    | 155/285 [03:11<01:54,  1.14it/s]Loading train:  55%|█████▍    | 156/285 [03:12<01:50,  1.17it/s]Loading train:  55%|█████▌    | 157/285 [03:13<01:59,  1.07it/s]Loading train:  55%|█████▌    | 158/285 [03:14<01:59,  1.06it/s]Loading train:  56%|█████▌    | 159/285 [03:15<02:00,  1.04it/s]Loading train:  56%|█████▌    | 160/285 [03:16<01:58,  1.06it/s]Loading train:  56%|█████▋    | 161/285 [03:17<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [03:18<01:56,  1.06it/s]Loading train:  57%|█████▋    | 163/285 [03:19<01:53,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [03:20<01:55,  1.04it/s]Loading train:  58%|█████▊    | 165/285 [03:21<01:50,  1.08it/s]Loading train:  58%|█████▊    | 166/285 [03:22<01:59,  1.00s/it]Loading train:  59%|█████▊    | 167/285 [03:23<02:06,  1.07s/it]Loading train:  59%|█████▉    | 168/285 [03:24<02:01,  1.03s/it]Loading train:  59%|█████▉    | 169/285 [03:25<01:58,  1.02s/it]Loading train:  60%|█████▉    | 170/285 [03:26<01:56,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:27<01:54,  1.01s/it]Loading train:  60%|██████    | 172/285 [03:28<01:55,  1.02s/it]Loading train:  61%|██████    | 173/285 [03:29<01:59,  1.06s/it]Loading train:  61%|██████    | 174/285 [03:30<01:48,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [03:31<01:46,  1.03it/s]Loading train:  62%|██████▏   | 176/285 [03:32<01:49,  1.01s/it]Loading train:  62%|██████▏   | 177/285 [03:33<01:49,  1.02s/it]Loading train:  62%|██████▏   | 178/285 [03:34<01:46,  1.00it/s]Loading train:  63%|██████▎   | 179/285 [03:36<01:52,  1.07s/it]Loading train:  63%|██████▎   | 180/285 [03:37<01:56,  1.11s/it]Loading train:  64%|██████▎   | 181/285 [03:38<02:00,  1.15s/it]Loading train:  64%|██████▍   | 182/285 [03:39<02:05,  1.22s/it]Loading train:  64%|██████▍   | 183/285 [03:40<01:58,  1.16s/it]Loading train:  65%|██████▍   | 184/285 [03:42<01:55,  1.15s/it]Loading train:  65%|██████▍   | 185/285 [03:43<01:56,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [03:44<02:05,  1.26s/it]Loading train:  66%|██████▌   | 187/285 [03:45<02:03,  1.26s/it]Loading train:  66%|██████▌   | 188/285 [03:47<02:04,  1.28s/it]Loading train:  66%|██████▋   | 189/285 [03:48<01:52,  1.17s/it]Loading train:  67%|██████▋   | 190/285 [03:49<01:50,  1.16s/it]Loading train:  67%|██████▋   | 191/285 [03:50<01:46,  1.14s/it]Loading train:  67%|██████▋   | 192/285 [03:51<01:42,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [03:52<01:34,  1.02s/it]Loading train:  68%|██████▊   | 194/285 [03:53<01:34,  1.04s/it]Loading train:  68%|██████▊   | 195/285 [03:54<01:41,  1.12s/it]Loading train:  69%|██████▉   | 196/285 [03:56<01:54,  1.29s/it]Loading train:  69%|██████▉   | 197/285 [03:57<01:57,  1.34s/it]Loading train:  69%|██████▉   | 198/285 [03:58<01:49,  1.26s/it]Loading train:  70%|██████▉   | 199/285 [04:00<01:46,  1.24s/it]Loading train:  70%|███████   | 200/285 [04:01<01:44,  1.23s/it]Loading train:  71%|███████   | 201/285 [04:02<01:52,  1.34s/it]Loading train:  71%|███████   | 202/285 [04:03<01:39,  1.20s/it]Loading train:  71%|███████   | 203/285 [04:04<01:35,  1.16s/it]Loading train:  72%|███████▏  | 204/285 [04:05<01:30,  1.11s/it]Loading train:  72%|███████▏  | 205/285 [04:06<01:27,  1.09s/it]Loading train:  72%|███████▏  | 206/285 [04:07<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [04:08<01:23,  1.08s/it]Loading train:  73%|███████▎  | 208/285 [04:10<01:31,  1.19s/it]Loading train:  73%|███████▎  | 209/285 [04:12<01:46,  1.40s/it]Loading train:  74%|███████▎  | 210/285 [04:13<01:41,  1.36s/it]Loading train:  74%|███████▍  | 211/285 [04:14<01:41,  1.37s/it]Loading train:  74%|███████▍  | 212/285 [04:16<01:39,  1.36s/it]Loading train:  75%|███████▍  | 213/285 [04:17<01:33,  1.30s/it]Loading train:  75%|███████▌  | 214/285 [04:18<01:33,  1.32s/it]Loading train:  75%|███████▌  | 215/285 [04:20<01:36,  1.38s/it]Loading train:  76%|███████▌  | 216/285 [04:21<01:33,  1.35s/it]Loading train:  76%|███████▌  | 217/285 [04:23<01:43,  1.53s/it]Loading train:  76%|███████▋  | 218/285 [04:24<01:37,  1.45s/it]Loading train:  77%|███████▋  | 219/285 [04:26<01:33,  1.42s/it]Loading train:  77%|███████▋  | 220/285 [04:27<01:30,  1.38s/it]Loading train:  78%|███████▊  | 221/285 [04:28<01:24,  1.31s/it]Loading train:  78%|███████▊  | 222/285 [04:30<01:31,  1.45s/it]Loading train:  78%|███████▊  | 223/285 [04:31<01:26,  1.40s/it]Loading train:  79%|███████▊  | 224/285 [04:33<01:29,  1.46s/it]Loading train:  79%|███████▉  | 225/285 [04:34<01:27,  1.45s/it]Loading train:  79%|███████▉  | 226/285 [04:36<01:33,  1.58s/it]Loading train:  80%|███████▉  | 227/285 [04:38<01:28,  1.53s/it]Loading train:  80%|████████  | 228/285 [04:39<01:31,  1.61s/it]Loading train:  80%|████████  | 229/285 [04:41<01:24,  1.50s/it]Loading train:  81%|████████  | 230/285 [04:42<01:16,  1.40s/it]Loading train:  81%|████████  | 231/285 [04:43<01:14,  1.37s/it]Loading train:  81%|████████▏ | 232/285 [04:45<01:14,  1.41s/it]Loading train:  82%|████████▏ | 233/285 [04:46<01:13,  1.41s/it]Loading train:  82%|████████▏ | 234/285 [04:47<01:12,  1.42s/it]Loading train:  82%|████████▏ | 235/285 [04:49<01:12,  1.44s/it]Loading train:  83%|████████▎ | 236/285 [04:51<01:15,  1.55s/it]Loading train:  83%|████████▎ | 237/285 [04:52<01:17,  1.61s/it]Loading train:  84%|████████▎ | 238/285 [04:54<01:18,  1.68s/it]Loading train:  84%|████████▍ | 239/285 [04:56<01:16,  1.66s/it]Loading train:  84%|████████▍ | 240/285 [04:58<01:15,  1.67s/it]Loading train:  85%|████████▍ | 241/285 [04:59<01:11,  1.64s/it]Loading train:  85%|████████▍ | 242/285 [05:01<01:08,  1.60s/it]Loading train:  85%|████████▌ | 243/285 [05:02<01:04,  1.53s/it]Loading train:  86%|████████▌ | 244/285 [05:04<01:04,  1.58s/it]Loading train:  86%|████████▌ | 245/285 [05:05<01:02,  1.55s/it]Loading train:  86%|████████▋ | 246/285 [05:07<01:03,  1.64s/it]Loading train:  87%|████████▋ | 247/285 [05:09<01:06,  1.74s/it]Loading train:  87%|████████▋ | 248/285 [05:11<01:02,  1.69s/it]Loading train:  87%|████████▋ | 249/285 [05:12<00:54,  1.52s/it]Loading train:  88%|████████▊ | 250/285 [05:13<00:49,  1.42s/it]Loading train:  88%|████████▊ | 251/285 [05:14<00:48,  1.42s/it]Loading train:  88%|████████▊ | 252/285 [05:16<00:49,  1.49s/it]Loading train:  89%|████████▉ | 253/285 [05:18<00:51,  1.61s/it]Loading train:  89%|████████▉ | 254/285 [05:20<00:50,  1.62s/it]Loading train:  89%|████████▉ | 255/285 [05:21<00:45,  1.53s/it]Loading train:  90%|████████▉ | 256/285 [05:22<00:40,  1.38s/it]Loading train:  90%|█████████ | 257/285 [05:23<00:39,  1.40s/it]Loading train:  91%|█████████ | 258/285 [05:25<00:38,  1.41s/it]Loading train:  91%|█████████ | 259/285 [05:26<00:35,  1.35s/it]Loading train:  91%|█████████ | 260/285 [05:28<00:37,  1.49s/it]Loading train:  92%|█████████▏| 261/285 [05:29<00:35,  1.47s/it]Loading train:  92%|█████████▏| 262/285 [05:31<00:33,  1.43s/it]Loading train:  92%|█████████▏| 263/285 [05:32<00:29,  1.36s/it]Loading train:  93%|█████████▎| 264/285 [05:33<00:27,  1.33s/it]Loading train:  93%|█████████▎| 265/285 [05:35<00:27,  1.40s/it]Loading train:  93%|█████████▎| 266/285 [05:36<00:25,  1.32s/it]Loading train:  94%|█████████▎| 267/285 [05:37<00:23,  1.28s/it]Loading train:  94%|█████████▍| 268/285 [05:38<00:21,  1.27s/it]Loading train:  94%|█████████▍| 269/285 [05:39<00:20,  1.26s/it]Loading train:  95%|█████████▍| 270/285 [05:40<00:18,  1.21s/it]Loading train:  95%|█████████▌| 271/285 [05:42<00:16,  1.20s/it]Loading train:  95%|█████████▌| 272/285 [05:43<00:15,  1.18s/it]Loading train:  96%|█████████▌| 273/285 [05:44<00:15,  1.31s/it]Loading train:  96%|█████████▌| 274/285 [05:46<00:16,  1.46s/it]Loading train:  96%|█████████▋| 275/285 [05:48<00:16,  1.65s/it]Loading train:  97%|█████████▋| 276/285 [05:50<00:14,  1.59s/it]Loading train:  97%|█████████▋| 277/285 [05:51<00:11,  1.43s/it]Loading train:  98%|█████████▊| 278/285 [05:52<00:09,  1.43s/it]Loading train:  98%|█████████▊| 279/285 [05:54<00:08,  1.42s/it]Loading train:  98%|█████████▊| 280/285 [05:55<00:06,  1.37s/it]Loading train:  99%|█████████▊| 281/285 [05:57<00:05,  1.47s/it]Loading train:  99%|█████████▉| 282/285 [05:58<00:04,  1.48s/it]Loading train:  99%|█████████▉| 283/285 [06:00<00:03,  1.55s/it]Loading train: 100%|█████████▉| 284/285 [06:01<00:01,  1.54s/it]Loading train: 100%|██████████| 285/285 [06:03<00:00,  1.50s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 64.55it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 63.92it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:04, 63.49it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:04, 63.19it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:03, 62.98it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:06, 37.89it/s]concatenating: train:  16%|█▌        | 46/285 [00:01<00:06, 36.17it/s]concatenating: train:  19%|█▊        | 53/285 [00:01<00:05, 41.84it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:04, 48.17it/s]concatenating: train:  25%|██▍       | 71/285 [00:01<00:03, 56.61it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:03, 65.83it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:02, 67.34it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:03, 48.83it/s]concatenating: train:  37%|███▋      | 105/285 [00:02<00:04, 41.84it/s]concatenating: train:  41%|████▏     | 118/285 [00:02<00:03, 52.28it/s]concatenating: train:  46%|████▋     | 132/285 [00:02<00:02, 64.03it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:01, 75.00it/s]concatenating: train:  55%|█████▌    | 157/285 [00:02<00:01, 83.81it/s]concatenating: train:  59%|█████▉    | 169/285 [00:02<00:01, 92.14it/s]concatenating: train:  64%|██████▍   | 183/285 [00:02<00:01, 100.89it/s]concatenating: train:  68%|██████▊   | 195/285 [00:03<00:01, 63.18it/s] concatenating: train:  72%|███████▏  | 205/285 [00:03<00:01, 63.46it/s]concatenating: train:  75%|███████▌  | 214/285 [00:03<00:01, 60.13it/s]concatenating: train:  78%|███████▊  | 222/285 [00:03<00:01, 60.82it/s]concatenating: train:  81%|████████  | 230/285 [00:03<00:01, 40.84it/s]concatenating: train:  83%|████████▎ | 236/285 [00:03<00:01, 38.37it/s]concatenating: train:  87%|████████▋ | 248/285 [00:04<00:00, 47.98it/s]concatenating: train:  91%|█████████ | 260/285 [00:04<00:00, 58.51it/s]concatenating: train:  96%|█████████▌| 274/285 [00:04<00:00, 70.04it/s]concatenating: train: 100%|█████████▉| 284/285 [00:04<00:00, 70.52it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 63.78it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.66s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.73s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.70s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 45.70it/s]2019-07-11 01:14:13.338738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:14:13.338864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:14:13.338883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:14:13.338896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:14:13.339422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.55it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.57it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.12it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.13it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.70it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.73it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.94it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.49it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.70it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.45it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.23it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.07it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.93it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.77it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.45it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.76it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.52it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.27it/s] min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 231,593
Trainable params: 56,833
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 17s - loss: 1.8549 - acc: 0.6621 - mDice: 0.2363 - val_loss: 0.8768 - val_acc: 0.9254 - val_mDice: 0.4568

Epoch 00001: val_mDice improved from -inf to 0.45678, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.6137 - acc: 0.9094 - mDice: 0.5311 - val_loss: 0.5747 - val_acc: 0.9365 - val_mDice: 0.5553

Epoch 00002: val_mDice improved from 0.45678 to 0.55526, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.4837 - acc: 0.9143 - mDice: 0.6032 - val_loss: 0.4880 - val_acc: 0.9381 - val_mDice: 0.6093

Epoch 00003: val_mDice improved from 0.55526 to 0.60934, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.4346 - acc: 0.9187 - mDice: 0.6345 - val_loss: 0.4726 - val_acc: 0.9431 - val_mDice: 0.6184

Epoch 00004: val_mDice improved from 0.60934 to 0.61837, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4053 - acc: 0.9248 - mDice: 0.6539 - val_loss: 0.4854 - val_acc: 0.9448 - val_mDice: 0.6081

Epoch 00005: val_mDice did not improve from 0.61837
Epoch 6/300
 - 12s - loss: 0.3853 - acc: 0.9328 - mDice: 0.6673 - val_loss: 0.4605 - val_acc: 0.9530 - val_mDice: 0.6216

Epoch 00006: val_mDice improved from 0.61837 to 0.62161, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.3695 - acc: 0.9405 - mDice: 0.6778 - val_loss: 0.4620 - val_acc: 0.9533 - val_mDice: 0.6210

Epoch 00007: val_mDice did not improve from 0.62161
Epoch 8/300
 - 13s - loss: 0.3557 - acc: 0.9448 - mDice: 0.6871 - val_loss: 0.4550 - val_acc: 0.9525 - val_mDice: 0.6260

Epoch 00008: val_mDice improved from 0.62161 to 0.62599, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.3440 - acc: 0.9471 - mDice: 0.6951 - val_loss: 0.4319 - val_acc: 0.9537 - val_mDice: 0.6391

Epoch 00009: val_mDice improved from 0.62599 to 0.63912, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.3353 - acc: 0.9481 - mDice: 0.7013 - val_loss: 0.4512 - val_acc: 0.9514 - val_mDice: 0.6277

Epoch 00010: val_mDice did not improve from 0.63912
Epoch 11/300
 - 12s - loss: 0.3279 - acc: 0.9488 - mDice: 0.7066 - val_loss: 0.4447 - val_acc: 0.9543 - val_mDice: 0.6311

Epoch 00011: val_mDice did not improve from 0.63912
Epoch 12/300
 - 13s - loss: 0.3220 - acc: 0.9495 - mDice: 0.7110 - val_loss: 0.4549 - val_acc: 0.9518 - val_mDice: 0.6260

Epoch 00012: val_mDice did not improve from 0.63912
Epoch 13/300
 - 12s - loss: 0.3164 - acc: 0.9500 - mDice: 0.7152 - val_loss: 0.4522 - val_acc: 0.9526 - val_mDice: 0.6264

Epoch 00013: val_mDice did not improve from 0.63912
Epoch 14/300
 - 12s - loss: 0.3120 - acc: 0.9505 - mDice: 0.7183 - val_loss: 0.4502 - val_acc: 0.9542 - val_mDice: 0.6286

Epoch 00014: val_mDice did not improve from 0.63912
Epoch 15/300
 - 12s - loss: 0.3078 - acc: 0.9509 - mDice: 0.7215 - val_loss: 0.4534 - val_acc: 0.9523 - val_mDice: 0.6276

Epoch 00015: val_mDice did not improve from 0.63912
Epoch 16/300
 - 13s - loss: 0.3017 - acc: 0.9513 - mDice: 0.7260 - val_loss: 0.4556 - val_acc: 0.9519 - val_mDice: 0.6262

Epoch 00016: val_mDice did not improve from 0.63912
Epoch 17/300
 - 12s - loss: 0.2992 - acc: 0.9516 - mDice: 0.7280 - val_loss: 0.4612 - val_acc: 0.9529 - val_mDice: 0.6207

Epoch 00017: val_mDice did not improve from 0.63912
Epoch 18/300
 - 13s - loss: 0.2970 - acc: 0.9519 - mDice: 0.7298 - val_loss: 0.4534 - val_acc: 0.9541 - val_mDice: 0.6263

Epoch 00018: val_mDice did not improve from 0.63912
Epoch 19/300
 - 12s - loss: 0.2955 - acc: 0.9519 - mDice: 0.7309 - val_loss: 0.4687 - val_acc: 0.9522 - val_mDice: 0.6205

Epoch 00019: val_mDice did not improve from 0.63912
Epoch 20/300
 - 12s - loss: 0.2926 - acc: 0.9524 - mDice: 0.7343 - val_loss: 0.4996 - val_acc: 0.9467 - val_mDice: 0.5975

Epoch 00020: val_mDice did not improve from 0.63912
Epoch 21/300
 - 12s - loss: 0.3259 - acc: 0.9500 - mDice: 0.7097 - val_loss: 0.4490 - val_acc: 0.9549 - val_mDice: 0.6294

Epoch 00021: val_mDice did not improve from 0.63912
Epoch 22/300
 - 12s - loss: 0.2907 - acc: 0.9524 - mDice: 0.7344 - val_loss: 0.4466 - val_acc: 0.9518 - val_mDice: 0.6301

Epoch 00022: val_mDice did not improve from 0.63912
Epoch 23/300
 - 13s - loss: 0.2844 - acc: 0.9527 - mDice: 0.7391 - val_loss: 0.4600 - val_acc: 0.9541 - val_mDice: 0.6275

Epoch 00023: val_mDice did not improve from 0.63912
Epoch 24/300
 - 12s - loss: 0.2804 - acc: 0.9530 - mDice: 0.7423 - val_loss: 0.4588 - val_acc: 0.9531 - val_mDice: 0.6244

Epoch 00024: val_mDice did not improve from 0.63912
Epoch 25/300
 - 12s - loss: 0.2773 - acc: 0.9534 - mDice: 0.7447 - val_loss: 0.4621 - val_acc: 0.9515 - val_mDice: 0.6239

Epoch 00025: val_mDice did not improve from 0.63912
Epoch 26/300
 - 12s - loss: 0.2755 - acc: 0.9535 - mDice: 0.7461 - val_loss: 0.4582 - val_acc: 0.9520 - val_mDice: 0.6277

Epoch 00026: val_mDice did not improve from 0.63912
Epoch 27/300
 - 12s - loss: 0.2738 - acc: 0.9536 - mDice: 0.7475 - val_loss: 0.4556 - val_acc: 0.9536 - val_mDice: 0.6263

Epoch 00027: val_mDice did not improve from 0.63912
Epoch 28/300
 - 13s - loss: 0.2728 - acc: 0.9536 - mDice: 0.7482 - val_loss: 0.4684 - val_acc: 0.9526 - val_mDice: 0.6204

Epoch 00028: val_mDice did not improve from 0.63912
Epoch 29/300
 - 12s - loss: 0.2716 - acc: 0.9538 - mDice: 0.7492 - val_loss: 0.4654 - val_acc: 0.9509 - val_mDice: 0.6218

Epoch 00029: val_mDice did not improve from 0.63912
Epoch 30/300
 - 13s - loss: 0.2688 - acc: 0.9539 - mDice: 0.7513 - val_loss: 0.4734 - val_acc: 0.9526 - val_mDice: 0.6156

Epoch 00030: val_mDice did not improve from 0.63912
Epoch 31/300
 - 12s - loss: 0.2666 - acc: 0.9542 - mDice: 0.7531 - val_loss: 0.4561 - val_acc: 0.9519 - val_mDice: 0.6275

Epoch 00031: val_mDice did not improve from 0.63912
Epoch 32/300
 - 12s - loss: 0.2660 - acc: 0.9542 - mDice: 0.7536 - val_loss: 0.4652 - val_acc: 0.9542 - val_mDice: 0.6244

Epoch 00032: val_mDice did not improve from 0.63912
Epoch 33/300
 - 12s - loss: 0.2650 - acc: 0.9544 - mDice: 0.7544 - val_loss: 0.4852 - val_acc: 0.9542 - val_mDice: 0.6126

Epoch 00033: val_mDice did not improve from 0.63912
Epoch 34/300
 - 12s - loss: 0.2636 - acc: 0.9544 - mDice: 0.7555 - val_loss: 0.4809 - val_acc: 0.9521 - val_mDice: 0.6151

Epoch 00034: val_mDice did not improve from 0.63912
Epoch 35/300
 - 12s - loss: 0.2618 - acc: 0.9545 - mDice: 0.7569 - val_loss: 0.4584 - val_acc: 0.9530 - val_mDice: 0.6292

Epoch 00035: val_mDice did not improve from 0.63912
Epoch 36/300
 - 12s - loss: 0.2609 - acc: 0.9546 - mDice: 0.7577 - val_loss: 0.4669 - val_acc: 0.9538 - val_mDice: 0.6256

Epoch 00036: val_mDice did not improve from 0.63912
Epoch 37/300
 - 13s - loss: 0.2585 - acc: 0.9547 - mDice: 0.7595 - val_loss: 0.4561 - val_acc: 0.9531 - val_mDice: 0.6258

Epoch 00037: val_mDice did not improve from 0.63912
Epoch 38/300
 - 12s - loss: 0.2600 - acc: 0.9546 - mDice: 0.7583 - val_loss: 0.4945 - val_acc: 0.9541 - val_mDice: 0.6064

Epoch 00038: val_mDice did not improve from 0.63912
Epoch 39/300
 - 13s - loss: 0.2576 - acc: 0.9548 - mDice: 0.7603 - val_loss: 0.4431 - val_acc: 0.9530 - val_mDice: 0.6333

Epoch 00039: val_mDice did not improve from 0.63912
Epoch 40/300
 - 12s - loss: 0.2556 - acc: 0.9550 - mDice: 0.7617 - val_loss: 0.4657 - val_acc: 0.9523 - val_mDice: 0.6209

Epoch 00040: val_mDice did not improve from 0.63912
Epoch 41/300
 - 12s - loss: 0.2542 - acc: 0.9551 - mDice: 0.7630 - val_loss: 0.5244 - val_acc: 0.9520 - val_mDice: 0.6013

Epoch 00041: val_mDice did not improve from 0.63912
Epoch 42/300
 - 13s - loss: 0.2534 - acc: 0.9552 - mDice: 0.7635 - val_loss: 0.4578 - val_acc: 0.9543 - val_mDice: 0.6260

Epoch 00042: val_mDice did not improve from 0.63912
Epoch 43/300
 - 12s - loss: 0.2525 - acc: 0.9552 - mDice: 0.7643 - val_loss: 0.4728 - val_acc: 0.9542 - val_mDice: 0.6204

Epoch 00043: val_mDice did not improve from 0.63912
Epoch 44/300
 - 13s - loss: 0.2528 - acc: 0.9553 - mDice: 0.7640 - val_loss: 0.4546 - val_acc: 0.9544 - val_mDice: 0.6262

Epoch 00044: val_mDice did not improve from 0.63912
Epoch 45/300
 - 12s - loss: 0.2513 - acc: 0.9554 - mDice: 0.7652 - val_loss: 0.4487 - val_acc: 0.9535 - val_mDice: 0.6319

Epoch 00045: val_mDice did not improve from 0.63912
Epoch 46/300
 - 12s - loss: 0.2500 - acc: 0.9555 - mDice: 0.7663 - val_loss: 0.4560 - val_acc: 0.9525 - val_mDice: 0.6257

Epoch 00046: val_mDice did not improve from 0.63912
Epoch 47/300
 - 13s - loss: 0.2507 - acc: 0.9555 - mDice: 0.7658 - val_loss: 0.4679 - val_acc: 0.9533 - val_mDice: 0.6214

Epoch 00047: val_mDice did not improve from 0.63912
Epoch 48/300
 - 12s - loss: 0.2497 - acc: 0.9555 - mDice: 0.7666 - val_loss: 0.4718 - val_acc: 0.9536 - val_mDice: 0.6236

Epoch 00048: val_mDice did not improve from 0.63912
Epoch 49/300
 - 13s - loss: 0.2478 - acc: 0.9557 - mDice: 0.7681 - val_loss: 0.4665 - val_acc: 0.9529 - val_mDice: 0.6222

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.49s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.24s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:03,  1.91s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:40,  1.84s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:24,  1.79s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:03,  1.72s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:27,  1.81s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:04,  1.74s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:14,  1.78s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:16,  1.79s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:56,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:16,  2.02s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:50,  1.94s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:06,  2.00s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:47,  1.94s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:44,  1.93s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:13,  2.05s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:31,  2.12s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:17,  2.08s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:00,  2.02s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:59,  2.04s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<09:14,  2.10s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:41,  1.98s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:47,  2.01s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<08:32,  1.96s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:51,  2.04s/it]predicting train subjects:   9%|▉         | 26/285 [00:51<08:59,  2.08s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:40,  2.02s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:26,  1.97s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:27,  1.98s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:32,  2.01s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:34,  2.03s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:07,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:12,  1.96s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:07,  1.94s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:23,  2.01s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<07:55,  1.91s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<08:07,  1.96s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<08:26,  2.05s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:00,  1.95s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:01,  1.97s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<07:43,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:21<07:32,  1.86s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:40,  1.90s/it]predicting train subjects:  15%|█▌        | 44/285 [01:26<07:56,  1.98s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:31,  1.88s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:49,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:28,  1.88s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<07:35,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<07:51,  2.00s/it]predicting train subjects:  18%|█▊        | 50/285 [01:37<07:57,  2.03s/it]predicting train subjects:  18%|█▊        | 51/285 [01:40<08:18,  2.13s/it]predicting train subjects:  18%|█▊        | 52/285 [01:41<07:44,  1.99s/it]predicting train subjects:  19%|█▊        | 53/285 [01:43<07:41,  1.99s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<07:54,  2.06s/it]predicting train subjects:  19%|█▉        | 55/285 [01:47<07:33,  1.97s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<07:39,  2.01s/it]predicting train subjects:  20%|██        | 57/285 [01:51<07:28,  1.97s/it]predicting train subjects:  20%|██        | 58/285 [01:53<07:26,  1.97s/it]predicting train subjects:  21%|██        | 59/285 [01:55<07:35,  2.02s/it]predicting train subjects:  21%|██        | 60/285 [01:58<07:55,  2.11s/it]predicting train subjects:  21%|██▏       | 61/285 [01:59<07:21,  1.97s/it]predicting train subjects:  22%|██▏       | 62/285 [02:01<07:17,  1.96s/it]predicting train subjects:  22%|██▏       | 63/285 [02:03<07:12,  1.95s/it]predicting train subjects:  22%|██▏       | 64/285 [02:05<07:01,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:07<06:56,  1.89s/it]predicting train subjects:  23%|██▎       | 66/285 [02:09<07:00,  1.92s/it]predicting train subjects:  24%|██▎       | 67/285 [02:11<06:54,  1.90s/it]predicting train subjects:  24%|██▍       | 68/285 [02:13<06:40,  1.84s/it]predicting train subjects:  24%|██▍       | 69/285 [02:14<06:36,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:16<06:39,  1.86s/it]predicting train subjects:  25%|██▍       | 71/285 [02:18<06:38,  1.86s/it]predicting train subjects:  25%|██▌       | 72/285 [02:20<06:27,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:22<06:39,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:24<06:35,  1.87s/it]predicting train subjects:  26%|██▋       | 75/285 [02:26<06:42,  1.91s/it]predicting train subjects:  27%|██▋       | 76/285 [02:28<06:52,  1.97s/it]predicting train subjects:  27%|██▋       | 77/285 [02:30<06:36,  1.91s/it]predicting train subjects:  27%|██▋       | 78/285 [02:31<06:22,  1.85s/it]predicting train subjects:  28%|██▊       | 79/285 [02:33<06:24,  1.87s/it]predicting train subjects:  28%|██▊       | 80/285 [02:35<06:30,  1.91s/it]predicting train subjects:  28%|██▊       | 81/285 [02:37<06:25,  1.89s/it]predicting train subjects:  29%|██▉       | 82/285 [02:39<06:28,  1.91s/it]predicting train subjects:  29%|██▉       | 83/285 [02:41<06:19,  1.88s/it]predicting train subjects:  29%|██▉       | 84/285 [02:43<06:08,  1.83s/it]predicting train subjects:  30%|██▉       | 85/285 [02:45<06:17,  1.89s/it]predicting train subjects:  30%|███       | 86/285 [02:47<06:24,  1.93s/it]predicting train subjects:  31%|███       | 87/285 [02:49<06:19,  1.92s/it]predicting train subjects:  31%|███       | 88/285 [02:50<06:13,  1.89s/it]predicting train subjects:  31%|███       | 89/285 [02:52<06:14,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:54<06:12,  1.91s/it]predicting train subjects:  32%|███▏      | 91/285 [02:56<06:02,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:58<06:12,  1.93s/it]predicting train subjects:  33%|███▎      | 93/285 [03:00<06:05,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [03:02<06:04,  1.91s/it]predicting train subjects:  33%|███▎      | 95/285 [03:04<06:09,  1.94s/it]predicting train subjects:  34%|███▎      | 96/285 [03:06<06:12,  1.97s/it]predicting train subjects:  34%|███▍      | 97/285 [03:08<06:12,  1.98s/it]predicting train subjects:  34%|███▍      | 98/285 [03:10<06:07,  1.96s/it]predicting train subjects:  35%|███▍      | 99/285 [03:12<06:06,  1.97s/it]predicting train subjects:  35%|███▌      | 100/285 [03:14<06:08,  1.99s/it]predicting train subjects:  35%|███▌      | 101/285 [03:16<05:50,  1.90s/it]predicting train subjects:  36%|███▌      | 102/285 [03:17<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:19<05:48,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:21<05:49,  1.93s/it]predicting train subjects:  37%|███▋      | 105/285 [03:23<05:49,  1.94s/it]predicting train subjects:  37%|███▋      | 106/285 [03:25<05:36,  1.88s/it]predicting train subjects:  38%|███▊      | 107/285 [03:27<05:28,  1.84s/it]predicting train subjects:  38%|███▊      | 108/285 [03:29<05:20,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:30<05:24,  1.84s/it]predicting train subjects:  39%|███▊      | 110/285 [03:33<05:41,  1.95s/it]predicting train subjects:  39%|███▉      | 111/285 [03:35<05:47,  2.00s/it]predicting train subjects:  39%|███▉      | 112/285 [03:37<05:52,  2.03s/it]predicting train subjects:  40%|███▉      | 113/285 [03:39<05:47,  2.02s/it]predicting train subjects:  40%|████      | 114/285 [03:41<05:44,  2.01s/it]predicting train subjects:  40%|████      | 115/285 [03:43<05:43,  2.02s/it]predicting train subjects:  41%|████      | 116/285 [03:45<05:48,  2.06s/it]predicting train subjects:  41%|████      | 117/285 [03:47<05:35,  2.00s/it]predicting train subjects:  41%|████▏     | 118/285 [03:49<05:24,  1.94s/it]predicting train subjects:  42%|████▏     | 119/285 [03:51<05:29,  1.99s/it]predicting train subjects:  42%|████▏     | 120/285 [03:53<05:23,  1.96s/it]predicting train subjects:  42%|████▏     | 121/285 [03:55<05:17,  1.94s/it]predicting train subjects:  43%|████▎     | 122/285 [03:56<05:04,  1.87s/it]predicting train subjects:  43%|████▎     | 123/285 [03:58<04:51,  1.80s/it]predicting train subjects:  44%|████▎     | 124/285 [04:00<04:48,  1.79s/it]predicting train subjects:  44%|████▍     | 125/285 [04:02<04:52,  1.83s/it]predicting train subjects:  44%|████▍     | 126/285 [04:03<04:47,  1.81s/it]predicting train subjects:  45%|████▍     | 127/285 [04:05<04:37,  1.76s/it]predicting train subjects:  45%|████▍     | 128/285 [04:07<04:42,  1.80s/it]predicting train subjects:  45%|████▌     | 129/285 [04:09<04:41,  1.81s/it]predicting train subjects:  46%|████▌     | 130/285 [04:11<04:45,  1.84s/it]predicting train subjects:  46%|████▌     | 131/285 [04:13<04:42,  1.84s/it]predicting train subjects:  46%|████▋     | 132/285 [04:14<04:37,  1.81s/it]predicting train subjects:  47%|████▋     | 133/285 [04:16<04:22,  1.73s/it]predicting train subjects:  47%|████▋     | 134/285 [04:17<04:16,  1.70s/it]predicting train subjects:  47%|████▋     | 135/285 [04:19<04:15,  1.70s/it]predicting train subjects:  48%|████▊     | 136/285 [04:21<04:08,  1.67s/it]predicting train subjects:  48%|████▊     | 137/285 [04:23<04:28,  1.82s/it]predicting train subjects:  48%|████▊     | 138/285 [04:25<04:18,  1.76s/it]predicting train subjects:  49%|████▉     | 139/285 [04:26<04:20,  1.78s/it]predicting train subjects:  49%|████▉     | 140/285 [04:28<04:20,  1.79s/it]predicting train subjects:  49%|████▉     | 141/285 [04:30<04:09,  1.73s/it]predicting train subjects:  50%|████▉     | 142/285 [04:31<04:00,  1.68s/it]predicting train subjects:  50%|█████     | 143/285 [04:33<03:59,  1.68s/it]predicting train subjects:  51%|█████     | 144/285 [04:35<04:08,  1.76s/it]predicting train subjects:  51%|█████     | 145/285 [04:37<03:59,  1.71s/it]predicting train subjects:  51%|█████     | 146/285 [04:38<04:03,  1.75s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:40<03:53,  1.69s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:42<03:53,  1.71s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:43<03:56,  1.74s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:45<03:50,  1.71s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:47<03:53,  1.74s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:49<03:49,  1.72s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:50<03:46,  1.71s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:52<03:53,  1.78s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:54<03:46,  1.74s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:56<03:50,  1.79s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:58<03:49,  1.79s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:59<03:49,  1.80s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:01<03:40,  1.75s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:03<03:37,  1.74s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:05<03:49,  1.85s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:07<03:38,  1.78s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:08<03:43,  1.83s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:10<03:41,  1.83s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:12<03:40,  1.84s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:14<03:31,  1.78s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:16<03:35,  1.83s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:18<03:32,  1.82s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:19<03:30,  1.81s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:21<03:32,  1.85s/it]predicting train subjects:  60%|██████    | 171/285 [05:23<03:31,  1.86s/it]predicting train subjects:  60%|██████    | 172/285 [05:25<03:24,  1.81s/it]predicting train subjects:  61%|██████    | 173/285 [05:27<03:22,  1.81s/it]predicting train subjects:  61%|██████    | 174/285 [05:28<03:13,  1.74s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:30<03:21,  1.83s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:32<03:23,  1.86s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:34<03:19,  1.84s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:36<03:10,  1.78s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:37<02:59,  1.69s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:39<03:09,  1.81s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:41<03:18,  1.91s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:43<03:18,  1.92s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:45<03:10,  1.87s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:47<03:02,  1.81s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:48<02:51,  1.71s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:50<02:57,  1.79s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:52<03:00,  1.84s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:54<02:58,  1.84s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:56<02:55,  1.83s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:57<02:46,  1.76s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:59<02:54,  1.86s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:01<02:54,  1.87s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:03<02:44,  1.79s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:05<02:39,  1.76s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:06<02:31,  1.68s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:08<02:43,  1.84s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:10<02:47,  1.91s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:13<02:52,  1.99s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:14<02:38,  1.85s/it]predicting train subjects:  70%|███████   | 200/285 [06:16<02:34,  1.81s/it]predicting train subjects:  71%|███████   | 201/285 [06:18<02:39,  1.89s/it]predicting train subjects:  71%|███████   | 202/285 [06:20<02:42,  1.96s/it]predicting train subjects:  71%|███████   | 203/285 [06:22<02:40,  1.95s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:24<02:33,  1.90s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:25<02:25,  1.82s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:27<02:16,  1.73s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:29<02:28,  1.90s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:32<02:37,  2.05s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:34<02:35,  2.05s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:35<02:23,  1.91s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:37<02:15,  1.83s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:39<02:20,  1.92s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:41<02:19,  1.93s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:43<02:14,  1.89s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:45<02:15,  1.94s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:47<02:09,  1.88s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:49<02:11,  1.93s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:51<02:12,  1.98s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:53<02:15,  2.05s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:54<02:04,  1.91s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:56<02:01,  1.90s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:58<02:03,  1.97s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:00<01:56,  1.88s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:02<01:50,  1.81s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:03<01:41,  1.70s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:05<01:45,  1.79s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:07<01:49,  1.88s/it]predicting train subjects:  80%|████████  | 228/285 [07:10<01:56,  2.04s/it]predicting train subjects:  80%|████████  | 229/285 [07:12<01:55,  2.06s/it]predicting train subjects:  81%|████████  | 230/285 [07:14<01:46,  1.94s/it]predicting train subjects:  81%|████████  | 231/285 [07:15<01:42,  1.90s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:17<01:40,  1.90s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:19<01:35,  1.84s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:21<01:40,  1.97s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:23<01:33,  1.88s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:25<01:38,  2.01s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:27<01:38,  2.05s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:30<01:38,  2.10s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:31<01:33,  2.03s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:33<01:26,  1.93s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:35<01:23,  1.90s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:37<01:19,  1.84s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:38<01:13,  1.75s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:40<01:16,  1.87s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:42<01:14,  1.86s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:45<01:18,  2.01s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:47<01:16,  2.01s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:48<01:13,  1.99s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:50<01:07,  1.87s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:52<01:03,  1.81s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:53<01:00,  1.78s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:55<00:56,  1.71s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:57<00:58,  1.84s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:59<01:00,  1.95s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:01<00:58,  1.95s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:03<00:53,  1.83s/it]predicting train subjects:  90%|█████████ | 257/285 [08:05<00:50,  1.79s/it]predicting train subjects:  91%|█████████ | 258/285 [08:07<00:51,  1.92s/it]predicting train subjects:  91%|█████████ | 259/285 [08:09<00:52,  2.01s/it]predicting train subjects:  91%|█████████ | 260/285 [08:11<00:48,  1.94s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:13<00:45,  1.90s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:14<00:41,  1.82s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:16<00:38,  1.75s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:18<00:38,  1.81s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:20<00:36,  1.84s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:21<00:33,  1.75s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:23<00:31,  1.76s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:25<00:31,  1.87s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:27<00:29,  1.87s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:29<00:28,  1.87s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:31<00:25,  1.82s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:33<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:34<00:21,  1.76s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:36<00:19,  1.75s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:38<00:18,  1.85s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:40<00:17,  1.91s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:41<00:14,  1.82s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:43<00:12,  1.73s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:45<00:10,  1.72s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:46<00:08,  1.67s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:48<00:06,  1.65s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:49<00:04,  1.61s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:51<00:03,  1.70s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:53<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [08:55<00:00,  1.80s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:33,  1.60s/it]Loading train:   1%|          | 2/285 [00:02<07:02,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<07:01,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:05<06:36,  1.41s/it]Loading train:   2%|▏         | 5/285 [00:07<06:51,  1.47s/it]Loading train:   2%|▏         | 6/285 [00:08<06:38,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<07:09,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:11<06:58,  1.51s/it]Loading train:   3%|▎         | 9/285 [00:13<07:09,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:47,  1.48s/it]Loading train:   4%|▍         | 11/285 [00:15<06:08,  1.34s/it]Loading train:   4%|▍         | 12/285 [00:16<05:47,  1.27s/it]Loading train:   5%|▍         | 13/285 [00:17<05:22,  1.19s/it]Loading train:   5%|▍         | 14/285 [00:19<05:22,  1.19s/it]Loading train:   5%|▌         | 15/285 [00:20<05:20,  1.19s/it]Loading train:   6%|▌         | 16/285 [00:21<04:57,  1.11s/it]Loading train:   6%|▌         | 17/285 [00:22<05:03,  1.13s/it]Loading train:   6%|▋         | 18/285 [00:23<04:41,  1.05s/it]Loading train:   7%|▋         | 19/285 [00:24<04:38,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:25<04:38,  1.05s/it]Loading train:   7%|▋         | 21/285 [00:26<04:35,  1.04s/it]Loading train:   8%|▊         | 22/285 [00:27<04:28,  1.02s/it]Loading train:   8%|▊         | 23/285 [00:28<04:36,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:29<04:27,  1.02s/it]Loading train:   9%|▉         | 25/285 [00:30<04:30,  1.04s/it]Loading train:   9%|▉         | 26/285 [00:31<04:43,  1.10s/it]Loading train:   9%|▉         | 27/285 [00:32<04:36,  1.07s/it]Loading train:  10%|▉         | 28/285 [00:33<04:18,  1.00s/it]Loading train:  10%|█         | 29/285 [00:34<04:25,  1.04s/it]Loading train:  11%|█         | 30/285 [00:35<04:29,  1.06s/it]Loading train:  11%|█         | 31/285 [00:36<04:30,  1.06s/it]Loading train:  11%|█         | 32/285 [00:38<04:38,  1.10s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:36,  1.10s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:30,  1.08s/it]Loading train:  12%|█▏        | 35/285 [00:41<04:40,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:46,  1.15s/it]Loading train:  13%|█▎        | 37/285 [00:43<04:36,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:44<04:20,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:16,  1.04s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:46,  1.17s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:44,  1.16s/it]Loading train:  15%|█▍        | 42/285 [00:49<04:47,  1.18s/it]Loading train:  15%|█▌        | 43/285 [00:50<04:42,  1.17s/it]Loading train:  15%|█▌        | 44/285 [00:51<04:51,  1.21s/it]Loading train:  16%|█▌        | 45/285 [00:52<04:21,  1.09s/it]Loading train:  16%|█▌        | 46/285 [00:53<04:12,  1.06s/it]Loading train:  16%|█▋        | 47/285 [00:54<04:19,  1.09s/it]Loading train:  17%|█▋        | 48/285 [00:55<04:02,  1.02s/it]Loading train:  17%|█▋        | 49/285 [00:56<04:10,  1.06s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:10,  1.06s/it]Loading train:  18%|█▊        | 51/285 [00:58<04:01,  1.03s/it]Loading train:  18%|█▊        | 52/285 [00:59<03:44,  1.04it/s]Loading train:  19%|█▊        | 53/285 [01:00<04:00,  1.03s/it]Loading train:  19%|█▉        | 54/285 [01:01<03:58,  1.03s/it]Loading train:  19%|█▉        | 55/285 [01:02<03:39,  1.05it/s]Loading train:  20%|█▉        | 56/285 [01:03<03:42,  1.03it/s]Loading train:  20%|██        | 57/285 [01:04<03:48,  1.00s/it]Loading train:  20%|██        | 58/285 [01:05<03:43,  1.01it/s]Loading train:  21%|██        | 59/285 [01:06<03:49,  1.01s/it]Loading train:  21%|██        | 60/285 [01:07<03:53,  1.04s/it]Loading train:  21%|██▏       | 61/285 [01:08<03:53,  1.04s/it]Loading train:  22%|██▏       | 62/285 [01:10<03:59,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:10<03:48,  1.03s/it]Loading train:  22%|██▏       | 64/285 [01:12<04:10,  1.13s/it]Loading train:  23%|██▎       | 65/285 [01:14<04:50,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:59,  1.37s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:50,  1.33s/it]Loading train:  24%|██▍       | 68/285 [01:17<04:30,  1.25s/it]Loading train:  24%|██▍       | 69/285 [01:18<04:22,  1.21s/it]Loading train:  25%|██▍       | 70/285 [01:20<04:14,  1.18s/it]Loading train:  25%|██▍       | 71/285 [01:21<04:07,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:22<03:47,  1.07s/it]Loading train:  26%|██▌       | 73/285 [01:23<03:40,  1.04s/it]Loading train:  26%|██▌       | 74/285 [01:23<03:32,  1.01s/it]Loading train:  26%|██▋       | 75/285 [01:25<03:39,  1.04s/it]Loading train:  27%|██▋       | 76/285 [01:26<03:40,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:27<03:40,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:28<03:26,  1.00it/s]Loading train:  28%|██▊       | 79/285 [01:29<03:41,  1.08s/it]Loading train:  28%|██▊       | 80/285 [01:30<03:39,  1.07s/it]Loading train:  28%|██▊       | 81/285 [01:31<03:23,  1.00it/s]Loading train:  29%|██▉       | 82/285 [01:32<03:34,  1.06s/it]Loading train:  29%|██▉       | 83/285 [01:33<03:26,  1.02s/it]Loading train:  29%|██▉       | 84/285 [01:34<03:10,  1.05it/s]Loading train:  30%|██▉       | 85/285 [01:35<03:31,  1.06s/it]Loading train:  30%|███       | 86/285 [01:36<03:49,  1.16s/it]Loading train:  31%|███       | 87/285 [01:37<03:40,  1.11s/it]Loading train:  31%|███       | 88/285 [01:38<03:24,  1.04s/it]Loading train:  31%|███       | 89/285 [01:39<03:20,  1.02s/it]Loading train:  32%|███▏      | 90/285 [01:40<03:17,  1.01s/it]Loading train:  32%|███▏      | 91/285 [01:41<03:07,  1.04it/s]Loading train:  32%|███▏      | 92/285 [01:42<03:20,  1.04s/it]Loading train:  33%|███▎      | 93/285 [01:43<03:13,  1.01s/it]Loading train:  33%|███▎      | 94/285 [01:44<03:12,  1.01s/it]Loading train:  33%|███▎      | 95/285 [01:45<03:14,  1.02s/it]Loading train:  34%|███▎      | 96/285 [01:46<03:14,  1.03s/it]Loading train:  34%|███▍      | 97/285 [01:47<03:05,  1.02it/s]Loading train:  34%|███▍      | 98/285 [01:48<03:08,  1.01s/it]Loading train:  35%|███▍      | 99/285 [01:49<03:07,  1.01s/it]Loading train:  35%|███▌      | 100/285 [01:50<03:04,  1.00it/s]Loading train:  35%|███▌      | 101/285 [01:51<03:01,  1.01it/s]Loading train:  36%|███▌      | 102/285 [01:52<03:00,  1.01it/s]Loading train:  36%|███▌      | 103/285 [01:53<03:05,  1.02s/it]Loading train:  36%|███▋      | 104/285 [01:55<03:16,  1.09s/it]Loading train:  37%|███▋      | 105/285 [01:55<03:00,  1.00s/it]Loading train:  37%|███▋      | 106/285 [01:56<02:51,  1.04it/s]Loading train:  38%|███▊      | 107/285 [01:57<02:52,  1.03it/s]Loading train:  38%|███▊      | 108/285 [01:58<02:47,  1.05it/s]Loading train:  38%|███▊      | 109/285 [01:59<02:57,  1.01s/it]Loading train:  39%|███▊      | 110/285 [02:00<02:57,  1.01s/it]Loading train:  39%|███▉      | 111/285 [02:01<03:01,  1.04s/it]Loading train:  39%|███▉      | 112/285 [02:03<03:18,  1.15s/it]Loading train:  40%|███▉      | 113/285 [02:04<03:11,  1.11s/it]Loading train:  40%|████      | 114/285 [02:05<03:09,  1.11s/it]Loading train:  40%|████      | 115/285 [02:06<03:01,  1.07s/it]Loading train:  41%|████      | 116/285 [02:07<03:09,  1.12s/it]Loading train:  41%|████      | 117/285 [02:08<02:56,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:09<02:49,  1.01s/it]Loading train:  42%|████▏     | 119/285 [02:10<02:46,  1.00s/it]Loading train:  42%|████▏     | 120/285 [02:11<02:36,  1.05it/s]Loading train:  42%|████▏     | 121/285 [02:12<02:59,  1.09s/it]Loading train:  43%|████▎     | 122/285 [02:13<03:03,  1.13s/it]Loading train:  43%|████▎     | 123/285 [02:15<03:31,  1.30s/it]Loading train:  44%|████▎     | 124/285 [02:16<03:18,  1.23s/it]Loading train:  44%|████▍     | 125/285 [02:17<03:05,  1.16s/it]Loading train:  44%|████▍     | 126/285 [02:18<02:45,  1.04s/it]Loading train:  45%|████▍     | 127/285 [02:19<02:43,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:20<02:36,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:21<02:35,  1.00it/s]Loading train:  46%|████▌     | 130/285 [02:22<02:26,  1.06it/s]Loading train:  46%|████▌     | 131/285 [02:23<02:29,  1.03it/s]Loading train:  46%|████▋     | 132/285 [02:24<02:32,  1.00it/s]Loading train:  47%|████▋     | 133/285 [02:25<02:30,  1.01it/s]Loading train:  47%|████▋     | 134/285 [02:26<02:20,  1.07it/s]Loading train:  47%|████▋     | 135/285 [02:26<02:14,  1.12it/s]Loading train:  48%|████▊     | 136/285 [02:27<02:12,  1.13it/s]Loading train:  48%|████▊     | 137/285 [02:28<02:19,  1.06it/s]Loading train:  48%|████▊     | 138/285 [02:29<02:13,  1.10it/s]Loading train:  49%|████▉     | 139/285 [02:30<02:16,  1.07it/s]Loading train:  49%|████▉     | 140/285 [02:31<02:18,  1.05it/s]Loading train:  49%|████▉     | 141/285 [02:32<02:12,  1.09it/s]Loading train:  50%|████▉     | 142/285 [02:33<02:19,  1.03it/s]Loading train:  50%|█████     | 143/285 [02:34<02:17,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:35<02:25,  1.03s/it]Loading train:  51%|█████     | 145/285 [02:36<02:25,  1.04s/it]Loading train:  51%|█████     | 146/285 [02:37<02:23,  1.04s/it]Loading train:  52%|█████▏    | 147/285 [02:38<02:19,  1.01s/it]Loading train:  52%|█████▏    | 148/285 [02:39<02:13,  1.02it/s]Loading train:  52%|█████▏    | 149/285 [02:40<02:19,  1.02s/it]Loading train:  53%|█████▎    | 150/285 [02:41<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:42<02:10,  1.03it/s]Loading train:  53%|█████▎    | 152/285 [02:43<02:15,  1.02s/it]Loading train:  54%|█████▎    | 153/285 [02:44<02:07,  1.03it/s]Loading train:  54%|█████▍    | 154/285 [02:45<02:14,  1.02s/it]Loading train:  54%|█████▍    | 155/285 [02:46<02:17,  1.06s/it]Loading train:  55%|█████▍    | 156/285 [02:47<02:12,  1.03s/it]Loading train:  55%|█████▌    | 157/285 [02:48<02:07,  1.00it/s]Loading train:  55%|█████▌    | 158/285 [02:49<02:09,  1.02s/it]Loading train:  56%|█████▌    | 159/285 [02:50<02:03,  1.02it/s]Loading train:  56%|█████▌    | 160/285 [02:51<01:56,  1.07it/s]Loading train:  56%|█████▋    | 161/285 [02:52<01:48,  1.15it/s]Loading train:  57%|█████▋    | 162/285 [02:53<01:51,  1.11it/s]Loading train:  57%|█████▋    | 163/285 [02:54<01:59,  1.02it/s]Loading train:  58%|█████▊    | 164/285 [02:55<01:58,  1.02it/s]Loading train:  58%|█████▊    | 165/285 [02:56<01:51,  1.07it/s]Loading train:  58%|█████▊    | 166/285 [02:57<01:55,  1.03it/s]Loading train:  59%|█████▊    | 167/285 [02:58<02:04,  1.06s/it]Loading train:  59%|█████▉    | 168/285 [02:59<01:57,  1.00s/it]Loading train:  59%|█████▉    | 169/285 [03:00<01:57,  1.01s/it]Loading train:  60%|█████▉    | 170/285 [03:01<01:44,  1.10it/s]Loading train:  60%|██████    | 171/285 [03:01<01:37,  1.17it/s]Loading train:  60%|██████    | 172/285 [03:02<01:36,  1.17it/s]Loading train:  61%|██████    | 173/285 [03:03<01:38,  1.13it/s]Loading train:  61%|██████    | 174/285 [03:04<01:39,  1.11it/s]Loading train:  61%|██████▏   | 175/285 [03:05<01:38,  1.12it/s]Loading train:  62%|██████▏   | 176/285 [03:06<01:41,  1.07it/s]Loading train:  62%|██████▏   | 177/285 [03:07<01:40,  1.07it/s]Loading train:  62%|██████▏   | 178/285 [03:08<01:35,  1.12it/s]Loading train:  63%|██████▎   | 179/285 [03:09<01:42,  1.04it/s]Loading train:  63%|██████▎   | 180/285 [03:10<01:43,  1.01it/s]Loading train:  64%|██████▎   | 181/285 [03:11<01:45,  1.01s/it]Loading train:  64%|██████▍   | 182/285 [03:12<01:39,  1.03it/s]Loading train:  64%|██████▍   | 183/285 [03:13<01:38,  1.04it/s]Loading train:  65%|██████▍   | 184/285 [03:14<01:37,  1.03it/s]Loading train:  65%|██████▍   | 185/285 [03:15<01:36,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [03:16<01:44,  1.06s/it]Loading train:  66%|██████▌   | 187/285 [03:17<01:40,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [03:18<01:39,  1.03s/it]Loading train:  66%|██████▋   | 189/285 [03:19<01:32,  1.04it/s]Loading train:  67%|██████▋   | 190/285 [03:20<01:32,  1.03it/s]Loading train:  67%|██████▋   | 191/285 [03:21<01:36,  1.02s/it]Loading train:  67%|██████▋   | 192/285 [03:22<01:37,  1.05s/it]Loading train:  68%|██████▊   | 193/285 [03:23<01:33,  1.01s/it]Loading train:  68%|██████▊   | 194/285 [03:24<01:34,  1.04s/it]Loading train:  68%|██████▊   | 195/285 [03:25<01:30,  1.00s/it]Loading train:  69%|██████▉   | 196/285 [03:26<01:38,  1.11s/it]Loading train:  69%|██████▉   | 197/285 [03:27<01:33,  1.06s/it]Loading train:  69%|██████▉   | 198/285 [03:28<01:29,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:29<01:24,  1.02it/s]Loading train:  70%|███████   | 200/285 [03:30<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:31<01:27,  1.05s/it]Loading train:  71%|███████   | 202/285 [03:32<01:28,  1.07s/it]Loading train:  71%|███████   | 203/285 [03:34<01:28,  1.08s/it]Loading train:  72%|███████▏  | 204/285 [03:34<01:19,  1.01it/s]Loading train:  72%|███████▏  | 205/285 [03:35<01:18,  1.02it/s]Loading train:  72%|███████▏  | 206/285 [03:36<01:14,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:38<01:24,  1.08s/it]Loading train:  73%|███████▎  | 208/285 [03:39<01:23,  1.08s/it]Loading train:  73%|███████▎  | 209/285 [03:40<01:21,  1.08s/it]Loading train:  74%|███████▎  | 210/285 [03:40<01:11,  1.05it/s]Loading train:  74%|███████▍  | 211/285 [03:41<01:11,  1.03it/s]Loading train:  74%|███████▍  | 212/285 [03:42<01:11,  1.02it/s]Loading train:  75%|███████▍  | 213/285 [03:43<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:44<01:06,  1.07it/s]Loading train:  75%|███████▌  | 215/285 [03:45<01:11,  1.03s/it]Loading train:  76%|███████▌  | 216/285 [03:46<01:06,  1.04it/s]Loading train:  76%|███████▌  | 217/285 [03:47<01:08,  1.00s/it]Loading train:  76%|███████▋  | 218/285 [03:49<01:11,  1.07s/it]Loading train:  77%|███████▋  | 219/285 [03:50<01:17,  1.17s/it]Loading train:  77%|███████▋  | 220/285 [03:51<01:08,  1.06s/it]Loading train:  78%|███████▊  | 221/285 [03:52<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [03:53<01:07,  1.07s/it]Loading train:  78%|███████▊  | 223/285 [03:54<01:03,  1.02s/it]Loading train:  79%|███████▊  | 224/285 [03:55<01:02,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [03:56<00:58,  1.02it/s]Loading train:  79%|███████▉  | 226/285 [03:57<00:59,  1.01s/it]Loading train:  80%|███████▉  | 227/285 [03:58<00:59,  1.02s/it]Loading train:  80%|████████  | 228/285 [03:59<00:59,  1.04s/it]Loading train:  80%|████████  | 229/285 [04:00<01:02,  1.11s/it]Loading train:  81%|████████  | 230/285 [04:01<00:56,  1.03s/it]Loading train:  81%|████████  | 231/285 [04:02<00:53,  1.01it/s]Loading train:  81%|████████▏ | 232/285 [04:03<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [04:04<00:52,  1.01s/it]Loading train:  82%|████████▏ | 234/285 [04:05<00:59,  1.16s/it]Loading train:  82%|████████▏ | 235/285 [04:06<00:52,  1.05s/it]Loading train:  83%|████████▎ | 236/285 [04:07<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:09<00:53,  1.12s/it]Loading train:  84%|████████▎ | 238/285 [04:10<00:51,  1.10s/it]Loading train:  84%|████████▍ | 239/285 [04:11<00:47,  1.04s/it]Loading train:  84%|████████▍ | 240/285 [04:11<00:44,  1.02it/s]Loading train:  85%|████████▍ | 241/285 [04:12<00:43,  1.01it/s]Loading train:  85%|████████▍ | 242/285 [04:13<00:41,  1.05it/s]Loading train:  85%|████████▌ | 243/285 [04:14<00:39,  1.07it/s]Loading train:  86%|████████▌ | 244/285 [04:15<00:39,  1.03it/s]Loading train:  86%|████████▌ | 245/285 [04:16<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [04:17<00:37,  1.04it/s]Loading train:  87%|████████▋ | 247/285 [04:18<00:37,  1.01it/s]Loading train:  87%|████████▋ | 248/285 [04:19<00:36,  1.02it/s]Loading train:  87%|████████▋ | 249/285 [04:20<00:33,  1.08it/s]Loading train:  88%|████████▊ | 250/285 [04:21<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [04:22<00:28,  1.18it/s]Loading train:  88%|████████▊ | 252/285 [04:23<00:29,  1.12it/s]Loading train:  89%|████████▉ | 253/285 [04:24<00:30,  1.05it/s]Loading train:  89%|████████▉ | 254/285 [04:25<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [04:26<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [04:27<00:27,  1.07it/s]Loading train:  90%|█████████ | 257/285 [04:28<00:28,  1.01s/it]Loading train:  91%|█████████ | 258/285 [04:29<00:29,  1.11s/it]Loading train:  91%|█████████ | 259/285 [04:30<00:28,  1.11s/it]Loading train:  91%|█████████ | 260/285 [04:31<00:25,  1.01s/it]Loading train:  92%|█████████▏| 261/285 [04:32<00:22,  1.05it/s]Loading train:  92%|█████████▏| 262/285 [04:33<00:21,  1.09it/s]Loading train:  92%|█████████▏| 263/285 [04:33<00:19,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:35<00:21,  1.00s/it]Loading train:  93%|█████████▎| 265/285 [04:36<00:20,  1.05s/it]Loading train:  93%|█████████▎| 266/285 [04:37<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [04:38<00:19,  1.09s/it]Loading train:  94%|█████████▍| 268/285 [04:39<00:18,  1.06s/it]Loading train:  94%|█████████▍| 269/285 [04:40<00:16,  1.06s/it]Loading train:  95%|█████████▍| 270/285 [04:41<00:15,  1.00s/it]Loading train:  95%|█████████▌| 271/285 [04:42<00:14,  1.05s/it]Loading train:  95%|█████████▌| 272/285 [04:43<00:13,  1.03s/it]Loading train:  96%|█████████▌| 273/285 [04:44<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [04:45<00:11,  1.04s/it]Loading train:  96%|█████████▋| 275/285 [04:46<00:10,  1.07s/it]Loading train:  97%|█████████▋| 276/285 [04:48<00:09,  1.10s/it]Loading train:  97%|█████████▋| 277/285 [04:48<00:07,  1.02it/s]Loading train:  98%|█████████▊| 278/285 [04:49<00:06,  1.06it/s]Loading train:  98%|█████████▊| 279/285 [04:50<00:05,  1.04it/s]Loading train:  98%|█████████▊| 280/285 [04:51<00:04,  1.13it/s]Loading train:  99%|█████████▊| 281/285 [04:52<00:03,  1.14it/s]Loading train:  99%|█████████▉| 282/285 [04:52<00:02,  1.23it/s]Loading train:  99%|█████████▉| 283/285 [04:54<00:01,  1.08it/s]Loading train: 100%|█████████▉| 284/285 [04:54<00:00,  1.06it/s]Loading train: 100%|██████████| 285/285 [04:56<00:00,  1.00it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:14, 19.73it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:11, 25.05it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:07, 34.53it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:04, 46.87it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:02, 62.95it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:01, 82.86it/s]concatenating: train:  55%|█████▌    | 158/285 [00:00<00:01, 103.97it/s]concatenating: train:  64%|██████▍   | 183/285 [00:00<00:00, 120.59it/s]concatenating: train:  72%|███████▏  | 206/285 [00:01<00:00, 86.36it/s] concatenating: train:  79%|███████▊  | 224/285 [00:01<00:00, 78.01it/s]concatenating: train:  84%|████████▍ | 239/285 [00:01<00:00, 75.68it/s]concatenating: train:  88%|████████▊ | 252/285 [00:02<00:00, 56.55it/s]concatenating: train:  92%|█████████▏| 262/285 [00:02<00:00, 45.10it/s]concatenating: train:  95%|█████████▍| 270/285 [00:02<00:00, 46.46it/s]concatenating: train:  97%|█████████▋| 277/285 [00:02<00:00, 47.09it/s]concatenating: train: 100%|█████████▉| 284/285 [00:03<00:00, 40.01it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 92.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.62s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.67s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 19.96it/s]2019-07-11 01:39:03.428329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:39:03.428430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:39:03.428445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:39:03.428454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:39:03.428870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.16it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.14it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.98it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.67it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.33it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.08it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.21it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.89it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.21it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.96it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.88it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.37it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.47it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.27it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.01it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.47it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.57it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.13it/s]
Epoch 00049: val_mDice did not improve from 0.63912
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
{'val_loss': [0.8767542905647662, 0.5746650759068281, 0.48802674649148015, 0.4725963346785007, 0.48543781474981895, 0.4605247478245357, 0.46197976846268723, 0.4549975538386979, 0.4318757643246784, 0.45117082309456513, 0.4446640860435017, 0.45489451472319703, 0.45215357581996385, 0.4501517032111823, 0.453414683568411, 0.45560993728690974, 0.4611743425523769, 0.4533822669663243, 0.4686816208189426, 0.49961102475001157, 0.4489990409526079, 0.4466011187883729, 0.4599835269943962, 0.4587580185362747, 0.4620617711344245, 0.4582456350326538, 0.45556222859707624, 0.4683838876266053, 0.46542441678446766, 0.47344828617639384, 0.4560904879143784, 0.4651777351368739, 0.48522878525643376, 0.48085461149002584, 0.45843963416595035, 0.4668902784752446, 0.4561225442247018, 0.4945220527702204, 0.44310086665872755, 0.46570298958091094, 0.5244460725251523, 0.45779040805454363, 0.4727945760641684, 0.4545857396871684, 0.44874088957323044, 0.45600300228129553, 0.46793494211228864, 0.4717952539134958, 0.4664859581926015], 'val_acc': [0.9254032876238477, 0.9365372278170878, 0.938140450909151, 0.9430762522713432, 0.9447621646540125, 0.9530283948562664, 0.9533424503976407, 0.9525449728832565, 0.9537246896567957, 0.951402439085465, 0.9543238242245253, 0.9517681085863593, 0.9525924651316424, 0.954216408329969, 0.9522722260246064, 0.9518879505509105, 0.9528796439730255, 0.9541482079628459, 0.9521668769793803, 0.9466815004801618, 0.9548754528914084, 0.9518239141842506, 0.954077956729761, 0.9531441091159203, 0.9514623404215168, 0.9519871276850141, 0.9535593913254126, 0.9525511574478789, 0.9508673345576452, 0.9525862799010463, 0.9518548822935733, 0.9542329391287692, 0.9541998722033793, 0.952096618087598, 0.9529850399693963, 0.9537846039793345, 0.9531193092548648, 0.9540986055768402, 0.9529788161123265, 0.9523135693379621, 0.9520325770591225, 0.9543382998285347, 0.9541667939564369, 0.9543568715036914, 0.9535036126994554, 0.9524602447142149, 0.9532990682058494, 0.9535655882105482, 0.9528548777436411], 'val_mDice': [0.45677784451559267, 0.5552595960361332, 0.6093368077411332, 0.6183731522640037, 0.608059236457228, 0.6216142810256787, 0.6210403249250444, 0.6259922371896286, 0.6391191202834998, 0.6277010926987205, 0.6311098177339778, 0.6259970105560132, 0.6264251950066849, 0.6286310756672694, 0.6275540187372176, 0.6261969065533004, 0.6206527205818858, 0.626294656172811, 0.6204973239472459, 0.5975005753213467, 0.6293589382864243, 0.6301312180204764, 0.6275422759562231, 0.6244193338815061, 0.6238852093339632, 0.6276524772857155, 0.6262698310047554, 0.6204387249227342, 0.6218315589361351, 0.6155606781304216, 0.6274895538164916, 0.6244360135254248, 0.6125504384493695, 0.6150811024884272, 0.6292234416114552, 0.6255671555103537, 0.6258468721166003, 0.6064068128942778, 0.6332678145536498, 0.6209161577943983, 0.6012772564781445, 0.6259865168086644, 0.6204274899466744, 0.626170609250415, 0.6319007394034103, 0.6256775982553067, 0.6213570933102229, 0.6235577294280409, 0.6222349525163959], 'loss': [1.854873379521702, 0.6137110257738264, 0.48371698765490845, 0.43458606227668345, 0.4052968534189179, 0.38534928273546964, 0.36952455662141004, 0.3556505763386597, 0.34403306741508277, 0.3352880219518927, 0.3279492822998938, 0.3219751262838795, 0.31637711945127267, 0.3120270548553211, 0.3078262984012507, 0.3017186821367309, 0.2991694661161556, 0.29699808058055177, 0.29549355890540396, 0.29263068563466393, 0.32592247417826103, 0.29071399668684766, 0.28439034850507394, 0.280407597831207, 0.2772889774493367, 0.2755201386458136, 0.27378186541804495, 0.27284410182644514, 0.2715739349684329, 0.26881472895844144, 0.26655467842004504, 0.2659880148222436, 0.26503168704086294, 0.2635838382628208, 0.2618390368088211, 0.2608568449534854, 0.25847882469666106, 0.2600035842344344, 0.25755209673574875, 0.2556160787184068, 0.2542201196775348, 0.2533653918875893, 0.25251173438261576, 0.2527944919694373, 0.2513274280056637, 0.25000879672411697, 0.2506571048667284, 0.24967318425270202, 0.2477707801028915], 'acc': [0.6620809632259597, 0.9093627526209405, 0.9142759481122256, 0.9186873521156076, 0.9248265969026752, 0.9328481421336376, 0.9405191036378576, 0.9448496807174066, 0.9470858202183937, 0.9480852094891739, 0.9488222976505065, 0.9494814141488375, 0.9499800236459768, 0.9504519842248955, 0.9508799168903982, 0.9512921347252444, 0.9516383931791462, 0.951852761568129, 0.9519197339001619, 0.9523752192955938, 0.9500432286469753, 0.952402812159079, 0.9527048581689604, 0.953040017433581, 0.9533620208516423, 0.9534942516346434, 0.9535967773598047, 0.9536471314714869, 0.9537748270944783, 0.9539232704187685, 0.9541928692390168, 0.9542187301040403, 0.9543602892720267, 0.9543646992268979, 0.9544962245578775, 0.9545863992728593, 0.9546935724462859, 0.9546330871031984, 0.9548390965648456, 0.9549839557642303, 0.9551252104554209, 0.9551990891806629, 0.9552347821598771, 0.95533635642792, 0.9554241342090338, 0.9554512231030903, 0.9554802876731343, 0.9555332023368591, 0.9557314160849091], 'mDice': [0.2363409759925881, 0.5310695043940358, 0.6031624578220718, 0.6344921104425335, 0.6538790360780513, 0.6672500061460339, 0.6778069885849245, 0.6871299152507754, 0.6951243600407221, 0.7013269240323394, 0.7065849735887344, 0.7110429211455189, 0.7151547029973973, 0.7183090040032026, 0.7214949509721067, 0.7259862573796981, 0.7280296129141814, 0.7297732497078356, 0.7308659016465993, 0.7342943126135588, 0.7097465757950738, 0.7344258960429169, 0.7391040428071349, 0.7422844864406537, 0.7447013811415613, 0.7460667756925539, 0.747454712135224, 0.7481905840611992, 0.7492145629017696, 0.7513032262539929, 0.7531024706557805, 0.7535534636055382, 0.7544457513803906, 0.7554911385985684, 0.7568613454560739, 0.7576651983119311, 0.7594561921401674, 0.7582663831209073, 0.7602974114338301, 0.7617291269540774, 0.7629636968248882, 0.7635370407298748, 0.7643348935071007, 0.7640283952532728, 0.765234788475288, 0.7662639261480185, 0.7657613285836633, 0.766577830041171, 0.7680568088017078]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 13)   793         dropout_6[0][0]                  
==================================================================================================
Total params: 231,593
Trainable params: 56,833
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 15s - loss: 2.9001 - acc: 0.7096 - mDice: 0.0971 - val_loss: 1.8786 - val_acc: 0.8976 - val_mDice: 0.2326

Epoch 00001: val_mDice improved from -inf to 0.23256, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 1.0938 - acc: 0.8907 - mDice: 0.3292 - val_loss: 2.1015 - val_acc: 0.9084 - val_mDice: 0.2848

Epoch 00002: val_mDice improved from 0.23256 to 0.28477, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.7842 - acc: 0.9009 - mDice: 0.4399 - val_loss: 1.3260 - val_acc: 0.9144 - val_mDice: 0.3610

Epoch 00003: val_mDice improved from 0.28477 to 0.36100, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.6558 - acc: 0.9097 - mDice: 0.5021 - val_loss: 0.8645 - val_acc: 0.9267 - val_mDice: 0.4970

Epoch 00004: val_mDice improved from 0.36100 to 0.49699, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.5812 - acc: 0.9177 - mDice: 0.5421 - val_loss: 0.7675 - val_acc: 0.9362 - val_mDice: 0.5426

Epoch 00005: val_mDice improved from 0.49699 to 0.54264, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.5319 - acc: 0.9238 - mDice: 0.5704 - val_loss: 0.7372 - val_acc: 0.9379 - val_mDice: 0.5649

Epoch 00006: val_mDice improved from 0.54264 to 0.56489, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.4974 - acc: 0.9273 - mDice: 0.5911 - val_loss: 0.7551 - val_acc: 0.9369 - val_mDice: 0.5621

Epoch 00007: val_mDice did not improve from 0.56489
Epoch 8/300
 - 10s - loss: 0.4726 - acc: 0.9299 - mDice: 0.6064 - val_loss: 0.7590 - val_acc: 0.9303 - val_mDice: 0.5529

Epoch 00008: val_mDice did not improve from 0.56489
Epoch 9/300
 - 10s - loss: 0.4505 - acc: 0.9318 - mDice: 0.6206 - val_loss: 0.7370 - val_acc: 0.9386 - val_mDice: 0.5689

Epoch 00009: val_mDice improved from 0.56489 to 0.56891, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.4354 - acc: 0.9333 - mDice: 0.6305 - val_loss: 0.7371 - val_acc: 0.9381 - val_mDice: 0.5655

Epoch 00010: val_mDice did not improve from 0.56891
Epoch 11/300
 - 10s - loss: 0.4229 - acc: 0.9345 - mDice: 0.6387 - val_loss: 0.7700 - val_acc: 0.9330 - val_mDice: 0.5631

Epoch 00011: val_mDice did not improve from 0.56891
Epoch 12/300
 - 10s - loss: 0.4115 - acc: 0.9356 - mDice: 0.6464 - val_loss: 0.7734 - val_acc: 0.9366 - val_mDice: 0.5612

Epoch 00012: val_mDice did not improve from 0.56891
Epoch 13/300
 - 10s - loss: 0.4014 - acc: 0.9365 - mDice: 0.6533 - val_loss: 0.7611 - val_acc: 0.9332 - val_mDice: 0.5712

Epoch 00013: val_mDice improved from 0.56891 to 0.57120, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 10s - loss: 0.3947 - acc: 0.9372 - mDice: 0.6579 - val_loss: 0.7892 - val_acc: 0.9413 - val_mDice: 0.5623

Epoch 00014: val_mDice did not improve from 0.57120
Epoch 15/300
 - 10s - loss: 0.3901 - acc: 0.9379 - mDice: 0.6613 - val_loss: 0.7676 - val_acc: 0.9372 - val_mDice: 0.5769

Epoch 00015: val_mDice improved from 0.57120 to 0.57692, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.3818 - acc: 0.9385 - mDice: 0.6669 - val_loss: 0.7354 - val_acc: 0.9380 - val_mDice: 0.5840

Epoch 00016: val_mDice improved from 0.57692 to 0.58397, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 10s - loss: 0.3758 - acc: 0.9392 - mDice: 0.6712 - val_loss: 0.7834 - val_acc: 0.9407 - val_mDice: 0.5736

Epoch 00017: val_mDice did not improve from 0.58397
Epoch 18/300
 - 10s - loss: 0.3687 - acc: 0.9400 - mDice: 0.6763 - val_loss: 0.7450 - val_acc: 0.9399 - val_mDice: 0.5858

Epoch 00018: val_mDice improved from 0.58397 to 0.58579, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 10s - loss: 0.3643 - acc: 0.9404 - mDice: 0.6793 - val_loss: 0.7434 - val_acc: 0.9402 - val_mDice: 0.5728

Epoch 00019: val_mDice did not improve from 0.58579
Epoch 20/300
 - 10s - loss: 0.3608 - acc: 0.9407 - mDice: 0.6818 - val_loss: 0.7684 - val_acc: 0.9439 - val_mDice: 0.5745

Epoch 00020: val_mDice did not improve from 0.58579
Epoch 21/300
 - 11s - loss: 0.3565 - acc: 0.9411 - mDice: 0.6849 - val_loss: 0.7469 - val_acc: 0.9384 - val_mDice: 0.5851

Epoch 00021: val_mDice did not improve from 0.58579
Epoch 22/300
 - 10s - loss: 0.3522 - acc: 0.9414 - mDice: 0.6880 - val_loss: 0.7819 - val_acc: 0.9394 - val_mDice: 0.5723

Epoch 00022: val_mDice did not improve from 0.58579
Epoch 23/300
 - 10s - loss: 0.3496 - acc: 0.9417 - mDice: 0.6899 - val_loss: 0.7347 - val_acc: 0.9398 - val_mDice: 0.5873

Epoch 00023: val_mDice improved from 0.58579 to 0.58730, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 10s - loss: 0.3444 - acc: 0.9421 - mDice: 0.6937 - val_loss: 0.7410 - val_acc: 0.9366 - val_mDice: 0.5887

Epoch 00024: val_mDice improved from 0.58730 to 0.58871, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 11s - loss: 0.3436 - acc: 0.9422 - mDice: 0.6943 - val_loss: 0.7253 - val_acc: 0.9426 - val_mDice: 0.5864

Epoch 00025: val_mDice did not improve from 0.58871
Epoch 26/300
 - 10s - loss: 0.3403 - acc: 0.9426 - mDice: 0.6967 - val_loss: 0.7183 - val_acc: 0.9413 - val_mDice: 0.5926

Epoch 00026: val_mDice improved from 0.58871 to 0.59264, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 11s - loss: 0.3403 - acc: 0.9427 - mDice: 0.6969 - val_loss: 0.7487 - val_acc: 0.9376 - val_mDice: 0.5706

Epoch 00027: val_mDice did not improve from 0.59264
Epoch 28/300
 - 10s - loss: 0.3328 - acc: 0.9432 - mDice: 0.7022 - val_loss: 0.7369 - val_acc: 0.9400 - val_mDice: 0.5810

Epoch 00028: val_mDice did not improve from 0.59264
Epoch 29/300
 - 11s - loss: 0.3323 - acc: 0.9432 - mDice: 0.7025 - val_loss: 0.7674 - val_acc: 0.9416 - val_mDice: 0.5765

Epoch 00029: val_mDice did not improve from 0.59264
Epoch 30/300
 - 10s - loss: 0.3290 - acc: 0.9435 - mDice: 0.7050 - val_loss: 0.7900 - val_acc: 0.9415 - val_mDice: 0.5600

Epoch 00030: val_mDice did not improve from 0.59264
Epoch 31/300
 - 10s - loss: 0.3268 - acc: 0.9437 - mDice: 0.7067 - val_loss: 0.7944 - val_acc: 0.9430 - val_mDice: 0.5672

Epoch 00031: val_mDice did not improve from 0.59264
Epoch 32/300
 - 10s - loss: 0.3247 - acc: 0.9439 - mDice: 0.7082 - val_loss: 0.7469 - val_acc: 0.9381 - val_mDice: 0.5859

Epoch 00032: val_mDice did not improve from 0.59264
Epoch 33/300
 - 10s - loss: 0.3228 - acc: 0.9440 - mDice: 0.7095 - val_loss: 0.7278 - val_acc: 0.9408 - val_mDice: 0.5898

Epoch 00033: val_mDice did not improve from 0.59264
Epoch 34/300
 - 10s - loss: 0.3203 - acc: 0.9441 - mDice: 0.7114 - val_loss: 0.7566 - val_acc: 0.9405 - val_mDice: 0.5774

Epoch 00034: val_mDice did not improve from 0.59264
Epoch 35/300
 - 10s - loss: 0.3181 - acc: 0.9444 - mDice: 0.7130 - val_loss: 0.7408 - val_acc: 0.9409 - val_mDice: 0.5851

Epoch 00035: val_mDice did not improve from 0.59264
Epoch 36/300
 - 10s - loss: 0.3161 - acc: 0.9447 - mDice: 0.7146 - val_loss: 0.7197 - val_acc: 0.9416 - val_mDice: 0.5840

Epoch 00036: val_mDice did not improve from 0.59264
Epoch 37/300
 - 10s - loss: 0.3140 - acc: 0.9448 - mDice: 0.7162 - val_loss: 0.7334 - val_acc: 0.9410 - val_mDice: 0.5793

Epoch 00037: val_mDice did not improve from 0.59264
Epoch 38/300
 - 10s - loss: 0.3137 - acc: 0.9449 - mDice: 0.7164 - val_loss: 0.7589 - val_acc: 0.9385 - val_mDice: 0.5852

Epoch 00038: val_mDice did not improve from 0.59264
Epoch 39/300
 - 10s - loss: 0.3111 - acc: 0.9450 - mDice: 0.7183 - val_loss: 0.7380 - val_acc: 0.9321 - val_mDice: 0.5733

Epoch 00039: val_mDice did not improve from 0.59264
Epoch 40/300
 - 10s - loss: 0.3112 - acc: 0.9450 - mDice: 0.7183 - val_loss: 0.7016 - val_acc: 0.9417 - val_mDice: 0.5885

Epoch 00040: val_mDice did not improve from 0.59264
Epoch 41/300
 - 10s - loss: 0.3106 - acc: 0.9451 - mDice: 0.7187 - val_loss: 0.7596 - val_acc: 0.9375 - val_mDice: 0.5701

Epoch 00041: val_mDice did not improve from 0.59264
Epoch 42/300
 - 11s - loss: 0.3077 - acc: 0.9453 - mDice: 0.7209 - val_loss: 0.7192 - val_acc: 0.9396 - val_mDice: 0.5881

Epoch 00042: val_mDice did not improve from 0.59264
Epoch 43/300
 - 10s - loss: 0.3098 - acc: 0.9451 - mDice: 0.7193 - val_loss: 0.7272 - val_acc: 0.9382 - val_mDice: 0.5781

Epoch 00043: val_mDice did not improve from 0.59264
Epoch 44/300
 - 11s - loss: 0.3045 - acc: 0.9455 - mDice: 0.7232 - val_loss: 0.6587 - val_acc: 0.9433 - val_mDice: 0.5890

Epoch 00044: val_mDice did not improve from 0.59264
Epoch 45/300
 - 10s - loss: 0.3043 - acc: 0.9455 - mDice: 0.7235 - val_loss: 0.7093 - val_acc: 0.9418 - val_mDice: 0.5867

Epoch 00045: val_mDice did not improve from 0.59264
Epoch 46/300
 - 11s - loss: 0.3016 - acc: 0.9458 - mDice: 0.7255 - val_loss: 0.7191 - val_acc: 0.9383 - val_mDice: 0.5806

Epoch 00046: val_mDice did not improve from 0.59264
Epoch 47/300
 - 10s - loss: 0.3024 - acc: 0.9458 - mDice: 0.7249 - val_loss: 0.6685 - val_acc: 0.9420 - val_mDice: 0.5802

Epoch 00047: val_mDice did not improve from 0.59264
Epoch 48/300
 - 10s - loss: 0.3011 - acc: 0.9458 - mDice: 0.7259 - val_loss: 0.6899 - val_acc: 0.9448 - val_mDice: 0.5900

Epoch 00048: val_mDice did not improve from 0.59264
Epoch 49/300
 - 10s - loss: 0.2987 - acc: 0.9459 - mDice: 0.7278 - val_loss: 0.6639 - val_acc: 0.9418 - val_mDice: 0.5801

Epoch 00049: val_mDice did not improve from 0.59264
Epoch 50/300
 - 11s - loss: 0.2989 - acc: 0.9460 - mDice: 0.7276 - val_loss: 0.7051 - val_acc: 0.9413 - val_mDice: 0.5831

Epoch 00050: val_mDice did not improve from 0.59264
Epoch 51/300
 - 10s - loss: 0.2963 - acc: 0.9462 - mDice: 0.7295 - val_loss: 0.6979 - val_acc: 0.9430 - val_mDice: 0.5758

Epoch 00051: val_mDice did not improve from 0.59264
Epoch 52/300
 - 11s - loss: 0.2942 - acc: 0.9463 - mDice: 0.7311 - val_loss: 0.6866 - val_acc: 0.9429 - val_mDice: 0.5746

Epoch 00052: val_mDice did not improve from 0.59264
Epoch 53/300
 - 10s - loss: 0.2935 - acc: 0.9464 - mDice: 0.7317 - val_loss: 0.6582 - val_acc: 0.9410 - val_mDice: 0.5845

Epoch 00053: val_mDice did not improve from 0.59264
Epoch 54/300
 - 11s - loss: 0.2949 - acc: 0.9463 - mDice: 0.7307 - val_loss: 0.6455 - val_acc: 0.9426 - val_mDice: 0.5867

Epoch 00054: val_mDice did not improve from 0.59264
Epoch 55/300
 - 10s - loss: 0.2923 - acc: 0.9466 - mDice: 0.7326 - val_loss: 0.6347 - val_acc: 0.9391 - val_mDice: 0.5698

Epoch 00055: val_mDice did not improve from 0.59264
Epoch 56/300
 - 11s - loss: 0.2921 - acc: 0.9465 - mDice: 0.7328 - val_loss: 0.6533 - val_acc: 0.9413 - val_mDice: 0.5899

Epoch 00056: val_mDice did not improve from 0.59264
Epoch 57/300
 - 10s - loss: 0.2922 - acc: 0.9465 - mDice: 0.7328 - val_loss: 0.6578 - val_acc: 0.9403 - val_mDice: 0.5835

Epoch 00057: val_mDice did not improve from 0.59264
Epoch 58/300
 - 11s - loss: 0.2908 - acc: 0.9467 - mDice: 0.7338 - val_loss: 0.6993 - val_acc: 0.9400 - val_mDice: 0.5819

Epoch 00058: val_mDice did not improve from 0.59264
Epoch 59/300
 - 10s - loss: 0.2891 - acc: 0.9467 - mDice: 0.7352 - val_loss: 0.6743 - val_acc: 0.9408 - val_mDice: 0.5829

Epoch 00059: val_mDice did not improve from 0.59264
Epoch 60/300
 - 11s - loss: 0.2882 - acc: 0.9468 - mDice: 0.7358 - val_loss: 0.6779 - val_acc: 0.9421 - val_mDice: 0.5807

Epoch 00060: val_mDice did not improve from 0.59264
Epoch 61/300
 - 10s - loss: 0.2868 - acc: 0.9469 - mDice: 0.7368 - val_loss: 0.6525 - val_acc: 0.9414 - val_mDice: 0.5802

Epoch 00061: val_mDice did not improve from 0.59264
Epoch 62/300
 - 11s - loss: 0.2869 - acc: 0.9470 - mDice: 0.7368 - val_loss: 0.6640 - val_acc: 0.9422 - val_mDice: 0.5833

Epoch 00062: val_mDice did not improve from 0.59264
Epoch 63/300
 - 10s - loss: 0.2855 - acc: 0.9470 - mDice: 0.7379 - val_loss: 0.6651 - val_acc: 0.9402 - val_mDice: 0.5826

Epoch 00063: val_mDice did not improve from 0.59264
Epoch 64/300
 - 11s - loss: 0.2855 - acc: 0.9471 - mDice: 0.7379 - val_loss: 0.6427 - val_acc: 0.9402 - val_mDice: 0.5826

Epoch 00064: val_mDice did not improve from 0.59264
Epoch 65/300
 - 10s - loss: 0.2842 - acc: 0.9472 - mDice: 0.7389 - val_loss: 0.6674 - val_acc: 0.9410 - val_mDice: 0.5852

Epoch 00065: val_mDice did not improve from 0.59264
Epoch 66/300
 - 10s - loss: 0.2832 - acc: 0.9472 - mDice: 0.7396 - val_loss: 0.6726 - val_acc: 0.9379 - val_mDice: 0.5779

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.72s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:33,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:47,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:49,  1.66s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:24,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:37,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:09,  1.54s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:26,  1.61s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:24,  1.60s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:01,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:06,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:43,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:55,  1.74s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:45,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:51,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:54,  1.76s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:01,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:42,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:25,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:32,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:49,  1.78s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:32,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:28,  1.71s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:13,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.75s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:39,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:14,  1.68s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:15,  1.70s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:21,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:34,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:27,  1.76s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:07,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:07,  1.70s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:18,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<06:57,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<06:51,  1.66s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<07:02,  1.72s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:11,  1.76s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:48,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:42,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:44,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:55,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:40,  1.67s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:51,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:52,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<07:02,  1.79s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:14,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:56,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:56,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:55,  1.80s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:42,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<07:00,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:42,  1.77s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:44,  1.78s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:51,  1.82s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:56,  1.85s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:38,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:41,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:43,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:22,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:35,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:30,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:35,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:27,  1.79s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:25,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:28,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:28,  1.81s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:10,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:13,  1.76s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:21,  1.81s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<06:18,  1.80s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<06:07,  1.76s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:42,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:46,  1.69s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:53,  1.74s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:45,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:40,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:49,  1.75s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:57,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:58,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:32<05:43,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:43,  1.75s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:41,  1.75s/it]predicting train subjects:  32%|███▏      | 91/285 [02:37<05:24,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:39<05:23,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:18,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:42<05:24,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:25,  1.71s/it]predicting train subjects:  34%|███▎      | 96/285 [02:46<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:48<05:34,  1.78s/it]predicting train subjects:  34%|███▍      | 98/285 [02:49<05:27,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:51<05:22,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:53<05:26,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:15,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:56<05:13,  1.72s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<05:01,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [03:00<05:09,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<05:05,  1.70s/it]predicting train subjects:  37%|███▋      | 106/285 [03:03<04:55,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [03:05<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:06<04:56,  1.68s/it]predicting train subjects:  38%|███▊      | 109/285 [03:08<04:56,  1.68s/it]predicting train subjects:  39%|███▊      | 110/285 [03:10<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:11<04:48,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:13<04:51,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:15<04:53,  1.71s/it]predicting train subjects:  40%|████      | 114/285 [03:17<04:54,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:18<04:50,  1.71s/it]predicting train subjects:  41%|████      | 116/285 [03:20<04:48,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:37,  1.65s/it]predicting train subjects:  41%|████▏     | 118/285 [03:23<04:34,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:25<04:37,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:26<04:31,  1.64s/it]predicting train subjects:  42%|████▏     | 121/285 [03:28<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:10,  1.54s/it]predicting train subjects:  43%|████▎     | 123/285 [03:31<03:57,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:02,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:34<04:03,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:37<04:04,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<04:02,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:40<03:58,  1.53s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<03:50,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:43<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<03:43,  1.46s/it]predicting train subjects:  47%|████▋     | 133/285 [03:46<03:39,  1.44s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:48<03:32,  1.42s/it]predicting train subjects:  48%|████▊     | 136/285 [03:50<03:30,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:43,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:53<03:45,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [03:55<03:45,  1.54s/it]predicting train subjects:  49%|████▉     | 140/285 [03:56<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [03:58<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [03:59<03:33,  1.49s/it]predicting train subjects:  50%|█████     | 143/285 [04:00<03:29,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:02<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:04<03:34,  1.53s/it]predicting train subjects:  51%|█████     | 146/285 [04:05<03:33,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:07<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:08<03:35,  1.57s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:10<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:11<03:28,  1.54s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:13<03:26,  1.54s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:15<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:16<03:17,  1.49s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:18<03:23,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:19<03:16,  1.51s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:21<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:22<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:24<03:12,  1.52s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:25<03:06,  1.48s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:26<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:28<03:11,  1.54s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:29<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:31<03:06,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:32<02:59,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:34<02:59,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:36<03:00,  1.51s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:37<03:02,  1.55s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:39<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:40<02:54,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:41<02:47,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:43<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:44<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:46<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:47<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:49<02:42,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:50<02:48,  1.54s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:52<02:43,  1.52s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:53<02:39,  1.49s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:56<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:58<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:59<02:40,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:01<02:30,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:02<02:31,  1.50s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:04<02:25,  1.46s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:05<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:07<02:43,  1.67s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:09<02:45,  1.70s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:33,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:12<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:30,  1.60s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:15<02:32,  1.64s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:22,  1.55s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:18<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:20<02:10,  1.45s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:21<02:16,  1.53s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:23<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:25<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:26<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:10,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:29<02:13,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:31<02:14,  1.62s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:12,  1.61s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<02:06,  1.56s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:36<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:37<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<02:07,  1.64s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:41<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:44<02:00,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:45<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:47<01:55,  1.58s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:49<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:50<01:50,  1.55s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:52<01:53,  1.62s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:53<01:45,  1.52s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:48,  1.60s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:57<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:49,  1.65s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:38,  1.54s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:06<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:27,  1.45s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:33,  1.59s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:11<01:35,  1.65s/it]predicting train subjects:  80%|████████  | 228/285 [06:13<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:16<01:28,  1.61s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:27,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:19<01:26,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:21,  1.56s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:22<01:23,  1.63s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:24<01:17,  1.55s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:25<01:21,  1.66s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:27<01:23,  1.74s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:29<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:31<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:32<01:13,  1.62s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:34<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:35<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:36<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:38<01:02,  1.53s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:39<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:41<00:59,  1.53s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:43<01:01,  1.63s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:45<01:00,  1.64s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:46<00:55,  1.54s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:47<00:53,  1.53s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:49<00:50,  1.49s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:50<00:48,  1.47s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:52<00:52,  1.63s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:54<00:52,  1.69s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:56<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:57<00:46,  1.60s/it]predicting train subjects:  90%|█████████ | 257/285 [06:59<00:43,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [07:00<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:02<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [07:03<00:39,  1.57s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:05<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:06<00:35,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:08<00:32,  1.49s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:10<00:33,  1.59s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:11<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:13<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:14<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:16<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:18<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:19<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:20<00:20,  1.49s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:22<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:23<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:25<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:27<00:15,  1.59s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:28<00:14,  1.65s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:30<00:12,  1.57s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:31<00:10,  1.56s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:33<00:09,  1.58s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:34<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:36<00:05,  1.48s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:37<00:04,  1.44s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:39<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:41<00:01,  1.69s/it]predicting train subjects: 100%|██████████| 285/285 [07:43<00:00,  1.73s/it]
Epoch 00066: val_mDice did not improve from 0.59264
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
{'val_loss': [1.8786438565987806, 2.1014885352208066, 1.3259857526192298, 0.8644556494859549, 0.7675255766281714, 0.7372045585742364, 0.7551242686234988, 0.7589853658125951, 0.7369511058697333, 0.7370893863531259, 0.7700239076064184, 0.7734492535774524, 0.7611223688492408, 0.7891668631480291, 0.7675595226196142, 0.7353621388857181, 0.7834042631662809, 0.7450287651557189, 0.7433769290263836, 0.7683706031395838, 0.7469154905814391, 0.781918486723533, 0.7346981546053519, 0.7409525272937921, 0.7252779786403363, 0.7183294892311096, 0.7486684024333954, 0.7368837927396481, 0.7674189038001574, 0.7899796091593229, 0.7943906646508437, 0.7468554366093415, 0.7277524253496757, 0.7566095006007415, 0.7408431986203561, 0.7196717869776946, 0.733407600567891, 0.758880635866752, 0.7379996318083543, 0.7015987072999661, 0.7596184863493993, 0.7191701428248332, 0.7272355992060441, 0.6586736773069088, 0.7093361088862786, 0.7191261568894753, 0.6685170737596658, 0.6898668224994953, 0.6638609881584461, 0.7051321531717594, 0.697882463152592, 0.6865863261314539, 0.6581598153481116, 0.6454845999295895, 0.6347445020308862, 0.6533351299854425, 0.6577902929140971, 0.6992565794632986, 0.6743047730280802, 0.6779469308944849, 0.6525447299847236, 0.6639798730611801, 0.6650746224018244, 0.6426870215397614, 0.6673660324170039, 0.6726067811250687], 'val_acc': [0.8976331628285922, 0.9083510270485511, 0.9143883838103368, 0.9267497177307422, 0.9362402650026175, 0.9378860203119425, 0.9369406654284551, 0.9303139081368079, 0.9386025621340826, 0.9380686008013212, 0.932976626432859, 0.9366239974131951, 0.9332077228105985, 0.9413276589833773, 0.9371625299637134, 0.9379900006147531, 0.9406873973516318, 0.9398945799240699, 0.9401789192969983, 0.9438586601844201, 0.9384292020247533, 0.9393814481221713, 0.9397767323714036, 0.9366424977779388, 0.942596605190864, 0.9412721785215231, 0.9375531490032489, 0.9399986060766073, 0.9416397259785578, 0.9414663544067969, 0.9429895258866824, 0.9380847880473504, 0.9407868064366854, 0.9404516655665177, 0.9408746270033029, 0.9416351043261014, 0.9409855833420386, 0.9384592244258294, 0.9321329799982218, 0.9417136632479154, 0.9374838333863479, 0.9396079870370718, 0.9382304159494547, 0.9433200863691477, 0.941808452972999, 0.938308997796132, 0.9420372820817507, 0.9447878163594466, 0.9417830178370843, 0.9412975907325745, 0.9430126662437732, 0.9429456064334283, 0.940985578757066, 0.9425526719826919, 0.9391410717597375, 0.9412976251198695, 0.9402806300383347, 0.9400147956151229, 0.9408099215764266, 0.9420534120156214, 0.9413854617338914, 0.9422106330211346, 0.940195097373082, 0.9402181735405555, 0.9410294775779431, 0.9379483851102682], 'val_mDice': [0.23256248894792336, 0.2847683492761392, 0.36099831473368865, 0.4969855627188316, 0.5426412167457434, 0.5648851801569645, 0.5620589204705678, 0.5529363218408364, 0.5689149103485621, 0.5655056169399848, 0.5630743996455119, 0.561163339477319, 0.5711984152977283, 0.5622796026559976, 0.5769185045590768, 0.5839683298881237, 0.5736344513984827, 0.5857878682705072, 0.5728114419258558, 0.5744912025447075, 0.5851035461975977, 0.5722971747700984, 0.5873032533205472, 0.5887081989875207, 0.5863692582799838, 0.5926416550691311, 0.5705641794663209, 0.5810249591102967, 0.5764994833331841, 0.5600183709309652, 0.5672244498362908, 0.5858657411657847, 0.5897973970724986, 0.5773550463983645, 0.5850525933962601, 0.584034756399118, 0.5792854691927249, 0.5851904148092637, 0.5733085177265681, 0.588472379801365, 0.570128881587432, 0.588110978786762, 0.578055033316979, 0.5889723197771952, 0.5867129999857682, 0.5806044073632131, 0.5802001540477459, 0.5899913677802453, 0.5800523958527125, 0.5831045766289418, 0.5757728666067123, 0.5745804295516931, 0.5844829174188467, 0.5867071469815878, 0.5697966086176726, 0.5898783120971459, 0.5835264631761954, 0.5818514886956948, 0.5828503439059625, 0.5807085916973077, 0.580233619763301, 0.5833042132166716, 0.5826244858595041, 0.5825669387212167, 0.5852363920555665, 0.5779133823055488], 'loss': [2.9001290576215886, 1.0937767965892777, 0.784170017447582, 0.6557804274183022, 0.5812434378633813, 0.5319081479735912, 0.49739403235926616, 0.4725756879844734, 0.4504583784600064, 0.43543832993678894, 0.4228649023278859, 0.4114539244457946, 0.4013516267573142, 0.3947341761789803, 0.3901257825839963, 0.3817886562323445, 0.3757770472975506, 0.36865567098978336, 0.36430937844724287, 0.3608079406895849, 0.35652846601477056, 0.35220109475315314, 0.3496459046847528, 0.34440319623925597, 0.34361686199603897, 0.3402613550630716, 0.34026112133073794, 0.33279263351243504, 0.3323279287221851, 0.32900866501931386, 0.326824090266529, 0.32472357150319425, 0.3228157805107973, 0.3203075331102644, 0.31814234575079253, 0.3161131840734852, 0.31395241029970783, 0.31369402248800254, 0.3110905765448177, 0.3112195591655899, 0.3106287043357175, 0.30768625036790387, 0.30976821959189116, 0.30454416287612684, 0.304287189453013, 0.30164217930223564, 0.30238989884152156, 0.3010620295253834, 0.29865854371136036, 0.29888595089166575, 0.2962547512739597, 0.2941630506805748, 0.29353351863418065, 0.2948797638512159, 0.29233297321130836, 0.29207546331066053, 0.29219458803340737, 0.29079115789589444, 0.28910321055507016, 0.2881845813840669, 0.2867925403319986, 0.28691225504343065, 0.28546899134939274, 0.28550610367600726, 0.28419581337365607, 0.283178966896105], 'acc': [0.7096404351893908, 0.890727381039774, 0.9009360454294236, 0.9097062819263301, 0.9177481793097373, 0.9237838227194987, 0.9273299996036891, 0.9298797883220477, 0.9317724922755916, 0.9332511828007936, 0.934509302729183, 0.9355843296066857, 0.936509065782849, 0.9371579680552311, 0.9378569495476755, 0.938518026575857, 0.9392131107007183, 0.9399604233144824, 0.9403552620225998, 0.9406674327054807, 0.9410612743069938, 0.9414206225087279, 0.9416867666696146, 0.9421110027150608, 0.9422159346445321, 0.9425909321576172, 0.9426656206474526, 0.9431875352103981, 0.9432167103674692, 0.9435198782368317, 0.9437216666586272, 0.9439389041832735, 0.9439810275932548, 0.9441112099643301, 0.9443501273468501, 0.9446860651605784, 0.9447669188694618, 0.9448790957509268, 0.9450478283316516, 0.9449855337379978, 0.9450677825792638, 0.9452895224891464, 0.9451031406449291, 0.9454522683789103, 0.9454936121515624, 0.945777408786226, 0.9457880930301175, 0.9458144317306101, 0.9459288913166018, 0.9460078374019993, 0.9461850587274825, 0.9462659344301115, 0.9464316546427723, 0.9463202496202936, 0.9465610326287448, 0.9465024381460964, 0.9465158968561966, 0.9466758291296751, 0.9467206126010078, 0.9468114151568098, 0.9469421262902923, 0.9470465718561968, 0.9469507538523608, 0.9471224582218369, 0.9471774587307559, 0.9472497306790923], 'mDice': [0.09713929682457446, 0.32916928197387, 0.4398872812911504, 0.5020952671422715, 0.5421358987236885, 0.5703502041843009, 0.5910549143809053, 0.606443145404187, 0.6206234348421661, 0.6304969191386297, 0.638691504382234, 0.6464414105450086, 0.6532628931243251, 0.6579032154152735, 0.6612638981373319, 0.666931950286296, 0.6712445554550334, 0.6762641323269112, 0.679282779591578, 0.6817898582205015, 0.6849099371053521, 0.6880248875280681, 0.6898846457631872, 0.6936626028478075, 0.6943223362180961, 0.6967435124383733, 0.6969147579790668, 0.7021503057315386, 0.7025131228543356, 0.7050154053735016, 0.7066581634251293, 0.708188578638986, 0.709527720722734, 0.7114020925237499, 0.713020131655706, 0.7146330020485533, 0.7162297824470691, 0.7164313983490664, 0.7183034422267223, 0.7183163276097326, 0.71867814643856, 0.7209091051185768, 0.7193102253700417, 0.7231961825913547, 0.7234871837691078, 0.7254775505460387, 0.7249344849535914, 0.7259251663773457, 0.727790616116686, 0.7275748027544076, 0.7295461391254863, 0.7311017433457804, 0.7317201769638906, 0.7306632809914709, 0.7326182271846489, 0.73284498214128, 0.7327526298867021, 0.7337915674628427, 0.7351805946434005, 0.7357521570169716, 0.7367907717396586, 0.736831065210636, 0.7379037172913299, 0.7378803598620207, 0.738899347439778, 0.7396163497146596]}
---------------------- check Layers Step ------------------------------mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:23,  1.77s/it]Loading train:   1%|          | 2/285 [00:03<08:08,  1.72s/it]Loading train:   1%|          | 3/285 [00:04<07:48,  1.66s/it]Loading train:   1%|▏         | 4/285 [00:06<07:16,  1.55s/it]Loading train:   2%|▏         | 5/285 [00:07<07:18,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:09<06:56,  1.49s/it]Loading train:   2%|▏         | 7/285 [00:11<07:27,  1.61s/it]Loading train:   3%|▎         | 8/285 [00:12<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:14<07:18,  1.59s/it]Loading train:   4%|▎         | 10/285 [00:15<06:49,  1.49s/it]Loading train:   4%|▍         | 11/285 [00:16<06:22,  1.39s/it]Loading train:   4%|▍         | 12/285 [00:17<06:12,  1.37s/it]Loading train:   5%|▍         | 13/285 [00:18<05:35,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:20<05:55,  1.31s/it]Loading train:   5%|▌         | 15/285 [00:21<05:53,  1.31s/it]Loading train:   6%|▌         | 16/285 [00:22<05:50,  1.30s/it]Loading train:   6%|▌         | 17/285 [00:23<05:20,  1.20s/it]Loading train:   6%|▋         | 18/285 [00:25<05:30,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:25<05:00,  1.13s/it]Loading train:   7%|▋         | 20/285 [00:27<05:15,  1.19s/it]Loading train:   7%|▋         | 21/285 [00:28<05:09,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:29<05:04,  1.16s/it]Loading train:   8%|▊         | 23/285 [00:30<05:09,  1.18s/it]Loading train:   8%|▊         | 24/285 [00:31<04:40,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:32<04:35,  1.06s/it]Loading train:   9%|▉         | 26/285 [00:33<04:42,  1.09s/it]Loading train:   9%|▉         | 27/285 [00:34<04:29,  1.05s/it]Loading train:  10%|▉         | 28/285 [00:35<04:34,  1.07s/it]Loading train:  10%|█         | 29/285 [00:37<04:52,  1.14s/it]Loading train:  11%|█         | 30/285 [00:38<04:36,  1.09s/it]Loading train:  11%|█         | 31/285 [00:39<04:50,  1.14s/it]Loading train:  11%|█         | 32/285 [00:40<04:34,  1.08s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:43,  1.13s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:40,  1.12s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:43,  1.13s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:36,  1.11s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:30,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:47,  1.16s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:36,  1.12s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:25,  1.08s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:15,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:05,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:35,  1.14s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:27,  1.11s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:01,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:34,  1.15s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:09,  1.05s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:17,  1.09s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:21,  1.11s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:36,  1.18s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:26,  1.14s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:45,  1.23s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:31,  1.17s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:06,  1.07s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:12,  1.10s/it]Loading train:  20%|██        | 57/285 [01:08<04:39,  1.22s/it]Loading train:  20%|██        | 58/285 [01:09<04:34,  1.21s/it]Loading train:  21%|██        | 59/285 [01:10<04:28,  1.19s/it]Loading train:  21%|██        | 60/285 [01:12<04:37,  1.23s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:28,  1.20s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:15,  1.15s/it]Loading train:  22%|██▏       | 63/285 [01:15<04:04,  1.10s/it]Loading train:  22%|██▏       | 64/285 [01:16<04:32,  1.23s/it]Loading train:  23%|██▎       | 65/285 [01:18<05:13,  1.42s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:22,  1.47s/it]Loading train:  24%|██▎       | 67/285 [01:21<04:54,  1.35s/it]Loading train:  24%|██▍       | 68/285 [01:22<04:25,  1.22s/it]Loading train:  24%|██▍       | 69/285 [01:23<04:18,  1.20s/it]Loading train:  25%|██▍       | 70/285 [01:24<04:00,  1.12s/it]Loading train:  25%|██▍       | 71/285 [01:25<03:48,  1.07s/it]Loading train:  25%|██▌       | 72/285 [01:26<03:33,  1.00s/it]Loading train:  26%|██▌       | 73/285 [01:27<03:30,  1.01it/s]Loading train:  26%|██▌       | 74/285 [01:28<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:29<03:56,  1.13s/it]Loading train:  27%|██▋       | 76/285 [01:30<03:48,  1.09s/it]Loading train:  27%|██▋       | 77/285 [01:31<03:34,  1.03s/it]Loading train:  27%|██▋       | 78/285 [01:32<03:41,  1.07s/it]Loading train:  28%|██▊       | 79/285 [01:33<03:42,  1.08s/it]Loading train:  28%|██▊       | 80/285 [01:35<04:10,  1.22s/it]Loading train:  28%|██▊       | 81/285 [01:36<04:20,  1.27s/it]Loading train:  29%|██▉       | 82/285 [01:37<04:02,  1.19s/it]Loading train:  29%|██▉       | 83/285 [01:38<04:03,  1.21s/it]Loading train:  29%|██▉       | 84/285 [01:40<04:09,  1.24s/it]Loading train:  30%|██▉       | 85/285 [01:41<04:11,  1.26s/it]Loading train:  30%|███       | 86/285 [01:43<04:59,  1.51s/it]Loading train:  31%|███       | 87/285 [01:45<04:50,  1.47s/it]Loading train:  31%|███       | 88/285 [01:46<04:26,  1.35s/it]Loading train:  31%|███       | 89/285 [01:47<04:11,  1.29s/it]Loading train:  32%|███▏      | 90/285 [01:48<04:00,  1.23s/it]Loading train:  32%|███▏      | 91/285 [01:49<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:50<04:00,  1.25s/it]Loading train:  33%|███▎      | 93/285 [01:52<04:02,  1.27s/it]Loading train:  33%|███▎      | 94/285 [01:53<04:00,  1.26s/it]Loading train:  33%|███▎      | 95/285 [01:55<04:22,  1.38s/it]Loading train:  34%|███▎      | 96/285 [01:56<04:26,  1.41s/it]Loading train:  34%|███▍      | 97/285 [01:57<04:20,  1.39s/it]Loading train:  34%|███▍      | 98/285 [01:59<04:15,  1.37s/it]Loading train:  35%|███▍      | 99/285 [02:01<04:44,  1.53s/it]Loading train:  35%|███▌      | 100/285 [02:02<04:37,  1.50s/it]Loading train:  35%|███▌      | 101/285 [02:03<04:33,  1.49s/it]Loading train:  36%|███▌      | 102/285 [02:05<04:15,  1.40s/it]Loading train:  36%|███▌      | 103/285 [02:06<04:04,  1.34s/it]Loading train:  36%|███▋      | 104/285 [02:07<04:05,  1.36s/it]Loading train:  37%|███▋      | 105/285 [02:09<04:02,  1.35s/it]Loading train:  37%|███▋      | 106/285 [02:10<04:15,  1.43s/it]Loading train:  38%|███▊      | 107/285 [02:12<04:33,  1.54s/it]Loading train:  38%|███▊      | 108/285 [02:13<04:06,  1.39s/it]Loading train:  38%|███▊      | 109/285 [02:14<03:52,  1.32s/it]Loading train:  39%|███▊      | 110/285 [02:16<04:07,  1.41s/it]Loading train:  39%|███▉      | 111/285 [02:17<04:01,  1.39s/it]Loading train:  39%|███▉      | 112/285 [02:19<04:13,  1.47s/it]Loading train:  40%|███▉      | 113/285 [02:21<04:34,  1.59s/it]Loading train:  40%|████      | 114/285 [02:22<04:17,  1.50s/it]Loading train:  40%|████      | 115/285 [02:23<04:15,  1.50s/it]Loading train:  41%|████      | 116/285 [02:25<04:25,  1.57s/it]Loading train:  41%|████      | 117/285 [02:26<04:09,  1.49s/it]Loading train:  41%|████▏     | 118/285 [02:28<04:01,  1.44s/it]Loading train:  42%|████▏     | 119/285 [02:29<04:02,  1.46s/it]Loading train:  42%|████▏     | 120/285 [02:30<03:39,  1.33s/it]Loading train:  42%|████▏     | 121/285 [02:32<03:52,  1.42s/it]Loading train:  43%|████▎     | 122/285 [02:33<03:50,  1.42s/it]Loading train:  43%|████▎     | 123/285 [02:35<03:45,  1.39s/it]Loading train:  44%|████▎     | 124/285 [02:36<03:58,  1.48s/it]Loading train:  44%|████▍     | 125/285 [02:38<03:46,  1.41s/it]Loading train:  44%|████▍     | 126/285 [02:39<03:31,  1.33s/it]Loading train:  45%|████▍     | 127/285 [02:40<03:43,  1.41s/it]Loading train:  45%|████▍     | 128/285 [02:41<03:24,  1.31s/it]Loading train:  45%|████▌     | 129/285 [02:42<03:09,  1.22s/it]Loading train:  46%|████▌     | 130/285 [02:44<03:06,  1.21s/it]Loading train:  46%|████▌     | 131/285 [02:45<03:12,  1.25s/it]Loading train:  46%|████▋     | 132/285 [02:46<03:15,  1.28s/it]Loading train:  47%|████▋     | 133/285 [02:47<03:03,  1.21s/it]Loading train:  47%|████▋     | 134/285 [02:48<02:54,  1.16s/it]Loading train:  47%|████▋     | 135/285 [02:50<03:06,  1.25s/it]Loading train:  48%|████▊     | 136/285 [02:51<03:00,  1.21s/it]Loading train:  48%|████▊     | 137/285 [02:52<02:56,  1.19s/it]Loading train:  48%|████▊     | 138/285 [02:53<02:45,  1.12s/it]Loading train:  49%|████▉     | 139/285 [02:54<02:51,  1.18s/it]Loading train:  49%|████▉     | 140/285 [02:56<02:59,  1.24s/it]Loading train:  49%|████▉     | 141/285 [02:57<02:50,  1.18s/it]Loading train:  50%|████▉     | 142/285 [02:58<02:52,  1.20s/it]Loading train:  50%|█████     | 143/285 [02:59<02:41,  1.14s/it]Loading train:  51%|█████     | 144/285 [03:00<02:34,  1.10s/it]Loading train:  51%|█████     | 145/285 [03:01<02:43,  1.17s/it]Loading train:  51%|█████     | 146/285 [03:03<02:47,  1.21s/it]Loading train:  52%|█████▏    | 147/285 [03:04<02:39,  1.16s/it]Loading train:  52%|█████▏    | 148/285 [03:05<02:52,  1.26s/it]Loading train:  52%|█████▏    | 149/285 [03:07<02:49,  1.24s/it]Loading train:  53%|█████▎    | 150/285 [03:07<02:35,  1.15s/it]Loading train:  53%|█████▎    | 151/285 [03:09<02:36,  1.17s/it]Loading train:  53%|█████▎    | 152/285 [03:10<02:40,  1.21s/it]Loading train:  54%|█████▎    | 153/285 [03:11<02:40,  1.21s/it]Loading train:  54%|█████▍    | 154/285 [03:12<02:42,  1.24s/it]Loading train:  54%|█████▍    | 155/285 [03:14<02:40,  1.23s/it]Loading train:  55%|█████▍    | 156/285 [03:15<02:53,  1.35s/it]Loading train:  55%|█████▌    | 157/285 [03:17<02:52,  1.35s/it]Loading train:  55%|█████▌    | 158/285 [03:18<02:55,  1.38s/it]Loading train:  56%|█████▌    | 159/285 [03:19<02:52,  1.37s/it]Loading train:  56%|█████▌    | 160/285 [03:21<02:40,  1.29s/it]Loading train:  56%|█████▋    | 161/285 [03:22<02:50,  1.38s/it]Loading train:  57%|█████▋    | 162/285 [03:23<02:45,  1.35s/it]Loading train:  57%|█████▋    | 163/285 [03:25<02:51,  1.40s/it]Loading train:  58%|█████▊    | 164/285 [03:26<02:37,  1.30s/it]Loading train:  58%|█████▊    | 165/285 [03:28<02:48,  1.40s/it]Loading train:  58%|█████▊    | 166/285 [03:29<02:47,  1.41s/it]Loading train:  59%|█████▊    | 167/285 [03:30<02:33,  1.30s/it]Loading train:  59%|█████▉    | 168/285 [03:31<02:31,  1.29s/it]Loading train:  59%|█████▉    | 169/285 [03:33<02:28,  1.28s/it]Loading train:  60%|█████▉    | 170/285 [03:34<02:30,  1.31s/it]Loading train:  60%|██████    | 171/285 [03:35<02:28,  1.31s/it]Loading train:  60%|██████    | 172/285 [03:37<02:34,  1.37s/it]Loading train:  61%|██████    | 173/285 [03:38<02:31,  1.35s/it]Loading train:  61%|██████    | 174/285 [03:39<02:22,  1.29s/it]Loading train:  61%|██████▏   | 175/285 [03:41<02:23,  1.31s/it]Loading train:  62%|██████▏   | 176/285 [03:42<02:25,  1.33s/it]Loading train:  62%|██████▏   | 177/285 [03:43<02:22,  1.32s/it]Loading train:  62%|██████▏   | 178/285 [03:45<02:31,  1.41s/it]Loading train:  63%|██████▎   | 179/285 [03:46<02:31,  1.43s/it]Loading train:  63%|██████▎   | 180/285 [03:48<02:34,  1.47s/it]Loading train:  64%|██████▎   | 181/285 [03:50<02:40,  1.54s/it]Loading train:  64%|██████▍   | 182/285 [03:51<02:27,  1.44s/it]Loading train:  64%|██████▍   | 183/285 [03:52<02:19,  1.37s/it]Loading train:  65%|██████▍   | 184/285 [03:53<02:14,  1.33s/it]Loading train:  65%|██████▍   | 185/285 [03:54<02:04,  1.24s/it]Loading train:  65%|██████▌   | 186/285 [03:56<02:11,  1.33s/it]Loading train:  66%|██████▌   | 187/285 [03:58<02:25,  1.48s/it]Loading train:  66%|██████▌   | 188/285 [03:59<02:23,  1.48s/it]Loading train:  66%|██████▋   | 189/285 [04:00<02:12,  1.38s/it]Loading train:  67%|██████▋   | 190/285 [04:02<02:15,  1.43s/it]Loading train:  67%|██████▋   | 191/285 [04:03<02:07,  1.36s/it]Loading train:  67%|██████▋   | 192/285 [04:04<02:05,  1.35s/it]Loading train:  68%|██████▊   | 193/285 [04:06<02:05,  1.36s/it]Loading train:  68%|██████▊   | 194/285 [04:07<01:52,  1.24s/it]Loading train:  68%|██████▊   | 195/285 [04:08<01:47,  1.19s/it]Loading train:  69%|██████▉   | 196/285 [04:09<01:45,  1.18s/it]Loading train:  69%|██████▉   | 197/285 [04:11<01:52,  1.28s/it]Loading train:  69%|██████▉   | 198/285 [04:12<01:48,  1.25s/it]Loading train:  70%|██████▉   | 199/285 [04:13<01:40,  1.17s/it]Loading train:  70%|███████   | 200/285 [04:14<01:41,  1.20s/it]Loading train:  71%|███████   | 201/285 [04:16<01:52,  1.34s/it]Loading train:  71%|███████   | 202/285 [04:17<01:50,  1.33s/it]Loading train:  71%|███████   | 203/285 [04:18<01:47,  1.31s/it]Loading train:  72%|███████▏  | 204/285 [04:19<01:39,  1.23s/it]Loading train:  72%|███████▏  | 205/285 [04:21<01:40,  1.25s/it]Loading train:  72%|███████▏  | 206/285 [04:22<01:36,  1.22s/it]Loading train:  73%|███████▎  | 207/285 [04:23<01:49,  1.40s/it]Loading train:  73%|███████▎  | 208/285 [04:25<01:46,  1.38s/it]Loading train:  73%|███████▎  | 209/285 [04:27<01:53,  1.49s/it]Loading train:  74%|███████▎  | 210/285 [04:28<01:45,  1.40s/it]Loading train:  74%|███████▍  | 211/285 [04:29<01:48,  1.47s/it]Loading train:  74%|███████▍  | 212/285 [04:31<01:40,  1.38s/it]Loading train:  75%|███████▍  | 213/285 [04:32<01:31,  1.27s/it]Loading train:  75%|███████▌  | 214/285 [04:33<01:22,  1.16s/it]Loading train:  75%|███████▌  | 215/285 [04:34<01:25,  1.22s/it]Loading train:  76%|███████▌  | 216/285 [04:35<01:24,  1.23s/it]Loading train:  76%|███████▌  | 217/285 [04:37<01:40,  1.47s/it]Loading train:  76%|███████▋  | 218/285 [04:39<01:43,  1.55s/it]Loading train:  77%|███████▋  | 219/285 [04:40<01:40,  1.52s/it]Loading train:  77%|███████▋  | 220/285 [04:41<01:26,  1.33s/it]Loading train:  78%|███████▊  | 221/285 [04:42<01:22,  1.29s/it]Loading train:  78%|███████▊  | 222/285 [04:44<01:23,  1.32s/it]Loading train:  78%|███████▊  | 223/285 [04:45<01:21,  1.32s/it]Loading train:  79%|███████▊  | 224/285 [04:46<01:20,  1.31s/it]Loading train:  79%|███████▉  | 225/285 [04:47<01:12,  1.21s/it]Loading train:  79%|███████▉  | 226/285 [04:49<01:19,  1.34s/it]Loading train:  80%|███████▉  | 227/285 [04:50<01:18,  1.36s/it]Loading train:  80%|████████  | 228/285 [04:52<01:20,  1.42s/it]Loading train:  80%|████████  | 229/285 [04:53<01:18,  1.41s/it]Loading train:  81%|████████  | 230/285 [04:54<01:09,  1.26s/it]Loading train:  81%|████████  | 231/285 [04:56<01:10,  1.31s/it]Loading train:  81%|████████▏ | 232/285 [04:57<01:07,  1.26s/it]Loading train:  82%|████████▏ | 233/285 [04:58<01:06,  1.27s/it]Loading train:  82%|████████▏ | 234/285 [05:00<01:07,  1.32s/it]Loading train:  82%|████████▏ | 235/285 [05:01<01:05,  1.32s/it]Loading train:  83%|████████▎ | 236/285 [05:03<01:08,  1.40s/it]Loading train:  83%|████████▎ | 237/285 [05:04<01:06,  1.38s/it]Loading train:  84%|████████▎ | 238/285 [05:06<01:09,  1.48s/it]Loading train:  84%|████████▍ | 239/285 [05:07<01:03,  1.39s/it]Loading train:  84%|████████▍ | 240/285 [05:08<01:02,  1.39s/it]Loading train:  85%|████████▍ | 241/285 [05:10<01:01,  1.39s/it]Loading train:  85%|████████▍ | 242/285 [05:11<00:55,  1.29s/it]Loading train:  85%|████████▌ | 243/285 [05:12<00:56,  1.35s/it]Loading train:  86%|████████▌ | 244/285 [05:14<00:59,  1.46s/it]Loading train:  86%|████████▌ | 245/285 [05:15<00:53,  1.34s/it]Loading train:  86%|████████▋ | 246/285 [05:16<00:55,  1.42s/it]Loading train:  87%|████████▋ | 247/285 [05:18<00:54,  1.44s/it]Loading train:  87%|████████▋ | 248/285 [05:19<00:51,  1.41s/it]Loading train:  87%|████████▋ | 249/285 [05:21<00:49,  1.38s/it]Loading train:  88%|████████▊ | 250/285 [05:22<00:43,  1.25s/it]Loading train:  88%|████████▊ | 251/285 [05:22<00:39,  1.15s/it]Loading train:  88%|████████▊ | 252/285 [05:23<00:34,  1.04s/it]Loading train:  89%|████████▉ | 253/285 [05:24<00:34,  1.08s/it]Loading train:  89%|████████▉ | 254/285 [05:26<00:35,  1.15s/it]Loading train:  89%|████████▉ | 255/285 [05:27<00:35,  1.17s/it]Loading train:  90%|████████▉ | 256/285 [05:28<00:34,  1.18s/it]Loading train:  90%|█████████ | 257/285 [05:29<00:33,  1.20s/it]Loading train:  91%|█████████ | 258/285 [05:31<00:36,  1.36s/it]Loading train:  91%|█████████ | 259/285 [05:33<00:36,  1.41s/it]Loading train:  91%|█████████ | 260/285 [05:34<00:34,  1.39s/it]Loading train:  92%|█████████▏| 261/285 [05:35<00:32,  1.34s/it]Loading train:  92%|█████████▏| 262/285 [05:36<00:29,  1.28s/it]Loading train:  92%|█████████▏| 263/285 [05:38<00:31,  1.43s/it]Loading train:  93%|█████████▎| 264/285 [05:39<00:28,  1.37s/it]Loading train:  93%|█████████▎| 265/285 [05:41<00:28,  1.44s/it]Loading train:  93%|█████████▎| 266/285 [05:42<00:27,  1.44s/it]Loading train:  94%|█████████▎| 267/285 [05:44<00:25,  1.40s/it]Loading train:  94%|█████████▍| 268/285 [05:46<00:26,  1.55s/it]Loading train:  94%|█████████▍| 269/285 [05:47<00:24,  1.51s/it]Loading train:  95%|█████████▍| 270/285 [05:48<00:20,  1.34s/it]Loading train:  95%|█████████▌| 271/285 [05:50<00:20,  1.49s/it]Loading train:  95%|█████████▌| 272/285 [05:51<00:17,  1.38s/it]Loading train:  96%|█████████▌| 273/285 [05:52<00:15,  1.32s/it]Loading train:  96%|█████████▌| 274/285 [05:53<00:14,  1.32s/it]Loading train:  96%|█████████▋| 275/285 [05:55<00:13,  1.38s/it]Loading train:  97%|█████████▋| 276/285 [05:57<00:13,  1.49s/it]Loading train:  97%|█████████▋| 277/285 [05:58<00:11,  1.38s/it]Loading train:  98%|█████████▊| 278/285 [05:59<00:08,  1.23s/it]Loading train:  98%|█████████▊| 279/285 [06:00<00:07,  1.29s/it]Loading train:  98%|█████████▊| 280/285 [06:01<00:06,  1.27s/it]Loading train:  99%|█████████▊| 281/285 [06:03<00:05,  1.27s/it]Loading train:  99%|█████████▉| 282/285 [06:04<00:03,  1.18s/it]Loading train:  99%|█████████▉| 283/285 [06:05<00:02,  1.27s/it]Loading train: 100%|█████████▉| 284/285 [06:07<00:01,  1.32s/it]Loading train: 100%|██████████| 285/285 [06:09<00:00,  1.52s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:04, 69.14it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 61.41it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:07, 36.96it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:05, 44.03it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:07, 34.39it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:05, 41.96it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:04, 51.86it/s]concatenating: train:  21%|██        | 60/285 [00:01<00:03, 58.08it/s]concatenating: train:  24%|██▍       | 69/285 [00:01<00:03, 64.38it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:02, 75.35it/s]concatenating: train:  33%|███▎      | 94/285 [00:01<00:02, 82.30it/s]concatenating: train:  36%|███▋      | 104/285 [00:01<00:02, 75.56it/s]concatenating: train:  40%|███▉      | 113/285 [00:01<00:02, 72.36it/s]concatenating: train:  42%|████▏     | 121/285 [00:01<00:02, 59.41it/s]concatenating: train:  47%|████▋     | 134/285 [00:01<00:02, 70.46it/s]concatenating: train:  51%|█████     | 144/285 [00:02<00:01, 76.60it/s]concatenating: train:  54%|█████▍    | 155/285 [00:02<00:01, 82.76it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:01, 63.58it/s]concatenating: train:  61%|██████    | 173/285 [00:02<00:02, 47.72it/s]concatenating: train:  64%|██████▎   | 181/285 [00:02<00:01, 53.81it/s]concatenating: train:  68%|██████▊   | 193/285 [00:02<00:01, 64.06it/s]concatenating: train:  72%|███████▏  | 206/285 [00:02<00:01, 75.04it/s]concatenating: train:  76%|███████▋  | 218/285 [00:03<00:00, 84.54it/s]concatenating: train:  81%|████████  | 231/285 [00:03<00:00, 93.64it/s]concatenating: train:  85%|████████▍ | 242/285 [00:03<00:00, 78.57it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 65.76it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 86.45it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.65s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.66s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.57s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 18.79it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 23.72it/s]2019-07-11 02:05:13.294359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:05:13.294470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:05:13.294485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:05:13.294493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:05:13.294888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.92it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.57it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.63it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.88it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.75it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.81it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.24it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.91it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.08it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:03,  6.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.16it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.05it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  6.50it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:01,  7.44it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.97it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.36it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.75it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.69it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.89it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.37it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  8.99it/s]
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 10)   4060        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 55)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   728         concatenate_8[0][0]              
==================================================================================================
Total params: 132,198
Trainable params: 33,698
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 2.8029 - acc: 0.6808 - mDice: 0.0958 - val_loss: 2.6434 - val_acc: 0.9036 - val_mDice: 0.1772

Epoch 00001: val_mDice improved from -inf to 0.17717, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 8s - loss: 1.1804 - acc: 0.8822 - mDice: 0.3099 - val_loss: 5.1577 - val_acc: 0.9054 - val_mDice: 0.0701

Epoch 00002: val_mDice did not improve from 0.17717
Epoch 3/300
 - 9s - loss: 0.7177 - acc: 0.8965 - mDice: 0.4726 - val_loss: 1.5927 - val_acc: 0.9163 - val_mDice: 0.3030

Epoch 00003: val_mDice improved from 0.17717 to 0.30295, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.5783 - acc: 0.9057 - mDice: 0.5443 - val_loss: 1.1002 - val_acc: 0.9337 - val_mDice: 0.5096

Epoch 00004: val_mDice improved from 0.30295 to 0.50959, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.5192 - acc: 0.9112 - mDice: 0.5796 - val_loss: 1.0724 - val_acc: 0.9409 - val_mDice: 0.5335

Epoch 00005: val_mDice improved from 0.50959 to 0.53352, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.4840 - acc: 0.9156 - mDice: 0.6009 - val_loss: 1.0270 - val_acc: 0.9424 - val_mDice: 0.5434

Epoch 00006: val_mDice improved from 0.53352 to 0.54337, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.4598 - acc: 0.9201 - mDice: 0.6163 - val_loss: 0.9411 - val_acc: 0.9442 - val_mDice: 0.5798

Epoch 00007: val_mDice improved from 0.54337 to 0.57984, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.4457 - acc: 0.9237 - mDice: 0.6254 - val_loss: 0.9700 - val_acc: 0.9444 - val_mDice: 0.5695

Epoch 00008: val_mDice did not improve from 0.57984
Epoch 9/300
 - 9s - loss: 0.4347 - acc: 0.9265 - mDice: 0.6326 - val_loss: 0.9388 - val_acc: 0.9444 - val_mDice: 0.5778

Epoch 00009: val_mDice did not improve from 0.57984
Epoch 10/300
 - 8s - loss: 0.4245 - acc: 0.9280 - mDice: 0.6393 - val_loss: 0.9707 - val_acc: 0.9433 - val_mDice: 0.5698

Epoch 00010: val_mDice did not improve from 0.57984
Epoch 11/300
 - 8s - loss: 0.4121 - acc: 0.9297 - mDice: 0.6472 - val_loss: 0.9262 - val_acc: 0.9426 - val_mDice: 0.5873

Epoch 00011: val_mDice improved from 0.57984 to 0.58727, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 8s - loss: 0.4049 - acc: 0.9306 - mDice: 0.6522 - val_loss: 0.9959 - val_acc: 0.9445 - val_mDice: 0.5514

Epoch 00012: val_mDice did not improve from 0.58727
Epoch 13/300
 - 9s - loss: 0.4005 - acc: 0.9311 - mDice: 0.6552 - val_loss: 0.9500 - val_acc: 0.9450 - val_mDice: 0.5741

Epoch 00013: val_mDice did not improve from 0.58727
Epoch 14/300
 - 9s - loss: 0.3947 - acc: 0.9318 - mDice: 0.6592 - val_loss: 0.9786 - val_acc: 0.9411 - val_mDice: 0.5622

Epoch 00014: val_mDice did not improve from 0.58727
Epoch 15/300
 - 8s - loss: 0.3893 - acc: 0.9325 - mDice: 0.6629 - val_loss: 0.9452 - val_acc: 0.9451 - val_mDice: 0.5629

Epoch 00015: val_mDice did not improve from 0.58727
Epoch 16/300
 - 8s - loss: 0.3833 - acc: 0.9330 - mDice: 0.6668 - val_loss: 0.9505 - val_acc: 0.9448 - val_mDice: 0.5625

Epoch 00016: val_mDice did not improve from 0.58727
Epoch 17/300
 - 8s - loss: 0.3807 - acc: 0.9333 - mDice: 0.6686 - val_loss: 0.9489 - val_acc: 0.9416 - val_mDice: 0.5616

Epoch 00017: val_mDice did not improve from 0.58727
Epoch 18/300
 - 8s - loss: 0.3766 - acc: 0.9338 - mDice: 0.6714 - val_loss: 0.8853 - val_acc: 0.9403 - val_mDice: 0.5864

Epoch 00018: val_mDice did not improve from 0.58727
Epoch 19/300
 - 8s - loss: 0.3722 - acc: 0.9343 - mDice: 0.6745 - val_loss: 0.9042 - val_acc: 0.9426 - val_mDice: 0.5790

Epoch 00019: val_mDice did not improve from 0.58727
Epoch 20/300
 - 9s - loss: 0.3703 - acc: 0.9343 - mDice: 0.6757 - val_loss: 0.9190 - val_acc: 0.9299 - val_mDice: 0.5689

Epoch 00020: val_mDice did not improve from 0.58727
Epoch 21/300
 - 9s - loss: 0.3666 - acc: 0.9349 - mDice: 0.6785 - val_loss: 0.9419 - val_acc: 0.9314 - val_mDice: 0.5663

Epoch 00021: val_mDice did not improve from 0.58727
Epoch 22/300
 - 8s - loss: 0.3613 - acc: 0.9356 - mDice: 0.6820 - val_loss: 0.9541 - val_acc: 0.9311 - val_mDice: 0.5588

Epoch 00022: val_mDice did not improve from 0.58727
Epoch 23/300
 - 9s - loss: 0.3607 - acc: 0.9356 - mDice: 0.6825 - val_loss: 0.8779 - val_acc: 0.9408 - val_mDice: 0.5722

Epoch 00023: val_mDice did not improve from 0.58727
Epoch 24/300
 - 8s - loss: 0.3572 - acc: 0.9358 - mDice: 0.6849 - val_loss: 0.8755 - val_acc: 0.9398 - val_mDice: 0.5702

Epoch 00024: val_mDice did not improve from 0.58727
Epoch 25/300
 - 8s - loss: 0.3558 - acc: 0.9362 - mDice: 0.6859 - val_loss: 0.8912 - val_acc: 0.9428 - val_mDice: 0.5578

Epoch 00025: val_mDice did not improve from 0.58727
Epoch 26/300
 - 9s - loss: 0.3534 - acc: 0.9366 - mDice: 0.6876 - val_loss: 0.8601 - val_acc: 0.9435 - val_mDice: 0.5688

Epoch 00026: val_mDice did not improve from 0.58727
Epoch 27/300
 - 9s - loss: 0.3513 - acc: 0.9368 - mDice: 0.6891 - val_loss: 0.8559 - val_acc: 0.9430 - val_mDice: 0.5708

Epoch 00027: val_mDice did not improve from 0.58727
Epoch 28/300
 - 9s - loss: 0.3491 - acc: 0.9370 - mDice: 0.6907 - val_loss: 0.8933 - val_acc: 0.9432 - val_mDice: 0.5527

Epoch 00028: val_mDice did not improve from 0.58727
Epoch 29/300
 - 8s - loss: 0.3461 - acc: 0.9372 - mDice: 0.6928 - val_loss: 0.8468 - val_acc: 0.9396 - val_mDice: 0.5709

Epoch 00029: val_mDice did not improve from 0.58727
Epoch 30/300
 - 8s - loss: 0.3449 - acc: 0.9375 - mDice: 0.6938 - val_loss: 0.8708 - val_acc: 0.9402 - val_mDice: 0.5700

Epoch 00030: val_mDice did not improve from 0.58727
Epoch 31/300
 - 9s - loss: 0.3433 - acc: 0.9374 - mDice: 0.6948 - val_loss: 0.8084 - val_acc: 0.9411 - val_mDice: 0.5686

Epoch 00031: val_mDice did not improve from 0.58727
Epoch 32/300
 - 9s - loss: 0.3417 - acc: 0.9375 - mDice: 0.6960 - val_loss: 0.8141 - val_acc: 0.9383 - val_mDice: 0.5719

Epoch 00032: val_mDice did not improve from 0.58727
Epoch 33/300
 - 8s - loss: 0.3387 - acc: 0.9378 - mDice: 0.6982 - val_loss: 0.8226 - val_acc: 0.9444 - val_mDice: 0.5709

Epoch 00033: val_mDice did not improve from 0.58727
Epoch 34/300
 - 8s - loss: 0.3385 - acc: 0.9378 - mDice: 0.6983 - val_loss: 0.8346 - val_acc: 0.9326 - val_mDice: 0.5638

Epoch 00034: val_mDice did not improve from 0.58727
Epoch 35/300
 - 8s - loss: 0.3357 - acc: 0.9382 - mDice: 0.7003 - val_loss: 0.7900 - val_acc: 0.9434 - val_mDice: 0.5709

Epoch 00035: val_mDice did not improve from 0.58727
Epoch 36/300
 - 8s - loss: 0.3378 - acc: 0.9379 - mDice: 0.6987 - val_loss: 0.7972 - val_acc: 0.9452 - val_mDice: 0.5650

Epoch 00036: val_mDice did not improve from 0.58727
Epoch 37/300
 - 9s - loss: 0.3335 - acc: 0.9384 - mDice: 0.7019 - val_loss: 0.8036 - val_acc: 0.9419 - val_mDice: 0.5717

Epoch 00037: val_mDice did not improve from 0.58727
Epoch 38/300
 - 8s - loss: 0.3322 - acc: 0.9385 - mDice: 0.7028 - val_loss: 0.7497 - val_acc: 0.9439 - val_mDice: 0.5707

Epoch 00038: val_mDice did not improve from 0.58727
Epoch 39/300
 - 9s - loss: 0.3298 - acc: 0.9387 - mDice: 0.7046 - val_loss: 0.8121 - val_acc: 0.9412 - val_mDice: 0.5573

Epoch 00039: val_mDice did not improve from 0.58727
Epoch 40/300
 - 8s - loss: 0.3276 - acc: 0.9388 - mDice: 0.7062 - val_loss: 0.7354 - val_acc: 0.9439 - val_mDice: 0.5744

Epoch 00040: val_mDice did not improve from 0.58727
Epoch 41/300
 - 8s - loss: 0.3277 - acc: 0.9389 - mDice: 0.7061 - val_loss: 0.8361 - val_acc: 0.9438 - val_mDice: 0.5535

Epoch 00041: val_mDice did not improve from 0.58727
Epoch 42/300
 - 9s - loss: 0.3278 - acc: 0.9389 - mDice: 0.7061 - val_loss: 0.7583 - val_acc: 0.9446 - val_mDice: 0.5664

Epoch 00042: val_mDice did not improve from 0.58727
Epoch 43/300
 - 9s - loss: 0.3241 - acc: 0.9392 - mDice: 0.7087 - val_loss: 0.7155 - val_acc: 0.9451 - val_mDice: 0.5795

Epoch 00043: val_mDice did not improve from 0.58727
Epoch 44/300
 - 8s - loss: 0.3240 - acc: 0.9393 - mDice: 0.7088 - val_loss: 0.7587 - val_acc: 0.9449 - val_mDice: 0.5674

Epoch 00044: val_mDice did not improve from 0.58727
Epoch 45/300
 - 9s - loss: 0.3244 - acc: 0.9391 - mDice: 0.7084 - val_loss: 0.7438 - val_acc: 0.9412 - val_mDice: 0.5709

Epoch 00045: val_mDice did not improve from 0.58727
Epoch 46/300
 - 8s - loss: 0.3228 - acc: 0.9393 - mDice: 0.7096 - val_loss: 0.7922 - val_acc: 0.9413 - val_mDice: 0.5652

Epoch 00046: val_mDice did not improve from 0.58727
Epoch 47/300
 - 9s - loss: 0.3219 - acc: 0.9395 - mDice: 0.7104 - val_loss: 0.7318 - val_acc: 0.9446 - val_mDice: 0.5670

Epoch 00047: val_mDice did not improve from 0.58727
Epoch 48/300
 - 9s - loss: 0.3204 - acc: 0.9395 - mDice: 0.7115 - val_loss: 0.6859 - val_acc: 0.9424 - val_mDice: 0.5688

Epoch 00048: val_mDice did not improve from 0.58727
Epoch 49/300
 - 8s - loss: 0.3185 - acc: 0.9397 - mDice: 0.7128 - val_loss: 0.7630 - val_acc: 0.9398 - val_mDice: 0.5665

Epoch 00049: val_mDice did not improve from 0.58727
Epoch 50/300
 - 9s - loss: 0.3168 - acc: 0.9399 - mDice: 0.7141 - val_loss: 0.6791 - val_acc: 0.9406 - val_mDice: 0.5729

Epoch 00050: val_mDice did not improve from 0.58727
Epoch 51/300
 - 8s - loss: 0.3175 - acc: 0.9399 - mDice: 0.7136 - val_loss: 0.6949 - val_acc: 0.9399 - val_mDice: 0.5667

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.98s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.79s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:04,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:25,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:04,  1.72s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:44,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:48,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:31,  1.62s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:46,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:34,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:00,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:46,  1.70s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:11,  1.80s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:57,  1.75s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:07,  1.80s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:20,  1.85s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:22,  1.87s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:58,  1.78s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:56,  1.78s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:33,  1.70s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:41,  1.74s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:51,  1.78s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:33,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:37,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:14,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:38,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:49,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:28,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:26,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:33,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:47,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:26,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:33,  1.80s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:43,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:54,  1.90s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:31,  1.82s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:30,  1.83s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:13,  1.76s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:08,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:50,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:33,  1.62s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:42,  1.66s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:04,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:44,  1.69s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<06:58,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:45,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<07:00,  1.78s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:19,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:18,  1.87s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:19,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<06:57,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<07:04,  1.83s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:14,  1.88s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:47,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:40,  1.75s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:26,  1.69s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:43,  1.78s/it]predicting train subjects:  21%|██        | 60/285 [01:45<07:03,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:42,  1.80s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:43,  1.81s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:45,  1.83s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:28,  1.76s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:36,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:28,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:16,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:13,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:15,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<05:57,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:07,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:09,  1.76s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:18,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:12,  1.79s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:55,  1.73s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:52,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:33,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:25,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:37,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:47,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:43,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:38,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:34,  1.71s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:33,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:27,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:37,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:24,  1.69s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:24,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:25,  1.71s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:21,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:28,  1.75s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:25,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:54<05:26,  1.76s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:14,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:12,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:59<05:05,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:10,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:10,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:07,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:06<05:10,  1.75s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<05:03,  1.72s/it]predicting train subjects:  38%|███▊      | 109/285 [03:10<05:10,  1.76s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:17,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<05:08,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:15<05:01,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:17<05:01,  1.75s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:52,  1.71s/it]predicting train subjects:  40%|████      | 115/285 [03:20<04:53,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:22<04:53,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:24<04:48,  1.71s/it]predicting train subjects:  41%|████▏     | 118/285 [03:25<04:38,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:43,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:32,  1.65s/it]predicting train subjects:  42%|████▏     | 121/285 [03:30<04:25,  1.62s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:19,  1.59s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:13,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<03:59,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<03:55,  1.48s/it]predicting train subjects:  45%|████▍     | 127/285 [03:39<03:53,  1.48s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:56,  1.51s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<03:54,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:40,  1.43s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<03:49,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<03:34,  1.42s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:35,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<03:32,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:48,  1.55s/it]predicting train subjects:  48%|████▊     | 138/285 [03:55<03:39,  1.49s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:43,  1.53s/it]predicting train subjects:  49%|████▉     | 140/285 [03:58<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:38,  1.52s/it]predicting train subjects:  50%|████▉     | 142/285 [04:01<03:31,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:31,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:04<03:32,  1.50s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:07<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:10<03:24,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:16,  1.44s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:13<03:16,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:16<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:17<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:19<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:20<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:22<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:23<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:02,  1.44s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:26<02:58,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<02:57,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:29<02:59,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<03:04,  1.50s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:32<03:03,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:54,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:35<02:48,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:36<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:38<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:39<02:48,  1.44s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:41<02:46,  1.44s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:42<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:43,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:45<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:46<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:49<02:43,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:52<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:34,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:44,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:59<02:46,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:00<02:49,  1.64s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:02<02:37,  1.54s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:03<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:05<02:30,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:07<02:39,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:08<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:44,  1.70s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:12<02:36,  1.63s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:15<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:16<02:28,  1.60s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:18<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:21<02:15,  1.51s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:23<02:25,  1.63s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:31,  1.72s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:26<02:34,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:28<02:22,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:29<02:13,  1.57s/it]predicting train subjects:  71%|███████   | 201/285 [05:31<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:32<02:10,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:34<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:35<02:01,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:37<01:56,  1.46s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:38<01:54,  1.45s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:40<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:42<02:10,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:44<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:45<02:04,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:47<01:55,  1.56s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:48<01:53,  1.56s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:50<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:51<01:45,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:53<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:54<01:46,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:56<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:58<01:55,  1.73s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:00<01:56,  1.77s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:01<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:03<01:42,  1.60s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:05<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:06<01:38,  1.59s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:07<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:09<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:11<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:13<01:37,  1.69s/it]predicting train subjects:  80%|████████  | 228/285 [06:14<01:36,  1.68s/it]predicting train subjects:  80%|████████  | 229/285 [06:16<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:17<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:19<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:20<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:22<01:20,  1.55s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:24<01:21,  1.59s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:25<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:27<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:29<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:31<01:24,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:33<01:20,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:34<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:35<01:09,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:37<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:38<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:40<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:41<01:01,  1.54s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:43<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:45<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:47<01:01,  1.67s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:48<00:57,  1.60s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:49<00:53,  1.53s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:51<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:52<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:54<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:56<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:58<00:49,  1.66s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:59<00:45,  1.56s/it]predicting train subjects:  90%|█████████ | 257/285 [07:00<00:42,  1.52s/it]predicting train subjects:  91%|█████████ | 258/285 [07:02<00:42,  1.58s/it]predicting train subjects:  91%|█████████ | 259/285 [07:04<00:41,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [07:05<00:37,  1.48s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:06<00:34,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:08<00:33,  1.44s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:09<00:31,  1.45s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:13<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:16<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:26,  1.63s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:20<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:22<00:21,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:20,  1.57s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:25<00:18,  1.51s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:26<00:16,  1.46s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:28<00:15,  1.58s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:30<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:31<00:12,  1.57s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:33<00:11,  1.58s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:35<00:09,  1.59s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:36<00:07,  1.56s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:37<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:39<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:41<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:43<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 285/285 [07:45<00:00,  1.76s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:33,  1.81s/it]Loading train:   1%|          | 2/285 [00:03<07:50,  1.66s/it]Loading train:   1%|          | 3/285 [00:04<07:39,  1.63s/it]Loading train:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]Loading train:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]Loading train:   2%|▏         | 6/285 [00:09<07:17,  1.57s/it]Loading train:   2%|▏         | 7/285 [00:11<07:45,  1.67s/it]Loading train:   3%|▎         | 8/285 [00:12<07:23,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:14<07:50,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:15<07:19,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<06:44,  1.48s/it]Loading train:   4%|▍         | 12/285 [00:18<07:02,  1.55s/it]Loading train:   5%|▍         | 13/285 [00:20<06:47,  1.50s/it]Loading train:   5%|▍         | 14/285 [00:21<06:29,  1.44s/it]Loading train:   5%|▌         | 15/285 [00:22<06:23,  1.42s/it]Loading train:   6%|▌         | 16/285 [00:24<06:12,  1.39s/it]Loading train:   6%|▌         | 17/285 [00:25<05:52,  1.32s/it]Loading train:   6%|▋         | 18/285 [00:26<05:50,  1.31s/it]Loading train:   7%|▋         | 19/285 [00:27<05:38,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:29<05:32,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:30<05:26,  1.24s/it]Loading train:   8%|▊         | 22/285 [00:31<05:01,  1.14s/it]Loading train:   8%|▊         | 23/285 [00:32<04:55,  1.13s/it]Loading train:   8%|▊         | 24/285 [00:33<04:40,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:34<04:51,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:35<04:53,  1.13s/it]Loading train:   9%|▉         | 27/285 [00:36<04:48,  1.12s/it]Loading train:  10%|▉         | 28/285 [00:38<05:10,  1.21s/it]Loading train:  10%|█         | 29/285 [00:39<05:14,  1.23s/it]Loading train:  11%|█         | 30/285 [00:41<05:42,  1.34s/it]Loading train:  11%|█         | 31/285 [00:42<05:44,  1.36s/it]Loading train:  11%|█         | 32/285 [00:43<05:25,  1.29s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:28,  1.30s/it]Loading train:  12%|█▏        | 34/285 [00:45<05:05,  1.22s/it]Loading train:  12%|█▏        | 35/285 [00:47<05:14,  1.26s/it]Loading train:  13%|█▎        | 36/285 [00:48<04:59,  1.20s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:00,  1.21s/it]Loading train:  13%|█▎        | 38/285 [00:51<05:22,  1.31s/it]Loading train:  14%|█▎        | 39/285 [00:52<04:59,  1.22s/it]Loading train:  14%|█▍        | 40/285 [00:53<04:44,  1.16s/it]Loading train:  14%|█▍        | 41/285 [00:54<04:30,  1.11s/it]Loading train:  15%|█▍        | 42/285 [00:55<04:29,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:31,  1.12s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:58,  1.24s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:46,  1.19s/it]Loading train:  16%|█▌        | 46/285 [01:00<04:58,  1.25s/it]Loading train:  16%|█▋        | 47/285 [01:01<04:42,  1.19s/it]Loading train:  17%|█▋        | 48/285 [01:02<04:42,  1.19s/it]Loading train:  17%|█▋        | 49/285 [01:04<05:05,  1.30s/it]Loading train:  18%|█▊        | 50/285 [01:05<04:46,  1.22s/it]Loading train:  18%|█▊        | 51/285 [01:06<04:43,  1.21s/it]Loading train:  18%|█▊        | 52/285 [01:07<04:33,  1.17s/it]Loading train:  19%|█▊        | 53/285 [01:08<04:41,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:10<05:11,  1.35s/it]Loading train:  19%|█▉        | 55/285 [01:11<04:51,  1.27s/it]Loading train:  20%|█▉        | 56/285 [01:12<04:33,  1.19s/it]Loading train:  20%|██        | 57/285 [01:13<04:35,  1.21s/it]Loading train:  20%|██        | 58/285 [01:15<04:41,  1.24s/it]Loading train:  21%|██        | 59/285 [01:16<04:54,  1.30s/it]Loading train:  21%|██        | 60/285 [01:17<04:50,  1.29s/it]Loading train:  21%|██▏       | 61/285 [01:18<04:20,  1.16s/it]Loading train:  22%|██▏       | 62/285 [01:19<04:23,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:21<04:26,  1.20s/it]Loading train:  22%|██▏       | 64/285 [01:22<05:05,  1.38s/it]Loading train:  23%|██▎       | 65/285 [01:24<05:34,  1.52s/it]Loading train:  23%|██▎       | 66/285 [01:26<05:40,  1.55s/it]Loading train:  24%|██▎       | 67/285 [01:28<05:44,  1.58s/it]Loading train:  24%|██▍       | 68/285 [01:29<05:29,  1.52s/it]Loading train:  24%|██▍       | 69/285 [01:30<05:27,  1.51s/it]Loading train:  25%|██▍       | 70/285 [01:32<04:56,  1.38s/it]Loading train:  25%|██▍       | 71/285 [01:33<04:42,  1.32s/it]Loading train:  25%|██▌       | 72/285 [01:34<04:42,  1.33s/it]Loading train:  26%|██▌       | 73/285 [01:36<04:52,  1.38s/it]Loading train:  26%|██▌       | 74/285 [01:37<04:37,  1.31s/it]Loading train:  26%|██▋       | 75/285 [01:38<04:27,  1.28s/it]Loading train:  27%|██▋       | 76/285 [01:39<04:16,  1.23s/it]Loading train:  27%|██▋       | 77/285 [01:40<04:24,  1.27s/it]Loading train:  27%|██▋       | 78/285 [01:42<04:39,  1.35s/it]Loading train:  28%|██▊       | 79/285 [01:43<04:52,  1.42s/it]Loading train:  28%|██▊       | 80/285 [01:45<04:34,  1.34s/it]Loading train:  28%|██▊       | 81/285 [01:46<04:16,  1.26s/it]Loading train:  29%|██▉       | 82/285 [01:47<04:04,  1.20s/it]Loading train:  29%|██▉       | 83/285 [01:48<03:50,  1.14s/it]Loading train:  29%|██▉       | 84/285 [01:49<03:48,  1.14s/it]Loading train:  30%|██▉       | 85/285 [01:50<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:51<03:51,  1.17s/it]Loading train:  31%|███       | 87/285 [01:52<03:42,  1.12s/it]Loading train:  31%|███       | 88/285 [01:54<03:59,  1.22s/it]Loading train:  31%|███       | 89/285 [01:55<04:05,  1.25s/it]Loading train:  32%|███▏      | 90/285 [01:57<04:21,  1.34s/it]Loading train:  32%|███▏      | 91/285 [01:58<04:07,  1.28s/it]Loading train:  32%|███▏      | 92/285 [01:59<04:14,  1.32s/it]Loading train:  33%|███▎      | 93/285 [02:00<04:09,  1.30s/it]Loading train:  33%|███▎      | 94/285 [02:02<04:10,  1.31s/it]Loading train:  33%|███▎      | 95/285 [02:03<04:07,  1.30s/it]Loading train:  34%|███▎      | 96/285 [02:04<03:49,  1.22s/it]Loading train:  34%|███▍      | 97/285 [02:05<03:48,  1.22s/it]Loading train:  34%|███▍      | 98/285 [02:06<03:48,  1.22s/it]Loading train:  35%|███▍      | 99/285 [02:08<03:48,  1.23s/it]Loading train:  35%|███▌      | 100/285 [02:09<03:45,  1.22s/it]Loading train:  35%|███▌      | 101/285 [02:10<03:43,  1.22s/it]Loading train:  36%|███▌      | 102/285 [02:11<03:46,  1.24s/it]Loading train:  36%|███▌      | 103/285 [02:13<03:52,  1.28s/it]Loading train:  36%|███▋      | 104/285 [02:14<03:38,  1.21s/it]Loading train:  37%|███▋      | 105/285 [02:15<03:26,  1.15s/it]Loading train:  37%|███▋      | 106/285 [02:16<03:18,  1.11s/it]Loading train:  38%|███▊      | 107/285 [02:17<03:19,  1.12s/it]Loading train:  38%|███▊      | 108/285 [02:18<03:07,  1.06s/it]Loading train:  38%|███▊      | 109/285 [02:19<03:12,  1.09s/it]Loading train:  39%|███▊      | 110/285 [02:20<03:17,  1.13s/it]Loading train:  39%|███▉      | 111/285 [02:21<03:11,  1.10s/it]Loading train:  39%|███▉      | 112/285 [02:23<03:21,  1.16s/it]Loading train:  40%|███▉      | 113/285 [02:24<03:26,  1.20s/it]Loading train:  40%|████      | 114/285 [02:25<03:35,  1.26s/it]Loading train:  40%|████      | 115/285 [02:27<03:44,  1.32s/it]Loading train:  41%|████      | 116/285 [02:28<03:46,  1.34s/it]Loading train:  41%|████      | 117/285 [02:29<03:31,  1.26s/it]Loading train:  41%|████▏     | 118/285 [02:30<03:14,  1.17s/it]Loading train:  42%|████▏     | 119/285 [02:31<03:18,  1.20s/it]Loading train:  42%|████▏     | 120/285 [02:33<03:10,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:34<03:33,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:36<03:34,  1.32s/it]Loading train:  43%|████▎     | 123/285 [02:37<03:37,  1.34s/it]Loading train:  44%|████▎     | 124/285 [02:38<03:33,  1.33s/it]Loading train:  44%|████▍     | 125/285 [02:39<03:25,  1.28s/it]Loading train:  44%|████▍     | 126/285 [02:40<03:07,  1.18s/it]Loading train:  45%|████▍     | 127/285 [02:42<03:09,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:43<03:12,  1.23s/it]Loading train:  45%|████▌     | 129/285 [02:44<03:10,  1.22s/it]Loading train:  46%|████▌     | 130/285 [02:45<03:03,  1.19s/it]Loading train:  46%|████▌     | 131/285 [02:46<03:01,  1.18s/it]Loading train:  46%|████▋     | 132/285 [02:47<02:59,  1.17s/it]Loading train:  47%|████▋     | 133/285 [02:49<02:54,  1.15s/it]Loading train:  47%|████▋     | 134/285 [02:50<02:52,  1.14s/it]Loading train:  47%|████▋     | 135/285 [02:51<02:44,  1.10s/it]Loading train:  48%|████▊     | 136/285 [02:52<02:34,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:53<02:35,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:54<02:28,  1.01s/it]Loading train:  49%|████▉     | 139/285 [02:55<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:56<02:30,  1.04s/it]Loading train:  49%|████▉     | 141/285 [02:57<02:24,  1.00s/it]Loading train:  50%|████▉     | 142/285 [02:58<02:30,  1.05s/it]Loading train:  50%|█████     | 143/285 [02:59<02:19,  1.02it/s]Loading train:  51%|█████     | 144/285 [03:00<02:29,  1.06s/it]Loading train:  51%|█████     | 145/285 [03:01<02:27,  1.05s/it]Loading train:  51%|█████     | 146/285 [03:02<02:21,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [03:03<02:17,  1.00it/s]Loading train:  52%|█████▏    | 148/285 [03:04<02:25,  1.06s/it]Loading train:  52%|█████▏    | 149/285 [03:05<02:20,  1.03s/it]Loading train:  53%|█████▎    | 150/285 [03:06<02:10,  1.04it/s]Loading train:  53%|█████▎    | 151/285 [03:07<02:07,  1.05it/s]Loading train:  53%|█████▎    | 152/285 [03:08<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [03:09<02:05,  1.05it/s]Loading train:  54%|█████▍    | 154/285 [03:10<02:08,  1.02it/s]Loading train:  54%|█████▍    | 155/285 [03:11<02:21,  1.09s/it]Loading train:  55%|█████▍    | 156/285 [03:12<02:12,  1.03s/it]Loading train:  55%|█████▌    | 157/285 [03:13<02:11,  1.03s/it]Loading train:  55%|█████▌    | 158/285 [03:14<02:12,  1.04s/it]Loading train:  56%|█████▌    | 159/285 [03:15<02:09,  1.03s/it]Loading train:  56%|█████▌    | 160/285 [03:16<02:10,  1.05s/it]Loading train:  56%|█████▋    | 161/285 [03:17<02:06,  1.02s/it]Loading train:  57%|█████▋    | 162/285 [03:18<02:03,  1.01s/it]Loading train:  57%|█████▋    | 163/285 [03:19<02:06,  1.03s/it]Loading train:  58%|█████▊    | 164/285 [03:20<02:04,  1.03s/it]Loading train:  58%|█████▊    | 165/285 [03:21<01:58,  1.02it/s]Loading train:  58%|█████▊    | 166/285 [03:22<02:00,  1.01s/it]Loading train:  59%|█████▊    | 167/285 [03:23<01:58,  1.01s/it]Loading train:  59%|█████▉    | 168/285 [03:24<01:58,  1.01s/it]Loading train:  59%|█████▉    | 169/285 [03:25<01:53,  1.03it/s]Loading train:  60%|█████▉    | 170/285 [03:26<01:55,  1.00s/it]Loading train:  60%|██████    | 171/285 [03:27<01:51,  1.03it/s]Loading train:  60%|██████    | 172/285 [03:28<01:54,  1.01s/it]Loading train:  61%|██████    | 173/285 [03:29<01:49,  1.02it/s]Loading train:  61%|██████    | 174/285 [03:30<01:49,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [03:31<01:50,  1.00s/it]Loading train:  62%|██████▏   | 176/285 [03:32<01:50,  1.01s/it]Loading train:  62%|██████▏   | 177/285 [03:33<01:46,  1.01it/s]Loading train:  62%|██████▏   | 178/285 [03:34<01:43,  1.03it/s]Loading train:  63%|██████▎   | 179/285 [03:35<01:46,  1.01s/it]Loading train:  63%|██████▎   | 180/285 [03:36<01:55,  1.10s/it]Loading train:  64%|██████▎   | 181/285 [03:37<01:52,  1.08s/it]Loading train:  64%|██████▍   | 182/285 [03:38<01:46,  1.03s/it]Loading train:  64%|██████▍   | 183/285 [03:39<01:48,  1.07s/it]Loading train:  65%|██████▍   | 184/285 [03:40<01:42,  1.02s/it]Loading train:  65%|██████▍   | 185/285 [03:41<01:37,  1.02it/s]Loading train:  65%|██████▌   | 186/285 [03:42<01:42,  1.04s/it]Loading train:  66%|██████▌   | 187/285 [03:44<01:47,  1.10s/it]Loading train:  66%|██████▌   | 188/285 [03:45<01:51,  1.15s/it]Loading train:  66%|██████▋   | 189/285 [03:46<01:51,  1.16s/it]Loading train:  67%|██████▋   | 190/285 [03:47<01:45,  1.11s/it]Loading train:  67%|██████▋   | 191/285 [03:48<01:50,  1.17s/it]Loading train:  67%|██████▋   | 192/285 [03:50<01:49,  1.18s/it]Loading train:  68%|██████▊   | 193/285 [03:51<01:42,  1.12s/it]Loading train:  68%|██████▊   | 194/285 [03:52<01:37,  1.08s/it]Loading train:  68%|██████▊   | 195/285 [03:52<01:31,  1.01s/it]Loading train:  69%|██████▉   | 196/285 [03:54<01:38,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:55<01:34,  1.08s/it]Loading train:  69%|██████▉   | 198/285 [03:56<01:34,  1.09s/it]Loading train:  70%|██████▉   | 199/285 [03:57<01:27,  1.02s/it]Loading train:  70%|███████   | 200/285 [03:58<01:26,  1.02s/it]Loading train:  71%|███████   | 201/285 [03:59<01:30,  1.08s/it]Loading train:  71%|███████   | 202/285 [04:00<01:32,  1.12s/it]Loading train:  71%|███████   | 203/285 [04:01<01:28,  1.08s/it]Loading train:  72%|███████▏  | 204/285 [04:02<01:27,  1.08s/it]Loading train:  72%|███████▏  | 205/285 [04:04<01:31,  1.14s/it]Loading train:  72%|███████▏  | 206/285 [04:05<01:34,  1.20s/it]Loading train:  73%|███████▎  | 207/285 [04:06<01:32,  1.18s/it]Loading train:  73%|███████▎  | 208/285 [04:07<01:27,  1.13s/it]Loading train:  73%|███████▎  | 209/285 [04:08<01:27,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [04:09<01:22,  1.09s/it]Loading train:  74%|███████▍  | 211/285 [04:10<01:16,  1.03s/it]Loading train:  74%|███████▍  | 212/285 [04:11<01:16,  1.04s/it]Loading train:  75%|███████▍  | 213/285 [04:12<01:18,  1.09s/it]Loading train:  75%|███████▌  | 214/285 [04:13<01:11,  1.00s/it]Loading train:  75%|███████▌  | 215/285 [04:14<01:10,  1.00s/it]Loading train:  76%|███████▌  | 216/285 [04:15<01:03,  1.08it/s]Loading train:  76%|███████▌  | 217/285 [04:16<01:04,  1.06it/s]Loading train:  76%|███████▋  | 218/285 [04:17<01:03,  1.06it/s]Loading train:  77%|███████▋  | 219/285 [04:18<01:02,  1.06it/s]Loading train:  77%|███████▋  | 220/285 [04:19<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [04:20<01:07,  1.06s/it]Loading train:  78%|███████▊  | 222/285 [04:21<01:05,  1.04s/it]Loading train:  78%|███████▊  | 223/285 [04:22<01:02,  1.00s/it]Loading train:  79%|███████▊  | 224/285 [04:23<01:05,  1.07s/it]Loading train:  79%|███████▉  | 225/285 [04:24<01:05,  1.08s/it]Loading train:  79%|███████▉  | 226/285 [04:26<01:07,  1.15s/it]Loading train:  80%|███████▉  | 227/285 [04:27<01:08,  1.19s/it]Loading train:  80%|████████  | 228/285 [04:28<01:12,  1.27s/it]Loading train:  80%|████████  | 229/285 [04:29<01:06,  1.19s/it]Loading train:  81%|████████  | 230/285 [04:30<01:02,  1.13s/it]Loading train:  81%|████████  | 231/285 [04:31<00:57,  1.06s/it]Loading train:  81%|████████▏ | 232/285 [04:32<00:55,  1.04s/it]Loading train:  82%|████████▏ | 233/285 [04:33<00:56,  1.09s/it]Loading train:  82%|████████▏ | 234/285 [04:35<00:56,  1.10s/it]Loading train:  82%|████████▏ | 235/285 [04:36<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [04:37<00:52,  1.07s/it]Loading train:  83%|████████▎ | 237/285 [04:38<00:53,  1.12s/it]Loading train:  84%|████████▎ | 238/285 [04:39<00:57,  1.22s/it]Loading train:  84%|████████▍ | 239/285 [04:41<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [04:42<00:52,  1.17s/it]Loading train:  85%|████████▍ | 241/285 [04:43<00:51,  1.18s/it]Loading train:  85%|████████▍ | 242/285 [04:44<00:45,  1.07s/it]Loading train:  85%|████████▌ | 243/285 [04:45<00:46,  1.10s/it]Loading train:  86%|████████▌ | 244/285 [04:46<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:47<00:44,  1.11s/it]Loading train:  86%|████████▋ | 246/285 [04:48<00:44,  1.14s/it]Loading train:  87%|████████▋ | 247/285 [04:50<00:45,  1.19s/it]Loading train:  87%|████████▋ | 248/285 [04:51<00:47,  1.29s/it]Loading train:  87%|████████▋ | 249/285 [04:52<00:45,  1.25s/it]Loading train:  88%|████████▊ | 250/285 [04:53<00:41,  1.20s/it]Loading train:  88%|████████▊ | 251/285 [04:55<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [04:56<00:39,  1.18s/it]Loading train:  89%|████████▉ | 253/285 [04:57<00:39,  1.22s/it]Loading train:  89%|████████▉ | 254/285 [04:58<00:38,  1.23s/it]Loading train:  89%|████████▉ | 255/285 [04:59<00:35,  1.19s/it]Loading train:  90%|████████▉ | 256/285 [05:00<00:31,  1.09s/it]Loading train:  90%|█████████ | 257/285 [05:01<00:28,  1.02s/it]Loading train:  91%|█████████ | 258/285 [05:02<00:26,  1.00it/s]Loading train:  91%|█████████ | 259/285 [05:03<00:25,  1.02it/s]Loading train:  91%|█████████ | 260/285 [05:04<00:27,  1.09s/it]Loading train:  92%|█████████▏| 261/285 [05:05<00:25,  1.07s/it]Loading train:  92%|█████████▏| 262/285 [05:06<00:22,  1.00it/s]Loading train:  92%|█████████▏| 263/285 [05:07<00:21,  1.00it/s]Loading train:  93%|█████████▎| 264/285 [05:09<00:23,  1.12s/it]Loading train:  93%|█████████▎| 265/285 [05:10<00:24,  1.25s/it]Loading train:  93%|█████████▎| 266/285 [05:11<00:23,  1.22s/it]Loading train:  94%|█████████▎| 267/285 [05:12<00:20,  1.15s/it]Loading train:  94%|█████████▍| 268/285 [05:13<00:19,  1.14s/it]Loading train:  94%|█████████▍| 269/285 [05:15<00:20,  1.28s/it]Loading train:  95%|█████████▍| 270/285 [05:16<00:17,  1.20s/it]Loading train:  95%|█████████▌| 271/285 [05:17<00:17,  1.26s/it]Loading train:  95%|█████████▌| 272/285 [05:19<00:18,  1.43s/it]Loading train:  96%|█████████▌| 273/285 [05:21<00:17,  1.48s/it]Loading train:  96%|█████████▌| 274/285 [05:23<00:17,  1.55s/it]Loading train:  96%|█████████▋| 275/285 [05:25<00:17,  1.70s/it]Loading train:  97%|█████████▋| 276/285 [05:26<00:15,  1.76s/it]Loading train:  97%|█████████▋| 277/285 [05:28<00:12,  1.62s/it]Loading train:  98%|█████████▊| 278/285 [05:29<00:10,  1.56s/it]Loading train:  98%|█████████▊| 279/285 [05:30<00:08,  1.40s/it]Loading train:  98%|█████████▊| 280/285 [05:31<00:06,  1.32s/it]Loading train:  99%|█████████▊| 281/285 [05:32<00:04,  1.22s/it]Loading train:  99%|█████████▉| 282/285 [05:34<00:03,  1.24s/it]Loading train:  99%|█████████▉| 283/285 [05:35<00:02,  1.39s/it]Loading train: 100%|█████████▉| 284/285 [05:37<00:01,  1.43s/it]Loading train: 100%|██████████| 285/285 [05:39<00:00,  1.60s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:17, 16.17it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:13, 21.02it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:09, 27.86it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:06, 36.18it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:05, 45.98it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:03, 56.74it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:03, 59.18it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:03, 62.01it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:04, 47.61it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:03, 53.04it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:03, 45.82it/s]concatenating: train:  39%|███▉      | 112/285 [00:01<00:03, 49.81it/s]concatenating: train:  41%|████▏     | 118/285 [00:01<00:03, 51.94it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:02, 57.62it/s]concatenating: train:  48%|████▊     | 138/285 [00:02<00:02, 49.44it/s]concatenating: train:  51%|█████     | 146/285 [00:02<00:02, 53.94it/s]concatenating: train:  54%|█████▎    | 153/285 [00:02<00:02, 48.81it/s]concatenating: train:  58%|█████▊    | 166/285 [00:02<00:01, 59.74it/s]concatenating: train:  63%|██████▎   | 180/285 [00:02<00:01, 71.70it/s]concatenating: train:  67%|██████▋   | 190/285 [00:02<00:01, 76.29it/s]concatenating: train:  70%|███████   | 200/285 [00:02<00:01, 76.73it/s]concatenating: train:  73%|███████▎  | 209/285 [00:03<00:01, 49.51it/s]concatenating: train:  76%|███████▌  | 216/285 [00:03<00:01, 40.43it/s]concatenating: train:  78%|███████▊  | 223/285 [00:03<00:01, 46.26it/s]concatenating: train:  82%|████████▏ | 235/285 [00:03<00:00, 56.40it/s]concatenating: train:  86%|████████▌ | 245/285 [00:03<00:00, 63.94it/s]concatenating: train:  89%|████████▉ | 254/285 [00:03<00:00, 63.45it/s]concatenating: train:  93%|█████████▎| 264/285 [00:04<00:00, 60.02it/s]concatenating: train:  95%|█████████▌| 271/285 [00:04<00:00, 40.75it/s]concatenating: train: 100%|█████████▉| 284/285 [00:04<00:00, 51.09it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 63.16it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.95s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.85s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 19.01it/s]2019-07-11 02:26:51.321071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:26:51.321177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:26:51.321196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:26:51.321209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:26:51.321698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.84it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.68it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.83it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.16it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.81it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.74it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.04it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.71it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.01it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.74it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.68it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  9.26it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.31it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.91it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.74it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  9.28it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.66it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.67it/s]
Epoch 00051: val_mDice did not improve from 0.58727
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [2.643352781023298, 5.157678013756161, 1.5927235739571708, 1.1001963728950137, 1.0724267391931444, 1.0270176842099143, 0.9410755918139503, 0.9699937105178833, 0.938753570829119, 0.9706814516158331, 0.9262396324248541, 0.9959104628789992, 0.9499534084683373, 0.9785842214311872, 0.9452158950624012, 0.9505353882199242, 0.9489115533374605, 0.8853201582318261, 0.9041527452923003, 0.9189660719462803, 0.9418656428654989, 0.9541469301496234, 0.8778770594369798, 0.8754583143052601, 0.891230855669294, 0.8601217951093402, 0.8559459107262748, 0.8932652019319081, 0.846838945434207, 0.8708184843971616, 0.8083548602603731, 0.814103535243443, 0.822580371584211, 0.8346278099786668, 0.7900406349272955, 0.7971689246949696, 0.8036421707698277, 0.749746975444612, 0.8121192341759091, 0.7353500241325015, 0.8360505558195568, 0.7582712400527227, 0.715488768759228, 0.7586559965496972, 0.7437893833432879, 0.7922136443001884, 0.7318227404639834, 0.6858880179268974, 0.7630342018036615, 0.6791480836414155, 0.6949022894813901], 'val_acc': [0.903624088991256, 0.9053571649960109, 0.916250018846421, 0.9336904571169898, 0.9409340478125072, 0.9423534870147705, 0.9442170517785209, 0.9443635571570623, 0.944439118816739, 0.9433127357846215, 0.9425984507515317, 0.9445329705874125, 0.9450320459547497, 0.9411149252028692, 0.9451465010643005, 0.9447916405541557, 0.9416300427346003, 0.940290751911345, 0.9426053109623137, 0.9299267445291791, 0.9313644766807556, 0.9311447086788359, 0.940801257178897, 0.9398076903252375, 0.9428067661467052, 0.9435096099263146, 0.9430013611203149, 0.9431936797641572, 0.9396474446569171, 0.9401945755595252, 0.9411149450710842, 0.9383447709537688, 0.9443727391106742, 0.9326167333693731, 0.943385987054734, 0.9452037726129804, 0.941884179910024, 0.9438850652603876, 0.9411584451085045, 0.943896526382083, 0.9437614367121742, 0.9445604227838063, 0.9450709422429403, 0.9448557779902503, 0.9412408669789633, 0.9412568608919779, 0.9446108142534891, 0.9423694979576838, 0.9397664808091664, 0.9406478688830421, 0.9398878472191947], 'val_mDice': [0.17717267705925874, 0.07013039158136096, 0.30295051226303693, 0.5095922476833775, 0.5335163330393178, 0.5433673750431764, 0.5798378739328611, 0.5694643418703761, 0.57778751992044, 0.5697645592902388, 0.5872726871498993, 0.5513856230037553, 0.5740574014683565, 0.5622180804965042, 0.5628889167592639, 0.5624758296069645, 0.5616369240340733, 0.5864326173350924, 0.5790353133564904, 0.5689156129956245, 0.5662755231772151, 0.5588215940764972, 0.5721895006440935, 0.5702387227543763, 0.5577654969834146, 0.5688331716117405, 0.5708472471506822, 0.5526562161034062, 0.5708921549930459, 0.5700113432747977, 0.5685562406267438, 0.5718885154596397, 0.5709100959911233, 0.5638092208121505, 0.5708869743560042, 0.5650254764727184, 0.5716882239849794, 0.5706836127099537, 0.5572538237486567, 0.5744065990050634, 0.553512637813886, 0.5663932214180628, 0.5794693777958552, 0.5673867825950895, 0.5708845406770706, 0.5651594751647541, 0.566979799064852, 0.5688201941194988, 0.5664815902709961, 0.5728705353325322, 0.5666733735374042], 'loss': [2.8028958623340783, 1.180362376400058, 0.7177189787688548, 0.5783115293861516, 0.5192059905560737, 0.48404521005724077, 0.4597997671897779, 0.44571488176395097, 0.43470655454935675, 0.42446343597589903, 0.41212097412477644, 0.40486187459256395, 0.40045054885769754, 0.3946690909465384, 0.389260341654813, 0.3833192880842666, 0.3807000940030357, 0.37662419137845315, 0.3721602129550115, 0.3703034625752988, 0.3666448363029178, 0.36134150966711764, 0.36071146449211683, 0.35723499450721286, 0.35576971279464753, 0.3533665091632441, 0.35128427253928696, 0.3490676414375938, 0.34612258016224284, 0.3448851136072353, 0.3433437437043154, 0.3416622199717114, 0.3387202354830677, 0.3384782783277742, 0.33567228846658465, 0.3378447502397585, 0.33349835310732445, 0.33221409284404324, 0.32982052709524495, 0.32757021519221713, 0.3276679638104561, 0.3277739155136231, 0.32414878204720593, 0.3239727602922919, 0.32444066364272883, 0.32281650523815814, 0.3219404812318318, 0.3204023524449468, 0.3185408240180956, 0.31684544905431244, 0.317495611630034], 'acc': [0.6807922399501385, 0.8821607684960411, 0.896532083536725, 0.9056787210230609, 0.9112160484501685, 0.915588806400369, 0.920138712388508, 0.9236821005609607, 0.9264579028758742, 0.9280162800569536, 0.9297225146434291, 0.9306217845129282, 0.9311327969083351, 0.931840766905727, 0.9324582257963959, 0.9329643205385666, 0.9332891905815679, 0.9338324501699672, 0.9343315744666619, 0.9342939437458413, 0.9348760230223614, 0.9355690007681375, 0.9356132318501484, 0.9358297501176636, 0.9361942652587788, 0.9365581577629029, 0.936781535804536, 0.9369604895747832, 0.9372249539817301, 0.9375285914874109, 0.9373754974226973, 0.9375435638593207, 0.9378092964651131, 0.9378473940602566, 0.9381628552681912, 0.937900526826497, 0.9384004824281498, 0.9385473194070834, 0.9387468083621404, 0.9387924805849486, 0.938940339955333, 0.9389306043001965, 0.9392311900181878, 0.939253946317743, 0.9391116283177549, 0.9392884731269743, 0.9395025560155824, 0.9395367129703512, 0.9397416663395087, 0.9398954592161103, 0.9399225036946707], 'mDice': [0.09581624033083593, 0.30994312213247216, 0.4725819040360606, 0.5443008299482474, 0.5795857671692074, 0.6009484762650867, 0.6162585731827732, 0.62541160967071, 0.6325988107525546, 0.6393270666759691, 0.6472290095530058, 0.6521832643503027, 0.6552472803458006, 0.6592058855972011, 0.662895252623263, 0.6667972010225833, 0.6686217761899272, 0.6713916433324054, 0.6745444071046967, 0.6756885661563135, 0.6784668409550881, 0.6819941653252934, 0.6825443772031365, 0.6848884012649945, 0.6859436060666624, 0.687597232699647, 0.6891487567025342, 0.6907444808991953, 0.692754190575302, 0.6937615637699257, 0.694816265132401, 0.6959977882754625, 0.6981550304789016, 0.6983399244776943, 0.7002594541878238, 0.6987117664970734, 0.7018966278129859, 0.7027679761296779, 0.7045593648281359, 0.7061964842724805, 0.7061309741828996, 0.7060974016799986, 0.7086985218104357, 0.7088459738766685, 0.7084316772166213, 0.7096319246756357, 0.7104175124803628, 0.7115073852141928, 0.7128129077022053, 0.7140692186557835, 0.7136015792975013]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 10)   5410        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 70)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 231,353
Trainable params: 56,633
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 19s - loss: 2.0430 - acc: 0.7163 - mDice: 0.1970 - val_loss: 1.6805 - val_acc: 0.9163 - val_mDice: 0.2363

Epoch 00001: val_mDice improved from -inf to 0.23626, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.7651 - acc: 0.9099 - mDice: 0.4493 - val_loss: 0.7934 - val_acc: 0.9285 - val_mDice: 0.4533

Epoch 00002: val_mDice improved from 0.23626 to 0.45330, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5967 - acc: 0.9228 - mDice: 0.5339 - val_loss: 0.6844 - val_acc: 0.9384 - val_mDice: 0.4989

Epoch 00003: val_mDice improved from 0.45330 to 0.49887, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5280 - acc: 0.9300 - mDice: 0.5739 - val_loss: 0.5920 - val_acc: 0.9443 - val_mDice: 0.5436

Epoch 00004: val_mDice improved from 0.49887 to 0.54360, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.4874 - acc: 0.9339 - mDice: 0.5985 - val_loss: 0.5588 - val_acc: 0.9436 - val_mDice: 0.5575

Epoch 00005: val_mDice improved from 0.54360 to 0.55747, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4594 - acc: 0.9366 - mDice: 0.6162 - val_loss: 0.5684 - val_acc: 0.9411 - val_mDice: 0.5547

Epoch 00006: val_mDice did not improve from 0.55747
Epoch 7/300
 - 13s - loss: 0.4396 - acc: 0.9385 - mDice: 0.6290 - val_loss: 0.5301 - val_acc: 0.9443 - val_mDice: 0.5750

Epoch 00007: val_mDice improved from 0.55747 to 0.57503, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.4227 - acc: 0.9400 - mDice: 0.6404 - val_loss: 0.5465 - val_acc: 0.9485 - val_mDice: 0.5704

Epoch 00008: val_mDice did not improve from 0.57503
Epoch 9/300
 - 12s - loss: 0.4077 - acc: 0.9412 - mDice: 0.6499 - val_loss: 0.5148 - val_acc: 0.9471 - val_mDice: 0.5875

Epoch 00009: val_mDice improved from 0.57503 to 0.58750, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.3951 - acc: 0.9422 - mDice: 0.6585 - val_loss: 0.5328 - val_acc: 0.9454 - val_mDice: 0.5792

Epoch 00010: val_mDice did not improve from 0.58750
Epoch 11/300
 - 13s - loss: 0.3867 - acc: 0.9431 - mDice: 0.6643 - val_loss: 0.5378 - val_acc: 0.9426 - val_mDice: 0.5735

Epoch 00011: val_mDice did not improve from 0.58750
Epoch 12/300
 - 13s - loss: 0.3788 - acc: 0.9439 - mDice: 0.6699 - val_loss: 0.5767 - val_acc: 0.9490 - val_mDice: 0.5563

Epoch 00012: val_mDice did not improve from 0.58750
Epoch 13/300
 - 13s - loss: 0.3738 - acc: 0.9444 - mDice: 0.6735 - val_loss: 0.5635 - val_acc: 0.9442 - val_mDice: 0.5572

Epoch 00013: val_mDice did not improve from 0.58750
Epoch 14/300
 - 13s - loss: 0.3637 - acc: 0.9451 - mDice: 0.6805 - val_loss: 0.5386 - val_acc: 0.9443 - val_mDice: 0.5724

Epoch 00014: val_mDice did not improve from 0.58750
Epoch 15/300
 - 13s - loss: 0.3576 - acc: 0.9457 - mDice: 0.6847 - val_loss: 0.4986 - val_acc: 0.9476 - val_mDice: 0.5967

Epoch 00015: val_mDice improved from 0.58750 to 0.59673, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 13s - loss: 0.3512 - acc: 0.9464 - mDice: 0.6893 - val_loss: 0.5635 - val_acc: 0.9453 - val_mDice: 0.5600

Epoch 00016: val_mDice did not improve from 0.59673
Epoch 17/300
 - 13s - loss: 0.3459 - acc: 0.9467 - mDice: 0.6931 - val_loss: 0.5452 - val_acc: 0.9430 - val_mDice: 0.5688

Epoch 00017: val_mDice did not improve from 0.59673
Epoch 18/300
 - 13s - loss: 0.3419 - acc: 0.9472 - mDice: 0.6960 - val_loss: 0.5300 - val_acc: 0.9491 - val_mDice: 0.5815

Epoch 00018: val_mDice did not improve from 0.59673
Epoch 19/300
 - 12s - loss: 0.3371 - acc: 0.9475 - mDice: 0.6995 - val_loss: 0.5162 - val_acc: 0.9493 - val_mDice: 0.5877

Epoch 00019: val_mDice did not improve from 0.59673
Epoch 20/300
 - 12s - loss: 0.3318 - acc: 0.9481 - mDice: 0.7034 - val_loss: 0.5024 - val_acc: 0.9466 - val_mDice: 0.5932

Epoch 00020: val_mDice did not improve from 0.59673
Epoch 21/300
 - 13s - loss: 0.3291 - acc: 0.9482 - mDice: 0.7054 - val_loss: 0.5306 - val_acc: 0.9474 - val_mDice: 0.5790

Epoch 00021: val_mDice did not improve from 0.59673
Epoch 22/300
 - 13s - loss: 0.3259 - acc: 0.9486 - mDice: 0.7077 - val_loss: 0.5658 - val_acc: 0.9494 - val_mDice: 0.5673

Epoch 00022: val_mDice did not improve from 0.59673
Epoch 23/300
 - 13s - loss: 0.3215 - acc: 0.9489 - mDice: 0.7109 - val_loss: 0.5347 - val_acc: 0.9464 - val_mDice: 0.5806

Epoch 00023: val_mDice did not improve from 0.59673
Epoch 24/300
 - 13s - loss: 0.3188 - acc: 0.9491 - mDice: 0.7129 - val_loss: 0.5123 - val_acc: 0.9495 - val_mDice: 0.5918

Epoch 00024: val_mDice did not improve from 0.59673
Epoch 25/300
 - 13s - loss: 0.3153 - acc: 0.9495 - mDice: 0.7157 - val_loss: 0.4979 - val_acc: 0.9494 - val_mDice: 0.5988

Epoch 00025: val_mDice improved from 0.59673 to 0.59879, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 13s - loss: 0.3120 - acc: 0.9497 - mDice: 0.7180 - val_loss: 0.5080 - val_acc: 0.9486 - val_mDice: 0.5934

Epoch 00026: val_mDice did not improve from 0.59879
Epoch 27/300
 - 13s - loss: 0.3119 - acc: 0.9498 - mDice: 0.7182 - val_loss: 0.5262 - val_acc: 0.9443 - val_mDice: 0.5790

Epoch 00027: val_mDice did not improve from 0.59879
Epoch 28/300
 - 13s - loss: 0.3245 - acc: 0.9487 - mDice: 0.7098 - val_loss: 0.5062 - val_acc: 0.9475 - val_mDice: 0.5931

Epoch 00028: val_mDice did not improve from 0.59879
Epoch 29/300
 - 13s - loss: 0.3062 - acc: 0.9502 - mDice: 0.7223 - val_loss: 0.5150 - val_acc: 0.9482 - val_mDice: 0.5873

Epoch 00029: val_mDice did not improve from 0.59879
Epoch 30/300
 - 13s - loss: 0.3047 - acc: 0.9503 - mDice: 0.7236 - val_loss: 0.5231 - val_acc: 0.9464 - val_mDice: 0.5827

Epoch 00030: val_mDice did not improve from 0.59879
Epoch 31/300
 - 13s - loss: 0.3013 - acc: 0.9506 - mDice: 0.7260 - val_loss: 0.5220 - val_acc: 0.9478 - val_mDice: 0.5842

Epoch 00031: val_mDice did not improve from 0.59879
Epoch 32/300
 - 12s - loss: 0.2994 - acc: 0.9508 - mDice: 0.7275 - val_loss: 0.5376 - val_acc: 0.9496 - val_mDice: 0.5805

Epoch 00032: val_mDice did not improve from 0.59879
Epoch 33/300
 - 13s - loss: 0.2974 - acc: 0.9509 - mDice: 0.7291 - val_loss: 0.6042 - val_acc: 0.9479 - val_mDice: 0.5528

Epoch 00033: val_mDice did not improve from 0.59879
Epoch 34/300
 - 13s - loss: 0.2942 - acc: 0.9511 - mDice: 0.7314 - val_loss: 0.5037 - val_acc: 0.9473 - val_mDice: 0.5938

Epoch 00034: val_mDice did not improve from 0.59879
Epoch 35/300
 - 13s - loss: 0.2938 - acc: 0.9512 - mDice: 0.7317 - val_loss: 0.5242 - val_acc: 0.9503 - val_mDice: 0.5846

Epoch 00035: val_mDice did not improve from 0.59879
Epoch 36/300
 - 13s - loss: 0.2928 - acc: 0.9513 - mDice: 0.7327 - val_loss: 0.5062 - val_acc: 0.9490 - val_mDice: 0.5944

Epoch 00036: val_mDice did not improve from 0.59879
Epoch 37/300
 - 13s - loss: 0.2894 - acc: 0.9514 - mDice: 0.7351 - val_loss: 0.5063 - val_acc: 0.9480 - val_mDice: 0.5920

Epoch 00037: val_mDice did not improve from 0.59879
Epoch 38/300
 - 14s - loss: 0.2886 - acc: 0.9514 - mDice: 0.7358 - val_loss: 0.5153 - val_acc: 0.9489 - val_mDice: 0.5908

Epoch 00038: val_mDice did not improve from 0.59879
Epoch 39/300
 - 13s - loss: 0.2853 - acc: 0.9518 - mDice: 0.7383 - val_loss: 0.5022 - val_acc: 0.9486 - val_mDice: 0.5962

Epoch 00039: val_mDice did not improve from 0.59879
Epoch 40/300
 - 12s - loss: 0.2861 - acc: 0.9518 - mDice: 0.7377 - val_loss: 0.5140 - val_acc: 0.9493 - val_mDice: 0.5906

Epoch 00040: val_mDice did not improve from 0.59879
Epoch 41/300
 - 13s - loss: 0.2847 - acc: 0.9519 - mDice: 0.7387 - val_loss: 0.5331 - val_acc: 0.9464 - val_mDice: 0.5787

Epoch 00041: val_mDice did not improve from 0.59879
Epoch 42/300
 - 12s - loss: 0.2824 - acc: 0.9521 - mDice: 0.7405 - val_loss: 0.5270 - val_acc: 0.9471 - val_mDice: 0.5813

Epoch 00042: val_mDice did not improve from 0.59879
Epoch 43/300
 - 13s - loss: 0.2804 - acc: 0.9522 - mDice: 0.7420 - val_loss: 0.5225 - val_acc: 0.9503 - val_mDice: 0.5849

Epoch 00043: val_mDice did not improve from 0.59879
Epoch 44/300
 - 13s - loss: 0.2794 - acc: 0.9523 - mDice: 0.7428 - val_loss: 0.5223 - val_acc: 0.9478 - val_mDice: 0.5859

Epoch 00044: val_mDice did not improve from 0.59879
Epoch 45/300
 - 13s - loss: 0.2787 - acc: 0.9524 - mDice: 0.7434 - val_loss: 0.5231 - val_acc: 0.9487 - val_mDice: 0.5874

Epoch 00045: val_mDice did not improve from 0.59879
Epoch 46/300
 - 13s - loss: 0.2775 - acc: 0.9525 - mDice: 0.7443 - val_loss: 0.4986 - val_acc: 0.9504 - val_mDice: 0.6008

Epoch 00046: val_mDice improved from 0.59879 to 0.60080, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 13s - loss: 0.2757 - acc: 0.9525 - mDice: 0.7457 - val_loss: 0.5091 - val_acc: 0.9493 - val_mDice: 0.5952

Epoch 00047: val_mDice did not improve from 0.60080
Epoch 48/300
 - 13s - loss: 0.2744 - acc: 0.9527 - mDice: 0.7467 - val_loss: 0.5726 - val_acc: 0.9460 - val_mDice: 0.5610

Epoch 00048: val_mDice did not improve from 0.60080
Epoch 49/300
 - 12s - loss: 0.2727 - acc: 0.9528 - mDice: 0.7480 - val_loss: 0.5689 - val_acc: 0.9492 - val_mDice: 0.5664

Epoch 00049: val_mDice did not improve from 0.60080
Epoch 50/300
 - 12s - loss: 0.2715 - acc: 0.9529 - mDice: 0.7489 - val_loss: 0.5155 - val_acc: 0.9473 - val_mDice: 0.5890

Epoch 00050: val_mDice did not improve from 0.60080
Epoch 51/300
 - 13s - loss: 0.2727 - acc: 0.9528 - mDice: 0.7479 - val_loss: 0.5044 - val_acc: 0.9486 - val_mDice: 0.5953

Epoch 00051: val_mDice did not improve from 0.60080
Epoch 52/300
 - 13s - loss: 0.2719 - acc: 0.9530 - mDice: 0.7487 - val_loss: 0.4990 - val_acc: 0.9492 - val_mDice: 0.5965

Epoch 00052: val_mDice did not improve from 0.60080
Epoch 53/300
 - 13s - loss: 0.2705 - acc: 0.9530 - mDice: 0.7497 - val_loss: 0.5479 - val_acc: 0.9493 - val_mDice: 0.5746

Epoch 00053: val_mDice did not improve from 0.60080
Epoch 54/300
 - 13s - loss: 0.2687 - acc: 0.9531 - mDice: 0.7511 - val_loss: 0.5204 - val_acc: 0.9483 - val_mDice: 0.5860

Epoch 00054: val_mDice did not improve from 0.60080
Epoch 55/300
 - 13s - loss: 0.2677 - acc: 0.9533 - mDice: 0.7520 - val_loss: 0.5447 - val_acc: 0.9499 - val_mDice: 0.5752

Epoch 00055: val_mDice did not improve from 0.60080
Epoch 56/300
 - 13s - loss: 0.2679 - acc: 0.9533 - mDice: 0.7520 - val_loss: 0.5198 - val_acc: 0.9502 - val_mDice: 0.5900

Epoch 00056: val_mDice did not improve from 0.60080
Epoch 57/300
 - 13s - loss: 0.2670 - acc: 0.9533 - mDice: 0.7525 - val_loss: 0.5343 - val_acc: 0.9478 - val_mDice: 0.5808

Epoch 00057: val_mDice did not improve from 0.60080
Epoch 58/300
 - 12s - loss: 0.2645 - acc: 0.9534 - mDice: 0.7544 - val_loss: 0.5355 - val_acc: 0.9488 - val_mDice: 0.5818

Epoch 00058: val_mDice did not improve from 0.60080
Epoch 59/300
 - 12s - loss: 0.2631 - acc: 0.9535 - mDice: 0.7555 - val_loss: 0.5523 - val_acc: 0.9481 - val_mDice: 0.5707

Epoch 00059: val_mDice did not improve from 0.60080
Epoch 60/300
 - 13s - loss: 0.2620 - acc: 0.9537 - mDice: 0.7564 - val_loss: 0.5307 - val_acc: 0.9479 - val_mDice: 0.5833

Epoch 00060: val_mDice did not improve from 0.60080
Epoch 61/300
 - 13s - loss: 0.2627 - acc: 0.9536 - mDice: 0.7559 - val_loss: 0.5304 - val_acc: 0.9499 - val_mDice: 0.5841

Epoch 00061: val_mDice did not improve from 0.60080
Epoch 62/300
 - 13s - loss: 0.2615 - acc: 0.9537 - mDice: 0.7568 - val_loss: 0.5277 - val_acc: 0.9463 - val_mDice: 0.5842

Epoch 00062: val_mDice did not improve from 0.60080
Epoch 63/300
 - 13s - loss: 0.2633 - acc: 0.9536 - mDice: 0.7555 - val_loss: 0.4948 - val_acc: 0.9512 - val_mDice: 0.6023

Epoch 00063: val_mDice improved from 0.60080 to 0.60227, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 64/300
 - 13s - loss: 0.2608 - acc: 0.9538 - mDice: 0.7574 - val_loss: 0.5278 - val_acc: 0.9504 - val_mDice: 0.5879

Epoch 00064: val_mDice did not improve from 0.60227
Epoch 65/300
 - 13s - loss: 0.2593 - acc: 0.9539 - mDice: 0.7586 - val_loss: 0.5235 - val_acc: 0.9506 - val_mDice: 0.5890

Epoch 00065: val_mDice did not improve from 0.60227
Epoch 66/300
 - 13s - loss: 0.2603 - acc: 0.9539 - mDice: 0.7578 - val_loss: 0.5168 - val_acc: 0.9507 - val_mDice: 0.5904

Epoch 00066: val_mDice did not improve from 0.60227
Epoch 67/300
 - 13s - loss: 0.2585 - acc: 0.9540 - mDice: 0.7592 - val_loss: 0.5561 - val_acc: 0.9487 - val_mDice: 0.5694

Epoch 00067: val_mDice did not improve from 0.60227
Epoch 68/300
 - 13s - loss: 0.2573 - acc: 0.9541 - mDice: 0.7601 - val_loss: 0.5557 - val_acc: 0.9463 - val_mDice: 0.5671

Epoch 00068: val_mDice did not improve from 0.60227
Epoch 69/300
 - 13s - loss: 0.2569 - acc: 0.9541 - mDice: 0.7605 - val_loss: 0.5202 - val_acc: 0.9462 - val_mDice: 0.5851

Epoch 00069: val_mDice did not improve from 0.60227
Epoch 70/300
 - 13s - loss: 0.2561 - acc: 0.9542 - mDice: 0.7611 - val_loss: 0.5285 - val_acc: 0.9510 - val_mDice: 0.5876

Epoch 00070: val_mDice did not improve from 0.60227
Epoch 71/300
 - 13s - loss: 0.2555 - acc: 0.9543 - mDice: 0.7616 - val_loss: 0.5487 - val_acc: 0.9455 - val_mDice: 0.5755

Epoch 00071: val_mDice did not improve from 0.60227
Epoch 72/300
 - 13s - loss: 0.2550 - acc: 0.9543 - mDice: 0.7620 - val_loss: 0.5519 - val_acc: 0.9486 - val_mDice: 0.5761

Epoch 00072: val_mDice did not improve from 0.60227
Epoch 73/300
 - 13s - loss: 0.2557 - acc: 0.9543 - mDice: 0.7620 - val_loss: 0.5395 - val_acc: 0.9506 - val_mDice: 0.5857

Epoch 00073: val_mDice did not improve from 0.60227
Epoch 74/300
 - 13s - loss: 0.4445 - acc: 0.9377 - mDice: 0.6338 - val_loss: 0.4964 - val_acc: 0.9474 - val_mDice: 0.5991

Epoch 00074: val_mDice did not improve from 0.60227
Epoch 75/300
 - 13s - loss: 0.3227 - acc: 0.9489 - mDice: 0.7103 - val_loss: 0.4934 - val_acc: 0.9487 - val_mDice: 0.6011

Epoch 00075: val_mDice did not improve from 0.60227
Epoch 76/300
 - 13s - loss: 0.2953 - acc: 0.9510 - mDice: 0.7306 - val_loss: 0.4922 - val_acc: 0.9495 - val_mDice: 0.6037

Epoch 00076: val_mDice improved from 0.60227 to 0.60369, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 77/300
 - 13s - loss: 0.2826 - acc: 0.9520 - mDice: 0.7403 - val_loss: 0.5006 - val_acc: 0.9487 - val_mDice: 0.5989

Epoch 00077: val_mDice did not improve from 0.60369
Epoch 78/300
 - 13s - loss: 0.2767 - acc: 0.9525 - mDice: 0.7451 - val_loss: 0.5097 - val_acc: 0.9504 - val_mDice: 0.5963

Epoch 00078: val_mDice did not improve from 0.60369
Epoch 79/300
 - 13s - loss: 0.2707 - acc: 0.9530 - mDice: 0.7495 - val_loss: 0.5170 - val_acc: 0.9503 - val_mDice: 0.5922

Epoch 00079: val_mDice did not improve from 0.60369
Epoch 80/300
 - 13s - loss: 0.2672 - acc: 0.9533 - mDice: 0.7525 - val_loss: 0.5199 - val_acc: 0.9497 - val_mDice: 0.5895

Epoch 00080: val_mDice did not improve from 0.60369
Epoch 81/300
 - 13s - loss: 0.2619 - acc: 0.9536 - mDice: 0.7564 - val_loss: 0.5141 - val_acc: 0.9494 - val_mDice: 0.5930

Epoch 00081: val_mDice did not improve from 0.60369
Epoch 82/300
 - 13s - loss: 0.2601 - acc: 0.9539 - mDice: 0.7579 - val_loss: 0.5420 - val_acc: 0.9467 - val_mDice: 0.5765

Epoch 00082: val_mDice did not improve from 0.60369
Epoch 83/300
 - 13s - loss: 0.2584 - acc: 0.9541 - mDice: 0.7593 - val_loss: 0.5471 - val_acc: 0.9500 - val_mDice: 0.5759

Epoch 00083: val_mDice did not improve from 0.60369
Epoch 84/300
 - 13s - loss: 0.2556 - acc: 0.9543 - mDice: 0.7615 - val_loss: 0.5506 - val_acc: 0.9490 - val_mDice: 0.5741

Epoch 00084: val_mDice did not improve from 0.60369
Epoch 85/300
 - 13s - loss: 0.2540 - acc: 0.9544 - mDice: 0.7628 - val_loss: 0.5343 - val_acc: 0.9496 - val_mDice: 0.5849

Epoch 00085: val_mDice did not improve from 0.60369
Epoch 86/300
 - 13s - loss: 0.2518 - acc: 0.9546 - mDice: 0.7645 - val_loss: 0.5464 - val_acc: 0.9500 - val_mDice: 0.5804

Epoch 00086: val_mDice did not improve from 0.60369
Epoch 87/300
 - 13s - loss: 0.2518 - acc: 0.9546 - mDice: 0.7646 - val_loss: 0.5260 - val_acc: 0.9492 - val_mDice: 0.5870

Epoch 00087: val_mDice did not improve from 0.60369
Epoch 88/300
 - 13s - loss: 0.2504 - acc: 0.9547 - mDice: 0.7657 - val_loss: 0.5365 - val_acc: 0.9507 - val_mDice: 0.5849

Epoch 00088: val_mDice did not improve from 0.60369
Epoch 89/300
 - 13s - loss: 0.2512 - acc: 0.9547 - mDice: 0.7650 - val_loss: 0.5356 - val_acc: 0.9505 - val_mDice: 0.5890

Epoch 00089: val_mDice did not improve from 0.60369
Epoch 90/300
 - 13s - loss: 0.2490 - acc: 0.9548 - mDice: 0.7669 - val_loss: 0.5432 - val_acc: 0.9499 - val_mDice: 0.5813

Epoch 00090: val_mDice did not improve from 0.60369
Epoch 91/300
 - 13s - loss: 0.2496 - acc: 0.9548 - mDice: 0.7663 - val_loss: 0.5878 - val_acc: 0.9461 - val_mDice: 0.5649

Epoch 00091: val_mDice did not improve from 0.60369
Epoch 92/300
 - 13s - loss: 0.2480 - acc: 0.9549 - mDice: 0.7676 - val_loss: 0.5137 - val_acc: 0.9494 - val_mDice: 0.5939

Epoch 00092: val_mDice did not improve from 0.60369
Epoch 93/300
 - 13s - loss: 0.2485 - acc: 0.9549 - mDice: 0.7674 - val_loss: 0.5580 - val_acc: 0.9486 - val_mDice: 0.5762

Epoch 00093: val_mDice did not improve from 0.60369
Epoch 94/300
 - 13s - loss: 0.2457 - acc: 0.9549 - mDice: 0.7694 - val_loss: 0.5234 - val_acc: 0.9501 - val_mDice: 0.5897

Epoch 00094: val_mDice did not improve from 0.60369
Epoch 95/300
 - 13s - loss: 0.2456 - acc: 0.9550 - mDice: 0.7696 - val_loss: 0.5299 - val_acc: 0.9475 - val_mDice: 0.5855

Epoch 00095: val_mDice did not improve from 0.60369
Epoch 96/300
 - 13s - loss: 0.2480 - acc: 0.9549 - mDice: 0.7677 - val_loss: 0.5356 - val_acc: 0.9513 - val_mDice: 0.5881

Epoch 00096: val_mDice did not improve from 0.60369
Epoch 97/300
 - 13s - loss: 0.2471 - acc: 0.9549 - mDice: 0.7684 - val_loss: 0.5519 - val_acc: 0.9504 - val_mDice: 0.5783

Epoch 00097: val_mDice did not improve from 0.60369
Epoch 98/300
 - 13s - loss: 0.2459 - acc: 0.9550 - mDice: 0.7693 - val_loss: 0.5448 - val_acc: 0.9508 - val_mDice: 0.5829

Epoch 00098: val_mDice did not improve from 0.60369
Epoch 99/300
 - 13s - loss: 0.2445 - acc: 0.9552 - mDice: 0.7705 - val_loss: 0.5232 - val_acc: 0.9504 - val_mDice: 0.5915

Epoch 00099: val_mDice did not improve from 0.60369
Epoch 100/300
 - 13s - loss: 0.2449 - acc: 0.9551 - mDice: 0.7701 - val_loss: 0.5298 - val_acc: 0.9495 - val_mDice: 0.5875

Epoch 00100: val_mDice did not improve from 0.60369
Epoch 101/300
 - 13s - loss: 0.2461 - acc: 0.9552 - mDice: 0.7694 - val_loss: 0.5172 - val_acc: 0.9487 - val_mDice: 0.5918

Epoch 00101: val_mDice did not improve from 0.60369
Epoch 102/300
 - 13s - loss: 0.2446 - acc: 0.9552 - mDice: 0.7704 - val_loss: 0.5360 - val_acc: 0.9502 - val_mDice: 0.5871

Epoch 00102: val_mDice did not improve from 0.60369
Epoch 103/300
 - 13s - loss: 0.2459 - acc: 0.9552 - mDice: 0.7694 - val_loss: 0.5732 - val_acc: 0.9498 - val_mDice: 0.5709

Epoch 00103: val_mDice did not improve from 0.60369
Epoch 104/300
 - 13s - loss: 0.2451 - acc: 0.9552 - mDice: 0.7701 - val_loss: 0.5884 - val_acc: 0.9521 - val_mDice: 0.5722

Epoch 00104: val_mDice did not improve from 0.60369
Epoch 105/300
 - 13s - loss: 0.2441 - acc: 0.9552 - mDice: 0.7707 - val_loss: 0.5505 - val_acc: 0.9492 - val_mDice: 0.5828

Epoch 00105: val_mDice did not improve from 0.60369
Epoch 106/300
 - 13s - loss: 0.2429 - acc: 0.9553 - mDice: 0.7717 - val_loss: 0.5566 - val_acc: 0.9481 - val_mDice: 0.5764

Epoch 00106: val_mDice did not improve from 0.60369
Epoch 107/300
 - 13s - loss: 0.2439 - acc: 0.9553 - mDice: 0.7709 - val_loss: 0.5864 - val_acc: 0.9498 - val_mDice: 0.5704

Epoch 00107: val_mDice did not improve from 0.60369
Epoch 108/300
 - 13s - loss: 0.2426 - acc: 0.9554 - mDice: 0.7720 - val_loss: 0.5998 - val_acc: 0.9501 - val_mDice: 0.5624

Epoch 00108: val_mDice did not improve from 0.60369
Epoch 109/300
 - 13s - loss: 0.2417 - acc: 0.9554 - mDice: 0.7727 - val_loss: 0.5354 - val_acc: 0.9502 - val_mDice: 0.5860

Epoch 00109: val_mDice did not improve from 0.60369
Epoch 110/300
 - 13s - loss: 0.2438 - acc: 0.9553 - mDice: 0.7711 - val_loss: 0.5389 - val_acc: 0.9517 - val_mDice: 0.5880

Epoch 00110: val_mDice did not improve from 0.60369
Epoch 111/300
 - 13s - loss: 0.2408 - acc: 0.9556 - mDice: 0.7735 - val_loss: 0.5382 - val_acc: 0.9498 - val_mDice: 0.5865

Epoch 00111: val_mDice did not improve from 0.60369
Epoch 112/300
 - 13s - loss: 0.2412 - acc: 0.9555 - mDice: 0.7732 - val_loss: 0.5493 - val_acc: 0.9503 - val_mDice: 0.5767

Epoch 00112: val_mDice did not improve from 0.60369
Epoch 113/300
 - 13s - loss: 0.2422 - acc: 0.9554 - mDice: 0.7723 - val_loss: 0.5638 - val_acc: 0.9487 - val_mDice: 0.5722

Epoch 00113: val_mDice did not improve from 0.60369
Epoch 114/300
 - 13s - loss: 0.2418 - acc: 0.9555 - mDice: 0.7727 - val_loss: 0.5229 - val_acc: 0.9485 - val_mDice: 0.5881

Epoch 00114: val_mDice did not improve from 0.60369
Epoch 115/300
 - 13s - loss: 0.2407 - acc: 0.9556 - mDice: 0.7736 - val_loss: 0.5934 - val_acc: 0.9489 - val_mDice: 0.5616

Epoch 00115: val_mDice did not improve from 0.60369
Epoch 116/300
 - 13s - loss: 0.2409 - acc: 0.9556 - mDice: 0.7734 - val_loss: 0.5399 - val_acc: 0.9499 - val_mDice: 0.5890

Epoch 00116: val_mDice did not improve from 0.60369
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [1.6805071024921354, 0.793437864527356, 0.6843509154612791, 0.591993324916456, 0.5587591851889754, 0.5683746191376414, 0.530107015338024, 0.5465232270389961, 0.5148371957533853, 0.5328015165622008, 0.5377531374632979, 0.5767076261882675, 0.5634845202195577, 0.5385743206439737, 0.49855315285688007, 0.5634764935717237, 0.5451999849447325, 0.5299727583730687, 0.5161686599587595, 0.5023708153703359, 0.5305839700405824, 0.5658038961154789, 0.5347350219774513, 0.51225843642677, 0.4978535458362302, 0.5080349238891175, 0.5262080414335155, 0.5062465674384347, 0.5150441084494138, 0.5230954102963709, 0.5219982572773981, 0.5375786197252114, 0.6041612025745754, 0.5037141339072968, 0.5241673315703536, 0.5061546767224147, 0.5062856717482626, 0.5153126596738506, 0.5021511905686149, 0.5139890409714682, 0.533057455244011, 0.5269922973723385, 0.5225135124595471, 0.5222821438778712, 0.5231183510918856, 0.4985991659777125, 0.5091304103089445, 0.572577573400636, 0.568893401982398, 0.5154535367502181, 0.5043578570781473, 0.4989867490097131, 0.547923543266744, 0.5203510176536091, 0.5446832136734904, 0.5198211972939901, 0.5343411398333544, 0.5355102909343868, 0.552306579810947, 0.5307141845452719, 0.5303793562857132, 0.5277226467372319, 0.4948443743769683, 0.5277555012170163, 0.5235172107233016, 0.5167842930255655, 0.5560636606962321, 0.5556785807263251, 0.5201837580297246, 0.5284659699354758, 0.5486700278420688, 0.5519204582581972, 0.5394900131491975, 0.4964121347033112, 0.493408283374829, 0.49218581442060416, 0.5005581052609662, 0.5096625469250387, 0.5169938453082932, 0.5198881582840861, 0.5140550273090767, 0.5419526872688165, 0.5471231231476341, 0.5505708206299297, 0.5343102493099661, 0.5463578088323497, 0.5259748101234436, 0.5364684089602039, 0.5356305308182147, 0.5431872213352992, 0.5878468655341165, 0.5136578572528988, 0.5579954322489946, 0.5234467387199402, 0.5298743271294919, 0.535573551441704, 0.5518631259156339, 0.5447730811614564, 0.5232409648389124, 0.5297688462214762, 0.517242302774717, 0.5360455985841804, 0.5732479385157537, 0.588436541277603, 0.5505071721929412, 0.5566436928077783, 0.5864250376903811, 0.5998165124621471, 0.5353797860651709, 0.5389393205083283, 0.5381543812805047, 0.5492616905180435, 0.5638274194142006, 0.5229299478024744, 0.5934199461057865, 0.5398507744240362], 'val_acc': [0.9163002881257893, 0.9285416243462589, 0.9384338576034461, 0.9443262046275858, 0.9436217033663276, 0.9410846120152394, 0.9443489472959294, 0.9485141105492022, 0.9470657819476207, 0.9453819707119265, 0.9425680051302777, 0.9490491930998903, 0.9441939941997635, 0.9442704346592866, 0.9476442803217712, 0.9452538866570542, 0.9430411411397284, 0.9490657248976511, 0.9492682035408873, 0.9466009479661227, 0.947410821581686, 0.9494355397517454, 0.9464129269456064, 0.9495099416658199, 0.9494190355918927, 0.9486339405262271, 0.9442807409350432, 0.947530661881303, 0.9482289785779389, 0.9463633435398506, 0.947805440625665, 0.949551242023873, 0.9479128798293002, 0.947280667347615, 0.9502702505228906, 0.9490450697238219, 0.9480182365332236, 0.9488508747942621, 0.9485864226378542, 0.9492702604006122, 0.9464315169350395, 0.9471236670483424, 0.950348728195915, 0.9477620427834921, 0.9487475632955242, 0.9504313845208238, 0.949257862634499, 0.9460265782958303, 0.9491793876253692, 0.9472848120348414, 0.9486256591434585, 0.9492351739100238, 0.9492805826597374, 0.9482847455493565, 0.94986735675588, 0.9502413269527797, 0.9478219934015967, 0.9488095308149327, 0.9481463395683459, 0.9478818960695959, 0.9498508242921456, 0.9463220458456924, 0.9512495355233134, 0.9504458727783331, 0.9506442130610929, 0.9507330389662162, 0.9486504533437378, 0.9463385366860715, 0.9462290396237506, 0.9510367542671758, 0.9455121412623528, 0.9486256548146296, 0.950567746961583, 0.9473963566332556, 0.9486814700691394, 0.9495182130589831, 0.9486835222670486, 0.9504065726722419, 0.9503177644154213, 0.9497186215230207, 0.9493901206794397, 0.9467435132857808, 0.9500223161787961, 0.9490120251085505, 0.949600824763655, 0.9499851162207194, 0.949171088927285, 0.9507495527826874, 0.9505470691446486, 0.9498776836768209, 0.9460761550418492, 0.9493880165355831, 0.9486153199020044, 0.9501152777805009, 0.9474562985937023, 0.951259884088399, 0.950373560689681, 0.9507537191140585, 0.9503756235431693, 0.9495202562662476, 0.9487351691922662, 0.9502227333004915, 0.9498115831247255, 0.9520883700035138, 0.9492268692181763, 0.9480761006557742, 0.9497950676433201, 0.9500553791083437, 0.9502433694940705, 0.9517495409070447, 0.9497826668803252, 0.950330157186732, 0.9487248502630096, 0.9484748600581505, 0.9488591188825043, 0.9499231413756003], 'val_mDice': [0.23626329396024096, 0.45329500909624154, 0.49887032831847333, 0.5436044425271743, 0.5574653674770333, 0.5546792415933236, 0.5750304497154065, 0.5703558096006596, 0.5874970565295087, 0.5792418918130118, 0.5734515276701091, 0.5562945391212761, 0.5571933618470943, 0.5723985270414939, 0.596726888384899, 0.5600405701711857, 0.5687715248022666, 0.5814948827860742, 0.5876641912833273, 0.5931593965551707, 0.5789527630006801, 0.5673488311927412, 0.5805614707190231, 0.5918215466611212, 0.5987940307436043, 0.5933565793756667, 0.5790198405361708, 0.5930503726671528, 0.5873014690489743, 0.5827084043838459, 0.5841566990207694, 0.5805269862686455, 0.5528009856879378, 0.5938428174184022, 0.5846196965798319, 0.5943918158222177, 0.5919857151681485, 0.590760654244343, 0.5961527824401855, 0.5905662052458225, 0.5787325278340771, 0.5813086002898615, 0.5849420881138168, 0.5859360188745254, 0.5873669582372271, 0.6008042823002991, 0.595247842746074, 0.5610499362039832, 0.5663946467404924, 0.589015133554043, 0.5953365484429471, 0.5965287608807314, 0.5746436705136432, 0.5860241631555824, 0.5752136674007224, 0.5899850423109598, 0.5808052097618913, 0.581754507299242, 0.5707278508047818, 0.5832717884852233, 0.5840587109826797, 0.5841822530970228, 0.6022654818422968, 0.5879258237071543, 0.5889785306413746, 0.590438957986885, 0.5694264296712822, 0.5671498435835599, 0.5851291744402667, 0.5875960488559148, 0.5755484706862679, 0.5761044231872985, 0.5856939427679477, 0.5990850286110819, 0.6010728112146175, 0.6036897314993362, 0.5989076571757567, 0.5962805794603998, 0.5921642820262376, 0.5894513026962067, 0.5929559962043549, 0.5764964885551837, 0.5759430374513125, 0.5741024903078985, 0.5848876724030052, 0.5803967248128113, 0.5870351328530126, 0.5848849871971088, 0.5889705805805142, 0.5812537563579708, 0.5648568948553927, 0.5939099136011561, 0.5761871760783914, 0.5896558228817732, 0.585498594704953, 0.5880854955598629, 0.5783487804775131, 0.5829050617511046, 0.5914925263580664, 0.5874825542865518, 0.5918469335779798, 0.5871193731963301, 0.5708725459082833, 0.5721988618040884, 0.5827796852122472, 0.5763949562051442, 0.5704445406045328, 0.5623990700231584, 0.5860060276931891, 0.5880420654179663, 0.5864715716026349, 0.5767233884534356, 0.5722309537440039, 0.5881040069644011, 0.5616388274304693, 0.5889955692451093], 'loss': [2.0429548907952593, 0.7651394119930647, 0.5967113414586457, 0.5279611967486576, 0.4874267780253599, 0.4593932852071911, 0.43959035307134875, 0.42267187944678375, 0.40774534010567715, 0.39510499508472696, 0.38674049784263154, 0.37881501047324656, 0.37378862502138493, 0.36365665635877714, 0.35755915610717925, 0.3511987567665361, 0.3458502370786851, 0.34193300292886786, 0.337119762060345, 0.33182550214336926, 0.3291328572644549, 0.32592952738698483, 0.3215063998128625, 0.3188443217238052, 0.315288668325229, 0.31198874040792907, 0.3119157782278642, 0.3244598945380101, 0.3062229858693406, 0.3046694786017136, 0.3013452340718234, 0.29941623704241654, 0.29737084511058615, 0.29422529038115075, 0.29378837451073386, 0.292758707549342, 0.2894041318872267, 0.2886425084255144, 0.28527034803300594, 0.28608112687002657, 0.2846898647520993, 0.2824155388071376, 0.28043390727628775, 0.279358708112174, 0.2787386913307611, 0.27746565576589394, 0.27566636566970093, 0.274407835341988, 0.27268788060892135, 0.2715475632859876, 0.27271361086053153, 0.2718725160123813, 0.2705245537829551, 0.26867691104587765, 0.26766794558009266, 0.26786438192906226, 0.26698812697098784, 0.2644869450484412, 0.2631278477990999, 0.2619656007875902, 0.2626967487346372, 0.2614826855397966, 0.26329951091442716, 0.26076538474898303, 0.2592875203982553, 0.26031328038734053, 0.2585432048353207, 0.2572962761048651, 0.2569416625363642, 0.25608653061501335, 0.2554881022725189, 0.2550379264308284, 0.2557005270796984, 0.44450514507828687, 0.32269613474264985, 0.2952855806563403, 0.2826263547190381, 0.27666342498514557, 0.27070851907005017, 0.26716818409764387, 0.2618889394756184, 0.2601009467141404, 0.2583747855131224, 0.25559833693703005, 0.2540134316891875, 0.2518099811814539, 0.2517725258203745, 0.2504144216030487, 0.25118486895604586, 0.24899392852783983, 0.2496126620142063, 0.2479798814601274, 0.24845931627191908, 0.24574595364984894, 0.2455611765347342, 0.2479716163920094, 0.24713003951592563, 0.24588459687054168, 0.24450420886627125, 0.24492596517129372, 0.24607033271765139, 0.24459792305380357, 0.24590246994542397, 0.24513645455453023, 0.2440912346228049, 0.2429361856455741, 0.24387395590175295, 0.2425657400554915, 0.24173697920060744, 0.24377828147421604, 0.24076401161041194, 0.24116577418643492, 0.2422121815258859, 0.24177940847206775, 0.24065652847075786, 0.24094558454655166], 'acc': [0.7162602089991056, 0.9099236820642805, 0.9227873047552144, 0.9300014927596167, 0.9338927766763984, 0.9365639516707502, 0.938451598869755, 0.939955561267259, 0.9411969559883852, 0.9422226128388085, 0.9431320127822249, 0.9438692004967214, 0.9444448314073539, 0.9451487466378848, 0.9456844553241841, 0.9463779161707598, 0.9467499129854382, 0.9471502298168949, 0.9474976954523251, 0.9480525589568392, 0.9482496855214922, 0.948566596876542, 0.9489442965192386, 0.9491353991224994, 0.9494517249684729, 0.949671151357424, 0.9498416088607913, 0.9486879906320123, 0.9502001931663302, 0.9503392121460851, 0.9505816173737854, 0.9507753799394172, 0.9509151633103542, 0.9511354330136466, 0.9511537008487829, 0.951271956262749, 0.9514295458436551, 0.9514499497721381, 0.9517610167685719, 0.9517625641552726, 0.9518851102563877, 0.9521172236989808, 0.9522233110913965, 0.9522706018275382, 0.9523610573183457, 0.9524845484911788, 0.9525397771240144, 0.9526775462436141, 0.9527930199668192, 0.9528861355141393, 0.952776983489879, 0.952960962054192, 0.953011477271441, 0.9531478782013334, 0.9532698546740933, 0.9532721715908113, 0.9533287081789343, 0.9533740864730558, 0.9534768516556006, 0.9536601615577966, 0.9535541535722334, 0.9537339811426097, 0.9536270255921979, 0.9537681009500519, 0.9538638718597874, 0.9539468378765145, 0.9539585813225033, 0.9540748597522374, 0.9541074455897862, 0.9542196581296285, 0.9542637655148222, 0.9543058627357242, 0.9543370028757775, 0.9376580315596865, 0.9488744638524643, 0.9510361132464127, 0.9519578001739529, 0.9525474897852053, 0.9529977376655415, 0.9533304189273549, 0.9536329292438174, 0.953855978930336, 0.9540786672265666, 0.9543215938821012, 0.954419587563666, 0.9545739288845845, 0.9545619870756623, 0.9547487790272533, 0.9546518203843543, 0.954848345770217, 0.9547606259056909, 0.9548613913866515, 0.9548675770963707, 0.954928968692357, 0.9549972508203086, 0.954867495725529, 0.9549329778018532, 0.955047946072087, 0.9551520808662025, 0.9551226921762219, 0.9552196968219215, 0.9552058999876423, 0.9551771546194453, 0.9551910953346171, 0.9552146555174865, 0.9553099918531687, 0.9552619517333211, 0.9554119476285948, 0.9553993407641548, 0.9553107160361307, 0.9555703811406323, 0.9554548299810568, 0.955358089704567, 0.9554749084878517, 0.9556222859729279, 0.9555656905754947], 'mDice': [0.19699328272185954, 0.44928744907479395, 0.5339300927107685, 0.5738898153158583, 0.59852443068098, 0.6161769582103211, 0.6290279611004548, 0.640429391203139, 0.6498683254662035, 0.658484077493867, 0.6642735265424637, 0.6699095414319944, 0.6735021044671565, 0.6804854119306399, 0.6847399686177659, 0.6892856727088694, 0.6930633093963929, 0.6960424676348419, 0.6994710951113479, 0.7033911916848771, 0.705390012989467, 0.7077027586094532, 0.7109442676673833, 0.7129284330724819, 0.7156590240517575, 0.7179826375322854, 0.7182386100120154, 0.7098105711573629, 0.7222876182848265, 0.7236465177441999, 0.726035451685822, 0.7274528399225895, 0.7290785741548926, 0.7313890890821666, 0.7317394614381979, 0.7326871400941374, 0.7350816353948592, 0.7357500648779012, 0.7382641001195924, 0.7376915911308632, 0.7387397349331999, 0.7404684427938757, 0.7420318833812053, 0.7427880319074688, 0.7434030773884966, 0.7443304537921733, 0.7457221702360444, 0.7466746486906432, 0.7479794010877882, 0.7488854271180944, 0.7479437895735574, 0.7486884202788867, 0.7497044044163977, 0.7511288841548137, 0.7519911713319941, 0.7519599606019403, 0.7525075116024305, 0.7544127341403881, 0.7555226510493404, 0.7564014846200446, 0.7559019304829403, 0.7568040698885197, 0.7554825953678669, 0.7574000130953544, 0.7585564361704921, 0.7577821658584886, 0.7592274936791644, 0.7600938881003878, 0.7604565211847635, 0.7611408433450099, 0.7615556584731095, 0.7619659718192809, 0.7619947492800392, 0.6338031382792124, 0.7102517211471636, 0.7306157014227259, 0.740319264268805, 0.7450542566297257, 0.7495403939047629, 0.7524657934671991, 0.7564393306608248, 0.7578913836390629, 0.7592967839277646, 0.7615369575799248, 0.762774225764464, 0.7645129618039092, 0.7645775452398227, 0.7657283028124802, 0.7650372653892829, 0.7668916541638896, 0.7663365674755113, 0.7676470255541403, 0.7673508187185919, 0.7694033841851503, 0.7695787768368887, 0.7676976585523229, 0.7683594171748066, 0.7692710469019814, 0.7704614847159958, 0.7700619792978486, 0.7693531008322744, 0.7704455292041146, 0.7693507182793539, 0.7700605186870185, 0.770719960869985, 0.7717109767188629, 0.7709223567403926, 0.7720245196664653, 0.7726908596303038, 0.7710965595002022, 0.7734829895760355, 0.7731506345864313, 0.7723033106812048, 0.7727169393616612, 0.7736120854748029, 0.7733890361356343]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.06s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:22,  1.98s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:41,  1.84s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:49,  1.88s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:11,  1.75s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:48,  1.89s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:09,  1.76s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:20,  1.80s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:09,  1.77s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:49,  1.92s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:10,  2.00s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:39,  1.90s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:07,  2.01s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:34,  1.89s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:23,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:35,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<08:56,  1.99s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:33,  1.91s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:42,  1.96s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:28,  1.91s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:27,  1.92s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:13,  1.88s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:46,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:20,  1.93s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:51,  2.05s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:24,  1.96s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:15,  1.93s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:15,  1.93s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:27,  1.99s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:34,  2.03s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:11,  1.94s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<08:10,  1.95s/it]predicting train subjects:  12%|█▏        | 34/285 [01:04<08:06,  1.94s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<08:11,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:49,  1.89s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<08:17,  2.01s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<08:01,  1.96s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:52,  1.93s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:29,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:10,  1.77s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:17,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<07:44,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:49,  1.96s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<08:00,  2.01s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:37,  1.92s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:42,  1.95s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<07:48,  1.98s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<07:46,  1.98s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<07:46,  2.00s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<07:30,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<07:32,  1.95s/it]predicting train subjects:  19%|█▉        | 54/285 [01:43<07:46,  2.02s/it]predicting train subjects:  19%|█▉        | 55/285 [01:45<07:26,  1.94s/it]predicting train subjects:  20%|█▉        | 56/285 [01:47<07:24,  1.94s/it]predicting train subjects:  20%|██        | 57/285 [01:49<07:08,  1.88s/it]predicting train subjects:  20%|██        | 58/285 [01:51<07:11,  1.90s/it]predicting train subjects:  21%|██        | 59/285 [01:53<07:32,  2.00s/it]predicting train subjects:  21%|██        | 60/285 [01:55<07:37,  2.03s/it]predicting train subjects:  21%|██▏       | 61/285 [01:57<07:11,  1.93s/it]predicting train subjects:  22%|██▏       | 62/285 [01:59<07:19,  1.97s/it]predicting train subjects:  22%|██▏       | 63/285 [02:01<07:15,  1.96s/it]predicting train subjects:  22%|██▏       | 64/285 [02:02<07:01,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:04<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:06<07:05,  1.94s/it]predicting train subjects:  24%|██▎       | 67/285 [02:08<06:59,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:10<06:45,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:12<06:45,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:14<06:52,  1.92s/it]predicting train subjects:  25%|██▍       | 71/285 [02:16<06:54,  1.94s/it]predicting train subjects:  25%|██▌       | 72/285 [02:18<06:43,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:20<06:43,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:22<06:39,  1.89s/it]predicting train subjects:  26%|██▋       | 75/285 [02:23<06:39,  1.90s/it]predicting train subjects:  27%|██▋       | 76/285 [02:25<06:33,  1.88s/it]predicting train subjects:  27%|██▋       | 77/285 [02:27<06:16,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:29<06:15,  1.81s/it]predicting train subjects:  28%|██▊       | 79/285 [02:31<06:30,  1.89s/it]predicting train subjects:  28%|██▊       | 80/285 [02:33<06:28,  1.90s/it]predicting train subjects:  28%|██▊       | 81/285 [02:35<06:24,  1.88s/it]predicting train subjects:  29%|██▉       | 82/285 [02:37<06:29,  1.92s/it]predicting train subjects:  29%|██▉       | 83/285 [02:38<06:12,  1.84s/it]predicting train subjects:  29%|██▉       | 84/285 [02:40<06:00,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:42<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:44<06:13,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:46<06:14,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:47<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:49<06:01,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:51<06:06,  1.88s/it]predicting train subjects:  32%|███▏      | 91/285 [02:53<06:02,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:55<06:01,  1.87s/it]predicting train subjects:  33%|███▎      | 93/285 [02:57<06:02,  1.89s/it]predicting train subjects:  33%|███▎      | 94/285 [02:59<05:58,  1.88s/it]predicting train subjects:  33%|███▎      | 95/285 [03:01<06:02,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [03:03<05:55,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [03:04<05:56,  1.90s/it]predicting train subjects:  34%|███▍      | 98/285 [03:06<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [03:08<05:47,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:10<05:49,  1.89s/it]predicting train subjects:  35%|███▌      | 101/285 [03:12<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 102/285 [03:14<05:52,  1.92s/it]predicting train subjects:  36%|███▌      | 103/285 [03:16<05:36,  1.85s/it]predicting train subjects:  36%|███▋      | 104/285 [03:18<05:36,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:20<05:47,  1.93s/it]predicting train subjects:  37%|███▋      | 106/285 [03:22<05:44,  1.93s/it]predicting train subjects:  38%|███▊      | 107/285 [03:24<05:45,  1.94s/it]predicting train subjects:  38%|███▊      | 108/285 [03:26<05:44,  1.94s/it]predicting train subjects:  38%|███▊      | 109/285 [03:28<05:44,  1.96s/it]predicting train subjects:  39%|███▊      | 110/285 [03:30<05:47,  1.98s/it]predicting train subjects:  39%|███▉      | 111/285 [03:31<05:33,  1.92s/it]predicting train subjects:  39%|███▉      | 112/285 [03:33<05:34,  1.94s/it]predicting train subjects:  40%|███▉      | 113/285 [03:35<05:31,  1.93s/it]predicting train subjects:  40%|████      | 114/285 [03:37<05:24,  1.90s/it]predicting train subjects:  40%|████      | 115/285 [03:39<05:21,  1.89s/it]predicting train subjects:  41%|████      | 116/285 [03:41<05:20,  1.90s/it]predicting train subjects:  41%|████      | 117/285 [03:43<05:14,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:44<05:10,  1.86s/it]predicting train subjects:  42%|████▏     | 119/285 [03:46<05:14,  1.90s/it]predicting train subjects:  42%|████▏     | 120/285 [03:48<05:10,  1.88s/it]predicting train subjects:  42%|████▏     | 121/285 [03:50<05:02,  1.85s/it]predicting train subjects:  43%|████▎     | 122/285 [03:52<04:48,  1.77s/it]predicting train subjects:  43%|████▎     | 123/285 [03:53<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:55<04:32,  1.69s/it]predicting train subjects:  44%|████▍     | 125/285 [03:57<04:30,  1.69s/it]predicting train subjects:  44%|████▍     | 126/285 [03:58<04:32,  1.71s/it]predicting train subjects:  45%|████▍     | 127/285 [04:00<04:19,  1.64s/it]predicting train subjects:  45%|████▍     | 128/285 [04:02<04:29,  1.72s/it]predicting train subjects:  45%|████▌     | 129/285 [04:03<04:28,  1.72s/it]predicting train subjects:  46%|████▌     | 130/285 [04:05<04:20,  1.68s/it]predicting train subjects:  46%|████▌     | 131/285 [04:07<04:11,  1.64s/it]predicting train subjects:  46%|████▋     | 132/285 [04:08<04:14,  1.67s/it]predicting train subjects:  47%|████▋     | 133/285 [04:10<04:09,  1.64s/it]predicting train subjects:  47%|████▋     | 134/285 [04:11<04:04,  1.62s/it]predicting train subjects:  47%|████▋     | 135/285 [04:13<03:55,  1.57s/it]predicting train subjects:  48%|████▊     | 136/285 [04:15<03:59,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [04:16<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:18<03:59,  1.63s/it]predicting train subjects:  49%|████▉     | 139/285 [04:20<04:05,  1.68s/it]predicting train subjects:  49%|████▉     | 140/285 [04:21<04:01,  1.67s/it]predicting train subjects:  49%|████▉     | 141/285 [04:23<03:54,  1.63s/it]predicting train subjects:  50%|████▉     | 142/285 [04:25<03:56,  1.65s/it]predicting train subjects:  50%|█████     | 143/285 [04:26<03:49,  1.61s/it]predicting train subjects:  51%|█████     | 144/285 [04:28<03:50,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:29<03:52,  1.66s/it]predicting train subjects:  51%|█████     | 146/285 [04:31<03:59,  1.72s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:33<03:54,  1.70s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:35<03:52,  1.69s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:36<03:48,  1.68s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:38<03:41,  1.64s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:40<03:49,  1.71s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:41<03:47,  1.71s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:43<03:41,  1.68s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:45<03:46,  1.73s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:47<03:42,  1.71s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:48<03:42,  1.72s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:50<03:29,  1.64s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:51<03:24,  1.61s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:53<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:54<03:18,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:56<03:22,  1.63s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:58<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:59<03:18,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:01<03:11,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:03<03:11,  1.60s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:04<03:11,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:06<03:09,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:07<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:09<03:01,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:10<03:02,  1.59s/it]predicting train subjects:  60%|██████    | 171/285 [05:12<03:01,  1.59s/it]predicting train subjects:  60%|██████    | 172/285 [05:14<02:57,  1.57s/it]predicting train subjects:  61%|██████    | 173/285 [05:15<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:16<02:49,  1.53s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:18<02:56,  1.61s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:20<03:02,  1.67s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:22<02:59,  1.67s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:23<02:55,  1.64s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:25<02:49,  1.60s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:27<03:01,  1.73s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:29<03:06,  1.79s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:31<03:05,  1.80s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:32<03:00,  1.77s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:34<02:52,  1.70s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:35<02:44,  1.65s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:37<02:54,  1.76s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:40<03:02,  1.86s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:42<03:06,  1.92s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:43<02:51,  1.78s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:45<02:46,  1.75s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:47<02:46,  1.77s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:48<02:41,  1.74s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:50<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:51<02:30,  1.66s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:53<02:24,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:55<02:34,  1.74s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:57<02:41,  1.84s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:59<02:41,  1.85s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:00<02:28,  1.73s/it]predicting train subjects:  70%|███████   | 200/285 [06:02<02:23,  1.69s/it]predicting train subjects:  71%|███████   | 201/285 [06:04<02:25,  1.73s/it]predicting train subjects:  71%|███████   | 202/285 [06:05<02:22,  1.71s/it]predicting train subjects:  71%|███████   | 203/285 [06:07<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:09<02:14,  1.66s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:10<02:09,  1.61s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:12<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:14<02:13,  1.72s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:16<02:16,  1.77s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:17<02:16,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:19<02:10,  1.74s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:21<02:04,  1.68s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:22<02:07,  1.75s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:24<02:08,  1.79s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:26<02:02,  1.73s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:28<02:03,  1.76s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:29<01:59,  1.74s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:32<02:05,  1.84s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:34<02:06,  1.89s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:36<02:10,  1.98s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:37<02:02,  1.88s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:39<01:54,  1.79s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:41<01:52,  1.78s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:42<01:49,  1.76s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:44<01:43,  1.70s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:46<01:41,  1.69s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:48<01:45,  1.79s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:50<01:50,  1.90s/it]predicting train subjects:  80%|████████  | 228/285 [06:52<01:48,  1.90s/it]predicting train subjects:  80%|████████  | 229/285 [06:54<01:46,  1.90s/it]predicting train subjects:  81%|████████  | 230/285 [06:55<01:38,  1.80s/it]predicting train subjects:  81%|████████  | 231/285 [06:57<01:32,  1.72s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:58<01:31,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:00<01:25,  1.65s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:02<01:30,  1.77s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:04<01:24,  1.69s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:06<01:27,  1.79s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:08<01:28,  1.84s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:09<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:11<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:13<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:14<01:13,  1.66s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:16<01:10,  1.64s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:17<01:07,  1.60s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:19<01:10,  1.71s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:21<01:07,  1.70s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:23<01:09,  1.79s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:25<01:10,  1.85s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:27<01:10,  1.91s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:29<01:05,  1.81s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:30<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:32<00:59,  1.74s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:34<00:58,  1.77s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:36<00:59,  1.87s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:38<00:58,  1.90s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:40<00:57,  1.91s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:41<00:53,  1.86s/it]predicting train subjects:  90%|█████████ | 257/285 [07:43<00:51,  1.85s/it]predicting train subjects:  91%|█████████ | 258/285 [07:45<00:50,  1.88s/it]predicting train subjects:  91%|█████████ | 259/285 [07:47<00:49,  1.91s/it]predicting train subjects:  91%|█████████ | 260/285 [07:49<00:47,  1.90s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:51<00:44,  1.86s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:52<00:40,  1.77s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:54<00:38,  1.77s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:56<00:40,  1.91s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:59<00:40,  2.02s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:00<00:35,  1.89s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:02<00:33,  1.86s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:04<00:32,  1.89s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:06<00:29,  1.87s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:07<00:26,  1.79s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:09<00:24,  1.75s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:11<00:24,  1.86s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:13<00:22,  1.85s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:15<00:19,  1.77s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:17<00:18,  1.87s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:19<00:17,  1.94s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:20<00:14,  1.81s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:22<00:12,  1.83s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:24<00:11,  1.83s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:26<00:08,  1.78s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:27<00:06,  1.74s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:29<00:05,  1.74s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:31<00:03,  1.84s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:33<00:01,  1.86s/it]predicting train subjects: 100%|██████████| 285/285 [08:35<00:00,  1.90s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<12:04,  2.55s/it]Loading train:   1%|          | 2/285 [00:04<11:04,  2.35s/it]Loading train:   1%|          | 3/285 [00:06<10:25,  2.22s/it]Loading train:   1%|▏         | 4/285 [00:08<10:02,  2.14s/it]Loading train:   2%|▏         | 5/285 [00:10<10:20,  2.22s/it]Loading train:   2%|▏         | 6/285 [00:12<09:33,  2.06s/it]Loading train:   2%|▏         | 7/285 [00:14<09:23,  2.03s/it]Loading train:   3%|▎         | 8/285 [00:16<09:14,  2.00s/it]Loading train:   3%|▎         | 9/285 [00:18<09:14,  2.01s/it]Loading train:   4%|▎         | 10/285 [00:19<08:41,  1.90s/it]Loading train:   4%|▍         | 11/285 [00:21<07:55,  1.74s/it]Loading train:   4%|▍         | 12/285 [00:22<07:27,  1.64s/it]Loading train:   5%|▍         | 13/285 [00:23<06:50,  1.51s/it]Loading train:   5%|▍         | 14/285 [00:25<06:47,  1.50s/it]Loading train:   5%|▌         | 15/285 [00:27<06:58,  1.55s/it]Loading train:   6%|▌         | 16/285 [00:28<06:56,  1.55s/it]Loading train:   6%|▌         | 17/285 [00:30<07:03,  1.58s/it]Loading train:   6%|▋         | 18/285 [00:32<07:21,  1.65s/it]Loading train:   7%|▋         | 19/285 [00:33<06:51,  1.55s/it]Loading train:   7%|▋         | 20/285 [00:35<07:20,  1.66s/it]Loading train:   7%|▋         | 21/285 [00:36<07:04,  1.61s/it]Loading train:   8%|▊         | 22/285 [00:38<06:44,  1.54s/it]Loading train:   8%|▊         | 23/285 [00:39<06:37,  1.52s/it]Loading train:   8%|▊         | 24/285 [00:41<06:24,  1.47s/it]Loading train:   9%|▉         | 25/285 [00:42<06:23,  1.48s/it]Loading train:   9%|▉         | 26/285 [00:44<06:48,  1.58s/it]Loading train:   9%|▉         | 27/285 [00:45<06:51,  1.60s/it]Loading train:  10%|▉         | 28/285 [00:47<06:37,  1.55s/it]Loading train:  10%|█         | 29/285 [00:48<06:21,  1.49s/it]Loading train:  11%|█         | 30/285 [00:50<06:34,  1.55s/it]Loading train:  11%|█         | 31/285 [00:52<06:44,  1.59s/it]Loading train:  11%|█         | 32/285 [00:53<06:32,  1.55s/it]Loading train:  12%|█▏        | 33/285 [00:55<06:26,  1.53s/it]Loading train:  12%|█▏        | 34/285 [00:56<06:35,  1.58s/it]Loading train:  12%|█▏        | 35/285 [00:58<06:35,  1.58s/it]Loading train:  13%|█▎        | 36/285 [00:59<06:06,  1.47s/it]Loading train:  13%|█▎        | 37/285 [01:00<05:54,  1.43s/it]Loading train:  13%|█▎        | 38/285 [01:02<06:25,  1.56s/it]Loading train:  14%|█▎        | 39/285 [01:04<06:13,  1.52s/it]Loading train:  14%|█▍        | 40/285 [01:05<05:57,  1.46s/it]Loading train:  14%|█▍        | 41/285 [01:06<05:23,  1.33s/it]Loading train:  15%|█▍        | 42/285 [01:07<05:08,  1.27s/it]Loading train:  15%|█▌        | 43/285 [01:08<04:45,  1.18s/it]Loading train:  15%|█▌        | 44/285 [01:10<04:58,  1.24s/it]Loading train:  16%|█▌        | 45/285 [01:11<04:49,  1.21s/it]Loading train:  16%|█▌        | 46/285 [01:12<05:01,  1.26s/it]Loading train:  16%|█▋        | 47/285 [01:13<05:01,  1.27s/it]Loading train:  17%|█▋        | 48/285 [01:15<05:32,  1.40s/it]Loading train:  17%|█▋        | 49/285 [01:17<06:27,  1.64s/it]Loading train:  18%|█▊        | 50/285 [01:19<06:37,  1.69s/it]Loading train:  18%|█▊        | 51/285 [01:20<06:12,  1.59s/it]Loading train:  18%|█▊        | 52/285 [01:22<05:43,  1.48s/it]Loading train:  19%|█▊        | 53/285 [01:23<05:42,  1.47s/it]Loading train:  19%|█▉        | 54/285 [01:25<05:54,  1.54s/it]Loading train:  19%|█▉        | 55/285 [01:26<05:54,  1.54s/it]Loading train:  20%|█▉        | 56/285 [01:28<05:46,  1.51s/it]Loading train:  20%|██        | 57/285 [01:29<05:27,  1.44s/it]Loading train:  20%|██        | 58/285 [01:30<05:05,  1.34s/it]Loading train:  21%|██        | 59/285 [01:31<04:53,  1.30s/it]Loading train:  21%|██        | 60/285 [01:33<05:42,  1.52s/it]Loading train:  21%|██▏       | 61/285 [01:35<05:42,  1.53s/it]Loading train:  22%|██▏       | 62/285 [01:36<05:42,  1.54s/it]Loading train:  22%|██▏       | 63/285 [01:38<05:41,  1.54s/it]Loading train:  22%|██▏       | 64/285 [01:40<05:44,  1.56s/it]Loading train:  23%|██▎       | 65/285 [01:42<06:12,  1.69s/it]Loading train:  23%|██▎       | 66/285 [01:44<06:51,  1.88s/it]Loading train:  24%|██▎       | 67/285 [01:46<06:32,  1.80s/it]Loading train:  24%|██▍       | 68/285 [01:47<05:46,  1.60s/it]Loading train:  24%|██▍       | 69/285 [01:48<05:29,  1.52s/it]Loading train:  25%|██▍       | 70/285 [01:50<05:29,  1.53s/it]Loading train:  25%|██▍       | 71/285 [01:51<05:22,  1.51s/it]Loading train:  25%|██▌       | 72/285 [01:52<05:01,  1.41s/it]Loading train:  26%|██▌       | 73/285 [01:54<05:33,  1.57s/it]Loading train:  26%|██▌       | 74/285 [01:56<05:36,  1.59s/it]Loading train:  26%|██▋       | 75/285 [01:57<05:37,  1.61s/it]Loading train:  27%|██▋       | 76/285 [01:59<05:46,  1.66s/it]Loading train:  27%|██▋       | 77/285 [02:00<05:15,  1.51s/it]Loading train:  27%|██▋       | 78/285 [02:02<05:13,  1.52s/it]Loading train:  28%|██▊       | 79/285 [02:04<05:38,  1.64s/it]Loading train:  28%|██▊       | 80/285 [02:06<05:50,  1.71s/it]Loading train:  28%|██▊       | 81/285 [02:07<05:22,  1.58s/it]Loading train:  29%|██▉       | 82/285 [02:09<05:29,  1.63s/it]Loading train:  29%|██▉       | 83/285 [02:10<05:21,  1.59s/it]Loading train:  29%|██▉       | 84/285 [02:12<05:22,  1.61s/it]Loading train:  30%|██▉       | 85/285 [02:13<05:06,  1.53s/it]Loading train:  30%|███       | 86/285 [02:15<05:08,  1.55s/it]Loading train:  31%|███       | 87/285 [02:16<05:11,  1.57s/it]Loading train:  31%|███       | 88/285 [02:18<04:38,  1.41s/it]Loading train:  31%|███       | 89/285 [02:19<04:36,  1.41s/it]Loading train:  32%|███▏      | 90/285 [02:20<04:24,  1.36s/it]Loading train:  32%|███▏      | 91/285 [02:21<04:05,  1.27s/it]Loading train:  32%|███▏      | 92/285 [02:23<04:07,  1.28s/it]Loading train:  33%|███▎      | 93/285 [02:24<03:53,  1.21s/it]Loading train:  33%|███▎      | 94/285 [02:25<04:05,  1.29s/it]Loading train:  33%|███▎      | 95/285 [02:27<04:29,  1.42s/it]Loading train:  34%|███▎      | 96/285 [02:28<04:26,  1.41s/it]Loading train:  34%|███▍      | 97/285 [02:30<04:41,  1.50s/it]Loading train:  34%|███▍      | 98/285 [02:31<04:45,  1.53s/it]Loading train:  35%|███▍      | 99/285 [02:33<04:26,  1.43s/it]Loading train:  35%|███▌      | 100/285 [02:34<04:24,  1.43s/it]Loading train:  35%|███▌      | 101/285 [02:36<04:28,  1.46s/it]Loading train:  36%|███▌      | 102/285 [02:37<04:29,  1.47s/it]Loading train:  36%|███▌      | 103/285 [02:39<04:45,  1.57s/it]Loading train:  36%|███▋      | 104/285 [02:41<04:57,  1.64s/it]Loading train:  37%|███▋      | 105/285 [02:42<04:57,  1.65s/it]Loading train:  37%|███▋      | 106/285 [02:44<04:36,  1.55s/it]Loading train:  38%|███▊      | 107/285 [02:45<04:28,  1.51s/it]Loading train:  38%|███▊      | 108/285 [02:46<04:14,  1.44s/it]Loading train:  38%|███▊      | 109/285 [02:48<04:03,  1.39s/it]Loading train:  39%|███▊      | 110/285 [02:49<04:07,  1.42s/it]Loading train:  39%|███▉      | 111/285 [02:51<04:05,  1.41s/it]Loading train:  39%|███▉      | 112/285 [02:52<04:24,  1.53s/it]Loading train:  40%|███▉      | 113/285 [02:54<04:34,  1.59s/it]Loading train:  40%|████      | 114/285 [02:55<04:15,  1.49s/it]Loading train:  40%|████      | 115/285 [02:57<04:05,  1.44s/it]Loading train:  41%|████      | 116/285 [02:58<03:56,  1.40s/it]Loading train:  41%|████      | 117/285 [02:59<03:53,  1.39s/it]Loading train:  41%|████▏     | 118/285 [03:01<03:40,  1.32s/it]Loading train:  42%|████▏     | 119/285 [03:02<03:55,  1.42s/it]Loading train:  42%|████▏     | 120/285 [03:04<04:10,  1.52s/it]Loading train:  42%|████▏     | 121/285 [03:06<04:37,  1.69s/it]Loading train:  43%|████▎     | 122/285 [03:08<04:40,  1.72s/it]Loading train:  43%|████▎     | 123/285 [03:09<04:28,  1.66s/it]Loading train:  44%|████▎     | 124/285 [03:11<04:16,  1.59s/it]Loading train:  44%|████▍     | 125/285 [03:12<03:52,  1.45s/it]Loading train:  44%|████▍     | 126/285 [03:13<03:24,  1.28s/it]Loading train:  45%|████▍     | 127/285 [03:14<03:22,  1.28s/it]Loading train:  45%|████▍     | 128/285 [03:15<03:21,  1.28s/it]Loading train:  45%|████▌     | 129/285 [03:17<03:15,  1.25s/it]Loading train:  46%|████▌     | 130/285 [03:18<03:19,  1.29s/it]Loading train:  46%|████▌     | 131/285 [03:19<03:02,  1.19s/it]Loading train:  46%|████▋     | 132/285 [03:21<03:29,  1.37s/it]Loading train:  47%|████▋     | 133/285 [03:22<03:16,  1.29s/it]Loading train:  47%|████▋     | 134/285 [03:23<03:07,  1.24s/it]Loading train:  47%|████▋     | 135/285 [03:24<02:58,  1.19s/it]Loading train:  48%|████▊     | 136/285 [03:25<02:53,  1.17s/it]Loading train:  48%|████▊     | 137/285 [03:26<02:53,  1.17s/it]Loading train:  48%|████▊     | 138/285 [03:27<02:53,  1.18s/it]Loading train:  49%|████▉     | 139/285 [03:29<03:17,  1.35s/it]Loading train:  49%|████▉     | 140/285 [03:31<03:21,  1.39s/it]Loading train:  49%|████▉     | 141/285 [03:32<03:06,  1.30s/it]Loading train:  50%|████▉     | 142/285 [03:33<02:56,  1.24s/it]Loading train:  50%|█████     | 143/285 [03:34<02:53,  1.22s/it]Loading train:  51%|█████     | 144/285 [03:35<02:58,  1.26s/it]Loading train:  51%|█████     | 145/285 [03:36<02:49,  1.21s/it]Loading train:  51%|█████     | 146/285 [03:38<02:57,  1.28s/it]Loading train:  52%|█████▏    | 147/285 [03:39<02:48,  1.22s/it]Loading train:  52%|█████▏    | 148/285 [03:41<03:00,  1.32s/it]Loading train:  52%|█████▏    | 149/285 [03:42<02:56,  1.30s/it]Loading train:  53%|█████▎    | 150/285 [03:43<03:04,  1.37s/it]Loading train:  53%|█████▎    | 151/285 [03:45<03:15,  1.46s/it]Loading train:  53%|█████▎    | 152/285 [03:46<03:14,  1.46s/it]Loading train:  54%|█████▎    | 153/285 [03:48<03:19,  1.51s/it]Loading train:  54%|█████▍    | 154/285 [03:50<03:28,  1.59s/it]Loading train:  54%|█████▍    | 155/285 [03:51<03:04,  1.42s/it]Loading train:  55%|█████▍    | 156/285 [03:52<02:53,  1.34s/it]Loading train:  55%|█████▌    | 157/285 [03:53<02:43,  1.28s/it]Loading train:  55%|█████▌    | 158/285 [03:55<02:48,  1.33s/it]Loading train:  56%|█████▌    | 159/285 [03:56<02:58,  1.42s/it]Loading train:  56%|█████▌    | 160/285 [03:58<03:16,  1.57s/it]Loading train:  56%|█████▋    | 161/285 [04:00<03:14,  1.57s/it]Loading train:  57%|█████▋    | 162/285 [04:01<03:12,  1.56s/it]Loading train:  57%|█████▋    | 163/285 [04:02<02:57,  1.45s/it]Loading train:  58%|█████▊    | 164/285 [04:04<02:51,  1.42s/it]Loading train:  58%|█████▊    | 165/285 [04:05<02:49,  1.42s/it]Loading train:  58%|█████▊    | 166/285 [04:07<02:51,  1.44s/it]Loading train:  59%|█████▊    | 167/285 [04:08<02:49,  1.44s/it]Loading train:  59%|█████▉    | 168/285 [04:10<02:50,  1.46s/it]Loading train:  59%|█████▉    | 169/285 [04:11<02:32,  1.32s/it]Loading train:  60%|█████▉    | 170/285 [04:12<02:27,  1.28s/it]Loading train:  60%|██████    | 171/285 [04:13<02:25,  1.28s/it]Loading train:  60%|██████    | 172/285 [04:15<02:36,  1.38s/it]Loading train:  61%|██████    | 173/285 [04:16<02:24,  1.29s/it]Loading train:  61%|██████    | 174/285 [04:17<02:22,  1.29s/it]Loading train:  61%|██████▏   | 175/285 [04:19<02:31,  1.38s/it]Loading train:  62%|██████▏   | 176/285 [04:20<02:35,  1.42s/it]Loading train:  62%|██████▏   | 177/285 [04:21<02:28,  1.37s/it]Loading train:  62%|██████▏   | 178/285 [04:23<02:35,  1.45s/it]Loading train:  63%|██████▎   | 179/285 [04:24<02:31,  1.43s/it]Loading train:  63%|██████▎   | 180/285 [04:26<02:31,  1.45s/it]Loading train:  64%|██████▎   | 181/285 [04:27<02:28,  1.42s/it]Loading train:  64%|██████▍   | 182/285 [04:28<02:11,  1.27s/it]Loading train:  64%|██████▍   | 183/285 [04:30<02:16,  1.33s/it]Loading train:  65%|██████▍   | 184/285 [04:31<02:11,  1.31s/it]Loading train:  65%|██████▍   | 185/285 [04:32<02:14,  1.35s/it]Loading train:  65%|██████▌   | 186/285 [04:33<02:04,  1.26s/it]Loading train:  66%|██████▌   | 187/285 [04:35<01:58,  1.21s/it]Loading train:  66%|██████▌   | 188/285 [04:36<01:57,  1.21s/it]Loading train:  66%|██████▋   | 189/285 [04:37<01:42,  1.07s/it]Loading train:  67%|██████▋   | 190/285 [04:37<01:32,  1.03it/s]Loading train:  67%|██████▋   | 191/285 [04:38<01:33,  1.00it/s]Loading train:  67%|██████▋   | 192/285 [04:39<01:30,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [04:40<01:29,  1.03it/s]Loading train:  68%|██████▊   | 194/285 [04:41<01:28,  1.03it/s]Loading train:  68%|██████▊   | 195/285 [04:42<01:27,  1.02it/s]Loading train:  69%|██████▉   | 196/285 [04:43<01:32,  1.04s/it]Loading train:  69%|██████▉   | 197/285 [04:44<01:29,  1.01s/it]Loading train:  69%|██████▉   | 198/285 [04:46<01:35,  1.10s/it]Loading train:  70%|██████▉   | 199/285 [04:46<01:26,  1.00s/it]Loading train:  70%|███████   | 200/285 [04:47<01:18,  1.08it/s]Loading train:  71%|███████   | 201/285 [04:48<01:18,  1.07it/s]Loading train:  71%|███████   | 202/285 [04:49<01:15,  1.10it/s]Loading train:  71%|███████   | 203/285 [04:50<01:20,  1.02it/s]Loading train:  72%|███████▏  | 204/285 [04:51<01:17,  1.04it/s]Loading train:  72%|███████▏  | 205/285 [04:52<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [04:53<01:19,  1.00s/it]Loading train:  73%|███████▎  | 207/285 [04:54<01:23,  1.07s/it]Loading train:  73%|███████▎  | 208/285 [04:56<01:25,  1.11s/it]Loading train:  73%|███████▎  | 209/285 [04:57<01:21,  1.08s/it]Loading train:  74%|███████▎  | 210/285 [04:57<01:17,  1.03s/it]Loading train:  74%|███████▍  | 211/285 [04:58<01:12,  1.02it/s]Loading train:  74%|███████▍  | 212/285 [04:59<01:14,  1.02s/it]Loading train:  75%|███████▍  | 213/285 [05:01<01:14,  1.04s/it]Loading train:  75%|███████▌  | 214/285 [05:02<01:13,  1.04s/it]Loading train:  75%|███████▌  | 215/285 [05:03<01:15,  1.08s/it]Loading train:  76%|███████▌  | 216/285 [05:04<01:12,  1.04s/it]Loading train:  76%|███████▌  | 217/285 [05:05<01:12,  1.07s/it]Loading train:  76%|███████▋  | 218/285 [05:06<01:13,  1.10s/it]Loading train:  77%|███████▋  | 219/285 [05:07<01:12,  1.10s/it]Loading train:  77%|███████▋  | 220/285 [05:08<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [05:09<01:02,  1.02it/s]Loading train:  78%|███████▊  | 222/285 [05:10<00:59,  1.05it/s]Loading train:  78%|███████▊  | 223/285 [05:11<00:57,  1.07it/s]Loading train:  79%|███████▊  | 224/285 [05:11<00:55,  1.10it/s]Loading train:  79%|███████▉  | 225/285 [05:12<00:56,  1.06it/s]Loading train:  79%|███████▉  | 226/285 [05:14<01:02,  1.07s/it]Loading train:  80%|███████▉  | 227/285 [05:15<01:01,  1.06s/it]Loading train:  80%|████████  | 228/285 [05:16<01:02,  1.10s/it]Loading train:  80%|████████  | 229/285 [05:17<01:01,  1.10s/it]Loading train:  81%|████████  | 230/285 [05:18<00:55,  1.01s/it]Loading train:  81%|████████  | 231/285 [05:19<00:53,  1.02it/s]Loading train:  81%|████████▏ | 232/285 [05:20<00:52,  1.02it/s]Loading train:  82%|████████▏ | 233/285 [05:21<00:48,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [05:22<00:54,  1.07s/it]Loading train:  82%|████████▏ | 235/285 [05:23<00:50,  1.00s/it]Loading train:  83%|████████▎ | 236/285 [05:24<00:48,  1.02it/s]Loading train:  83%|████████▎ | 237/285 [05:25<00:48,  1.00s/it]Loading train:  84%|████████▎ | 238/285 [05:26<00:49,  1.06s/it]Loading train:  84%|████████▍ | 239/285 [05:27<00:46,  1.01s/it]Loading train:  84%|████████▍ | 240/285 [05:28<00:43,  1.03it/s]Loading train:  85%|████████▍ | 241/285 [05:29<00:41,  1.06it/s]Loading train:  85%|████████▍ | 242/285 [05:30<00:40,  1.06it/s]Loading train:  85%|████████▌ | 243/285 [05:31<00:40,  1.03it/s]Loading train:  86%|████████▌ | 244/285 [05:32<00:40,  1.01it/s]Loading train:  86%|████████▌ | 245/285 [05:33<00:40,  1.01s/it]Loading train:  86%|████████▋ | 246/285 [05:34<00:42,  1.10s/it]Loading train:  87%|████████▋ | 247/285 [05:35<00:41,  1.09s/it]Loading train:  87%|████████▋ | 248/285 [05:36<00:39,  1.08s/it]Loading train:  87%|████████▋ | 249/285 [05:37<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [05:38<00:34,  1.01it/s]Loading train:  88%|████████▊ | 251/285 [05:39<00:32,  1.03it/s]Loading train:  88%|████████▊ | 252/285 [05:40<00:28,  1.14it/s]Loading train:  89%|████████▉ | 253/285 [05:41<00:31,  1.03it/s]Loading train:  89%|████████▉ | 254/285 [05:42<00:33,  1.08s/it]Loading train:  89%|████████▉ | 255/285 [05:43<00:34,  1.13s/it]Loading train:  90%|████████▉ | 256/285 [05:44<00:29,  1.03s/it]Loading train:  90%|█████████ | 257/285 [05:45<00:28,  1.03s/it]Loading train:  91%|█████████ | 258/285 [05:46<00:27,  1.02s/it]Loading train:  91%|█████████ | 259/285 [05:47<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [05:48<00:25,  1.01s/it]Loading train:  92%|█████████▏| 261/285 [05:49<00:24,  1.01s/it]Loading train:  92%|█████████▏| 262/285 [05:50<00:23,  1.03s/it]Loading train:  92%|█████████▏| 263/285 [05:51<00:23,  1.06s/it]Loading train:  93%|█████████▎| 264/285 [05:53<00:23,  1.11s/it]Loading train:  93%|█████████▎| 265/285 [05:54<00:21,  1.09s/it]Loading train:  93%|█████████▎| 266/285 [05:54<00:18,  1.03it/s]Loading train:  94%|█████████▎| 267/285 [05:56<00:18,  1.00s/it]Loading train:  94%|█████████▍| 268/285 [05:56<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [05:58<00:16,  1.06s/it]Loading train:  95%|█████████▍| 270/285 [05:58<00:14,  1.02it/s]Loading train:  95%|█████████▌| 271/285 [06:00<00:14,  1.00s/it]Loading train:  95%|█████████▌| 272/285 [06:00<00:12,  1.04it/s]Loading train:  96%|█████████▌| 273/285 [06:01<00:11,  1.04it/s]Loading train:  96%|█████████▌| 274/285 [06:02<00:09,  1.12it/s]Loading train:  96%|█████████▋| 275/285 [06:03<00:08,  1.12it/s]Loading train:  97%|█████████▋| 276/285 [06:04<00:08,  1.10it/s]Loading train:  97%|█████████▋| 277/285 [06:05<00:07,  1.12it/s]Loading train:  98%|█████████▊| 278/285 [06:06<00:06,  1.08it/s]Loading train:  98%|█████████▊| 279/285 [06:07<00:05,  1.11it/s]Loading train:  98%|█████████▊| 280/285 [06:08<00:04,  1.08it/s]Loading train:  99%|█████████▊| 281/285 [06:08<00:03,  1.13it/s]Loading train:  99%|█████████▉| 282/285 [06:09<00:02,  1.09it/s]Loading train:  99%|█████████▉| 283/285 [06:11<00:01,  1.03it/s]Loading train: 100%|█████████▉| 284/285 [06:12<00:01,  1.00s/it]Loading train: 100%|██████████| 285/285 [06:13<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:02, 117.39it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:02, 99.71it/s] concatenating: train:   9%|▉         | 26/285 [00:00<00:04, 61.96it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:03, 68.46it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:02, 81.38it/s]concatenating: train:  26%|██▌       | 74/285 [00:00<00:02, 100.03it/s]concatenating: train:  35%|███▍      | 99/285 [00:00<00:01, 121.76it/s]concatenating: train:  46%|████▌     | 130/285 [00:00<00:01, 148.48it/s]concatenating: train:  55%|█████▌    | 158/285 [00:00<00:00, 171.65it/s]concatenating: train:  64%|██████▎   | 181/285 [00:01<00:00, 106.22it/s]concatenating: train:  70%|██████▉   | 199/285 [00:01<00:01, 84.34it/s] concatenating: train:  75%|███████▍  | 213/285 [00:01<00:00, 93.46it/s]concatenating: train:  80%|███████▉  | 227/285 [00:02<00:00, 75.96it/s]concatenating: train:  84%|████████▎ | 238/285 [00:02<00:00, 47.45it/s]concatenating: train:  87%|████████▋ | 247/285 [00:02<00:00, 49.14it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 50.90it/s]concatenating: train:  92%|█████████▏| 262/285 [00:02<00:00, 51.48it/s]concatenating: train:  94%|█████████▍| 269/285 [00:03<00:00, 45.76it/s]concatenating: train:  96%|█████████▋| 275/285 [00:03<00:00, 33.62it/s]concatenating: train:  99%|█████████▉| 282/285 [00:03<00:00, 39.69it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 79.36it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.64s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 87.51it/s]2019-07-11 03:07:29.244447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:07:29.244578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:07:29.244594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:07:29.244603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:07:29.245058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.86it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.62it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.72it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.96it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.83it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.76it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.23it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.72it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.53it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.34it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.16it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.66it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.97it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.40it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.24it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.58it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  9.14it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.53it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.99it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 10)   5410        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 70)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 231,353
Trainable params: 56,633
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.7074 - acc: 0.4988 - mDice: 0.1140 - val_loss: 1.4875 - val_acc: 0.9027 - val_mDice: 0.3026

Epoch 00001: val_mDice improved from -inf to 0.30261, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 0.7926 - acc: 0.9034 - mDice: 0.4430 - val_loss: 1.0691 - val_acc: 0.9220 - val_mDice: 0.4337

Epoch 00002: val_mDice improved from 0.30261 to 0.43375, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.5714 - acc: 0.9142 - mDice: 0.5509 - val_loss: 0.8403 - val_acc: 0.9295 - val_mDice: 0.5305

Epoch 00003: val_mDice improved from 0.43375 to 0.53052, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.5033 - acc: 0.9198 - mDice: 0.5903 - val_loss: 0.7759 - val_acc: 0.9367 - val_mDice: 0.5546

Epoch 00004: val_mDice improved from 0.53052 to 0.55463, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.4685 - acc: 0.9244 - mDice: 0.6120 - val_loss: 0.7284 - val_acc: 0.9406 - val_mDice: 0.5746

Epoch 00005: val_mDice improved from 0.55463 to 0.57463, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.4436 - acc: 0.9278 - mDice: 0.6276 - val_loss: 0.7597 - val_acc: 0.9392 - val_mDice: 0.5698

Epoch 00006: val_mDice did not improve from 0.57463
Epoch 7/300
 - 11s - loss: 0.4268 - acc: 0.9311 - mDice: 0.6386 - val_loss: 0.7455 - val_acc: 0.9432 - val_mDice: 0.5736

Epoch 00007: val_mDice did not improve from 0.57463
Epoch 8/300
 - 11s - loss: 0.4112 - acc: 0.9336 - mDice: 0.6488 - val_loss: 0.7812 - val_acc: 0.9415 - val_mDice: 0.5720

Epoch 00008: val_mDice did not improve from 0.57463
Epoch 9/300
 - 10s - loss: 0.3996 - acc: 0.9353 - mDice: 0.6562 - val_loss: 0.7759 - val_acc: 0.9435 - val_mDice: 0.5764

Epoch 00009: val_mDice improved from 0.57463 to 0.57640, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.3920 - acc: 0.9367 - mDice: 0.6616 - val_loss: 0.7768 - val_acc: 0.9416 - val_mDice: 0.5685

Epoch 00010: val_mDice did not improve from 0.57640
Epoch 11/300
 - 10s - loss: 0.3798 - acc: 0.9380 - mDice: 0.6696 - val_loss: 0.7919 - val_acc: 0.9400 - val_mDice: 0.5651

Epoch 00011: val_mDice did not improve from 0.57640
Epoch 12/300
 - 11s - loss: 0.3722 - acc: 0.9389 - mDice: 0.6748 - val_loss: 0.7977 - val_acc: 0.9426 - val_mDice: 0.5636

Epoch 00012: val_mDice did not improve from 0.57640
Epoch 13/300
 - 11s - loss: 0.3676 - acc: 0.9395 - mDice: 0.6780 - val_loss: 0.7889 - val_acc: 0.9424 - val_mDice: 0.5702

Epoch 00013: val_mDice did not improve from 0.57640
Epoch 14/300
 - 10s - loss: 0.3605 - acc: 0.9405 - mDice: 0.6829 - val_loss: 0.7904 - val_acc: 0.9410 - val_mDice: 0.5722

Epoch 00014: val_mDice did not improve from 0.57640
Epoch 15/300
 - 10s - loss: 0.3585 - acc: 0.9409 - mDice: 0.6845 - val_loss: 0.7927 - val_acc: 0.9394 - val_mDice: 0.5635

Epoch 00015: val_mDice did not improve from 0.57640
Epoch 16/300
 - 10s - loss: 0.3511 - acc: 0.9415 - mDice: 0.6895 - val_loss: 0.7744 - val_acc: 0.9384 - val_mDice: 0.5783

Epoch 00016: val_mDice improved from 0.57640 to 0.57832, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 10s - loss: 0.3472 - acc: 0.9419 - mDice: 0.6923 - val_loss: 0.7885 - val_acc: 0.9371 - val_mDice: 0.5649

Epoch 00017: val_mDice did not improve from 0.57832
Epoch 18/300
 - 10s - loss: 0.3459 - acc: 0.9423 - mDice: 0.6932 - val_loss: 0.7898 - val_acc: 0.9400 - val_mDice: 0.5694

Epoch 00018: val_mDice did not improve from 0.57832
Epoch 19/300
 - 11s - loss: 0.3396 - acc: 0.9426 - mDice: 0.6976 - val_loss: 0.7946 - val_acc: 0.9409 - val_mDice: 0.5693

Epoch 00019: val_mDice did not improve from 0.57832
Epoch 20/300
 - 11s - loss: 0.3354 - acc: 0.9430 - mDice: 0.7007 - val_loss: 0.7825 - val_acc: 0.9421 - val_mDice: 0.5724

Epoch 00020: val_mDice did not improve from 0.57832
Epoch 21/300
 - 10s - loss: 0.3333 - acc: 0.9433 - mDice: 0.7023 - val_loss: 0.7837 - val_acc: 0.9396 - val_mDice: 0.5785

Epoch 00021: val_mDice improved from 0.57832 to 0.57850, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 10s - loss: 0.3323 - acc: 0.9435 - mDice: 0.7031 - val_loss: 0.7784 - val_acc: 0.9425 - val_mDice: 0.5839

Epoch 00022: val_mDice improved from 0.57850 to 0.58395, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 10s - loss: 0.3266 - acc: 0.9439 - mDice: 0.7070 - val_loss: 0.8010 - val_acc: 0.9424 - val_mDice: 0.5621

Epoch 00023: val_mDice did not improve from 0.58395
Epoch 24/300
 - 10s - loss: 0.3241 - acc: 0.9442 - mDice: 0.7089 - val_loss: 0.7772 - val_acc: 0.9432 - val_mDice: 0.5780

Epoch 00024: val_mDice did not improve from 0.58395
Epoch 25/300
 - 11s - loss: 0.3218 - acc: 0.9445 - mDice: 0.7106 - val_loss: 0.7541 - val_acc: 0.9409 - val_mDice: 0.5760

Epoch 00025: val_mDice did not improve from 0.58395
Epoch 26/300
 - 10s - loss: 0.3211 - acc: 0.9445 - mDice: 0.7110 - val_loss: 0.7635 - val_acc: 0.9426 - val_mDice: 0.5744

Epoch 00026: val_mDice did not improve from 0.58395
Epoch 27/300
 - 11s - loss: 0.3176 - acc: 0.9447 - mDice: 0.7137 - val_loss: 0.7764 - val_acc: 0.9402 - val_mDice: 0.5764

Epoch 00027: val_mDice did not improve from 0.58395
Epoch 28/300
 - 10s - loss: 0.3138 - acc: 0.9450 - mDice: 0.7164 - val_loss: 0.8168 - val_acc: 0.9433 - val_mDice: 0.5549

Epoch 00028: val_mDice did not improve from 0.58395
Epoch 29/300
 - 11s - loss: 0.3140 - acc: 0.9452 - mDice: 0.7163 - val_loss: 0.7516 - val_acc: 0.9426 - val_mDice: 0.5793

Epoch 00029: val_mDice did not improve from 0.58395
Epoch 30/300
 - 10s - loss: 0.3105 - acc: 0.9455 - mDice: 0.7189 - val_loss: 0.7504 - val_acc: 0.9389 - val_mDice: 0.5794

Epoch 00030: val_mDice did not improve from 0.58395
Epoch 31/300
 - 11s - loss: 0.3078 - acc: 0.9457 - mDice: 0.7209 - val_loss: 0.7805 - val_acc: 0.9426 - val_mDice: 0.5799

Epoch 00031: val_mDice did not improve from 0.58395
Epoch 32/300
 - 10s - loss: 0.3068 - acc: 0.9458 - mDice: 0.7217 - val_loss: 0.7646 - val_acc: 0.9420 - val_mDice: 0.5791

Epoch 00032: val_mDice did not improve from 0.58395
Epoch 33/300
 - 11s - loss: 0.3055 - acc: 0.9459 - mDice: 0.7227 - val_loss: 0.7984 - val_acc: 0.9435 - val_mDice: 0.5525

Epoch 00033: val_mDice did not improve from 0.58395
Epoch 34/300
 - 10s - loss: 0.3043 - acc: 0.9460 - mDice: 0.7236 - val_loss: 0.7547 - val_acc: 0.9407 - val_mDice: 0.5798

Epoch 00034: val_mDice did not improve from 0.58395
Epoch 35/300
 - 11s - loss: 0.3023 - acc: 0.9463 - mDice: 0.7251 - val_loss: 0.7506 - val_acc: 0.9418 - val_mDice: 0.5885

Epoch 00035: val_mDice improved from 0.58395 to 0.58852, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 10s - loss: 0.3001 - acc: 0.9464 - mDice: 0.7267 - val_loss: 0.7512 - val_acc: 0.9394 - val_mDice: 0.5807

Epoch 00036: val_mDice did not improve from 0.58852
Epoch 37/300
 - 11s - loss: 0.2994 - acc: 0.9465 - mDice: 0.7273 - val_loss: 0.7506 - val_acc: 0.9408 - val_mDice: 0.5809

Epoch 00037: val_mDice did not improve from 0.58852
Epoch 38/300
 - 10s - loss: 0.2976 - acc: 0.9466 - mDice: 0.7286 - val_loss: 0.7424 - val_acc: 0.9420 - val_mDice: 0.5800

Epoch 00038: val_mDice did not improve from 0.58852
Epoch 39/300
 - 11s - loss: 0.2972 - acc: 0.9466 - mDice: 0.7289 - val_loss: 0.7546 - val_acc: 0.9418 - val_mDice: 0.5849

Epoch 00039: val_mDice did not improve from 0.58852
Epoch 40/300
 - 10s - loss: 0.2931 - acc: 0.9470 - mDice: 0.7320 - val_loss: 0.7388 - val_acc: 0.9374 - val_mDice: 0.5720

Epoch 00040: val_mDice did not improve from 0.58852
Epoch 41/300
 - 11s - loss: 0.2942 - acc: 0.9470 - mDice: 0.7312 - val_loss: 0.7580 - val_acc: 0.9420 - val_mDice: 0.5794

Epoch 00041: val_mDice did not improve from 0.58852
Epoch 42/300
 - 10s - loss: 0.2924 - acc: 0.9471 - mDice: 0.7326 - val_loss: 0.7465 - val_acc: 0.9417 - val_mDice: 0.5764

Epoch 00042: val_mDice did not improve from 0.58852
Epoch 43/300
 - 11s - loss: 0.2913 - acc: 0.9473 - mDice: 0.7334 - val_loss: 0.7385 - val_acc: 0.9429 - val_mDice: 0.5776

Epoch 00043: val_mDice did not improve from 0.58852
Epoch 44/300
 - 10s - loss: 0.2888 - acc: 0.9474 - mDice: 0.7352 - val_loss: 0.7407 - val_acc: 0.9403 - val_mDice: 0.5836

Epoch 00044: val_mDice did not improve from 0.58852
Epoch 45/300
 - 11s - loss: 0.2903 - acc: 0.9473 - mDice: 0.7342 - val_loss: 0.7553 - val_acc: 0.9390 - val_mDice: 0.5800

Epoch 00045: val_mDice did not improve from 0.58852
Epoch 46/300
 - 10s - loss: 0.2884 - acc: 0.9474 - mDice: 0.7355 - val_loss: 0.7270 - val_acc: 0.9427 - val_mDice: 0.5864

Epoch 00046: val_mDice did not improve from 0.58852
Epoch 47/300
 - 11s - loss: 0.2868 - acc: 0.9476 - mDice: 0.7368 - val_loss: 0.7367 - val_acc: 0.9417 - val_mDice: 0.5835

Epoch 00047: val_mDice did not improve from 0.58852
Epoch 48/300
 - 10s - loss: 0.2869 - acc: 0.9476 - mDice: 0.7368 - val_loss: 0.7109 - val_acc: 0.9400 - val_mDice: 0.5777

Epoch 00048: val_mDice did not improve from 0.58852
Epoch 49/300
 - 11s - loss: 0.2829 - acc: 0.9479 - mDice: 0.7398 - val_loss: 0.7132 - val_acc: 0.9402 - val_mDice: 0.5832

Epoch 00049: val_mDice did not improve from 0.58852
Epoch 50/300
 - 10s - loss: 0.2824 - acc: 0.9479 - mDice: 0.7402 - val_loss: 0.7306 - val_acc: 0.9412 - val_mDice: 0.5753

Epoch 00050: val_mDice did not improve from 0.58852
Epoch 51/300
 - 11s - loss: 0.2865 - acc: 0.9479 - mDice: 0.7396 - val_loss: 0.8758 - val_acc: 0.9396 - val_mDice: 0.4968

Epoch 00051: val_mDice did not improve from 0.58852
Epoch 52/300
 - 11s - loss: 0.4680 - acc: 0.9313 - mDice: 0.6154 - val_loss: 0.7695 - val_acc: 0.9318 - val_mDice: 0.5655

Epoch 00052: val_mDice did not improve from 0.58852
Epoch 53/300
 - 11s - loss: 0.3522 - acc: 0.9419 - mDice: 0.6883 - val_loss: 0.7240 - val_acc: 0.9362 - val_mDice: 0.5767

Epoch 00053: val_mDice did not improve from 0.58852
Epoch 54/300
 - 11s - loss: 0.3243 - acc: 0.9443 - mDice: 0.7084 - val_loss: 0.7207 - val_acc: 0.9403 - val_mDice: 0.5708

Epoch 00054: val_mDice did not improve from 0.58852
Epoch 55/300
 - 11s - loss: 0.3113 - acc: 0.9455 - mDice: 0.7181 - val_loss: 0.7080 - val_acc: 0.9414 - val_mDice: 0.5779

Epoch 00055: val_mDice did not improve from 0.58852
Epoch 56/300
 - 11s - loss: 0.3028 - acc: 0.9462 - mDice: 0.7244 - val_loss: 0.6947 - val_acc: 0.9436 - val_mDice: 0.5823

Epoch 00056: val_mDice did not improve from 0.58852
Epoch 57/300
 - 10s - loss: 0.2982 - acc: 0.9466 - mDice: 0.7279 - val_loss: 0.7060 - val_acc: 0.9401 - val_mDice: 0.5741

Epoch 00057: val_mDice did not improve from 0.58852
Epoch 58/300
 - 11s - loss: 0.2936 - acc: 0.9470 - mDice: 0.7314 - val_loss: 0.6937 - val_acc: 0.9404 - val_mDice: 0.5802

Epoch 00058: val_mDice did not improve from 0.58852
Epoch 59/300
 - 10s - loss: 0.2905 - acc: 0.9472 - mDice: 0.7338 - val_loss: 0.6980 - val_acc: 0.9411 - val_mDice: 0.5807

Epoch 00059: val_mDice did not improve from 0.58852
Epoch 60/300
 - 11s - loss: 0.2879 - acc: 0.9475 - mDice: 0.7358 - val_loss: 0.6851 - val_acc: 0.9419 - val_mDice: 0.5819

Epoch 00060: val_mDice did not improve from 0.58852
Epoch 61/300
 - 10s - loss: 0.2866 - acc: 0.9476 - mDice: 0.7368 - val_loss: 0.6858 - val_acc: 0.9409 - val_mDice: 0.5840

Epoch 00061: val_mDice did not improve from 0.58852
Epoch 62/300
 - 11s - loss: 0.2834 - acc: 0.9478 - mDice: 0.7393 - val_loss: 0.6826 - val_acc: 0.9413 - val_mDice: 0.5810

Epoch 00062: val_mDice did not improve from 0.58852
Epoch 63/300
 - 10s - loss: 0.2830 - acc: 0.9479 - mDice: 0.7397 - val_loss: 0.6699 - val_acc: 0.9415 - val_mDice: 0.5846

Epoch 00063: val_mDice did not improve from 0.58852
Epoch 64/300
 - 11s - loss: 0.2819 - acc: 0.9480 - mDice: 0.7406 - val_loss: 0.6611 - val_acc: 0.9405 - val_mDice: 0.5815

Epoch 00064: val_mDice did not improve from 0.58852
Epoch 65/300
 - 11s - loss: 0.2795 - acc: 0.9482 - mDice: 0.7424 - val_loss: 0.6741 - val_acc: 0.9414 - val_mDice: 0.5826

Epoch 00065: val_mDice did not improve from 0.58852
Epoch 66/300
 - 11s - loss: 0.2788 - acc: 0.9483 - mDice: 0.7430 - val_loss: 0.6684 - val_acc: 0.9420 - val_mDice: 0.5851

Epoch 00066: val_mDice did not improve from 0.58852
Epoch 67/300
 - 11s - loss: 0.2784 - acc: 0.9483 - mDice: 0.7433 - val_loss: 0.6699 - val_acc: 0.9411 - val_mDice: 0.5854

Epoch 00067: val_mDice did not improve from 0.58852
Epoch 68/300
 - 11s - loss: 0.2773 - acc: 0.9484 - mDice: 0.7441 - val_loss: 0.6762 - val_acc: 0.9424 - val_mDice: 0.5788

Epoch 00068: val_mDice did not improve from 0.58852
Epoch 69/300
 - 10s - loss: 0.2779 - acc: 0.9484 - mDice: 0.7436 - val_loss: 0.6607 - val_acc: 0.9407 - val_mDice: 0.5818

Epoch 00069: val_mDice did not improve from 0.58852
Epoch 70/300
 - 11s - loss: 0.2802 - acc: 0.9483 - mDice: 0.7420 - val_loss: 0.6725 - val_acc: 0.9403 - val_mDice: 0.5806

Epoch 00070: val_mDice did not improve from 0.58852
Epoch 71/300
 - 10s - loss: 0.2749 - acc: 0.9486 - mDice: 0.7460 - val_loss: 0.6515 - val_acc: 0.9407 - val_mDice: 0.5828

Epoch 00071: val_mDice did not improve from 0.58852
Epoch 72/300
 - 11s - loss: 0.2740 - acc: 0.9486 - mDice: 0.7467 - val_loss: 0.6588 - val_acc: 0.9413 - val_mDice: 0.5813

Epoch 00072: val_mDice did not improve from 0.58852
Epoch 73/300
 - 10s - loss: 0.2751 - acc: 0.9486 - mDice: 0.7458 - val_loss: 0.6664 - val_acc: 0.9421 - val_mDice: 0.5811

Epoch 00073: val_mDice did not improve from 0.58852
Epoch 74/300
 - 11s - loss: 0.2720 - acc: 0.9488 - mDice: 0.7482 - val_loss: 0.6766 - val_acc: 0.9414 - val_mDice: 0.5768

Epoch 00074: val_mDice did not improve from 0.58852
Epoch 75/300
 - 10s - loss: 0.2723 - acc: 0.9487 - mDice: 0.7480 - val_loss: 0.6891 - val_acc: 0.9431 - val_mDice: 0.5609

Epoch 00075: val_mDice did not improve from 0.58852
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [1.4874851657794073, 1.0690923562416663, 0.8402657875647912, 0.7758597273093003, 0.7283511070104746, 0.7596599367948679, 0.7455433469552261, 0.7811777316606962, 0.775879864509289, 0.7768273101403163, 0.7919335640393771, 0.7976724299100729, 0.7889053775713994, 0.7904053972317622, 0.7926930051583511, 0.7743538973423151, 0.7885141487304981, 0.7898138303023118, 0.7946142691832322, 0.7824819936202123, 0.7836531538229722, 0.7784491559633842, 0.8010051663105304, 0.777235175554569, 0.7540697455406189, 0.7634899020195007, 0.776392767062554, 0.8168307176003089, 0.7516120339815433, 0.7503691579286869, 0.7804697786386197, 0.7646024353229083, 0.798398691874284, 0.7547237082169607, 0.7505847731461892, 0.75119776565295, 0.7506366750368705, 0.742416092982659, 0.7545937700913503, 0.7388196770961468, 0.75802404490801, 0.7464513297264392, 0.7385142273627795, 0.7406632292729157, 0.7553480508235785, 0.7270343154668808, 0.7366530620134794, 0.7108856989787176, 0.7131877839565277, 0.7306229036587936, 0.8757502001065475, 0.769497967683352, 0.7240478763213525, 0.7207484245300293, 0.7079992019213163, 0.6946826588649017, 0.7059944638839135, 0.6937106629976859, 0.6980029550882486, 0.6851156250788615, 0.6858446322954618, 0.6825724599453119, 0.6699109203540362, 0.6610546719569427, 0.6741234064102173, 0.6683949988621932, 0.669868738605426, 0.6762250799399155, 0.6606639405855765, 0.6725117759062693, 0.6515377026337844, 0.6588104516267776, 0.6664271778785266, 0.6766079159883353, 0.6891337816531842], 'val_acc': [0.9026766029688028, 0.9219882465325869, 0.9295395796115582, 0.9366725247639877, 0.940615747983639, 0.9392335667059972, 0.9432368622376368, 0.9414501900856311, 0.9435396561255822, 0.9416050475377303, 0.9399708692844098, 0.9426220517892104, 0.9423885826881115, 0.9410294936253474, 0.939406890135545, 0.9383552326605871, 0.9371116963716654, 0.940044818016199, 0.9408954404867612, 0.9420603903440329, 0.9395825335612664, 0.9424717930647043, 0.9424209548876836, 0.9431536724934211, 0.940946271786323, 0.9426243557379796, 0.9402390237037952, 0.9432692527770996, 0.9426104655632606, 0.9388891298037308, 0.9426151055556077, 0.9419887432685266, 0.9435350436430711, 0.9407336482634912, 0.9417784099395459, 0.9394184442666861, 0.9408168403001932, 0.9420488087030557, 0.9418015067393963, 0.937361343548848, 0.9420349575006045, 0.9417182871928582, 0.9429410054133489, 0.9403129540956937, 0.9389862349400153, 0.9427190927358774, 0.9416697460871476, 0.9400217326787802, 0.9401835478269137, 0.9411566119927627, 0.9395941083247845, 0.9318093772117908, 0.9362264092151935, 0.9402967553872329, 0.9414247136849624, 0.9436390652106359, 0.9400818325006045, 0.9403545627227197, 0.9410502933538877, 0.9419448031828954, 0.9409393553550427, 0.9412537125440744, 0.9414663383593926, 0.9404932787785163, 0.941433982207225, 0.9420210856657761, 0.941135803094277, 0.9424255582002493, 0.9407451657148508, 0.9402782848248115, 0.9407012646014874, 0.9412768299763019, 0.9420534509878892, 0.9413692767803485, 0.9430981759841626], 'val_mDice': [0.30261489605674374, 0.43374932500032276, 0.5305207824477782, 0.5546279492286535, 0.5746321718280132, 0.5697806517665203, 0.5736325841683608, 0.5719815263381371, 0.5763965019812951, 0.5685485291939515, 0.565131212083193, 0.5636232541157649, 0.5701825750561861, 0.5722334625629278, 0.5635103898552748, 0.5783245259752641, 0.5649023365515929, 0.5693771426494305, 0.569344797386573, 0.572356750185673, 0.5785030871629715, 0.5839489469161401, 0.562070234463765, 0.5779906230477186, 0.5759646560137088, 0.5744486250556432, 0.5763514592097356, 0.5549379724722642, 0.5792586310551717, 0.5793798262110124, 0.5798556162760808, 0.5791482191819411, 0.552493596306214, 0.5798378953566918, 0.5885244745474595, 0.58068865021834, 0.5809368330698746, 0.5800426808687357, 0.5849253369065431, 0.5720285807664578, 0.5794395483457125, 0.5763842199857419, 0.5776195170787665, 0.5836142817368875, 0.5800252298896129, 0.5864023692332782, 0.5834683082424678, 0.5777407059302697, 0.5831978481549484, 0.5752752480598596, 0.4968183728364798, 0.5655202693664111, 0.5767062673201928, 0.5708137807937769, 0.5779470050564179, 0.5823384047700808, 0.574120812691175, 0.580230139195919, 0.5806919290469243, 0.5818952041176649, 0.5840197228468381, 0.5810184054649793, 0.5845877648546145, 0.5814693019940302, 0.5826383244532806, 0.5850736326896228, 0.5853573611149421, 0.5788235377806884, 0.5817707822873042, 0.5806495203421667, 0.582791004043359, 0.5813078513512244, 0.5811445541106738, 0.5767684447077605, 0.5609134682095968], 'loss': [2.707354361727527, 0.7926330160503182, 0.5714153381255042, 0.5033021540392438, 0.46845051274356353, 0.4435820542561066, 0.4268050729063047, 0.4112001267084609, 0.3996369271610184, 0.391968538826444, 0.3798404938453657, 0.37222323694550596, 0.3676386218273056, 0.3605100963538526, 0.35853576592267533, 0.3510683557621768, 0.3471935113961875, 0.345912853257414, 0.339593322264096, 0.33542287240584245, 0.3333461855177531, 0.33229483315384634, 0.32659491708629806, 0.32406511733224774, 0.3218044494693156, 0.3211009025430807, 0.3175816666422477, 0.31384356859303547, 0.31397813263661106, 0.3105410006937259, 0.3078063529602861, 0.3067610363376258, 0.30548306209821385, 0.30433591947139527, 0.3023123855158971, 0.30011936296596964, 0.29939408426485764, 0.2976137586161295, 0.29722864764934864, 0.29307632469431694, 0.2942429338254184, 0.2923504786001936, 0.29125827225736833, 0.28882126946197734, 0.29031472392795954, 0.2883884091581969, 0.2868057471419748, 0.28691873071456014, 0.28292031386764266, 0.2824229343998622, 0.28647477008051225, 0.46803614267132704, 0.35221210810890347, 0.32426191764839635, 0.3113177977567624, 0.3028324968335726, 0.2981973990851593, 0.29363089061350683, 0.29054236097341535, 0.2879400120651789, 0.28664841779338407, 0.2834368252610188, 0.282966412096064, 0.28191809152134184, 0.27946827521702794, 0.27878279195581207, 0.27839968626232897, 0.27725941211020916, 0.27790400628002215, 0.2801961313943785, 0.2749017298078665, 0.27399696333705414, 0.27506802927619867, 0.2720192333384984, 0.272305980903311], 'acc': [0.4988381822250717, 0.903449382859381, 0.9141508981738046, 0.9198322736292344, 0.9243656846910322, 0.9278216969204995, 0.9310578999512312, 0.9336299239671132, 0.9353362072506899, 0.9367122054100037, 0.9380064857992246, 0.9388840464409741, 0.9395324168066296, 0.9404714311509403, 0.9408916111066312, 0.9414977509465526, 0.9418994389721073, 0.9422575435020119, 0.9426423002848334, 0.9430155490450255, 0.94331785051143, 0.9434977339376749, 0.9438926192828675, 0.9441571217021698, 0.9445282400704327, 0.9445266011048647, 0.9447498672190797, 0.9450438182413122, 0.9451916187789996, 0.9454803791783188, 0.9456636138555145, 0.9457529323034859, 0.945943587536325, 0.9460009633587766, 0.9462526553585049, 0.9463871365531085, 0.9464951474310606, 0.9465648025964158, 0.946621401848899, 0.9469720811451602, 0.9469736550200154, 0.9471240988310266, 0.9472895933233217, 0.9473883144630999, 0.9472702632726124, 0.947376786585082, 0.9476375435426162, 0.9476009879584552, 0.9478610364216385, 0.9479418015728509, 0.9478925813621979, 0.9313300107113167, 0.9419044472794575, 0.9443089858331023, 0.9455231891823553, 0.9462173414177575, 0.9465700812932586, 0.9469724986195444, 0.9471728262410528, 0.9475261854045804, 0.9476344595973061, 0.9478452289982893, 0.9478649823447716, 0.9480032975423229, 0.9482068368168892, 0.9482904816150973, 0.9483348007221059, 0.9483726203612028, 0.9483543970834876, 0.9483216990681798, 0.9486020091636962, 0.9486461085091545, 0.9486012598371677, 0.9488152133839097, 0.9487339416729241], 'mDice': [0.11401687958528994, 0.442996321509028, 0.5508655795507476, 0.5902995671786627, 0.6120245704503118, 0.6275699875522537, 0.6386101945491225, 0.6487524894224281, 0.6562317488191973, 0.6615602335212614, 0.6696306285103517, 0.6747661388625102, 0.6780143670025187, 0.6829455707012304, 0.6844604602986284, 0.6895455698525895, 0.6922894154682949, 0.6932083978695172, 0.6976079667097175, 0.700658367544943, 0.7022541322732757, 0.703084077505699, 0.7070291724183468, 0.7089033477433678, 0.7106280867864118, 0.7109892967606365, 0.7137134026680707, 0.7164122345240191, 0.716307267858612, 0.718948428886772, 0.7209376569582749, 0.7217006505959415, 0.7226601445365961, 0.7235693628691466, 0.7251124528295867, 0.7266527004460946, 0.7272737331081666, 0.7285811861128888, 0.7288739446079578, 0.7320133302249802, 0.7311658866124258, 0.7326116842679582, 0.7334288818022867, 0.735234522417134, 0.7342302300751259, 0.7355488172637727, 0.7368068953540221, 0.7367510521069979, 0.7398081746673514, 0.7401963998050385, 0.7395600213958781, 0.6153744291711709, 0.6883445051305026, 0.7084426749107704, 0.7180602860211073, 0.7244279190566744, 0.7279260799826087, 0.7314087203273933, 0.7337606679158579, 0.7358436144542774, 0.7368202582888087, 0.7392587325597815, 0.7396854129673579, 0.740572537375829, 0.7423780397010841, 0.7430314665888218, 0.7432971078839611, 0.7441176484346411, 0.7436493246205496, 0.7419819387685523, 0.7459665945971857, 0.746723541010243, 0.74584542663843, 0.7482130366377446, 0.7480203898028014]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.19s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.02s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:33,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:51,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:45,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:22,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:40,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:50,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:03,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:18,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:01,  1.76s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:48,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:54,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:07,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:07,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:44,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:58,  1.79s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:35,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:31,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:42,  1.75s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:23,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:37,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:24,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:48,  1.80s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<08:00,  1.85s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:35,  1.76s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:30,  1.75s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:31,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:45,  1.83s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:47,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:29,  1.78s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:25,  1.77s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:39,  1.83s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:46,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:49,  1.89s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:52,  1.91s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:18,  1.78s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:19,  1.79s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:05,  1.74s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:49,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<07:00,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:12,  1.80s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<06:59,  1.76s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<06:56,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:09,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:01,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:05,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<07:08,  1.85s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:11,  1.87s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<07:00,  1.83s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:57,  1.82s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:58,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:56,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:53,  1.83s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:54,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:34,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:29,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:27,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:16,  1.73s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:30,  1.81s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:26,  1.80s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:25,  1.80s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:10,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:19,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<06:23,  1.82s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<06:23,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<06:27,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<06:14,  1.80s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<06:12,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<06:07,  1.78s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:46,  1.70s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:50,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:27<05:38,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:30,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:46,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:51,  1.77s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:58,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:36<05:50,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:37<05:49,  1.78s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:51,  1.80s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<05:39,  1.75s/it]predicting train subjects:  32%|███▏      | 92/285 [02:43<05:42,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:44<05:35,  1.75s/it]predicting train subjects:  33%|███▎      | 94/285 [02:46<05:31,  1.74s/it]predicting train subjects:  33%|███▎      | 95/285 [02:48<05:41,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [02:50<05:37,  1.78s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<05:30,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<05:27,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<05:29,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [02:57<05:34,  1.81s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:18,  1.73s/it]predicting train subjects:  36%|███▌      | 102/285 [03:00<05:20,  1.75s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:07,  1.69s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:09,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:05<05:16,  1.76s/it]predicting train subjects:  37%|███▋      | 106/285 [03:07<05:07,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:09<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 108/285 [03:10<04:59,  1.69s/it]predicting train subjects:  38%|███▊      | 109/285 [03:12<05:00,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:14<04:58,  1.71s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<04:52,  1.68s/it]predicting train subjects:  39%|███▉      | 112/285 [03:17<04:55,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:19<05:02,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:21<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:23<05:04,  1.79s/it]predicting train subjects:  41%|████      | 116/285 [03:24<04:59,  1.77s/it]predicting train subjects:  41%|████      | 117/285 [03:26<04:44,  1.69s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:31,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:42,  1.70s/it]predicting train subjects:  42%|████▏     | 120/285 [03:31<04:40,  1.70s/it]predicting train subjects:  42%|████▏     | 121/285 [03:33<04:35,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:34<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:36<04:14,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:37<04:18,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:39<04:09,  1.56s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:02,  1.52s/it]predicting train subjects:  45%|████▍     | 127/285 [03:42<03:58,  1.51s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:45<03:57,  1.52s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<03:58,  1.54s/it]predicting train subjects:  46%|████▌     | 131/285 [03:48<03:55,  1.53s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<03:56,  1.55s/it]predicting train subjects:  47%|████▋     | 133/285 [03:51<03:56,  1.55s/it]predicting train subjects:  47%|████▋     | 134/285 [03:52<03:47,  1.51s/it]predicting train subjects:  47%|████▋     | 135/285 [03:54<03:45,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [03:55<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [03:57<03:48,  1.54s/it]predicting train subjects:  48%|████▊     | 138/285 [03:58<03:38,  1.48s/it]predicting train subjects:  49%|████▉     | 139/285 [04:00<03:43,  1.53s/it]predicting train subjects:  49%|████▉     | 140/285 [04:01<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [04:03<03:36,  1.50s/it]predicting train subjects:  50%|████▉     | 142/285 [04:04<03:35,  1.50s/it]predicting train subjects:  50%|█████     | 143/285 [04:06<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:07<03:36,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:09<03:33,  1.52s/it]predicting train subjects:  51%|█████     | 146/285 [04:11<03:36,  1.56s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:12<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:14<03:27,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:15<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:16<03:14,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:18<03:18,  1.48s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:19<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:21<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:24<03:22,  1.55s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:26<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:27<03:13,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:10,  1.50s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:30<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:32<03:15,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:33<03:15,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<03:12,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:36<03:06,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:38<03:03,  1.52s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:39<02:59,  1.49s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:41<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:43<03:08,  1.60s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:44<02:58,  1.53s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:45<02:54,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:47<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [04:48<02:47,  1.47s/it]predicting train subjects:  60%|██████    | 172/285 [04:50<02:46,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [04:51<02:43,  1.46s/it]predicting train subjects:  61%|██████    | 174/285 [04:53<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:54<02:44,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:56<02:49,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:57<02:46,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:59<02:38,  1.48s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:00<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:02<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:04<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:05<02:47,  1.63s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:07<02:37,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:08<02:36,  1.55s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:10<02:29,  1.49s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:11<02:37,  1.60s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:13<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:15<02:49,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:17<02:37,  1.64s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:18<02:31,  1.60s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:20<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:22<02:34,  1.66s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:23<02:25,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:24<02:19,  1.54s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:26<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:27<02:17,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:29<02:18,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:31<02:19,  1.61s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:32<02:10,  1.51s/it]predicting train subjects:  70%|███████   | 200/285 [05:33<02:06,  1.49s/it]predicting train subjects:  71%|███████   | 201/285 [05:35<02:12,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:37<02:12,  1.60s/it]predicting train subjects:  71%|███████   | 203/285 [05:39<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:40<02:06,  1.56s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:42<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:43<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:45<02:05,  1.61s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:47<02:09,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:49<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:50<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:51<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:53<01:55,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:55<01:56,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:56<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:58<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:59<01:49,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:01<01:53,  1.67s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:03<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:05<01:54,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:06<01:45,  1.62s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:08<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:09<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:11<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:12<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:14<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:15<01:34,  1.61s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:17<01:37,  1.69s/it]predicting train subjects:  80%|████████  | 228/285 [06:19<01:40,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:38,  1.76s/it]predicting train subjects:  81%|████████  | 230/285 [06:22<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:25,  1.58s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:25<01:24,  1.60s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:27<01:19,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:29<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:30<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:32<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:34<01:19,  1.66s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:35<01:19,  1.69s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:37<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:38<01:13,  1.62s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:40<01:11,  1.62s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:41<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:43<01:00,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:44<01:02,  1.52s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:46<00:58,  1.45s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:47<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:49<01:01,  1.61s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:51<01:00,  1.62s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:52<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:54<00:52,  1.49s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:55<00:50,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:56<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:58<00:50,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:00<00:51,  1.66s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:02<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:03<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:05<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [07:06<00:43,  1.59s/it]predicting train subjects:  91%|█████████ | 259/285 [07:08<00:42,  1.63s/it]predicting train subjects:  91%|█████████ | 260/285 [07:09<00:38,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:11<00:35,  1.50s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:12<00:34,  1.49s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:14<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:16<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:17<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:19<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:20<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:22<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:24<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:25<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:26<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:28<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:29<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:31<00:15,  1.45s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:32<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:34<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:36<00:12,  1.61s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:37<00:10,  1.56s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:39<00:09,  1.59s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:42<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:04,  1.50s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.62s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.70s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:07,  2.35s/it]Loading train:   1%|          | 2/285 [00:04<10:12,  2.16s/it]Loading train:   1%|          | 3/285 [00:05<09:40,  2.06s/it]Loading train:   1%|▏         | 4/285 [00:07<09:31,  2.04s/it]Loading train:   2%|▏         | 5/285 [00:09<09:18,  1.99s/it]Loading train:   2%|▏         | 6/285 [00:11<08:56,  1.92s/it]Loading train:   2%|▏         | 7/285 [00:13<08:59,  1.94s/it]Loading train:   3%|▎         | 8/285 [00:15<08:46,  1.90s/it]Loading train:   3%|▎         | 9/285 [00:17<09:17,  2.02s/it]Loading train:   4%|▎         | 10/285 [00:19<08:54,  1.94s/it]Loading train:   4%|▍         | 11/285 [00:21<08:27,  1.85s/it]Loading train:   4%|▍         | 12/285 [00:22<08:06,  1.78s/it]Loading train:   5%|▍         | 13/285 [00:23<07:26,  1.64s/it]Loading train:   5%|▍         | 14/285 [00:25<07:13,  1.60s/it]Loading train:   5%|▌         | 15/285 [00:27<07:24,  1.65s/it]Loading train:   6%|▌         | 16/285 [00:28<07:03,  1.57s/it]Loading train:   6%|▌         | 17/285 [00:29<06:35,  1.48s/it]Loading train:   6%|▋         | 18/285 [00:30<05:59,  1.35s/it]Loading train:   7%|▋         | 19/285 [00:32<06:11,  1.40s/it]Loading train:   7%|▋         | 20/285 [00:34<06:36,  1.50s/it]Loading train:   7%|▋         | 21/285 [00:35<06:42,  1.52s/it]Loading train:   8%|▊         | 22/285 [00:36<06:14,  1.43s/it]Loading train:   8%|▊         | 23/285 [00:38<06:37,  1.52s/it]Loading train:   8%|▊         | 24/285 [00:40<06:37,  1.52s/it]Loading train:   9%|▉         | 25/285 [00:41<06:35,  1.52s/it]Loading train:   9%|▉         | 26/285 [00:43<07:01,  1.63s/it]Loading train:   9%|▉         | 27/285 [00:44<06:13,  1.45s/it]Loading train:  10%|▉         | 28/285 [00:46<06:19,  1.48s/it]Loading train:  10%|█         | 29/285 [00:47<06:17,  1.48s/it]Loading train:  11%|█         | 30/285 [00:49<06:49,  1.60s/it]Loading train:  11%|█         | 31/285 [00:51<06:50,  1.62s/it]Loading train:  11%|█         | 32/285 [00:52<06:13,  1.48s/it]Loading train:  12%|█▏        | 33/285 [00:53<06:00,  1.43s/it]Loading train:  12%|█▏        | 34/285 [00:54<05:48,  1.39s/it]Loading train:  12%|█▏        | 35/285 [00:56<05:23,  1.29s/it]Loading train:  13%|█▎        | 36/285 [00:57<05:12,  1.26s/it]Loading train:  13%|█▎        | 37/285 [00:58<05:13,  1.27s/it]Loading train:  13%|█▎        | 38/285 [01:00<06:20,  1.54s/it]Loading train:  14%|█▎        | 39/285 [01:02<06:30,  1.59s/it]Loading train:  14%|█▍        | 40/285 [01:03<06:20,  1.55s/it]Loading train:  14%|█▍        | 41/285 [01:04<05:43,  1.41s/it]Loading train:  15%|█▍        | 42/285 [01:05<05:15,  1.30s/it]Loading train:  15%|█▌        | 43/285 [01:07<05:13,  1.30s/it]Loading train:  15%|█▌        | 44/285 [01:09<06:11,  1.54s/it]Loading train:  16%|█▌        | 45/285 [01:10<05:43,  1.43s/it]Loading train:  16%|█▌        | 46/285 [01:11<05:21,  1.35s/it]Loading train:  16%|█▋        | 47/285 [01:12<04:46,  1.20s/it]Loading train:  17%|█▋        | 48/285 [01:13<04:39,  1.18s/it]Loading train:  17%|█▋        | 49/285 [01:15<05:12,  1.33s/it]Loading train:  18%|█▊        | 50/285 [01:17<05:46,  1.47s/it]Loading train:  18%|█▊        | 51/285 [01:18<05:42,  1.46s/it]Loading train:  18%|█▊        | 52/285 [01:20<05:37,  1.45s/it]Loading train:  19%|█▊        | 53/285 [01:22<06:20,  1.64s/it]Loading train:  19%|█▉        | 54/285 [01:23<06:24,  1.66s/it]Loading train:  19%|█▉        | 55/285 [01:25<06:06,  1.59s/it]Loading train:  20%|█▉        | 56/285 [01:26<05:35,  1.46s/it]Loading train:  20%|██        | 57/285 [01:27<05:09,  1.36s/it]Loading train:  20%|██        | 58/285 [01:28<05:03,  1.34s/it]Loading train:  21%|██        | 59/285 [01:30<05:12,  1.38s/it]Loading train:  21%|██        | 60/285 [01:32<05:59,  1.60s/it]Loading train:  21%|██▏       | 61/285 [01:33<05:34,  1.49s/it]Loading train:  22%|██▏       | 62/285 [01:35<05:33,  1.49s/it]Loading train:  22%|██▏       | 63/285 [01:37<05:58,  1.62s/it]Loading train:  22%|██▏       | 64/285 [01:39<06:30,  1.77s/it]Loading train:  23%|██▎       | 65/285 [01:41<06:56,  1.90s/it]Loading train:  23%|██▎       | 66/285 [01:43<07:14,  1.98s/it]Loading train:  24%|██▎       | 67/285 [01:45<07:09,  1.97s/it]Loading train:  24%|██▍       | 68/285 [01:47<06:43,  1.86s/it]Loading train:  24%|██▍       | 69/285 [01:48<06:24,  1.78s/it]Loading train:  25%|██▍       | 70/285 [01:50<06:45,  1.89s/it]Loading train:  25%|██▍       | 71/285 [01:53<07:15,  2.03s/it]Loading train:  25%|██▌       | 72/285 [01:54<06:54,  1.95s/it]Loading train:  26%|██▌       | 73/285 [01:56<06:13,  1.76s/it]Loading train:  26%|██▌       | 74/285 [01:57<05:40,  1.61s/it]Loading train:  26%|██▋       | 75/285 [01:59<05:32,  1.59s/it]Loading train:  27%|██▋       | 76/285 [02:00<05:39,  1.62s/it]Loading train:  27%|██▋       | 77/285 [02:02<05:37,  1.62s/it]Loading train:  27%|██▋       | 78/285 [02:03<05:03,  1.47s/it]Loading train:  28%|██▊       | 79/285 [02:05<05:05,  1.48s/it]Loading train:  28%|██▊       | 80/285 [02:06<05:11,  1.52s/it]Loading train:  28%|██▊       | 81/285 [02:07<04:59,  1.47s/it]Loading train:  29%|██▉       | 82/285 [02:09<05:14,  1.55s/it]Loading train:  29%|██▉       | 83/285 [02:11<05:09,  1.53s/it]Loading train:  29%|██▉       | 84/285 [02:12<05:04,  1.52s/it]Loading train:  30%|██▉       | 85/285 [02:14<05:11,  1.56s/it]Loading train:  30%|███       | 86/285 [02:16<05:22,  1.62s/it]Loading train:  31%|███       | 87/285 [02:17<05:16,  1.60s/it]Loading train:  31%|███       | 88/285 [02:18<04:59,  1.52s/it]Loading train:  31%|███       | 89/285 [02:20<05:07,  1.57s/it]Loading train:  32%|███▏      | 90/285 [02:21<04:46,  1.47s/it]Loading train:  32%|███▏      | 91/285 [02:23<04:23,  1.36s/it]Loading train:  32%|███▏      | 92/285 [02:24<04:12,  1.31s/it]Loading train:  33%|███▎      | 93/285 [02:25<03:47,  1.18s/it]Loading train:  33%|███▎      | 94/285 [02:26<03:53,  1.22s/it]Loading train:  33%|███▎      | 95/285 [02:28<04:35,  1.45s/it]Loading train:  34%|███▎      | 96/285 [02:29<04:36,  1.46s/it]Loading train:  34%|███▍      | 97/285 [02:31<04:37,  1.47s/it]Loading train:  34%|███▍      | 98/285 [02:33<04:53,  1.57s/it]Loading train:  35%|███▍      | 99/285 [02:34<04:41,  1.51s/it]Loading train:  35%|███▌      | 100/285 [02:36<04:47,  1.55s/it]Loading train:  35%|███▌      | 101/285 [02:37<04:54,  1.60s/it]Loading train:  36%|███▌      | 102/285 [02:39<05:01,  1.65s/it]Loading train:  36%|███▌      | 103/285 [02:41<04:51,  1.60s/it]Loading train:  36%|███▋      | 104/285 [02:42<04:52,  1.61s/it]Loading train:  37%|███▋      | 105/285 [02:44<04:58,  1.66s/it]Loading train:  37%|███▋      | 106/285 [02:46<04:47,  1.61s/it]Loading train:  38%|███▊      | 107/285 [02:47<04:35,  1.55s/it]Loading train:  38%|███▊      | 108/285 [02:48<04:33,  1.54s/it]Loading train:  38%|███▊      | 109/285 [02:50<04:22,  1.49s/it]Loading train:  39%|███▊      | 110/285 [02:51<04:24,  1.51s/it]Loading train:  39%|███▉      | 111/285 [02:53<04:31,  1.56s/it]Loading train:  39%|███▉      | 112/285 [02:55<04:26,  1.54s/it]Loading train:  40%|███▉      | 113/285 [02:56<04:40,  1.63s/it]Loading train:  40%|████      | 114/285 [02:58<04:34,  1.60s/it]Loading train:  40%|████      | 115/285 [03:00<04:52,  1.72s/it]Loading train:  41%|████      | 116/285 [03:02<04:55,  1.75s/it]Loading train:  41%|████      | 117/285 [03:03<04:32,  1.62s/it]Loading train:  41%|████▏     | 118/285 [03:05<04:46,  1.71s/it]Loading train:  42%|████▏     | 119/285 [03:07<04:50,  1.75s/it]Loading train:  42%|████▏     | 120/285 [03:09<04:50,  1.76s/it]Loading train:  42%|████▏     | 121/285 [03:10<04:41,  1.71s/it]Loading train:  43%|████▎     | 122/285 [03:12<04:26,  1.64s/it]Loading train:  43%|████▎     | 123/285 [03:13<04:24,  1.63s/it]Loading train:  44%|████▎     | 124/285 [03:15<04:15,  1.59s/it]Loading train:  44%|████▍     | 125/285 [03:16<03:58,  1.49s/it]Loading train:  44%|████▍     | 126/285 [03:18<04:01,  1.52s/it]Loading train:  45%|████▍     | 127/285 [03:19<03:52,  1.47s/it]Loading train:  45%|████▍     | 128/285 [03:20<03:29,  1.34s/it]Loading train:  45%|████▌     | 129/285 [03:21<03:20,  1.28s/it]Loading train:  46%|████▌     | 130/285 [03:22<03:01,  1.17s/it]Loading train:  46%|████▌     | 131/285 [03:24<03:31,  1.37s/it]Loading train:  46%|████▋     | 132/285 [03:26<03:49,  1.50s/it]Loading train:  47%|████▋     | 133/285 [03:28<04:07,  1.63s/it]Loading train:  47%|████▋     | 134/285 [03:29<04:00,  1.59s/it]Loading train:  47%|████▋     | 135/285 [03:30<03:40,  1.47s/it]Loading train:  48%|████▊     | 136/285 [03:32<03:26,  1.39s/it]Loading train:  48%|████▊     | 137/285 [03:33<03:31,  1.43s/it]Loading train:  48%|████▊     | 138/285 [03:34<03:14,  1.32s/it]Loading train:  49%|████▉     | 139/285 [03:35<03:05,  1.27s/it]Loading train:  49%|████▉     | 140/285 [03:36<02:55,  1.21s/it]Loading train:  49%|████▉     | 141/285 [03:37<02:44,  1.14s/it]Loading train:  50%|████▉     | 142/285 [03:39<03:10,  1.33s/it]Loading train:  50%|█████     | 143/285 [03:41<03:10,  1.34s/it]Loading train:  51%|█████     | 144/285 [03:42<03:19,  1.42s/it]Loading train:  51%|█████     | 145/285 [03:43<03:07,  1.34s/it]Loading train:  51%|█████     | 146/285 [03:45<03:10,  1.37s/it]Loading train:  52%|█████▏    | 147/285 [03:46<03:13,  1.41s/it]Loading train:  52%|█████▏    | 148/285 [03:48<03:13,  1.41s/it]Loading train:  52%|█████▏    | 149/285 [03:49<02:59,  1.32s/it]Loading train:  53%|█████▎    | 150/285 [03:50<03:00,  1.34s/it]Loading train:  53%|█████▎    | 151/285 [03:51<02:57,  1.32s/it]Loading train:  53%|█████▎    | 152/285 [03:53<03:08,  1.42s/it]Loading train:  54%|█████▎    | 153/285 [03:54<02:59,  1.36s/it]Loading train:  54%|█████▍    | 154/285 [03:57<03:34,  1.64s/it]Loading train:  54%|█████▍    | 155/285 [03:58<03:22,  1.56s/it]Loading train:  55%|█████▍    | 156/285 [03:59<03:19,  1.55s/it]Loading train:  55%|█████▌    | 157/285 [04:01<03:15,  1.53s/it]Loading train:  55%|█████▌    | 158/285 [04:02<03:09,  1.49s/it]Loading train:  56%|█████▌    | 159/285 [04:04<03:13,  1.54s/it]Loading train:  56%|█████▌    | 160/285 [04:06<03:11,  1.53s/it]Loading train:  56%|█████▋    | 161/285 [04:07<03:14,  1.57s/it]Loading train:  57%|█████▋    | 162/285 [04:09<03:05,  1.50s/it]Loading train:  57%|█████▋    | 163/285 [04:10<02:58,  1.46s/it]Loading train:  58%|█████▊    | 164/285 [04:12<03:16,  1.63s/it]Loading train:  58%|█████▊    | 165/285 [04:13<03:01,  1.52s/it]Loading train:  58%|█████▊    | 166/285 [04:14<02:45,  1.39s/it]Loading train:  59%|█████▊    | 167/285 [04:15<02:32,  1.29s/it]Loading train:  59%|█████▉    | 168/285 [04:16<02:20,  1.21s/it]Loading train:  59%|█████▉    | 169/285 [04:17<02:19,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [04:18<02:09,  1.12s/it]Loading train:  60%|██████    | 171/285 [04:20<02:18,  1.21s/it]Loading train:  60%|██████    | 172/285 [04:21<02:29,  1.32s/it]Loading train:  61%|██████    | 173/285 [04:23<02:28,  1.32s/it]Loading train:  61%|██████    | 174/285 [04:24<02:33,  1.38s/it]Loading train:  61%|██████▏   | 175/285 [04:26<02:26,  1.34s/it]Loading train:  62%|██████▏   | 176/285 [04:27<02:35,  1.43s/it]Loading train:  62%|██████▏   | 177/285 [04:29<02:38,  1.47s/it]Loading train:  62%|██████▏   | 178/285 [04:30<02:46,  1.55s/it]Loading train:  63%|██████▎   | 179/285 [04:32<02:33,  1.45s/it]Loading train:  63%|██████▎   | 180/285 [04:33<02:37,  1.50s/it]Loading train:  64%|██████▎   | 181/285 [04:35<02:33,  1.48s/it]Loading train:  64%|██████▍   | 182/285 [04:36<02:27,  1.44s/it]Loading train:  64%|██████▍   | 183/285 [04:37<02:20,  1.38s/it]Loading train:  65%|██████▍   | 184/285 [04:39<02:18,  1.38s/it]Loading train:  65%|██████▍   | 185/285 [04:40<02:24,  1.44s/it]Loading train:  65%|██████▌   | 186/285 [04:42<02:37,  1.59s/it]Loading train:  66%|██████▌   | 187/285 [04:44<02:44,  1.68s/it]Loading train:  66%|██████▌   | 188/285 [04:46<02:51,  1.77s/it]Loading train:  66%|██████▋   | 189/285 [04:48<02:40,  1.68s/it]Loading train:  67%|██████▋   | 190/285 [04:49<02:25,  1.53s/it]Loading train:  67%|██████▋   | 191/285 [04:51<02:36,  1.66s/it]Loading train:  67%|██████▋   | 192/285 [04:52<02:30,  1.61s/it]Loading train:  68%|██████▊   | 193/285 [04:54<02:31,  1.64s/it]Loading train:  68%|██████▊   | 194/285 [04:56<02:33,  1.68s/it]Loading train:  68%|██████▊   | 195/285 [04:57<02:18,  1.54s/it]Loading train:  69%|██████▉   | 196/285 [04:59<02:34,  1.73s/it]Loading train:  69%|██████▉   | 197/285 [05:01<02:32,  1.74s/it]Loading train:  69%|██████▉   | 198/285 [05:03<02:30,  1.73s/it]Loading train:  70%|██████▉   | 199/285 [05:04<02:11,  1.53s/it]Loading train:  70%|███████   | 200/285 [05:05<02:06,  1.49s/it]Loading train:  71%|███████   | 201/285 [05:06<02:03,  1.47s/it]Loading train:  71%|███████   | 202/285 [05:08<01:54,  1.38s/it]Loading train:  71%|███████   | 203/285 [05:09<01:52,  1.37s/it]Loading train:  72%|███████▏  | 204/285 [05:10<01:50,  1.36s/it]Loading train:  72%|███████▏  | 205/285 [05:12<01:51,  1.39s/it]Loading train:  72%|███████▏  | 206/285 [05:13<01:48,  1.37s/it]Loading train:  73%|███████▎  | 207/285 [05:15<02:03,  1.58s/it]Loading train:  73%|███████▎  | 208/285 [05:17<02:18,  1.80s/it]Loading train:  73%|███████▎  | 209/285 [05:20<02:28,  1.95s/it]Loading train:  74%|███████▎  | 210/285 [05:21<02:21,  1.89s/it]Loading train:  74%|███████▍  | 211/285 [05:23<02:11,  1.78s/it]Loading train:  74%|███████▍  | 212/285 [05:25<02:10,  1.79s/it]Loading train:  75%|███████▍  | 213/285 [05:26<02:00,  1.67s/it]Loading train:  75%|███████▌  | 214/285 [05:28<01:53,  1.60s/it]Loading train:  75%|███████▌  | 215/285 [05:30<02:02,  1.75s/it]Loading train:  76%|███████▌  | 216/285 [05:31<01:49,  1.59s/it]Loading train:  76%|███████▌  | 217/285 [05:33<01:49,  1.61s/it]Loading train:  76%|███████▋  | 218/285 [05:34<01:53,  1.69s/it]Loading train:  77%|███████▋  | 219/285 [05:36<01:55,  1.74s/it]Loading train:  77%|███████▋  | 220/285 [05:38<01:53,  1.74s/it]Loading train:  78%|███████▊  | 221/285 [05:40<01:52,  1.76s/it]Loading train:  78%|███████▊  | 222/285 [05:41<01:42,  1.62s/it]Loading train:  78%|███████▊  | 223/285 [05:42<01:34,  1.52s/it]Loading train:  79%|███████▊  | 224/285 [05:44<01:31,  1.50s/it]Loading train:  79%|███████▉  | 225/285 [05:45<01:17,  1.29s/it]Loading train:  79%|███████▉  | 226/285 [05:46<01:20,  1.36s/it]Loading train:  80%|███████▉  | 227/285 [05:48<01:23,  1.43s/it]Loading train:  80%|████████  | 228/285 [05:49<01:21,  1.42s/it]Loading train:  80%|████████  | 229/285 [05:51<01:27,  1.57s/it]Loading train:  81%|████████  | 230/285 [05:53<01:25,  1.56s/it]Loading train:  81%|████████  | 231/285 [05:54<01:23,  1.54s/it]Loading train:  81%|████████▏ | 232/285 [05:55<01:16,  1.44s/it]Loading train:  82%|████████▏ | 233/285 [05:57<01:16,  1.47s/it]Loading train:  82%|████████▏ | 234/285 [05:58<01:13,  1.43s/it]Loading train:  82%|████████▏ | 235/285 [05:59<01:06,  1.32s/it]Loading train:  83%|████████▎ | 236/285 [06:01<01:04,  1.31s/it]Loading train:  83%|████████▎ | 237/285 [06:02<01:00,  1.27s/it]Loading train:  84%|████████▎ | 238/285 [06:03<01:00,  1.29s/it]Loading train:  84%|████████▍ | 239/285 [06:05<01:07,  1.46s/it]Loading train:  84%|████████▍ | 240/285 [06:06<01:00,  1.34s/it]Loading train:  85%|████████▍ | 241/285 [06:08<01:05,  1.50s/it]Loading train:  85%|████████▍ | 242/285 [06:10<01:07,  1.57s/it]Loading train:  85%|████████▌ | 243/285 [06:12<01:13,  1.75s/it]Loading train:  86%|████████▌ | 244/285 [06:14<01:13,  1.79s/it]Loading train:  86%|████████▌ | 245/285 [06:15<01:01,  1.53s/it]Loading train:  86%|████████▋ | 246/285 [06:16<00:58,  1.51s/it]Loading train:  87%|████████▋ | 247/285 [06:18<00:59,  1.56s/it]Loading train:  87%|████████▋ | 248/285 [06:19<00:55,  1.50s/it]Loading train:  87%|████████▋ | 249/285 [06:20<00:50,  1.41s/it]Loading train:  88%|████████▊ | 250/285 [06:22<00:52,  1.50s/it]Loading train:  88%|████████▊ | 251/285 [06:24<00:51,  1.50s/it]Loading train:  88%|████████▊ | 252/285 [06:25<00:46,  1.40s/it]Loading train:  89%|████████▉ | 253/285 [06:26<00:47,  1.49s/it]Loading train:  89%|████████▉ | 254/285 [06:28<00:47,  1.55s/it]Loading train:  89%|████████▉ | 255/285 [06:30<00:50,  1.69s/it]Loading train:  90%|████████▉ | 256/285 [06:32<00:47,  1.64s/it]Loading train:  90%|█████████ | 257/285 [06:33<00:46,  1.66s/it]Loading train:  91%|█████████ | 258/285 [06:35<00:46,  1.72s/it]Loading train:  91%|█████████ | 259/285 [06:37<00:43,  1.67s/it]Loading train:  91%|█████████ | 260/285 [06:38<00:38,  1.54s/it]Loading train:  92%|█████████▏| 261/285 [06:39<00:36,  1.50s/it]Loading train:  92%|█████████▏| 262/285 [06:41<00:33,  1.48s/it]Loading train:  92%|█████████▏| 263/285 [06:42<00:31,  1.45s/it]Loading train:  93%|█████████▎| 264/285 [06:44<00:32,  1.54s/it]Loading train:  93%|█████████▎| 265/285 [06:46<00:31,  1.60s/it]Loading train:  93%|█████████▎| 266/285 [06:47<00:26,  1.40s/it]Loading train:  94%|█████████▎| 267/285 [06:48<00:25,  1.42s/it]Loading train:  94%|█████████▍| 268/285 [06:50<00:25,  1.51s/it]Loading train:  94%|█████████▍| 269/285 [06:51<00:23,  1.47s/it]Loading train:  95%|█████████▍| 270/285 [06:52<00:21,  1.40s/it]Loading train:  95%|█████████▌| 271/285 [06:54<00:19,  1.39s/it]Loading train:  95%|█████████▌| 272/285 [06:55<00:17,  1.36s/it]Loading train:  96%|█████████▌| 273/285 [06:57<00:17,  1.43s/it]Loading train:  96%|█████████▌| 274/285 [06:58<00:14,  1.35s/it]Loading train:  96%|█████████▋| 275/285 [07:00<00:14,  1.49s/it]Loading train:  97%|█████████▋| 276/285 [07:02<00:14,  1.65s/it]Loading train:  97%|█████████▋| 277/285 [07:03<00:11,  1.44s/it]Loading train:  98%|█████████▊| 278/285 [07:04<00:10,  1.44s/it]Loading train:  98%|█████████▊| 279/285 [07:05<00:08,  1.42s/it]Loading train:  98%|█████████▊| 280/285 [07:07<00:06,  1.33s/it]Loading train:  99%|█████████▊| 281/285 [07:08<00:05,  1.44s/it]Loading train:  99%|█████████▉| 282/285 [07:10<00:04,  1.61s/it]Loading train:  99%|█████████▉| 283/285 [07:12<00:03,  1.59s/it]Loading train: 100%|█████████▉| 284/285 [07:13<00:01,  1.56s/it]Loading train: 100%|██████████| 285/285 [07:15<00:00,  1.57s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:08, 34.47it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:07, 36.35it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:06, 41.27it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:05, 45.24it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:05, 45.06it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:05, 49.18it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:04, 52.54it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:04, 55.18it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:04, 57.19it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:03, 66.93it/s]concatenating: train:  27%|██▋       | 76/285 [00:01<00:03, 64.90it/s]concatenating: train:  29%|██▉       | 83/285 [00:01<00:03, 64.16it/s]concatenating: train:  33%|███▎      | 95/285 [00:01<00:02, 73.96it/s]concatenating: train:  38%|███▊      | 108/285 [00:01<00:02, 84.29it/s]concatenating: train:  42%|████▏     | 121/285 [00:01<00:01, 93.42it/s]concatenating: train:  47%|████▋     | 133/285 [00:01<00:01, 99.36it/s]concatenating: train:  51%|█████     | 146/285 [00:01<00:01, 106.61it/s]concatenating: train:  55%|█████▌    | 158/285 [00:02<00:02, 56.35it/s] concatenating: train:  60%|██████    | 171/285 [00:02<00:01, 67.39it/s]concatenating: train:  65%|██████▍   | 185/285 [00:02<00:01, 78.73it/s]concatenating: train:  69%|██████▉   | 198/285 [00:02<00:00, 88.56it/s]concatenating: train:  74%|███████▎  | 210/285 [00:02<00:00, 95.20it/s]concatenating: train:  78%|███████▊  | 223/285 [00:02<00:00, 101.65it/s]concatenating: train:  82%|████████▏ | 235/285 [00:03<00:00, 89.41it/s] concatenating: train:  86%|████████▋ | 246/285 [00:03<00:00, 58.62it/s]concatenating: train:  89%|████████▉ | 255/285 [00:03<00:00, 62.01it/s]concatenating: train:  94%|█████████▍| 268/285 [00:03<00:00, 73.06it/s]concatenating: train:  98%|█████████▊| 278/285 [00:03<00:00, 74.51it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 73.98it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.86s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 36.82it/s]2019-07-11 03:36:53.510142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:36:53.510257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:36:53.510278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:36:53.510291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:36:53.510805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.39it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.62it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.33it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.62it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  3.93it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:07,  4.67it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  4.83it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.41it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:04,  5.77it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  5.21it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.75it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.43it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:02,  7.19it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.83it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.54it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.57it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:00,  6.00it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.31it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.25it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.50it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 20)   8120        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 65)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   858         concatenate_8[0][0]              
==================================================================================================
Total params: 137,918
Trainable params: 39,378
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 2.8896 - acc: 0.5704 - mDice: 0.0953 - val_loss: 2.9922 - val_acc: 0.9044 - val_mDice: 0.1063

Epoch 00001: val_mDice improved from -inf to 0.10625, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.2431 - acc: 0.8729 - mDice: 0.2932 - val_loss: 1.7689 - val_acc: 0.9082 - val_mDice: 0.3086

Epoch 00002: val_mDice improved from 0.10625 to 0.30856, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8431 - acc: 0.8764 - mDice: 0.4163 - val_loss: 1.8214 - val_acc: 0.9095 - val_mDice: 0.3070

Epoch 00003: val_mDice did not improve from 0.30856
Epoch 4/300
 - 9s - loss: 0.7031 - acc: 0.8790 - mDice: 0.4784 - val_loss: 1.4481 - val_acc: 0.9093 - val_mDice: 0.3904

Epoch 00004: val_mDice improved from 0.30856 to 0.39044, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6290 - acc: 0.8817 - mDice: 0.5165 - val_loss: 1.1161 - val_acc: 0.9140 - val_mDice: 0.4971

Epoch 00005: val_mDice improved from 0.39044 to 0.49713, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5774 - acc: 0.8848 - mDice: 0.5453 - val_loss: 1.0497 - val_acc: 0.9173 - val_mDice: 0.5220

Epoch 00006: val_mDice improved from 0.49713 to 0.52197, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5317 - acc: 0.8884 - mDice: 0.5723 - val_loss: 1.0367 - val_acc: 0.9197 - val_mDice: 0.5234

Epoch 00007: val_mDice improved from 0.52197 to 0.52340, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.5038 - acc: 0.8921 - mDice: 0.5896 - val_loss: 1.0508 - val_acc: 0.9254 - val_mDice: 0.5134

Epoch 00008: val_mDice did not improve from 0.52340
Epoch 9/300
 - 9s - loss: 0.4786 - acc: 0.8958 - mDice: 0.6054 - val_loss: 0.9909 - val_acc: 0.9294 - val_mDice: 0.5375

Epoch 00009: val_mDice improved from 0.52340 to 0.53752, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.4612 - acc: 0.8990 - mDice: 0.6165 - val_loss: 0.9809 - val_acc: 0.9283 - val_mDice: 0.5401

Epoch 00010: val_mDice improved from 0.53752 to 0.54008, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4500 - acc: 0.9014 - mDice: 0.6238 - val_loss: 0.9599 - val_acc: 0.9330 - val_mDice: 0.5617

Epoch 00011: val_mDice improved from 0.54008 to 0.56171, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4369 - acc: 0.9033 - mDice: 0.6325 - val_loss: 0.9696 - val_acc: 0.9301 - val_mDice: 0.5460

Epoch 00012: val_mDice did not improve from 0.56171
Epoch 13/300
 - 9s - loss: 0.4272 - acc: 0.9056 - mDice: 0.6390 - val_loss: 0.9276 - val_acc: 0.9314 - val_mDice: 0.5600

Epoch 00013: val_mDice did not improve from 0.56171
Epoch 14/300
 - 9s - loss: 0.4188 - acc: 0.9075 - mDice: 0.6446 - val_loss: 0.9251 - val_acc: 0.9339 - val_mDice: 0.5619

Epoch 00014: val_mDice improved from 0.56171 to 0.56195, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 9s - loss: 0.4111 - acc: 0.9096 - mDice: 0.6496 - val_loss: 0.9153 - val_acc: 0.9357 - val_mDice: 0.5615

Epoch 00015: val_mDice did not improve from 0.56195
Epoch 16/300
 - 9s - loss: 0.4061 - acc: 0.9119 - mDice: 0.6531 - val_loss: 0.9324 - val_acc: 0.9400 - val_mDice: 0.5565

Epoch 00016: val_mDice did not improve from 0.56195
Epoch 17/300
 - 9s - loss: 0.3982 - acc: 0.9149 - mDice: 0.6582 - val_loss: 0.9501 - val_acc: 0.9407 - val_mDice: 0.5446

Epoch 00017: val_mDice did not improve from 0.56195
Epoch 18/300
 - 9s - loss: 0.3940 - acc: 0.9199 - mDice: 0.6611 - val_loss: 0.9058 - val_acc: 0.9458 - val_mDice: 0.5694

Epoch 00018: val_mDice improved from 0.56195 to 0.56937, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 9s - loss: 0.3903 - acc: 0.9280 - mDice: 0.6632 - val_loss: 0.8871 - val_acc: 0.9467 - val_mDice: 0.5793

Epoch 00019: val_mDice improved from 0.56937 to 0.57929, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.3842 - acc: 0.9328 - mDice: 0.6670 - val_loss: 0.8750 - val_acc: 0.9464 - val_mDice: 0.5799

Epoch 00020: val_mDice improved from 0.57929 to 0.57993, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 10s - loss: 0.3805 - acc: 0.9338 - mDice: 0.6694 - val_loss: 0.8772 - val_acc: 0.9464 - val_mDice: 0.5777

Epoch 00021: val_mDice did not improve from 0.57993
Epoch 22/300
 - 9s - loss: 0.3746 - acc: 0.9346 - mDice: 0.6732 - val_loss: 0.8891 - val_acc: 0.9419 - val_mDice: 0.5671

Epoch 00022: val_mDice did not improve from 0.57993
Epoch 23/300
 - 10s - loss: 0.3731 - acc: 0.9350 - mDice: 0.6742 - val_loss: 0.8709 - val_acc: 0.9454 - val_mDice: 0.5816

Epoch 00023: val_mDice improved from 0.57993 to 0.58163, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 9s - loss: 0.3702 - acc: 0.9353 - mDice: 0.6762 - val_loss: 0.8534 - val_acc: 0.9450 - val_mDice: 0.5808

Epoch 00024: val_mDice did not improve from 0.58163
Epoch 25/300
 - 10s - loss: 0.3657 - acc: 0.9358 - mDice: 0.6793 - val_loss: 0.8515 - val_acc: 0.9436 - val_mDice: 0.5753

Epoch 00025: val_mDice did not improve from 0.58163
Epoch 26/300
 - 9s - loss: 0.3638 - acc: 0.9359 - mDice: 0.6805 - val_loss: 0.8827 - val_acc: 0.9385 - val_mDice: 0.5777

Epoch 00026: val_mDice did not improve from 0.58163
Epoch 27/300
 - 10s - loss: 0.3586 - acc: 0.9364 - mDice: 0.6842 - val_loss: 0.8623 - val_acc: 0.9441 - val_mDice: 0.5777

Epoch 00027: val_mDice did not improve from 0.58163
Epoch 28/300
 - 9s - loss: 0.3574 - acc: 0.9367 - mDice: 0.6850 - val_loss: 0.8594 - val_acc: 0.9402 - val_mDice: 0.5810

Epoch 00028: val_mDice did not improve from 0.58163
Epoch 29/300
 - 9s - loss: 0.3552 - acc: 0.9368 - mDice: 0.6865 - val_loss: 0.8552 - val_acc: 0.9460 - val_mDice: 0.5743

Epoch 00029: val_mDice did not improve from 0.58163
Epoch 30/300
 - 9s - loss: 0.3525 - acc: 0.9373 - mDice: 0.6885 - val_loss: 0.8453 - val_acc: 0.9453 - val_mDice: 0.5608

Epoch 00030: val_mDice did not improve from 0.58163
Epoch 31/300
 - 9s - loss: 0.3492 - acc: 0.9374 - mDice: 0.6909 - val_loss: 0.8235 - val_acc: 0.9457 - val_mDice: 0.5698

Epoch 00031: val_mDice did not improve from 0.58163
Epoch 32/300
 - 9s - loss: 0.3466 - acc: 0.9378 - mDice: 0.6925 - val_loss: 0.8198 - val_acc: 0.9444 - val_mDice: 0.5828

Epoch 00032: val_mDice improved from 0.58163 to 0.58277, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 9s - loss: 0.3465 - acc: 0.9378 - mDice: 0.6928 - val_loss: 0.8411 - val_acc: 0.9403 - val_mDice: 0.5830

Epoch 00033: val_mDice improved from 0.58277 to 0.58302, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 9s - loss: 0.3425 - acc: 0.9382 - mDice: 0.6956 - val_loss: 0.8062 - val_acc: 0.9462 - val_mDice: 0.5752

Epoch 00034: val_mDice did not improve from 0.58302
Epoch 35/300
 - 9s - loss: 0.3403 - acc: 0.9383 - mDice: 0.6972 - val_loss: 0.8401 - val_acc: 0.9415 - val_mDice: 0.5736

Epoch 00035: val_mDice did not improve from 0.58302
Epoch 36/300
 - 10s - loss: 0.3373 - acc: 0.9388 - mDice: 0.6993 - val_loss: 0.8156 - val_acc: 0.9462 - val_mDice: 0.5677

Epoch 00036: val_mDice did not improve from 0.58302
Epoch 37/300
 - 9s - loss: 0.3387 - acc: 0.9387 - mDice: 0.6983 - val_loss: 0.8343 - val_acc: 0.9435 - val_mDice: 0.5738

Epoch 00037: val_mDice did not improve from 0.58302
Epoch 38/300
 - 9s - loss: 0.3358 - acc: 0.9390 - mDice: 0.7003 - val_loss: 0.7823 - val_acc: 0.9478 - val_mDice: 0.5863

Epoch 00038: val_mDice improved from 0.58302 to 0.58630, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 9s - loss: 0.3359 - acc: 0.9392 - mDice: 0.7004 - val_loss: 0.8015 - val_acc: 0.9439 - val_mDice: 0.5818

Epoch 00039: val_mDice did not improve from 0.58630
Epoch 40/300
 - 9s - loss: 0.3333 - acc: 0.9394 - mDice: 0.7023 - val_loss: 0.7648 - val_acc: 0.9436 - val_mDice: 0.5856

Epoch 00040: val_mDice did not improve from 0.58630
Epoch 41/300
 - 9s - loss: 0.3299 - acc: 0.9397 - mDice: 0.7048 - val_loss: 0.8082 - val_acc: 0.9442 - val_mDice: 0.5770

Epoch 00041: val_mDice did not improve from 0.58630
Epoch 42/300
 - 9s - loss: 0.3302 - acc: 0.9397 - mDice: 0.7044 - val_loss: 0.7768 - val_acc: 0.9452 - val_mDice: 0.5844

Epoch 00042: val_mDice did not improve from 0.58630
Epoch 43/300
 - 9s - loss: 0.3287 - acc: 0.9399 - mDice: 0.7055 - val_loss: 0.7779 - val_acc: 0.9452 - val_mDice: 0.5802

Epoch 00043: val_mDice did not improve from 0.58630
Epoch 44/300
 - 9s - loss: 0.3271 - acc: 0.9401 - mDice: 0.7068 - val_loss: 0.8367 - val_acc: 0.9449 - val_mDice: 0.5552

Epoch 00044: val_mDice did not improve from 0.58630
Epoch 45/300
 - 9s - loss: 0.3261 - acc: 0.9403 - mDice: 0.7074 - val_loss: 0.7724 - val_acc: 0.9460 - val_mDice: 0.5873

Epoch 00045: val_mDice improved from 0.58630 to 0.58727, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 9s - loss: 0.3237 - acc: 0.9404 - mDice: 0.7091 - val_loss: 0.7598 - val_acc: 0.9435 - val_mDice: 0.5757

Epoch 00046: val_mDice did not improve from 0.58727
Epoch 47/300
 - 9s - loss: 0.3230 - acc: 0.9408 - mDice: 0.7097 - val_loss: 0.7399 - val_acc: 0.9439 - val_mDice: 0.5794

Epoch 00047: val_mDice did not improve from 0.58727
Epoch 48/300
 - 10s - loss: 0.3233 - acc: 0.9406 - mDice: 0.7094 - val_loss: 0.7566 - val_acc: 0.9450 - val_mDice: 0.5676

Epoch 00048: val_mDice did not improve from 0.58727
Epoch 49/300
 - 9s - loss: 0.3221 - acc: 0.9406 - mDice: 0.7103 - val_loss: 0.7494 - val_acc: 0.9421 - val_mDice: 0.5811

Epoch 00049: val_mDice did not improve from 0.58727
Epoch 50/300
 - 9s - loss: 0.3197 - acc: 0.9410 - mDice: 0.7121 - val_loss: 0.7323 - val_acc: 0.9427 - val_mDice: 0.5742

Epoch 00050: val_mDice did not improve from 0.58727
Epoch 51/300
 - 9s - loss: 0.3174 - acc: 0.9414 - mDice: 0.7138 - val_loss: 0.7809 - val_acc: 0.9469 - val_mDice: 0.5746

Epoch 00051: val_mDice did not improve from 0.58727
Epoch 52/300
 - 9s - loss: 0.3163 - acc: 0.9415 - mDice: 0.7147 - val_loss: 0.7445 - val_acc: 0.9393 - val_mDice: 0.5790

Epoch 00052: val_mDice did not improve from 0.58727
Epoch 53/300
 - 9s - loss: 0.3166 - acc: 0.9416 - mDice: 0.7145 - val_loss: 0.7380 - val_acc: 0.9445 - val_mDice: 0.5856

Epoch 00053: val_mDice did not improve from 0.58727
Epoch 54/300
 - 9s - loss: 0.3163 - acc: 0.9415 - mDice: 0.7145 - val_loss: 0.7180 - val_acc: 0.9444 - val_mDice: 0.5792

Epoch 00054: val_mDice did not improve from 0.58727
Epoch 55/300
 - 9s - loss: 0.3132 - acc: 0.9419 - mDice: 0.7168 - val_loss: 0.7188 - val_acc: 0.9398 - val_mDice: 0.5778

Epoch 00055: val_mDice did not improve from 0.58727
Epoch 56/300
 - 9s - loss: 0.3123 - acc: 0.9420 - mDice: 0.7175 - val_loss: 0.6837 - val_acc: 0.9452 - val_mDice: 0.5775

Epoch 00056: val_mDice did not improve from 0.58727
Epoch 57/300
 - 9s - loss: 0.3129 - acc: 0.9418 - mDice: 0.7172 - val_loss: 0.7109 - val_acc: 0.9442 - val_mDice: 0.5830

Epoch 00057: val_mDice did not improve from 0.58727
Epoch 58/300
 - 9s - loss: 0.3118 - acc: 0.9420 - mDice: 0.7179 - val_loss: 0.7136 - val_acc: 0.9448 - val_mDice: 0.5845

Epoch 00058: val_mDice did not improve from 0.58727
Epoch 59/300
 - 9s - loss: 0.3113 - acc: 0.9420 - mDice: 0.7183 - val_loss: 0.6827 - val_acc: 0.9441 - val_mDice: 0.5823

Epoch 00059: val_mDice did not improve from 0.58727
Epoch 60/300
 - 10s - loss: 0.3128 - acc: 0.9419 - mDice: 0.7171 - val_loss: 0.6662 - val_acc: 0.9439 - val_mDice: 0.5812

Epoch 00060: val_mDice did not improve from 0.58727
Epoch 61/300
 - 9s - loss: 0.3091 - acc: 0.9422 - mDice: 0.7198 - val_loss: 0.7220 - val_acc: 0.9442 - val_mDice: 0.5806

Epoch 00061: val_mDice did not improve from 0.58727
Epoch 62/300
 - 10s - loss: 0.3082 - acc: 0.9423 - mDice: 0.7206 - val_loss: 0.7672 - val_acc: 0.9415 - val_mDice: 0.5774

Epoch 00062: val_mDice did not improve from 0.58727
Epoch 63/300
 - 9s - loss: 0.3072 - acc: 0.9425 - mDice: 0.7214 - val_loss: 0.7136 - val_acc: 0.9427 - val_mDice: 0.5866

Epoch 00063: val_mDice did not improve from 0.58727
Epoch 64/300
 - 9s - loss: 0.3067 - acc: 0.9425 - mDice: 0.7218 - val_loss: 0.6762 - val_acc: 0.9436 - val_mDice: 0.5823

Epoch 00064: val_mDice did not improve from 0.58727
Epoch 65/300
 - 9s - loss: 0.3052 - acc: 0.9426 - mDice: 0.7228 - val_loss: 0.7553 - val_acc: 0.9448 - val_mDice: 0.5658

Epoch 00065: val_mDice did not improve from 0.58727
Epoch 66/300
 - 9s - loss: 0.3049 - acc: 0.9426 - mDice: 0.7231 - val_loss: 0.6761 - val_acc: 0.9456 - val_mDice: 0.5785

Epoch 00066: val_mDice did not improve from 0.58727
Epoch 67/300
 - 9s - loss: 0.3051 - acc: 0.9425 - mDice: 0.7229 - val_loss: 0.6985 - val_acc: 0.9443 - val_mDice: 0.5837

Epoch 00067: val_mDice did not improve from 0.58727
Epoch 68/300
 - 9s - loss: 0.3028 - acc: 0.9428 - mDice: 0.7247 - val_loss: 0.6977 - val_acc: 0.9473 - val_mDice: 0.5811

Epoch 00068: val_mDice did not improve from 0.58727
Epoch 69/300
 - 9s - loss: 0.3032 - acc: 0.9428 - mDice: 0.7243 - val_loss: 0.6506 - val_acc: 0.9453 - val_mDice: 0.5812

Epoch 00069: val_mDice did not improve from 0.58727
Epoch 70/300
 - 9s - loss: 0.3016 - acc: 0.9429 - mDice: 0.7256 - val_loss: 0.6838 - val_acc: 0.9450 - val_mDice: 0.5787

Epoch 00070: val_mDice did not improve from 0.58727
Epoch 71/300
 - 9s - loss: 0.3015 - acc: 0.9430 - mDice: 0.7257 - val_loss: 0.7132 - val_acc: 0.9382 - val_mDice: 0.5729

Epoch 00071: val_mDice did not improve from 0.58727
Epoch 72/300
 - 9s - loss: 0.3007 - acc: 0.9430 - mDice: 0.7262 - val_loss: 0.6263 - val_acc: 0.9411 - val_mDice: 0.5824

Epoch 00072: val_mDice did not improve from 0.58727
Epoch 73/300
 - 9s - loss: 0.2996 - acc: 0.9430 - mDice: 0.7271 - val_loss: 0.6279 - val_acc: 0.9457 - val_mDice: 0.5907

Epoch 00073: val_mDice improved from 0.58727 to 0.59072, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 9s - loss: 0.2999 - acc: 0.9431 - mDice: 0.7269 - val_loss: 0.6655 - val_acc: 0.9433 - val_mDice: 0.5805

Epoch 00074: val_mDice did not improve from 0.59072
Epoch 75/300
 - 9s - loss: 0.3002 - acc: 0.9430 - mDice: 0.7266 - val_loss: 0.6896 - val_acc: 0.9416 - val_mDice: 0.5790

Epoch 00075: val_mDice did not improve from 0.59072
Epoch 76/300
 - 9s - loss: 0.2986 - acc: 0.9432 - mDice: 0.7278 - val_loss: 0.6755 - val_acc: 0.9456 - val_mDice: 0.5803

Epoch 00076: val_mDice did not improve from 0.59072
Epoch 77/300
 - 9s - loss: 0.2991 - acc: 0.9430 - mDice: 0.7274 - val_loss: 0.6329 - val_acc: 0.9441 - val_mDice: 0.5607

Epoch 00077: val_mDice did not improve from 0.59072
Epoch 78/300
 - 9s - loss: 0.2986 - acc: 0.9432 - mDice: 0.7278 - val_loss: 0.6198 - val_acc: 0.9430 - val_mDice: 0.5751

Epoch 00078: val_mDice did not improve from 0.59072
Epoch 79/300
 - 9s - loss: 0.2970 - acc: 0.9434 - mDice: 0.7290 - val_loss: 0.6289 - val_acc: 0.9464 - val_mDice: 0.5711

Epoch 00079: val_mDice did not improve from 0.59072
Epoch 80/300
 - 9s - loss: 0.2974 - acc: 0.9433 - mDice: 0.7287 - val_loss: 0.6880 - val_acc: 0.9447 - val_mDice: 0.5689

Epoch 00080: val_mDice did not improve from 0.59072
Epoch 81/300
 - 9s - loss: 0.2959 - acc: 0.9433 - mDice: 0.7298 - val_loss: 0.6468 - val_acc: 0.9438 - val_mDice: 0.5832

Epoch 00081: val_mDice did not improve from 0.59072
Epoch 82/300
 - 9s - loss: 0.2957 - acc: 0.9434 - mDice: 0.7300 - val_loss: 0.6899 - val_acc: 0.9449 - val_mDice: 0.5720

Epoch 00082: val_mDice did not improve from 0.59072
Epoch 83/300
 - 9s - loss: 0.2961 - acc: 0.9435 - mDice: 0.7298 - val_loss: 0.6209 - val_acc: 0.9456 - val_mDice: 0.5775

Epoch 00083: val_mDice did not improve from 0.59072
Epoch 84/300
 - 9s - loss: 0.2942 - acc: 0.9437 - mDice: 0.7312 - val_loss: 0.6843 - val_acc: 0.9402 - val_mDice: 0.5763

Epoch 00084: val_mDice did not improve from 0.59072
Epoch 85/300
 - 10s - loss: 0.2937 - acc: 0.9437 - mDice: 0.7315 - val_loss: 0.6131 - val_acc: 0.9360 - val_mDice: 0.5741

Epoch 00085: val_mDice did not improve from 0.59072
Epoch 86/300
 - 9s - loss: 0.2937 - acc: 0.9436 - mDice: 0.7315 - val_loss: 0.6038 - val_acc: 0.9439 - val_mDice: 0.5713

Epoch 00086: val_mDice did not improve from 0.59072
Epoch 87/300
 - 9s - loss: 0.2933 - acc: 0.9438 - mDice: 0.7319 - val_loss: 0.6244 - val_acc: 0.9449 - val_mDice: 0.5813

Epoch 00087: val_mDice did not improve from 0.59072
Epoch 88/300
 - 9s - loss: 0.2936 - acc: 0.9436 - mDice: 0.7316 - val_loss: 0.5819 - val_acc: 0.9461 - val_mDice: 0.5745

Epoch 00088: val_mDice did not improve from 0.59072
Epoch 89/300
 - 9s - loss: 0.2911 - acc: 0.9439 - mDice: 0.7336 - val_loss: 0.6864 - val_acc: 0.9400 - val_mDice: 0.5631

Epoch 00089: val_mDice did not improve from 0.59072
Epoch 90/300
 - 9s - loss: 0.2916 - acc: 0.9441 - mDice: 0.7332 - val_loss: 0.5939 - val_acc: 0.9429 - val_mDice: 0.5730

Epoch 00090: val_mDice did not improve from 0.59072
Epoch 91/300
 - 9s - loss: 0.2924 - acc: 0.9439 - mDice: 0.7326 - val_loss: 0.6075 - val_acc: 0.9418 - val_mDice: 0.5762

Epoch 00091: val_mDice did not improve from 0.59072
Epoch 92/300
 - 10s - loss: 0.2926 - acc: 0.9438 - mDice: 0.7325 - val_loss: 0.5976 - val_acc: 0.9426 - val_mDice: 0.5798

Epoch 00092: val_mDice did not improve from 0.59072
Epoch 93/300
 - 9s - loss: 0.2909 - acc: 0.9440 - mDice: 0.7337 - val_loss: 0.6050 - val_acc: 0.9443 - val_mDice: 0.5718

Epoch 00093: val_mDice did not improve from 0.59072
Epoch 94/300
 - 9s - loss: 0.2904 - acc: 0.9439 - mDice: 0.7341 - val_loss: 0.6373 - val_acc: 0.9455 - val_mDice: 0.5695

Epoch 00094: val_mDice did not improve from 0.59072
Epoch 95/300
 - 9s - loss: 0.2888 - acc: 0.9442 - mDice: 0.7353 - val_loss: 0.5547 - val_acc: 0.9424 - val_mDice: 0.5749

Epoch 00095: val_mDice did not improve from 0.59072
Epoch 96/300
 - 9s - loss: 0.2906 - acc: 0.9438 - mDice: 0.7339 - val_loss: 0.5659 - val_acc: 0.9453 - val_mDice: 0.5727

Epoch 00096: val_mDice did not improve from 0.59072
Epoch 97/300
 - 10s - loss: 0.2895 - acc: 0.9440 - mDice: 0.7347 - val_loss: 0.5651 - val_acc: 0.9430 - val_mDice: 0.5785

Epoch 00097: val_mDice did not improve from 0.59072
Epoch 98/300
 - 9s - loss: 0.2888 - acc: 0.9442 - mDice: 0.7353 - val_loss: 0.6115 - val_acc: 0.9458 - val_mDice: 0.5837

Epoch 00098: val_mDice did not improve from 0.59072
Epoch 99/300
 - 10s - loss: 0.2881 - acc: 0.9443 - mDice: 0.7358 - val_loss: 0.6155 - val_acc: 0.9439 - val_mDice: 0.5752

Epoch 00099: val_mDice did not improve from 0.59072
Epoch 100/300
 - 9s - loss: 0.2885 - acc: 0.9441 - mDice: 0.7355 - val_loss: 0.6373 - val_acc: 0.9437 - val_mDice: 0.5650

Epoch 00100: val_mDice did not improve from 0.59072
Epoch 101/300
 - 9s - loss: 0.2891 - acc: 0.9441 - mDice: 0.7351 - val_loss: 0.5972 - val_acc: 0.9417 - val_mDice: 0.5734

Epoch 00101: val_mDice did not improve from 0.59072
Epoch 102/300
 - 10s - loss: 0.2878 - acc: 0.9441 - mDice: 0.7360 - val_loss: 0.6539 - val_acc: 0.9424 - val_mDice: 0.5792

Epoch 00102: val_mDice did not improve from 0.59072
Epoch 103/300
 - 9s - loss: 0.2866 - acc: 0.9444 - mDice: 0.7369 - val_loss: 0.5248 - val_acc: 0.9443 - val_mDice: 0.5749

Epoch 00103: val_mDice did not improve from 0.59072
Epoch 104/300
 - 9s - loss: 0.2874 - acc: 0.9443 - mDice: 0.7364 - val_loss: 0.5894 - val_acc: 0.9438 - val_mDice: 0.5694

Epoch 00104: val_mDice did not improve from 0.59072
Epoch 105/300
 - 9s - loss: 0.2858 - acc: 0.9445 - mDice: 0.7376 - val_loss: 0.5773 - val_acc: 0.9447 - val_mDice: 0.5733

Epoch 00105: val_mDice did not improve from 0.59072
Epoch 106/300
 - 9s - loss: 0.2858 - acc: 0.9444 - mDice: 0.7376 - val_loss: 0.5620 - val_acc: 0.9459 - val_mDice: 0.5807

Epoch 00106: val_mDice did not improve from 0.59072
Epoch 107/300
 - 9s - loss: 0.2849 - acc: 0.9445 - mDice: 0.7383 - val_loss: 0.5290 - val_acc: 0.9441 - val_mDice: 0.5716

Epoch 00107: val_mDice did not improve from 0.59072
Epoch 108/300
 - 9s - loss: 0.2859 - acc: 0.9444 - mDice: 0.7375 - val_loss: 0.6408 - val_acc: 0.9446 - val_mDice: 0.5344

Epoch 00108: val_mDice did not improve from 0.59072
Epoch 109/300
 - 10s - loss: 0.2843 - acc: 0.9445 - mDice: 0.7388 - val_loss: 0.5561 - val_acc: 0.9391 - val_mDice: 0.5713

Epoch 00109: val_mDice did not improve from 0.59072
Epoch 110/300
 - 9s - loss: 0.2844 - acc: 0.9445 - mDice: 0.7386 - val_loss: 0.5612 - val_acc: 0.9447 - val_mDice: 0.5572

Epoch 00110: val_mDice did not improve from 0.59072
Epoch 111/300
 - 9s - loss: 0.2845 - acc: 0.9444 - mDice: 0.7386 - val_loss: 0.5419 - val_acc: 0.9431 - val_mDice: 0.5732

Epoch 00111: val_mDice did not improve from 0.59072
Epoch 112/300
 - 9s - loss: 0.2842 - acc: 0.9447 - mDice: 0.7389 - val_loss: 0.5448 - val_acc: 0.9458 - val_mDice: 0.5596

Epoch 00112: val_mDice did not improve from 0.59072
Epoch 113/300
 - 9s - loss: 0.2823 - acc: 0.9448 - mDice: 0.7404 - val_loss: 0.5735 - val_acc: 0.9407 - val_mDice: 0.5548

Epoch 00113: val_mDice did not improve from 0.59072
Restoring model weights from the end of the best epoch
Epoch 00113: early stopping
{'val_loss': [2.9921791439964656, 1.768913359869094, 1.8213829540071034, 1.4481027466910226, 1.1160523777916318, 1.0496655645824613, 1.0367403484526134, 1.0507765611012776, 0.9909367334275019, 0.9809027966998872, 0.9598835309346517, 0.9695946716126942, 0.927623158409482, 0.9251230330694289, 0.9152818861461821, 0.9323784850892567, 0.9501271134331113, 0.9058223849251157, 0.8871147292000907, 0.8749623866308303, 0.877218382699149, 0.8891171954926991, 0.8708989676975069, 0.8533913521539598, 0.8514777649016607, 0.8826706352688017, 0.8622709001813617, 0.8593507834843227, 0.8551849524180094, 0.845328240167527, 0.8235084896995908, 0.8197617928187052, 0.841149023600987, 0.8061559427352178, 0.8401138271604266, 0.8156121401559739, 0.8343459310985747, 0.7822972592853364, 0.8014780112675258, 0.7648008210318429, 0.8082258531025478, 0.7767988613673619, 0.777949781644912, 0.836720659619286, 0.7723599785850161, 0.7598248436337426, 0.7399299371810186, 0.7565516574042184, 0.7493830011004493, 0.7323393481118339, 0.780877845627921, 0.7444682745706468, 0.737985440662929, 0.7180455071585519, 0.7188014302934919, 0.6837310450417655, 0.7108768565314156, 0.7135935170309884, 0.682739394051688, 0.6662041062400454, 0.7220418396450224, 0.7671886001314435, 0.7135857911336989, 0.6761930613290696, 0.7552616198857626, 0.6761473587581089, 0.6984714780535016, 0.697659413019816, 0.6506377855936686, 0.6837699924196515, 0.7131671678452265, 0.6263105471928915, 0.6279391050338745, 0.665492574373881, 0.6896263417743501, 0.6755176782608032, 0.6328861713409424, 0.6197973716826666, 0.6289345593679518, 0.6879847447077433, 0.6468443246114821, 0.6899425302233014, 0.6208979004905337, 0.6843005532310122, 0.613070045198713, 0.6038100378853934, 0.6243597382590884, 0.5819170020875477, 0.6863890716007778, 0.5939031498772758, 0.6075068996066139, 0.5976053192501977, 0.6049866335732597, 0.6373303163619268, 0.5546830495198568, 0.5658930256253197, 0.5650818007332938, 0.6114747183663505, 0.6155105318341937, 0.6372681912921724, 0.5972037769499279, 0.6539338827133179, 0.5247519356863839, 0.5893723680859521, 0.5773328429176694, 0.562032767704555, 0.5290282340276808, 0.6408405644553048, 0.556061517624628, 0.5611508176440284, 0.5418711446580433, 0.544831667627607, 0.5735441730135963], 'val_acc': [0.9043727119763693, 0.9081501818838573, 0.9095146287055242, 0.9093360872495742, 0.9140086940356663, 0.9173443402562823, 0.9196611813136509, 0.9254143862497239, 0.9293841492562067, 0.928271546250298, 0.9329990716207595, 0.9300732499077207, 0.9313805216834659, 0.9338988094102769, 0.9356776419140044, 0.9400160454568409, 0.940661629041036, 0.9457852670124599, 0.9467238840602693, 0.9464033842086792, 0.9463530296371097, 0.941900182337988, 0.9453777443794977, 0.9450228810310364, 0.9436332640193758, 0.9385348019145784, 0.9440544644991556, 0.9402358333269755, 0.9459890155565172, 0.9452586968739828, 0.9457005659739176, 0.9443841321127755, 0.9402678438595363, 0.9461904820941743, 0.9415110009057182, 0.9461538451058524, 0.9434935791151864, 0.9477884570757548, 0.9439171212060111, 0.9436149114654178, 0.9442353447278341, 0.945167138462975, 0.9452266352517265, 0.9449336131413778, 0.9460004369417826, 0.9434913198153178, 0.9438782192411876, 0.9450297469184512, 0.9420650232405889, 0.9427128973461333, 0.9469436832836696, 0.9393314832732791, 0.9444963392757234, 0.9443795539083935, 0.9398397178876967, 0.9452083366257804, 0.9441712328365871, 0.9448191523551941, 0.9440751018978301, 0.9438896576563517, 0.9442010010991778, 0.9415292881783985, 0.9426831773349217, 0.9435531326702663, 0.9448145486059643, 0.9455609094528925, 0.9443475547290984, 0.9472871167319161, 0.9452724229721796, 0.9450434872082302, 0.9381776395298186, 0.9410622886248997, 0.9456822105816433, 0.9432669225193205, 0.9415544810749236, 0.9455700374784923, 0.9440682047889346, 0.9429670543897719, 0.9463621803692409, 0.9446977859451657, 0.9437660092399234, 0.9448626296860831, 0.9455929710751488, 0.94016942239943, 0.9360370948201134, 0.9439423254558018, 0.9448672334353129, 0.9460828928720384, 0.9399885733922323, 0.9428571405864897, 0.9417857045219058, 0.9426350508417402, 0.9443338144393194, 0.9454944928487142, 0.9423878306434268, 0.9452541300228664, 0.9430036488033476, 0.9457898310252598, 0.9438598638489133, 0.9437294148263478, 0.9416712408974057, 0.9423626235553196, 0.9443269315220061, 0.943839274701618, 0.9446543199675423, 0.945904328709557, 0.9441346242314294, 0.9446268308730352, 0.9390590645018078, 0.9447183836074102, 0.9431272688366118, 0.9457509063539051, 0.9406753778457642], 'val_mDice': [0.10625203922280066, 0.3085605703471672, 0.3069713635458833, 0.39044185337566195, 0.4971306724917321, 0.5219714215823582, 0.5233999047250975, 0.5134260175483567, 0.5375204118234771, 0.5400812226746764, 0.5617109636465708, 0.5459716075233051, 0.5600172024042833, 0.5619485518407255, 0.5614951547412645, 0.5565272498698461, 0.5445902865557444, 0.5693653408615362, 0.5792865261790299, 0.5799342936703137, 0.5776722791294256, 0.5671224902783122, 0.5816304291642848, 0.5807636585973558, 0.5752781931133497, 0.577687735358874, 0.5776534942643983, 0.5809736883356458, 0.5743491344508671, 0.5607944228464649, 0.5697798406084379, 0.5827737441729932, 0.583023975825026, 0.5751897788473538, 0.5736225155137834, 0.5676899900039037, 0.5737846947851635, 0.5862982964941433, 0.581769925497827, 0.5855824915426118, 0.5769785255903289, 0.5843707064077968, 0.5802266746759415, 0.5551569401508286, 0.5872672297770068, 0.575712668399016, 0.5793761706777981, 0.5675889498421124, 0.581149967476016, 0.5741536778708299, 0.5746087737026668, 0.5790147211934839, 0.5855516064025107, 0.5791834003868557, 0.5778033596773943, 0.5775124485648814, 0.5829961214746747, 0.5844501065356391, 0.5823361217266038, 0.5811709821933791, 0.5805686158793313, 0.5774076408928349, 0.5865838573802085, 0.5823023379558608, 0.5658421441912651, 0.578496903181076, 0.5836850686797074, 0.5811148800310635, 0.5812134533410981, 0.5786790145295007, 0.572871274713959, 0.5823858206470808, 0.5907168721868878, 0.5805443085375286, 0.579010646080687, 0.580310255111683, 0.5607012127126966, 0.5751320960975829, 0.5711319451885564, 0.5688688705364863, 0.5831895958454836, 0.5720377782625812, 0.577459880816085, 0.5763409504933017, 0.5741245624210153, 0.5712977732930865, 0.5812809238476413, 0.5745482386222908, 0.5631326962084997, 0.5729700202743212, 0.5762261159363247, 0.5797669992205643, 0.5717512381573518, 0.5694817304611206, 0.5748992576485589, 0.5727180753435407, 0.5785152305449758, 0.5837279052606651, 0.5752358716868219, 0.5650325862779504, 0.5733619985126314, 0.579189812675828, 0.5748936860334306, 0.5693625609079996, 0.5732599503937221, 0.5807270640063853, 0.5716165792019594, 0.5344276669479552, 0.5712554273860795, 0.5571655290467399, 0.573168773381483, 0.5595682408838045, 0.5547888296700659], 'loss': [2.8896128153419456, 1.2430559416163833, 0.8431293994607736, 0.7031056242157366, 0.6290296939197524, 0.5774224146220963, 0.5316833445900365, 0.5037840882063785, 0.4785968109502805, 0.46123966612015155, 0.45001542485470436, 0.4368647506741722, 0.4272371343973861, 0.4187512228328965, 0.41107879268518643, 0.4060876943689563, 0.3982445150240322, 0.39402122934912126, 0.3903084656039437, 0.3842226743169527, 0.38046646436469184, 0.3746207335251752, 0.3730855100194406, 0.3701866036070917, 0.3656531418705115, 0.3637531975893609, 0.3585875019393768, 0.3573729967551583, 0.3552269892458606, 0.3525418711232615, 0.34920682079396265, 0.34663398161383985, 0.3465083166540347, 0.3424822753257597, 0.3402604975807476, 0.33729295604647713, 0.3387374059988948, 0.3358314768448027, 0.335924802963872, 0.33326593186783154, 0.3298900484153938, 0.33020174740044306, 0.3287166970955606, 0.32705639594318736, 0.3261425454986102, 0.32367172444834286, 0.32296898353184855, 0.32333544707376416, 0.32212874118661705, 0.3197112327047642, 0.3173772948645939, 0.31627532142836257, 0.31656310875245275, 0.3163085912311378, 0.3132387827604245, 0.3123252936266327, 0.3128751426481295, 0.31175759996617713, 0.31128226801198594, 0.31284791458680355, 0.3091371304926349, 0.30823843597400524, 0.3072398963267803, 0.3066705656816947, 0.30515290599970635, 0.30486499049747656, 0.3051421485506594, 0.3027898252630868, 0.303247824371585, 0.30156057876544995, 0.3014640097147425, 0.3006955079026183, 0.29957324002711605, 0.299933086763992, 0.30024885634868526, 0.29864521050283116, 0.2991085592862014, 0.2986258388381485, 0.2970385466303144, 0.29740760551956963, 0.2959382076219302, 0.2957041648878903, 0.29605556193380794, 0.29419787983363915, 0.29369982634639613, 0.2937199170991178, 0.2932663714182453, 0.29361088324287204, 0.2910670954436035, 0.2915790995088459, 0.2923906274572236, 0.2925915144382471, 0.29085647136530296, 0.29036126559424635, 0.2887794467751084, 0.2905609377356239, 0.28946851862403083, 0.28875442734338286, 0.28811800219614153, 0.28846451251727895, 0.2890698270161579, 0.28783489827225384, 0.2866499218059133, 0.28737011233551873, 0.28579148247978786, 0.28577361041717686, 0.28490430599282146, 0.285875709100061, 0.2842875979919757, 0.2844389583279867, 0.28446361277175586, 0.2841866614502796, 0.2822530607003248], 'acc': [0.57041804602286, 0.8729351106948514, 0.8764002954360031, 0.8790305542054148, 0.8816815735357493, 0.884753861051776, 0.8884358630719065, 0.8920695089825045, 0.8958274265440622, 0.8990427442476748, 0.9013972159109526, 0.9032842621468661, 0.9055660375515482, 0.9074688830861978, 0.909591424837493, 0.9118891417669933, 0.9149262317003302, 0.9199313223189601, 0.9280327037048633, 0.9328419998222081, 0.9337733663505089, 0.9345910515724544, 0.9349787420267679, 0.9352606299504026, 0.9358342689127506, 0.9358999834185693, 0.9363975776328916, 0.9367356072943955, 0.9368409486963314, 0.9372781306442002, 0.9373878498791683, 0.9378086257606015, 0.9378263035077039, 0.9382383275266463, 0.9383479006055556, 0.9388345830100843, 0.9387394861033226, 0.939018149802927, 0.9392499357766445, 0.9393993953599483, 0.9397340217306822, 0.9397057015725314, 0.9399044506692785, 0.9401032164396982, 0.9403039525877609, 0.9404440741675056, 0.9407573354503932, 0.9406154768669653, 0.9406186023129878, 0.9410310168130241, 0.9413920791594537, 0.9414518642728904, 0.941632718163831, 0.9414695423992011, 0.9418755853500168, 0.9419502226148516, 0.9417532835366157, 0.9420259910809274, 0.9420322946944125, 0.9419141165870496, 0.9421557991151202, 0.9423425682758076, 0.942471216128055, 0.9424813635574041, 0.9425993564272745, 0.9425936777490124, 0.9425243503421815, 0.9428386280296257, 0.9428123278794364, 0.9429192192204683, 0.9430078510284792, 0.943034178217367, 0.9429979140597179, 0.9430901565624382, 0.9430276399199297, 0.9431648661411404, 0.9430309292873437, 0.9432122023183301, 0.9434298580267858, 0.943307324942307, 0.9432722451899676, 0.9434186877578308, 0.9434540495262087, 0.9436637298298268, 0.9437026349662103, 0.9435985491917913, 0.9437714575893827, 0.9435754935820024, 0.9439369060525734, 0.9440508661229693, 0.9439361653898822, 0.9438478780178888, 0.9439952760067247, 0.9439493239856718, 0.9441997406338827, 0.9438382136539064, 0.9440131856799011, 0.9441713593887276, 0.9442510449842656, 0.9441351383344181, 0.9441043202739611, 0.9441495505927362, 0.9443779336434006, 0.9443193083212098, 0.9444973837991475, 0.9444399380904529, 0.9444927487365078, 0.9443567773729062, 0.9445117273288401, 0.9444796118360277, 0.9444384122598095, 0.9446584288499845, 0.944751323878202], 'mDice': [0.09533075436860673, 0.2932068254186028, 0.4162822999268431, 0.4783834358826294, 0.5164806404531128, 0.5452713084308219, 0.5723301268552387, 0.5896107077437696, 0.6053992500993726, 0.6164611445954247, 0.6238267591906486, 0.6325050217236124, 0.6389654313228667, 0.6445737093405524, 0.6496331213939528, 0.6531410655328159, 0.6582433292579394, 0.6610790432729036, 0.6632431637512275, 0.6669858456209534, 0.6693700231038607, 0.6732217011847936, 0.6742187034814877, 0.6762053339334727, 0.6792687854947027, 0.680504673807888, 0.6841773595082776, 0.6849769040387743, 0.6864697494464549, 0.6885128683935408, 0.6908522719635494, 0.6925325082496157, 0.6928345175269299, 0.6956049021278154, 0.6971694407307714, 0.6992678886804825, 0.6983310512111025, 0.7003373766487817, 0.7003808421207941, 0.7022640752337308, 0.7047710901444786, 0.7044084368125308, 0.7055205509040726, 0.7067547615998877, 0.7073939196838679, 0.709090694977595, 0.709662131498332, 0.70938565162466, 0.7102937877051789, 0.7120771542182887, 0.7138020503215301, 0.7146611298833575, 0.7144546827324006, 0.7145474975753064, 0.7168198677301637, 0.7175258593750478, 0.7171602920688874, 0.7179139932961921, 0.7182684952476844, 0.717118177348211, 0.7198366099914328, 0.7205815962198867, 0.7213834757999761, 0.7217684066063502, 0.722824794239039, 0.7231282906332801, 0.7228818163835913, 0.7246630808763337, 0.724330425469292, 0.7256043222406959, 0.7256734799805555, 0.726211802277327, 0.7270569341914006, 0.7268725788292224, 0.7266481655145487, 0.7277690994502815, 0.7274190778789296, 0.7277810383743925, 0.7290368751452703, 0.7287330575501365, 0.7297784480052071, 0.7300175641781337, 0.7297780302555914, 0.7311832795304923, 0.7315278506495025, 0.7314923359108082, 0.7318695237785032, 0.7315563324537951, 0.7335761931330017, 0.733153177544127, 0.7325520012703662, 0.7324519294154467, 0.7336561407384694, 0.7340550462657692, 0.7352671304695036, 0.7338902044323844, 0.7347443017836409, 0.7353473168612675, 0.7357567200799519, 0.7355256193815364, 0.7350900376350957, 0.7360424617018478, 0.736926600495032, 0.7363950123165485, 0.7376424730548009, 0.73762065306642, 0.7382822704724271, 0.7375047340176113, 0.738751596836357, 0.7386242219402952, 0.738599262831412, 0.7388759536253181, 0.740375542263776]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.32s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:43,  1.84s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:56,  1.68s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:02,  1.71s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:31,  1.61s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:51,  1.68s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:26,  1.60s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:41,  1.66s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:31,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:06,  1.76s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:41,  1.90s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:22,  1.83s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:38,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:14,  1.82s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:30,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:51,  1.97s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:44,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:20,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:18,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:00,  1.81s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:10,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:44,  1.99s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:17,  1.89s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:17,  1.90s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:56,  1.83s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:14,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:27,  1.96s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:56,  1.85s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:00,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:52,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:07,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:18,  1.96s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:54,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:51,  1.88s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:28,  1.80s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:55,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:47,  1.90s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:47,  1.91s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:29,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:14,  1.79s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:17,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:23,  1.84s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:01,  1.76s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:09,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<06:59,  1.76s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<07:11,  1.82s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:24,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:29,  1.91s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:44,  1.99s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:32,  1.94s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:32,  1.95s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:35,  1.97s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:06,  1.85s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:08,  1.87s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:48,  1.79s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:54,  1.82s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:08,  1.90s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:18,  1.95s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<06:55,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<07:03,  1.91s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:54,  1.87s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:54,  1.88s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:51,  1.88s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:52,  1.89s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:34,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:31,  1.81s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:30,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:37,  1.86s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:24,  1.81s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:28,  1.83s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:23,  1.82s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:31,  1.86s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:39,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:30,  1.88s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:15,  1.81s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<06:11,  1.80s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<06:17,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:09,  1.82s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:50,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:37,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<05:37,  1.69s/it]predicting train subjects:  30%|███       | 86/285 [02:38<05:42,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:39<05:46,  1.75s/it]predicting train subjects:  31%|███       | 88/285 [02:41<05:41,  1.73s/it]predicting train subjects:  31%|███       | 89/285 [02:43<05:44,  1.76s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<05:49,  1.79s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:42,  1.76s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<05:54,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<05:44,  1.80s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<05:47,  1.82s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<05:50,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:46,  1.83s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<06:00,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<06:03,  1.94s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:55,  1.91s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<06:10,  2.00s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:54,  1.92s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<06:01,  1.98s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:52,  1.94s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:49,  1.93s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:52,  1.96s/it]predicting train subjects:  37%|███▋      | 106/285 [03:15<05:45,  1.93s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:39,  1.91s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:27,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:24,  1.84s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:35,  1.92s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:19,  1.84s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:27,  1.89s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:33,  1.94s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:26,  1.91s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:24,  1.91s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:30,  1.96s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:18,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:22,  1.95s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:05,  1.85s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:58,  1.82s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:48,  1.77s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:31,  1.67s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:25,  1.65s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:06,  1.55s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:07,  1.59s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:01,  1.56s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<04:11,  1.64s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<04:09,  1.64s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<03:56,  1.57s/it]predicting train subjects:  47%|████▋     | 135/285 [04:06<03:59,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<03:56,  1.59s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<04:00,  1.64s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<04:06,  1.69s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<04:01,  1.67s/it]predicting train subjects:  49%|████▉     | 141/285 [04:16<04:02,  1.68s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:50,  1.61s/it]predicting train subjects:  50%|█████     | 143/285 [04:19<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:52,  1.65s/it]predicting train subjects:  51%|█████     | 145/285 [04:22<03:45,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:57,  1.71s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:55,  1.71s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:59,  1.75s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:50,  1.70s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:39,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:44,  1.68s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:40,  1.66s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:39,  1.66s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:47,  1.74s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:39,  1.69s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:39,  1.71s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:39,  1.71s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:33,  1.68s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:30,  1.67s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:48<03:39,  1.76s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:50<03:46,  1.82s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:34,  1.74s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:53<03:29,  1.71s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:23,  1.68s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:56<03:14,  1.62s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:58<03:14,  1.64s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:24,  1.73s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:01<03:14,  1.66s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:04<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<02:56,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [05:07<02:55,  1.55s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:55,  1.56s/it]predicting train subjects:  61%|██████    | 174/285 [05:10<02:49,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<03:08,  1.72s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<03:11,  1.75s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:16<03:10,  1.76s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:56,  1.65s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:19<02:52,  1.63s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:21<03:01,  1.73s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:23<03:01,  1.75s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:25<03:05,  1.80s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:26<02:57,  1.74s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:28<02:48,  1.66s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:29<02:44,  1.65s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:31<02:52,  1.74s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:33<03:01,  1.85s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:35<03:01,  1.87s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:37<02:45,  1.72s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:38<02:46,  1.75s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:40<02:41,  1.72s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:42<02:40,  1.72s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:43<02:34,  1.68s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:45<02:28,  1.63s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:46<02:25,  1.62s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:49<02:35,  1.75s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:50<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:52<02:38,  1.82s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:54<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [05:55<02:17,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:57<02:28,  1.76s/it]predicting train subjects:  71%|███████   | 202/285 [05:59<02:28,  1.78s/it]predicting train subjects:  71%|███████   | 203/285 [06:01<02:22,  1.74s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:02<02:14,  1.66s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:04<02:10,  1.64s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:05<02:05,  1.59s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:07<02:16,  1.75s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:09<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:11<02:26,  1.92s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:13<02:19,  1.86s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:15<02:21,  1.91s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:17<02:15,  1.86s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:19<02:16,  1.90s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:21<02:08,  1.80s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:23<02:17,  1.97s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:24<02:06,  1.83s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:26<02:08,  1.89s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:29<02:16,  2.04s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:31<02:14,  2.03s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:33<02:07,  1.96s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:34<02:01,  1.91s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:36<02:03,  1.97s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:38<01:52,  1.81s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:40<01:54,  1.87s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:42<01:49,  1.82s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:44<01:55,  1.96s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:46<01:57,  2.03s/it]predicting train subjects:  80%|████████  | 228/285 [06:48<01:57,  2.06s/it]predicting train subjects:  80%|████████  | 229/285 [06:51<01:59,  2.13s/it]predicting train subjects:  81%|████████  | 230/285 [06:52<01:49,  1.99s/it]predicting train subjects:  81%|████████  | 231/285 [06:54<01:45,  1.96s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:56<01:44,  1.96s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:58<01:39,  1.92s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:00<01:40,  1.98s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:02<01:38,  1.96s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:04<01:36,  1.97s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:06<01:41,  2.10s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:08<01:37,  2.07s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:10<01:34,  2.05s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:12<01:26,  1.93s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:14<01:27,  1.98s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:16<01:21,  1.89s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:18<01:18,  1.86s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:20<01:20,  1.95s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:22<01:16,  1.91s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:24<01:18,  2.00s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:26<01:16,  2.01s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:28<01:12,  1.95s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:29<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:31<01:02,  1.78s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:32<00:58,  1.72s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:34<00:55,  1.69s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:36<01:01,  1.93s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:38<01:00,  1.94s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:41<00:59,  1.98s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:42<00:54,  1.86s/it]predicting train subjects:  90%|█████████ | 257/285 [07:44<00:53,  1.91s/it]predicting train subjects:  91%|█████████ | 258/285 [07:46<00:54,  2.01s/it]predicting train subjects:  91%|█████████ | 259/285 [07:49<00:54,  2.08s/it]predicting train subjects:  91%|█████████ | 260/285 [07:50<00:49,  1.97s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:52<00:45,  1.89s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:54<00:43,  1.90s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:56<00:40,  1.83s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:58<00:43,  2.05s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:01<00:42,  2.14s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:02<00:39,  2.06s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:04<00:36,  2.02s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:07<00:35,  2.09s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:09<00:34,  2.16s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:10<00:29,  1.97s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:12<00:27,  1.94s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:14<00:25,  1.95s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:16<00:22,  1.85s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:17<00:19,  1.76s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:20<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:22<00:17,  2.00s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:24<00:15,  1.97s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:26<00:13,  1.93s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:28<00:11,  1.97s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:29<00:09,  1.89s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:31<00:07,  1.79s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:33<00:05,  1.77s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:35<00:03,  1.91s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:37<00:02,  2.07s/it]predicting train subjects: 100%|██████████| 285/285 [08:40<00:00,  2.09s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:41,  2.05s/it]Loading train:   1%|          | 2/285 [00:03<09:10,  1.95s/it]Loading train:   1%|          | 3/285 [00:05<09:11,  1.96s/it]Loading train:   1%|▏         | 4/285 [00:08<09:50,  2.10s/it]Loading train:   2%|▏         | 5/285 [00:10<10:37,  2.28s/it]Loading train:   2%|▏         | 6/285 [00:12<10:06,  2.17s/it]Loading train:   2%|▏         | 7/285 [00:15<10:16,  2.22s/it]Loading train:   3%|▎         | 8/285 [00:17<10:22,  2.25s/it]Loading train:   3%|▎         | 9/285 [00:19<10:35,  2.30s/it]Loading train:   4%|▎         | 10/285 [00:21<09:48,  2.14s/it]Loading train:   4%|▍         | 11/285 [00:23<09:04,  1.99s/it]Loading train:   4%|▍         | 12/285 [00:25<09:02,  1.99s/it]Loading train:   5%|▍         | 13/285 [00:26<08:04,  1.78s/it]Loading train:   5%|▍         | 14/285 [00:28<07:39,  1.70s/it]Loading train:   5%|▌         | 15/285 [00:30<08:10,  1.81s/it]Loading train:   6%|▌         | 16/285 [00:32<08:43,  1.95s/it]Loading train:   6%|▌         | 17/285 [00:33<08:01,  1.80s/it]Loading train:   6%|▋         | 18/285 [00:35<07:41,  1.73s/it]Loading train:   7%|▋         | 19/285 [00:37<07:37,  1.72s/it]Loading train:   7%|▋         | 20/285 [00:39<08:35,  1.94s/it]Loading train:   7%|▋         | 21/285 [00:41<08:53,  2.02s/it]Loading train:   8%|▊         | 22/285 [00:43<08:19,  1.90s/it]Loading train:   8%|▊         | 23/285 [00:44<07:51,  1.80s/it]Loading train:   8%|▊         | 24/285 [00:47<08:10,  1.88s/it]Loading train:   9%|▉         | 25/285 [00:49<08:33,  1.97s/it]Loading train:   9%|▉         | 26/285 [00:51<08:40,  2.01s/it]Loading train:   9%|▉         | 27/285 [00:52<07:47,  1.81s/it]Loading train:  10%|▉         | 28/285 [00:54<08:12,  1.92s/it]Loading train:  10%|█         | 29/285 [00:56<07:42,  1.81s/it]Loading train:  11%|█         | 30/285 [00:58<08:33,  2.01s/it]Loading train:  11%|█         | 31/285 [01:01<09:14,  2.18s/it]Loading train:  11%|█         | 32/285 [01:03<08:34,  2.03s/it]Loading train:  12%|█▏        | 33/285 [01:04<08:11,  1.95s/it]Loading train:  12%|█▏        | 34/285 [01:06<07:50,  1.87s/it]Loading train:  12%|█▏        | 35/285 [01:09<09:14,  2.22s/it]Loading train:  13%|█▎        | 36/285 [01:11<08:53,  2.14s/it]Loading train:  13%|█▎        | 37/285 [01:13<08:17,  2.01s/it]Loading train:  13%|█▎        | 38/285 [01:15<07:56,  1.93s/it]Loading train:  14%|█▎        | 39/285 [01:16<07:32,  1.84s/it]Loading train:  14%|█▍        | 40/285 [01:18<06:56,  1.70s/it]Loading train:  14%|█▍        | 41/285 [01:19<06:40,  1.64s/it]Loading train:  15%|█▍        | 42/285 [01:21<06:43,  1.66s/it]Loading train:  15%|█▌        | 43/285 [01:22<06:32,  1.62s/it]Loading train:  15%|█▌        | 44/285 [01:24<06:23,  1.59s/it]Loading train:  16%|█▌        | 45/285 [01:25<06:09,  1.54s/it]Loading train:  16%|█▌        | 46/285 [01:27<06:58,  1.75s/it]Loading train:  16%|█▋        | 47/285 [01:29<06:42,  1.69s/it]Loading train:  17%|█▋        | 48/285 [01:31<06:54,  1.75s/it]Loading train:  17%|█▋        | 49/285 [01:33<06:59,  1.78s/it]Loading train:  18%|█▊        | 50/285 [01:35<07:18,  1.86s/it]Loading train:  18%|█▊        | 51/285 [01:37<07:37,  1.95s/it]Loading train:  18%|█▊        | 52/285 [01:38<07:02,  1.81s/it]Loading train:  19%|█▊        | 53/285 [01:40<07:18,  1.89s/it]Loading train:  19%|█▉        | 54/285 [01:43<07:47,  2.03s/it]Loading train:  19%|█▉        | 55/285 [01:44<06:55,  1.81s/it]Loading train:  20%|█▉        | 56/285 [01:45<06:06,  1.60s/it]Loading train:  20%|██        | 57/285 [01:46<05:36,  1.48s/it]Loading train:  20%|██        | 58/285 [01:48<05:59,  1.58s/it]Loading train:  21%|██        | 59/285 [01:50<06:37,  1.76s/it]Loading train:  21%|██        | 60/285 [01:52<06:31,  1.74s/it]Loading train:  21%|██▏       | 61/285 [01:53<05:57,  1.60s/it]Loading train:  22%|██▏       | 62/285 [01:55<05:37,  1.51s/it]Loading train:  22%|██▏       | 63/285 [01:56<05:50,  1.58s/it]Loading train:  22%|██▏       | 64/285 [01:58<05:51,  1.59s/it]Loading train:  23%|██▎       | 65/285 [02:00<06:08,  1.67s/it]Loading train:  23%|██▎       | 66/285 [02:02<06:35,  1.80s/it]Loading train:  24%|██▎       | 67/285 [02:04<06:13,  1.71s/it]Loading train:  24%|██▍       | 68/285 [02:05<06:03,  1.67s/it]Loading train:  24%|██▍       | 69/285 [02:07<05:59,  1.66s/it]Loading train:  25%|██▍       | 70/285 [02:08<05:57,  1.66s/it]Loading train:  25%|██▍       | 71/285 [02:10<06:03,  1.70s/it]Loading train:  25%|██▌       | 72/285 [02:12<05:40,  1.60s/it]Loading train:  26%|██▌       | 73/285 [02:13<05:54,  1.67s/it]Loading train:  26%|██▌       | 74/285 [02:15<05:58,  1.70s/it]Loading train:  26%|██▋       | 75/285 [02:17<05:57,  1.70s/it]Loading train:  27%|██▋       | 76/285 [02:18<05:43,  1.64s/it]Loading train:  27%|██▋       | 77/285 [02:20<06:06,  1.76s/it]Loading train:  27%|██▋       | 78/285 [02:22<06:16,  1.82s/it]Loading train:  28%|██▊       | 79/285 [02:24<05:49,  1.70s/it]Loading train:  28%|██▊       | 80/285 [02:26<05:48,  1.70s/it]Loading train:  28%|██▊       | 81/285 [02:27<05:27,  1.61s/it]Loading train:  29%|██▉       | 82/285 [02:28<05:09,  1.52s/it]Loading train:  29%|██▉       | 83/285 [02:30<04:56,  1.47s/it]Loading train:  29%|██▉       | 84/285 [02:31<04:43,  1.41s/it]Loading train:  30%|██▉       | 85/285 [02:32<04:54,  1.47s/it]Loading train:  30%|███       | 86/285 [02:34<04:57,  1.49s/it]Loading train:  31%|███       | 87/285 [02:36<05:09,  1.56s/it]Loading train:  31%|███       | 88/285 [02:37<04:49,  1.47s/it]Loading train:  31%|███       | 89/285 [02:39<04:57,  1.52s/it]Loading train:  32%|███▏      | 90/285 [02:40<04:57,  1.52s/it]Loading train:  32%|███▏      | 91/285 [02:42<04:51,  1.51s/it]Loading train:  32%|███▏      | 92/285 [02:43<04:55,  1.53s/it]Loading train:  33%|███▎      | 93/285 [02:45<04:58,  1.55s/it]Loading train:  33%|███▎      | 94/285 [02:47<05:10,  1.62s/it]Loading train:  33%|███▎      | 95/285 [02:48<04:56,  1.56s/it]Loading train:  34%|███▎      | 96/285 [02:50<05:05,  1.62s/it]Loading train:  34%|███▍      | 97/285 [02:52<05:12,  1.66s/it]Loading train:  34%|███▍      | 98/285 [02:53<04:47,  1.54s/it]Loading train:  35%|███▍      | 99/285 [02:54<04:32,  1.46s/it]Loading train:  35%|███▌      | 100/285 [02:56<04:40,  1.52s/it]Loading train:  35%|███▌      | 101/285 [02:57<04:47,  1.56s/it]Loading train:  36%|███▌      | 102/285 [03:00<05:34,  1.83s/it]Loading train:  36%|███▌      | 103/285 [03:01<05:00,  1.65s/it]Loading train:  36%|███▋      | 104/285 [03:03<04:55,  1.63s/it]Loading train:  37%|███▋      | 105/285 [03:04<04:52,  1.62s/it]Loading train:  37%|███▋      | 106/285 [03:06<04:54,  1.65s/it]Loading train:  38%|███▊      | 107/285 [03:07<04:44,  1.60s/it]Loading train:  38%|███▊      | 108/285 [03:09<05:03,  1.71s/it]Loading train:  38%|███▊      | 109/285 [03:12<05:31,  1.89s/it]Loading train:  39%|███▊      | 110/285 [03:13<05:13,  1.79s/it]Loading train:  39%|███▉      | 111/285 [03:15<05:10,  1.78s/it]Loading train:  39%|███▉      | 112/285 [03:17<05:10,  1.80s/it]Loading train:  40%|███▉      | 113/285 [03:18<04:57,  1.73s/it]Loading train:  40%|████      | 114/285 [03:20<04:49,  1.69s/it]Loading train:  40%|████      | 115/285 [03:22<05:03,  1.78s/it]Loading train:  41%|████      | 116/285 [03:24<05:10,  1.84s/it]Loading train:  41%|████      | 117/285 [03:25<04:34,  1.63s/it]Loading train:  41%|████▏     | 118/285 [03:27<04:28,  1.61s/it]Loading train:  42%|████▏     | 119/285 [03:28<04:22,  1.58s/it]Loading train:  42%|████▏     | 120/285 [03:30<04:34,  1.67s/it]Loading train:  42%|████▏     | 121/285 [03:32<04:31,  1.66s/it]Loading train:  43%|████▎     | 122/285 [03:33<04:28,  1.65s/it]Loading train:  43%|████▎     | 123/285 [03:35<04:37,  1.71s/it]Loading train:  44%|████▎     | 124/285 [03:37<04:26,  1.66s/it]Loading train:  44%|████▍     | 125/285 [03:38<04:08,  1.56s/it]Loading train:  44%|████▍     | 126/285 [03:40<04:10,  1.58s/it]Loading train:  45%|████▍     | 127/285 [03:41<03:52,  1.47s/it]Loading train:  45%|████▍     | 128/285 [03:42<03:43,  1.42s/it]Loading train:  45%|████▌     | 129/285 [03:43<03:33,  1.37s/it]Loading train:  46%|████▌     | 130/285 [03:45<03:36,  1.40s/it]Loading train:  46%|████▌     | 131/285 [03:46<03:29,  1.36s/it]Loading train:  46%|████▋     | 132/285 [03:48<03:40,  1.44s/it]Loading train:  47%|████▋     | 133/285 [03:49<03:37,  1.43s/it]Loading train:  47%|████▋     | 134/285 [03:51<03:38,  1.45s/it]Loading train:  47%|████▋     | 135/285 [03:52<03:29,  1.40s/it]Loading train:  48%|████▊     | 136/285 [03:53<03:31,  1.42s/it]Loading train:  48%|████▊     | 137/285 [03:55<03:31,  1.43s/it]Loading train:  48%|████▊     | 138/285 [03:56<03:23,  1.39s/it]Loading train:  49%|████▉     | 139/285 [03:58<03:30,  1.45s/it]Loading train:  49%|████▉     | 140/285 [03:59<03:31,  1.46s/it]Loading train:  49%|████▉     | 141/285 [04:00<03:08,  1.31s/it]Loading train:  50%|████▉     | 142/285 [04:02<03:23,  1.42s/it]Loading train:  50%|█████     | 143/285 [04:03<03:17,  1.39s/it]Loading train:  51%|█████     | 144/285 [04:04<03:00,  1.28s/it]Loading train:  51%|█████     | 145/285 [04:05<02:51,  1.23s/it]Loading train:  51%|█████     | 146/285 [04:07<02:49,  1.22s/it]Loading train:  52%|█████▏    | 147/285 [04:08<02:42,  1.18s/it]Loading train:  52%|█████▏    | 148/285 [04:09<02:59,  1.31s/it]Loading train:  52%|█████▏    | 149/285 [04:10<02:43,  1.20s/it]Loading train:  53%|█████▎    | 150/285 [04:11<02:38,  1.17s/it]Loading train:  53%|█████▎    | 151/285 [04:12<02:23,  1.07s/it]Loading train:  53%|█████▎    | 152/285 [04:13<02:15,  1.02s/it]Loading train:  54%|█████▎    | 153/285 [04:14<02:19,  1.06s/it]Loading train:  54%|█████▍    | 154/285 [04:15<02:11,  1.00s/it]Loading train:  54%|█████▍    | 155/285 [04:16<02:13,  1.03s/it]Loading train:  55%|█████▍    | 156/285 [04:17<02:16,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [04:18<02:11,  1.02s/it]Loading train:  55%|█████▌    | 158/285 [04:19<02:11,  1.03s/it]Loading train:  56%|█████▌    | 159/285 [04:20<02:02,  1.03it/s]Loading train:  56%|█████▌    | 160/285 [04:21<02:09,  1.04s/it]Loading train:  56%|█████▋    | 161/285 [04:22<02:05,  1.01s/it]Loading train:  57%|█████▋    | 162/285 [04:23<02:00,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [04:24<02:01,  1.01it/s]Loading train:  58%|█████▊    | 164/285 [04:25<01:59,  1.01it/s]Loading train:  58%|█████▊    | 165/285 [04:26<01:58,  1.01it/s]Loading train:  58%|█████▊    | 166/285 [04:27<01:59,  1.01s/it]Loading train:  59%|█████▊    | 167/285 [04:28<02:00,  1.02s/it]Loading train:  59%|█████▉    | 168/285 [04:29<01:56,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [04:30<01:57,  1.01s/it]Loading train:  60%|█████▉    | 170/285 [04:31<01:49,  1.05it/s]Loading train:  60%|██████    | 171/285 [04:32<01:53,  1.01it/s]Loading train:  60%|██████    | 172/285 [04:33<01:54,  1.01s/it]Loading train:  61%|██████    | 173/285 [04:34<01:49,  1.02it/s]Loading train:  61%|██████    | 174/285 [04:35<01:48,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [04:36<01:53,  1.03s/it]Loading train:  62%|██████▏   | 176/285 [04:37<01:46,  1.02it/s]Loading train:  62%|██████▏   | 177/285 [04:38<01:49,  1.01s/it]Loading train:  62%|██████▏   | 178/285 [04:39<01:42,  1.04it/s]Loading train:  63%|██████▎   | 179/285 [04:40<01:39,  1.06it/s]Loading train:  63%|██████▎   | 180/285 [04:41<01:43,  1.02it/s]Loading train:  64%|██████▎   | 181/285 [04:42<01:50,  1.07s/it]Loading train:  64%|██████▍   | 182/285 [04:43<01:46,  1.03s/it]Loading train:  64%|██████▍   | 183/285 [04:44<01:45,  1.03s/it]Loading train:  65%|██████▍   | 184/285 [04:45<01:43,  1.02s/it]Loading train:  65%|██████▍   | 185/285 [04:46<01:36,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [04:47<01:47,  1.09s/it]Loading train:  66%|██████▌   | 187/285 [04:48<01:43,  1.06s/it]Loading train:  66%|██████▌   | 188/285 [04:49<01:39,  1.02s/it]Loading train:  66%|██████▋   | 189/285 [04:50<01:32,  1.04it/s]Loading train:  67%|██████▋   | 190/285 [04:51<01:33,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [04:52<01:38,  1.05s/it]Loading train:  67%|██████▋   | 192/285 [04:53<01:35,  1.03s/it]Loading train:  68%|██████▊   | 193/285 [04:54<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [04:55<01:21,  1.12it/s]Loading train:  68%|██████▊   | 195/285 [04:56<01:15,  1.19it/s]Loading train:  69%|██████▉   | 196/285 [04:57<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [04:58<01:17,  1.14it/s]Loading train:  69%|██████▉   | 198/285 [04:59<01:20,  1.09it/s]Loading train:  70%|██████▉   | 199/285 [04:59<01:19,  1.08it/s]Loading train:  70%|███████   | 200/285 [05:00<01:17,  1.10it/s]Loading train:  71%|███████   | 201/285 [05:02<01:22,  1.02it/s]Loading train:  71%|███████   | 202/285 [05:02<01:18,  1.05it/s]Loading train:  71%|███████   | 203/285 [05:03<01:17,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [05:04<01:17,  1.04it/s]Loading train:  72%|███████▏  | 205/285 [05:05<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [05:06<01:18,  1.00it/s]Loading train:  73%|███████▎  | 207/285 [05:08<01:24,  1.08s/it]Loading train:  73%|███████▎  | 208/285 [05:09<01:22,  1.07s/it]Loading train:  73%|███████▎  | 209/285 [05:10<01:21,  1.08s/it]Loading train:  74%|███████▎  | 210/285 [05:11<01:15,  1.01s/it]Loading train:  74%|███████▍  | 211/285 [05:12<01:13,  1.00it/s]Loading train:  74%|███████▍  | 212/285 [05:13<01:15,  1.04s/it]Loading train:  75%|███████▍  | 213/285 [05:14<01:14,  1.04s/it]Loading train:  75%|███████▌  | 214/285 [05:15<01:07,  1.05it/s]Loading train:  75%|███████▌  | 215/285 [05:16<01:14,  1.07s/it]Loading train:  76%|███████▌  | 216/285 [05:17<01:07,  1.02it/s]Loading train:  76%|███████▌  | 217/285 [05:18<01:12,  1.06s/it]Loading train:  76%|███████▋  | 218/285 [05:19<01:10,  1.05s/it]Loading train:  77%|███████▋  | 219/285 [05:20<01:09,  1.06s/it]Loading train:  77%|███████▋  | 220/285 [05:21<01:03,  1.02it/s]Loading train:  78%|███████▊  | 221/285 [05:22<01:01,  1.03it/s]Loading train:  78%|███████▊  | 222/285 [05:23<01:10,  1.12s/it]Loading train:  78%|███████▊  | 223/285 [05:24<01:04,  1.04s/it]Loading train:  79%|███████▊  | 224/285 [05:25<00:58,  1.03it/s]Loading train:  79%|███████▉  | 225/285 [05:26<00:59,  1.02it/s]Loading train:  79%|███████▉  | 226/285 [05:27<01:03,  1.07s/it]Loading train:  80%|███████▉  | 227/285 [05:28<01:02,  1.07s/it]Loading train:  80%|████████  | 228/285 [05:29<00:59,  1.04s/it]Loading train:  80%|████████  | 229/285 [05:30<00:55,  1.00it/s]Loading train:  81%|████████  | 230/285 [05:31<00:54,  1.01it/s]Loading train:  81%|████████  | 231/285 [05:32<00:53,  1.01it/s]Loading train:  81%|████████▏ | 232/285 [05:33<00:54,  1.03s/it]Loading train:  82%|████████▏ | 233/285 [05:34<00:50,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [05:35<00:55,  1.09s/it]Loading train:  82%|████████▏ | 235/285 [05:36<00:50,  1.01s/it]Loading train:  83%|████████▎ | 236/285 [05:37<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [05:38<00:50,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [05:40<00:52,  1.11s/it]Loading train:  84%|████████▍ | 239/285 [05:41<00:49,  1.07s/it]Loading train:  84%|████████▍ | 240/285 [05:42<00:47,  1.05s/it]Loading train:  85%|████████▍ | 241/285 [05:43<00:43,  1.01it/s]Loading train:  85%|████████▍ | 242/285 [05:43<00:40,  1.07it/s]Loading train:  85%|████████▌ | 243/285 [05:44<00:39,  1.06it/s]Loading train:  86%|████████▌ | 244/285 [05:45<00:41,  1.01s/it]Loading train:  86%|████████▌ | 245/285 [05:46<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [05:47<00:38,  1.01it/s]Loading train:  87%|████████▋ | 247/285 [05:48<00:38,  1.01s/it]Loading train:  87%|████████▋ | 248/285 [05:49<00:35,  1.03it/s]Loading train:  87%|████████▋ | 249/285 [05:50<00:35,  1.02it/s]Loading train:  88%|████████▊ | 250/285 [05:51<00:34,  1.02it/s]Loading train:  88%|████████▊ | 251/285 [05:52<00:34,  1.00s/it]Loading train:  88%|████████▊ | 252/285 [05:53<00:34,  1.04s/it]Loading train:  89%|████████▉ | 253/285 [05:55<00:34,  1.09s/it]Loading train:  89%|████████▉ | 254/285 [05:56<00:33,  1.08s/it]Loading train:  89%|████████▉ | 255/285 [05:57<00:30,  1.03s/it]Loading train:  90%|████████▉ | 256/285 [05:58<00:28,  1.01it/s]Loading train:  90%|█████████ | 257/285 [05:59<00:28,  1.00s/it]Loading train:  91%|█████████ | 258/285 [06:00<00:26,  1.01it/s]Loading train:  91%|█████████ | 259/285 [06:01<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [06:02<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [06:03<00:24,  1.02s/it]Loading train:  92%|█████████▏| 262/285 [06:04<00:22,  1.01it/s]Loading train:  92%|█████████▏| 263/285 [06:05<00:22,  1.01s/it]Loading train:  93%|█████████▎| 264/285 [06:06<00:23,  1.10s/it]Loading train:  93%|█████████▎| 265/285 [06:08<00:26,  1.31s/it]Loading train:  93%|█████████▎| 266/285 [06:09<00:22,  1.17s/it]Loading train:  94%|█████████▎| 267/285 [06:09<00:19,  1.07s/it]Loading train:  94%|█████████▍| 268/285 [06:10<00:17,  1.02s/it]Loading train:  94%|█████████▍| 269/285 [06:11<00:15,  1.01it/s]Loading train:  95%|█████████▍| 270/285 [06:12<00:15,  1.01s/it]Loading train:  95%|█████████▌| 271/285 [06:14<00:15,  1.10s/it]Loading train:  95%|█████████▌| 272/285 [06:15<00:14,  1.08s/it]Loading train:  96%|█████████▌| 273/285 [06:16<00:13,  1.12s/it]Loading train:  96%|█████████▌| 274/285 [06:17<00:11,  1.08s/it]Loading train:  96%|█████████▋| 275/285 [06:18<00:11,  1.16s/it]Loading train:  97%|█████████▋| 276/285 [06:19<00:10,  1.15s/it]Loading train:  97%|█████████▋| 277/285 [06:20<00:08,  1.07s/it]Loading train:  98%|█████████▊| 278/285 [06:21<00:06,  1.01it/s]Loading train:  98%|█████████▊| 279/285 [06:22<00:05,  1.04it/s]Loading train:  98%|█████████▊| 280/285 [06:23<00:05,  1.01s/it]Loading train:  99%|█████████▊| 281/285 [06:24<00:03,  1.03it/s]Loading train:  99%|█████████▉| 282/285 [06:25<00:02,  1.02it/s]Loading train:  99%|█████████▉| 283/285 [06:26<00:02,  1.08s/it]Loading train: 100%|█████████▉| 284/285 [06:27<00:01,  1.08s/it]Loading train: 100%|██████████| 285/285 [06:29<00:00,  1.13s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:02, 135.42it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:01, 132.88it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:01, 138.10it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:01, 140.35it/s]concatenating: train:  26%|██▌       | 73/285 [00:00<00:01, 141.54it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:02, 81.39it/s] concatenating: train:  36%|███▌      | 103/285 [00:00<00:01, 97.21it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:01, 106.05it/s]concatenating: train:  48%|████▊     | 136/285 [00:01<00:01, 121.52it/s]concatenating: train:  54%|█████▍    | 155/285 [00:01<00:00, 135.58it/s]concatenating: train:  62%|██████▏   | 177/285 [00:01<00:00, 151.52it/s]concatenating: train:  69%|██████▉   | 197/285 [00:01<00:00, 163.23it/s]concatenating: train:  77%|███████▋  | 219/285 [00:01<00:00, 175.80it/s]concatenating: train:  84%|████████▍ | 239/285 [00:01<00:00, 167.02it/s]concatenating: train:  91%|█████████ | 258/285 [00:01<00:00, 172.82it/s]concatenating: train:  99%|█████████▊| 281/285 [00:01<00:00, 186.21it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 151.58it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.67s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.59s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.54s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 60.40it/s]2019-07-11 04:10:24.126616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:10:24.126702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:10:24.126717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:10:24.126725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:10:24.127119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.08it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.28it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.66it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.09it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.01it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.08it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.84it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.29it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.03it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.86it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.06it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.57it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.50it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.76it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.69it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.38it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.19it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   10820       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 80)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 238,873
Trainable params: 64,113
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 19s - loss: 2.0148 - acc: 0.7606 - mDice: 0.2001 - val_loss: 1.3762 - val_acc: 0.9173 - val_mDice: 0.3270

Epoch 00001: val_mDice improved from -inf to 0.32703, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.7195 - acc: 0.9086 - mDice: 0.4748 - val_loss: 0.6707 - val_acc: 0.9320 - val_mDice: 0.5101

Epoch 00002: val_mDice improved from 0.32703 to 0.51005, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.5382 - acc: 0.9228 - mDice: 0.5693 - val_loss: 0.6467 - val_acc: 0.9390 - val_mDice: 0.5149

Epoch 00003: val_mDice improved from 0.51005 to 0.51487, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.4617 - acc: 0.9339 - mDice: 0.6157 - val_loss: 0.5089 - val_acc: 0.9506 - val_mDice: 0.5898

Epoch 00004: val_mDice improved from 0.51487 to 0.58978, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4213 - acc: 0.9401 - mDice: 0.6421 - val_loss: 0.4940 - val_acc: 0.9508 - val_mDice: 0.6001

Epoch 00005: val_mDice improved from 0.58978 to 0.60010, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.3981 - acc: 0.9433 - mDice: 0.6573 - val_loss: 0.4848 - val_acc: 0.9504 - val_mDice: 0.6070

Epoch 00006: val_mDice improved from 0.60010 to 0.60699, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.3756 - acc: 0.9455 - mDice: 0.6725 - val_loss: 0.4863 - val_acc: 0.9517 - val_mDice: 0.6076

Epoch 00007: val_mDice improved from 0.60699 to 0.60761, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.3609 - acc: 0.9467 - mDice: 0.6829 - val_loss: 0.4694 - val_acc: 0.9539 - val_mDice: 0.6185

Epoch 00008: val_mDice improved from 0.60761 to 0.61851, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.3480 - acc: 0.9480 - mDice: 0.6919 - val_loss: 0.4734 - val_acc: 0.9504 - val_mDice: 0.6133

Epoch 00009: val_mDice did not improve from 0.61851
Epoch 10/300
 - 13s - loss: 0.3377 - acc: 0.9486 - mDice: 0.6993 - val_loss: 0.4821 - val_acc: 0.9511 - val_mDice: 0.6092

Epoch 00010: val_mDice did not improve from 0.61851
Epoch 11/300
 - 13s - loss: 0.3310 - acc: 0.9493 - mDice: 0.7041 - val_loss: 0.4799 - val_acc: 0.9530 - val_mDice: 0.6114

Epoch 00011: val_mDice did not improve from 0.61851
Epoch 12/300
 - 14s - loss: 0.3229 - acc: 0.9499 - mDice: 0.7101 - val_loss: 0.4864 - val_acc: 0.9517 - val_mDice: 0.6081

Epoch 00012: val_mDice did not improve from 0.61851
Epoch 13/300
 - 13s - loss: 0.3154 - acc: 0.9505 - mDice: 0.7155 - val_loss: 0.4627 - val_acc: 0.9526 - val_mDice: 0.6186

Epoch 00013: val_mDice improved from 0.61851 to 0.61858, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 0.3111 - acc: 0.9508 - mDice: 0.7188 - val_loss: 0.4668 - val_acc: 0.9517 - val_mDice: 0.6166

Epoch 00014: val_mDice did not improve from 0.61858
Epoch 15/300
 - 14s - loss: 0.3088 - acc: 0.9512 - mDice: 0.7207 - val_loss: 0.4645 - val_acc: 0.9519 - val_mDice: 0.6177

Epoch 00015: val_mDice did not improve from 0.61858
Epoch 16/300
 - 13s - loss: 0.3005 - acc: 0.9517 - mDice: 0.7267 - val_loss: 0.4665 - val_acc: 0.9516 - val_mDice: 0.6179

Epoch 00016: val_mDice did not improve from 0.61858
Epoch 17/300
 - 13s - loss: 0.2991 - acc: 0.9520 - mDice: 0.7280 - val_loss: 0.4698 - val_acc: 0.9523 - val_mDice: 0.6163

Epoch 00017: val_mDice did not improve from 0.61858
Epoch 18/300
 - 13s - loss: 0.2927 - acc: 0.9523 - mDice: 0.7327 - val_loss: 0.4754 - val_acc: 0.9515 - val_mDice: 0.6126

Epoch 00018: val_mDice did not improve from 0.61858
Epoch 19/300
 - 13s - loss: 0.2884 - acc: 0.9527 - mDice: 0.7358 - val_loss: 0.4784 - val_acc: 0.9518 - val_mDice: 0.6113

Epoch 00019: val_mDice did not improve from 0.61858
Epoch 20/300
 - 14s - loss: 0.2868 - acc: 0.9528 - mDice: 0.7372 - val_loss: 0.4704 - val_acc: 0.9530 - val_mDice: 0.6151

Epoch 00020: val_mDice did not improve from 0.61858
Epoch 21/300
 - 13s - loss: 0.2863 - acc: 0.9530 - mDice: 0.7377 - val_loss: 0.5220 - val_acc: 0.9513 - val_mDice: 0.5898

Epoch 00021: val_mDice did not improve from 0.61858
Epoch 22/300
 - 14s - loss: 0.2907 - acc: 0.9532 - mDice: 0.7394 - val_loss: 0.4623 - val_acc: 0.9523 - val_mDice: 0.6208

Epoch 00022: val_mDice improved from 0.61858 to 0.62076, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 14s - loss: 0.2794 - acc: 0.9535 - mDice: 0.7430 - val_loss: 0.4610 - val_acc: 0.9511 - val_mDice: 0.6216

Epoch 00023: val_mDice improved from 0.62076 to 0.62159, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 13s - loss: 0.2755 - acc: 0.9537 - mDice: 0.7460 - val_loss: 0.4955 - val_acc: 0.9537 - val_mDice: 0.6078

Epoch 00024: val_mDice did not improve from 0.62159
Epoch 25/300
 - 14s - loss: 0.2721 - acc: 0.9540 - mDice: 0.7485 - val_loss: 0.4593 - val_acc: 0.9531 - val_mDice: 0.6211

Epoch 00025: val_mDice did not improve from 0.62159
Epoch 26/300
 - 13s - loss: 0.2719 - acc: 0.9540 - mDice: 0.7487 - val_loss: 0.4617 - val_acc: 0.9542 - val_mDice: 0.6215

Epoch 00026: val_mDice did not improve from 0.62159
Epoch 27/300
 - 13s - loss: 0.2695 - acc: 0.9541 - mDice: 0.7506 - val_loss: 0.4756 - val_acc: 0.9542 - val_mDice: 0.6150

Epoch 00027: val_mDice did not improve from 0.62159
Epoch 28/300
 - 13s - loss: 0.2681 - acc: 0.9543 - mDice: 0.7516 - val_loss: 0.4763 - val_acc: 0.9548 - val_mDice: 0.6140

Epoch 00028: val_mDice did not improve from 0.62159
Epoch 29/300
 - 14s - loss: 0.2655 - acc: 0.9545 - mDice: 0.7537 - val_loss: 0.4694 - val_acc: 0.9538 - val_mDice: 0.6181

Epoch 00029: val_mDice did not improve from 0.62159
Epoch 30/300
 - 14s - loss: 0.2648 - acc: 0.9546 - mDice: 0.7544 - val_loss: 0.4815 - val_acc: 0.9521 - val_mDice: 0.6110

Epoch 00030: val_mDice did not improve from 0.62159
Epoch 31/300
 - 13s - loss: 0.2614 - acc: 0.9548 - mDice: 0.7570 - val_loss: 0.4821 - val_acc: 0.9528 - val_mDice: 0.6107

Epoch 00031: val_mDice did not improve from 0.62159
Epoch 32/300
 - 14s - loss: 0.2706 - acc: 0.9539 - mDice: 0.7500 - val_loss: 0.5028 - val_acc: 0.9527 - val_mDice: 0.6030

Epoch 00032: val_mDice did not improve from 0.62159
Epoch 33/300
 - 13s - loss: 0.2599 - acc: 0.9550 - mDice: 0.7583 - val_loss: 0.4787 - val_acc: 0.9532 - val_mDice: 0.6120

Epoch 00033: val_mDice did not improve from 0.62159
Epoch 34/300
 - 14s - loss: 0.2570 - acc: 0.9551 - mDice: 0.7605 - val_loss: 0.4687 - val_acc: 0.9545 - val_mDice: 0.6174

Epoch 00034: val_mDice did not improve from 0.62159
Epoch 35/300
 - 13s - loss: 0.2545 - acc: 0.9553 - mDice: 0.7625 - val_loss: 0.4758 - val_acc: 0.9542 - val_mDice: 0.6138

Epoch 00035: val_mDice did not improve from 0.62159
Epoch 36/300
 - 14s - loss: 0.2545 - acc: 0.9554 - mDice: 0.7625 - val_loss: 0.4973 - val_acc: 0.9533 - val_mDice: 0.6059

Epoch 00036: val_mDice did not improve from 0.62159
Epoch 37/300
 - 14s - loss: 0.2920 - acc: 0.9529 - mDice: 0.7385 - val_loss: 0.5362 - val_acc: 0.9510 - val_mDice: 0.5751

Epoch 00037: val_mDice did not improve from 0.62159
Epoch 38/300
 - 13s - loss: 0.2723 - acc: 0.9538 - mDice: 0.7482 - val_loss: 0.4868 - val_acc: 0.9538 - val_mDice: 0.6082

Epoch 00038: val_mDice did not improve from 0.62159
Epoch 39/300
 - 14s - loss: 0.2588 - acc: 0.9549 - mDice: 0.7590 - val_loss: 0.4769 - val_acc: 0.9531 - val_mDice: 0.6138

Epoch 00039: val_mDice did not improve from 0.62159
Epoch 40/300
 - 13s - loss: 0.2555 - acc: 0.9553 - mDice: 0.7616 - val_loss: 0.4750 - val_acc: 0.9516 - val_mDice: 0.6136

Epoch 00040: val_mDice did not improve from 0.62159
Epoch 41/300
 - 14s - loss: 0.2512 - acc: 0.9555 - mDice: 0.7651 - val_loss: 0.4958 - val_acc: 0.9539 - val_mDice: 0.6069

Epoch 00041: val_mDice did not improve from 0.62159
Epoch 42/300
 - 13s - loss: 0.2492 - acc: 0.9557 - mDice: 0.7667 - val_loss: 0.4827 - val_acc: 0.9546 - val_mDice: 0.6117

Epoch 00042: val_mDice did not improve from 0.62159
Epoch 43/300
 - 14s - loss: 0.2490 - acc: 0.9557 - mDice: 0.7669 - val_loss: 0.4889 - val_acc: 0.9536 - val_mDice: 0.6093

Epoch 00043: val_mDice did not improve from 0.62159
Epoch 44/300
 - 13s - loss: 0.2488 - acc: 0.9558 - mDice: 0.7670 - val_loss: 0.4668 - val_acc: 0.9540 - val_mDice: 0.6210

Epoch 00044: val_mDice did not improve from 0.62159
Epoch 45/300
 - 14s - loss: 0.2466 - acc: 0.9559 - mDice: 0.7688 - val_loss: 0.4906 - val_acc: 0.9523 - val_mDice: 0.6073

Epoch 00045: val_mDice did not improve from 0.62159
Epoch 46/300
 - 13s - loss: 0.2462 - acc: 0.9559 - mDice: 0.7691 - val_loss: 0.4756 - val_acc: 0.9507 - val_mDice: 0.6144

Epoch 00046: val_mDice did not improve from 0.62159
Epoch 47/300
 - 14s - loss: 0.2449 - acc: 0.9560 - mDice: 0.7702 - val_loss: 0.4802 - val_acc: 0.9548 - val_mDice: 0.6106

Epoch 00047: val_mDice did not improve from 0.62159
Epoch 48/300
 - 13s - loss: 0.2418 - acc: 0.9562 - mDice: 0.7726 - val_loss: 0.4707 - val_acc: 0.9544 - val_mDice: 0.6180

Epoch 00048: val_mDice did not improve from 0.62159
Epoch 49/300
 - 13s - loss: 0.2418 - acc: 0.9562 - mDice: 0.7727 - val_loss: 0.4844 - val_acc: 0.9546 - val_mDice: 0.6095

Epoch 00049: val_mDice did not improve from 0.62159
Epoch 50/300
 - 14s - loss: 0.2420 - acc: 0.9562 - mDice: 0.7725 - val_loss: 0.4807 - val_acc: 0.9530 - val_mDice: 0.6115

Epoch 00050: val_mDice did not improve from 0.62159
Epoch 51/300
 - 13s - loss: 0.2385 - acc: 0.9564 - mDice: 0.7753 - val_loss: 0.4735 - val_acc: 0.9542 - val_mDice: 0.6149

Epoch 00051: val_mDice did not improve from 0.62159
Epoch 52/300
 - 14s - loss: 0.2407 - acc: 0.9564 - mDice: 0.7736 - val_loss: 0.4899 - val_acc: 0.9528 - val_mDice: 0.6087

Epoch 00052: val_mDice did not improve from 0.62159
Epoch 53/300
 - 13s - loss: 0.2408 - acc: 0.9564 - mDice: 0.7735 - val_loss: 0.5090 - val_acc: 0.9522 - val_mDice: 0.5973

Epoch 00053: val_mDice did not improve from 0.62159
Epoch 54/300
 - 14s - loss: 0.2392 - acc: 0.9564 - mDice: 0.7749 - val_loss: 0.4968 - val_acc: 0.9534 - val_mDice: 0.6051

Epoch 00054: val_mDice did not improve from 0.62159
Epoch 55/300
 - 13s - loss: 0.2379 - acc: 0.9566 - mDice: 0.7759 - val_loss: 0.5163 - val_acc: 0.9528 - val_mDice: 0.5957

Epoch 00055: val_mDice did not improve from 0.62159
Epoch 56/300
 - 14s - loss: 0.2361 - acc: 0.9567 - mDice: 0.7773 - val_loss: 0.4856 - val_acc: 0.9543 - val_mDice: 0.6115

Epoch 00056: val_mDice did not improve from 0.62159
Epoch 57/300
 - 13s - loss: 0.2377 - acc: 0.9566 - mDice: 0.7763 - val_loss: 0.5025 - val_acc: 0.9532 - val_mDice: 0.6015

Epoch 00057: val_mDice did not improve from 0.62159
Epoch 58/300
 - 13s - loss: 0.2353 - acc: 0.9567 - mDice: 0.7780 - val_loss: 0.4869 - val_acc: 0.9537 - val_mDice: 0.6080

Epoch 00058: val_mDice did not improve from 0.62159
Epoch 59/300
 - 14s - loss: 0.2350 - acc: 0.9568 - mDice: 0.7782 - val_loss: 0.5056 - val_acc: 0.9522 - val_mDice: 0.5984

Epoch 00059: val_mDice did not improve from 0.62159
Epoch 60/300
 - 13s - loss: 0.2330 - acc: 0.9569 - mDice: 0.7798 - val_loss: 0.4839 - val_acc: 0.9537 - val_mDice: 0.6131

Epoch 00060: val_mDice did not improve from 0.62159
Epoch 61/300
 - 14s - loss: 0.2351 - acc: 0.9568 - mDice: 0.7781 - val_loss: 0.4834 - val_acc: 0.9508 - val_mDice: 0.6095

Epoch 00061: val_mDice did not improve from 0.62159
Epoch 62/300
 - 13s - loss: 0.2338 - acc: 0.9568 - mDice: 0.7792 - val_loss: 0.4978 - val_acc: 0.9534 - val_mDice: 0.6027

Epoch 00062: val_mDice did not improve from 0.62159
Epoch 63/300
 - 14s - loss: 0.2319 - acc: 0.9570 - mDice: 0.7807 - val_loss: 0.4861 - val_acc: 0.9534 - val_mDice: 0.6086

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.43s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:14,  2.16s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:24,  1.99s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:09,  1.95s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:24,  1.79s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:47,  1.89s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:26,  1.81s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:34,  1.85s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:36,  1.86s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<09:05,  1.98s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:46,  2.13s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:13,  2.02s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:43,  2.14s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:13,  2.03s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:17,  2.06s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:50,  2.20s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:20,  2.09s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<09:08,  2.05s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:13,  2.08s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:26,  2.14s/it]predicting train subjects:   7%|▋         | 21/285 [00:42<09:42,  2.21s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:11,  2.10s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:04,  2.08s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<08:40,  1.99s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<09:04,  2.09s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:22,  2.17s/it]predicting train subjects:   9%|▉         | 27/285 [00:54<08:54,  2.07s/it]predicting train subjects:  10%|▉         | 28/285 [00:56<08:51,  2.07s/it]predicting train subjects:  10%|█         | 29/285 [00:59<08:53,  2.08s/it]predicting train subjects:  11%|█         | 30/285 [01:01<09:09,  2.16s/it]predicting train subjects:  11%|█         | 31/285 [01:04<09:47,  2.31s/it]predicting train subjects:  11%|█         | 32/285 [01:05<09:08,  2.17s/it]predicting train subjects:  12%|█▏        | 33/285 [01:07<09:00,  2.15s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<09:03,  2.17s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<09:18,  2.23s/it]predicting train subjects:  13%|█▎        | 36/285 [01:14<08:43,  2.10s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:50,  2.14s/it]predicting train subjects:  13%|█▎        | 38/285 [01:18<08:53,  2.16s/it]predicting train subjects:  14%|█▎        | 39/285 [01:21<09:12,  2.25s/it]predicting train subjects:  14%|█▍        | 40/285 [01:23<09:35,  2.35s/it]predicting train subjects:  14%|█▍        | 41/285 [01:26<09:43,  2.39s/it]predicting train subjects:  15%|█▍        | 42/285 [01:28<09:20,  2.31s/it]predicting train subjects:  15%|█▌        | 43/285 [01:30<09:33,  2.37s/it]predicting train subjects:  15%|█▌        | 44/285 [01:33<09:39,  2.40s/it]predicting train subjects:  16%|█▌        | 45/285 [01:35<09:24,  2.35s/it]predicting train subjects:  16%|█▌        | 46/285 [01:38<10:02,  2.52s/it]predicting train subjects:  16%|█▋        | 47/285 [01:41<09:58,  2.52s/it]predicting train subjects:  17%|█▋        | 48/285 [01:43<09:38,  2.44s/it]predicting train subjects:  17%|█▋        | 49/285 [01:46<09:59,  2.54s/it]predicting train subjects:  18%|█▊        | 50/285 [01:48<09:59,  2.55s/it]predicting train subjects:  18%|█▊        | 51/285 [01:51<10:13,  2.62s/it]predicting train subjects:  18%|█▊        | 52/285 [01:53<09:39,  2.49s/it]predicting train subjects:  19%|█▊        | 53/285 [01:56<09:29,  2.46s/it]predicting train subjects:  19%|█▉        | 54/285 [01:58<09:28,  2.46s/it]predicting train subjects:  19%|█▉        | 55/285 [02:00<08:54,  2.32s/it]predicting train subjects:  20%|█▉        | 56/285 [02:03<09:03,  2.37s/it]predicting train subjects:  20%|██        | 57/285 [02:05<08:57,  2.36s/it]predicting train subjects:  20%|██        | 58/285 [02:07<09:00,  2.38s/it]predicting train subjects:  21%|██        | 59/285 [02:10<09:43,  2.58s/it]predicting train subjects:  21%|██        | 60/285 [02:13<09:51,  2.63s/it]predicting train subjects:  21%|██▏       | 61/285 [02:15<09:29,  2.54s/it]predicting train subjects:  22%|██▏       | 62/285 [02:18<09:18,  2.51s/it]predicting train subjects:  22%|██▏       | 63/285 [02:20<09:04,  2.45s/it]predicting train subjects:  22%|██▏       | 64/285 [02:23<09:05,  2.47s/it]predicting train subjects:  23%|██▎       | 65/285 [02:25<08:51,  2.42s/it]predicting train subjects:  23%|██▎       | 66/285 [02:27<08:48,  2.41s/it]predicting train subjects:  24%|██▎       | 67/285 [02:30<08:30,  2.34s/it]predicting train subjects:  24%|██▍       | 68/285 [02:32<08:05,  2.24s/it]predicting train subjects:  24%|██▍       | 69/285 [02:34<07:52,  2.19s/it]predicting train subjects:  25%|██▍       | 70/285 [02:36<07:56,  2.22s/it]predicting train subjects:  25%|██▍       | 71/285 [02:38<07:59,  2.24s/it]predicting train subjects:  25%|██▌       | 72/285 [02:40<07:55,  2.23s/it]predicting train subjects:  26%|██▌       | 73/285 [02:43<08:13,  2.33s/it]predicting train subjects:  26%|██▌       | 74/285 [02:45<08:22,  2.38s/it]predicting train subjects:  26%|██▋       | 75/285 [02:48<08:36,  2.46s/it]predicting train subjects:  27%|██▋       | 76/285 [02:51<08:32,  2.45s/it]predicting train subjects:  27%|██▋       | 77/285 [02:53<08:37,  2.49s/it]predicting train subjects:  27%|██▋       | 78/285 [02:55<08:03,  2.33s/it]predicting train subjects:  28%|██▊       | 79/285 [02:57<07:47,  2.27s/it]predicting train subjects:  28%|██▊       | 80/285 [02:59<07:37,  2.23s/it]predicting train subjects:  28%|██▊       | 81/285 [03:01<07:21,  2.16s/it]predicting train subjects:  29%|██▉       | 82/285 [03:03<07:16,  2.15s/it]predicting train subjects:  29%|██▉       | 83/285 [03:06<07:22,  2.19s/it]predicting train subjects:  29%|██▉       | 84/285 [03:08<07:18,  2.18s/it]predicting train subjects:  30%|██▉       | 85/285 [03:10<07:03,  2.12s/it]predicting train subjects:  30%|███       | 86/285 [03:12<06:55,  2.09s/it]predicting train subjects:  31%|███       | 87/285 [03:14<06:59,  2.12s/it]predicting train subjects:  31%|███       | 88/285 [03:16<06:57,  2.12s/it]predicting train subjects:  31%|███       | 89/285 [03:18<06:51,  2.10s/it]predicting train subjects:  32%|███▏      | 90/285 [03:21<07:07,  2.19s/it]predicting train subjects:  32%|███▏      | 91/285 [03:23<07:11,  2.22s/it]predicting train subjects:  32%|███▏      | 92/285 [03:25<07:08,  2.22s/it]predicting train subjects:  33%|███▎      | 93/285 [03:28<07:29,  2.34s/it]predicting train subjects:  33%|███▎      | 94/285 [03:30<07:29,  2.35s/it]predicting train subjects:  33%|███▎      | 95/285 [03:33<07:26,  2.35s/it]predicting train subjects:  34%|███▎      | 96/285 [03:35<07:41,  2.44s/it]predicting train subjects:  34%|███▍      | 97/285 [03:38<07:46,  2.48s/it]predicting train subjects:  34%|███▍      | 98/285 [03:40<07:50,  2.52s/it]predicting train subjects:  35%|███▍      | 99/285 [03:43<07:33,  2.44s/it]predicting train subjects:  35%|███▌      | 100/285 [03:45<07:20,  2.38s/it]predicting train subjects:  35%|███▌      | 101/285 [03:47<07:18,  2.39s/it]predicting train subjects:  36%|███▌      | 102/285 [03:50<07:33,  2.48s/it]predicting train subjects:  36%|███▌      | 103/285 [03:53<07:59,  2.64s/it]predicting train subjects:  36%|███▋      | 104/285 [03:56<07:57,  2.64s/it]predicting train subjects:  37%|███▋      | 105/285 [03:58<07:35,  2.53s/it]predicting train subjects:  37%|███▋      | 106/285 [04:00<07:22,  2.47s/it]predicting train subjects:  38%|███▊      | 107/285 [04:03<07:14,  2.44s/it]predicting train subjects:  38%|███▊      | 108/285 [04:05<07:01,  2.38s/it]predicting train subjects:  38%|███▊      | 109/285 [04:07<07:10,  2.45s/it]predicting train subjects:  39%|███▊      | 110/285 [04:10<07:00,  2.40s/it]predicting train subjects:  39%|███▉      | 111/285 [04:12<07:02,  2.43s/it]predicting train subjects:  39%|███▉      | 112/285 [04:14<06:52,  2.38s/it]predicting train subjects:  40%|███▉      | 113/285 [04:17<07:05,  2.47s/it]predicting train subjects:  40%|████      | 114/285 [04:19<06:53,  2.42s/it]predicting train subjects:  40%|████      | 115/285 [04:22<06:33,  2.32s/it]predicting train subjects:  41%|████      | 116/285 [04:24<06:18,  2.24s/it]predicting train subjects:  41%|████      | 117/285 [04:26<06:15,  2.23s/it]predicting train subjects:  41%|████▏     | 118/285 [04:28<06:04,  2.18s/it]predicting train subjects:  42%|████▏     | 119/285 [04:30<06:06,  2.21s/it]predicting train subjects:  42%|████▏     | 120/285 [04:32<06:06,  2.22s/it]predicting train subjects:  42%|████▏     | 121/285 [04:35<06:04,  2.22s/it]predicting train subjects:  43%|████▎     | 122/285 [04:37<05:51,  2.16s/it]predicting train subjects:  43%|████▎     | 123/285 [04:39<05:37,  2.08s/it]predicting train subjects:  44%|████▎     | 124/285 [04:40<05:26,  2.03s/it]predicting train subjects:  44%|████▍     | 125/285 [04:43<05:26,  2.04s/it]predicting train subjects:  44%|████▍     | 126/285 [04:45<05:54,  2.23s/it]predicting train subjects:  45%|████▍     | 127/285 [04:47<05:39,  2.15s/it]predicting train subjects:  45%|████▍     | 128/285 [04:49<05:32,  2.12s/it]predicting train subjects:  45%|████▌     | 129/285 [04:51<05:17,  2.03s/it]predicting train subjects:  46%|████▌     | 130/285 [04:53<05:09,  2.00s/it]predicting train subjects:  46%|████▌     | 131/285 [04:55<04:48,  1.87s/it]predicting train subjects:  46%|████▋     | 132/285 [04:57<05:17,  2.08s/it]predicting train subjects:  47%|████▋     | 133/285 [04:59<05:16,  2.08s/it]predicting train subjects:  47%|████▋     | 134/285 [05:01<05:17,  2.10s/it]predicting train subjects:  47%|████▋     | 135/285 [05:03<05:06,  2.04s/it]predicting train subjects:  48%|████▊     | 136/285 [05:05<04:56,  1.99s/it]predicting train subjects:  48%|████▊     | 137/285 [05:07<04:49,  1.95s/it]predicting train subjects:  48%|████▊     | 138/285 [05:09<04:43,  1.93s/it]predicting train subjects:  49%|████▉     | 139/285 [05:11<04:49,  1.98s/it]predicting train subjects:  49%|████▉     | 140/285 [05:13<04:52,  2.02s/it]predicting train subjects:  49%|████▉     | 141/285 [05:15<04:37,  1.93s/it]predicting train subjects:  50%|████▉     | 142/285 [05:17<04:45,  2.00s/it]predicting train subjects:  50%|█████     | 143/285 [05:19<04:39,  1.97s/it]predicting train subjects:  51%|█████     | 144/285 [05:21<04:37,  1.97s/it]predicting train subjects:  51%|█████     | 145/285 [05:23<04:27,  1.91s/it]predicting train subjects:  51%|█████     | 146/285 [05:25<04:29,  1.94s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:26<04:18,  1.87s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:28<04:26,  1.95s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:30<04:27,  1.96s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:32<04:15,  1.89s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:34<04:16,  1.91s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:36<04:01,  1.82s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:38<04:06,  1.87s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:40<04:22,  2.01s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:42<04:09,  1.92s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:44<04:16,  1.99s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:46<04:22,  2.05s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:48<04:21,  2.06s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:50<04:11,  2.00s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:52<04:10,  2.00s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:54<04:19,  2.09s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:56<03:59,  1.95s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:58<04:14,  2.09s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:00<04:11,  2.08s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:02<04:05,  2.05s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:04<04:04,  2.06s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:07<04:09,  2.11s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:08<03:48,  1.95s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:10<03:41,  1.91s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:12<03:39,  1.91s/it]predicting train subjects:  60%|██████    | 171/285 [06:14<03:35,  1.89s/it]predicting train subjects:  60%|██████    | 172/285 [06:15<03:24,  1.81s/it]predicting train subjects:  61%|██████    | 173/285 [06:17<03:23,  1.82s/it]predicting train subjects:  61%|██████    | 174/285 [06:19<03:11,  1.73s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:21<03:20,  1.82s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:23<03:13,  1.77s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:24<03:05,  1.72s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:26<02:57,  1.66s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:27<03:02,  1.72s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:30<03:12,  1.83s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:32<03:13,  1.86s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:33<03:12,  1.87s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:35<03:02,  1.79s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:37<02:55,  1.74s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:38<02:53,  1.74s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:40<03:03,  1.85s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:43<03:10,  1.94s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:45<03:09,  1.95s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:46<02:54,  1.81s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:48<02:42,  1.71s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:49<02:39,  1.70s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:51<02:43,  1.76s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:53<02:45,  1.80s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:55<02:36,  1.72s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:56<02:33,  1.71s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:58<02:41,  1.81s/it]predicting train subjects:  69%|██████▉   | 197/285 [07:00<02:46,  1.90s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:02<02:49,  1.94s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:04<02:36,  1.82s/it]predicting train subjects:  70%|███████   | 200/285 [07:06<02:30,  1.77s/it]predicting train subjects:  71%|███████   | 201/285 [07:08<02:34,  1.84s/it]predicting train subjects:  71%|███████   | 202/285 [07:09<02:31,  1.83s/it]predicting train subjects:  71%|███████   | 203/285 [07:11<02:29,  1.82s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:13<02:18,  1.72s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:14<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:16<02:10,  1.65s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:18<02:18,  1.78s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:20<02:23,  1.87s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:22<02:28,  1.96s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:24<02:17,  1.84s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:26<02:14,  1.82s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:28<02:18,  1.89s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:29<02:14,  1.87s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:31<02:08,  1.80s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:33<02:08,  1.83s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:35<02:05,  1.82s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:37<02:10,  1.91s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:39<02:12,  1.98s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:41<02:14,  2.04s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:43<02:08,  1.97s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:45<01:58,  1.85s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:46<01:55,  1.83s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:48<01:48,  1.75s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:50<01:45,  1.74s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:51<01:39,  1.67s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:53<01:45,  1.79s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:56<01:53,  1.96s/it]predicting train subjects:  80%|████████  | 228/285 [07:58<01:51,  1.96s/it]predicting train subjects:  80%|████████  | 229/285 [07:59<01:44,  1.86s/it]predicting train subjects:  81%|████████  | 230/285 [08:01<01:34,  1.72s/it]predicting train subjects:  81%|████████  | 231/285 [08:02<01:28,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:04<01:28,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:05<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:07<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [08:08<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:10<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:12<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:14<01:25,  1.82s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:16<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:17<01:15,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:19<01:12,  1.64s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:20<01:07,  1.58s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:22<01:06,  1.58s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:24<01:09,  1.69s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:25<01:04,  1.62s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:27<01:07,  1.73s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:29<01:07,  1.78s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:31<01:05,  1.76s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:32<01:00,  1.67s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:34<00:57,  1.64s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:35<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:37<00:53,  1.61s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:39<00:54,  1.71s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:41<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:43<00:53,  1.79s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:44<00:49,  1.72s/it]predicting train subjects:  90%|█████████ | 257/285 [08:46<00:46,  1.66s/it]predicting train subjects:  91%|█████████ | 258/285 [08:48<00:46,  1.71s/it]predicting train subjects:  91%|█████████ | 259/285 [08:49<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [08:51<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:52<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:54<00:36,  1.57s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:55<00:34,  1.56s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:57<00:35,  1.68s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:59<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:01<00:31,  1.65s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:02<00:29,  1.64s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:04<00:29,  1.71s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:06<00:27,  1.71s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:07<00:25,  1.68s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:09<00:23,  1.65s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:11<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:12<00:19,  1.61s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:14<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:16<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:17<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:19<00:13,  1.67s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:21<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:22<00:10,  1.72s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:24<00:08,  1.66s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:25<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:27<00:04,  1.59s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:29<00:03,  1.69s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:31<00:01,  1.79s/it]predicting train subjects: 100%|██████████| 285/285 [09:33<00:00,  1.83s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:30,  1.80s/it]Loading train:   1%|          | 2/285 [00:03<07:57,  1.69s/it]Loading train:   1%|          | 3/285 [00:04<07:33,  1.61s/it]
Epoch 00063: val_mDice did not improve from 0.62159
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
{'val_loss': [1.376189611477559, 0.6706506906274977, 0.6466791233536917, 0.5088805776068618, 0.4940146617383264, 0.484835356973403, 0.4863038485942606, 0.4694203564574599, 0.4734406121616257, 0.4821253475530187, 0.4798826928245289, 0.486445804880984, 0.4627092094394748, 0.466761690278293, 0.46447669893669685, 0.4665210879714795, 0.4698373165876506, 0.4753589923155374, 0.47842486877015183, 0.4704340153566286, 0.5220230717898747, 0.46234213540007946, 0.46096042514513325, 0.49550400765914493, 0.45928276317745614, 0.4617380669663072, 0.47563857139821825, 0.4763334003906676, 0.4693985714592747, 0.4815100980870551, 0.48211542887394654, 0.5027681016389218, 0.47871796079188084, 0.4686599939895076, 0.4758334356313311, 0.49725713510087083, 0.5361585623725167, 0.48679548735059175, 0.4768701189057121, 0.4749930327831034, 0.49578876568618435, 0.4826551868928877, 0.4888690553563933, 0.4668377621213817, 0.49061440522444316, 0.475632639903596, 0.4802397179869966, 0.4706557123354693, 0.4843844181998482, 0.48070992637612964, 0.4734724746736068, 0.48986269142374644, 0.5090342187348691, 0.4968186407115872, 0.5163145048658275, 0.4856182816308304, 0.5025371872512988, 0.4868617743753188, 0.5055558534973826, 0.4839077049127504, 0.4834366310908142, 0.49775920333809026, 0.48612623074867206], 'val_acc': [0.9173477708294405, 0.9320229198679578, 0.9390453969300127, 0.9506276832612534, 0.9508136224480315, 0.9504024729382392, 0.9517350852822458, 0.9539044173070172, 0.9504499738442831, 0.9510636016643247, 0.9529664319986738, 0.9516751439877729, 0.9525800970013582, 0.9517123376190996, 0.9519334109135846, 0.9515635780782007, 0.952309407002433, 0.9514830132436486, 0.9517825895181581, 0.9530449552908956, 0.9512536878692371, 0.9523259461259043, 0.951053287063897, 0.9537494712035749, 0.9530593762850629, 0.9542411888777876, 0.9541585455393659, 0.9548176087480683, 0.9538011371090426, 0.9521028212994836, 0.9528073432059262, 0.9527247231765832, 0.953193700846347, 0.9544725857633453, 0.9542225809070651, 0.953270143969765, 0.9509974624857557, 0.9538362519035126, 0.9530635419504603, 0.9515553269972349, 0.9538961445819066, 0.9545593691271776, 0.9536420153505976, 0.9540304298507435, 0.9523073521406291, 0.9507144503087305, 0.9547680459874969, 0.9544457167220515, 0.9545717658943305, 0.9529684845295698, 0.954189533627899, 0.9528424633281857, 0.9521854646379055, 0.9534498826085522, 0.9528218258026592, 0.954334151478453, 0.9532205425827197, 0.9537308535762339, 0.952245404933418, 0.9536957534331849, 0.9507826113834061, 0.9533796543515595, 0.953404424576786], 'val_mDice': [0.3270318175161351, 0.5100543339159236, 0.5148746211435542, 0.5897789657448923, 0.6001045577352939, 0.6069860947864681, 0.6076113471771751, 0.6185104697110266, 0.613283334497633, 0.6091976039236484, 0.6114460269832078, 0.6080510180089727, 0.6185779891200571, 0.6166066344223875, 0.6177432790148858, 0.6178753522521291, 0.6163345428818431, 0.6125750678211617, 0.6112628515872209, 0.615143998708139, 0.5897745250323632, 0.6207597368922313, 0.6215859498391604, 0.6078136050501349, 0.6210873240199168, 0.6215213437320134, 0.6150240588454561, 0.6139879416487071, 0.618113174451796, 0.6109998639069456, 0.6106797003879227, 0.6030230115911814, 0.6119744105046022, 0.6173517487568563, 0.6137646370093915, 0.6059368838811053, 0.5751473996892321, 0.6082221336204913, 0.6137701179728162, 0.613605444657736, 0.606898185261135, 0.611711038224524, 0.6092737716669477, 0.6209552980668052, 0.6073426534343698, 0.6143551841794446, 0.6105508924196552, 0.6179661754123326, 0.6095426935057401, 0.6114864742289708, 0.6148744398655173, 0.6086841781712111, 0.5973128220222516, 0.605070209702966, 0.5957266132258836, 0.6114714172299348, 0.6014752108291541, 0.608012865708527, 0.5983578546087169, 0.61311197680468, 0.6095481238551645, 0.6027467410657659, 0.6086435344632112], 'loss': [2.0147763090899526, 0.7194990842542736, 0.5381522929023719, 0.4617119468275832, 0.42127853773348045, 0.39809362607274684, 0.375560065498994, 0.36093129685979336, 0.3479773678422383, 0.33768780322306285, 0.3310133042006209, 0.32287376285261543, 0.3153744432169279, 0.3111164520690075, 0.3088067704527137, 0.30049604932068935, 0.2990772911915494, 0.2926919490129793, 0.2884163280391958, 0.28679342306677624, 0.286343601959722, 0.29065011501520016, 0.27944769502744377, 0.27549267375652947, 0.2721432890597138, 0.271892968248512, 0.2694764627340241, 0.2681076331882265, 0.26545321418159207, 0.2647509604755761, 0.2613729703683465, 0.27060123592538843, 0.25988901992274244, 0.2569574918838363, 0.2544983121031906, 0.2545130190980583, 0.29203325112520057, 0.2723349792577753, 0.2588153421362659, 0.25551454333573165, 0.2511549123988082, 0.24915572612492465, 0.24897712995644897, 0.24884079373270446, 0.2465534926947604, 0.2462316932946234, 0.24485879278015477, 0.24177841777817355, 0.24183900798531205, 0.24202927980075103, 0.23852109142452482, 0.24073081918579775, 0.24079043818717363, 0.239213347452852, 0.23790361303047874, 0.23614308678709756, 0.23770688198245915, 0.23529393767182147, 0.23502855840253775, 0.23303096880256258, 0.2351434005181012, 0.23383992201238862, 0.23192135268427383], 'acc': [0.7606446685682461, 0.9086158206978237, 0.9228285148469564, 0.9338502584183621, 0.9400708920996821, 0.9433363741645691, 0.9454565723473052, 0.946749245722461, 0.9480089906948622, 0.9486359869152832, 0.9492821132108982, 0.9498823378432921, 0.9505034078635471, 0.9508175577520578, 0.9512470418913069, 0.951713823258023, 0.9519544983603558, 0.9523467987712501, 0.9526564363437076, 0.9528161204495557, 0.952952762800821, 0.9531759145985592, 0.9535194486907141, 0.9536929498453246, 0.9539995301030156, 0.9539810212587818, 0.9541430974128713, 0.9543296300918862, 0.9545228715380788, 0.9546182011864581, 0.954766505729736, 0.9539416622189705, 0.9549575532666285, 0.9551015228145062, 0.9552951879532766, 0.9553841933836105, 0.952942933725133, 0.953828788181515, 0.9549120332990737, 0.9552781059911948, 0.9555192227801442, 0.9556566921267841, 0.9556779590646891, 0.9558074922968337, 0.9559069531661585, 0.9559028015878944, 0.9560336446224503, 0.9561814205539129, 0.9562013642433831, 0.9562053531026874, 0.9564274564157365, 0.9563631193225313, 0.9563533325229333, 0.9564437893674327, 0.9565654036318462, 0.9566573129325616, 0.9566395265150613, 0.9566682497015395, 0.9567623510579386, 0.9569156317434035, 0.9567695222975583, 0.9568126460876245, 0.9569720679018714], 'mDice': [0.20005938586747035, 0.47481048620706107, 0.5692879900804539, 0.6157327638713306, 0.6420976615674057, 0.657339806825752, 0.6725458300689565, 0.6828592735258532, 0.6918904304400514, 0.6992773644759643, 0.7041323548775795, 0.7100990453217519, 0.7154858693935781, 0.7187870375523542, 0.7206927866212722, 0.7266802952496173, 0.7280198322532678, 0.7326556737954941, 0.7358093791346646, 0.7372210686304596, 0.7376621912704899, 0.7393962124757313, 0.7429892958901844, 0.7459809912698252, 0.7485394461061056, 0.7486879812964076, 0.7506051826019977, 0.7516379538824288, 0.7536902281981033, 0.7543825675742467, 0.7569998775839475, 0.7500228538446181, 0.7583182606358951, 0.7604983129322669, 0.7624632767112769, 0.7624597071523559, 0.7385373280644514, 0.7482335680184635, 0.7589567919441261, 0.7615948553912735, 0.7651166122831373, 0.7667404369106545, 0.7669017726666956, 0.7670099913674654, 0.7688201498630799, 0.7691485252679546, 0.770193206712731, 0.7726332292039438, 0.7726523944069557, 0.7725271709207733, 0.775320510830237, 0.773604217668185, 0.7735250700592027, 0.7748515589240719, 0.775878375005465, 0.7772960625282528, 0.7763485627316953, 0.7779724145206995, 0.7781971286671671, 0.7798471506349233, 0.7781365932602033, 0.7792065170723969, 0.7807243070040943]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label valuesLoading train:   1%|▏         | 4/285 [00:06<07:12,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:07<07:08,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<06:36,  1.42s/it]Loading train:   2%|▏         | 7/285 [00:10<06:46,  1.46s/it]Loading train:   3%|▎         | 8/285 [00:11<06:47,  1.47s/it]Loading train:   3%|▎         | 9/285 [00:13<07:03,  1.53s/it]Loading train:   4%|▎         | 10/285 [00:14<06:15,  1.36s/it]Loading train:   4%|▍         | 11/285 [00:15<05:35,  1.22s/it]Loading train:   4%|▍         | 12/285 [00:16<05:25,  1.19s/it]Loading train:   5%|▍         | 13/285 [00:17<05:15,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:18<05:16,  1.17s/it]Loading train:   5%|▌         | 15/285 [00:19<05:07,  1.14s/it]Loading train:   6%|▌         | 16/285 [00:21<05:18,  1.18s/it]Loading train:   6%|▌         | 17/285 [00:22<05:09,  1.15s/it]Loading train:   6%|▋         | 18/285 [00:23<04:55,  1.11s/it]Loading train:   7%|▋         | 19/285 [00:23<04:34,  1.03s/it]Loading train:   7%|▋         | 20/285 [00:24<04:18,  1.02it/s]Loading train:   7%|▋         | 21/285 [00:25<04:16,  1.03it/s]Loading train:   8%|▊         | 22/285 [00:26<04:25,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:27<04:19,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:28<04:12,  1.04it/s]Loading train:   9%|▉         | 25/285 [00:30<04:53,  1.13s/it]Loading train:   9%|▉         | 26/285 [00:31<05:04,  1.18s/it]Loading train:   9%|▉         | 27/285 [00:32<04:53,  1.14s/it]Loading train:  10%|▉         | 28/285 [00:33<04:47,  1.12s/it]Loading train:  10%|█         | 29/285 [00:34<04:45,  1.11s/it]Loading train:  11%|█         | 30/285 [00:35<04:49,  1.13s/it]Loading train:  11%|█         | 31/285 [00:37<04:55,  1.17s/it]Loading train:  11%|█         | 32/285 [00:38<04:31,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:19,  1.03s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:19,  1.03s/it]Loading train:  12%|█▏        | 35/285 [00:41<04:36,  1.10s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:40,  1.13s/it]Loading train:  13%|█▎        | 37/285 [00:43<04:36,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:44<04:20,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:01,  1.02it/s]Loading train:  14%|█▍        | 40/285 [00:46<03:59,  1.03it/s]Loading train:  14%|█▍        | 41/285 [00:47<04:06,  1.01s/it]Loading train:  15%|█▍        | 42/285 [00:48<03:45,  1.08it/s]Loading train:  15%|█▌        | 43/285 [00:49<03:46,  1.07it/s]Loading train:  15%|█▌        | 44/285 [00:50<04:09,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:51<03:52,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:52<03:47,  1.05it/s]Loading train:  16%|█▋        | 47/285 [00:52<03:32,  1.12it/s]Loading train:  17%|█▋        | 48/285 [00:53<03:30,  1.13it/s]Loading train:  17%|█▋        | 49/285 [00:54<03:36,  1.09it/s]Loading train:  18%|█▊        | 50/285 [00:55<03:29,  1.12it/s]Loading train:  18%|█▊        | 51/285 [00:56<03:36,  1.08it/s]Loading train:  18%|█▊        | 52/285 [00:57<03:43,  1.04it/s]Loading train:  19%|█▊        | 53/285 [00:58<03:52,  1.00s/it]Loading train:  19%|█▉        | 54/285 [00:59<04:06,  1.06s/it]Loading train:  19%|█▉        | 55/285 [01:00<03:55,  1.02s/it]Loading train:  20%|█▉        | 56/285 [01:01<04:07,  1.08s/it]Loading train:  20%|██        | 57/285 [01:02<03:54,  1.03s/it]Loading train:  20%|██        | 58/285 [01:03<03:57,  1.04s/it]Loading train:  21%|██        | 59/285 [01:05<04:18,  1.14s/it]Loading train:  21%|██        | 60/285 [01:06<04:13,  1.13s/it]Loading train:  21%|██▏       | 61/285 [01:07<03:51,  1.03s/it]Loading train:  22%|██▏       | 62/285 [01:08<03:57,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:09<03:54,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:10<04:16,  1.16s/it]Loading train:  23%|██▎       | 65/285 [01:12<04:38,  1.27s/it]Loading train:  23%|██▎       | 66/285 [01:13<04:58,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:14<04:28,  1.23s/it]Loading train:  24%|██▍       | 68/285 [01:15<04:02,  1.12s/it]Loading train:  24%|██▍       | 69/285 [01:16<04:01,  1.12s/it]Loading train:  25%|██▍       | 70/285 [01:17<03:49,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:18<03:37,  1.02s/it]Loading train:  25%|██▌       | 72/285 [01:19<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:20<03:27,  1.02it/s]Loading train:  26%|██▌       | 74/285 [01:21<03:18,  1.06it/s]Loading train:  26%|██▋       | 75/285 [01:22<03:19,  1.06it/s]Loading train:  27%|██▋       | 76/285 [01:23<03:33,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:24<03:30,  1.01s/it]Loading train:  27%|██▋       | 78/285 [01:25<03:31,  1.02s/it]Loading train:  28%|██▊       | 79/285 [01:26<03:36,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:27<03:28,  1.02s/it]Loading train:  28%|██▊       | 81/285 [01:28<03:30,  1.03s/it]Loading train:  29%|██▉       | 82/285 [01:29<03:34,  1.06s/it]Loading train:  29%|██▉       | 83/285 [01:30<03:31,  1.05s/it]Loading train:  29%|██▉       | 84/285 [01:31<03:25,  1.02s/it]Loading train:  30%|██▉       | 85/285 [01:33<03:39,  1.10s/it]Loading train:  30%|███       | 86/285 [01:34<03:36,  1.09s/it]Loading train:  31%|███       | 87/285 [01:35<03:25,  1.04s/it]Loading train:  31%|███       | 88/285 [01:36<03:22,  1.03s/it]Loading train:  31%|███       | 89/285 [01:37<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:38<03:18,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:38<03:09,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:40<03:20,  1.04s/it]Loading train:  33%|███▎      | 93/285 [01:41<03:24,  1.06s/it]Loading train:  33%|███▎      | 94/285 [01:42<03:14,  1.02s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:13,  1.02s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:19,  1.06s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:12,  1.02s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:29,  1.12s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:27,  1.12s/it]Loading train:  35%|███▌      | 100/285 [01:48<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:49<03:06,  1.01s/it]Loading train:  36%|███▌      | 102/285 [01:50<02:58,  1.03it/s]Loading train:  36%|███▌      | 103/285 [01:51<02:50,  1.07it/s]Loading train:  36%|███▋      | 104/285 [01:52<03:03,  1.01s/it]Loading train:  37%|███▋      | 105/285 [01:53<03:04,  1.03s/it]Loading train:  37%|███▋      | 106/285 [01:54<02:57,  1.01it/s]Loading train:  38%|███▊      | 107/285 [01:55<02:54,  1.02it/s]Loading train:  38%|███▊      | 108/285 [01:56<02:57,  1.01s/it]Loading train:  38%|███▊      | 109/285 [01:57<02:55,  1.01it/s]Loading train:  39%|███▊      | 110/285 [01:58<02:58,  1.02s/it]Loading train:  39%|███▉      | 111/285 [01:59<02:54,  1.00s/it]Loading train:  39%|███▉      | 112/285 [02:00<02:53,  1.00s/it]Loading train:  40%|███▉      | 113/285 [02:01<02:58,  1.04s/it]Loading train:  40%|████      | 114/285 [02:02<02:59,  1.05s/it]Loading train:  40%|████      | 115/285 [02:03<03:06,  1.10s/it]Loading train:  41%|████      | 116/285 [02:04<02:55,  1.04s/it]Loading train:  41%|████      | 117/285 [02:05<02:56,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:06<02:40,  1.04it/s]Loading train:  42%|████▏     | 119/285 [02:07<02:31,  1.10it/s]Loading train:  42%|████▏     | 120/285 [02:08<02:20,  1.17it/s]Loading train:  42%|████▏     | 121/285 [02:09<02:43,  1.00it/s]Loading train:  43%|████▎     | 122/285 [02:10<02:50,  1.05s/it]Loading train:  43%|████▎     | 123/285 [02:11<02:55,  1.09s/it]Loading train:  44%|████▎     | 124/285 [02:12<02:50,  1.06s/it]Loading train:  44%|████▍     | 125/285 [02:13<02:47,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:14<02:46,  1.05s/it]Loading train:  45%|████▍     | 127/285 [02:15<02:44,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:17<02:48,  1.07s/it]Loading train:  45%|████▌     | 129/285 [02:18<02:40,  1.03s/it]Loading train:  46%|████▌     | 130/285 [02:18<02:27,  1.05it/s]Loading train:  46%|████▌     | 131/285 [02:19<02:19,  1.10it/s]Loading train:  46%|████▋     | 132/285 [02:20<02:18,  1.10it/s]Loading train:  47%|████▋     | 133/285 [02:21<02:14,  1.13it/s]Loading train:  47%|████▋     | 134/285 [02:22<02:09,  1.17it/s]Loading train:  47%|████▋     | 135/285 [02:22<02:07,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:23<02:08,  1.16it/s]Loading train:  48%|████▊     | 137/285 [02:24<02:10,  1.13it/s]Loading train:  48%|████▊     | 138/285 [02:25<02:00,  1.22it/s]Loading train:  49%|████▉     | 139/285 [02:26<02:01,  1.20it/s]Loading train:  49%|████▉     | 140/285 [02:27<02:05,  1.15it/s]Loading train:  49%|████▉     | 141/285 [02:28<02:09,  1.11it/s]Loading train:  50%|████▉     | 142/285 [02:29<02:10,  1.09it/s]Loading train:  50%|█████     | 143/285 [02:30<02:14,  1.06it/s]Loading train:  51%|█████     | 144/285 [02:31<02:19,  1.01it/s]Loading train:  51%|█████     | 145/285 [02:32<02:23,  1.02s/it]Loading train:  51%|█████     | 146/285 [02:33<02:29,  1.07s/it]Loading train:  52%|█████▏    | 147/285 [02:34<02:27,  1.07s/it]Loading train:  52%|█████▏    | 148/285 [02:35<02:25,  1.06s/it]Loading train:  52%|█████▏    | 149/285 [02:36<02:18,  1.02s/it]Loading train:  53%|█████▎    | 150/285 [02:37<02:14,  1.00it/s]Loading train:  53%|█████▎    | 151/285 [02:38<02:17,  1.03s/it]Loading train:  53%|█████▎    | 152/285 [02:39<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [02:40<02:08,  1.03it/s]Loading train:  54%|█████▍    | 154/285 [02:41<02:05,  1.05it/s]Loading train:  54%|█████▍    | 155/285 [02:42<02:06,  1.02it/s]Loading train:  55%|█████▍    | 156/285 [02:43<01:58,  1.09it/s]Loading train:  55%|█████▌    | 157/285 [02:44<01:54,  1.12it/s]Loading train:  55%|█████▌    | 158/285 [02:44<01:47,  1.19it/s]Loading train:  56%|█████▌    | 159/285 [02:45<01:44,  1.21it/s]Loading train:  56%|█████▌    | 160/285 [02:46<01:40,  1.24it/s]Loading train:  56%|█████▋    | 161/285 [02:47<01:36,  1.29it/s]Loading train:  57%|█████▋    | 162/285 [02:47<01:40,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [02:48<01:44,  1.17it/s]Loading train:  58%|█████▊    | 164/285 [02:49<01:49,  1.11it/s]Loading train:  58%|█████▊    | 165/285 [02:50<01:54,  1.05it/s]Loading train:  58%|█████▊    | 166/285 [02:51<01:53,  1.05it/s]Loading train:  59%|█████▊    | 167/285 [02:53<01:57,  1.01it/s]Loading train:  59%|█████▉    | 168/285 [02:53<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [02:55<01:56,  1.00s/it]Loading train:  60%|█████▉    | 170/285 [02:55<01:46,  1.08it/s]Loading train:  60%|██████    | 171/285 [02:56<01:39,  1.15it/s]Loading train:  60%|██████    | 172/285 [02:57<01:34,  1.20it/s]Loading train:  61%|██████    | 173/285 [02:58<01:32,  1.22it/s]Loading train:  61%|██████    | 174/285 [02:58<01:34,  1.18it/s]Loading train:  61%|██████▏   | 175/285 [03:00<01:40,  1.10it/s]Loading train:  62%|██████▏   | 176/285 [03:00<01:36,  1.13it/s]Loading train:  62%|██████▏   | 177/285 [03:01<01:30,  1.19it/s]Loading train:  62%|██████▏   | 178/285 [03:02<01:36,  1.11it/s]Loading train:  63%|██████▎   | 179/285 [03:03<01:36,  1.10it/s]Loading train:  63%|██████▎   | 180/285 [03:04<01:45,  1.01s/it]Loading train:  64%|██████▎   | 181/285 [03:05<01:47,  1.04s/it]Loading train:  64%|██████▍   | 182/285 [03:06<01:46,  1.03s/it]Loading train:  64%|██████▍   | 183/285 [03:07<01:44,  1.03s/it]Loading train:  65%|██████▍   | 184/285 [03:08<01:38,  1.02it/s]Loading train:  65%|██████▍   | 185/285 [03:09<01:36,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [03:10<01:41,  1.03s/it]Loading train:  66%|██████▌   | 187/285 [03:11<01:41,  1.04s/it]Loading train:  66%|██████▌   | 188/285 [03:13<01:42,  1.06s/it]Loading train:  66%|██████▋   | 189/285 [03:13<01:32,  1.04it/s]Loading train:  67%|██████▋   | 190/285 [03:14<01:35,  1.00s/it]Loading train:  67%|██████▋   | 191/285 [03:15<01:33,  1.00it/s]Loading train:  67%|██████▋   | 192/285 [03:16<01:35,  1.03s/it]Loading train:  68%|██████▊   | 193/285 [03:17<01:33,  1.02s/it]Loading train:  68%|██████▊   | 194/285 [03:19<01:33,  1.03s/it]Loading train:  68%|██████▊   | 195/285 [03:20<01:31,  1.02s/it]Loading train:  69%|██████▉   | 196/285 [03:20<01:28,  1.01it/s]Loading train:  69%|██████▉   | 197/285 [03:22<01:29,  1.01s/it]Loading train:  69%|██████▉   | 198/285 [03:23<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [03:23<01:21,  1.06it/s]Loading train:  70%|███████   | 200/285 [03:24<01:16,  1.11it/s]Loading train:  71%|███████   | 201/285 [03:25<01:19,  1.05it/s]Loading train:  71%|███████   | 202/285 [03:26<01:19,  1.05it/s]Loading train:  71%|███████   | 203/285 [03:27<01:15,  1.09it/s]Loading train:  72%|███████▏  | 204/285 [03:28<01:14,  1.08it/s]Loading train:  72%|███████▏  | 205/285 [03:29<01:15,  1.07it/s]Loading train:  72%|███████▏  | 206/285 [03:30<01:13,  1.08it/s]Loading train:  73%|███████▎  | 207/285 [03:31<01:17,  1.01it/s]Loading train:  73%|███████▎  | 208/285 [03:32<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [03:33<01:21,  1.07s/it]Loading train:  74%|███████▎  | 210/285 [03:34<01:13,  1.02it/s]Loading train:  74%|███████▍  | 211/285 [03:35<01:11,  1.04it/s]Loading train:  74%|███████▍  | 212/285 [03:36<01:13,  1.01s/it]Loading train:  75%|███████▍  | 213/285 [03:37<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:38<01:07,  1.05it/s]Loading train:  75%|███████▌  | 215/285 [03:39<01:07,  1.04it/s]Loading train:  76%|███████▌  | 216/285 [03:40<01:04,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:41<01:04,  1.05it/s]Loading train:  76%|███████▋  | 218/285 [03:42<01:03,  1.06it/s]Loading train:  77%|███████▋  | 219/285 [03:43<01:03,  1.04it/s]Loading train:  77%|███████▋  | 220/285 [03:44<01:01,  1.05it/s]Loading train:  78%|███████▊  | 221/285 [03:44<00:55,  1.15it/s]Loading train:  78%|███████▊  | 222/285 [03:45<00:56,  1.11it/s]Loading train:  78%|███████▊  | 223/285 [03:46<00:56,  1.10it/s]Loading train:  79%|███████▊  | 224/285 [03:47<00:55,  1.09it/s]Loading train:  79%|███████▉  | 225/285 [03:48<00:57,  1.05it/s]Loading train:  79%|███████▉  | 226/285 [03:49<00:58,  1.00it/s]Loading train:  80%|███████▉  | 227/285 [03:50<00:59,  1.03s/it]Loading train:  80%|████████  | 228/285 [03:52<01:01,  1.08s/it]Loading train:  80%|████████  | 229/285 [03:52<00:57,  1.03s/it]Loading train:  81%|████████  | 230/285 [03:53<00:54,  1.01it/s]Loading train:  81%|████████  | 231/285 [03:54<00:50,  1.07it/s]Loading train:  81%|████████▏ | 232/285 [03:55<00:46,  1.13it/s]Loading train:  82%|████████▏ | 233/285 [03:56<00:42,  1.23it/s]Loading train:  82%|████████▏ | 234/285 [03:57<00:44,  1.15it/s]Loading train:  82%|████████▏ | 235/285 [03:57<00:43,  1.14it/s]Loading train:  83%|████████▎ | 236/285 [03:59<00:48,  1.01it/s]Loading train:  83%|████████▎ | 237/285 [04:00<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [04:01<00:45,  1.04it/s]Loading train:  84%|████████▍ | 239/285 [04:02<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [04:02<00:41,  1.09it/s]Loading train:  85%|████████▍ | 241/285 [04:03<00:38,  1.14it/s]Loading train:  85%|████████▍ | 242/285 [04:04<00:34,  1.23it/s]Loading train:  85%|████████▌ | 243/285 [04:05<00:34,  1.23it/s]Loading train:  86%|████████▌ | 244/285 [04:06<00:37,  1.08it/s]Loading train:  86%|████████▌ | 245/285 [04:07<00:37,  1.07it/s]Loading train:  86%|████████▋ | 246/285 [04:08<00:38,  1.00it/s]Loading train:  87%|████████▋ | 247/285 [04:09<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:10<00:37,  1.02s/it]Loading train:  87%|████████▋ | 249/285 [04:11<00:34,  1.04it/s]Loading train:  88%|████████▊ | 250/285 [04:12<00:34,  1.00it/s]Loading train:  88%|████████▊ | 251/285 [04:13<00:32,  1.05it/s]Loading train:  88%|████████▊ | 252/285 [04:14<00:32,  1.03it/s]Loading train:  89%|████████▉ | 253/285 [04:15<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:16<00:32,  1.06s/it]Loading train:  89%|████████▉ | 255/285 [04:17<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [04:18<00:27,  1.04it/s]Loading train:  90%|█████████ | 257/285 [04:19<00:26,  1.08it/s]Loading train:  91%|█████████ | 258/285 [04:20<00:27,  1.00s/it]Loading train:  91%|█████████ | 259/285 [04:21<00:28,  1.10s/it]Loading train:  91%|█████████ | 260/285 [04:22<00:26,  1.06s/it]Loading train:  92%|█████████▏| 261/285 [04:23<00:24,  1.01s/it]Loading train:  92%|█████████▏| 262/285 [04:24<00:20,  1.11it/s]Loading train:  92%|█████████▏| 263/285 [04:24<00:18,  1.18it/s]Loading train:  93%|█████████▎| 264/285 [04:26<00:19,  1.06it/s]Loading train:  93%|█████████▎| 265/285 [04:27<00:18,  1.05it/s]Loading train:  93%|█████████▎| 266/285 [04:27<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:28<00:16,  1.07it/s]Loading train:  94%|█████████▍| 268/285 [04:29<00:16,  1.01it/s]Loading train:  94%|█████████▍| 269/285 [04:31<00:16,  1.02s/it]Loading train:  95%|█████████▍| 270/285 [04:31<00:14,  1.03it/s]Loading train:  95%|█████████▌| 271/285 [04:32<00:12,  1.09it/s]Loading train:  95%|█████████▌| 272/285 [04:33<00:11,  1.16it/s]Loading train:  96%|█████████▌| 273/285 [04:34<00:10,  1.18it/s]Loading train:  96%|█████████▌| 274/285 [04:35<00:09,  1.15it/s]Loading train:  96%|█████████▋| 275/285 [04:36<00:08,  1.13it/s]Loading train:  97%|█████████▋| 276/285 [04:37<00:08,  1.08it/s]Loading train:  97%|█████████▋| 277/285 [04:38<00:07,  1.10it/s]Loading train:  98%|█████████▊| 278/285 [04:38<00:06,  1.15it/s]Loading train:  98%|█████████▊| 279/285 [04:39<00:05,  1.13it/s]Loading train:  98%|█████████▊| 280/285 [04:40<00:04,  1.22it/s]Loading train:  99%|█████████▊| 281/285 [04:41<00:03,  1.26it/s]Loading train:  99%|█████████▉| 282/285 [04:41<00:02,  1.25it/s]Loading train:  99%|█████████▉| 283/285 [04:43<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:44<00:00,  1.07it/s]Loading train: 100%|██████████| 285/285 [04:45<00:00,  1.02s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:09, 30.51it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:08, 32.25it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:06, 39.03it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:05, 45.79it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:04, 58.76it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:03, 74.23it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:02, 90.90it/s]concatenating: train:  38%|███▊      | 108/285 [00:00<00:01, 112.57it/s]concatenating: train:  44%|████▍     | 126/285 [00:00<00:01, 124.76it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 84.59it/s] concatenating: train:  55%|█████▌    | 158/285 [00:01<00:01, 95.11it/s]concatenating: train:  60%|██████    | 172/285 [00:01<00:01, 90.54it/s]concatenating: train:  65%|██████▍   | 184/285 [00:01<00:01, 97.29it/s]concatenating: train:  71%|███████   | 201/285 [00:01<00:00, 110.12it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 129.12it/s]concatenating: train:  84%|████████▍ | 240/285 [00:02<00:00, 125.62it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 104.24it/s]concatenating: train:  94%|█████████▍| 268/285 [00:02<00:00, 103.34it/s]concatenating: train:  99%|█████████▊| 281/285 [00:02<00:00, 108.21it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 111.34it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 172.84it/s]2019-07-11 04:39:46.529704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:39:46.529824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:39:46.529840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:39:46.529849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:39:46.530251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.37it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.27it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.22it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.81it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  7.68it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.32it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.49it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.28it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.03it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.28it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.46it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.75it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.23it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.54it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.80it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.95it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.60it/s] min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   10820       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 80)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 238,873
Trainable params: 64,113
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 17s - loss: 2.6220 - acc: 0.5911 - mDice: 0.1316 - val_loss: 1.6584 - val_acc: 0.9062 - val_mDice: 0.2675

Epoch 00001: val_mDice improved from -inf to 0.26746, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.9078 - acc: 0.8936 - mDice: 0.3967 - val_loss: 1.0930 - val_acc: 0.9008 - val_mDice: 0.4248

Epoch 00002: val_mDice improved from 0.26746 to 0.42479, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6549 - acc: 0.9109 - mDice: 0.5049 - val_loss: 0.8928 - val_acc: 0.9294 - val_mDice: 0.5077

Epoch 00003: val_mDice improved from 0.42479 to 0.50774, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5706 - acc: 0.9214 - mDice: 0.5502 - val_loss: 0.8304 - val_acc: 0.9270 - val_mDice: 0.5395

Epoch 00004: val_mDice improved from 0.50774 to 0.53945, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5260 - acc: 0.9260 - mDice: 0.5756 - val_loss: 0.7895 - val_acc: 0.9330 - val_mDice: 0.5525

Epoch 00005: val_mDice improved from 0.53945 to 0.55253, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4935 - acc: 0.9291 - mDice: 0.5952 - val_loss: 0.7852 - val_acc: 0.9260 - val_mDice: 0.5477

Epoch 00006: val_mDice did not improve from 0.55253
Epoch 7/300
 - 11s - loss: 0.4705 - acc: 0.9313 - mDice: 0.6094 - val_loss: 0.7431 - val_acc: 0.9364 - val_mDice: 0.5691

Epoch 00007: val_mDice improved from 0.55253 to 0.56912, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4540 - acc: 0.9327 - mDice: 0.6199 - val_loss: 0.7638 - val_acc: 0.9222 - val_mDice: 0.5470

Epoch 00008: val_mDice did not improve from 0.56912
Epoch 9/300
 - 11s - loss: 0.4373 - acc: 0.9342 - mDice: 0.6304 - val_loss: 0.7253 - val_acc: 0.9395 - val_mDice: 0.5829

Epoch 00009: val_mDice improved from 0.56912 to 0.58292, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 11s - loss: 0.4274 - acc: 0.9351 - mDice: 0.6372 - val_loss: 0.7437 - val_acc: 0.9360 - val_mDice: 0.5754

Epoch 00010: val_mDice did not improve from 0.58292
Epoch 11/300
 - 11s - loss: 0.4168 - acc: 0.9363 - mDice: 0.6442 - val_loss: 0.7325 - val_acc: 0.9313 - val_mDice: 0.5659

Epoch 00011: val_mDice did not improve from 0.58292
Epoch 12/300
 - 11s - loss: 0.4074 - acc: 0.9370 - mDice: 0.6503 - val_loss: 0.7266 - val_acc: 0.9393 - val_mDice: 0.5689

Epoch 00012: val_mDice did not improve from 0.58292
Epoch 13/300
 - 11s - loss: 0.4004 - acc: 0.9376 - mDice: 0.6550 - val_loss: 0.7377 - val_acc: 0.9322 - val_mDice: 0.5664

Epoch 00013: val_mDice did not improve from 0.58292
Epoch 14/300
 - 11s - loss: 0.3951 - acc: 0.9382 - mDice: 0.6587 - val_loss: 0.7247 - val_acc: 0.9391 - val_mDice: 0.5728

Epoch 00014: val_mDice did not improve from 0.58292
Epoch 15/300
 - 11s - loss: 0.3895 - acc: 0.9385 - mDice: 0.6623 - val_loss: 0.7400 - val_acc: 0.9400 - val_mDice: 0.5765

Epoch 00015: val_mDice did not improve from 0.58292
Epoch 16/300
 - 11s - loss: 0.3812 - acc: 0.9393 - mDice: 0.6680 - val_loss: 0.7220 - val_acc: 0.9362 - val_mDice: 0.5731

Epoch 00016: val_mDice did not improve from 0.58292
Epoch 17/300
 - 11s - loss: 0.3760 - acc: 0.9398 - mDice: 0.6717 - val_loss: 0.7241 - val_acc: 0.9363 - val_mDice: 0.5708

Epoch 00017: val_mDice did not improve from 0.58292
Epoch 18/300
 - 11s - loss: 0.3723 - acc: 0.9400 - mDice: 0.6741 - val_loss: 0.7415 - val_acc: 0.9358 - val_mDice: 0.5621

Epoch 00018: val_mDice did not improve from 0.58292
Epoch 19/300
 - 11s - loss: 0.3644 - acc: 0.9407 - mDice: 0.6796 - val_loss: 0.7425 - val_acc: 0.9300 - val_mDice: 0.5622

Epoch 00019: val_mDice did not improve from 0.58292
Epoch 20/300
 - 11s - loss: 0.3623 - acc: 0.9410 - mDice: 0.6812 - val_loss: 0.7634 - val_acc: 0.9335 - val_mDice: 0.5638

Epoch 00020: val_mDice did not improve from 0.58292
Epoch 21/300
 - 11s - loss: 0.3594 - acc: 0.9412 - mDice: 0.6832 - val_loss: 0.7218 - val_acc: 0.9319 - val_mDice: 0.5692

Epoch 00021: val_mDice did not improve from 0.58292
Epoch 22/300
 - 11s - loss: 0.3553 - acc: 0.9415 - mDice: 0.6861 - val_loss: 0.7173 - val_acc: 0.9381 - val_mDice: 0.5773

Epoch 00022: val_mDice did not improve from 0.58292
Epoch 23/300
 - 11s - loss: 0.3500 - acc: 0.9419 - mDice: 0.6899 - val_loss: 0.7495 - val_acc: 0.9406 - val_mDice: 0.5779

Epoch 00023: val_mDice did not improve from 0.58292
Epoch 24/300
 - 11s - loss: 0.3475 - acc: 0.9421 - mDice: 0.6917 - val_loss: 0.7326 - val_acc: 0.9373 - val_mDice: 0.5696

Epoch 00024: val_mDice did not improve from 0.58292
Epoch 25/300
 - 11s - loss: 0.3441 - acc: 0.9424 - mDice: 0.6940 - val_loss: 0.7608 - val_acc: 0.9360 - val_mDice: 0.5681

Epoch 00025: val_mDice did not improve from 0.58292
Epoch 26/300
 - 11s - loss: 0.3424 - acc: 0.9425 - mDice: 0.6952 - val_loss: 0.7168 - val_acc: 0.9410 - val_mDice: 0.5868

Epoch 00026: val_mDice improved from 0.58292 to 0.58678, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 11s - loss: 0.3395 - acc: 0.9428 - mDice: 0.6973 - val_loss: 0.7910 - val_acc: 0.9415 - val_mDice: 0.5561

Epoch 00027: val_mDice did not improve from 0.58678
Epoch 28/300
 - 11s - loss: 0.3367 - acc: 0.9429 - mDice: 0.6993 - val_loss: 0.7285 - val_acc: 0.9378 - val_mDice: 0.5734

Epoch 00028: val_mDice did not improve from 0.58678
Epoch 29/300
 - 11s - loss: 0.3354 - acc: 0.9431 - mDice: 0.7004 - val_loss: 0.7954 - val_acc: 0.9264 - val_mDice: 0.5428

Epoch 00029: val_mDice did not improve from 0.58678
Epoch 30/300
 - 11s - loss: 0.3315 - acc: 0.9434 - mDice: 0.7031 - val_loss: 0.7410 - val_acc: 0.9419 - val_mDice: 0.5791

Epoch 00030: val_mDice did not improve from 0.58678
Epoch 31/300
 - 11s - loss: 0.3303 - acc: 0.9435 - mDice: 0.7041 - val_loss: 0.7291 - val_acc: 0.9369 - val_mDice: 0.5776

Epoch 00031: val_mDice did not improve from 0.58678
Epoch 32/300
 - 11s - loss: 0.3274 - acc: 0.9437 - mDice: 0.7061 - val_loss: 0.7444 - val_acc: 0.9402 - val_mDice: 0.5787

Epoch 00032: val_mDice did not improve from 0.58678
Epoch 33/300
 - 11s - loss: 0.3251 - acc: 0.9438 - mDice: 0.7078 - val_loss: 0.7526 - val_acc: 0.9418 - val_mDice: 0.5758

Epoch 00033: val_mDice did not improve from 0.58678
Epoch 34/300
 - 11s - loss: 0.3246 - acc: 0.9440 - mDice: 0.7083 - val_loss: 0.7494 - val_acc: 0.9394 - val_mDice: 0.5799

Epoch 00034: val_mDice did not improve from 0.58678
Epoch 35/300
 - 12s - loss: 0.3239 - acc: 0.9440 - mDice: 0.7089 - val_loss: 0.7286 - val_acc: 0.9361 - val_mDice: 0.5762

Epoch 00035: val_mDice did not improve from 0.58678
Epoch 36/300
 - 11s - loss: 0.3203 - acc: 0.9443 - mDice: 0.7114 - val_loss: 0.7387 - val_acc: 0.9416 - val_mDice: 0.5837

Epoch 00036: val_mDice did not improve from 0.58678
Epoch 37/300
 - 11s - loss: 0.3211 - acc: 0.9442 - mDice: 0.7110 - val_loss: 0.7253 - val_acc: 0.9399 - val_mDice: 0.5811

Epoch 00037: val_mDice did not improve from 0.58678
Epoch 38/300
 - 11s - loss: 0.3165 - acc: 0.9446 - mDice: 0.7141 - val_loss: 0.7411 - val_acc: 0.9388 - val_mDice: 0.5762

Epoch 00038: val_mDice did not improve from 0.58678
Epoch 39/300
 - 11s - loss: 0.3150 - acc: 0.9448 - mDice: 0.7153 - val_loss: 0.7427 - val_acc: 0.9385 - val_mDice: 0.5578

Epoch 00039: val_mDice did not improve from 0.58678
Epoch 40/300
 - 11s - loss: 0.3141 - acc: 0.9447 - mDice: 0.7160 - val_loss: 0.7309 - val_acc: 0.9407 - val_mDice: 0.5833

Epoch 00040: val_mDice did not improve from 0.58678
Epoch 41/300
 - 12s - loss: 0.3111 - acc: 0.9450 - mDice: 0.7182 - val_loss: 0.7230 - val_acc: 0.9386 - val_mDice: 0.5819

Epoch 00041: val_mDice did not improve from 0.58678
Epoch 42/300
 - 11s - loss: 0.3109 - acc: 0.9451 - mDice: 0.7183 - val_loss: 0.6877 - val_acc: 0.9397 - val_mDice: 0.5838

Epoch 00042: val_mDice did not improve from 0.58678
Epoch 43/300
 - 11s - loss: 0.3111 - acc: 0.9451 - mDice: 0.7183 - val_loss: 0.7013 - val_acc: 0.9368 - val_mDice: 0.5705

Epoch 00043: val_mDice did not improve from 0.58678
Epoch 44/300
 - 11s - loss: 0.3077 - acc: 0.9453 - mDice: 0.7208 - val_loss: 0.7311 - val_acc: 0.9374 - val_mDice: 0.5751

Epoch 00044: val_mDice did not improve from 0.58678
Epoch 45/300
 - 11s - loss: 0.3059 - acc: 0.9455 - mDice: 0.7221 - val_loss: 0.7804 - val_acc: 0.9370 - val_mDice: 0.5562

Epoch 00045: val_mDice did not improve from 0.58678
Epoch 46/300
 - 11s - loss: 0.3049 - acc: 0.9457 - mDice: 0.7230 - val_loss: 0.7698 - val_acc: 0.9380 - val_mDice: 0.5602

Epoch 00046: val_mDice did not improve from 0.58678
Epoch 47/300
 - 11s - loss: 0.3038 - acc: 0.9456 - mDice: 0.7237 - val_loss: 0.7483 - val_acc: 0.9393 - val_mDice: 0.5735

Epoch 00047: val_mDice did not improve from 0.58678
Epoch 48/300
 - 11s - loss: 0.3028 - acc: 0.9458 - mDice: 0.7245 - val_loss: 0.7725 - val_acc: 0.9366 - val_mDice: 0.5596

Epoch 00048: val_mDice did not improve from 0.58678
Epoch 49/300
 - 11s - loss: 0.3024 - acc: 0.9458 - mDice: 0.7248 - val_loss: 0.7065 - val_acc: 0.9410 - val_mDice: 0.5835

Epoch 00049: val_mDice did not improve from 0.58678
Epoch 50/300
 - 11s - loss: 0.3004 - acc: 0.9458 - mDice: 0.7263 - val_loss: 0.7276 - val_acc: 0.9346 - val_mDice: 0.5714

Epoch 00050: val_mDice did not improve from 0.58678
Epoch 51/300
 - 11s - loss: 0.2989 - acc: 0.9460 - mDice: 0.7275 - val_loss: 0.7562 - val_acc: 0.9327 - val_mDice: 0.5679

Epoch 00051: val_mDice did not improve from 0.58678
Epoch 52/300
 - 11s - loss: 0.2988 - acc: 0.9460 - mDice: 0.7275 - val_loss: 0.7508 - val_acc: 0.9345 - val_mDice: 0.5703

Epoch 00052: val_mDice did not improve from 0.58678
Epoch 53/300
 - 11s - loss: 0.3000 - acc: 0.9460 - mDice: 0.7267 - val_loss: 0.7361 - val_acc: 0.9347 - val_mDice: 0.5650

Epoch 00053: val_mDice did not improve from 0.58678
Epoch 54/300
 - 11s - loss: 0.2975 - acc: 0.9461 - mDice: 0.7285 - val_loss: 0.7677 - val_acc: 0.9319 - val_mDice: 0.5578

Epoch 00054: val_mDice did not improve from 0.58678
Epoch 55/300
 - 11s - loss: 0.2968 - acc: 0.9461 - mDice: 0.7291 - val_loss: 0.7534 - val_acc: 0.9355 - val_mDice: 0.5559

Epoch 00055: val_mDice did not improve from 0.58678
Epoch 56/300
 - 11s - loss: 0.2955 - acc: 0.9463 - mDice: 0.7301 - val_loss: 0.7210 - val_acc: 0.9372 - val_mDice: 0.5745

Epoch 00056: val_mDice did not improve from 0.58678
Epoch 57/300
 - 11s - loss: 0.2928 - acc: 0.9466 - mDice: 0.7321 - val_loss: 0.7240 - val_acc: 0.9392 - val_mDice: 0.5690

Epoch 00057: val_mDice did not improve from 0.58678
Epoch 58/300
 - 11s - loss: 0.2919 - acc: 0.9466 - mDice: 0.7329 - val_loss: 0.7371 - val_acc: 0.9381 - val_mDice: 0.5676

Epoch 00058: val_mDice did not improve from 0.58678
Epoch 59/300
 - 11s - loss: 0.2927 - acc: 0.9465 - mDice: 0.7322 - val_loss: 0.7487 - val_acc: 0.9391 - val_mDice: 0.5652

Epoch 00059: val_mDice did not improve from 0.58678
Epoch 60/300
 - 11s - loss: 0.2925 - acc: 0.9466 - mDice: 0.7324 - val_loss: 0.7426 - val_acc: 0.9392 - val_mDice: 0.5701

Epoch 00060: val_mDice did not improve from 0.58678
Epoch 61/300
 - 11s - loss: 0.2906 - acc: 0.9467 - mDice: 0.7339 - val_loss: 0.7308 - val_acc: 0.9373 - val_mDice: 0.5780

Epoch 00061: val_mDice did not improve from 0.58678
Epoch 62/300
 - 11s - loss: 0.2907 - acc: 0.9466 - mDice: 0.7337 - val_loss: 0.6817 - val_acc: 0.9423 - val_mDice: 0.5876

Epoch 00062: val_mDice improved from 0.58678 to 0.58761, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 11s - loss: 0.2876 - acc: 0.9470 - mDice: 0.7361 - val_loss: 0.7271 - val_acc: 0.9369 - val_mDice: 0.5728

Epoch 00063: val_mDice did not improve from 0.58761
Epoch 64/300
 - 11s - loss: 0.2878 - acc: 0.9468 - mDice: 0.7360 - val_loss: 0.7055 - val_acc: 0.9369 - val_mDice: 0.5807

Epoch 00064: val_mDice did not improve from 0.58761
Epoch 65/300
 - 11s - loss: 0.2861 - acc: 0.9471 - mDice: 0.7372 - val_loss: 0.7220 - val_acc: 0.9382 - val_mDice: 0.5761

Epoch 00065: val_mDice did not improve from 0.58761
Epoch 66/300
 - 11s - loss: 0.2868 - acc: 0.9470 - mDice: 0.7368 - val_loss: 0.7494 - val_acc: 0.9331 - val_mDice: 0.5651

Epoch 00066: val_mDice did not improve from 0.58761
Epoch 67/300
 - 11s - loss: 0.2859 - acc: 0.9472 - mDice: 0.7374 - val_loss: 0.7269 - val_acc: 0.9364 - val_mDice: 0.5716

Epoch 00067: val_mDice did not improve from 0.58761
Epoch 68/300
 - 11s - loss: 0.2852 - acc: 0.9471 - mDice: 0.7380 - val_loss: 0.7092 - val_acc: 0.9388 - val_mDice: 0.5764

Epoch 00068: val_mDice did not improve from 0.58761
Epoch 69/300
 - 11s - loss: 0.2833 - acc: 0.9472 - mDice: 0.7394 - val_loss: 0.7000 - val_acc: 0.9377 - val_mDice: 0.5806

Epoch 00069: val_mDice did not improve from 0.58761
Epoch 70/300
 - 11s - loss: 0.2848 - acc: 0.9472 - mDice: 0.7383 - val_loss: 0.7265 - val_acc: 0.9363 - val_mDice: 0.5637

Epoch 00070: val_mDice did not improve from 0.58761
Epoch 71/300
 - 11s - loss: 0.2833 - acc: 0.9473 - mDice: 0.7395 - val_loss: 0.6981 - val_acc: 0.9358 - val_mDice: 0.5716

Epoch 00071: val_mDice did not improve from 0.58761
Epoch 72/300
 - 12s - loss: 0.2808 - acc: 0.9474 - mDice: 0.7414 - val_loss: 0.7226 - val_acc: 0.9420 - val_mDice: 0.5813

Epoch 00072: val_mDice did not improve from 0.58761
Epoch 73/300
 - 11s - loss: 0.2824 - acc: 0.9473 - mDice: 0.7402 - val_loss: 0.7222 - val_acc: 0.9369 - val_mDice: 0.5683

Epoch 00073: val_mDice did not improve from 0.58761
Epoch 74/300
 - 11s - loss: 0.2809 - acc: 0.9475 - mDice: 0.7413 - val_loss: 0.7148 - val_acc: 0.9425 - val_mDice: 0.5862

Epoch 00074: val_mDice did not improve from 0.58761
Epoch 75/300
 - 11s - loss: 0.2806 - acc: 0.9476 - mDice: 0.7415 - val_loss: 0.7406 - val_acc: 0.9367 - val_mDice: 0.5630

Epoch 00075: val_mDice did not improve from 0.58761
Epoch 76/300
 - 11s - loss: 0.2805 - acc: 0.9475 - mDice: 0.7416 - val_loss: 0.7078 - val_acc: 0.9386 - val_mDice: 0.5746

Epoch 00076: val_mDice did not improve from 0.58761
Epoch 77/300
 - 11s - loss: 0.2774 - acc: 0.9477 - mDice: 0.7440 - val_loss: 0.6838 - val_acc: 0.9407 - val_mDice: 0.5840

Epoch 00077: val_mDice did not improve from 0.58761
Epoch 78/300
 - 11s - loss: 0.2778 - acc: 0.9478 - mDice: 0.7436 - val_loss: 0.7028 - val_acc: 0.9370 - val_mDice: 0.5843

Epoch 00078: val_mDice did not improve from 0.58761
Epoch 79/300
 - 11s - loss: 0.2801 - acc: 0.9475 - mDice: 0.7420 - val_loss: 0.7408 - val_acc: 0.9382 - val_mDice: 0.5646

Epoch 00079: val_mDice did not improve from 0.58761
Epoch 80/300
 - 11s - loss: 0.2769 - acc: 0.9478 - mDice: 0.7444 - val_loss: 0.7200 - val_acc: 0.9369 - val_mDice: 0.5748

Epoch 00080: val_mDice did not improve from 0.58761
Epoch 81/300
 - 11s - loss: 0.2769 - acc: 0.9478 - mDice: 0.7444 - val_loss: 0.7058 - val_acc: 0.9370 - val_mDice: 0.5694

Epoch 00081: val_mDice did not improve from 0.58761
Epoch 82/300
 - 12s - loss: 0.2756 - acc: 0.9479 - mDice: 0.7454 - val_loss: 0.7122 - val_acc: 0.9348 - val_mDice: 0.5636

Epoch 00082: val_mDice did not improve from 0.58761
Epoch 83/300
 - 11s - loss: 0.2751 - acc: 0.9480 - mDice: 0.7458 - val_loss: 0.7243 - val_acc: 0.9387 - val_mDice: 0.5784

Epoch 00083: val_mDice did not improve from 0.58761
Epoch 84/300
 - 11s - loss: 0.2758 - acc: 0.9479 - mDice: 0.7453 - val_loss: 0.7164 - val_acc: 0.9415 - val_mDice: 0.5791

Epoch 00084: val_mDice did not improve from 0.58761
Epoch 85/300
 - 11s - loss: 0.2744 - acc: 0.9480 - mDice: 0.7464 - val_loss: 0.6942 - val_acc: 0.9391 - val_mDice: 0.5818

Epoch 00085: val_mDice did not improve from 0.58761
Epoch 86/300
 - 11s - loss: 0.2723 - acc: 0.9481 - mDice: 0.7479 - val_loss: 0.7220 - val_acc: 0.9300 - val_mDice: 0.5654

Epoch 00086: val_mDice did not improve from 0.58761
Epoch 87/300
 - 11s - loss: 0.2729 - acc: 0.9480 - mDice: 0.7475 - val_loss: 0.7269 - val_acc: 0.9368 - val_mDice: 0.5703

Epoch 00087: val_mDice did not improve from 0.58761
Epoch 88/300
 - 11s - loss: 0.2732 - acc: 0.9480 - mDice: 0.7473 - val_loss: 0.7110 - val_acc: 0.9360 - val_mDice: 0.5697

Epoch 00088: val_mDice did not improve from 0.58761
Epoch 89/300
 - 11s - loss: 0.2706 - acc: 0.9483 - mDice: 0.7493 - val_loss: 0.6948 - val_acc: 0.9387 - val_mDice: 0.5843

Epoch 00089: val_mDice did not improve from 0.58761
Epoch 90/300
 - 11s - loss: 0.2718 - acc: 0.9482 - mDice: 0.7484 - val_loss: 0.7060 - val_acc: 0.9400 - val_mDice: 0.5821

Epoch 00090: val_mDice did not improve from 0.58761
Epoch 91/300
 - 11s - loss: 0.2720 - acc: 0.9481 - mDice: 0.7482 - val_loss: 0.7224 - val_acc: 0.9403 - val_mDice: 0.5701

Epoch 00091: val_mDice did not improve from 0.58761
Epoch 92/300
 - 12s - loss: 0.2700 - acc: 0.9484 - mDice: 0.7498 - val_loss: 0.7374 - val_acc: 0.9329 - val_mDice: 0.5665

Epoch 00092: val_mDice did not improve from 0.58761
Epoch 93/300
 - 11s - loss: 0.2693 - acc: 0.9483 - mDice: 0.7504 - val_loss: 0.7320 - val_acc: 0.9393 - val_mDice: 0.5745

Epoch 00093: val_mDice did not improve from 0.58761
Epoch 94/300
 - 11s - loss: 0.2698 - acc: 0.9484 - mDice: 0.7500 - val_loss: 0.6998 - val_acc: 0.9357 - val_mDice: 0.5766

Epoch 00094: val_mDice did not improve from 0.58761
Epoch 95/300
 - 11s - loss: 0.2699 - acc: 0.9483 - mDice: 0.7499 - val_loss: 0.7564 - val_acc: 0.9393 - val_mDice: 0.5665

Epoch 00095: val_mDice did not improve from 0.58761
Epoch 96/300
 - 11s - loss: 0.2684 - acc: 0.9484 - mDice: 0.7510 - val_loss: 0.6918 - val_acc: 0.9419 - val_mDice: 0.5658

Epoch 00096: val_mDice did not improve from 0.58761
Epoch 97/300
 - 11s - loss: 0.2681 - acc: 0.9484 - mDice: 0.7513 - val_loss: 0.7181 - val_acc: 0.9382 - val_mDice: 0.5780

Epoch 00097: val_mDice did not improve from 0.58761
Epoch 98/300
 - 11s - loss: 0.2670 - acc: 0.9486 - mDice: 0.7522 - val_loss: 0.7202 - val_acc: 0.9340 - val_mDice: 0.5605

Epoch 00098: val_mDice did not improve from 0.58761
Epoch 99/300
 - 11s - loss: 0.2678 - acc: 0.9485 - mDice: 0.7515 - val_loss: 0.7297 - val_acc: 0.9350 - val_mDice: 0.5643

Epoch 00099: val_mDice did not improve from 0.58761
Epoch 100/300
 - 11s - loss: 0.2673 - acc: 0.9486 - mDice: 0.7521 - val_loss: 0.7400 - val_acc: 0.9341 - val_mDice: 0.5676

Epoch 00100: val_mDice did not improve from 0.58761
Epoch 101/300
 - 11s - loss: 0.2664 - acc: 0.9486 - mDice: 0.7526 - val_loss: 0.7103 - val_acc: 0.9389 - val_mDice: 0.5680

Epoch 00101: val_mDice did not improve from 0.58761
Epoch 102/300
 - 11s - loss: 0.2660 - acc: 0.9486 - mDice: 0.7530 - val_loss: 0.7198 - val_acc: 0.9367 - val_mDice: 0.5710

Epoch 00102: val_mDice did not improve from 0.58761
Restoring model weights from the end of the best epoch
Epoch 00102: early stopping
{'val_loss': [1.6583518890234141, 1.0930449297794929, 0.8928470221849588, 0.830430445762781, 0.7895461206252758, 0.7852112513322097, 0.7431481205500089, 0.7637846722052648, 0.7253321008040354, 0.743662974009147, 0.7324936825495499, 0.7266126962808462, 0.7377108427194449, 0.7246729548160846, 0.7399963037325785, 0.721992029593541, 0.7241386266855093, 0.7414678381039546, 0.7424709132084479, 0.7633810226733868, 0.7217644223800073, 0.7173133950967056, 0.7495439832027142, 0.7326082449692947, 0.7607571184635162, 0.7167556217083564, 0.7909891697076651, 0.7284902104964623, 0.7954061398139367, 0.7410012013637103, 0.7291183173656464, 0.7443822954709713, 0.7525911193627578, 0.7494415743992879, 0.7285699408787948, 0.7386898478636374, 0.7253309453909214, 0.7410613642289088, 0.7426942930771754, 0.7308569023242364, 0.7230246743330588, 0.6877005787996145, 0.7013062009444604, 0.7311408588519464, 0.7803765260256253, 0.7697663215490488, 0.7482589872983786, 0.7725158035755157, 0.706544754596857, 0.7275748482117286, 0.7562313767579886, 0.7507652411094079, 0.7360605322397672, 0.7677255043616662, 0.7533706587094527, 0.7209745278725257, 0.7239584693541894, 0.7371362424813784, 0.748679307790903, 0.7425782909760108, 0.7308190854696127, 0.6817016842273566, 0.7271179052499624, 0.7055411396118311, 0.7220366872273959, 0.7494113399432256, 0.7268792711771451, 0.7092181490017817, 0.700028026333222, 0.7265168749369108, 0.6980734421656682, 0.7226351362008315, 0.7222235821760618, 0.7147837453163587, 0.7406155581657703, 0.7077786074234889, 0.6838407837427579, 0.7028033400957401, 0.7408276658791763, 0.7199872594613296, 0.7058478960624108, 0.7121535264528714, 0.7243054646712083, 0.7164227343522586, 0.6941603387777622, 0.7219524062596835, 0.7269299763899583, 0.7109787257818075, 0.6948252068116114, 0.7060362639335486, 0.722378318126385, 0.737395146718392, 0.7320029964813819, 0.6998173204752115, 0.7564179484660809, 0.6917676765185136, 0.7181223860153785, 0.7202429473400116, 0.7297030710257016, 0.7399671925948217, 0.7103355183051183, 0.7198242178330054], 'val_acc': [0.9062060736692868, 0.9008320982639606, 0.9294101550028875, 0.9269693081195538, 0.932988159931623, 0.9260355257070981, 0.9363674017099234, 0.9221662191244272, 0.9394623935222626, 0.9360068692610815, 0.9313401235983922, 0.9392844071755042, 0.9321953700138972, 0.9390578820155218, 0.9399662682643304, 0.9362403154373169, 0.9363003992117368, 0.9357687876774714, 0.9300087942526891, 0.9334874542859884, 0.9319156820957477, 0.938084765122487, 0.9405949276227218, 0.937335878610611, 0.9360160690087539, 0.941038734637774, 0.9415241342324477, 0.9378143480190864, 0.9264284234780532, 0.9418662442610815, 0.9368851689191965, 0.940243640771279, 0.9418107660917135, 0.9394230842590332, 0.9361154643388895, 0.9415934590192941, 0.9399361770886642, 0.9388267489580008, 0.9385285583826212, 0.9406620011879847, 0.9386209983092088, 0.9397143240158374, 0.9367881165100977, 0.9373959692624899, 0.936986893415451, 0.9380408823490143, 0.9392659136882195, 0.9365777671337128, 0.9410017660030952, 0.9346454418622531, 0.9327084651360145, 0.9345137041348678, 0.93466389637727, 0.9318925554935749, 0.9354983361867758, 0.9371787172097427, 0.9391919213991898, 0.9381217818993789, 0.9391456934121939, 0.9391595881718856, 0.9372943020783938, 0.9423446632348574, 0.9368620331470783, 0.9368574046171628, 0.9382257553247305, 0.9331268622325017, 0.9363697583858783, 0.9387504641826336, 0.9376826263391055, 0.9363049910618708, 0.9358265285308545, 0.9419910518022684, 0.9368597429532272, 0.9424810271996719, 0.936725703569559, 0.9386487717811878, 0.940650442471871, 0.9369637347184695, 0.9381587321941669, 0.9368920784730178, 0.9369660501296704, 0.9348025918006897, 0.9386533590463492, 0.9415241411099067, 0.9391087247775152, 0.9300064788414881, 0.93678345817786, 0.9359975915688735, 0.9387111893066993, 0.9400147658128005, 0.940319877404433, 0.9328633776077857, 0.9392843659107502, 0.9357294829992148, 0.9392936321405264, 0.9419147647344149, 0.9382280844908494, 0.9339705017896799, 0.9349828935586489, 0.9341253752891834, 0.9388845494160285, 0.9367002753111032], 'val_mDice': [0.2674576829259212, 0.42478970552866274, 0.5077421527642471, 0.5394500800623343, 0.5525327812020595, 0.547730918114002, 0.569118918134616, 0.5470156681079131, 0.5829174919770315, 0.5754476074989026, 0.565927226956074, 0.5689458594872401, 0.5663515776395798, 0.5728285742493776, 0.5765343170899612, 0.5730862055833523, 0.5707896810311538, 0.5620709118934778, 0.5622345415445474, 0.5638242959976196, 0.5691769552918581, 0.5772715726724038, 0.5778996715178857, 0.5695619302300307, 0.5680567450248278, 0.5867796219312228, 0.5560840586057076, 0.5733581752731249, 0.5427555396006658, 0.5791070845264655, 0.5775564542183509, 0.5787102052798638, 0.5757870674133301, 0.5799329252197192, 0.5762457222892687, 0.5836831119198066, 0.5810606256127357, 0.5762171103404119, 0.5578024135186122, 0.5833208641180625, 0.5818919310202966, 0.5838041053368495, 0.570507851930765, 0.5750590562820435, 0.5561557589815214, 0.560184949865708, 0.5735026001930237, 0.5596464379475667, 0.5834683053768598, 0.5714025222338163, 0.5678955511404917, 0.570316093472334, 0.5649860587257606, 0.5578304408834531, 0.5559437200427055, 0.5744876362956487, 0.5690461672269381, 0.5675950015966709, 0.5651802346110344, 0.5700905368878291, 0.5779883855810533, 0.5876074834511831, 0.5727750945549744, 0.5806701767903107, 0.576050250002971, 0.5650843399075361, 0.5715545771213678, 0.5764404558218442, 0.5805625491417371, 0.5636827189188737, 0.5716087010044318, 0.5812692246758021, 0.5682526889901894, 0.5861666150964223, 0.5629958968896133, 0.5746033988319911, 0.5839596390724182, 0.5843474194407463, 0.5646393522620201, 0.5748220401314589, 0.569436293381911, 0.5635534633810704, 0.5783593895343634, 0.5791393312124106, 0.5817505831901844, 0.5653544217348099, 0.5702626607739009, 0.56971208521953, 0.5843461499764369, 0.5821201572051415, 0.5701060146093369, 0.5664861901448324, 0.5744906503420609, 0.57659433896725, 0.5664859884060346, 0.5658240679364938, 0.5779754811754594, 0.5605218284405195, 0.564336318236131, 0.5676261862883201, 0.5679673357651784, 0.5710463363390702], 'loss': [2.6220378426512503, 0.9077622895254857, 0.654923970877635, 0.5706284173924819, 0.5259869723321986, 0.4935149681158065, 0.470452695494042, 0.453999329240496, 0.4373226871511807, 0.42735206689175387, 0.41676959043046946, 0.4073965395881078, 0.40039709546541163, 0.39512660532137084, 0.38950652232317867, 0.381212385567332, 0.3759750106353816, 0.37229756261000035, 0.36441763083037443, 0.36233016310401767, 0.35937649917802633, 0.355250966149833, 0.35002394003653936, 0.3474769209717117, 0.3441388605211116, 0.342399233427367, 0.3395345603244436, 0.3367336495032799, 0.3353962556721924, 0.3315179695928491, 0.33029955834972125, 0.3273618343455165, 0.32514989752616874, 0.32456015019215395, 0.32392381610580556, 0.32029950207288793, 0.32105206228661426, 0.3164852287489407, 0.31502229220464995, 0.3141124800547104, 0.31109642225537454, 0.31087357627887036, 0.3110657307721917, 0.30772936022843445, 0.3059427871630881, 0.30486214708976284, 0.3038373550596486, 0.30276652948504323, 0.3023578167307985, 0.3003666907271303, 0.298868338461238, 0.29884137781763787, 0.2999552241756304, 0.2974619435079971, 0.29679900634270096, 0.2954685322189313, 0.2927745833345679, 0.2918884027221926, 0.29272983393952334, 0.29247930902380637, 0.29062177680201234, 0.29073707596804726, 0.28762014857915497, 0.2877672900933022, 0.28613280870977564, 0.2867904477790967, 0.2859288212102596, 0.28515070588026037, 0.2833116119894981, 0.2847679847997239, 0.2832869044157628, 0.28075153028614286, 0.2823871784953188, 0.2808927222887089, 0.2806478190782665, 0.28047381454834275, 0.27738598907091716, 0.27784588171922775, 0.28008503450696937, 0.2768734724805505, 0.27690883525170096, 0.2756132688385352, 0.27507064753514116, 0.2757561963763083, 0.27438050190768953, 0.272348836065713, 0.27292977727933815, 0.2732144144807675, 0.27060153823403277, 0.2717822545609065, 0.27201901828793046, 0.27000064114016775, 0.2692903806244569, 0.2697717880401226, 0.2699327284775459, 0.26838135154476184, 0.26809617812141195, 0.26698433124006515, 0.2678026343765134, 0.2672661797928654, 0.266443601148678, 0.26603350643850854], 'acc': [0.5911043958696703, 0.8935547083558537, 0.9109152320631204, 0.9214014999048303, 0.9260160550138425, 0.9291297255335924, 0.9312782907391413, 0.9326747710179504, 0.9341773580418602, 0.9351284081872336, 0.9362587039347319, 0.9370236651413469, 0.9375745559666613, 0.938184575495614, 0.9384955231701219, 0.9392910795019175, 0.9397516756230128, 0.9400277955719194, 0.9407164930835549, 0.9409560802501142, 0.9411861754086013, 0.9415268797304076, 0.9419345109376764, 0.9421252796408722, 0.9423824928623278, 0.9425378099013813, 0.942781965802717, 0.9429308783740868, 0.9431249291532035, 0.9434007167112538, 0.9435113901297325, 0.9436531624406573, 0.943840034397438, 0.9439933799096583, 0.9440484898980667, 0.9442504104802302, 0.9442493467217473, 0.944565926680626, 0.9447587585851603, 0.9447498481057947, 0.9449628311132335, 0.9450847636748534, 0.9450867842794575, 0.9452585489352141, 0.9454886046028067, 0.945699239287288, 0.9456234631047613, 0.9457633966703889, 0.9457506274842781, 0.945804387124869, 0.946027655448903, 0.9460440849307982, 0.9460341749865884, 0.9461001507043948, 0.9461417204392832, 0.9462687954200784, 0.9465553587481048, 0.9465564431920325, 0.9464781185605039, 0.9465643158370605, 0.946670506088032, 0.9465532762135987, 0.9470027856453862, 0.9468440284294076, 0.9470725772093442, 0.9469691577800292, 0.9471622065601562, 0.9470618654251715, 0.947215281651599, 0.9472087834974854, 0.9472745846285984, 0.9473860286967094, 0.9473376584363074, 0.9475167655894251, 0.9475983257587464, 0.9475054809124303, 0.9477421859473218, 0.9477775683649723, 0.9475350746213098, 0.947829860103072, 0.9477750187176109, 0.9479009828850713, 0.9479746136247128, 0.9478851777210145, 0.9480433116416084, 0.9480752155073431, 0.9479916136631785, 0.9480463955924155, 0.9482974641978119, 0.9481808091181841, 0.9480574807975165, 0.9483877623157067, 0.948260976925642, 0.948418754350762, 0.9483182156843463, 0.9484275550263115, 0.9484400803462546, 0.948614644320438, 0.948490693985201, 0.9485903038295181, 0.9486459746501943, 0.9486058664357081], 'mDice': [0.13162229918915772, 0.396730292242501, 0.5049253212485401, 0.5501681702455603, 0.575617368608496, 0.5952186121674995, 0.6093536672706062, 0.6198625984056008, 0.6304124562346516, 0.6371713065797636, 0.6441687553898386, 0.6503397034980886, 0.6550032288553441, 0.6587329898979527, 0.6622764143921359, 0.6680007430995444, 0.6717191862464116, 0.67410400568378, 0.6796074079695437, 0.6812130282706443, 0.6831899645154155, 0.6861174013037903, 0.6898672462532158, 0.691712879149509, 0.6940065050140514, 0.695207455589643, 0.6973248711153885, 0.6993167405252493, 0.7004259756094502, 0.7031490223484484, 0.704061838332263, 0.7061432242602382, 0.7077742090724792, 0.7083179798830285, 0.7088610165389406, 0.7113728549750234, 0.7110117521715221, 0.7141271999904087, 0.7153049198109912, 0.7159698562825242, 0.7182310256506809, 0.7183290289565997, 0.7182814710850228, 0.7207836002526463, 0.7221460401225791, 0.7229987942819543, 0.7236964785776752, 0.724544426028957, 0.7247800040066952, 0.726318954910221, 0.7275028904513614, 0.7274806315989267, 0.7267244109574866, 0.7285446363721048, 0.7291438615015376, 0.7300741772452459, 0.7321226967554146, 0.7328574961537663, 0.7322358132607051, 0.7323790676290562, 0.7339266867509223, 0.7336755242886869, 0.7360524939817882, 0.7360345583378494, 0.7372382830003525, 0.7367827103255168, 0.7373887006893244, 0.7380220631023598, 0.7393908001812998, 0.7383122948453312, 0.7394741147160145, 0.7413802966688497, 0.7401787712104996, 0.7412999351998927, 0.7414671929078515, 0.7416186167186096, 0.7440106294630726, 0.7436358877117977, 0.7419820011766989, 0.7444093597998404, 0.7444437701225193, 0.7453833363938571, 0.7458033188016259, 0.7453351009159217, 0.7463772512445324, 0.7479309875741058, 0.747467979441091, 0.7473039437426552, 0.749332822205824, 0.7484007041403522, 0.7482193901421651, 0.7497603623264337, 0.7503895711208373, 0.7500027429570486, 0.7498801682561149, 0.7510296549731533, 0.751345771122911, 0.752190034074844, 0.7515458511182614, 0.7520600547322618, 0.7526271215974213, 0.7529629558135165]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.10s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.91s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.74s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:30,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:49,  1.66s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:41,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:14,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:27,  1.60s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:06,  1.53s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:22,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:15,  1.57s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:36,  1.66s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:52,  1.72s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:35,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:50,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:35,  1.67s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:37,  1.69s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:48,  1.73s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:56,  1.77s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:32,  1.69s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:33,  1.70s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:26,  1.68s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:36,  1.73s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:18,  1.67s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:18,  1.67s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:04,  1.63s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:16,  1.68s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:24,  1.72s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:11,  1.67s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:10,  1.67s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:09,  1.68s/it]predicting train subjects:  11%|█         | 30/285 [00:49<07:18,  1.72s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:24,  1.75s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:06,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:54<07:05,  1.69s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:20,  1.76s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<07:04,  1.70s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<07:04,  1.71s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:23,  1.79s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<07:12,  1.76s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:53,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:36,  1.63s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:46,  1.68s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<07:08,  1.78s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:56,  1.74s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<07:06,  1.79s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:47,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:49,  1.73s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<07:02,  1.79s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:57,  1.78s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<07:05,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<06:46,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:49,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:36,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:35<06:41,  1.75s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:28,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:40<06:46,  1.80s/it]predicting train subjects:  21%|██        | 60/285 [01:42<06:53,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<06:35,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<06:44,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:18,  1.72s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<06:17,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<06:17,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [01:56<06:04,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:11,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [01:59<06:08,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:01<06:09,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:02<05:56,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:04<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:06<05:57,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:08<05:59,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:09<05:57,  1.71s/it]predicting train subjects:  27%|██▋       | 77/285 [02:11<05:48,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:38,  1.64s/it]predicting train subjects:  28%|██▊       | 79/285 [02:14<05:46,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:16<05:49,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:17<05:34,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:19<05:35,  1.66s/it]predicting train subjects:  29%|██▉       | 83/285 [02:21<05:26,  1.61s/it]predicting train subjects:  29%|██▉       | 84/285 [02:22<05:24,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:24<05:26,  1.63s/it]predicting train subjects:  30%|███       | 86/285 [02:26<05:35,  1.69s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:37,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:29<05:27,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:31<05:30,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:33<05:31,  1.70s/it]predicting train subjects:  32%|███▏      | 91/285 [02:34<05:27,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:36<05:30,  1.71s/it]predicting train subjects:  33%|███▎      | 93/285 [02:38<05:22,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:39<05:22,  1.69s/it]predicting train subjects:  33%|███▎      | 95/285 [02:41<05:26,  1.72s/it]predicting train subjects:  34%|███▎      | 96/285 [02:43<05:20,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:20,  1.71s/it]predicting train subjects:  34%|███▍      | 98/285 [02:46<05:21,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:48<05:17,  1.71s/it]predicting train subjects:  35%|███▌      | 100/285 [02:50<05:15,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:51<05:03,  1.65s/it]predicting train subjects:  36%|███▌      | 102/285 [02:53<05:02,  1.65s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<04:51,  1.60s/it]predicting train subjects:  36%|███▋      | 104/285 [02:56<04:54,  1.63s/it]predicting train subjects:  37%|███▋      | 105/285 [02:58<04:57,  1.66s/it]predicting train subjects:  37%|███▋      | 106/285 [02:59<04:50,  1.62s/it]predicting train subjects:  38%|███▊      | 107/285 [03:01<04:52,  1.64s/it]predicting train subjects:  38%|███▊      | 108/285 [03:03<04:52,  1.65s/it]predicting train subjects:  38%|███▊      | 109/285 [03:04<05:00,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:06<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:08<04:59,  1.72s/it]predicting train subjects:  39%|███▉      | 112/285 [03:10<05:08,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<05:12,  1.81s/it]predicting train subjects:  40%|████      | 114/285 [03:14<05:18,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:16<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:18<05:21,  1.90s/it]predicting train subjects:  41%|████      | 117/285 [03:19<05:07,  1.83s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:23<05:07,  1.85s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<05:00,  1.82s/it]predicting train subjects:  42%|████▏     | 121/285 [03:26<04:52,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:28<04:44,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:38,  1.72s/it]predicting train subjects:  44%|████▎     | 124/285 [03:31<04:29,  1.67s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:34<04:14,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:36<04:09,  1.58s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<04:16,  1.63s/it]predicting train subjects:  45%|████▌     | 129/285 [03:39<04:10,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<04:05,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [03:42<04:07,  1.61s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<04:10,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [03:46<04:10,  1.64s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<04:08,  1.64s/it]predicting train subjects:  47%|████▋     | 135/285 [03:49<04:01,  1.61s/it]predicting train subjects:  48%|████▊     | 136/285 [03:50<04:00,  1.62s/it]predicting train subjects:  48%|████▊     | 137/285 [03:53<04:18,  1.75s/it]predicting train subjects:  48%|████▊     | 138/285 [03:54<04:10,  1.70s/it]predicting train subjects:  49%|████▉     | 139/285 [03:56<04:07,  1.70s/it]predicting train subjects:  49%|████▉     | 140/285 [03:58<04:09,  1.72s/it]predicting train subjects:  49%|████▉     | 141/285 [03:59<03:58,  1.66s/it]predicting train subjects:  50%|████▉     | 142/285 [04:01<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:02<03:46,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:04<03:47,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:05<03:43,  1.60s/it]predicting train subjects:  51%|█████     | 146/285 [04:07<03:45,  1.62s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:40,  1.60s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:10<03:48,  1.67s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:41,  1.63s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:13<03:33,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:33,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:29,  1.57s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:34,  1.62s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:35,  1.65s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:22<03:37,  1.67s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:35,  1.67s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:25<03:30,  1.64s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:27<03:26,  1.63s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:28<03:21,  1.60s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:30<03:14,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:31<03:14,  1.57s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:33<03:13,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:34<03:15,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<03:17,  1.63s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<03:15,  1.63s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:40<03:19,  1.67s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<03:20,  1.70s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:43<03:15,  1.67s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:45<03:12,  1.66s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:46<03:06,  1.62s/it]predicting train subjects:  60%|██████    | 171/285 [04:48<03:06,  1.64s/it]predicting train subjects:  60%|██████    | 172/285 [04:49<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [04:51<02:58,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [04:52<02:52,  1.55s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:54<02:56,  1.61s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:56<03:06,  1.71s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:58<03:00,  1.67s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:59<02:48,  1.57s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:00<02:46,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:02<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:04<03:02,  1.76s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:06<03:00,  1.75s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:08<02:51,  1.68s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:09<02:47,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:11<02:38,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:13<02:52,  1.74s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:15<02:52,  1.76s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:17<02:57,  1.83s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:18<02:46,  1.73s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:19<02:36,  1.65s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:21<02:37,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:23<02:37,  1.69s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:25<02:32,  1.65s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:26<02:24,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:27<02:21,  1.58s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:29<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:31<02:36,  1.78s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:33<02:40,  1.85s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:35<02:26,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:36<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:38<02:25,  1.73s/it]predicting train subjects:  71%|███████   | 202/285 [05:40<02:23,  1.73s/it]predicting train subjects:  71%|███████   | 203/285 [05:42<02:23,  1.75s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:43<02:16,  1.69s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:45<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:46<02:04,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:48<02:12,  1.70s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:50<02:15,  1.76s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:52<02:18,  1.82s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:54<02:08,  1.71s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:55<01:58,  1.60s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:57<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:58<01:56,  1.62s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:00<01:51,  1.57s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:02<01:56,  1.66s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:03<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:05<01:55,  1.70s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:07<02:00,  1.81s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:09<02:02,  1.85s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:10<01:51,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:12<01:47,  1.68s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:14<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:15<01:40,  1.62s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:16<01:34,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:18<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:20<01:40,  1.70s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:22<01:44,  1.80s/it]predicting train subjects:  80%|████████  | 228/285 [06:24<01:44,  1.83s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:43,  1.85s/it]predicting train subjects:  81%|████████  | 230/285 [06:27<01:35,  1.73s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:30,  1.68s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:31<01:28,  1.68s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:32<01:25,  1.64s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:34<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:36<01:22,  1.64s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:37<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:39<01:27,  1.82s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:41<01:25,  1.81s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:43<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:44<01:16,  1.70s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:46<01:13,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:48<01:11,  1.66s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:49<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:51<01:08,  1.68s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:53<01:04,  1.62s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:54<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:57<01:09,  1.83s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:58<01:08,  1.85s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:00<01:02,  1.73s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:01<00:58,  1.66s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:03<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:04<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:06<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:08<00:53,  1.74s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:10<00:51,  1.71s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:11<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:47,  1.68s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:49,  1.83s/it]predicting train subjects:  91%|█████████ | 259/285 [07:17<00:47,  1.83s/it]predicting train subjects:  91%|█████████ | 260/285 [07:19<00:43,  1.74s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:20<00:40,  1.71s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:22<00:37,  1.64s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:23<00:34,  1.57s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:25<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:27<00:34,  1.74s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:28<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:30<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:32<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:33<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:34<00:22,  1.53s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:36<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:37<00:19,  1.51s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:39<00:17,  1.47s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:40<00:15,  1.42s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:42<00:15,  1.51s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:43<00:14,  1.56s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:45<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:46<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:48<00:08,  1.48s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:49<00:07,  1.44s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:50<00:05,  1.43s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:52<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:53<00:02,  1.47s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:55<00:01,  1.53s/it]predicting train subjects: 100%|██████████| 285/285 [07:57<00:00,  1.57s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:33,  1.81s/it]Loading train:   1%|          | 2/285 [00:03<07:58,  1.69s/it]Loading train:   1%|          | 3/285 [00:04<07:51,  1.67s/it]Loading train:   1%|▏         | 4/285 [00:06<08:04,  1.73s/it]Loading train:   2%|▏         | 5/285 [00:08<07:57,  1.70s/it]Loading train:   2%|▏         | 6/285 [00:09<07:32,  1.62s/it]Loading train:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]Loading train:   3%|▎         | 8/285 [00:12<07:17,  1.58s/it]Loading train:   3%|▎         | 9/285 [00:14<07:25,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<06:53,  1.50s/it]Loading train:   4%|▍         | 11/285 [00:16<06:16,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:18<05:54,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:19<05:31,  1.22s/it]Loading train:   5%|▍         | 14/285 [00:20<06:00,  1.33s/it]Loading train:   5%|▌         | 15/285 [00:22<06:05,  1.35s/it]Loading train:   6%|▌         | 16/285 [00:23<05:51,  1.31s/it]Loading train:   6%|▌         | 17/285 [00:24<05:25,  1.22s/it]Loading train:   6%|▋         | 18/285 [00:25<05:43,  1.29s/it]Loading train:   7%|▋         | 19/285 [00:26<05:19,  1.20s/it]Loading train:   7%|▋         | 20/285 [00:27<05:20,  1.21s/it]Loading train:   7%|▋         | 21/285 [00:29<05:28,  1.24s/it]Loading train:   8%|▊         | 22/285 [00:30<05:06,  1.17s/it]Loading train:   8%|▊         | 23/285 [00:31<05:17,  1.21s/it]Loading train:   8%|▊         | 24/285 [00:32<04:58,  1.14s/it]Loading train:   9%|▉         | 25/285 [00:33<05:00,  1.16s/it]Loading train:   9%|▉         | 26/285 [00:34<04:58,  1.15s/it]Loading train:   9%|▉         | 27/285 [00:35<04:37,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:37<05:22,  1.25s/it]Loading train:  10%|█         | 29/285 [00:38<05:10,  1.21s/it]Loading train:  11%|█         | 30/285 [00:39<05:09,  1.21s/it]Loading train:  11%|█         | 31/285 [00:40<04:56,  1.17s/it]Loading train:  11%|█         | 32/285 [00:41<04:26,  1.05s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:46,  1.14s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:49,  1.15s/it]Loading train:  12%|█▏        | 35/285 [00:45<04:55,  1.18s/it]Loading train:  13%|█▎        | 36/285 [00:46<04:44,  1.14s/it]Loading train:  13%|█▎        | 37/285 [00:47<04:34,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:48<04:19,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:05,  1.00it/s]Loading train:  14%|█▍        | 40/285 [00:50<03:55,  1.04it/s]Loading train:  14%|█▍        | 41/285 [00:50<03:34,  1.14it/s]Loading train:  15%|█▍        | 42/285 [00:51<03:21,  1.20it/s]Loading train:  15%|█▌        | 43/285 [00:52<03:21,  1.20it/s]Loading train:  15%|█▌        | 44/285 [00:53<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:54<03:34,  1.12it/s]Loading train:  16%|█▌        | 46/285 [00:55<03:38,  1.09it/s]Loading train:  16%|█▋        | 47/285 [00:56<03:42,  1.07it/s]Loading train:  17%|█▋        | 48/285 [00:57<03:39,  1.08it/s]Loading train:  17%|█▋        | 49/285 [00:58<03:39,  1.07it/s]Loading train:  18%|█▊        | 50/285 [00:59<03:37,  1.08it/s]Loading train:  18%|█▊        | 51/285 [01:00<03:39,  1.07it/s]Loading train:  18%|█▊        | 52/285 [01:00<03:26,  1.13it/s]Loading train:  19%|█▊        | 53/285 [01:01<03:25,  1.13it/s]Loading train:  19%|█▉        | 54/285 [01:02<03:24,  1.13it/s]Loading train:  19%|█▉        | 55/285 [01:03<03:21,  1.14it/s]Loading train:  20%|█▉        | 56/285 [01:05<04:10,  1.09s/it]Loading train:  20%|██        | 57/285 [01:05<03:44,  1.01it/s]Loading train:  20%|██        | 58/285 [01:06<03:40,  1.03it/s]Loading train:  21%|██        | 59/285 [01:07<03:41,  1.02it/s]Loading train:  21%|██        | 60/285 [01:08<03:39,  1.03it/s]Loading train:  21%|██▏       | 61/285 [01:09<03:24,  1.10it/s]Loading train:  22%|██▏       | 62/285 [01:10<03:21,  1.11it/s]Loading train:  22%|██▏       | 63/285 [01:11<03:32,  1.05it/s]Loading train:  22%|██▏       | 64/285 [01:12<03:51,  1.05s/it]Loading train:  23%|██▎       | 65/285 [01:14<04:29,  1.22s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:07,  1.13s/it]Loading train:  24%|██▍       | 68/285 [01:17<03:39,  1.01s/it]Loading train:  24%|██▍       | 69/285 [01:18<03:28,  1.04it/s]Loading train:  25%|██▍       | 70/285 [01:18<03:27,  1.04it/s]Loading train:  25%|██▍       | 71/285 [01:19<03:25,  1.04it/s]Loading train:  25%|██▌       | 72/285 [01:20<03:17,  1.08it/s]Loading train:  26%|██▌       | 73/285 [01:21<03:15,  1.09it/s]Loading train:  26%|██▌       | 74/285 [01:22<03:09,  1.12it/s]Loading train:  26%|██▋       | 75/285 [01:23<03:12,  1.09it/s]Loading train:  27%|██▋       | 76/285 [01:24<03:12,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:25<03:03,  1.13it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:01,  1.14it/s]Loading train:  28%|██▊       | 79/285 [01:27<03:08,  1.10it/s]Loading train:  28%|██▊       | 80/285 [01:27<03:04,  1.11it/s]Loading train:  28%|██▊       | 81/285 [01:28<02:58,  1.15it/s]Loading train:  29%|██▉       | 82/285 [01:29<02:58,  1.13it/s]Loading train:  29%|██▉       | 83/285 [01:30<02:55,  1.15it/s]Loading train:  29%|██▉       | 84/285 [01:31<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:32<02:51,  1.16it/s]Loading train:  30%|███       | 86/285 [01:33<02:52,  1.15it/s]Loading train:  31%|███       | 87/285 [01:34<02:55,  1.13it/s]Loading train:  31%|███       | 88/285 [01:34<02:56,  1.12it/s]Loading train:  31%|███       | 89/285 [01:35<02:55,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:36<02:57,  1.10it/s]Loading train:  32%|███▏      | 91/285 [01:37<02:51,  1.13it/s]Loading train:  32%|███▏      | 92/285 [01:38<02:55,  1.10it/s]Loading train:  33%|███▎      | 93/285 [01:39<02:53,  1.11it/s]Loading train:  33%|███▎      | 94/285 [01:40<02:51,  1.12it/s]Loading train:  33%|███▎      | 95/285 [01:41<02:55,  1.08it/s]Loading train:  34%|███▎      | 96/285 [01:42<02:46,  1.13it/s]Loading train:  34%|███▍      | 97/285 [01:42<02:47,  1.12it/s]Loading train:  34%|███▍      | 98/285 [01:43<02:48,  1.11it/s]Loading train:  35%|███▍      | 99/285 [01:44<02:46,  1.12it/s]Loading train:  35%|███▌      | 100/285 [01:45<02:50,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:46<02:42,  1.13it/s]Loading train:  36%|███▌      | 102/285 [01:47<02:44,  1.12it/s]Loading train:  36%|███▌      | 103/285 [01:48<02:36,  1.16it/s]Loading train:  36%|███▋      | 104/285 [01:49<02:33,  1.18it/s]Loading train:  37%|███▋      | 105/285 [01:50<02:41,  1.11it/s]Loading train:  37%|███▋      | 106/285 [01:50<02:38,  1.13it/s]Loading train:  38%|███▊      | 107/285 [01:51<02:42,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:52<02:36,  1.13it/s]Loading train:  38%|███▊      | 109/285 [01:53<02:36,  1.12it/s]Loading train:  39%|███▊      | 110/285 [01:54<02:37,  1.11it/s]Loading train:  39%|███▉      | 111/285 [01:55<02:31,  1.15it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:28,  1.16it/s]Loading train:  40%|███▉      | 113/285 [01:57<02:31,  1.13it/s]Loading train:  40%|████      | 114/285 [01:58<02:29,  1.15it/s]Loading train:  40%|████      | 115/285 [01:58<02:30,  1.13it/s]Loading train:  41%|████      | 116/285 [01:59<02:32,  1.11it/s]Loading train:  41%|████      | 117/285 [02:00<02:31,  1.11it/s]Loading train:  41%|████▏     | 118/285 [02:01<02:23,  1.16it/s]Loading train:  42%|████▏     | 119/285 [02:02<02:25,  1.14it/s]Loading train:  42%|████▏     | 120/285 [02:03<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [02:04<02:44,  1.00s/it]Loading train:  43%|████▎     | 122/285 [02:05<02:50,  1.04s/it]Loading train:  43%|████▎     | 123/285 [02:06<02:51,  1.06s/it]Loading train:  44%|████▎     | 124/285 [02:07<02:34,  1.04it/s]Loading train:  44%|████▍     | 125/285 [02:08<02:22,  1.12it/s]Loading train:  44%|████▍     | 126/285 [02:09<02:13,  1.19it/s]Loading train:  45%|████▍     | 127/285 [02:09<02:06,  1.25it/s]Loading train:  45%|████▍     | 128/285 [02:10<02:09,  1.21it/s]Loading train:  45%|████▌     | 129/285 [02:11<02:06,  1.24it/s]Loading train:  46%|████▌     | 130/285 [02:12<01:58,  1.31it/s]Loading train:  46%|████▌     | 131/285 [02:12<01:54,  1.34it/s]Loading train:  46%|████▋     | 132/285 [02:13<01:50,  1.38it/s]Loading train:  47%|████▋     | 133/285 [02:14<01:47,  1.42it/s]Loading train:  47%|████▋     | 134/285 [02:14<01:47,  1.41it/s]Loading train:  47%|████▋     | 135/285 [02:15<01:45,  1.42it/s]Loading train:  48%|████▊     | 136/285 [02:16<01:42,  1.45it/s]Loading train:  48%|████▊     | 137/285 [02:16<01:44,  1.42it/s]Loading train:  48%|████▊     | 138/285 [02:17<01:43,  1.42it/s]Loading train:  49%|████▉     | 139/285 [02:18<01:43,  1.40it/s]Loading train:  49%|████▉     | 140/285 [02:19<01:41,  1.43it/s]Loading train:  49%|████▉     | 141/285 [02:19<01:37,  1.48it/s]Loading train:  50%|████▉     | 142/285 [02:20<01:34,  1.52it/s]Loading train:  50%|█████     | 143/285 [02:20<01:34,  1.50it/s]Loading train:  51%|█████     | 144/285 [02:21<01:37,  1.44it/s]Loading train:  51%|█████     | 145/285 [02:22<01:39,  1.40it/s]Loading train:  51%|█████     | 146/285 [02:23<01:44,  1.33it/s]Loading train:  52%|█████▏    | 147/285 [02:24<01:45,  1.31it/s]Loading train:  52%|█████▏    | 148/285 [02:24<01:46,  1.28it/s]Loading train:  52%|█████▏    | 149/285 [02:25<01:48,  1.25it/s]Loading train:  53%|█████▎    | 150/285 [02:26<01:42,  1.31it/s]Loading train:  53%|█████▎    | 151/285 [02:27<01:43,  1.29it/s]Loading train:  53%|█████▎    | 152/285 [02:27<01:39,  1.34it/s]Loading train:  54%|█████▎    | 153/285 [02:28<01:40,  1.31it/s]Loading train:  54%|█████▍    | 154/285 [02:29<01:40,  1.30it/s]Loading train:  54%|█████▍    | 155/285 [02:30<01:36,  1.34it/s]Loading train:  55%|█████▍    | 156/285 [02:31<01:39,  1.29it/s]Loading train:  55%|█████▌    | 157/285 [02:31<01:35,  1.34it/s]Loading train:  55%|█████▌    | 158/285 [02:32<01:33,  1.35it/s]Loading train:  56%|█████▌    | 159/285 [02:33<01:28,  1.42it/s]Loading train:  56%|█████▌    | 160/285 [02:33<01:25,  1.47it/s]Loading train:  56%|█████▋    | 161/285 [02:34<01:24,  1.47it/s]Loading train:  57%|█████▋    | 162/285 [02:35<01:28,  1.39it/s]Loading train:  57%|█████▋    | 163/285 [02:35<01:28,  1.37it/s]Loading train:  58%|█████▊    | 164/285 [02:36<01:30,  1.34it/s]Loading train:  58%|█████▊    | 165/285 [02:37<01:28,  1.35it/s]Loading train:  58%|█████▊    | 166/285 [02:38<01:29,  1.33it/s]Loading train:  59%|█████▊    | 167/285 [02:38<01:28,  1.34it/s]Loading train:  59%|█████▉    | 168/285 [02:39<01:27,  1.34it/s]Loading train:  59%|█████▉    | 169/285 [02:40<01:31,  1.27it/s]Loading train:  60%|█████▉    | 170/285 [02:41<01:28,  1.30it/s]Loading train:  60%|██████    | 171/285 [02:42<01:25,  1.33it/s]Loading train:  60%|██████    | 172/285 [02:42<01:21,  1.38it/s]Loading train:  61%|██████    | 173/285 [02:43<01:22,  1.36it/s]Loading train:  61%|██████    | 174/285 [02:44<01:22,  1.34it/s]Loading train:  61%|██████▏   | 175/285 [02:44<01:22,  1.33it/s]Loading train:  62%|██████▏   | 176/285 [02:45<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:46<01:21,  1.33it/s]Loading train:  62%|██████▏   | 178/285 [02:47<01:19,  1.35it/s]Loading train:  63%|██████▎   | 179/285 [02:48<01:20,  1.32it/s]Loading train:  63%|██████▎   | 180/285 [02:48<01:26,  1.21it/s]Loading train:  64%|██████▎   | 181/285 [02:49<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [02:50<01:26,  1.19it/s]Loading train:  64%|██████▍   | 183/285 [02:51<01:20,  1.26it/s]Loading train:  65%|██████▍   | 184/285 [02:52<01:19,  1.27it/s]Loading train:  65%|██████▍   | 185/285 [02:52<01:16,  1.30it/s]Loading train:  65%|██████▌   | 186/285 [02:53<01:21,  1.21it/s]Loading train:  66%|██████▌   | 187/285 [02:54<01:25,  1.15it/s]Loading train:  66%|██████▌   | 188/285 [02:55<01:25,  1.13it/s]Loading train:  66%|██████▋   | 189/285 [02:56<01:18,  1.22it/s]Loading train:  67%|██████▋   | 190/285 [02:57<01:13,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:15,  1.25it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:12,  1.28it/s]Loading train:  68%|██████▊   | 193/285 [02:59<01:09,  1.33it/s]Loading train:  68%|██████▊   | 194/285 [03:00<01:08,  1.33it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:08,  1.31it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:11,  1.24it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:13,  1.19it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:12,  1.21it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [03:04<01:05,  1.30it/s]Loading train:  71%|███████   | 201/285 [03:05<01:10,  1.19it/s]Loading train:  71%|███████   | 202/285 [03:06<01:10,  1.18it/s]Loading train:  71%|███████   | 203/285 [03:07<01:07,  1.22it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:03,  1.28it/s]Loading train:  72%|███████▏  | 205/285 [03:08<00:59,  1.34it/s]Loading train:  72%|███████▏  | 206/285 [03:09<00:58,  1.35it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:03,  1.22it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:03,  1.22it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:06,  1.15it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [03:13<00:58,  1.27it/s]Loading train:  74%|███████▍  | 212/285 [03:14<00:57,  1.27it/s]Loading train:  75%|███████▍  | 213/285 [03:15<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:16<00:53,  1.33it/s]Loading train:  75%|███████▌  | 215/285 [03:17<00:56,  1.25it/s]Loading train:  76%|███████▌  | 216/285 [03:17<00:53,  1.29it/s]Loading train:  76%|███████▌  | 217/285 [03:18<00:54,  1.26it/s]Loading train:  76%|███████▋  | 218/285 [03:19<00:54,  1.23it/s]Loading train:  77%|███████▋  | 219/285 [03:20<00:55,  1.20it/s]Loading train:  77%|███████▋  | 220/285 [03:20<00:50,  1.30it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:47,  1.35it/s]Loading train:  78%|███████▊  | 222/285 [03:22<00:45,  1.38it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:23<00:42,  1.45it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:40,  1.47it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:45,  1.31it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:46,  1.26it/s]Loading train:  80%|████████  | 228/285 [03:26<00:46,  1.24it/s]Loading train:  80%|████████  | 229/285 [03:27<00:44,  1.27it/s]Loading train:  81%|████████  | 230/285 [03:28<00:41,  1.33it/s]Loading train:  81%|████████  | 231/285 [03:29<00:39,  1.37it/s]Loading train:  81%|████████▏ | 232/285 [03:29<00:38,  1.37it/s]Loading train:  82%|████████▏ | 233/285 [03:30<00:35,  1.45it/s]Loading train:  82%|████████▏ | 234/285 [03:31<00:38,  1.31it/s]Loading train:  82%|████████▏ | 235/285 [03:32<00:36,  1.36it/s]Loading train:  83%|████████▎ | 236/285 [03:32<00:38,  1.27it/s]Loading train:  83%|████████▎ | 237/285 [03:33<00:38,  1.24it/s]Loading train:  84%|████████▎ | 238/285 [03:34<00:39,  1.20it/s]Loading train:  84%|████████▍ | 239/285 [03:35<00:37,  1.21it/s]Loading train:  84%|████████▍ | 240/285 [03:36<00:35,  1.27it/s]Loading train:  85%|████████▍ | 241/285 [03:36<00:32,  1.34it/s]Loading train:  85%|████████▍ | 242/285 [03:37<00:30,  1.40it/s]Loading train:  85%|████████▌ | 243/285 [03:38<00:29,  1.44it/s]Loading train:  86%|████████▌ | 244/285 [03:38<00:30,  1.32it/s]Loading train:  86%|████████▌ | 245/285 [03:39<00:27,  1.43it/s]Loading train:  86%|████████▋ | 246/285 [03:40<00:30,  1.27it/s]Loading train:  87%|████████▋ | 247/285 [03:41<00:31,  1.21it/s]Loading train:  87%|████████▋ | 248/285 [03:42<00:30,  1.20it/s]Loading train:  87%|████████▋ | 249/285 [03:43<00:28,  1.27it/s]Loading train:  88%|████████▊ | 250/285 [03:43<00:26,  1.30it/s]Loading train:  88%|████████▊ | 251/285 [03:44<00:25,  1.34it/s]Loading train:  88%|████████▊ | 252/285 [03:45<00:24,  1.37it/s]Loading train:  89%|████████▉ | 253/285 [03:45<00:24,  1.29it/s]Loading train:  89%|████████▉ | 254/285 [03:46<00:25,  1.21it/s]Loading train:  89%|████████▉ | 255/285 [03:47<00:24,  1.24it/s]Loading train:  90%|████████▉ | 256/285 [03:48<00:21,  1.33it/s]Loading train:  90%|█████████ | 257/285 [03:49<00:20,  1.35it/s]Loading train:  91%|█████████ | 258/285 [03:49<00:21,  1.27it/s]Loading train:  91%|█████████ | 259/285 [03:50<00:20,  1.27it/s]Loading train:  91%|█████████ | 260/285 [03:51<00:18,  1.34it/s]Loading train:  92%|█████████▏| 261/285 [03:52<00:17,  1.38it/s]Loading train:  92%|█████████▏| 262/285 [03:52<00:16,  1.40it/s]Loading train:  92%|█████████▏| 263/285 [03:53<00:15,  1.41it/s]Loading train:  93%|█████████▎| 264/285 [03:54<00:16,  1.29it/s]Loading train:  93%|█████████▎| 265/285 [03:55<00:17,  1.16it/s]Loading train:  93%|█████████▎| 266/285 [03:56<00:15,  1.20it/s]Loading train:  94%|█████████▎| 267/285 [03:56<00:14,  1.22it/s]Loading train:  94%|█████████▍| 268/285 [03:57<00:13,  1.22it/s]Loading train:  94%|█████████▍| 269/285 [03:58<00:13,  1.21it/s]Loading train:  95%|█████████▍| 270/285 [03:59<00:11,  1.25it/s]Loading train:  95%|█████████▌| 271/285 [04:00<00:10,  1.28it/s]Loading train:  95%|█████████▌| 272/285 [04:00<00:10,  1.25it/s]Loading train:  96%|█████████▌| 273/285 [04:01<00:09,  1.28it/s]Loading train:  96%|█████████▌| 274/285 [04:02<00:08,  1.33it/s]Loading train:  96%|█████████▋| 275/285 [04:03<00:08,  1.25it/s]Loading train:  97%|█████████▋| 276/285 [04:04<00:07,  1.18it/s]Loading train:  97%|█████████▋| 277/285 [04:04<00:06,  1.25it/s]Loading train:  98%|█████████▊| 278/285 [04:05<00:05,  1.29it/s]Loading train:  98%|█████████▊| 279/285 [04:06<00:04,  1.28it/s]Loading train:  98%|█████████▊| 280/285 [04:07<00:03,  1.32it/s]Loading train:  99%|█████████▊| 281/285 [04:07<00:02,  1.35it/s]Loading train:  99%|█████████▉| 282/285 [04:08<00:02,  1.37it/s]Loading train:  99%|█████████▉| 283/285 [04:09<00:01,  1.27it/s]Loading train: 100%|█████████▉| 284/285 [04:10<00:00,  1.19it/s]Loading train: 100%|██████████| 285/285 [04:11<00:00,  1.11it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 54.27it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:04, 62.85it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:02, 82.95it/s]concatenating: train:  28%|██▊       | 80/285 [00:00<00:01, 106.26it/s]concatenating: train:  39%|███▉      | 111/285 [00:00<00:01, 132.22it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:00, 161.38it/s]concatenating: train:  63%|██████▎   | 179/285 [00:00<00:00, 191.43it/s]concatenating: train:  75%|███████▍  | 213/285 [00:00<00:00, 217.36it/s]concatenating: train:  87%|████████▋ | 248/285 [00:00<00:00, 244.91it/s]concatenating: train:  98%|█████████▊| 279/285 [00:01<00:00, 257.01it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 272.56it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.21s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 819.09it/s]2019-07-11 05:11:44.759955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:11:44.760044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:11:44.760060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:11:44.760068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:11:44.760487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.36it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.39it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.99it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.65it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.79it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.60it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.73it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.70it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.01it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.58it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.39it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.49it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.70it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.93it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.85it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.28it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.22it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.29it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 30)   12180       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 75)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   988         concatenate_8[0][0]              
==================================================================================================
Total params: 143,638
Trainable params: 45,058
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 2.9695 - acc: 0.6259 - mDice: 0.0919 - val_loss: 2.3636 - val_acc: 0.9017 - val_mDice: 0.1975

Epoch 00001: val_mDice improved from -inf to 0.19751, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.3037 - acc: 0.8771 - mDice: 0.2825 - val_loss: 2.1326 - val_acc: 0.9088 - val_mDice: 0.2476

Epoch 00002: val_mDice improved from 0.19751 to 0.24763, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.9088 - acc: 0.8859 - mDice: 0.3935 - val_loss: 1.8408 - val_acc: 0.9090 - val_mDice: 0.3008

Epoch 00003: val_mDice improved from 0.24763 to 0.30078, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7408 - acc: 0.8943 - mDice: 0.4602 - val_loss: 1.3235 - val_acc: 0.9156 - val_mDice: 0.4300

Epoch 00004: val_mDice improved from 0.30078 to 0.42997, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6593 - acc: 0.9006 - mDice: 0.4996 - val_loss: 1.1932 - val_acc: 0.9252 - val_mDice: 0.4914

Epoch 00005: val_mDice improved from 0.42997 to 0.49137, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.6057 - acc: 0.9062 - mDice: 0.5280 - val_loss: 1.1642 - val_acc: 0.9247 - val_mDice: 0.5054

Epoch 00006: val_mDice improved from 0.49137 to 0.50543, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5688 - acc: 0.9111 - mDice: 0.5489 - val_loss: 1.1697 - val_acc: 0.9170 - val_mDice: 0.5009

Epoch 00007: val_mDice did not improve from 0.50543
Epoch 8/300
 - 9s - loss: 0.5378 - acc: 0.9144 - mDice: 0.5668 - val_loss: 1.1354 - val_acc: 0.9312 - val_mDice: 0.4850

Epoch 00008: val_mDice did not improve from 0.50543
Epoch 9/300
 - 9s - loss: 0.5148 - acc: 0.9176 - mDice: 0.5806 - val_loss: 1.1015 - val_acc: 0.9234 - val_mDice: 0.5105

Epoch 00009: val_mDice improved from 0.50543 to 0.51048, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.4972 - acc: 0.9199 - mDice: 0.5916 - val_loss: 1.1276 - val_acc: 0.9341 - val_mDice: 0.5096

Epoch 00010: val_mDice did not improve from 0.51048
Epoch 11/300
 - 9s - loss: 0.4827 - acc: 0.9216 - mDice: 0.6006 - val_loss: 1.0644 - val_acc: 0.9291 - val_mDice: 0.5222

Epoch 00011: val_mDice improved from 0.51048 to 0.52224, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4672 - acc: 0.9240 - mDice: 0.6104 - val_loss: 1.0582 - val_acc: 0.9328 - val_mDice: 0.5300

Epoch 00012: val_mDice improved from 0.52224 to 0.53003, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.4557 - acc: 0.9253 - mDice: 0.6179 - val_loss: 1.0418 - val_acc: 0.9357 - val_mDice: 0.5380

Epoch 00013: val_mDice improved from 0.53003 to 0.53805, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 9s - loss: 0.4452 - acc: 0.9267 - mDice: 0.6249 - val_loss: 1.0465 - val_acc: 0.9332 - val_mDice: 0.5402

Epoch 00014: val_mDice improved from 0.53805 to 0.54018, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 9s - loss: 0.4350 - acc: 0.9280 - mDice: 0.6315 - val_loss: 1.0534 - val_acc: 0.9220 - val_mDice: 0.5298

Epoch 00015: val_mDice did not improve from 0.54018
Epoch 16/300
 - 9s - loss: 0.4289 - acc: 0.9287 - mDice: 0.6354 - val_loss: 1.0580 - val_acc: 0.9257 - val_mDice: 0.5277

Epoch 00016: val_mDice did not improve from 0.54018
Epoch 17/300
 - 9s - loss: 0.4204 - acc: 0.9299 - mDice: 0.6412 - val_loss: 1.0178 - val_acc: 0.9374 - val_mDice: 0.5476

Epoch 00017: val_mDice improved from 0.54018 to 0.54763, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.4142 - acc: 0.9308 - mDice: 0.6453 - val_loss: 1.0000 - val_acc: 0.9285 - val_mDice: 0.5420

Epoch 00018: val_mDice did not improve from 0.54763
Epoch 19/300
 - 9s - loss: 0.4091 - acc: 0.9313 - mDice: 0.6488 - val_loss: 0.9959 - val_acc: 0.9402 - val_mDice: 0.5459

Epoch 00019: val_mDice did not improve from 0.54763
Epoch 20/300
 - 9s - loss: 0.4016 - acc: 0.9322 - mDice: 0.6538 - val_loss: 1.0007 - val_acc: 0.9327 - val_mDice: 0.5471

Epoch 00020: val_mDice did not improve from 0.54763
Epoch 21/300
 - 9s - loss: 0.3966 - acc: 0.9329 - mDice: 0.6571 - val_loss: 1.0176 - val_acc: 0.9369 - val_mDice: 0.5512

Epoch 00021: val_mDice improved from 0.54763 to 0.55119, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 9s - loss: 0.3928 - acc: 0.9334 - mDice: 0.6597 - val_loss: 0.9721 - val_acc: 0.9377 - val_mDice: 0.5578

Epoch 00022: val_mDice improved from 0.55119 to 0.55783, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 9s - loss: 0.3864 - acc: 0.9341 - mDice: 0.6642 - val_loss: 0.9450 - val_acc: 0.9388 - val_mDice: 0.5618

Epoch 00023: val_mDice improved from 0.55783 to 0.56181, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 9s - loss: 0.3849 - acc: 0.9342 - mDice: 0.6652 - val_loss: 1.0106 - val_acc: 0.9421 - val_mDice: 0.5461

Epoch 00024: val_mDice did not improve from 0.56181
Epoch 25/300
 - 9s - loss: 0.3802 - acc: 0.9350 - mDice: 0.6685 - val_loss: 0.9530 - val_acc: 0.9428 - val_mDice: 0.5581

Epoch 00025: val_mDice did not improve from 0.56181
Epoch 26/300
 - 9s - loss: 0.3764 - acc: 0.9355 - mDice: 0.6712 - val_loss: 0.9831 - val_acc: 0.9432 - val_mDice: 0.5566

Epoch 00026: val_mDice did not improve from 0.56181
Epoch 27/300
 - 9s - loss: 0.3741 - acc: 0.9355 - mDice: 0.6728 - val_loss: 0.9634 - val_acc: 0.9409 - val_mDice: 0.5598

Epoch 00027: val_mDice did not improve from 0.56181
Epoch 28/300
 - 9s - loss: 0.3688 - acc: 0.9362 - mDice: 0.6765 - val_loss: 0.9313 - val_acc: 0.9439 - val_mDice: 0.5692

Epoch 00028: val_mDice improved from 0.56181 to 0.56919, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 9s - loss: 0.3664 - acc: 0.9366 - mDice: 0.6783 - val_loss: 0.9213 - val_acc: 0.9420 - val_mDice: 0.5687

Epoch 00029: val_mDice did not improve from 0.56919
Epoch 30/300
 - 9s - loss: 0.3668 - acc: 0.9364 - mDice: 0.6780 - val_loss: 0.9109 - val_acc: 0.9412 - val_mDice: 0.5747

Epoch 00030: val_mDice improved from 0.56919 to 0.57473, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 9s - loss: 0.3600 - acc: 0.9372 - mDice: 0.6827 - val_loss: 0.9582 - val_acc: 0.9444 - val_mDice: 0.5521

Epoch 00031: val_mDice did not improve from 0.57473
Epoch 32/300
 - 9s - loss: 0.3599 - acc: 0.9375 - mDice: 0.6829 - val_loss: 0.9629 - val_acc: 0.9376 - val_mDice: 0.5649

Epoch 00032: val_mDice did not improve from 0.57473
Epoch 33/300
 - 9s - loss: 0.3580 - acc: 0.9376 - mDice: 0.6842 - val_loss: 0.9324 - val_acc: 0.9442 - val_mDice: 0.5527

Epoch 00033: val_mDice did not improve from 0.57473
Epoch 34/300
 - 9s - loss: 0.3579 - acc: 0.9374 - mDice: 0.6842 - val_loss: 0.9862 - val_acc: 0.9406 - val_mDice: 0.5388

Epoch 00034: val_mDice did not improve from 0.57473
Epoch 35/300
 - 9s - loss: 0.3510 - acc: 0.9383 - mDice: 0.6892 - val_loss: 0.9106 - val_acc: 0.9419 - val_mDice: 0.5670

Epoch 00035: val_mDice did not improve from 0.57473
Epoch 36/300
 - 10s - loss: 0.3509 - acc: 0.9383 - mDice: 0.6893 - val_loss: 0.8979 - val_acc: 0.9429 - val_mDice: 0.5693

Epoch 00036: val_mDice did not improve from 0.57473
Epoch 37/300
 - 9s - loss: 0.3458 - acc: 0.9389 - mDice: 0.6929 - val_loss: 0.8870 - val_acc: 0.9456 - val_mDice: 0.5736

Epoch 00037: val_mDice did not improve from 0.57473
Epoch 38/300
 - 9s - loss: 0.3453 - acc: 0.9387 - mDice: 0.6932 - val_loss: 0.9221 - val_acc: 0.9350 - val_mDice: 0.5518

Epoch 00038: val_mDice did not improve from 0.57473
Epoch 39/300
 - 9s - loss: 0.3454 - acc: 0.9390 - mDice: 0.6933 - val_loss: 0.9556 - val_acc: 0.9426 - val_mDice: 0.5305

Epoch 00039: val_mDice did not improve from 0.57473
Epoch 40/300
 - 9s - loss: 0.3412 - acc: 0.9393 - mDice: 0.6963 - val_loss: 0.8929 - val_acc: 0.9434 - val_mDice: 0.5674

Epoch 00040: val_mDice did not improve from 0.57473
Epoch 41/300
 - 9s - loss: 0.3412 - acc: 0.9392 - mDice: 0.6962 - val_loss: 0.9019 - val_acc: 0.9383 - val_mDice: 0.5605

Epoch 00041: val_mDice did not improve from 0.57473
Epoch 42/300
 - 9s - loss: 0.3406 - acc: 0.9393 - mDice: 0.6967 - val_loss: 0.9065 - val_acc: 0.9431 - val_mDice: 0.5661

Epoch 00042: val_mDice did not improve from 0.57473
Epoch 43/300
 - 9s - loss: 0.3378 - acc: 0.9397 - mDice: 0.6988 - val_loss: 0.9087 - val_acc: 0.9336 - val_mDice: 0.5537

Epoch 00043: val_mDice did not improve from 0.57473
Epoch 44/300
 - 9s - loss: 0.3362 - acc: 0.9398 - mDice: 0.6999 - val_loss: 0.8628 - val_acc: 0.9346 - val_mDice: 0.5606

Epoch 00044: val_mDice did not improve from 0.57473
Epoch 45/300
 - 9s - loss: 0.3345 - acc: 0.9398 - mDice: 0.7011 - val_loss: 0.9033 - val_acc: 0.9431 - val_mDice: 0.5405

Epoch 00045: val_mDice did not improve from 0.57473
Epoch 46/300
 - 9s - loss: 0.3320 - acc: 0.9402 - mDice: 0.7029 - val_loss: 0.8410 - val_acc: 0.9424 - val_mDice: 0.5777

Epoch 00046: val_mDice improved from 0.57473 to 0.57773, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 9s - loss: 0.3310 - acc: 0.9402 - mDice: 0.7036 - val_loss: 0.8551 - val_acc: 0.9406 - val_mDice: 0.5715

Epoch 00047: val_mDice did not improve from 0.57773
Epoch 48/300
 - 10s - loss: 0.3296 - acc: 0.9405 - mDice: 0.7046 - val_loss: 0.8470 - val_acc: 0.9455 - val_mDice: 0.5701

Epoch 00048: val_mDice did not improve from 0.57773
Epoch 49/300
 - 9s - loss: 0.3280 - acc: 0.9407 - mDice: 0.7059 - val_loss: 0.9208 - val_acc: 0.9366 - val_mDice: 0.5515

Epoch 00049: val_mDice did not improve from 0.57773
Epoch 50/300
 - 9s - loss: 0.3281 - acc: 0.9407 - mDice: 0.7058 - val_loss: 0.8551 - val_acc: 0.9415 - val_mDice: 0.5790

Epoch 00050: val_mDice improved from 0.57773 to 0.57904, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 51/300
 - 9s - loss: 0.3268 - acc: 0.9408 - mDice: 0.7068 - val_loss: 0.8525 - val_acc: 0.9448 - val_mDice: 0.5664

Epoch 00051: val_mDice did not improve from 0.57904
Epoch 52/300
 - 9s - loss: 0.3258 - acc: 0.9408 - mDice: 0.7074 - val_loss: 0.8356 - val_acc: 0.9429 - val_mDice: 0.5644

Epoch 00052: val_mDice did not improve from 0.57904
Epoch 53/300
 - 9s - loss: 0.3252 - acc: 0.9410 - mDice: 0.7079 - val_loss: 0.8680 - val_acc: 0.9358 - val_mDice: 0.5523

Epoch 00053: val_mDice did not improve from 0.57904
Epoch 54/300
 - 9s - loss: 0.3218 - acc: 0.9412 - mDice: 0.7103 - val_loss: 0.8522 - val_acc: 0.9457 - val_mDice: 0.5662

Epoch 00054: val_mDice did not improve from 0.57904
Epoch 55/300
 - 9s - loss: 0.3223 - acc: 0.9411 - mDice: 0.7101 - val_loss: 0.8997 - val_acc: 0.9412 - val_mDice: 0.5548

Epoch 00055: val_mDice did not improve from 0.57904
Epoch 56/300
 - 9s - loss: 0.3211 - acc: 0.9413 - mDice: 0.7109 - val_loss: 0.8215 - val_acc: 0.9417 - val_mDice: 0.5746

Epoch 00056: val_mDice did not improve from 0.57904
Epoch 57/300
 - 9s - loss: 0.3204 - acc: 0.9414 - mDice: 0.7114 - val_loss: 0.8121 - val_acc: 0.9422 - val_mDice: 0.5769

Epoch 00057: val_mDice did not improve from 0.57904
Epoch 58/300
 - 9s - loss: 0.3178 - acc: 0.9416 - mDice: 0.7133 - val_loss: 0.8446 - val_acc: 0.9395 - val_mDice: 0.5622

Epoch 00058: val_mDice did not improve from 0.57904
Epoch 59/300
 - 10s - loss: 0.3170 - acc: 0.9416 - mDice: 0.7139 - val_loss: 0.8517 - val_acc: 0.9401 - val_mDice: 0.5639

Epoch 00059: val_mDice did not improve from 0.57904
Epoch 60/300
 - 10s - loss: 0.3175 - acc: 0.9416 - mDice: 0.7136 - val_loss: 0.7696 - val_acc: 0.9412 - val_mDice: 0.5842

Epoch 00060: val_mDice improved from 0.57904 to 0.58422, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 61/300
 - 9s - loss: 0.3173 - acc: 0.9417 - mDice: 0.7138 - val_loss: 0.8788 - val_acc: 0.9386 - val_mDice: 0.5526

Epoch 00061: val_mDice did not improve from 0.58422
Epoch 62/300
 - 9s - loss: 0.3137 - acc: 0.9420 - mDice: 0.7165 - val_loss: 0.8102 - val_acc: 0.9437 - val_mDice: 0.5603

Epoch 00062: val_mDice did not improve from 0.58422
Epoch 63/300
 - 10s - loss: 0.3133 - acc: 0.9421 - mDice: 0.7168 - val_loss: 0.7584 - val_acc: 0.9371 - val_mDice: 0.5688

Epoch 00063: val_mDice did not improve from 0.58422
Epoch 64/300
 - 9s - loss: 0.3148 - acc: 0.9419 - mDice: 0.7156 - val_loss: 0.8211 - val_acc: 0.9433 - val_mDice: 0.5698

Epoch 00064: val_mDice did not improve from 0.58422
Epoch 65/300
 - 9s - loss: 0.3117 - acc: 0.9422 - mDice: 0.7179 - val_loss: 0.8310 - val_acc: 0.9406 - val_mDice: 0.5592

Epoch 00065: val_mDice did not improve from 0.58422
Epoch 66/300
 - 9s - loss: 0.3104 - acc: 0.9423 - mDice: 0.7189 - val_loss: 0.7268 - val_acc: 0.9384 - val_mDice: 0.5680

Epoch 00066: val_mDice did not improve from 0.58422
Epoch 67/300
 - 9s - loss: 0.3103 - acc: 0.9423 - mDice: 0.7189 - val_loss: 0.7831 - val_acc: 0.9447 - val_mDice: 0.5750

Epoch 00067: val_mDice did not improve from 0.58422
Epoch 68/300
 - 9s - loss: 0.3108 - acc: 0.9422 - mDice: 0.7186 - val_loss: 0.8110 - val_acc: 0.9437 - val_mDice: 0.5524

Epoch 00068: val_mDice did not improve from 0.58422
Epoch 69/300
 - 10s - loss: 0.3100 - acc: 0.9423 - mDice: 0.7192 - val_loss: 0.7898 - val_acc: 0.9437 - val_mDice: 0.5683

Epoch 00069: val_mDice did not improve from 0.58422
Epoch 70/300
 - 10s - loss: 0.3097 - acc: 0.9424 - mDice: 0.7195 - val_loss: 0.8225 - val_acc: 0.9417 - val_mDice: 0.5558

Epoch 00070: val_mDice did not improve from 0.58422
Epoch 71/300
 - 9s - loss: 0.3092 - acc: 0.9425 - mDice: 0.7198 - val_loss: 0.6944 - val_acc: 0.9430 - val_mDice: 0.5818

Epoch 00071: val_mDice did not improve from 0.58422
Epoch 72/300
 - 9s - loss: 0.3060 - acc: 0.9427 - mDice: 0.7222 - val_loss: 0.7434 - val_acc: 0.9347 - val_mDice: 0.5505

Epoch 00072: val_mDice did not improve from 0.58422
Epoch 73/300
 - 10s - loss: 0.3062 - acc: 0.9426 - mDice: 0.7220 - val_loss: 0.7446 - val_acc: 0.9434 - val_mDice: 0.5740

Epoch 00073: val_mDice did not improve from 0.58422
Epoch 74/300
 - 9s - loss: 0.3064 - acc: 0.9427 - mDice: 0.7218 - val_loss: 0.8089 - val_acc: 0.9439 - val_mDice: 0.5461

Epoch 00074: val_mDice did not improve from 0.58422
Epoch 75/300
 - 9s - loss: 0.3051 - acc: 0.9428 - mDice: 0.7229 - val_loss: 0.7818 - val_acc: 0.9425 - val_mDice: 0.5599

Epoch 00075: val_mDice did not improve from 0.58422
Epoch 76/300
 - 9s - loss: 0.3051 - acc: 0.9428 - mDice: 0.7229 - val_loss: 0.7306 - val_acc: 0.9351 - val_mDice: 0.5648

Epoch 00076: val_mDice did not improve from 0.58422
Epoch 77/300
 - 9s - loss: 0.3039 - acc: 0.9427 - mDice: 0.7237 - val_loss: 0.7485 - val_acc: 0.9379 - val_mDice: 0.5627

Epoch 00077: val_mDice did not improve from 0.58422
Epoch 78/300
 - 9s - loss: 0.3016 - acc: 0.9431 - mDice: 0.7255 - val_loss: 0.7440 - val_acc: 0.9423 - val_mDice: 0.5756

Epoch 00078: val_mDice did not improve from 0.58422
Epoch 79/300
 - 9s - loss: 0.3022 - acc: 0.9431 - mDice: 0.7251 - val_loss: 0.7501 - val_acc: 0.9409 - val_mDice: 0.5707

Epoch 00079: val_mDice did not improve from 0.58422
Epoch 80/300
 - 10s - loss: 0.3003 - acc: 0.9434 - mDice: 0.7265 - val_loss: 0.6852 - val_acc: 0.9392 - val_mDice: 0.5670

Epoch 00080: val_mDice did not improve from 0.58422
Epoch 81/300
 - 10s - loss: 0.3025 - acc: 0.9431 - mDice: 0.7248 - val_loss: 0.7684 - val_acc: 0.9462 - val_mDice: 0.5693

Epoch 00081: val_mDice did not improve from 0.58422
Epoch 82/300
 - 9s - loss: 0.3008 - acc: 0.9432 - mDice: 0.7261 - val_loss: 0.7323 - val_acc: 0.9438 - val_mDice: 0.5699

Epoch 00082: val_mDice did not improve from 0.58422
Epoch 83/300
 - 9s - loss: 0.2990 - acc: 0.9433 - mDice: 0.7274 - val_loss: 0.7720 - val_acc: 0.9452 - val_mDice: 0.5586

Epoch 00083: val_mDice did not improve from 0.58422
Epoch 84/300
 - 10s - loss: 0.2988 - acc: 0.9435 - mDice: 0.7277 - val_loss: 0.7397 - val_acc: 0.9386 - val_mDice: 0.5615

Epoch 00084: val_mDice did not improve from 0.58422
Epoch 85/300
 - 9s - loss: 0.2992 - acc: 0.9433 - mDice: 0.7273 - val_loss: 0.7488 - val_acc: 0.9422 - val_mDice: 0.5665

Epoch 00085: val_mDice did not improve from 0.58422
Epoch 86/300
 - 9s - loss: 0.2969 - acc: 0.9435 - mDice: 0.7290 - val_loss: 0.7266 - val_acc: 0.9420 - val_mDice: 0.5729

Epoch 00086: val_mDice did not improve from 0.58422
Epoch 87/300
 - 9s - loss: 0.2978 - acc: 0.9433 - mDice: 0.7283 - val_loss: 0.7033 - val_acc: 0.9422 - val_mDice: 0.5748

Epoch 00087: val_mDice did not improve from 0.58422
Epoch 88/300
 - 9s - loss: 0.2964 - acc: 0.9436 - mDice: 0.7295 - val_loss: 0.7009 - val_acc: 0.9391 - val_mDice: 0.5670

Epoch 00088: val_mDice did not improve from 0.58422
Epoch 89/300
 - 9s - loss: 0.2966 - acc: 0.9436 - mDice: 0.7293 - val_loss: 0.7263 - val_acc: 0.9457 - val_mDice: 0.5641

Epoch 00089: val_mDice did not improve from 0.58422
Epoch 90/300
 - 9s - loss: 0.2958 - acc: 0.9436 - mDice: 0.7299 - val_loss: 0.7532 - val_acc: 0.9426 - val_mDice: 0.5524

Epoch 00090: val_mDice did not improve from 0.58422
Epoch 91/300
 - 9s - loss: 0.2955 - acc: 0.9437 - mDice: 0.7301 - val_loss: 0.7673 - val_acc: 0.9371 - val_mDice: 0.5504

Epoch 00091: val_mDice did not improve from 0.58422
Epoch 92/300
 - 10s - loss: 0.2934 - acc: 0.9438 - mDice: 0.7317 - val_loss: 0.7165 - val_acc: 0.9297 - val_mDice: 0.5348

Epoch 00092: val_mDice did not improve from 0.58422
Epoch 93/300
 - 10s - loss: 0.2948 - acc: 0.9436 - mDice: 0.7306 - val_loss: 0.7351 - val_acc: 0.9416 - val_mDice: 0.5633

Epoch 00093: val_mDice did not improve from 0.58422
Epoch 94/300
 - 9s - loss: 0.2937 - acc: 0.9438 - mDice: 0.7315 - val_loss: 0.7330 - val_acc: 0.9370 - val_mDice: 0.5493

Epoch 00094: val_mDice did not improve from 0.58422
Epoch 95/300
 - 9s - loss: 0.2937 - acc: 0.9439 - mDice: 0.7316 - val_loss: 0.6520 - val_acc: 0.9443 - val_mDice: 0.5690

Epoch 00095: val_mDice did not improve from 0.58422
Epoch 96/300
 - 9s - loss: 0.2922 - acc: 0.9439 - mDice: 0.7327 - val_loss: 0.7230 - val_acc: 0.9403 - val_mDice: 0.5640

Epoch 00096: val_mDice did not improve from 0.58422
Epoch 97/300
 - 9s - loss: 0.2915 - acc: 0.9441 - mDice: 0.7332 - val_loss: 0.7284 - val_acc: 0.9436 - val_mDice: 0.5580

Epoch 00097: val_mDice did not improve from 0.58422
Epoch 98/300
 - 9s - loss: 0.2920 - acc: 0.9439 - mDice: 0.7327 - val_loss: 0.7400 - val_acc: 0.9348 - val_mDice: 0.5501

Epoch 00098: val_mDice did not improve from 0.58422
Epoch 99/300
 - 9s - loss: 0.2920 - acc: 0.9440 - mDice: 0.7328 - val_loss: 0.6480 - val_acc: 0.9430 - val_mDice: 0.5755

Epoch 00099: val_mDice did not improve from 0.58422
Epoch 100/300
 - 9s - loss: 0.2929 - acc: 0.9440 - mDice: 0.7322 - val_loss: 0.7642 - val_acc: 0.9431 - val_mDice: 0.5544

Epoch 00100: val_mDice did not improve from 0.58422
Restoring model weights from the end of the best epoch
Epoch 00100: early stopping
{'val_loss': [2.3635864484877813, 2.1325892947968983, 1.8407641365414573, 1.3234599317823137, 1.1932048116411482, 1.1641757715316046, 1.16973192351205, 1.1354112738654727, 1.101517120997111, 1.1276389871324812, 1.0644276255653018, 1.058203867503575, 1.041811261858259, 1.0465175424303328, 1.0533927508762904, 1.0579581828344435, 1.0178342319670177, 0.9999939600626627, 0.9959102471669515, 1.000723918279012, 1.0175535565330869, 0.9721323194957915, 0.9450318699791318, 1.010562158766247, 0.9529573349725633, 0.9831121876126244, 0.9633653163909912, 0.9313024282455444, 0.9212553955259777, 0.9108900626500448, 0.9582060178120931, 0.9628729139055524, 0.9323532467796689, 0.9862070991879418, 0.9106014456067767, 0.8978651080812726, 0.8869645992914835, 0.9220861934480213, 0.9555527596246629, 0.8928877058483305, 0.9018928323473249, 0.90651840255374, 0.9086864789326986, 0.8627964542025611, 0.9033445176624116, 0.8409855195454189, 0.8550600437890916, 0.8470005251112438, 0.9207646960303897, 0.855110452288673, 0.8524702106203351, 0.8355937685285296, 0.8680055254981631, 0.8521763710748582, 0.8996544451940627, 0.821492212159293, 0.8121167932237897, 0.8445587044670468, 0.8516684259687152, 0.7695827200299218, 0.8787946814582461, 0.8102081843784877, 0.7583891720998854, 0.8210550603412446, 0.8309936069306874, 0.726846382731483, 0.7830552998043242, 0.8110309668949672, 0.7897545269557408, 0.8225096180325463, 0.6943856761569068, 0.7433645611717588, 0.7445853380929857, 0.8088733695802235, 0.7817614646185012, 0.7305829808825538, 0.7484913894108364, 0.7440291245778402, 0.7501151221139091, 0.6851901383627028, 0.7684409448078701, 0.7323261953535534, 0.772021906716483, 0.7397079694838751, 0.7488278434390113, 0.7265511467343285, 0.7033310050056094, 0.7008876970836094, 0.7263263861338297, 0.7531705129714239, 0.7672598702566964, 0.7164590131668818, 0.7350662435804095, 0.7329781850179037, 0.6520104465030488, 0.7229512532552084, 0.7284058275676909, 0.7400261561075846, 0.6479923952193487, 0.7642342022487095], 'val_acc': [0.901746806644258, 0.908832399618058, 0.9090155618531364, 0.9156410126459031, 0.9252014812969026, 0.9247252714066279, 0.9170055219105312, 0.9312156438827515, 0.9233974644115993, 0.9340659124510629, 0.9290590825535002, 0.9328022145089649, 0.9357211731729054, 0.9332417788959685, 0.9220009304228283, 0.9257394955271766, 0.9373946644010998, 0.9285348086130052, 0.9401671432313465, 0.9326671134857905, 0.9368520776430765, 0.9377266424042838, 0.9388301400911241, 0.9420741597811381, 0.9427609926178342, 0.9432234451884315, 0.940858508859362, 0.9439331264722914, 0.9419780174891154, 0.9411584082103911, 0.9443543979099819, 0.9375732399168468, 0.9442422304834638, 0.9405723639896938, 0.9419299534388951, 0.9429235202925546, 0.9455540151823134, 0.935016013327099, 0.94257785876592, 0.9433676997820536, 0.9382600954600743, 0.943099802448636, 0.9335691304433913, 0.9346130972816831, 0.9431341517539251, 0.9424404956045604, 0.9406204053333828, 0.9455357193946838, 0.9366414575349717, 0.9415270232018971, 0.9448145571209136, 0.9429464567275274, 0.9357577902930123, 0.9457486129942394, 0.9411675759724208, 0.9416621100334894, 0.9422092267445156, 0.939539821374984, 0.9401327882494245, 0.9412477158364796, 0.9386057683399746, 0.9436973588807243, 0.9371084939865839, 0.9432692499387831, 0.9405632132575625, 0.9384272212073916, 0.9446955379985628, 0.9436881627355304, 0.9437202158428374, 0.9417376546632676, 0.9429555790764945, 0.9346863286835807, 0.9434317776135036, 0.9439148391996112, 0.9425480905033293, 0.9351235997109186, 0.9378685695784432, 0.942261917250497, 0.9408951572009495, 0.9392147234507969, 0.9461790408406939, 0.9438232353755406, 0.94516940060116, 0.9385691171600705, 0.9422206765129453, 0.942030688126882, 0.9421771707988921, 0.9390567796570914, 0.9457325963746934, 0.9426122080712092, 0.9371039583569482, 0.9296543144044422, 0.94155220190684, 0.9370306645120893, 0.9443040234701974, 0.940290751911345, 0.9436401185535249, 0.9348214211918059, 0.9429807691347032, 0.9430586071241469], 'val_mDice': [0.19751071965410597, 0.24763346642430406, 0.30078218925544725, 0.42996931244574843, 0.4913699836248443, 0.5054314333413329, 0.5008910092569533, 0.4849770555184001, 0.510484813756886, 0.5095712608169942, 0.5222424073588281, 0.5300250369168463, 0.5380491192142168, 0.5401757033098311, 0.5297536505829721, 0.5276692436919326, 0.5476292300791967, 0.5419623919186138, 0.5459433634366307, 0.5471347233369237, 0.5511918713649114, 0.5578295105979556, 0.5618091122735114, 0.546137423032806, 0.5580749224339213, 0.5565581208183652, 0.5598124187617075, 0.5691947149378913, 0.5687179171613285, 0.5747259809147744, 0.5520619405877023, 0.5648973603688535, 0.5527322842251687, 0.5387644739378066, 0.566973027551458, 0.5692999036539168, 0.5736450387963227, 0.5517875513150579, 0.5304954459979421, 0.5673525152461869, 0.5605248666944957, 0.5661160745436237, 0.5537493594345593, 0.5605704355097952, 0.5404537618160248, 0.5777318972562041, 0.5715498250155222, 0.570093959569931, 0.5514740887142363, 0.579035784339621, 0.5663883996506532, 0.5644338547828651, 0.5523129456809589, 0.5661604223506791, 0.554812563849347, 0.5745941446650595, 0.5769396401232197, 0.5621685811451503, 0.5638842942814032, 0.5842246533859343, 0.5525536079491887, 0.5602688619068691, 0.5687968337110111, 0.5698493506227221, 0.5591863088664555, 0.5679968269098372, 0.5750078959834009, 0.552367436743918, 0.5683269458157676, 0.5557922791867029, 0.5817738500024591, 0.5504855364561081, 0.5740374876629739, 0.5461084037309601, 0.5598866155459767, 0.5647757433000065, 0.5626738986798695, 0.5755934273558003, 0.5707422909992081, 0.5669979243761017, 0.5692985206842422, 0.5699132038723855, 0.5586066563569364, 0.5615149920894986, 0.5664567434716792, 0.5728567267457644, 0.5748165707503047, 0.5670017912274316, 0.5641420093320665, 0.5523804906933081, 0.55040236136743, 0.5348215101375466, 0.5632934284706911, 0.5493459499308041, 0.5690052273372809, 0.5639900075537818, 0.5580486419300238, 0.5500695881034646, 0.5755216078389258, 0.5543857372942425], 'loss': [2.9694633764271012, 1.3036736018721575, 0.908761386550045, 0.7408225475098555, 0.6592921711862122, 0.6056929345486687, 0.5687876644450758, 0.5378382130236393, 0.514839871014293, 0.49718438854492397, 0.4827215627643077, 0.4671922325455938, 0.4557022453216268, 0.44515183524908947, 0.435043351376059, 0.42893726349520456, 0.42037807619017814, 0.4141868886711833, 0.4091395536598866, 0.40157415610254216, 0.39664571401193605, 0.3927959229115556, 0.38637929076929645, 0.3849421917691221, 0.3802168309022081, 0.3764239047588078, 0.37411574256059316, 0.36881171475721736, 0.36637248227838515, 0.3668269478782928, 0.35996952431151835, 0.359926613644182, 0.3580318494513703, 0.3579281252807612, 0.3509636168848096, 0.35090448611821884, 0.3458146890027458, 0.34533514525703274, 0.3453685758900776, 0.34123937672150256, 0.34121833000197815, 0.34063730726863506, 0.3378118420005741, 0.336242929529036, 0.33450689617094104, 0.3319624635739802, 0.3309744640952111, 0.3296376209176757, 0.32801003979652954, 0.32811008786474877, 0.3267634153733806, 0.32581895757024865, 0.32521805328074416, 0.32183554635839423, 0.3222516001259083, 0.32108571745652054, 0.3204091943675483, 0.3178319920630774, 0.3170161886161891, 0.3175334280077745, 0.31734883514630996, 0.3136761612703236, 0.3132993355695053, 0.3148445097701913, 0.3116664491638366, 0.3103816537055432, 0.31033708173828317, 0.31076395689165615, 0.3099524332237354, 0.3096893788280344, 0.3091591380914328, 0.3059746812241188, 0.3062163064342853, 0.30641081065071646, 0.30509235377092914, 0.30505289332425867, 0.3039103922286382, 0.3016443936804574, 0.3021687072367252, 0.3003194853993815, 0.302488166833857, 0.3008310113979117, 0.2990191609029345, 0.2987696103434216, 0.2991701010532041, 0.2968687032639739, 0.297844793954198, 0.29636921511694764, 0.2966212855671007, 0.29577101268059536, 0.2954959515342139, 0.2933714843989108, 0.29481707983033517, 0.29368331945652626, 0.2936514251053345, 0.2922158280112092, 0.2915471254147522, 0.2920087574590992, 0.2920216525396171, 0.29285908216498874], 'acc': [0.6259379927876921, 0.8770919522270201, 0.8858594099106025, 0.8943270256185155, 0.900563794959366, 0.9061590024035446, 0.9111360358047375, 0.9144319276807854, 0.9175557688823757, 0.9199227032942742, 0.9216477551486926, 0.9239742501705442, 0.925327349368699, 0.9266993098229555, 0.9280358140744845, 0.9286732664681915, 0.9298701881557985, 0.9307949738004245, 0.9313402078573199, 0.9322490985507976, 0.9329249069068802, 0.933434710030108, 0.9340502228584275, 0.9342093478973739, 0.9350027007497711, 0.9355469421658278, 0.9355118551970402, 0.936230463031999, 0.936563558492997, 0.9363709086049883, 0.9371538804587266, 0.9375414796617418, 0.9375849957523121, 0.9374260118133143, 0.9383420644179691, 0.9382937517794934, 0.9388522628485777, 0.9386555332311988, 0.9389828837214349, 0.9392941741440506, 0.9392270233352129, 0.9393320351706917, 0.9396595455489224, 0.9397643536806153, 0.9398299971251031, 0.9401790108872857, 0.9402484142047168, 0.9405454278268036, 0.9406755390897155, 0.9406989179458236, 0.9407660238931743, 0.9408486094092366, 0.9410030708759765, 0.941222672899587, 0.9411176567089587, 0.9412582378431578, 0.9413944664938224, 0.9415801684245545, 0.9416245162222734, 0.9415725442010451, 0.9416710680473832, 0.9419617596586385, 0.9421021822952732, 0.9419269094996676, 0.9422147531878955, 0.9423048203681414, 0.9423497761746052, 0.9422206803624837, 0.9423446500602429, 0.942367405268138, 0.9424535375765714, 0.9427055318345908, 0.9426318671240475, 0.9427030231305945, 0.9428418936103393, 0.942811216155711, 0.9427104897068855, 0.9431268392855753, 0.9431181951871791, 0.9433854598748056, 0.9430620068526576, 0.9432380407192539, 0.9433327200487672, 0.9435147846712643, 0.9433491981647735, 0.9435429121226687, 0.9433046126609275, 0.9436380118332733, 0.943616206220333, 0.9436022812791107, 0.9436744385678483, 0.9438132333093603, 0.9436466066345949, 0.9437539157252425, 0.943875567862954, 0.9439315512986088, 0.9441056148220355, 0.943916424037359, 0.9440221550240783, 0.9439547476061557], 'mDice': [0.09191801426427681, 0.2824828502459404, 0.3934823107128776, 0.4602127435902812, 0.49962017653143337, 0.527953528107672, 0.5489004345925668, 0.5667945668144403, 0.5805500361508938, 0.5915654814034178, 0.6005749841496645, 0.6104468222364929, 0.6179255071646081, 0.6249400202837757, 0.6314667223826846, 0.6354073935421947, 0.6411879040244827, 0.6453330045217996, 0.6487985021787179, 0.653785096879683, 0.6570842393174988, 0.6597045564527385, 0.6642480555448501, 0.6651629886117909, 0.6684627732905161, 0.6711519951302811, 0.6727638271058574, 0.6764523111971812, 0.678284294600199, 0.6779928892730218, 0.6827178474724672, 0.6828844824208674, 0.6841893611856111, 0.6842448485364154, 0.689232870577295, 0.6892867119803648, 0.6929183478113634, 0.6931659462641768, 0.6933353278755061, 0.6963108526343483, 0.6961838227603531, 0.6966710702426543, 0.6987519975294146, 0.6998744169273472, 0.7010652473925717, 0.7028855654989705, 0.7036260099155447, 0.7046071000932981, 0.7058840119266455, 0.7058077672094607, 0.7067969137013062, 0.7074422663361759, 0.707867408502026, 0.7103474303686437, 0.710124657060775, 0.7108830862452534, 0.7114074849567593, 0.7132615573102393, 0.713945117384247, 0.7136029558349993, 0.7137919697937121, 0.7164738348552159, 0.7167715883356127, 0.7155826787670982, 0.7179242552119641, 0.7189125512775622, 0.7188852631634363, 0.7185735373178015, 0.719238007771893, 0.719460936417257, 0.7197933510959964, 0.722231842015827, 0.7219690827935422, 0.721835084910197, 0.7228933774324104, 0.7229135977594476, 0.7237259938994055, 0.7255473991844129, 0.7250769006762404, 0.7265293416729639, 0.7248481030819939, 0.7261062897720248, 0.7274263756385951, 0.7276522212113997, 0.7272736818454434, 0.7290305194423587, 0.7283116179393255, 0.7294635441300036, 0.7292810068301482, 0.729865462214174, 0.7300861412237346, 0.7316803391415971, 0.7305828416786466, 0.731496263669593, 0.731557925932895, 0.7326742771252378, 0.7331750820844601, 0.7327482432144236, 0.7327506297329199, 0.7321930934014476]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.27s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:05,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:17,  1.76s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:06,  1.72s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:35,  1.62s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:28,  1.61s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:45,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:41,  1.67s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:13,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:27,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:00,  1.75s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:17,  1.82s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:52,  1.74s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:02,  1.78s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:09,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:14,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:53,  1.77s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:54,  1.78s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:36,  1.72s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:46,  1.76s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:19,  1.89s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<08:04,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<08:16,  1.89s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<08:06,  1.86s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<08:32,  1.97s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:45,  2.03s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<08:12,  1.91s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<08:20,  1.95s/it]predicting train subjects:  10%|█         | 29/285 [00:52<08:30,  2.00s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:25,  1.98s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:23,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [00:58<08:02,  1.91s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<08:04,  1.92s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<08:10,  1.95s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:20,  2.00s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:58,  1.93s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:15,  2.01s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:57,  1.94s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<08:00,  1.96s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:33,  1.86s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:23,  1.82s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:33,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:46,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:30,  1.88s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:47,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:27,  1.88s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:35,  1.92s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:54,  2.01s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:50,  2.00s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<08:01,  2.06s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:41,  1.98s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:37,  1.97s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:33,  1.96s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:23,  1.93s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:19,  1.92s/it]predicting train subjects:  20%|██        | 57/285 [01:46<07:01,  1.85s/it]predicting train subjects:  20%|██        | 58/285 [01:48<07:02,  1.86s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:15,  1.93s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:23,  1.97s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:53,  1.85s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:06,  1.91s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<07:13,  1.95s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<07:08,  1.94s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:57,  1.91s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<07:03,  1.94s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:53,  1.91s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:52,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<07:00,  1.95s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<07:09,  2.01s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:58,  1.96s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:49,  1.93s/it]predicting train subjects:  26%|██▌       | 74/285 [02:19<06:39,  1.89s/it]predicting train subjects:  26%|██▋       | 75/285 [02:21<06:34,  1.88s/it]predicting train subjects:  27%|██▋       | 76/285 [02:23<06:38,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:27,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:17,  1.82s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<06:25,  1.88s/it]predicting train subjects:  28%|██▊       | 81/285 [02:32<06:11,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:34<06:11,  1.83s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<06:02,  1.80s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:01,  1.80s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:10,  1.85s/it]predicting train subjects:  30%|███       | 86/285 [02:41<06:31,  1.97s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:35,  2.00s/it]predicting train subjects:  31%|███       | 88/285 [02:45<06:15,  1.91s/it]predicting train subjects:  31%|███       | 89/285 [02:47<06:06,  1.87s/it]predicting train subjects:  32%|███▏      | 90/285 [02:49<06:06,  1.88s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<05:49,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:54<06:06,  1.91s/it]predicting train subjects:  33%|███▎      | 94/285 [02:56<05:59,  1.88s/it]predicting train subjects:  33%|███▎      | 95/285 [02:58<06:02,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<05:58,  1.90s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<06:02,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<05:49,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<05:43,  1.86s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:38,  1.84s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:23,  1.78s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:29,  1.82s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:40,  1.90s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:38,  1.90s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:27,  1.85s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:23,  1.84s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:29,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:27,  1.88s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:23,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:17,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:20,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:37<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:39<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:14,  1.89s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:18,  1.92s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:08,  1.87s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<04:51,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:42,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:35,  1.71s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:29,  1.69s/it]predicting train subjects:  44%|████▍     | 126/285 [03:54<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:56<04:03,  1.54s/it]predicting train subjects:  45%|████▍     | 128/285 [03:58<04:10,  1.60s/it]predicting train subjects:  45%|████▌     | 129/285 [03:59<04:02,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [04:01<04:02,  1.56s/it]predicting train subjects:  46%|████▌     | 131/285 [04:02<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [04:04<04:04,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [04:05<03:53,  1.54s/it]predicting train subjects:  47%|████▋     | 134/285 [04:07<03:48,  1.51s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<03:43,  1.49s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<03:36,  1.45s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<03:38,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:32,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<03:34,  1.47s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:28,  1.44s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:26,  1.44s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:22,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [04:21<03:25,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:19,  1.43s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:22,  1.46s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:25<03:17,  1.43s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:24,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:28<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:12,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:14,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:33<03:07,  1.41s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:34<03:06,  1.41s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:06,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:43<03:03,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:44<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:02,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<02:57,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<03:01,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:50<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<02:54,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:53<02:55,  1.48s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:55<02:56,  1.49s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:56<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<02:47,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:59<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:42,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:39,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:42,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:36,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:28,  1.40s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:41,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:15<02:43,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:17<02:40,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:18<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:19<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:21<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:23<02:31,  1.53s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:24<02:38,  1.61s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:26<02:39,  1.64s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:27<02:27,  1.53s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:21,  1.49s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:30<02:21,  1.51s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:32<02:22,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:33<02:14,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:35<02:11,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:36<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:38<02:16,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:40<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:41<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:43<02:13,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:44<02:06,  1.49s/it]predicting train subjects:  71%|███████   | 201/285 [05:46<02:11,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:47<02:09,  1.56s/it]predicting train subjects:  71%|███████   | 203/285 [05:49<02:08,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:50<02:00,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:52<01:56,  1.46s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:53<01:51,  1.41s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:55<01:58,  1.52s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:01<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:03<01:51,  1.53s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:04<01:51,  1.55s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:05<01:45,  1.49s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:07<01:49,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:08<01:42,  1.48s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:10<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:12<01:47,  1.60s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:14<01:48,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:15<01:40,  1.54s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:16<01:34,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:18<01:33,  1.49s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:19<01:27,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:20<01:25,  1.40s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:22<01:21,  1.36s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:23<01:26,  1.46s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:25<01:29,  1.54s/it]predicting train subjects:  80%|████████  | 228/285 [06:27<01:28,  1.56s/it]predicting train subjects:  80%|████████  | 229/285 [06:28<01:26,  1.55s/it]predicting train subjects:  81%|████████  | 230/285 [06:29<01:20,  1.46s/it]predicting train subjects:  81%|████████  | 231/285 [06:31<01:16,  1.42s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:32<01:16,  1.45s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:34<01:12,  1.40s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:35<01:16,  1.50s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:37<01:12,  1.44s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:38<01:14,  1.52s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:40<01:15,  1.58s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:42<01:15,  1.61s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:43<01:12,  1.58s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:45<01:06,  1.49s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:46<01:03,  1.45s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:47<01:00,  1.40s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:48<00:56,  1.35s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:50<00:59,  1.46s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:51<00:55,  1.39s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:53<00:57,  1.49s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:55<00:58,  1.54s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<00:56,  1.53s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<00:52,  1.45s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:59<00:49,  1.42s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:00<00:46,  1.38s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:01<00:44,  1.35s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:03<00:46,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:05<00:47,  1.52s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:06<00:45,  1.52s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:08<00:41,  1.45s/it]predicting train subjects:  90%|█████████ | 257/285 [07:09<00:39,  1.42s/it]predicting train subjects:  91%|█████████ | 258/285 [07:11<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [07:12<00:39,  1.51s/it]predicting train subjects:  91%|█████████ | 260/285 [07:13<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:15<00:33,  1.40s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:16<00:31,  1.36s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:17<00:29,  1.35s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:19<00:30,  1.47s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:21<00:31,  1.55s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:22<00:27,  1.46s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:23<00:25,  1.41s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:25<00:25,  1.50s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:27<00:24,  1.51s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:28<00:21,  1.45s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:29<00:19,  1.41s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:31<00:18,  1.45s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:32<00:16,  1.40s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:33<00:14,  1.36s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:35<00:14,  1.47s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:37<00:13,  1.53s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:38<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:39<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:41<00:08,  1.47s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:42<00:07,  1.42s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:44<00:05,  1.40s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:45<00:04,  1.36s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:47<00:02,  1.48s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:48<00:01,  1.56s/it]predicting train subjects: 100%|██████████| 285/285 [07:50<00:00,  1.62s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:57,  1.68s/it]Loading train:   1%|          | 2/285 [00:02<07:20,  1.56s/it]Loading train:   1%|          | 3/285 [00:04<07:12,  1.54s/it]Loading train:   1%|▏         | 4/285 [00:05<06:46,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:07<07:07,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<07:02,  1.51s/it]Loading train:   2%|▏         | 7/285 [00:10<07:08,  1.54s/it]Loading train:   3%|▎         | 8/285 [00:11<06:56,  1.50s/it]Loading train:   3%|▎         | 9/285 [00:13<07:18,  1.59s/it]Loading train:   4%|▎         | 10/285 [00:14<06:38,  1.45s/it]Loading train:   4%|▍         | 11/285 [00:15<05:52,  1.29s/it]Loading train:   4%|▍         | 12/285 [00:16<05:43,  1.26s/it]Loading train:   5%|▍         | 13/285 [00:17<05:20,  1.18s/it]Loading train:   5%|▍         | 14/285 [00:19<05:29,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:20<05:35,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:21<05:32,  1.24s/it]Loading train:   6%|▌         | 17/285 [00:22<04:58,  1.11s/it]Loading train:   6%|▋         | 18/285 [00:23<04:48,  1.08s/it]Loading train:   7%|▋         | 19/285 [00:24<04:39,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:25<04:41,  1.06s/it]Loading train:   7%|▋         | 21/285 [00:26<04:53,  1.11s/it]Loading train:   8%|▊         | 22/285 [00:27<04:29,  1.02s/it]Loading train:   8%|▊         | 23/285 [00:28<04:32,  1.04s/it]Loading train:   8%|▊         | 24/285 [00:29<04:25,  1.02s/it]Loading train:   9%|▉         | 25/285 [00:30<04:40,  1.08s/it]Loading train:   9%|▉         | 26/285 [00:32<04:47,  1.11s/it]Loading train:   9%|▉         | 27/285 [00:33<04:34,  1.06s/it]Loading train:  10%|▉         | 28/285 [00:34<04:37,  1.08s/it]Loading train:  10%|█         | 29/285 [00:35<04:33,  1.07s/it]Loading train:  11%|█         | 30/285 [00:36<04:35,  1.08s/it]Loading train:  11%|█         | 31/285 [00:37<04:40,  1.10s/it]Loading train:  11%|█         | 32/285 [00:38<04:22,  1.04s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:21,  1.04s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:10,  1.00it/s]Loading train:  12%|█▏        | 35/285 [00:41<04:17,  1.03s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:06,  1.01it/s]Loading train:  13%|█▎        | 37/285 [00:43<04:10,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:44<04:33,  1.11s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:14,  1.04s/it]Loading train:  14%|█▍        | 40/285 [00:46<04:02,  1.01it/s]Loading train:  14%|█▍        | 41/285 [00:47<03:46,  1.08it/s]Loading train:  15%|█▍        | 42/285 [00:48<03:36,  1.12it/s]Loading train:  15%|█▌        | 43/285 [00:49<03:41,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:50<03:57,  1.01it/s]Loading train:  16%|█▌        | 45/285 [00:51<03:55,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:52<04:14,  1.06s/it]Loading train:  16%|█▋        | 47/285 [00:53<04:04,  1.03s/it]Loading train:  17%|█▋        | 48/285 [00:54<03:58,  1.01s/it]Loading train:  17%|█▋        | 49/285 [00:55<04:17,  1.09s/it]Loading train:  18%|█▊        | 50/285 [00:56<04:12,  1.07s/it]Loading train:  18%|█▊        | 51/285 [00:57<04:16,  1.10s/it]Loading train:  18%|█▊        | 52/285 [00:58<04:08,  1.07s/it]Loading train:  19%|█▊        | 53/285 [00:59<04:09,  1.07s/it]Loading train:  19%|█▉        | 54/285 [01:01<04:25,  1.15s/it]Loading train:  19%|█▉        | 55/285 [01:02<04:14,  1.11s/it]Loading train:  20%|█▉        | 56/285 [01:03<04:07,  1.08s/it]Loading train:  20%|██        | 57/285 [01:04<03:53,  1.02s/it]Loading train:  20%|██        | 58/285 [01:05<03:52,  1.03s/it]Loading train:  21%|██        | 59/285 [01:06<04:10,  1.11s/it]Loading train:  21%|██        | 60/285 [01:07<04:13,  1.13s/it]Loading train:  21%|██▏       | 61/285 [01:08<04:05,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:09<04:03,  1.09s/it]Loading train:  22%|██▏       | 63/285 [01:10<03:59,  1.08s/it]Loading train:  22%|██▏       | 64/285 [01:12<04:20,  1.18s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:52,  1.33s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:58,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:36,  1.27s/it]Loading train:  24%|██▍       | 68/285 [01:17<04:16,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:18<04:04,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:19<03:59,  1.12s/it]Loading train:  25%|██▍       | 71/285 [01:20<03:54,  1.10s/it]Loading train:  25%|██▌       | 72/285 [01:21<03:46,  1.06s/it]Loading train:  26%|██▌       | 73/285 [01:22<03:43,  1.06s/it]Loading train:  26%|██▌       | 74/285 [01:23<03:40,  1.05s/it]Loading train:  26%|██▋       | 75/285 [01:24<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:25<03:43,  1.07s/it]Loading train:  27%|██▋       | 77/285 [01:26<03:30,  1.01s/it]Loading train:  27%|██▋       | 78/285 [01:27<03:24,  1.01it/s]Loading train:  28%|██▊       | 79/285 [01:28<03:27,  1.01s/it]Loading train:  28%|██▊       | 80/285 [01:29<03:26,  1.01s/it]Loading train:  28%|██▊       | 81/285 [01:30<03:23,  1.00it/s]Loading train:  29%|██▉       | 82/285 [01:31<03:23,  1.00s/it]Loading train:  29%|██▉       | 83/285 [01:32<03:23,  1.01s/it]Loading train:  29%|██▉       | 84/285 [01:33<03:18,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:34<03:19,  1.00it/s]Loading train:  30%|███       | 86/285 [01:35<03:18,  1.00it/s]Loading train:  31%|███       | 87/285 [01:36<03:23,  1.03s/it]Loading train:  31%|███       | 88/285 [01:37<03:14,  1.01it/s]Loading train:  31%|███       | 89/285 [01:38<03:11,  1.02it/s]Loading train:  32%|███▏      | 90/285 [01:39<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:40<03:13,  1.00it/s]Loading train:  32%|███▏      | 92/285 [01:41<03:16,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:42<03:08,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:43<03:10,  1.00it/s]Loading train:  33%|███▎      | 95/285 [01:44<03:17,  1.04s/it]Loading train:  34%|███▎      | 96/285 [01:45<03:09,  1.00s/it]Loading train:  34%|███▍      | 97/285 [01:46<03:09,  1.01s/it]Loading train:  34%|███▍      | 98/285 [01:47<03:06,  1.00it/s]Loading train:  35%|███▍      | 99/285 [01:48<03:03,  1.01it/s]Loading train:  35%|███▌      | 100/285 [01:49<03:03,  1.01it/s]Loading train:  35%|███▌      | 101/285 [01:50<02:59,  1.03it/s]Loading train:  36%|███▌      | 102/285 [01:51<03:04,  1.01s/it]Loading train:  36%|███▌      | 103/285 [01:52<02:59,  1.02it/s]Loading train:  36%|███▋      | 104/285 [01:53<02:56,  1.03it/s]Loading train:  37%|███▋      | 105/285 [01:54<03:00,  1.00s/it]Loading train:  37%|███▋      | 106/285 [01:55<02:59,  1.00s/it]Loading train:  38%|███▊      | 107/285 [01:56<02:59,  1.01s/it]Loading train:  38%|███▊      | 108/285 [01:57<02:54,  1.01it/s]Loading train:  38%|███▊      | 109/285 [01:58<02:57,  1.01s/it]Loading train:  39%|███▊      | 110/285 [01:59<03:00,  1.03s/it]Loading train:  39%|███▉      | 111/285 [02:00<02:55,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:01<02:59,  1.04s/it]Loading train:  40%|███▉      | 113/285 [02:02<02:58,  1.04s/it]Loading train:  40%|████      | 114/285 [02:03<02:57,  1.04s/it]Loading train:  40%|████      | 115/285 [02:04<02:56,  1.04s/it]Loading train:  41%|████      | 116/285 [02:05<02:52,  1.02s/it]Loading train:  41%|████      | 117/285 [02:06<02:49,  1.01s/it]Loading train:  41%|████▏     | 118/285 [02:07<02:44,  1.01it/s]Loading train:  42%|████▏     | 119/285 [02:08<02:48,  1.02s/it]Loading train:  42%|████▏     | 120/285 [02:09<02:45,  1.00s/it]Loading train:  42%|████▏     | 121/285 [02:11<03:03,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:12<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:13<03:13,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:14<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:15<02:46,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:16<02:37,  1.01it/s]Loading train:  45%|████▍     | 127/285 [02:17<02:37,  1.00it/s]Loading train:  45%|████▍     | 128/285 [02:18<02:34,  1.02it/s]Loading train:  45%|████▌     | 129/285 [02:19<02:27,  1.06it/s]Loading train:  46%|████▌     | 130/285 [02:20<02:23,  1.08it/s]Loading train:  46%|████▌     | 131/285 [02:20<02:18,  1.11it/s]Loading train:  46%|████▋     | 132/285 [02:21<02:18,  1.11it/s]Loading train:  47%|████▋     | 133/285 [02:22<02:15,  1.12it/s]Loading train:  47%|████▋     | 134/285 [02:23<02:14,  1.12it/s]Loading train:  47%|████▋     | 135/285 [02:24<02:10,  1.15it/s]Loading train:  48%|████▊     | 136/285 [02:25<02:08,  1.16it/s]Loading train:  48%|████▊     | 137/285 [02:26<02:08,  1.15it/s]Loading train:  48%|████▊     | 138/285 [02:26<02:04,  1.18it/s]Loading train:  49%|████▉     | 139/285 [02:27<02:05,  1.16it/s]Loading train:  49%|████▉     | 140/285 [02:28<02:02,  1.18it/s]Loading train:  49%|████▉     | 141/285 [02:29<02:00,  1.20it/s]Loading train:  50%|████▉     | 142/285 [02:30<02:01,  1.18it/s]Loading train:  50%|█████     | 143/285 [02:31<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:32<02:07,  1.11it/s]Loading train:  51%|█████     | 145/285 [02:32<02:03,  1.14it/s]Loading train:  51%|█████     | 146/285 [02:33<02:01,  1.14it/s]Loading train:  52%|█████▏    | 147/285 [02:34<01:59,  1.15it/s]Loading train:  52%|█████▏    | 148/285 [02:35<02:00,  1.13it/s]Loading train:  52%|█████▏    | 149/285 [02:36<02:02,  1.11it/s]Loading train:  53%|█████▎    | 150/285 [02:37<01:58,  1.13it/s]Loading train:  53%|█████▎    | 151/285 [02:38<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:39<01:56,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:39<01:53,  1.17it/s]Loading train:  54%|█████▍    | 154/285 [02:40<01:52,  1.17it/s]Loading train:  54%|█████▍    | 155/285 [02:41<01:54,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:42<01:54,  1.12it/s]Loading train:  55%|█████▌    | 157/285 [02:43<01:55,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [02:44<01:53,  1.12it/s]Loading train:  56%|█████▌    | 159/285 [02:45<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [02:46<01:49,  1.14it/s]Loading train:  56%|█████▋    | 161/285 [02:47<01:50,  1.12it/s]Loading train:  57%|█████▋    | 162/285 [02:47<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:48<01:47,  1.13it/s]Loading train:  58%|█████▊    | 164/285 [02:49<01:47,  1.12it/s]Loading train:  58%|█████▊    | 165/285 [02:50<01:47,  1.11it/s]Loading train:  58%|█████▊    | 166/285 [02:51<01:46,  1.12it/s]Loading train:  59%|█████▊    | 167/285 [02:52<01:44,  1.12it/s]Loading train:  59%|█████▉    | 168/285 [02:53<01:39,  1.17it/s]Loading train:  59%|█████▉    | 169/285 [02:53<01:36,  1.20it/s]Loading train:  60%|█████▉    | 170/285 [02:54<01:31,  1.25it/s]Loading train:  60%|██████    | 171/285 [02:55<01:34,  1.21it/s]Loading train:  60%|██████    | 172/285 [02:56<01:35,  1.18it/s]Loading train:  61%|██████    | 173/285 [02:57<01:36,  1.16it/s]Loading train:  61%|██████    | 174/285 [02:58<01:32,  1.19it/s]Loading train:  61%|██████▏   | 175/285 [02:59<01:36,  1.14it/s]Loading train:  62%|██████▏   | 176/285 [03:00<01:37,  1.12it/s]Loading train:  62%|██████▏   | 177/285 [03:00<01:36,  1.12it/s]Loading train:  62%|██████▏   | 178/285 [03:01<01:33,  1.14it/s]Loading train:  63%|██████▎   | 179/285 [03:02<01:34,  1.13it/s]Loading train:  63%|██████▎   | 180/285 [03:03<01:36,  1.09it/s]Loading train:  64%|██████▎   | 181/285 [03:04<01:37,  1.07it/s]Loading train:  64%|██████▍   | 182/285 [03:05<01:36,  1.07it/s]Loading train:  64%|██████▍   | 183/285 [03:06<01:31,  1.11it/s]Loading train:  65%|██████▍   | 184/285 [03:07<01:28,  1.14it/s]Loading train:  65%|██████▍   | 185/285 [03:07<01:24,  1.18it/s]Loading train:  65%|██████▌   | 186/285 [03:09<01:32,  1.07it/s]Loading train:  66%|██████▌   | 187/285 [03:10<01:34,  1.03it/s]Loading train:  66%|██████▌   | 188/285 [03:11<01:36,  1.01it/s]Loading train:  66%|██████▋   | 189/285 [03:12<01:31,  1.05it/s]Loading train:  67%|██████▋   | 190/285 [03:12<01:28,  1.07it/s]Loading train:  67%|██████▋   | 191/285 [03:13<01:27,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:14<01:24,  1.11it/s]Loading train:  68%|██████▊   | 193/285 [03:15<01:22,  1.12it/s]Loading train:  68%|██████▊   | 194/285 [03:16<01:20,  1.12it/s]Loading train:  68%|██████▊   | 195/285 [03:17<01:20,  1.11it/s]Loading train:  69%|██████▉   | 196/285 [03:18<01:25,  1.05it/s]Loading train:  69%|██████▉   | 197/285 [03:19<01:26,  1.02it/s]Loading train:  69%|██████▉   | 198/285 [03:20<01:25,  1.02it/s]Loading train:  70%|██████▉   | 199/285 [03:21<01:22,  1.05it/s]Loading train:  70%|███████   | 200/285 [03:22<01:17,  1.09it/s]Loading train:  71%|███████   | 201/285 [03:23<01:19,  1.06it/s]Loading train:  71%|███████   | 202/285 [03:24<01:20,  1.04it/s]Loading train:  71%|███████   | 203/285 [03:25<01:17,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [03:25<01:14,  1.09it/s]Loading train:  72%|███████▏  | 205/285 [03:26<01:12,  1.10it/s]Loading train:  72%|███████▏  | 206/285 [03:27<01:11,  1.10it/s]Loading train:  73%|███████▎  | 207/285 [03:28<01:12,  1.07it/s]Loading train:  73%|███████▎  | 208/285 [03:29<01:14,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [03:30<01:15,  1.00it/s]Loading train:  74%|███████▎  | 210/285 [03:31<01:11,  1.05it/s]Loading train:  74%|███████▍  | 211/285 [03:32<01:07,  1.10it/s]Loading train:  74%|███████▍  | 212/285 [03:33<01:06,  1.09it/s]Loading train:  75%|███████▍  | 213/285 [03:34<01:06,  1.08it/s]Loading train:  75%|███████▌  | 214/285 [03:35<01:05,  1.09it/s]Loading train:  75%|███████▌  | 215/285 [03:36<01:07,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [03:37<01:04,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:38<01:07,  1.00it/s]Loading train:  76%|███████▋  | 218/285 [03:39<01:06,  1.01it/s]Loading train:  77%|███████▋  | 219/285 [03:40<01:06,  1.00s/it]Loading train:  77%|███████▋  | 220/285 [03:41<01:00,  1.07it/s]Loading train:  78%|███████▊  | 221/285 [03:42<00:57,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [03:42<00:54,  1.15it/s]Loading train:  78%|███████▊  | 223/285 [03:43<00:52,  1.18it/s]Loading train:  79%|███████▊  | 224/285 [03:44<00:51,  1.19it/s]Loading train:  79%|███████▉  | 225/285 [03:45<00:48,  1.24it/s]Loading train:  79%|███████▉  | 226/285 [03:46<00:50,  1.16it/s]Loading train:  80%|███████▉  | 227/285 [03:47<00:50,  1.16it/s]Loading train:  80%|████████  | 228/285 [03:48<00:53,  1.07it/s]Loading train:  80%|████████  | 229/285 [03:49<00:53,  1.05it/s]Loading train:  81%|████████  | 230/285 [03:50<00:52,  1.04it/s]Loading train:  81%|████████  | 231/285 [03:50<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [03:51<00:47,  1.11it/s]Loading train:  82%|████████▏ | 233/285 [03:52<00:44,  1.17it/s]Loading train:  82%|████████▏ | 234/285 [03:53<00:45,  1.12it/s]Loading train:  82%|████████▏ | 235/285 [03:54<00:42,  1.19it/s]Loading train:  83%|████████▎ | 236/285 [03:55<00:43,  1.14it/s]Loading train:  83%|████████▎ | 237/285 [03:56<00:44,  1.08it/s]Loading train:  84%|████████▎ | 238/285 [03:57<00:45,  1.02it/s]Loading train:  84%|████████▍ | 239/285 [03:58<00:43,  1.05it/s]Loading train:  84%|████████▍ | 240/285 [03:59<00:41,  1.08it/s]Loading train:  85%|████████▍ | 241/285 [03:59<00:40,  1.09it/s]Loading train:  85%|████████▍ | 242/285 [04:00<00:37,  1.13it/s]Loading train:  85%|████████▌ | 243/285 [04:01<00:37,  1.12it/s]Loading train:  86%|████████▌ | 244/285 [04:02<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [04:03<00:34,  1.16it/s]Loading train:  86%|████████▋ | 246/285 [04:04<00:34,  1.12it/s]Loading train:  87%|████████▋ | 247/285 [04:05<00:34,  1.10it/s]Loading train:  87%|████████▋ | 248/285 [04:06<00:32,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [04:07<00:32,  1.12it/s]Loading train:  88%|████████▊ | 250/285 [04:07<00:31,  1.12it/s]Loading train:  88%|████████▊ | 251/285 [04:08<00:29,  1.14it/s]Loading train:  88%|████████▊ | 252/285 [04:09<00:28,  1.15it/s]Loading train:  89%|████████▉ | 253/285 [04:10<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [04:11<00:29,  1.03it/s]Loading train:  89%|████████▉ | 255/285 [04:12<00:28,  1.04it/s]Loading train:  90%|████████▉ | 256/285 [04:13<00:26,  1.11it/s]Loading train:  90%|█████████ | 257/285 [04:14<00:23,  1.18it/s]Loading train:  91%|█████████ | 258/285 [04:15<00:23,  1.16it/s]Loading train:  91%|█████████ | 259/285 [04:15<00:22,  1.16it/s]Loading train:  91%|█████████ | 260/285 [04:16<00:21,  1.19it/s]Loading train:  92%|█████████▏| 261/285 [04:17<00:19,  1.23it/s]Loading train:  92%|█████████▏| 262/285 [04:18<00:18,  1.22it/s]Loading train:  92%|█████████▏| 263/285 [04:19<00:17,  1.25it/s]Loading train:  93%|█████████▎| 264/285 [04:20<00:18,  1.14it/s]Loading train:  93%|█████████▎| 265/285 [04:21<00:19,  1.03it/s]Loading train:  93%|█████████▎| 266/285 [04:22<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:23<00:16,  1.09it/s]Loading train:  94%|█████████▍| 268/285 [04:24<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [04:25<00:15,  1.06it/s]Loading train:  95%|█████████▍| 270/285 [04:25<00:14,  1.07it/s]Loading train:  95%|█████████▌| 271/285 [04:26<00:12,  1.13it/s]Loading train:  95%|█████████▌| 272/285 [04:27<00:11,  1.13it/s]Loading train:  96%|█████████▌| 273/285 [04:28<00:10,  1.10it/s]Loading train:  96%|█████████▌| 274/285 [04:29<00:10,  1.09it/s]Loading train:  96%|█████████▋| 275/285 [04:30<00:09,  1.03it/s]Loading train:  97%|█████████▋| 276/285 [04:31<00:09,  1.01s/it]Loading train:  97%|█████████▋| 277/285 [04:32<00:07,  1.05it/s]Loading train:  98%|█████████▊| 278/285 [04:33<00:06,  1.07it/s]Loading train:  98%|█████████▊| 279/285 [04:34<00:05,  1.05it/s]Loading train:  98%|█████████▊| 280/285 [04:35<00:04,  1.09it/s]Loading train:  99%|█████████▊| 281/285 [04:36<00:03,  1.13it/s]Loading train:  99%|█████████▉| 282/285 [04:36<00:02,  1.17it/s]Loading train:  99%|█████████▉| 283/285 [04:37<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:38<00:00,  1.10it/s]Loading train: 100%|██████████| 285/285 [04:39<00:00,  1.11it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:01, 195.60it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:01, 209.57it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:01, 212.03it/s]concatenating: train:  33%|███▎      | 93/285 [00:00<00:00, 216.32it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 232.64it/s]concatenating: train:  54%|█████▎    | 153/285 [00:00<00:00, 250.09it/s]concatenating: train:  65%|██████▍   | 185/285 [00:00<00:00, 266.46it/s]concatenating: train:  75%|███████▌  | 215/285 [00:00<00:00, 274.53it/s]concatenating: train:  86%|████████▌ | 245/285 [00:00<00:00, 281.52it/s]concatenating: train:  98%|█████████▊| 278/285 [00:01<00:00, 292.47it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 273.09it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 688.83it/s]2019-07-11 05:40:39.674111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:40:39.674197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:40:39.674221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:40:39.674231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:40:39.674656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.71it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.82it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.53it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.38it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.19it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.76it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.42it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.42it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.38it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.70it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.81it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.57it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.58it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.86it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.94it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.63it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.19it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 30)   16230       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 90)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 246,393
Trainable params: 71,593
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.1858 - acc: 0.7329 - mDice: 0.1823 - val_loss: 0.9108 - val_acc: 0.9216 - val_mDice: 0.3880

Epoch 00001: val_mDice improved from -inf to 0.38799, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.7723 - acc: 0.8983 - mDice: 0.4488 - val_loss: 0.7377 - val_acc: 0.9325 - val_mDice: 0.4812

Epoch 00002: val_mDice improved from 0.38799 to 0.48123, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6079 - acc: 0.9061 - mDice: 0.5304 - val_loss: 0.5891 - val_acc: 0.9352 - val_mDice: 0.5419

Epoch 00003: val_mDice improved from 0.48123 to 0.54194, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5301 - acc: 0.9131 - mDice: 0.5746 - val_loss: 0.6149 - val_acc: 0.9388 - val_mDice: 0.5330

Epoch 00004: val_mDice did not improve from 0.54194
Epoch 5/300
 - 13s - loss: 0.4840 - acc: 0.9197 - mDice: 0.6022 - val_loss: 0.5538 - val_acc: 0.9426 - val_mDice: 0.5633

Epoch 00005: val_mDice improved from 0.54194 to 0.56332, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4767 - acc: 0.9245 - mDice: 0.6095 - val_loss: 0.5552 - val_acc: 0.9443 - val_mDice: 0.5634

Epoch 00006: val_mDice improved from 0.56332 to 0.56344, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.4304 - acc: 0.9317 - mDice: 0.6362 - val_loss: 0.5393 - val_acc: 0.9479 - val_mDice: 0.5722

Epoch 00007: val_mDice improved from 0.56344 to 0.57225, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4127 - acc: 0.9369 - mDice: 0.6477 - val_loss: 0.5409 - val_acc: 0.9481 - val_mDice: 0.5712

Epoch 00008: val_mDice did not improve from 0.57225
Epoch 9/300
 - 13s - loss: 0.3985 - acc: 0.9407 - mDice: 0.6569 - val_loss: 0.5266 - val_acc: 0.9467 - val_mDice: 0.5789

Epoch 00009: val_mDice improved from 0.57225 to 0.57886, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.3870 - acc: 0.9424 - mDice: 0.6648 - val_loss: 0.5312 - val_acc: 0.9435 - val_mDice: 0.5755

Epoch 00010: val_mDice did not improve from 0.57886
Epoch 11/300
 - 13s - loss: 0.3736 - acc: 0.9438 - mDice: 0.6739 - val_loss: 0.5202 - val_acc: 0.9451 - val_mDice: 0.5815

Epoch 00011: val_mDice improved from 0.57886 to 0.58146, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 14s - loss: 0.3641 - acc: 0.9447 - mDice: 0.6805 - val_loss: 0.5401 - val_acc: 0.9484 - val_mDice: 0.5737

Epoch 00012: val_mDice did not improve from 0.58146
Epoch 13/300
 - 14s - loss: 0.3575 - acc: 0.9454 - mDice: 0.6852 - val_loss: 0.5240 - val_acc: 0.9462 - val_mDice: 0.5822

Epoch 00013: val_mDice improved from 0.58146 to 0.58217, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 0.3526 - acc: 0.9459 - mDice: 0.6888 - val_loss: 0.5525 - val_acc: 0.9439 - val_mDice: 0.5632

Epoch 00014: val_mDice did not improve from 0.58217
Epoch 15/300
 - 13s - loss: 0.3415 - acc: 0.9469 - mDice: 0.6964 - val_loss: 0.5504 - val_acc: 0.9454 - val_mDice: 0.5645

Epoch 00015: val_mDice did not improve from 0.58217
Epoch 16/300
 - 13s - loss: 0.3366 - acc: 0.9473 - mDice: 0.7001 - val_loss: 0.5084 - val_acc: 0.9465 - val_mDice: 0.5921

Epoch 00016: val_mDice improved from 0.58217 to 0.59209, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.3291 - acc: 0.9480 - mDice: 0.7055 - val_loss: 0.5860 - val_acc: 0.9463 - val_mDice: 0.5541

Epoch 00017: val_mDice did not improve from 0.59209
Epoch 18/300
 - 13s - loss: 0.3244 - acc: 0.9484 - mDice: 0.7089 - val_loss: 0.5609 - val_acc: 0.9486 - val_mDice: 0.5664

Epoch 00018: val_mDice did not improve from 0.59209
Epoch 19/300
 - 14s - loss: 0.3182 - acc: 0.9490 - mDice: 0.7134 - val_loss: 0.5427 - val_acc: 0.9483 - val_mDice: 0.5764

Epoch 00019: val_mDice did not improve from 0.59209
Epoch 20/300
 - 13s - loss: 0.3151 - acc: 0.9493 - mDice: 0.7157 - val_loss: 0.5166 - val_acc: 0.9471 - val_mDice: 0.5855

Epoch 00020: val_mDice did not improve from 0.59209
Epoch 21/300
 - 13s - loss: 0.3111 - acc: 0.9495 - mDice: 0.7187 - val_loss: 0.4984 - val_acc: 0.9493 - val_mDice: 0.5993

Epoch 00021: val_mDice improved from 0.59209 to 0.59925, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 14s - loss: 0.3083 - acc: 0.9499 - mDice: 0.7209 - val_loss: 0.5211 - val_acc: 0.9488 - val_mDice: 0.5845

Epoch 00022: val_mDice did not improve from 0.59925
Epoch 23/300
 - 14s - loss: 0.3027 - acc: 0.9503 - mDice: 0.7250 - val_loss: 0.5288 - val_acc: 0.9467 - val_mDice: 0.5847

Epoch 00023: val_mDice did not improve from 0.59925
Epoch 24/300
 - 13s - loss: 0.3004 - acc: 0.9505 - mDice: 0.7267 - val_loss: 0.5157 - val_acc: 0.9476 - val_mDice: 0.5895

Epoch 00024: val_mDice did not improve from 0.59925
Epoch 25/300
 - 13s - loss: 0.2979 - acc: 0.9508 - mDice: 0.7287 - val_loss: 0.5012 - val_acc: 0.9473 - val_mDice: 0.5979

Epoch 00025: val_mDice did not improve from 0.59925
Epoch 26/300
 - 14s - loss: 0.2959 - acc: 0.9510 - mDice: 0.7302 - val_loss: 0.5456 - val_acc: 0.9469 - val_mDice: 0.5783

Epoch 00026: val_mDice did not improve from 0.59925
Epoch 27/300
 - 14s - loss: 0.2920 - acc: 0.9513 - mDice: 0.7332 - val_loss: 0.5355 - val_acc: 0.9470 - val_mDice: 0.5754

Epoch 00027: val_mDice did not improve from 0.59925
Epoch 28/300
 - 13s - loss: 0.2903 - acc: 0.9514 - mDice: 0.7345 - val_loss: 0.5095 - val_acc: 0.9463 - val_mDice: 0.5927

Epoch 00028: val_mDice did not improve from 0.59925
Epoch 29/300
 - 14s - loss: 0.2878 - acc: 0.9516 - mDice: 0.7364 - val_loss: 0.5185 - val_acc: 0.9495 - val_mDice: 0.5899

Epoch 00029: val_mDice did not improve from 0.59925
Epoch 30/300
 - 14s - loss: 0.2863 - acc: 0.9517 - mDice: 0.7374 - val_loss: 0.5069 - val_acc: 0.9464 - val_mDice: 0.5915

Epoch 00030: val_mDice did not improve from 0.59925
Epoch 31/300
 - 14s - loss: 0.2851 - acc: 0.9518 - mDice: 0.7385 - val_loss: 0.4962 - val_acc: 0.9474 - val_mDice: 0.6000

Epoch 00031: val_mDice improved from 0.59925 to 0.59996, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 14s - loss: 0.2810 - acc: 0.9522 - mDice: 0.7417 - val_loss: 0.5428 - val_acc: 0.9488 - val_mDice: 0.5778

Epoch 00032: val_mDice did not improve from 0.59996
Epoch 33/300
 - 14s - loss: 0.2793 - acc: 0.9523 - mDice: 0.7430 - val_loss: 0.5169 - val_acc: 0.9491 - val_mDice: 0.5890

Epoch 00033: val_mDice did not improve from 0.59996
Epoch 34/300
 - 14s - loss: 0.2783 - acc: 0.9524 - mDice: 0.7438 - val_loss: 0.5152 - val_acc: 0.9481 - val_mDice: 0.5900

Epoch 00034: val_mDice did not improve from 0.59996
Epoch 35/300
 - 14s - loss: 0.2751 - acc: 0.9527 - mDice: 0.7461 - val_loss: 0.5349 - val_acc: 0.9457 - val_mDice: 0.5775

Epoch 00035: val_mDice did not improve from 0.59996
Epoch 36/300
 - 14s - loss: 0.2738 - acc: 0.9527 - mDice: 0.7472 - val_loss: 0.5860 - val_acc: 0.9477 - val_mDice: 0.5678

Epoch 00036: val_mDice did not improve from 0.59996
Epoch 37/300
 - 14s - loss: 0.2735 - acc: 0.9529 - mDice: 0.7474 - val_loss: 0.5399 - val_acc: 0.9492 - val_mDice: 0.5789

Epoch 00037: val_mDice did not improve from 0.59996
Epoch 38/300
 - 14s - loss: 0.2703 - acc: 0.9531 - mDice: 0.7499 - val_loss: 0.5097 - val_acc: 0.9494 - val_mDice: 0.5932

Epoch 00038: val_mDice did not improve from 0.59996
Epoch 39/300
 - 14s - loss: 0.2679 - acc: 0.9533 - mDice: 0.7518 - val_loss: 0.4961 - val_acc: 0.9480 - val_mDice: 0.5992

Epoch 00039: val_mDice did not improve from 0.59996
Epoch 40/300
 - 14s - loss: 0.2677 - acc: 0.9534 - mDice: 0.7522 - val_loss: 0.5070 - val_acc: 0.9490 - val_mDice: 0.5955

Epoch 00040: val_mDice did not improve from 0.59996
Epoch 41/300
 - 14s - loss: 0.2648 - acc: 0.9536 - mDice: 0.7543 - val_loss: 0.5552 - val_acc: 0.9492 - val_mDice: 0.5733

Epoch 00041: val_mDice did not improve from 0.59996
Epoch 42/300
 - 14s - loss: 0.2660 - acc: 0.9534 - mDice: 0.7534 - val_loss: 0.5095 - val_acc: 0.9493 - val_mDice: 0.6002

Epoch 00042: val_mDice improved from 0.59996 to 0.60019, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 14s - loss: 0.2624 - acc: 0.9537 - mDice: 0.7561 - val_loss: 0.5137 - val_acc: 0.9484 - val_mDice: 0.5921

Epoch 00043: val_mDice did not improve from 0.60019
Epoch 44/300
 - 14s - loss: 0.2628 - acc: 0.9537 - mDice: 0.7559 - val_loss: 0.5211 - val_acc: 0.9500 - val_mDice: 0.5881

Epoch 00044: val_mDice did not improve from 0.60019
Epoch 45/300
 - 14s - loss: 0.2606 - acc: 0.9538 - mDice: 0.7576 - val_loss: 0.5307 - val_acc: 0.9510 - val_mDice: 0.5873

Epoch 00045: val_mDice did not improve from 0.60019
Epoch 46/300
 - 14s - loss: 0.2596 - acc: 0.9539 - mDice: 0.7584 - val_loss: 0.4986 - val_acc: 0.9474 - val_mDice: 0.5970

Epoch 00046: val_mDice did not improve from 0.60019
Epoch 47/300
 - 14s - loss: 0.2591 - acc: 0.9541 - mDice: 0.7589 - val_loss: 0.5597 - val_acc: 0.9479 - val_mDice: 0.5674

Epoch 00047: val_mDice did not improve from 0.60019
Epoch 48/300
 - 14s - loss: 0.2566 - acc: 0.9541 - mDice: 0.7608 - val_loss: 0.5025 - val_acc: 0.9497 - val_mDice: 0.5976

Epoch 00048: val_mDice did not improve from 0.60019
Epoch 49/300
 - 14s - loss: 0.2557 - acc: 0.9543 - mDice: 0.7614 - val_loss: 0.5386 - val_acc: 0.9476 - val_mDice: 0.5817

Epoch 00049: val_mDice did not improve from 0.60019
Epoch 50/300
 - 14s - loss: 0.2539 - acc: 0.9543 - mDice: 0.7629 - val_loss: 0.5143 - val_acc: 0.9494 - val_mDice: 0.5898

Epoch 00050: val_mDice did not improve from 0.60019
Epoch 51/300
 - 14s - loss: 0.2526 - acc: 0.9545 - mDice: 0.7640 - val_loss: 0.5333 - val_acc: 0.9486 - val_mDice: 0.5828

Epoch 00051: val_mDice did not improve from 0.60019
Epoch 52/300
 - 14s - loss: 0.2531 - acc: 0.9545 - mDice: 0.7636 - val_loss: 0.5383 - val_acc: 0.9503 - val_mDice: 0.5828

Epoch 00052: val_mDice did not improve from 0.60019
Epoch 53/300
 - 14s - loss: 0.2501 - acc: 0.9547 - mDice: 0.7659 - val_loss: 0.5312 - val_acc: 0.9489 - val_mDice: 0.5834

Epoch 00053: val_mDice did not improve from 0.60019
Epoch 54/300
 - 14s - loss: 0.2515 - acc: 0.9546 - mDice: 0.7649 - val_loss: 0.5157 - val_acc: 0.9493 - val_mDice: 0.5921

Epoch 00054: val_mDice did not improve from 0.60019
Epoch 55/300
 - 14s - loss: 0.2502 - acc: 0.9547 - mDice: 0.7659 - val_loss: 0.5132 - val_acc: 0.9489 - val_mDice: 0.5968

Epoch 00055: val_mDice did not improve from 0.60019
Epoch 56/300
 - 14s - loss: 0.2508 - acc: 0.9547 - mDice: 0.7655 - val_loss: 0.5042 - val_acc: 0.9502 - val_mDice: 0.5955

Epoch 00056: val_mDice did not improve from 0.60019
Epoch 57/300
 - 14s - loss: 0.2486 - acc: 0.9547 - mDice: 0.7671 - val_loss: 0.5280 - val_acc: 0.9488 - val_mDice: 0.5852

Epoch 00057: val_mDice did not improve from 0.60019
Epoch 58/300
 - 14s - loss: 0.2487 - acc: 0.9548 - mDice: 0.7671 - val_loss: 0.5347 - val_acc: 0.9489 - val_mDice: 0.5854

Epoch 00058: val_mDice did not improve from 0.60019
Epoch 59/300
 - 14s - loss: 0.2468 - acc: 0.9549 - mDice: 0.7686 - val_loss: 0.5203 - val_acc: 0.9495 - val_mDice: 0.5860

Epoch 00059: val_mDice did not improve from 0.60019
Epoch 60/300
 - 14s - loss: 0.2454 - acc: 0.9550 - mDice: 0.7697 - val_loss: 0.5282 - val_acc: 0.9485 - val_mDice: 0.5857

Epoch 00060: val_mDice did not improve from 0.60019
Epoch 61/300
 - 14s - loss: 0.2548 - acc: 0.9549 - mDice: 0.7678 - val_loss: 0.5198 - val_acc: 0.9501 - val_mDice: 0.5924

Epoch 00061: val_mDice did not improve from 0.60019
Epoch 62/300
 - 14s - loss: 0.2451 - acc: 0.9552 - mDice: 0.7700 - val_loss: 0.5200 - val_acc: 0.9464 - val_mDice: 0.5849

Epoch 00062: val_mDice did not improve from 0.60019
Epoch 63/300
 - 14s - loss: 0.2440 - acc: 0.9552 - mDice: 0.7709 - val_loss: 0.5790 - val_acc: 0.9460 - val_mDice: 0.5576

Epoch 00063: val_mDice did not improve from 0.60019
Epoch 64/300
 - 14s - loss: 0.2438 - acc: 0.9552 - mDice: 0.7711 - val_loss: 0.5424 - val_acc: 0.9488 - val_mDice: 0.5770

Epoch 00064: val_mDice did not improve from 0.60019
Epoch 65/300
 - 14s - loss: 0.2430 - acc: 0.9554 - mDice: 0.7718 - val_loss: 0.5855 - val_acc: 0.9464 - val_mDice: 0.5580

Epoch 00065: val_mDice did not improve from 0.60019
Epoch 66/300
 - 14s - loss: 0.2417 - acc: 0.9553 - mDice: 0.7728 - val_loss: 0.5726 - val_acc: 0.9501 - val_mDice: 0.5692

Epoch 00066: val_mDice did not improve from 0.60019
Epoch 67/300
 - 14s - loss: 0.2412 - acc: 0.9555 - mDice: 0.7732 - val_loss: 0.5359 - val_acc: 0.9475 - val_mDice: 0.5849

Epoch 00067: val_mDice did not improve from 0.60019
Epoch 68/300
 - 14s - loss: 0.2421 - acc: 0.9554 - mDice: 0.7725 - val_loss: 0.5227 - val_acc: 0.9474 - val_mDice: 0.5844

Epoch 00068: val_mDice did not improve from 0.60019
Epoch 69/300
 - 14s - loss: 0.2389 - acc: 0.9556 - mDice: 0.7750 - val_loss: 0.5312 - val_acc: 0.9489 - val_mDice: 0.5861

Epoch 00069: val_mDice did not improve from 0.60019
Epoch 70/300
 - 14s - loss: 0.2398 - acc: 0.9555 - mDice: 0.7743 - val_loss: 0.4990 - val_acc: 0.9491 - val_mDice: 0.6007

Epoch 00070: val_mDice improved from 0.60019 to 0.60068, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 71/300
 - 14s - loss: 0.2394 - acc: 0.9556 - mDice: 0.7746 - val_loss: 0.4897 - val_acc: 0.9494 - val_mDice: 0.6049

Epoch 00071: val_mDice improved from 0.60068 to 0.60486, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 13s - loss: 0.2389 - acc: 0.9556 - mDice: 0.7751 - val_loss: 0.5120 - val_acc: 0.9480 - val_mDice: 0.5916

Epoch 00072: val_mDice did not improve from 0.60486
Epoch 73/300
 - 14s - loss: 0.2384 - acc: 0.9557 - mDice: 0.7755 - val_loss: 0.5031 - val_acc: 0.9498 - val_mDice: 0.5975

Epoch 00073: val_mDice did not improve from 0.60486
Epoch 74/300
 - 14s - loss: 0.2364 - acc: 0.9558 - mDice: 0.7771 - val_loss: 0.5536 - val_acc: 0.9495 - val_mDice: 0.5752

Epoch 00074: val_mDice did not improve from 0.60486
Epoch 75/300
 - 14s - loss: 0.2381 - acc: 0.9557 - mDice: 0.7757 - val_loss: 0.5389 - val_acc: 0.9457 - val_mDice: 0.5757

Epoch 00075: val_mDice did not improve from 0.60486
Epoch 76/300
 - 14s - loss: 0.2354 - acc: 0.9559 - mDice: 0.7779 - val_loss: 0.5013 - val_acc: 0.9505 - val_mDice: 0.6011

Epoch 00076: val_mDice did not improve from 0.60486
Epoch 77/300
 - 14s - loss: 0.2361 - acc: 0.9559 - mDice: 0.7773 - val_loss: 0.5469 - val_acc: 0.9501 - val_mDice: 0.5752

Epoch 00077: val_mDice did not improve from 0.60486
Epoch 78/300
 - 14s - loss: 0.2360 - acc: 0.9560 - mDice: 0.7775 - val_loss: 0.5020 - val_acc: 0.9490 - val_mDice: 0.5986

Epoch 00078: val_mDice did not improve from 0.60486
Epoch 79/300
 - 14s - loss: 0.2349 - acc: 0.9560 - mDice: 0.7783 - val_loss: 0.5078 - val_acc: 0.9496 - val_mDice: 0.5963

Epoch 00079: val_mDice did not improve from 0.60486
Epoch 80/300
 - 14s - loss: 0.2335 - acc: 0.9560 - mDice: 0.7794 - val_loss: 0.5219 - val_acc: 0.9498 - val_mDice: 0.5909

Epoch 00080: val_mDice did not improve from 0.60486
Epoch 81/300
 - 14s - loss: 0.2344 - acc: 0.9559 - mDice: 0.7787 - val_loss: 0.5350 - val_acc: 0.9506 - val_mDice: 0.5855

Epoch 00081: val_mDice did not improve from 0.60486
Epoch 82/300
 - 14s - loss: 0.2340 - acc: 0.9560 - mDice: 0.7790 - val_loss: 0.5316 - val_acc: 0.9507 - val_mDice: 0.5917

Epoch 00082: val_mDice did not improve from 0.60486
Epoch 83/300
 - 14s - loss: 0.2318 - acc: 0.9561 - mDice: 0.7808 - val_loss: 0.5216 - val_acc: 0.9511 - val_mDice: 0.5955

Epoch 00083: val_mDice did not improve from 0.60486
Epoch 84/300
 - 14s - loss: 0.2316 - acc: 0.9562 - mDice: 0.7811 - val_loss: 0.5197 - val_acc: 0.9491 - val_mDice: 0.5915

Epoch 00084: val_mDice did not improve from 0.60486
Epoch 85/300
 - 14s - loss: 0.2321 - acc: 0.9561 - mDice: 0.7807 - val_loss: 0.5308 - val_acc: 0.9503 - val_mDice: 0.5864

Epoch 00085: val_mDice did not improve from 0.60486
Epoch 86/300
 - 14s - loss: 0.2330 - acc: 0.9561 - mDice: 0.7799 - val_loss: 0.5102 - val_acc: 0.9489 - val_mDice: 0.5945

Epoch 00086: val_mDice did not improve from 0.60486
Epoch 87/300
 - 14s - loss: 0.2325 - acc: 0.9561 - mDice: 0.7804 - val_loss: 0.5103 - val_acc: 0.9511 - val_mDice: 0.5980

Epoch 00087: val_mDice did not improve from 0.60486
Epoch 88/300
 - 14s - loss: 0.2312 - acc: 0.9562 - mDice: 0.7814 - val_loss: 0.5483 - val_acc: 0.9483 - val_mDice: 0.5773

Epoch 00088: val_mDice did not improve from 0.60486
Epoch 89/300
 - 14s - loss: 0.2297 - acc: 0.9564 - mDice: 0.7826 - val_loss: 0.5130 - val_acc: 0.9507 - val_mDice: 0.5982

Epoch 00089: val_mDice did not improve from 0.60486
Epoch 90/300
 - 14s - loss: 0.2312 - acc: 0.9563 - mDice: 0.7814 - val_loss: 0.5131 - val_acc: 0.9491 - val_mDice: 0.5938

Epoch 00090: val_mDice did not improve from 0.60486
Epoch 91/300
 - 14s - loss: 0.2301 - acc: 0.9563 - mDice: 0.7822 - val_loss: 0.5199 - val_acc: 0.9490 - val_mDice: 0.5916

Epoch 00091: val_mDice did not improve from 0.60486
Epoch 92/300
 - 14s - loss: 0.2323 - acc: 0.9562 - mDice: 0.7806 - val_loss: 0.5105 - val_acc: 0.9502 - val_mDice: 0.5987

Epoch 00092: val_mDice did not improve from 0.60486
Epoch 93/300
 - 14s - loss: 0.2284 - acc: 0.9565 - mDice: 0.7837 - val_loss: 0.4931 - val_acc: 0.9490 - val_mDice: 0.6045

Epoch 00093: val_mDice did not improve from 0.60486
Epoch 94/300
 - 14s - loss: 0.2281 - acc: 0.9565 - mDice: 0.7839 - val_loss: 0.5107 - val_acc: 0.9509 - val_mDice: 0.5974

Epoch 00094: val_mDice did not improve from 0.60486
Epoch 95/300
 - 14s - loss: 0.2779 - acc: 0.9525 - mDice: 0.7489 - val_loss: 0.5090 - val_acc: 0.9496 - val_mDice: 0.5940

Epoch 00095: val_mDice did not improve from 0.60486
Epoch 96/300
 - 14s - loss: 0.2358 - acc: 0.9558 - mDice: 0.7776 - val_loss: 0.5066 - val_acc: 0.9509 - val_mDice: 0.5983

Epoch 00096: val_mDice did not improve from 0.60486
Epoch 97/300
 - 14s - loss: 0.2302 - acc: 0.9563 - mDice: 0.7822 - val_loss: 0.5045 - val_acc: 0.9496 - val_mDice: 0.5994

Epoch 00097: val_mDice did not improve from 0.60486
Epoch 98/300
 - 14s - loss: 0.2295 - acc: 0.9564 - mDice: 0.7828 - val_loss: 0.5197 - val_acc: 0.9502 - val_mDice: 0.5928

Epoch 00098: val_mDice did not improve from 0.60486
Epoch 99/300
 - 14s - loss: 0.2262 - acc: 0.9566 - mDice: 0.7855 - val_loss: 0.5432 - val_acc: 0.9497 - val_mDice: 0.5882

Epoch 00099: val_mDice did not improve from 0.60486
Epoch 100/300
 - 14s - loss: 0.2264 - acc: 0.9566 - mDice: 0.7853 - val_loss: 0.5334 - val_acc: 0.9492 - val_mDice: 0.5903

Epoch 00100: val_mDice did not improve from 0.60486
Epoch 101/300
 - 14s - loss: 0.2260 - acc: 0.9566 - mDice: 0.7857 - val_loss: 0.5167 - val_acc: 0.9505 - val_mDice: 0.5926

Epoch 00101: val_mDice did not improve from 0.60486
Epoch 102/300
 - 13s - loss: 0.2267 - acc: 0.9567 - mDice: 0.7851 - val_loss: 0.5285 - val_acc: 0.9493 - val_mDice: 0.5868

Epoch 00102: val_mDice did not improve from 0.60486
Epoch 103/300
 - 14s - loss: 0.2252 - acc: 0.9568 - mDice: 0.7863 - val_loss: 0.5283 - val_acc: 0.9499 - val_mDice: 0.5904

Epoch 00103: val_mDice did not improve from 0.60486
Epoch 104/300
 - 14s - loss: 0.2261 - acc: 0.9566 - mDice: 0.7855 - val_loss: 0.4938 - val_acc: 0.9516 - val_mDice: 0.6062

Epoch 00104: val_mDice improved from 0.60486 to 0.60623, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 105/300
 - 14s - loss: 0.2250 - acc: 0.9568 - mDice: 0.7866 - val_loss: 0.4984 - val_acc: 0.9512 - val_mDice: 0.6036

Epoch 00105: val_mDice did not improve from 0.60623
Epoch 106/300
 - 14s - loss: 0.2239 - acc: 0.9568 - mDice: 0.7873 - val_loss: 0.5451 - val_acc: 0.9497 - val_mDice: 0.5790

Epoch 00106: val_mDice did not improve from 0.60623
Epoch 107/300
 - 14s - loss: 0.2240 - acc: 0.9568 - mDice: 0.7874 - val_loss: 0.5012 - val_acc: 0.9494 - val_mDice: 0.6014

Epoch 00107: val_mDice did not improve from 0.60623
Epoch 108/300
 - 14s - loss: 0.2254 - acc: 0.9567 - mDice: 0.7862 - val_loss: 0.5190 - val_acc: 0.9505 - val_mDice: 0.5965

Epoch 00108: val_mDice did not improve from 0.60623
Epoch 109/300
 - 14s - loss: 0.2239 - acc: 0.9569 - mDice: 0.7875 - val_loss: 0.5298 - val_acc: 0.9486 - val_mDice: 0.5901

Epoch 00109: val_mDice did not improve from 0.60623
Epoch 110/300
 - 14s - loss: 0.2246 - acc: 0.9568 - mDice: 0.7868 - val_loss: 0.5009 - val_acc: 0.9506 - val_mDice: 0.6042

Epoch 00110: val_mDice did not improve from 0.60623
Epoch 111/300
 - 13s - loss: 0.2245 - acc: 0.9569 - mDice: 0.7870 - val_loss: 0.5268 - val_acc: 0.9506 - val_mDice: 0.5924

Epoch 00111: val_mDice did not improve from 0.60623
Epoch 112/300
 - 13s - loss: 0.2262 - acc: 0.9570 - mDice: 0.7884 - val_loss: 0.5170 - val_acc: 0.9503 - val_mDice: 0.5924

Epoch 00112: val_mDice did not improve from 0.60623
Epoch 113/300
 - 13s - loss: 0.2325 - acc: 0.9561 - mDice: 0.7803 - val_loss: 0.5415 - val_acc: 0.9498 - val_mDice: 0.5823

Epoch 00113: val_mDice did not improve from 0.60623
Epoch 114/300
 - 13s - loss: 0.2246 - acc: 0.9567 - mDice: 0.7869 - val_loss: 0.5323 - val_acc: 0.9495 - val_mDice: 0.5879

Epoch 00114: val_mDice did not improve from 0.60623
Epoch 115/300
 - 14s - loss: 0.2227 - acc: 0.9570 - mDice: 0.7885 - val_loss: 0.5271 - val_acc: 0.9512 - val_mDice: 0.5925

Epoch 00115: val_mDice did not improve from 0.60623
Epoch 116/300
 - 14s - loss: 0.2216 - acc: 0.9571 - mDice: 0.7893 - val_loss: 0.5356 - val_acc: 0.9477 - val_mDice: 0.5837

Epoch 00116: val_mDice did not improve from 0.60623
Epoch 117/300
 - 14s - loss: 0.2227 - acc: 0.9571 - mDice: 0.7885 - val_loss: 0.5470 - val_acc: 0.9503 - val_mDice: 0.5823

Epoch 00117: val_mDice did not improve from 0.60623
Epoch 118/300
 - 14s - loss: 0.2211 - acc: 0.9572 - mDice: 0.7898 - val_loss: 0.5057 - val_acc: 0.9509 - val_mDice: 0.6034

Epoch 00118: val_mDice did not improve from 0.60623
Epoch 119/300
 - 14s - loss: 0.2217 - acc: 0.9571 - mDice: 0.7892 - val_loss: 0.5138 - val_acc: 0.9502 - val_mDice: 0.5950

Epoch 00119: val_mDice did not improve from 0.60623
Epoch 120/300
 - 13s - loss: 0.2209 - acc: 0.9571 - mDice: 0.7899 - val_loss: 0.5132 - val_acc: 0.9503 - val_mDice: 0.5990

Epoch 00120: val_mDice did not improve from 0.60623
Epoch 121/300
 - 13s - loss: 0.2212 - acc: 0.9571 - mDice: 0.7897 - val_loss: 0.5202 - val_acc: 0.9504 - val_mDice: 0.5951

Epoch 00121: val_mDice did not improve from 0.60623
Epoch 122/300
 - 14s - loss: 0.2207 - acc: 0.9571 - mDice: 0.7900 - val_loss: 0.5232 - val_acc: 0.9510 - val_mDice: 0.5902

Epoch 00122: val_mDice did not improve from 0.60623
Epoch 123/300
 - 13s - loss: 0.2211 - acc: 0.9571 - mDice: 0.7897 - val_loss: 0.4961 - val_acc: 0.9512 - val_mDice: 0.6056

Epoch 00123: val_mDice did not improve from 0.60623
Epoch 124/300
 - 13s - loss: 0.2196 - acc: 0.9573 - mDice: 0.7909 - val_loss: 0.5413 - val_acc: 0.9497 - val_mDice: 0.5856

Epoch 00124: val_mDice did not improve from 0.60623
Epoch 125/300
 - 13s - loss: 0.2213 - acc: 0.9572 - mDice: 0.7896 - val_loss: 0.5229 - val_acc: 0.9505 - val_mDice: 0.5902

Epoch 00125: val_mDice did not improve from 0.60623
Epoch 126/300
 - 13s - loss: 0.2203 - acc: 0.9573 - mDice: 0.7904 - val_loss: 0.5314 - val_acc: 0.9500 - val_mDice: 0.5840

Epoch 00126: val_mDice did not improve from 0.60623
Epoch 127/300
 - 14s - loss: 0.2190 - acc: 0.9573 - mDice: 0.7915 - val_loss: 0.5175 - val_acc: 0.9496 - val_mDice: 0.5920

Epoch 00127: val_mDice did not improve from 0.60623
Epoch 128/300
 - 14s - loss: 0.2191 - acc: 0.9573 - mDice: 0.7914 - val_loss: 0.5230 - val_acc: 0.9489 - val_mDice: 0.5914

Epoch 00128: val_mDice did not improve from 0.60623
Epoch 129/300
 - 13s - loss: 0.2198 - acc: 0.9572 - mDice: 0.7908 - val_loss: 0.5383 - val_acc: 0.9494 - val_mDice: 0.5821

Epoch 00129: val_mDice did not improve from 0.60623
Epoch 130/300
 - 13s - loss: 0.2188 - acc: 0.9574 - mDice: 0.7916 - val_loss: 0.5178 - val_acc: 0.9500 - val_mDice: 0.5937

Epoch 00130: val_mDice did not improve from 0.60623
Epoch 131/300
 - 14s - loss: 0.2193 - acc: 0.9573 - mDice: 0.7912 - val_loss: 0.5233 - val_acc: 0.9490 - val_mDice: 0.5900

Epoch 00131: val_mDice did not improve from 0.60623
Epoch 132/300
 - 13s - loss: 0.2189 - acc: 0.9573 - mDice: 0.7915 - val_loss: 0.5099 - val_acc: 0.9488 - val_mDice: 0.5951

Epoch 00132: val_mDice did not improve from 0.60623
Epoch 133/300
 - 13s - loss: 0.2179 - acc: 0.9573 - mDice: 0.7924 - val_loss: 0.5386 - val_acc: 0.9504 - val_mDice: 0.5868

Epoch 00133: val_mDice did not improve from 0.60623
Epoch 134/300
 - 13s - loss: 0.2188 - acc: 0.9573 - mDice: 0.7917 - val_loss: 0.5024 - val_acc: 0.9505 - val_mDice: 0.6021

Epoch 00134: val_mDice did not improve from 0.60623
Epoch 135/300
 - 13s - loss: 0.2182 - acc: 0.9574 - mDice: 0.7921 - val_loss: 0.5328 - val_acc: 0.9512 - val_mDice: 0.5871

Epoch 00135: val_mDice did not improve from 0.60623
Epoch 136/300
 - 14s - loss: 0.2174 - acc: 0.9575 - mDice: 0.7928 - val_loss: 0.5288 - val_acc: 0.9511 - val_mDice: 0.5877

Epoch 00136: val_mDice did not improve from 0.60623
Epoch 137/300
 - 13s - loss: 0.2175 - acc: 0.9574 - mDice: 0.7926 - val_loss: 0.5279 - val_acc: 0.9485 - val_mDice: 0.5884

Epoch 00137: val_mDice did not improve from 0.60623
Epoch 138/300
 - 13s - loss: 0.2169 - acc: 0.9574 - mDice: 0.7933 - val_loss: 0.5017 - val_acc: 0.9513 - val_mDice: 0.6042

Epoch 00138: val_mDice did not improve from 0.60623
Epoch 139/300
 - 14s - loss: 0.2194 - acc: 0.9573 - mDice: 0.7913 - val_loss: 0.5364 - val_acc: 0.9514 - val_mDice: 0.5868

Epoch 00139: val_mDice did not improve from 0.60623
Epoch 140/300
 - 14s - loss: 0.2195 - acc: 0.9573 - mDice: 0.7911 - val_loss: 0.5034 - val_acc: 0.9508 - val_mDice: 0.5999

Epoch 00140: val_mDice did not improve from 0.60623
Epoch 141/300
 - 14s - loss: 0.2166 - acc: 0.9575 - mDice: 0.7935 - val_loss: 0.5551 - val_acc: 0.9480 - val_mDice: 0.5794

Epoch 00141: val_mDice did not improve from 0.60623
Epoch 142/300
 - 13s - loss: 0.2216 - acc: 0.9572 - mDice: 0.7897 - val_loss: 0.5095 - val_acc: 0.9514 - val_mDice: 0.5993

Epoch 00142: val_mDice did not improve from 0.60623
Epoch 143/300
 - 13s - loss: 0.2173 - acc: 0.9575 - mDice: 0.7929 - val_loss: 0.5202 - val_acc: 0.9495 - val_mDice: 0.5935

Epoch 00143: val_mDice did not improve from 0.60623
Epoch 144/300
 - 14s - loss: 0.2162 - acc: 0.9576 - mDice: 0.7938 - val_loss: 0.5310 - val_acc: 0.9498 - val_mDice: 0.5850

Epoch 00144: val_mDice did not improve from 0.60623
Restoring model weights from the end of the best epoch
Epoch 00144: early stopping
{'val_loss': [0.910785354382499, 0.7377337893294222, 0.589051441773356, 0.6149409752984286, 0.5538079442258653, 0.555151480869208, 0.5393319239829506, 0.5408816137793344, 0.5266476789666288, 0.5312107921312641, 0.5201833614423954, 0.5401095651381509, 0.5239664749060263, 0.5524931566675282, 0.5503985415623841, 0.5084252474028305, 0.5859557360244196, 0.5609365059010809, 0.542740447894155, 0.5165943150413769, 0.4983640939163762, 0.5210866734968217, 0.5288332820604633, 0.5157288795742909, 0.5012095490647428, 0.5456141912737372, 0.5354710018168615, 0.5094760063640232, 0.5185140238127894, 0.5068847403845973, 0.4962295600155878, 0.5428310476201873, 0.5169208376101275, 0.5152312077623505, 0.5348667875348523, 0.5859755184397352, 0.539856934680619, 0.5097481821502388, 0.49606081194051815, 0.5069797788252378, 0.5551802006513713, 0.5094524505418107, 0.5137415997808872, 0.5210858460245186, 0.5307377533539713, 0.49860855287679745, 0.5597085166909841, 0.5024806507472885, 0.5385638005906643, 0.5143435947055923, 0.5332694040330429, 0.5382748306130564, 0.5312193891855591, 0.515720867244891, 0.5131544956947838, 0.504215780250187, 0.5279643518964672, 0.534716495921492, 0.5203106806264909, 0.5281955932771694, 0.5198417559016351, 0.5199697826827705, 0.5789725960299955, 0.5423879357023612, 0.5855205438656514, 0.5725874844210108, 0.5359440276076674, 0.5227168348914418, 0.5312300357738686, 0.4990479503263974, 0.4897267209085006, 0.5120276628925814, 0.5030684441161555, 0.5536013362127975, 0.5389453189333058, 0.5012728398738626, 0.546906533520981, 0.5020469806713765, 0.5077731752528825, 0.5218728537666065, 0.5350059250879554, 0.5315933417341563, 0.5216203152134432, 0.5196972332853179, 0.5308471804890553, 0.5101908022464987, 0.5102574089385944, 0.5483106441337969, 0.5129556382834578, 0.5130519896912176, 0.5198839293511887, 0.5104827601150428, 0.4931031272398027, 0.5106867428598457, 0.5090059801186929, 0.5066390976559516, 0.5045045068144133, 0.5197487923020091, 0.5432021534642694, 0.5333541215465055, 0.5167186919537337, 0.528479788889432, 0.5282949725342863, 0.49383916868177874, 0.4984342805500137, 0.5451297177282791, 0.5011892568465718, 0.5190062559516736, 0.5298156035679012, 0.5008795750873715, 0.5267979675831076, 0.5169527091127534, 0.5414576440550095, 0.5322593357309949, 0.5270991788230128, 0.5355572577295357, 0.5469869055561514, 0.5057000431268575, 0.5138197647792667, 0.5131759946572714, 0.5202441098969742, 0.5232089917752996, 0.49608945480272093, 0.5412680949578738, 0.5229106202471856, 0.531382137170717, 0.5175165840367365, 0.5229806147474151, 0.5383305249933424, 0.5177621218745269, 0.5233426157322676, 0.5099435278823256, 0.5385790277459768, 0.5024422230667243, 0.5327805007636214, 0.5288283375388417, 0.5279391244803061, 0.5016859679914719, 0.536426413658611, 0.5034447612043199, 0.5551119506692087, 0.5094748445729304, 0.5202124388524274, 0.5310434532565111], 'val_acc': [0.9216286110478407, 0.932460908117241, 0.9351901335423219, 0.9388305215196237, 0.942607273269632, 0.9442538912069864, 0.9478756905268024, 0.9481236032267523, 0.946733173378353, 0.9435080542910699, 0.9451154393856752, 0.9483715478934389, 0.9461794652086396, 0.9438964674592684, 0.9453778280226212, 0.9465245018458234, 0.9462806782242972, 0.9486008522896793, 0.9482702806009261, 0.9471009230480514, 0.9493074343857153, 0.9487558150424638, 0.9466897835278644, 0.947631903533829, 0.9472868732233953, 0.9469026080722915, 0.9470079344744123, 0.946315820989662, 0.9495347235455859, 0.9464274072114316, 0.9474149442917807, 0.948838485019833, 0.9490553989756707, 0.9481091339494929, 0.9456650155216622, 0.9476670236560886, 0.9492330907443383, 0.9493921578929411, 0.9479666005965718, 0.9489851424147963, 0.9492124095975354, 0.94933019803223, 0.9483674291791863, 0.9500223265013881, 0.9510450126738522, 0.9473901644099358, 0.9479438878970439, 0.9496814149052071, 0.9476070840265498, 0.9493901070269792, 0.9485657531455909, 0.950330150859982, 0.9489004502083336, 0.9493033356506732, 0.9489004412176889, 0.9502268719939546, 0.9487599494070981, 0.9488777418376347, 0.9494582631068522, 0.9484872168668822, 0.9500698334011952, 0.9464150011206472, 0.9459521900342164, 0.9488012627516379, 0.9464439083744027, 0.9501028813463349, 0.9475182474658476, 0.9474335665809376, 0.9488653117717978, 0.9491359984408544, 0.9494087026771887, 0.9479893196228496, 0.9497578630234276, 0.9495078558362396, 0.9457476691826762, 0.9505429570901327, 0.9500677758754965, 0.9490202785204243, 0.949629783963358, 0.9497558021678605, 0.9506441957457772, 0.950689652445596, 0.951069777904276, 0.9491070452349146, 0.9503136064087212, 0.9489438480505065, 0.9511482902079321, 0.948264110021751, 0.9506669270925682, 0.9490740049484722, 0.9489624257194264, 0.950185539003191, 0.9490202955027532, 0.9509148248081101, 0.9496049711158155, 0.9509437880036551, 0.9496029055984326, 0.9501628173130184, 0.9497062024457494, 0.9492495845815989, 0.9505119600109548, 0.9492826681563308, 0.9499231217293765, 0.9515842425756614, 0.9512247536435473, 0.9497289317946195, 0.9493735525861132, 0.950485124934319, 0.9486111848713965, 0.9505532840110736, 0.9505966645379306, 0.9503012123054633, 0.9498487780879996, 0.949495492700758, 0.9511627738036257, 0.9477227916264667, 0.9502743689041564, 0.9508797336557058, 0.9502123910621558, 0.9502888188681788, 0.9503756182153797, 0.9509727019171476, 0.9512040748276525, 0.9496896946230414, 0.9504933806771007, 0.9500119736074736, 0.9495760568693363, 0.948877722191411, 0.9493611624786974, 0.9499685694385507, 0.9489831091971371, 0.9487930343137773, 0.9503983205923155, 0.9504871854568993, 0.9511503607201177, 0.9511359290703715, 0.9484583199357187, 0.9513445896143354, 0.9514313833007599, 0.9507536791556375, 0.9480161919940118, 0.9513610901113329, 0.9495161498725081, 0.9497702627874619], 'val_mDice': [0.3879879539905314, 0.4812256570634895, 0.5419368903730168, 0.5330078089037421, 0.5633237984593354, 0.563441327164293, 0.5722495996752265, 0.5711972833345722, 0.5788629927448721, 0.5755132383474425, 0.5814569272808523, 0.5736919002160014, 0.5821655362677973, 0.5631764810844506, 0.5644799014709515, 0.5920909443381113, 0.5540664076139141, 0.5663992153199692, 0.5764283870851528, 0.5855158087927536, 0.5992526348742693, 0.5844939314453296, 0.5846515664175236, 0.5895149294890505, 0.597893164144548, 0.57830880673904, 0.5754473715521103, 0.592748560718984, 0.5899135170702162, 0.591506716259365, 0.599963582427808, 0.5777970066283669, 0.5890312417925403, 0.5899725266675043, 0.5774772959714495, 0.5677805919220994, 0.5789253938131492, 0.5932370347683656, 0.5992305928102418, 0.5955498771294535, 0.5733006213630378, 0.600189899599086, 0.592086780337648, 0.5881346554063552, 0.5873187790369855, 0.596960794992287, 0.5674292711572274, 0.5975510311526293, 0.5816703422109508, 0.5898406911828664, 0.5828080124029235, 0.5827833720425654, 0.5833850859263756, 0.5921020734243553, 0.5968129674815599, 0.5955021308121069, 0.5851685834330553, 0.5854189132844936, 0.5859826070636345, 0.5857254379954417, 0.592446674847736, 0.5848809780355272, 0.557551421932668, 0.5770448492891962, 0.5580419957970774, 0.569204725366731, 0.5848942422334042, 0.5844375924025168, 0.5861289394634396, 0.6006781705264939, 0.6048593730899875, 0.5916154804176459, 0.5975490535437727, 0.5751964519809745, 0.5757282932377394, 0.6010861373480472, 0.5751984878625284, 0.5985662284510096, 0.5962624370052828, 0.5909220283257894, 0.585453184623292, 0.5917316065820236, 0.5954830626535682, 0.5914641415606664, 0.5864092361327656, 0.5944858073522259, 0.5980045708864095, 0.5772919205313954, 0.598218410374732, 0.5937810896495201, 0.5916345126136056, 0.5987465281726262, 0.6045213531515452, 0.5974438693270337, 0.594027399350811, 0.598347700840934, 0.5994022978084713, 0.59277842331199, 0.5882145193036042, 0.5903365735235161, 0.59264721550755, 0.5868025328859937, 0.5904034256269146, 0.6062272397499511, 0.6035774513329873, 0.5789709870375734, 0.6014400394269208, 0.5965451228552024, 0.5900556068846633, 0.6042256501799855, 0.5923643698239459, 0.5924183616425072, 0.582259653666832, 0.587875802423701, 0.5924993903277307, 0.5836980329545517, 0.5822644992913614, 0.6034358972943695, 0.5950327382407374, 0.5989751789156951, 0.5951013411889529, 0.5901728705320944, 0.6056016860061517, 0.585634524595804, 0.5901627300837853, 0.5840315722220437, 0.5920252633494372, 0.5914007425308228, 0.5821315789355912, 0.5936789925537962, 0.5899924153056224, 0.5950962131915811, 0.5867991234337151, 0.6020992388272418, 0.5871434684572273, 0.5877104687957124, 0.5884038176616477, 0.604215464112479, 0.5867963290081344, 0.599850071209103, 0.579408294661751, 0.599315167805336, 0.5935316701841088, 0.5849559799918915], 'loss': [2.185825014677931, 0.7723307456269541, 0.6078553341532394, 0.5300574772310286, 0.4840390446671577, 0.4767491366211271, 0.4303887815369246, 0.4126776444432159, 0.39846992252127655, 0.38695214044800397, 0.3735990953107174, 0.3640611930357969, 0.3575111420385965, 0.3525776303718243, 0.3415297118090809, 0.33658454496871804, 0.32913037391342853, 0.32439635495761404, 0.3182372350048301, 0.3151276063087375, 0.31111315089330116, 0.30830173406957523, 0.3026917172581352, 0.300436806533664, 0.29792883211793375, 0.2959000926334337, 0.29195966633613657, 0.2903088775506162, 0.28782034520684524, 0.28634852437300135, 0.2851145562539465, 0.2809769760844274, 0.2792954675110264, 0.27827279073864436, 0.27511873576552914, 0.27381344995859125, 0.2735360408944701, 0.27025450498350995, 0.2679364734677394, 0.26768311005383755, 0.26476486195640675, 0.2660314834401613, 0.26240040270012, 0.2628255037870953, 0.26064317985613566, 0.2595587809986619, 0.25910751275520594, 0.2566172830984877, 0.255732520591829, 0.2538822841965018, 0.2525801761212299, 0.2531014922433128, 0.2501499977781066, 0.25145498570384467, 0.2501896358261531, 0.25079551497404823, 0.248618805508625, 0.2486798639138029, 0.24683351747711516, 0.24542744779751052, 0.2547745262550364, 0.24512035820756328, 0.2440439468115466, 0.24376604660885323, 0.2429516310534, 0.24166503645847726, 0.24118932201077908, 0.24213502846342125, 0.23890977205680117, 0.23983034566933473, 0.23943586865091343, 0.2389353705742255, 0.23842728409601072, 0.23642961209937446, 0.2381141735434071, 0.235365961847284, 0.23613117769888872, 0.23596888765011806, 0.23487449653215783, 0.23351885309621118, 0.2344455684900258, 0.2340248196239364, 0.23179943719987847, 0.23158852456474438, 0.23205916830172926, 0.23304441375729434, 0.23248791186438555, 0.23119688528950494, 0.2297264464565965, 0.23119873664090332, 0.23012976063297022, 0.2323338906997157, 0.22836292488117518, 0.22807654883615344, 0.27793583141602396, 0.23582373617988844, 0.2302031663483988, 0.2294612439276963, 0.22622925569325397, 0.22638837176303928, 0.22597016232230943, 0.2266507059786939, 0.22520773818592746, 0.22613453512669363, 0.22495455457201244, 0.22392414324401505, 0.22395206154460812, 0.22542045655921097, 0.2238866788867278, 0.2245638948170281, 0.22447589185559785, 0.22621099964530048, 0.23253754167137086, 0.22459885159398948, 0.22268820849793208, 0.22157387201461803, 0.22270160638914668, 0.22106725290757717, 0.22169129956158787, 0.22091865531597435, 0.2211957625603664, 0.2207041315608188, 0.22114431178944413, 0.2196489805801522, 0.22129758322224638, 0.22025850477395745, 0.21900193372210883, 0.21912945373035855, 0.21977685918041087, 0.21877633747981268, 0.2193003880733187, 0.21893015349848158, 0.21791072413069668, 0.2187626419386945, 0.2182169248677178, 0.2174285492606623, 0.2175143600276311, 0.21685013313139195, 0.21941292037417714, 0.2194700563946007, 0.21664332452244206, 0.2216466331097576, 0.21726712522167285, 0.21619769276068185], 'acc': [0.7329492741792681, 0.8982624000963072, 0.9061121625335679, 0.9131482132872779, 0.9196807027583769, 0.9244965319409881, 0.9317105210630549, 0.9369262614727254, 0.9406727265736408, 0.9424280983243046, 0.9438182620640954, 0.9447255865965694, 0.945371533448475, 0.9458876463441208, 0.9468697358999537, 0.9473149090003853, 0.9480330414693084, 0.9484484251415111, 0.9489661100857216, 0.9492873084466575, 0.9495001452225342, 0.9499262252064821, 0.9503200567922369, 0.9505348474649191, 0.9507880494599897, 0.9509839047943349, 0.9512532243807327, 0.9514174798164587, 0.9516496532694797, 0.9517330974413479, 0.9518232755194588, 0.9521794826089346, 0.9522933602709636, 0.9524356239365698, 0.9526572425013163, 0.9527239910132173, 0.9528734028667258, 0.9530624734843117, 0.9532801670340189, 0.9533730600304959, 0.9535972798749075, 0.9534419253431993, 0.9536847731145299, 0.953688703102845, 0.9538411345008437, 0.9539364250609639, 0.954069864463588, 0.9541041254120762, 0.9542871344927694, 0.9543035673936736, 0.9545147551196144, 0.9544530808260144, 0.9546836235997048, 0.9546021486177897, 0.9547205638388171, 0.9546724446140196, 0.9547051142213989, 0.954812428529379, 0.9549093741125598, 0.9550453078304655, 0.9549266539246654, 0.9551627553013777, 0.9551796524114751, 0.9552292608207142, 0.9553602647855387, 0.955319073395521, 0.9554966045558261, 0.9553675958257272, 0.9555926997543037, 0.9555174278463714, 0.9555772086074361, 0.9555655892758411, 0.9557242656603312, 0.955777260230833, 0.9557012642470654, 0.9558631037258192, 0.9558771630042739, 0.9559594202058507, 0.9559541628690699, 0.9560113067292199, 0.955924255780019, 0.9559990990058664, 0.95607511558393, 0.9562175376055178, 0.9561450502677821, 0.9561314519814732, 0.9560894585663402, 0.9562204765712544, 0.956354621610937, 0.9562586254462211, 0.9563027983604904, 0.9562038781758351, 0.9564964009664864, 0.9564504970795746, 0.9524739331737089, 0.9558118020590273, 0.9563132718357215, 0.9564067097435031, 0.95659638381551, 0.9566263339792317, 0.9566376333136449, 0.9566891759246089, 0.9568207425318294, 0.9566433132814754, 0.9567734083996366, 0.9568205832409239, 0.9568401386870141, 0.956724988239717, 0.9569083963673551, 0.9568030977812697, 0.9568867468085984, 0.9570452028204884, 0.9561275040413207, 0.9567213228738202, 0.9570184524143309, 0.9570971873290762, 0.9571097156112149, 0.9571542877574664, 0.9570597830203602, 0.9571245013222923, 0.9571279234521549, 0.9571126174656669, 0.9571431334368914, 0.9572627310964266, 0.9571688720054288, 0.9572599332068106, 0.9573089535326864, 0.9572886349679494, 0.9572068206119054, 0.9574152265172348, 0.957329583985439, 0.9573219477542767, 0.9572947192611495, 0.9573336512030525, 0.9573840675780693, 0.9574526088552391, 0.9574040657593192, 0.9574456583810174, 0.9573361091017496, 0.9573228562730673, 0.9574656221161649, 0.9572082285586022, 0.9575180702366332, 0.95757601675492], 'mDice': [0.18229243700811465, 0.44876498062654385, 0.5304293280092954, 0.5745524188238749, 0.6021503020356108, 0.6095041926568984, 0.636183353052388, 0.6476536901108444, 0.6569252256071715, 0.6647720536039867, 0.6738928805917613, 0.680482137022075, 0.6852420056400577, 0.688790330653889, 0.6964067401245044, 0.7000560545043536, 0.7054740158497823, 0.7089207005146302, 0.7134210380695788, 0.7157451286469662, 0.7186594252934104, 0.7208732179447259, 0.7249791757303816, 0.7267402487378722, 0.7287168773935547, 0.7301964285742334, 0.7331730317111161, 0.7345031012014187, 0.7363627263224661, 0.7374493152667647, 0.7384676969062398, 0.7416803489537237, 0.7430150572052904, 0.7438437656882048, 0.7460985104247289, 0.7471909423349964, 0.7474351772704446, 0.7499441027050476, 0.7517819973542198, 0.7521782941979511, 0.7543320167909344, 0.7534107544032468, 0.7561428747199977, 0.7558511418913465, 0.7575846923202038, 0.758408533527625, 0.7588684734621116, 0.7607584073518747, 0.7614013811457839, 0.7628913124066917, 0.7640183512619537, 0.763555509125665, 0.7658733353428602, 0.7649140969307541, 0.7659068761759545, 0.7654967860136473, 0.7671494760594333, 0.7671006010979922, 0.7686081530156916, 0.7696883488464937, 0.7678382805694741, 0.7700199387534616, 0.7709202566903101, 0.7710963735152717, 0.7718052698774968, 0.7727910328207436, 0.7731875253037932, 0.7725173968270508, 0.7750136956534389, 0.7743231975287564, 0.7746067779930671, 0.7750747900572447, 0.7754579840399304, 0.7771004149352964, 0.7756905166887651, 0.7778966309918953, 0.7773074439184695, 0.7775181403516405, 0.7783223630543025, 0.7794361804105716, 0.7787108895994338, 0.7790435764707905, 0.7808083233104331, 0.7810741632886263, 0.7807143144790374, 0.7799475134655863, 0.7803835658996974, 0.7813570641833747, 0.7825739062382345, 0.781381894905098, 0.78223722607967, 0.7806498115504595, 0.783733793414176, 0.7839224823912818, 0.7488905160711856, 0.7775935085924432, 0.7821926445841796, 0.7828368729388335, 0.7854845936466787, 0.7853434453809919, 0.7856885328914052, 0.7851489468679391, 0.7863151851409882, 0.7855374371587993, 0.7865524413012892, 0.7873422498829218, 0.787402744510323, 0.7861565670951001, 0.7874636957701382, 0.7868394163152075, 0.7869592684623261, 0.7883595253029106, 0.7803440667738758, 0.7868600027551189, 0.7884530329664031, 0.7893278658386799, 0.7885034049747361, 0.7897621506108781, 0.7891844891883742, 0.7898568124833706, 0.7897377292949269, 0.7900153275318093, 0.789728633394351, 0.7909109757737484, 0.7896109932317277, 0.790440641770883, 0.7914632115383032, 0.7913802702710894, 0.7908192771328124, 0.7916413113336068, 0.7912305131092823, 0.7914969981167936, 0.792368631043223, 0.7916766321287066, 0.7921196403868818, 0.7927946143404577, 0.7926419396577308, 0.7932589733680474, 0.791254987423732, 0.7911334887912257, 0.7934724128614433, 0.7896549864231089, 0.7928692701595111, 0.7938045500689658]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.75s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:25,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:50,  1.66s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:50,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:24,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:20,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:39,  1.65s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:31,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:04,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:19,  1.82s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:17,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:30,  1.87s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:03,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:01,  1.78s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:17,  1.84s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:28,  1.89s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:00,  1.79s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:58,  1.79s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:43,  1.74s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:43,  1.75s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:01,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:40,  1.75s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:39,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:18,  1.68s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:38,  1.76s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:51,  1.82s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:28,  1.74s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:27,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:22,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:37,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:50,  1.85s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:23,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:28,  1.79s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:37,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:12,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:17,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:27,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:07,  1.74s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:07,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:52,  1.69s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:38,  1.64s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:44,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:05,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:51,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:11,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:57,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:00,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:14,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<06:49,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:48,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:36,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:37,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:31,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:34,  1.74s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:49,  1.81s/it]predicting train subjects:  21%|██        | 60/285 [01:45<07:00,  1.87s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:40,  1.79s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:36,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:31,  1.76s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:20,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:25,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:26,  1.77s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:25,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:17,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:20,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:21,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:06,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:09,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:13,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:15,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:04,  1.75s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:58,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:59,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<06:00,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:51,  1.72s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:51,  1.73s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:36,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:41,  1.71s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:46,  1.74s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:47,  1.75s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:38,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:43,  1.75s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:47,  1.78s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:37,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:29,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:29,  1.73s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:29,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:25,  1.73s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:24,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:23,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:27,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:18,  1.73s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:18,  1.74s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:14,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:11,  1.72s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:11,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:04,  1.70s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:10<05:05,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<04:59,  1.72s/it]predicting train subjects:  39%|███▉      | 112/285 [03:15<04:58,  1.72s/it]predicting train subjects:  40%|███▉      | 113/285 [03:17<04:57,  1.73s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:55,  1.73s/it]predicting train subjects:  40%|████      | 115/285 [03:20<04:53,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:22<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:24<04:45,  1.70s/it]predicting train subjects:  41%|████▏     | 118/285 [03:25<04:38,  1.67s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:44,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:36,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:30<04:32,  1.66s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:20,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:10,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<04:07,  1.55s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<04:04,  1.54s/it]predicting train subjects:  45%|████▍     | 127/285 [03:39<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<03:52,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:46,  1.46s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:49,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:46,  1.49s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:44,  1.49s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:41,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:41,  1.49s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:37,  1.48s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:41,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:35,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:31,  1.49s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:29,  1.50s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:29,  1.51s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:23,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:24,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:14,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:17,  1.51s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:16,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:10,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:26<03:07,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:04,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:29<03:05,  1.48s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:07,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:32<03:04,  1.50s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:07,  1.54s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:35<03:05,  1.53s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:59,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:38<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<03:03,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:41<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:56,  1.53s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:44<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [04:45<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [04:47<02:48,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [04:48<02:44,  1.47s/it]predicting train subjects:  61%|██████    | 174/285 [04:50<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:51<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<02:48,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:54<02:46,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:57<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:47,  1.60s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:47,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:02<02:47,  1.62s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:04<02:40,  1.57s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:34,  1.53s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:29,  1.50s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:38,  1.60s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:10<02:43,  1.67s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:12<02:43,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:33,  1.60s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:15<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:17<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:18<02:28,  1.59s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:22,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:21<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:24<02:21,  1.59s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:26<02:25,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:28<02:27,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:29<02:19,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:31<02:13,  1.57s/it]predicting train subjects:  71%|███████   | 201/285 [05:33<02:17,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:34<02:16,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:36<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:37<02:06,  1.56s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:39<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:40<01:56,  1.48s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:42<02:03,  1.58s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:44<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:45<02:07,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:47<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:48<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:50<01:56,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:52<01:56,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:53<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:55<01:53,  1.62s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:56<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:58<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:00<01:53,  1.70s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:02<01:54,  1.74s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:03<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:05<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:06<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:08<01:36,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:09<01:32,  1.52s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:10<01:27,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:12<01:32,  1.56s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:14<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:16<01:35,  1.67s/it]predicting train subjects:  80%|████████  | 229/285 [06:17<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:19<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [06:20<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:22<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:23<01:18,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:25<01:21,  1.60s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:26<01:16,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:28<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:30<01:19,  1.66s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:32<01:19,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:33<01:16,  1.67s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:35<01:12,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:36<01:07,  1.54s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:04,  1.50s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:39<01:03,  1.50s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:41<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:42<01:01,  1.53s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:44<01:04,  1.65s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:46<01:03,  1.68s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:02,  1.68s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:49<00:57,  1.60s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<00:53,  1.54s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:52<00:50,  1.49s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:53<00:48,  1.47s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:00<00:45,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [07:01<00:42,  1.52s/it]predicting train subjects:  91%|█████████ | 258/285 [07:03<00:43,  1.59s/it]predicting train subjects:  91%|█████████ | 259/285 [07:05<00:41,  1.61s/it]predicting train subjects:  91%|█████████ | 260/285 [07:06<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:08<00:36,  1.52s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:09<00:34,  1.49s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:11<00:32,  1.48s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:12<00:33,  1.60s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:14<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:16<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:17<00:27,  1.54s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:19<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:20<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:22<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:23<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:25<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:26<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:28<00:16,  1.49s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:30<00:15,  1.59s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:31<00:14,  1.65s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:33<00:12,  1.59s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:34<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:36<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:37<00:07,  1.53s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:39<00:05,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:40<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:42<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:44<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [07:46<00:00,  1.72s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:48,  1.65s/it]Loading train:   1%|          | 2/285 [00:02<07:15,  1.54s/it]Loading train:   1%|          | 3/285 [00:04<07:05,  1.51s/it]Loading train:   1%|▏         | 4/285 [00:05<06:37,  1.42s/it]Loading train:   2%|▏         | 5/285 [00:07<06:52,  1.47s/it]Loading train:   2%|▏         | 6/285 [00:08<06:33,  1.41s/it]Loading train:   2%|▏         | 7/285 [00:10<06:56,  1.50s/it]Loading train:   3%|▎         | 8/285 [00:11<06:45,  1.46s/it]Loading train:   3%|▎         | 9/285 [00:13<06:58,  1.51s/it]Loading train:   4%|▎         | 10/285 [00:14<06:18,  1.38s/it]Loading train:   4%|▍         | 11/285 [00:15<05:28,  1.20s/it]Loading train:   4%|▍         | 12/285 [00:15<05:08,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:16<04:41,  1.04s/it]Loading train:   5%|▍         | 14/285 [00:17<04:55,  1.09s/it]Loading train:   5%|▌         | 15/285 [00:19<05:18,  1.18s/it]Loading train:   6%|▌         | 16/285 [00:20<05:08,  1.15s/it]Loading train:   6%|▌         | 17/285 [00:21<04:47,  1.07s/it]Loading train:   6%|▋         | 18/285 [00:22<04:33,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:23<04:17,  1.03it/s]Loading train:   7%|▋         | 20/285 [00:24<04:18,  1.02it/s]Loading train:   7%|▋         | 21/285 [00:24<04:10,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:25<04:14,  1.03it/s]Loading train:   8%|▊         | 23/285 [00:26<04:15,  1.02it/s]Loading train:   8%|▊         | 24/285 [00:27<04:01,  1.08it/s]Loading train:   9%|▉         | 25/285 [00:28<04:16,  1.01it/s]Loading train:   9%|▉         | 26/285 [00:29<04:20,  1.00s/it]Loading train:   9%|▉         | 27/285 [00:30<04:03,  1.06it/s]Loading train:  10%|▉         | 28/285 [00:31<04:05,  1.05it/s]Loading train:  10%|█         | 29/285 [00:32<03:58,  1.07it/s]Loading train:  11%|█         | 30/285 [00:33<04:20,  1.02s/it]Loading train:  11%|█         | 31/285 [00:35<04:34,  1.08s/it]Loading train:  11%|█         | 32/285 [00:35<04:13,  1.00s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:14,  1.01s/it]Loading train:  12%|█▏        | 34/285 [00:37<04:07,  1.02it/s]Loading train:  12%|█▏        | 35/285 [00:38<04:12,  1.01s/it]Loading train:  13%|█▎        | 36/285 [00:39<03:57,  1.05it/s]Loading train:  13%|█▎        | 37/285 [00:40<03:54,  1.06it/s]Loading train:  13%|█▎        | 38/285 [00:41<04:05,  1.01it/s]Loading train:  14%|█▎        | 39/285 [00:42<03:51,  1.06it/s]Loading train:  14%|█▍        | 40/285 [00:43<03:52,  1.06it/s]Loading train:  14%|█▍        | 41/285 [00:44<03:48,  1.07it/s]Loading train:  15%|█▍        | 42/285 [00:45<03:42,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:46<03:40,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:47<03:41,  1.09it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:36,  1.11it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:42,  1.07it/s]Loading train:  16%|█▋        | 47/285 [00:49<03:27,  1.15it/s]Loading train:  17%|█▋        | 48/285 [00:50<03:29,  1.13it/s]Loading train:  17%|█▋        | 49/285 [00:51<03:33,  1.11it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:31,  1.11it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:36,  1.08it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:30,  1.11it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:31,  1.10it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:36,  1.06it/s]Loading train:  19%|█▉        | 55/285 [00:57<03:27,  1.11it/s]Loading train:  20%|█▉        | 56/285 [00:58<03:33,  1.07it/s]Loading train:  20%|██        | 57/285 [00:58<03:25,  1.11it/s]Loading train:  20%|██        | 58/285 [00:59<03:25,  1.11it/s]Loading train:  21%|██        | 59/285 [01:00<03:31,  1.07it/s]Loading train:  21%|██        | 60/285 [01:01<03:42,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:02<03:32,  1.06it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:42,  1.00it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:38,  1.01it/s]Loading train:  22%|██▏       | 64/285 [01:06<04:03,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:29,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:27,  1.22s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:05,  1.13s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:31,  1.02it/s]Loading train:  25%|██▍       | 70/285 [01:12<03:27,  1.04it/s]Loading train:  25%|██▍       | 71/285 [01:13<03:31,  1.01it/s]Loading train:  25%|██▌       | 72/285 [01:14<03:28,  1.02it/s]Loading train:  26%|██▌       | 73/285 [01:15<03:21,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:16<03:20,  1.05it/s]Loading train:  26%|██▋       | 75/285 [01:17<03:16,  1.07it/s]Loading train:  27%|██▋       | 76/285 [01:18<03:22,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:18<03:03,  1.13it/s]Loading train:  27%|██▋       | 78/285 [01:19<02:53,  1.19it/s]Loading train:  28%|██▊       | 79/285 [01:20<02:56,  1.17it/s]Loading train:  28%|██▊       | 80/285 [01:21<03:02,  1.12it/s]Loading train:  28%|██▊       | 81/285 [01:22<02:57,  1.15it/s]Loading train:  29%|██▉       | 82/285 [01:23<03:13,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:24<03:02,  1.11it/s]Loading train:  29%|██▉       | 84/285 [01:25<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:26<03:05,  1.08it/s]Loading train:  30%|███       | 86/285 [01:27<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:28<03:07,  1.05it/s]Loading train:  31%|███       | 88/285 [01:28<03:04,  1.07it/s]Loading train:  31%|███       | 89/285 [01:29<03:08,  1.04it/s]Loading train:  32%|███▏      | 90/285 [01:31<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:32<03:09,  1.03it/s]Loading train:  32%|███▏      | 92/285 [01:32<03:06,  1.04it/s]Loading train:  33%|███▎      | 93/285 [01:33<02:53,  1.10it/s]Loading train:  33%|███▎      | 94/285 [01:34<02:49,  1.13it/s]Loading train:  33%|███▎      | 95/285 [01:35<02:49,  1.12it/s]Loading train:  34%|███▎      | 96/285 [01:36<02:49,  1.11it/s]Loading train:  34%|███▍      | 97/285 [01:37<02:50,  1.10it/s]Loading train:  34%|███▍      | 98/285 [01:38<02:49,  1.10it/s]Loading train:  35%|███▍      | 99/285 [01:39<02:51,  1.08it/s]Loading train:  35%|███▌      | 100/285 [01:40<02:53,  1.06it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:46,  1.10it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:47,  1.09it/s]Loading train:  36%|███▌      | 103/285 [01:42<02:43,  1.12it/s]Loading train:  36%|███▋      | 104/285 [01:43<02:42,  1.11it/s]Loading train:  37%|███▋      | 105/285 [01:44<02:44,  1.10it/s]Loading train:  37%|███▋      | 106/285 [01:45<02:41,  1.11it/s]Loading train:  38%|███▊      | 107/285 [01:46<02:45,  1.08it/s]Loading train:  38%|███▊      | 108/285 [01:47<02:34,  1.14it/s]Loading train:  38%|███▊      | 109/285 [01:48<02:35,  1.13it/s]Loading train:  39%|███▊      | 110/285 [01:49<02:40,  1.09it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:28,  1.17it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:30,  1.15it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:34,  1.12it/s]Loading train:  40%|████      | 114/285 [01:52<02:32,  1.12it/s]Loading train:  40%|████      | 115/285 [01:53<02:30,  1.13it/s]Loading train:  41%|████      | 116/285 [01:54<02:27,  1.15it/s]Loading train:  41%|████      | 117/285 [01:54<02:15,  1.24it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:14,  1.24it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:18,  1.20it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:16,  1.21it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:37,  1.04it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:47,  1.03s/it]Loading train:  43%|████▎     | 123/285 [02:01<02:53,  1.07s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:37,  1.02it/s]Loading train:  44%|████▍     | 125/285 [02:02<02:25,  1.10it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:18,  1.14it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:14,  1.17it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:14,  1.16it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:10,  1.20it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:04,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:05,  1.23it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:04,  1.22it/s]Loading train:  47%|████▋     | 133/285 [02:09<02:06,  1.20it/s]Loading train:  47%|████▋     | 134/285 [02:09<02:01,  1.25it/s]Loading train:  47%|████▋     | 135/285 [02:10<02:07,  1.17it/s]Loading train:  48%|████▊     | 136/285 [02:11<02:08,  1.16it/s]Loading train:  48%|████▊     | 137/285 [02:12<02:12,  1.12it/s]Loading train:  48%|████▊     | 138/285 [02:13<02:04,  1.18it/s]Loading train:  49%|████▉     | 139/285 [02:14<02:05,  1.16it/s]Loading train:  49%|████▉     | 140/285 [02:15<02:02,  1.18it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:57,  1.23it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:57,  1.22it/s]Loading train:  50%|█████     | 143/285 [02:17<01:58,  1.20it/s]Loading train:  51%|█████     | 144/285 [02:18<02:00,  1.17it/s]Loading train:  51%|█████     | 145/285 [02:19<01:58,  1.18it/s]Loading train:  51%|█████     | 146/285 [02:20<01:56,  1.19it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:52,  1.22it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:53,  1.21it/s]Loading train:  52%|█████▏    | 149/285 [02:22<01:52,  1.21it/s]Loading train:  53%|█████▎    | 150/285 [02:23<01:49,  1.23it/s]Loading train:  53%|█████▎    | 151/285 [02:24<01:52,  1.19it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:45,  1.25it/s]Loading train:  54%|█████▎    | 153/285 [02:25<01:42,  1.29it/s]Loading train:  54%|█████▍    | 154/285 [02:26<01:45,  1.25it/s]Loading train:  54%|█████▍    | 155/285 [02:27<01:45,  1.24it/s]Loading train:  55%|█████▍    | 156/285 [02:28<01:47,  1.21it/s]Loading train:  55%|█████▌    | 157/285 [02:29<01:45,  1.21it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:45,  1.20it/s]Loading train:  56%|█████▌    | 159/285 [02:30<01:38,  1.28it/s]Loading train:  56%|█████▌    | 160/285 [02:31<01:38,  1.26it/s]Loading train:  56%|█████▋    | 161/285 [02:32<01:37,  1.27it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:37,  1.26it/s]Loading train:  57%|█████▋    | 163/285 [02:33<01:38,  1.23it/s]Loading train:  58%|█████▊    | 164/285 [02:34<01:39,  1.21it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:41,  1.19it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:42,  1.16it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:37,  1.21it/s]Loading train:  59%|█████▉    | 168/285 [02:38<01:40,  1.17it/s]Loading train:  59%|█████▉    | 169/285 [02:39<01:42,  1.14it/s]Loading train:  60%|█████▉    | 170/285 [02:39<01:39,  1.16it/s]Loading train:  60%|██████    | 171/285 [02:40<01:33,  1.22it/s]Loading train:  60%|██████    | 172/285 [02:41<01:31,  1.24it/s]Loading train:  61%|██████    | 173/285 [02:42<01:27,  1.28it/s]Loading train:  61%|██████    | 174/285 [02:42<01:23,  1.33it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:31,  1.21it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:31,  1.19it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:27,  1.23it/s]Loading train:  62%|██████▏   | 178/285 [02:46<01:27,  1.22it/s]Loading train:  63%|██████▎   | 179/285 [02:47<01:26,  1.22it/s]Loading train:  63%|██████▎   | 180/285 [02:47<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:31,  1.14it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:27,  1.17it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:27,  1.17it/s]Loading train:  65%|██████▍   | 184/285 [02:51<01:23,  1.21it/s]Loading train:  65%|██████▍   | 185/285 [02:52<01:19,  1.26it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:22,  1.20it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:25,  1.15it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:20,  1.19it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:18,  1.21it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:18,  1.19it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:16,  1.20it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:16,  1.19it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:12,  1.23it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:15,  1.16it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:15,  1.15it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:11,  1.19it/s]Loading train:  70%|███████   | 200/285 [03:04<01:09,  1.22it/s]Loading train:  71%|███████   | 201/285 [03:05<01:16,  1.10it/s]Loading train:  71%|███████   | 202/285 [03:06<01:13,  1.14it/s]Loading train:  71%|███████   | 203/285 [03:07<01:13,  1.11it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:07,  1.20it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:06,  1.20it/s]Loading train:  72%|███████▏  | 206/285 [03:09<01:04,  1.22it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:07,  1.16it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:07,  1.14it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:07,  1.12it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:05,  1.15it/s]Loading train:  74%|███████▍  | 211/285 [03:14<01:05,  1.13it/s]Loading train:  74%|███████▍  | 212/285 [03:15<01:04,  1.13it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:05,  1.10it/s]Loading train:  75%|███████▌  | 214/285 [03:17<01:00,  1.17it/s]Loading train:  75%|███████▌  | 215/285 [03:18<01:02,  1.12it/s]Loading train:  76%|███████▌  | 216/285 [03:18<01:00,  1.14it/s]Loading train:  76%|███████▌  | 217/285 [03:19<01:01,  1.11it/s]Loading train:  76%|███████▋  | 218/285 [03:20<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:21<01:03,  1.04it/s]Loading train:  77%|███████▋  | 220/285 [03:22<01:00,  1.08it/s]Loading train:  78%|███████▊  | 221/285 [03:23<00:57,  1.11it/s]Loading train:  78%|███████▊  | 222/285 [03:24<00:55,  1.13it/s]Loading train:  78%|███████▊  | 223/285 [03:25<00:50,  1.22it/s]Loading train:  79%|███████▊  | 224/285 [03:26<00:52,  1.17it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:48,  1.24it/s]Loading train:  79%|███████▉  | 226/285 [03:27<00:49,  1.20it/s]Loading train:  80%|███████▉  | 227/285 [03:28<00:49,  1.18it/s]Loading train:  80%|████████  | 228/285 [03:29<00:50,  1.14it/s]Loading train:  80%|████████  | 229/285 [03:30<00:47,  1.18it/s]Loading train:  81%|████████  | 230/285 [03:30<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [03:32<00:48,  1.12it/s]Loading train:  81%|████████▏ | 232/285 [03:32<00:47,  1.12it/s]Loading train:  82%|████████▏ | 233/285 [03:33<00:46,  1.11it/s]Loading train:  82%|████████▏ | 234/285 [03:34<00:47,  1.08it/s]Loading train:  82%|████████▏ | 235/285 [03:35<00:44,  1.13it/s]Loading train:  83%|████████▎ | 236/285 [03:36<00:44,  1.09it/s]Loading train:  83%|████████▎ | 237/285 [03:37<00:44,  1.07it/s]Loading train:  84%|████████▎ | 238/285 [03:38<00:46,  1.01it/s]Loading train:  84%|████████▍ | 239/285 [03:39<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:40<00:39,  1.13it/s]Loading train:  85%|████████▍ | 241/285 [03:41<00:38,  1.15it/s]Loading train:  85%|████████▍ | 242/285 [03:41<00:35,  1.21it/s]Loading train:  85%|████████▌ | 243/285 [03:42<00:33,  1.27it/s]Loading train:  86%|████████▌ | 244/285 [03:43<00:35,  1.15it/s]Loading train:  86%|████████▌ | 245/285 [03:44<00:32,  1.23it/s]Loading train:  86%|████████▋ | 246/285 [03:45<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [03:46<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [03:47<00:32,  1.14it/s]Loading train:  87%|████████▋ | 249/285 [03:47<00:29,  1.22it/s]Loading train:  88%|████████▊ | 250/285 [03:48<00:27,  1.28it/s]Loading train:  88%|████████▊ | 251/285 [03:49<00:25,  1.35it/s]Loading train:  88%|████████▊ | 252/285 [03:49<00:23,  1.42it/s]Loading train:  89%|████████▉ | 253/285 [03:50<00:23,  1.35it/s]Loading train:  89%|████████▉ | 254/285 [03:51<00:24,  1.24it/s]Loading train:  89%|████████▉ | 255/285 [03:52<00:24,  1.21it/s]Loading train:  90%|████████▉ | 256/285 [03:53<00:24,  1.20it/s]Loading train:  90%|█████████ | 257/285 [03:54<00:23,  1.19it/s]Loading train:  91%|█████████ | 258/285 [03:55<00:23,  1.14it/s]Loading train:  91%|█████████ | 259/285 [03:55<00:22,  1.16it/s]Loading train:  91%|█████████ | 260/285 [03:56<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [03:57<00:19,  1.23it/s]Loading train:  92%|█████████▏| 262/285 [03:58<00:17,  1.31it/s]Loading train:  92%|█████████▏| 263/285 [03:58<00:17,  1.27it/s]Loading train:  93%|█████████▎| 264/285 [03:59<00:17,  1.23it/s]Loading train:  93%|█████████▎| 265/285 [04:00<00:17,  1.15it/s]Loading train:  93%|█████████▎| 266/285 [04:01<00:16,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:15,  1.15it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:14,  1.14it/s]Loading train:  94%|█████████▍| 269/285 [04:04<00:14,  1.13it/s]Loading train:  95%|█████████▍| 270/285 [04:04<00:12,  1.20it/s]Loading train:  95%|█████████▌| 271/285 [04:05<00:11,  1.22it/s]Loading train:  95%|█████████▌| 272/285 [04:06<00:10,  1.22it/s]Loading train:  96%|█████████▌| 273/285 [04:07<00:09,  1.25it/s]Loading train:  96%|█████████▌| 274/285 [04:07<00:08,  1.31it/s]Loading train:  96%|█████████▋| 275/285 [04:08<00:08,  1.22it/s]Loading train:  97%|█████████▋| 276/285 [04:09<00:07,  1.18it/s]Loading train:  97%|█████████▋| 277/285 [04:10<00:06,  1.22it/s]Loading train:  98%|█████████▊| 278/285 [04:11<00:05,  1.25it/s]Loading train:  98%|█████████▊| 279/285 [04:12<00:05,  1.19it/s]Loading train:  98%|█████████▊| 280/285 [04:13<00:04,  1.22it/s]Loading train:  99%|█████████▊| 281/285 [04:13<00:03,  1.20it/s]Loading train:  99%|█████████▉| 282/285 [04:14<00:02,  1.18it/s]Loading train:  99%|█████████▉| 283/285 [04:15<00:01,  1.16it/s]Loading train: 100%|█████████▉| 284/285 [04:16<00:00,  1.08it/s]Loading train: 100%|██████████| 285/285 [04:17<00:00,  1.09it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:00, 289.83it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:00, 278.00it/s]concatenating: train:  31%|███       | 89/285 [00:00<00:00, 290.36it/s]concatenating: train:  44%|████▎     | 124/285 [00:00<00:00, 303.66it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 306.54it/s]concatenating: train:  66%|██████▌   | 188/285 [00:00<00:00, 309.09it/s]concatenating: train:  76%|███████▋  | 218/285 [00:00<00:00, 305.47it/s]concatenating: train:  88%|████████▊ | 251/285 [00:00<00:00, 310.59it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 315.00it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 689.78it/s]2019-07-11 06:26:13.283139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:26:13.283236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:26:13.283252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:26:13.283261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:26:13.283656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.90it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.96it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.77it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.48it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.34it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.92it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.98it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.10it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.11it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.53it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.71it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.55it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.59it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.97it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.05it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.70it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.90it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 30)   16230       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 90)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 246,393
Trainable params: 71,593
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 17s - loss: 2.6950 - acc: 0.5088 - mDice: 0.1242 - val_loss: 1.7111 - val_acc: 0.9106 - val_mDice: 0.2672

Epoch 00001: val_mDice improved from -inf to 0.26721, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.9265 - acc: 0.9004 - mDice: 0.3896 - val_loss: 1.1724 - val_acc: 0.9199 - val_mDice: 0.4125

Epoch 00002: val_mDice improved from 0.26721 to 0.41248, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.6856 - acc: 0.9096 - mDice: 0.4882 - val_loss: 1.0263 - val_acc: 0.9246 - val_mDice: 0.4608

Epoch 00003: val_mDice improved from 0.41248 to 0.46077, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5934 - acc: 0.9171 - mDice: 0.5359 - val_loss: 0.9415 - val_acc: 0.9285 - val_mDice: 0.4967

Epoch 00004: val_mDice improved from 0.46077 to 0.49672, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5346 - acc: 0.9238 - mDice: 0.5691 - val_loss: 0.9520 - val_acc: 0.9235 - val_mDice: 0.4862

Epoch 00005: val_mDice did not improve from 0.49672
Epoch 6/300
 - 11s - loss: 0.4999 - acc: 0.9277 - mDice: 0.5897 - val_loss: 0.8710 - val_acc: 0.9311 - val_mDice: 0.5294

Epoch 00006: val_mDice improved from 0.49672 to 0.52944, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4754 - acc: 0.9303 - mDice: 0.6049 - val_loss: 0.8417 - val_acc: 0.9357 - val_mDice: 0.5523

Epoch 00007: val_mDice improved from 0.52944 to 0.55232, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4565 - acc: 0.9322 - mDice: 0.6169 - val_loss: 0.8308 - val_acc: 0.9363 - val_mDice: 0.5566

Epoch 00008: val_mDice improved from 0.55232 to 0.55655, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.4400 - acc: 0.9336 - mDice: 0.6275 - val_loss: 0.8336 - val_acc: 0.9389 - val_mDice: 0.5538

Epoch 00009: val_mDice did not improve from 0.55655
Epoch 10/300
 - 11s - loss: 0.4266 - acc: 0.9349 - mDice: 0.6365 - val_loss: 0.8271 - val_acc: 0.9365 - val_mDice: 0.5643

Epoch 00010: val_mDice improved from 0.55655 to 0.56426, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 11s - loss: 0.4184 - acc: 0.9355 - mDice: 0.6420 - val_loss: 0.8344 - val_acc: 0.9350 - val_mDice: 0.5571

Epoch 00011: val_mDice did not improve from 0.56426
Epoch 12/300
 - 11s - loss: 0.4101 - acc: 0.9363 - mDice: 0.6475 - val_loss: 0.8045 - val_acc: 0.9361 - val_mDice: 0.5584

Epoch 00012: val_mDice did not improve from 0.56426
Epoch 13/300
 - 11s - loss: 0.4012 - acc: 0.9371 - mDice: 0.6536 - val_loss: 0.7859 - val_acc: 0.9347 - val_mDice: 0.5628

Epoch 00013: val_mDice did not improve from 0.56426
Epoch 14/300
 - 11s - loss: 0.3920 - acc: 0.9379 - mDice: 0.6598 - val_loss: 0.7739 - val_acc: 0.9330 - val_mDice: 0.5596

Epoch 00014: val_mDice did not improve from 0.56426
Epoch 15/300
 - 11s - loss: 0.3886 - acc: 0.9383 - mDice: 0.6622 - val_loss: 0.7657 - val_acc: 0.9384 - val_mDice: 0.5658

Epoch 00015: val_mDice improved from 0.56426 to 0.56578, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 12s - loss: 0.3821 - acc: 0.9390 - mDice: 0.6668 - val_loss: 0.7491 - val_acc: 0.9375 - val_mDice: 0.5753

Epoch 00016: val_mDice improved from 0.56578 to 0.57532, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 11s - loss: 0.3777 - acc: 0.9393 - mDice: 0.6699 - val_loss: 0.8359 - val_acc: 0.9389 - val_mDice: 0.5550

Epoch 00017: val_mDice did not improve from 0.57532
Epoch 18/300
 - 11s - loss: 0.3708 - acc: 0.9399 - mDice: 0.6746 - val_loss: 0.7855 - val_acc: 0.9339 - val_mDice: 0.5540

Epoch 00018: val_mDice did not improve from 0.57532
Epoch 19/300
 - 11s - loss: 0.3680 - acc: 0.9401 - mDice: 0.6766 - val_loss: 0.7839 - val_acc: 0.9387 - val_mDice: 0.5745

Epoch 00019: val_mDice did not improve from 0.57532
Epoch 20/300
 - 11s - loss: 0.3623 - acc: 0.9407 - mDice: 0.6807 - val_loss: 0.8048 - val_acc: 0.9383 - val_mDice: 0.5638

Epoch 00020: val_mDice did not improve from 0.57532
Epoch 21/300
 - 11s - loss: 0.3583 - acc: 0.9410 - mDice: 0.6835 - val_loss: 0.7739 - val_acc: 0.9394 - val_mDice: 0.5722

Epoch 00021: val_mDice did not improve from 0.57532
Epoch 22/300
 - 11s - loss: 0.3538 - acc: 0.9414 - mDice: 0.6867 - val_loss: 0.7747 - val_acc: 0.9285 - val_mDice: 0.5532

Epoch 00022: val_mDice did not improve from 0.57532
Epoch 23/300
 - 11s - loss: 0.3527 - acc: 0.9415 - mDice: 0.6875 - val_loss: 0.7289 - val_acc: 0.9399 - val_mDice: 0.5771

Epoch 00023: val_mDice improved from 0.57532 to 0.57714, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 11s - loss: 0.3504 - acc: 0.9416 - mDice: 0.6891 - val_loss: 0.7477 - val_acc: 0.9353 - val_mDice: 0.5722

Epoch 00024: val_mDice did not improve from 0.57714
Epoch 25/300
 - 11s - loss: 0.3424 - acc: 0.9423 - mDice: 0.6948 - val_loss: 0.7829 - val_acc: 0.9389 - val_mDice: 0.5680

Epoch 00025: val_mDice did not improve from 0.57714
Epoch 26/300
 - 11s - loss: 0.3434 - acc: 0.9423 - mDice: 0.6943 - val_loss: 0.7491 - val_acc: 0.9325 - val_mDice: 0.5639

Epoch 00026: val_mDice did not improve from 0.57714
Epoch 27/300
 - 11s - loss: 0.3371 - acc: 0.9428 - mDice: 0.6987 - val_loss: 0.7872 - val_acc: 0.9406 - val_mDice: 0.5690

Epoch 00027: val_mDice did not improve from 0.57714
Epoch 28/300
 - 11s - loss: 0.3353 - acc: 0.9430 - mDice: 0.7001 - val_loss: 0.7486 - val_acc: 0.9388 - val_mDice: 0.5732

Epoch 00028: val_mDice did not improve from 0.57714
Epoch 29/300
 - 11s - loss: 0.3358 - acc: 0.9430 - mDice: 0.6999 - val_loss: 0.7937 - val_acc: 0.9393 - val_mDice: 0.5673

Epoch 00029: val_mDice did not improve from 0.57714
Epoch 30/300
 - 11s - loss: 0.3320 - acc: 0.9433 - mDice: 0.7024 - val_loss: 0.7640 - val_acc: 0.9382 - val_mDice: 0.5708

Epoch 00030: val_mDice did not improve from 0.57714
Epoch 31/300
 - 11s - loss: 0.3304 - acc: 0.9433 - mDice: 0.7037 - val_loss: 0.7990 - val_acc: 0.9387 - val_mDice: 0.5664

Epoch 00031: val_mDice did not improve from 0.57714
Epoch 32/300
 - 11s - loss: 0.3248 - acc: 0.9438 - mDice: 0.7078 - val_loss: 0.7513 - val_acc: 0.9381 - val_mDice: 0.5770

Epoch 00032: val_mDice did not improve from 0.57714
Epoch 33/300
 - 11s - loss: 0.3270 - acc: 0.9437 - mDice: 0.7062 - val_loss: 0.7348 - val_acc: 0.9391 - val_mDice: 0.5733

Epoch 00033: val_mDice did not improve from 0.57714
Epoch 34/300
 - 11s - loss: 0.3245 - acc: 0.9441 - mDice: 0.7083 - val_loss: 0.7941 - val_acc: 0.9388 - val_mDice: 0.5740

Epoch 00034: val_mDice did not improve from 0.57714
Epoch 35/300
 - 12s - loss: 0.3225 - acc: 0.9442 - mDice: 0.7095 - val_loss: 0.7765 - val_acc: 0.9394 - val_mDice: 0.5746

Epoch 00035: val_mDice did not improve from 0.57714
Epoch 36/300
 - 11s - loss: 0.3192 - acc: 0.9445 - mDice: 0.7120 - val_loss: 0.7329 - val_acc: 0.9406 - val_mDice: 0.5747

Epoch 00036: val_mDice did not improve from 0.57714
Epoch 37/300
 - 11s - loss: 0.3178 - acc: 0.9445 - mDice: 0.7130 - val_loss: 0.7490 - val_acc: 0.9371 - val_mDice: 0.5765

Epoch 00037: val_mDice did not improve from 0.57714
Epoch 38/300
 - 11s - loss: 0.3185 - acc: 0.9445 - mDice: 0.7125 - val_loss: 0.7291 - val_acc: 0.9357 - val_mDice: 0.5714

Epoch 00038: val_mDice did not improve from 0.57714
Epoch 39/300
 - 11s - loss: 0.3143 - acc: 0.9448 - mDice: 0.7155 - val_loss: 0.7470 - val_acc: 0.9407 - val_mDice: 0.5790

Epoch 00039: val_mDice improved from 0.57714 to 0.57896, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 11s - loss: 0.3124 - acc: 0.9450 - mDice: 0.7171 - val_loss: 0.7769 - val_acc: 0.9392 - val_mDice: 0.5735

Epoch 00040: val_mDice did not improve from 0.57896
Epoch 41/300
 - 11s - loss: 0.3127 - acc: 0.9450 - mDice: 0.7168 - val_loss: 0.7904 - val_acc: 0.9389 - val_mDice: 0.5587

Epoch 00041: val_mDice did not improve from 0.57896
Epoch 42/300
 - 11s - loss: 0.3093 - acc: 0.9452 - mDice: 0.7194 - val_loss: 0.7157 - val_acc: 0.9379 - val_mDice: 0.5743

Epoch 00042: val_mDice did not improve from 0.57896
Epoch 43/300
 - 11s - loss: 0.3068 - acc: 0.9455 - mDice: 0.7212 - val_loss: 0.7178 - val_acc: 0.9360 - val_mDice: 0.5722

Epoch 00043: val_mDice did not improve from 0.57896
Epoch 44/300
 - 11s - loss: 0.3062 - acc: 0.9454 - mDice: 0.7217 - val_loss: 0.7576 - val_acc: 0.9403 - val_mDice: 0.5716

Epoch 00044: val_mDice did not improve from 0.57896
Epoch 45/300
 - 12s - loss: 0.3057 - acc: 0.9455 - mDice: 0.7222 - val_loss: 0.7191 - val_acc: 0.9404 - val_mDice: 0.5668

Epoch 00045: val_mDice did not improve from 0.57896
Epoch 46/300
 - 12s - loss: 0.3051 - acc: 0.9455 - mDice: 0.7225 - val_loss: 0.7480 - val_acc: 0.9386 - val_mDice: 0.5711

Epoch 00046: val_mDice did not improve from 0.57896
Epoch 47/300
 - 11s - loss: 0.3011 - acc: 0.9459 - mDice: 0.7256 - val_loss: 0.7450 - val_acc: 0.9381 - val_mDice: 0.5761

Epoch 00047: val_mDice did not improve from 0.57896
Epoch 48/300
 - 11s - loss: 0.3025 - acc: 0.9459 - mDice: 0.7245 - val_loss: 0.7274 - val_acc: 0.9382 - val_mDice: 0.5733

Epoch 00048: val_mDice did not improve from 0.57896
Epoch 49/300
 - 11s - loss: 0.3015 - acc: 0.9459 - mDice: 0.7253 - val_loss: 0.7147 - val_acc: 0.9393 - val_mDice: 0.5734

Epoch 00049: val_mDice did not improve from 0.57896
Epoch 50/300
 - 11s - loss: 0.3001 - acc: 0.9461 - mDice: 0.7263 - val_loss: 0.7836 - val_acc: 0.9391 - val_mDice: 0.5694

Epoch 00050: val_mDice did not improve from 0.57896
Epoch 51/300
 - 11s - loss: 0.2972 - acc: 0.9463 - mDice: 0.7286 - val_loss: 0.6987 - val_acc: 0.9383 - val_mDice: 0.5682

Epoch 00051: val_mDice did not improve from 0.57896
Epoch 52/300
 - 11s - loss: 0.2958 - acc: 0.9465 - mDice: 0.7297 - val_loss: 0.7289 - val_acc: 0.9328 - val_mDice: 0.5556

Epoch 00052: val_mDice did not improve from 0.57896
Epoch 53/300
 - 11s - loss: 0.2955 - acc: 0.9464 - mDice: 0.7298 - val_loss: 0.7487 - val_acc: 0.9368 - val_mDice: 0.5657

Epoch 00053: val_mDice did not improve from 0.57896
Epoch 54/300
 - 11s - loss: 0.2938 - acc: 0.9465 - mDice: 0.7311 - val_loss: 0.7137 - val_acc: 0.9389 - val_mDice: 0.5759

Epoch 00054: val_mDice did not improve from 0.57896
Epoch 55/300
 - 12s - loss: 0.2944 - acc: 0.9466 - mDice: 0.7307 - val_loss: 0.6946 - val_acc: 0.9384 - val_mDice: 0.5752

Epoch 00055: val_mDice did not improve from 0.57896
Epoch 56/300
 - 12s - loss: 0.2915 - acc: 0.9469 - mDice: 0.7329 - val_loss: 0.7605 - val_acc: 0.9372 - val_mDice: 0.5613

Epoch 00056: val_mDice did not improve from 0.57896
Epoch 57/300
 - 11s - loss: 0.2907 - acc: 0.9469 - mDice: 0.7335 - val_loss: 0.7309 - val_acc: 0.9299 - val_mDice: 0.5495

Epoch 00057: val_mDice did not improve from 0.57896
Epoch 58/300
 - 11s - loss: 0.2904 - acc: 0.9470 - mDice: 0.7337 - val_loss: 0.7174 - val_acc: 0.9370 - val_mDice: 0.5691

Epoch 00058: val_mDice did not improve from 0.57896
Epoch 59/300
 - 11s - loss: 0.2900 - acc: 0.9470 - mDice: 0.7341 - val_loss: 0.7569 - val_acc: 0.9388 - val_mDice: 0.5734

Epoch 00059: val_mDice did not improve from 0.57896
Epoch 60/300
 - 11s - loss: 0.2868 - acc: 0.9472 - mDice: 0.7365 - val_loss: 0.6924 - val_acc: 0.9382 - val_mDice: 0.5764

Epoch 00060: val_mDice did not improve from 0.57896
Epoch 61/300
 - 11s - loss: 0.2869 - acc: 0.9472 - mDice: 0.7364 - val_loss: 0.6700 - val_acc: 0.9362 - val_mDice: 0.5722

Epoch 00061: val_mDice did not improve from 0.57896
Epoch 62/300
 - 11s - loss: 0.2852 - acc: 0.9473 - mDice: 0.7378 - val_loss: 0.7166 - val_acc: 0.9375 - val_mDice: 0.5707

Epoch 00062: val_mDice did not improve from 0.57896
Epoch 63/300
 - 11s - loss: 0.2850 - acc: 0.9473 - mDice: 0.7379 - val_loss: 0.7646 - val_acc: 0.9360 - val_mDice: 0.5565

Epoch 00063: val_mDice did not improve from 0.57896
Epoch 64/300
 - 11s - loss: 0.2840 - acc: 0.9474 - mDice: 0.7387 - val_loss: 0.7037 - val_acc: 0.9379 - val_mDice: 0.5702

Epoch 00064: val_mDice did not improve from 0.57896
Epoch 65/300
 - 11s - loss: 0.2841 - acc: 0.9474 - mDice: 0.7387 - val_loss: 0.7056 - val_acc: 0.9301 - val_mDice: 0.5464

Epoch 00065: val_mDice did not improve from 0.57896
Epoch 66/300
 - 12s - loss: 0.2826 - acc: 0.9476 - mDice: 0.7398 - val_loss: 0.7023 - val_acc: 0.9372 - val_mDice: 0.5798

Epoch 00066: val_mDice improved from 0.57896 to 0.57982, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 11s - loss: 0.2808 - acc: 0.9477 - mDice: 0.7411 - val_loss: 0.7452 - val_acc: 0.9367 - val_mDice: 0.5708

Epoch 00067: val_mDice did not improve from 0.57982
Epoch 68/300
 - 11s - loss: 0.2817 - acc: 0.9477 - mDice: 0.7405 - val_loss: 0.6962 - val_acc: 0.9406 - val_mDice: 0.5722

Epoch 00068: val_mDice did not improve from 0.57982
Epoch 69/300
 - 11s - loss: 0.2830 - acc: 0.9475 - mDice: 0.7395 - val_loss: 0.6966 - val_acc: 0.9395 - val_mDice: 0.5688

Epoch 00069: val_mDice did not improve from 0.57982
Epoch 70/300
 - 12s - loss: 0.2806 - acc: 0.9478 - mDice: 0.7414 - val_loss: 0.7138 - val_acc: 0.9399 - val_mDice: 0.5770

Epoch 00070: val_mDice did not improve from 0.57982
Epoch 71/300
 - 11s - loss: 0.2790 - acc: 0.9479 - mDice: 0.7426 - val_loss: 0.7519 - val_acc: 0.9392 - val_mDice: 0.5729

Epoch 00071: val_mDice did not improve from 0.57982
Epoch 72/300
 - 11s - loss: 0.2789 - acc: 0.9479 - mDice: 0.7427 - val_loss: 0.7143 - val_acc: 0.9410 - val_mDice: 0.5717

Epoch 00072: val_mDice did not improve from 0.57982
Epoch 73/300
 - 11s - loss: 0.2777 - acc: 0.9481 - mDice: 0.7436 - val_loss: 0.6659 - val_acc: 0.9415 - val_mDice: 0.5838

Epoch 00073: val_mDice improved from 0.57982 to 0.58376, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 11s - loss: 0.2778 - acc: 0.9481 - mDice: 0.7436 - val_loss: 0.7114 - val_acc: 0.9337 - val_mDice: 0.5623

Epoch 00074: val_mDice did not improve from 0.58376
Epoch 75/300
 - 12s - loss: 0.2761 - acc: 0.9482 - mDice: 0.7448 - val_loss: 0.6776 - val_acc: 0.9389 - val_mDice: 0.5768

Epoch 00075: val_mDice did not improve from 0.58376
Epoch 76/300
 - 12s - loss: 0.2773 - acc: 0.9481 - mDice: 0.7440 - val_loss: 0.7146 - val_acc: 0.9403 - val_mDice: 0.5827

Epoch 00076: val_mDice did not improve from 0.58376
Epoch 77/300
 - 12s - loss: 0.2755 - acc: 0.9483 - mDice: 0.7453 - val_loss: 0.7044 - val_acc: 0.9373 - val_mDice: 0.5671

Epoch 00077: val_mDice did not improve from 0.58376
Epoch 78/300
 - 12s - loss: 0.2763 - acc: 0.9482 - mDice: 0.7448 - val_loss: 0.6863 - val_acc: 0.9397 - val_mDice: 0.5777

Epoch 00078: val_mDice did not improve from 0.58376
Epoch 79/300
 - 12s - loss: 0.2739 - acc: 0.9485 - mDice: 0.7466 - val_loss: 0.6968 - val_acc: 0.9382 - val_mDice: 0.5702

Epoch 00079: val_mDice did not improve from 0.58376
Epoch 80/300
 - 12s - loss: 0.2735 - acc: 0.9485 - mDice: 0.7469 - val_loss: 0.7138 - val_acc: 0.9399 - val_mDice: 0.5721

Epoch 00080: val_mDice did not improve from 0.58376
Epoch 81/300
 - 11s - loss: 0.2725 - acc: 0.9486 - mDice: 0.7477 - val_loss: 0.7291 - val_acc: 0.9384 - val_mDice: 0.5751

Epoch 00081: val_mDice did not improve from 0.58376
Epoch 82/300
 - 11s - loss: 0.2719 - acc: 0.9486 - mDice: 0.7482 - val_loss: 0.7642 - val_acc: 0.9373 - val_mDice: 0.5529

Epoch 00082: val_mDice did not improve from 0.58376
Epoch 83/300
 - 11s - loss: 0.2724 - acc: 0.9486 - mDice: 0.7478 - val_loss: 0.7286 - val_acc: 0.9405 - val_mDice: 0.5721

Epoch 00083: val_mDice did not improve from 0.58376
Epoch 84/300
 - 11s - loss: 0.2696 - acc: 0.9487 - mDice: 0.7499 - val_loss: 0.7141 - val_acc: 0.9361 - val_mDice: 0.5580

Epoch 00084: val_mDice did not improve from 0.58376
Epoch 85/300
 - 11s - loss: 0.2706 - acc: 0.9487 - mDice: 0.7491 - val_loss: 0.7417 - val_acc: 0.9388 - val_mDice: 0.5669

Epoch 00085: val_mDice did not improve from 0.58376
Epoch 86/300
 - 11s - loss: 0.2696 - acc: 0.9488 - mDice: 0.7500 - val_loss: 0.7398 - val_acc: 0.9414 - val_mDice: 0.5692

Epoch 00086: val_mDice did not improve from 0.58376
Epoch 87/300
 - 12s - loss: 0.2699 - acc: 0.9488 - mDice: 0.7498 - val_loss: 0.6738 - val_acc: 0.9396 - val_mDice: 0.5731

Epoch 00087: val_mDice did not improve from 0.58376
Epoch 88/300
 - 12s - loss: 0.2701 - acc: 0.9487 - mDice: 0.7496 - val_loss: 0.6883 - val_acc: 0.9402 - val_mDice: 0.5810

Epoch 00088: val_mDice did not improve from 0.58376
Epoch 89/300
 - 12s - loss: 0.2688 - acc: 0.9489 - mDice: 0.7506 - val_loss: 0.7025 - val_acc: 0.9408 - val_mDice: 0.5775

Epoch 00089: val_mDice did not improve from 0.58376
Epoch 90/300
 - 12s - loss: 0.2690 - acc: 0.9488 - mDice: 0.7505 - val_loss: 0.7116 - val_acc: 0.9429 - val_mDice: 0.5771

Epoch 00090: val_mDice did not improve from 0.58376
Epoch 91/300
 - 12s - loss: 0.2676 - acc: 0.9490 - mDice: 0.7515 - val_loss: 0.7195 - val_acc: 0.9406 - val_mDice: 0.5659

Epoch 00091: val_mDice did not improve from 0.58376
Epoch 92/300
 - 12s - loss: 0.2689 - acc: 0.9488 - mDice: 0.7506 - val_loss: 0.7328 - val_acc: 0.9392 - val_mDice: 0.5626

Epoch 00092: val_mDice did not improve from 0.58376
Epoch 93/300
 - 11s - loss: 0.2662 - acc: 0.9492 - mDice: 0.7526 - val_loss: 0.6808 - val_acc: 0.9392 - val_mDice: 0.5777

Epoch 00093: val_mDice did not improve from 0.58376
Epoch 94/300
 - 12s - loss: 0.2660 - acc: 0.9491 - mDice: 0.7529 - val_loss: 0.7125 - val_acc: 0.9371 - val_mDice: 0.5751

Epoch 00094: val_mDice did not improve from 0.58376
Epoch 95/300
 - 12s - loss: 0.2653 - acc: 0.9492 - mDice: 0.7535 - val_loss: 0.6850 - val_acc: 0.9372 - val_mDice: 0.5697

Epoch 00095: val_mDice did not improve from 0.58376
Epoch 96/300
 - 12s - loss: 0.2627 - acc: 0.9494 - mDice: 0.7554 - val_loss: 0.7132 - val_acc: 0.9398 - val_mDice: 0.5682

Epoch 00096: val_mDice did not improve from 0.58376
Epoch 97/300
 - 12s - loss: 0.2631 - acc: 0.9493 - mDice: 0.7551 - val_loss: 0.7136 - val_acc: 0.9380 - val_mDice: 0.5728

Epoch 00097: val_mDice did not improve from 0.58376
Epoch 98/300
 - 12s - loss: 0.2636 - acc: 0.9493 - mDice: 0.7547 - val_loss: 0.7222 - val_acc: 0.9389 - val_mDice: 0.5770

Epoch 00098: val_mDice did not improve from 0.58376
Epoch 99/300
 - 12s - loss: 0.2641 - acc: 0.9492 - mDice: 0.7543 - val_loss: 0.6734 - val_acc: 0.9387 - val_mDice: 0.5652

Epoch 00099: val_mDice did not improve from 0.58376
Epoch 100/300
 - 12s - loss: 0.2620 - acc: 0.9495 - mDice: 0.7560 - val_loss: 0.7070 - val_acc: 0.9377 - val_mDice: 0.5632

Epoch 00100: val_mDice did not improve from 0.58376
Epoch 101/300
 - 12s - loss: 0.2620 - acc: 0.9494 - mDice: 0.7560 - val_loss: 0.6896 - val_acc: 0.9383 - val_mDice: 0.5749

Epoch 00101: val_mDice did not improve from 0.58376
Epoch 102/300
 - 12s - loss: 0.2607 - acc: 0.9495 - mDice: 0.7570 - val_loss: 0.7099 - val_acc: 0.9404 - val_mDice: 0.5654

Epoch 00102: val_mDice did not improve from 0.58376
Epoch 103/300
 - 12s - loss: 0.2623 - acc: 0.9494 - mDice: 0.7558 - val_loss: 0.6594 - val_acc: 0.9370 - val_mDice: 0.5691

Epoch 00103: val_mDice did not improve from 0.58376
Epoch 104/300
 - 12s - loss: 0.2618 - acc: 0.9494 - mDice: 0.7562 - val_loss: 0.7060 - val_acc: 0.9312 - val_mDice: 0.5466

Epoch 00104: val_mDice did not improve from 0.58376
Epoch 105/300
 - 11s - loss: 0.2617 - acc: 0.9494 - mDice: 0.7563 - val_loss: 0.6838 - val_acc: 0.9400 - val_mDice: 0.5714

Epoch 00105: val_mDice did not improve from 0.58376
Epoch 106/300
 - 11s - loss: 0.2619 - acc: 0.9494 - mDice: 0.7560 - val_loss: 0.6815 - val_acc: 0.9390 - val_mDice: 0.5717

Epoch 00106: val_mDice did not improve from 0.58376
Epoch 107/300
 - 12s - loss: 0.2605 - acc: 0.9496 - mDice: 0.7572 - val_loss: 0.6759 - val_acc: 0.9381 - val_mDice: 0.5635

Epoch 00107: val_mDice did not improve from 0.58376
Epoch 108/300
 - 12s - loss: 0.2603 - acc: 0.9497 - mDice: 0.7574 - val_loss: 0.6952 - val_acc: 0.9407 - val_mDice: 0.5689

Epoch 00108: val_mDice did not improve from 0.58376
Epoch 109/300
 - 12s - loss: 0.2614 - acc: 0.9496 - mDice: 0.7566 - val_loss: 0.6591 - val_acc: 0.9400 - val_mDice: 0.5738

Epoch 00109: val_mDice did not improve from 0.58376
Epoch 110/300
 - 11s - loss: 0.2597 - acc: 0.9496 - mDice: 0.7578 - val_loss: 0.7059 - val_acc: 0.9366 - val_mDice: 0.5635

Epoch 00110: val_mDice did not improve from 0.58376
Epoch 111/300
 - 12s - loss: 0.2577 - acc: 0.9499 - mDice: 0.7594 - val_loss: 0.6842 - val_acc: 0.9394 - val_mDice: 0.5673

Epoch 00111: val_mDice did not improve from 0.58376
Epoch 112/300
 - 12s - loss: 0.2594 - acc: 0.9497 - mDice: 0.7581 - val_loss: 0.6583 - val_acc: 0.9396 - val_mDice: 0.5685

Epoch 00112: val_mDice did not improve from 0.58376
Epoch 113/300
 - 11s - loss: 0.2590 - acc: 0.9498 - mDice: 0.7584 - val_loss: 0.6814 - val_acc: 0.9391 - val_mDice: 0.5717

Epoch 00113: val_mDice did not improve from 0.58376
Restoring model weights from the end of the best epoch
Epoch 00113: early stopping
{'val_loss': [1.711097593490894, 1.172363457771448, 1.026300535752223, 0.9415161311626434, 0.9519881904125214, 0.8710195238773639, 0.8417030366567465, 0.8308140818889325, 0.8336465610907628, 0.827052102639125, 0.834354409804711, 0.8044626644024482, 0.7858830552834731, 0.7738536275350131, 0.7656656022255237, 0.7490587922242972, 0.8359288000143491, 0.7854564556708703, 0.7838816894934728, 0.8048238823047051, 0.7738742163548102, 0.7747426010095156, 0.7288894263597635, 0.7476847607355851, 0.7829344799885383, 0.7490680446991553, 0.7871748575797448, 0.748626362818938, 0.793664425611496, 0.7639710994867178, 0.7990096028034503, 0.7512571318791463, 0.7347610248969152, 0.7941069900989532, 0.7764788613869593, 0.7329300664938413, 0.7489529664699848, 0.7290864036633418, 0.7470233451861602, 0.7769336310716776, 0.790362692796267, 0.7157199015984168, 0.7178361668036535, 0.7575896519881028, 0.7190885085325974, 0.748013111261221, 0.7450356712708106, 0.7274291079777938, 0.7146644592285156, 0.7836370055492108, 0.6987138023743262, 0.7288947816078479, 0.7487056071941669, 0.7136540367053106, 0.6946499462311084, 0.7605322553561285, 0.7309078872203827, 0.7173705353186681, 0.7569091503436749, 0.6924046690647419, 0.6699577615811274, 0.7166071350757892, 0.7645670221402094, 0.7036835963909442, 0.7055654777930334, 0.7022716494706961, 0.7451547063313998, 0.6961767925665929, 0.6965786608365866, 0.7137984255185494, 0.7519287810875819, 0.7143161411468799, 0.6659301679867965, 0.7113586022303655, 0.6775738275968112, 0.7146170620734875, 0.7043982171095334, 0.6863161910038728, 0.6967746707109305, 0.7138389119735131, 0.7291273589317615, 0.7642178466686835, 0.7286220605556781, 0.7141429323416489, 0.7416741251945496, 0.7397595621072329, 0.6737875319444216, 0.6883269250392914, 0.7024517460511281, 0.711562902881549, 0.7194725825236394, 0.7328428075863764, 0.6807596981525421, 0.7125419882627634, 0.684978370483105, 0.7132420494006231, 0.7135611130641057, 0.7222184642003133, 0.6734210665409381, 0.706972734286235, 0.689590009359213, 0.7099388883664057, 0.6593844340397761, 0.7059684945986822, 0.6837745881997622, 0.6815376098339374, 0.6759390349571521, 0.695228636264801, 0.6590703267317551, 0.705878482415126, 0.6842258847676791, 0.6583060163718003, 0.6814340949058533], 'val_acc': [0.9106138921700991, 0.9198664105855502, 0.92463251719108, 0.9284994304180145, 0.9235091301111075, 0.9310581409014188, 0.9356554884176987, 0.9363073225204761, 0.9388752900637113, 0.9364691445460687, 0.9350060270382807, 0.9360877275466919, 0.9347194203963647, 0.9329997301101685, 0.9383760117567502, 0.9374745648640853, 0.9388937514561874, 0.9338942307692307, 0.9386949860132657, 0.9383020538550156, 0.9394300144452316, 0.9284601280322442, 0.9398784431127402, 0.935304201566256, 0.938868339245136, 0.9325258640142587, 0.9405510563116807, 0.9388036200633416, 0.9393375447163215, 0.9382211267948151, 0.9386810935460604, 0.9381356308093438, 0.9391156710111178, 0.9388475257616776, 0.9393676129671243, 0.9405810695428115, 0.9371093809604645, 0.9356578359237084, 0.9406620103579301, 0.9392150457088764, 0.9388567782365359, 0.9379484332524813, 0.936039211658331, 0.9402783008722159, 0.9403776893248925, 0.938611782514132, 0.9380616797850683, 0.9381795548475705, 0.9392636166169093, 0.9390856394400964, 0.9383089863337003, 0.9327916984374707, 0.9367557488954984, 0.9389122495284448, 0.9383806265317477, 0.9372018438119155, 0.9298678040504456, 0.937030764726492, 0.9388429362040299, 0.9381934381448306, 0.9362287567212031, 0.937506921016253, 0.9359952944975632, 0.9378605576661917, 0.9301058627091922, 0.9372157133542575, 0.9366679054040176, 0.9405764776926774, 0.9395317137241364, 0.9398992428412805, 0.9391596065117762, 0.9409555448935583, 0.941512561761416, 0.9337139221338125, 0.9389145764020773, 0.9403222019855793, 0.9373335700768691, 0.9397328220880948, 0.9381911296110886, 0.939866861471763, 0.9383713923967801, 0.9373312707130725, 0.9404701246665075, 0.9361408811349136, 0.9387943767584287, 0.9413854365165417, 0.9396033745545608, 0.940158119568458, 0.9407798395707057, 0.942924806704888, 0.9405579612805293, 0.9391803718530215, 0.9391526579856873, 0.9371417233577142, 0.937224940611766, 0.9398229397260226, 0.9380154655529902, 0.9388821996175326, 0.9386973289343027, 0.9377219149699578, 0.9382650829278506, 0.9403522335566007, 0.9369845780042502, 0.9312106806498307, 0.939966238462008, 0.9390116654909574, 0.9381448947466337, 0.9407220941323501, 0.9400101785476391, 0.9366124134797317, 0.9393606598560627, 0.939617225757012, 0.9391410740522238], 'val_mDice': [0.26721105065483314, 0.41248484872854674, 0.460770787527928, 0.4967167228460312, 0.4862066232241117, 0.5294419125868723, 0.5523163991478773, 0.5565526256194482, 0.5537573878581707, 0.5642600873341928, 0.5570737925859598, 0.558398904135594, 0.5627537747988334, 0.5595837590786127, 0.5657792280499752, 0.5753233100359256, 0.5549544336704108, 0.5540459912556869, 0.574499368094481, 0.5638338613968629, 0.5721670022377601, 0.5531691765555968, 0.5771438381992854, 0.5722087621688843, 0.5680087478115008, 0.5638970480515406, 0.5689842391472596, 0.5731759380835754, 0.5673020080878184, 0.5707633203038802, 0.5663965447590902, 0.5770085895290742, 0.573265933073484, 0.5740264975107633, 0.574585606272404, 0.5747023201905764, 0.5764537350489543, 0.5713659673929214, 0.5789627983019903, 0.5734845950053289, 0.5587152844438186, 0.5742610394954681, 0.5722377787415798, 0.5716169201410733, 0.5668477656749579, 0.5710683694252601, 0.5761276265749564, 0.5732856197999074, 0.5734197646379471, 0.5694211904819195, 0.5682338883097355, 0.5555741225297635, 0.5656714760340177, 0.5759431931834954, 0.5752193555235863, 0.5613395273685455, 0.549470240680071, 0.5690888430063541, 0.5733612196949812, 0.5764317799072999, 0.5722455210410632, 0.5707121921273378, 0.5565253427395453, 0.5701843419900308, 0.5463558538601949, 0.5798228085041046, 0.5707850055052683, 0.5721703481215697, 0.5687670627465615, 0.5770033082136741, 0.5729412482335017, 0.5717195157821362, 0.5837618284500562, 0.5622774391220167, 0.5768189298418852, 0.5827300376616992, 0.5671419891027304, 0.5776689350605011, 0.5702007160736964, 0.5721058461528558, 0.575146832718299, 0.5529424387675065, 0.5720992844838363, 0.5579503568319174, 0.5668986737728119, 0.5692426871794921, 0.5731342744368774, 0.581033774293386, 0.5774825536287748, 0.5771042830668963, 0.565878329368738, 0.5625735607284766, 0.5777122940008457, 0.575102995794553, 0.5697114307146806, 0.5681804212240072, 0.5728435046397723, 0.5770491373080474, 0.5651554877941425, 0.5631717959275613, 0.5748797574868569, 0.5653828101662489, 0.5690721525595739, 0.5466466660682971, 0.5714360934037429, 0.5716777592897415, 0.5635113888061963, 0.5689354149194864, 0.5737903227026646, 0.5634831121334662, 0.567294645194824, 0.5684534265444829, 0.5717410611418577], 'loss': [2.6950130971234674, 0.9264669377876583, 0.6855888725217612, 0.5934328123189135, 0.5345826370188597, 0.4998950299923791, 0.47541787841657995, 0.4565227536255612, 0.44001376770974787, 0.4265905422779793, 0.4184188794069467, 0.41012160867977593, 0.4012405010295686, 0.3919796741097811, 0.38860686631711944, 0.3820629938550511, 0.3776682170512854, 0.37082841539695166, 0.36795200441724246, 0.3622731270522283, 0.3582760079544892, 0.35378843133634036, 0.35270284184294304, 0.3504204941743592, 0.34242389544694835, 0.3434027453404692, 0.33714981285461276, 0.3352989028528763, 0.33582769806101614, 0.33199770987050337, 0.33041765241179644, 0.3247693461195675, 0.3270182678848574, 0.32448040102995446, 0.322538623711527, 0.3192431120390735, 0.3178220482634671, 0.3184955672266562, 0.31428899301777224, 0.31244228645454175, 0.3127056181645202, 0.30932020105955443, 0.30680750036255017, 0.3061944880103379, 0.30568858605683163, 0.30513794567766833, 0.30107911259697273, 0.3024796122479107, 0.30146197813205655, 0.30009133151115597, 0.29720811185379, 0.29578794555053667, 0.29550506344561006, 0.2938243931981016, 0.2943931656064972, 0.2915324523974903, 0.29066150014519, 0.2904464516743714, 0.2899506622812883, 0.2867548735826908, 0.28692828838503975, 0.2851590390609088, 0.28501434164503275, 0.2840311394992882, 0.2841258351679472, 0.28257600971773567, 0.2808199821583385, 0.28170351973651225, 0.2830052423672868, 0.2806152549878836, 0.27902078566148386, 0.27891513445517413, 0.2777400169053289, 0.2777699526469118, 0.2761323612922344, 0.2772927064962914, 0.2754813498300918, 0.27625513683383035, 0.2739215566752901, 0.27352851324445104, 0.272497830389391, 0.2719122027159067, 0.27236704279177415, 0.26961255246429966, 0.27062635715900724, 0.26959356436658627, 0.26989396491042367, 0.27008758683623746, 0.268781391136059, 0.2689507315819151, 0.26762279443203013, 0.2689091887029238, 0.2662482862459121, 0.26598425276998683, 0.26526236453861546, 0.2627403273784091, 0.26306831512373774, 0.2635824216926031, 0.2640747332346458, 0.2619700671523125, 0.26197961959508603, 0.2607032073211441, 0.2622898264552662, 0.26179804705357534, 0.2617327511272098, 0.26189645593273875, 0.26050139495689445, 0.26025927220171013, 0.2613575152972412, 0.2597106976597267, 0.257713921792083, 0.2593691849564534, 0.2589857324917994], 'acc': [0.5087987896662065, 0.9004443419504065, 0.9095747472999567, 0.9170503018692412, 0.9238478938756829, 0.9277378519907502, 0.9303093902642333, 0.9321513705771205, 0.9336498786434964, 0.9349041846222206, 0.9355332955689181, 0.9363094048395397, 0.9371467944243886, 0.9378689674887832, 0.9382621901430878, 0.9389654111292687, 0.9392690907091515, 0.9398828729276649, 0.9400973434126334, 0.9407122569650145, 0.9409987566810378, 0.9414040831350636, 0.9415491595486373, 0.9415935231818492, 0.9423113699923755, 0.9423233652361137, 0.9428100089442848, 0.9430458703285586, 0.9430389800964879, 0.9432865453252359, 0.9433000459889144, 0.9438378844909383, 0.9437288040825882, 0.9441059996509402, 0.9441948097361021, 0.9444681178057951, 0.9444937000940462, 0.9444501799135578, 0.9447580294823236, 0.9449511711353153, 0.9450073001031384, 0.9451633537705068, 0.9454592929261972, 0.9454194380273285, 0.9455156492964869, 0.9454520884545694, 0.9458507670639824, 0.9458790334797231, 0.9459086068714609, 0.9460501116953421, 0.9462652043268094, 0.9464552651238399, 0.9464369300138925, 0.9465377549618073, 0.9465577496622999, 0.9468623879408139, 0.9468791685145708, 0.9469551659428544, 0.9469542785686045, 0.9471810750060665, 0.9472471602198538, 0.9473039168422319, 0.9473138901180945, 0.9473749878913793, 0.9473695128174887, 0.9476484306226036, 0.9476871375754828, 0.9476588515132421, 0.9475188910834719, 0.9477920665090555, 0.9479466098750923, 0.9478941127172774, 0.9480611183354636, 0.9480930635610938, 0.9481566899884597, 0.9481246300501367, 0.948253634961496, 0.9482418208294642, 0.9484844008165345, 0.9484902991587129, 0.9486346015859374, 0.94857928468811, 0.9485843638800766, 0.9487278253062673, 0.9486800911933813, 0.9488365189743078, 0.9487541158579927, 0.9487176671532108, 0.9489137786764792, 0.9488479593720789, 0.9489895560518684, 0.9488323758385734, 0.9491746297766996, 0.9490871029916883, 0.9491823882257587, 0.9494166745643031, 0.9493094614474941, 0.9492622161333735, 0.949209344631124, 0.9494590196817946, 0.9494154348393642, 0.9495011629416672, 0.9493546867671845, 0.949443231426701, 0.949410910790206, 0.9494180052931058, 0.949597332488124, 0.9496603423320179, 0.9495793543024211, 0.9496481897183849, 0.9498837872216878, 0.9497172722162976, 0.9497617853421144], 'mDice': [0.12422590786808478, 0.38964821047408216, 0.48823203702348084, 0.5359263174661156, 0.5690714268241104, 0.5896583713861142, 0.6048950155282894, 0.6169490715206896, 0.6275079680810629, 0.6364670627552305, 0.6419619611408354, 0.6475343308490129, 0.6535923361206565, 0.659821651463006, 0.6621643539384471, 0.6668360729306801, 0.6698528548772513, 0.6746223713653967, 0.6765789169727805, 0.6806622414992193, 0.6834504936472094, 0.6866567389536067, 0.6874557253587271, 0.6891315671380217, 0.6948206918624168, 0.6942705854403844, 0.6986800684520352, 0.7000614687777045, 0.6998967142889203, 0.7024156228429352, 0.7036904450724136, 0.7077729581500247, 0.7061938079731783, 0.7083004692059695, 0.7094924463333486, 0.7119668132867648, 0.7129861688488559, 0.7124844834690855, 0.715530330625988, 0.717109259331698, 0.7167673282030488, 0.7193540794036051, 0.7212471118835707, 0.721685252841148, 0.7221638274887638, 0.7225436130639076, 0.7255524344729243, 0.7245357012953209, 0.7253371301825764, 0.726313359049384, 0.7285587525803104, 0.729668057345271, 0.7298067888738176, 0.7311357037339232, 0.7307389788463592, 0.7328547061638541, 0.7335350186602937, 0.7337287060616147, 0.7341297231102676, 0.7365463388743441, 0.7363809154975418, 0.737814384737897, 0.7379068296729424, 0.7386965572938459, 0.7386583135454107, 0.7398305053444, 0.7411309204219859, 0.7405110296371469, 0.7394857009783296, 0.7413865761883109, 0.7425604831036701, 0.7426934307828487, 0.7436209673108863, 0.7435544102347822, 0.7448436473553376, 0.7440443705019449, 0.7453458717715242, 0.7448317635645344, 0.7465817341557797, 0.7468734556355732, 0.7477207700341849, 0.7481824955926614, 0.7477984955903845, 0.7499451995236753, 0.7491439225697203, 0.7499607949583202, 0.7497823142119244, 0.7496454831002153, 0.7506497069488293, 0.7505259970001197, 0.7515148216427159, 0.7505658017657817, 0.7526160910606032, 0.7528934174112581, 0.7534627879137572, 0.7554119172971825, 0.7550968068734225, 0.7547041761097868, 0.7543467956913866, 0.7560037986374447, 0.7559561558362579, 0.757026182168262, 0.7558148430632367, 0.7561944326791092, 0.7562637727418685, 0.7560272047597303, 0.7571899863469318, 0.7573878707606931, 0.7565746326777676, 0.7578293998655024, 0.759404517804346, 0.7580946884196611, 0.758384988579068]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.06s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.70s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:25,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:42,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:33,  1.61s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:05,  1.52s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:22,  1.58s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:04,  1.52s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:18,  1.58s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:14,  1.57s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:36,  1.65s/it]predicting train subjects:   4%|▎         | 10/285 [00:15<07:50,  1.71s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:25,  1.63s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:42,  1.69s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:30,  1.66s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:36,  1.68s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:46,  1.73s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:54,  1.76s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:32,  1.69s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:27,  1.68s/it]predicting train subjects:   7%|▋         | 19/285 [00:30<07:16,  1.64s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:18,  1.67s/it]predicting train subjects:   8%|▊         | 23/285 [00:37<07:19,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:03,  1.62s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:13,  1.67s/it]predicting train subjects:   9%|▉         | 26/285 [00:42<07:25,  1.72s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:06,  1.65s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:11,  1.68s/it]predicting train subjects:  10%|█         | 29/285 [00:47<07:09,  1.68s/it]predicting train subjects:  11%|█         | 30/285 [00:49<07:25,  1.75s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:31,  1.78s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:07,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:54<07:02,  1.68s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<06:59,  1.67s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 36/285 [00:59<06:50,  1.65s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<06:57,  1.68s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:08,  1.73s/it]predicting train subjects:  14%|█▎        | 39/285 [01:04<06:49,  1.66s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:59,  1.71s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:47,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:09<06:35,  1.63s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:39,  1.65s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:52,  1.71s/it]predicting train subjects:  16%|█▌        | 45/285 [01:14<06:36,  1.65s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:40,  1.67s/it]predicting train subjects:  16%|█▋        | 47/285 [01:17<06:21,  1.60s/it]predicting train subjects:  17%|█▋        | 48/285 [01:19<06:22,  1.61s/it]predicting train subjects:  17%|█▋        | 49/285 [01:21<06:37,  1.69s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:35,  1.68s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<06:49,  1.75s/it]predicting train subjects:  18%|█▊        | 52/285 [01:26<06:32,  1.69s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:30,  1.68s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:43,  1.75s/it]predicting train subjects:  19%|█▉        | 55/285 [01:31<06:30,  1.70s/it]predicting train subjects:  20%|█▉        | 56/285 [01:33<06:29,  1.70s/it]predicting train subjects:  20%|██        | 57/285 [01:34<06:17,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:36<06:19,  1.67s/it]predicting train subjects:  21%|██        | 59/285 [01:38<06:27,  1.71s/it]predicting train subjects:  21%|██        | 60/285 [01:40<06:32,  1.74s/it]predicting train subjects:  21%|██▏       | 61/285 [01:41<06:16,  1.68s/it]predicting train subjects:  22%|██▏       | 62/285 [01:43<06:19,  1.70s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<06:18,  1.70s/it]predicting train subjects:  22%|██▏       | 64/285 [01:46<06:03,  1.65s/it]predicting train subjects:  23%|██▎       | 65/285 [01:48<06:06,  1.67s/it]predicting train subjects:  23%|██▎       | 66/285 [01:50<06:05,  1.67s/it]predicting train subjects:  24%|██▎       | 67/285 [01:51<06:08,  1.69s/it]predicting train subjects:  24%|██▍       | 68/285 [01:53<05:55,  1.64s/it]predicting train subjects:  24%|██▍       | 69/285 [01:55<06:01,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [01:56<05:58,  1.67s/it]predicting train subjects:  25%|██▍       | 71/285 [01:58<06:08,  1.72s/it]predicting train subjects:  25%|██▌       | 72/285 [02:00<05:54,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:01<05:53,  1.67s/it]predicting train subjects:  26%|██▌       | 74/285 [02:03<05:52,  1.67s/it]predicting train subjects:  26%|██▋       | 75/285 [02:05<05:55,  1.69s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:08<05:45,  1.66s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:37,  1.63s/it]predicting train subjects:  28%|██▊       | 79/285 [02:11<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:13<05:47,  1.70s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:34,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:16<05:35,  1.65s/it]predicting train subjects:  29%|██▉       | 83/285 [02:18<05:28,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:21,  1.60s/it]predicting train subjects:  30%|██▉       | 85/285 [02:21<05:30,  1.65s/it]predicting train subjects:  30%|███       | 86/285 [02:23<05:31,  1.67s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:31,  1.67s/it]predicting train subjects:  31%|███       | 88/285 [02:26<05:20,  1.63s/it]predicting train subjects:  31%|███       | 89/285 [02:28<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:27,  1.68s/it]predicting train subjects:  32%|███▏      | 91/285 [02:31<05:15,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:33<05:16,  1.64s/it]predicting train subjects:  33%|███▎      | 93/285 [02:34<05:08,  1.61s/it]predicting train subjects:  33%|███▎      | 94/285 [02:36<05:18,  1.67s/it]predicting train subjects:  33%|███▎      | 95/285 [02:38<05:17,  1.67s/it]predicting train subjects:  34%|███▎      | 96/285 [02:40<05:16,  1.68s/it]predicting train subjects:  34%|███▍      | 97/285 [02:41<05:16,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:43<05:15,  1.69s/it]predicting train subjects:  35%|███▍      | 99/285 [02:45<05:12,  1.68s/it]predicting train subjects:  35%|███▌      | 100/285 [02:46<05:14,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:48<05:05,  1.66s/it]predicting train subjects:  36%|███▌      | 102/285 [02:50<05:10,  1.70s/it]predicting train subjects:  36%|███▌      | 103/285 [02:51<05:02,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [02:53<05:08,  1.70s/it]predicting train subjects:  37%|███▋      | 105/285 [02:55<05:04,  1.69s/it]predicting train subjects:  37%|███▋      | 106/285 [02:56<04:53,  1.64s/it]predicting train subjects:  38%|███▊      | 107/285 [02:58<04:56,  1.66s/it]predicting train subjects:  38%|███▊      | 108/285 [02:59<04:46,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:01<04:51,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:03<04:51,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:05<04:45,  1.64s/it]predicting train subjects:  39%|███▉      | 112/285 [03:06<04:51,  1.68s/it]predicting train subjects:  40%|███▉      | 113/285 [03:08<04:56,  1.73s/it]predicting train subjects:  40%|████      | 114/285 [03:10<04:54,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:12<04:51,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:13<04:49,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:15<04:42,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:16<04:37,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:18<04:40,  1.69s/it]predicting train subjects:  42%|████▏     | 120/285 [03:20<04:35,  1.67s/it]predicting train subjects:  42%|████▏     | 121/285 [03:21<04:25,  1.62s/it]predicting train subjects:  43%|████▎     | 122/285 [03:23<04:22,  1.61s/it]predicting train subjects:  43%|████▎     | 123/285 [03:24<04:08,  1.53s/it]predicting train subjects:  44%|████▎     | 124/285 [03:26<04:07,  1.54s/it]predicting train subjects:  44%|████▍     | 125/285 [03:27<04:05,  1.53s/it]predicting train subjects:  44%|████▍     | 126/285 [03:29<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:30<03:58,  1.51s/it]predicting train subjects:  45%|████▍     | 128/285 [03:32<03:58,  1.52s/it]predicting train subjects:  45%|████▌     | 129/285 [03:33<03:55,  1.51s/it]predicting train subjects:  46%|████▌     | 130/285 [03:35<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:36<03:42,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:38<03:45,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:39<03:46,  1.49s/it]predicting train subjects:  47%|████▋     | 134/285 [03:41<03:42,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:42<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:43<03:33,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:45<03:41,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:46<03:34,  1.46s/it]predicting train subjects:  49%|████▉     | 139/285 [03:48<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:49<03:35,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:51<03:27,  1.44s/it]predicting train subjects:  50%|████▉     | 142/285 [03:52<03:23,  1.42s/it]predicting train subjects:  50%|█████     | 143/285 [03:54<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:55<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [03:57<03:22,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [03:58<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:59<03:20,  1.45s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:01<03:25,  1.50s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:03<03:24,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:04<03:20,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:06<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:07<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:08<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:10<03:15,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:11<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:13<03:12,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:14<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:16<03:02,  1.44s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:17<02:59,  1.42s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:18<02:56,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:20<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:21<02:57,  1.44s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:23<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:24<02:54,  1.44s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:26<02:56,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:27<02:59,  1.51s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:29<02:57,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:30<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:32<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:33<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:35<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:36<02:44,  1.46s/it]predicting train subjects:  61%|██████    | 173/285 [04:38<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:39<02:38,  1.43s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:40<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:42<02:45,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:44<02:41,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:45<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:46<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:48<02:39,  1.52s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:50<02:42,  1.56s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:51<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:53<02:33,  1.51s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:54<02:28,  1.47s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:55<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:57<02:30,  1.52s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:59<02:38,  1.62s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:01<02:39,  1.65s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:02<02:28,  1.55s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:03<02:23,  1.51s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:05<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:07<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:08<02:17,  1.49s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:09<02:12,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:11<02:07,  1.41s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:12<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:14<02:20,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:16<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:17<02:15,  1.57s/it]predicting train subjects:  70%|███████   | 200/285 [05:19<02:08,  1.51s/it]predicting train subjects:  71%|███████   | 201/285 [05:20<02:10,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:22<02:10,  1.57s/it]predicting train subjects:  71%|███████   | 203/285 [05:24<02:11,  1.61s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:25<02:02,  1.52s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:26<01:56,  1.46s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:28<01:52,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:30<02:01,  1.56s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:31<02:06,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:33<02:06,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:35<01:57,  1.57s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:36<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:38<01:53,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:39<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:41<01:47,  1.52s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:42<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:44<01:46,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:46<01:50,  1.63s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:47<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:49<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:50<01:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:52<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:54<01:39,  1.58s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:55<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:56<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:57<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:59<01:28,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:01<01:31,  1.57s/it]predicting train subjects:  80%|████████  | 228/285 [06:03<01:31,  1.61s/it]predicting train subjects:  80%|████████  | 229/285 [06:04<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:06<01:24,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:07<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:09<01:21,  1.53s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:10<01:18,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:12<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:13<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:15<01:18,  1.61s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:17<01:18,  1.65s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:18<01:17,  1.65s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:20<01:16,  1.67s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:10,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:23<01:07,  1.53s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:24<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:26<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:27<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:29<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:31<01:01,  1.57s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:32<01:01,  1.63s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:34<01:00,  1.64s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:35<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:37<00:52,  1.51s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:38<00:49,  1.45s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:39<00:46,  1.41s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:41<00:48,  1.52s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:43<00:48,  1.58s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:45<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:46<00:43,  1.51s/it]predicting train subjects:  90%|█████████ | 257/285 [06:47<00:41,  1.48s/it]predicting train subjects:  91%|█████████ | 258/285 [06:49<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [06:50<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [06:52<00:36,  1.47s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:53<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:54<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:56<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:57<00:31,  1.48s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:59<00:31,  1.56s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:00<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:02<00:25,  1.43s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:03<00:25,  1.50s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:05<00:24,  1.51s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:06<00:21,  1.43s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:08<00:19,  1.40s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:09<00:18,  1.44s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:10<00:16,  1.41s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:12<00:14,  1.36s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:13<00:14,  1.48s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:15<00:13,  1.54s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:16<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:18<00:10,  1.44s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:19<00:08,  1.47s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:21<00:07,  1.43s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:22<00:05,  1.41s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:23<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:25<00:02,  1.48s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:27<00:01,  1.56s/it]predicting train subjects: 100%|██████████| 285/285 [07:29<00:00,  1.61s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:32,  1.59s/it]Loading train:   1%|          | 2/285 [00:02<06:59,  1.48s/it]Loading train:   1%|          | 3/285 [00:04<06:47,  1.45s/it]Loading train:   1%|▏         | 4/285 [00:05<06:17,  1.34s/it]Loading train:   2%|▏         | 5/285 [00:06<06:37,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:08<06:16,  1.35s/it]Loading train:   2%|▏         | 7/285 [00:09<06:29,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:22,  1.38s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:02,  1.32s/it]Loading train:   4%|▍         | 11/285 [00:14<05:26,  1.19s/it]Loading train:   4%|▍         | 12/285 [00:15<05:09,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:16<04:36,  1.02s/it]Loading train:   5%|▍         | 14/285 [00:17<04:33,  1.01s/it]Loading train:   5%|▌         | 15/285 [00:18<04:24,  1.02it/s]Loading train:   6%|▌         | 16/285 [00:19<04:32,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:20<04:17,  1.04it/s]Loading train:   6%|▋         | 18/285 [00:20<04:16,  1.04it/s]Loading train:   7%|▋         | 19/285 [00:21<03:58,  1.12it/s]Loading train:   7%|▋         | 20/285 [00:22<03:56,  1.12it/s]Loading train:   7%|▋         | 21/285 [00:23<04:06,  1.07it/s]Loading train:   8%|▊         | 22/285 [00:24<04:02,  1.08it/s]Loading train:   8%|▊         | 23/285 [00:25<04:13,  1.03it/s]Loading train:   8%|▊         | 24/285 [00:26<04:04,  1.07it/s]Loading train:   9%|▉         | 25/285 [00:27<04:05,  1.06it/s]Loading train:   9%|▉         | 26/285 [00:28<04:12,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:29<04:03,  1.06it/s]Loading train:  10%|▉         | 28/285 [00:30<03:59,  1.07it/s]Loading train:  10%|█         | 29/285 [00:31<04:07,  1.03it/s]Loading train:  11%|█         | 30/285 [00:32<04:13,  1.01it/s]Loading train:  11%|█         | 31/285 [00:33<04:14,  1.00s/it]Loading train:  11%|█         | 32/285 [00:34<04:02,  1.04it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:04,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:36<04:03,  1.03it/s]Loading train:  12%|█▏        | 35/285 [00:37<04:00,  1.04it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:39,  1.13it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:53,  1.06it/s]Loading train:  13%|█▎        | 38/285 [00:40<04:13,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:41<04:02,  1.01it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:58,  1.03it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:43,  1.09it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:32,  1.14it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:28,  1.16it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:45,  1.07it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:30,  1.14it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:46,  1.06it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:46,  1.05it/s]Loading train:  17%|█▋        | 48/285 [00:49<03:45,  1.05it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:45,  1.05it/s]Loading train:  18%|█▊        | 50/285 [00:51<03:46,  1.04it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:51,  1.01it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:32,  1.10it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:36,  1.07it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:42,  1.04it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:26,  1.11it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:37,  1.05it/s]Loading train:  20%|██        | 57/285 [00:57<03:21,  1.13it/s]Loading train:  20%|██        | 58/285 [00:58<03:19,  1.14it/s]Loading train:  21%|██        | 59/285 [00:59<03:33,  1.06it/s]Loading train:  21%|██        | 60/285 [01:00<03:32,  1.06it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:23,  1.10it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:18,  1.12it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:23,  1.09it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:48,  1.04s/it]Loading train:  23%|██▎       | 65/285 [01:05<04:17,  1.17s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:06,  1.13s/it]Loading train:  24%|██▍       | 68/285 [01:08<03:42,  1.03s/it]Loading train:  24%|██▍       | 69/285 [01:09<03:42,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:10<03:38,  1.01s/it]Loading train:  25%|██▍       | 71/285 [01:12<03:45,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:12<03:33,  1.00s/it]Loading train:  26%|██▌       | 73/285 [01:13<03:23,  1.04it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:18,  1.06it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:26,  1.02it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:32,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:17<03:18,  1.05it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:09,  1.09it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:09,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:16,  1.04it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:05,  1.10it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:08,  1.07it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:02,  1.11it/s]Loading train:  29%|██▉       | 84/285 [01:24<03:01,  1.11it/s]Loading train:  30%|██▉       | 85/285 [01:24<03:03,  1.09it/s]Loading train:  30%|███       | 86/285 [01:25<03:02,  1.09it/s]Loading train:  31%|███       | 87/285 [01:26<03:07,  1.06it/s]Loading train:  31%|███       | 88/285 [01:27<02:58,  1.11it/s]Loading train:  31%|███       | 89/285 [01:28<02:56,  1.11it/s]Loading train:  32%|███▏      | 90/285 [01:29<02:52,  1.13it/s]Loading train:  32%|███▏      | 91/285 [01:30<02:45,  1.17it/s]Loading train:  32%|███▏      | 92/285 [01:31<02:45,  1.16it/s]Loading train:  33%|███▎      | 93/285 [01:31<02:40,  1.20it/s]Loading train:  33%|███▎      | 94/285 [01:32<02:38,  1.21it/s]Loading train:  33%|███▎      | 95/285 [01:33<02:42,  1.17it/s]Loading train:  34%|███▎      | 96/285 [01:34<02:42,  1.16it/s]Loading train:  34%|███▍      | 97/285 [01:35<02:48,  1.11it/s]Loading train:  34%|███▍      | 98/285 [01:36<02:44,  1.14it/s]Loading train:  35%|███▍      | 99/285 [01:37<02:51,  1.09it/s]Loading train:  35%|███▌      | 100/285 [01:38<02:50,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:39<02:42,  1.13it/s]Loading train:  36%|███▌      | 102/285 [01:39<02:44,  1.12it/s]Loading train:  36%|███▌      | 103/285 [01:40<02:39,  1.14it/s]Loading train:  36%|███▋      | 104/285 [01:41<02:37,  1.15it/s]Loading train:  37%|███▋      | 105/285 [01:42<02:38,  1.14it/s]Loading train:  37%|███▋      | 106/285 [01:43<02:32,  1.17it/s]Loading train:  38%|███▊      | 107/285 [01:44<02:28,  1.20it/s]Loading train:  38%|███▊      | 108/285 [01:45<02:30,  1.18it/s]Loading train:  38%|███▊      | 109/285 [01:45<02:30,  1.17it/s]Loading train:  39%|███▊      | 110/285 [01:46<02:36,  1.12it/s]Loading train:  39%|███▉      | 111/285 [01:47<02:33,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:48<02:33,  1.13it/s]Loading train:  40%|███▉      | 113/285 [01:49<02:44,  1.04it/s]Loading train:  40%|████      | 114/285 [01:50<02:38,  1.08it/s]Loading train:  40%|████      | 115/285 [01:51<02:36,  1.09it/s]Loading train:  41%|████      | 116/285 [01:52<02:39,  1.06it/s]Loading train:  41%|████      | 117/285 [01:53<02:30,  1.12it/s]Loading train:  41%|████▏     | 118/285 [01:54<02:24,  1.16it/s]Loading train:  42%|████▏     | 119/285 [01:55<02:31,  1.09it/s]Loading train:  42%|████▏     | 120/285 [01:56<02:30,  1.10it/s]Loading train:  42%|████▏     | 121/285 [01:57<02:50,  1.04s/it]Loading train:  43%|████▎     | 122/285 [01:58<02:52,  1.06s/it]Loading train:  43%|████▎     | 123/285 [01:59<02:53,  1.07s/it]Loading train:  44%|████▎     | 124/285 [02:00<02:38,  1.02it/s]Loading train:  44%|████▍     | 125/285 [02:01<02:34,  1.03it/s]Loading train:  44%|████▍     | 126/285 [02:02<02:21,  1.12it/s]Loading train:  45%|████▍     | 127/285 [02:02<02:14,  1.18it/s]Loading train:  45%|████▍     | 128/285 [02:03<02:10,  1.21it/s]Loading train:  45%|████▌     | 129/285 [02:04<02:07,  1.23it/s]Loading train:  46%|████▌     | 130/285 [02:05<02:01,  1.27it/s]Loading train:  46%|████▌     | 131/285 [02:05<01:56,  1.32it/s]Loading train:  46%|████▋     | 132/285 [02:06<01:57,  1.30it/s]Loading train:  47%|████▋     | 133/285 [02:07<01:56,  1.31it/s]Loading train:  47%|████▋     | 134/285 [02:08<01:55,  1.31it/s]Loading train:  47%|████▋     | 135/285 [02:08<01:48,  1.39it/s]Loading train:  48%|████▊     | 136/285 [02:09<01:47,  1.39it/s]Loading train:  48%|████▊     | 137/285 [02:10<01:49,  1.36it/s]Loading train:  48%|████▊     | 138/285 [02:10<01:48,  1.35it/s]Loading train:  49%|████▉     | 139/285 [02:11<01:47,  1.36it/s]Loading train:  49%|████▉     | 140/285 [02:12<01:49,  1.33it/s]Loading train:  49%|████▉     | 141/285 [02:13<01:47,  1.34it/s]Loading train:  50%|████▉     | 142/285 [02:13<01:45,  1.35it/s]Loading train:  50%|█████     | 143/285 [02:14<01:46,  1.33it/s]Loading train:  51%|█████     | 144/285 [02:15<01:51,  1.26it/s]Loading train:  51%|█████     | 145/285 [02:16<01:47,  1.30it/s]Loading train:  51%|█████     | 146/285 [02:17<01:46,  1.30it/s]Loading train:  52%|█████▏    | 147/285 [02:17<01:44,  1.31it/s]Loading train:  52%|█████▏    | 148/285 [02:18<01:42,  1.33it/s]Loading train:  52%|█████▏    | 149/285 [02:19<01:40,  1.35it/s]Loading train:  53%|█████▎    | 150/285 [02:19<01:38,  1.37it/s]Loading train:  53%|█████▎    | 151/285 [02:20<01:38,  1.36it/s]Loading train:  53%|█████▎    | 152/285 [02:21<01:40,  1.33it/s]Loading train:  54%|█████▎    | 153/285 [02:22<01:40,  1.32it/s]Loading train:  54%|█████▍    | 154/285 [02:23<01:40,  1.31it/s]Loading train:  54%|█████▍    | 155/285 [02:23<01:41,  1.27it/s]Loading train:  55%|█████▍    | 156/285 [02:24<01:49,  1.18it/s]Loading train:  55%|█████▌    | 157/285 [02:25<01:43,  1.24it/s]Loading train:  55%|█████▌    | 158/285 [02:26<01:44,  1.22it/s]Loading train:  56%|█████▌    | 159/285 [02:27<01:38,  1.27it/s]Loading train:  56%|█████▌    | 160/285 [02:27<01:40,  1.24it/s]Loading train:  56%|█████▋    | 161/285 [02:28<01:36,  1.28it/s]Loading train:  57%|█████▋    | 162/285 [02:29<01:33,  1.31it/s]Loading train:  57%|█████▋    | 163/285 [02:30<01:29,  1.36it/s]Loading train:  58%|█████▊    | 164/285 [02:30<01:24,  1.43it/s]Loading train:  58%|█████▊    | 165/285 [02:31<01:26,  1.39it/s]Loading train:  58%|█████▊    | 166/285 [02:32<01:28,  1.35it/s]Loading train:  59%|█████▊    | 167/285 [02:33<01:30,  1.30it/s]Loading train:  59%|█████▉    | 168/285 [02:33<01:27,  1.33it/s]Loading train:  59%|█████▉    | 169/285 [02:34<01:25,  1.35it/s]Loading train:  60%|█████▉    | 170/285 [02:35<01:25,  1.34it/s]Loading train:  60%|██████    | 171/285 [02:36<01:29,  1.28it/s]Loading train:  60%|██████    | 172/285 [02:36<01:27,  1.29it/s]Loading train:  61%|██████    | 173/285 [02:37<01:26,  1.30it/s]Loading train:  61%|██████    | 174/285 [02:38<01:25,  1.30it/s]Loading train:  61%|██████▏   | 175/285 [02:39<01:23,  1.32it/s]Loading train:  62%|██████▏   | 176/285 [02:39<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:40<01:19,  1.35it/s]Loading train:  62%|██████▏   | 178/285 [02:41<01:22,  1.30it/s]Loading train:  63%|██████▎   | 179/285 [02:42<01:25,  1.24it/s]Loading train:  63%|██████▎   | 180/285 [02:43<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [02:44<01:31,  1.13it/s]Loading train:  64%|██████▍   | 182/285 [02:45<01:28,  1.16it/s]Loading train:  64%|██████▍   | 183/285 [02:45<01:25,  1.20it/s]Loading train:  65%|██████▍   | 184/285 [02:46<01:24,  1.20it/s]Loading train:  65%|██████▍   | 185/285 [02:47<01:20,  1.24it/s]Loading train:  65%|██████▌   | 186/285 [02:48<01:21,  1.21it/s]Loading train:  66%|██████▌   | 187/285 [02:49<01:23,  1.17it/s]Loading train:  66%|██████▌   | 188/285 [02:50<01:24,  1.15it/s]Loading train:  66%|██████▋   | 189/285 [02:50<01:18,  1.22it/s]Loading train:  67%|██████▋   | 190/285 [02:51<01:15,  1.26it/s]Loading train:  67%|██████▋   | 191/285 [02:52<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [02:53<01:18,  1.18it/s]Loading train:  68%|██████▊   | 193/285 [02:54<01:14,  1.23it/s]Loading train:  68%|██████▊   | 194/285 [02:54<01:14,  1.22it/s]Loading train:  68%|██████▊   | 195/285 [02:55<01:10,  1.28it/s]Loading train:  69%|██████▉   | 196/285 [02:56<01:13,  1.22it/s]Loading train:  69%|██████▉   | 197/285 [02:57<01:14,  1.18it/s]Loading train:  69%|██████▉   | 198/285 [02:58<01:17,  1.13it/s]Loading train:  70%|██████▉   | 199/285 [02:59<01:10,  1.22it/s]Loading train:  70%|███████   | 200/285 [02:59<01:07,  1.27it/s]Loading train:  71%|███████   | 201/285 [03:00<01:08,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:01<01:08,  1.21it/s]Loading train:  71%|███████   | 203/285 [03:02<01:05,  1.24it/s]Loading train:  72%|███████▏  | 204/285 [03:02<01:02,  1.30it/s]Loading train:  72%|███████▏  | 205/285 [03:03<01:01,  1.30it/s]Loading train:  72%|███████▏  | 206/285 [03:04<01:02,  1.27it/s]Loading train:  73%|███████▎  | 207/285 [03:05<01:02,  1.25it/s]Loading train:  73%|███████▎  | 208/285 [03:06<01:03,  1.21it/s]Loading train:  73%|███████▎  | 209/285 [03:07<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:08<01:03,  1.17it/s]Loading train:  74%|███████▍  | 211/285 [03:08<01:04,  1.14it/s]Loading train:  74%|███████▍  | 212/285 [03:10<01:11,  1.02it/s]Loading train:  75%|███████▍  | 213/285 [03:11<01:08,  1.05it/s]Loading train:  75%|███████▌  | 214/285 [03:11<01:04,  1.11it/s]Loading train:  75%|███████▌  | 215/285 [03:12<01:06,  1.06it/s]Loading train:  76%|███████▌  | 216/285 [03:13<00:59,  1.15it/s]Loading train:  76%|███████▌  | 217/285 [03:14<01:02,  1.09it/s]Loading train:  76%|███████▋  | 218/285 [03:15<01:00,  1.10it/s]Loading train:  77%|███████▋  | 219/285 [03:16<01:00,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:17<00:57,  1.13it/s]Loading train:  78%|███████▊  | 221/285 [03:18<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [03:18<00:54,  1.16it/s]Loading train:  78%|███████▊  | 223/285 [03:19<00:52,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [03:20<00:50,  1.20it/s]Loading train:  79%|███████▉  | 225/285 [03:21<00:48,  1.23it/s]Loading train:  79%|███████▉  | 226/285 [03:22<00:49,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:23<00:51,  1.13it/s]Loading train:  80%|████████  | 228/285 [03:24<00:52,  1.08it/s]Loading train:  80%|████████  | 229/285 [03:24<00:48,  1.16it/s]Loading train:  81%|████████  | 230/285 [03:25<00:44,  1.24it/s]Loading train:  81%|████████  | 231/285 [03:26<00:42,  1.28it/s]Loading train:  81%|████████▏ | 232/285 [03:27<00:42,  1.25it/s]Loading train:  82%|████████▏ | 233/285 [03:27<00:40,  1.30it/s]Loading train:  82%|████████▏ | 234/285 [03:28<00:41,  1.24it/s]Loading train:  82%|████████▏ | 235/285 [03:29<00:40,  1.24it/s]Loading train:  83%|████████▎ | 236/285 [03:30<00:41,  1.18it/s]Loading train:  83%|████████▎ | 237/285 [03:31<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:32<00:43,  1.08it/s]Loading train:  84%|████████▍ | 239/285 [03:33<00:41,  1.11it/s]Loading train:  84%|████████▍ | 240/285 [03:34<00:37,  1.19it/s]Loading train:  85%|████████▍ | 241/285 [03:34<00:35,  1.25it/s]Loading train:  85%|████████▍ | 242/285 [03:35<00:32,  1.33it/s]Loading train:  85%|████████▌ | 243/285 [03:36<00:30,  1.38it/s]Loading train:  86%|████████▌ | 244/285 [03:36<00:31,  1.31it/s]Loading train:  86%|████████▌ | 245/285 [03:37<00:28,  1.39it/s]Loading train:  86%|████████▋ | 246/285 [03:38<00:31,  1.24it/s]Loading train:  87%|████████▋ | 247/285 [03:39<00:31,  1.19it/s]Loading train:  87%|████████▋ | 248/285 [03:40<00:30,  1.21it/s]Loading train:  87%|████████▋ | 249/285 [03:40<00:27,  1.29it/s]Loading train:  88%|████████▊ | 250/285 [03:41<00:26,  1.32it/s]Loading train:  88%|████████▊ | 251/285 [03:42<00:24,  1.38it/s]Loading train:  88%|████████▊ | 252/285 [03:43<00:25,  1.28it/s]Loading train:  89%|████████▉ | 253/285 [03:44<00:26,  1.19it/s]Loading train:  89%|████████▉ | 254/285 [03:45<00:26,  1.17it/s]Loading train:  89%|████████▉ | 255/285 [03:45<00:26,  1.15it/s]Loading train:  90%|████████▉ | 256/285 [03:46<00:24,  1.20it/s]Loading train:  90%|█████████ | 257/285 [03:47<00:22,  1.26it/s]Loading train:  91%|█████████ | 258/285 [03:48<00:22,  1.21it/s]Loading train:  91%|█████████ | 259/285 [03:49<00:22,  1.15it/s]Loading train:  91%|█████████ | 260/285 [03:50<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [03:50<00:19,  1.24it/s]Loading train:  92%|█████████▏| 262/285 [03:51<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [03:52<00:17,  1.27it/s]Loading train:  93%|█████████▎| 264/285 [03:53<00:17,  1.19it/s]Loading train:  93%|█████████▎| 265/285 [03:54<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [03:55<00:16,  1.16it/s]Loading train:  94%|█████████▎| 267/285 [03:55<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [03:56<00:15,  1.13it/s]Loading train:  94%|█████████▍| 269/285 [03:57<00:13,  1.19it/s]Loading train:  95%|█████████▍| 270/285 [03:58<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [03:59<00:10,  1.30it/s]Loading train:  95%|█████████▌| 272/285 [04:00<00:11,  1.12it/s]Loading train:  96%|█████████▌| 273/285 [04:01<00:10,  1.12it/s]Loading train:  96%|█████████▌| 274/285 [04:01<00:09,  1.14it/s]Loading train:  96%|█████████▋| 275/285 [04:03<00:09,  1.07it/s]Loading train:  97%|█████████▋| 276/285 [04:04<00:08,  1.01it/s]Loading train:  97%|█████████▋| 277/285 [04:04<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [04:05<00:06,  1.13it/s]Loading train:  98%|█████████▊| 279/285 [04:06<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:07<00:04,  1.11it/s]Loading train:  99%|█████████▊| 281/285 [04:08<00:03,  1.15it/s]Loading train:  99%|█████████▉| 282/285 [04:09<00:02,  1.15it/s]Loading train:  99%|█████████▉| 283/285 [04:10<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:11<00:00,  1.09it/s]Loading train: 100%|██████████| 285/285 [04:12<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 65.09it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 65.66it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:03, 70.20it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:03, 72.87it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:02, 83.87it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:02, 104.21it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:02, 98.79it/s] concatenating: train:  33%|███▎      | 93/285 [00:00<00:01, 97.12it/s]concatenating: train:  36%|███▋      | 104/285 [00:01<00:01, 97.56it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:02, 83.51it/s]concatenating: train:  44%|████▍     | 126/285 [00:01<00:01, 89.13it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 104.97it/s]concatenating: train:  59%|█████▉    | 168/285 [00:01<00:00, 125.57it/s]concatenating: train:  65%|██████▍   | 184/285 [00:01<00:00, 126.48it/s]concatenating: train:  70%|██████▉   | 199/285 [00:01<00:00, 128.63it/s]concatenating: train:  75%|███████▌  | 214/285 [00:01<00:00, 98.47it/s] concatenating: train:  86%|████████▌ | 245/285 [00:02<00:00, 123.51it/s]concatenating: train:  92%|█████████▏| 263/285 [00:02<00:00, 119.43it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 124.58it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.30s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 78.32it/s]2019-07-11 07:00:21.846344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:00:21.846452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:00:21.846467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:00:21.846475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:00:21.846901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.97it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.99it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.65it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.20it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.50it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.31it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.25it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.03it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.08it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.81it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.15it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.40it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.27it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.87it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.04it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.94it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.80it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.20it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 40)   16240       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 85)   0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_8[0][0]              
==================================================================================================
Total params: 149,358
Trainable params: 50,738
Non-trainable params: 98,620
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 2.6108 - acc: 0.6372 - mDice: 0.1288 - val_loss: 2.2583 - val_acc: 0.9066 - val_mDice: 0.1851

Epoch 00001: val_mDice improved from -inf to 0.18507, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 0.8491 - acc: 0.8841 - mDice: 0.4315 - val_loss: 1.2727 - val_acc: 0.9163 - val_mDice: 0.4567

Epoch 00002: val_mDice improved from 0.18507 to 0.45667, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.5377 - acc: 0.8936 - mDice: 0.5688 - val_loss: 1.0007 - val_acc: 0.9314 - val_mDice: 0.5729

Epoch 00003: val_mDice improved from 0.45667 to 0.57286, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.4784 - acc: 0.8979 - mDice: 0.6057 - val_loss: 1.1601 - val_acc: 0.9218 - val_mDice: 0.4734

Epoch 00004: val_mDice did not improve from 0.57286
Epoch 5/300
 - 10s - loss: 0.4479 - acc: 0.9018 - mDice: 0.6252 - val_loss: 1.0963 - val_acc: 0.9231 - val_mDice: 0.5023

Epoch 00005: val_mDice did not improve from 0.57286
Epoch 6/300
 - 10s - loss: 0.4300 - acc: 0.9064 - mDice: 0.6370 - val_loss: 1.1236 - val_acc: 0.9255 - val_mDice: 0.4956

Epoch 00006: val_mDice did not improve from 0.57286
Epoch 7/300
 - 11s - loss: 0.4162 - acc: 0.9105 - mDice: 0.6463 - val_loss: 0.9498 - val_acc: 0.9438 - val_mDice: 0.5881

Epoch 00007: val_mDice improved from 0.57286 to 0.58806, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.4066 - acc: 0.9159 - mDice: 0.6528 - val_loss: 0.9568 - val_acc: 0.9467 - val_mDice: 0.5858

Epoch 00008: val_mDice did not improve from 0.58806
Epoch 9/300
 - 10s - loss: 0.3994 - acc: 0.9250 - mDice: 0.6576 - val_loss: 0.9047 - val_acc: 0.9466 - val_mDice: 0.5960

Epoch 00009: val_mDice improved from 0.58806 to 0.59600, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.3869 - acc: 0.9337 - mDice: 0.6651 - val_loss: 0.9218 - val_acc: 0.9463 - val_mDice: 0.5903

Epoch 00010: val_mDice did not improve from 0.59600
Epoch 11/300
 - 10s - loss: 0.3800 - acc: 0.9357 - mDice: 0.6692 - val_loss: 0.9359 - val_acc: 0.9410 - val_mDice: 0.5786

Epoch 00011: val_mDice did not improve from 0.59600
Epoch 12/300
 - 10s - loss: 0.3774 - acc: 0.9360 - mDice: 0.6708 - val_loss: 0.9870 - val_acc: 0.9432 - val_mDice: 0.5441

Epoch 00012: val_mDice did not improve from 0.59600
Epoch 13/300
 - 10s - loss: 0.3710 - acc: 0.9368 - mDice: 0.6753 - val_loss: 0.9461 - val_acc: 0.9453 - val_mDice: 0.5783

Epoch 00013: val_mDice did not improve from 0.59600
Epoch 14/300
 - 10s - loss: 0.3639 - acc: 0.9375 - mDice: 0.6803 - val_loss: 0.9343 - val_acc: 0.9458 - val_mDice: 0.5808

Epoch 00014: val_mDice did not improve from 0.59600
Epoch 15/300
 - 10s - loss: 0.3622 - acc: 0.9377 - mDice: 0.6814 - val_loss: 0.9155 - val_acc: 0.9403 - val_mDice: 0.5840

Epoch 00015: val_mDice did not improve from 0.59600
Epoch 16/300
 - 10s - loss: 0.3588 - acc: 0.9377 - mDice: 0.6837 - val_loss: 0.9303 - val_acc: 0.9446 - val_mDice: 0.5743

Epoch 00016: val_mDice did not improve from 0.59600
Epoch 17/300
 - 11s - loss: 0.3543 - acc: 0.9384 - mDice: 0.6869 - val_loss: 0.9286 - val_acc: 0.9342 - val_mDice: 0.5727

Epoch 00017: val_mDice did not improve from 0.59600
Epoch 18/300
 - 10s - loss: 0.3521 - acc: 0.9386 - mDice: 0.6886 - val_loss: 0.9569 - val_acc: 0.9469 - val_mDice: 0.5667

Epoch 00018: val_mDice did not improve from 0.59600
Epoch 19/300
 - 10s - loss: 0.3477 - acc: 0.9391 - mDice: 0.6917 - val_loss: 0.9425 - val_acc: 0.9447 - val_mDice: 0.5701

Epoch 00019: val_mDice did not improve from 0.59600
Epoch 20/300
 - 10s - loss: 0.3445 - acc: 0.9394 - mDice: 0.6939 - val_loss: 0.9425 - val_acc: 0.9421 - val_mDice: 0.5634

Epoch 00020: val_mDice did not improve from 0.59600
Epoch 21/300
 - 10s - loss: 0.3428 - acc: 0.9397 - mDice: 0.6951 - val_loss: 0.9067 - val_acc: 0.9437 - val_mDice: 0.5691

Epoch 00021: val_mDice did not improve from 0.59600
Epoch 22/300
 - 10s - loss: 0.3399 - acc: 0.9398 - mDice: 0.6973 - val_loss: 0.8744 - val_acc: 0.9453 - val_mDice: 0.5932

Epoch 00022: val_mDice did not improve from 0.59600
Epoch 23/300
 - 10s - loss: 0.3381 - acc: 0.9400 - mDice: 0.6985 - val_loss: 0.9259 - val_acc: 0.9444 - val_mDice: 0.5541

Epoch 00023: val_mDice did not improve from 0.59600
Epoch 24/300
 - 10s - loss: 0.3374 - acc: 0.9401 - mDice: 0.6990 - val_loss: 0.8644 - val_acc: 0.9465 - val_mDice: 0.5896

Epoch 00024: val_mDice did not improve from 0.59600
Epoch 25/300
 - 10s - loss: 0.3356 - acc: 0.9402 - mDice: 0.7003 - val_loss: 0.9023 - val_acc: 0.9424 - val_mDice: 0.5757

Epoch 00025: val_mDice did not improve from 0.59600
Epoch 26/300
 - 10s - loss: 0.3327 - acc: 0.9405 - mDice: 0.7024 - val_loss: 0.8867 - val_acc: 0.9427 - val_mDice: 0.5790

Epoch 00026: val_mDice did not improve from 0.59600
Epoch 27/300
 - 10s - loss: 0.3295 - acc: 0.9409 - mDice: 0.7046 - val_loss: 0.8744 - val_acc: 0.9455 - val_mDice: 0.5713

Epoch 00027: val_mDice did not improve from 0.59600
Epoch 28/300
 - 10s - loss: 0.3291 - acc: 0.9410 - mDice: 0.7051 - val_loss: 0.8936 - val_acc: 0.9463 - val_mDice: 0.5601

Epoch 00028: val_mDice did not improve from 0.59600
Epoch 29/300
 - 10s - loss: 0.3259 - acc: 0.9413 - mDice: 0.7074 - val_loss: 0.8185 - val_acc: 0.9457 - val_mDice: 0.5870

Epoch 00029: val_mDice did not improve from 0.59600
Epoch 30/300
 - 10s - loss: 0.3241 - acc: 0.9414 - mDice: 0.7087 - val_loss: 0.8655 - val_acc: 0.9446 - val_mDice: 0.5621

Epoch 00030: val_mDice did not improve from 0.59600
Epoch 31/300
 - 10s - loss: 0.3230 - acc: 0.9415 - mDice: 0.7096 - val_loss: 0.8917 - val_acc: 0.9454 - val_mDice: 0.5595

Epoch 00031: val_mDice did not improve from 0.59600
Epoch 32/300
 - 10s - loss: 0.3213 - acc: 0.9416 - mDice: 0.7107 - val_loss: 0.8702 - val_acc: 0.9443 - val_mDice: 0.5741

Epoch 00032: val_mDice did not improve from 0.59600
Epoch 33/300
 - 10s - loss: 0.3207 - acc: 0.9417 - mDice: 0.7111 - val_loss: 0.8695 - val_acc: 0.9433 - val_mDice: 0.5880

Epoch 00033: val_mDice did not improve from 0.59600
Epoch 34/300
 - 10s - loss: 0.3178 - acc: 0.9418 - mDice: 0.7133 - val_loss: 0.8188 - val_acc: 0.9421 - val_mDice: 0.5783

Epoch 00034: val_mDice did not improve from 0.59600
Epoch 35/300
 - 10s - loss: 0.3159 - acc: 0.9422 - mDice: 0.7147 - val_loss: 0.8703 - val_acc: 0.9459 - val_mDice: 0.5624

Epoch 00035: val_mDice did not improve from 0.59600
Epoch 36/300
 - 11s - loss: 0.3140 - acc: 0.9423 - mDice: 0.7161 - val_loss: 0.7955 - val_acc: 0.9458 - val_mDice: 0.5867

Epoch 00036: val_mDice did not improve from 0.59600
Epoch 37/300
 - 10s - loss: 0.3149 - acc: 0.9422 - mDice: 0.7155 - val_loss: 0.8536 - val_acc: 0.9452 - val_mDice: 0.5543

Epoch 00037: val_mDice did not improve from 0.59600
Epoch 38/300
 - 10s - loss: 0.3133 - acc: 0.9424 - mDice: 0.7166 - val_loss: 0.8373 - val_acc: 0.9451 - val_mDice: 0.5757

Epoch 00038: val_mDice did not improve from 0.59600
Epoch 39/300
 - 10s - loss: 0.3120 - acc: 0.9426 - mDice: 0.7177 - val_loss: 0.8613 - val_acc: 0.9459 - val_mDice: 0.5547

Epoch 00039: val_mDice did not improve from 0.59600
Epoch 40/300
 - 10s - loss: 0.3097 - acc: 0.9426 - mDice: 0.7193 - val_loss: 0.8325 - val_acc: 0.9377 - val_mDice: 0.5644

Epoch 00040: val_mDice did not improve from 0.59600
Epoch 41/300
 - 10s - loss: 0.3080 - acc: 0.9429 - mDice: 0.7207 - val_loss: 0.7618 - val_acc: 0.9440 - val_mDice: 0.5861

Epoch 00041: val_mDice did not improve from 0.59600
Epoch 42/300
 - 10s - loss: 0.3089 - acc: 0.9427 - mDice: 0.7199 - val_loss: 0.7950 - val_acc: 0.9409 - val_mDice: 0.5715

Epoch 00042: val_mDice did not improve from 0.59600
Epoch 43/300
 - 10s - loss: 0.3091 - acc: 0.9426 - mDice: 0.7198 - val_loss: 0.7720 - val_acc: 0.9426 - val_mDice: 0.5777

Epoch 00043: val_mDice did not improve from 0.59600
Epoch 44/300
 - 10s - loss: 0.3078 - acc: 0.9427 - mDice: 0.7208 - val_loss: 0.7879 - val_acc: 0.9438 - val_mDice: 0.5686

Epoch 00044: val_mDice did not improve from 0.59600
Epoch 45/300
 - 10s - loss: 0.3061 - acc: 0.9430 - mDice: 0.7221 - val_loss: 0.7820 - val_acc: 0.9447 - val_mDice: 0.5625

Epoch 00045: val_mDice did not improve from 0.59600
Epoch 46/300
 - 11s - loss: 0.3054 - acc: 0.9431 - mDice: 0.7226 - val_loss: 0.7427 - val_acc: 0.9460 - val_mDice: 0.5888

Epoch 00046: val_mDice did not improve from 0.59600
Epoch 47/300
 - 10s - loss: 0.3028 - acc: 0.9432 - mDice: 0.7245 - val_loss: 0.7898 - val_acc: 0.9456 - val_mDice: 0.5563

Epoch 00047: val_mDice did not improve from 0.59600
Epoch 48/300
 - 10s - loss: 0.3015 - acc: 0.9435 - mDice: 0.7255 - val_loss: 0.7477 - val_acc: 0.9456 - val_mDice: 0.5837

Epoch 00048: val_mDice did not improve from 0.59600
Epoch 49/300
 - 10s - loss: 0.3003 - acc: 0.9434 - mDice: 0.7264 - val_loss: 0.8066 - val_acc: 0.9449 - val_mDice: 0.5571

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.09s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.72s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:14,  1.74s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:47,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:39,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:11,  1.55s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:20,  1.59s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:42,  1.68s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:58,  1.74s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:36,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:48,  1.72s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:28,  1.65s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:31,  1.67s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:45,  1.72s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:50,  1.75s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:27,  1.67s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:28,  1.68s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:11,  1.62s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:20,  1.66s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:35,  1.73s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:17,  1.66s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:21,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<06:59,  1.61s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:17,  1.68s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:26,  1.72s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:03,  1.64s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:10,  1.67s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:10,  1.68s/it]predicting train subjects:  11%|█         | 30/285 [00:49<07:17,  1.71s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:24,  1.75s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:01,  1.67s/it]predicting train subjects:  12%|█▏        | 33/285 [00:54<07:03,  1.68s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:04,  1.69s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:12,  1.73s/it]predicting train subjects:  13%|█▎        | 36/285 [00:59<06:52,  1.66s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<06:54,  1.67s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:01,  1.71s/it]predicting train subjects:  14%|█▎        | 39/285 [01:04<06:41,  1.63s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:45,  1.65s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:29,  1.59s/it]predicting train subjects:  15%|█▍        | 42/285 [01:09<06:19,  1.56s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:33,  1.62s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:45,  1.68s/it]predicting train subjects:  16%|█▌        | 45/285 [01:14<06:31,  1.63s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:46,  1.70s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:30,  1.64s/it]predicting train subjects:  17%|█▋        | 48/285 [01:19<06:38,  1.68s/it]predicting train subjects:  17%|█▋        | 49/285 [01:21<06:54,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:52,  1.75s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<07:00,  1.80s/it]predicting train subjects:  18%|█▊        | 52/285 [01:26<06:39,  1.72s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:41,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:51,  1.78s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:33<06:24,  1.68s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:07,  1.61s/it]predicting train subjects:  20%|██        | 58/285 [01:36<06:21,  1.68s/it]predicting train subjects:  21%|██        | 59/285 [01:38<06:30,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [01:40<06:43,  1.79s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:22,  1.71s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:25,  1.73s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<06:32,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:23,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:19,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:19,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<06:03,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:02,  1.68s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:03,  1.69s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:13,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:57,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:59,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:59,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:08<06:05,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:55,  1.71s/it]predicting train subjects:  27%|██▋       | 78/285 [02:11<05:43,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:40,  1.65s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:16<05:32,  1.63s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:32,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:29,  1.63s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:25,  1.62s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:27,  1.64s/it]predicting train subjects:  30%|███       | 86/285 [02:24<05:38,  1.70s/it]predicting train subjects:  31%|███       | 87/285 [02:26<05:40,  1.72s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:31,  1.68s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:31,  1.69s/it]predicting train subjects:  32%|███▏      | 90/285 [02:31<05:34,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:33<05:24,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:32,  1.72s/it]predicting train subjects:  33%|███▎      | 93/285 [02:36<05:22,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:38<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:27,  1.72s/it]predicting train subjects:  34%|███▎      | 96/285 [02:41<05:28,  1.74s/it]predicting train subjects:  34%|███▍      | 97/285 [02:43<05:26,  1.74s/it]predicting train subjects:  34%|███▍      | 98/285 [02:45<05:22,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:48<05:21,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:50<05:08,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:10,  1.70s/it]predicting train subjects:  36%|███▌      | 103/285 [02:53<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:02,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:07,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<04:56,  1.66s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<04:56,  1.66s/it]predicting train subjects:  38%|███▊      | 108/285 [03:01<04:52,  1.65s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<04:52,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<04:57,  1.70s/it]predicting train subjects:  39%|███▉      | 111/285 [03:06<04:48,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<04:49,  1.67s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:50,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:11<04:48,  1.69s/it]predicting train subjects:  40%|████      | 115/285 [03:13<04:51,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:52,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:42,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:18<04:34,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:20<04:43,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:34,  1.66s/it]predicting train subjects:  42%|████▏     | 121/285 [03:23<04:28,  1.64s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:14,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:27<04:02,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<03:54,  1.47s/it]predicting train subjects:  44%|████▍     | 126/285 [03:30<03:50,  1.45s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:44,  1.42s/it]predicting train subjects:  45%|████▍     | 128/285 [03:33<03:49,  1.46s/it]predicting train subjects:  45%|████▌     | 129/285 [03:35<03:47,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:36<03:41,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:37<03:37,  1.41s/it]predicting train subjects:  46%|████▋     | 132/285 [03:39<03:40,  1.44s/it]predicting train subjects:  47%|████▋     | 133/285 [03:40<03:36,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:42<03:33,  1.41s/it]predicting train subjects:  47%|████▋     | 135/285 [03:43<03:28,  1.39s/it]predicting train subjects:  48%|████▊     | 136/285 [03:44<03:25,  1.38s/it]predicting train subjects:  48%|████▊     | 137/285 [03:46<03:31,  1.43s/it]predicting train subjects:  48%|████▊     | 138/285 [03:47<03:27,  1.41s/it]predicting train subjects:  49%|████▉     | 139/285 [03:49<03:31,  1.45s/it]predicting train subjects:  49%|████▉     | 140/285 [03:50<03:34,  1.48s/it]predicting train subjects:  49%|████▉     | 141/285 [03:52<03:25,  1.43s/it]predicting train subjects:  50%|████▉     | 142/285 [03:53<03:22,  1.41s/it]predicting train subjects:  50%|█████     | 143/285 [03:54<03:17,  1.39s/it]predicting train subjects:  51%|█████     | 144/285 [03:56<03:20,  1.42s/it]predicting train subjects:  51%|█████     | 145/285 [03:57<03:18,  1.42s/it]predicting train subjects:  51%|█████     | 146/285 [03:59<03:22,  1.46s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:00<03:15,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:02<03:16,  1.44s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:03<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:04<03:07,  1.39s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:06<03:11,  1.43s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:07<03:06,  1.40s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:08<03:02,  1.39s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:10<03:07,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:11<03:03,  1.41s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:13<03:08,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:14<03:01,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:16<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:17<02:56,  1.40s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:18<02:53,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:20<02:56,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:21<02:53,  1.41s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:23<02:56,  1.44s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:24<02:51,  1.42s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:26<02:48,  1.40s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:27<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:29<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:30<02:48,  1.44s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:31<02:43,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:33<02:39,  1.39s/it]predicting train subjects:  60%|██████    | 171/285 [04:34<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:35<02:35,  1.38s/it]predicting train subjects:  61%|██████    | 173/285 [04:37<02:33,  1.37s/it]predicting train subjects:  61%|██████    | 174/285 [04:38<02:31,  1.36s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:40<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:41<02:38,  1.45s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:42<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:44<02:28,  1.39s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:45<02:26,  1.38s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:47<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:49<02:38,  1.52s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:50<02:38,  1.54s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:51<02:30,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:53<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:54<02:21,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:56<02:31,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:58<02:37,  1.60s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:00<02:40,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:01<02:31,  1.57s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:02<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:04<02:24,  1.53s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:05<02:23,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:07<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:08<02:10,  1.44s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:09<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:11<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:13<02:20,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:15<02:22,  1.64s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:16<02:12,  1.54s/it]predicting train subjects:  70%|███████   | 200/285 [05:17<02:06,  1.48s/it]predicting train subjects:  71%|███████   | 201/285 [05:19<02:10,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:21<02:08,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:22<02:07,  1.56s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:24<02:00,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:25<01:56,  1.45s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:26<01:51,  1.41s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:28<01:58,  1.52s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:30<02:03,  1.61s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:32<02:05,  1.65s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:33<01:55,  1.54s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:34<01:50,  1.49s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:36<01:49,  1.50s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:37<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:39<01:47,  1.51s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:41<01:50,  1.58s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:42<01:43,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:44<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:45<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:47<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:48<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:50<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:51<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:53<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:54<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:56<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:57<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:59<01:32,  1.60s/it]predicting train subjects:  80%|████████  | 228/285 [06:01<01:32,  1.63s/it]predicting train subjects:  80%|████████  | 229/285 [06:02<01:29,  1.60s/it]predicting train subjects:  81%|████████  | 230/285 [06:04<01:24,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:05<01:20,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:07<01:19,  1.51s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:08<01:15,  1.45s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:10<01:17,  1.53s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:11<01:13,  1.47s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:13<01:16,  1.56s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:14<01:17,  1.61s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:16<01:17,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:18<01:14,  1.62s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:19<01:08,  1.53s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:20<01:05,  1.48s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:22<01:01,  1.43s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:23<00:58,  1.39s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:25<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:26<00:57,  1.44s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:28<01:00,  1.54s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:30<01:00,  1.60s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:31<00:58,  1.59s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:32<00:54,  1.51s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:34<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:35<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:37<00:46,  1.40s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:38<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:40<00:48,  1.58s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:42<00:46,  1.56s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:43<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [06:44<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [06:46<00:41,  1.55s/it]predicting train subjects:  91%|█████████ | 259/285 [06:48<00:40,  1.56s/it]predicting train subjects:  91%|█████████ | 260/285 [06:49<00:36,  1.46s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:50<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:51<00:32,  1.39s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:53<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:55<00:31,  1.52s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:56<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:58<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:59<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:01<00:26,  1.56s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:03<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:04<00:22,  1.49s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:05<00:20,  1.44s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:07<00:19,  1.48s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:08<00:17,  1.44s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:09<00:15,  1.40s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:11<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:13<00:14,  1.57s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:14<00:11,  1.48s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:16<00:10,  1.45s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:17<00:08,  1.49s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:18<00:07,  1.44s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:20<00:05,  1.41s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:21<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:23<00:03,  1.51s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:25<00:01,  1.57s/it]predicting train subjects: 100%|██████████| 285/285 [07:26<00:00,  1.63s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:02,  1.70s/it]Loading train:   1%|          | 2/285 [00:03<07:27,  1.58s/it]Loading train:   1%|          | 3/285 [00:04<07:31,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:05<07:04,  1.51s/it]Loading train:   2%|▏         | 5/285 [00:07<07:19,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:09<07:02,  1.52s/it]Loading train:   2%|▏         | 7/285 [00:10<07:11,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:12<07:06,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:14<07:34,  1.65s/it]Loading train:   4%|▎         | 10/285 [00:15<07:00,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:16,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<05:57,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:18<05:26,  1.20s/it]Loading train:   5%|▍         | 14/285 [00:19<05:27,  1.21s/it]Loading train:   5%|▌         | 15/285 [00:21<05:44,  1.28s/it]Loading train:   6%|▌         | 16/285 [00:22<05:35,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:23<05:35,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:24<05:31,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:25<05:18,  1.20s/it]Loading train:   7%|▋         | 20/285 [00:26<05:05,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:28<05:36,  1.27s/it]Loading train:   8%|▊         | 22/285 [00:29<05:16,  1.20s/it]Loading train:   8%|▊         | 23/285 [00:30<05:23,  1.24s/it]Loading train:   8%|▊         | 24/285 [00:31<04:58,  1.14s/it]Loading train:   9%|▉         | 25/285 [00:33<05:12,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:34<05:17,  1.23s/it]Loading train:   9%|▉         | 27/285 [00:35<05:00,  1.16s/it]Loading train:  10%|▉         | 28/285 [00:36<05:06,  1.19s/it]Loading train:  10%|█         | 29/285 [00:37<04:57,  1.16s/it]Loading train:  11%|█         | 30/285 [00:38<04:56,  1.16s/it]Loading train:  11%|█         | 31/285 [00:40<05:01,  1.19s/it]Loading train:  11%|█         | 32/285 [00:41<04:40,  1.11s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:41,  1.12s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:45,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:50,  1.16s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:52,  1.18s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:48,  1.16s/it]Loading train:  13%|█▎        | 38/285 [00:48<04:53,  1.19s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:45,  1.16s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:37,  1.13s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:29,  1.11s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:28,  1.10s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:24,  1.09s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:43,  1.18s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:19,  1.08s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:30,  1.13s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:17,  1.08s/it]Loading train:  17%|█▋        | 48/285 [00:59<04:10,  1.05s/it]Loading train:  17%|█▋        | 49/285 [01:00<04:22,  1.11s/it]Loading train:  18%|█▊        | 50/285 [01:01<04:21,  1.11s/it]Loading train:  18%|█▊        | 51/285 [01:02<04:27,  1.14s/it]Loading train:  18%|█▊        | 52/285 [01:03<04:17,  1.10s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:15,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:20,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:10,  1.09s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:05,  1.07s/it]Loading train:  20%|██        | 57/285 [01:08<03:56,  1.04s/it]Loading train:  20%|██        | 58/285 [01:10<04:07,  1.09s/it]Loading train:  21%|██        | 59/285 [01:11<04:17,  1.14s/it]Loading train:  21%|██        | 60/285 [01:12<04:20,  1.16s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:16,  1.14s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:08,  1.11s/it]Loading train:  22%|██▏       | 63/285 [01:15<04:10,  1.13s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:36,  1.25s/it]Loading train:  23%|██▎       | 65/285 [01:19<04:58,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:05,  1.39s/it]Loading train:  24%|██▎       | 67/285 [01:21<04:41,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:22<04:25,  1.22s/it]Loading train:  24%|██▍       | 69/285 [01:23<04:26,  1.23s/it]Loading train:  25%|██▍       | 70/285 [01:25<04:25,  1.24s/it]Loading train:  25%|██▍       | 71/285 [01:26<04:13,  1.19s/it]Loading train:  25%|██▌       | 72/285 [01:27<04:14,  1.20s/it]Loading train:  26%|██▌       | 73/285 [01:28<04:10,  1.18s/it]Loading train:  26%|██▌       | 74/285 [01:29<04:01,  1.15s/it]Loading train:  26%|██▋       | 75/285 [01:30<04:02,  1.15s/it]Loading train:  27%|██▋       | 76/285 [01:31<03:56,  1.13s/it]Loading train:  27%|██▋       | 77/285 [01:32<03:49,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:33<03:45,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:35<03:47,  1.10s/it]Loading train:  28%|██▊       | 80/285 [01:36<03:51,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:37<03:55,  1.16s/it]Loading train:  29%|██▉       | 82/285 [01:38<03:46,  1.12s/it]Loading train:  29%|██▉       | 83/285 [01:39<03:46,  1.12s/it]Loading train:  29%|██▉       | 84/285 [01:40<03:43,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:41<03:43,  1.12s/it]Loading train:  30%|███       | 86/285 [01:43<03:55,  1.18s/it]Loading train:  31%|███       | 87/285 [01:44<03:56,  1.19s/it]Loading train:  31%|███       | 88/285 [01:45<03:42,  1.13s/it]Loading train:  31%|███       | 89/285 [01:46<03:43,  1.14s/it]Loading train:  32%|███▏      | 90/285 [01:47<03:47,  1.17s/it]Loading train:  32%|███▏      | 91/285 [01:48<03:39,  1.13s/it]Loading train:  32%|███▏      | 92/285 [01:50<03:41,  1.15s/it]Loading train:  33%|███▎      | 93/285 [01:51<03:39,  1.14s/it]Loading train:  33%|███▎      | 94/285 [01:52<03:40,  1.15s/it]Loading train:  33%|███▎      | 95/285 [01:53<03:38,  1.15s/it]Loading train:  34%|███▎      | 96/285 [01:54<03:34,  1.13s/it]Loading train:  34%|███▍      | 97/285 [01:55<03:37,  1.16s/it]Loading train:  34%|███▍      | 98/285 [01:56<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:57<03:25,  1.10s/it]Loading train:  35%|███▌      | 100/285 [01:59<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [02:00<03:19,  1.09s/it]Loading train:  36%|███▌      | 102/285 [02:01<03:23,  1.11s/it]Loading train:  36%|███▌      | 103/285 [02:02<03:19,  1.09s/it]Loading train:  36%|███▋      | 104/285 [02:03<03:20,  1.11s/it]Loading train:  37%|███▋      | 105/285 [02:04<03:17,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:05<03:16,  1.10s/it]Loading train:  38%|███▊      | 107/285 [02:06<03:10,  1.07s/it]Loading train:  38%|███▊      | 108/285 [02:07<03:05,  1.05s/it]Loading train:  38%|███▊      | 109/285 [02:08<03:08,  1.07s/it]Loading train:  39%|███▊      | 110/285 [02:09<03:09,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:10<03:06,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:12<03:10,  1.10s/it]Loading train:  40%|███▉      | 113/285 [02:13<03:05,  1.08s/it]Loading train:  40%|████      | 114/285 [02:14<03:02,  1.06s/it]Loading train:  40%|████      | 115/285 [02:15<03:04,  1.08s/it]Loading train:  41%|████      | 116/285 [02:16<03:03,  1.09s/it]Loading train:  41%|████      | 117/285 [02:17<03:00,  1.08s/it]Loading train:  41%|████▏     | 118/285 [02:18<03:00,  1.08s/it]Loading train:  42%|████▏     | 119/285 [02:19<02:57,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:20<03:08,  1.14s/it]Loading train:  42%|████▏     | 121/285 [02:22<03:26,  1.26s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:26,  1.27s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:27,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:25<03:12,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:26<02:59,  1.12s/it]Loading train:  44%|████▍     | 126/285 [02:27<02:50,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:28<02:45,  1.05s/it]Loading train:  45%|████▍     | 128/285 [02:29<02:42,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:30<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:31<02:30,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:32<02:24,  1.06it/s]Loading train:  46%|████▋     | 132/285 [02:33<02:19,  1.10it/s]Loading train:  47%|████▋     | 133/285 [02:34<02:21,  1.07it/s]Loading train:  47%|████▋     | 134/285 [02:35<02:25,  1.03it/s]Loading train:  47%|████▋     | 135/285 [02:36<02:29,  1.00it/s]Loading train:  48%|████▊     | 136/285 [02:37<02:34,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:38<02:42,  1.10s/it]Loading train:  48%|████▊     | 138/285 [02:40<02:48,  1.14s/it]Loading train:  49%|████▉     | 139/285 [02:41<02:49,  1.16s/it]Loading train:  49%|████▉     | 140/285 [02:42<02:42,  1.12s/it]Loading train:  49%|████▉     | 141/285 [02:43<02:35,  1.08s/it]Loading train:  50%|████▉     | 142/285 [02:44<02:35,  1.09s/it]Loading train:  50%|█████     | 143/285 [02:45<02:32,  1.08s/it]Loading train:  51%|█████     | 144/285 [02:46<02:38,  1.13s/it]Loading train:  51%|█████     | 145/285 [02:48<02:51,  1.22s/it]Loading train:  51%|█████     | 146/285 [02:49<02:44,  1.19s/it]Loading train:  52%|█████▏    | 147/285 [02:50<02:43,  1.19s/it]Loading train:  52%|█████▏    | 148/285 [02:51<02:41,  1.18s/it]Loading train:  52%|█████▏    | 149/285 [02:53<03:00,  1.33s/it]Loading train:  53%|█████▎    | 150/285 [02:54<02:54,  1.29s/it]Loading train:  53%|█████▎    | 151/285 [02:55<02:46,  1.24s/it]Loading train:  53%|█████▎    | 152/285 [02:56<02:42,  1.22s/it]Loading train:  54%|█████▎    | 153/285 [02:57<02:35,  1.18s/it]Loading train:  54%|█████▍    | 154/285 [02:59<02:32,  1.17s/it]Loading train:  54%|█████▍    | 155/285 [03:00<02:26,  1.12s/it]Loading train:  55%|█████▍    | 156/285 [03:01<02:26,  1.14s/it]Loading train:  55%|█████▌    | 157/285 [03:02<02:19,  1.09s/it]Loading train:  55%|█████▌    | 158/285 [03:03<02:17,  1.08s/it]Loading train:  56%|█████▌    | 159/285 [03:04<02:15,  1.08s/it]Loading train:  56%|█████▌    | 160/285 [03:05<02:15,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [03:06<02:20,  1.13s/it]Loading train:  57%|█████▋    | 162/285 [03:07<02:21,  1.15s/it]Loading train:  57%|█████▋    | 163/285 [03:09<02:23,  1.18s/it]Loading train:  58%|█████▊    | 164/285 [03:10<02:21,  1.17s/it]Loading train:  58%|█████▊    | 165/285 [03:11<02:12,  1.11s/it]Loading train:  58%|█████▊    | 166/285 [03:12<02:13,  1.12s/it]Loading train:  59%|█████▊    | 167/285 [03:13<02:12,  1.12s/it]Loading train:  59%|█████▉    | 168/285 [03:14<02:07,  1.09s/it]Loading train:  59%|█████▉    | 169/285 [03:15<02:08,  1.11s/it]Loading train:  60%|█████▉    | 170/285 [03:16<02:05,  1.09s/it]Loading train:  60%|██████    | 171/285 [03:17<02:02,  1.08s/it]Loading train:  60%|██████    | 172/285 [03:18<02:05,  1.11s/it]Loading train:  61%|██████    | 173/285 [03:20<02:06,  1.13s/it]Loading train:  61%|██████    | 174/285 [03:21<02:07,  1.15s/it]Loading train:  61%|██████▏   | 175/285 [03:22<02:05,  1.14s/it]Loading train:  62%|██████▏   | 176/285 [03:23<02:02,  1.12s/it]Loading train:  62%|██████▏   | 177/285 [03:24<02:02,  1.13s/it]Loading train:  62%|██████▏   | 178/285 [03:25<02:00,  1.12s/it]Loading train:  63%|██████▎   | 179/285 [03:26<01:58,  1.12s/it]Loading train:  63%|██████▎   | 180/285 [03:28<02:01,  1.16s/it]Loading train:  64%|██████▎   | 181/285 [03:29<01:59,  1.15s/it]Loading train:  64%|██████▍   | 182/285 [03:30<01:57,  1.14s/it]Loading train:  64%|██████▍   | 183/285 [03:31<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [03:32<01:51,  1.11s/it]Loading train:  65%|██████▍   | 185/285 [03:33<01:44,  1.05s/it]Loading train:  65%|██████▌   | 186/285 [03:35<01:59,  1.21s/it]Loading train:  66%|██████▌   | 187/285 [03:36<01:57,  1.20s/it]Loading train:  66%|██████▌   | 188/285 [03:37<01:57,  1.21s/it]Loading train:  66%|██████▋   | 189/285 [03:38<01:53,  1.18s/it]Loading train:  67%|██████▋   | 190/285 [03:39<01:45,  1.11s/it]Loading train:  67%|██████▋   | 191/285 [03:40<01:43,  1.10s/it]Loading train:  67%|██████▋   | 192/285 [03:41<01:47,  1.15s/it]Loading train:  68%|██████▊   | 193/285 [03:42<01:45,  1.15s/it]Loading train:  68%|██████▊   | 194/285 [03:44<01:48,  1.20s/it]Loading train:  68%|██████▊   | 195/285 [03:45<01:45,  1.18s/it]Loading train:  69%|██████▉   | 196/285 [03:46<01:45,  1.19s/it]Loading train:  69%|██████▉   | 197/285 [03:47<01:46,  1.21s/it]Loading train:  69%|██████▉   | 198/285 [03:49<01:44,  1.20s/it]Loading train:  70%|██████▉   | 199/285 [03:50<01:37,  1.14s/it]Loading train:  70%|███████   | 200/285 [03:51<01:35,  1.12s/it]Loading train:  71%|███████   | 201/285 [03:52<01:37,  1.17s/it]Loading train:  71%|███████   | 202/285 [03:53<01:37,  1.17s/it]Loading train:  71%|███████   | 203/285 [03:54<01:40,  1.23s/it]Loading train:  72%|███████▏  | 204/285 [03:56<01:39,  1.23s/it]Loading train:  72%|███████▏  | 205/285 [03:57<01:35,  1.19s/it]Loading train:  72%|███████▏  | 206/285 [03:58<01:28,  1.12s/it]Loading train:  73%|███████▎  | 207/285 [03:59<01:29,  1.15s/it]Loading train:  73%|███████▎  | 208/285 [04:00<01:30,  1.18s/it]Loading train:  73%|███████▎  | 209/285 [04:01<01:28,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [04:02<01:26,  1.16s/it]Loading train:  74%|███████▍  | 211/285 [04:04<01:28,  1.20s/it]Loading train:  74%|███████▍  | 212/285 [04:05<01:23,  1.15s/it]Loading train:  75%|███████▍  | 213/285 [04:06<01:22,  1.15s/it]Loading train:  75%|███████▌  | 214/285 [04:07<01:20,  1.14s/it]Loading train:  75%|███████▌  | 215/285 [04:08<01:20,  1.15s/it]Loading train:  76%|███████▌  | 216/285 [04:09<01:15,  1.09s/it]Loading train:  76%|███████▌  | 217/285 [04:11<01:21,  1.20s/it]Loading train:  76%|███████▋  | 218/285 [04:12<01:24,  1.26s/it]Loading train:  77%|███████▋  | 219/285 [04:13<01:23,  1.27s/it]Loading train:  77%|███████▋  | 220/285 [04:15<01:21,  1.25s/it]Loading train:  78%|███████▊  | 221/285 [04:16<01:18,  1.23s/it]Loading train:  78%|███████▊  | 222/285 [04:17<01:15,  1.19s/it]Loading train:  78%|███████▊  | 223/285 [04:18<01:12,  1.17s/it]Loading train:  79%|███████▊  | 224/285 [04:19<01:16,  1.26s/it]Loading train:  79%|███████▉  | 225/285 [04:21<01:13,  1.23s/it]Loading train:  79%|███████▉  | 226/285 [04:22<01:12,  1.24s/it]Loading train:  80%|███████▉  | 227/285 [04:23<01:12,  1.25s/it]Loading train:  80%|████████  | 228/285 [04:24<01:10,  1.24s/it]Loading train:  80%|████████  | 229/285 [04:26<01:09,  1.23s/it]Loading train:  81%|████████  | 230/285 [04:27<01:04,  1.18s/it]Loading train:  81%|████████  | 231/285 [04:28<00:59,  1.10s/it]Loading train:  81%|████████▏ | 232/285 [04:29<00:58,  1.10s/it]Loading train:  82%|████████▏ | 233/285 [04:30<00:58,  1.13s/it]Loading train:  82%|████████▏ | 234/285 [04:31<01:01,  1.21s/it]Loading train:  82%|████████▏ | 235/285 [04:32<00:58,  1.16s/it]Loading train:  83%|████████▎ | 236/285 [04:33<00:57,  1.17s/it]Loading train:  83%|████████▎ | 237/285 [04:35<00:57,  1.20s/it]Loading train:  84%|████████▎ | 238/285 [04:36<00:57,  1.22s/it]Loading train:  84%|████████▍ | 239/285 [04:37<00:57,  1.26s/it]Loading train:  84%|████████▍ | 240/285 [04:39<00:57,  1.27s/it]Loading train:  85%|████████▍ | 241/285 [04:40<00:52,  1.20s/it]Loading train:  85%|████████▍ | 242/285 [04:41<00:49,  1.15s/it]Loading train:  85%|████████▌ | 243/285 [04:42<00:48,  1.16s/it]Loading train:  86%|████████▌ | 244/285 [04:43<00:49,  1.21s/it]Loading train:  86%|████████▌ | 245/285 [04:45<00:50,  1.27s/it]Loading train:  86%|████████▋ | 246/285 [04:46<00:50,  1.30s/it]Loading train:  87%|████████▋ | 247/285 [04:47<00:49,  1.30s/it]Loading train:  87%|████████▋ | 248/285 [04:48<00:46,  1.27s/it]Loading train:  87%|████████▋ | 249/285 [04:49<00:42,  1.18s/it]Loading train:  88%|████████▊ | 250/285 [04:51<00:41,  1.17s/it]Loading train:  88%|████████▊ | 251/285 [04:52<00:40,  1.18s/it]Loading train:  88%|████████▊ | 252/285 [04:53<00:40,  1.24s/it]Loading train:  89%|████████▉ | 253/285 [04:54<00:40,  1.26s/it]Loading train:  89%|████████▉ | 254/285 [04:56<00:38,  1.23s/it]Loading train:  89%|████████▉ | 255/285 [04:57<00:35,  1.19s/it]Loading train:  90%|████████▉ | 256/285 [04:58<00:32,  1.12s/it]Loading train:  90%|█████████ | 257/285 [04:59<00:31,  1.12s/it]Loading train:  91%|█████████ | 258/285 [05:00<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [05:01<00:31,  1.19s/it]Loading train:  91%|█████████ | 260/285 [05:02<00:28,  1.13s/it]Loading train:  92%|█████████▏| 261/285 [05:03<00:26,  1.10s/it]Loading train:  92%|█████████▏| 262/285 [05:04<00:25,  1.09s/it]Loading train:  92%|█████████▏| 263/285 [05:06<00:24,  1.12s/it]Loading train:  93%|█████████▎| 264/285 [05:07<00:24,  1.17s/it]Loading train:  93%|█████████▎| 265/285 [05:08<00:22,  1.13s/it]Loading train:  93%|█████████▎| 266/285 [05:09<00:22,  1.18s/it]Loading train:  94%|█████████▎| 267/285 [05:10<00:20,  1.12s/it]Loading train:  94%|█████████▍| 268/285 [05:11<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [05:13<00:18,  1.14s/it]Loading train:  95%|█████████▍| 270/285 [05:13<00:16,  1.07s/it]Loading train:  95%|█████████▌| 271/285 [05:15<00:15,  1.08s/it]Loading train:  95%|█████████▌| 272/285 [05:16<00:14,  1.10s/it]Loading train:  96%|█████████▌| 273/285 [05:17<00:13,  1.11s/it]Loading train:  96%|█████████▌| 274/285 [05:18<00:12,  1.11s/it]Loading train:  96%|█████████▋| 275/285 [05:19<00:11,  1.19s/it]Loading train:  97%|█████████▋| 276/285 [05:20<00:10,  1.18s/it]Loading train:  97%|█████████▋| 277/285 [05:22<00:09,  1.19s/it]Loading train:  98%|█████████▊| 278/285 [05:23<00:07,  1.11s/it]Loading train:  98%|█████████▊| 279/285 [05:24<00:06,  1.10s/it]Loading train:  98%|█████████▊| 280/285 [05:25<00:05,  1.08s/it]Loading train:  99%|█████████▊| 281/285 [05:26<00:04,  1.03s/it]Loading train:  99%|█████████▉| 282/285 [05:27<00:03,  1.06s/it]Loading train:  99%|█████████▉| 283/285 [05:28<00:02,  1.14s/it]Loading train: 100%|█████████▉| 284/285 [05:29<00:01,  1.15s/it]Loading train: 100%|██████████| 285/285 [05:30<00:00,  1.13s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:04, 58.76it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:04, 59.90it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:04, 61.29it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:03, 65.78it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:03, 75.16it/s]concatenating: train:  20%|██        | 57/285 [00:00<00:02, 89.30it/s]concatenating: train:  26%|██▋       | 75/285 [00:00<00:02, 104.57it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 103.65it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 90.47it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:02, 81.17it/s]concatenating: train:  42%|████▏     | 121/285 [00:01<00:01, 85.04it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:01, 86.27it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 95.11it/s]concatenating: train:  54%|█████▍    | 155/285 [00:01<00:01, 98.21it/s]concatenating: train:  58%|█████▊    | 166/285 [00:01<00:01, 83.84it/s]concatenating: train:  62%|██████▏   | 176/285 [00:01<00:01, 80.36it/s]concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 90.00it/s]concatenating: train:  70%|███████   | 200/285 [00:02<00:00, 94.34it/s]concatenating: train:  74%|███████▍  | 211/285 [00:02<00:00, 88.87it/s]concatenating: train:  78%|███████▊  | 222/285 [00:02<00:00, 92.52it/s]concatenating: train:  81%|████████▏ | 232/285 [00:02<00:00, 81.57it/s]concatenating: train:  86%|████████▌ | 245/285 [00:02<00:00, 91.05it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 82.56it/s]concatenating: train:  94%|█████████▍| 269/285 [00:02<00:00, 93.29it/s]concatenating: train:  98%|█████████▊| 280/285 [00:03<00:00, 85.96it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 91.63it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.91s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.75s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 46.78it/s]2019-07-11 07:22:26.551565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:22:26.551673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:22:26.551689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:22:26.551697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:22:26.552123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.19it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.94it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.62it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.29it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.08it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.47it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.51it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.35it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.71it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.93it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.73it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.60it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.07it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.19it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.08it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.17it/s]
Epoch 00049: val_mDice did not improve from 0.59600
Restoring model weights from the end of the best epoch
Epoch 00049: early stopping
{'val_loss': [2.2583234196617488, 1.2727206207457042, 1.000662122453962, 1.1601441587720598, 1.096264986764817, 1.1236297403063094, 0.9497880140940348, 0.9567636251449585, 0.9046741383416312, 0.9217919224784488, 0.9358623992829096, 0.987044958841233, 0.9460659367697579, 0.9342897562753587, 0.9154965650467646, 0.9302926517668224, 0.9286471435001918, 0.9568560066677275, 0.9424565973735991, 0.9425035317738851, 0.9066836606888544, 0.8743866852351597, 0.9258696351732526, 0.8643732808885121, 0.9022536675135294, 0.8866671380542573, 0.8743580977121989, 0.8935842854636056, 0.8184624967120943, 0.8655322279248919, 0.8916659468696231, 0.8702156146367391, 0.8695164237703595, 0.8188400665918986, 0.8703208764394125, 0.795483566465832, 0.853646301087879, 0.837273773692903, 0.8612939062572661, 0.8325394789377848, 0.7618084067390078, 0.7950267280851092, 0.7719912926355997, 0.7878565958568028, 0.7820196151733398, 0.7427146661849249, 0.7897680714016869, 0.7476950316202073, 0.8066485722859701], 'val_acc': [0.9066094301995777, 0.9163278653508141, 0.9313988288243612, 0.9218291980879647, 0.9231250229335967, 0.925485372543335, 0.943766040461404, 0.9467216105688185, 0.9465659601347787, 0.9462866385777792, 0.9410416852860224, 0.9432028532028198, 0.9453274039995103, 0.945773837112245, 0.9402770172981989, 0.944647437050229, 0.9342101500147865, 0.9468727282115391, 0.9447435679889861, 0.9420924725986662, 0.9436858722141811, 0.945320515405564, 0.9443910462515694, 0.9464972331410363, 0.9424061491375878, 0.9427358025596255, 0.9455173980622065, 0.9462706020900181, 0.9456685213815599, 0.9445604653585524, 0.945446423121861, 0.9443063452130273, 0.9432646575428191, 0.9421337246894836, 0.9458951723007929, 0.9457509091922215, 0.9452152053515116, 0.9450823976880028, 0.9458768140702021, 0.9377083125568572, 0.9440041383107504, 0.9409317516145252, 0.9426030431474958, 0.9438141272181556, 0.9447046944073269, 0.9459958587374006, 0.9456478839828855, 0.9456181526184082, 0.9449336330095927], 'val_mDice': [0.18507098259786808, 0.4566716065719014, 0.5728558929903167, 0.4733736825486024, 0.5023143007641747, 0.4956143235876447, 0.5880640344250769, 0.585765803676276, 0.5960006962219874, 0.5903375861900193, 0.5785945253003211, 0.5440858813623587, 0.5782845236715817, 0.5807822116074108, 0.5840178506360167, 0.574320215909254, 0.5727427883871964, 0.5667473840571585, 0.5700554989633106, 0.5633984708360263, 0.5690905533376194, 0.5931905667696681, 0.554111565152804, 0.5896190644374916, 0.5756967525397029, 0.5789925418794155, 0.5713185850708258, 0.560115735268309, 0.5869692454025859, 0.5620642387796015, 0.5594650441337199, 0.5741398710580099, 0.5880252944216842, 0.5783114296694597, 0.5623618059215092, 0.5866646113849822, 0.5542547720528784, 0.5757063793994132, 0.5546545223111198, 0.564389284167971, 0.5860706372630029, 0.5715344397439843, 0.577719913706893, 0.5685963840002105, 0.5624807079633077, 0.5887597150036267, 0.5562852974094096, 0.5836562015825794, 0.5571203622080031], 'loss': [2.6107965854406125, 0.8491057549020287, 0.5376722291068854, 0.4783951359112782, 0.4479360945920667, 0.43000650293270426, 0.4162045799745906, 0.40662656835055383, 0.39935861008806633, 0.38692903334243645, 0.3800031288536109, 0.37740826828529866, 0.3709581006301812, 0.3639254148224312, 0.3622490293618363, 0.3588213722313303, 0.3543097832677726, 0.35212544992591965, 0.3476705560282933, 0.34449124035174294, 0.3427795561805083, 0.3398529390494029, 0.3380738994749796, 0.33736173271650244, 0.3355889744742059, 0.33273563859364835, 0.3295462654980019, 0.3290577525057865, 0.32591615965170095, 0.32410993358522155, 0.3229576727375029, 0.3212702273920319, 0.32065774813791403, 0.3178401058157308, 0.3159491192152304, 0.31401666002005124, 0.31494981124034754, 0.313328529515431, 0.31204535594812954, 0.30973523651815826, 0.30795659011376025, 0.3088928293074076, 0.309083900735262, 0.30783162431632344, 0.30607292125605196, 0.3053767454056513, 0.3028211224187149, 0.3015225287207248, 0.3003256975547275], 'acc': [0.6371871553618531, 0.8841237231143895, 0.8935722918875396, 0.8979242898628664, 0.9017765409849456, 0.9063640754531292, 0.9104629378454842, 0.9158687438490488, 0.9250321862714608, 0.9336830666236664, 0.9356896344903395, 0.9360477044009188, 0.9368074628137912, 0.937472773306122, 0.937681111993876, 0.9376783291912502, 0.9383686639703214, 0.9385911607549258, 0.939084049810535, 0.9393535402093707, 0.9396520852238222, 0.9397855324048354, 0.9399980160457816, 0.940099183238033, 0.9402427069939053, 0.9405448501202466, 0.9408599825201408, 0.9410422789308178, 0.94128194693221, 0.9414410434500983, 0.9414726008057985, 0.9415802366245867, 0.9416982725633232, 0.9418302822807103, 0.9422157911498675, 0.942291405358617, 0.9421617531560394, 0.9423758407675142, 0.9425696506536096, 0.9425859613089472, 0.9428558227458349, 0.9427374140223902, 0.9426326093380452, 0.9426978135214666, 0.9430058111982674, 0.9430854799018008, 0.9432382047900304, 0.9434904530831149, 0.9433919262375839], 'mDice': [0.1288498582532807, 0.4314557634752243, 0.568818393368608, 0.605668737809277, 0.6251723332420718, 0.6370230709883619, 0.6463173000665904, 0.652780686416262, 0.6575702963616317, 0.6651331265123911, 0.6692201396921179, 0.6708278948340959, 0.6753182660092364, 0.6802743897402197, 0.6814252813358355, 0.6837077815224262, 0.6868581777366343, 0.6885663277730102, 0.6917059507493181, 0.693873025558807, 0.6951232284439628, 0.6972793439277133, 0.6985217469699676, 0.699012220675761, 0.7002549658328185, 0.7023695375571389, 0.7046190227918917, 0.7050905054374447, 0.7073675470129704, 0.7086916418348591, 0.709564387625942, 0.7107086678633278, 0.7111128116701986, 0.7132744351770002, 0.7147225328026788, 0.7161065945970959, 0.7154932761665758, 0.7166265018969481, 0.7176984974890747, 0.7193108562883532, 0.7206621478466668, 0.7198760887205382, 0.7197559934510922, 0.7207819140093024, 0.7220852333087785, 0.7225960639140407, 0.724525600332779, 0.7254707217561226, 0.7263527626197922]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 40)   21640       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 100)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 253,913
Trainable params: 79,073
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 1.8676 - acc: 0.7721 - mDice: 0.2660 - val_loss: 0.5910 - val_acc: 0.9280 - val_mDice: 0.5475

Epoch 00001: val_mDice improved from -inf to 0.54747, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.4834 - acc: 0.9200 - mDice: 0.6037 - val_loss: 0.4920 - val_acc: 0.9497 - val_mDice: 0.6071

Epoch 00002: val_mDice improved from 0.54747 to 0.60708, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.4079 - acc: 0.9376 - mDice: 0.6518 - val_loss: 0.4482 - val_acc: 0.9534 - val_mDice: 0.6312

Epoch 00003: val_mDice improved from 0.60708 to 0.63125, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.3788 - acc: 0.9451 - mDice: 0.6709 - val_loss: 0.4651 - val_acc: 0.9529 - val_mDice: 0.6210

Epoch 00004: val_mDice did not improve from 0.63125
Epoch 5/300
 - 15s - loss: 0.3609 - acc: 0.9471 - mDice: 0.6833 - val_loss: 0.4876 - val_acc: 0.9507 - val_mDice: 0.6109

Epoch 00005: val_mDice did not improve from 0.63125
Epoch 6/300
 - 14s - loss: 0.3461 - acc: 0.9485 - mDice: 0.6936 - val_loss: 0.4635 - val_acc: 0.9508 - val_mDice: 0.6216

Epoch 00006: val_mDice did not improve from 0.63125
Epoch 7/300
 - 14s - loss: 0.3343 - acc: 0.9494 - mDice: 0.7020 - val_loss: 0.4710 - val_acc: 0.9513 - val_mDice: 0.6191

Epoch 00007: val_mDice did not improve from 0.63125
Epoch 8/300
 - 15s - loss: 0.3273 - acc: 0.9502 - mDice: 0.7072 - val_loss: 0.4693 - val_acc: 0.9529 - val_mDice: 0.6224

Epoch 00008: val_mDice did not improve from 0.63125
Epoch 9/300
 - 15s - loss: 0.3175 - acc: 0.9510 - mDice: 0.7145 - val_loss: 0.4786 - val_acc: 0.9516 - val_mDice: 0.6137

Epoch 00009: val_mDice did not improve from 0.63125
Epoch 10/300
 - 14s - loss: 0.3126 - acc: 0.9514 - mDice: 0.7180 - val_loss: 0.4734 - val_acc: 0.9527 - val_mDice: 0.6196

Epoch 00010: val_mDice did not improve from 0.63125
Epoch 11/300
 - 14s - loss: 0.3057 - acc: 0.9519 - mDice: 0.7231 - val_loss: 0.4471 - val_acc: 0.9528 - val_mDice: 0.6297

Epoch 00011: val_mDice did not improve from 0.63125
Epoch 12/300
 - 14s - loss: 0.3004 - acc: 0.9524 - mDice: 0.7270 - val_loss: 0.4705 - val_acc: 0.9527 - val_mDice: 0.6186

Epoch 00012: val_mDice did not improve from 0.63125
Epoch 13/300
 - 14s - loss: 0.2956 - acc: 0.9527 - mDice: 0.7306 - val_loss: 0.4831 - val_acc: 0.9512 - val_mDice: 0.6108

Epoch 00013: val_mDice did not improve from 0.63125
Epoch 14/300
 - 14s - loss: 0.2924 - acc: 0.9530 - mDice: 0.7330 - val_loss: 0.4769 - val_acc: 0.9548 - val_mDice: 0.6202

Epoch 00014: val_mDice did not improve from 0.63125
Epoch 15/300
 - 14s - loss: 0.2875 - acc: 0.9533 - mDice: 0.7367 - val_loss: 0.4766 - val_acc: 0.9529 - val_mDice: 0.6168

Epoch 00015: val_mDice did not improve from 0.63125
Epoch 16/300
 - 15s - loss: 0.2849 - acc: 0.9535 - mDice: 0.7388 - val_loss: 0.4723 - val_acc: 0.9526 - val_mDice: 0.6162

Epoch 00016: val_mDice did not improve from 0.63125
Epoch 17/300
 - 15s - loss: 0.2827 - acc: 0.9538 - mDice: 0.7406 - val_loss: 0.4718 - val_acc: 0.9520 - val_mDice: 0.6171

Epoch 00017: val_mDice did not improve from 0.63125
Epoch 18/300
 - 14s - loss: 0.2780 - acc: 0.9541 - mDice: 0.7442 - val_loss: 0.4768 - val_acc: 0.9528 - val_mDice: 0.6177

Epoch 00018: val_mDice did not improve from 0.63125
Epoch 19/300
 - 14s - loss: 0.2750 - acc: 0.9542 - mDice: 0.7464 - val_loss: 0.4726 - val_acc: 0.9506 - val_mDice: 0.6160

Epoch 00019: val_mDice did not improve from 0.63125
Epoch 20/300
 - 15s - loss: 0.2724 - acc: 0.9545 - mDice: 0.7484 - val_loss: 0.4752 - val_acc: 0.9547 - val_mDice: 0.6183

Epoch 00020: val_mDice did not improve from 0.63125
Epoch 21/300
 - 15s - loss: 0.2694 - acc: 0.9547 - mDice: 0.7507 - val_loss: 0.4601 - val_acc: 0.9510 - val_mDice: 0.6247

Epoch 00021: val_mDice did not improve from 0.63125
Epoch 22/300
 - 15s - loss: 0.2697 - acc: 0.9547 - mDice: 0.7506 - val_loss: 0.4775 - val_acc: 0.9541 - val_mDice: 0.6190

Epoch 00022: val_mDice did not improve from 0.63125
Epoch 23/300
 - 15s - loss: 0.2652 - acc: 0.9550 - mDice: 0.7541 - val_loss: 0.4464 - val_acc: 0.9541 - val_mDice: 0.6322

Epoch 00023: val_mDice improved from 0.63125 to 0.63216, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 15s - loss: 0.2641 - acc: 0.9551 - mDice: 0.7550 - val_loss: 0.4786 - val_acc: 0.9530 - val_mDice: 0.6144

Epoch 00024: val_mDice did not improve from 0.63216
Epoch 25/300
 - 15s - loss: 0.2613 - acc: 0.9553 - mDice: 0.7571 - val_loss: 0.4634 - val_acc: 0.9550 - val_mDice: 0.6251

Epoch 00025: val_mDice did not improve from 0.63216
Epoch 26/300
 - 15s - loss: 0.2588 - acc: 0.9555 - mDice: 0.7592 - val_loss: 0.4892 - val_acc: 0.9546 - val_mDice: 0.6176

Epoch 00026: val_mDice did not improve from 0.63216
Epoch 27/300
 - 15s - loss: 0.2570 - acc: 0.9556 - mDice: 0.7605 - val_loss: 0.4631 - val_acc: 0.9523 - val_mDice: 0.6223

Epoch 00027: val_mDice did not improve from 0.63216
Epoch 28/300
 - 15s - loss: 0.2564 - acc: 0.9558 - mDice: 0.7611 - val_loss: 0.4583 - val_acc: 0.9555 - val_mDice: 0.6248

Epoch 00028: val_mDice did not improve from 0.63216
Epoch 29/300
 - 15s - loss: 0.2545 - acc: 0.9558 - mDice: 0.7626 - val_loss: 0.4996 - val_acc: 0.9529 - val_mDice: 0.6096

Epoch 00029: val_mDice did not improve from 0.63216
Epoch 30/300
 - 15s - loss: 0.2536 - acc: 0.9560 - mDice: 0.7634 - val_loss: 0.4659 - val_acc: 0.9537 - val_mDice: 0.6214

Epoch 00030: val_mDice did not improve from 0.63216
Epoch 31/300
 - 16s - loss: 0.2525 - acc: 0.9560 - mDice: 0.7642 - val_loss: 0.4606 - val_acc: 0.9539 - val_mDice: 0.6235

Epoch 00031: val_mDice did not improve from 0.63216
Epoch 32/300
 - 15s - loss: 0.2501 - acc: 0.9561 - mDice: 0.7661 - val_loss: 0.4538 - val_acc: 0.9535 - val_mDice: 0.6282

Epoch 00032: val_mDice did not improve from 0.63216
Epoch 33/300
 - 15s - loss: 0.2491 - acc: 0.9563 - mDice: 0.7669 - val_loss: 0.4735 - val_acc: 0.9552 - val_mDice: 0.6195

Epoch 00033: val_mDice did not improve from 0.63216
Epoch 34/300
 - 15s - loss: 0.2477 - acc: 0.9563 - mDice: 0.7680 - val_loss: 0.5022 - val_acc: 0.9541 - val_mDice: 0.6103

Epoch 00034: val_mDice did not improve from 0.63216
Epoch 35/300
 - 15s - loss: 0.2458 - acc: 0.9565 - mDice: 0.7696 - val_loss: 0.4712 - val_acc: 0.9523 - val_mDice: 0.6178

Epoch 00035: val_mDice did not improve from 0.63216
Epoch 36/300
 - 15s - loss: 0.2465 - acc: 0.9565 - mDice: 0.7689 - val_loss: 0.4663 - val_acc: 0.9547 - val_mDice: 0.6240

Epoch 00036: val_mDice did not improve from 0.63216
Epoch 37/300
 - 15s - loss: 0.2456 - acc: 0.9566 - mDice: 0.7697 - val_loss: 0.4615 - val_acc: 0.9546 - val_mDice: 0.6233

Epoch 00037: val_mDice did not improve from 0.63216
Epoch 38/300
 - 15s - loss: 0.2435 - acc: 0.9567 - mDice: 0.7714 - val_loss: 0.4657 - val_acc: 0.9528 - val_mDice: 0.6204

Epoch 00038: val_mDice did not improve from 0.63216
Epoch 39/300
 - 16s - loss: 0.2411 - acc: 0.9568 - mDice: 0.7733 - val_loss: 0.4844 - val_acc: 0.9520 - val_mDice: 0.6124

Epoch 00039: val_mDice did not improve from 0.63216
Epoch 40/300
 - 15s - loss: 0.2406 - acc: 0.9569 - mDice: 0.7737 - val_loss: 0.4595 - val_acc: 0.9533 - val_mDice: 0.6247

Epoch 00040: val_mDice did not improve from 0.63216
Epoch 41/300
 - 15s - loss: 0.2406 - acc: 0.9569 - mDice: 0.7737 - val_loss: 0.4891 - val_acc: 0.9529 - val_mDice: 0.6113

Epoch 00041: val_mDice did not improve from 0.63216
Epoch 42/300
 - 15s - loss: 0.2389 - acc: 0.9570 - mDice: 0.7752 - val_loss: 0.4634 - val_acc: 0.9535 - val_mDice: 0.6223

Epoch 00042: val_mDice did not improve from 0.63216
Epoch 43/300
 - 15s - loss: 0.2374 - acc: 0.9571 - mDice: 0.7763 - val_loss: 0.4543 - val_acc: 0.9549 - val_mDice: 0.6278

Epoch 00043: val_mDice did not improve from 0.63216
Epoch 44/300
 - 15s - loss: 0.2380 - acc: 0.9571 - mDice: 0.7759 - val_loss: 0.4817 - val_acc: 0.9546 - val_mDice: 0.6176

Epoch 00044: val_mDice did not improve from 0.63216
Epoch 45/300
 - 15s - loss: 0.2348 - acc: 0.9572 - mDice: 0.7785 - val_loss: 0.4717 - val_acc: 0.9519 - val_mDice: 0.6185

Epoch 00045: val_mDice did not improve from 0.63216
Epoch 46/300
 - 16s - loss: 0.2353 - acc: 0.9574 - mDice: 0.7780 - val_loss: 0.4634 - val_acc: 0.9520 - val_mDice: 0.6237

Epoch 00046: val_mDice did not improve from 0.63216
Epoch 47/300
 - 15s - loss: 0.2338 - acc: 0.9574 - mDice: 0.7793 - val_loss: 0.4810 - val_acc: 0.9547 - val_mDice: 0.6256

Epoch 00047: val_mDice did not improve from 0.63216
Epoch 48/300
 - 15s - loss: 0.2340 - acc: 0.9575 - mDice: 0.7791 - val_loss: 0.4691 - val_acc: 0.9538 - val_mDice: 0.6216

Epoch 00048: val_mDice did not improve from 0.63216
Epoch 49/300
 - 15s - loss: 0.2332 - acc: 0.9574 - mDice: 0.7798 - val_loss: 0.4559 - val_acc: 0.9534 - val_mDice: 0.6253

Epoch 00049: val_mDice did not improve from 0.63216
Epoch 50/300
 - 15s - loss: 0.2326 - acc: 0.9575 - mDice: 0.7803 - val_loss: 0.4458 - val_acc: 0.9539 - val_mDice: 0.6318

Epoch 00050: val_mDice did not improve from 0.63216
Epoch 51/300
 - 15s - loss: 0.2313 - acc: 0.9576 - mDice: 0.7813 - val_loss: 0.4737 - val_acc: 0.9516 - val_mDice: 0.6159

Epoch 00051: val_mDice did not improve from 0.63216
Epoch 52/300
 - 15s - loss: 0.2299 - acc: 0.9577 - mDice: 0.7825 - val_loss: 0.4647 - val_acc: 0.9508 - val_mDice: 0.6199

Epoch 00052: val_mDice did not improve from 0.63216
Epoch 53/300
 - 15s - loss: 0.2289 - acc: 0.9578 - mDice: 0.7833 - val_loss: 0.4429 - val_acc: 0.9541 - val_mDice: 0.6323

Epoch 00053: val_mDice improved from 0.63216 to 0.63233, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 16s - loss: 0.2306 - acc: 0.9577 - mDice: 0.7820 - val_loss: 0.4511 - val_acc: 0.9535 - val_mDice: 0.6279

Epoch 00054: val_mDice did not improve from 0.63233
Epoch 55/300
 - 15s - loss: 0.2293 - acc: 0.9578 - mDice: 0.7830 - val_loss: 0.4529 - val_acc: 0.9518 - val_mDice: 0.6255

Epoch 00055: val_mDice did not improve from 0.63233
Epoch 56/300
 - 15s - loss: 0.2300 - acc: 0.9577 - mDice: 0.7825 - val_loss: 0.4742 - val_acc: 0.9538 - val_mDice: 0.6177

Epoch 00056: val_mDice did not improve from 0.63233
Epoch 57/300
 - 15s - loss: 0.2281 - acc: 0.9578 - mDice: 0.7840 - val_loss: 0.4637 - val_acc: 0.9534 - val_mDice: 0.6208

Epoch 00057: val_mDice did not improve from 0.63233
Epoch 58/300
 - 15s - loss: 0.2268 - acc: 0.9579 - mDice: 0.7850 - val_loss: 0.4639 - val_acc: 0.9543 - val_mDice: 0.6210

Epoch 00058: val_mDice did not improve from 0.63233
Epoch 59/300
 - 15s - loss: 0.2263 - acc: 0.9580 - mDice: 0.7855 - val_loss: 0.4851 - val_acc: 0.9512 - val_mDice: 0.6081

Epoch 00059: val_mDice did not improve from 0.63233
Epoch 60/300
 - 15s - loss: 0.2257 - acc: 0.9580 - mDice: 0.7859 - val_loss: 0.4779 - val_acc: 0.9540 - val_mDice: 0.6133

Epoch 00060: val_mDice did not improve from 0.63233
Epoch 61/300
 - 15s - loss: 0.2259 - acc: 0.9580 - mDice: 0.7858 - val_loss: 0.4595 - val_acc: 0.9537 - val_mDice: 0.6256

Epoch 00061: val_mDice did not improve from 0.63233
Epoch 62/300
 - 16s - loss: 0.2260 - acc: 0.9580 - mDice: 0.7857 - val_loss: 0.4629 - val_acc: 0.9526 - val_mDice: 0.6233

Epoch 00062: val_mDice did not improve from 0.63233
Epoch 63/300
 - 15s - loss: 0.2238 - acc: 0.9581 - mDice: 0.7875 - val_loss: 0.4897 - val_acc: 0.9526 - val_mDice: 0.6083

Epoch 00063: val_mDice did not improve from 0.63233
Epoch 64/300
 - 15s - loss: 0.2241 - acc: 0.9582 - mDice: 0.7873 - val_loss: 0.4766 - val_acc: 0.9540 - val_mDice: 0.6149

Epoch 00064: val_mDice did not improve from 0.63233
Epoch 65/300
 - 15s - loss: 0.2240 - acc: 0.9582 - mDice: 0.7874 - val_loss: 0.4710 - val_acc: 0.9531 - val_mDice: 0.6156

Epoch 00065: val_mDice did not improve from 0.63233
Epoch 66/300
 - 15s - loss: 0.2234 - acc: 0.9582 - mDice: 0.7879 - val_loss: 0.4610 - val_acc: 0.9545 - val_mDice: 0.6250

Epoch 00066: val_mDice did not improve from 0.63233
Epoch 67/300
 - 15s - loss: 0.2252 - acc: 0.9581 - mDice: 0.7864 - val_loss: 0.5474 - val_acc: 0.9515 - val_mDice: 0.5832

Epoch 00067: val_mDice did not improve from 0.63233
Epoch 68/300
 - 15s - loss: 0.2226 - acc: 0.9582 - mDice: 0.7885 - val_loss: 0.4712 - val_acc: 0.9529 - val_mDice: 0.6184

Epoch 00068: val_mDice did not improve from 0.63233
Epoch 69/300
 - 15s - loss: 0.2236 - acc: 0.9583 - mDice: 0.7877 - val_loss: 0.4908 - val_acc: 0.9546 - val_mDice: 0.6138

Epoch 00069: val_mDice did not improve from 0.63233
Epoch 70/300
 - 16s - loss: 0.2208 - acc: 0.9584 - mDice: 0.7900 - val_loss: 0.4830 - val_acc: 0.9543 - val_mDice: 0.6137

Epoch 00070: val_mDice did not improve from 0.63233
Epoch 71/300
 - 15s - loss: 0.2210 - acc: 0.9584 - mDice: 0.7898 - val_loss: 0.4682 - val_acc: 0.9547 - val_mDice: 0.6206

Epoch 00071: val_mDice did not improve from 0.63233
Epoch 72/300
 - 15s - loss: 0.2203 - acc: 0.9584 - mDice: 0.7904 - val_loss: 0.4853 - val_acc: 0.9542 - val_mDice: 0.6119

Epoch 00072: val_mDice did not improve from 0.63233
Epoch 73/300
 - 15s - loss: 0.2197 - acc: 0.9584 - mDice: 0.7909 - val_loss: 0.4478 - val_acc: 0.9533 - val_mDice: 0.6312

Epoch 00073: val_mDice did not improve from 0.63233
Epoch 74/300
 - 15s - loss: 0.2189 - acc: 0.9586 - mDice: 0.7916 - val_loss: 0.4758 - val_acc: 0.9518 - val_mDice: 0.6170

Epoch 00074: val_mDice did not improve from 0.63233
Epoch 75/300
 - 15s - loss: 0.2187 - acc: 0.9585 - mDice: 0.7918 - val_loss: 0.4575 - val_acc: 0.9533 - val_mDice: 0.6258

Epoch 00075: val_mDice did not improve from 0.63233
Epoch 76/300
 - 15s - loss: 0.2185 - acc: 0.9586 - mDice: 0.7920 - val_loss: 0.4596 - val_acc: 0.9539 - val_mDice: 0.6237

Epoch 00076: val_mDice did not improve from 0.63233
Epoch 77/300
 - 15s - loss: 0.2177 - acc: 0.9586 - mDice: 0.7926 - val_loss: 0.4682 - val_acc: 0.9520 - val_mDice: 0.6181

Epoch 00077: val_mDice did not improve from 0.63233
Epoch 78/300
 - 15s - loss: 0.2176 - acc: 0.9586 - mDice: 0.7927 - val_loss: 0.4618 - val_acc: 0.9538 - val_mDice: 0.6222

Epoch 00078: val_mDice did not improve from 0.63233
Epoch 79/300
 - 15s - loss: 0.2186 - acc: 0.9586 - mDice: 0.7918 - val_loss: 0.5153 - val_acc: 0.9525 - val_mDice: 0.5995

Epoch 00079: val_mDice did not improve from 0.63233
Epoch 80/300
 - 15s - loss: 0.2162 - acc: 0.9587 - mDice: 0.7939 - val_loss: 0.4589 - val_acc: 0.9530 - val_mDice: 0.6244

Epoch 00080: val_mDice did not improve from 0.63233
Epoch 81/300
 - 15s - loss: 0.2169 - acc: 0.9588 - mDice: 0.7933 - val_loss: 0.4952 - val_acc: 0.9528 - val_mDice: 0.6063

Epoch 00081: val_mDice did not improve from 0.63233
Epoch 82/300
 - 15s - loss: 0.2168 - acc: 0.9588 - mDice: 0.7934 - val_loss: 0.4498 - val_acc: 0.9521 - val_mDice: 0.6311

Epoch 00082: val_mDice did not improve from 0.63233
Epoch 83/300
 - 15s - loss: 0.2158 - acc: 0.9588 - mDice: 0.7942 - val_loss: 0.4906 - val_acc: 0.9513 - val_mDice: 0.6099

Epoch 00083: val_mDice did not improve from 0.63233
Epoch 84/300
 - 15s - loss: 0.2160 - acc: 0.9588 - mDice: 0.7941 - val_loss: 0.4670 - val_acc: 0.9548 - val_mDice: 0.6196

Epoch 00084: val_mDice did not improve from 0.63233
Epoch 85/300
 - 15s - loss: 0.2160 - acc: 0.9588 - mDice: 0.7940 - val_loss: 0.4737 - val_acc: 0.9522 - val_mDice: 0.6171

Epoch 00085: val_mDice did not improve from 0.63233
Epoch 86/300
 - 15s - loss: 0.2147 - acc: 0.9588 - mDice: 0.7951 - val_loss: 0.4682 - val_acc: 0.9545 - val_mDice: 0.6185

Epoch 00086: val_mDice did not improve from 0.63233
Epoch 87/300
 - 15s - loss: 0.2135 - acc: 0.9589 - mDice: 0.7961 - val_loss: 0.4695 - val_acc: 0.9516 - val_mDice: 0.6171

Epoch 00087: val_mDice did not improve from 0.63233
Epoch 88/300
 - 15s - loss: 0.2145 - acc: 0.9589 - mDice: 0.7953 - val_loss: 0.4850 - val_acc: 0.9535 - val_mDice: 0.6110

Epoch 00088: val_mDice did not improve from 0.63233
Epoch 89/300
 - 15s - loss: 0.2149 - acc: 0.9589 - mDice: 0.7950 - val_loss: 0.4588 - val_acc: 0.9525 - val_mDice: 0.6234

Epoch 00089: val_mDice did not improve from 0.63233
Epoch 90/300
 - 15s - loss: 0.2141 - acc: 0.9589 - mDice: 0.7956 - val_loss: 0.4777 - val_acc: 0.9537 - val_mDice: 0.6171

Epoch 00090: val_mDice did not improve from 0.63233
Epoch 91/300
 - 15s - loss: 0.2129 - acc: 0.9589 - mDice: 0.7965 - val_loss: 0.5251 - val_acc: 0.9535 - val_mDice: 0.5906

Epoch 00091: val_mDice did not improve from 0.63233
Epoch 92/300
 - 15s - loss: 0.2131 - acc: 0.9590 - mDice: 0.7964 - val_loss: 0.4986 - val_acc: 0.9538 - val_mDice: 0.6069

Epoch 00092: val_mDice did not improve from 0.63233
Epoch 93/300
 - 15s - loss: 0.2143 - acc: 0.9590 - mDice: 0.7955 - val_loss: 0.4675 - val_acc: 0.9534 - val_mDice: 0.6200

Epoch 00093: val_mDice did not improve from 0.63233
Restoring model weights from the end of the best epoch
Epoch 00093: early stopping
{'val_loss': [0.5909555587688637, 0.4920446593002234, 0.44816387731935725, 0.4650741802247543, 0.48756278826537747, 0.46348061341813157, 0.4710477697116703, 0.46926317035152926, 0.4785895584015873, 0.47336423030778685, 0.447061908311684, 0.47054939829437425, 0.48310294231222994, 0.4769019914072985, 0.47657583479108756, 0.4722688241377889, 0.47184691549013447, 0.4767500831428187, 0.47264782976171826, 0.47516185378229153, 0.46010097977835374, 0.4775419634813703, 0.44642784941795816, 0.47858541304838725, 0.46340804959142673, 0.48920236120010885, 0.46313288558128823, 0.4582655719538641, 0.49955595838291017, 0.46588251177825074, 0.4605841476824031, 0.45377679377294783, 0.47351055604785514, 0.5022318799402461, 0.4712408058470188, 0.4662851857739454, 0.46150821047788226, 0.4656682194278227, 0.48442441691233457, 0.4594949680333697, 0.4890618747173075, 0.46342453976583214, 0.4543368899622443, 0.48165619606412324, 0.47172198815052735, 0.46335368982240477, 0.48097787922321084, 0.4690763257735268, 0.4559131314634611, 0.44583316888223146, 0.4736887246536809, 0.4646742463777851, 0.4428558336289901, 0.451141431344954, 0.4529303954966241, 0.47415081782047974, 0.46373808184149545, 0.46393562295583374, 0.4850690461403831, 0.4778934437469397, 0.4595466182884557, 0.46292458166623246, 0.48965688657494233, 0.4765857774452124, 0.4710295959557901, 0.46100408438197726, 0.5474390407514306, 0.47124767303466797, 0.49083163285388626, 0.48296104862703293, 0.4681957094362994, 0.48531862577246554, 0.44779193467934036, 0.4758095761251183, 0.4574708618931264, 0.4595895233101019, 0.468161551979001, 0.4618399985675705, 0.5153097194000329, 0.45887269920476986, 0.4951882991710855, 0.4497898107800404, 0.4906234178463174, 0.4670136254592981, 0.47366601295311356, 0.4681840861975814, 0.46951635223527194, 0.48504231162577366, 0.4588372041393259, 0.4777428331321844, 0.5250845777921836, 0.4985560508413688, 0.4675478092784988], 'val_acc': [0.9280333665496144, 0.9497413265638511, 0.9533507151310671, 0.9528920400742046, 0.950652453153493, 0.9508446082056567, 0.9513156460650141, 0.9529313188691378, 0.9515821667356864, 0.9526627373428984, 0.9527805021355272, 0.9527246952056885, 0.9512495298625371, 0.954829993194708, 0.9528693250437689, 0.9525635525500974, 0.9519581804728375, 0.9527949351172208, 0.9506297481126625, 0.9546771146065696, 0.9509685698834212, 0.9540614339226451, 0.9540634964431465, 0.9530180849176545, 0.9550366158591969, 0.9546378651144785, 0.9522536480226996, 0.9555180076114292, 0.9528858345314111, 0.9536998704825034, 0.9538589752586194, 0.9534705361174471, 0.9551688172963745, 0.9541358018720616, 0.9522991010596632, 0.9546915575778684, 0.954617210606623, 0.9527763564493403, 0.951974727587993, 0.9532598073922056, 0.952892051728744, 0.9534664237299445, 0.954875447563619, 0.9546109984040926, 0.9518734962580591, 0.9519974532740076, 0.954703984313837, 0.9537969754394873, 0.9534044305705491, 0.953935408392432, 0.9516462087631226, 0.9508466830466713, 0.9540759215141807, 0.9535284088976557, 0.9517763923000357, 0.9538424427948851, 0.9534230382082849, 0.9542763046712183, 0.9512288863432474, 0.9539540110353651, 0.9537060550471258, 0.9525511484572341, 0.952640012988831, 0.954024258272608, 0.9530614667764589, 0.9545428133543643, 0.9515388015262242, 0.9528631428100544, 0.9545717492449883, 0.954299013374904, 0.954703984313837, 0.9541729871787172, 0.9532701492975544, 0.9518321905722166, 0.9533114429958706, 0.9539002952628961, 0.9520160755631644, 0.9537618340060697, 0.9525118746571035, 0.9529953455791793, 0.9527908054144023, 0.9521234864629181, 0.9513342666892366, 0.954813464060842, 0.952226785308156, 0.9545366491019392, 0.9516007700445932, 0.9535263227350885, 0.9524664415993505, 0.9536916243963401, 0.9534808816856513, 0.9537928563922478, 0.9533631185579566], 'val_mDice': [0.5474690540209829, 0.6070840205560183, 0.6312460686241448, 0.6209910561918547, 0.6109326834785206, 0.6216027020742108, 0.6190740938959175, 0.6223743461363809, 0.6137326995753709, 0.6196094801306059, 0.6296594489220134, 0.6185634995306004, 0.6108197916153423, 0.6201600305860935, 0.6168488550452547, 0.616211767303211, 0.6170727600598468, 0.6177062941663092, 0.6160158718098475, 0.6183285813091853, 0.62470947164397, 0.6189960580964328, 0.6321564646406547, 0.6144211119113687, 0.6250680818238072, 0.6175715530384852, 0.6223466089983892, 0.6248435917513331, 0.609620215506527, 0.6214193571879211, 0.6234870116803899, 0.6281797239900301, 0.6195265753975128, 0.6102589731775848, 0.6177721216691939, 0.6239932162801647, 0.6232692669223807, 0.6204154048552061, 0.6123560314071911, 0.6246953493390004, 0.6112713457485817, 0.6223186254501343, 0.6277565093679801, 0.617628232060864, 0.6184852043343656, 0.6236901862661266, 0.6255710850880799, 0.6215910921549664, 0.6253317651135961, 0.6317578767265022, 0.6158701554357007, 0.6199086947814046, 0.6323346255877831, 0.6279236777534698, 0.625456671808019, 0.6176834885634523, 0.620795291895307, 0.620962404671994, 0.6081183925687268, 0.6133391817188796, 0.6256149214739241, 0.6232798039580191, 0.6083396636573962, 0.6148638398953656, 0.6155976070372086, 0.6250373501351426, 0.5832035944448503, 0.6183721436468582, 0.6138052644010362, 0.6136890430024217, 0.6205587700092593, 0.6119086479341518, 0.6311626580840383, 0.6170093517063716, 0.6258365322091726, 0.6237270082841372, 0.618067038125832, 0.622156222439345, 0.59949286523478, 0.6244433458956926, 0.6062973444688253, 0.6310838860506452, 0.6099478159536863, 0.6196404525687574, 0.6170515188291752, 0.6184809127999418, 0.6170590939468512, 0.6110087862893856, 0.6233518909475657, 0.617144144780143, 0.5905872516791913, 0.6068837978986389, 0.6199683730162722], 'loss': [1.8676193580895712, 0.4833718654630387, 0.4079246647713991, 0.3787607985084713, 0.3608622583069902, 0.346133920869941, 0.3342524801105152, 0.32730688502128774, 0.31745875594299233, 0.31257565796008446, 0.305687602968311, 0.30038754803592504, 0.29560811612401017, 0.29240688998113173, 0.2875177629515598, 0.2848672512589012, 0.2826861876443115, 0.278013596214128, 0.2749706429695292, 0.2723865522683741, 0.2694217384212138, 0.26967052942098574, 0.26516622893139336, 0.2640769851538203, 0.2613352392663961, 0.2587992091284333, 0.2570468646337586, 0.25635424283918007, 0.25446503374916907, 0.2535667358631078, 0.2524786672150801, 0.2501302035742028, 0.24911664099833797, 0.24774280883058158, 0.24577166275367532, 0.24653041934672928, 0.2455600741190573, 0.2434900427483362, 0.24112192675553273, 0.24058793288359914, 0.24059253369036157, 0.23888162585958067, 0.2373873464031538, 0.2380351263105165, 0.23476438326329474, 0.23532320751122454, 0.2337971146656572, 0.23400522753240027, 0.23321870812909562, 0.23261402143443127, 0.23134179163031715, 0.2298932910877715, 0.22887389713104084, 0.23056066356955202, 0.22925352021166392, 0.23003392755404178, 0.2281250085907495, 0.22684848013559034, 0.2263185845812865, 0.2257180262573482, 0.22586070190788282, 0.22599194222260494, 0.22384675090352302, 0.2240647637557116, 0.2239821220236688, 0.22343976760126785, 0.22517605458078, 0.22263119991851082, 0.22361261958270465, 0.22075081301549637, 0.22103785513698598, 0.2202821187514715, 0.21970883247172038, 0.21892440876363572, 0.2186737783830622, 0.21846691520929168, 0.21767616294371875, 0.21757801879540448, 0.21860668422362817, 0.21616463015901582, 0.21685817050902023, 0.2168265911105554, 0.21579223726934665, 0.2160058355204492, 0.2159824423399842, 0.21465869799047751, 0.21350194409186918, 0.21446075777583934, 0.2148554581371919, 0.2141047866864763, 0.2129367414003078, 0.2131091040700072, 0.2143018072865951], 'acc': [0.7720928086403811, 0.9200031911162703, 0.9376182323654949, 0.945079338361635, 0.9471204399309427, 0.9484802888672139, 0.9494397397927161, 0.9501720130700028, 0.9509971418981166, 0.951352701565778, 0.9519365935191617, 0.9523617458475954, 0.9526754111111615, 0.9529583226341768, 0.953290719838192, 0.9534920982289734, 0.953757847750033, 0.9541483171871367, 0.9542363760329937, 0.9544988634357667, 0.954708154016081, 0.9547234429759168, 0.9550323548526535, 0.9551352830398291, 0.9553498520056969, 0.9555426910580468, 0.955622229643763, 0.9557723633169537, 0.9558313406764873, 0.9559845177736829, 0.9559869362075541, 0.9561173710991345, 0.9562700461129803, 0.9563279964034253, 0.95654016568584, 0.9565042151350918, 0.9566014796247099, 0.9567219076524872, 0.9568398958567629, 0.9568926891362016, 0.9568979037099529, 0.9569981335834002, 0.957085786100943, 0.9570976695777557, 0.9572445057776037, 0.9573731317212916, 0.9574228177616769, 0.9574644121915438, 0.9574416941511145, 0.9575002429421824, 0.957604517338615, 0.957666997867734, 0.9577717121426144, 0.9577074214644853, 0.9577753187381561, 0.9576919929932278, 0.9578080692976092, 0.9578968354004102, 0.9579533932126041, 0.9580160751593905, 0.9580201212925223, 0.9579690219133964, 0.9581028458132125, 0.958161801442258, 0.9581800487415313, 0.9582219017005799, 0.9580818760739803, 0.9582251647570367, 0.958251591033519, 0.9583959866469932, 0.958390667368258, 0.9583851921065597, 0.9584420919548186, 0.9585655407282037, 0.9585323662391955, 0.9586050193571173, 0.9586276593638637, 0.9585830636951868, 0.9585998210796091, 0.958692837158168, 0.9588031726013074, 0.958768872921649, 0.9588119542213718, 0.9587684890444934, 0.9588282292240177, 0.9588498799741532, 0.9589489183974652, 0.9588950202814486, 0.958853265745864, 0.9589257944474896, 0.9589473663393913, 0.9589926279952639, 0.9589712555537939], 'mDice': [0.2659979814327845, 0.6036595650555735, 0.6517888375256006, 0.6709437684895693, 0.6833220709935557, 0.6935559624674066, 0.7019683202687746, 0.7071888962833913, 0.7144874987256312, 0.7180135130336891, 0.7230911026930187, 0.7269946117720815, 0.7306435066080776, 0.7329924711149559, 0.7367292411913897, 0.7387982026326047, 0.7406150425326414, 0.7442110079116898, 0.7463963583438824, 0.7484437650626836, 0.7506738763561657, 0.7506412443794733, 0.7540745356589204, 0.7550346627421618, 0.7570861940173294, 0.7591596413889674, 0.7604614826181305, 0.7611276986688436, 0.7626135173683287, 0.7633653317594521, 0.7642026380622357, 0.7660583929521873, 0.7669390541530307, 0.7679634634091907, 0.7696010917985137, 0.7689313762919406, 0.7697364018637464, 0.7714268250063117, 0.7732810424853304, 0.7736828217390322, 0.7737460332455429, 0.7751756779677883, 0.7763129577814094, 0.7758842113555487, 0.7785085296197158, 0.7780361477634394, 0.7792621938032195, 0.7790962470771765, 0.7797942502385267, 0.780268601995688, 0.7813077768393379, 0.7824797473937544, 0.7833415306469538, 0.7819792327911504, 0.7830061992751793, 0.7824622330326159, 0.7839630499208657, 0.7849944395266109, 0.7854501688690085, 0.7859109837039806, 0.7858219679213123, 0.785659211080946, 0.7874506239596032, 0.7872912360817952, 0.7874322837879764, 0.7878813988294654, 0.7864448700223339, 0.7884955354248748, 0.7877468835534266, 0.7900070563250069, 0.7897952537664913, 0.7904300257944216, 0.7909289478937542, 0.7916137118412515, 0.7918012902521242, 0.7919590223212757, 0.7925519365662096, 0.7926525003113691, 0.7918291222094113, 0.7938518785948614, 0.7933024948026729, 0.7933544418915809, 0.7941735943030781, 0.7940537419709224, 0.7940474404507516, 0.7951250855202417, 0.7960645734767147, 0.7952790853926691, 0.7949842135829998, 0.7956186387866263, 0.7965492147952927, 0.79644710754921, 0.7954867321138229]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.24s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.00s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:46,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:16,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:16,  1.76s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:55,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:10,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:46,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:11,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:58,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:30,  1.85s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:46,  1.92s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:25,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:40,  1.91s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:17,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:32,  1.90s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:48,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:29,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:27,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:11,  1.85s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:14,  1.87s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:32,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:07,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:56,  1.83s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:32,  1.98s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:05,  1.88s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:05,  1.89s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:01,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:12,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:19,  1.97s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:53,  1.87s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:55,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:54,  1.89s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:03,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:41,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:36,  1.86s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:31,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:16,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:04,  1.75s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:17,  1.81s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:32,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:10,  1.80s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:35,  1.91s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:17,  1.84s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:27,  1.89s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:40,  1.95s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:34,  1.94s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:53,  2.02s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:29,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:28,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:40,  1.99s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:24,  1.93s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:23,  1.94s/it]predicting train subjects:  20%|██        | 57/285 [01:46<07:11,  1.89s/it]predicting train subjects:  20%|██        | 58/285 [01:48<07:06,  1.88s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:23,  1.96s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:30,  2.00s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<07:04,  1.90s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:07,  1.92s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<07:00,  1.89s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:46,  1.84s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:50,  1.86s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:51,  1.88s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:47,  1.87s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:37,  1.83s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:36,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:37,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:40,  1.87s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:29,  1.83s/it]predicting train subjects:  26%|██▌       | 73/285 [02:16<06:29,  1.84s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:31,  1.85s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:31,  1.86s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:32,  1.88s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:19,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:25<06:10,  1.79s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<06:16,  1.83s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:14,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:05,  1.79s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:06,  1.80s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<06:01,  1.79s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:57,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:06,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:43<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:45<06:01,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<06:07,  1.88s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<05:55,  1.83s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<05:46,  1.80s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:47,  1.82s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:48,  1.83s/it]predicting train subjects:  34%|███▎      | 96/285 [02:58<05:46,  1.83s/it]predicting train subjects:  34%|███▍      | 97/285 [03:00<05:47,  1.85s/it]predicting train subjects:  34%|███▍      | 98/285 [03:02<05:45,  1.85s/it]predicting train subjects:  35%|███▍      | 99/285 [03:04<05:45,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [03:06<05:43,  1.86s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:33,  1.81s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:35,  1.83s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:27,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:25,  1.80s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:24,  1.80s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:17,  1.77s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:16,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:17,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:09,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:12,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:14,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:11,  1.82s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:08,  1.81s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:09,  1.83s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:01,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<04:54,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:34,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:22,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:22,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:17,  1.61s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:15,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:07,  1.56s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:09,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:04,  1.57s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:05,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:01,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<04:05,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<04:02,  1.59s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<03:58,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:51,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<03:46,  1.52s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<03:52,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<03:47,  1.55s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<03:51,  1.60s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:45,  1.56s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:43,  1.56s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:36,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:44,  1.59s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:41,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:44,  1.61s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:25<03:31,  1.54s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:28<03:23,  1.51s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:27,  1.55s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:23,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:23,  1.56s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:19,  1.53s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:20,  1.56s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:39<03:11,  1.50s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:42<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:43<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:45<03:03,  1.48s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:00,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:48<03:01,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:51<02:57,  1.48s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:01,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<02:55,  1.50s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<02:53,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:48,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:46,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [05:04<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:44,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:07<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:13<02:43,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:15<02:45,  1.59s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:17<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:18<02:37,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:20<02:33,  1.52s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:21<02:27,  1.48s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:23<02:37,  1.59s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:25<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:27<02:45,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:28<02:35,  1.62s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:29,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:31<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:33<02:30,  1.62s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:34<02:22,  1.55s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:36<02:19,  1.53s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:37<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:39<02:22,  1.60s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:41<02:25,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:42<02:26,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:44<02:17,  1.59s/it]predicting train subjects:  70%|███████   | 200/285 [05:45<02:10,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:47<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:49<02:13,  1.60s/it]predicting train subjects:  71%|███████   | 203/285 [05:50<02:11,  1.61s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:52<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:53<02:00,  1.50s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:54<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:56<02:04,  1.59s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:58<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:00<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:01<02:00,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:03<01:54,  1.55s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:04<01:55,  1.58s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:06<01:55,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<01:53,  1.63s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:11<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:12<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:14<01:54,  1.70s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:16<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:17<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:19<01:41,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:21<01:41,  1.61s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:22<01:35,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:23<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:25<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:27<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:28<01:35,  1.65s/it]predicting train subjects:  80%|████████  | 228/285 [06:30<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:32<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:33<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:35<01:25,  1.58s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:37<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:38<01:20,  1.55s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:40<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:41<01:17,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:43<01:20,  1.65s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:45<01:21,  1.69s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:47<01:21,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:48<01:18,  1.71s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:50<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:51<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:53<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:54<01:03,  1.51s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:56<01:04,  1.58s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:57<01:01,  1.53s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:59<01:03,  1.63s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:01<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:04<00:57,  1.61s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:05<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:07<00:51,  1.53s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:08<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:10<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:12<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:14<00:49,  1.65s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:15<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:16<00:43,  1.56s/it]predicting train subjects:  91%|█████████ | 258/285 [07:18<00:43,  1.63s/it]predicting train subjects:  91%|█████████ | 259/285 [07:20<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:21<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:23<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:24<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:26<00:32,  1.49s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:28<00:33,  1.60s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:29<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:31<00:30,  1.58s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:32<00:27,  1.54s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:34<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:36<00:26,  1.63s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:37<00:23,  1.58s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:40<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:43<00:16,  1.53s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:45<00:16,  1.63s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:47<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:48<00:12,  1.62s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:10,  1.57s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:51<00:09,  1.60s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:07,  1.55s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:54<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:56<00:04,  1.49s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:58<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:00<00:01,  1.69s/it]predicting train subjects: 100%|██████████| 285/285 [08:01<00:00,  1.73s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:35,  1.61s/it]Loading train:   1%|          | 2/285 [00:02<06:55,  1.47s/it]Loading train:   1%|          | 3/285 [00:04<06:51,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:05<06:15,  1.34s/it]Loading train:   2%|▏         | 5/285 [00:06<06:30,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:07<06:11,  1.33s/it]Loading train:   2%|▏         | 7/285 [00:09<06:29,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:34,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:12<06:52,  1.49s/it]Loading train:   4%|▎         | 10/285 [00:13<06:07,  1.34s/it]Loading train:   4%|▍         | 11/285 [00:14<05:27,  1.19s/it]Loading train:   4%|▍         | 12/285 [00:15<05:12,  1.15s/it]Loading train:   5%|▍         | 13/285 [00:16<04:47,  1.06s/it]Loading train:   5%|▍         | 14/285 [00:17<04:51,  1.08s/it]Loading train:   5%|▌         | 15/285 [00:18<04:41,  1.04s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:20<04:28,  1.00s/it]Loading train:   6%|▋         | 18/285 [00:21<04:33,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:22<04:17,  1.03it/s]Loading train:   7%|▋         | 20/285 [00:23<04:20,  1.02it/s]Loading train:   7%|▋         | 21/285 [00:24<04:20,  1.01it/s]Loading train:   8%|▊         | 22/285 [00:25<03:59,  1.10it/s]Loading train:   8%|▊         | 23/285 [00:25<03:57,  1.10it/s]Loading train:   8%|▊         | 24/285 [00:26<03:51,  1.13it/s]Loading train:   9%|▉         | 25/285 [00:27<03:58,  1.09it/s]Loading train:   9%|▉         | 26/285 [00:28<03:58,  1.08it/s]Loading train:   9%|▉         | 27/285 [00:29<03:55,  1.10it/s]Loading train:  10%|▉         | 28/285 [00:30<04:03,  1.05it/s]Loading train:  10%|█         | 29/285 [00:31<04:00,  1.06it/s]Loading train:  11%|█         | 30/285 [00:32<04:01,  1.05it/s]Loading train:  11%|█         | 31/285 [00:33<04:12,  1.00it/s]Loading train:  11%|█         | 32/285 [00:34<03:56,  1.07it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:50,  1.09it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:47,  1.10it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:55,  1.06it/s]Loading train:  13%|█▎        | 36/285 [00:38<03:47,  1.10it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:40,  1.12it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:51,  1.07it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:36,  1.14it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:42,  1.10it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:39,  1.11it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:32,  1.15it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:40,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:41,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:45,  1.06it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:44,  1.06it/s]Loading train:  17%|█▋        | 48/285 [00:49<03:38,  1.09it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:43,  1.05it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:41,  1.06it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:44,  1.04it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:39,  1.06it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:38,  1.06it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:30,  1.09it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:29,  1.10it/s]Loading train:  20%|██        | 57/285 [00:57<03:19,  1.14it/s]Loading train:  20%|██        | 58/285 [00:58<03:16,  1.16it/s]Loading train:  21%|██        | 59/285 [00:59<03:25,  1.10it/s]Loading train:  21%|██        | 60/285 [01:00<03:30,  1.07it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:24,  1.10it/s]Loading train:  22%|██▏       | 62/285 [01:01<03:22,  1.10it/s]Loading train:  22%|██▏       | 63/285 [01:02<03:20,  1.10it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:48,  1.03s/it]Loading train:  23%|██▎       | 65/285 [01:05<04:29,  1.22s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:33,  1.25s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:09,  1.15s/it]Loading train:  24%|██▍       | 68/285 [01:08<03:47,  1.05s/it]Loading train:  24%|██▍       | 69/285 [01:09<03:42,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:10<03:30,  1.02it/s]Loading train:  25%|██▍       | 71/285 [01:11<03:36,  1.01s/it]Loading train:  25%|██▌       | 72/285 [01:12<03:26,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:13<03:19,  1.06it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:15,  1.08it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:07,  1.12it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:18,  1.05it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:05,  1.12it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:04,  1.12it/s]Loading train:  28%|██▊       | 79/285 [01:18<03:03,  1.12it/s]Loading train:  28%|██▊       | 80/285 [01:19<03:03,  1.12it/s]Loading train:  28%|██▊       | 81/285 [01:20<02:59,  1.14it/s]Loading train:  29%|██▉       | 82/285 [01:21<03:03,  1.11it/s]Loading train:  29%|██▉       | 83/285 [01:22<02:52,  1.17it/s]Loading train:  29%|██▉       | 84/285 [01:23<02:46,  1.21it/s]Loading train:  30%|██▉       | 85/285 [01:24<02:50,  1.17it/s]Loading train:  30%|███       | 86/285 [01:25<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:25<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:26<02:50,  1.16it/s]Loading train:  31%|███       | 89/285 [01:27<02:51,  1.14it/s]Loading train:  32%|███▏      | 90/285 [01:28<02:52,  1.13it/s]Loading train:  32%|███▏      | 91/285 [01:29<02:48,  1.15it/s]Loading train:  32%|███▏      | 92/285 [01:30<02:48,  1.14it/s]Loading train:  33%|███▎      | 93/285 [01:30<02:40,  1.20it/s]Loading train:  33%|███▎      | 94/285 [01:32<02:49,  1.12it/s]Loading train:  33%|███▎      | 95/285 [01:32<02:50,  1.12it/s]Loading train:  34%|███▎      | 96/285 [01:33<02:50,  1.11it/s]Loading train:  34%|███▍      | 97/285 [01:34<02:58,  1.06it/s]Loading train:  34%|███▍      | 98/285 [01:35<02:54,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:36<02:54,  1.07it/s]Loading train:  35%|███▌      | 100/285 [01:37<02:52,  1.07it/s]Loading train:  35%|███▌      | 101/285 [01:38<02:42,  1.13it/s]Loading train:  36%|███▌      | 102/285 [01:39<02:42,  1.12it/s]Loading train:  36%|███▌      | 103/285 [01:40<02:37,  1.15it/s]Loading train:  36%|███▋      | 104/285 [01:41<02:43,  1.11it/s]Loading train:  37%|███▋      | 105/285 [01:42<02:41,  1.12it/s]Loading train:  37%|███▋      | 106/285 [01:42<02:30,  1.19it/s]Loading train:  38%|███▊      | 107/285 [01:43<02:31,  1.17it/s]Loading train:  38%|███▊      | 108/285 [01:44<02:23,  1.23it/s]Loading train:  38%|███▊      | 109/285 [01:45<02:26,  1.20it/s]Loading train:  39%|███▊      | 110/285 [01:46<02:26,  1.20it/s]Loading train:  39%|███▉      | 111/285 [01:46<02:21,  1.23it/s]Loading train:  39%|███▉      | 112/285 [01:47<02:26,  1.18it/s]Loading train:  40%|███▉      | 113/285 [01:48<02:30,  1.14it/s]Loading train:  40%|████      | 114/285 [01:49<02:32,  1.12it/s]Loading train:  40%|████      | 115/285 [01:50<02:29,  1.14it/s]Loading train:  41%|████      | 116/285 [01:51<02:31,  1.11it/s]Loading train:  41%|████      | 117/285 [01:52<02:23,  1.17it/s]Loading train:  41%|████▏     | 118/285 [01:52<02:22,  1.17it/s]Loading train:  42%|████▏     | 119/285 [01:53<02:25,  1.14it/s]Loading train:  42%|████▏     | 120/285 [01:54<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [01:56<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:57<02:48,  1.04s/it]Loading train:  43%|████▎     | 123/285 [01:58<02:53,  1.07s/it]Loading train:  44%|████▎     | 124/285 [01:59<02:41,  1.00s/it]Loading train:  44%|████▍     | 125/285 [02:00<02:34,  1.04it/s]Loading train:  44%|████▍     | 126/285 [02:00<02:28,  1.07it/s]Loading train:  45%|████▍     | 127/285 [02:01<02:21,  1.12it/s]Loading train:  45%|████▍     | 128/285 [02:02<02:16,  1.15it/s]Loading train:  45%|████▌     | 129/285 [02:03<02:13,  1.17it/s]Loading train:  46%|████▌     | 130/285 [02:04<02:07,  1.22it/s]Loading train:  46%|████▌     | 131/285 [02:04<02:05,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:05<02:07,  1.20it/s]Loading train:  47%|████▋     | 133/285 [02:06<02:02,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:07<02:01,  1.24it/s]Loading train:  47%|████▋     | 135/285 [02:08<01:59,  1.26it/s]Loading train:  48%|████▊     | 136/285 [02:08<01:54,  1.30it/s]Loading train:  48%|████▊     | 137/285 [02:09<01:56,  1.27it/s]Loading train:  48%|████▊     | 138/285 [02:10<01:58,  1.24it/s]Loading train:  49%|████▉     | 139/285 [02:11<01:57,  1.24it/s]Loading train:  49%|████▉     | 140/285 [02:12<01:57,  1.23it/s]Loading train:  49%|████▉     | 141/285 [02:12<01:51,  1.29it/s]Loading train:  50%|████▉     | 142/285 [02:13<01:51,  1.28it/s]Loading train:  50%|█████     | 143/285 [02:14<01:50,  1.28it/s]Loading train:  51%|█████     | 144/285 [02:15<01:52,  1.26it/s]Loading train:  51%|█████     | 145/285 [02:16<01:51,  1.25it/s]Loading train:  51%|█████     | 146/285 [02:16<01:52,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:17<01:51,  1.24it/s]Loading train:  52%|█████▏    | 148/285 [02:18<01:52,  1.22it/s]Loading train:  52%|█████▏    | 149/285 [02:19<01:48,  1.25it/s]Loading train:  53%|█████▎    | 150/285 [02:20<01:45,  1.27it/s]Loading train:  53%|█████▎    | 151/285 [02:20<01:46,  1.25it/s]Loading train:  53%|█████▎    | 152/285 [02:21<01:43,  1.29it/s]Loading train:  54%|█████▎    | 153/285 [02:22<01:46,  1.24it/s]Loading train:  54%|█████▍    | 154/285 [02:23<01:43,  1.26it/s]Loading train:  54%|█████▍    | 155/285 [02:23<01:42,  1.26it/s]Loading train:  55%|█████▍    | 156/285 [02:24<01:42,  1.26it/s]Loading train:  55%|█████▌    | 157/285 [02:25<01:39,  1.29it/s]Loading train:  55%|█████▌    | 158/285 [02:26<01:37,  1.30it/s]Loading train:  56%|█████▌    | 159/285 [02:27<01:36,  1.31it/s]Loading train:  56%|█████▌    | 160/285 [02:27<01:35,  1.31it/s]Loading train:  56%|█████▋    | 161/285 [02:28<01:36,  1.29it/s]Loading train:  57%|█████▋    | 162/285 [02:29<01:34,  1.31it/s]Loading train:  57%|█████▋    | 163/285 [02:30<01:40,  1.21it/s]Loading train:  58%|█████▊    | 164/285 [02:31<01:35,  1.26it/s]Loading train:  58%|█████▊    | 165/285 [02:31<01:38,  1.22it/s]Loading train:  58%|█████▊    | 166/285 [02:32<01:36,  1.23it/s]Loading train:  59%|█████▊    | 167/285 [02:33<01:34,  1.24it/s]Loading train:  59%|█████▉    | 168/285 [02:34<01:30,  1.29it/s]Loading train:  59%|█████▉    | 169/285 [02:34<01:28,  1.30it/s]Loading train:  60%|█████▉    | 170/285 [02:35<01:30,  1.28it/s]Loading train:  60%|██████    | 171/285 [02:36<01:26,  1.32it/s]Loading train:  60%|██████    | 172/285 [02:37<01:28,  1.28it/s]Loading train:  61%|██████    | 173/285 [02:37<01:24,  1.32it/s]Loading train:  61%|██████    | 174/285 [02:38<01:24,  1.32it/s]Loading train:  61%|██████▏   | 175/285 [02:39<01:24,  1.31it/s]Loading train:  62%|██████▏   | 176/285 [02:40<01:28,  1.23it/s]Loading train:  62%|██████▏   | 177/285 [02:41<01:24,  1.28it/s]Loading train:  62%|██████▏   | 178/285 [02:41<01:21,  1.31it/s]Loading train:  63%|██████▎   | 179/285 [02:42<01:18,  1.35it/s]Loading train:  63%|██████▎   | 180/285 [02:43<01:24,  1.24it/s]Loading train:  64%|██████▎   | 181/285 [02:44<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [02:45<01:29,  1.15it/s]Loading train:  64%|██████▍   | 183/285 [02:46<01:26,  1.18it/s]Loading train:  65%|██████▍   | 184/285 [02:46<01:23,  1.21it/s]Loading train:  65%|██████▍   | 185/285 [02:47<01:22,  1.22it/s]Loading train:  65%|██████▌   | 186/285 [02:48<01:24,  1.17it/s]Loading train:  66%|██████▌   | 187/285 [02:49<01:26,  1.14it/s]Loading train:  66%|██████▌   | 188/285 [02:50<01:28,  1.09it/s]Loading train:  66%|██████▋   | 189/285 [02:51<01:24,  1.14it/s]Loading train:  67%|██████▋   | 190/285 [02:52<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [02:53<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [02:53<01:18,  1.19it/s]Loading train:  68%|██████▊   | 193/285 [02:54<01:13,  1.26it/s]Loading train:  68%|██████▊   | 194/285 [02:55<01:10,  1.29it/s]Loading train:  68%|██████▊   | 195/285 [02:56<01:07,  1.34it/s]Loading train:  69%|██████▉   | 196/285 [02:56<01:10,  1.27it/s]Loading train:  69%|██████▉   | 197/285 [02:57<01:11,  1.24it/s]Loading train:  69%|██████▉   | 198/285 [02:58<01:14,  1.17it/s]Loading train:  70%|██████▉   | 199/285 [02:59<01:08,  1.26it/s]Loading train:  70%|███████   | 200/285 [03:00<01:06,  1.29it/s]Loading train:  71%|███████   | 201/285 [03:01<01:08,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:01<01:07,  1.23it/s]Loading train:  71%|███████   | 203/285 [03:02<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:03<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:04<01:02,  1.28it/s]Loading train:  72%|███████▏  | 206/285 [03:04<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [03:05<01:02,  1.25it/s]Loading train:  73%|███████▎  | 208/285 [03:06<01:04,  1.19it/s]Loading train:  73%|███████▎  | 209/285 [03:07<01:05,  1.16it/s]Loading train:  74%|███████▎  | 210/285 [03:08<01:01,  1.22it/s]Loading train:  74%|███████▍  | 211/285 [03:09<00:57,  1.29it/s]Loading train:  74%|███████▍  | 212/285 [03:09<00:56,  1.29it/s]Loading train:  75%|███████▍  | 213/285 [03:10<00:54,  1.31it/s]Loading train:  75%|███████▌  | 214/285 [03:11<00:53,  1.33it/s]Loading train:  75%|███████▌  | 215/285 [03:12<00:56,  1.23it/s]Loading train:  76%|███████▌  | 216/285 [03:12<00:52,  1.31it/s]Loading train:  76%|███████▌  | 217/285 [03:13<00:54,  1.24it/s]Loading train:  76%|███████▋  | 218/285 [03:14<00:56,  1.19it/s]Loading train:  77%|███████▋  | 219/285 [03:15<00:58,  1.14it/s]Loading train:  77%|███████▋  | 220/285 [03:16<00:53,  1.21it/s]Loading train:  78%|███████▊  | 221/285 [03:17<00:51,  1.25it/s]Loading train:  78%|███████▊  | 222/285 [03:18<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [03:18<00:49,  1.26it/s]Loading train:  79%|███████▊  | 224/285 [03:19<00:51,  1.19it/s]Loading train:  79%|███████▉  | 225/285 [03:20<00:49,  1.21it/s]Loading train:  79%|███████▉  | 226/285 [03:21<00:50,  1.17it/s]Loading train:  80%|███████▉  | 227/285 [03:22<00:52,  1.11it/s]Loading train:  80%|████████  | 228/285 [03:23<00:52,  1.08it/s]Loading train:  80%|████████  | 229/285 [03:24<00:49,  1.12it/s]Loading train:  81%|████████  | 230/285 [03:25<00:48,  1.15it/s]Loading train:  81%|████████  | 231/285 [03:25<00:44,  1.22it/s]Loading train:  81%|████████▏ | 232/285 [03:26<00:43,  1.22it/s]Loading train:  82%|████████▏ | 233/285 [03:27<00:40,  1.27it/s]Loading train:  82%|████████▏ | 234/285 [03:28<00:42,  1.21it/s]Loading train:  82%|████████▏ | 235/285 [03:29<00:41,  1.21it/s]Loading train:  83%|████████▎ | 236/285 [03:29<00:40,  1.20it/s]Loading train:  83%|████████▎ | 237/285 [03:30<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:31<00:42,  1.12it/s]Loading train:  84%|████████▍ | 239/285 [03:32<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:33<00:39,  1.15it/s]Loading train:  85%|████████▍ | 241/285 [03:34<00:36,  1.21it/s]Loading train:  85%|████████▍ | 242/285 [03:34<00:35,  1.22it/s]Loading train:  85%|████████▌ | 243/285 [03:35<00:33,  1.25it/s]Loading train:  86%|████████▌ | 244/285 [03:36<00:35,  1.17it/s]Loading train:  86%|████████▌ | 245/285 [03:37<00:32,  1.24it/s]Loading train:  86%|████████▋ | 246/285 [03:38<00:32,  1.20it/s]Loading train:  87%|████████▋ | 247/285 [03:39<00:33,  1.15it/s]Loading train:  87%|████████▋ | 248/285 [03:40<00:32,  1.15it/s]Loading train:  87%|████████▋ | 249/285 [03:40<00:29,  1.22it/s]Loading train:  88%|████████▊ | 250/285 [03:41<00:27,  1.26it/s]Loading train:  88%|████████▊ | 251/285 [03:42<00:26,  1.27it/s]Loading train:  88%|████████▊ | 252/285 [03:43<00:25,  1.29it/s]Loading train:  89%|████████▉ | 253/285 [03:44<00:26,  1.22it/s]Loading train:  89%|████████▉ | 254/285 [03:45<00:26,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:45<00:25,  1.17it/s]Loading train:  90%|████████▉ | 256/285 [03:46<00:23,  1.22it/s]Loading train:  90%|█████████ | 257/285 [03:47<00:22,  1.27it/s]Loading train:  91%|█████████ | 258/285 [03:48<00:22,  1.21it/s]Loading train:  91%|█████████ | 259/285 [03:49<00:21,  1.20it/s]Loading train:  91%|█████████ | 260/285 [03:49<00:20,  1.23it/s]Loading train:  92%|█████████▏| 261/285 [03:50<00:20,  1.19it/s]Loading train:  92%|█████████▏| 262/285 [03:51<00:17,  1.29it/s]Loading train:  92%|█████████▏| 263/285 [03:52<00:16,  1.34it/s]Loading train:  93%|█████████▎| 264/285 [03:52<00:16,  1.24it/s]Loading train:  93%|█████████▎| 265/285 [03:53<00:17,  1.17it/s]Loading train:  93%|█████████▎| 266/285 [03:54<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [03:55<00:14,  1.23it/s]Loading train:  94%|█████████▍| 268/285 [03:56<00:14,  1.14it/s]Loading train:  94%|█████████▍| 269/285 [03:57<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [03:58<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [03:58<00:11,  1.21it/s]Loading train:  95%|█████████▌| 272/285 [03:59<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [04:00<00:09,  1.30it/s]Loading train:  96%|█████████▌| 274/285 [04:01<00:08,  1.34it/s]Loading train:  96%|█████████▋| 275/285 [04:01<00:07,  1.28it/s]Loading train:  97%|█████████▋| 276/285 [04:02<00:07,  1.17it/s]Loading train:  97%|█████████▋| 277/285 [04:03<00:06,  1.22it/s]Loading train:  98%|█████████▊| 278/285 [04:04<00:05,  1.27it/s]Loading train:  98%|█████████▊| 279/285 [04:05<00:04,  1.28it/s]Loading train:  98%|█████████▊| 280/285 [04:05<00:03,  1.27it/s]Loading train:  99%|█████████▊| 281/285 [04:06<00:03,  1.33it/s]Loading train:  99%|█████████▉| 282/285 [04:07<00:02,  1.23it/s]Loading train:  99%|█████████▉| 283/285 [04:08<00:01,  1.21it/s]Loading train: 100%|█████████▉| 284/285 [04:09<00:00,  1.18it/s]Loading train: 100%|██████████| 285/285 [04:10<00:00,  1.15it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:00, 298.28it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:00, 301.59it/s]concatenating: train:  34%|███▎      | 96/285 [00:00<00:00, 314.59it/s]concatenating: train:  46%|████▋     | 132/285 [00:00<00:00, 326.09it/s]concatenating: train:  58%|█████▊    | 165/285 [00:00<00:00, 327.16it/s]concatenating: train:  69%|██████▉   | 198/285 [00:00<00:00, 325.85it/s]concatenating: train:  81%|████████  | 231/285 [00:00<00:00, 326.52it/s]concatenating: train:  93%|█████████▎| 265/285 [00:00<00:00, 327.67it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 329.18it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 564.97it/s]2019-07-11 07:58:44.388502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:58:44.388589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:58:44.388603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:58:44.388611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:58:44.389023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.23it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.23it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.70it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.31it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.09it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.05it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.95it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.36it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.18it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.57it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.67it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.84it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.67it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.84it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.05it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.67it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.92it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 40)   21640       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 100)  0           dropout_6[0][0]                  
                                                                 dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 253,913
Trainable params: 79,073
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 17s - loss: 2.4012 - acc: 0.6647 - mDice: 0.1557 - val_loss: 1.6734 - val_acc: 0.9151 - val_mDice: 0.2830

Epoch 00001: val_mDice improved from -inf to 0.28300, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.7261 - acc: 0.9062 - mDice: 0.4791 - val_loss: 0.9478 - val_acc: 0.9370 - val_mDice: 0.5149

Epoch 00002: val_mDice improved from 0.28300 to 0.51495, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5217 - acc: 0.9241 - mDice: 0.5813 - val_loss: 0.8232 - val_acc: 0.9400 - val_mDice: 0.5555

Epoch 00003: val_mDice improved from 0.51495 to 0.55553, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.4701 - acc: 0.9328 - mDice: 0.6119 - val_loss: 0.8604 - val_acc: 0.9272 - val_mDice: 0.5285

Epoch 00004: val_mDice did not improve from 0.55553
Epoch 5/300
 - 12s - loss: 0.4374 - acc: 0.9358 - mDice: 0.6320 - val_loss: 0.8237 - val_acc: 0.9389 - val_mDice: 0.5557

Epoch 00005: val_mDice improved from 0.55553 to 0.55572, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.4189 - acc: 0.9376 - mDice: 0.6440 - val_loss: 0.8514 - val_acc: 0.9393 - val_mDice: 0.5405

Epoch 00006: val_mDice did not improve from 0.55572
Epoch 7/300
 - 12s - loss: 0.4047 - acc: 0.9387 - mDice: 0.6531 - val_loss: 0.8178 - val_acc: 0.9321 - val_mDice: 0.5594

Epoch 00007: val_mDice improved from 0.55572 to 0.55940, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.3936 - acc: 0.9395 - mDice: 0.6605 - val_loss: 0.7781 - val_acc: 0.9383 - val_mDice: 0.5817

Epoch 00008: val_mDice improved from 0.55940 to 0.58173, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.3823 - acc: 0.9403 - mDice: 0.6679 - val_loss: 0.7928 - val_acc: 0.9418 - val_mDice: 0.5778

Epoch 00009: val_mDice did not improve from 0.58173
Epoch 10/300
 - 12s - loss: 0.3717 - acc: 0.9413 - mDice: 0.6752 - val_loss: 0.8161 - val_acc: 0.9382 - val_mDice: 0.5667

Epoch 00010: val_mDice did not improve from 0.58173
Epoch 11/300
 - 12s - loss: 0.3641 - acc: 0.9417 - mDice: 0.6803 - val_loss: 0.8173 - val_acc: 0.9321 - val_mDice: 0.5474

Epoch 00011: val_mDice did not improve from 0.58173
Epoch 12/300
 - 12s - loss: 0.3608 - acc: 0.9421 - mDice: 0.6827 - val_loss: 0.8250 - val_acc: 0.9365 - val_mDice: 0.5696

Epoch 00012: val_mDice did not improve from 0.58173
Epoch 13/300
 - 12s - loss: 0.3553 - acc: 0.9426 - mDice: 0.6866 - val_loss: 0.7998 - val_acc: 0.9391 - val_mDice: 0.5774

Epoch 00013: val_mDice did not improve from 0.58173
Epoch 14/300
 - 12s - loss: 0.3465 - acc: 0.9432 - mDice: 0.6926 - val_loss: 0.8227 - val_acc: 0.9380 - val_mDice: 0.5702

Epoch 00014: val_mDice did not improve from 0.58173
Epoch 15/300
 - 12s - loss: 0.3433 - acc: 0.9435 - mDice: 0.6951 - val_loss: 0.8269 - val_acc: 0.9346 - val_mDice: 0.5643

Epoch 00015: val_mDice did not improve from 0.58173
Epoch 16/300
 - 12s - loss: 0.3407 - acc: 0.9438 - mDice: 0.6968 - val_loss: 0.7934 - val_acc: 0.9343 - val_mDice: 0.5794

Epoch 00016: val_mDice did not improve from 0.58173
Epoch 17/300
 - 12s - loss: 0.3353 - acc: 0.9441 - mDice: 0.7008 - val_loss: 0.7851 - val_acc: 0.9334 - val_mDice: 0.5690

Epoch 00017: val_mDice did not improve from 0.58173
Epoch 18/300
 - 12s - loss: 0.3310 - acc: 0.9445 - mDice: 0.7039 - val_loss: 0.8291 - val_acc: 0.9381 - val_mDice: 0.5659

Epoch 00018: val_mDice did not improve from 0.58173
Epoch 19/300
 - 12s - loss: 0.3273 - acc: 0.9447 - mDice: 0.7065 - val_loss: 0.7920 - val_acc: 0.9385 - val_mDice: 0.5796

Epoch 00019: val_mDice did not improve from 0.58173
Epoch 20/300
 - 12s - loss: 0.3250 - acc: 0.9450 - mDice: 0.7081 - val_loss: 0.7821 - val_acc: 0.9421 - val_mDice: 0.5839

Epoch 00020: val_mDice improved from 0.58173 to 0.58393, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 12s - loss: 0.3209 - acc: 0.9453 - mDice: 0.7112 - val_loss: 0.8069 - val_acc: 0.9413 - val_mDice: 0.5741

Epoch 00021: val_mDice did not improve from 0.58393
Epoch 22/300
 - 12s - loss: 0.3188 - acc: 0.9453 - mDice: 0.7126 - val_loss: 0.7962 - val_acc: 0.9393 - val_mDice: 0.5800

Epoch 00022: val_mDice did not improve from 0.58393
Epoch 23/300
 - 12s - loss: 0.3149 - acc: 0.9457 - mDice: 0.7155 - val_loss: 0.7977 - val_acc: 0.9403 - val_mDice: 0.5822

Epoch 00023: val_mDice did not improve from 0.58393
Epoch 24/300
 - 12s - loss: 0.3139 - acc: 0.9458 - mDice: 0.7162 - val_loss: 0.8086 - val_acc: 0.9352 - val_mDice: 0.5713

Epoch 00024: val_mDice did not improve from 0.58393
Epoch 25/300
 - 12s - loss: 0.3113 - acc: 0.9460 - mDice: 0.7183 - val_loss: 0.7815 - val_acc: 0.9381 - val_mDice: 0.5874

Epoch 00025: val_mDice improved from 0.58393 to 0.58736, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 13s - loss: 0.3085 - acc: 0.9462 - mDice: 0.7203 - val_loss: 0.7827 - val_acc: 0.9413 - val_mDice: 0.5843

Epoch 00026: val_mDice did not improve from 0.58736
Epoch 27/300
 - 12s - loss: 0.3052 - acc: 0.9466 - mDice: 0.7229 - val_loss: 0.7966 - val_acc: 0.9401 - val_mDice: 0.5819

Epoch 00027: val_mDice did not improve from 0.58736
Epoch 28/300
 - 12s - loss: 0.3040 - acc: 0.9465 - mDice: 0.7237 - val_loss: 0.8044 - val_acc: 0.9380 - val_mDice: 0.5777

Epoch 00028: val_mDice did not improve from 0.58736
Epoch 29/300
 - 12s - loss: 0.3029 - acc: 0.9467 - mDice: 0.7246 - val_loss: 0.7998 - val_acc: 0.9433 - val_mDice: 0.5803

Epoch 00029: val_mDice did not improve from 0.58736
Epoch 30/300
 - 12s - loss: 0.3002 - acc: 0.9470 - mDice: 0.7266 - val_loss: 0.7783 - val_acc: 0.9389 - val_mDice: 0.5802

Epoch 00030: val_mDice did not improve from 0.58736
Epoch 31/300
 - 12s - loss: 0.2991 - acc: 0.9470 - mDice: 0.7274 - val_loss: 0.7831 - val_acc: 0.9334 - val_mDice: 0.5738

Epoch 00031: val_mDice did not improve from 0.58736
Epoch 32/300
 - 12s - loss: 0.2977 - acc: 0.9472 - mDice: 0.7285 - val_loss: 0.7744 - val_acc: 0.9421 - val_mDice: 0.5850

Epoch 00032: val_mDice did not improve from 0.58736
Epoch 33/300
 - 12s - loss: 0.2944 - acc: 0.9474 - mDice: 0.7310 - val_loss: 0.7760 - val_acc: 0.9414 - val_mDice: 0.5730

Epoch 00033: val_mDice did not improve from 0.58736
Epoch 34/300
 - 12s - loss: 0.2935 - acc: 0.9475 - mDice: 0.7316 - val_loss: 0.7482 - val_acc: 0.9383 - val_mDice: 0.5792

Epoch 00034: val_mDice did not improve from 0.58736
Epoch 35/300
 - 13s - loss: 0.2925 - acc: 0.9477 - mDice: 0.7325 - val_loss: 0.7347 - val_acc: 0.9378 - val_mDice: 0.5871

Epoch 00035: val_mDice did not improve from 0.58736
Epoch 36/300
 - 13s - loss: 0.2915 - acc: 0.9477 - mDice: 0.7332 - val_loss: 0.7782 - val_acc: 0.9411 - val_mDice: 0.5860

Epoch 00036: val_mDice did not improve from 0.58736
Epoch 37/300
 - 13s - loss: 0.2918 - acc: 0.9476 - mDice: 0.7330 - val_loss: 0.7837 - val_acc: 0.9424 - val_mDice: 0.5810

Epoch 00037: val_mDice did not improve from 0.58736
Epoch 38/300
 - 12s - loss: 0.2870 - acc: 0.9479 - mDice: 0.7366 - val_loss: 0.7959 - val_acc: 0.9390 - val_mDice: 0.5808

Epoch 00038: val_mDice did not improve from 0.58736
Epoch 39/300
 - 12s - loss: 0.2886 - acc: 0.9479 - mDice: 0.7355 - val_loss: 0.7858 - val_acc: 0.9429 - val_mDice: 0.5810

Epoch 00039: val_mDice did not improve from 0.58736
Epoch 40/300
 - 12s - loss: 0.2851 - acc: 0.9481 - mDice: 0.7380 - val_loss: 0.7847 - val_acc: 0.9415 - val_mDice: 0.5756

Epoch 00040: val_mDice did not improve from 0.58736
Epoch 41/300
 - 12s - loss: 0.2846 - acc: 0.9482 - mDice: 0.7386 - val_loss: 0.7749 - val_acc: 0.9452 - val_mDice: 0.5873

Epoch 00041: val_mDice did not improve from 0.58736
Epoch 42/300
 - 12s - loss: 0.2844 - acc: 0.9481 - mDice: 0.7387 - val_loss: 0.7771 - val_acc: 0.9377 - val_mDice: 0.5755

Epoch 00042: val_mDice did not improve from 0.58736
Epoch 43/300
 - 13s - loss: 0.2815 - acc: 0.9484 - mDice: 0.7408 - val_loss: 0.7671 - val_acc: 0.9443 - val_mDice: 0.5883

Epoch 00043: val_mDice improved from 0.58736 to 0.58830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 12s - loss: 0.2804 - acc: 0.9485 - mDice: 0.7417 - val_loss: 0.7250 - val_acc: 0.9431 - val_mDice: 0.5886

Epoch 00044: val_mDice improved from 0.58830 to 0.58856, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 13s - loss: 0.2802 - acc: 0.9486 - mDice: 0.7420 - val_loss: 0.7640 - val_acc: 0.9414 - val_mDice: 0.5794

Epoch 00045: val_mDice did not improve from 0.58856
Epoch 46/300
 - 13s - loss: 0.2796 - acc: 0.9486 - mDice: 0.7423 - val_loss: 0.7830 - val_acc: 0.9406 - val_mDice: 0.5855

Epoch 00046: val_mDice did not improve from 0.58856
Epoch 47/300
 - 13s - loss: 0.2791 - acc: 0.9486 - mDice: 0.7427 - val_loss: 0.7241 - val_acc: 0.9379 - val_mDice: 0.5853

Epoch 00047: val_mDice did not improve from 0.58856
Epoch 48/300
 - 13s - loss: 0.2785 - acc: 0.9487 - mDice: 0.7432 - val_loss: 0.7817 - val_acc: 0.9422 - val_mDice: 0.5869

Epoch 00048: val_mDice did not improve from 0.58856
Epoch 49/300
 - 13s - loss: 0.2757 - acc: 0.9489 - mDice: 0.7454 - val_loss: 0.7576 - val_acc: 0.9405 - val_mDice: 0.5860

Epoch 00049: val_mDice did not improve from 0.58856
Epoch 50/300
 - 13s - loss: 0.2743 - acc: 0.9490 - mDice: 0.7465 - val_loss: 0.7685 - val_acc: 0.9390 - val_mDice: 0.5836

Epoch 00050: val_mDice did not improve from 0.58856
Epoch 51/300
 - 13s - loss: 0.2755 - acc: 0.9489 - mDice: 0.7456 - val_loss: 0.7544 - val_acc: 0.9393 - val_mDice: 0.5823

Epoch 00051: val_mDice did not improve from 0.58856
Epoch 52/300
 - 13s - loss: 0.2729 - acc: 0.9491 - mDice: 0.7477 - val_loss: 0.7744 - val_acc: 0.9365 - val_mDice: 0.5774

Epoch 00052: val_mDice did not improve from 0.58856
Epoch 53/300
 - 13s - loss: 0.2735 - acc: 0.9490 - mDice: 0.7471 - val_loss: 0.7394 - val_acc: 0.9430 - val_mDice: 0.5861

Epoch 00053: val_mDice did not improve from 0.58856
Epoch 54/300
 - 13s - loss: 0.2710 - acc: 0.9493 - mDice: 0.7490 - val_loss: 0.7284 - val_acc: 0.9395 - val_mDice: 0.5798

Epoch 00054: val_mDice did not improve from 0.58856
Epoch 55/300
 - 13s - loss: 0.2729 - acc: 0.9492 - mDice: 0.7476 - val_loss: 0.7644 - val_acc: 0.9408 - val_mDice: 0.5771

Epoch 00055: val_mDice did not improve from 0.58856
Epoch 56/300
 - 13s - loss: 0.2709 - acc: 0.9493 - mDice: 0.7491 - val_loss: 0.7755 - val_acc: 0.9434 - val_mDice: 0.5845

Epoch 00056: val_mDice did not improve from 0.58856
Epoch 57/300
 - 13s - loss: 0.2698 - acc: 0.9493 - mDice: 0.7500 - val_loss: 0.7948 - val_acc: 0.9409 - val_mDice: 0.5628

Epoch 00057: val_mDice did not improve from 0.58856
Epoch 58/300
 - 13s - loss: 0.2684 - acc: 0.9495 - mDice: 0.7511 - val_loss: 0.7656 - val_acc: 0.9429 - val_mDice: 0.5742

Epoch 00058: val_mDice did not improve from 0.58856
Epoch 59/300
 - 13s - loss: 0.2678 - acc: 0.9495 - mDice: 0.7515 - val_loss: 0.7032 - val_acc: 0.9414 - val_mDice: 0.5897

Epoch 00059: val_mDice improved from 0.58856 to 0.58972, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 60/300
 - 13s - loss: 0.2675 - acc: 0.9496 - mDice: 0.7519 - val_loss: 0.7412 - val_acc: 0.9404 - val_mDice: 0.5726

Epoch 00060: val_mDice did not improve from 0.58972
Epoch 61/300
 - 13s - loss: 0.2675 - acc: 0.9496 - mDice: 0.7518 - val_loss: 0.7501 - val_acc: 0.9384 - val_mDice: 0.5633

Epoch 00061: val_mDice did not improve from 0.58972
Epoch 62/300
 - 13s - loss: 0.2652 - acc: 0.9499 - mDice: 0.7536 - val_loss: 0.7242 - val_acc: 0.9413 - val_mDice: 0.5811

Epoch 00062: val_mDice did not improve from 0.58972
Epoch 63/300
 - 13s - loss: 0.2658 - acc: 0.9498 - mDice: 0.7532 - val_loss: 0.7384 - val_acc: 0.9421 - val_mDice: 0.5684

Epoch 00063: val_mDice did not improve from 0.58972
Epoch 64/300
 - 13s - loss: 0.2649 - acc: 0.9497 - mDice: 0.7538 - val_loss: 0.7275 - val_acc: 0.9379 - val_mDice: 0.5729

Epoch 00064: val_mDice did not improve from 0.58972
Epoch 65/300
 - 13s - loss: 0.2638 - acc: 0.9498 - mDice: 0.7547 - val_loss: 0.7024 - val_acc: 0.9393 - val_mDice: 0.5813

Epoch 00065: val_mDice did not improve from 0.58972
Epoch 66/300
 - 13s - loss: 0.2629 - acc: 0.9500 - mDice: 0.7554 - val_loss: 0.7210 - val_acc: 0.9393 - val_mDice: 0.5794

Epoch 00066: val_mDice did not improve from 0.58972
Epoch 67/300
 - 13s - loss: 0.2630 - acc: 0.9499 - mDice: 0.7554 - val_loss: 0.7585 - val_acc: 0.9429 - val_mDice: 0.5673

Epoch 00067: val_mDice did not improve from 0.58972
Epoch 68/300
 - 13s - loss: 0.2624 - acc: 0.9500 - mDice: 0.7558 - val_loss: 0.7429 - val_acc: 0.9426 - val_mDice: 0.5814

Epoch 00068: val_mDice did not improve from 0.58972
Epoch 69/300
 - 13s - loss: 0.2624 - acc: 0.9500 - mDice: 0.7559 - val_loss: 0.7554 - val_acc: 0.9418 - val_mDice: 0.5700

Epoch 00069: val_mDice did not improve from 0.58972
Epoch 70/300
 - 13s - loss: 0.2599 - acc: 0.9502 - mDice: 0.7578 - val_loss: 0.6763 - val_acc: 0.9399 - val_mDice: 0.5809

Epoch 00070: val_mDice did not improve from 0.58972
Epoch 71/300
 - 13s - loss: 0.2600 - acc: 0.9502 - mDice: 0.7578 - val_loss: 0.6922 - val_acc: 0.9421 - val_mDice: 0.5814

Epoch 00071: val_mDice did not improve from 0.58972
Epoch 72/300
 - 13s - loss: 0.2601 - acc: 0.9500 - mDice: 0.7577 - val_loss: 0.7358 - val_acc: 0.9403 - val_mDice: 0.5780

Epoch 00072: val_mDice did not improve from 0.58972
Epoch 73/300
 - 13s - loss: 0.2594 - acc: 0.9503 - mDice: 0.7583 - val_loss: 0.7512 - val_acc: 0.9414 - val_mDice: 0.5700

Epoch 00073: val_mDice did not improve from 0.58972
Epoch 74/300
 - 13s - loss: 0.2576 - acc: 0.9503 - mDice: 0.7596 - val_loss: 0.7412 - val_acc: 0.9418 - val_mDice: 0.5754

Epoch 00074: val_mDice did not improve from 0.58972
Epoch 75/300
 - 13s - loss: 0.2577 - acc: 0.9504 - mDice: 0.7596 - val_loss: 0.7126 - val_acc: 0.9389 - val_mDice: 0.5772

Epoch 00075: val_mDice did not improve from 0.58972
Epoch 76/300
 - 13s - loss: 0.2582 - acc: 0.9503 - mDice: 0.7592 - val_loss: 0.7459 - val_acc: 0.9372 - val_mDice: 0.5677

Epoch 00076: val_mDice did not improve from 0.58972
Epoch 77/300
 - 13s - loss: 0.2559 - acc: 0.9505 - mDice: 0.7610 - val_loss: 0.7310 - val_acc: 0.9394 - val_mDice: 0.5816

Epoch 00077: val_mDice did not improve from 0.58972
Epoch 78/300
 - 13s - loss: 0.2566 - acc: 0.9505 - mDice: 0.7605 - val_loss: 0.7274 - val_acc: 0.9400 - val_mDice: 0.5846

Epoch 00078: val_mDice did not improve from 0.58972
Epoch 79/300
 - 13s - loss: 0.2571 - acc: 0.9505 - mDice: 0.7601 - val_loss: 0.7233 - val_acc: 0.9426 - val_mDice: 0.5763

Epoch 00079: val_mDice did not improve from 0.58972
Epoch 80/300
 - 13s - loss: 0.2551 - acc: 0.9505 - mDice: 0.7617 - val_loss: 0.7324 - val_acc: 0.9403 - val_mDice: 0.5782

Epoch 00080: val_mDice did not improve from 0.58972
Epoch 81/300
 - 13s - loss: 0.2556 - acc: 0.9505 - mDice: 0.7613 - val_loss: 0.6878 - val_acc: 0.9393 - val_mDice: 0.5826

Epoch 00081: val_mDice did not improve from 0.58972
Epoch 82/300
 - 13s - loss: 0.2552 - acc: 0.9506 - mDice: 0.7616 - val_loss: 0.7207 - val_acc: 0.9407 - val_mDice: 0.5701

Epoch 00082: val_mDice did not improve from 0.58972
Epoch 83/300
 - 13s - loss: 0.2532 - acc: 0.9507 - mDice: 0.7633 - val_loss: 0.6650 - val_acc: 0.9396 - val_mDice: 0.5809

Epoch 00083: val_mDice did not improve from 0.58972
Epoch 84/300
 - 13s - loss: 0.2535 - acc: 0.9507 - mDice: 0.7629 - val_loss: 0.7375 - val_acc: 0.9420 - val_mDice: 0.5759

Epoch 00084: val_mDice did not improve from 0.58972
Epoch 85/300
 - 13s - loss: 0.2532 - acc: 0.9508 - mDice: 0.7632 - val_loss: 0.6540 - val_acc: 0.9405 - val_mDice: 0.5816

Epoch 00085: val_mDice did not improve from 0.58972
Epoch 86/300
 - 13s - loss: 0.2533 - acc: 0.9507 - mDice: 0.7632 - val_loss: 0.7451 - val_acc: 0.9430 - val_mDice: 0.5707

Epoch 00086: val_mDice did not improve from 0.58972
Epoch 87/300
 - 13s - loss: 0.2532 - acc: 0.9507 - mDice: 0.7633 - val_loss: 0.6642 - val_acc: 0.9418 - val_mDice: 0.5808

Epoch 00087: val_mDice did not improve from 0.58972
Epoch 88/300
 - 13s - loss: 0.2511 - acc: 0.9508 - mDice: 0.7649 - val_loss: 0.6938 - val_acc: 0.9386 - val_mDice: 0.5801

Epoch 00088: val_mDice did not improve from 0.58972
Epoch 89/300
 - 13s - loss: 0.2510 - acc: 0.9508 - mDice: 0.7649 - val_loss: 0.7048 - val_acc: 0.9367 - val_mDice: 0.5716

Epoch 00089: val_mDice did not improve from 0.58972
Epoch 90/300
 - 13s - loss: 0.2516 - acc: 0.9508 - mDice: 0.7645 - val_loss: 0.7011 - val_acc: 0.9422 - val_mDice: 0.5823

Epoch 00090: val_mDice did not improve from 0.58972
Epoch 91/300
 - 13s - loss: 0.2505 - acc: 0.9509 - mDice: 0.7654 - val_loss: 0.6497 - val_acc: 0.9402 - val_mDice: 0.5784

Epoch 00091: val_mDice did not improve from 0.58972
Epoch 92/300
 - 13s - loss: 0.2498 - acc: 0.9510 - mDice: 0.7659 - val_loss: 0.6903 - val_acc: 0.9407 - val_mDice: 0.5744

Epoch 00092: val_mDice did not improve from 0.58972
Epoch 93/300
 - 13s - loss: 0.2494 - acc: 0.9510 - mDice: 0.7662 - val_loss: 0.6442 - val_acc: 0.9402 - val_mDice: 0.5844

Epoch 00093: val_mDice did not improve from 0.58972
Epoch 94/300
 - 13s - loss: 0.2490 - acc: 0.9511 - mDice: 0.7665 - val_loss: 0.7279 - val_acc: 0.9415 - val_mDice: 0.5568

Epoch 00094: val_mDice did not improve from 0.58972
Epoch 95/300
 - 13s - loss: 0.2492 - acc: 0.9510 - mDice: 0.7663 - val_loss: 0.7155 - val_acc: 0.9423 - val_mDice: 0.5706

Epoch 00095: val_mDice did not improve from 0.58972
Epoch 96/300
 - 13s - loss: 0.2483 - acc: 0.9511 - mDice: 0.7671 - val_loss: 0.7301 - val_acc: 0.9427 - val_mDice: 0.5641

Epoch 00096: val_mDice did not improve from 0.58972
Epoch 97/300
 - 13s - loss: 0.2479 - acc: 0.9511 - mDice: 0.7674 - val_loss: 0.7087 - val_acc: 0.9430 - val_mDice: 0.5805

Epoch 00097: val_mDice did not improve from 0.58972
Epoch 98/300
 - 13s - loss: 0.2494 - acc: 0.9511 - mDice: 0.7662 - val_loss: 0.7075 - val_acc: 0.9414 - val_mDice: 0.5704

Epoch 00098: val_mDice did not improve from 0.58972
Epoch 99/300
 - 13s - loss: 0.2468 - acc: 0.9512 - mDice: 0.7683 - val_loss: 0.6901 - val_acc: 0.9413 - val_mDice: 0.5674

Epoch 00099: val_mDice did not improve from 0.58972
Restoring model weights from the end of the best epoch
Epoch 00099: early stopping
{'val_loss': [1.6733568219038157, 0.9478361216875223, 0.8231694102287292, 0.8604021370410919, 0.8237163424491882, 0.8513754789645855, 0.8177965833590581, 0.7780738748036898, 0.7928239072744663, 0.8161430129638085, 0.8173041160290058, 0.824995022553664, 0.7998394920275762, 0.8226617482992319, 0.8268758471195514, 0.793397395656659, 0.7850734431010026, 0.829086225766402, 0.7920335680246353, 0.7820900713021939, 0.8068691813028775, 0.7961863348117242, 0.7977044272881287, 0.8085999763928927, 0.7815407995994275, 0.7827111333608627, 0.7965638213432752, 0.8044263273477554, 0.7998490665967648, 0.7783039739498725, 0.7831311478064611, 0.774438467163306, 0.7759797825263097, 0.7481508965675647, 0.7346971734211996, 0.7781534641981125, 0.783679587336687, 0.7958516627550125, 0.7857747192566211, 0.7846947449904221, 0.774947064427229, 0.7770667626307561, 0.7671183943748474, 0.7250184691869296, 0.7640089312425027, 0.7829598371799176, 0.7241063977663333, 0.7817128529915442, 0.7576419997673768, 0.768541944714693, 0.7544292406393931, 0.7743583596669711, 0.7393859842648873, 0.7284452055509274, 0.7644093678547785, 0.7755493831176025, 0.7947551241287818, 0.7655597145740802, 0.7032265903858038, 0.7411790260901818, 0.7501488603078402, 0.7241983448083584, 0.7384001337564908, 0.7274560148899372, 0.7024157712092767, 0.720996998823606, 0.7584982101733868, 0.7429304982607181, 0.7553596313183124, 0.6763062580273702, 0.6921501297217149, 0.7358334947090882, 0.7511874597806197, 0.7412462922242972, 0.7125666256134326, 0.7458994182256552, 0.7310475924840341, 0.727351074035351, 0.7233287783769461, 0.732358625301948, 0.6878472176881937, 0.720685601234436, 0.6650204337560214, 0.7375428057633914, 0.6539764094811219, 0.7450727178500249, 0.6642054995665183, 0.6938359061112771, 0.7048372236581949, 0.7011261009252988, 0.64974756194995, 0.6902541609910818, 0.6441666655815564, 0.72786801136457, 0.715457178079165, 0.7300588305179889, 0.7087123554486495, 0.707458679492657, 0.6900705901476053], 'val_acc': [0.9151257689182575, 0.9370053685628451, 0.9399962883729202, 0.9272397183454953, 0.938914567232132, 0.9392774861592513, 0.932054340839386, 0.9382742918454684, 0.9418454376550821, 0.9382003408211929, 0.9320820776315836, 0.936459862268888, 0.939085623392692, 0.9380362217242901, 0.9345668668930347, 0.9342848406388209, 0.9334250023731818, 0.9381495278615218, 0.9385101038676041, 0.9420788930012629, 0.9413369252131536, 0.9392867157092462, 0.9403060124470637, 0.93516782613901, 0.938137969145408, 0.9412883611825796, 0.9400818347930908, 0.9379715323448181, 0.9432969735218928, 0.9388961012546833, 0.9333995695297534, 0.9420603742966285, 0.9413600426453811, 0.9382650898053095, 0.9378051207615778, 0.9411103748358213, 0.9424094168039469, 0.9389700293540955, 0.9428901603588691, 0.9414709943991441, 0.9451622343980349, 0.9377149801987869, 0.9443255433669457, 0.9430796710344461, 0.9413692859502939, 0.9406157823709341, 0.9379183466617877, 0.9422267881723551, 0.9404862912801596, 0.9389746441290929, 0.9393144662563617, 0.9364968675833482, 0.9430126547813416, 0.9395109254580277, 0.9408260836051061, 0.9433616697788239, 0.9409370559912461, 0.9428693560453562, 0.9414478815518893, 0.9404077231884003, 0.9383528897395501, 0.9413230442083799, 0.942090433377486, 0.9379368814138266, 0.9392936298480401, 0.9393329276488378, 0.9429155633999751, 0.942615114725553, 0.9417552947998047, 0.9399246573448181, 0.9421250866009638, 0.9402852081335508, 0.9414409330258002, 0.9417760761884543, 0.9388891183412992, 0.9371879375897921, 0.9393814687545483, 0.9399801194667816, 0.9425688706911527, 0.9402968035294459, 0.9392682382693658, 0.9407220643300277, 0.939642642553036, 0.9420141348472009, 0.9404701177890484, 0.9429965156775254, 0.9418292183142442, 0.9386233389377594, 0.9366702299851638, 0.9421620896229377, 0.9401673422409937, 0.9407105308312637, 0.9401604074698228, 0.9414686331382165, 0.9422591397395501, 0.9426659437326285, 0.943049628000993, 0.9414293605547684, 0.9412629398015829], 'val_mDice': [0.28300402571375555, 0.5149493406598384, 0.5555295485716599, 0.5284878852275702, 0.5557192311837122, 0.5404662552934426, 0.5594002002706895, 0.5817266444747264, 0.5777610374184755, 0.5666807116224215, 0.5474474710913805, 0.5695573544273009, 0.5774057152179571, 0.5701817589310499, 0.5643403828144073, 0.5794007835479883, 0.5690330387308047, 0.5658522454591898, 0.5795677384504905, 0.583933993600882, 0.5741342873527453, 0.5799539570625012, 0.5821825208572241, 0.5713240040036348, 0.5873556790443567, 0.5843184762276136, 0.5818762386647555, 0.5777032819504921, 0.5802681537774893, 0.5801632885749524, 0.5738496619921464, 0.5849539769383577, 0.5730365546276937, 0.5792100555621661, 0.5871023730589793, 0.5859902707430032, 0.5809645389135067, 0.5808323249220848, 0.5809928299142764, 0.5755719553965789, 0.5873103783680842, 0.5755446232282199, 0.5883039797727878, 0.5885612838543378, 0.5793541136842507, 0.5854949607298925, 0.5853274275477116, 0.586894337947552, 0.5859766310224166, 0.5835760545272094, 0.5822910425754694, 0.5773683345088592, 0.5860646223792663, 0.5798115134239197, 0.5771091740864974, 0.5844929229754668, 0.5628156810998917, 0.5741949316400748, 0.5897246455916991, 0.5726057176406567, 0.5632536365435674, 0.5811394338424389, 0.5683852921311672, 0.5728887720749929, 0.5812988481842555, 0.5793877725417798, 0.5673024425139794, 0.5814011612763772, 0.5699979244516447, 0.5808751772229488, 0.5813778031330842, 0.5779726339074281, 0.5700070789227119, 0.575394794344902, 0.5771806131188686, 0.5677240261664758, 0.5815922904473084, 0.5845534474803851, 0.5763265490531921, 0.5781534807040141, 0.58259284725556, 0.5701340775077159, 0.580914318561554, 0.5759343424668679, 0.5816137762023852, 0.5706789803046447, 0.580815029832033, 0.580105375785094, 0.5715832962439611, 0.5822607273092637, 0.5784151462408212, 0.574401627939481, 0.584446336214359, 0.5567631520904027, 0.5705947394554431, 0.5640501471666189, 0.5805482199558845, 0.5703708294492501, 0.567409329689466], 'loss': [2.401170176245086, 0.72612756021808, 0.5217192218190001, 0.4700672502591581, 0.4374092280820739, 0.4189445796948918, 0.40470363838881745, 0.3935878408562045, 0.3823154409779599, 0.3716812319947072, 0.36409295922351215, 0.36080890002037824, 0.35532282052758674, 0.3465181104725471, 0.34334808353028545, 0.3406781423914249, 0.3352521038644705, 0.33095965181605946, 0.32732367288260444, 0.32497841242900427, 0.3209430742344051, 0.31879177776405887, 0.3149181789498944, 0.31386536752552074, 0.3113416165489998, 0.30847318574235105, 0.3051733046118694, 0.30398588322421166, 0.30293895646532576, 0.30017422019946094, 0.2990525446782019, 0.29770094685907195, 0.2944166463678925, 0.29348311863030874, 0.2924991737050367, 0.29154569408632586, 0.29180446907260876, 0.28699254597958346, 0.2886207208585708, 0.2850958150542223, 0.2846110718563387, 0.2843724888601086, 0.2814959583550288, 0.28040850760586467, 0.2801817701161485, 0.27962196362224173, 0.27912639487023877, 0.27847094985157494, 0.27573399076292043, 0.2742527904220693, 0.2755362408732638, 0.2728557594173412, 0.2735414567286597, 0.27099239717635415, 0.2729375819202104, 0.2708938736037378, 0.2697703644412036, 0.26841246304472005, 0.2678376967084811, 0.26746220617488686, 0.26754572237207475, 0.2651969578382022, 0.2658429443396447, 0.2649144287683488, 0.2638439494976641, 0.2629282916921383, 0.26304459589978685, 0.2624417397546711, 0.26237874651465326, 0.2599026468350286, 0.26000343753899485, 0.26008214118196377, 0.2593605122676274, 0.2576041862905922, 0.2576920576589437, 0.2581742526716844, 0.25591899407181495, 0.2566258784678659, 0.25709824926033237, 0.25511920065949306, 0.2555575028843824, 0.255168734120232, 0.2531840475125802, 0.2534696468331877, 0.2531967530111034, 0.2532659838046357, 0.25319451379658364, 0.25108696874201897, 0.2510258492635843, 0.2516266453681722, 0.2504584013365802, 0.2497817761979617, 0.24942700829957118, 0.24895699465834412, 0.24923841423415768, 0.24830696029624827, 0.24794021838789637, 0.24941638737633848, 0.2468426050138157], 'acc': [0.6646512022229409, 0.9062127572555863, 0.9240600494433404, 0.9327942678588217, 0.9357538555289154, 0.9376220435747897, 0.9386582955117486, 0.9395202879128196, 0.9403347547595422, 0.9412549252353075, 0.9416600095052665, 0.9420921149030005, 0.9425595588683202, 0.9431578100557687, 0.9435294566587209, 0.9437581388248703, 0.9441245764392246, 0.9444564112402752, 0.9447368779525891, 0.9449535609336068, 0.9453387131201081, 0.9453200922453853, 0.9456734548225885, 0.9458492782231814, 0.9460210950020812, 0.946244320498504, 0.9465721625689375, 0.946509933907047, 0.9466955165114117, 0.9469655164930858, 0.9469737887525431, 0.9472067231821044, 0.9473604474803855, 0.9474637807487485, 0.9476558108133198, 0.9476953431500793, 0.9476297415293397, 0.9478659791875169, 0.9479182097653033, 0.9481272684255782, 0.948170453191826, 0.9481418796277382, 0.9483912215454491, 0.9484727373699701, 0.9485727672448053, 0.9486277915230209, 0.948608017776941, 0.9487256055211137, 0.9488992796473691, 0.9490362468883251, 0.9489250419039376, 0.9490701415810783, 0.9490311454662392, 0.9493038990692625, 0.9491533233507482, 0.9493085296130055, 0.9493099484267319, 0.9495340654311953, 0.9495367644447292, 0.9495857354075906, 0.9496074433059783, 0.9498558549888457, 0.9497747576006947, 0.949716249696775, 0.9498296918975002, 0.9499635329537206, 0.9499312272472464, 0.9499704471529822, 0.9500461782376111, 0.9501867763485777, 0.9501765578927495, 0.9500423224168236, 0.9502724862336167, 0.950349525998332, 0.9503960632358784, 0.9503130993697516, 0.9504680454505609, 0.9504842744106232, 0.950468534408741, 0.9504950699150524, 0.9505050908394497, 0.950563240598777, 0.9507172052396088, 0.9506938422417758, 0.950759352792687, 0.9507287824757478, 0.9507148131600366, 0.9508447734223161, 0.9508381211910478, 0.9508484511767697, 0.9509089511775293, 0.9509898728301007, 0.9510038397655841, 0.9510999411869497, 0.9510431219585309, 0.9511391169512765, 0.9510613677906922, 0.9510630955228196, 0.9511900640035329], 'mDice': [0.15569932184639995, 0.47911573537631985, 0.581266592846886, 0.611949039651142, 0.6319823705170479, 0.6439833684094243, 0.6531436329759553, 0.660480120723388, 0.6679325829646822, 0.6751858892557774, 0.6803045344948604, 0.6827031638661203, 0.6865776794583202, 0.692632241573631, 0.6950501093705685, 0.696837130149638, 0.7007698097000766, 0.7038798733774745, 0.7065468827352019, 0.7081356713783474, 0.7111615629628456, 0.7126199900581752, 0.7155458064445609, 0.7162404175197398, 0.718273079511832, 0.7203294120678809, 0.7228781463892535, 0.7237331367535069, 0.7245506785193636, 0.7266140500634818, 0.7273917446538419, 0.7284863546228184, 0.7309799225614221, 0.7316311625859113, 0.7324765951587497, 0.7332234119045264, 0.7330237082380502, 0.7366089800027951, 0.7354981303599821, 0.738049037823936, 0.7385546775318474, 0.7386532262177922, 0.7408329858932066, 0.7417184866564218, 0.7419867094763858, 0.7422985800856386, 0.742705374205782, 0.7432418459952345, 0.7453747279450735, 0.7465385108111496, 0.7455905358762547, 0.7476781222649433, 0.747123134605649, 0.7490451656715529, 0.7476217840239646, 0.7491353710210269, 0.7500152975983212, 0.751146237332146, 0.7515457915411019, 0.7518500666122292, 0.7518083356430112, 0.7536162110884713, 0.753202896754504, 0.7537612649256108, 0.7547262563791638, 0.7554466560803182, 0.7553749317108326, 0.7558488258574046, 0.7558656129396831, 0.7578437256766875, 0.757753783911343, 0.7577352788432282, 0.7582760583724437, 0.7596127632072598, 0.7596131422571796, 0.7592122236828979, 0.761011754351657, 0.7604754003917314, 0.7600852205207358, 0.7616863337036297, 0.7613273802074484, 0.7616280620194642, 0.7632503220650869, 0.7629309604993157, 0.7631967350707265, 0.7631560634403534, 0.76326333587596, 0.7648570846941796, 0.7649035190652023, 0.7644520674663904, 0.7654356015274955, 0.7659235288326584, 0.7661811871897148, 0.7665404892656006, 0.7663311241770938, 0.7671065356726358, 0.7673960409073837, 0.7662361053966193, 0.7682891545134761]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.03s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.66s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:15,  1.74s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:35,  1.61s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:42,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:10,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:24,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:03,  1.52s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:21,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:19,  1.59s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:36,  1.65s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:50,  1.71s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:24,  1.62s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:39,  1.68s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:28,  1.65s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:30,  1.66s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:46,  1.73s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:59,  1.78s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:38,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:36,  1.71s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:22,  1.66s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:23,  1.67s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:41,  1.75s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:21,  1.68s/it]predicting train subjects:   8%|▊         | 23/285 [00:37<07:19,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:03,  1.62s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:15,  1.68s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:28,  1.73s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:08,  1.66s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:10,  1.68s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:14,  1.70s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:34,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:36,  1.80s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:17,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:12,  1.71s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:08,  1.71s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:14,  1.74s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<06:58,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<06:58,  1.69s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:03,  1.71s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:44,  1.64s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:46,  1.66s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:34,  1.62s/it]predicting train subjects:  15%|█▍        | 42/285 [01:09<06:25,  1.59s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:32,  1.62s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:55,  1.72s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:38,  1.66s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:46,  1.70s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:33,  1.65s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:36,  1.67s/it]predicting train subjects:  17%|█▋        | 49/285 [01:21<06:46,  1.72s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:42,  1.71s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<06:49,  1.75s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:33,  1.69s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:37,  1.71s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:42,  1.74s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:23,  1.67s/it]predicting train subjects:  20%|█▉        | 56/285 [01:33<06:22,  1.67s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:10,  1.62s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:12,  1.64s/it]predicting train subjects:  21%|██        | 59/285 [01:38<06:22,  1.69s/it]predicting train subjects:  21%|██        | 60/285 [01:40<06:31,  1.74s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:18,  1.69s/it]predicting train subjects:  22%|██▏       | 62/285 [01:43<06:17,  1.69s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<06:18,  1.70s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:02,  1.64s/it]predicting train subjects:  23%|██▎       | 65/285 [01:48<06:03,  1.65s/it]predicting train subjects:  23%|██▎       | 66/285 [01:50<06:08,  1.68s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:06,  1.68s/it]predicting train subjects:  24%|██▍       | 68/285 [01:53<05:58,  1.65s/it]predicting train subjects:  24%|██▍       | 69/285 [01:55<05:59,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<05:58,  1.67s/it]predicting train subjects:  25%|██▍       | 71/285 [01:58<05:56,  1.67s/it]predicting train subjects:  25%|██▌       | 72/285 [02:00<05:50,  1.64s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:56,  1.68s/it]predicting train subjects:  26%|██▌       | 74/285 [02:03<05:56,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:05<05:53,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:51,  1.68s/it]predicting train subjects:  27%|██▋       | 77/285 [02:08<05:41,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:33,  1.61s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:13<05:38,  1.65s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:29,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:16<05:30,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:18<05:22,  1.60s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:17,  1.58s/it]predicting train subjects:  30%|██▉       | 85/285 [02:21<05:22,  1.61s/it]predicting train subjects:  30%|███       | 86/285 [02:23<05:25,  1.64s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:28,  1.66s/it]predicting train subjects:  31%|███       | 88/285 [02:26<05:14,  1.60s/it]predicting train subjects:  31%|███       | 89/285 [02:28<05:17,  1.62s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:25,  1.67s/it]predicting train subjects:  32%|███▏      | 91/285 [02:31<05:15,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:33<05:16,  1.64s/it]predicting train subjects:  33%|███▎      | 93/285 [02:34<05:08,  1.61s/it]predicting train subjects:  33%|███▎      | 94/285 [02:36<05:12,  1.63s/it]predicting train subjects:  33%|███▎      | 95/285 [02:38<05:17,  1.67s/it]predicting train subjects:  34%|███▎      | 96/285 [02:39<05:17,  1.68s/it]predicting train subjects:  34%|███▍      | 97/285 [02:41<05:18,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:43<05:15,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:45<05:15,  1.70s/it]predicting train subjects:  35%|███▌      | 100/285 [02:46<05:10,  1.68s/it]predicting train subjects:  35%|███▌      | 101/285 [02:48<04:56,  1.61s/it]predicting train subjects:  36%|███▌      | 102/285 [02:49<04:59,  1.64s/it]predicting train subjects:  36%|███▌      | 103/285 [02:51<04:47,  1.58s/it]predicting train subjects:  36%|███▋      | 104/285 [02:52<04:50,  1.60s/it]predicting train subjects:  37%|███▋      | 105/285 [02:54<04:53,  1.63s/it]predicting train subjects:  37%|███▋      | 106/285 [02:56<04:45,  1.59s/it]predicting train subjects:  38%|███▊      | 107/285 [02:57<04:48,  1.62s/it]predicting train subjects:  38%|███▊      | 108/285 [02:59<04:41,  1.59s/it]predicting train subjects:  38%|███▊      | 109/285 [03:00<04:43,  1.61s/it]predicting train subjects:  39%|███▊      | 110/285 [03:02<04:45,  1.63s/it]predicting train subjects:  39%|███▉      | 111/285 [03:04<04:37,  1.60s/it]predicting train subjects:  39%|███▉      | 112/285 [03:05<04:40,  1.62s/it]predicting train subjects:  40%|███▉      | 113/285 [03:07<04:41,  1.64s/it]predicting train subjects:  40%|████      | 114/285 [03:09<04:44,  1.67s/it]predicting train subjects:  40%|████      | 115/285 [03:11<04:50,  1.71s/it]predicting train subjects:  41%|████      | 116/285 [03:12<04:47,  1.70s/it]predicting train subjects:  41%|████      | 117/285 [03:14<04:36,  1.64s/it]predicting train subjects:  41%|████▏     | 118/285 [03:15<04:28,  1.61s/it]predicting train subjects:  42%|████▏     | 119/285 [03:17<04:31,  1.64s/it]predicting train subjects:  42%|████▏     | 120/285 [03:19<04:27,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:20<04:18,  1.57s/it]predicting train subjects:  43%|████▎     | 122/285 [03:21<04:05,  1.51s/it]predicting train subjects:  43%|████▎     | 123/285 [03:23<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:24<03:57,  1.48s/it]predicting train subjects:  44%|████▍     | 125/285 [03:26<03:53,  1.46s/it]predicting train subjects:  44%|████▍     | 126/285 [03:27<03:50,  1.45s/it]predicting train subjects:  45%|████▍     | 127/285 [03:28<03:45,  1.42s/it]predicting train subjects:  45%|████▍     | 128/285 [03:30<03:50,  1.47s/it]predicting train subjects:  45%|████▌     | 129/285 [03:31<03:46,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:33<03:40,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:34<03:34,  1.40s/it]predicting train subjects:  46%|████▋     | 132/285 [03:36<03:39,  1.43s/it]predicting train subjects:  47%|████▋     | 133/285 [03:37<03:36,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:38<03:31,  1.40s/it]predicting train subjects:  47%|████▋     | 135/285 [03:40<03:26,  1.38s/it]predicting train subjects:  48%|████▊     | 136/285 [03:41<03:23,  1.36s/it]predicting train subjects:  48%|████▊     | 137/285 [03:43<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 138/285 [03:44<03:23,  1.38s/it]predicting train subjects:  49%|████▉     | 139/285 [03:45<03:26,  1.41s/it]predicting train subjects:  49%|████▉     | 140/285 [03:47<03:27,  1.43s/it]predicting train subjects:  49%|████▉     | 141/285 [03:48<03:22,  1.40s/it]predicting train subjects:  50%|████▉     | 142/285 [03:50<03:21,  1.41s/it]predicting train subjects:  50%|█████     | 143/285 [03:51<03:17,  1.39s/it]predicting train subjects:  51%|█████     | 144/285 [03:53<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [03:54<03:21,  1.44s/it]predicting train subjects:  51%|█████     | 146/285 [03:56<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:57<03:19,  1.44s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:58<03:19,  1.45s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:00<03:13,  1.42s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:01<03:10,  1.41s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:03<03:13,  1.44s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:04<03:07,  1.41s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:05<03:02,  1.38s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:07<03:05,  1.42s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:08<03:03,  1.41s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:10<03:06,  1.44s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:11<03:01,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:12<02:59,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:14<02:55,  1.39s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:15<02:53,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:17<02:55,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:18<02:52,  1.40s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:20<02:56,  1.44s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:21<02:52,  1.42s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:22<02:48,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:24<02:50,  1.43s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:25<02:50,  1.44s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:27<02:43,  1.40s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:28<02:43,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:29<02:42,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:31<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:32<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:34<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:35<02:38,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:37<02:43,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:38<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:40<02:39,  1.48s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:41<02:35,  1.45s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:43<02:31,  1.43s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:44<02:39,  1.52s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:46<02:39,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:47<02:39,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:49<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:50<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:51<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:53<02:30,  1.52s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:55<02:35,  1.58s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:57<02:39,  1.65s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:58<02:29,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:00<02:23,  1.51s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:01<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:03<02:26,  1.58s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:04<02:18,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:06<02:14,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:07<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:09<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:10<02:17,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:12<02:18,  1.60s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:13<02:07,  1.49s/it]predicting train subjects:  70%|███████   | 200/285 [05:15<02:03,  1.45s/it]predicting train subjects:  71%|███████   | 201/285 [05:16<02:09,  1.54s/it]predicting train subjects:  71%|███████   | 202/285 [05:18<02:09,  1.56s/it]predicting train subjects:  71%|███████   | 203/285 [05:19<02:08,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:21<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:22<01:56,  1.46s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:24<01:52,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:25<02:01,  1.56s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:27<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:29<02:07,  1.68s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:30<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:32<01:53,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:33<01:54,  1.57s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:35<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:36<01:46,  1.49s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:38<01:49,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:39<01:43,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:41<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:43<01:48,  1.62s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:45<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:46<01:43,  1.58s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:47<01:37,  1.52s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:49<01:36,  1.54s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:50<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:52<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:53<01:26,  1.44s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:55<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:57<01:33,  1.61s/it]predicting train subjects:  80%|████████  | 228/285 [05:58<01:34,  1.65s/it]predicting train subjects:  80%|████████  | 229/285 [06:00<01:31,  1.63s/it]predicting train subjects:  81%|████████  | 230/285 [06:01<01:24,  1.54s/it]predicting train subjects:  81%|████████  | 231/285 [06:03<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:04<01:20,  1.52s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:06<01:15,  1.46s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:07<01:18,  1.53s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:09<01:13,  1.47s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:11<01:17,  1.58s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:12<01:18,  1.63s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:14<01:17,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:16<01:15,  1.65s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:17<01:09,  1.54s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:18<01:05,  1.49s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:20<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:21<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:23<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:24<00:57,  1.45s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:26<00:59,  1.53s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:27<01:00,  1.59s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:29<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:30<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:32<00:52,  1.50s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:33<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:35<00:46,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:36<00:49,  1.55s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:38<00:49,  1.59s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:40<00:47,  1.59s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:41<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [06:42<00:40,  1.46s/it]predicting train subjects:  91%|█████████ | 258/285 [06:44<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [06:46<00:39,  1.53s/it]predicting train subjects:  91%|█████████ | 260/285 [06:47<00:36,  1.46s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:48<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:50<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:51<00:31,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:53<00:31,  1.52s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:54<00:31,  1.57s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:56<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:57<00:26,  1.46s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:59<00:26,  1.54s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:00<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:02<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:03<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:05<00:19,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:06<00:17,  1.47s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:08<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:09<00:15,  1.52s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:11<00:14,  1.58s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:12<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:14<00:10,  1.46s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:15<00:09,  1.50s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:17<00:07,  1.45s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:18<00:05,  1.43s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:19<00:04,  1.40s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:21<00:03,  1.52s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:23<00:01,  1.57s/it]predicting train subjects: 100%|██████████| 285/285 [07:25<00:00,  1.66s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:39,  1.62s/it]Loading train:   1%|          | 2/285 [00:02<07:08,  1.51s/it]Loading train:   1%|          | 3/285 [00:04<07:02,  1.50s/it]Loading train:   1%|▏         | 4/285 [00:05<07:09,  1.53s/it]Loading train:   2%|▏         | 5/285 [00:07<07:20,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:08<06:53,  1.48s/it]Loading train:   2%|▏         | 7/285 [00:10<07:05,  1.53s/it]Loading train:   3%|▎         | 8/285 [00:11<06:48,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:13<07:07,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:48,  1.49s/it]Loading train:   4%|▍         | 11/285 [00:15<06:04,  1.33s/it]Loading train:   4%|▍         | 12/285 [00:17<05:58,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:18<05:37,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:19<05:32,  1.23s/it]Loading train:   5%|▌         | 15/285 [00:20<05:24,  1.20s/it]Loading train:   6%|▌         | 16/285 [00:21<05:34,  1.24s/it]Loading train:   6%|▌         | 17/285 [00:23<05:19,  1.19s/it]Loading train:   6%|▋         | 18/285 [00:24<05:32,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:25<05:24,  1.22s/it]Loading train:   7%|▋         | 20/285 [00:26<05:13,  1.18s/it]Loading train:   7%|▋         | 21/285 [00:27<05:09,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:28<05:01,  1.15s/it]Loading train:   8%|▊         | 23/285 [00:30<05:09,  1.18s/it]Loading train:   8%|▊         | 24/285 [00:31<04:47,  1.10s/it]Loading train:   9%|▉         | 25/285 [00:32<04:59,  1.15s/it]Loading train:   9%|▉         | 26/285 [00:33<05:10,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:34<04:49,  1.12s/it]Loading train:  10%|▉         | 28/285 [00:35<04:56,  1.15s/it]Loading train:  10%|█         | 29/285 [00:36<04:44,  1.11s/it]Loading train:  11%|█         | 30/285 [00:37<04:43,  1.11s/it]Loading train:  11%|█         | 31/285 [00:39<05:08,  1.21s/it]Loading train:  11%|█         | 32/285 [00:40<05:02,  1.20s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:54,  1.17s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:45,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:49,  1.16s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:28,  1.08s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:25,  1.07s/it]Loading train:  13%|█▎        | 38/285 [00:47<05:05,  1.24s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:45,  1.16s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:44,  1.16s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:27,  1.10s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:13,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:08,  1.03s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:21,  1.08s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:18,  1.08s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:22,  1.10s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:07,  1.04s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:03,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:01,  1.02s/it]Loading train:  18%|█▊        | 50/285 [00:59<03:57,  1.01s/it]Loading train:  18%|█▊        | 51/285 [01:00<04:06,  1.06s/it]Loading train:  18%|█▊        | 52/285 [01:01<04:02,  1.04s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:03,  1.05s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:05,  1.06s/it]Loading train:  19%|█▉        | 55/285 [01:05<03:57,  1.03s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:03,  1.06s/it]Loading train:  20%|██        | 57/285 [01:07<03:55,  1.03s/it]Loading train:  20%|██        | 58/285 [01:08<04:02,  1.07s/it]Loading train:  21%|██        | 59/285 [01:09<04:15,  1.13s/it]Loading train:  21%|██        | 60/285 [01:10<04:12,  1.12s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:01,  1.08s/it]Loading train:  22%|██▏       | 62/285 [01:12<04:03,  1.09s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:59,  1.08s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:26,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:57,  1.35s/it]Loading train:  23%|██▎       | 66/285 [01:18<04:50,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:32,  1.25s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:17,  1.19s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:05,  1.14s/it]Loading train:  25%|██▍       | 70/285 [01:22<03:59,  1.11s/it]Loading train:  25%|██▍       | 71/285 [01:23<04:01,  1.13s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:53,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:45,  1.06s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:50,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:41,  1.07s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:33,  1.03s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:25,  1.00it/s]Loading train:  28%|██▊       | 80/285 [01:32<03:32,  1.04s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:35,  1.06s/it]Loading train:  29%|██▉       | 82/285 [01:35<03:36,  1.07s/it]Loading train:  29%|██▉       | 83/285 [01:36<03:29,  1.04s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:16,  1.02it/s]Loading train:  30%|██▉       | 85/285 [01:37<03:15,  1.03it/s]Loading train:  30%|███       | 86/285 [01:39<03:39,  1.10s/it]Loading train:  31%|███       | 87/285 [01:40<03:52,  1.17s/it]Loading train:  31%|███       | 88/285 [01:41<03:36,  1.10s/it]Loading train:  31%|███       | 89/285 [01:42<03:30,  1.07s/it]Loading train:  32%|███▏      | 90/285 [01:43<03:32,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:44<03:30,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:45<03:27,  1.07s/it]Loading train:  33%|███▎      | 93/285 [01:46<03:15,  1.02s/it]Loading train:  33%|███▎      | 94/285 [01:47<03:18,  1.04s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:31,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:50<03:39,  1.16s/it]Loading train:  34%|███▍      | 97/285 [01:51<03:32,  1.13s/it]Loading train:  34%|███▍      | 98/285 [01:52<03:31,  1.13s/it]Loading train:  35%|███▍      | 99/285 [01:53<03:32,  1.14s/it]Loading train:  35%|███▌      | 100/285 [01:55<03:41,  1.20s/it]Loading train:  35%|███▌      | 101/285 [01:55<03:25,  1.12s/it]Loading train:  36%|███▌      | 102/285 [01:57<03:22,  1.11s/it]Loading train:  36%|███▌      | 103/285 [01:58<03:16,  1.08s/it]Loading train:  36%|███▋      | 104/285 [01:59<03:10,  1.05s/it]Loading train:  37%|███▋      | 105/285 [02:00<03:05,  1.03s/it]Loading train:  37%|███▋      | 106/285 [02:01<03:01,  1.01s/it]Loading train:  38%|███▊      | 107/285 [02:02<03:03,  1.03s/it]Loading train:  38%|███▊      | 108/285 [02:03<02:59,  1.01s/it]Loading train:  38%|███▊      | 109/285 [02:04<02:58,  1.01s/it]Loading train:  39%|███▊      | 110/285 [02:05<02:56,  1.01s/it]Loading train:  39%|███▉      | 111/285 [02:06<02:53,  1.00it/s]Loading train:  39%|███▉      | 112/285 [02:07<02:59,  1.04s/it]Loading train:  40%|███▉      | 113/285 [02:08<02:57,  1.03s/it]Loading train:  40%|████      | 114/285 [02:09<02:50,  1.00it/s]Loading train:  40%|████      | 115/285 [02:10<02:52,  1.01s/it]Loading train:  41%|████      | 116/285 [02:11<02:54,  1.03s/it]Loading train:  41%|████      | 117/285 [02:12<02:51,  1.02s/it]Loading train:  41%|████▏     | 118/285 [02:13<02:52,  1.03s/it]Loading train:  42%|████▏     | 119/285 [02:14<02:50,  1.03s/it]Loading train:  42%|████▏     | 120/285 [02:15<02:44,  1.00it/s]Loading train:  42%|████▏     | 121/285 [02:16<03:03,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:03,  1.13s/it]Loading train:  43%|████▎     | 123/285 [02:18<03:05,  1.15s/it]Loading train:  44%|████▎     | 124/285 [02:19<02:55,  1.09s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:45,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:37,  1.01it/s]Loading train:  45%|████▍     | 127/285 [02:22<02:32,  1.04it/s]Loading train:  45%|████▍     | 128/285 [02:23<02:27,  1.06it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:14,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:24<02:03,  1.26it/s]Loading train:  46%|████▌     | 131/285 [02:25<02:05,  1.23it/s]Loading train:  46%|████▋     | 132/285 [02:26<02:10,  1.17it/s]Loading train:  47%|████▋     | 133/285 [02:27<02:14,  1.13it/s]Loading train:  47%|████▋     | 134/285 [02:28<02:19,  1.08it/s]Loading train:  47%|████▋     | 135/285 [02:29<02:16,  1.10it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:06,  1.18it/s]Loading train:  48%|████▊     | 137/285 [02:30<01:59,  1.24it/s]Loading train:  48%|████▊     | 138/285 [02:31<02:05,  1.17it/s]Loading train:  49%|████▉     | 139/285 [02:32<01:59,  1.22it/s]Loading train:  49%|████▉     | 140/285 [02:33<01:52,  1.29it/s]Loading train:  49%|████▉     | 141/285 [02:33<01:47,  1.34it/s]Loading train:  50%|████▉     | 142/285 [02:34<01:42,  1.40it/s]Loading train:  50%|█████     | 143/285 [02:35<01:37,  1.45it/s]Loading train:  51%|█████     | 144/285 [02:36<01:49,  1.28it/s]Loading train:  51%|█████     | 145/285 [02:37<01:52,  1.24it/s]Loading train:  51%|█████     | 146/285 [02:37<01:50,  1.26it/s]Loading train:  52%|█████▏    | 147/285 [02:38<01:52,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:39<01:57,  1.16it/s]Loading train:  52%|█████▏    | 149/285 [02:40<01:51,  1.22it/s]Loading train:  53%|█████▎    | 150/285 [02:41<01:43,  1.30it/s]Loading train:  53%|█████▎    | 151/285 [02:41<01:46,  1.26it/s]Loading train:  53%|█████▎    | 152/285 [02:42<01:49,  1.22it/s]Loading train:  54%|█████▎    | 153/285 [02:43<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [02:44<01:49,  1.20it/s]Loading train:  54%|█████▍    | 155/285 [02:45<01:48,  1.19it/s]Loading train:  55%|█████▍    | 156/285 [02:46<01:50,  1.17it/s]Loading train:  55%|█████▌    | 157/285 [02:46<01:46,  1.20it/s]Loading train:  55%|█████▌    | 158/285 [02:47<01:40,  1.26it/s]Loading train:  56%|█████▌    | 159/285 [02:48<01:36,  1.31it/s]Loading train:  56%|█████▌    | 160/285 [02:49<01:36,  1.30it/s]Loading train:  56%|█████▋    | 161/285 [02:50<01:39,  1.24it/s]Loading train:  57%|█████▋    | 162/285 [02:50<01:33,  1.31it/s]Loading train:  57%|█████▋    | 163/285 [02:51<01:32,  1.32it/s]Loading train:  58%|█████▊    | 164/285 [02:52<01:27,  1.38it/s]Loading train:  58%|█████▊    | 165/285 [02:52<01:26,  1.39it/s]Loading train:  58%|█████▊    | 166/285 [02:53<01:25,  1.40it/s]Loading train:  59%|█████▊    | 167/285 [02:54<01:23,  1.42it/s]Loading train:  59%|█████▉    | 168/285 [02:54<01:21,  1.44it/s]Loading train:  59%|█████▉    | 169/285 [02:55<01:19,  1.47it/s]Loading train:  60%|█████▉    | 170/285 [02:56<01:16,  1.50it/s]Loading train:  60%|██████    | 171/285 [02:56<01:14,  1.54it/s]Loading train:  60%|██████    | 172/285 [02:57<01:13,  1.53it/s]Loading train:  61%|██████    | 173/285 [02:58<01:13,  1.53it/s]Loading train:  61%|██████    | 174/285 [02:58<01:10,  1.58it/s]Loading train:  61%|██████▏   | 175/285 [02:59<01:11,  1.54it/s]Loading train:  62%|██████▏   | 176/285 [03:00<01:11,  1.52it/s]Loading train:  62%|██████▏   | 177/285 [03:00<01:09,  1.56it/s]Loading train:  62%|██████▏   | 178/285 [03:01<01:11,  1.49it/s]Loading train:  63%|██████▎   | 179/285 [03:02<01:13,  1.44it/s]Loading train:  63%|██████▎   | 180/285 [03:03<01:27,  1.20it/s]Loading train:  64%|██████▎   | 181/285 [03:04<01:26,  1.21it/s]Loading train:  64%|██████▍   | 182/285 [03:04<01:24,  1.22it/s]Loading train:  64%|██████▍   | 183/285 [03:05<01:20,  1.26it/s]Loading train:  65%|██████▍   | 184/285 [03:06<01:19,  1.27it/s]Loading train:  65%|██████▍   | 185/285 [03:07<01:16,  1.30it/s]Loading train:  65%|██████▌   | 186/285 [03:07<01:18,  1.26it/s]Loading train:  66%|██████▌   | 187/285 [03:08<01:22,  1.19it/s]Loading train:  66%|██████▌   | 188/285 [03:09<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [03:10<01:23,  1.16it/s]Loading train:  67%|██████▋   | 190/285 [03:11<01:18,  1.21it/s]Loading train:  67%|██████▋   | 191/285 [03:12<01:19,  1.18it/s]Loading train:  67%|██████▋   | 192/285 [03:13<01:17,  1.20it/s]Loading train:  68%|██████▊   | 193/285 [03:13<01:12,  1.27it/s]Loading train:  68%|██████▊   | 194/285 [03:14<01:11,  1.26it/s]Loading train:  68%|██████▊   | 195/285 [03:15<01:09,  1.29it/s]Loading train:  69%|██████▉   | 196/285 [03:16<01:13,  1.22it/s]Loading train:  69%|██████▉   | 197/285 [03:17<01:14,  1.18it/s]Loading train:  69%|██████▉   | 198/285 [03:18<01:15,  1.15it/s]Loading train:  70%|██████▉   | 199/285 [03:18<01:09,  1.23it/s]Loading train:  70%|███████   | 200/285 [03:19<01:06,  1.28it/s]Loading train:  71%|███████   | 201/285 [03:20<01:07,  1.24it/s]Loading train:  71%|███████   | 202/285 [03:21<01:06,  1.25it/s]Loading train:  71%|███████   | 203/285 [03:21<01:04,  1.28it/s]Loading train:  72%|███████▏  | 204/285 [03:22<01:01,  1.32it/s]Loading train:  72%|███████▏  | 205/285 [03:23<00:59,  1.35it/s]Loading train:  72%|███████▏  | 206/285 [03:24<00:59,  1.34it/s]Loading train:  73%|███████▎  | 207/285 [03:25<01:01,  1.26it/s]Loading train:  73%|███████▎  | 208/285 [03:25<01:03,  1.20it/s]Loading train:  73%|███████▎  | 209/285 [03:26<01:06,  1.15it/s]Loading train:  74%|███████▎  | 210/285 [03:27<01:03,  1.18it/s]Loading train:  74%|███████▍  | 211/285 [03:28<00:59,  1.24it/s]Loading train:  74%|███████▍  | 212/285 [03:29<00:58,  1.25it/s]Loading train:  75%|███████▍  | 213/285 [03:29<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:30<00:54,  1.30it/s]Loading train:  75%|███████▌  | 215/285 [03:31<00:57,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:32<00:52,  1.31it/s]Loading train:  76%|███████▌  | 217/285 [03:33<00:55,  1.22it/s]Loading train:  76%|███████▋  | 218/285 [03:34<00:56,  1.19it/s]Loading train:  77%|███████▋  | 219/285 [03:34<00:55,  1.18it/s]Loading train:  77%|███████▋  | 220/285 [03:35<00:50,  1.29it/s]Loading train:  78%|███████▊  | 221/285 [03:36<00:46,  1.38it/s]Loading train:  78%|███████▊  | 222/285 [03:36<00:45,  1.39it/s]Loading train:  78%|███████▊  | 223/285 [03:37<00:41,  1.48it/s]Loading train:  79%|███████▊  | 224/285 [03:38<00:41,  1.47it/s]Loading train:  79%|███████▉  | 225/285 [03:38<00:38,  1.54it/s]Loading train:  79%|███████▉  | 226/285 [03:39<00:42,  1.38it/s]Loading train:  80%|███████▉  | 227/285 [03:40<00:43,  1.33it/s]Loading train:  80%|████████  | 228/285 [03:41<00:44,  1.29it/s]Loading train:  80%|████████  | 229/285 [03:41<00:42,  1.32it/s]Loading train:  81%|████████  | 230/285 [03:42<00:39,  1.38it/s]Loading train:  81%|████████  | 231/285 [03:43<00:37,  1.43it/s]Loading train:  81%|████████▏ | 232/285 [03:43<00:37,  1.41it/s]Loading train:  82%|████████▏ | 233/285 [03:44<00:35,  1.46it/s]Loading train:  82%|████████▏ | 234/285 [03:45<00:37,  1.35it/s]Loading train:  82%|████████▏ | 235/285 [03:46<00:34,  1.43it/s]Loading train:  83%|████████▎ | 236/285 [03:46<00:36,  1.32it/s]Loading train:  83%|████████▎ | 237/285 [03:47<00:37,  1.29it/s]Loading train:  84%|████████▎ | 238/285 [03:48<00:37,  1.25it/s]Loading train:  84%|████████▍ | 239/285 [03:49<00:35,  1.31it/s]Loading train:  84%|████████▍ | 240/285 [03:49<00:32,  1.39it/s]Loading train:  85%|████████▍ | 241/285 [03:50<00:30,  1.42it/s]Loading train:  85%|████████▍ | 242/285 [03:51<00:29,  1.46it/s]Loading train:  85%|████████▌ | 243/285 [03:51<00:28,  1.49it/s]Loading train:  86%|████████▌ | 244/285 [03:52<00:30,  1.36it/s]Loading train:  86%|████████▌ | 245/285 [03:53<00:27,  1.44it/s]Loading train:  86%|████████▋ | 246/285 [03:54<00:28,  1.35it/s]Loading train:  87%|████████▋ | 247/285 [03:55<00:29,  1.31it/s]Loading train:  87%|████████▋ | 248/285 [03:55<00:27,  1.37it/s]Loading train:  87%|████████▋ | 249/285 [03:56<00:24,  1.45it/s]Loading train:  88%|████████▊ | 250/285 [03:56<00:23,  1.49it/s]Loading train:  88%|████████▊ | 251/285 [03:57<00:22,  1.48it/s]Loading train:  88%|████████▊ | 252/285 [03:58<00:21,  1.51it/s]Loading train:  89%|████████▉ | 253/285 [03:59<00:23,  1.39it/s]Loading train:  89%|████████▉ | 254/285 [03:59<00:23,  1.34it/s]Loading train:  89%|████████▉ | 255/285 [04:00<00:22,  1.32it/s]Loading train:  90%|████████▉ | 256/285 [04:01<00:20,  1.40it/s]Loading train:  90%|█████████ | 257/285 [04:01<00:19,  1.42it/s]Loading train:  91%|█████████ | 258/285 [04:02<00:20,  1.33it/s]Loading train:  91%|█████████ | 259/285 [04:03<00:18,  1.38it/s]Loading train:  91%|█████████ | 260/285 [04:04<00:17,  1.45it/s]Loading train:  92%|█████████▏| 261/285 [04:04<00:16,  1.46it/s]Loading train:  92%|█████████▏| 262/285 [04:05<00:15,  1.52it/s]Loading train:  92%|█████████▏| 263/285 [04:06<00:14,  1.54it/s]Loading train:  93%|█████████▎| 264/285 [04:06<00:14,  1.40it/s]Loading train:  93%|█████████▎| 265/285 [04:07<00:15,  1.33it/s]Loading train:  93%|█████████▎| 266/285 [04:08<00:13,  1.40it/s]Loading train:  94%|█████████▎| 267/285 [04:08<00:12,  1.45it/s]Loading train:  94%|█████████▍| 268/285 [04:09<00:12,  1.35it/s]Loading train:  94%|█████████▍| 269/285 [04:10<00:12,  1.33it/s]Loading train:  95%|█████████▍| 270/285 [04:11<00:10,  1.40it/s]Loading train:  95%|█████████▌| 271/285 [04:11<00:09,  1.44it/s]Loading train:  95%|█████████▌| 272/285 [04:12<00:09,  1.40it/s]Loading train:  96%|█████████▌| 273/285 [04:13<00:08,  1.48it/s]Loading train:  96%|█████████▌| 274/285 [04:13<00:07,  1.54it/s]Loading train:  96%|█████████▋| 275/285 [04:14<00:07,  1.42it/s]Loading train:  97%|█████████▋| 276/285 [04:15<00:06,  1.35it/s]Loading train:  97%|█████████▋| 277/285 [04:16<00:05,  1.40it/s]Loading train:  98%|█████████▊| 278/285 [04:16<00:05,  1.39it/s]Loading train:  98%|█████████▊| 279/285 [04:17<00:04,  1.40it/s]Loading train:  98%|█████████▊| 280/285 [04:18<00:03,  1.47it/s]Loading train:  99%|█████████▊| 281/285 [04:18<00:02,  1.49it/s]Loading train:  99%|█████████▉| 282/285 [04:19<00:01,  1.50it/s]Loading train:  99%|█████████▉| 283/285 [04:20<00:01,  1.41it/s]Loading train: 100%|█████████▉| 284/285 [04:21<00:00,  1.34it/s]Loading train: 100%|██████████| 285/285 [04:21<00:00,  1.28it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:00, 330.32it/s]concatenating: train:  23%|██▎       | 66/285 [00:00<00:00, 326.71it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:00, 329.69it/s]concatenating: train:  47%|████▋     | 135/285 [00:00<00:00, 335.19it/s]concatenating: train:  60%|█████▉    | 170/285 [00:00<00:00, 338.30it/s]concatenating: train:  72%|███████▏  | 204/285 [00:00<00:00, 336.26it/s]concatenating: train:  84%|████████▎ | 238/285 [00:00<00:00, 335.94it/s]concatenating: train:  97%|█████████▋| 277/285 [00:00<00:00, 349.62it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 344.89it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.11s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.11s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 805.82it/s]2019-07-11 08:32:09.781766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 08:32:09.781856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 08:32:09.781871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 08:32:09.781890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 08:32:09.782303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.28it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.20it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.79it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.41it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.50it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.43it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.55it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.48it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.95it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.37it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.22it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.61it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.78it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.42it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.76it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.77it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.74it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.92it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 10)   4060        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 10)   910         dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 55)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   728         concatenate_8[0][0]              
==================================================================================================
Total params: 133,148
Trainable params: 34,628
Non-trainable params: 98,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 14s - loss: 3.3678 - acc: 0.1207 - mDice: 0.0612 - val_loss: 3.1312 - val_acc: 0.5405 - val_mDice: 0.1114

Epoch 00001: val_mDice improved from -inf to 0.11136, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.8665 - acc: 0.7943 - mDice: 0.1825 - val_loss: 1.9720 - val_acc: 0.9056 - val_mDice: 0.2511

Epoch 00002: val_mDice improved from 0.11136 to 0.25113, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 1.1513 - acc: 0.8728 - mDice: 0.3056 - val_loss: 1.7799 - val_acc: 0.9064 - val_mDice: 0.3174

Epoch 00003: val_mDice improved from 0.25113 to 0.31741, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.9438 - acc: 0.8791 - mDice: 0.3746 - val_loss: 1.4038 - val_acc: 0.9084 - val_mDice: 0.4084

Epoch 00004: val_mDice improved from 0.31741 to 0.40845, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.8361 - acc: 0.8826 - mDice: 0.4173 - val_loss: 1.3323 - val_acc: 0.9129 - val_mDice: 0.4408

Epoch 00005: val_mDice improved from 0.40845 to 0.44080, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.7651 - acc: 0.8856 - mDice: 0.4487 - val_loss: 1.3344 - val_acc: 0.9150 - val_mDice: 0.4365

Epoch 00006: val_mDice did not improve from 0.44080
Epoch 7/300
 - 9s - loss: 0.7131 - acc: 0.8879 - mDice: 0.4729 - val_loss: 1.2418 - val_acc: 0.9159 - val_mDice: 0.4475

Epoch 00007: val_mDice improved from 0.44080 to 0.44752, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.6794 - acc: 0.8897 - mDice: 0.4896 - val_loss: 1.1874 - val_acc: 0.9188 - val_mDice: 0.4678

Epoch 00008: val_mDice improved from 0.44752 to 0.46784, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.6490 - acc: 0.8923 - mDice: 0.5051 - val_loss: 1.1711 - val_acc: 0.9186 - val_mDice: 0.4640

Epoch 00009: val_mDice did not improve from 0.46784
Epoch 10/300
 - 9s - loss: 0.6238 - acc: 0.8945 - mDice: 0.5186 - val_loss: 1.0977 - val_acc: 0.9214 - val_mDice: 0.4857

Epoch 00010: val_mDice improved from 0.46784 to 0.48568, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.6008 - acc: 0.8971 - mDice: 0.5312 - val_loss: 1.0658 - val_acc: 0.9255 - val_mDice: 0.4944

Epoch 00011: val_mDice improved from 0.48568 to 0.49437, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.5818 - acc: 0.8994 - mDice: 0.5418 - val_loss: 1.0990 - val_acc: 0.9280 - val_mDice: 0.4854

Epoch 00012: val_mDice did not improve from 0.49437
Epoch 13/300
 - 9s - loss: 0.5676 - acc: 0.9021 - mDice: 0.5499 - val_loss: 1.0861 - val_acc: 0.9285 - val_mDice: 0.4887

Epoch 00013: val_mDice did not improve from 0.49437
Epoch 14/300
 - 9s - loss: 0.5548 - acc: 0.9046 - mDice: 0.5572 - val_loss: 1.0320 - val_acc: 0.9306 - val_mDice: 0.5033

Epoch 00014: val_mDice improved from 0.49437 to 0.50334, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 9s - loss: 0.5413 - acc: 0.9072 - mDice: 0.5654 - val_loss: 1.0432 - val_acc: 0.9251 - val_mDice: 0.5059

Epoch 00015: val_mDice improved from 0.50334 to 0.50585, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.5322 - acc: 0.9097 - mDice: 0.5707 - val_loss: 1.0410 - val_acc: 0.9294 - val_mDice: 0.5152

Epoch 00016: val_mDice improved from 0.50585 to 0.51524, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 9s - loss: 0.5225 - acc: 0.9118 - mDice: 0.5766 - val_loss: 1.0587 - val_acc: 0.9275 - val_mDice: 0.4964

Epoch 00017: val_mDice did not improve from 0.51524
Epoch 18/300
 - 9s - loss: 0.5116 - acc: 0.9137 - mDice: 0.5831 - val_loss: 0.9834 - val_acc: 0.9314 - val_mDice: 0.5182

Epoch 00018: val_mDice improved from 0.51524 to 0.51820, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 9s - loss: 0.5042 - acc: 0.9147 - mDice: 0.5874 - val_loss: 1.0210 - val_acc: 0.9253 - val_mDice: 0.5102

Epoch 00019: val_mDice did not improve from 0.51820
Epoch 20/300
 - 9s - loss: 0.4937 - acc: 0.9160 - mDice: 0.5938 - val_loss: 0.9827 - val_acc: 0.9311 - val_mDice: 0.5134

Epoch 00020: val_mDice did not improve from 0.51820
Epoch 21/300
 - 9s - loss: 0.4908 - acc: 0.9167 - mDice: 0.5957 - val_loss: 1.0742 - val_acc: 0.9279 - val_mDice: 0.5133

Epoch 00021: val_mDice did not improve from 0.51820
Epoch 22/300
 - 9s - loss: 0.4824 - acc: 0.9176 - mDice: 0.6009 - val_loss: 1.0111 - val_acc: 0.9275 - val_mDice: 0.5096

Epoch 00022: val_mDice did not improve from 0.51820
Epoch 23/300
 - 9s - loss: 0.4768 - acc: 0.9183 - mDice: 0.6043 - val_loss: 1.0383 - val_acc: 0.9270 - val_mDice: 0.5157

Epoch 00023: val_mDice did not improve from 0.51820
Epoch 24/300
 - 9s - loss: 0.4718 - acc: 0.9192 - mDice: 0.6076 - val_loss: 1.0313 - val_acc: 0.9284 - val_mDice: 0.5105

Epoch 00024: val_mDice did not improve from 0.51820
Epoch 25/300
 - 9s - loss: 0.4674 - acc: 0.9199 - mDice: 0.6105 - val_loss: 0.9928 - val_acc: 0.9336 - val_mDice: 0.5097

Epoch 00025: val_mDice did not improve from 0.51820
Epoch 26/300
 - 9s - loss: 0.4620 - acc: 0.9204 - mDice: 0.6140 - val_loss: 0.9852 - val_acc: 0.9328 - val_mDice: 0.5174

Epoch 00026: val_mDice did not improve from 0.51820
Epoch 27/300
 - 9s - loss: 0.4563 - acc: 0.9210 - mDice: 0.6175 - val_loss: 1.0114 - val_acc: 0.9315 - val_mDice: 0.5124

Epoch 00027: val_mDice did not improve from 0.51820
Epoch 28/300
 - 9s - loss: 0.4559 - acc: 0.9212 - mDice: 0.6178 - val_loss: 0.9604 - val_acc: 0.9310 - val_mDice: 0.5167

Epoch 00028: val_mDice did not improve from 0.51820
Epoch 29/300
 - 9s - loss: 0.4514 - acc: 0.9218 - mDice: 0.6207 - val_loss: 0.9737 - val_acc: 0.9327 - val_mDice: 0.5109

Epoch 00029: val_mDice did not improve from 0.51820
Epoch 30/300
 - 9s - loss: 0.4452 - acc: 0.9226 - mDice: 0.6247 - val_loss: 0.9448 - val_acc: 0.9326 - val_mDice: 0.5157

Epoch 00030: val_mDice did not improve from 0.51820
Epoch 31/300
 - 9s - loss: 0.4417 - acc: 0.9230 - mDice: 0.6270 - val_loss: 1.0105 - val_acc: 0.9289 - val_mDice: 0.5141

Epoch 00031: val_mDice did not improve from 0.51820
Epoch 32/300
 - 9s - loss: 0.4373 - acc: 0.9236 - mDice: 0.6300 - val_loss: 0.9334 - val_acc: 0.9374 - val_mDice: 0.5177

Epoch 00032: val_mDice did not improve from 0.51820
Epoch 33/300
 - 9s - loss: 0.4354 - acc: 0.9238 - mDice: 0.6312 - val_loss: 0.9503 - val_acc: 0.9360 - val_mDice: 0.5253

Epoch 00033: val_mDice improved from 0.51820 to 0.52530, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 9s - loss: 0.4318 - acc: 0.9243 - mDice: 0.6336 - val_loss: 0.9382 - val_acc: 0.9368 - val_mDice: 0.5214

Epoch 00034: val_mDice did not improve from 0.52530
Epoch 35/300
 - 9s - loss: 0.4291 - acc: 0.9246 - mDice: 0.6353 - val_loss: 0.9326 - val_acc: 0.9302 - val_mDice: 0.5113

Epoch 00035: val_mDice did not improve from 0.52530
Epoch 36/300
 - 9s - loss: 0.4254 - acc: 0.9250 - mDice: 0.6376 - val_loss: 0.9053 - val_acc: 0.9340 - val_mDice: 0.5254

Epoch 00036: val_mDice improved from 0.52530 to 0.52541, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 9s - loss: 0.4220 - acc: 0.9254 - mDice: 0.6399 - val_loss: 0.8973 - val_acc: 0.9346 - val_mDice: 0.5160

Epoch 00037: val_mDice did not improve from 0.52541
Epoch 38/300
 - 9s - loss: 0.4223 - acc: 0.9258 - mDice: 0.6398 - val_loss: 0.9577 - val_acc: 0.9345 - val_mDice: 0.5164

Epoch 00038: val_mDice did not improve from 0.52541
Epoch 39/300
 - 9s - loss: 0.4174 - acc: 0.9263 - mDice: 0.6431 - val_loss: 0.9091 - val_acc: 0.9364 - val_mDice: 0.5174

Epoch 00039: val_mDice did not improve from 0.52541
Epoch 40/300
 - 9s - loss: 0.4169 - acc: 0.9265 - mDice: 0.6436 - val_loss: 0.8841 - val_acc: 0.9387 - val_mDice: 0.5281

Epoch 00040: val_mDice improved from 0.52541 to 0.52814, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 9s - loss: 0.4150 - acc: 0.9267 - mDice: 0.6449 - val_loss: 0.9158 - val_acc: 0.9333 - val_mDice: 0.5158

Epoch 00041: val_mDice did not improve from 0.52814
Epoch 42/300
 - 9s - loss: 0.4097 - acc: 0.9271 - mDice: 0.6484 - val_loss: 0.8561 - val_acc: 0.9358 - val_mDice: 0.5140

Epoch 00042: val_mDice did not improve from 0.52814
Epoch 43/300
 - 9s - loss: 0.4078 - acc: 0.9275 - mDice: 0.6496 - val_loss: 0.8657 - val_acc: 0.9362 - val_mDice: 0.5175

Epoch 00043: val_mDice did not improve from 0.52814
Epoch 44/300
 - 9s - loss: 0.4050 - acc: 0.9278 - mDice: 0.6516 - val_loss: 0.8600 - val_acc: 0.9369 - val_mDice: 0.5142

Epoch 00044: val_mDice did not improve from 0.52814
Epoch 45/300
 - 9s - loss: 0.4035 - acc: 0.9279 - mDice: 0.6524 - val_loss: 0.8722 - val_acc: 0.9372 - val_mDice: 0.5206

Epoch 00045: val_mDice did not improve from 0.52814
Epoch 46/300
 - 9s - loss: 0.4001 - acc: 0.9284 - mDice: 0.6547 - val_loss: 0.8726 - val_acc: 0.9371 - val_mDice: 0.5172

Epoch 00046: val_mDice did not improve from 0.52814
Epoch 47/300
 - 9s - loss: 0.3986 - acc: 0.9287 - mDice: 0.6558 - val_loss: 0.8629 - val_acc: 0.9376 - val_mDice: 0.5151

Epoch 00047: val_mDice did not improve from 0.52814
Epoch 48/300
 - 9s - loss: 0.3967 - acc: 0.9288 - mDice: 0.6571 - val_loss: 0.8355 - val_acc: 0.9316 - val_mDice: 0.5116

Epoch 00048: val_mDice did not improve from 0.52814
Epoch 49/300
 - 9s - loss: 0.3955 - acc: 0.9290 - mDice: 0.6581 - val_loss: 0.8109 - val_acc: 0.9352 - val_mDice: 0.5164

Epoch 00049: val_mDice did not improve from 0.52814
Epoch 50/300
 - 9s - loss: 0.3923 - acc: 0.9294 - mDice: 0.6601 - val_loss: 0.7678 - val_acc: 0.9382 - val_mDice: 0.5317

Epoch 00050: val_mDice improved from 0.52814 to 0.53172, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 51/300
 - 9s - loss: 0.3910 - acc: 0.9295 - mDice: 0.6611 - val_loss: 0.8072 - val_acc: 0.9383 - val_mDice: 0.5169

Epoch 00051: val_mDice did not improve from 0.53172
Epoch 52/300
 - 9s - loss: 0.3905 - acc: 0.9296 - mDice: 0.6614 - val_loss: 0.7605 - val_acc: 0.9370 - val_mDice: 0.5149

Epoch 00052: val_mDice did not improve from 0.53172
Epoch 53/300
 - 9s - loss: 0.3863 - acc: 0.9302 - mDice: 0.6643 - val_loss: 0.7489 - val_acc: 0.9370 - val_mDice: 0.5160

Epoch 00053: val_mDice did not improve from 0.53172
Epoch 54/300
 - 9s - loss: 0.3856 - acc: 0.9302 - mDice: 0.6647 - val_loss: 0.7562 - val_acc: 0.9375 - val_mDice: 0.5205

Epoch 00054: val_mDice did not improve from 0.53172
Epoch 55/300
 - 9s - loss: 0.3852 - acc: 0.9303 - mDice: 0.6651 - val_loss: 0.7660 - val_acc: 0.9356 - val_mDice: 0.5201

Epoch 00055: val_mDice did not improve from 0.53172
Epoch 56/300
 - 9s - loss: 0.3841 - acc: 0.9302 - mDice: 0.6659 - val_loss: 0.7131 - val_acc: 0.9393 - val_mDice: 0.5198

Epoch 00056: val_mDice did not improve from 0.53172
Epoch 57/300
 - 9s - loss: 0.3820 - acc: 0.9307 - mDice: 0.6673 - val_loss: 0.7333 - val_acc: 0.9408 - val_mDice: 0.5280

Epoch 00057: val_mDice did not improve from 0.53172
Epoch 58/300
 - 9s - loss: 0.3818 - acc: 0.9307 - mDice: 0.6673 - val_loss: 0.7863 - val_acc: 0.9363 - val_mDice: 0.5163

Epoch 00058: val_mDice did not improve from 0.53172
Epoch 59/300
 - 9s - loss: 0.3807 - acc: 0.9307 - mDice: 0.6680 - val_loss: 0.7850 - val_acc: 0.9355 - val_mDice: 0.5191

Epoch 00059: val_mDice did not improve from 0.53172
Epoch 60/300
 - 9s - loss: 0.3777 - acc: 0.9311 - mDice: 0.6702 - val_loss: 0.7383 - val_acc: 0.9370 - val_mDice: 0.5225

Epoch 00060: val_mDice did not improve from 0.53172
Epoch 61/300
 - 9s - loss: 0.3766 - acc: 0.9312 - mDice: 0.6710 - val_loss: 0.7444 - val_acc: 0.9364 - val_mDice: 0.5252

Epoch 00061: val_mDice did not improve from 0.53172
Epoch 62/300
 - 9s - loss: 0.3763 - acc: 0.9313 - mDice: 0.6713 - val_loss: 0.7244 - val_acc: 0.9348 - val_mDice: 0.5318

Epoch 00062: val_mDice improved from 0.53172 to 0.53184, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 9s - loss: 0.3738 - acc: 0.9315 - mDice: 0.6730 - val_loss: 0.7126 - val_acc: 0.9375 - val_mDice: 0.5183

Epoch 00063: val_mDice did not improve from 0.53184
Epoch 64/300
 - 9s - loss: 0.3724 - acc: 0.9318 - mDice: 0.6740 - val_loss: 0.6959 - val_acc: 0.9381 - val_mDice: 0.5153

Epoch 00064: val_mDice did not improve from 0.53184
Epoch 65/300
 - 9s - loss: 0.3721 - acc: 0.9319 - mDice: 0.6742 - val_loss: 0.7295 - val_acc: 0.9373 - val_mDice: 0.5295

Epoch 00065: val_mDice did not improve from 0.53184
Epoch 66/300
 - 9s - loss: 0.3711 - acc: 0.9320 - mDice: 0.6749 - val_loss: 0.6772 - val_acc: 0.9376 - val_mDice: 0.5166

Epoch 00066: val_mDice did not improve from 0.53184
Epoch 67/300
 - 9s - loss: 0.3695 - acc: 0.9320 - mDice: 0.6760 - val_loss: 0.7268 - val_acc: 0.9388 - val_mDice: 0.5262

Epoch 00067: val_mDice did not improve from 0.53184
Epoch 68/300
 - 9s - loss: 0.3683 - acc: 0.9320 - mDice: 0.6768 - val_loss: 0.6744 - val_acc: 0.9398 - val_mDice: 0.5288

Epoch 00068: val_mDice did not improve from 0.53184
Epoch 69/300
 - 9s - loss: 0.3669 - acc: 0.9323 - mDice: 0.6777 - val_loss: 0.6549 - val_acc: 0.9380 - val_mDice: 0.5165

Epoch 00069: val_mDice did not improve from 0.53184
Epoch 70/300
 - 9s - loss: 0.3661 - acc: 0.9325 - mDice: 0.6784 - val_loss: 0.6755 - val_acc: 0.9350 - val_mDice: 0.5127

Epoch 00070: val_mDice did not improve from 0.53184
Epoch 71/300
 - 9s - loss: 0.3637 - acc: 0.9325 - mDice: 0.6801 - val_loss: 0.6888 - val_acc: 0.9376 - val_mDice: 0.5288

Epoch 00071: val_mDice did not improve from 0.53184
Epoch 72/300
 - 9s - loss: 0.3634 - acc: 0.9327 - mDice: 0.6803 - val_loss: 0.6354 - val_acc: 0.9393 - val_mDice: 0.5248

Epoch 00072: val_mDice did not improve from 0.53184
Epoch 73/300
 - 9s - loss: 0.3637 - acc: 0.9327 - mDice: 0.6800 - val_loss: 0.6267 - val_acc: 0.9401 - val_mDice: 0.5333

Epoch 00073: val_mDice improved from 0.53184 to 0.53327, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 9s - loss: 0.3616 - acc: 0.9329 - mDice: 0.6814 - val_loss: 0.6464 - val_acc: 0.9392 - val_mDice: 0.5204

Epoch 00074: val_mDice did not improve from 0.53327
Epoch 75/300
 - 9s - loss: 0.3629 - acc: 0.9329 - mDice: 0.6807 - val_loss: 0.6598 - val_acc: 0.9354 - val_mDice: 0.5114

Epoch 00075: val_mDice did not improve from 0.53327
Epoch 76/300
 - 9s - loss: 0.3609 - acc: 0.9329 - mDice: 0.6820 - val_loss: 0.6403 - val_acc: 0.9392 - val_mDice: 0.5208

Epoch 00076: val_mDice did not improve from 0.53327
Epoch 77/300
 - 9s - loss: 0.3601 - acc: 0.9331 - mDice: 0.6826 - val_loss: 0.6382 - val_acc: 0.9400 - val_mDice: 0.5244

Epoch 00077: val_mDice did not improve from 0.53327
Epoch 78/300
 - 9s - loss: 0.3576 - acc: 0.9333 - mDice: 0.6844 - val_loss: 0.6174 - val_acc: 0.9415 - val_mDice: 0.5238

Epoch 00078: val_mDice did not improve from 0.53327
Epoch 79/300
 - 9s - loss: 0.3591 - acc: 0.9331 - mDice: 0.6833 - val_loss: 0.6903 - val_acc: 0.9373 - val_mDice: 0.5221

Epoch 00079: val_mDice did not improve from 0.53327
Epoch 80/300
 - 9s - loss: 0.3561 - acc: 0.9335 - mDice: 0.6853 - val_loss: 0.6802 - val_acc: 0.9372 - val_mDice: 0.5169

Epoch 00080: val_mDice did not improve from 0.53327
Epoch 81/300
 - 9s - loss: 0.3572 - acc: 0.9333 - mDice: 0.6847 - val_loss: 0.6372 - val_acc: 0.9384 - val_mDice: 0.5263

Epoch 00081: val_mDice did not improve from 0.53327
Epoch 82/300
 - 9s - loss: 0.3551 - acc: 0.9335 - mDice: 0.6862 - val_loss: 0.6450 - val_acc: 0.9350 - val_mDice: 0.5068

Epoch 00082: val_mDice did not improve from 0.53327
Epoch 83/300
 - 9s - loss: 0.3546 - acc: 0.9336 - mDice: 0.6865 - val_loss: 0.7783 - val_acc: 0.9341 - val_mDice: 0.4987

Epoch 00083: val_mDice did not improve from 0.53327
Epoch 84/300
 - 9s - loss: 0.3539 - acc: 0.9337 - mDice: 0.6871 - val_loss: 0.5998 - val_acc: 0.9372 - val_mDice: 0.5301

Epoch 00084: val_mDice did not improve from 0.53327
Epoch 85/300
 - 9s - loss: 0.3531 - acc: 0.9337 - mDice: 0.6875 - val_loss: 0.6154 - val_acc: 0.9387 - val_mDice: 0.5215

Epoch 00085: val_mDice did not improve from 0.53327
Epoch 86/300
 - 9s - loss: 0.3516 - acc: 0.9339 - mDice: 0.6886 - val_loss: 0.5945 - val_acc: 0.9421 - val_mDice: 0.5383

Epoch 00086: val_mDice improved from 0.53327 to 0.53834, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 87/300
 - 9s - loss: 0.3526 - acc: 0.9338 - mDice: 0.6880 - val_loss: 0.6055 - val_acc: 0.9416 - val_mDice: 0.5347

Epoch 00087: val_mDice did not improve from 0.53834
Epoch 88/300
 - 9s - loss: 0.3507 - acc: 0.9342 - mDice: 0.6892 - val_loss: 0.6253 - val_acc: 0.9385 - val_mDice: 0.5215

Epoch 00088: val_mDice did not improve from 0.53834
Epoch 89/300
 - 9s - loss: 0.3520 - acc: 0.9339 - mDice: 0.6884 - val_loss: 0.6302 - val_acc: 0.9367 - val_mDice: 0.5114

Epoch 00089: val_mDice did not improve from 0.53834
Epoch 90/300
 - 9s - loss: 0.3506 - acc: 0.9340 - mDice: 0.6893 - val_loss: 0.6284 - val_acc: 0.9359 - val_mDice: 0.5156

Epoch 00090: val_mDice did not improve from 0.53834
Epoch 91/300
 - 9s - loss: 0.3494 - acc: 0.9342 - mDice: 0.6902 - val_loss: 0.6354 - val_acc: 0.9368 - val_mDice: 0.5213

Epoch 00091: val_mDice did not improve from 0.53834
Epoch 92/300
 - 9s - loss: 0.3481 - acc: 0.9345 - mDice: 0.6911 - val_loss: 0.6046 - val_acc: 0.9399 - val_mDice: 0.5292

Epoch 00092: val_mDice did not improve from 0.53834
Epoch 93/300
 - 9s - loss: 0.3456 - acc: 0.9345 - mDice: 0.6930 - val_loss: 0.5964 - val_acc: 0.9348 - val_mDice: 0.5276

Epoch 00093: val_mDice did not improve from 0.53834
Epoch 94/300
 - 9s - loss: 0.3469 - acc: 0.9345 - mDice: 0.6920 - val_loss: 0.6006 - val_acc: 0.9392 - val_mDice: 0.5264

Epoch 00094: val_mDice did not improve from 0.53834
Epoch 95/300
 - 9s - loss: 0.3457 - acc: 0.9346 - mDice: 0.6929 - val_loss: 0.5921 - val_acc: 0.9415 - val_mDice: 0.5320

Epoch 00095: val_mDice did not improve from 0.53834
Epoch 96/300
 - 9s - loss: 0.3451 - acc: 0.9347 - mDice: 0.6934 - val_loss: 0.5953 - val_acc: 0.9406 - val_mDice: 0.5320

Epoch 00096: val_mDice did not improve from 0.53834
Epoch 97/300
 - 9s - loss: 0.3457 - acc: 0.9345 - mDice: 0.6929 - val_loss: 0.5994 - val_acc: 0.9409 - val_mDice: 0.5321

Epoch 00097: val_mDice did not improve from 0.53834
Epoch 98/300
 - 9s - loss: 0.3446 - acc: 0.9348 - mDice: 0.6936 - val_loss: 0.7159 - val_acc: 0.9337 - val_mDice: 0.5152

Epoch 00098: val_mDice did not improve from 0.53834
Epoch 99/300
 - 9s - loss: 0.3434 - acc: 0.9348 - mDice: 0.6945 - val_loss: 0.5662 - val_acc: 0.9405 - val_mDice: 0.5456

Epoch 00099: val_mDice improved from 0.53834 to 0.54558, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 100/300
 - 9s - loss: 0.3455 - acc: 0.9346 - mDice: 0.6930 - val_loss: 0.5993 - val_acc: 0.9416 - val_mDice: 0.5271

Epoch 00100: val_mDice did not improve from 0.54558
Epoch 101/300
 - 9s - loss: 0.3432 - acc: 0.9348 - mDice: 0.6947 - val_loss: 0.5897 - val_acc: 0.9422 - val_mDice: 0.5331

Epoch 00101: val_mDice did not improve from 0.54558
Epoch 102/300
 - 9s - loss: 0.3437 - acc: 0.9348 - mDice: 0.6944 - val_loss: 0.7138 - val_acc: 0.9315 - val_mDice: 0.5011

Epoch 00102: val_mDice did not improve from 0.54558
Epoch 103/300
 - 9s - loss: 0.3413 - acc: 0.9351 - mDice: 0.6961 - val_loss: 0.5945 - val_acc: 0.9413 - val_mDice: 0.5262

Epoch 00103: val_mDice did not improve from 0.54558
Epoch 104/300
 - 9s - loss: 0.3400 - acc: 0.9353 - mDice: 0.6970 - val_loss: 0.6141 - val_acc: 0.9377 - val_mDice: 0.5139

Epoch 00104: val_mDice did not improve from 0.54558
Epoch 105/300
 - 9s - loss: 0.3397 - acc: 0.9353 - mDice: 0.6973 - val_loss: 0.5969 - val_acc: 0.9418 - val_mDice: 0.5263

Epoch 00105: val_mDice did not improve from 0.54558
Epoch 106/300
 - 9s - loss: 0.3405 - acc: 0.9353 - mDice: 0.6967 - val_loss: 0.5940 - val_acc: 0.9383 - val_mDice: 0.5348

Epoch 00106: val_mDice did not improve from 0.54558
Epoch 107/300
 - 9s - loss: 0.3401 - acc: 0.9353 - mDice: 0.6970 - val_loss: 0.5834 - val_acc: 0.9404 - val_mDice: 0.5367

Epoch 00107: val_mDice did not improve from 0.54558
Epoch 108/300
 - 9s - loss: 0.3398 - acc: 0.9354 - mDice: 0.6972 - val_loss: 0.6396 - val_acc: 0.9380 - val_mDice: 0.5351

Epoch 00108: val_mDice did not improve from 0.54558
Epoch 109/300
 - 9s - loss: 0.3371 - acc: 0.9355 - mDice: 0.6991 - val_loss: 0.5960 - val_acc: 0.9410 - val_mDice: 0.5281

Epoch 00109: val_mDice did not improve from 0.54558
Epoch 110/300
 - 9s - loss: 0.3371 - acc: 0.9356 - mDice: 0.6992 - val_loss: 0.6643 - val_acc: 0.9375 - val_mDice: 0.5197

Epoch 00110: val_mDice did not improve from 0.54558
Epoch 111/300
 - 9s - loss: 0.3395 - acc: 0.9356 - mDice: 0.6975 - val_loss: 0.6417 - val_acc: 0.9399 - val_mDice: 0.5373

Epoch 00111: val_mDice did not improve from 0.54558
Epoch 112/300
 - 9s - loss: 0.3368 - acc: 0.9357 - mDice: 0.6994 - val_loss: 0.5759 - val_acc: 0.9392 - val_mDice: 0.5384

Epoch 00112: val_mDice did not improve from 0.54558
Epoch 113/300
 - 9s - loss: 0.3369 - acc: 0.9357 - mDice: 0.6993 - val_loss: 0.6002 - val_acc: 0.9401 - val_mDice: 0.5278

Epoch 00113: val_mDice did not improve from 0.54558
Epoch 114/300
 - 9s - loss: 0.3363 - acc: 0.9357 - mDice: 0.6997 - val_loss: 0.6114 - val_acc: 0.9403 - val_mDice: 0.5236

Epoch 00114: val_mDice did not improve from 0.54558
Epoch 115/300
 - 9s - loss: 0.3367 - acc: 0.9357 - mDice: 0.6995 - val_loss: 0.5822 - val_acc: 0.9417 - val_mDice: 0.5366

Epoch 00115: val_mDice did not improve from 0.54558
Epoch 116/300
 - 9s - loss: 0.3349 - acc: 0.9359 - mDice: 0.7007 - val_loss: 0.5774 - val_acc: 0.9421 - val_mDice: 0.5359

Epoch 00116: val_mDice did not improve from 0.54558
Epoch 117/300
 - 9s - loss: 0.3349 - acc: 0.9357 - mDice: 0.7007 - val_loss: 0.6018 - val_acc: 0.9399 - val_mDice: 0.5255

Epoch 00117: val_mDice did not improve from 0.54558
Epoch 118/300
 - 9s - loss: 0.3344 - acc: 0.9360 - mDice: 0.7010 - val_loss: 0.5965 - val_acc: 0.9401 - val_mDice: 0.5404

Epoch 00118: val_mDice did not improve from 0.54558
Epoch 119/300
 - 9s - loss: 0.3332 - acc: 0.9361 - mDice: 0.7019 - val_loss: 0.6183 - val_acc: 0.9382 - val_mDice: 0.5147

Epoch 00119: val_mDice did not improve from 0.54558
Epoch 120/300
 - 9s - loss: 0.3336 - acc: 0.9362 - mDice: 0.7017 - val_loss: 0.5863 - val_acc: 0.9387 - val_mDice: 0.5325

Epoch 00120: val_mDice did not improve from 0.54558
Epoch 121/300
 - 9s - loss: 0.3323 - acc: 0.9362 - mDice: 0.7026 - val_loss: 0.7627 - val_acc: 0.9280 - val_mDice: 0.4824

Epoch 00121: val_mDice did not improve from 0.54558
Epoch 122/300
 - 9s - loss: 0.3312 - acc: 0.9360 - mDice: 0.7034 - val_loss: 0.5933 - val_acc: 0.9423 - val_mDice: 0.5324

Epoch 00122: val_mDice did not improve from 0.54558
Epoch 123/300
 - 9s - loss: 0.3334 - acc: 0.9361 - mDice: 0.7019 - val_loss: 0.6063 - val_acc: 0.9379 - val_mDice: 0.5186

Epoch 00123: val_mDice did not improve from 0.54558
Epoch 124/300
 - 9s - loss: 0.3320 - acc: 0.9362 - mDice: 0.7029 - val_loss: 0.6564 - val_acc: 0.9408 - val_mDice: 0.5282

Epoch 00124: val_mDice did not improve from 0.54558
Epoch 125/300
 - 9s - loss: 0.3306 - acc: 0.9365 - mDice: 0.7038 - val_loss: 0.5968 - val_acc: 0.9425 - val_mDice: 0.5263

Epoch 00125: val_mDice did not improve from 0.54558
Epoch 126/300
 - 9s - loss: 0.3316 - acc: 0.9363 - mDice: 0.7031 - val_loss: 0.6050 - val_acc: 0.9379 - val_mDice: 0.5183

Epoch 00126: val_mDice did not improve from 0.54558
Epoch 127/300
 - 9s - loss: 0.3301 - acc: 0.9365 - mDice: 0.7043 - val_loss: 0.6442 - val_acc: 0.9389 - val_mDice: 0.5305

Epoch 00127: val_mDice did not improve from 0.54558
Epoch 128/300
 - 9s - loss: 0.3300 - acc: 0.9365 - mDice: 0.7043 - val_loss: 0.6049 - val_acc: 0.9420 - val_mDice: 0.5233

Epoch 00128: val_mDice did not improve from 0.54558
Epoch 129/300
 - 9s - loss: 0.3294 - acc: 0.9364 - mDice: 0.7047 - val_loss: 0.5950 - val_acc: 0.9408 - val_mDice: 0.5274

Epoch 00129: val_mDice did not improve from 0.54558
Epoch 130/300
 - 9s - loss: 0.3285 - acc: 0.9366 - mDice: 0.7053 - val_loss: 0.5843 - val_acc: 0.9425 - val_mDice: 0.5374

Epoch 00130: val_mDice did not improve from 0.54558
Epoch 131/300
 - 9s - loss: 0.3281 - acc: 0.9367 - mDice: 0.7057 - val_loss: 0.6070 - val_acc: 0.9379 - val_mDice: 0.5185

Epoch 00131: val_mDice did not improve from 0.54558
Epoch 132/300
 - 9s - loss: 0.3273 - acc: 0.9368 - mDice: 0.7062 - val_loss: 0.5887 - val_acc: 0.9421 - val_mDice: 0.5288

Epoch 00132: val_mDice did not improve from 0.54558
Epoch 133/300
 - 9s - loss: 0.3305 - acc: 0.9364 - mDice: 0.7039 - val_loss: 0.6712 - val_acc: 0.9393 - val_mDice: 0.5234

Epoch 00133: val_mDice did not improve from 0.54558
Epoch 134/300
 - 9s - loss: 0.3282 - acc: 0.9368 - mDice: 0.7056 - val_loss: 0.5703 - val_acc: 0.9397 - val_mDice: 0.5398

Epoch 00134: val_mDice did not improve from 0.54558
Epoch 135/300
 - 9s - loss: 0.3279 - acc: 0.9368 - mDice: 0.7059 - val_loss: 0.5762 - val_acc: 0.9400 - val_mDice: 0.5341

Epoch 00135: val_mDice did not improve from 0.54558
Epoch 136/300
 - 9s - loss: 0.3268 - acc: 0.9368 - mDice: 0.7067 - val_loss: 0.5566 - val_acc: 0.9422 - val_mDice: 0.5474

Epoch 00136: val_mDice improved from 0.54558 to 0.54738, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 137/300
 - 9s - loss: 0.3271 - acc: 0.9370 - mDice: 0.7065 - val_loss: 0.6116 - val_acc: 0.9395 - val_mDice: 0.5194

Epoch 00137: val_mDice did not improve from 0.54738
Epoch 138/300
 - 9s - loss: 0.3257 - acc: 0.9370 - mDice: 0.7074 - val_loss: 0.5726 - val_acc: 0.9398 - val_mDice: 0.5360

Epoch 00138: val_mDice did not improve from 0.54738
Epoch 139/300
 - 9s - loss: 0.3265 - acc: 0.9369 - mDice: 0.7069 - val_loss: 0.5785 - val_acc: 0.9412 - val_mDice: 0.5370

Epoch 00139: val_mDice did not improve from 0.54738
Epoch 140/300
 - 9s - loss: 0.3254 - acc: 0.9369 - mDice: 0.7077 - val_loss: 0.6023 - val_acc: 0.9396 - val_mDice: 0.5198

Epoch 00140: val_mDice did not improve from 0.54738
Epoch 141/300
 - 9s - loss: 0.3258 - acc: 0.9370 - mDice: 0.7075 - val_loss: 0.5914 - val_acc: 0.9380 - val_mDice: 0.5289

Epoch 00141: val_mDice did not improve from 0.54738
Epoch 142/300
 - 9s - loss: 0.3259 - acc: 0.9370 - mDice: 0.7073 - val_loss: 0.5756 - val_acc: 0.9406 - val_mDice: 0.5355

Epoch 00142: val_mDice did not improve from 0.54738
Epoch 143/300
 - 9s - loss: 0.3266 - acc: 0.9369 - mDice: 0.7068 - val_loss: 0.5974 - val_acc: 0.9394 - val_mDice: 0.5260

Epoch 00143: val_mDice did not improve from 0.54738
Epoch 144/300
 - 9s - loss: 0.3244 - acc: 0.9372 - mDice: 0.7085 - val_loss: 0.6359 - val_acc: 0.9416 - val_mDice: 0.5376

Epoch 00144: val_mDice did not improve from 0.54738
Epoch 145/300
 - 9s - loss: 0.3236 - acc: 0.9374 - mDice: 0.7090 - val_loss: 0.5890 - val_acc: 0.9411 - val_mDice: 0.5282

Epoch 00145: val_mDice did not improve from 0.54738
Epoch 146/300
 - 9s - loss: 0.3220 - acc: 0.9373 - mDice: 0.7101 - val_loss: 0.6664 - val_acc: 0.9404 - val_mDice: 0.5224

Epoch 00146: val_mDice did not improve from 0.54738
Epoch 147/300
 - 9s - loss: 0.3241 - acc: 0.9374 - mDice: 0.7086 - val_loss: 0.5893 - val_acc: 0.9414 - val_mDice: 0.5267

Epoch 00147: val_mDice did not improve from 0.54738
Epoch 148/300
 - 9s - loss: 0.3238 - acc: 0.9374 - mDice: 0.7089 - val_loss: 0.5777 - val_acc: 0.9406 - val_mDice: 0.5337

Epoch 00148: val_mDice did not improve from 0.54738
Epoch 149/300
 - 9s - loss: 0.3228 - acc: 0.9374 - mDice: 0.7097 - val_loss: 0.5860 - val_acc: 0.9416 - val_mDice: 0.5305

Epoch 00149: val_mDice did not improve from 0.54738
Epoch 150/300
 - 9s - loss: 0.3232 - acc: 0.9374 - mDice: 0.7093 - val_loss: 0.6680 - val_acc: 0.9393 - val_mDice: 0.5206

Epoch 00150: val_mDice did not improve from 0.54738
Epoch 151/300
 - 9s - loss: 0.3226 - acc: 0.9375 - mDice: 0.7098 - val_loss: 0.5689 - val_acc: 0.9426 - val_mDice: 0.5391

Epoch 00151: val_mDice did not improve from 0.54738
Epoch 152/300
 - 9s - loss: 0.3206 - acc: 0.9377 - mDice: 0.7113 - val_loss: 0.5735 - val_acc: 0.9418 - val_mDice: 0.5367

Epoch 00152: val_mDice did not improve from 0.54738
Epoch 153/300
 - 9s - loss: 0.3225 - acc: 0.9377 - mDice: 0.7098 - val_loss: 0.6665 - val_acc: 0.9392 - val_mDice: 0.5235

Epoch 00153: val_mDice did not improve from 0.54738
Epoch 154/300
 - 9s - loss: 0.3191 - acc: 0.9378 - mDice: 0.7123 - val_loss: 0.6590 - val_acc: 0.9405 - val_mDice: 0.5274

Epoch 00154: val_mDice did not improve from 0.54738
Epoch 155/300
 - 9s - loss: 0.3200 - acc: 0.9378 - mDice: 0.7117 - val_loss: 0.6424 - val_acc: 0.9403 - val_mDice: 0.5301

Epoch 00155: val_mDice did not improve from 0.54738
Epoch 156/300
 - 9s - loss: 0.3200 - acc: 0.9378 - mDice: 0.7116 - val_loss: 0.6433 - val_acc: 0.9408 - val_mDice: 0.5335

Epoch 00156: val_mDice did not improve from 0.54738
Epoch 157/300
 - 9s - loss: 0.3194 - acc: 0.9379 - mDice: 0.7122 - val_loss: 0.5658 - val_acc: 0.9426 - val_mDice: 0.5414

Epoch 00157: val_mDice did not improve from 0.54738
Epoch 158/300
 - 9s - loss: 0.3191 - acc: 0.9379 - mDice: 0.7124 - val_loss: 0.6524 - val_acc: 0.9392 - val_mDice: 0.5317

Epoch 00158: val_mDice did not improve from 0.54738
Epoch 159/300
 - 9s - loss: 0.3194 - acc: 0.9378 - mDice: 0.7121 - val_loss: 0.5912 - val_acc: 0.9397 - val_mDice: 0.5285

Epoch 00159: val_mDice did not improve from 0.54738
Epoch 160/300
 - 9s - loss: 0.3203 - acc: 0.9378 - mDice: 0.7115 - val_loss: 0.5760 - val_acc: 0.9388 - val_mDice: 0.5348

Epoch 00160: val_mDice did not improve from 0.54738
Epoch 161/300
 - 9s - loss: 0.3193 - acc: 0.9380 - mDice: 0.7122 - val_loss: 0.5832 - val_acc: 0.9375 - val_mDice: 0.5319

Epoch 00161: val_mDice did not improve from 0.54738
Epoch 162/300
 - 9s - loss: 0.3196 - acc: 0.9378 - mDice: 0.7120 - val_loss: 0.6404 - val_acc: 0.9431 - val_mDice: 0.5388

Epoch 00162: val_mDice did not improve from 0.54738
Epoch 163/300
 - 9s - loss: 0.3201 - acc: 0.9378 - mDice: 0.7116 - val_loss: 0.6537 - val_acc: 0.9414 - val_mDice: 0.5294

Epoch 00163: val_mDice did not improve from 0.54738
Epoch 164/300
 - 9s - loss: 0.3176 - acc: 0.9380 - mDice: 0.7134 - val_loss: 0.6505 - val_acc: 0.9398 - val_mDice: 0.5321

Epoch 00164: val_mDice did not improve from 0.54738
Epoch 165/300
 - 9s - loss: 0.3179 - acc: 0.9381 - mDice: 0.7132 - val_loss: 0.6115 - val_acc: 0.9384 - val_mDice: 0.5190

Epoch 00165: val_mDice did not improve from 0.54738
Epoch 166/300
 - 9s - loss: 0.3193 - acc: 0.9378 - mDice: 0.7122 - val_loss: 0.5917 - val_acc: 0.9366 - val_mDice: 0.5267

Epoch 00166: val_mDice did not improve from 0.54738
Epoch 167/300
 - 9s - loss: 0.3177 - acc: 0.9381 - mDice: 0.7133 - val_loss: 0.5802 - val_acc: 0.9405 - val_mDice: 0.5334

Epoch 00167: val_mDice did not improve from 0.54738
Epoch 168/300
 - 9s - loss: 0.3177 - acc: 0.9381 - mDice: 0.7134 - val_loss: 0.5869 - val_acc: 0.9397 - val_mDice: 0.5348

Epoch 00168: val_mDice did not improve from 0.54738
Epoch 169/300
 - 9s - loss: 0.3170 - acc: 0.9380 - mDice: 0.7139 - val_loss: 0.6712 - val_acc: 0.9391 - val_mDice: 0.5206

Epoch 00169: val_mDice did not improve from 0.54738
Epoch 170/300
 - 9s - loss: 0.3171 - acc: 0.9382 - mDice: 0.7138 - val_loss: 0.6162 - val_acc: 0.9414 - val_mDice: 0.5272

Epoch 00170: val_mDice did not improve from 0.54738
Epoch 171/300
 - 9s - loss: 0.3168 - acc: 0.9382 - mDice: 0.7141 - val_loss: 0.5997 - val_acc: 0.9379 - val_mDice: 0.5211

Epoch 00171: val_mDice did not improve from 0.54738
Epoch 172/300
 - 9s - loss: 0.3172 - acc: 0.9382 - mDice: 0.7137 - val_loss: 0.6622 - val_acc: 0.9364 - val_mDice: 0.5247

Epoch 00172: val_mDice did not improve from 0.54738
Epoch 173/300
 - 9s - loss: 0.3167 - acc: 0.9382 - mDice: 0.7141 - val_loss: 0.6392 - val_acc: 0.9426 - val_mDice: 0.5363

Epoch 00173: val_mDice did not improve from 0.54738
Epoch 174/300
 - 9s - loss: 0.3152 - acc: 0.9385 - mDice: 0.7152 - val_loss: 0.5900 - val_acc: 0.9429 - val_mDice: 0.5381

Epoch 00174: val_mDice did not improve from 0.54738
Epoch 175/300
 - 9s - loss: 0.3140 - acc: 0.9385 - mDice: 0.7161 - val_loss: 0.6039 - val_acc: 0.9408 - val_mDice: 0.5205

Epoch 00175: val_mDice did not improve from 0.54738
Epoch 176/300
 - 9s - loss: 0.3172 - acc: 0.9384 - mDice: 0.7137 - val_loss: 0.6812 - val_acc: 0.9392 - val_mDice: 0.5164

Epoch 00176: val_mDice did not improve from 0.54738
Restoring model weights from the end of the best epoch
Epoch 00176: early stopping
{'val_loss': [3.1312423887706937, 1.9719853174118769, 1.7798566137041365, 1.4037721157073975, 1.3322684878394717, 1.3343945684887113, 1.241783721106393, 1.1873842421032132, 1.1710767859504336, 1.0976969855172294, 1.0657806623549688, 1.0989636580149333, 1.0861397357214064, 1.0319522335415794, 1.0431609380812872, 1.0410302593594505, 1.0587384700775146, 0.9834288869585309, 1.0210459345862979, 0.9826601800464448, 1.074228252683367, 1.0111122812543596, 1.0383371171497164, 1.031297967547462, 0.9927713757469541, 0.9851675147101993, 1.011398190543765, 0.9604008992513021, 0.9736547810690743, 0.9447749228704543, 1.0105316866011846, 0.9333540598551432, 0.950264987491426, 0.9382327284131732, 0.932630527587164, 0.9052729379563105, 0.8972905817485991, 0.9577220508030483, 0.9091271672930036, 0.8840722697121757, 0.9158040682474772, 0.8560855275108701, 0.8657112348647344, 0.860016731988816, 0.8721631708599272, 0.8726482731955392, 0.8629424004327684, 0.8354902267456055, 0.8109269596281505, 0.7677719252450126, 0.807197820572626, 0.7605294045947847, 0.7488915352594285, 0.7561553659893218, 0.765966018040975, 0.7131176789601644, 0.7333469844999767, 0.7863094466073173, 0.7849867003304618, 0.7383258910406203, 0.744364375159854, 0.7244322299957275, 0.7126279217856271, 0.695858739671253, 0.729474941889445, 0.6771758965083531, 0.7268299942924863, 0.6744467757997059, 0.6548794621513003, 0.6755172411600748, 0.6887939316885812, 0.6354246934254965, 0.6266804763248989, 0.6463637124924433, 0.659786581993103, 0.6403221913746425, 0.6382281609943935, 0.6173587242762247, 0.6903043815067836, 0.6802435488927931, 0.6372013319106329, 0.6450485388437907, 0.7783354918162028, 0.5998261258715675, 0.6153809059233892, 0.5945450408118111, 0.6054948795409429, 0.6252508787881761, 0.6301668882369995, 0.6283976236979166, 0.6353551319667271, 0.6046393712361654, 0.5964087134315854, 0.6005876972561791, 0.5920736278806414, 0.5952720471790859, 0.5993577923093524, 0.7159140450613839, 0.5662111952191308, 0.5993068218231201, 0.5897345997038341, 0.7137632483527774, 0.5944676058632987, 0.6141354895773388, 0.5969307025273641, 0.5939754985627674, 0.5833780765533447, 0.6395822139013381, 0.5960412082217988, 0.6643176759992327, 0.6417321023486909, 0.5759489195687431, 0.6001612402143932, 0.6114152442841303, 0.5822336730502901, 0.5774393933159965, 0.6018054485321045, 0.5965139865875244, 0.6182577382950556, 0.586306611696879, 0.7627464476085845, 0.5932724759692237, 0.6063459600721087, 0.656372240611485, 0.5968243564878192, 0.6050018611408415, 0.6441902887253534, 0.6048943826130458, 0.5950244438080561, 0.5843184391657511, 0.6070280813035511, 0.5887106912476676, 0.6711532842545282, 0.5703291438874745, 0.5761548394248599, 0.5566283861796061, 0.6116148403712681, 0.5726008784203303, 0.5785439241500128, 0.6023456312361217, 0.5913829973765782, 0.5755535704748971, 0.5973822389330182, 0.6359146776653472, 0.5890329849152338, 0.6663532938276019, 0.5892582223528907, 0.5777338175546556, 0.5860477033115569, 0.6679590770176479, 0.5688674932434445, 0.5734780175345284, 0.6665307113102504, 0.659004154659453, 0.6424151602245513, 0.643333185286749, 0.5658396482467651, 0.6524182047162738, 0.5912289732978457, 0.5760374750409808, 0.583165827251616, 0.640376261302403, 0.6536533719017392, 0.650514352889288, 0.6114964343252636, 0.5917187020892188, 0.5801996815772283, 0.586903765088036, 0.6712051573253813, 0.6162453038351876, 0.5997000024432227, 0.6622316042582194, 0.6391658328828358, 0.5900051537014189, 0.6038941144943237, 0.6811619599660238], 'val_acc': [0.5404739039284843, 0.9056250254313151, 0.9063644863310314, 0.9083928607759022, 0.9129303778920855, 0.9149954006785438, 0.9159065882364908, 0.9188003540039062, 0.9186217699732099, 0.9214423043387276, 0.9255403195108686, 0.9279922076633998, 0.9284592356000628, 0.9306135773658752, 0.9250732433228266, 0.9293749871708098, 0.9274817109107971, 0.9313736444427854, 0.9252770060584659, 0.9311492755299523, 0.927948704787663, 0.9275297607694354, 0.9270008887563433, 0.9283974284217471, 0.9336057816232953, 0.9328136699540275, 0.9314972758293152, 0.9310347948755536, 0.9327037334442139, 0.9326327982402983, 0.9289217307454064, 0.937367232072921, 0.9359913298061916, 0.9368315026873634, 0.9301946049644834, 0.9340292896543231, 0.934587938444955, 0.9345261000451588, 0.9363896250724792, 0.9387179698262896, 0.933294395605723, 0.9357669154802958, 0.9362019442376637, 0.9368910023144313, 0.9371611930075145, 0.9370558403787159, 0.9376167399542672, 0.93157050155458, 0.935173994018918, 0.9381593607720875, 0.9383310363406226, 0.9369505388396127, 0.9370123630478269, 0.9375274550347101, 0.9356204469998678, 0.9393475339526222, 0.940787550948915, 0.9362683239437285, 0.935524270648048, 0.9370215166182745, 0.9363736254828317, 0.9347916472525823, 0.9374748326483227, 0.9381135616983686, 0.9373351477441334, 0.9375892877578735, 0.938756891659328, 0.9397664836474827, 0.9379853492691403, 0.9350343545277914, 0.9376213323502314, 0.9392811287017095, 0.9401236204873948, 0.9392239252726237, 0.9354097871553331, 0.9392376286642892, 0.9399633492742266, 0.9415407663299924, 0.9372619049889701, 0.9371932290849232, 0.9383768410909743, 0.9349656871386937, 0.9341231612932115, 0.9372000864573887, 0.938727114881788, 0.9421428839365641, 0.941630020028069, 0.9384867066428775, 0.9367078826540992, 0.9358836866560436, 0.9367719831920805, 0.939903838293893, 0.9348420585904803, 0.9391758470308214, 0.9415475953192938, 0.9405815090451922, 0.9409432496343341, 0.9336561220032829, 0.9405357383546376, 0.941559062117622, 0.9422206736746288, 0.9315087142444792, 0.9412683418818882, 0.9376717096283322, 0.941778818766276, 0.9382669613474891, 0.9404464080220177, 0.9379899047669911, 0.9409798752693903, 0.9374588103521437, 0.9398901065190634, 0.939244514419919, 0.940119050797962, 0.9402815784726825, 0.9416941489492144, 0.9421337104979015, 0.9399153050922212, 0.9401190394446963, 0.9382074361755735, 0.9387431371779669, 0.9280334398860023, 0.94228253194264, 0.9379281032653082, 0.9407509026073274, 0.9425182995342073, 0.9378891785939535, 0.9388919245629084, 0.9420398161524818, 0.9408127211389088, 0.942456515062423, 0.9378823467663356, 0.942074199517568, 0.9392628045309157, 0.9397367380914234, 0.9400412071318853, 0.9422367413838705, 0.9394848971139818, 0.9398236955915179, 0.9411584138870239, 0.939599355061849, 0.9379944914863223, 0.9405632132575625, 0.9394345397040957, 0.9415796711331322, 0.9410531237011864, 0.9403525534130278, 0.9414422881035578, 0.9406250062442961, 0.941627732345036, 0.9392559358051845, 0.9426007043747675, 0.9417696680341449, 0.9392101509230477, 0.9405013918876648, 0.9402747409684318, 0.9407555177098229, 0.942619039898827, 0.9392445002283368, 0.9397458576020741, 0.9388324362891061, 0.9374862370036897, 0.9431135342234657, 0.9414285960651579, 0.9398488856497265, 0.9384249051411947, 0.936611703463963, 0.9405425673439389, 0.9397229892866952, 0.9390934194837298, 0.9414239724477133, 0.9378640084039598, 0.936366734050569, 0.9426167493774777, 0.9429143780753726, 0.9408081542877924, 0.9392330476215908], 'val_mDice': [0.11135582546038288, 0.251133637214523, 0.3174063054445599, 0.40844734607353095, 0.44080427874411854, 0.4364516029045695, 0.4475196088176398, 0.46784227518808275, 0.4639512346613975, 0.48567582862008185, 0.49436948395201136, 0.4853529852061045, 0.48871976722564014, 0.5033429188742524, 0.5058534560459, 0.5152381633718809, 0.49636896415835335, 0.5181970727585611, 0.5101786317924658, 0.5134415830529871, 0.5132838178958211, 0.5096362513445672, 0.5156808353605724, 0.5104613928567796, 0.509720327598708, 0.5173808598802203, 0.5124269253796055, 0.5166979971386138, 0.5108617884772164, 0.5156794367801576, 0.5141425256927808, 0.5176820229916346, 0.525298709315913, 0.5213623969327836, 0.5113202677596183, 0.5254143971417632, 0.5160118446108841, 0.5163861403153056, 0.5174184324485915, 0.5281435002883276, 0.5158007638085456, 0.5139678409766584, 0.5175229098115649, 0.5142417897780737, 0.5206480835165296, 0.5171655696772394, 0.5151023052278019, 0.5116416332977158, 0.5164065258133979, 0.5317216714223226, 0.5169469556283384, 0.5149410237513837, 0.5159794019446486, 0.5205383258206504, 0.5200715767485755, 0.5198104356726011, 0.527988483508428, 0.5162972477929932, 0.5190990783628964, 0.5224547930771396, 0.5251813208063444, 0.5318386680668309, 0.5182789975688571, 0.5152697158711297, 0.5295081741753078, 0.5165909605012053, 0.5262348580928076, 0.5288370838832288, 0.5164947940834931, 0.5126877721576464, 0.528809786197685, 0.5247840689761298, 0.5332737561492693, 0.520445885935, 0.5113954132511502, 0.5207534322426433, 0.5244239276008946, 0.5238398366740772, 0.5220707165343421, 0.5168976758917173, 0.5262896617253622, 0.5067803034824985, 0.49873098198856625, 0.5301130483193057, 0.5215368157341367, 0.5383418285775752, 0.5347097044189771, 0.5215118688841661, 0.5113973062308061, 0.5155621940890948, 0.5213292723610288, 0.5292221284693196, 0.5275554121250198, 0.5264286125699679, 0.5320277270816621, 0.5319948157384282, 0.532077737507366, 0.5152201304833094, 0.5455848095672471, 0.5271068275684402, 0.5331175841745877, 0.5011110181609789, 0.5261842147225425, 0.513949955325751, 0.5263096839189529, 0.5348128275502295, 0.5366716964968613, 0.5350881485002381, 0.5281272182861964, 0.5196915786890757, 0.5372534475865818, 0.5383867898157665, 0.5277987830340862, 0.5235861021847952, 0.5366140845276061, 0.5359201500458377, 0.5255429492819876, 0.5404372697784787, 0.5146590183888163, 0.5325407627083006, 0.48236179405025076, 0.5323623266248476, 0.5186272659117267, 0.5281739508112272, 0.5262541100382805, 0.5182567433941931, 0.5305179220934709, 0.5232810922676608, 0.5274177906768662, 0.5374463626316616, 0.5184520543331191, 0.5287626357305617, 0.5233630019994009, 0.5398176963485423, 0.5340700807670752, 0.5473782539012886, 0.5194125209181082, 0.5359886125439689, 0.5370381229690143, 0.5198398819636731, 0.528896726667881, 0.53546591848135, 0.5260393431498891, 0.5375541381183124, 0.5281768730353742, 0.5224403561580748, 0.5267484046164013, 0.5336675427499271, 0.5304568299934977, 0.5205898082682064, 0.5390936274613652, 0.5367213590514093, 0.5235036283376671, 0.5274043296064649, 0.5301413770232882, 0.5334903938429696, 0.5413520712228048, 0.5316532502571741, 0.5284872769954658, 0.5347855876953829, 0.5318663035120282, 0.5387834172163691, 0.5294024915922255, 0.5320572029976618, 0.5190315317539942, 0.5267209820449352, 0.5333996134854498, 0.5347692586836361, 0.5205909758806229, 0.5271650318588529, 0.5211444355192638, 0.524719678752479, 0.5362588326845851, 0.5381154054332347, 0.5204554129214514, 0.5163992632712636], 'loss': [3.367827261025124, 1.8665287943733941, 1.15132818756155, 0.9437642361884727, 0.8360832596712313, 0.7650513209794697, 0.7131442498880383, 0.6794359860149956, 0.6489773979415916, 0.6238072128316123, 0.6007601603253719, 0.5817730706827889, 0.5676496468781735, 0.5548342446474664, 0.5413414359046748, 0.5322472405084323, 0.522487189525213, 0.5116180830696356, 0.5042402045860533, 0.4937479147762606, 0.490773397562291, 0.4824110617843556, 0.4767618527675792, 0.47179248291838943, 0.4674008046647637, 0.46200948759427946, 0.45634394868596434, 0.4559154123763071, 0.45141459931085304, 0.44518246314809207, 0.44174621208959264, 0.43727507297303697, 0.43538797310213606, 0.43176684117349373, 0.42910208921798376, 0.4254322311127602, 0.4219992031751397, 0.42233676071660653, 0.4174207326980692, 0.41688424948669706, 0.41495167145569106, 0.409695017951427, 0.4077639651190506, 0.40496602476918675, 0.40354763620364453, 0.40013594909028694, 0.39861709491375075, 0.39672915660188174, 0.3955342737562467, 0.3922948050825311, 0.3909849611773343, 0.3904713381628368, 0.38628494001225466, 0.38563970708079437, 0.38523250003529347, 0.3840509866769543, 0.38197842499459206, 0.38179900399954164, 0.3807427961632813, 0.3776715583129726, 0.37658355635715995, 0.3763395999067202, 0.3738421224630796, 0.3723625802387041, 0.372097355547911, 0.3710664405410451, 0.36950004810378667, 0.3683313082782248, 0.3669226094376542, 0.3661088738766437, 0.363731362765893, 0.3633965658491141, 0.3637499126173155, 0.3616255801239293, 0.3628699315152739, 0.3608983403654578, 0.3600572313627159, 0.3575710117104473, 0.3590857297475108, 0.35605737824349915, 0.3571609424239343, 0.3550792644427005, 0.3546384116496474, 0.35385220701671044, 0.35311534259046734, 0.3516302146398196, 0.35255524579881586, 0.3506931844636933, 0.3519696492507137, 0.35059867171002923, 0.3493857713926498, 0.34809085271688056, 0.3455560027185561, 0.3468988510669255, 0.3457219320465564, 0.34507347432799895, 0.3457217487051052, 0.3446207607564656, 0.3434443423139904, 0.3455246514453119, 0.34317654716570944, 0.3437113005726099, 0.3413088159602985, 0.33995303210551187, 0.3396847815510853, 0.34049798841533435, 0.3401067357072946, 0.339778133398861, 0.33714078928386865, 0.33707420097303825, 0.3395133304910805, 0.33680404662074714, 0.33685247068325175, 0.33631513231127436, 0.3366605242380683, 0.3349054743897968, 0.3349336965341018, 0.33439449778360647, 0.3331748111953114, 0.33355332487852607, 0.3322657888361271, 0.33122496302012466, 0.33337333830583754, 0.331993972080761, 0.3306055619568638, 0.3315713886399248, 0.3301471664780524, 0.3300301468864167, 0.32944254673398343, 0.32854591312035214, 0.32806841725440805, 0.32734137816031084, 0.3305491706999552, 0.328223243151783, 0.3278783818120462, 0.3267535484087635, 0.32706444938448964, 0.3257133669020791, 0.32652875243272994, 0.3254058817022679, 0.3258005766503632, 0.32592241922531695, 0.32660374061459635, 0.3243571581616667, 0.32364959304953717, 0.321998208422226, 0.3241342689826904, 0.3237973517631092, 0.32275680826191544, 0.32322228760969346, 0.32262484022296417, 0.3206067104398894, 0.3225197087702596, 0.31910053243153536, 0.31997615005300295, 0.319985724849142, 0.31944159022043134, 0.31913376696219625, 0.31944117578026965, 0.32028635157333624, 0.31931269011424873, 0.3195762379748159, 0.32009768329743177, 0.3175788519813165, 0.3179286634942712, 0.3193408662766787, 0.3177465464893232, 0.3176887241751099, 0.3170195171339838, 0.31709288101746025, 0.31684201600143896, 0.3171548951228322, 0.3167046481172129, 0.31524302044401104, 0.3140266768121526, 0.3171512771886921], 'acc': [0.12066322815298736, 0.794274357062947, 0.8728374636929367, 0.8790775282157278, 0.8826041890633963, 0.8855547269966783, 0.8879215659630053, 0.8897381665873486, 0.8922528664408931, 0.8945278569363619, 0.8970546288850658, 0.8994185708381317, 0.9021393857825944, 0.9045838755588668, 0.9072173788456965, 0.9096660836367609, 0.91176378358093, 0.9137303782539007, 0.9146762517391659, 0.9160412614093205, 0.9166890513765943, 0.9175723119349247, 0.9183463461256128, 0.9192480560164473, 0.9198817609476634, 0.9204287997026629, 0.9209853197559815, 0.92121879484972, 0.9218101655446382, 0.9226036856968278, 0.9230263174809724, 0.9236082052573179, 0.9238434238472448, 0.9242631335559093, 0.924600820378667, 0.9250421699288035, 0.925411900688923, 0.9257686547812916, 0.9262996137728231, 0.9264984534199077, 0.9266980083686942, 0.9270851883856989, 0.9274730371192446, 0.9277923219300934, 0.9279053052519244, 0.928402552203404, 0.9286782945399802, 0.9287886169114415, 0.9289883798272343, 0.9294361334580642, 0.9294755497671906, 0.9295712946604414, 0.9302498307879867, 0.9301692853779239, 0.9302743262515629, 0.9302147279958723, 0.9307098149770667, 0.9307457138996996, 0.9307374377941979, 0.9310770643476762, 0.9312217064346908, 0.9313381659127348, 0.9314966885736046, 0.9317918491198053, 0.9319371595901171, 0.9319672647964893, 0.9319848925455563, 0.9320263241972334, 0.932286224855677, 0.9324990097028983, 0.932508833219441, 0.9326573176974158, 0.9327060698497633, 0.9328524951464137, 0.932878540250316, 0.9329253205541519, 0.9331103296024343, 0.9333352580083366, 0.9330976312735509, 0.9334502553167613, 0.9333253399770063, 0.9334736630501534, 0.9335802322250353, 0.9337257931451703, 0.9336785935289211, 0.933882601485906, 0.9337786504108597, 0.9341506963753392, 0.9338631311293992, 0.9340347906332933, 0.9341735205416829, 0.9344675242153923, 0.9345003848524481, 0.9345145642539083, 0.9346194861825546, 0.9346575080394653, 0.9345310143199941, 0.9348464542463011, 0.9348384835643301, 0.9346438378457599, 0.9348374640111958, 0.9348149631486271, 0.9350869323514619, 0.9352828744911655, 0.9352721223050697, 0.9352650042096843, 0.9353118836247717, 0.9354207012403762, 0.9354599048021742, 0.9356446541272677, 0.9355944379896977, 0.9357387769973782, 0.9356688208632417, 0.9357407702883935, 0.9356777458745251, 0.9359292504367788, 0.9357029543530626, 0.9360019632081708, 0.9360919641418818, 0.9361607126930396, 0.9361502871661372, 0.9359742959202519, 0.9360817669328293, 0.9361671769529357, 0.9364989507926873, 0.9362705940567783, 0.936507710710481, 0.9364584043395067, 0.93638439354971, 0.9365910137460391, 0.9367025647407923, 0.9368074625494945, 0.9364421579427334, 0.9367575037104788, 0.9367991677593674, 0.9368253535840101, 0.9370130945750461, 0.9370308635389734, 0.9369118067715838, 0.9369445255387834, 0.9370446956431174, 0.9369793972896431, 0.9369165802912053, 0.9372296077634688, 0.9373907455824372, 0.9373205779994731, 0.9374171608625544, 0.9374051102903369, 0.9374309737190061, 0.9373844183776014, 0.9375432664221459, 0.9376769602838821, 0.9376619923820334, 0.9378034810420519, 0.9377997947125299, 0.9378340467221709, 0.9378914411688025, 0.9378828224888514, 0.9377608658698843, 0.9378299653036001, 0.9379524986523756, 0.9378191906063226, 0.9378178970809614, 0.9379711509072668, 0.9380590213110435, 0.9378070009336182, 0.9380734325351572, 0.9380598072489034, 0.9380161776486586, 0.9382448104137121, 0.9381738375532667, 0.9381546047190285, 0.938239761140734, 0.9384696239654743, 0.9384686960888111, 0.9383625512594705], 'mDice': [0.06124185066557422, 0.1824832680581828, 0.3056400841845697, 0.3745679642358037, 0.41727007820079015, 0.4487135616460241, 0.4729318355511948, 0.4896104058503231, 0.5051405705627918, 0.5185714866560227, 0.5311574696207497, 0.541806761426045, 0.5498505987274364, 0.557210413952749, 0.5653554367403177, 0.5707419906159874, 0.5765925437838259, 0.5830672664267262, 0.5873888551051248, 0.5937942247733643, 0.5957012680860666, 0.6009220642369677, 0.6043488989681643, 0.6076339415003621, 0.6105495767830561, 0.6140402955817699, 0.6174687402933715, 0.6178174793019284, 0.6207163249432799, 0.6247244285254757, 0.6270358610847264, 0.6299793612228461, 0.6311824176383657, 0.6335646643076923, 0.6353302592828551, 0.6376404488318822, 0.639910441190033, 0.639815253020482, 0.6431194800436094, 0.6435770631319115, 0.6448622080478591, 0.648389789371884, 0.6495536064421347, 0.6515751034165017, 0.652398552764972, 0.6546944550220415, 0.6557699774923594, 0.6571004608359116, 0.6580906491392675, 0.6601229311299733, 0.6611139707443962, 0.66140121426085, 0.6642689670191717, 0.6647356321799266, 0.6651221252094465, 0.6658608664752937, 0.6672822039596649, 0.6672867917591652, 0.668018196540139, 0.670244102122261, 0.6710201347864775, 0.6712787920095247, 0.6730004659801267, 0.6739947450098928, 0.6741741695959306, 0.6748793351528432, 0.6760268107599575, 0.6767724994659792, 0.6776827482191703, 0.678358788869044, 0.6801128114191397, 0.6802857614836758, 0.6800335691870121, 0.6814176864837299, 0.6807428554507701, 0.682037867492211, 0.6825768233540662, 0.6844239525650654, 0.6833453950726598, 0.6853249536581942, 0.6846718312642789, 0.6861954604083227, 0.6864847217724, 0.6870732249173903, 0.6874918063320773, 0.6886250377620647, 0.6879891444314347, 0.6892362582285969, 0.6883558812388708, 0.6893344731466008, 0.6901903831708264, 0.6911319198924635, 0.6929547952874814, 0.6920231883871043, 0.6928642229443689, 0.6934332911945709, 0.692900099493714, 0.6935892607610947, 0.694477504391833, 0.6930158216759766, 0.694737037057382, 0.6943626002537301, 0.6961244664625187, 0.6970113035063765, 0.6972650918906333, 0.6966857794095538, 0.6969757444692619, 0.6971854913411675, 0.6990793934212224, 0.6991861642889372, 0.6974655870231149, 0.6993631923132051, 0.6993022984752357, 0.6997229718440342, 0.6994749078039078, 0.7007096772343754, 0.7006623774037234, 0.7010373555903768, 0.7019307589471191, 0.7016655336530401, 0.7026147189019892, 0.7033746726990482, 0.7019098050474362, 0.7028831530794004, 0.7038426300866631, 0.7031097116097104, 0.7042560635078199, 0.704331170979414, 0.7046897895813724, 0.7053240274495878, 0.7057195882910314, 0.7062013308414035, 0.7039319905146298, 0.7055673429288913, 0.7059356113470242, 0.7066659361313643, 0.706476832127925, 0.7074365809700589, 0.7068798943293998, 0.7076554121551933, 0.7074513958901, 0.707313222050414, 0.7068304586943712, 0.7084661790095981, 0.7089654036470983, 0.7101494894106769, 0.7086462748402319, 0.7088792227540421, 0.7096639719913983, 0.709271088636103, 0.7097995692832819, 0.7112533807616622, 0.709759756919849, 0.7122942532605006, 0.7117416023380705, 0.7116453691509755, 0.7121565319082055, 0.7123841447638988, 0.7121104172527709, 0.711533900145646, 0.7122324543788021, 0.7119958353957299, 0.7116018632990284, 0.7134221088617367, 0.7131704083752122, 0.7121556368847677, 0.7133134988684036, 0.7133591201279189, 0.7138711635561286, 0.7138397673639415, 0.7140909670542402, 0.7137421939399217, 0.71407047735144, 0.7151808903032079, 0.716056877830848, 0.7137374572724489]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.16s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.75s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:11,  1.73s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:41,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:38,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:09,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:04,  1.52s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:26,  1.61s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:15,  1.57s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:47,  1.69s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:01,  1.75s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:35,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:52,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:33,  1.67s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:41,  1.70s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:52,  1.75s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:58,  1.78s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:32,  1.69s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:37,  1.71s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:19,  1.65s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:23,  1.67s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:17,  1.66s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:25,  1.70s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:04,  1.63s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:17,  1.68s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:27,  1.73s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:08,  1.66s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:16,  1.70s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:18,  1.71s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:23,  1.74s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:28,  1.77s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:06,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:05,  1.69s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:04,  1.69s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<06:48,  1.64s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<06:54,  1.67s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:04,  1.72s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:44,  1.65s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:48,  1.67s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:35,  1.62s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:27,  1.59s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:36,  1.64s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:47,  1.69s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:32,  1.63s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:45,  1.70s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:28,  1.63s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:34,  1.66s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<06:49,  1.73s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:47,  1.73s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<06:58,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:37,  1.71s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:46,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:29,  1.70s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:16,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:19,  1.67s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:29,  1.72s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:37,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:17,  1.69s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:20,  1.71s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:22,  1.72s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:09,  1.67s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:13,  1.70s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:14,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:15,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<06:02,  1.67s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:04,  1.69s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:04,  1.70s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:56,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:55,  1.67s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:55,  1.68s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:53,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:43,  1.65s/it]predicting train subjects:  27%|██▋       | 78/285 [02:11<05:31,  1.60s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:34,  1.62s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:33,  1.63s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:27,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:30,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:26,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:23,  1.61s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:27,  1.64s/it]predicting train subjects:  30%|███       | 86/285 [02:24<05:34,  1.68s/it]predicting train subjects:  31%|███       | 87/285 [02:26<05:38,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:27,  1.66s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:24,  1.66s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:29,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:19,  1.65s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:24,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:35<05:15,  1.64s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:15,  1.65s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:21,  1.69s/it]predicting train subjects:  34%|███▎      | 96/285 [02:40<05:18,  1.68s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:23,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:20,  1.71s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:14,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:47<05:16,  1.71s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:05,  1.66s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:52<04:56,  1.63s/it]predicting train subjects:  36%|███▋      | 104/285 [02:54<04:59,  1.65s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:03,  1.69s/it]predicting train subjects:  37%|███▋      | 106/285 [02:57<04:55,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [02:59<04:57,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [03:00<04:47,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:02<04:47,  1.63s/it]predicting train subjects:  39%|███▊      | 110/285 [03:04<04:52,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:05<04:44,  1.63s/it]predicting train subjects:  39%|███▉      | 112/285 [03:07<04:47,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:09<04:49,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:10<04:44,  1.66s/it]predicting train subjects:  40%|████      | 115/285 [03:12<04:41,  1.66s/it]predicting train subjects:  41%|████      | 116/285 [03:14<04:44,  1.68s/it]predicting train subjects:  41%|████      | 117/285 [03:15<04:37,  1.65s/it]predicting train subjects:  41%|████▏     | 118/285 [03:17<04:32,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:19<04:38,  1.68s/it]predicting train subjects:  42%|████▏     | 120/285 [03:20<04:28,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:22<04:20,  1.59s/it]predicting train subjects:  43%|████▎     | 122/285 [03:23<04:08,  1.52s/it]predicting train subjects:  43%|████▎     | 123/285 [03:25<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:26<03:58,  1.48s/it]predicting train subjects:  44%|████▍     | 125/285 [03:27<03:51,  1.45s/it]predicting train subjects:  44%|████▍     | 126/285 [03:29<03:45,  1.42s/it]predicting train subjects:  45%|████▍     | 127/285 [03:30<03:39,  1.39s/it]predicting train subjects:  45%|████▍     | 128/285 [03:32<03:43,  1.43s/it]predicting train subjects:  45%|████▌     | 129/285 [03:33<03:40,  1.42s/it]predicting train subjects:  46%|████▌     | 130/285 [03:34<03:36,  1.39s/it]predicting train subjects:  46%|████▌     | 131/285 [03:36<03:32,  1.38s/it]predicting train subjects:  46%|████▋     | 132/285 [03:37<03:37,  1.42s/it]predicting train subjects:  47%|████▋     | 133/285 [03:39<03:33,  1.41s/it]predicting train subjects:  47%|████▋     | 134/285 [03:40<03:29,  1.39s/it]predicting train subjects:  47%|████▋     | 135/285 [03:41<03:26,  1.38s/it]predicting train subjects:  48%|████▊     | 136/285 [03:43<03:23,  1.36s/it]predicting train subjects:  48%|████▊     | 137/285 [03:44<03:27,  1.40s/it]predicting train subjects:  48%|████▊     | 138/285 [03:45<03:23,  1.38s/it]predicting train subjects:  49%|████▉     | 139/285 [03:47<03:29,  1.43s/it]predicting train subjects:  49%|████▉     | 140/285 [03:48<03:32,  1.46s/it]predicting train subjects:  49%|████▉     | 141/285 [03:50<03:26,  1.43s/it]predicting train subjects:  50%|████▉     | 142/285 [03:51<03:22,  1.41s/it]predicting train subjects:  50%|█████     | 143/285 [03:53<03:18,  1.40s/it]predicting train subjects:  51%|█████     | 144/285 [03:54<03:22,  1.43s/it]predicting train subjects:  51%|█████     | 145/285 [03:55<03:17,  1.41s/it]predicting train subjects:  51%|█████     | 146/285 [03:57<03:20,  1.44s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:58<03:13,  1.40s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:00<03:16,  1.44s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:01<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:03<03:09,  1.40s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:04<03:12,  1.43s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:05<03:08,  1.41s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:07<03:04,  1.39s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:08<03:07,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:10<03:03,  1.41s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:11<03:06,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:13<03:02,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:14<02:59,  1.41s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:15<02:54,  1.38s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:17<02:52,  1.38s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:18<02:55,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:19<02:51,  1.40s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:21<02:53,  1.42s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:22<02:50,  1.41s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:24<02:47,  1.39s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:25<02:48,  1.42s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:27<02:50,  1.44s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:28<02:45,  1.41s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:29<02:42,  1.40s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:31<02:38,  1.38s/it]predicting train subjects:  60%|██████    | 171/285 [04:32<02:36,  1.37s/it]predicting train subjects:  60%|██████    | 172/285 [04:33<02:34,  1.37s/it]predicting train subjects:  61%|██████    | 173/285 [04:35<02:32,  1.36s/it]predicting train subjects:  61%|██████    | 174/285 [04:36<02:30,  1.35s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:38<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:39<02:37,  1.45s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:40<02:32,  1.41s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:42<02:28,  1.38s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:43<02:25,  1.38s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:45<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:47<02:38,  1.52s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:48<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:49<02:28,  1.45s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:51<02:23,  1.42s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:52<02:17,  1.37s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:54<02:28,  1.50s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:55<02:33,  1.57s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:57<02:36,  1.62s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:59<02:26,  1.52s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:00<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:01<02:21,  1.50s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:03<02:21,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:04<02:13,  1.45s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:06<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:07<02:05,  1.39s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:09<02:14,  1.51s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:10<02:18,  1.58s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:12<02:21,  1.63s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:14<02:13,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:15<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:17<02:11,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:18<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:20<02:07,  1.56s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:21<01:59,  1.47s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:22<01:55,  1.44s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:24<01:49,  1.39s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:25<01:56,  1.49s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:27<01:59,  1.55s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:29<02:01,  1.60s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:30<01:52,  1.50s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:31<01:47,  1.45s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:33<01:49,  1.49s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:35<01:49,  1.52s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:36<01:43,  1.46s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:38<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:39<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:41<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:43<01:48,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:44<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:46<01:41,  1.57s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:47<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:49<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:50<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:51<01:27,  1.43s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:53<01:23,  1.39s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:54<01:28,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:56<01:31,  1.58s/it]predicting train subjects:  80%|████████  | 228/285 [05:58<01:31,  1.61s/it]predicting train subjects:  80%|████████  | 229/285 [05:59<01:29,  1.59s/it]predicting train subjects:  81%|████████  | 230/285 [06:01<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [06:02<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:03<01:18,  1.48s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:05<01:14,  1.44s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:07<01:17,  1.53s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:08<01:12,  1.46s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:10<01:15,  1.54s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:11<01:16,  1.59s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:13<01:17,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:15<01:14,  1.61s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:16<01:08,  1.52s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:17<01:06,  1.50s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:19<01:02,  1.44s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:20<00:58,  1.40s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:22<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:23<00:57,  1.43s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:25<00:59,  1.54s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:27<01:01,  1.61s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:28<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:29<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:31<00:51,  1.47s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:32<00:48,  1.42s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:33<00:45,  1.38s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:35<00:47,  1.49s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:37<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:38<00:46,  1.55s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:40<00:42,  1.47s/it]predicting train subjects:  90%|█████████ | 257/285 [06:41<00:40,  1.43s/it]predicting train subjects:  91%|█████████ | 258/285 [06:43<00:41,  1.54s/it]predicting train subjects:  91%|█████████ | 259/285 [06:44<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [06:46<00:36,  1.47s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:47<00:34,  1.44s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:48<00:32,  1.41s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:50<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:51<00:31,  1.49s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:53<00:31,  1.56s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:54<00:28,  1.49s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:56<00:26,  1.46s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:58<00:26,  1.54s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:59<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:00<00:21,  1.46s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:02<00:20,  1.44s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:03<00:19,  1.47s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:05<00:16,  1.41s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:06<00:15,  1.36s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:08<00:14,  1.48s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:09<00:13,  1.54s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:11<00:11,  1.45s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:12<00:09,  1.42s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:13<00:08,  1.45s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:15<00:07,  1.40s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:16<00:05,  1.40s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:17<00:04,  1.37s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:19<00:03,  1.51s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:21<00:01,  1.58s/it]predicting train subjects: 100%|██████████| 285/285 [07:23<00:00,  1.63s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:06,  1.71s/it]Loading train:   1%|          | 2/285 [00:03<07:42,  1.64s/it]Loading train:   1%|          | 3/285 [00:04<07:31,  1.60s/it]Loading train:   1%|▏         | 4/285 [00:06<07:13,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:07<07:18,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:09<06:53,  1.48s/it]Loading train:   2%|▏         | 7/285 [00:10<07:04,  1.53s/it]Loading train:   3%|▎         | 8/285 [00:11<06:49,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:13<07:14,  1.58s/it]Loading train:   4%|▎         | 10/285 [00:15<06:51,  1.50s/it]Loading train:   4%|▍         | 11/285 [00:16<06:12,  1.36s/it]Loading train:   4%|▍         | 12/285 [00:17<06:01,  1.32s/it]Loading train:   5%|▍         | 13/285 [00:18<05:34,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:19<05:32,  1.23s/it]Loading train:   5%|▌         | 15/285 [00:20<05:34,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:22<05:37,  1.26s/it]Loading train:   6%|▌         | 17/285 [00:23<05:23,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:24<05:18,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:25<05:12,  1.17s/it]Loading train:   7%|▋         | 20/285 [00:26<05:05,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:27<05:10,  1.18s/it]Loading train:   8%|▊         | 22/285 [00:28<04:47,  1.09s/it]Loading train:   8%|▊         | 23/285 [00:29<04:51,  1.11s/it]Loading train:   8%|▊         | 24/285 [00:30<04:40,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:32<04:51,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:33<04:49,  1.12s/it]Loading train:   9%|▉         | 27/285 [00:34<04:39,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:35<04:40,  1.09s/it]Loading train:  10%|█         | 29/285 [00:36<04:43,  1.11s/it]Loading train:  11%|█         | 30/285 [00:37<04:55,  1.16s/it]Loading train:  11%|█         | 31/285 [00:39<05:04,  1.20s/it]Loading train:  11%|█         | 32/285 [00:40<04:49,  1.15s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:46,  1.14s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:42,  1.13s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:37,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:40,  1.13s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:38,  1.12s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:43,  1.15s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:28,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:23,  1.08s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:12,  1.03s/it]Loading train:  15%|█▍        | 42/285 [00:50<03:58,  1.02it/s]Loading train:  15%|█▌        | 43/285 [00:51<04:06,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:18,  1.07s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:03,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:16,  1.07s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:15,  1.08s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:22,  1.11s/it]Loading train:  18%|█▊        | 50/285 [00:59<04:24,  1.12s/it]Loading train:  18%|█▊        | 51/285 [01:00<04:29,  1.15s/it]Loading train:  18%|█▊        | 52/285 [01:01<04:15,  1.10s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:14,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:20,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:13,  1.10s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:04,  1.07s/it]Loading train:  20%|██        | 57/285 [01:07<04:03,  1.07s/it]Loading train:  20%|██        | 58/285 [01:08<04:03,  1.07s/it]Loading train:  21%|██        | 59/285 [01:09<04:18,  1.14s/it]Loading train:  21%|██        | 60/285 [01:10<04:26,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:06,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:12<03:57,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:24,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:59,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:18<05:01,  1.38s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:42,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:24,  1.22s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:10,  1.16s/it]Loading train:  25%|██▍       | 70/285 [01:22<04:01,  1.12s/it]Loading train:  25%|██▍       | 71/285 [01:23<03:54,  1.09s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:49,  1.08s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:50,  1.09s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:48,  1.09s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:49,  1.09s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:40,  1.05s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:37,  1.05s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:29,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:30,  1.02s/it]Loading train:  28%|██▊       | 80/285 [01:32<03:25,  1.00s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:34,  1.05s/it]Loading train:  29%|██▉       | 82/285 [01:35<03:33,  1.05s/it]Loading train:  29%|██▉       | 83/285 [01:36<03:26,  1.02s/it]Loading train:  29%|██▉       | 84/285 [01:37<03:21,  1.00s/it]Loading train:  30%|██▉       | 85/285 [01:38<03:28,  1.04s/it]Loading train:  30%|███       | 86/285 [01:39<03:36,  1.09s/it]Loading train:  31%|███       | 87/285 [01:40<03:31,  1.07s/it]Loading train:  31%|███       | 88/285 [01:41<03:26,  1.05s/it]Loading train:  31%|███       | 89/285 [01:42<03:24,  1.04s/it]Loading train:  32%|███▏      | 90/285 [01:43<03:22,  1.04s/it]Loading train:  32%|███▏      | 91/285 [01:44<03:20,  1.03s/it]Loading train:  32%|███▏      | 92/285 [01:45<03:21,  1.04s/it]Loading train:  33%|███▎      | 93/285 [01:46<03:15,  1.02s/it]Loading train:  33%|███▎      | 94/285 [01:47<03:16,  1.03s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:21,  1.06s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:18,  1.05s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:15,  1.04s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:17,  1.06s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:14,  1.04s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:13,  1.04s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:07,  1.02s/it]Loading train:  36%|███▌      | 102/285 [01:56<03:14,  1.06s/it]Loading train:  36%|███▌      | 103/285 [01:57<03:10,  1.05s/it]Loading train:  36%|███▋      | 104/285 [01:58<03:12,  1.06s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:21,  1.12s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:19,  1.12s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:13,  1.08s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:12,  1.09s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:03,  1.04s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:11,  1.10s/it]Loading train:  39%|███▉      | 111/285 [02:05<03:06,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:07<03:14,  1.12s/it]Loading train:  40%|███▉      | 113/285 [02:08<03:09,  1.10s/it]Loading train:  40%|████      | 114/285 [02:09<03:05,  1.08s/it]Loading train:  40%|████      | 115/285 [02:10<03:04,  1.08s/it]Loading train:  41%|████      | 116/285 [02:11<03:05,  1.10s/it]Loading train:  41%|████      | 117/285 [02:12<03:00,  1.07s/it]Loading train:  41%|████▏     | 118/285 [02:13<02:51,  1.03s/it]Loading train:  42%|████▏     | 119/285 [02:14<02:53,  1.05s/it]Loading train:  42%|████▏     | 120/285 [02:15<02:47,  1.02s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:04,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:05,  1.14s/it]Loading train:  43%|████▎     | 123/285 [02:19<03:11,  1.18s/it]Loading train:  44%|████▎     | 124/285 [02:20<02:57,  1.10s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:46,  1.04s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:35,  1.02it/s]Loading train:  45%|████▍     | 127/285 [02:22<02:29,  1.06it/s]Loading train:  45%|████▍     | 128/285 [02:23<02:22,  1.10it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:16,  1.14it/s]Loading train:  46%|████▌     | 130/285 [02:25<02:22,  1.09it/s]Loading train:  46%|████▌     | 131/285 [02:26<02:19,  1.10it/s]Loading train:  46%|████▋     | 132/285 [02:27<02:22,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:28<02:29,  1.02it/s]Loading train:  47%|████▋     | 134/285 [02:29<02:22,  1.06it/s]Loading train:  47%|████▋     | 135/285 [02:29<02:14,  1.11it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:11,  1.13it/s]Loading train:  48%|████▊     | 137/285 [02:31<02:13,  1.11it/s]Loading train:  48%|████▊     | 138/285 [02:32<02:16,  1.08it/s]Loading train:  49%|████▉     | 139/285 [02:33<02:13,  1.10it/s]Loading train:  49%|████▉     | 140/285 [02:34<02:07,  1.13it/s]Loading train:  49%|████▉     | 141/285 [02:35<02:04,  1.16it/s]Loading train:  50%|████▉     | 142/285 [02:36<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:36<02:02,  1.16it/s]Loading train:  51%|█████     | 144/285 [02:37<02:05,  1.13it/s]Loading train:  51%|█████     | 145/285 [02:38<02:01,  1.15it/s]Loading train:  51%|█████     | 146/285 [02:39<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:40<02:00,  1.15it/s]Loading train:  52%|█████▏    | 148/285 [02:41<01:59,  1.15it/s]Loading train:  52%|█████▏    | 149/285 [02:42<02:00,  1.13it/s]Loading train:  53%|█████▎    | 150/285 [02:43<01:58,  1.14it/s]Loading train:  53%|█████▎    | 151/285 [02:43<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:44<01:59,  1.12it/s]Loading train:  54%|█████▎    | 153/285 [02:45<01:55,  1.14it/s]Loading train:  54%|█████▍    | 154/285 [02:46<01:54,  1.15it/s]Loading train:  54%|█████▍    | 155/285 [02:47<01:53,  1.15it/s]Loading train:  55%|█████▍    | 156/285 [02:48<01:53,  1.14it/s]Loading train:  55%|█████▌    | 157/285 [02:49<01:52,  1.14it/s]Loading train:  55%|█████▌    | 158/285 [02:50<01:48,  1.17it/s]Loading train:  56%|█████▌    | 159/285 [02:50<01:48,  1.16it/s]Loading train:  56%|█████▌    | 160/285 [02:51<01:45,  1.18it/s]Loading train:  56%|█████▋    | 161/285 [02:52<01:52,  1.10it/s]Loading train:  57%|█████▋    | 162/285 [02:53<01:46,  1.16it/s]Loading train:  57%|█████▋    | 163/285 [02:54<01:42,  1.19it/s]Loading train:  58%|█████▊    | 164/285 [02:55<01:37,  1.24it/s]Loading train:  58%|█████▊    | 165/285 [02:55<01:34,  1.27it/s]Loading train:  58%|█████▊    | 166/285 [02:56<01:36,  1.23it/s]Loading train:  59%|█████▊    | 167/285 [02:57<01:39,  1.19it/s]Loading train:  59%|█████▉    | 168/285 [02:58<01:36,  1.21it/s]Loading train:  59%|█████▉    | 169/285 [02:59<01:38,  1.18it/s]Loading train:  60%|█████▉    | 170/285 [03:00<01:34,  1.22it/s]Loading train:  60%|██████    | 171/285 [03:00<01:33,  1.23it/s]Loading train:  60%|██████    | 172/285 [03:01<01:29,  1.26it/s]Loading train:  61%|██████    | 173/285 [03:02<01:26,  1.30it/s]Loading train:  61%|██████    | 174/285 [03:03<01:24,  1.31it/s]Loading train:  61%|██████▏   | 175/285 [03:03<01:26,  1.27it/s]Loading train:  62%|██████▏   | 176/285 [03:04<01:27,  1.25it/s]Loading train:  62%|██████▏   | 177/285 [03:05<01:27,  1.24it/s]Loading train:  62%|██████▏   | 178/285 [03:06<01:28,  1.21it/s]Loading train:  63%|██████▎   | 179/285 [03:07<01:31,  1.16it/s]Loading train:  63%|██████▎   | 180/285 [03:08<01:37,  1.08it/s]Loading train:  64%|██████▎   | 181/285 [03:09<01:40,  1.04it/s]Loading train:  64%|██████▍   | 182/285 [03:10<01:38,  1.04it/s]Loading train:  64%|██████▍   | 183/285 [03:11<01:33,  1.09it/s]Loading train:  65%|██████▍   | 184/285 [03:12<01:29,  1.12it/s]Loading train:  65%|██████▍   | 185/285 [03:12<01:26,  1.15it/s]Loading train:  65%|██████▌   | 186/285 [03:13<01:31,  1.08it/s]Loading train:  66%|██████▌   | 187/285 [03:14<01:30,  1.08it/s]Loading train:  66%|██████▌   | 188/285 [03:15<01:32,  1.05it/s]Loading train:  66%|██████▋   | 189/285 [03:16<01:27,  1.10it/s]Loading train:  67%|██████▋   | 190/285 [03:17<01:26,  1.10it/s]Loading train:  67%|██████▋   | 191/285 [03:18<01:28,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:19<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:20<01:23,  1.10it/s]Loading train:  68%|██████▊   | 194/285 [03:21<01:22,  1.11it/s]Loading train:  68%|██████▊   | 195/285 [03:22<01:20,  1.12it/s]Loading train:  69%|██████▉   | 196/285 [03:23<01:25,  1.05it/s]Loading train:  69%|██████▉   | 197/285 [03:24<01:23,  1.05it/s]Loading train:  69%|██████▉   | 198/285 [03:25<01:24,  1.02it/s]Loading train:  70%|██████▉   | 199/285 [03:26<01:19,  1.08it/s]Loading train:  70%|███████   | 200/285 [03:26<01:15,  1.13it/s]Loading train:  71%|███████   | 201/285 [03:27<01:16,  1.10it/s]Loading train:  71%|███████   | 202/285 [03:28<01:16,  1.09it/s]Loading train:  71%|███████   | 203/285 [03:29<01:13,  1.12it/s]Loading train:  72%|███████▏  | 204/285 [03:30<01:11,  1.14it/s]Loading train:  72%|███████▏  | 205/285 [03:31<01:08,  1.17it/s]Loading train:  72%|███████▏  | 206/285 [03:31<01:05,  1.21it/s]Loading train:  73%|███████▎  | 207/285 [03:32<01:07,  1.15it/s]Loading train:  73%|███████▎  | 208/285 [03:33<01:09,  1.11it/s]Loading train:  73%|███████▎  | 209/285 [03:34<01:08,  1.11it/s]Loading train:  74%|███████▎  | 210/285 [03:35<01:03,  1.18it/s]Loading train:  74%|███████▍  | 211/285 [03:36<01:01,  1.21it/s]Loading train:  74%|███████▍  | 212/285 [03:37<01:02,  1.17it/s]Loading train:  75%|███████▍  | 213/285 [03:38<01:01,  1.17it/s]Loading train:  75%|███████▌  | 214/285 [03:38<00:59,  1.19it/s]Loading train:  75%|███████▌  | 215/285 [03:39<01:03,  1.11it/s]Loading train:  76%|███████▌  | 216/285 [03:40<00:59,  1.15it/s]Loading train:  76%|███████▌  | 217/285 [03:41<01:03,  1.07it/s]Loading train:  76%|███████▋  | 218/285 [03:42<01:04,  1.04it/s]Loading train:  77%|███████▋  | 219/285 [03:43<01:03,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [03:44<00:59,  1.09it/s]Loading train:  78%|███████▊  | 221/285 [03:45<00:56,  1.13it/s]Loading train:  78%|███████▊  | 222/285 [03:46<00:55,  1.13it/s]Loading train:  78%|███████▊  | 223/285 [03:47<00:53,  1.16it/s]Loading train:  79%|███████▊  | 224/285 [03:47<00:50,  1.21it/s]Loading train:  79%|███████▉  | 225/285 [03:48<00:47,  1.25it/s]Loading train:  79%|███████▉  | 226/285 [03:49<00:49,  1.19it/s]Loading train:  80%|███████▉  | 227/285 [03:50<00:50,  1.16it/s]Loading train:  80%|████████  | 228/285 [03:51<00:51,  1.12it/s]Loading train:  80%|████████  | 229/285 [03:52<00:49,  1.14it/s]Loading train:  81%|████████  | 230/285 [03:53<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [03:53<00:45,  1.19it/s]Loading train:  81%|████████▏ | 232/285 [03:54<00:44,  1.19it/s]Loading train:  82%|████████▏ | 233/285 [03:55<00:42,  1.23it/s]Loading train:  82%|████████▏ | 234/285 [03:56<00:43,  1.17it/s]Loading train:  82%|████████▏ | 235/285 [03:57<00:40,  1.22it/s]Loading train:  83%|████████▎ | 236/285 [03:58<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:58<00:42,  1.14it/s]Loading train:  84%|████████▎ | 238/285 [03:59<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [04:00<00:39,  1.16it/s]Loading train:  84%|████████▍ | 240/285 [04:01<00:36,  1.22it/s]Loading train:  85%|████████▍ | 241/285 [04:02<00:34,  1.26it/s]Loading train:  85%|████████▍ | 242/285 [04:02<00:34,  1.25it/s]Loading train:  85%|████████▌ | 243/285 [04:03<00:33,  1.26it/s]Loading train:  86%|████████▌ | 244/285 [04:04<00:33,  1.22it/s]Loading train:  86%|████████▌ | 245/285 [04:05<00:32,  1.23it/s]Loading train:  86%|████████▋ | 246/285 [04:06<00:33,  1.16it/s]Loading train:  87%|████████▋ | 247/285 [04:07<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [04:08<00:32,  1.15it/s]Loading train:  87%|████████▋ | 249/285 [04:08<00:30,  1.18it/s]Loading train:  88%|████████▊ | 250/285 [04:09<00:28,  1.22it/s]Loading train:  88%|████████▊ | 251/285 [04:10<00:27,  1.25it/s]Loading train:  88%|████████▊ | 252/285 [04:11<00:25,  1.27it/s]Loading train:  89%|████████▉ | 253/285 [04:12<00:27,  1.17it/s]Loading train:  89%|████████▉ | 254/285 [04:13<00:26,  1.16it/s]Loading train:  89%|████████▉ | 255/285 [04:13<00:25,  1.18it/s]Loading train:  90%|████████▉ | 256/285 [04:14<00:23,  1.24it/s]Loading train:  90%|█████████ | 257/285 [04:15<00:22,  1.27it/s]Loading train:  91%|█████████ | 258/285 [04:16<00:22,  1.21it/s]Loading train:  91%|█████████ | 259/285 [04:17<00:21,  1.22it/s]Loading train:  91%|█████████ | 260/285 [04:17<00:19,  1.25it/s]Loading train:  92%|█████████▏| 261/285 [04:18<00:18,  1.28it/s]Loading train:  92%|█████████▏| 262/285 [04:19<00:17,  1.30it/s]Loading train:  92%|█████████▏| 263/285 [04:20<00:16,  1.30it/s]Loading train:  93%|█████████▎| 264/285 [04:21<00:17,  1.19it/s]Loading train:  93%|█████████▎| 265/285 [04:22<00:17,  1.14it/s]Loading train:  93%|█████████▎| 266/285 [04:22<00:15,  1.21it/s]Loading train:  94%|█████████▎| 267/285 [04:23<00:14,  1.26it/s]Loading train:  94%|█████████▍| 268/285 [04:24<00:14,  1.21it/s]Loading train:  94%|█████████▍| 269/285 [04:25<00:13,  1.21it/s]Loading train:  95%|█████████▍| 270/285 [04:25<00:12,  1.25it/s]Loading train:  95%|█████████▌| 271/285 [04:26<00:11,  1.26it/s]Loading train:  95%|█████████▌| 272/285 [04:27<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [04:28<00:09,  1.28it/s]Loading train:  96%|█████████▌| 274/285 [04:29<00:08,  1.29it/s]Loading train:  96%|█████████▋| 275/285 [04:30<00:08,  1.22it/s]Loading train:  97%|█████████▋| 276/285 [04:31<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [04:31<00:06,  1.19it/s]Loading train:  98%|█████████▊| 278/285 [04:32<00:05,  1.24it/s]Loading train:  98%|█████████▊| 279/285 [04:33<00:04,  1.21it/s]Loading train:  98%|█████████▊| 280/285 [04:34<00:04,  1.23it/s]Loading train:  99%|█████████▊| 281/285 [04:34<00:03,  1.27it/s]Loading train:  99%|█████████▉| 282/285 [04:35<00:02,  1.30it/s]Loading train:  99%|█████████▉| 283/285 [04:36<00:01,  1.17it/s]Loading train: 100%|█████████▉| 284/285 [04:37<00:00,  1.08it/s]Loading train: 100%|██████████| 285/285 [04:38<00:00,  1.01it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:00, 266.81it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:00, 266.38it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:00, 269.55it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 277.79it/s]concatenating: train:  51%|█████     | 144/285 [00:00<00:00, 287.37it/s]concatenating: train:  62%|██████▏   | 176/285 [00:00<00:00, 295.27it/s]concatenating: train:  73%|███████▎  | 208/285 [00:00<00:00, 300.37it/s]concatenating: train:  85%|████████▍ | 241/285 [00:00<00:00, 307.81it/s]concatenating: train:  97%|█████████▋| 276/285 [00:00<00:00, 317.62it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 302.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.34s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 194.07it/s]2019-07-11 09:11:07.129781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 09:11:07.129868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 09:11:07.129882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 09:11:07.129890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 09:11:07.133127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.29it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.68it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.63it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.44it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.63it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.47it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.86it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.42it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.27it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.71it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.75it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.76it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.57it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.85it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.81it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.78it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.98it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 10)   5410        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 10)   910         dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 70)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 232,303
Trainable params: 57,563
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 1.9801 - acc: 0.7349 - mDice: 0.2326 - val_loss: 0.7929 - val_acc: 0.9236 - val_mDice: 0.4506

Epoch 00001: val_mDice improved from -inf to 0.45056, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.5689 - acc: 0.9063 - mDice: 0.5539 - val_loss: 0.5185 - val_acc: 0.9365 - val_mDice: 0.5894

Epoch 00002: val_mDice improved from 0.45056 to 0.58937, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.4672 - acc: 0.9164 - mDice: 0.6162 - val_loss: 0.4842 - val_acc: 0.9419 - val_mDice: 0.6102

Epoch 00003: val_mDice improved from 0.58937 to 0.61022, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.4146 - acc: 0.9275 - mDice: 0.6477 - val_loss: 0.5056 - val_acc: 0.9475 - val_mDice: 0.6011

Epoch 00004: val_mDice did not improve from 0.61022
Epoch 5/300
 - 13s - loss: 0.3888 - acc: 0.9386 - mDice: 0.6643 - val_loss: 0.4606 - val_acc: 0.9544 - val_mDice: 0.6246

Epoch 00005: val_mDice improved from 0.61022 to 0.62456, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.3717 - acc: 0.9436 - mDice: 0.6759 - val_loss: 0.4736 - val_acc: 0.9550 - val_mDice: 0.6223

Epoch 00006: val_mDice did not improve from 0.62456
Epoch 7/300
 - 13s - loss: 0.3600 - acc: 0.9462 - mDice: 0.6840 - val_loss: 0.4571 - val_acc: 0.9531 - val_mDice: 0.6278

Epoch 00007: val_mDice improved from 0.62456 to 0.62777, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.3482 - acc: 0.9477 - mDice: 0.6921 - val_loss: 0.4763 - val_acc: 0.9547 - val_mDice: 0.6232

Epoch 00008: val_mDice did not improve from 0.62777
Epoch 9/300
 - 13s - loss: 0.3399 - acc: 0.9486 - mDice: 0.6982 - val_loss: 0.4552 - val_acc: 0.9545 - val_mDice: 0.6271

Epoch 00009: val_mDice did not improve from 0.62777
Epoch 10/300
 - 13s - loss: 0.3330 - acc: 0.9492 - mDice: 0.7030 - val_loss: 0.4418 - val_acc: 0.9535 - val_mDice: 0.6351

Epoch 00010: val_mDice improved from 0.62777 to 0.63507, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3264 - acc: 0.9499 - mDice: 0.7079 - val_loss: 0.4299 - val_acc: 0.9543 - val_mDice: 0.6421

Epoch 00011: val_mDice improved from 0.63507 to 0.64213, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 13s - loss: 0.3195 - acc: 0.9503 - mDice: 0.7128 - val_loss: 0.4522 - val_acc: 0.9530 - val_mDice: 0.6297

Epoch 00012: val_mDice did not improve from 0.64213
Epoch 13/300
 - 13s - loss: 0.3140 - acc: 0.9508 - mDice: 0.7169 - val_loss: 0.4431 - val_acc: 0.9554 - val_mDice: 0.6389

Epoch 00013: val_mDice did not improve from 0.64213
Epoch 14/300
 - 13s - loss: 0.3112 - acc: 0.9511 - mDice: 0.7191 - val_loss: 0.4577 - val_acc: 0.9535 - val_mDice: 0.6302

Epoch 00014: val_mDice did not improve from 0.64213
Epoch 15/300
 - 13s - loss: 0.3063 - acc: 0.9515 - mDice: 0.7227 - val_loss: 0.4555 - val_acc: 0.9539 - val_mDice: 0.6298

Epoch 00015: val_mDice did not improve from 0.64213
Epoch 16/300
 - 13s - loss: 0.3023 - acc: 0.9518 - mDice: 0.7258 - val_loss: 0.4828 - val_acc: 0.9542 - val_mDice: 0.6208

Epoch 00016: val_mDice did not improve from 0.64213
Epoch 17/300
 - 13s - loss: 0.2985 - acc: 0.9521 - mDice: 0.7287 - val_loss: 0.4424 - val_acc: 0.9538 - val_mDice: 0.6369

Epoch 00017: val_mDice did not improve from 0.64213
Epoch 18/300
 - 13s - loss: 0.2943 - acc: 0.9525 - mDice: 0.7318 - val_loss: 0.4584 - val_acc: 0.9524 - val_mDice: 0.6224

Epoch 00018: val_mDice did not improve from 0.64213
Epoch 19/300
 - 13s - loss: 0.2919 - acc: 0.9527 - mDice: 0.7336 - val_loss: 0.4725 - val_acc: 0.9542 - val_mDice: 0.6247

Epoch 00019: val_mDice did not improve from 0.64213
Epoch 20/300
 - 13s - loss: 0.2891 - acc: 0.9529 - mDice: 0.7357 - val_loss: 0.4430 - val_acc: 0.9543 - val_mDice: 0.6353

Epoch 00020: val_mDice did not improve from 0.64213
Epoch 21/300
 - 13s - loss: 0.2851 - acc: 0.9532 - mDice: 0.7386 - val_loss: 0.4383 - val_acc: 0.9549 - val_mDice: 0.6359

Epoch 00021: val_mDice did not improve from 0.64213
Epoch 22/300
 - 13s - loss: 0.2841 - acc: 0.9533 - mDice: 0.7395 - val_loss: 0.4609 - val_acc: 0.9545 - val_mDice: 0.6250

Epoch 00022: val_mDice did not improve from 0.64213
Epoch 23/300
 - 13s - loss: 0.2820 - acc: 0.9535 - mDice: 0.7412 - val_loss: 0.4449 - val_acc: 0.9540 - val_mDice: 0.6350

Epoch 00023: val_mDice did not improve from 0.64213
Epoch 24/300
 - 13s - loss: 0.2798 - acc: 0.9536 - mDice: 0.7429 - val_loss: 0.4556 - val_acc: 0.9530 - val_mDice: 0.6310

Epoch 00024: val_mDice did not improve from 0.64213
Epoch 25/300
 - 13s - loss: 0.2771 - acc: 0.9538 - mDice: 0.7449 - val_loss: 0.4513 - val_acc: 0.9534 - val_mDice: 0.6312

Epoch 00025: val_mDice did not improve from 0.64213
Epoch 26/300
 - 13s - loss: 0.2736 - acc: 0.9541 - mDice: 0.7477 - val_loss: 0.4520 - val_acc: 0.9552 - val_mDice: 0.6281

Epoch 00026: val_mDice did not improve from 0.64213
Epoch 27/300
 - 13s - loss: 0.2727 - acc: 0.9542 - mDice: 0.7484 - val_loss: 0.4571 - val_acc: 0.9557 - val_mDice: 0.6274

Epoch 00027: val_mDice did not improve from 0.64213
Epoch 28/300
 - 14s - loss: 0.2728 - acc: 0.9542 - mDice: 0.7483 - val_loss: 0.4429 - val_acc: 0.9549 - val_mDice: 0.6358

Epoch 00028: val_mDice did not improve from 0.64213
Epoch 29/300
 - 14s - loss: 0.2688 - acc: 0.9544 - mDice: 0.7514 - val_loss: 0.4444 - val_acc: 0.9551 - val_mDice: 0.6318

Epoch 00029: val_mDice did not improve from 0.64213
Epoch 30/300
 - 13s - loss: 0.2771 - acc: 0.9544 - mDice: 0.7498 - val_loss: 0.4377 - val_acc: 0.9548 - val_mDice: 0.6375

Epoch 00030: val_mDice did not improve from 0.64213
Epoch 31/300
 - 13s - loss: 0.2690 - acc: 0.9544 - mDice: 0.7512 - val_loss: 0.4597 - val_acc: 0.9539 - val_mDice: 0.6236

Epoch 00031: val_mDice did not improve from 0.64213
Epoch 32/300
 - 13s - loss: 0.2653 - acc: 0.9547 - mDice: 0.7541 - val_loss: 0.4389 - val_acc: 0.9540 - val_mDice: 0.6373

Epoch 00032: val_mDice did not improve from 0.64213
Epoch 33/300
 - 13s - loss: 0.2644 - acc: 0.9548 - mDice: 0.7549 - val_loss: 0.4659 - val_acc: 0.9522 - val_mDice: 0.6236

Epoch 00033: val_mDice did not improve from 0.64213
Epoch 34/300
 - 13s - loss: 0.2632 - acc: 0.9548 - mDice: 0.7557 - val_loss: 0.4603 - val_acc: 0.9542 - val_mDice: 0.6249

Epoch 00034: val_mDice did not improve from 0.64213
Epoch 35/300
 - 13s - loss: 0.2643 - acc: 0.9549 - mDice: 0.7551 - val_loss: 0.4363 - val_acc: 0.9549 - val_mDice: 0.6392

Epoch 00035: val_mDice did not improve from 0.64213
Epoch 36/300
 - 14s - loss: 0.2607 - acc: 0.9551 - mDice: 0.7578 - val_loss: 0.4498 - val_acc: 0.9544 - val_mDice: 0.6308

Epoch 00036: val_mDice did not improve from 0.64213
Epoch 37/300
 - 14s - loss: 0.2582 - acc: 0.9552 - mDice: 0.7597 - val_loss: 0.4552 - val_acc: 0.9550 - val_mDice: 0.6282

Epoch 00037: val_mDice did not improve from 0.64213
Epoch 38/300
 - 13s - loss: 0.2592 - acc: 0.9552 - mDice: 0.7589 - val_loss: 0.4435 - val_acc: 0.9562 - val_mDice: 0.6342

Epoch 00038: val_mDice did not improve from 0.64213
Epoch 39/300
 - 13s - loss: 0.2562 - acc: 0.9555 - mDice: 0.7614 - val_loss: 0.4438 - val_acc: 0.9539 - val_mDice: 0.6345

Epoch 00039: val_mDice did not improve from 0.64213
Epoch 40/300
 - 13s - loss: 0.2559 - acc: 0.9554 - mDice: 0.7616 - val_loss: 0.4503 - val_acc: 0.9556 - val_mDice: 0.6327

Epoch 00040: val_mDice did not improve from 0.64213
Epoch 41/300
 - 13s - loss: 0.2546 - acc: 0.9556 - mDice: 0.7626 - val_loss: 0.4536 - val_acc: 0.9530 - val_mDice: 0.6272

Epoch 00041: val_mDice did not improve from 0.64213
Epoch 42/300
 - 13s - loss: 0.2533 - acc: 0.9555 - mDice: 0.7636 - val_loss: 0.4539 - val_acc: 0.9535 - val_mDice: 0.6252

Epoch 00042: val_mDice did not improve from 0.64213
Epoch 43/300
 - 13s - loss: 0.2526 - acc: 0.9556 - mDice: 0.7642 - val_loss: 0.4480 - val_acc: 0.9554 - val_mDice: 0.6337

Epoch 00043: val_mDice did not improve from 0.64213
Epoch 44/300
 - 14s - loss: 0.2510 - acc: 0.9558 - mDice: 0.7654 - val_loss: 0.4577 - val_acc: 0.9529 - val_mDice: 0.6238

Epoch 00044: val_mDice did not improve from 0.64213
Epoch 45/300
 - 13s - loss: 0.2516 - acc: 0.9557 - mDice: 0.7651 - val_loss: 0.4508 - val_acc: 0.9539 - val_mDice: 0.6291

Epoch 00045: val_mDice did not improve from 0.64213
Epoch 46/300
 - 13s - loss: 0.2501 - acc: 0.9558 - mDice: 0.7662 - val_loss: 0.4593 - val_acc: 0.9541 - val_mDice: 0.6259

Epoch 00046: val_mDice did not improve from 0.64213
Epoch 47/300
 - 13s - loss: 0.2501 - acc: 0.9559 - mDice: 0.7664 - val_loss: 0.4672 - val_acc: 0.9539 - val_mDice: 0.6203

Epoch 00047: val_mDice did not improve from 0.64213
Epoch 48/300
 - 14s - loss: 0.2482 - acc: 0.9559 - mDice: 0.7678 - val_loss: 0.4576 - val_acc: 0.9547 - val_mDice: 0.6248

Epoch 00048: val_mDice did not improve from 0.64213
Epoch 49/300
 - 14s - loss: 0.2472 - acc: 0.9560 - mDice: 0.7685 - val_loss: 0.4732 - val_acc: 0.9555 - val_mDice: 0.6233

Epoch 00049: val_mDice did not improve from 0.64213
Epoch 50/300
 - 13s - loss: 0.2461 - acc: 0.9560 - mDice: 0.7694 - val_loss: 0.4491 - val_acc: 0.9551 - val_mDice: 0.6308

Epoch 00050: val_mDice did not improve from 0.64213
Epoch 51/300
 - 13s - loss: 0.2467 - acc: 0.9560 - mDice: 0.7689 - val_loss: 0.4969 - val_acc: 0.9558 - val_mDice: 0.6145

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:51,  1.87s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:20,  1.77s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:12,  1.75s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:44,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:58,  1.71s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:33,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:50,  1.69s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:52,  1.71s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:20,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:18,  1.82s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:36,  1.89s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:09,  1.80s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:09,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:30,  1.89s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:44,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:15,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:12,  1.85s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:02,  1.82s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:00,  1.81s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:23,  1.91s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:00,  1.83s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:03,  1.85s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:44,  1.78s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<07:59,  1.84s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:14,  1.91s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:52,  1.83s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:56,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:52,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:09,  1.92s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:18,  1.96s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:51,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:54,  1.90s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:41,  1.86s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:31,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:28,  1.83s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:16,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<07:07,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:10,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:28,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:08,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:20,  1.84s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<07:01,  1.77s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<07:04,  1.79s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<07:20,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:27,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<07:40,  1.97s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:20,  1.89s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:15,  1.88s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:24,  1.92s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<07:00,  1.83s/it]predicting train subjects:  20%|█▉        | 56/285 [01:42<06:59,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:45,  1.78s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:47,  1.79s/it]predicting train subjects:  21%|██        | 59/285 [01:48<07:02,  1.87s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:19,  1.95s/it]predicting train subjects:  21%|██▏       | 61/285 [01:51<06:55,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [01:53<06:56,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [01:55<06:57,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:57<06:44,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:44,  1.84s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:50,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:03<06:45,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:04<06:32,  1.81s/it]predicting train subjects:  24%|██▍       | 69/285 [02:06<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:08<06:32,  1.83s/it]predicting train subjects:  25%|██▍       | 71/285 [02:10<06:31,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:11<06:23,  1.80s/it]predicting train subjects:  26%|██▌       | 73/285 [02:13<06:26,  1.82s/it]predicting train subjects:  26%|██▌       | 74/285 [02:15<06:25,  1.82s/it]predicting train subjects:  26%|██▋       | 75/285 [02:17<06:27,  1.84s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<06:26,  1.85s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<06:15,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:22<06:07,  1.77s/it]predicting train subjects:  28%|██▊       | 79/285 [02:24<06:09,  1.79s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<06:17,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<06:04,  1.79s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<06:00,  1.78s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:54,  1.76s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:58,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:37<06:04,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:41<05:58,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:42<06:02,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:44<06:00,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:48,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<05:53,  1.83s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<05:45,  1.80s/it]predicting train subjects:  33%|███▎      | 94/285 [02:51<05:44,  1.81s/it]predicting train subjects:  33%|███▎      | 95/285 [02:53<05:44,  1.82s/it]predicting train subjects:  34%|███▎      | 96/285 [02:55<05:44,  1.82s/it]predicting train subjects:  34%|███▍      | 97/285 [02:57<05:45,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [02:59<05:42,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [03:01<05:40,  1.83s/it]predicting train subjects:  35%|███▌      | 100/285 [03:03<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:04<05:36,  1.83s/it]predicting train subjects:  36%|███▌      | 102/285 [03:06<05:37,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:08<05:28,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:10<05:25,  1.80s/it]predicting train subjects:  37%|███▋      | 105/285 [03:12<05:26,  1.81s/it]predicting train subjects:  37%|███▋      | 106/285 [03:13<05:17,  1.77s/it]predicting train subjects:  38%|███▊      | 107/285 [03:15<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:17<05:15,  1.78s/it]predicting train subjects:  38%|███▊      | 109/285 [03:19<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:20<05:16,  1.81s/it]predicting train subjects:  39%|███▉      | 111/285 [03:22<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 112/285 [03:24<05:07,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:26<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:28<05:09,  1.81s/it]predicting train subjects:  40%|████      | 115/285 [03:30<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:31<05:13,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:33<05:07,  1.83s/it]predicting train subjects:  41%|████▏     | 118/285 [03:35<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<05:02,  1.82s/it]predicting train subjects:  42%|████▏     | 120/285 [03:38<04:53,  1.78s/it]predicting train subjects:  42%|████▏     | 121/285 [03:40<04:45,  1.74s/it]predicting train subjects:  43%|████▎     | 122/285 [03:42<04:32,  1.67s/it]predicting train subjects:  43%|████▎     | 123/285 [03:43<04:21,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:45<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [03:46<04:14,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:48<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:49<04:04,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:51<04:07,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:53<04:08,  1.59s/it]predicting train subjects:  46%|████▌     | 130/285 [03:54<04:04,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [03:56<04:00,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [03:57<04:02,  1.59s/it]predicting train subjects:  47%|████▋     | 133/285 [03:59<03:57,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:00<03:53,  1.54s/it]predicting train subjects:  47%|████▋     | 135/285 [04:02<03:50,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [04:03<03:47,  1.52s/it]predicting train subjects:  48%|████▊     | 137/285 [04:05<03:51,  1.57s/it]predicting train subjects:  48%|████▊     | 138/285 [04:06<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [04:08<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:10<03:51,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:11<03:45,  1.57s/it]predicting train subjects:  50%|████▉     | 142/285 [04:13<03:46,  1.58s/it]predicting train subjects:  50%|█████     | 143/285 [04:14<03:41,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:16<03:43,  1.58s/it]predicting train subjects:  51%|█████     | 145/285 [04:18<03:39,  1.57s/it]predicting train subjects:  51%|█████     | 146/285 [04:19<03:39,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:21<03:35,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:22<03:37,  1.59s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:24<03:32,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:25<03:30,  1.56s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:27<03:32,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:28<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:30<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:32<03:23,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:33<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:35<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:36<03:17,  1.54s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:38<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:39<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:41<03:15,  1.56s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:43<03:20,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:44<03:13,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:46<03:13,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:47<03:09,  1.57s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:49<03:06,  1.55s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:50<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:52<03:08,  1.60s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:53<03:02,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:55<02:59,  1.55s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:56<02:55,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [04:58<02:53,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [05:00<02:52,  1.53s/it]predicting train subjects:  61%|██████    | 173/285 [05:01<02:50,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [05:03<02:47,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:04<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:06<02:51,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:07<02:48,  1.56s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:09<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:10<02:39,  1.50s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:12<02:46,  1.58s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:14<02:47,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:15<02:52,  1.67s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:17<02:44,  1.61s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:18<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:20<02:32,  1.53s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:22<02:46,  1.68s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:24<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:26<02:53,  1.79s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:27<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:29<02:34,  1.62s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:30<02:35,  1.65s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:32<02:36,  1.68s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:34<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:35<02:22,  1.57s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:36<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:38<02:25,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:40<02:30,  1.71s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:42<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:43<02:21,  1.65s/it]predicting train subjects:  70%|███████   | 200/285 [05:45<02:15,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:47<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:48<02:17,  1.66s/it]predicting train subjects:  71%|███████   | 203/285 [05:50<02:16,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:52<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:53<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:54<02:00,  1.53s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:56<02:07,  1.64s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:58<02:12,  1.72s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:00<02:13,  1.75s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:01<02:04,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:03<01:57,  1.59s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:05<01:58,  1.62s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:06<01:58,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:08<01:52,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<01:54,  1.63s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:11<01:47,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:13<01:51,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:15<01:53,  1.69s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:16<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:18<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:19<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:21<01:42,  1.62s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:22<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:24<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:25<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:27<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:29<01:36,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:31<01:37,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:32<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:34<01:28,  1.60s/it]predicting train subjects:  81%|████████  | 231/285 [06:35<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:37<01:24,  1.60s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:38<01:20,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:40<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:42<01:18,  1.58s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:43<01:21,  1.67s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:45<01:22,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:47<01:21,  1.73s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:49<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:50<01:13,  1.63s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:52<01:09,  1.59s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:53<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:54<01:03,  1.50s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:56<01:05,  1.60s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:58<01:01,  1.54s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:00<01:03,  1.63s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:01<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:02,  1.69s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:04<00:58,  1.62s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<00:55,  1.58s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:07<00:52,  1.53s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:09<00:49,  1.50s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:11<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:12<00:51,  1.66s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:14<00:49,  1.66s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:16<00:46,  1.59s/it]predicting train subjects:  90%|█████████ | 257/285 [07:17<00:43,  1.55s/it]predicting train subjects:  91%|█████████ | 258/285 [07:19<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:20<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:22<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:23<00:36,  1.53s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:25<00:34,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:26<00:32,  1.48s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:28<00:33,  1.60s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:30<00:33,  1.65s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:31<00:30,  1.58s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:33<00:27,  1.54s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:34<00:27,  1.62s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:36<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:38<00:23,  1.58s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:16,  1.52s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:46<00:16,  1.62s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:47<00:15,  1.67s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:49<00:12,  1.59s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:10,  1.52s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:52<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:07,  1.53s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:55<00:06,  1.51s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:56<00:04,  1.49s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:58<00:03,  1.59s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:00<00:01,  1.66s/it]predicting train subjects: 100%|██████████| 285/285 [08:02<00:00,  1.72s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:00,  1.48s/it]Loading train:   1%|          | 2/285 [00:02<06:31,  1.38s/it]Loading train:   1%|          | 3/285 [00:04<06:36,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:05<05:55,  1.27s/it]Loading train:   2%|▏         | 5/285 [00:06<06:14,  1.34s/it]Loading train:   2%|▏         | 6/285 [00:07<05:57,  1.28s/it]Loading train:   2%|▏         | 7/285 [00:09<06:06,  1.32s/it]Loading train:   3%|▎         | 8/285 [00:10<06:10,  1.34s/it]Loading train:   3%|▎         | 9/285 [00:12<06:27,  1.40s/it]Loading train:   4%|▎         | 10/285 [00:12<05:39,  1.24s/it]Loading train:   4%|▍         | 11/285 [00:13<05:03,  1.11s/it]Loading train:   4%|▍         | 12/285 [00:14<05:07,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:15<04:44,  1.05s/it]Loading train:   5%|▍         | 14/285 [00:16<04:34,  1.01s/it]Loading train:   5%|▌         | 15/285 [00:17<04:21,  1.03it/s]Loading train:   6%|▌         | 16/285 [00:18<04:10,  1.07it/s]Loading train:   6%|▌         | 17/285 [00:19<03:53,  1.15it/s]Loading train:   6%|▋         | 18/285 [00:19<03:53,  1.14it/s]Loading train:   7%|▋         | 19/285 [00:20<03:49,  1.16it/s]Loading train:   7%|▋         | 20/285 [00:21<03:44,  1.18it/s]Loading train:   7%|▋         | 21/285 [00:22<03:46,  1.17it/s]Loading train:   8%|▊         | 22/285 [00:23<03:51,  1.14it/s]Loading train:   8%|▊         | 23/285 [00:24<03:49,  1.14it/s]Loading train:   8%|▊         | 24/285 [00:25<03:47,  1.15it/s]Loading train:   9%|▉         | 25/285 [00:26<03:52,  1.12it/s]Loading train:   9%|▉         | 26/285 [00:27<03:56,  1.10it/s]Loading train:   9%|▉         | 27/285 [00:27<03:44,  1.15it/s]Loading train:  10%|▉         | 28/285 [00:28<04:01,  1.07it/s]Loading train:  10%|█         | 29/285 [00:29<03:58,  1.07it/s]Loading train:  11%|█         | 30/285 [00:30<04:04,  1.04it/s]Loading train:  11%|█         | 31/285 [00:31<04:14,  1.00s/it]Loading train:  11%|█         | 32/285 [00:32<03:52,  1.09it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:49,  1.10it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:48,  1.10it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:44,  1.11it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:40,  1.13it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:44,  1.11it/s]Loading train:  13%|█▎        | 38/285 [00:38<03:51,  1.07it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:38,  1.13it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:45,  1.09it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:39,  1.11it/s]Loading train:  15%|█▍        | 42/285 [00:41<03:31,  1.15it/s]Loading train:  15%|█▌        | 43/285 [00:42<03:26,  1.17it/s]Loading train:  15%|█▌        | 44/285 [00:43<03:36,  1.11it/s]Loading train:  16%|█▌        | 45/285 [00:44<03:26,  1.16it/s]Loading train:  16%|█▌        | 46/285 [00:45<03:26,  1.16it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:18,  1.20it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:25,  1.16it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:35,  1.09it/s]Loading train:  18%|█▊        | 50/285 [00:48<03:25,  1.14it/s]Loading train:  18%|█▊        | 51/285 [00:49<03:25,  1.14it/s]Loading train:  18%|█▊        | 52/285 [00:50<03:17,  1.18it/s]Loading train:  19%|█▊        | 53/285 [00:51<03:22,  1.15it/s]Loading train:  19%|█▉        | 54/285 [00:52<03:24,  1.13it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:16,  1.17it/s]Loading train:  20%|█▉        | 56/285 [00:53<03:13,  1.18it/s]Loading train:  20%|██        | 57/285 [00:54<03:01,  1.26it/s]Loading train:  20%|██        | 58/285 [00:55<03:01,  1.25it/s]Loading train:  21%|██        | 59/285 [00:56<03:12,  1.17it/s]Loading train:  21%|██        | 60/285 [00:57<03:18,  1.14it/s]Loading train:  21%|██▏       | 61/285 [00:57<03:11,  1.17it/s]Loading train:  22%|██▏       | 62/285 [00:58<03:16,  1.13it/s]Loading train:  22%|██▏       | 63/285 [00:59<03:16,  1.13it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:39,  1.01it/s]Loading train:  23%|██▎       | 65/285 [01:02<04:06,  1.12s/it]Loading train:  23%|██▎       | 66/285 [01:03<04:13,  1.16s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:58,  1.09s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:06<03:36,  1.00s/it]Loading train:  25%|██▍       | 70/285 [01:07<03:27,  1.04it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:17,  1.08it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:08,  1.13it/s]Loading train:  26%|██▌       | 73/285 [01:09<03:10,  1.11it/s]Loading train:  26%|██▌       | 74/285 [01:10<03:08,  1.12it/s]Loading train:  26%|██▋       | 75/285 [01:11<03:10,  1.10it/s]Loading train:  27%|██▋       | 76/285 [01:12<03:11,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:13<03:04,  1.13it/s]Loading train:  27%|██▋       | 78/285 [01:14<02:59,  1.15it/s]Loading train:  28%|██▊       | 79/285 [01:15<03:05,  1.11it/s]Loading train:  28%|██▊       | 80/285 [01:16<02:56,  1.16it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:43,  1.25it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:44,  1.23it/s]Loading train:  29%|██▉       | 83/285 [01:18<02:36,  1.29it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:34,  1.30it/s]Loading train:  30%|██▉       | 85/285 [01:19<02:42,  1.23it/s]Loading train:  30%|███       | 86/285 [01:20<02:47,  1.19it/s]Loading train:  31%|███       | 87/285 [01:21<02:51,  1.16it/s]Loading train:  31%|███       | 88/285 [01:22<02:44,  1.19it/s]Loading train:  31%|███       | 89/285 [01:23<02:45,  1.19it/s]Loading train:  32%|███▏      | 90/285 [01:24<02:47,  1.16it/s]Loading train:  32%|███▏      | 91/285 [01:25<02:43,  1.19it/s]Loading train:  32%|███▏      | 92/285 [01:25<02:42,  1.19it/s]Loading train:  33%|███▎      | 93/285 [01:26<02:34,  1.25it/s]Loading train:  33%|███▎      | 94/285 [01:27<02:44,  1.16it/s]Loading train:  33%|███▎      | 95/285 [01:28<02:50,  1.11it/s]Loading train:  34%|███▎      | 96/285 [01:29<02:51,  1.10it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:50,  1.10it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:51,  1.09it/s]Loading train:  35%|███▍      | 99/285 [01:32<02:45,  1.13it/s]Loading train:  35%|███▌      | 100/285 [01:33<02:42,  1.14it/s]Loading train:  35%|███▌      | 101/285 [01:33<02:38,  1.16it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:33,  1.19it/s]Loading train:  36%|███▌      | 103/285 [01:35<02:30,  1.21it/s]Loading train:  36%|███▋      | 104/285 [01:36<02:30,  1.20it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:36,  1.15it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:31,  1.18it/s]Loading train:  38%|███▊      | 107/285 [01:38<02:34,  1.15it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:25,  1.22it/s]Loading train:  38%|███▊      | 109/285 [01:40<02:27,  1.19it/s]Loading train:  39%|███▊      | 110/285 [01:41<02:32,  1.15it/s]Loading train:  39%|███▉      | 111/285 [01:42<02:26,  1.19it/s]Loading train:  39%|███▉      | 112/285 [01:43<02:30,  1.15it/s]Loading train:  40%|███▉      | 113/285 [01:44<02:33,  1.12it/s]Loading train:  40%|████      | 114/285 [01:45<02:39,  1.07it/s]Loading train:  40%|████      | 115/285 [01:46<02:39,  1.07it/s]Loading train:  41%|████      | 116/285 [01:46<02:33,  1.10it/s]Loading train:  41%|████      | 117/285 [01:47<02:26,  1.15it/s]Loading train:  41%|████▏     | 118/285 [01:48<02:24,  1.16it/s]Loading train:  42%|████▏     | 119/285 [01:49<02:25,  1.14it/s]Loading train:  42%|████▏     | 120/285 [01:50<02:20,  1.17it/s]Loading train:  42%|████▏     | 121/285 [01:51<02:38,  1.03it/s]Loading train:  43%|████▎     | 122/285 [01:52<02:48,  1.03s/it]Loading train:  43%|████▎     | 123/285 [01:53<02:56,  1.09s/it]Loading train:  44%|████▎     | 124/285 [01:54<02:37,  1.02it/s]Loading train:  44%|████▍     | 125/285 [01:55<02:22,  1.12it/s]Loading train:  44%|████▍     | 126/285 [01:56<02:13,  1.19it/s]Loading train:  45%|████▍     | 127/285 [01:56<02:10,  1.21it/s]Loading train:  45%|████▍     | 128/285 [01:57<02:11,  1.19it/s]Loading train:  45%|████▌     | 129/285 [01:58<02:10,  1.20it/s]Loading train:  46%|████▌     | 130/285 [01:59<02:02,  1.26it/s]Loading train:  46%|████▌     | 131/285 [01:59<01:57,  1.32it/s]Loading train:  46%|████▋     | 132/285 [02:00<01:59,  1.28it/s]Loading train:  47%|████▋     | 133/285 [02:01<01:54,  1.33it/s]Loading train:  47%|████▋     | 134/285 [02:02<01:49,  1.37it/s]Loading train:  47%|████▋     | 135/285 [02:02<01:47,  1.40it/s]Loading train:  48%|████▊     | 136/285 [02:03<01:42,  1.46it/s]Loading train:  48%|████▊     | 137/285 [02:04<01:43,  1.44it/s]Loading train:  48%|████▊     | 138/285 [02:04<01:39,  1.48it/s]Loading train:  49%|████▉     | 139/285 [02:05<01:46,  1.37it/s]Loading train:  49%|████▉     | 140/285 [02:06<01:50,  1.31it/s]Loading train:  49%|████▉     | 141/285 [02:07<01:49,  1.32it/s]Loading train:  50%|████▉     | 142/285 [02:07<01:45,  1.35it/s]Loading train:  50%|█████     | 143/285 [02:08<01:47,  1.32it/s]Loading train:  51%|█████     | 144/285 [02:09<01:46,  1.32it/s]Loading train:  51%|█████     | 145/285 [02:10<01:51,  1.26it/s]Loading train:  51%|█████     | 146/285 [02:11<01:50,  1.26it/s]Loading train:  52%|█████▏    | 147/285 [02:11<01:47,  1.28it/s]Loading train:  52%|█████▏    | 148/285 [02:12<01:47,  1.27it/s]Loading train:  52%|█████▏    | 149/285 [02:13<01:45,  1.29it/s]Loading train:  53%|█████▎    | 150/285 [02:14<01:47,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:15<01:50,  1.21it/s]Loading train:  53%|█████▎    | 152/285 [02:15<01:49,  1.22it/s]Loading train:  54%|█████▎    | 153/285 [02:16<01:47,  1.23it/s]Loading train:  54%|█████▍    | 154/285 [02:17<01:49,  1.20it/s]Loading train:  54%|█████▍    | 155/285 [02:18<01:47,  1.20it/s]Loading train:  55%|█████▍    | 156/285 [02:19<01:45,  1.22it/s]Loading train:  55%|█████▌    | 157/285 [02:19<01:41,  1.26it/s]Loading train:  55%|█████▌    | 158/285 [02:20<01:39,  1.28it/s]Loading train:  56%|█████▌    | 159/285 [02:21<01:36,  1.31it/s]Loading train:  56%|█████▌    | 160/285 [02:22<01:33,  1.34it/s]Loading train:  56%|█████▋    | 161/285 [02:22<01:34,  1.32it/s]Loading train:  57%|█████▋    | 162/285 [02:23<01:36,  1.28it/s]Loading train:  57%|█████▋    | 163/285 [02:24<01:34,  1.29it/s]Loading train:  58%|█████▊    | 164/285 [02:25<01:34,  1.28it/s]Loading train:  58%|█████▊    | 165/285 [02:26<01:31,  1.31it/s]Loading train:  58%|█████▊    | 166/285 [02:26<01:35,  1.25it/s]Loading train:  59%|█████▊    | 167/285 [02:27<01:35,  1.24it/s]Loading train:  59%|█████▉    | 168/285 [02:28<01:30,  1.29it/s]Loading train:  59%|█████▉    | 169/285 [02:29<01:26,  1.35it/s]Loading train:  60%|█████▉    | 170/285 [02:29<01:23,  1.38it/s]Loading train:  60%|██████    | 171/285 [02:30<01:26,  1.32it/s]Loading train:  60%|██████    | 172/285 [02:31<01:27,  1.30it/s]Loading train:  61%|██████    | 173/285 [02:32<01:24,  1.32it/s]Loading train:  61%|██████    | 174/285 [02:32<01:25,  1.30it/s]Loading train:  61%|██████▏   | 175/285 [02:33<01:25,  1.29it/s]Loading train:  62%|██████▏   | 176/285 [02:34<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [02:35<01:21,  1.33it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:20,  1.32it/s]Loading train:  63%|██████▎   | 179/285 [02:36<01:20,  1.32it/s]Loading train:  63%|██████▎   | 180/285 [02:37<01:25,  1.23it/s]Loading train:  64%|██████▎   | 181/285 [02:38<01:27,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [02:39<01:25,  1.21it/s]Loading train:  64%|██████▍   | 183/285 [02:40<01:21,  1.25it/s]Loading train:  65%|██████▍   | 184/285 [02:40<01:18,  1.28it/s]Loading train:  65%|██████▍   | 185/285 [02:41<01:15,  1.33it/s]Loading train:  65%|██████▌   | 186/285 [02:42<01:19,  1.25it/s]Loading train:  66%|██████▌   | 187/285 [02:43<01:19,  1.24it/s]Loading train:  66%|██████▌   | 188/285 [02:44<01:22,  1.18it/s]Loading train:  66%|██████▋   | 189/285 [02:44<01:17,  1.24it/s]Loading train:  67%|██████▋   | 190/285 [02:45<01:14,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [02:46<01:14,  1.27it/s]Loading train:  67%|██████▋   | 192/285 [02:47<01:13,  1.26it/s]Loading train:  68%|██████▊   | 193/285 [02:48<01:10,  1.30it/s]Loading train:  68%|██████▊   | 194/285 [02:48<01:08,  1.32it/s]Loading train:  68%|██████▊   | 195/285 [02:49<01:02,  1.43it/s]Loading train:  69%|██████▉   | 196/285 [02:50<01:03,  1.39it/s]Loading train:  69%|██████▉   | 197/285 [02:50<01:04,  1.36it/s]Loading train:  69%|██████▉   | 198/285 [02:51<01:05,  1.32it/s]Loading train:  70%|██████▉   | 199/285 [02:52<01:00,  1.43it/s]Loading train:  70%|███████   | 200/285 [02:52<00:58,  1.46it/s]Loading train:  71%|███████   | 201/285 [02:53<01:01,  1.36it/s]Loading train:  71%|███████   | 202/285 [02:54<01:01,  1.34it/s]Loading train:  71%|███████   | 203/285 [02:55<01:01,  1.32it/s]Loading train:  72%|███████▏  | 204/285 [02:55<00:57,  1.40it/s]Loading train:  72%|███████▏  | 205/285 [02:56<00:55,  1.43it/s]Loading train:  72%|███████▏  | 206/285 [02:57<00:54,  1.46it/s]Loading train:  73%|███████▎  | 207/285 [02:58<00:56,  1.39it/s]Loading train:  73%|███████▎  | 208/285 [02:58<00:57,  1.35it/s]Loading train:  73%|███████▎  | 209/285 [02:59<00:58,  1.30it/s]Loading train:  74%|███████▎  | 210/285 [03:00<00:55,  1.36it/s]Loading train:  74%|███████▍  | 211/285 [03:00<00:52,  1.41it/s]Loading train:  74%|███████▍  | 212/285 [03:01<00:51,  1.41it/s]Loading train:  75%|███████▍  | 213/285 [03:02<00:51,  1.40it/s]Loading train:  75%|███████▌  | 214/285 [03:03<00:49,  1.44it/s]Loading train:  75%|███████▌  | 215/285 [03:03<00:52,  1.34it/s]Loading train:  76%|███████▌  | 216/285 [03:04<00:49,  1.38it/s]Loading train:  76%|███████▌  | 217/285 [03:05<00:53,  1.26it/s]Loading train:  76%|███████▋  | 218/285 [03:06<00:55,  1.21it/s]Loading train:  77%|███████▋  | 219/285 [03:07<00:56,  1.17it/s]Loading train:  77%|███████▋  | 220/285 [03:08<00:53,  1.22it/s]Loading train:  78%|███████▊  | 221/285 [03:08<00:51,  1.25it/s]Loading train:  78%|███████▊  | 222/285 [03:09<00:52,  1.19it/s]Loading train:  78%|███████▊  | 223/285 [03:10<00:48,  1.27it/s]Loading train:  79%|███████▊  | 224/285 [03:11<00:46,  1.32it/s]Loading train:  79%|███████▉  | 225/285 [03:11<00:43,  1.39it/s]Loading train:  79%|███████▉  | 226/285 [03:12<00:46,  1.26it/s]Loading train:  80%|███████▉  | 227/285 [03:13<00:48,  1.20it/s]Loading train:  80%|████████  | 228/285 [03:14<00:50,  1.13it/s]Loading train:  80%|████████  | 229/285 [03:15<00:49,  1.14it/s]Loading train:  81%|████████  | 230/285 [03:16<00:45,  1.20it/s]Loading train:  81%|████████  | 231/285 [03:16<00:43,  1.24it/s]Loading train:  81%|████████▏ | 232/285 [03:17<00:42,  1.24it/s]Loading train:  82%|████████▏ | 233/285 [03:18<00:39,  1.31it/s]Loading train:  82%|████████▏ | 234/285 [03:19<00:41,  1.23it/s]Loading train:  82%|████████▏ | 235/285 [03:20<00:39,  1.27it/s]Loading train:  83%|████████▎ | 236/285 [03:20<00:38,  1.27it/s]Loading train:  83%|████████▎ | 237/285 [03:21<00:39,  1.21it/s]Loading train:  84%|████████▎ | 238/285 [03:22<00:39,  1.19it/s]Loading train:  84%|████████▍ | 239/285 [03:23<00:38,  1.19it/s]Loading train:  84%|████████▍ | 240/285 [03:24<00:36,  1.22it/s]Loading train:  85%|████████▍ | 241/285 [03:25<00:35,  1.26it/s]Loading train:  85%|████████▍ | 242/285 [03:25<00:33,  1.28it/s]Loading train:  85%|████████▌ | 243/285 [03:26<00:31,  1.32it/s]Loading train:  86%|████████▌ | 244/285 [03:27<00:32,  1.27it/s]Loading train:  86%|████████▌ | 245/285 [03:28<00:30,  1.32it/s]Loading train:  86%|████████▋ | 246/285 [03:28<00:30,  1.26it/s]Loading train:  87%|████████▋ | 247/285 [03:29<00:30,  1.24it/s]Loading train:  87%|████████▋ | 248/285 [03:30<00:30,  1.23it/s]Loading train:  87%|████████▋ | 249/285 [03:31<00:28,  1.27it/s]Loading train:  88%|████████▊ | 250/285 [03:32<00:27,  1.29it/s]Loading train:  88%|████████▊ | 251/285 [03:32<00:25,  1.32it/s]Loading train:  88%|████████▊ | 252/285 [03:33<00:23,  1.38it/s]Loading train:  89%|████████▉ | 253/285 [03:34<00:25,  1.28it/s]Loading train:  89%|████████▉ | 254/285 [03:35<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [03:35<00:23,  1.25it/s]Loading train:  90%|████████▉ | 256/285 [03:36<00:22,  1.30it/s]Loading train:  90%|█████████ | 257/285 [03:37<00:21,  1.33it/s]Loading train:  91%|█████████ | 258/285 [03:38<00:20,  1.30it/s]Loading train:  91%|█████████ | 259/285 [03:39<00:20,  1.28it/s]Loading train:  91%|█████████ | 260/285 [03:39<00:19,  1.30it/s]Loading train:  92%|█████████▏| 261/285 [03:40<00:18,  1.31it/s]Loading train:  92%|█████████▏| 262/285 [03:41<00:17,  1.32it/s]Loading train:  92%|█████████▏| 263/285 [03:41<00:16,  1.35it/s]Loading train:  93%|█████████▎| 264/285 [03:42<00:16,  1.29it/s]Loading train:  93%|█████████▎| 265/285 [03:43<00:16,  1.23it/s]Loading train:  93%|█████████▎| 266/285 [03:44<00:15,  1.26it/s]Loading train:  94%|█████████▎| 267/285 [03:45<00:14,  1.27it/s]Loading train:  94%|█████████▍| 268/285 [03:46<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [03:46<00:13,  1.21it/s]Loading train:  95%|█████████▍| 270/285 [03:47<00:11,  1.25it/s]Loading train:  95%|█████████▌| 271/285 [03:48<00:10,  1.30it/s]Loading train:  95%|█████████▌| 272/285 [03:49<00:10,  1.26it/s]Loading train:  96%|█████████▌| 273/285 [03:49<00:08,  1.34it/s]Loading train:  96%|█████████▌| 274/285 [03:50<00:08,  1.37it/s]Loading train:  96%|█████████▋| 275/285 [03:51<00:07,  1.33it/s]Loading train:  97%|█████████▋| 276/285 [03:52<00:07,  1.26it/s]Loading train:  97%|█████████▋| 277/285 [03:52<00:05,  1.33it/s]Loading train:  98%|█████████▊| 278/285 [03:53<00:04,  1.42it/s]Loading train:  98%|█████████▊| 279/285 [03:54<00:04,  1.36it/s]Loading train:  98%|█████████▊| 280/285 [03:54<00:03,  1.41it/s]Loading train:  99%|█████████▊| 281/285 [03:55<00:02,  1.41it/s]Loading train:  99%|█████████▉| 282/285 [03:56<00:02,  1.44it/s]Loading train:  99%|█████████▉| 283/285 [03:57<00:01,  1.36it/s]Loading train: 100%|█████████▉| 284/285 [03:58<00:00,  1.31it/s]Loading train: 100%|██████████| 285/285 [03:58<00:00,  1.21it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:03, 83.29it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:02, 106.95it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:01, 132.11it/s]concatenating: train:  37%|███▋      | 105/285 [00:00<00:01, 161.17it/s]concatenating: train:  47%|████▋     | 135/285 [00:00<00:00, 186.76it/s]concatenating: train:  57%|█████▋    | 162/285 [00:00<00:00, 205.28it/s]concatenating: train:  67%|██████▋   | 191/285 [00:00<00:00, 223.61it/s]concatenating: train:  78%|███████▊  | 222/285 [00:00<00:00, 242.29it/s]concatenating: train:  88%|████████▊ | 252/285 [00:00<00:00, 257.08it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 283.34it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.18s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 120.77it/s]2019-07-11 09:35:06.884051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 09:35:06.884144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 09:35:06.884159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 09:35:06.884167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 09:35:06.884548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.26it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.27it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.86it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.45it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.38it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.37it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.20it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.79it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.33it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.12it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.44it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.54it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.61it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.44it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.75it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.96it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.71it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.84it/s]
Epoch 00051: val_mDice did not improve from 0.64213
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [0.7928718581545953, 0.5185222639051895, 0.48416026011525587, 0.5056439065400449, 0.4606061681022857, 0.4736446898076787, 0.45710348217180985, 0.47634335769621355, 0.4552278119092547, 0.4418266262422061, 0.4299167637718456, 0.45216635219211687, 0.4431320701897477, 0.45771601246721916, 0.45553164875041174, 0.4827511067496998, 0.4424061432231072, 0.4584478789201662, 0.47251710245729156, 0.442959102838399, 0.4383471851242321, 0.46087181401652333, 0.44493082681847684, 0.45562925052376435, 0.4513415464475834, 0.4519973527119812, 0.4571090140822213, 0.44287318224347505, 0.4443933807271819, 0.4376996632394844, 0.45970895969667913, 0.4389395204336284, 0.46594002826253794, 0.46031845082117856, 0.4363394406254731, 0.4498134351975425, 0.4552178213050246, 0.4434707248011115, 0.4438098366034097, 0.450307970606415, 0.4535797191731757, 0.4538964719079726, 0.4479828763274507, 0.45771482037432365, 0.45084970123941004, 0.459297301050005, 0.4672404021524184, 0.45759343901160043, 0.47320173905548435, 0.44909620717917076, 0.49688221089666784], 'val_acc': [0.9236285789718841, 0.9364669562718055, 0.9419130909376304, 0.9474583268165588, 0.954408520759817, 0.9549932283396162, 0.9530779979082459, 0.9546605731521904, 0.9545015259827981, 0.9535015475150593, 0.9543444917188676, 0.9529684851955436, 0.955449822561701, 0.9535221813777306, 0.9539229943099634, 0.9542122316760058, 0.9538300387020218, 0.9524354525118567, 0.954214313509744, 0.9543382668628373, 0.9549498428179565, 0.9544560259946898, 0.9539808357894087, 0.9529850083356463, 0.9534064957549452, 0.9551543689972861, 0.9557039571207995, 0.9548734140129729, 0.9551275202681898, 0.9547969242713971, 0.9539353950729583, 0.9539767177411298, 0.9522350743496218, 0.9541626486032369, 0.9548527365290252, 0.9543692579482521, 0.9549911591593779, 0.9562452525399917, 0.9539333382132333, 0.9555923692340957, 0.9530077520029505, 0.9534602401642825, 0.9553774928247463, 0.9528879093724256, 0.9538899786645474, 0.954144087916646, 0.9538878935009407, 0.9547080970343265, 0.9555180106083108, 0.9551171876864726, 0.9558485812981036], 'val_mDice': [0.45056397505312656, 0.5893682121564556, 0.61022139761035, 0.6011340997738546, 0.6245618202832824, 0.6223409602095961, 0.6277672854881713, 0.623171129040212, 0.6270611429347672, 0.6350677842534455, 0.6421304821302105, 0.62969971968475, 0.6388685590062062, 0.6301770902878745, 0.6297964896569704, 0.6208444097854572, 0.6368617548622899, 0.622367904838903, 0.6246717046093009, 0.6352973017612649, 0.6359387256579692, 0.6249815755050275, 0.6350191025760586, 0.630978780418801, 0.6311565650907974, 0.628062762361665, 0.6274140813497192, 0.6357924731750062, 0.6317591996832267, 0.6375359376715548, 0.6235960132582894, 0.6373432734825092, 0.6236239511873469, 0.6249217191221994, 0.6392424705974217, 0.6308374504803279, 0.628185975152021, 0.6341723083783795, 0.6345185281178138, 0.6327056828157862, 0.6272204455050676, 0.6252149483345074, 0.6336658393870519, 0.6237756882965898, 0.6291077599845118, 0.6259422122433199, 0.6203348916336144, 0.6248109966682989, 0.6232606275787567, 0.6307505725482323, 0.6144598888951307], 'loss': [1.9801294744537388, 0.5688641597993376, 0.4672085941292337, 0.4146128140658142, 0.3887798079890004, 0.3717034306961703, 0.35995464046649, 0.34824900507251716, 0.3398708277609956, 0.33303777441194937, 0.3264142137344844, 0.3195342658151826, 0.3140022375213445, 0.3111541690334802, 0.30631252452767654, 0.30227287502163125, 0.2985423019730144, 0.2942669344415177, 0.2918510184777042, 0.2891176674001896, 0.28514309480756295, 0.2841119759823981, 0.2819937343762582, 0.2798072618000336, 0.27705141518099247, 0.2735886336327326, 0.2726528911047541, 0.2727604883619334, 0.26875610857914684, 0.2771354034331219, 0.2690369913286649, 0.2652905758314679, 0.2643697271549093, 0.26324382892303444, 0.26434903400706916, 0.26068247388627336, 0.25818651866876485, 0.2592397517439496, 0.2561652134637493, 0.2559000447325104, 0.25461943572165235, 0.25330056041117155, 0.252626417986377, 0.2510369298203073, 0.2515910063721075, 0.2500905908989521, 0.2500534561972922, 0.2481687023856724, 0.24721433393696568, 0.2461497277438553, 0.24668125957485948], 'acc': [0.7348534710724353, 0.9063381679917296, 0.9164036419207114, 0.9275030911627772, 0.9385632429336659, 0.9435813370194286, 0.9462361162468848, 0.9477132107299837, 0.9485744307304894, 0.9492415879931132, 0.9498596364951498, 0.9502791087908278, 0.9507654304500759, 0.9510500515333793, 0.9514636440959074, 0.9518375332679736, 0.9521217757428071, 0.9524672080810719, 0.9526976687437724, 0.952897736241398, 0.9531529510334799, 0.9533366846704553, 0.9535116359829273, 0.9536083788596742, 0.9538183346837897, 0.9540843863118728, 0.9541525466432629, 0.9541995984414234, 0.9543954769573364, 0.9543665489835694, 0.9544370678520223, 0.9546962528990722, 0.9548064277528009, 0.9548377269922301, 0.9548804861814535, 0.9551045647387372, 0.9551593724545502, 0.9551607388717976, 0.9554735620740803, 0.9554117271878232, 0.9555665147855751, 0.9555128986562405, 0.9555794054870674, 0.9557510937787915, 0.9556920186353076, 0.9557831220640854, 0.9558923087714252, 0.9558841298591415, 0.9559624608737777, 0.9560386191739684, 0.955975334107126], 'mDice': [0.23261650229638506, 0.5538877287784125, 0.6161837043419921, 0.6476664179635265, 0.6643165402419946, 0.67591036421094, 0.6840027316477127, 0.6920821299824824, 0.698176235121246, 0.702988507441073, 0.7079167428063928, 0.7127939751871362, 0.7168957240752526, 0.7191097892568844, 0.7227248677461536, 0.7257521240145454, 0.7286776542131187, 0.7317749378104776, 0.7336480248942432, 0.7356971354014759, 0.7386414201182612, 0.7394993928034421, 0.7412359220037195, 0.7428633157097108, 0.7448816993749322, 0.7476847281896707, 0.7483601861449084, 0.7483214626001393, 0.7513783148876249, 0.7497645413964528, 0.7511881659132328, 0.7541433452332788, 0.7548674501940859, 0.7556971473168212, 0.7550523264606394, 0.7578221530113388, 0.7596671598863058, 0.7589378101712354, 0.7614263442079328, 0.7615845931211943, 0.7626376567495381, 0.7636382227324172, 0.7641619554785795, 0.765438912571999, 0.765102172971103, 0.7662079713390152, 0.7663511092266377, 0.7677579265645592, 0.7685319907355819, 0.7693984945688714, 0.7689292356148699]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 10)   5410        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 10)   40          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 10)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 10)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 10)   910         dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 70)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 232,303
Trainable params: 57,563
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.7558 - acc: 0.5741 - mDice: 0.1186 - val_loss: 1.4976 - val_acc: 0.8897 - val_mDice: 0.2965

Epoch 00001: val_mDice improved from -inf to 0.29649, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.9091 - acc: 0.8989 - mDice: 0.3952 - val_loss: 1.1187 - val_acc: 0.9317 - val_mDice: 0.4376

Epoch 00002: val_mDice improved from 0.29649 to 0.43758, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6166 - acc: 0.9148 - mDice: 0.5263 - val_loss: 0.8672 - val_acc: 0.9415 - val_mDice: 0.5335

Epoch 00003: val_mDice improved from 0.43758 to 0.53350, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5157 - acc: 0.9240 - mDice: 0.5828 - val_loss: 0.8371 - val_acc: 0.9400 - val_mDice: 0.5605

Epoch 00004: val_mDice improved from 0.53350 to 0.56046, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.4694 - acc: 0.9293 - mDice: 0.6109 - val_loss: 0.8020 - val_acc: 0.9434 - val_mDice: 0.5705

Epoch 00005: val_mDice improved from 0.56046 to 0.57047, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4420 - acc: 0.9328 - mDice: 0.6278 - val_loss: 0.8148 - val_acc: 0.9366 - val_mDice: 0.5667

Epoch 00006: val_mDice did not improve from 0.57047
Epoch 7/300
 - 11s - loss: 0.4240 - acc: 0.9347 - mDice: 0.6395 - val_loss: 0.7636 - val_acc: 0.9441 - val_mDice: 0.5808

Epoch 00007: val_mDice improved from 0.57047 to 0.58084, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.4101 - acc: 0.9365 - mDice: 0.6487 - val_loss: 0.7840 - val_acc: 0.9421 - val_mDice: 0.5837

Epoch 00008: val_mDice improved from 0.58084 to 0.58366, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.3997 - acc: 0.9376 - mDice: 0.6556 - val_loss: 0.7467 - val_acc: 0.9409 - val_mDice: 0.5909

Epoch 00009: val_mDice improved from 0.58366 to 0.59092, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 11s - loss: 0.3895 - acc: 0.9386 - mDice: 0.6626 - val_loss: 0.7355 - val_acc: 0.9426 - val_mDice: 0.5951

Epoch 00010: val_mDice improved from 0.59092 to 0.59507, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.3796 - acc: 0.9396 - mDice: 0.6692 - val_loss: 0.7560 - val_acc: 0.9442 - val_mDice: 0.5966

Epoch 00011: val_mDice improved from 0.59507 to 0.59661, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 11s - loss: 0.3752 - acc: 0.9401 - mDice: 0.6724 - val_loss: 0.7618 - val_acc: 0.9412 - val_mDice: 0.5949

Epoch 00012: val_mDice did not improve from 0.59661
Epoch 13/300
 - 11s - loss: 0.3688 - acc: 0.9407 - mDice: 0.6767 - val_loss: 0.7394 - val_acc: 0.9423 - val_mDice: 0.5963

Epoch 00013: val_mDice did not improve from 0.59661
Epoch 14/300
 - 11s - loss: 0.3641 - acc: 0.9412 - mDice: 0.6800 - val_loss: 0.7365 - val_acc: 0.9411 - val_mDice: 0.5902

Epoch 00014: val_mDice did not improve from 0.59661
Epoch 15/300
 - 10s - loss: 0.3609 - acc: 0.9414 - mDice: 0.6823 - val_loss: 0.7406 - val_acc: 0.9386 - val_mDice: 0.5912

Epoch 00015: val_mDice did not improve from 0.59661
Epoch 16/300
 - 11s - loss: 0.3533 - acc: 0.9420 - mDice: 0.6877 - val_loss: 0.7580 - val_acc: 0.9379 - val_mDice: 0.5870

Epoch 00016: val_mDice did not improve from 0.59661
Epoch 17/300
 - 11s - loss: 0.3487 - acc: 0.9424 - mDice: 0.6908 - val_loss: 0.7411 - val_acc: 0.9366 - val_mDice: 0.5812

Epoch 00017: val_mDice did not improve from 0.59661
Epoch 18/300
 - 11s - loss: 0.3442 - acc: 0.9429 - mDice: 0.6940 - val_loss: 0.7223 - val_acc: 0.9447 - val_mDice: 0.5989

Epoch 00018: val_mDice improved from 0.59661 to 0.59887, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 10s - loss: 0.3406 - acc: 0.9432 - mDice: 0.6967 - val_loss: 0.7325 - val_acc: 0.9464 - val_mDice: 0.5947

Epoch 00019: val_mDice did not improve from 0.59887
Epoch 20/300
 - 10s - loss: 0.3367 - acc: 0.9434 - mDice: 0.6994 - val_loss: 0.7258 - val_acc: 0.9450 - val_mDice: 0.6030

Epoch 00020: val_mDice improved from 0.59887 to 0.60299, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 11s - loss: 0.3351 - acc: 0.9436 - mDice: 0.7007 - val_loss: 0.7443 - val_acc: 0.9431 - val_mDice: 0.5971

Epoch 00021: val_mDice did not improve from 0.60299
Epoch 22/300
 - 11s - loss: 0.3319 - acc: 0.9440 - mDice: 0.7031 - val_loss: 0.7464 - val_acc: 0.9380 - val_mDice: 0.5849

Epoch 00022: val_mDice did not improve from 0.60299
Epoch 23/300
 - 11s - loss: 0.3297 - acc: 0.9441 - mDice: 0.7047 - val_loss: 0.7276 - val_acc: 0.9409 - val_mDice: 0.5889

Epoch 00023: val_mDice did not improve from 0.60299
Epoch 24/300
 - 11s - loss: 0.3260 - acc: 0.9445 - mDice: 0.7073 - val_loss: 0.7315 - val_acc: 0.9405 - val_mDice: 0.5905

Epoch 00024: val_mDice did not improve from 0.60299
Epoch 25/300
 - 11s - loss: 0.3236 - acc: 0.9448 - mDice: 0.7092 - val_loss: 0.7591 - val_acc: 0.9421 - val_mDice: 0.5852

Epoch 00025: val_mDice did not improve from 0.60299
Epoch 26/300
 - 11s - loss: 0.3204 - acc: 0.9450 - mDice: 0.7115 - val_loss: 0.7531 - val_acc: 0.9398 - val_mDice: 0.5922

Epoch 00026: val_mDice did not improve from 0.60299
Epoch 27/300
 - 11s - loss: 0.3197 - acc: 0.9450 - mDice: 0.7121 - val_loss: 0.7517 - val_acc: 0.9444 - val_mDice: 0.5992

Epoch 00027: val_mDice did not improve from 0.60299
Epoch 28/300
 - 11s - loss: 0.3163 - acc: 0.9453 - mDice: 0.7144 - val_loss: 0.7587 - val_acc: 0.9420 - val_mDice: 0.5823

Epoch 00028: val_mDice did not improve from 0.60299
Epoch 29/300
 - 11s - loss: 0.3148 - acc: 0.9455 - mDice: 0.7156 - val_loss: 0.7399 - val_acc: 0.9401 - val_mDice: 0.5798

Epoch 00029: val_mDice did not improve from 0.60299
Epoch 30/300
 - 11s - loss: 0.3134 - acc: 0.9455 - mDice: 0.7167 - val_loss: 0.7585 - val_acc: 0.9375 - val_mDice: 0.5756

Epoch 00030: val_mDice did not improve from 0.60299
Epoch 31/300
 - 11s - loss: 0.3087 - acc: 0.9458 - mDice: 0.7201 - val_loss: 0.7446 - val_acc: 0.9428 - val_mDice: 0.5940

Epoch 00031: val_mDice did not improve from 0.60299
Epoch 32/300
 - 11s - loss: 0.3099 - acc: 0.9457 - mDice: 0.7193 - val_loss: 0.7652 - val_acc: 0.9415 - val_mDice: 0.5883

Epoch 00032: val_mDice did not improve from 0.60299
Epoch 33/300
 - 11s - loss: 0.3088 - acc: 0.9458 - mDice: 0.7201 - val_loss: 0.7428 - val_acc: 0.9430 - val_mDice: 0.5884

Epoch 00033: val_mDice did not improve from 0.60299
Epoch 34/300
 - 11s - loss: 0.3087 - acc: 0.9459 - mDice: 0.7202 - val_loss: 0.7685 - val_acc: 0.9401 - val_mDice: 0.5831

Epoch 00034: val_mDice did not improve from 0.60299
Epoch 35/300
 - 11s - loss: 0.3049 - acc: 0.9461 - mDice: 0.7230 - val_loss: 0.7607 - val_acc: 0.9424 - val_mDice: 0.5847

Epoch 00035: val_mDice did not improve from 0.60299
Epoch 36/300
 - 11s - loss: 0.3041 - acc: 0.9463 - mDice: 0.7237 - val_loss: 0.6966 - val_acc: 0.9404 - val_mDice: 0.5871

Epoch 00036: val_mDice did not improve from 0.60299
Epoch 37/300
 - 11s - loss: 0.3018 - acc: 0.9464 - mDice: 0.7255 - val_loss: 0.7434 - val_acc: 0.9417 - val_mDice: 0.5806

Epoch 00037: val_mDice did not improve from 0.60299
Epoch 38/300
 - 11s - loss: 0.3004 - acc: 0.9465 - mDice: 0.7264 - val_loss: 0.7083 - val_acc: 0.9424 - val_mDice: 0.5861

Epoch 00038: val_mDice did not improve from 0.60299
Epoch 39/300
 - 11s - loss: 0.2988 - acc: 0.9466 - mDice: 0.7276 - val_loss: 0.7502 - val_acc: 0.9431 - val_mDice: 0.5854

Epoch 00039: val_mDice did not improve from 0.60299
Epoch 40/300
 - 11s - loss: 0.2970 - acc: 0.9466 - mDice: 0.7290 - val_loss: 0.7426 - val_acc: 0.9417 - val_mDice: 0.5828

Epoch 00040: val_mDice did not improve from 0.60299
Epoch 41/300
 - 11s - loss: 0.2982 - acc: 0.9468 - mDice: 0.7281 - val_loss: 0.7290 - val_acc: 0.9422 - val_mDice: 0.5848

Epoch 00041: val_mDice did not improve from 0.60299
Epoch 42/300
 - 12s - loss: 0.2960 - acc: 0.9469 - mDice: 0.7298 - val_loss: 0.7333 - val_acc: 0.9423 - val_mDice: 0.5842

Epoch 00042: val_mDice did not improve from 0.60299
Epoch 43/300
 - 11s - loss: 0.2947 - acc: 0.9471 - mDice: 0.7309 - val_loss: 0.7377 - val_acc: 0.9438 - val_mDice: 0.5785

Epoch 00043: val_mDice did not improve from 0.60299
Epoch 44/300
 - 11s - loss: 0.2943 - acc: 0.9471 - mDice: 0.7310 - val_loss: 0.7358 - val_acc: 0.9461 - val_mDice: 0.5900

Epoch 00044: val_mDice did not improve from 0.60299
Epoch 45/300
 - 11s - loss: 0.2912 - acc: 0.9473 - mDice: 0.7334 - val_loss: 0.7452 - val_acc: 0.9453 - val_mDice: 0.5749

Epoch 00045: val_mDice did not improve from 0.60299
Epoch 46/300
 - 11s - loss: 0.2920 - acc: 0.9473 - mDice: 0.7329 - val_loss: 0.7548 - val_acc: 0.9409 - val_mDice: 0.5718

Epoch 00046: val_mDice did not improve from 0.60299
Epoch 47/300
 - 11s - loss: 0.2912 - acc: 0.9474 - mDice: 0.7335 - val_loss: 0.7424 - val_acc: 0.9445 - val_mDice: 0.5747

Epoch 00047: val_mDice did not improve from 0.60299
Epoch 48/300
 - 11s - loss: 0.2898 - acc: 0.9474 - mDice: 0.7346 - val_loss: 0.7285 - val_acc: 0.9424 - val_mDice: 0.5866

Epoch 00048: val_mDice did not improve from 0.60299
Epoch 49/300
 - 11s - loss: 0.2895 - acc: 0.9475 - mDice: 0.7348 - val_loss: 0.7357 - val_acc: 0.9391 - val_mDice: 0.5812

Epoch 00049: val_mDice did not improve from 0.60299
Epoch 50/300
 - 11s - loss: 0.2895 - acc: 0.9474 - mDice: 0.7348 - val_loss: 0.7339 - val_acc: 0.9409 - val_mDice: 0.5789

Epoch 00050: val_mDice did not improve from 0.60299
Epoch 51/300
 - 11s - loss: 0.2866 - acc: 0.9477 - mDice: 0.7370 - val_loss: 0.7283 - val_acc: 0.9431 - val_mDice: 0.5841

Epoch 00051: val_mDice did not improve from 0.60299
Epoch 52/300
 - 11s - loss: 0.2856 - acc: 0.9479 - mDice: 0.7378 - val_loss: 0.7235 - val_acc: 0.9458 - val_mDice: 0.5839

Epoch 00052: val_mDice did not improve from 0.60299
Epoch 53/300
 - 11s - loss: 0.2865 - acc: 0.9478 - mDice: 0.7371 - val_loss: 0.7002 - val_acc: 0.9411 - val_mDice: 0.5737

Epoch 00053: val_mDice did not improve from 0.60299
Epoch 54/300
 - 11s - loss: 0.2824 - acc: 0.9481 - mDice: 0.7402 - val_loss: 0.7357 - val_acc: 0.9429 - val_mDice: 0.5753

Epoch 00054: val_mDice did not improve from 0.60299
Epoch 55/300
 - 11s - loss: 0.2850 - acc: 0.9479 - mDice: 0.7382 - val_loss: 0.7448 - val_acc: 0.9397 - val_mDice: 0.5684

Epoch 00055: val_mDice did not improve from 0.60299
Epoch 56/300
 - 11s - loss: 0.2824 - acc: 0.9482 - mDice: 0.7403 - val_loss: 0.7203 - val_acc: 0.9412 - val_mDice: 0.5803

Epoch 00056: val_mDice did not improve from 0.60299
Epoch 57/300
 - 11s - loss: 0.2814 - acc: 0.9481 - mDice: 0.7410 - val_loss: 0.7151 - val_acc: 0.9426 - val_mDice: 0.5744

Epoch 00057: val_mDice did not improve from 0.60299
Epoch 58/300
 - 11s - loss: 0.2817 - acc: 0.9482 - mDice: 0.7409 - val_loss: 0.7326 - val_acc: 0.9423 - val_mDice: 0.5705

Epoch 00058: val_mDice did not improve from 0.60299
Epoch 59/300
 - 11s - loss: 0.2816 - acc: 0.9482 - mDice: 0.7409 - val_loss: 0.7127 - val_acc: 0.9437 - val_mDice: 0.5856

Epoch 00059: val_mDice did not improve from 0.60299
Epoch 60/300
 - 11s - loss: 0.2794 - acc: 0.9484 - mDice: 0.7426 - val_loss: 0.7128 - val_acc: 0.9448 - val_mDice: 0.5845

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.06s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.85s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.67s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:49,  1.65s/it]predicting train subjects:   1%|          | 2/285 [00:02<07:13,  1.53s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:10,  1.53s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<06:54,  1.48s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:13,  1.55s/it]predicting train subjects:   2%|▏         | 6/285 [00:08<06:58,  1.50s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:16,  1.57s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:04,  1.53s/it]predicting train subjects:   3%|▎         | 9/285 [00:13<07:27,  1.62s/it]predicting train subjects:   4%|▎         | 10/285 [00:15<07:40,  1.68s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:22,  1.61s/it]predicting train subjects:   4%|▍         | 12/285 [00:18<07:37,  1.67s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:23,  1.63s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:28,  1.65s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:41,  1.71s/it]predicting train subjects:   6%|▌         | 16/285 [00:25<07:50,  1.75s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:35,  1.70s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:34,  1.70s/it]predicting train subjects:   7%|▋         | 19/285 [00:30<07:16,  1.64s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:23,  1.68s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:34,  1.72s/it]predicting train subjects:   8%|▊         | 22/285 [00:35<07:13,  1.65s/it]predicting train subjects:   8%|▊         | 23/285 [00:37<07:12,  1.65s/it]predicting train subjects:   8%|▊         | 24/285 [00:38<06:53,  1.58s/it]predicting train subjects:   9%|▉         | 25/285 [00:40<07:04,  1.63s/it]predicting train subjects:   9%|▉         | 26/285 [00:42<07:15,  1.68s/it]predicting train subjects:   9%|▉         | 27/285 [00:43<07:09,  1.66s/it]predicting train subjects:  10%|▉         | 28/285 [00:45<07:11,  1.68s/it]predicting train subjects:  10%|█         | 29/285 [00:47<07:11,  1.69s/it]predicting train subjects:  11%|█         | 30/285 [00:49<07:22,  1.74s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:24,  1.75s/it]predicting train subjects:  11%|█         | 32/285 [00:52<07:02,  1.67s/it]predicting train subjects:  12%|█▏        | 33/285 [00:54<07:02,  1.68s/it]predicting train subjects:  12%|█▏        | 34/285 [00:55<06:59,  1.67s/it]predicting train subjects:  12%|█▏        | 35/285 [00:57<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 36/285 [00:59<06:58,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:00<06:57,  1.68s/it]predicting train subjects:  13%|█▎        | 38/285 [01:02<07:05,  1.72s/it]predicting train subjects:  14%|█▎        | 39/285 [01:04<06:45,  1.65s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:49,  1.67s/it]predicting train subjects:  14%|█▍        | 41/285 [01:07<06:47,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:09<06:42,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:10<06:43,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:12<06:55,  1.72s/it]predicting train subjects:  16%|█▌        | 45/285 [01:14<06:38,  1.66s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:47,  1.71s/it]predicting train subjects:  16%|█▋        | 47/285 [01:17<06:45,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:19<06:47,  1.72s/it]predicting train subjects:  17%|█▋        | 49/285 [01:21<07:00,  1.78s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:53,  1.76s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<07:05,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:26<06:48,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:45,  1.75s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:46,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:31<06:32,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:33<06:28,  1.70s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:19,  1.66s/it]predicting train subjects:  20%|██        | 58/285 [01:36<06:24,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:38<06:34,  1.75s/it]predicting train subjects:  21%|██        | 60/285 [01:40<06:46,  1.80s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:27,  1.73s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:27,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<06:23,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:17,  1.71s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:15,  1.71s/it]predicting train subjects:  23%|██▎       | 66/285 [01:50<06:14,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:22,  1.75s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<06:03,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:55<06:08,  1.71s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:07,  1.72s/it]predicting train subjects:  25%|██▌       | 72/285 [02:00<05:53,  1.66s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:53,  1.67s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:53,  1.67s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:51,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:55,  1.70s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:48,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:36,  1.63s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:38,  1.65s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:28,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:24,  1.61s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:15,  1.57s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:21,  1.61s/it]predicting train subjects:  30%|███       | 86/285 [02:23<05:28,  1.65s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:27,  1.65s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:19,  1.62s/it]predicting train subjects:  31%|███       | 89/285 [02:28<05:23,  1.65s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:26,  1.68s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:14,  1.62s/it]predicting train subjects:  32%|███▏      | 92/285 [02:33<05:14,  1.63s/it]predicting train subjects:  33%|███▎      | 93/285 [02:35<05:09,  1.61s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:12,  1.64s/it]predicting train subjects:  33%|███▎      | 95/285 [02:38<05:13,  1.65s/it]predicting train subjects:  34%|███▎      | 96/285 [02:40<05:10,  1.64s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:15,  1.68s/it]predicting train subjects:  34%|███▍      | 98/285 [02:43<05:13,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:45<05:11,  1.68s/it]predicting train subjects:  35%|███▌      | 100/285 [02:47<05:10,  1.68s/it]predicting train subjects:  35%|███▌      | 101/285 [02:48<04:57,  1.62s/it]predicting train subjects:  36%|███▌      | 102/285 [02:50<04:59,  1.64s/it]predicting train subjects:  36%|███▌      | 103/285 [02:51<04:49,  1.59s/it]predicting train subjects:  36%|███▋      | 104/285 [02:53<04:56,  1.64s/it]predicting train subjects:  37%|███▋      | 105/285 [02:55<04:56,  1.65s/it]predicting train subjects:  37%|███▋      | 106/285 [02:56<04:45,  1.60s/it]predicting train subjects:  38%|███▊      | 107/285 [02:58<04:50,  1.63s/it]predicting train subjects:  38%|███▊      | 108/285 [02:59<04:39,  1.58s/it]predicting train subjects:  38%|███▊      | 109/285 [03:01<04:41,  1.60s/it]predicting train subjects:  39%|███▊      | 110/285 [03:03<04:44,  1.62s/it]predicting train subjects:  39%|███▉      | 111/285 [03:04<04:40,  1.61s/it]predicting train subjects:  39%|███▉      | 112/285 [03:06<04:43,  1.64s/it]predicting train subjects:  40%|███▉      | 113/285 [03:08<04:43,  1.65s/it]predicting train subjects:  40%|████      | 114/285 [03:09<04:42,  1.65s/it]predicting train subjects:  40%|████      | 115/285 [03:11<04:42,  1.66s/it]predicting train subjects:  41%|████      | 116/285 [03:13<04:42,  1.67s/it]predicting train subjects:  41%|████      | 117/285 [03:14<04:32,  1.62s/it]predicting train subjects:  41%|████▏     | 118/285 [03:16<04:24,  1.59s/it]predicting train subjects:  42%|████▏     | 119/285 [03:17<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 120/285 [03:19<04:28,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:21<04:22,  1.60s/it]predicting train subjects:  43%|████▎     | 122/285 [03:22<04:12,  1.55s/it]predicting train subjects:  43%|████▎     | 123/285 [03:23<04:02,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:25<04:02,  1.51s/it]predicting train subjects:  44%|████▍     | 125/285 [03:26<03:55,  1.47s/it]predicting train subjects:  44%|████▍     | 126/285 [03:28<03:53,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:29<03:45,  1.43s/it]predicting train subjects:  45%|████▍     | 128/285 [03:31<03:48,  1.45s/it]predicting train subjects:  45%|████▌     | 129/285 [03:32<03:44,  1.44s/it]predicting train subjects:  46%|████▌     | 130/285 [03:33<03:38,  1.41s/it]predicting train subjects:  46%|████▌     | 131/285 [03:35<03:33,  1.38s/it]predicting train subjects:  46%|████▋     | 132/285 [03:36<03:36,  1.42s/it]predicting train subjects:  47%|████▋     | 133/285 [03:38<03:37,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:39<03:32,  1.41s/it]predicting train subjects:  47%|████▋     | 135/285 [03:40<03:28,  1.39s/it]predicting train subjects:  48%|████▊     | 136/285 [03:42<03:24,  1.38s/it]predicting train subjects:  48%|████▊     | 137/285 [03:43<03:31,  1.43s/it]predicting train subjects:  48%|████▊     | 138/285 [03:45<03:27,  1.41s/it]predicting train subjects:  49%|████▉     | 139/285 [03:46<03:30,  1.44s/it]predicting train subjects:  49%|████▉     | 140/285 [03:48<03:32,  1.46s/it]predicting train subjects:  49%|████▉     | 141/285 [03:49<03:25,  1.43s/it]predicting train subjects:  50%|████▉     | 142/285 [03:50<03:23,  1.42s/it]predicting train subjects:  50%|█████     | 143/285 [03:52<03:19,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:53<03:21,  1.43s/it]predicting train subjects:  51%|█████     | 145/285 [03:55<03:20,  1.43s/it]predicting train subjects:  51%|█████     | 146/285 [03:56<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:58<03:19,  1.45s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:59<03:21,  1.47s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:01<03:16,  1.44s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:02<03:13,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:03<03:17,  1.48s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:05<03:12,  1.44s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:06<03:08,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:08<03:12,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:09<03:09,  1.46s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:11<03:12,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:12<03:06,  1.45s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:14<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:15<03:00,  1.43s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:16<02:58,  1.43s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:18<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:19<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:21<02:56,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:22<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:24<02:50,  1.42s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:25<02:54,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:27<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:28<02:45,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:29<02:44,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:31<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 171/285 [04:32<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:33<02:36,  1.38s/it]predicting train subjects:  61%|██████    | 173/285 [04:35<02:34,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:36<02:32,  1.37s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:38<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:39<02:39,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:41<02:34,  1.43s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:42<02:28,  1.39s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:43<02:25,  1.37s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:45<02:32,  1.46s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:46<02:34,  1.48s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:48<02:35,  1.51s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:49<02:27,  1.45s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:51<02:23,  1.42s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:52<02:19,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:54<02:27,  1.49s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:55<02:32,  1.56s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:57<02:35,  1.60s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:58<02:25,  1.51s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:00<02:20,  1.48s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:01<02:20,  1.50s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:03<02:21,  1.53s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:04<02:13,  1.45s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:06<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:07<02:03,  1.37s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:09<02:10,  1.47s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:10<02:16,  1.55s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:12<02:20,  1.61s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:13<02:11,  1.53s/it]predicting train subjects:  70%|███████   | 200/285 [05:15<02:05,  1.48s/it]predicting train subjects:  71%|███████   | 201/285 [05:16<02:10,  1.55s/it]predicting train subjects:  71%|███████   | 202/285 [05:18<02:08,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:20<02:09,  1.58s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:21<02:00,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:22<01:54,  1.44s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:24<01:49,  1.39s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:25<01:55,  1.49s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:27<01:59,  1.55s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:29<02:00,  1.58s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:30<01:51,  1.48s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:31<01:47,  1.45s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:33<01:48,  1.48s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:34<01:48,  1.50s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:36<01:42,  1.45s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:37<01:48,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:39<01:42,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:41<01:46,  1.56s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:42<01:47,  1.60s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:44<01:48,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:45<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:47<01:34,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:48<01:35,  1.51s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:49<01:28,  1.43s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:51<01:25,  1.40s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:52<01:21,  1.36s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:54<01:25,  1.46s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:55<01:29,  1.54s/it]predicting train subjects:  80%|████████  | 228/285 [05:57<01:29,  1.58s/it]predicting train subjects:  80%|████████  | 229/285 [05:59<01:28,  1.59s/it]predicting train subjects:  81%|████████  | 230/285 [06:00<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:01<01:18,  1.45s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:03<01:19,  1.50s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:04<01:14,  1.43s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:06<01:16,  1.51s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:07<01:11,  1.43s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:09<01:14,  1.51s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:10<01:14,  1.55s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:12<01:15,  1.60s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:14<01:12,  1.58s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:15<01:06,  1.49s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:16<01:03,  1.45s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:18<01:00,  1.42s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:19<00:58,  1.38s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:21<01:00,  1.49s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:22<00:56,  1.42s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:24<00:59,  1.52s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:25<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:27<00:58,  1.57s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:28<00:52,  1.47s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:30<00:50,  1.44s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:31<00:46,  1.37s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:32<00:44,  1.35s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:34<00:46,  1.46s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:35<00:47,  1.52s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:37<00:46,  1.54s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:38<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [06:40<00:39,  1.42s/it]predicting train subjects:  91%|█████████ | 258/285 [06:41<00:40,  1.50s/it]predicting train subjects:  91%|█████████ | 259/285 [06:43<00:39,  1.51s/it]predicting train subjects:  91%|█████████ | 260/285 [06:44<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:45<00:33,  1.40s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:47<00:31,  1.36s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:48<00:29,  1.32s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:50<00:29,  1.43s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:51<00:29,  1.49s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:52<00:26,  1.41s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:54<00:25,  1.40s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:56<00:25,  1.50s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:57<00:24,  1.50s/it]predicting train subjects:  95%|█████████▍| 270/285 [06:58<00:21,  1.42s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:00<00:19,  1.39s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:01<00:18,  1.44s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:03<00:16,  1.39s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:04<00:14,  1.35s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:05<00:14,  1.45s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:07<00:13,  1.51s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:08<00:11,  1.44s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:10<00:09,  1.39s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:11<00:08,  1.44s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:12<00:06,  1.38s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:14<00:05,  1.38s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:15<00:04,  1.36s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:17<00:02,  1.46s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:18<00:01,  1.51s/it]predicting train subjects: 100%|██████████| 285/285 [07:20<00:00,  1.58s/it]
Epoch 00060: val_mDice did not improve from 0.60299
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
{'val_loss': [1.4975706017934358, 1.1186974828059857, 0.8672367701163659, 0.8370604239977323, 0.8020436442815341, 0.8148226990149572, 0.7635723558756021, 0.7839773606795531, 0.746732608630107, 0.7354964063717768, 0.7559529806558902, 0.7618471005788217, 0.739391504571988, 0.7365342390078765, 0.7406196158665878, 0.7579793895666416, 0.7410567895724223, 0.7223463356494904, 0.7325059874699666, 0.7258281937012305, 0.7443401034061725, 0.7463660010924706, 0.7276479590397614, 0.7315030980568665, 0.7591053763261209, 0.7530780927493022, 0.7517295342225295, 0.7586912432542214, 0.7398546968515103, 0.7584561797288748, 0.7445861135537808, 0.7652223969881351, 0.742758068900842, 0.7684995085000992, 0.7606742771772238, 0.6965954911250335, 0.7434167781701455, 0.7083114351217563, 0.7501532423954743, 0.742590993642807, 0.7289900688024668, 0.7332790173017062, 0.7377380912120526, 0.7357692053684821, 0.7451524849121387, 0.7547654142746558, 0.7423634345714862, 0.7285396479643308, 0.7357264871780689, 0.7338940661687118, 0.7282660798384593, 0.7234574693899888, 0.7002381178048941, 0.7357240869448736, 0.7447512264435108, 0.7203314888935822, 0.7150580745476943, 0.7325784380619342, 0.7126959539376773, 0.7127818992504706], 'val_acc': [0.8897466980493985, 0.9317492796824529, 0.9415264335962442, 0.9400124641565176, 0.9433848055509421, 0.9365962697909429, 0.9440990113295041, 0.942136654487023, 0.9409254583028647, 0.9426382252803216, 0.9442145778582647, 0.9411681867562808, 0.9422845725829785, 0.9410595527062049, 0.9386325799501859, 0.9378628753698789, 0.9365685215363135, 0.9446606934070587, 0.9464427782939031, 0.945016643175712, 0.9430611867171067, 0.9379854110571054, 0.9409301280975342, 0.9405487225605891, 0.9421181334899023, 0.9397582388841189, 0.9443509578704834, 0.941991035754864, 0.9400748633421384, 0.9375393023857703, 0.942753764299246, 0.9414547704733335, 0.9429664153319138, 0.9400933522444505, 0.9423932180954859, 0.9404400632931635, 0.9416813185581794, 0.9424255627852219, 0.9430889510191404, 0.9416628159009494, 0.9422175746697646, 0.9423053952363821, 0.9438286011035626, 0.946135339828638, 0.9453448676145993, 0.9408954221468705, 0.9445081284412971, 0.9423608413109412, 0.9390787046689254, 0.940893136537992, 0.9430866401929122, 0.9457817261035626, 0.9411404201617608, 0.9429132915460147, 0.93967732328635, 0.9412467663104718, 0.942557325729957, 0.9423192716561831, 0.943687610901319, 0.9447878140669602], 'val_mDice': [0.2964855827964269, 0.43757660686969757, 0.5334959488648635, 0.5604584750074607, 0.5704701519929446, 0.5666888046723145, 0.580839502123686, 0.5836589600031192, 0.5909232749388769, 0.59507288898413, 0.596607179595874, 0.5948552695604471, 0.5963052958250046, 0.590178173321944, 0.5911679697724489, 0.5869698833960754, 0.5811658983047192, 0.5988727062940598, 0.5947152691391798, 0.6029931673636804, 0.5971153831252685, 0.5848853547985737, 0.5889400329727393, 0.5904867901251867, 0.5851808958328687, 0.5921544134616852, 0.599153801225699, 0.5822759327980188, 0.5798326656222343, 0.5755590406747965, 0.593968967978771, 0.5882757231593132, 0.58844993607356, 0.5831229016184807, 0.584670399244015, 0.5871144109047376, 0.5806261839774939, 0.5860506846354558, 0.5854036452678534, 0.5827909123439056, 0.5848317942940272, 0.5842489141684312, 0.5784622980998113, 0.5899746899421399, 0.5749150468752935, 0.5717608550420175, 0.574711547448085, 0.5865606763041936, 0.5811968480165188, 0.5789461548511798, 0.5841106245150933, 0.5838968707964971, 0.5737323227983254, 0.5752799224395019, 0.5683925335223858, 0.5803188515397218, 0.5743983216010607, 0.5705010833648535, 0.5856217506986398, 0.5844543776833094], 'loss': [2.7558472476233793, 0.9090792084437261, 0.6166343571602567, 0.5156603989225795, 0.4693940006822477, 0.441952236591093, 0.42402528669576217, 0.4101345653651793, 0.39967363357631897, 0.3895324509538299, 0.37959384178033473, 0.37521853893211954, 0.3688467957789219, 0.36412427451605506, 0.3608811000286626, 0.3532588682216021, 0.3486605029033359, 0.34421325859840557, 0.340591864887995, 0.3366692725702657, 0.33512035974505905, 0.3319268246220562, 0.3296852924666985, 0.32601478781623616, 0.32356057923009207, 0.3203847885549613, 0.31972134100393673, 0.3163316959408193, 0.3148013929302464, 0.31343798635521136, 0.308749727021831, 0.30992178688033484, 0.3088378679331275, 0.3087280160450885, 0.30488117166872913, 0.3040880286296685, 0.3017694581965508, 0.3004279632850029, 0.2988439945951221, 0.29702176786234247, 0.29817179175779013, 0.2960080574642388, 0.29472715781753733, 0.2943099323650859, 0.2911961762643241, 0.29198661500167705, 0.29123389519724274, 0.2897569600873731, 0.2895377222340364, 0.289493364389231, 0.28663305608282713, 0.28557143086416525, 0.28651322423174935, 0.28243361687919677, 0.2849641219090681, 0.28238276476670066, 0.2814478074356516, 0.281738064511834, 0.28155502533490484, 0.27942884148107205], 'acc': [0.5740743548538284, 0.8988928095414653, 0.9147946385619145, 0.9240297942949619, 0.9293082579633665, 0.9327963487661974, 0.9346998080406463, 0.9365001311109128, 0.9375732475999073, 0.938630868975641, 0.9396212515626063, 0.9401374464488872, 0.9406985841003674, 0.9411601511125777, 0.9413942415633128, 0.9420289117439222, 0.9424234189297191, 0.942917731968578, 0.9431576311593785, 0.9434247032793248, 0.9436049459990481, 0.9440206465966959, 0.9440937597604516, 0.9444823043214255, 0.9447610428673441, 0.9449570223072034, 0.9450035365945154, 0.945279280214548, 0.9454793576372733, 0.9454755015196444, 0.9457663226576185, 0.9456810123980028, 0.945824385305002, 0.9459446549283659, 0.9460772937221258, 0.9462646470786262, 0.9464115462795258, 0.9464899805829411, 0.9466177200541047, 0.9466257226496817, 0.9467985371453598, 0.9468623829494816, 0.9470982240715843, 0.9470531326163512, 0.9473186531245439, 0.9473243773857584, 0.9473722178173233, 0.94743187636629, 0.9474596980477153, 0.9474197062225257, 0.9477313201959355, 0.9478656673501759, 0.9477616934926706, 0.9481080739928888, 0.947932954513091, 0.9482320667049777, 0.9481229038901691, 0.9481686144795111, 0.9482013148475614, 0.9483535767843898], 'mDice': [0.1186179580246128, 0.3951746487484464, 0.5262714126206166, 0.5827501751197327, 0.6108773725615275, 0.6278115643309808, 0.6395302849711719, 0.6487144258182163, 0.6556373300515428, 0.6625696787873306, 0.6692357134205559, 0.6724268200981719, 0.6767123841078401, 0.6799648377735501, 0.6823153601167256, 0.6876924647832394, 0.6908388228024173, 0.6940385795580685, 0.6966897158960041, 0.6994300768580547, 0.7007273883823099, 0.7030799757683397, 0.7047205374632926, 0.7073433883051848, 0.7091582248343496, 0.7115070343644243, 0.7120520379681171, 0.7144216087749938, 0.7156478920062508, 0.7167122964323375, 0.7201186488181103, 0.7192574580481139, 0.7200709394420038, 0.7202332241282542, 0.7230148624694404, 0.7236599839064596, 0.7254935412524338, 0.726425212961957, 0.7275740325775224, 0.728981544052797, 0.728142125716698, 0.7297957741080708, 0.7308570972549226, 0.7310422562996554, 0.7334331874641602, 0.7328998477852764, 0.7334672032681864, 0.7345579974954555, 0.7347737377578016, 0.734811479316628, 0.7369786809370943, 0.7378070731560132, 0.7371177657343393, 0.7401567439767781, 0.7382357429338867, 0.7403006575088444, 0.7409587573776449, 0.740868281341837, 0.7408875152874089, 0.7425787663103568]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_amkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:41,  1.63s/it]Loading train:   1%|          | 2/285 [00:02<06:58,  1.48s/it]Loading train:   1%|          | 3/285 [00:04<06:42,  1.43s/it]Loading train:   1%|▏         | 4/285 [00:05<06:16,  1.34s/it]Loading train:   2%|▏         | 5/285 [00:06<06:22,  1.37s/it]Loading train:   2%|▏         | 6/285 [00:07<06:20,  1.37s/it]Loading train:   2%|▏         | 7/285 [00:09<06:36,  1.43s/it]Loading train:   3%|▎         | 8/285 [00:10<06:23,  1.38s/it]Loading train:   3%|▎         | 9/285 [00:12<06:36,  1.44s/it]Loading train:   4%|▎         | 10/285 [00:13<06:01,  1.31s/it]Loading train:   4%|▍         | 11/285 [00:14<05:21,  1.17s/it]Loading train:   4%|▍         | 12/285 [00:15<05:08,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:16<04:44,  1.04s/it]Loading train:   5%|▍         | 14/285 [00:17<05:07,  1.13s/it]Loading train:   5%|▌         | 15/285 [00:18<04:59,  1.11s/it]Loading train:   6%|▌         | 16/285 [00:19<04:38,  1.04s/it]Loading train:   6%|▌         | 17/285 [00:20<04:13,  1.06it/s]Loading train:   6%|▋         | 18/285 [00:21<04:13,  1.05it/s]Loading train:   7%|▋         | 19/285 [00:21<03:59,  1.11it/s]Loading train:   7%|▋         | 20/285 [00:22<03:59,  1.11it/s]Loading train:   7%|▋         | 21/285 [00:23<03:57,  1.11it/s]Loading train:   8%|▊         | 22/285 [00:24<03:45,  1.17it/s]Loading train:   8%|▊         | 23/285 [00:25<03:46,  1.15it/s]Loading train:   8%|▊         | 24/285 [00:26<03:30,  1.24it/s]Loading train:   9%|▉         | 25/285 [00:26<03:32,  1.22it/s]Loading train:   9%|▉         | 26/285 [00:27<03:35,  1.20it/s]Loading train:   9%|▉         | 27/285 [00:28<03:17,  1.30it/s]Loading train:  10%|▉         | 28/285 [00:29<03:19,  1.29it/s]Loading train:  10%|█         | 29/285 [00:29<03:21,  1.27it/s]Loading train:  11%|█         | 30/285 [00:30<03:27,  1.23it/s]Loading train:  11%|█         | 31/285 [00:31<03:33,  1.19it/s]Loading train:  11%|█         | 32/285 [00:32<03:27,  1.22it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:29,  1.20it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:42,  1.13it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:50,  1.08it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:31,  1.18it/s]Loading train:  13%|█▎        | 37/285 [00:36<03:31,  1.17it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:37,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:23,  1.21it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:23,  1.21it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:12,  1.27it/s]Loading train:  15%|█▍        | 42/285 [00:40<03:04,  1.32it/s]Loading train:  15%|█▌        | 43/285 [00:41<03:06,  1.30it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:16,  1.23it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:12,  1.25it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:18,  1.20it/s]Loading train:  16%|█▋        | 47/285 [00:44<03:17,  1.20it/s]Loading train:  17%|█▋        | 48/285 [00:45<03:29,  1.13it/s]Loading train:  17%|█▋        | 49/285 [00:46<03:32,  1.11it/s]Loading train:  18%|█▊        | 50/285 [00:47<03:31,  1.11it/s]Loading train:  18%|█▊        | 51/285 [00:48<03:32,  1.10it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:17,  1.18it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:33,  1.09it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:40,  1.05it/s]Loading train:  19%|█▉        | 55/285 [00:52<03:30,  1.09it/s]Loading train:  20%|█▉        | 56/285 [00:53<04:03,  1.07s/it]Loading train:  20%|██        | 57/285 [00:54<03:43,  1.02it/s]Loading train:  20%|██        | 58/285 [00:55<03:36,  1.05it/s]Loading train:  21%|██        | 59/285 [00:56<03:41,  1.02it/s]Loading train:  21%|██        | 60/285 [00:57<03:38,  1.03it/s]Loading train:  21%|██▏       | 61/285 [00:58<03:25,  1.09it/s]Loading train:  22%|██▏       | 62/285 [00:59<03:20,  1.11it/s]Loading train:  22%|██▏       | 63/285 [01:00<03:25,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:55,  1.06s/it]Loading train:  23%|██▎       | 65/285 [01:03<04:29,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:04<04:35,  1.26s/it]Loading train:  24%|██▎       | 67/285 [01:05<04:17,  1.18s/it]Loading train:  24%|██▍       | 68/285 [01:06<03:50,  1.06s/it]Loading train:  24%|██▍       | 69/285 [01:07<03:37,  1.01s/it]Loading train:  25%|██▍       | 70/285 [01:08<03:32,  1.01it/s]Loading train:  25%|██▍       | 71/285 [01:09<03:30,  1.02it/s]Loading train:  25%|██▌       | 72/285 [01:09<03:13,  1.10it/s]Loading train:  26%|██▌       | 73/285 [01:10<03:06,  1.14it/s]Loading train:  26%|██▌       | 74/285 [01:11<03:02,  1.15it/s]Loading train:  26%|██▋       | 75/285 [01:12<03:03,  1.15it/s]Loading train:  27%|██▋       | 76/285 [01:13<02:59,  1.16it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:51,  1.21it/s]Loading train:  27%|██▋       | 78/285 [01:14<02:39,  1.30it/s]Loading train:  28%|██▊       | 79/285 [01:15<02:40,  1.28it/s]Loading train:  28%|██▊       | 80/285 [01:16<02:48,  1.22it/s]Loading train:  28%|██▊       | 81/285 [01:17<02:52,  1.18it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:50,  1.19it/s]Loading train:  29%|██▉       | 83/285 [01:18<02:57,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:19<02:55,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:20<03:02,  1.10it/s]Loading train:  30%|███       | 86/285 [01:21<03:08,  1.05it/s]Loading train:  31%|███       | 87/285 [01:22<03:16,  1.01it/s]Loading train:  31%|███       | 88/285 [01:23<03:01,  1.08it/s]Loading train:  31%|███       | 89/285 [01:24<03:01,  1.08it/s]Loading train:  32%|███▏      | 90/285 [01:25<02:56,  1.10it/s]Loading train:  32%|███▏      | 91/285 [01:26<02:44,  1.18it/s]Loading train:  32%|███▏      | 92/285 [01:27<02:43,  1.18it/s]Loading train:  33%|███▎      | 93/285 [01:27<02:35,  1.24it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:32,  1.25it/s]Loading train:  33%|███▎      | 95/285 [01:29<02:32,  1.25it/s]Loading train:  34%|███▎      | 96/285 [01:30<02:26,  1.29it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:29,  1.25it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:30,  1.24it/s]Loading train:  35%|███▍      | 99/285 [01:32<02:24,  1.29it/s]Loading train:  35%|███▌      | 100/285 [01:33<02:28,  1.25it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:25,  1.26it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:28,  1.24it/s]Loading train:  36%|███▌      | 103/285 [01:35<02:22,  1.28it/s]Loading train:  36%|███▋      | 104/285 [01:36<02:23,  1.26it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:27,  1.22it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:20,  1.28it/s]Loading train:  38%|███▊      | 107/285 [01:38<02:17,  1.30it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:14,  1.32it/s]Loading train:  38%|███▊      | 109/285 [01:40<02:14,  1.31it/s]Loading train:  39%|███▊      | 110/285 [01:41<02:16,  1.28it/s]Loading train:  39%|███▉      | 111/285 [01:41<02:12,  1.31it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:16,  1.27it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:16,  1.26it/s]Loading train:  40%|████      | 114/285 [01:44<02:14,  1.28it/s]Loading train:  40%|████      | 115/285 [01:45<02:11,  1.29it/s]Loading train:  41%|████      | 116/285 [01:45<02:19,  1.21it/s]Loading train:  41%|████      | 117/285 [01:46<02:17,  1.22it/s]Loading train:  41%|████▏     | 118/285 [01:47<02:16,  1.22it/s]Loading train:  42%|████▏     | 119/285 [01:48<02:23,  1.16it/s]Loading train:  42%|████▏     | 120/285 [01:49<02:18,  1.20it/s]Loading train:  42%|████▏     | 121/285 [01:50<02:33,  1.07it/s]Loading train:  43%|████▎     | 122/285 [01:51<02:39,  1.02it/s]Loading train:  43%|████▎     | 123/285 [01:52<02:41,  1.01it/s]Loading train:  44%|████▎     | 124/285 [01:53<02:24,  1.11it/s]Loading train:  44%|████▍     | 125/285 [01:54<02:15,  1.18it/s]Loading train:  44%|████▍     | 126/285 [01:54<02:09,  1.23it/s]Loading train:  45%|████▍     | 127/285 [01:55<02:06,  1.25it/s]Loading train:  45%|████▍     | 128/285 [01:56<02:04,  1.27it/s]Loading train:  45%|████▌     | 129/285 [01:57<02:00,  1.30it/s]Loading train:  46%|████▌     | 130/285 [01:57<01:51,  1.39it/s]Loading train:  46%|████▌     | 131/285 [01:58<01:50,  1.40it/s]Loading train:  46%|████▋     | 132/285 [01:59<01:53,  1.34it/s]Loading train:  47%|████▋     | 133/285 [01:59<01:52,  1.35it/s]Loading train:  47%|████▋     | 134/285 [02:00<01:52,  1.34it/s]Loading train:  47%|████▋     | 135/285 [02:01<01:47,  1.40it/s]Loading train:  48%|████▊     | 136/285 [02:01<01:46,  1.40it/s]Loading train:  48%|████▊     | 137/285 [02:02<01:53,  1.31it/s]Loading train:  48%|████▊     | 138/285 [02:03<01:49,  1.35it/s]Loading train:  49%|████▉     | 139/285 [02:04<01:50,  1.32it/s]Loading train:  49%|████▉     | 140/285 [02:05<01:49,  1.32it/s]Loading train:  49%|████▉     | 141/285 [02:05<01:45,  1.36it/s]Loading train:  50%|████▉     | 142/285 [02:06<01:42,  1.39it/s]Loading train:  50%|█████     | 143/285 [02:07<01:40,  1.42it/s]Loading train:  51%|█████     | 144/285 [02:07<01:40,  1.41it/s]Loading train:  51%|█████     | 145/285 [02:08<01:37,  1.43it/s]Loading train:  51%|█████     | 146/285 [02:09<01:37,  1.43it/s]Loading train:  52%|█████▏    | 147/285 [02:09<01:35,  1.45it/s]Loading train:  52%|█████▏    | 148/285 [02:10<01:37,  1.41it/s]Loading train:  52%|█████▏    | 149/285 [02:11<01:37,  1.40it/s]Loading train:  53%|█████▎    | 150/285 [02:12<01:35,  1.41it/s]Loading train:  53%|█████▎    | 151/285 [02:12<01:38,  1.35it/s]Loading train:  53%|█████▎    | 152/285 [02:13<01:37,  1.36it/s]Loading train:  54%|█████▎    | 153/285 [02:14<01:35,  1.38it/s]Loading train:  54%|█████▍    | 154/285 [02:15<01:38,  1.33it/s]Loading train:  54%|█████▍    | 155/285 [02:15<01:37,  1.34it/s]Loading train:  55%|█████▍    | 156/285 [02:16<01:37,  1.32it/s]Loading train:  55%|█████▌    | 157/285 [02:17<01:33,  1.37it/s]Loading train:  55%|█████▌    | 158/285 [02:18<01:32,  1.37it/s]Loading train:  56%|█████▌    | 159/285 [02:18<01:34,  1.34it/s]Loading train:  56%|█████▌    | 160/285 [02:19<01:33,  1.34it/s]Loading train:  56%|█████▋    | 161/285 [02:20<01:32,  1.34it/s]Loading train:  57%|█████▋    | 162/285 [02:20<01:29,  1.37it/s]Loading train:  57%|█████▋    | 163/285 [02:21<01:29,  1.36it/s]Loading train:  58%|█████▊    | 164/285 [02:22<01:26,  1.39it/s]Loading train:  58%|█████▊    | 165/285 [02:23<01:25,  1.41it/s]Loading train:  58%|█████▊    | 166/285 [02:23<01:28,  1.35it/s]Loading train:  59%|█████▊    | 167/285 [02:24<01:28,  1.34it/s]Loading train:  59%|█████▉    | 168/285 [02:25<01:26,  1.35it/s]Loading train:  59%|█████▉    | 169/285 [02:26<01:23,  1.39it/s]Loading train:  60%|█████▉    | 170/285 [02:26<01:21,  1.41it/s]Loading train:  60%|██████    | 171/285 [02:27<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:28<01:22,  1.37it/s]Loading train:  61%|██████    | 173/285 [02:28<01:21,  1.38it/s]Loading train:  61%|██████    | 174/285 [02:29<01:19,  1.40it/s]Loading train:  61%|██████▏   | 175/285 [02:30<01:21,  1.35it/s]Loading train:  62%|██████▏   | 176/285 [02:31<01:18,  1.38it/s]Loading train:  62%|██████▏   | 177/285 [02:31<01:18,  1.38it/s]Loading train:  62%|██████▏   | 178/285 [02:32<01:15,  1.42it/s]Loading train:  63%|██████▎   | 179/285 [02:33<01:17,  1.37it/s]Loading train:  63%|██████▎   | 180/285 [02:34<01:20,  1.30it/s]Loading train:  64%|██████▎   | 181/285 [02:34<01:18,  1.32it/s]Loading train:  64%|██████▍   | 182/285 [02:35<01:18,  1.31it/s]Loading train:  64%|██████▍   | 183/285 [02:36<01:18,  1.30it/s]Loading train:  65%|██████▍   | 184/285 [02:37<01:16,  1.33it/s]Loading train:  65%|██████▍   | 185/285 [02:37<01:12,  1.38it/s]Loading train:  65%|██████▌   | 186/285 [02:38<01:20,  1.23it/s]Loading train:  66%|██████▌   | 187/285 [02:39<01:22,  1.20it/s]Loading train:  66%|██████▌   | 188/285 [02:40<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [02:41<01:17,  1.24it/s]Loading train:  67%|██████▋   | 190/285 [02:42<01:11,  1.32it/s]Loading train:  67%|██████▋   | 191/285 [02:42<01:16,  1.23it/s]Loading train:  67%|██████▋   | 192/285 [02:43<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [02:44<01:12,  1.27it/s]Loading train:  68%|██████▊   | 194/285 [02:45<01:08,  1.33it/s]Loading train:  68%|██████▊   | 195/285 [02:45<01:05,  1.37it/s]Loading train:  69%|██████▉   | 196/285 [02:46<01:10,  1.26it/s]Loading train:  69%|██████▉   | 197/285 [02:47<01:12,  1.22it/s]Loading train:  69%|██████▉   | 198/285 [02:48<01:15,  1.15it/s]Loading train:  70%|██████▉   | 199/285 [02:49<01:11,  1.21it/s]Loading train:  70%|███████   | 200/285 [02:50<01:06,  1.29it/s]Loading train:  71%|███████   | 201/285 [02:50<01:05,  1.29it/s]Loading train:  71%|███████   | 202/285 [02:51<01:03,  1.30it/s]Loading train:  71%|███████   | 203/285 [02:52<01:02,  1.31it/s]Loading train:  72%|███████▏  | 204/285 [02:53<01:00,  1.34it/s]Loading train:  72%|███████▏  | 205/285 [02:53<00:58,  1.38it/s]Loading train:  72%|███████▏  | 206/285 [02:54<00:55,  1.43it/s]Loading train:  73%|███████▎  | 207/285 [02:55<00:58,  1.33it/s]Loading train:  73%|███████▎  | 208/285 [02:55<00:58,  1.32it/s]Loading train:  73%|███████▎  | 209/285 [02:56<01:01,  1.23it/s]Loading train:  74%|███████▎  | 210/285 [02:57<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [02:58<00:59,  1.24it/s]Loading train:  74%|███████▍  | 212/285 [02:59<00:59,  1.22it/s]Loading train:  75%|███████▍  | 213/285 [03:00<00:58,  1.23it/s]Loading train:  75%|███████▌  | 214/285 [03:00<00:54,  1.30it/s]Loading train:  75%|███████▌  | 215/285 [03:01<00:57,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:02<00:55,  1.24it/s]Loading train:  76%|███████▌  | 217/285 [03:03<00:57,  1.18it/s]Loading train:  76%|███████▋  | 218/285 [03:04<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [03:05<00:55,  1.19it/s]Loading train:  77%|███████▋  | 220/285 [03:05<00:49,  1.31it/s]Loading train:  78%|███████▊  | 221/285 [03:06<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:07<00:43,  1.43it/s]Loading train:  78%|███████▊  | 223/285 [03:07<00:41,  1.51it/s]Loading train:  79%|███████▊  | 224/285 [03:08<00:40,  1.50it/s]Loading train:  79%|███████▉  | 225/285 [03:08<00:39,  1.54it/s]Loading train:  79%|███████▉  | 226/285 [03:09<00:43,  1.36it/s]Loading train:  80%|███████▉  | 227/285 [03:10<00:45,  1.26it/s]Loading train:  80%|████████  | 228/285 [03:11<00:48,  1.17it/s]Loading train:  80%|████████  | 229/285 [03:12<00:46,  1.19it/s]Loading train:  81%|████████  | 230/285 [03:13<00:44,  1.23it/s]Loading train:  81%|████████  | 231/285 [03:13<00:40,  1.32it/s]Loading train:  81%|████████▏ | 232/285 [03:14<00:39,  1.33it/s]Loading train:  82%|████████▏ | 233/285 [03:15<00:36,  1.41it/s]Loading train:  82%|████████▏ | 234/285 [03:16<00:37,  1.37it/s]Loading train:  82%|████████▏ | 235/285 [03:16<00:34,  1.46it/s]Loading train:  83%|████████▎ | 236/285 [03:17<00:37,  1.32it/s]Loading train:  83%|████████▎ | 237/285 [03:18<00:38,  1.25it/s]Loading train:  84%|████████▎ | 238/285 [03:19<00:39,  1.18it/s]Loading train:  84%|████████▍ | 239/285 [03:20<00:38,  1.21it/s]Loading train:  84%|████████▍ | 240/285 [03:20<00:35,  1.28it/s]Loading train:  85%|████████▍ | 241/285 [03:21<00:33,  1.30it/s]Loading train:  85%|████████▍ | 242/285 [03:22<00:32,  1.31it/s]Loading train:  85%|████████▌ | 243/285 [03:23<00:30,  1.36it/s]Loading train:  86%|████████▌ | 244/285 [03:23<00:32,  1.28it/s]Loading train:  86%|████████▌ | 245/285 [03:24<00:29,  1.35it/s]Loading train:  86%|████████▋ | 246/285 [03:25<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [03:26<00:32,  1.17it/s]Loading train:  87%|████████▋ | 248/285 [03:27<00:30,  1.23it/s]Loading train:  87%|████████▋ | 249/285 [03:28<00:28,  1.25it/s]Loading train:  88%|████████▊ | 250/285 [03:28<00:28,  1.25it/s]Loading train:  88%|████████▊ | 251/285 [03:29<00:25,  1.35it/s]Loading train:  88%|████████▊ | 252/285 [03:30<00:24,  1.37it/s]Loading train:  89%|████████▉ | 253/285 [03:31<00:24,  1.28it/s]Loading train:  89%|████████▉ | 254/285 [03:31<00:25,  1.22it/s]Loading train:  89%|████████▉ | 255/285 [03:32<00:23,  1.27it/s]Loading train:  90%|████████▉ | 256/285 [03:33<00:21,  1.35it/s]Loading train:  90%|█████████ | 257/285 [03:34<00:20,  1.36it/s]Loading train:  91%|█████████ | 258/285 [03:34<00:20,  1.30it/s]Loading train:  91%|█████████ | 259/285 [03:35<00:19,  1.34it/s]Loading train:  91%|█████████ | 260/285 [03:36<00:18,  1.38it/s]Loading train:  92%|█████████▏| 261/285 [03:36<00:16,  1.42it/s]Loading train:  92%|█████████▏| 262/285 [03:37<00:15,  1.45it/s]Loading train:  92%|█████████▏| 263/285 [03:38<00:14,  1.48it/s]Loading train:  93%|█████████▎| 264/285 [03:39<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [03:40<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [03:40<00:14,  1.27it/s]Loading train:  94%|█████████▎| 267/285 [03:41<00:13,  1.31it/s]Loading train:  94%|█████████▍| 268/285 [03:42<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [03:43<00:12,  1.27it/s]Loading train:  95%|█████████▍| 270/285 [03:43<00:11,  1.36it/s]Loading train:  95%|█████████▌| 271/285 [03:44<00:10,  1.37it/s]Loading train:  95%|█████████▌| 272/285 [03:45<00:09,  1.37it/s]Loading train:  96%|█████████▌| 273/285 [03:46<00:08,  1.37it/s]Loading train:  96%|█████████▌| 274/285 [03:46<00:08,  1.32it/s]Loading train:  96%|█████████▋| 275/285 [03:47<00:07,  1.27it/s]Loading train:  97%|█████████▋| 276/285 [03:48<00:07,  1.19it/s]Loading train:  97%|█████████▋| 277/285 [03:49<00:06,  1.27it/s]Loading train:  98%|█████████▊| 278/285 [03:50<00:05,  1.31it/s]Loading train:  98%|█████████▊| 279/285 [03:50<00:04,  1.33it/s]Loading train:  98%|█████████▊| 280/285 [03:51<00:03,  1.38it/s]Loading train:  99%|█████████▊| 281/285 [03:52<00:02,  1.36it/s]Loading train:  99%|█████████▉| 282/285 [03:52<00:02,  1.40it/s]Loading train:  99%|█████████▉| 283/285 [03:53<00:01,  1.29it/s]Loading train: 100%|█████████▉| 284/285 [03:54<00:00,  1.25it/s]Loading train: 100%|██████████| 285/285 [03:55<00:00,  1.23it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:04, 59.83it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:03, 75.08it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:02, 96.53it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:01, 121.84it/s]concatenating: train:  42%|████▏     | 120/285 [00:00<00:01, 150.27it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 181.18it/s]concatenating: train:  67%|██████▋   | 192/285 [00:00<00:00, 212.42it/s]concatenating: train:  80%|████████  | 229/285 [00:00<00:00, 242.93it/s]concatenating: train:  92%|█████████▏| 262/285 [00:00<00:00, 263.26it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 291.88it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.11s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.12s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 450.77it/s]2019-07-11 09:58:16.004000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 09:58:16.004102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 09:58:16.004116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 09:58:16.004125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 09:58:16.004508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.43it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.43it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.12it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.84it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.55it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.36it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.47it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.85it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.74it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.60it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.90it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.04it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  7.96it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.75it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.00it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.14it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.71it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.21it/s]
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 20)   8120        dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 20)   3620        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 65)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   858         concatenate_8[0][0]              
==================================================================================================
Total params: 141,618
Trainable params: 43,038
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 3.3151 - acc: 0.1383 - mDice: 0.0585 - val_loss: 4.0700 - val_acc: 0.2950 - val_mDice: 0.0700

Epoch 00001: val_mDice improved from -inf to 0.07004, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.5932 - acc: 0.6910 - mDice: 0.2471 - val_loss: 3.9766 - val_acc: 0.9015 - val_mDice: 0.1037

Epoch 00002: val_mDice improved from 0.07004 to 0.10370, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.9530 - acc: 0.8777 - mDice: 0.3728 - val_loss: 1.4755 - val_acc: 0.9069 - val_mDice: 0.3808

Epoch 00003: val_mDice improved from 0.10370 to 0.38082, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7793 - acc: 0.8835 - mDice: 0.4403 - val_loss: 1.4752 - val_acc: 0.9094 - val_mDice: 0.3888

Epoch 00004: val_mDice improved from 0.38082 to 0.38882, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6957 - acc: 0.8903 - mDice: 0.4797 - val_loss: 1.2884 - val_acc: 0.9154 - val_mDice: 0.4211

Epoch 00005: val_mDice improved from 0.38882 to 0.42111, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.6430 - acc: 0.8968 - mDice: 0.5070 - val_loss: 1.1754 - val_acc: 0.9208 - val_mDice: 0.4646

Epoch 00006: val_mDice improved from 0.42111 to 0.46460, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.6034 - acc: 0.9017 - mDice: 0.5283 - val_loss: 1.1185 - val_acc: 0.9226 - val_mDice: 0.4801

Epoch 00007: val_mDice improved from 0.46460 to 0.48015, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.5779 - acc: 0.9047 - mDice: 0.5427 - val_loss: 1.1023 - val_acc: 0.9172 - val_mDice: 0.5076

Epoch 00008: val_mDice improved from 0.48015 to 0.50762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.5521 - acc: 0.9082 - mDice: 0.5577 - val_loss: 1.1045 - val_acc: 0.9246 - val_mDice: 0.4989

Epoch 00009: val_mDice did not improve from 0.50762
Epoch 10/300
 - 9s - loss: 0.5314 - acc: 0.9110 - mDice: 0.5699 - val_loss: 1.1068 - val_acc: 0.9275 - val_mDice: 0.4976

Epoch 00010: val_mDice did not improve from 0.50762
Epoch 11/300
 - 9s - loss: 0.5167 - acc: 0.9132 - mDice: 0.5788 - val_loss: 1.0788 - val_acc: 0.9289 - val_mDice: 0.5139

Epoch 00011: val_mDice improved from 0.50762 to 0.51392, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 10s - loss: 0.5016 - acc: 0.9152 - mDice: 0.5883 - val_loss: 1.0800 - val_acc: 0.9295 - val_mDice: 0.5119

Epoch 00012: val_mDice did not improve from 0.51392
Epoch 13/300
 - 10s - loss: 0.4885 - acc: 0.9172 - mDice: 0.5963 - val_loss: 1.0871 - val_acc: 0.9331 - val_mDice: 0.5216

Epoch 00013: val_mDice improved from 0.51392 to 0.52163, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 10s - loss: 0.4794 - acc: 0.9189 - mDice: 0.6020 - val_loss: 1.0900 - val_acc: 0.9129 - val_mDice: 0.4975

Epoch 00014: val_mDice did not improve from 0.52163
Epoch 15/300
 - 10s - loss: 0.4688 - acc: 0.9209 - mDice: 0.6090 - val_loss: 1.0104 - val_acc: 0.9297 - val_mDice: 0.5317

Epoch 00015: val_mDice improved from 0.52163 to 0.53168, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.4625 - acc: 0.9224 - mDice: 0.6128 - val_loss: 1.0518 - val_acc: 0.9340 - val_mDice: 0.5278

Epoch 00016: val_mDice did not improve from 0.53168
Epoch 17/300
 - 10s - loss: 0.4524 - acc: 0.9238 - mDice: 0.6194 - val_loss: 1.0398 - val_acc: 0.9333 - val_mDice: 0.5196

Epoch 00017: val_mDice did not improve from 0.53168
Epoch 18/300
 - 10s - loss: 0.4484 - acc: 0.9246 - mDice: 0.6219 - val_loss: 1.0277 - val_acc: 0.9329 - val_mDice: 0.5330

Epoch 00018: val_mDice improved from 0.53168 to 0.53297, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 10s - loss: 0.4413 - acc: 0.9255 - mDice: 0.6268 - val_loss: 1.0175 - val_acc: 0.9294 - val_mDice: 0.5465

Epoch 00019: val_mDice improved from 0.53297 to 0.54650, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 10s - loss: 0.4341 - acc: 0.9265 - mDice: 0.6313 - val_loss: 1.0315 - val_acc: 0.9333 - val_mDice: 0.5342

Epoch 00020: val_mDice did not improve from 0.54650
Epoch 21/300
 - 10s - loss: 0.4298 - acc: 0.9269 - mDice: 0.6343 - val_loss: 1.0116 - val_acc: 0.9366 - val_mDice: 0.5344

Epoch 00021: val_mDice did not improve from 0.54650
Epoch 22/300
 - 10s - loss: 0.4205 - acc: 0.9279 - mDice: 0.6402 - val_loss: 1.0030 - val_acc: 0.9344 - val_mDice: 0.5427

Epoch 00022: val_mDice did not improve from 0.54650
Epoch 23/300
 - 10s - loss: 0.4232 - acc: 0.9276 - mDice: 0.6386 - val_loss: 1.0738 - val_acc: 0.9081 - val_mDice: 0.5031

Epoch 00023: val_mDice did not improve from 0.54650
Epoch 24/300
 - 10s - loss: 0.4164 - acc: 0.9284 - mDice: 0.6431 - val_loss: 0.9761 - val_acc: 0.9333 - val_mDice: 0.5446

Epoch 00024: val_mDice did not improve from 0.54650
Epoch 25/300
 - 10s - loss: 0.4138 - acc: 0.9287 - mDice: 0.6449 - val_loss: 0.9823 - val_acc: 0.9371 - val_mDice: 0.5397

Epoch 00025: val_mDice did not improve from 0.54650
Epoch 26/300
 - 10s - loss: 0.4084 - acc: 0.9294 - mDice: 0.6485 - val_loss: 0.9815 - val_acc: 0.9342 - val_mDice: 0.5413

Epoch 00026: val_mDice did not improve from 0.54650
Epoch 27/300
 - 10s - loss: 0.4038 - acc: 0.9299 - mDice: 0.6516 - val_loss: 0.9599 - val_acc: 0.9384 - val_mDice: 0.5295

Epoch 00027: val_mDice did not improve from 0.54650
Epoch 28/300
 - 10s - loss: 0.3999 - acc: 0.9303 - mDice: 0.6543 - val_loss: 0.9792 - val_acc: 0.9404 - val_mDice: 0.5327

Epoch 00028: val_mDice did not improve from 0.54650
Epoch 29/300
 - 10s - loss: 0.3985 - acc: 0.9304 - mDice: 0.6552 - val_loss: 0.9837 - val_acc: 0.9376 - val_mDice: 0.5297

Epoch 00029: val_mDice did not improve from 0.54650
Epoch 30/300
 - 10s - loss: 0.3959 - acc: 0.9307 - mDice: 0.6570 - val_loss: 0.9652 - val_acc: 0.9319 - val_mDice: 0.5443

Epoch 00030: val_mDice did not improve from 0.54650
Epoch 31/300
 - 10s - loss: 0.3921 - acc: 0.9315 - mDice: 0.6598 - val_loss: 0.9402 - val_acc: 0.9403 - val_mDice: 0.5453

Epoch 00031: val_mDice did not improve from 0.54650
Epoch 32/300
 - 10s - loss: 0.3925 - acc: 0.9312 - mDice: 0.6595 - val_loss: 0.9596 - val_acc: 0.9382 - val_mDice: 0.5360

Epoch 00032: val_mDice did not improve from 0.54650
Epoch 33/300
 - 10s - loss: 0.3893 - acc: 0.9315 - mDice: 0.6616 - val_loss: 0.9755 - val_acc: 0.9249 - val_mDice: 0.5285

Epoch 00033: val_mDice did not improve from 0.54650
Epoch 34/300
 - 10s - loss: 0.3858 - acc: 0.9319 - mDice: 0.6641 - val_loss: 0.9324 - val_acc: 0.9313 - val_mDice: 0.5464

Epoch 00034: val_mDice did not improve from 0.54650
Epoch 35/300
 - 10s - loss: 0.3839 - acc: 0.9322 - mDice: 0.6653 - val_loss: 0.9161 - val_acc: 0.9330 - val_mDice: 0.5386

Epoch 00035: val_mDice did not improve from 0.54650
Epoch 36/300
 - 10s - loss: 0.3819 - acc: 0.9324 - mDice: 0.6667 - val_loss: 0.9464 - val_acc: 0.9308 - val_mDice: 0.5369

Epoch 00036: val_mDice did not improve from 0.54650
Epoch 37/300
 - 10s - loss: 0.3793 - acc: 0.9326 - mDice: 0.6686 - val_loss: 0.9177 - val_acc: 0.9376 - val_mDice: 0.5523

Epoch 00037: val_mDice improved from 0.54650 to 0.55234, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 38/300
 - 10s - loss: 0.3765 - acc: 0.9330 - mDice: 0.6705 - val_loss: 0.9294 - val_acc: 0.9383 - val_mDice: 0.5335

Epoch 00038: val_mDice did not improve from 0.55234
Epoch 39/300
 - 10s - loss: 0.3787 - acc: 0.9327 - mDice: 0.6691 - val_loss: 0.8703 - val_acc: 0.9360 - val_mDice: 0.5496

Epoch 00039: val_mDice did not improve from 0.55234
Epoch 40/300
 - 10s - loss: 0.3731 - acc: 0.9334 - mDice: 0.6729 - val_loss: 0.8528 - val_acc: 0.9386 - val_mDice: 0.5586

Epoch 00040: val_mDice improved from 0.55234 to 0.55856, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 10s - loss: 0.3709 - acc: 0.9336 - mDice: 0.6743 - val_loss: 0.8742 - val_acc: 0.9274 - val_mDice: 0.5478

Epoch 00041: val_mDice did not improve from 0.55856
Epoch 42/300
 - 10s - loss: 0.3709 - acc: 0.9336 - mDice: 0.6744 - val_loss: 0.8772 - val_acc: 0.9350 - val_mDice: 0.5494

Epoch 00042: val_mDice did not improve from 0.55856
Epoch 43/300
 - 10s - loss: 0.3668 - acc: 0.9340 - mDice: 0.6774 - val_loss: 0.8430 - val_acc: 0.9374 - val_mDice: 0.5474

Epoch 00043: val_mDice did not improve from 0.55856
Epoch 44/300
 - 10s - loss: 0.3662 - acc: 0.9341 - mDice: 0.6778 - val_loss: 0.8570 - val_acc: 0.9353 - val_mDice: 0.5443

Epoch 00044: val_mDice did not improve from 0.55856
Epoch 45/300
 - 10s - loss: 0.3638 - acc: 0.9343 - mDice: 0.6794 - val_loss: 0.9087 - val_acc: 0.9341 - val_mDice: 0.5298

Epoch 00045: val_mDice did not improve from 0.55856
Epoch 46/300
 - 10s - loss: 0.3629 - acc: 0.9346 - mDice: 0.6802 - val_loss: 0.8578 - val_acc: 0.9368 - val_mDice: 0.5488

Epoch 00046: val_mDice did not improve from 0.55856
Epoch 47/300
 - 10s - loss: 0.3607 - acc: 0.9349 - mDice: 0.6817 - val_loss: 0.8196 - val_acc: 0.9396 - val_mDice: 0.5305

Epoch 00047: val_mDice did not improve from 0.55856
Epoch 48/300
 - 10s - loss: 0.3587 - acc: 0.9349 - mDice: 0.6831 - val_loss: 0.8319 - val_acc: 0.9393 - val_mDice: 0.5424

Epoch 00048: val_mDice did not improve from 0.55856
Epoch 49/300
 - 10s - loss: 0.3564 - acc: 0.9350 - mDice: 0.6846 - val_loss: 0.8368 - val_acc: 0.9348 - val_mDice: 0.5400

Epoch 00049: val_mDice did not improve from 0.55856
Epoch 50/300
 - 10s - loss: 0.3567 - acc: 0.9350 - mDice: 0.6845 - val_loss: 0.7731 - val_acc: 0.9414 - val_mDice: 0.5537

Epoch 00050: val_mDice did not improve from 0.55856
Epoch 51/300
 - 10s - loss: 0.3555 - acc: 0.9353 - mDice: 0.6854 - val_loss: 0.8118 - val_acc: 0.9418 - val_mDice: 0.5302

Epoch 00051: val_mDice did not improve from 0.55856
Epoch 52/300
 - 10s - loss: 0.3558 - acc: 0.9353 - mDice: 0.6852 - val_loss: 0.8131 - val_acc: 0.9340 - val_mDice: 0.5458

Epoch 00052: val_mDice did not improve from 0.55856
Epoch 53/300
 - 10s - loss: 0.3529 - acc: 0.9357 - mDice: 0.6872 - val_loss: 0.7591 - val_acc: 0.9405 - val_mDice: 0.5311

Epoch 00053: val_mDice did not improve from 0.55856
Epoch 54/300
 - 10s - loss: 0.3520 - acc: 0.9358 - mDice: 0.6878 - val_loss: 0.7986 - val_acc: 0.9386 - val_mDice: 0.5276

Epoch 00054: val_mDice did not improve from 0.55856
Epoch 55/300
 - 10s - loss: 0.3495 - acc: 0.9358 - mDice: 0.6897 - val_loss: 0.8103 - val_acc: 0.9355 - val_mDice: 0.5345

Epoch 00055: val_mDice did not improve from 0.55856
Epoch 56/300
 - 10s - loss: 0.3503 - acc: 0.9357 - mDice: 0.6892 - val_loss: 0.7773 - val_acc: 0.9374 - val_mDice: 0.5386

Epoch 00056: val_mDice did not improve from 0.55856
Epoch 57/300
 - 10s - loss: 0.3486 - acc: 0.9361 - mDice: 0.6904 - val_loss: 0.7645 - val_acc: 0.9412 - val_mDice: 0.5442

Epoch 00057: val_mDice did not improve from 0.55856
Epoch 58/300
 - 10s - loss: 0.3476 - acc: 0.9363 - mDice: 0.6910 - val_loss: 0.7507 - val_acc: 0.9375 - val_mDice: 0.5465

Epoch 00058: val_mDice did not improve from 0.55856
Epoch 59/300
 - 10s - loss: 0.3468 - acc: 0.9363 - mDice: 0.6916 - val_loss: 0.7171 - val_acc: 0.9386 - val_mDice: 0.5508

Epoch 00059: val_mDice did not improve from 0.55856
Epoch 60/300
 - 10s - loss: 0.3474 - acc: 0.9362 - mDice: 0.6913 - val_loss: 0.7289 - val_acc: 0.9404 - val_mDice: 0.5227

Epoch 00060: val_mDice did not improve from 0.55856
Epoch 61/300
 - 10s - loss: 0.3451 - acc: 0.9363 - mDice: 0.6929 - val_loss: 0.7903 - val_acc: 0.9301 - val_mDice: 0.5287

Epoch 00061: val_mDice did not improve from 0.55856
Epoch 62/300
 - 10s - loss: 0.3420 - acc: 0.9367 - mDice: 0.6950 - val_loss: 0.7029 - val_acc: 0.9410 - val_mDice: 0.5285

Epoch 00062: val_mDice did not improve from 0.55856
Epoch 63/300
 - 10s - loss: 0.3423 - acc: 0.9368 - mDice: 0.6949 - val_loss: 0.7768 - val_acc: 0.9276 - val_mDice: 0.5398

Epoch 00063: val_mDice did not improve from 0.55856
Epoch 64/300
 - 10s - loss: 0.3402 - acc: 0.9370 - mDice: 0.6965 - val_loss: 0.7226 - val_acc: 0.9394 - val_mDice: 0.5435

Epoch 00064: val_mDice did not improve from 0.55856
Epoch 65/300
 - 10s - loss: 0.3401 - acc: 0.9368 - mDice: 0.6966 - val_loss: 0.7088 - val_acc: 0.9394 - val_mDice: 0.5425

Epoch 00065: val_mDice did not improve from 0.55856
Epoch 66/300
 - 10s - loss: 0.3405 - acc: 0.9369 - mDice: 0.6962 - val_loss: 0.7844 - val_acc: 0.9340 - val_mDice: 0.5048

Epoch 00066: val_mDice did not improve from 0.55856
Epoch 67/300
 - 10s - loss: 0.3403 - acc: 0.9371 - mDice: 0.6964 - val_loss: 0.7134 - val_acc: 0.9321 - val_mDice: 0.5445

Epoch 00067: val_mDice did not improve from 0.55856
Epoch 68/300
 - 10s - loss: 0.3377 - acc: 0.9373 - mDice: 0.6983 - val_loss: 0.7598 - val_acc: 0.9378 - val_mDice: 0.5313

Epoch 00068: val_mDice did not improve from 0.55856
Epoch 69/300
 - 10s - loss: 0.3362 - acc: 0.9375 - mDice: 0.6995 - val_loss: 0.7303 - val_acc: 0.9350 - val_mDice: 0.5375

Epoch 00069: val_mDice did not improve from 0.55856
Epoch 70/300
 - 10s - loss: 0.3364 - acc: 0.9374 - mDice: 0.6992 - val_loss: 0.7248 - val_acc: 0.9337 - val_mDice: 0.5430

Epoch 00070: val_mDice did not improve from 0.55856
Epoch 71/300
 - 10s - loss: 0.3342 - acc: 0.9376 - mDice: 0.7009 - val_loss: 0.6917 - val_acc: 0.9362 - val_mDice: 0.5487

Epoch 00071: val_mDice did not improve from 0.55856
Epoch 72/300
 - 10s - loss: 0.3347 - acc: 0.9376 - mDice: 0.7005 - val_loss: 0.6748 - val_acc: 0.9385 - val_mDice: 0.5437

Epoch 00072: val_mDice did not improve from 0.55856
Epoch 73/300
 - 10s - loss: 0.3314 - acc: 0.9379 - mDice: 0.7029 - val_loss: 0.6808 - val_acc: 0.9353 - val_mDice: 0.5359

Epoch 00073: val_mDice did not improve from 0.55856
Epoch 74/300
 - 10s - loss: 0.3322 - acc: 0.9377 - mDice: 0.7023 - val_loss: 0.7014 - val_acc: 0.9334 - val_mDice: 0.5405

Epoch 00074: val_mDice did not improve from 0.55856
Epoch 75/300
 - 10s - loss: 0.3305 - acc: 0.9379 - mDice: 0.7035 - val_loss: 0.6801 - val_acc: 0.9387 - val_mDice: 0.5426

Epoch 00075: val_mDice did not improve from 0.55856
Epoch 76/300
 - 10s - loss: 0.3309 - acc: 0.9379 - mDice: 0.7033 - val_loss: 0.6824 - val_acc: 0.9351 - val_mDice: 0.5479

Epoch 00076: val_mDice did not improve from 0.55856
Epoch 77/300
 - 10s - loss: 0.3299 - acc: 0.9380 - mDice: 0.7040 - val_loss: 0.6092 - val_acc: 0.9383 - val_mDice: 0.5477

Epoch 00077: val_mDice did not improve from 0.55856
Epoch 78/300
 - 10s - loss: 0.3298 - acc: 0.9382 - mDice: 0.7041 - val_loss: 0.6672 - val_acc: 0.9358 - val_mDice: 0.5256

Epoch 00078: val_mDice did not improve from 0.55856
Epoch 79/300
 - 10s - loss: 0.3306 - acc: 0.9381 - mDice: 0.7035 - val_loss: 0.6137 - val_acc: 0.9413 - val_mDice: 0.5370

Epoch 00079: val_mDice did not improve from 0.55856
Epoch 80/300
 - 10s - loss: 0.3306 - acc: 0.9380 - mDice: 0.7035 - val_loss: 0.6037 - val_acc: 0.9414 - val_mDice: 0.5450

Epoch 00080: val_mDice did not improve from 0.55856
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [4.070028259640648, 3.9766435623168945, 1.4754699979509627, 1.475160417102632, 1.2883638881501698, 1.1753572055271693, 1.1185203847431002, 1.1023095789409818, 1.1044957070123582, 1.1068188576471238, 1.078752801531837, 1.0799753779456729, 1.087125959850493, 1.0899523326328822, 1.0103691759563627, 1.0518046106610979, 1.0398307300749279, 1.0277132306780135, 1.0175202914646693, 1.031516324906122, 1.0116252217973982, 1.0030319009508406, 1.073828969682966, 0.9761467207045782, 0.9822650409880138, 0.9815089134942918, 0.9598556473141625, 0.9792150429316929, 0.9837242875780378, 0.9652074178059896, 0.9401794388180688, 0.9596162182944161, 0.975450561160133, 0.9323804037911552, 0.9161103793552944, 0.9464273339226132, 0.9176521868932814, 0.9294351055508568, 0.8702819687979562, 0.8527847358158657, 0.8742421468098959, 0.8771624451591855, 0.8429604371388754, 0.8570253962562198, 0.9086753981454032, 0.8578425589061919, 0.8195720286596389, 0.8318553992680141, 0.8367970330374581, 0.7730713685353597, 0.8118348802839007, 0.813147919518607, 0.7591355414617629, 0.7986110278538295, 0.8103424594515846, 0.7773082483382452, 0.7644914558955601, 0.7507485662187848, 0.717116219656808, 0.7288600490206764, 0.7903187047867548, 0.7029403845469157, 0.776756343387422, 0.7225713048662458, 0.7088369755517869, 0.7844390869140625, 0.7134157021840414, 0.7597673052833194, 0.7303285712287539, 0.7248082501547677, 0.691708871296474, 0.6748363063448951, 0.6807504835582915, 0.7013765403202602, 0.6800880091530936, 0.6824292909531366, 0.6092420986720494, 0.6672068323407855, 0.6137338706425258, 0.6037393865131196], 'val_acc': [0.29502517978350323, 0.9014743367830912, 0.9068795641263326, 0.9093726816631499, 0.9154143957864671, 0.9207555169150943, 0.9226442490305219, 0.9172435913767133, 0.9245695727212089, 0.9275412190528143, 0.9288530292965117, 0.9295444318226406, 0.9330883906001136, 0.9129052247319903, 0.9296932475907462, 0.9340178427242097, 0.9333310269174122, 0.9329189828463963, 0.9294185013998122, 0.9333333571751913, 0.9365773569969904, 0.9344482819239298, 0.9080860870225089, 0.933321890376863, 0.937078751268841, 0.9341735470862615, 0.9383607932499477, 0.9403548297427949, 0.9375915584110078, 0.9319436777205694, 0.9403045149076552, 0.9382303158442179, 0.924940498102279, 0.9313255378178188, 0.9330036555017743, 0.9308310207866487, 0.9376419527190072, 0.9383310505322048, 0.9360347844305492, 0.9386240641276041, 0.9273534842899868, 0.9350251612209138, 0.9374175696145921, 0.9352586893808275, 0.93409568355197, 0.9368498382114229, 0.9396474191120693, 0.9393429671015058, 0.9348236918449402, 0.9414262686456952, 0.9418063050224668, 0.9340132673581442, 0.9404601625033787, 0.9385576787449065, 0.9355403184890747, 0.9374382155282157, 0.9411675901640029, 0.9374977038020179, 0.9385622455960229, 0.9403754330816723, 0.9300572162582761, 0.9410233242171151, 0.92757324945359, 0.9393612884339833, 0.939402475243523, 0.9339789350827535, 0.9321382954007104, 0.9378319354284377, 0.9350252037956601, 0.9336973599025181, 0.9362271172659737, 0.9385393545741126, 0.9353159495762416, 0.9333516245796567, 0.9386973522958302, 0.9350755697204953, 0.9383013106527782, 0.9358058429899669, 0.9412866263162523, 0.9413873666808719], 'val_mDice': [0.07004151177326483, 0.10370010271054482, 0.38081969640084673, 0.38882369539212613, 0.4211142233439854, 0.4646045459168298, 0.48014641801516217, 0.5076188533788636, 0.4989030591788746, 0.4975544136194956, 0.5139222542444865, 0.5118549168109894, 0.5216311223450161, 0.4975170491351968, 0.5316803519214902, 0.5278154389844054, 0.5196092345175289, 0.5329725258052349, 0.5465000176004001, 0.5342264512465114, 0.5344141689794404, 0.5427334947245461, 0.50313938444569, 0.5445617251098156, 0.5396704217862516, 0.5412830531242347, 0.5294870634873708, 0.5326747390485945, 0.5296543389558792, 0.544343173326481, 0.545272399627027, 0.5359886281547093, 0.5285363339242481, 0.5463939649718148, 0.5386411930833545, 0.5368855657676855, 0.5523354418220974, 0.5334628612867424, 0.5495706865830081, 0.5585642765675273, 0.5478447501858076, 0.5494465168033328, 0.5473704556269305, 0.5442544409916514, 0.5298191120936757, 0.5488425851577804, 0.5304698660260155, 0.5423769565920035, 0.5400197296625092, 0.5537389699547064, 0.5301943866624719, 0.5458359157755261, 0.5310547775810673, 0.5276147691266877, 0.5344693085977009, 0.5386400098601977, 0.5441870526188896, 0.5465161892629805, 0.5507642844957965, 0.522743528797513, 0.5286623940226578, 0.5284625699832326, 0.5397742624793734, 0.543474771259796, 0.5425420623450052, 0.5047697380539917, 0.5444871000945568, 0.531333536441837, 0.5375227403073084, 0.5429708038767179, 0.548719332154308, 0.5436859354376793, 0.5358501850139528, 0.5404919346883184, 0.5425984107312702, 0.5479207837155887, 0.5477386675775051, 0.5256217588626203, 0.5369670305933271, 0.5450293120174181], 'loss': [3.3150653328444197, 1.5931968194385335, 0.9530373242794491, 0.7793045574721974, 0.6956931812836298, 0.6430183376952451, 0.6034023886658172, 0.5779352333588432, 0.5520736185806161, 0.5313993722389998, 0.5167166850046084, 0.5015506214527398, 0.4885414575988074, 0.47944779832261547, 0.46876346436980054, 0.46252615600163616, 0.45236169166341555, 0.44841854542878773, 0.44133223688324363, 0.4340583060963066, 0.4298066158664233, 0.420520061429167, 0.4231515630938907, 0.41637519019197494, 0.41377279668592504, 0.40841029423818853, 0.40381760546208256, 0.399853281933884, 0.39851685848244356, 0.39591585806690704, 0.39208773268609004, 0.39251566634188273, 0.389288392747462, 0.3857550876940839, 0.3838658745414792, 0.38193655759814343, 0.3793115346147211, 0.37648716111598685, 0.3786604187553826, 0.37309566987647885, 0.37094647043330925, 0.37091414397429795, 0.36675754316468584, 0.3661870096652338, 0.36379105751285074, 0.3629378534671036, 0.36068886780476833, 0.3587034276415669, 0.3564145667993749, 0.35666484041137686, 0.35552206937692654, 0.35581626810732436, 0.3529314815377555, 0.3520491444549741, 0.34951292710058807, 0.3503099105618743, 0.3485511813649603, 0.3475835856753368, 0.34679973326553054, 0.34738330593315053, 0.3450609317158191, 0.34202293947364915, 0.342294485324928, 0.3401905557933239, 0.3401424275247582, 0.34049002446143734, 0.3403259709445824, 0.33767705545596405, 0.33617827033109465, 0.3364253308080354, 0.3341771387941281, 0.33466894901945615, 0.33138191762033953, 0.3322372695706542, 0.3305398359081753, 0.330913515628269, 0.32988047086137645, 0.32979900966335035, 0.3306080565094971, 0.330647695563261], 'acc': [0.13834273687172238, 0.6909545501900565, 0.8777410200572046, 0.8835292290418576, 0.8903397071078859, 0.8967584678495645, 0.9017481055015173, 0.9046763747396188, 0.9082015077686733, 0.9109948973033339, 0.9131670732683866, 0.9151576946690428, 0.9172416506117884, 0.9189020307026825, 0.9208799790779888, 0.9223586876819376, 0.9237741635602771, 0.924564067168757, 0.9254656859691694, 0.926478806294893, 0.9268762012288271, 0.9279043122778422, 0.9275650280000434, 0.9283621180648172, 0.9287007475878338, 0.9294277895777033, 0.9299466756926765, 0.9302818547077484, 0.9303797812551025, 0.9307149151673729, 0.9314680908579851, 0.9312043508537385, 0.9315136238653949, 0.9318989504043229, 0.9321672353690269, 0.932427686614891, 0.9326205695665983, 0.9330344880181102, 0.932713115309529, 0.9333968240331771, 0.9335599744483091, 0.9336050698608706, 0.9340025557013681, 0.9341157514832488, 0.9343260838871911, 0.9346012275803174, 0.9348897388359704, 0.9348840390599392, 0.9350457351998784, 0.9350440396677903, 0.9353257160621593, 0.9352731167730026, 0.9357005689377175, 0.9357589603113903, 0.9358497236720487, 0.9357413060637092, 0.9360896682311787, 0.9362670273847011, 0.936283707515293, 0.9362176714063909, 0.9362924243182559, 0.9367129674117781, 0.9367572739332518, 0.9370331121405724, 0.9368488500981011, 0.9369481167100128, 0.9370602230725087, 0.9372890436835479, 0.9374502738339836, 0.9373905356504427, 0.9376167651084155, 0.9375660377751202, 0.9378627300584204, 0.9377148282971483, 0.9379229078247802, 0.9379009893686527, 0.9380169879018123, 0.9381738142951597, 0.9380873598550495, 0.9379565060678787], 'mDice': [0.058511740627696984, 0.24710580905393437, 0.37278370680734557, 0.44027810661416306, 0.47969916838084614, 0.5069862371445254, 0.5283137735590577, 0.5426832379140168, 0.5576546537938182, 0.5699191473687295, 0.578815278024234, 0.588258612539719, 0.5962919779358881, 0.6019956852306353, 0.6089674503513216, 0.6128245963051941, 0.6193573790201452, 0.6219244623014135, 0.6267682019630471, 0.631305009867843, 0.6342608987285334, 0.6402270356101615, 0.6386477185715962, 0.6430503676248833, 0.6448748358325138, 0.6485004858265545, 0.651636771666698, 0.654291455700192, 0.6552458552581533, 0.6570308619389443, 0.6598037205864888, 0.6594503885844275, 0.6616077647632962, 0.6640806483790345, 0.6653301434202509, 0.6666837315442637, 0.6685545308892842, 0.6704862326446792, 0.669133132550214, 0.6729170321406991, 0.6743448414576405, 0.6744112463523272, 0.6773820607354698, 0.6777672015312942, 0.679414789479478, 0.6801588488080172, 0.6817081930528424, 0.6830613862257002, 0.6845533901817288, 0.6844591766808427, 0.6854068426031448, 0.6851648884240616, 0.6872458382105124, 0.6878050024600899, 0.6896845743287062, 0.689162582095841, 0.6903780022636415, 0.691040611000495, 0.6916405487915489, 0.6912792607932186, 0.6928786693659044, 0.6950358265232713, 0.6948879197403625, 0.6965403739533168, 0.6965639436775856, 0.6961731983329695, 0.6964321045234803, 0.6982872530355466, 0.6994705747404332, 0.6992046491291244, 0.7008842559064862, 0.7005022609075279, 0.7029154095917234, 0.7022555748322853, 0.7035347886321769, 0.7032636923437889, 0.7040311328036858, 0.7040748986086451, 0.7035122634313321, 0.7035322593360226]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.12s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.73s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:21,  1.77s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:40,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:41,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:14,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:31,  1.61s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:14,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:18,  1.58s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:42,  1.67s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:53,  1.72s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:30,  1.64s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:48,  1.72s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:30,  1.66s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:38,  1.69s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:49,  1.74s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:53,  1.76s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:28,  1.67s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:14,  1.63s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:17,  1.65s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:32,  1.71s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:20,  1.67s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:23,  1.69s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:07,  1.64s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:22,  1.70s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:32,  1.75s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:10,  1.67s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:18,  1.71s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:20,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:25,  1.75s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:29,  1.77s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:06,  1.69s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:06,  1.69s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:07,  1.70s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:18,  1.75s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<06:59,  1.68s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<06:58,  1.69s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:07,  1.73s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:48,  1.66s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:52,  1.68s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:38,  1.63s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:28,  1.60s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:39,  1.65s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:50,  1.70s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:32,  1.64s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:44,  1.69s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:26,  1.62s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:31,  1.65s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<06:44,  1.72s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:45,  1.73s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<06:58,  1.79s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:37,  1.71s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:37,  1.71s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:46,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:27,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:31,  1.71s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:16,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:24,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:34,  1.75s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:41,  1.78s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:22,  1.71s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:24,  1.72s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:25,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:11,  1.68s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:15,  1.70s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:14,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:53<06:15,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<06:01,  1.66s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:01,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:05,  1.70s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:11,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:57,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<05:54,  1.67s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:57,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:57,  1.70s/it]predicting train subjects:  27%|██▋       | 76/285 [02:08<05:57,  1.71s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:42,  1.65s/it]predicting train subjects:  27%|██▋       | 78/285 [02:11<05:37,  1.63s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:36,  1.63s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:37,  1.65s/it]predicting train subjects:  28%|██▊       | 81/285 [02:16<05:30,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:36,  1.66s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:28,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:22,  1.60s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:25,  1.63s/it]predicting train subjects:  30%|███       | 86/285 [02:24<05:35,  1.69s/it]predicting train subjects:  31%|███       | 87/285 [02:26<05:37,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:28,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:25,  1.66s/it]predicting train subjects:  32%|███▏      | 90/285 [02:31<05:33,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:20,  1.65s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:22,  1.67s/it]predicting train subjects:  33%|███▎      | 93/285 [02:36<05:12,  1.63s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:15,  1.65s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:23,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [02:41<05:21,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:43<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:25,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:48<05:21,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:11,  1.69s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:14,  1.72s/it]predicting train subjects:  36%|███▌      | 103/285 [02:53<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:05,  1.69s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:09,  1.72s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<04:58,  1.67s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<04:57,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [03:01<04:49,  1.63s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<04:51,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<04:55,  1.69s/it]predicting train subjects:  39%|███▉      | 111/285 [03:06<04:47,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<04:47,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:51,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:11<04:45,  1.67s/it]predicting train subjects:  40%|████      | 115/285 [03:13<04:49,  1.70s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:50,  1.72s/it]predicting train subjects:  41%|████      | 117/285 [03:16<04:41,  1.67s/it]predicting train subjects:  41%|████▏     | 118/285 [03:18<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:20<04:41,  1.70s/it]predicting train subjects:  42%|████▏     | 120/285 [03:21<04:33,  1.66s/it]predicting train subjects:  42%|████▏     | 121/285 [03:23<04:31,  1.65s/it]predicting train subjects:  43%|████▎     | 122/285 [03:24<04:17,  1.58s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<04:05,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:27<04:06,  1.53s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<03:57,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:30<03:51,  1.45s/it]predicting train subjects:  45%|████▍     | 127/285 [03:31<03:46,  1.44s/it]predicting train subjects:  45%|████▍     | 128/285 [03:33<03:50,  1.47s/it]predicting train subjects:  45%|████▌     | 129/285 [03:34<03:46,  1.45s/it]predicting train subjects:  46%|████▌     | 130/285 [03:36<03:41,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:37<03:37,  1.41s/it]predicting train subjects:  46%|████▋     | 132/285 [03:39<03:41,  1.45s/it]predicting train subjects:  47%|████▋     | 133/285 [03:40<03:36,  1.42s/it]predicting train subjects:  47%|████▋     | 134/285 [03:41<03:31,  1.40s/it]predicting train subjects:  47%|████▋     | 135/285 [03:43<03:27,  1.39s/it]predicting train subjects:  48%|████▊     | 136/285 [03:44<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:46<03:35,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:47<03:28,  1.42s/it]predicting train subjects:  49%|████▉     | 139/285 [03:49<03:33,  1.46s/it]predicting train subjects:  49%|████▉     | 140/285 [03:50<03:35,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:52<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:53<03:30,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [03:54<03:25,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [03:56<03:27,  1.47s/it]predicting train subjects:  51%|█████     | 145/285 [03:57<03:25,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [03:59<03:29,  1.51s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:00<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:02<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:03<03:18,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:05<03:15,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:06<03:21,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:08<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:09<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:11<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:12<03:09,  1.46s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:14<03:11,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:15<03:06,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:16<03:02,  1.44s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:18<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:19<02:54,  1.40s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:21<02:55,  1.41s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:22<02:52,  1.40s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:24<02:56,  1.44s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:25<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:26<02:50,  1.42s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:28<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:29<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:31<02:46,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:32<02:44,  1.42s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:33<02:39,  1.39s/it]predicting train subjects:  60%|██████    | 171/285 [04:35<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:36<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:38<02:39,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:39<02:40,  1.45s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:41<02:45,  1.50s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:43<02:49,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:44<02:46,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:46<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:47<02:42,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:49<02:52,  1.65s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:52,  1.66s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:56,  1.71s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:43,  1.60s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:33,  1.52s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:26,  1.46s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:01<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:03<03:05,  1.91s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:04<02:47,  1.74s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:06<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:07<02:33,  1.63s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:09<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:10<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:11<02:14,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:13<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:15<02:17,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:16<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:18<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:20<02:14,  1.57s/it]predicting train subjects:  70%|███████   | 200/285 [05:21<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:23<02:10,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:09,  1.56s/it]predicting train subjects:  71%|███████   | 203/285 [05:26<02:07,  1.56s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:27<02:00,  1.49s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:28<01:58,  1.48s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:30<01:53,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:32<02:00,  1.54s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:33<02:04,  1.61s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:35<02:06,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:36<01:57,  1.57s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:38<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:40<01:53,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:41<01:53,  1.57s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:43<01:47,  1.51s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:44<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:46<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:48<01:49,  1.60s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:49<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:51<01:50,  1.68s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:52<01:42,  1.58s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:54<01:39,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:55<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:57<01:31,  1.48s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:58<01:28,  1.45s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:59<01:24,  1.41s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:01<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:03<01:37,  1.67s/it]predicting train subjects:  80%|████████  | 228/285 [06:05<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:07<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:08<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:09<01:22,  1.53s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:11<01:21,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:12<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:14<01:20,  1.59s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:16<01:18,  1.56s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:17<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:19<01:19,  1.65s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:21<01:18,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:22<01:15,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:24<01:09,  1.54s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:25<01:06,  1.50s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:26<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:28<00:59,  1.41s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:30<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:31<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:33<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:34<01:01,  1.62s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:36<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:37<00:54,  1.52s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:39<00:51,  1.47s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:40<00:48,  1.42s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:41<00:45,  1.39s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:43<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:45<00:50,  1.62s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:47<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:48<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [06:49<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [06:51<00:42,  1.57s/it]predicting train subjects:  91%|█████████ | 259/285 [06:53<00:40,  1.57s/it]predicting train subjects:  91%|█████████ | 260/285 [06:54<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:55<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:57<00:32,  1.41s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:58<00:31,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:00<00:32,  1.53s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:02<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:03<00:28,  1.51s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:04<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:06<00:28,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:08<00:26,  1.66s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:09<00:23,  1.56s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:11<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:12<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:14<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:15<00:16,  1.49s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:17<00:16,  1.63s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:19<00:15,  1.68s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:20<00:12,  1.60s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:22<00:11,  1.58s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:24<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:25<00:07,  1.57s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:27<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:28<00:04,  1.51s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:30<00:03,  1.63s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:32<00:01,  1.70s/it]predicting train subjects: 100%|██████████| 285/285 [07:34<00:00,  1.75s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:50,  1.87s/it]Loading train:   1%|          | 2/285 [00:03<08:10,  1.73s/it]Loading train:   1%|          | 3/285 [00:05<08:13,  1.75s/it]Loading train:   1%|▏         | 4/285 [00:06<07:53,  1.68s/it]Loading train:   2%|▏         | 5/285 [00:08<08:19,  1.78s/it]Loading train:   2%|▏         | 6/285 [00:10<07:50,  1.69s/it]Loading train:   2%|▏         | 7/285 [00:11<07:52,  1.70s/it]Loading train:   3%|▎         | 8/285 [00:13<07:53,  1.71s/it]Loading train:   3%|▎         | 9/285 [00:15<08:07,  1.77s/it]Loading train:   4%|▎         | 10/285 [00:16<07:23,  1.61s/it]Loading train:   4%|▍         | 11/285 [00:17<06:33,  1.44s/it]Loading train:   4%|▍         | 12/285 [00:19<06:26,  1.42s/it]Loading train:   5%|▍         | 13/285 [00:20<06:01,  1.33s/it]Loading train:   5%|▍         | 14/285 [00:21<05:53,  1.31s/it]Loading train:   5%|▌         | 15/285 [00:22<05:52,  1.31s/it]Loading train:   6%|▌         | 16/285 [00:24<05:51,  1.31s/it]Loading train:   6%|▌         | 17/285 [00:25<05:33,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:26<05:42,  1.28s/it]Loading train:   7%|▋         | 19/285 [00:27<05:27,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:28<05:29,  1.24s/it]Loading train:   7%|▋         | 21/285 [00:30<05:48,  1.32s/it]Loading train:   8%|▊         | 22/285 [00:31<05:20,  1.22s/it]Loading train:   8%|▊         | 23/285 [00:32<05:20,  1.22s/it]Loading train:   8%|▊         | 24/285 [00:33<05:21,  1.23s/it]Loading train:   9%|▉         | 25/285 [00:35<05:34,  1.29s/it]Loading train:   9%|▉         | 26/285 [00:36<05:33,  1.29s/it]Loading train:   9%|▉         | 27/285 [00:37<05:13,  1.22s/it]Loading train:  10%|▉         | 28/285 [00:38<05:20,  1.25s/it]Loading train:  10%|█         | 29/285 [00:40<05:20,  1.25s/it]Loading train:  11%|█         | 30/285 [00:41<05:42,  1.34s/it]Loading train:  11%|█         | 31/285 [00:43<05:42,  1.35s/it]Loading train:  11%|█         | 32/285 [00:44<05:41,  1.35s/it]Loading train:  12%|█▏        | 33/285 [00:45<05:37,  1.34s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:39,  1.35s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:44,  1.38s/it]Loading train:  13%|█▎        | 36/285 [00:49<05:30,  1.33s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:51,  1.42s/it]Loading train:  13%|█▎        | 38/285 [00:53<06:09,  1.50s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:39,  1.38s/it]Loading train:  14%|█▍        | 40/285 [00:56<06:18,  1.55s/it]Loading train:  14%|█▍        | 41/285 [00:57<06:28,  1.59s/it]Loading train:  15%|█▍        | 42/285 [00:59<06:19,  1.56s/it]Loading train:  15%|█▌        | 43/285 [01:00<06:00,  1.49s/it]Loading train:  15%|█▌        | 44/285 [01:02<06:08,  1.53s/it]Loading train:  16%|█▌        | 45/285 [01:03<06:14,  1.56s/it]Loading train:  16%|█▌        | 46/285 [01:05<06:35,  1.65s/it]Loading train:  16%|█▋        | 47/285 [01:07<06:31,  1.65s/it]Loading train:  17%|█▋        | 48/285 [01:09<06:37,  1.68s/it]Loading train:  17%|█▋        | 49/285 [01:11<07:09,  1.82s/it]Loading train:  18%|█▊        | 50/285 [01:13<07:16,  1.86s/it]Loading train:  18%|█▊        | 51/285 [01:15<07:20,  1.88s/it]Loading train:  18%|█▊        | 52/285 [01:17<07:18,  1.88s/it]Loading train:  19%|█▊        | 53/285 [01:18<06:31,  1.69s/it]Loading train:  19%|█▉        | 54/285 [01:19<06:00,  1.56s/it]Loading train:  19%|█▉        | 55/285 [01:20<05:30,  1.44s/it]Loading train:  20%|█▉        | 56/285 [01:22<05:26,  1.43s/it]Loading train:  20%|██        | 57/285 [01:23<05:04,  1.34s/it]Loading train:  20%|██        | 58/285 [01:24<05:06,  1.35s/it]Loading train:  21%|██        | 59/285 [01:26<05:46,  1.53s/it]Loading train:  21%|██        | 60/285 [01:28<05:44,  1.53s/it]Loading train:  21%|██▏       | 61/285 [01:29<05:12,  1.39s/it]Loading train:  22%|██▏       | 62/285 [01:30<04:57,  1.33s/it]Loading train:  22%|██▏       | 63/285 [01:31<04:56,  1.34s/it]Loading train:  22%|██▏       | 64/285 [01:33<05:13,  1.42s/it]Loading train:  23%|██▎       | 65/285 [01:35<05:33,  1.52s/it]Loading train:  23%|██▎       | 66/285 [01:37<06:03,  1.66s/it]Loading train:  24%|██▎       | 67/285 [01:38<05:44,  1.58s/it]Loading train:  24%|██▍       | 68/285 [01:40<05:49,  1.61s/it]Loading train:  24%|██▍       | 69/285 [01:42<06:42,  1.86s/it]Loading train:  25%|██▍       | 70/285 [01:45<07:32,  2.10s/it]Loading train:  25%|██▍       | 71/285 [01:48<08:16,  2.32s/it]Loading train:  25%|██▌       | 72/285 [01:49<07:33,  2.13s/it]Loading train:  26%|██▌       | 73/285 [01:52<07:43,  2.18s/it]Loading train:  26%|██▌       | 74/285 [01:53<06:55,  1.97s/it]Loading train:  26%|██▋       | 75/285 [01:55<06:32,  1.87s/it]Loading train:  27%|██▋       | 76/285 [01:58<07:51,  2.26s/it]Loading train:  27%|██▋       | 77/285 [02:00<07:56,  2.29s/it]Loading train:  27%|██▋       | 78/285 [02:02<07:36,  2.21s/it]Loading train:  28%|██▊       | 79/285 [02:04<07:11,  2.09s/it]Loading train:  28%|██▊       | 80/285 [02:06<07:10,  2.10s/it]Loading train:  28%|██▊       | 81/285 [02:08<06:53,  2.03s/it]Loading train:  29%|██▉       | 82/285 [02:10<06:41,  1.98s/it]Loading train:  29%|██▉       | 83/285 [02:12<06:34,  1.95s/it]Loading train:  29%|██▉       | 84/285 [02:14<06:55,  2.07s/it]Loading train:  30%|██▉       | 85/285 [02:16<07:06,  2.13s/it]Loading train:  30%|███       | 86/285 [02:19<07:02,  2.12s/it]Loading train:  31%|███       | 87/285 [02:21<07:15,  2.20s/it]Loading train:  31%|███       | 88/285 [02:23<06:47,  2.07s/it]Loading train:  31%|███       | 89/285 [02:24<06:16,  1.92s/it]Loading train:  32%|███▏      | 90/285 [02:26<05:48,  1.79s/it]Loading train:  32%|███▏      | 91/285 [02:27<05:29,  1.70s/it]Loading train:  32%|███▏      | 92/285 [02:29<05:21,  1.67s/it]Loading train:  33%|███▎      | 93/285 [02:30<05:03,  1.58s/it]Loading train:  33%|███▎      | 94/285 [02:32<04:48,  1.51s/it]Loading train:  33%|███▎      | 95/285 [02:33<04:43,  1.49s/it]Loading train:  34%|███▎      | 96/285 [02:35<05:19,  1.69s/it]Loading train:  34%|███▍      | 97/285 [02:37<05:52,  1.88s/it]Loading train:  34%|███▍      | 98/285 [02:40<06:17,  2.02s/it]Loading train:  35%|███▍      | 99/285 [02:42<06:05,  1.96s/it]Loading train:  35%|███▌      | 100/285 [02:43<05:42,  1.85s/it]Loading train:  35%|███▌      | 101/285 [02:44<05:02,  1.64s/it]Loading train:  36%|███▌      | 102/285 [02:48<06:27,  2.12s/it]Loading train:  36%|███▌      | 103/285 [02:50<06:37,  2.18s/it]Loading train:  36%|███▋      | 104/285 [02:51<05:48,  1.93s/it]Loading train:  37%|███▋      | 105/285 [02:53<05:27,  1.82s/it]Loading train:  37%|███▋      | 106/285 [02:54<04:46,  1.60s/it]Loading train:  38%|███▊      | 107/285 [02:55<04:38,  1.57s/it]Loading train:  38%|███▊      | 108/285 [02:57<04:36,  1.56s/it]Loading train:  38%|███▊      | 109/285 [02:58<04:29,  1.53s/it]Loading train:  39%|███▊      | 110/285 [03:00<04:41,  1.61s/it]Loading train:  39%|███▉      | 111/285 [03:02<04:40,  1.61s/it]Loading train:  39%|███▉      | 112/285 [03:04<04:45,  1.65s/it]Loading train:  40%|███▉      | 113/285 [03:05<04:39,  1.62s/it]Loading train:  40%|████      | 114/285 [03:07<04:27,  1.56s/it]Loading train:  40%|████      | 115/285 [03:08<04:29,  1.58s/it]Loading train:  41%|████      | 116/285 [03:10<04:28,  1.59s/it]Loading train:  41%|████      | 117/285 [03:11<04:07,  1.48s/it]Loading train:  41%|████▏     | 118/285 [03:12<03:54,  1.40s/it]Loading train:  42%|████▏     | 119/285 [03:13<03:37,  1.31s/it]Loading train:  42%|████▏     | 120/285 [03:15<03:29,  1.27s/it]Loading train:  42%|████▏     | 121/285 [03:16<03:38,  1.33s/it]Loading train:  43%|████▎     | 122/285 [03:17<03:39,  1.35s/it]Loading train:  43%|████▎     | 123/285 [03:19<03:49,  1.42s/it]Loading train:  44%|████▎     | 124/285 [03:20<03:37,  1.35s/it]Loading train:  44%|████▍     | 125/285 [03:21<03:19,  1.25s/it]Loading train:  44%|████▍     | 126/285 [03:22<03:14,  1.23s/it]Loading train:  45%|████▍     | 127/285 [03:23<03:04,  1.17s/it]Loading train:  45%|████▍     | 128/285 [03:25<03:03,  1.17s/it]Loading train:  45%|████▌     | 129/285 [03:26<02:56,  1.13s/it]Loading train:  46%|████▌     | 130/285 [03:27<02:57,  1.15s/it]Loading train:  46%|████▌     | 131/285 [03:28<03:15,  1.27s/it]Loading train:  46%|████▋     | 132/285 [03:29<03:07,  1.23s/it]Loading train:  47%|████▋     | 133/285 [03:31<03:20,  1.32s/it]Loading train:  47%|████▋     | 134/285 [03:32<03:08,  1.25s/it]Loading train:  47%|████▋     | 135/285 [03:33<02:57,  1.19s/it]Loading train:  48%|████▊     | 136/285 [03:34<02:52,  1.16s/it]Loading train:  48%|████▊     | 137/285 [03:35<02:48,  1.14s/it]Loading train:  48%|████▊     | 138/285 [03:36<02:45,  1.13s/it]Loading train:  49%|████▉     | 139/285 [03:38<02:43,  1.12s/it]Loading train:  49%|████▉     | 140/285 [03:39<02:43,  1.13s/it]Loading train:  49%|████▉     | 141/285 [03:40<02:38,  1.10s/it]Loading train:  50%|████▉     | 142/285 [03:41<02:34,  1.08s/it]Loading train:  50%|█████     | 143/285 [03:42<02:28,  1.04s/it]Loading train:  51%|█████     | 144/285 [03:43<02:25,  1.03s/it]Loading train:  51%|█████     | 145/285 [03:44<02:22,  1.02s/it]Loading train:  51%|█████     | 146/285 [03:45<02:34,  1.11s/it]Loading train:  52%|█████▏    | 147/285 [03:46<02:41,  1.17s/it]Loading train:  52%|█████▏    | 148/285 [03:47<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [03:48<02:29,  1.10s/it]Loading train:  53%|█████▎    | 150/285 [03:49<02:22,  1.05s/it]Loading train:  53%|█████▎    | 151/285 [03:50<02:17,  1.03s/it]Loading train:  53%|█████▎    | 152/285 [03:51<02:14,  1.01s/it]Loading train:  54%|█████▎    | 153/285 [03:52<02:16,  1.04s/it]Loading train:  54%|█████▍    | 154/285 [03:54<02:18,  1.06s/it]Loading train:  54%|█████▍    | 155/285 [03:55<02:17,  1.06s/it]Loading train:  55%|█████▍    | 156/285 [03:56<02:16,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [03:57<02:15,  1.06s/it]Loading train:  55%|█████▌    | 158/285 [03:58<02:18,  1.09s/it]Loading train:  56%|█████▌    | 159/285 [03:59<02:26,  1.16s/it]Loading train:  56%|█████▌    | 160/285 [04:01<02:31,  1.22s/it]Loading train:  56%|█████▋    | 161/285 [04:02<02:31,  1.22s/it]Loading train:  57%|█████▋    | 162/285 [04:03<02:25,  1.19s/it]Loading train:  57%|█████▋    | 163/285 [04:04<02:16,  1.12s/it]Loading train:  58%|█████▊    | 164/285 [04:05<02:14,  1.11s/it]Loading train:  58%|█████▊    | 165/285 [04:06<02:06,  1.05s/it]Loading train:  58%|█████▊    | 166/285 [04:07<02:03,  1.03s/it]Loading train:  59%|█████▊    | 167/285 [04:08<02:07,  1.08s/it]Loading train:  59%|█████▉    | 168/285 [04:09<02:04,  1.06s/it]Loading train:  59%|█████▉    | 169/285 [04:10<02:02,  1.05s/it]Loading train:  60%|█████▉    | 170/285 [04:11<01:59,  1.04s/it]Loading train:  60%|██████    | 171/285 [04:12<02:06,  1.11s/it]Loading train:  60%|██████    | 172/285 [04:13<02:03,  1.09s/it]Loading train:  61%|██████    | 173/285 [04:15<02:05,  1.12s/it]Loading train:  61%|██████    | 174/285 [04:16<02:02,  1.11s/it]Loading train:  61%|██████▏   | 175/285 [04:17<02:00,  1.10s/it]Loading train:  62%|██████▏   | 176/285 [04:18<01:55,  1.06s/it]Loading train:  62%|██████▏   | 177/285 [04:19<01:52,  1.04s/it]Loading train:  62%|██████▏   | 178/285 [04:20<01:48,  1.01s/it]Loading train:  63%|██████▎   | 179/285 [04:21<01:47,  1.01s/it]Loading train:  63%|██████▎   | 180/285 [04:22<01:56,  1.11s/it]Loading train:  64%|██████▎   | 181/285 [04:23<01:53,  1.09s/it]Loading train:  64%|██████▍   | 182/285 [04:24<01:50,  1.07s/it]Loading train:  64%|██████▍   | 183/285 [04:25<01:43,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [04:26<01:37,  1.04it/s]Loading train:  65%|██████▍   | 185/285 [04:27<01:35,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [04:28<01:49,  1.11s/it]Loading train:  66%|██████▌   | 187/285 [04:29<01:53,  1.15s/it]Loading train:  66%|██████▌   | 188/285 [04:31<01:52,  1.16s/it]Loading train:  66%|██████▋   | 189/285 [04:32<01:45,  1.10s/it]Loading train:  67%|██████▋   | 190/285 [04:33<01:40,  1.06s/it]Loading train:  67%|██████▋   | 191/285 [04:34<01:39,  1.06s/it]Loading train:  67%|██████▋   | 192/285 [04:35<01:36,  1.04s/it]Loading train:  68%|██████▊   | 193/285 [04:36<01:37,  1.06s/it]Loading train:  68%|██████▊   | 194/285 [04:37<01:34,  1.04s/it]Loading train:  68%|██████▊   | 195/285 [04:38<01:40,  1.12s/it]Loading train:  69%|██████▉   | 196/285 [04:40<01:51,  1.25s/it]Loading train:  69%|██████▉   | 197/285 [04:41<01:56,  1.32s/it]Loading train:  69%|██████▉   | 198/285 [04:42<01:57,  1.35s/it]Loading train:  70%|██████▉   | 199/285 [04:44<01:49,  1.28s/it]Loading train:  70%|███████   | 200/285 [04:45<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:46<01:40,  1.19s/it]Loading train:  71%|███████   | 202/285 [04:47<01:36,  1.16s/it]Loading train:  71%|███████   | 203/285 [04:48<01:39,  1.22s/it]Loading train:  72%|███████▏  | 204/285 [04:49<01:34,  1.17s/it]Loading train:  72%|███████▏  | 205/285 [04:51<01:42,  1.28s/it]Loading train:  72%|███████▏  | 206/285 [04:52<01:37,  1.23s/it]Loading train:  73%|███████▎  | 207/285 [04:54<01:45,  1.35s/it]Loading train:  73%|███████▎  | 208/285 [04:55<01:43,  1.34s/it]Loading train:  73%|███████▎  | 209/285 [04:56<01:34,  1.24s/it]Loading train:  74%|███████▎  | 210/285 [04:57<01:31,  1.23s/it]Loading train:  74%|███████▍  | 211/285 [04:58<01:31,  1.24s/it]Loading train:  74%|███████▍  | 212/285 [05:00<01:39,  1.36s/it]Loading train:  75%|███████▍  | 213/285 [05:01<01:34,  1.31s/it]Loading train:  75%|███████▌  | 214/285 [05:02<01:26,  1.22s/it]Loading train:  75%|███████▌  | 215/285 [05:03<01:23,  1.19s/it]Loading train:  76%|███████▌  | 216/285 [05:04<01:13,  1.07s/it]Loading train:  76%|███████▌  | 217/285 [05:05<01:17,  1.13s/it]Loading train:  76%|███████▋  | 218/285 [05:07<01:20,  1.20s/it]Loading train:  77%|███████▋  | 219/285 [05:08<01:21,  1.23s/it]Loading train:  77%|███████▋  | 220/285 [05:09<01:15,  1.17s/it]Loading train:  78%|███████▊  | 221/285 [05:10<01:11,  1.12s/it]Loading train:  78%|███████▊  | 222/285 [05:11<01:15,  1.19s/it]Loading train:  78%|███████▊  | 223/285 [05:13<01:12,  1.17s/it]Loading train:  79%|███████▊  | 224/285 [05:14<01:07,  1.11s/it]Loading train:  79%|███████▉  | 225/285 [05:14<01:03,  1.06s/it]Loading train:  79%|███████▉  | 226/285 [05:16<01:03,  1.08s/it]Loading train:  80%|███████▉  | 227/285 [05:17<01:04,  1.10s/it]Loading train:  80%|████████  | 228/285 [05:18<01:04,  1.13s/it]Loading train:  80%|████████  | 229/285 [05:19<01:02,  1.11s/it]Loading train:  81%|████████  | 230/285 [05:20<00:58,  1.06s/it]Loading train:  81%|████████  | 231/285 [05:21<00:54,  1.00s/it]Loading train:  81%|████████▏ | 232/285 [05:22<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [05:23<00:51,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [05:24<00:55,  1.09s/it]Loading train:  82%|████████▏ | 235/285 [05:25<00:55,  1.10s/it]Loading train:  83%|████████▎ | 236/285 [05:26<00:55,  1.13s/it]Loading train:  83%|████████▎ | 237/285 [05:28<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [05:29<00:55,  1.19s/it]Loading train:  84%|████████▍ | 239/285 [05:30<00:53,  1.17s/it]Loading train:  84%|████████▍ | 240/285 [05:31<00:51,  1.15s/it]Loading train:  85%|████████▍ | 241/285 [05:32<00:50,  1.15s/it]Loading train:  85%|████████▍ | 242/285 [05:34<00:51,  1.19s/it]Loading train:  85%|████████▌ | 243/285 [05:35<00:49,  1.17s/it]Loading train:  86%|████████▌ | 244/285 [05:36<00:50,  1.23s/it]Loading train:  86%|████████▌ | 245/285 [05:37<00:47,  1.19s/it]Loading train:  86%|████████▋ | 246/285 [05:38<00:47,  1.21s/it]Loading train:  87%|████████▋ | 247/285 [05:39<00:44,  1.18s/it]Loading train:  87%|████████▋ | 248/285 [05:41<00:42,  1.14s/it]Loading train:  87%|████████▋ | 249/285 [05:42<00:41,  1.16s/it]Loading train:  88%|████████▊ | 250/285 [05:43<00:41,  1.19s/it]Loading train:  88%|████████▊ | 251/285 [05:44<00:40,  1.18s/it]Loading train:  88%|████████▊ | 252/285 [05:46<00:41,  1.25s/it]Loading train:  89%|████████▉ | 253/285 [05:47<00:40,  1.26s/it]Loading train:  89%|████████▉ | 254/285 [05:48<00:40,  1.29s/it]Loading train:  89%|████████▉ | 255/285 [05:49<00:36,  1.23s/it]Loading train:  90%|████████▉ | 256/285 [05:50<00:33,  1.17s/it]Loading train:  90%|█████████ | 257/285 [05:51<00:32,  1.15s/it]Loading train:  91%|█████████ | 258/285 [05:53<00:34,  1.28s/it]Loading train:  91%|█████████ | 259/285 [05:54<00:31,  1.22s/it]Loading train:  91%|█████████ | 260/285 [05:55<00:28,  1.12s/it]Loading train:  92%|█████████▏| 261/285 [05:56<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [05:57<00:22,  1.03it/s]Loading train:  92%|█████████▏| 263/285 [05:57<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [05:59<00:20,  1.03it/s]Loading train:  93%|█████████▎| 265/285 [06:00<00:21,  1.09s/it]Loading train:  93%|█████████▎| 266/285 [06:01<00:19,  1.05s/it]Loading train:  94%|█████████▎| 267/285 [06:02<00:18,  1.05s/it]Loading train:  94%|█████████▍| 268/285 [06:03<00:19,  1.15s/it]Loading train:  94%|█████████▍| 269/285 [06:04<00:17,  1.12s/it]Loading train:  95%|█████████▍| 270/285 [06:05<00:16,  1.12s/it]Loading train:  95%|█████████▌| 271/285 [06:06<00:15,  1.07s/it]Loading train:  95%|█████████▌| 272/285 [06:08<00:14,  1.08s/it]Loading train:  96%|█████████▌| 273/285 [06:09<00:12,  1.07s/it]Loading train:  96%|█████████▌| 274/285 [06:09<00:11,  1.01s/it]Loading train:  96%|█████████▋| 275/285 [06:11<00:11,  1.17s/it]Loading train:  97%|█████████▋| 276/285 [06:12<00:11,  1.24s/it]Loading train:  97%|█████████▋| 277/285 [06:14<00:09,  1.24s/it]Loading train:  98%|█████████▊| 278/285 [06:15<00:08,  1.24s/it]Loading train:  98%|█████████▊| 279/285 [06:16<00:07,  1.18s/it]Loading train:  98%|█████████▊| 280/285 [06:17<00:05,  1.09s/it]Loading train:  99%|█████████▊| 281/285 [06:18<00:04,  1.11s/it]Loading train:  99%|█████████▉| 282/285 [06:19<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [06:20<00:02,  1.12s/it]Loading train: 100%|█████████▉| 284/285 [06:22<00:01,  1.19s/it]Loading train: 100%|██████████| 285/285 [06:23<00:00,  1.28s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:02, 99.00it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:02, 103.26it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:02, 95.29it/s] concatenating: train:  16%|█▌        | 45/285 [00:00<00:02, 101.95it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:01, 115.21it/s]concatenating: train:  28%|██▊       | 79/285 [00:00<00:01, 126.19it/s]concatenating: train:  33%|███▎      | 95/285 [00:00<00:01, 134.07it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:01, 142.04it/s]concatenating: train:  45%|████▍     | 127/285 [00:00<00:01, 140.11it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:00, 146.45it/s]concatenating: train:  56%|█████▌    | 159/285 [00:01<00:00, 128.25it/s]concatenating: train:  61%|██████    | 173/285 [00:01<00:00, 121.69it/s]concatenating: train:  67%|██████▋   | 190/285 [00:01<00:00, 132.29it/s]concatenating: train:  74%|███████▎  | 210/285 [00:01<00:00, 146.94it/s]concatenating: train:  80%|███████▉  | 227/285 [00:01<00:00, 152.48it/s]concatenating: train:  86%|████████▋ | 246/285 [00:01<00:00, 161.92it/s]concatenating: train:  93%|█████████▎| 265/285 [00:01<00:00, 166.84it/s]concatenating: train: 100%|█████████▉| 284/285 [00:01<00:00, 172.51it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 145.69it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.57s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.56s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 171.55it/s]2019-07-11 10:26:05.923402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 10:26:05.923541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 10:26:05.923557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 10:26:05.923565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 10:26:05.923865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:14,  3.05it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:11,  3.58it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:11,  3.36it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:08,  4.25it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.72it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:07,  4.22it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.77it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.84it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:06,  3.89it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:05,  4.29it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:06,  3.79it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:03,  4.91it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:03,  5.52it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.75it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.31it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:02,  4.53it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.67it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  6.08it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  4.86it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.38it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.55it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.68it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   10820       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 20)   3620        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 80)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 242,573
Trainable params: 67,773
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 22s - loss: 2.2779 - acc: 0.6767 - mDice: 0.1748 - val_loss: 3.1303 - val_acc: 0.9143 - val_mDice: 0.1741

Epoch 00001: val_mDice improved from -inf to 0.17407, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.8539 - acc: 0.8971 - mDice: 0.4181 - val_loss: 0.7208 - val_acc: 0.9264 - val_mDice: 0.4813

Epoch 00002: val_mDice improved from 0.17407 to 0.48126, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.6896 - acc: 0.9055 - mDice: 0.4928 - val_loss: 0.7796 - val_acc: 0.9236 - val_mDice: 0.4684

Epoch 00003: val_mDice did not improve from 0.48126
Epoch 4/300
 - 15s - loss: 0.5730 - acc: 0.9159 - mDice: 0.5513 - val_loss: 0.5655 - val_acc: 0.9427 - val_mDice: 0.5564

Epoch 00004: val_mDice improved from 0.48126 to 0.55640, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 0.5193 - acc: 0.9248 - mDice: 0.5818 - val_loss: 0.5433 - val_acc: 0.9455 - val_mDice: 0.5691

Epoch 00005: val_mDice improved from 0.55640 to 0.56911, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.4819 - acc: 0.9313 - mDice: 0.6038 - val_loss: 0.5540 - val_acc: 0.9465 - val_mDice: 0.5644

Epoch 00006: val_mDice did not improve from 0.56911
Epoch 7/300
 - 15s - loss: 0.4521 - acc: 0.9363 - mDice: 0.6220 - val_loss: 0.5973 - val_acc: 0.9448 - val_mDice: 0.5466

Epoch 00007: val_mDice did not improve from 0.56911
Epoch 8/300
 - 15s - loss: 0.4307 - acc: 0.9391 - mDice: 0.6357 - val_loss: 0.5656 - val_acc: 0.9456 - val_mDice: 0.5629

Epoch 00008: val_mDice did not improve from 0.56911
Epoch 9/300
 - 15s - loss: 0.4166 - acc: 0.9407 - mDice: 0.6448 - val_loss: 0.6560 - val_acc: 0.9356 - val_mDice: 0.5166

Epoch 00009: val_mDice did not improve from 0.56911
Epoch 10/300
 - 15s - loss: 0.4031 - acc: 0.9419 - mDice: 0.6540 - val_loss: 0.5755 - val_acc: 0.9439 - val_mDice: 0.5544

Epoch 00010: val_mDice did not improve from 0.56911
Epoch 11/300
 - 14s - loss: 0.3944 - acc: 0.9429 - mDice: 0.6602 - val_loss: 0.5686 - val_acc: 0.9466 - val_mDice: 0.5571

Epoch 00011: val_mDice did not improve from 0.56911
Epoch 12/300
 - 15s - loss: 0.3859 - acc: 0.9435 - mDice: 0.6655 - val_loss: 0.5398 - val_acc: 0.9450 - val_mDice: 0.5800

Epoch 00012: val_mDice improved from 0.56911 to 0.57997, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 15s - loss: 0.3741 - acc: 0.9444 - mDice: 0.6736 - val_loss: 0.5807 - val_acc: 0.9456 - val_mDice: 0.5645

Epoch 00013: val_mDice did not improve from 0.57997
Epoch 14/300
 - 15s - loss: 0.3651 - acc: 0.9454 - mDice: 0.6798 - val_loss: 0.5428 - val_acc: 0.9473 - val_mDice: 0.5764

Epoch 00014: val_mDice did not improve from 0.57997
Epoch 15/300
 - 15s - loss: 0.3566 - acc: 0.9459 - mDice: 0.6857 - val_loss: 0.5420 - val_acc: 0.9455 - val_mDice: 0.5800

Epoch 00015: val_mDice improved from 0.57997 to 0.58001, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 15s - loss: 0.3508 - acc: 0.9465 - mDice: 0.6899 - val_loss: 0.5153 - val_acc: 0.9489 - val_mDice: 0.5899

Epoch 00016: val_mDice improved from 0.58001 to 0.58989, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 15s - loss: 0.3464 - acc: 0.9469 - mDice: 0.6930 - val_loss: 0.5328 - val_acc: 0.9493 - val_mDice: 0.5818

Epoch 00017: val_mDice did not improve from 0.58989
Epoch 18/300
 - 15s - loss: 0.3419 - acc: 0.9472 - mDice: 0.6963 - val_loss: 0.5177 - val_acc: 0.9458 - val_mDice: 0.5887

Epoch 00018: val_mDice did not improve from 0.58989
Epoch 19/300
 - 15s - loss: 0.3353 - acc: 0.9478 - mDice: 0.7010 - val_loss: 0.5595 - val_acc: 0.9496 - val_mDice: 0.5721

Epoch 00019: val_mDice did not improve from 0.58989
Epoch 20/300
 - 15s - loss: 0.3388 - acc: 0.9476 - mDice: 0.6990 - val_loss: 0.5640 - val_acc: 0.9481 - val_mDice: 0.5633

Epoch 00020: val_mDice did not improve from 0.58989
Epoch 21/300
 - 15s - loss: 0.3296 - acc: 0.9482 - mDice: 0.7052 - val_loss: 0.6033 - val_acc: 0.9484 - val_mDice: 0.5507

Epoch 00021: val_mDice did not improve from 0.58989
Epoch 22/300
 - 14s - loss: 0.3257 - acc: 0.9486 - mDice: 0.7082 - val_loss: 0.5446 - val_acc: 0.9484 - val_mDice: 0.5772

Epoch 00022: val_mDice did not improve from 0.58989
Epoch 23/300
 - 15s - loss: 0.3211 - acc: 0.9490 - mDice: 0.7113 - val_loss: 0.5395 - val_acc: 0.9480 - val_mDice: 0.5886

Epoch 00023: val_mDice did not improve from 0.58989
Epoch 24/300
 - 14s - loss: 0.3170 - acc: 0.9493 - mDice: 0.7144 - val_loss: 0.5853 - val_acc: 0.9492 - val_mDice: 0.5656

Epoch 00024: val_mDice did not improve from 0.58989
Epoch 25/300
 - 15s - loss: 0.3152 - acc: 0.9495 - mDice: 0.7158 - val_loss: 0.5955 - val_acc: 0.9454 - val_mDice: 0.5534

Epoch 00025: val_mDice did not improve from 0.58989
Epoch 26/300
 - 15s - loss: 0.3116 - acc: 0.9496 - mDice: 0.7185 - val_loss: 0.5829 - val_acc: 0.9489 - val_mDice: 0.5746

Epoch 00026: val_mDice did not improve from 0.58989
Epoch 27/300
 - 15s - loss: 0.3081 - acc: 0.9500 - mDice: 0.7210 - val_loss: 0.5769 - val_acc: 0.9475 - val_mDice: 0.5703

Epoch 00027: val_mDice did not improve from 0.58989
Epoch 28/300
 - 15s - loss: 0.3084 - acc: 0.9500 - mDice: 0.7208 - val_loss: 0.5319 - val_acc: 0.9497 - val_mDice: 0.5860

Epoch 00028: val_mDice did not improve from 0.58989
Epoch 29/300
 - 15s - loss: 0.3030 - acc: 0.9505 - mDice: 0.7250 - val_loss: 0.6131 - val_acc: 0.9473 - val_mDice: 0.5554

Epoch 00029: val_mDice did not improve from 0.58989
Epoch 30/300
 - 15s - loss: 0.2996 - acc: 0.9507 - mDice: 0.7275 - val_loss: 0.5764 - val_acc: 0.9495 - val_mDice: 0.5653

Epoch 00030: val_mDice did not improve from 0.58989
Epoch 31/300
 - 15s - loss: 0.2975 - acc: 0.9509 - mDice: 0.7290 - val_loss: 0.6296 - val_acc: 0.9499 - val_mDice: 0.5476

Epoch 00031: val_mDice did not improve from 0.58989
Epoch 32/300
 - 15s - loss: 0.2959 - acc: 0.9510 - mDice: 0.7302 - val_loss: 0.5594 - val_acc: 0.9467 - val_mDice: 0.5747

Epoch 00032: val_mDice did not improve from 0.58989
Epoch 33/300
 - 15s - loss: 0.2967 - acc: 0.9510 - mDice: 0.7298 - val_loss: 0.5419 - val_acc: 0.9490 - val_mDice: 0.5812

Epoch 00033: val_mDice did not improve from 0.58989
Epoch 34/300
 - 14s - loss: 0.2937 - acc: 0.9513 - mDice: 0.7320 - val_loss: 0.5867 - val_acc: 0.9470 - val_mDice: 0.5639

Epoch 00034: val_mDice did not improve from 0.58989
Epoch 35/300
 - 15s - loss: 0.2924 - acc: 0.9514 - mDice: 0.7330 - val_loss: 0.5814 - val_acc: 0.9491 - val_mDice: 0.5659

Epoch 00035: val_mDice did not improve from 0.58989
Epoch 36/300
 - 15s - loss: 0.2904 - acc: 0.9515 - mDice: 0.7345 - val_loss: 0.5511 - val_acc: 0.9494 - val_mDice: 0.5771

Epoch 00036: val_mDice did not improve from 0.58989
Epoch 37/300
 - 15s - loss: 0.2890 - acc: 0.9516 - mDice: 0.7355 - val_loss: 0.5535 - val_acc: 0.9503 - val_mDice: 0.5723

Epoch 00037: val_mDice did not improve from 0.58989
Epoch 38/300
 - 14s - loss: 0.2841 - acc: 0.9520 - mDice: 0.7393 - val_loss: 0.6155 - val_acc: 0.9491 - val_mDice: 0.5593

Epoch 00038: val_mDice did not improve from 0.58989
Epoch 39/300
 - 14s - loss: 0.2844 - acc: 0.9520 - mDice: 0.7391 - val_loss: 0.6307 - val_acc: 0.9508 - val_mDice: 0.5405

Epoch 00039: val_mDice did not improve from 0.58989
Epoch 40/300
 - 14s - loss: 0.2831 - acc: 0.9521 - mDice: 0.7402 - val_loss: 0.5444 - val_acc: 0.9509 - val_mDice: 0.5802

Epoch 00040: val_mDice did not improve from 0.58989
Epoch 41/300
 - 14s - loss: 0.2829 - acc: 0.9521 - mDice: 0.7403 - val_loss: 0.5635 - val_acc: 0.9503 - val_mDice: 0.5782

Epoch 00041: val_mDice did not improve from 0.58989
Epoch 42/300
 - 14s - loss: 0.2783 - acc: 0.9524 - mDice: 0.7437 - val_loss: 0.5506 - val_acc: 0.9495 - val_mDice: 0.5765

Epoch 00042: val_mDice did not improve from 0.58989
Epoch 43/300
 - 14s - loss: 0.2779 - acc: 0.9525 - mDice: 0.7441 - val_loss: 0.5631 - val_acc: 0.9491 - val_mDice: 0.5691

Epoch 00043: val_mDice did not improve from 0.58989
Epoch 44/300
 - 14s - loss: 0.2779 - acc: 0.9525 - mDice: 0.7441 - val_loss: 0.5491 - val_acc: 0.9511 - val_mDice: 0.5735

Epoch 00044: val_mDice did not improve from 0.58989
Epoch 45/300
 - 14s - loss: 0.2751 - acc: 0.9528 - mDice: 0.7463 - val_loss: 0.5921 - val_acc: 0.9496 - val_mDice: 0.5638

Epoch 00045: val_mDice did not improve from 0.58989
Epoch 46/300
 - 14s - loss: 0.2754 - acc: 0.9527 - mDice: 0.7461 - val_loss: 0.5762 - val_acc: 0.9492 - val_mDice: 0.5734

Epoch 00046: val_mDice did not improve from 0.58989
Epoch 47/300
 - 14s - loss: 0.2733 - acc: 0.9528 - mDice: 0.7475 - val_loss: 0.5818 - val_acc: 0.9505 - val_mDice: 0.5663

Epoch 00047: val_mDice did not improve from 0.58989
Epoch 48/300
 - 14s - loss: 0.2716 - acc: 0.9529 - mDice: 0.7489 - val_loss: 0.6329 - val_acc: 0.9497 - val_mDice: 0.5559

Epoch 00048: val_mDice did not improve from 0.58989
Epoch 49/300
 - 14s - loss: 0.2696 - acc: 0.9532 - mDice: 0.7506 - val_loss: 0.5195 - val_acc: 0.9488 - val_mDice: 0.5921

Epoch 00049: val_mDice improved from 0.58989 to 0.59214, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 50/300
 - 14s - loss: 0.2753 - acc: 0.9529 - mDice: 0.7464 - val_loss: 0.5497 - val_acc: 0.9511 - val_mDice: 0.5809

Epoch 00050: val_mDice did not improve from 0.59214
Epoch 51/300
 - 15s - loss: 0.2691 - acc: 0.9533 - mDice: 0.7511 - val_loss: 0.5896 - val_acc: 0.9479 - val_mDice: 0.5683

Epoch 00051: val_mDice did not improve from 0.59214
Epoch 52/300
 - 14s - loss: 0.2676 - acc: 0.9534 - mDice: 0.7521 - val_loss: 0.5493 - val_acc: 0.9487 - val_mDice: 0.5813

Epoch 00052: val_mDice did not improve from 0.59214
Epoch 53/300
 - 15s - loss: 0.2678 - acc: 0.9534 - mDice: 0.7520 - val_loss: 0.6170 - val_acc: 0.9510 - val_mDice: 0.5587

Epoch 00053: val_mDice did not improve from 0.59214
Epoch 54/300
 - 15s - loss: 0.2643 - acc: 0.9535 - mDice: 0.7546 - val_loss: 0.5516 - val_acc: 0.9490 - val_mDice: 0.5810

Epoch 00054: val_mDice did not improve from 0.59214
Epoch 55/300
 - 15s - loss: 0.2645 - acc: 0.9535 - mDice: 0.7545 - val_loss: 0.6533 - val_acc: 0.9478 - val_mDice: 0.5456

Epoch 00055: val_mDice did not improve from 0.59214
Epoch 56/300
 - 14s - loss: 0.2650 - acc: 0.9536 - mDice: 0.7542 - val_loss: 0.5823 - val_acc: 0.9483 - val_mDice: 0.5688

Epoch 00056: val_mDice did not improve from 0.59214
Epoch 57/300
 - 15s - loss: 0.2617 - acc: 0.9538 - mDice: 0.7568 - val_loss: 0.6582 - val_acc: 0.9504 - val_mDice: 0.5550

Epoch 00057: val_mDice did not improve from 0.59214
Epoch 58/300
 - 15s - loss: 0.2619 - acc: 0.9539 - mDice: 0.7565 - val_loss: 0.5807 - val_acc: 0.9482 - val_mDice: 0.5693

Epoch 00058: val_mDice did not improve from 0.59214
Epoch 59/300
 - 14s - loss: 0.2617 - acc: 0.9539 - mDice: 0.7567 - val_loss: 0.5671 - val_acc: 0.9497 - val_mDice: 0.5736

Epoch 00059: val_mDice did not improve from 0.59214
Epoch 60/300
 - 14s - loss: 0.2616 - acc: 0.9539 - mDice: 0.7569 - val_loss: 0.5874 - val_acc: 0.9497 - val_mDice: 0.5614

Epoch 00060: val_mDice did not improve from 0.59214
Epoch 61/300
 - 15s - loss: 0.2581 - acc: 0.9541 - mDice: 0.7595 - val_loss: 0.5494 - val_acc: 0.9509 - val_mDice: 0.5780

Epoch 00061: val_mDice did not improve from 0.59214
Epoch 62/300
 - 14s - loss: 0.2599 - acc: 0.9539 - mDice: 0.7582 - val_loss: 0.5736 - val_acc: 0.9461 - val_mDice: 0.5718

Epoch 00062: val_mDice did not improve from 0.59214
Epoch 63/300
 - 15s - loss: 0.2577 - acc: 0.9541 - mDice: 0.7598 - val_loss: 0.6014 - val_acc: 0.9487 - val_mDice: 0.5655

Epoch 00063: val_mDice did not improve from 0.59214
Epoch 64/300
 - 15s - loss: 0.2554 - acc: 0.9543 - mDice: 0.7617 - val_loss: 0.5949 - val_acc: 0.9509 - val_mDice: 0.5741

Epoch 00064: val_mDice did not improve from 0.59214
Epoch 65/300
 - 15s - loss: 0.2565 - acc: 0.9542 - mDice: 0.7608 - val_loss: 0.5779 - val_acc: 0.9493 - val_mDice: 0.5749

Epoch 00065: val_mDice did not improve from 0.59214
Epoch 66/300
 - 15s - loss: 0.2562 - acc: 0.9542 - mDice: 0.7611 - val_loss: 0.6131 - val_acc: 0.9474 - val_mDice: 0.5638

Epoch 00066: val_mDice did not improve from 0.59214
Epoch 67/300
 - 14s - loss: 0.2554 - acc: 0.9544 - mDice: 0.7617 - val_loss: 0.5953 - val_acc: 0.9475 - val_mDice: 0.5660

Epoch 00067: val_mDice did not improve from 0.59214
Epoch 68/300
 - 14s - loss: 0.2535 - acc: 0.9545 - mDice: 0.7632 - val_loss: 0.5871 - val_acc: 0.9489 - val_mDice: 0.5611

Epoch 00068: val_mDice did not improve from 0.59214
Epoch 69/300
 - 15s - loss: 0.2550 - acc: 0.9543 - mDice: 0.7619 - val_loss: 0.5497 - val_acc: 0.9496 - val_mDice: 0.5783

Epoch 00069: val_mDice did not improve from 0.59214
Epoch 70/300
 - 15s - loss: 0.2521 - acc: 0.9546 - mDice: 0.7643 - val_loss: 0.6111 - val_acc: 0.9487 - val_mDice: 0.5587

Epoch 00070: val_mDice did not improve from 0.59214
Epoch 71/300
 - 16s - loss: 0.2532 - acc: 0.9545 - mDice: 0.7635 - val_loss: 0.6563 - val_acc: 0.9476 - val_mDice: 0.5501

Epoch 00071: val_mDice did not improve from 0.59214
Epoch 72/300
 - 16s - loss: 0.2515 - acc: 0.9546 - mDice: 0.7648 - val_loss: 0.5886 - val_acc: 0.9504 - val_mDice: 0.5727

Epoch 00072: val_mDice did not improve from 0.59214
Epoch 73/300
 - 16s - loss: 0.2521 - acc: 0.9545 - mDice: 0.7643 - val_loss: 0.6376 - val_acc: 0.9496 - val_mDice: 0.5530

Epoch 00073: val_mDice did not improve from 0.59214
Epoch 74/300
 - 15s - loss: 0.2502 - acc: 0.9548 - mDice: 0.7658 - val_loss: 0.5375 - val_acc: 0.9504 - val_mDice: 0.5898

Epoch 00074: val_mDice did not improve from 0.59214
Epoch 75/300
 - 16s - loss: 0.2497 - acc: 0.9548 - mDice: 0.7662 - val_loss: 0.5467 - val_acc: 0.9503 - val_mDice: 0.5885

Epoch 00075: val_mDice did not improve from 0.59214
Epoch 76/300
 - 15s - loss: 0.2903 - acc: 0.9513 - mDice: 0.7378 - val_loss: 0.5693 - val_acc: 0.9504 - val_mDice: 0.5739

Epoch 00076: val_mDice did not improve from 0.59214
Epoch 77/300
 - 15s - loss: 0.2592 - acc: 0.9541 - mDice: 0.7589 - val_loss: 0.5512 - val_acc: 0.9502 - val_mDice: 0.5804

Epoch 00077: val_mDice did not improve from 0.59214
Epoch 78/300
 - 15s - loss: 0.2529 - acc: 0.9546 - mDice: 0.7637 - val_loss: 0.6110 - val_acc: 0.9506 - val_mDice: 0.5623

Epoch 00078: val_mDice did not improve from 0.59214
Epoch 79/300
 - 16s - loss: 0.2497 - acc: 0.9548 - mDice: 0.7662 - val_loss: 0.5800 - val_acc: 0.9498 - val_mDice: 0.5729

Epoch 00079: val_mDice did not improve from 0.59214
Epoch 80/300
 - 15s - loss: 0.2477 - acc: 0.9549 - mDice: 0.7678 - val_loss: 0.5604 - val_acc: 0.9495 - val_mDice: 0.5747

Epoch 00080: val_mDice did not improve from 0.59214
Epoch 81/300
 - 16s - loss: 0.2469 - acc: 0.9551 - mDice: 0.7685 - val_loss: 0.5777 - val_acc: 0.9500 - val_mDice: 0.5714

Epoch 00081: val_mDice did not improve from 0.59214
Epoch 82/300
 - 16s - loss: 0.2466 - acc: 0.9551 - mDice: 0.7687 - val_loss: 0.5724 - val_acc: 0.9511 - val_mDice: 0.5783

Epoch 00082: val_mDice did not improve from 0.59214
Epoch 83/300
 - 15s - loss: 0.2460 - acc: 0.9551 - mDice: 0.7693 - val_loss: 0.5905 - val_acc: 0.9474 - val_mDice: 0.5678

Epoch 00083: val_mDice did not improve from 0.59214
Epoch 84/300
 - 16s - loss: 0.2473 - acc: 0.9550 - mDice: 0.7684 - val_loss: 0.6128 - val_acc: 0.9478 - val_mDice: 0.5501

Epoch 00084: val_mDice did not improve from 0.59214
Epoch 85/300
 - 15s - loss: 0.2445 - acc: 0.9551 - mDice: 0.7704 - val_loss: 0.5708 - val_acc: 0.9502 - val_mDice: 0.5675

Epoch 00085: val_mDice did not improve from 0.59214
Epoch 86/300
 - 15s - loss: 0.2442 - acc: 0.9553 - mDice: 0.7707 - val_loss: 0.5784 - val_acc: 0.9488 - val_mDice: 0.5647

Epoch 00086: val_mDice did not improve from 0.59214
Epoch 87/300
 - 16s - loss: 0.2452 - acc: 0.9552 - mDice: 0.7699 - val_loss: 0.5475 - val_acc: 0.9474 - val_mDice: 0.5744

Epoch 00087: val_mDice did not improve from 0.59214
Epoch 88/300
 - 16s - loss: 0.2457 - acc: 0.9552 - mDice: 0.7695 - val_loss: 0.6004 - val_acc: 0.9501 - val_mDice: 0.5568

Epoch 00088: val_mDice did not improve from 0.59214
Epoch 89/300
 - 15s - loss: 0.2435 - acc: 0.9553 - mDice: 0.7712 - val_loss: 0.6306 - val_acc: 0.9511 - val_mDice: 0.5542

Epoch 00089: val_mDice did not improve from 0.59214
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
{'val_loss': [3.130294613332056, 0.7208147997962696, 0.7795771530220629, 0.5655447724145218, 0.5432885891898385, 0.5539948250994337, 0.5972964780290699, 0.5655523921524346, 0.6560010054257995, 0.5755312259636778, 0.5686425803093936, 0.5398263887986124, 0.5806906153369882, 0.542759981901286, 0.5419968376612531, 0.515298854039368, 0.5327979286289748, 0.5177195012236441, 0.5595373291543076, 0.5640499232201602, 0.6033066577751544, 0.5446029608476095, 0.5394517706093176, 0.5853183842238101, 0.5955073430551497, 0.5828738185946502, 0.5768750153440337, 0.531909668245795, 0.6131280577382562, 0.5763762320220137, 0.6295743354871952, 0.5593907586689102, 0.5418854062783651, 0.5867482626904322, 0.5813846065345423, 0.5511235428256029, 0.5535050490714984, 0.6155013681790016, 0.6306558854087105, 0.5444052405863501, 0.5635384727456716, 0.5506424857251471, 0.563134514752713, 0.5491112067712752, 0.5921210453496965, 0.5761913996834994, 0.5818435995938391, 0.6329248404369674, 0.5195343391189362, 0.54974862550224, 0.5896304013342831, 0.5493228542072147, 0.6170305413240827, 0.5516055975546384, 0.6532672333983736, 0.5823344761432883, 0.6581552258416927, 0.5807394571810461, 0.5671435694454768, 0.5873578187473659, 0.5493734452311553, 0.5736275704879334, 0.6013919547949423, 0.5949027295219166, 0.577934997374785, 0.6130521846883124, 0.5952643432430715, 0.5871230696832668, 0.5496754516436401, 0.6111275610311071, 0.6563340668571728, 0.5885969670125226, 0.6375818212605056, 0.5374873323813497, 0.5466966292711609, 0.5693135780995119, 0.5511904658551988, 0.6110301613807678, 0.5800186675354089, 0.5604268732017645, 0.5776982720337767, 0.5723816479384566, 0.5904814424461493, 0.6128347219701585, 0.570811722531665, 0.5784362544560565, 0.547500773848102, 0.6003571592229705, 0.6306156732516581], 'val_acc': [0.9143148357641764, 0.9264363083759499, 0.9235893164933061, 0.9427270982518542, 0.9454542581595522, 0.9464852373693242, 0.9447993286495102, 0.9456009758251339, 0.9356013196806668, 0.9438902948821724, 0.946576142111304, 0.9449729033688593, 0.945605102198084, 0.9473343837860576, 0.9454832290137947, 0.9489107754643403, 0.9492971537499454, 0.9458220264765137, 0.9496462704749081, 0.9480781478588808, 0.9484087388608708, 0.9484417748184844, 0.948043036727266, 0.9491938335935497, 0.9453592709988855, 0.9488963041891599, 0.9474542130971088, 0.9496752180200715, 0.9472827162156557, 0.9494686383108853, 0.9498962829898856, 0.9467104463603909, 0.9490347431358679, 0.9470368713639968, 0.9491463143732295, 0.9494004369448017, 0.950340477447936, 0.9491194446659621, 0.9507681700770415, 0.9508921157714375, 0.950264019673097, 0.9494809984494854, 0.9490884589083368, 0.9510863146968394, 0.9496152993687038, 0.949222745509121, 0.9504809822450137, 0.9497165243718877, 0.9487661482901547, 0.9511131660898304, 0.9478529781602615, 0.9486711105154879, 0.9509644238642474, 0.9489810030553594, 0.9478137113528544, 0.9483240260092239, 0.9503632091277139, 0.9481959046598253, 0.949730985324476, 0.9496711043006215, 0.9509127885935693, 0.9461340021820708, 0.9486504543426982, 0.9508590821447319, 0.9492950865676283, 0.9473612621509829, 0.947505850365708, 0.9488673886107333, 0.949588453969476, 0.9486545927031746, 0.9475926330635668, 0.9503570119095914, 0.9496483393221594, 0.9504355108937738, 0.9502847078126236, 0.9504272418315184, 0.9502475088535074, 0.9505677589491093, 0.9497971238370714, 0.9495140733665595, 0.9499830603599548, 0.9510904550552368, 0.9473612328481408, 0.9478219897387414, 0.9501710577384054, 0.9488074832788392, 0.9474335545934113, 0.9500946132830401, 0.9510739305831867], 'val_mDice': [0.17407425039307364, 0.48125793647499726, 0.4684278440542061, 0.5564021231741879, 0.5691124267418292, 0.564363880530416, 0.546634008098581, 0.5628847962651173, 0.5166110146645061, 0.5544226039721313, 0.5570926006945818, 0.5799707117693385, 0.5644923292058807, 0.5763513648976161, 0.5800118982458914, 0.5898948951140462, 0.5817913063411606, 0.5887345951362695, 0.572107478893003, 0.5633335013629338, 0.5507343408115749, 0.5772353001147009, 0.5885579312979842, 0.5656436148968489, 0.5533689813240946, 0.5746216337774053, 0.5703127560668817, 0.5860054303147939, 0.5554163316108661, 0.5652511799135688, 0.5476300613174225, 0.5746649217339201, 0.5811719521463916, 0.563931116178715, 0.565936552412683, 0.577097110242151, 0.5723107543737529, 0.5593325901963857, 0.5404997604519295, 0.5802186501092751, 0.5781565947905599, 0.5764941200197742, 0.5691448843012975, 0.5734821967572473, 0.5637671614492406, 0.5733929885832291, 0.5663418699909188, 0.5559493486441713, 0.5921388458273265, 0.5808783293436359, 0.5682556023144855, 0.5812866128356763, 0.558652474893538, 0.5810074639719958, 0.5456408581920176, 0.5687841529952747, 0.5549784116238855, 0.5693122035298268, 0.5735858562272355, 0.5613884792647548, 0.5780476085300552, 0.5718267626602557, 0.5654677698732088, 0.5740797100120416, 0.5749051687437728, 0.5637901808296502, 0.5660013027031329, 0.5610602028543057, 0.5782936008948854, 0.5586648906409407, 0.5501013687869024, 0.5727457577289816, 0.5530366115063928, 0.5898199334490899, 0.5884694666835849, 0.5739332397556838, 0.5803501978932812, 0.5623244703148996, 0.5729210370079765, 0.5746866814251053, 0.5714182021231625, 0.5782582230408099, 0.5677815299460341, 0.5501415759491521, 0.5675464438992506, 0.5646940856006558, 0.5743881200944911, 0.5567897118669648, 0.5541579553534864], 'loss': [2.277888964232871, 0.8539449259136427, 0.6895838794050689, 0.5730331885039459, 0.5192854988354885, 0.4819405516614115, 0.4520669689099777, 0.430700987338838, 0.4166071421504962, 0.40305706509499306, 0.394377617015408, 0.3859002742055883, 0.37405110392868635, 0.365112224558354, 0.35656592030747514, 0.35079038733166357, 0.34638100819165435, 0.3419054118086262, 0.33532246839025626, 0.33877879037562814, 0.3296248373801682, 0.3256556552892988, 0.3210857019131106, 0.3170352704361642, 0.31524162651744453, 0.311581721563146, 0.30811515877036627, 0.30840839085986127, 0.30298874214722515, 0.29961055636334527, 0.2975110538199566, 0.2958959917796605, 0.2966929859591364, 0.2936559738978329, 0.29239650527010763, 0.29044196193536753, 0.28900803334474967, 0.2841278360865941, 0.28436163565794514, 0.28305612466095204, 0.2829261021308666, 0.27825885410077966, 0.2779364684286944, 0.27787633706629844, 0.2750746401188245, 0.27537077675392396, 0.2733131178576769, 0.271644465232894, 0.269608034743027, 0.2753172966284233, 0.2690555045667164, 0.26755867380279386, 0.26779355778523267, 0.26430392249575446, 0.2645048131468015, 0.264975641096257, 0.26165114974645765, 0.2618977313895844, 0.2616651991465325, 0.26160934665001695, 0.2580604959598041, 0.25987928809861743, 0.25766740634572394, 0.2553568027191683, 0.25650582792410165, 0.2561926712729327, 0.2554205378804498, 0.25350135292929504, 0.2550296354007178, 0.25213639567597074, 0.25319902672791533, 0.2514679482126864, 0.25207469859847015, 0.25023391144814283, 0.24967492752787165, 0.29032434398854884, 0.2591524657782539, 0.25290426366320495, 0.24970735063753347, 0.24772975607399042, 0.24686279007665382, 0.24664303403126375, 0.2460040716987687, 0.24730334391612632, 0.24450176663241882, 0.24423212826213028, 0.2452323400541222, 0.24565444690528943, 0.2435122887950325], 'acc': [0.6767138972441022, 0.8970852154810491, 0.9054620240704763, 0.9159047302873324, 0.9248153163024487, 0.9312822262378996, 0.9362596136364995, 0.9391425191450402, 0.9406530883348454, 0.9419409515070672, 0.9428916822090874, 0.943497423720278, 0.94443975560163, 0.9453844042114167, 0.9459175115304019, 0.9464927225758013, 0.9469109883619273, 0.9471983086971291, 0.947805968574771, 0.9476483969327172, 0.94820630095583, 0.9485760429288417, 0.9489998055740572, 0.9492827967246706, 0.9494835089529582, 0.9496292974115113, 0.9499939018900531, 0.9499865693338595, 0.9504857641193292, 0.9506903024587449, 0.9508657770007273, 0.9510083974534199, 0.9509901338027171, 0.9512547322474211, 0.9513722804466446, 0.9514628383927756, 0.9516289060681054, 0.9519941378708441, 0.9520159100442208, 0.95214658928855, 0.9521439929983921, 0.9523856128056152, 0.9525342357651444, 0.9524958290070025, 0.9527997460722903, 0.9526737585260447, 0.9527943900588369, 0.9529259961860695, 0.9532122283153015, 0.9528653061563274, 0.9533071569527464, 0.9533585591530737, 0.9533736639069313, 0.9535249322433694, 0.9535265598679659, 0.953603321294705, 0.9538042950062741, 0.9538582758305931, 0.9538524548385822, 0.9539326987854244, 0.9541211829168086, 0.9538906235579578, 0.9541106506322673, 0.9543075761330958, 0.9542163961249611, 0.954218529695961, 0.9543645189943465, 0.9544976723881681, 0.9543352128795715, 0.95461852690031, 0.9544647035661862, 0.9545559649613939, 0.954479246034737, 0.9548037475532232, 0.9547523273263945, 0.9512753780679852, 0.9540938725594076, 0.9546239220279928, 0.9547927491182232, 0.9549373293726748, 0.9550641215053378, 0.955055056820832, 0.955112036407062, 0.9550408979437657, 0.9551194304669646, 0.9552674310982964, 0.9551542371285844, 0.9551748194002935, 0.9552772000661688], 'mDice': [0.17478866116154668, 0.4181497375544792, 0.4928297939062132, 0.5513353788198894, 0.5817503227685559, 0.6038078328933496, 0.6219882732395721, 0.6357491732351362, 0.6448144785433734, 0.6540465106450423, 0.660206291032288, 0.6654606742813699, 0.673588766702269, 0.6797501093473487, 0.6856735101530972, 0.6899056903748891, 0.6930325615056089, 0.6962624262194833, 0.7009677840346547, 0.6989851846433167, 0.7051692304869089, 0.7081949019489202, 0.7112846656644483, 0.7144017250545274, 0.7157898519619715, 0.7184528204735234, 0.7210475092788361, 0.7208027933477661, 0.724979106322021, 0.7274537923113855, 0.728975526187085, 0.7302033171194856, 0.7297739777928065, 0.7319847211216564, 0.7329666677250283, 0.7345443430351254, 0.7355494762608367, 0.7392739597621758, 0.7390925000873593, 0.7401613460361786, 0.7402833249079273, 0.7437321129632628, 0.7440629821380469, 0.7440892540449593, 0.746255907128887, 0.7460737017516276, 0.7475436919720161, 0.7488875026783648, 0.7505512028099904, 0.7463658007230967, 0.7510768556626013, 0.7521103937494347, 0.7519986621240574, 0.7545760932730132, 0.7545120873960767, 0.7541673584874111, 0.7567681048334661, 0.7565101608394583, 0.7567271016520695, 0.7568616887581815, 0.759537174797001, 0.7581758825265142, 0.7598320685708895, 0.761721470975894, 0.7607703093064194, 0.7610727416443854, 0.761731943340903, 0.7631944757285418, 0.7619403580987929, 0.7642662981861356, 0.7634641131858187, 0.7647856018309642, 0.7643343392400647, 0.7657896779856191, 0.766241409888838, 0.7377624439521849, 0.7588628424349502, 0.7637132289369254, 0.7662412010794287, 0.7678475629451663, 0.7685228522992148, 0.7687377160939832, 0.7692808380061249, 0.7683526547696166, 0.7703950886411881, 0.7706629114371487, 0.7698559390518843, 0.7695463956340545, 0.7711906816781356]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.01s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:05<00:02,  2.79s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.65s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<14:10,  2.99s/it]predicting train subjects:   1%|          | 2/285 [00:05<13:16,  2.81s/it]predicting train subjects:   1%|          | 3/285 [00:07<12:25,  2.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:09<11:06,  2.37s/it]predicting train subjects:   2%|▏         | 5/285 [00:11<10:44,  2.30s/it]predicting train subjects:   2%|▏         | 6/285 [00:13<09:52,  2.12s/it]predicting train subjects:   2%|▏         | 7/285 [00:15<10:21,  2.24s/it]predicting train subjects:   3%|▎         | 8/285 [00:18<11:00,  2.38s/it]predicting train subjects:   3%|▎         | 9/285 [00:21<11:49,  2.57s/it]predicting train subjects:   4%|▎         | 10/285 [00:24<12:42,  2.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:26<11:55,  2.61s/it]predicting train subjects:   4%|▍         | 12/285 [00:29<11:24,  2.51s/it]predicting train subjects:   5%|▍         | 13/285 [00:31<10:38,  2.35s/it]predicting train subjects:   5%|▍         | 14/285 [00:33<10:18,  2.28s/it]predicting train subjects:   5%|▌         | 15/285 [00:36<11:10,  2.48s/it]predicting train subjects:   6%|▌         | 16/285 [00:39<12:05,  2.70s/it]predicting train subjects:   6%|▌         | 17/285 [00:42<11:53,  2.66s/it]predicting train subjects:   6%|▋         | 18/285 [00:45<12:26,  2.80s/it]predicting train subjects:   7%|▋         | 19/285 [00:47<11:17,  2.55s/it]predicting train subjects:   7%|▋         | 20/285 [00:49<10:38,  2.41s/it]predicting train subjects:   7%|▋         | 21/285 [00:51<10:29,  2.38s/it]predicting train subjects:   8%|▊         | 22/285 [00:53<09:54,  2.26s/it]predicting train subjects:   8%|▊         | 23/285 [00:56<10:48,  2.48s/it]predicting train subjects:   8%|▊         | 24/285 [00:59<10:55,  2.51s/it]predicting train subjects:   9%|▉         | 25/285 [01:02<11:41,  2.70s/it]predicting train subjects:   9%|▉         | 26/285 [01:05<12:13,  2.83s/it]predicting train subjects:   9%|▉         | 27/285 [01:07<10:59,  2.56s/it]predicting train subjects:  10%|▉         | 28/285 [01:09<10:23,  2.43s/it]predicting train subjects:  10%|█         | 29/285 [01:11<09:57,  2.33s/it]predicting train subjects:  11%|█         | 30/285 [01:14<10:18,  2.42s/it]predicting train subjects:  11%|█         | 31/285 [01:17<11:08,  2.63s/it]predicting train subjects:  11%|█         | 32/285 [01:20<11:16,  2.67s/it]predicting train subjects:  12%|█▏        | 33/285 [01:23<11:38,  2.77s/it]predicting train subjects:  12%|█▏        | 34/285 [01:25<11:35,  2.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:28<11:08,  2.67s/it]predicting train subjects:  13%|█▎        | 36/285 [01:30<10:17,  2.48s/it]predicting train subjects:  13%|█▎        | 37/285 [01:32<09:46,  2.37s/it]predicting train subjects:  13%|█▎        | 38/285 [01:35<10:24,  2.53s/it]predicting train subjects:  14%|█▎        | 39/285 [01:37<10:22,  2.53s/it]predicting train subjects:  14%|█▍        | 40/285 [01:40<10:36,  2.60s/it]predicting train subjects:  14%|█▍        | 41/285 [01:43<10:38,  2.62s/it]predicting train subjects:  15%|█▍        | 42/285 [01:45<09:57,  2.46s/it]predicting train subjects:  15%|█▌        | 43/285 [01:47<09:25,  2.34s/it]predicting train subjects:  15%|█▌        | 44/285 [01:49<09:19,  2.32s/it]predicting train subjects:  16%|█▌        | 45/285 [01:51<08:51,  2.21s/it]predicting train subjects:  16%|█▌        | 46/285 [01:54<09:42,  2.44s/it]predicting train subjects:  16%|█▋        | 47/285 [01:57<09:57,  2.51s/it]predicting train subjects:  17%|█▋        | 48/285 [01:59<10:07,  2.56s/it]predicting train subjects:  17%|█▋        | 49/285 [02:03<10:50,  2.76s/it]predicting train subjects:  18%|█▊        | 50/285 [02:05<10:17,  2.63s/it]predicting train subjects:  18%|█▊        | 51/285 [02:07<09:57,  2.55s/it]predicting train subjects:  18%|█▊        | 52/285 [02:09<09:09,  2.36s/it]predicting train subjects:  19%|█▊        | 53/285 [02:11<08:56,  2.31s/it]predicting train subjects:  19%|█▉        | 54/285 [02:14<09:43,  2.53s/it]predicting train subjects:  19%|█▉        | 55/285 [02:17<09:58,  2.60s/it]predicting train subjects:  20%|█▉        | 56/285 [02:20<10:12,  2.67s/it]predicting train subjects:  20%|██        | 57/285 [02:23<10:20,  2.72s/it]predicting train subjects:  20%|██        | 58/285 [02:25<09:42,  2.57s/it]predicting train subjects:  21%|██        | 59/285 [02:28<09:28,  2.52s/it]predicting train subjects:  21%|██        | 60/285 [02:30<09:19,  2.49s/it]predicting train subjects:  21%|██▏       | 61/285 [02:32<08:55,  2.39s/it]predicting train subjects:  22%|██▏       | 62/285 [02:35<09:17,  2.50s/it]predicting train subjects:  22%|██▏       | 63/285 [02:38<09:41,  2.62s/it]predicting train subjects:  22%|██▏       | 64/285 [02:41<09:46,  2.65s/it]predicting train subjects:  23%|██▎       | 65/285 [02:44<10:07,  2.76s/it]predicting train subjects:  23%|██▎       | 66/285 [02:46<09:21,  2.56s/it]predicting train subjects:  24%|██▎       | 67/285 [02:48<08:56,  2.46s/it]predicting train subjects:  24%|██▍       | 68/285 [02:50<08:55,  2.47s/it]predicting train subjects:  24%|██▍       | 69/285 [02:53<09:20,  2.60s/it]predicting train subjects:  25%|██▍       | 70/285 [02:56<09:58,  2.78s/it]predicting train subjects:  25%|██▍       | 71/285 [03:00<11:06,  3.11s/it]predicting train subjects:  25%|██▌       | 72/285 [03:03<10:58,  3.09s/it]predicting train subjects:  26%|██▌       | 73/285 [03:06<10:23,  2.94s/it]predicting train subjects:  26%|██▌       | 74/285 [03:08<09:50,  2.80s/it]predicting train subjects:  26%|██▋       | 75/285 [03:11<09:36,  2.74s/it]predicting train subjects:  27%|██▋       | 76/285 [03:14<09:42,  2.78s/it]predicting train subjects:  27%|██▋       | 77/285 [03:17<09:50,  2.84s/it]predicting train subjects:  27%|██▋       | 78/285 [03:20<10:11,  2.95s/it]predicting train subjects:  28%|██▊       | 79/285 [03:23<10:27,  3.05s/it]predicting train subjects:  28%|██▊       | 80/285 [03:26<10:24,  3.04s/it]predicting train subjects:  28%|██▊       | 81/285 [03:29<09:49,  2.89s/it]predicting train subjects:  29%|██▉       | 82/285 [03:31<09:14,  2.73s/it]predicting train subjects:  29%|██▉       | 83/285 [03:34<08:49,  2.62s/it]predicting train subjects:  29%|██▉       | 84/285 [03:36<08:46,  2.62s/it]predicting train subjects:  30%|██▉       | 85/285 [03:40<09:33,  2.87s/it]predicting train subjects:  30%|███       | 86/285 [03:43<09:42,  2.93s/it]predicting train subjects:  31%|███       | 87/285 [03:46<09:53,  3.00s/it]predicting train subjects:  31%|███       | 88/285 [03:48<09:10,  2.79s/it]predicting train subjects:  31%|███       | 89/285 [03:50<08:30,  2.61s/it]predicting train subjects:  32%|███▏      | 90/285 [03:53<08:10,  2.51s/it]predicting train subjects:  32%|███▏      | 91/285 [03:55<07:50,  2.43s/it]predicting train subjects:  32%|███▏      | 92/285 [03:58<08:24,  2.61s/it]predicting train subjects:  33%|███▎      | 93/285 [04:01<08:48,  2.75s/it]predicting train subjects:  33%|███▎      | 94/285 [04:04<08:46,  2.76s/it]predicting train subjects:  33%|███▎      | 95/285 [04:07<08:50,  2.79s/it]predicting train subjects:  34%|███▎      | 96/285 [04:09<08:26,  2.68s/it]predicting train subjects:  34%|███▍      | 97/285 [04:11<08:03,  2.57s/it]predicting train subjects:  34%|███▍      | 98/285 [04:14<07:58,  2.56s/it]predicting train subjects:  35%|███▍      | 99/285 [04:17<08:07,  2.62s/it]predicting train subjects:  35%|███▌      | 100/285 [04:20<08:35,  2.78s/it]predicting train subjects:  35%|███▌      | 101/285 [04:23<08:47,  2.87s/it]predicting train subjects:  36%|███▌      | 102/285 [04:27<09:24,  3.08s/it]predicting train subjects:  36%|███▌      | 103/285 [04:29<08:52,  2.92s/it]predicting train subjects:  36%|███▋      | 104/285 [04:32<08:31,  2.82s/it]predicting train subjects:  37%|███▋      | 105/285 [04:34<07:54,  2.64s/it]predicting train subjects:  37%|███▋      | 106/285 [04:36<07:44,  2.60s/it]predicting train subjects:  38%|███▊      | 107/285 [04:39<07:46,  2.62s/it]predicting train subjects:  38%|███▊      | 108/285 [04:42<07:46,  2.64s/it]predicting train subjects:  38%|███▊      | 109/285 [04:45<07:50,  2.67s/it]predicting train subjects:  39%|███▊      | 110/285 [04:47<07:42,  2.64s/it]predicting train subjects:  39%|███▉      | 111/285 [04:49<07:21,  2.54s/it]predicting train subjects:  39%|███▉      | 112/285 [04:52<06:57,  2.41s/it]predicting train subjects:  40%|███▉      | 113/285 [04:54<06:41,  2.34s/it]predicting train subjects:  40%|████      | 114/285 [04:56<06:27,  2.26s/it]predicting train subjects:  40%|████      | 115/285 [04:58<06:30,  2.30s/it]predicting train subjects:  41%|████      | 116/285 [05:01<06:53,  2.45s/it]predicting train subjects:  41%|████      | 117/285 [05:03<06:51,  2.45s/it]predicting train subjects:  41%|████▏     | 118/285 [05:06<06:50,  2.46s/it]predicting train subjects:  42%|████▏     | 119/285 [05:08<06:51,  2.48s/it]predicting train subjects:  42%|████▏     | 120/285 [05:10<06:20,  2.31s/it]predicting train subjects:  42%|████▏     | 121/285 [05:12<05:58,  2.19s/it]predicting train subjects:  43%|████▎     | 122/285 [05:14<05:31,  2.03s/it]predicting train subjects:  43%|████▎     | 123/285 [05:16<05:13,  1.94s/it]predicting train subjects:  44%|████▎     | 124/285 [05:18<05:17,  1.97s/it]predicting train subjects:  44%|████▍     | 125/285 [05:20<05:17,  1.98s/it]predicting train subjects:  44%|████▍     | 126/285 [05:22<05:08,  1.94s/it]predicting train subjects:  45%|████▍     | 127/285 [05:23<05:04,  1.93s/it]predicting train subjects:  45%|████▍     | 128/285 [05:26<05:20,  2.04s/it]predicting train subjects:  45%|████▌     | 129/285 [05:28<05:16,  2.03s/it]predicting train subjects:  46%|████▌     | 130/285 [05:29<04:59,  1.93s/it]predicting train subjects:  46%|████▌     | 131/285 [05:31<04:52,  1.90s/it]predicting train subjects:  46%|████▋     | 132/285 [05:33<04:47,  1.88s/it]predicting train subjects:  47%|████▋     | 133/285 [05:35<04:36,  1.82s/it]predicting train subjects:  47%|████▋     | 134/285 [05:37<04:37,  1.84s/it]predicting train subjects:  47%|████▋     | 135/285 [05:39<04:44,  1.89s/it]predicting train subjects:  48%|████▊     | 136/285 [05:41<04:45,  1.92s/it]predicting train subjects:  48%|████▊     | 137/285 [05:43<05:00,  2.03s/it]predicting train subjects:  48%|████▊     | 138/285 [05:45<04:55,  2.01s/it]predicting train subjects:  49%|████▉     | 139/285 [05:47<05:01,  2.07s/it]predicting train subjects:  49%|████▉     | 140/285 [05:49<04:53,  2.02s/it]predicting train subjects:  49%|████▉     | 141/285 [05:51<04:35,  1.92s/it]predicting train subjects:  50%|████▉     | 142/285 [05:52<04:27,  1.87s/it]predicting train subjects:  50%|█████     | 143/285 [05:54<04:15,  1.80s/it]predicting train subjects:  51%|█████     | 144/285 [05:56<04:30,  1.92s/it]predicting train subjects:  51%|█████     | 145/285 [05:58<04:40,  2.00s/it]predicting train subjects:  51%|█████     | 146/285 [06:01<04:53,  2.11s/it]predicting train subjects:  52%|█████▏    | 147/285 [06:03<04:45,  2.07s/it]predicting train subjects:  52%|█████▏    | 148/285 [06:05<04:46,  2.09s/it]predicting train subjects:  52%|█████▏    | 149/285 [06:07<04:33,  2.01s/it]predicting train subjects:  53%|█████▎    | 150/285 [06:08<04:16,  1.90s/it]predicting train subjects:  53%|█████▎    | 151/285 [06:10<04:12,  1.88s/it]predicting train subjects:  53%|█████▎    | 152/285 [06:12<04:07,  1.86s/it]predicting train subjects:  54%|█████▎    | 153/285 [06:14<03:55,  1.78s/it]predicting train subjects:  54%|█████▍    | 154/285 [06:16<04:11,  1.92s/it]predicting train subjects:  54%|█████▍    | 155/285 [06:18<04:15,  1.97s/it]predicting train subjects:  55%|█████▍    | 156/285 [06:20<04:26,  2.06s/it]predicting train subjects:  55%|█████▌    | 157/285 [06:22<04:22,  2.05s/it]predicting train subjects:  55%|█████▌    | 158/285 [06:24<04:24,  2.09s/it]predicting train subjects:  56%|█████▌    | 159/285 [06:26<04:05,  1.95s/it]predicting train subjects:  56%|█████▌    | 160/285 [06:28<03:55,  1.89s/it]predicting train subjects:  56%|█████▋    | 161/285 [06:30<03:55,  1.90s/it]predicting train subjects:  57%|█████▋    | 162/285 [06:31<03:44,  1.82s/it]predicting train subjects:  57%|█████▋    | 163/285 [06:33<03:49,  1.88s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:35<03:52,  1.92s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:37<03:47,  1.90s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:40<03:58,  2.00s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:42<04:11,  2.13s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:44<03:55,  2.02s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:45<03:43,  1.93s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:47<03:35,  1.87s/it]predicting train subjects:  60%|██████    | 171/285 [06:49<03:28,  1.83s/it]predicting train subjects:  60%|██████    | 172/285 [06:51<03:23,  1.80s/it]predicting train subjects:  61%|██████    | 173/285 [06:53<03:28,  1.87s/it]predicting train subjects:  61%|██████    | 174/285 [06:55<03:37,  1.96s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:57<03:44,  2.04s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:59<03:52,  2.13s/it]predicting train subjects:  62%|██████▏   | 177/285 [07:02<03:49,  2.13s/it]predicting train subjects:  62%|██████▏   | 178/285 [07:03<03:36,  2.03s/it]predicting train subjects:  63%|██████▎   | 179/285 [07:05<03:23,  1.92s/it]predicting train subjects:  63%|██████▎   | 180/285 [07:07<03:30,  2.00s/it]predicting train subjects:  64%|██████▎   | 181/285 [07:09<03:31,  2.03s/it]predicting train subjects:  64%|██████▍   | 182/285 [07:11<03:32,  2.06s/it]predicting train subjects:  64%|██████▍   | 183/285 [07:13<03:23,  2.00s/it]predicting train subjects:  65%|██████▍   | 184/285 [07:15<03:25,  2.04s/it]predicting train subjects:  65%|██████▍   | 185/285 [07:17<03:19,  2.00s/it]predicting train subjects:  65%|██████▌   | 186/285 [07:20<03:33,  2.15s/it]predicting train subjects:  66%|██████▌   | 187/285 [07:22<03:42,  2.27s/it]predicting train subjects:  66%|██████▌   | 188/285 [07:24<03:34,  2.21s/it]predicting train subjects:  66%|██████▋   | 189/285 [07:26<03:17,  2.05s/it]predicting train subjects:  67%|██████▋   | 190/285 [07:28<03:03,  1.93s/it]predicting train subjects:  67%|██████▋   | 191/285 [07:30<03:02,  1.94s/it]predicting train subjects:  67%|██████▋   | 192/285 [07:32<03:08,  2.03s/it]predicting train subjects:  68%|██████▊   | 193/285 [07:34<03:08,  2.05s/it]predicting train subjects:  68%|██████▊   | 194/285 [07:36<03:09,  2.08s/it]predicting train subjects:  68%|██████▊   | 195/285 [07:38<03:06,  2.07s/it]predicting train subjects:  69%|██████▉   | 196/285 [07:41<03:20,  2.25s/it]predicting train subjects:  69%|██████▉   | 197/285 [07:43<03:12,  2.19s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:45<03:06,  2.14s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:47<02:50,  1.98s/it]predicting train subjects:  70%|███████   | 200/285 [07:48<02:39,  1.88s/it]predicting train subjects:  71%|███████   | 201/285 [07:51<02:51,  2.04s/it]predicting train subjects:  71%|███████   | 202/285 [07:53<02:55,  2.11s/it]predicting train subjects:  71%|███████   | 203/285 [07:55<03:02,  2.23s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:57<02:53,  2.14s/it]predicting train subjects:  72%|███████▏  | 205/285 [08:00<02:55,  2.19s/it]predicting train subjects:  72%|███████▏  | 206/285 [08:01<02:39,  2.02s/it]predicting train subjects:  73%|███████▎  | 207/285 [08:04<02:43,  2.09s/it]predicting train subjects:  73%|███████▎  | 208/285 [08:06<02:40,  2.08s/it]predicting train subjects:  73%|███████▎  | 209/285 [08:08<02:43,  2.15s/it]predicting train subjects:  74%|███████▎  | 210/285 [08:10<02:34,  2.06s/it]predicting train subjects:  74%|███████▍  | 211/285 [08:12<02:30,  2.04s/it]predicting train subjects:  74%|███████▍  | 212/285 [08:14<02:35,  2.13s/it]predicting train subjects:  75%|███████▍  | 213/285 [08:16<02:36,  2.18s/it]predicting train subjects:  75%|███████▌  | 214/285 [08:18<02:31,  2.13s/it]predicting train subjects:  75%|███████▌  | 215/285 [08:21<02:28,  2.12s/it]predicting train subjects:  76%|███████▌  | 216/285 [08:22<02:17,  1.99s/it]predicting train subjects:  76%|███████▌  | 217/285 [08:24<02:17,  2.03s/it]predicting train subjects:  76%|███████▋  | 218/285 [08:27<02:21,  2.11s/it]predicting train subjects:  77%|███████▋  | 219/285 [08:29<02:23,  2.18s/it]predicting train subjects:  77%|███████▋  | 220/285 [08:31<02:18,  2.13s/it]predicting train subjects:  78%|███████▊  | 221/285 [08:33<02:13,  2.09s/it]predicting train subjects:  78%|███████▊  | 222/285 [08:35<02:14,  2.14s/it]predicting train subjects:  78%|███████▊  | 223/285 [08:37<02:10,  2.11s/it]predicting train subjects:  79%|███████▊  | 224/285 [08:39<02:00,  1.97s/it]predicting train subjects:  79%|███████▉  | 225/285 [08:41<01:52,  1.87s/it]predicting train subjects:  79%|███████▉  | 226/285 [08:43<01:56,  1.97s/it]predicting train subjects:  80%|███████▉  | 227/285 [08:45<01:56,  2.02s/it]predicting train subjects:  80%|████████  | 228/285 [08:47<02:00,  2.11s/it]predicting train subjects:  80%|████████  | 229/285 [08:49<02:00,  2.15s/it]predicting train subjects:  81%|████████  | 230/285 [08:51<01:55,  2.10s/it]predicting train subjects:  81%|████████  | 231/285 [08:53<01:51,  2.07s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:56<01:54,  2.16s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:57<01:43,  1.99s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:59<01:41,  1.99s/it]predicting train subjects:  82%|████████▏ | 235/285 [09:01<01:33,  1.88s/it]predicting train subjects:  83%|████████▎ | 236/285 [09:03<01:34,  1.93s/it]predicting train subjects:  83%|████████▎ | 237/285 [09:05<01:38,  2.06s/it]predicting train subjects:  84%|████████▎ | 238/285 [09:08<01:42,  2.17s/it]predicting train subjects:  84%|████████▍ | 239/285 [09:10<01:43,  2.25s/it]predicting train subjects:  84%|████████▍ | 240/285 [09:12<01:36,  2.14s/it]predicting train subjects:  85%|████████▍ | 241/285 [09:14<01:35,  2.18s/it]predicting train subjects:  85%|████████▍ | 242/285 [09:16<01:26,  2.02s/it]predicting train subjects:  85%|████████▌ | 243/285 [09:18<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [09:20<01:20,  1.97s/it]predicting train subjects:  86%|████████▌ | 245/285 [09:22<01:15,  1.88s/it]predicting train subjects:  86%|████████▋ | 246/285 [09:24<01:19,  2.05s/it]predicting train subjects:  87%|████████▋ | 247/285 [09:26<01:22,  2.18s/it]predicting train subjects:  87%|████████▋ | 248/285 [09:29<01:22,  2.24s/it]predicting train subjects:  87%|████████▋ | 249/285 [09:31<01:18,  2.18s/it]predicting train subjects:  88%|████████▊ | 250/285 [09:33<01:15,  2.17s/it]predicting train subjects:  88%|████████▊ | 251/285 [09:35<01:08,  2.02s/it]predicting train subjects:  88%|████████▊ | 252/285 [09:36<01:03,  1.92s/it]predicting train subjects:  89%|████████▉ | 253/285 [09:38<01:03,  1.98s/it]predicting train subjects:  89%|████████▉ | 254/285 [09:41<01:02,  2.01s/it]predicting train subjects:  89%|████████▉ | 255/285 [09:43<01:02,  2.08s/it]predicting train subjects:  90%|████████▉ | 256/285 [09:45<00:59,  2.05s/it]predicting train subjects:  90%|█████████ | 257/285 [09:47<00:57,  2.05s/it]predicting train subjects:  91%|█████████ | 258/285 [09:49<00:58,  2.15s/it]predicting train subjects:  91%|█████████ | 259/285 [09:52<00:57,  2.20s/it]predicting train subjects:  91%|█████████ | 260/285 [09:53<00:51,  2.04s/it]predicting train subjects:  92%|█████████▏| 261/285 [09:55<00:46,  1.94s/it]predicting train subjects:  92%|█████████▏| 262/285 [09:57<00:42,  1.87s/it]predicting train subjects:  92%|█████████▏| 263/285 [09:58<00:39,  1.81s/it]predicting train subjects:  93%|█████████▎| 264/285 [10:01<00:41,  2.00s/it]predicting train subjects:  93%|█████████▎| 265/285 [10:03<00:42,  2.12s/it]predicting train subjects:  93%|█████████▎| 266/285 [10:05<00:39,  2.07s/it]predicting train subjects:  94%|█████████▎| 267/285 [10:07<00:36,  2.05s/it]predicting train subjects:  94%|█████████▍| 268/285 [10:10<00:37,  2.20s/it]predicting train subjects:  94%|█████████▍| 269/285 [10:12<00:34,  2.16s/it]predicting train subjects:  95%|█████████▍| 270/285 [10:13<00:29,  2.00s/it]predicting train subjects:  95%|█████████▌| 271/285 [10:15<00:26,  1.87s/it]predicting train subjects:  95%|█████████▌| 272/285 [10:17<00:24,  1.88s/it]predicting train subjects:  96%|█████████▌| 273/285 [10:18<00:21,  1.80s/it]predicting train subjects:  96%|█████████▌| 274/285 [10:20<00:20,  1.82s/it]predicting train subjects:  96%|█████████▋| 275/285 [10:23<00:20,  2.07s/it]predicting train subjects:  97%|█████████▋| 276/285 [10:25<00:19,  2.20s/it]predicting train subjects:  97%|█████████▋| 277/285 [10:27<00:17,  2.15s/it]predicting train subjects:  98%|█████████▊| 278/285 [10:30<00:14,  2.13s/it]predicting train subjects:  98%|█████████▊| 279/285 [10:31<00:12,  2.07s/it]predicting train subjects:  98%|█████████▊| 280/285 [10:33<00:09,  1.97s/it]predicting train subjects:  99%|█████████▊| 281/285 [10:35<00:07,  1.91s/it]predicting train subjects:  99%|█████████▉| 282/285 [10:37<00:05,  1.84s/it]predicting train subjects:  99%|█████████▉| 283/285 [10:39<00:03,  2.00s/it]predicting train subjects: 100%|█████████▉| 284/285 [10:42<00:02,  2.18s/it]predicting train subjects: 100%|██████████| 285/285 [10:44<00:00,  2.26s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:24,  1.99s/it]Loading train:   1%|          | 2/285 [00:03<08:38,  1.83s/it]Loading train:   1%|          | 3/285 [00:05<08:26,  1.80s/it]Loading train:   1%|▏         | 4/285 [00:06<07:51,  1.68s/it]Loading train:   2%|▏         | 5/285 [00:08<07:54,  1.70s/it]Loading train:   2%|▏         | 6/285 [00:10<07:53,  1.70s/it]Loading train:   2%|▏         | 7/285 [00:11<07:51,  1.69s/it]Loading train:   3%|▎         | 8/285 [00:13<07:46,  1.68s/it]Loading train:   3%|▎         | 9/285 [00:15<08:33,  1.86s/it]Loading train:   4%|▎         | 10/285 [00:17<08:00,  1.75s/it]Loading train:   4%|▍         | 11/285 [00:18<07:24,  1.62s/it]Loading train:   4%|▍         | 12/285 [00:19<07:17,  1.60s/it]Loading train:   5%|▍         | 13/285 [00:21<07:34,  1.67s/it]Loading train:   5%|▍         | 14/285 [00:23<07:04,  1.57s/it]Loading train:   5%|▌         | 15/285 [00:24<06:31,  1.45s/it]Loading train:   6%|▌         | 16/285 [00:25<06:16,  1.40s/it]Loading train:   6%|▌         | 17/285 [00:26<06:01,  1.35s/it]Loading train:   6%|▋         | 18/285 [00:28<05:53,  1.32s/it]Loading train:   7%|▋         | 19/285 [00:29<05:26,  1.23s/it]Loading train:   7%|▋         | 20/285 [00:30<05:19,  1.21s/it]Loading train:   7%|▋         | 21/285 [00:31<05:25,  1.23s/it]Loading train:   8%|▊         | 22/285 [00:32<05:02,  1.15s/it]Loading train:   8%|▊         | 23/285 [00:34<05:29,  1.26s/it]Loading train:   8%|▊         | 24/285 [00:35<05:24,  1.24s/it]Loading train:   9%|▉         | 25/285 [00:36<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:38<05:53,  1.37s/it]Loading train:   9%|▉         | 27/285 [00:39<05:40,  1.32s/it]Loading train:  10%|▉         | 28/285 [00:40<05:53,  1.37s/it]Loading train:  10%|█         | 29/285 [00:42<05:38,  1.32s/it]Loading train:  11%|█         | 30/285 [00:43<05:44,  1.35s/it]Loading train:  11%|█         | 31/285 [00:44<05:35,  1.32s/it]Loading train:  11%|█         | 32/285 [00:46<05:29,  1.30s/it]Loading train:  12%|█▏        | 33/285 [00:47<05:26,  1.30s/it]Loading train:  12%|█▏        | 34/285 [00:48<05:17,  1.26s/it]Loading train:  12%|█▏        | 35/285 [00:50<05:56,  1.43s/it]Loading train:  13%|█▎        | 36/285 [00:51<05:27,  1.32s/it]Loading train:  13%|█▎        | 37/285 [00:53<05:58,  1.45s/it]Loading train:  13%|█▎        | 38/285 [00:54<05:49,  1.42s/it]Loading train:  14%|█▎        | 39/285 [00:55<05:41,  1.39s/it]Loading train:  14%|█▍        | 40/285 [00:57<05:27,  1.34s/it]Loading train:  14%|█▍        | 41/285 [00:58<05:12,  1.28s/it]Loading train:  15%|█▍        | 42/285 [00:59<04:58,  1.23s/it]Loading train:  15%|█▌        | 43/285 [01:00<05:07,  1.27s/it]Loading train:  15%|█▌        | 44/285 [01:02<05:22,  1.34s/it]Loading train:  16%|█▌        | 45/285 [01:03<05:27,  1.37s/it]Loading train:  16%|█▌        | 46/285 [01:04<05:25,  1.36s/it]Loading train:  16%|█▋        | 47/285 [01:05<04:57,  1.25s/it]Loading train:  17%|█▋        | 48/285 [01:07<04:56,  1.25s/it]Loading train:  17%|█▋        | 49/285 [01:08<05:09,  1.31s/it]Loading train:  18%|█▊        | 50/285 [01:09<05:06,  1.30s/it]Loading train:  18%|█▊        | 51/285 [01:11<05:06,  1.31s/it]Loading train:  18%|█▊        | 52/285 [01:12<05:01,  1.29s/it]Loading train:  19%|█▊        | 53/285 [01:13<04:58,  1.29s/it]Loading train:  19%|█▉        | 54/285 [01:15<05:11,  1.35s/it]Loading train:  19%|█▉        | 55/285 [01:16<05:03,  1.32s/it]Loading train:  20%|█▉        | 56/285 [01:18<05:24,  1.42s/it]Loading train:  20%|██        | 57/285 [01:19<05:13,  1.38s/it]Loading train:  20%|██        | 58/285 [01:20<05:01,  1.33s/it]Loading train:  21%|██        | 59/285 [01:22<05:44,  1.53s/it]Loading train:  21%|██        | 60/285 [01:24<06:02,  1.61s/it]Loading train:  21%|██▏       | 61/285 [01:25<05:35,  1.50s/it]Loading train:  22%|██▏       | 62/285 [01:27<05:46,  1.56s/it]Loading train:  22%|██▏       | 63/285 [01:28<05:23,  1.46s/it]Loading train:  22%|██▏       | 64/285 [01:30<05:20,  1.45s/it]Loading train:  23%|██▎       | 65/285 [01:31<05:26,  1.48s/it]Loading train:  23%|██▎       | 66/285 [01:33<06:02,  1.66s/it]Loading train:  24%|██▎       | 67/285 [01:34<05:36,  1.54s/it]Loading train:  24%|██▍       | 68/285 [01:36<05:16,  1.46s/it]Loading train:  24%|██▍       | 69/285 [01:37<05:15,  1.46s/it]Loading train:  25%|██▍       | 70/285 [01:39<05:08,  1.44s/it]Loading train:  25%|██▍       | 71/285 [01:40<05:12,  1.46s/it]Loading train:  25%|██▌       | 72/285 [01:42<05:14,  1.48s/it]Loading train:  26%|██▌       | 73/285 [01:43<05:15,  1.49s/it]Loading train:  26%|██▌       | 74/285 [01:44<05:05,  1.45s/it]Loading train:  26%|██▋       | 75/285 [01:46<05:06,  1.46s/it]Loading train:  27%|██▋       | 76/285 [01:47<05:08,  1.47s/it]Loading train:  27%|██▋       | 77/285 [01:49<05:12,  1.50s/it]Loading train:  27%|██▋       | 78/285 [01:50<04:42,  1.37s/it]Loading train:  28%|██▊       | 79/285 [01:51<04:23,  1.28s/it]Loading train:  28%|██▊       | 80/285 [01:53<04:35,  1.34s/it]Loading train:  28%|██▊       | 81/285 [01:54<04:28,  1.32s/it]Loading train:  29%|██▉       | 82/285 [01:55<04:28,  1.32s/it]Loading train:  29%|██▉       | 83/285 [01:56<04:05,  1.21s/it]Loading train:  29%|██▉       | 84/285 [01:57<03:37,  1.08s/it]Loading train:  30%|██▉       | 85/285 [01:58<03:30,  1.05s/it]Loading train:  30%|███       | 86/285 [01:59<03:39,  1.10s/it]Loading train:  31%|███       | 87/285 [02:01<03:57,  1.20s/it]Loading train:  31%|███       | 88/285 [02:02<04:12,  1.28s/it]Loading train:  31%|███       | 89/285 [02:04<04:34,  1.40s/it]Loading train:  32%|███▏      | 90/285 [02:05<04:34,  1.41s/it]Loading train:  32%|███▏      | 91/285 [02:06<04:16,  1.32s/it]Loading train:  32%|███▏      | 92/285 [02:08<04:21,  1.35s/it]Loading train:  33%|███▎      | 93/285 [02:09<04:08,  1.29s/it]Loading train:  33%|███▎      | 94/285 [02:11<04:33,  1.43s/it]Loading train:  33%|███▎      | 95/285 [02:12<04:27,  1.41s/it]Loading train:  34%|███▎      | 96/285 [02:13<04:26,  1.41s/it]Loading train:  34%|███▍      | 97/285 [02:15<04:23,  1.40s/it]Loading train:  34%|███▍      | 98/285 [02:16<04:02,  1.30s/it]Loading train:  35%|███▍      | 99/285 [02:17<03:51,  1.24s/it]Loading train:  35%|███▌      | 100/285 [02:18<04:02,  1.31s/it]Loading train:  35%|███▌      | 101/285 [02:20<03:58,  1.30s/it]Loading train:  36%|███▌      | 102/285 [02:21<04:11,  1.37s/it]Loading train:  36%|███▌      | 103/285 [02:22<03:42,  1.22s/it]Loading train:  36%|███▋      | 104/285 [02:23<03:48,  1.26s/it]Loading train:  37%|███▋      | 105/285 [02:25<03:59,  1.33s/it]Loading train:  37%|███▋      | 106/285 [02:26<03:49,  1.28s/it]Loading train:  38%|███▊      | 107/285 [02:27<03:53,  1.31s/it]Loading train:  38%|███▊      | 108/285 [02:29<04:09,  1.41s/it]Loading train:  38%|███▊      | 109/285 [02:30<04:00,  1.37s/it]Loading train:  39%|███▊      | 110/285 [02:31<03:46,  1.30s/it]Loading train:  39%|███▉      | 111/285 [02:33<03:41,  1.27s/it]Loading train:  39%|███▉      | 112/285 [02:34<03:45,  1.30s/it]Loading train:  40%|███▉      | 113/285 [02:36<03:52,  1.35s/it]Loading train:  40%|████      | 114/285 [02:37<03:46,  1.32s/it]Loading train:  40%|████      | 115/285 [02:38<03:29,  1.24s/it]Loading train:  41%|████      | 116/285 [02:39<03:24,  1.21s/it]Loading train:  41%|████      | 117/285 [02:40<03:28,  1.24s/it]Loading train:  41%|████▏     | 118/285 [02:42<03:33,  1.28s/it]Loading train:  42%|████▏     | 119/285 [02:43<03:28,  1.26s/it]Loading train:  42%|████▏     | 120/285 [02:44<03:39,  1.33s/it]Loading train:  42%|████▏     | 121/285 [02:46<03:54,  1.43s/it]Loading train:  43%|████▎     | 122/285 [02:48<03:55,  1.45s/it]Loading train:  43%|████▎     | 123/285 [02:49<03:54,  1.45s/it]Loading train:  44%|████▎     | 124/285 [02:50<03:51,  1.44s/it]Loading train:  44%|████▍     | 125/285 [02:51<03:24,  1.28s/it]Loading train:  44%|████▍     | 126/285 [02:53<03:30,  1.32s/it]Loading train:  45%|████▍     | 127/285 [02:54<03:29,  1.33s/it]Loading train:  45%|████▍     | 128/285 [02:55<03:24,  1.30s/it]Loading train:  45%|████▌     | 129/285 [02:56<03:14,  1.25s/it]Loading train:  46%|████▌     | 130/285 [02:57<03:00,  1.17s/it]Loading train:  46%|████▌     | 131/285 [02:59<02:58,  1.16s/it]Loading train:  46%|████▋     | 132/285 [03:00<03:04,  1.20s/it]Loading train:  47%|████▋     | 133/285 [03:01<03:08,  1.24s/it]Loading train:  47%|████▋     | 134/285 [03:02<03:00,  1.20s/it]Loading train:  47%|████▋     | 135/285 [03:03<02:58,  1.19s/it]Loading train:  48%|████▊     | 136/285 [03:04<02:49,  1.14s/it]Loading train:  48%|████▊     | 137/285 [03:06<02:49,  1.14s/it]Loading train:  48%|████▊     | 138/285 [03:07<02:50,  1.16s/it]Loading train:  49%|████▉     | 139/285 [03:08<02:57,  1.21s/it]Loading train:  49%|████▉     | 140/285 [03:09<02:49,  1.17s/it]Loading train:  49%|████▉     | 141/285 [03:10<02:46,  1.15s/it]Loading train:  50%|████▉     | 142/285 [03:12<02:45,  1.16s/it]Loading train:  50%|█████     | 143/285 [03:13<03:01,  1.28s/it]Loading train:  51%|█████     | 144/285 [03:14<03:03,  1.30s/it]Loading train:  51%|█████     | 145/285 [03:16<02:57,  1.27s/it]Loading train:  51%|█████     | 146/285 [03:17<02:51,  1.23s/it]Loading train:  52%|█████▏    | 147/285 [03:18<02:42,  1.17s/it]Loading train:  52%|█████▏    | 148/285 [03:19<02:42,  1.19s/it]Loading train:  52%|█████▏    | 149/285 [03:20<02:35,  1.15s/it]Loading train:  53%|█████▎    | 150/285 [03:21<02:31,  1.12s/it]Loading train:  53%|█████▎    | 151/285 [03:22<02:36,  1.17s/it]Loading train:  53%|█████▎    | 152/285 [03:24<02:37,  1.18s/it]Loading train:  54%|█████▎    | 153/285 [03:25<02:36,  1.18s/it]Loading train:  54%|█████▍    | 154/285 [03:26<02:39,  1.22s/it]Loading train:  54%|█████▍    | 155/285 [03:27<02:35,  1.19s/it]Loading train:  55%|█████▍    | 156/285 [03:29<02:38,  1.23s/it]Loading train:  55%|█████▌    | 157/285 [03:30<02:35,  1.21s/it]Loading train:  55%|█████▌    | 158/285 [03:31<02:33,  1.21s/it]Loading train:  56%|█████▌    | 159/285 [03:32<02:28,  1.18s/it]Loading train:  56%|█████▌    | 160/285 [03:34<02:38,  1.27s/it]Loading train:  56%|█████▋    | 161/285 [03:35<02:46,  1.34s/it]Loading train:  57%|█████▋    | 162/285 [03:36<02:30,  1.22s/it]Loading train:  57%|█████▋    | 163/285 [03:37<02:18,  1.13s/it]Loading train:  58%|█████▊    | 164/285 [03:38<02:18,  1.14s/it]Loading train:  58%|█████▊    | 165/285 [03:39<02:10,  1.09s/it]Loading train:  58%|█████▊    | 166/285 [03:40<02:13,  1.12s/it]Loading train:  59%|█████▊    | 167/285 [03:41<02:10,  1.11s/it]Loading train:  59%|█████▉    | 168/285 [03:42<02:08,  1.10s/it]Loading train:  59%|█████▉    | 169/285 [03:44<02:12,  1.14s/it]Loading train:  60%|█████▉    | 170/285 [03:45<02:17,  1.19s/it]Loading train:  60%|██████    | 171/285 [03:46<02:20,  1.23s/it]Loading train:  60%|██████    | 172/285 [03:48<02:29,  1.32s/it]Loading train:  61%|██████    | 173/285 [03:49<02:34,  1.38s/it]Loading train:  61%|██████    | 174/285 [03:51<02:31,  1.37s/it]Loading train:  61%|██████▏   | 175/285 [03:52<02:35,  1.42s/it]Loading train:  62%|██████▏   | 176/285 [03:53<02:31,  1.39s/it]Loading train:  62%|██████▏   | 177/285 [03:55<02:35,  1.44s/it]Loading train:  62%|██████▏   | 178/285 [03:56<02:25,  1.36s/it]Loading train:  63%|██████▎   | 179/285 [03:58<02:32,  1.44s/it]Loading train:  63%|██████▎   | 180/285 [03:59<02:25,  1.39s/it]Loading train:  64%|██████▎   | 181/285 [04:01<02:24,  1.39s/it]Loading train:  64%|██████▍   | 182/285 [04:02<02:12,  1.29s/it]Loading train:  64%|██████▍   | 183/285 [04:03<02:09,  1.27s/it]Loading train:  65%|██████▍   | 184/285 [04:04<02:12,  1.31s/it]Loading train:  65%|██████▍   | 185/285 [04:05<02:02,  1.22s/it]Loading train:  65%|██████▌   | 186/285 [04:06<01:58,  1.19s/it]Loading train:  66%|██████▌   | 187/285 [04:08<01:59,  1.22s/it]Loading train:  66%|██████▌   | 188/285 [04:09<02:01,  1.26s/it]Loading train:  66%|██████▋   | 189/285 [04:10<01:51,  1.16s/it]Loading train:  67%|██████▋   | 190/285 [04:11<01:48,  1.14s/it]Loading train:  67%|██████▋   | 191/285 [04:13<02:00,  1.28s/it]Loading train:  67%|██████▋   | 192/285 [04:14<02:00,  1.29s/it]Loading train:  68%|██████▊   | 193/285 [04:15<01:57,  1.28s/it]Loading train:  68%|██████▊   | 194/285 [04:16<01:55,  1.26s/it]Loading train:  68%|██████▊   | 195/285 [04:18<01:52,  1.25s/it]Loading train:  69%|██████▉   | 196/285 [04:19<02:01,  1.36s/it]Loading train:  69%|██████▉   | 197/285 [04:20<01:56,  1.32s/it]Loading train:  69%|██████▉   | 198/285 [04:22<01:55,  1.33s/it]Loading train:  70%|██████▉   | 199/285 [04:23<01:42,  1.20s/it]Loading train:  70%|███████   | 200/285 [04:23<01:31,  1.08s/it]Loading train:  71%|███████   | 201/285 [04:25<01:32,  1.10s/it]Loading train:  71%|███████   | 202/285 [04:26<01:32,  1.11s/it]Loading train:  71%|███████   | 203/285 [04:27<01:32,  1.13s/it]Loading train:  72%|███████▏  | 204/285 [04:28<01:24,  1.04s/it]Loading train:  72%|███████▏  | 205/285 [04:29<01:24,  1.06s/it]Loading train:  72%|███████▏  | 206/285 [04:30<01:25,  1.08s/it]Loading train:  73%|███████▎  | 207/285 [04:31<01:30,  1.15s/it]Loading train:  73%|███████▎  | 208/285 [04:33<01:43,  1.34s/it]Loading train:  73%|███████▎  | 209/285 [04:35<01:52,  1.47s/it]Loading train:  74%|███████▎  | 210/285 [04:36<01:44,  1.39s/it]Loading train:  74%|███████▍  | 211/285 [04:37<01:41,  1.37s/it]Loading train:  74%|███████▍  | 212/285 [04:39<01:40,  1.38s/it]Loading train:  75%|███████▍  | 213/285 [04:40<01:30,  1.25s/it]Loading train:  75%|███████▌  | 214/285 [04:41<01:24,  1.19s/it]Loading train:  75%|███████▌  | 215/285 [04:42<01:29,  1.27s/it]Loading train:  76%|███████▌  | 216/285 [04:44<01:27,  1.27s/it]Loading train:  76%|███████▌  | 217/285 [04:45<01:27,  1.28s/it]Loading train:  76%|███████▋  | 218/285 [04:47<01:34,  1.41s/it]Loading train:  77%|███████▋  | 219/285 [04:48<01:42,  1.55s/it]Loading train:  77%|███████▋  | 220/285 [04:50<01:35,  1.46s/it]Loading train:  78%|███████▊  | 221/285 [04:51<01:28,  1.38s/it]Loading train:  78%|███████▊  | 222/285 [04:52<01:25,  1.36s/it]Loading train:  78%|███████▊  | 223/285 [04:53<01:18,  1.27s/it]Loading train:  79%|███████▊  | 224/285 [04:54<01:14,  1.22s/it]Loading train:  79%|███████▉  | 225/285 [04:56<01:11,  1.19s/it]Loading train:  79%|███████▉  | 226/285 [04:57<01:17,  1.31s/it]Loading train:  80%|███████▉  | 227/285 [04:59<01:20,  1.39s/it]Loading train:  80%|████████  | 228/285 [05:00<01:21,  1.44s/it]Loading train:  80%|████████  | 229/285 [05:01<01:17,  1.38s/it]Loading train:  81%|████████  | 230/285 [05:03<01:14,  1.35s/it]Loading train:  81%|████████  | 231/285 [05:04<01:15,  1.39s/it]Loading train:  81%|████████▏ | 232/285 [05:05<01:11,  1.34s/it]Loading train:  82%|████████▏ | 233/285 [05:07<01:08,  1.31s/it]Loading train:  82%|████████▏ | 234/285 [05:08<01:05,  1.29s/it]Loading train:  82%|████████▏ | 235/285 [05:09<01:01,  1.22s/it]Loading train:  83%|████████▎ | 236/285 [05:10<01:01,  1.25s/it]Loading train:  83%|████████▎ | 237/285 [05:11<00:58,  1.23s/it]Loading train:  84%|████████▎ | 238/285 [05:13<01:03,  1.35s/it]Loading train:  84%|████████▍ | 239/285 [05:14<01:02,  1.36s/it]Loading train:  84%|████████▍ | 240/285 [05:15<00:54,  1.20s/it]Loading train:  85%|████████▍ | 241/285 [05:17<00:53,  1.21s/it]Loading train:  85%|████████▍ | 242/285 [05:18<00:53,  1.23s/it]Loading train:  85%|████████▌ | 243/285 [05:19<00:52,  1.24s/it]Loading train:  86%|████████▌ | 244/285 [05:21<00:55,  1.36s/it]Loading train:  86%|████████▌ | 245/285 [05:22<00:54,  1.37s/it]Loading train:  86%|████████▋ | 246/285 [05:23<00:53,  1.37s/it]Loading train:  87%|████████▋ | 247/285 [05:25<00:52,  1.37s/it]Loading train:  87%|████████▋ | 248/285 [05:27<00:53,  1.46s/it]Loading train:  87%|████████▋ | 249/285 [05:28<00:48,  1.34s/it]Loading train:  88%|████████▊ | 250/285 [05:29<00:44,  1.28s/it]Loading train:  88%|████████▊ | 251/285 [05:30<00:43,  1.29s/it]Loading train:  88%|████████▊ | 252/285 [05:31<00:41,  1.27s/it]Loading train:  89%|████████▉ | 253/285 [05:33<00:43,  1.35s/it]Loading train:  89%|████████▉ | 254/285 [05:34<00:43,  1.42s/it]Loading train:  89%|████████▉ | 255/285 [05:36<00:41,  1.38s/it]Loading train:  90%|████████▉ | 256/285 [05:37<00:37,  1.28s/it]Loading train:  90%|█████████ | 257/285 [05:38<00:33,  1.20s/it]Loading train:  91%|█████████ | 258/285 [05:39<00:32,  1.20s/it]Loading train:  91%|█████████ | 259/285 [05:40<00:30,  1.16s/it]Loading train:  91%|█████████ | 260/285 [05:41<00:27,  1.10s/it]Loading train:  92%|█████████▏| 261/285 [05:42<00:28,  1.18s/it]Loading train:  92%|█████████▏| 262/285 [05:44<00:28,  1.22s/it]Loading train:  92%|█████████▏| 263/285 [05:45<00:26,  1.23s/it]Loading train:  93%|█████████▎| 264/285 [05:47<00:28,  1.36s/it]Loading train:  93%|█████████▎| 265/285 [05:48<00:29,  1.45s/it]Loading train:  93%|█████████▎| 266/285 [05:49<00:26,  1.37s/it]Loading train:  94%|█████████▎| 267/285 [05:51<00:23,  1.30s/it]Loading train:  94%|█████████▍| 268/285 [05:52<00:22,  1.32s/it]Loading train:  94%|█████████▍| 269/285 [05:53<00:21,  1.35s/it]Loading train:  95%|█████████▍| 270/285 [05:54<00:19,  1.29s/it]Loading train:  95%|█████████▌| 271/285 [05:56<00:16,  1.21s/it]Loading train:  95%|█████████▌| 272/285 [05:56<00:14,  1.11s/it]Loading train:  96%|█████████▌| 273/285 [05:57<00:13,  1.10s/it]Loading train:  96%|█████████▌| 274/285 [05:59<00:12,  1.12s/it]Loading train:  96%|█████████▋| 275/285 [06:00<00:12,  1.27s/it]Loading train:  97%|█████████▋| 276/285 [06:02<00:12,  1.44s/it]Loading train:  97%|█████████▋| 277/285 [06:03<00:10,  1.37s/it]Loading train:  98%|█████████▊| 278/285 [06:04<00:09,  1.31s/it]Loading train:  98%|█████████▊| 279/285 [06:06<00:08,  1.38s/it]Loading train:  98%|█████████▊| 280/285 [06:07<00:06,  1.38s/it]Loading train:  99%|█████████▊| 281/285 [06:08<00:05,  1.30s/it]Loading train:  99%|█████████▉| 282/285 [06:10<00:03,  1.30s/it]Loading train:  99%|█████████▉| 283/285 [06:11<00:02,  1.31s/it]Loading train: 100%|█████████▉| 284/285 [06:13<00:01,  1.35s/it]Loading train: 100%|██████████| 285/285 [06:14<00:00,  1.35s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 44.76it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:06, 43.21it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:05, 45.46it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:05, 46.30it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:05, 50.20it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:05, 42.05it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:06, 38.54it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:06, 39.43it/s]concatenating: train:  16%|█▋        | 47/285 [00:01<00:05, 41.68it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:04, 46.31it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:04, 50.21it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:04, 53.36it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:04, 49.70it/s]concatenating: train:  28%|██▊       | 80/285 [00:01<00:04, 41.87it/s]concatenating: train:  30%|██▉       | 85/285 [00:01<00:04, 42.47it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:04, 44.22it/s]concatenating: train:  34%|███▎      | 96/285 [00:02<00:04, 46.67it/s]concatenating: train:  35%|███▌      | 101/285 [00:02<00:03, 46.04it/s]concatenating: train:  37%|███▋      | 106/285 [00:02<00:03, 46.64it/s]concatenating: train:  39%|███▉      | 112/285 [00:02<00:03, 49.47it/s]concatenating: train:  42%|████▏     | 119/285 [00:02<00:03, 53.75it/s]concatenating: train:  44%|████▍     | 125/285 [00:02<00:04, 38.68it/s]concatenating: train:  46%|████▌     | 131/285 [00:02<00:03, 42.25it/s]concatenating: train:  50%|█████     | 143/285 [00:02<00:02, 52.06it/s]concatenating: train:  55%|█████▌    | 157/285 [00:03<00:02, 63.86it/s]concatenating: train:  63%|██████▎   | 180/285 [00:03<00:01, 81.32it/s]concatenating: train:  71%|███████   | 203/285 [00:03<00:00, 99.92it/s]concatenating: train:  79%|███████▉  | 225/285 [00:03<00:00, 118.72it/s]concatenating: train:  87%|████████▋ | 247/285 [00:03<00:00, 135.59it/s]concatenating: train:  95%|█████████▍| 270/285 [00:03<00:00, 139.71it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 70.82it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.96s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.86s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.83s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 34.88it/s]2019-07-11 11:06:10.809447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 11:06:10.809613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 11:06:10.809630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 11:06:10.809639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 11:06:10.810090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.81it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:09,  4.27it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.92it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  5.01it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  4.37it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  4.73it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:07,  4.24it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.56it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:05,  4.66it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.16it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.49it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.96it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.94it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.38it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.50it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.65it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.99it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.64it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.11it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.38it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  7.09it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   10820       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 20)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 20)   3620        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 80)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 242,573
Trainable params: 67,773
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2.8114 - acc: 0.4962 - mDice: 0.1141 - val_loss: 1.7986 - val_acc: 0.9020 - val_mDice: 0.2320

Epoch 00001: val_mDice improved from -inf to 0.23196, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 1.0718 - acc: 0.8800 - mDice: 0.3364 - val_loss: 1.2682 - val_acc: 0.9058 - val_mDice: 0.3794

Epoch 00002: val_mDice improved from 0.23196 to 0.37938, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.7899 - acc: 0.8849 - mDice: 0.4396 - val_loss: 1.1137 - val_acc: 0.9126 - val_mDice: 0.4269

Epoch 00003: val_mDice improved from 0.37938 to 0.42692, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.6713 - acc: 0.8881 - mDice: 0.4961 - val_loss: 1.0015 - val_acc: 0.9134 - val_mDice: 0.4640

Epoch 00004: val_mDice improved from 0.42692 to 0.46396, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.6006 - acc: 0.8920 - mDice: 0.5335 - val_loss: 0.9221 - val_acc: 0.9148 - val_mDice: 0.4796

Epoch 00005: val_mDice improved from 0.46396 to 0.47960, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.5544 - acc: 0.8954 - mDice: 0.5589 - val_loss: 0.9376 - val_acc: 0.9211 - val_mDice: 0.4912

Epoch 00006: val_mDice improved from 0.47960 to 0.49115, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.5226 - acc: 0.8994 - mDice: 0.5785 - val_loss: 0.8451 - val_acc: 0.9222 - val_mDice: 0.5231

Epoch 00007: val_mDice improved from 0.49115 to 0.52315, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.5009 - acc: 0.9019 - mDice: 0.5915 - val_loss: 0.8600 - val_acc: 0.9237 - val_mDice: 0.5249

Epoch 00008: val_mDice improved from 0.52315 to 0.52487, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.4798 - acc: 0.9044 - mDice: 0.6044 - val_loss: 0.8306 - val_acc: 0.9250 - val_mDice: 0.5374

Epoch 00009: val_mDice improved from 0.52487 to 0.53745, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.4646 - acc: 0.9073 - mDice: 0.6144 - val_loss: 0.8515 - val_acc: 0.9271 - val_mDice: 0.5326

Epoch 00010: val_mDice did not improve from 0.53745
Epoch 11/300
 - 12s - loss: 0.4507 - acc: 0.9104 - mDice: 0.6231 - val_loss: 0.8640 - val_acc: 0.9246 - val_mDice: 0.5239

Epoch 00011: val_mDice did not improve from 0.53745
Epoch 12/300
 - 12s - loss: 0.4399 - acc: 0.9134 - mDice: 0.6303 - val_loss: 0.8463 - val_acc: 0.9303 - val_mDice: 0.5289

Epoch 00012: val_mDice did not improve from 0.53745
Epoch 13/300
 - 12s - loss: 0.4297 - acc: 0.9187 - mDice: 0.6369 - val_loss: 0.8861 - val_acc: 0.9304 - val_mDice: 0.5201

Epoch 00013: val_mDice did not improve from 0.53745
Epoch 14/300
 - 12s - loss: 0.4240 - acc: 0.9237 - mDice: 0.6404 - val_loss: 0.8187 - val_acc: 0.9332 - val_mDice: 0.5391

Epoch 00014: val_mDice improved from 0.53745 to 0.53907, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 13s - loss: 0.4150 - acc: 0.9279 - mDice: 0.6463 - val_loss: 0.8874 - val_acc: 0.9263 - val_mDice: 0.5129

Epoch 00015: val_mDice did not improve from 0.53907
Epoch 16/300
 - 12s - loss: 0.4051 - acc: 0.9312 - mDice: 0.6526 - val_loss: 0.8468 - val_acc: 0.9337 - val_mDice: 0.5381

Epoch 00016: val_mDice did not improve from 0.53907
Epoch 17/300
 - 12s - loss: 0.4000 - acc: 0.9336 - mDice: 0.6559 - val_loss: 0.8218 - val_acc: 0.9379 - val_mDice: 0.5416

Epoch 00017: val_mDice improved from 0.53907 to 0.54164, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 12s - loss: 0.3920 - acc: 0.9359 - mDice: 0.6614 - val_loss: 0.8191 - val_acc: 0.9344 - val_mDice: 0.5394

Epoch 00018: val_mDice did not improve from 0.54164
Epoch 19/300
 - 12s - loss: 0.3856 - acc: 0.9374 - mDice: 0.6656 - val_loss: 0.8543 - val_acc: 0.9338 - val_mDice: 0.5337

Epoch 00019: val_mDice did not improve from 0.54164
Epoch 20/300
 - 12s - loss: 0.3782 - acc: 0.9385 - mDice: 0.6705 - val_loss: 0.8400 - val_acc: 0.9327 - val_mDice: 0.5338

Epoch 00020: val_mDice did not improve from 0.54164
Epoch 21/300
 - 13s - loss: 0.3772 - acc: 0.9389 - mDice: 0.6713 - val_loss: 0.8192 - val_acc: 0.9383 - val_mDice: 0.5387

Epoch 00021: val_mDice did not improve from 0.54164
Epoch 22/300
 - 13s - loss: 0.3739 - acc: 0.9397 - mDice: 0.6736 - val_loss: 0.8204 - val_acc: 0.9370 - val_mDice: 0.5407

Epoch 00022: val_mDice did not improve from 0.54164
Epoch 23/300
 - 12s - loss: 0.3685 - acc: 0.9401 - mDice: 0.6771 - val_loss: 0.8384 - val_acc: 0.9356 - val_mDice: 0.5337

Epoch 00023: val_mDice did not improve from 0.54164
Epoch 24/300
 - 12s - loss: 0.3633 - acc: 0.9406 - mDice: 0.6808 - val_loss: 0.8152 - val_acc: 0.9348 - val_mDice: 0.5391

Epoch 00024: val_mDice did not improve from 0.54164
Epoch 25/300
 - 12s - loss: 0.3584 - acc: 0.9410 - mDice: 0.6841 - val_loss: 0.8123 - val_acc: 0.9360 - val_mDice: 0.5423

Epoch 00025: val_mDice improved from 0.54164 to 0.54230, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 12s - loss: 0.3557 - acc: 0.9412 - mDice: 0.6860 - val_loss: 0.8770 - val_acc: 0.9365 - val_mDice: 0.5254

Epoch 00026: val_mDice did not improve from 0.54230
Epoch 27/300
 - 12s - loss: 0.3519 - acc: 0.9416 - mDice: 0.6887 - val_loss: 0.8693 - val_acc: 0.9286 - val_mDice: 0.5080

Epoch 00027: val_mDice did not improve from 0.54230
Epoch 28/300
 - 12s - loss: 0.3488 - acc: 0.9421 - mDice: 0.6910 - val_loss: 0.8178 - val_acc: 0.9302 - val_mDice: 0.5368

Epoch 00028: val_mDice did not improve from 0.54230
Epoch 29/300
 - 13s - loss: 0.3495 - acc: 0.9421 - mDice: 0.6906 - val_loss: 0.8013 - val_acc: 0.9377 - val_mDice: 0.5507

Epoch 00029: val_mDice improved from 0.54230 to 0.55075, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 13s - loss: 0.3421 - acc: 0.9426 - mDice: 0.6958 - val_loss: 0.8112 - val_acc: 0.9357 - val_mDice: 0.5382

Epoch 00030: val_mDice did not improve from 0.55075
Epoch 31/300
 - 12s - loss: 0.3404 - acc: 0.9427 - mDice: 0.6970 - val_loss: 0.8099 - val_acc: 0.9370 - val_mDice: 0.5511

Epoch 00031: val_mDice improved from 0.55075 to 0.55110, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 12s - loss: 0.3405 - acc: 0.9429 - mDice: 0.6971 - val_loss: 0.8248 - val_acc: 0.9412 - val_mDice: 0.5352

Epoch 00032: val_mDice did not improve from 0.55110
Epoch 33/300
 - 12s - loss: 0.3375 - acc: 0.9431 - mDice: 0.6993 - val_loss: 0.8193 - val_acc: 0.9367 - val_mDice: 0.5375

Epoch 00033: val_mDice did not improve from 0.55110
Epoch 34/300
 - 12s - loss: 0.3342 - acc: 0.9433 - mDice: 0.7016 - val_loss: 0.8138 - val_acc: 0.9382 - val_mDice: 0.5375

Epoch 00034: val_mDice did not improve from 0.55110
Epoch 35/300
 - 12s - loss: 0.3299 - acc: 0.9437 - mDice: 0.7047 - val_loss: 0.7701 - val_acc: 0.9381 - val_mDice: 0.5535

Epoch 00035: val_mDice improved from 0.55110 to 0.55349, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 12s - loss: 0.3289 - acc: 0.9438 - mDice: 0.7054 - val_loss: 0.7868 - val_acc: 0.9362 - val_mDice: 0.5492

Epoch 00036: val_mDice did not improve from 0.55349
Epoch 37/300
 - 12s - loss: 0.3288 - acc: 0.9437 - mDice: 0.7055 - val_loss: 0.7788 - val_acc: 0.9358 - val_mDice: 0.5486

Epoch 00037: val_mDice did not improve from 0.55349
Epoch 38/300
 - 12s - loss: 0.3251 - acc: 0.9441 - mDice: 0.7081 - val_loss: 0.8016 - val_acc: 0.9380 - val_mDice: 0.5443

Epoch 00038: val_mDice did not improve from 0.55349
Epoch 39/300
 - 13s - loss: 0.3231 - acc: 0.9442 - mDice: 0.7096 - val_loss: 0.8144 - val_acc: 0.9358 - val_mDice: 0.5376

Epoch 00039: val_mDice did not improve from 0.55349
Epoch 40/300
 - 12s - loss: 0.3214 - acc: 0.9444 - mDice: 0.7109 - val_loss: 0.7869 - val_acc: 0.9351 - val_mDice: 0.5399

Epoch 00040: val_mDice did not improve from 0.55349
Epoch 41/300
 - 12s - loss: 0.3208 - acc: 0.9445 - mDice: 0.7114 - val_loss: 0.8037 - val_acc: 0.9356 - val_mDice: 0.5431

Epoch 00041: val_mDice did not improve from 0.55349
Epoch 42/300
 - 12s - loss: 0.3195 - acc: 0.9448 - mDice: 0.7124 - val_loss: 0.7768 - val_acc: 0.9383 - val_mDice: 0.5518

Epoch 00042: val_mDice did not improve from 0.55349
Epoch 43/300
 - 12s - loss: 0.3159 - acc: 0.9449 - mDice: 0.7151 - val_loss: 0.7779 - val_acc: 0.9342 - val_mDice: 0.5404

Epoch 00043: val_mDice did not improve from 0.55349
Epoch 44/300
 - 11s - loss: 0.3156 - acc: 0.9450 - mDice: 0.7152 - val_loss: 0.7729 - val_acc: 0.9378 - val_mDice: 0.5474

Epoch 00044: val_mDice did not improve from 0.55349
Epoch 45/300
 - 12s - loss: 0.3144 - acc: 0.9451 - mDice: 0.7161 - val_loss: 0.7537 - val_acc: 0.9361 - val_mDice: 0.5490

Epoch 00045: val_mDice did not improve from 0.55349
Epoch 46/300
 - 13s - loss: 0.3123 - acc: 0.9453 - mDice: 0.7177 - val_loss: 0.8118 - val_acc: 0.9349 - val_mDice: 0.5352

Epoch 00046: val_mDice did not improve from 0.55349
Epoch 47/300
 - 12s - loss: 0.3095 - acc: 0.9455 - mDice: 0.7197 - val_loss: 0.7752 - val_acc: 0.9354 - val_mDice: 0.5417

Epoch 00047: val_mDice did not improve from 0.55349
Epoch 48/300
 - 12s - loss: 0.3089 - acc: 0.9456 - mDice: 0.7203 - val_loss: 0.7481 - val_acc: 0.9381 - val_mDice: 0.5483

Epoch 00048: val_mDice did not improve from 0.55349
Epoch 49/300
 - 12s - loss: 0.3064 - acc: 0.9457 - mDice: 0.7221 - val_loss: 0.7695 - val_acc: 0.9370 - val_mDice: 0.5359

Epoch 00049: val_mDice did not improve from 0.55349
Epoch 50/300
 - 12s - loss: 0.3051 - acc: 0.9459 - mDice: 0.7230 - val_loss: 0.8013 - val_acc: 0.9391 - val_mDice: 0.5330

Epoch 00050: val_mDice did not improve from 0.55349
Epoch 51/300
 - 12s - loss: 0.3049 - acc: 0.9459 - mDice: 0.7232 - val_loss: 0.7445 - val_acc: 0.9361 - val_mDice: 0.5509

Epoch 00051: val_mDice did not improve from 0.55349
Epoch 52/300
 - 12s - loss: 0.3025 - acc: 0.9461 - mDice: 0.7250 - val_loss: 0.7921 - val_acc: 0.9370 - val_mDice: 0.5340

Epoch 00052: val_mDice did not improve from 0.55349
Epoch 53/300
 - 13s - loss: 0.3019 - acc: 0.9460 - mDice: 0.7253 - val_loss: 0.7632 - val_acc: 0.9358 - val_mDice: 0.5439

Epoch 00053: val_mDice did not improve from 0.55349
Epoch 54/300
 - 12s - loss: 0.3026 - acc: 0.9462 - mDice: 0.7250 - val_loss: 0.7336 - val_acc: 0.9364 - val_mDice: 0.5471

Epoch 00054: val_mDice did not improve from 0.55349
Epoch 55/300
 - 13s - loss: 0.3013 - acc: 0.9461 - mDice: 0.7258 - val_loss: 0.7486 - val_acc: 0.9361 - val_mDice: 0.5465

Epoch 00055: val_mDice did not improve from 0.55349
Epoch 56/300
 - 12s - loss: 0.2992 - acc: 0.9464 - mDice: 0.7276 - val_loss: 0.7770 - val_acc: 0.9370 - val_mDice: 0.5439

Epoch 00056: val_mDice did not improve from 0.55349
Epoch 57/300
 - 12s - loss: 0.2983 - acc: 0.9465 - mDice: 0.7282 - val_loss: 0.7653 - val_acc: 0.9376 - val_mDice: 0.5511

Epoch 00057: val_mDice did not improve from 0.55349
Epoch 58/300
 - 12s - loss: 0.2967 - acc: 0.9467 - mDice: 0.7295 - val_loss: 0.7684 - val_acc: 0.9394 - val_mDice: 0.5580

Epoch 00058: val_mDice improved from 0.55349 to 0.55797, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 59/300
 - 12s - loss: 0.2960 - acc: 0.9467 - mDice: 0.7299 - val_loss: 0.7390 - val_acc: 0.9404 - val_mDice: 0.5525

Epoch 00059: val_mDice did not improve from 0.55797
Epoch 60/300
 - 12s - loss: 0.2939 - acc: 0.9468 - mDice: 0.7316 - val_loss: 0.7861 - val_acc: 0.9374 - val_mDice: 0.5462

Epoch 00060: val_mDice did not improve from 0.55797
Epoch 61/300
 - 12s - loss: 0.2934 - acc: 0.9470 - mDice: 0.7319 - val_loss: 0.6946 - val_acc: 0.9374 - val_mDice: 0.5526

Epoch 00061: val_mDice did not improve from 0.55797
Epoch 62/300
 - 13s - loss: 0.2932 - acc: 0.9469 - mDice: 0.7321 - val_loss: 0.7233 - val_acc: 0.9359 - val_mDice: 0.5476

Epoch 00062: val_mDice did not improve from 0.55797
Epoch 63/300
 - 12s - loss: 0.2919 - acc: 0.9471 - mDice: 0.7330 - val_loss: 0.7759 - val_acc: 0.9359 - val_mDice: 0.5365

Epoch 00063: val_mDice did not improve from 0.55797
Epoch 64/300
 - 12s - loss: 0.2895 - acc: 0.9473 - mDice: 0.7349 - val_loss: 0.7553 - val_acc: 0.9375 - val_mDice: 0.5474

Epoch 00064: val_mDice did not improve from 0.55797
Epoch 65/300
 - 12s - loss: 0.2884 - acc: 0.9472 - mDice: 0.7357 - val_loss: 0.7167 - val_acc: 0.9390 - val_mDice: 0.5543

Epoch 00065: val_mDice did not improve from 0.55797
Epoch 66/300
 - 12s - loss: 0.2887 - acc: 0.9473 - mDice: 0.7355 - val_loss: 0.7020 - val_acc: 0.9381 - val_mDice: 0.5478

Epoch 00066: val_mDice did not improve from 0.55797
Epoch 67/300
 - 12s - loss: 0.2886 - acc: 0.9474 - mDice: 0.7356 - val_loss: 0.7579 - val_acc: 0.9382 - val_mDice: 0.5448

Epoch 00067: val_mDice did not improve from 0.55797
Epoch 68/300
 - 12s - loss: 0.2868 - acc: 0.9474 - mDice: 0.7369 - val_loss: 0.7356 - val_acc: 0.9350 - val_mDice: 0.5425

Epoch 00068: val_mDice did not improve from 0.55797
Epoch 69/300
 - 12s - loss: 0.2874 - acc: 0.9474 - mDice: 0.7365 - val_loss: 0.6931 - val_acc: 0.9393 - val_mDice: 0.5632

Epoch 00069: val_mDice improved from 0.55797 to 0.56315, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 12s - loss: 0.2869 - acc: 0.9475 - mDice: 0.7369 - val_loss: 0.8008 - val_acc: 0.9366 - val_mDice: 0.5352

Epoch 00070: val_mDice did not improve from 0.56315
Epoch 71/300
 - 13s - loss: 0.2840 - acc: 0.9478 - mDice: 0.7390 - val_loss: 0.7336 - val_acc: 0.9367 - val_mDice: 0.5453

Epoch 00071: val_mDice did not improve from 0.56315
Epoch 72/300
 - 12s - loss: 0.2852 - acc: 0.9476 - mDice: 0.7381 - val_loss: 0.7432 - val_acc: 0.9381 - val_mDice: 0.5387

Epoch 00072: val_mDice did not improve from 0.56315
Epoch 73/300
 - 12s - loss: 0.2849 - acc: 0.9477 - mDice: 0.7384 - val_loss: 0.7248 - val_acc: 0.9400 - val_mDice: 0.5576

Epoch 00073: val_mDice did not improve from 0.56315
Epoch 74/300
 - 12s - loss: 0.2823 - acc: 0.9479 - mDice: 0.7404 - val_loss: 0.6695 - val_acc: 0.9372 - val_mDice: 0.5505

Epoch 00074: val_mDice did not improve from 0.56315
Epoch 75/300
 - 13s - loss: 0.2815 - acc: 0.9479 - mDice: 0.7409 - val_loss: 0.7763 - val_acc: 0.9400 - val_mDice: 0.5542

Epoch 00075: val_mDice did not improve from 0.56315
Epoch 76/300
 - 12s - loss: 0.2811 - acc: 0.9480 - mDice: 0.7414 - val_loss: 0.7762 - val_acc: 0.9366 - val_mDice: 0.5429

Epoch 00076: val_mDice did not improve from 0.56315
Epoch 77/300
 - 12s - loss: 0.2803 - acc: 0.9480 - mDice: 0.7419 - val_loss: 0.7515 - val_acc: 0.9362 - val_mDice: 0.5521

Epoch 00077: val_mDice did not improve from 0.56315
Epoch 78/300
 - 12s - loss: 0.2788 - acc: 0.9481 - mDice: 0.7430 - val_loss: 0.7239 - val_acc: 0.9395 - val_mDice: 0.5459

Epoch 00078: val_mDice did not improve from 0.56315
Epoch 79/300
 - 13s - loss: 0.2792 - acc: 0.9481 - mDice: 0.7428 - val_loss: 0.7314 - val_acc: 0.9391 - val_mDice: 0.5379

Epoch 00079: val_mDice did not improve from 0.56315
Epoch 80/300
 - 12s - loss: 0.2769 - acc: 0.9483 - mDice: 0.7445 - val_loss: 0.7178 - val_acc: 0.9402 - val_mDice: 0.5599

Epoch 00080: val_mDice did not improve from 0.56315
Epoch 81/300
 - 12s - loss: 0.2773 - acc: 0.9482 - mDice: 0.7443 - val_loss: 0.7188 - val_acc: 0.9415 - val_mDice: 0.5576

Epoch 00081: val_mDice did not improve from 0.56315
Epoch 82/300
 - 12s - loss: 0.2777 - acc: 0.9482 - mDice: 0.7439 - val_loss: 0.7492 - val_acc: 0.9369 - val_mDice: 0.5462

Epoch 00082: val_mDice did not improve from 0.56315
Epoch 83/300
 - 12s - loss: 0.2757 - acc: 0.9484 - mDice: 0.7455 - val_loss: 0.7373 - val_acc: 0.9386 - val_mDice: 0.5390

Epoch 00083: val_mDice did not improve from 0.56315
Epoch 84/300
 - 13s - loss: 0.2744 - acc: 0.9484 - mDice: 0.7464 - val_loss: 0.7273 - val_acc: 0.9377 - val_mDice: 0.5475

Epoch 00084: val_mDice did not improve from 0.56315
Epoch 85/300
 - 12s - loss: 0.2752 - acc: 0.9484 - mDice: 0.7458 - val_loss: 0.7126 - val_acc: 0.9388 - val_mDice: 0.5515

Epoch 00085: val_mDice did not improve from 0.56315
Epoch 86/300
 - 12s - loss: 0.2742 - acc: 0.9484 - mDice: 0.7466 - val_loss: 0.7799 - val_acc: 0.9376 - val_mDice: 0.5451

Epoch 00086: val_mDice did not improve from 0.56315
Epoch 87/300
 - 12s - loss: 0.2742 - acc: 0.9485 - mDice: 0.7466 - val_loss: 0.7258 - val_acc: 0.9386 - val_mDice: 0.5540

Epoch 00087: val_mDice did not improve from 0.56315
Epoch 88/300
 - 12s - loss: 0.2721 - acc: 0.9487 - mDice: 0.7483 - val_loss: 0.7651 - val_acc: 0.9385 - val_mDice: 0.5315

Epoch 00088: val_mDice did not improve from 0.56315
Epoch 89/300
 - 12s - loss: 0.2732 - acc: 0.9485 - mDice: 0.7474 - val_loss: 0.7576 - val_acc: 0.9368 - val_mDice: 0.5477

Epoch 00089: val_mDice did not improve from 0.56315
Epoch 90/300
 - 12s - loss: 0.2727 - acc: 0.9487 - mDice: 0.7478 - val_loss: 0.7920 - val_acc: 0.9399 - val_mDice: 0.5519

Epoch 00090: val_mDice did not improve from 0.56315
Epoch 91/300
 - 12s - loss: 0.2706 - acc: 0.9488 - mDice: 0.7494 - val_loss: 0.6726 - val_acc: 0.9388 - val_mDice: 0.5561

Epoch 00091: val_mDice did not improve from 0.56315
Epoch 92/300
 - 12s - loss: 0.2727 - acc: 0.9486 - mDice: 0.7478 - val_loss: 0.7355 - val_acc: 0.9409 - val_mDice: 0.5597

Epoch 00092: val_mDice did not improve from 0.56315
Epoch 93/300
 - 12s - loss: 0.2697 - acc: 0.9489 - mDice: 0.7502 - val_loss: 0.7805 - val_acc: 0.9378 - val_mDice: 0.5446

Epoch 00093: val_mDice did not improve from 0.56315
Epoch 94/300
 - 12s - loss: 0.2690 - acc: 0.9488 - mDice: 0.7506 - val_loss: 0.7397 - val_acc: 0.9388 - val_mDice: 0.5605

Epoch 00094: val_mDice did not improve from 0.56315
Epoch 95/300
 - 12s - loss: 0.2697 - acc: 0.9489 - mDice: 0.7502 - val_loss: 0.7553 - val_acc: 0.9381 - val_mDice: 0.5539

Epoch 00095: val_mDice did not improve from 0.56315
Epoch 96/300
 - 13s - loss: 0.2700 - acc: 0.9489 - mDice: 0.7499 - val_loss: 0.7796 - val_acc: 0.9382 - val_mDice: 0.5419

Epoch 00096: val_mDice did not improve from 0.56315
Epoch 97/300
 - 12s - loss: 0.2681 - acc: 0.9489 - mDice: 0.7513 - val_loss: 0.8222 - val_acc: 0.9387 - val_mDice: 0.5464

Epoch 00097: val_mDice did not improve from 0.56315
Epoch 98/300
 - 12s - loss: 0.2680 - acc: 0.9490 - mDice: 0.7514 - val_loss: 0.7196 - val_acc: 0.9412 - val_mDice: 0.5588

Epoch 00098: val_mDice did not improve from 0.56315
Epoch 99/300
 - 12s - loss: 0.2696 - acc: 0.9488 - mDice: 0.7502 - val_loss: 0.7663 - val_acc: 0.9394 - val_mDice: 0.5585

Epoch 00099: val_mDice did not improve from 0.56315
Epoch 100/300
 - 13s - loss: 0.2682 - acc: 0.9490 - mDice: 0.7513 - val_loss: 0.8327 - val_acc: 0.9367 - val_mDice: 0.5436

Epoch 00100: val_mDice did not improve from 0.56315
Epoch 101/300
 - 12s - loss: 0.2660 - acc: 0.9491 - mDice: 0.7531 - val_loss: 0.7033 - val_acc: 0.9388 - val_mDice: 0.5549

Epoch 00101: val_mDice did not improve from 0.56315
Epoch 102/300
 - 12s - loss: 0.2653 - acc: 0.9493 - mDice: 0.7536 - val_loss: 0.7038 - val_acc: 0.9404 - val_mDice: 0.5605

Epoch 00102: val_mDice did not improve from 0.56315
Epoch 103/300
 - 12s - loss: 0.2666 - acc: 0.9491 - mDice: 0.7526 - val_loss: 0.7867 - val_acc: 0.9389 - val_mDice: 0.5470

Epoch 00103: val_mDice did not improve from 0.56315
Epoch 104/300
 - 12s - loss: 0.2653 - acc: 0.9493 - mDice: 0.7536 - val_loss: 0.7795 - val_acc: 0.9411 - val_mDice: 0.5402

Epoch 00104: val_mDice did not improve from 0.56315
Epoch 105/300
 - 12s - loss: 0.2668 - acc: 0.9491 - mDice: 0.7524 - val_loss: 0.7721 - val_acc: 0.9412 - val_mDice: 0.5573

Epoch 00105: val_mDice did not improve from 0.56315
Epoch 106/300
 - 12s - loss: 0.2650 - acc: 0.9492 - mDice: 0.7538 - val_loss: 0.7120 - val_acc: 0.9377 - val_mDice: 0.5492

Epoch 00106: val_mDice did not improve from 0.56315
Epoch 107/300
 - 12s - loss: 0.2644 - acc: 0.9492 - mDice: 0.7543 - val_loss: 0.7741 - val_acc: 0.9378 - val_mDice: 0.5438

Epoch 00107: val_mDice did not improve from 0.56315
Epoch 108/300
 - 12s - loss: 0.2648 - acc: 0.9492 - mDice: 0.7540 - val_loss: 0.7424 - val_acc: 0.9394 - val_mDice: 0.5503

Epoch 00108: val_mDice did not improve from 0.56315
Epoch 109/300
 - 12s - loss: 0.2639 - acc: 0.9493 - mDice: 0.7547 - val_loss: 0.7135 - val_acc: 0.9385 - val_mDice: 0.5514

Epoch 00109: val_mDice did not improve from 0.56315
Restoring model weights from the end of the best epoch
Epoch 00109: early stopping
{'val_loss': [1.7986451937602117, 1.2682179854466364, 1.1136959859958062, 1.0014581771997304, 0.9220819060619061, 0.9376041751641494, 0.8450994262328515, 0.8599885770907769, 0.8306256440969614, 0.8514763162686274, 0.8639913361806136, 0.8463011475709769, 0.8860925298470718, 0.8186572996469644, 0.8873743965075567, 0.8467633770062373, 0.8217547100323898, 0.8191057099745824, 0.8542815332229321, 0.8400244483580956, 0.8192459849210886, 0.8203915861936716, 0.838407420195066, 0.8152422125522907, 0.8123217889895806, 0.8769561740068289, 0.8693181184621958, 0.8178162345519433, 0.8013012386285342, 0.8111735055079827, 0.8099323419424204, 0.8247507673043472, 0.8192925682434669, 0.8137559982446524, 0.770103768660472, 0.7867827163292811, 0.7787913084030151, 0.8016153092567737, 0.8144394732438601, 0.786885678768158, 0.8036706264202411, 0.7768250749661372, 0.777875556395604, 0.7729304753817045, 0.7537077160981985, 0.8117853265542251, 0.7751701795137845, 0.7480684862687037, 0.7695030478330759, 0.801336047741083, 0.7444631182230436, 0.7921147896693304, 0.7632403809290665, 0.7336477866539588, 0.7485755819540757, 0.7769774427780738, 0.7653438196732447, 0.7683909008136163, 0.739042497598208, 0.786085830284999, 0.6946148574352264, 0.7233038796828344, 0.7759151481665097, 0.7552748505885785, 0.716733992099762, 0.7020281828366793, 0.7578686613302964, 0.7355977090505453, 0.6931483928973858, 0.8008308685742892, 0.7335711488356957, 0.7431736473853772, 0.7247505050439101, 0.6695266366004944, 0.7762660177854391, 0.7761952028824732, 0.751506528029075, 0.7238703507643479, 0.73136767745018, 0.7178321205652677, 0.7188316606558286, 0.7492272005631373, 0.7373278668293586, 0.7272657431088961, 0.7126214962739211, 0.7799176688377674, 0.7258105530188634, 0.7650948556569906, 0.7575507462024689, 0.7919596777512476, 0.6726115231330578, 0.7354910992659055, 0.7805359844978039, 0.739664579813297, 0.7552679983469156, 0.7795599721945249, 0.8221906767441676, 0.7195963813708379, 0.7663149650280292, 0.8327255799220159, 0.7032894537999079, 0.7038392241184528, 0.7867480103786175, 0.7794554462799659, 0.772107883141591, 0.711990081346952, 0.7740676471820245, 0.7424291165975424, 0.7134517706357516], 'val_acc': [0.9020109176635742, 0.905843205176867, 0.9125785965185899, 0.9134153219369742, 0.9147744178771973, 0.9211422846867487, 0.9222378776623652, 0.923675550864293, 0.925036969093176, 0.9270987671155196, 0.9245539055420802, 0.9303254645604354, 0.9304456435717069, 0.9331615177484659, 0.9263428999827459, 0.9337208706599015, 0.9379114095981305, 0.9343680854027088, 0.9337694232280438, 0.9326553505200607, 0.9383112834050105, 0.9369776180157294, 0.9355561045499948, 0.9348418873090011, 0.9360345693734976, 0.9364783420012548, 0.9286057926141299, 0.9302098728143252, 0.9377010854390951, 0.935711010144307, 0.9370446365613204, 0.941158957206286, 0.9366956238563244, 0.9382465871480795, 0.9381078848472009, 0.9362079363602859, 0.93579651759221, 0.9379761310724112, 0.9357572152064397, 0.9350961767710172, 0.9356023646317996, 0.9382789364227881, 0.934178521999946, 0.9378467293886038, 0.9360669622054467, 0.9349112648230332, 0.9353712040644425, 0.9380824795136085, 0.9369730055332184, 0.939060199719209, 0.9360807858980619, 0.9370122781166663, 0.9358080786008102, 0.936406685755803, 0.9360877642264733, 0.9370446480237521, 0.9376432941510127, 0.9394091940843142, 0.9404262189681714, 0.9374352739407465, 0.9374028948637155, 0.9359282576120816, 0.9359097549548516, 0.9374514611867758, 0.9390278458595276, 0.9380801824422983, 0.9381772554837741, 0.9349574882250565, 0.9392751203133509, 0.9365661786152766, 0.9367233766959264, 0.9381078825547144, 0.9399731846956106, 0.9372087762906001, 0.9399916804753817, 0.936649386699383, 0.9362125350878789, 0.9394508072963128, 0.9391364546922537, 0.9402205279240241, 0.941537999189817, 0.9368620606569144, 0.9385609007798709, 0.9376687453343318, 0.9387782238996946, 0.9376456187321589, 0.9385585968311017, 0.9384569273545191, 0.93682278578098, 0.9398830601802239, 0.9388082394233117, 0.940872304714643, 0.937821273620312, 0.9388359647530776, 0.9380824657586905, 0.9381610567753131, 0.9386533773862399, 0.9411866619036748, 0.9393606713184943, 0.9366771441239578, 0.9387897275961362, 0.9404146694220029, 0.9388614159363967, 0.9410873055458069, 0.941175089432643, 0.9376918627665594, 0.9378004830617171, 0.9393768746119279, 0.9384892789217142], 'val_mDice': [0.23196124170835203, 0.37938135805038303, 0.4269237698843846, 0.46395543905404896, 0.4796047107531474, 0.4911519033977619, 0.5231486043104758, 0.5248715310142591, 0.5374458105518267, 0.53257793875841, 0.5239211613169084, 0.5289181837668786, 0.5200593686447694, 0.5390677182720258, 0.5128992171241686, 0.5381213237459843, 0.5416419735321631, 0.5394000726250502, 0.5336703062057495, 0.5337900954943436, 0.5387059215169686, 0.5406552765231866, 0.5336543212716396, 0.539078910763447, 0.5423015694205577, 0.5254458979918406, 0.5080159650399134, 0.5368061300653678, 0.550749285862996, 0.5381979927993737, 0.5511005515089402, 0.5351712978803195, 0.5374956804399307, 0.5375149318805108, 0.553492373571946, 0.5492110682221559, 0.5485829080526645, 0.5442859455943108, 0.5376175974424069, 0.5399263776265658, 0.543051893894489, 0.5518238051579549, 0.5403674095869064, 0.5473913252353668, 0.5490144307796772, 0.5351536523264188, 0.54165255307005, 0.5483418628573418, 0.5359189728131661, 0.5330055229938947, 0.5509290408629638, 0.5339895509756528, 0.5439354267257911, 0.5470672473311424, 0.5465291119538821, 0.5438907097738522, 0.5511172769161371, 0.557971944889197, 0.5525401039765432, 0.5462091347345939, 0.5526167349173472, 0.5475812124518248, 0.5365245491266251, 0.5473678922997072, 0.5542612987068983, 0.547846610729511, 0.5447691277815745, 0.5425491823026767, 0.5631538526369975, 0.5352351616781491, 0.5452969349347628, 0.5386562129625907, 0.5576221725115409, 0.5505267811509279, 0.5542135760188103, 0.5428508815283959, 0.5520843645701041, 0.545932778945336, 0.5379361687944486, 0.5599292465127431, 0.5575620297055978, 0.5461966209113598, 0.539008840918541, 0.5474684307208428, 0.5515047283126757, 0.545051100735481, 0.5539928926871374, 0.5315456974964875, 0.5476966259571222, 0.5519215991863837, 0.5561183748336939, 0.5596736319936239, 0.5446455679260768, 0.560492893251089, 0.553875405054826, 0.5419035324683557, 0.5463560693539106, 0.5588394816105182, 0.558541669868506, 0.5435599372364007, 0.5548741020835363, 0.5605062028536429, 0.5469889623614458, 0.5402197697414801, 0.557343784146584, 0.5492118132802156, 0.5438114307247676, 0.5503258149211223, 0.5514272313851577], 'loss': [2.8114036028756546, 1.071821898994307, 0.7898846589187563, 0.6712795993526033, 0.600603273733289, 0.5543905880731992, 0.5225927831776345, 0.5009328815469353, 0.4797696711930646, 0.46464448602428454, 0.45071770292987223, 0.4398562020479528, 0.4297091887796056, 0.42396944481200927, 0.4149575428907517, 0.40512464438803597, 0.39999384681017297, 0.3920485085582619, 0.38563090099418096, 0.3782237843950219, 0.3771690582229699, 0.3738897369047114, 0.36850039185297334, 0.36328205621012744, 0.3583964993705677, 0.355747018497632, 0.3518956211300823, 0.34880343807652836, 0.34953608298383054, 0.34205780612095404, 0.3404004969802893, 0.3404647443090694, 0.33747121101594174, 0.33421224000037714, 0.329853878083467, 0.32893997949174353, 0.3288324268269031, 0.32514957989217563, 0.3231381059468018, 0.3214394489546648, 0.32078035106399916, 0.31954167744643486, 0.3158821813472905, 0.31563940458188666, 0.31444277069527515, 0.3122754048308378, 0.30954720699555166, 0.30894027909130495, 0.30635349402609735, 0.3050718875863857, 0.3049135762700997, 0.3025030327230255, 0.301884538700448, 0.30255749936001797, 0.30125566871197235, 0.299161427579858, 0.29825886114600353, 0.29669175464750974, 0.29595211977493846, 0.29389331826565174, 0.29344571166391203, 0.2931641097477988, 0.29193257763851266, 0.2895224722650101, 0.28837650015786664, 0.28874040557528335, 0.2885977344479737, 0.28681286143429835, 0.28742964085722983, 0.28687616617908496, 0.2840476633327579, 0.28522722582354004, 0.28491299893708066, 0.2823123035588784, 0.28153328275830064, 0.2810822505138682, 0.2803180520631044, 0.27880816638640105, 0.27918822968411816, 0.27689875752341203, 0.27730350385323055, 0.27774565738581936, 0.27572933248924747, 0.2743881017500147, 0.27524982663930525, 0.2741665242068565, 0.27419083047306736, 0.27206843654124113, 0.2732008610342983, 0.27265962774184294, 0.27059356393183465, 0.2727194036503378, 0.2696532754867068, 0.26898319920435454, 0.2696847095707625, 0.2700278914377147, 0.26805839043948565, 0.2680064487762912, 0.26961880928639126, 0.26819116819073086, 0.26597679198134555, 0.26527255553386975, 0.2665508802192387, 0.2653059517805134, 0.26682978597754187, 0.2650194495193503, 0.26441260006917444, 0.2647527675753775, 0.26386032583671093], 'acc': [0.49617229284153297, 0.8799907871962891, 0.884904942806715, 0.8881387463808169, 0.8919510069966899, 0.8954209002370622, 0.8993645999293743, 0.9018643499135334, 0.904421166719287, 0.9073001284127876, 0.9104356800763356, 0.9133700429211351, 0.9186990334683542, 0.9236692720801697, 0.9279058768577069, 0.9311979681509046, 0.9336250904333566, 0.9358703586147751, 0.9374095038559388, 0.9385041226367059, 0.9388683048834234, 0.9396789830669666, 0.9400520954065675, 0.9405975113723767, 0.9409502944273009, 0.9412436857606546, 0.9415937868539317, 0.9420858656558605, 0.9420754007612395, 0.9425533081974412, 0.9427146630721218, 0.942906779726416, 0.943118811753099, 0.9433151896749927, 0.9437117804507318, 0.9437660957398608, 0.9437328436921512, 0.9440789284559234, 0.9442356463772866, 0.944361014119002, 0.9445199915527869, 0.9447507111555447, 0.9449127731118312, 0.9449835345939243, 0.9450710803547941, 0.9452585735345672, 0.9454790434526867, 0.9456214197807995, 0.9457458140312894, 0.9459385129508965, 0.9459108445110724, 0.9461275535041882, 0.9460406701557973, 0.9462156076168735, 0.9461413173452137, 0.9463773357915469, 0.9465069622557223, 0.9467474623248882, 0.9467326711269253, 0.946807716689426, 0.9469581803448315, 0.9469195571067115, 0.9470806442085012, 0.947265982836757, 0.9472222422625562, 0.9473146458267121, 0.9473944130302696, 0.9473798885882412, 0.9474416542710671, 0.9474664634854814, 0.9477535800268474, 0.9475745588642727, 0.9476956074433299, 0.9479027150918073, 0.947864250092118, 0.9479726388106363, 0.9480020124391361, 0.9481021060084303, 0.9481161415912256, 0.9482875142075046, 0.9482197593160632, 0.9481667102642036, 0.9483609378343357, 0.9484226813804925, 0.948430240659996, 0.9484292201798835, 0.9485293795160291, 0.9487023037825411, 0.9485237733427035, 0.9486561036963068, 0.9488111353663735, 0.9485675143841545, 0.9488911243873824, 0.9488302890823236, 0.9488834493177618, 0.9488734746236571, 0.9488745647295588, 0.9490276881714627, 0.9487798501784914, 0.9490172460291819, 0.9490999368452382, 0.9492861404142333, 0.9491359625895679, 0.9492954063941047, 0.9491287582553666, 0.9492074599853578, 0.9492117188947179, 0.9492412266900132, 0.9492737680610382], 'mDice': [0.1140945867888604, 0.3363562697338726, 0.43957899719336524, 0.4960658950173722, 0.5335100663166737, 0.5589315265755168, 0.5784638364365826, 0.5914764097285955, 0.6044359979160727, 0.6143625630319179, 0.6231181765739453, 0.6303261856437774, 0.6368928547551093, 0.6404462949075042, 0.6462665216504764, 0.6525691715617533, 0.6559090659064933, 0.6613799153048867, 0.6655616303777866, 0.6704614179266078, 0.6712546760301732, 0.6736077858624858, 0.6770965635727046, 0.6807925893593503, 0.684119718360426, 0.6860017728334994, 0.6886973217504881, 0.6910033673748894, 0.6905812083064196, 0.6958079681805026, 0.696981448732728, 0.6971116086098251, 0.6992867239493676, 0.7015716010031419, 0.7047292371413194, 0.7053971904390337, 0.7054665754457731, 0.7081325042734812, 0.7095601296365498, 0.7108942757978284, 0.7114170659273343, 0.712357169520005, 0.7151021061376333, 0.7151543071522194, 0.7160834978616931, 0.7177266341826578, 0.7197236436149747, 0.7203122848493855, 0.7220619487650312, 0.7229951169562716, 0.7232410205660585, 0.725043120259323, 0.7253413477485321, 0.7249746280909134, 0.7258245768411171, 0.727555823531701, 0.7281952861775158, 0.729464363729691, 0.7298584579596888, 0.7316047507854864, 0.731928007888319, 0.7321485150600286, 0.7330291138895431, 0.7348816069050006, 0.735696747834465, 0.7354574762872255, 0.7356214574438108, 0.7368994825805211, 0.7364954662578062, 0.7368744214962167, 0.7390248806045844, 0.7381478011096897, 0.7383935730868266, 0.740358422649728, 0.7409245192229522, 0.7413643071882995, 0.7418661508339859, 0.7430234239746325, 0.7428155914285708, 0.7445243541510312, 0.7442741275196485, 0.7438719362160667, 0.7454620510914179, 0.7464466762643871, 0.7458002052381449, 0.7465932277321299, 0.7466429669863841, 0.7483106946072257, 0.7474072795726492, 0.7477714456305187, 0.7494046147388802, 0.7477851813870537, 0.75015642977636, 0.7506235136621213, 0.7502236361929293, 0.7499028336932537, 0.7513491713252002, 0.7514399594127346, 0.7502098192667748, 0.751275018584538, 0.7530767825172472, 0.7535741149439183, 0.7525964819900138, 0.7536416455277392, 0.75240111830357, 0.7538234881509068, 0.7542507157470427, 0.7539996321181754, 0.7547348178005808]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.41s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.16s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:57,  1.89s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:14,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:11,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:56,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:45,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:07,  1.75s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:54,  1.71s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:20,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:30,  1.86s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:02,  1.76s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:19,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:05,  1.79s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:17,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:27,  1.88s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:41,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:19,  1.86s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:23,  1.89s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:14,  1.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:05,  1.83s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:16,  1.88s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:59,  1.82s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<07:58,  1.82s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:41,  1.77s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:54,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:02,  1.86s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:44,  1.80s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:41,  1.80s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:41,  1.80s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:03,  1.89s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:03,  1.90s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:40,  1.82s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:36,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:31,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:45,  1.86s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:25,  1.79s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:47,  1.89s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:30,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:31,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:11,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<06:59,  1.73s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:18,  1.84s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<07:07,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<07:07,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<07:18,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<07:25,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<07:34,  1.94s/it]predicting train subjects:  18%|█▊        | 52/285 [01:34<07:12,  1.86s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<07:07,  1.84s/it]predicting train subjects:  19%|█▉        | 54/285 [01:38<07:15,  1.88s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:58,  1.82s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<06:55,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:34,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:47,  1.80s/it]predicting train subjects:  21%|██        | 59/285 [01:47<07:05,  1.88s/it]predicting train subjects:  21%|██        | 60/285 [01:49<07:07,  1.90s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<06:46,  1.82s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<06:47,  1.83s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<06:44,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<06:39,  1.81s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:43,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [02:00<06:48,  1.86s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:39,  1.83s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:22,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:07<06:27,  1.80s/it]predicting train subjects:  25%|██▍       | 71/285 [02:09<06:30,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:16,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:12<06:17,  1.78s/it]predicting train subjects:  26%|██▌       | 74/285 [02:14<06:16,  1.78s/it]predicting train subjects:  26%|██▋       | 75/285 [02:16<06:25,  1.83s/it]predicting train subjects:  27%|██▋       | 76/285 [02:18<06:20,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:19<06:04,  1.75s/it]predicting train subjects:  27%|██▋       | 78/285 [02:21<06:03,  1.76s/it]predicting train subjects:  28%|██▊       | 79/285 [02:23<06:08,  1.79s/it]predicting train subjects:  28%|██▊       | 80/285 [02:25<06:10,  1.80s/it]predicting train subjects:  28%|██▊       | 81/285 [02:26<05:54,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:28<06:05,  1.80s/it]predicting train subjects:  29%|██▉       | 83/285 [02:30<05:55,  1.76s/it]predicting train subjects:  29%|██▉       | 84/285 [02:31<05:44,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:33<05:55,  1.78s/it]predicting train subjects:  30%|███       | 86/285 [02:35<05:59,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:37<05:57,  1.80s/it]predicting train subjects:  31%|███       | 88/285 [02:39<05:50,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:40<05:49,  1.78s/it]predicting train subjects:  32%|███▏      | 90/285 [02:42<05:50,  1.80s/it]predicting train subjects:  32%|███▏      | 91/285 [02:44<05:45,  1.78s/it]predicting train subjects:  32%|███▏      | 92/285 [02:46<05:53,  1.83s/it]predicting train subjects:  33%|███▎      | 93/285 [02:48<05:47,  1.81s/it]predicting train subjects:  33%|███▎      | 94/285 [02:50<05:46,  1.82s/it]predicting train subjects:  33%|███▎      | 95/285 [02:51<05:43,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:53<05:39,  1.80s/it]predicting train subjects:  34%|███▍      | 97/285 [02:55<05:48,  1.86s/it]predicting train subjects:  34%|███▍      | 98/285 [02:57<05:55,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [02:59<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:01<05:46,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:02<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:32,  1.82s/it]predicting train subjects:  36%|███▌      | 103/285 [03:06<05:18,  1.75s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:22,  1.78s/it]predicting train subjects:  37%|███▋      | 105/285 [03:10<05:29,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:11<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:13<05:17,  1.78s/it]predicting train subjects:  38%|███▊      | 108/285 [03:15<05:06,  1.73s/it]predicting train subjects:  38%|███▊      | 109/285 [03:17<05:14,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:19<05:15,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<05:08,  1.77s/it]predicting train subjects:  39%|███▉      | 112/285 [03:22<05:15,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:24<05:13,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:26<05:11,  1.82s/it]predicting train subjects:  40%|████      | 115/285 [03:28<05:13,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:30<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:31<05:01,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:33<04:52,  1.75s/it]predicting train subjects:  42%|████▏     | 119/285 [03:35<04:54,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:46,  1.74s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:40<04:40,  1.72s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:43<04:24,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [03:45<04:19,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:46<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:48<04:11,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:14,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [03:51<04:11,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:52<04:04,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [03:54<03:58,  1.55s/it]predicting train subjects:  46%|████▋     | 132/285 [03:56<04:00,  1.57s/it]predicting train subjects:  47%|████▋     | 133/285 [03:57<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [03:59<03:59,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [04:00<03:54,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:02<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 137/285 [04:04<04:00,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:05<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:07<04:02,  1.66s/it]predicting train subjects:  49%|████▉     | 140/285 [04:09<04:03,  1.68s/it]predicting train subjects:  49%|████▉     | 141/285 [04:10<03:55,  1.64s/it]predicting train subjects:  50%|████▉     | 142/285 [04:12<03:48,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:13<03:40,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:15<03:41,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:16<03:34,  1.53s/it]predicting train subjects:  51%|█████     | 146/285 [04:18<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:19<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:21<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:22<03:23,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:24<03:23,  1.51s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:25<03:30,  1.57s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:27<03:27,  1.56s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:28<03:24,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:30<03:30,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:32<03:34,  1.65s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:34<03:35,  1.67s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:35<03:31,  1.65s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:37<03:30,  1.65s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:38<03:21,  1.60s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:40<03:17,  1.58s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:42<03:15,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:43<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:45<03:10,  1.56s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:46<03:07,  1.55s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:48<03:05,  1.55s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:49<03:04,  1.55s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:51<03:07,  1.59s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:52<03:02,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:54<03:00,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:55<02:56,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [04:57<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [04:59<02:53,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:00<02:49,  1.51s/it]predicting train subjects:  61%|██████    | 174/285 [05:02<02:48,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:03<02:48,  1.53s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:05<02:49,  1.56s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:06<02:46,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:08<02:45,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:09<02:40,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:11<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:13<02:52,  1.66s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:14<02:50,  1.66s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:16<02:43,  1.60s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:18<02:41,  1.60s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:19<02:32,  1.52s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:21<02:44,  1.66s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:23<02:48,  1.72s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:25<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:26<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:28<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:29<02:34,  1.65s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:31<02:34,  1.66s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:32<02:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:34<02:17,  1.51s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:35<02:17,  1.52s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:37<02:25,  1.63s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:39<02:33,  1.74s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:41<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:42<02:22,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:44<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:46<02:21,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:47<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:49<02:17,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:50<02:08,  1.58s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:52<02:04,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:53<01:59,  1.51s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:55<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:57<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:59<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:02<01:57,  1.59s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:03<01:57,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:05<01:57,  1.63s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:06<01:51,  1.57s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:08<01:57,  1.68s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:10<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:12<01:55,  1.70s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:14<01:55,  1.73s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:15<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:17<01:48,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:18<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:20<01:45,  1.67s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:22<01:38,  1.59s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:23<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:24<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:26<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:28<01:35,  1.65s/it]predicting train subjects:  80%|████████  | 228/285 [06:30<01:38,  1.72s/it]predicting train subjects:  80%|████████  | 229/285 [06:31<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:33<01:27,  1.60s/it]predicting train subjects:  81%|████████  | 231/285 [06:34<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:36<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:37<01:21,  1.56s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:39<01:24,  1.65s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:41<01:20,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:43<01:22,  1.69s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:44<01:21,  1.71s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:46<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:48<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:49<01:14,  1.65s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:51<01:10,  1.61s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:52<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:54<01:04,  1.53s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:56<01:06,  1.63s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:57<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:59<01:05,  1.68s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:01<01:06,  1.74s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:03<01:04,  1.75s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:04<00:58,  1.64s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:06<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:07<00:53,  1.57s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:09<00:50,  1.52s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:11<00:52,  1.65s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:12<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:14<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:16<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:17<00:44,  1.60s/it]predicting train subjects:  91%|█████████ | 258/285 [07:19<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:21<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [07:22<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:23<00:37,  1.57s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:25<00:35,  1.55s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:26<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:28<00:34,  1.62s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:30<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:32<00:31,  1.64s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:33<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:35<00:29,  1.71s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:37<00:27,  1.71s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:38<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:40<00:22,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:43<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:16,  1.51s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:46<00:16,  1.64s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:48<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:50<00:13,  1.64s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:51<00:11,  1.61s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:53<00:09,  1.63s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:54<00:07,  1.55s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:56<00:06,  1.54s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:57<00:04,  1.50s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:59<00:03,  1.60s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:01<00:01,  1.67s/it]predicting train subjects: 100%|██████████| 285/285 [08:02<00:00,  1.70s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:07,  1.72s/it]Loading train:   1%|          | 2/285 [00:02<07:29,  1.59s/it]Loading train:   1%|          | 3/285 [00:04<07:16,  1.55s/it]Loading train:   1%|▏         | 4/285 [00:05<06:49,  1.46s/it]Loading train:   2%|▏         | 5/285 [00:07<07:01,  1.50s/it]Loading train:   2%|▏         | 6/285 [00:08<06:48,  1.46s/it]Loading train:   2%|▏         | 7/285 [00:10<07:01,  1.52s/it]Loading train:   3%|▎         | 8/285 [00:11<06:40,  1.45s/it]Loading train:   3%|▎         | 9/285 [00:13<06:59,  1.52s/it]Loading train:   4%|▎         | 10/285 [00:14<06:23,  1.39s/it]Loading train:   4%|▍         | 11/285 [00:15<05:52,  1.29s/it]Loading train:   4%|▍         | 12/285 [00:16<05:32,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:03,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:18<05:00,  1.11s/it]Loading train:   5%|▌         | 15/285 [00:19<05:04,  1.13s/it]Loading train:   6%|▌         | 16/285 [00:20<04:57,  1.11s/it]Loading train:   6%|▌         | 17/285 [00:21<04:39,  1.04s/it]Loading train:   6%|▋         | 18/285 [00:22<04:39,  1.05s/it]Loading train:   7%|▋         | 19/285 [00:23<04:26,  1.00s/it]Loading train:   7%|▋         | 20/285 [00:24<04:28,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:25<04:27,  1.01s/it]Loading train:   8%|▊         | 22/285 [00:26<04:24,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:27<04:36,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:28<04:25,  1.02s/it]Loading train:   9%|▉         | 25/285 [00:29<04:28,  1.03s/it]Loading train:   9%|▉         | 26/285 [00:30<04:26,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:31<04:15,  1.01it/s]Loading train:  10%|▉         | 28/285 [00:33<04:42,  1.10s/it]Loading train:  10%|█         | 29/285 [00:34<04:38,  1.09s/it]Loading train:  11%|█         | 30/285 [00:35<04:29,  1.06s/it]Loading train:  11%|█         | 31/285 [00:36<04:25,  1.05s/it]Loading train:  11%|█         | 32/285 [00:36<04:10,  1.01it/s]Loading train:  12%|█▏        | 33/285 [00:38<04:35,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:31,  1.08s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:24,  1.06s/it]Loading train:  13%|█▎        | 36/285 [00:41<04:05,  1.01it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:10,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:14,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:44<04:00,  1.02it/s]Loading train:  14%|█▍        | 40/285 [00:45<04:03,  1.01it/s]Loading train:  14%|█▍        | 41/285 [00:46<03:54,  1.04it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:46,  1.07it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:49,  1.06it/s]Loading train:  15%|█▌        | 44/285 [00:49<04:04,  1.02s/it]Loading train:  16%|█▌        | 45/285 [00:49<03:51,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:51<04:01,  1.01s/it]Loading train:  16%|█▋        | 47/285 [00:51<03:47,  1.04it/s]Loading train:  17%|█▋        | 48/285 [00:52<03:50,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:54,  1.00it/s]Loading train:  18%|█▊        | 50/285 [00:54<03:52,  1.01it/s]Loading train:  18%|█▊        | 51/285 [00:55<03:52,  1.01it/s]Loading train:  18%|█▊        | 52/285 [00:56<03:39,  1.06it/s]Loading train:  19%|█▊        | 53/285 [00:57<03:43,  1.04it/s]Loading train:  19%|█▉        | 54/285 [00:58<03:49,  1.01it/s]Loading train:  19%|█▉        | 55/285 [00:59<03:41,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:00<03:43,  1.02it/s]Loading train:  20%|██        | 57/285 [01:01<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:02<03:57,  1.04s/it]Loading train:  21%|██        | 59/285 [01:04<04:16,  1.13s/it]Loading train:  21%|██        | 60/285 [01:05<04:29,  1.20s/it]Loading train:  21%|██▏       | 61/285 [01:06<04:08,  1.11s/it]Loading train:  22%|██▏       | 62/285 [01:07<04:08,  1.12s/it]Loading train:  22%|██▏       | 63/285 [01:08<04:04,  1.10s/it]Loading train:  22%|██▏       | 64/285 [01:10<04:23,  1.19s/it]Loading train:  23%|██▎       | 65/285 [01:11<04:51,  1.33s/it]Loading train:  23%|██▎       | 66/285 [01:13<04:55,  1.35s/it]Loading train:  24%|██▎       | 67/285 [01:14<04:42,  1.30s/it]Loading train:  24%|██▍       | 68/285 [01:15<04:28,  1.24s/it]Loading train:  24%|██▍       | 69/285 [01:16<04:12,  1.17s/it]Loading train:  25%|██▍       | 70/285 [01:17<04:10,  1.16s/it]Loading train:  25%|██▍       | 71/285 [01:18<04:07,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:19<03:57,  1.12s/it]Loading train:  26%|██▌       | 73/285 [01:20<03:43,  1.06s/it]Loading train:  26%|██▌       | 74/285 [01:21<03:45,  1.07s/it]Loading train:  26%|██▋       | 75/285 [01:22<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:23<03:46,  1.08s/it]Loading train:  27%|██▋       | 77/285 [01:24<03:38,  1.05s/it]Loading train:  27%|██▋       | 78/285 [01:25<03:26,  1.00it/s]Loading train:  28%|██▊       | 79/285 [01:26<03:28,  1.01s/it]Loading train:  28%|██▊       | 80/285 [01:27<03:24,  1.00it/s]Loading train:  28%|██▊       | 81/285 [01:28<03:20,  1.02it/s]Loading train:  29%|██▉       | 82/285 [01:29<03:14,  1.04it/s]Loading train:  29%|██▉       | 83/285 [01:30<03:13,  1.05it/s]Loading train:  29%|██▉       | 84/285 [01:31<03:11,  1.05it/s]Loading train:  30%|██▉       | 85/285 [01:32<03:10,  1.05it/s]Loading train:  30%|███       | 86/285 [01:33<03:23,  1.02s/it]Loading train:  31%|███       | 87/285 [01:34<03:19,  1.01s/it]Loading train:  31%|███       | 88/285 [01:35<03:10,  1.04it/s]Loading train:  31%|███       | 89/285 [01:36<03:14,  1.01it/s]Loading train:  32%|███▏      | 90/285 [01:37<03:27,  1.06s/it]Loading train:  32%|███▏      | 91/285 [01:38<03:18,  1.02s/it]Loading train:  32%|███▏      | 92/285 [01:39<03:28,  1.08s/it]Loading train:  33%|███▎      | 93/285 [01:40<03:17,  1.03s/it]Loading train:  33%|███▎      | 94/285 [01:41<03:21,  1.05s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:21,  1.06s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:21,  1.07s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:24,  1.09s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:17,  1.06s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:08,  1.01s/it]Loading train:  35%|███▌      | 100/285 [01:48<03:12,  1.04s/it]Loading train:  35%|███▌      | 101/285 [01:49<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:50<03:11,  1.05s/it]Loading train:  36%|███▌      | 103/285 [01:51<03:05,  1.02s/it]Loading train:  36%|███▋      | 104/285 [01:52<03:04,  1.02s/it]Loading train:  37%|███▋      | 105/285 [01:53<03:02,  1.02s/it]Loading train:  37%|███▋      | 106/285 [01:54<02:58,  1.00it/s]Loading train:  38%|███▊      | 107/285 [01:55<03:00,  1.01s/it]Loading train:  38%|███▊      | 108/285 [01:56<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [01:57<03:10,  1.08s/it]Loading train:  39%|███▊      | 110/285 [01:58<03:11,  1.10s/it]Loading train:  39%|███▉      | 111/285 [01:59<02:56,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:00<02:54,  1.01s/it]Loading train:  40%|███▉      | 113/285 [02:01<02:59,  1.05s/it]Loading train:  40%|████      | 114/285 [02:02<02:55,  1.03s/it]Loading train:  40%|████      | 115/285 [02:03<02:53,  1.02s/it]Loading train:  41%|████      | 116/285 [02:04<02:50,  1.01s/it]Loading train:  41%|████      | 117/285 [02:05<02:49,  1.01s/it]Loading train:  41%|████▏     | 118/285 [02:06<02:42,  1.03it/s]Loading train:  42%|████▏     | 119/285 [02:07<02:45,  1.00it/s]Loading train:  42%|████▏     | 120/285 [02:08<02:38,  1.04it/s]Loading train:  42%|████▏     | 121/285 [02:09<02:58,  1.09s/it]Loading train:  43%|████▎     | 122/285 [02:11<03:10,  1.17s/it]Loading train:  43%|████▎     | 123/285 [02:12<03:13,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:13<03:05,  1.15s/it]Loading train:  44%|████▍     | 125/285 [02:14<02:49,  1.06s/it]Loading train:  44%|████▍     | 126/285 [02:15<02:34,  1.03it/s]Loading train:  45%|████▍     | 127/285 [02:15<02:29,  1.06it/s]Loading train:  45%|████▍     | 128/285 [02:16<02:30,  1.04it/s]Loading train:  45%|████▌     | 129/285 [02:17<02:27,  1.06it/s]Loading train:  46%|████▌     | 130/285 [02:18<02:18,  1.12it/s]Loading train:  46%|████▌     | 131/285 [02:19<02:14,  1.14it/s]Loading train:  46%|████▋     | 132/285 [02:20<02:17,  1.11it/s]Loading train:  47%|████▋     | 133/285 [02:21<02:15,  1.12it/s]Loading train:  47%|████▋     | 134/285 [02:22<02:07,  1.19it/s]Loading train:  47%|████▋     | 135/285 [02:22<02:06,  1.18it/s]Loading train:  48%|████▊     | 136/285 [02:23<02:06,  1.18it/s]Loading train:  48%|████▊     | 137/285 [02:24<02:06,  1.17it/s]Loading train:  48%|████▊     | 138/285 [02:25<02:08,  1.14it/s]Loading train:  49%|████▉     | 139/285 [02:26<02:09,  1.12it/s]Loading train:  49%|████▉     | 140/285 [02:27<02:09,  1.12it/s]Loading train:  49%|████▉     | 141/285 [02:28<02:04,  1.16it/s]Loading train:  50%|████▉     | 142/285 [02:29<02:05,  1.14it/s]Loading train:  50%|█████     | 143/285 [02:29<01:58,  1.20it/s]Loading train:  51%|█████     | 144/285 [02:30<02:03,  1.14it/s]Loading train:  51%|█████     | 145/285 [02:31<02:04,  1.13it/s]Loading train:  51%|█████     | 146/285 [02:32<02:05,  1.11it/s]Loading train:  52%|█████▏    | 147/285 [02:33<02:11,  1.05it/s]Loading train:  52%|█████▏    | 148/285 [02:34<02:12,  1.03it/s]Loading train:  52%|█████▏    | 149/285 [02:35<02:10,  1.05it/s]Loading train:  53%|█████▎    | 150/285 [02:36<02:06,  1.07it/s]Loading train:  53%|█████▎    | 151/285 [02:37<02:03,  1.08it/s]Loading train:  53%|█████▎    | 152/285 [02:38<01:59,  1.11it/s]Loading train:  54%|█████▎    | 153/285 [02:39<02:00,  1.09it/s]Loading train:  54%|█████▍    | 154/285 [02:40<02:01,  1.08it/s]Loading train:  54%|█████▍    | 155/285 [02:40<01:55,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:41<01:55,  1.12it/s]Loading train:  55%|█████▌    | 157/285 [02:42<01:49,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:43<01:51,  1.14it/s]Loading train:  56%|█████▌    | 159/285 [02:44<01:53,  1.11it/s]Loading train:  56%|█████▌    | 160/285 [02:45<01:49,  1.15it/s]Loading train:  56%|█████▋    | 161/285 [02:46<01:49,  1.13it/s]Loading train:  57%|█████▋    | 162/285 [02:47<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:48<01:48,  1.13it/s]Loading train:  58%|█████▊    | 164/285 [02:48<01:47,  1.12it/s]Loading train:  58%|█████▊    | 165/285 [02:49<01:44,  1.15it/s]Loading train:  58%|█████▊    | 166/285 [02:50<01:43,  1.15it/s]Loading train:  59%|█████▊    | 167/285 [02:51<01:44,  1.13it/s]Loading train:  59%|█████▉    | 168/285 [02:52<01:45,  1.11it/s]Loading train:  59%|█████▉    | 169/285 [02:53<01:43,  1.12it/s]Loading train:  60%|█████▉    | 170/285 [02:54<01:40,  1.15it/s]Loading train:  60%|██████    | 171/285 [02:55<01:46,  1.07it/s]Loading train:  60%|██████    | 172/285 [02:56<01:41,  1.12it/s]Loading train:  61%|██████    | 173/285 [02:56<01:38,  1.14it/s]Loading train:  61%|██████    | 174/285 [02:57<01:36,  1.16it/s]Loading train:  61%|██████▏   | 175/285 [02:58<01:39,  1.11it/s]Loading train:  62%|██████▏   | 176/285 [02:59<01:42,  1.07it/s]Loading train:  62%|██████▏   | 177/285 [03:00<01:35,  1.14it/s]Loading train:  62%|██████▏   | 178/285 [03:01<01:33,  1.14it/s]Loading train:  63%|██████▎   | 179/285 [03:02<01:36,  1.10it/s]Loading train:  63%|██████▎   | 180/285 [03:03<01:43,  1.01it/s]Loading train:  64%|██████▎   | 181/285 [03:04<01:48,  1.04s/it]Loading train:  64%|██████▍   | 182/285 [03:05<01:50,  1.07s/it]Loading train:  64%|██████▍   | 183/285 [03:06<01:45,  1.04s/it]Loading train:  65%|██████▍   | 184/285 [03:07<01:38,  1.02it/s]Loading train:  65%|██████▍   | 185/285 [03:08<01:36,  1.03it/s]Loading train:  65%|██████▌   | 186/285 [03:09<01:37,  1.01it/s]Loading train:  66%|██████▌   | 187/285 [03:10<01:37,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:11<01:40,  1.04s/it]Loading train:  66%|██████▋   | 189/285 [03:12<01:31,  1.05it/s]Loading train:  67%|██████▋   | 190/285 [03:13<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:14<01:24,  1.11it/s]Loading train:  67%|██████▋   | 192/285 [03:15<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:16<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [03:17<01:23,  1.09it/s]Loading train:  68%|██████▊   | 195/285 [03:17<01:20,  1.12it/s]Loading train:  69%|██████▉   | 196/285 [03:18<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:19<01:23,  1.06it/s]Loading train:  69%|██████▉   | 198/285 [03:20<01:25,  1.02it/s]Loading train:  70%|██████▉   | 199/285 [03:21<01:16,  1.12it/s]Loading train:  70%|███████   | 200/285 [03:22<01:13,  1.15it/s]Loading train:  71%|███████   | 201/285 [03:23<01:20,  1.04it/s]Loading train:  71%|███████   | 202/285 [03:24<01:17,  1.08it/s]Loading train:  71%|███████   | 203/285 [03:25<01:14,  1.10it/s]Loading train:  72%|███████▏  | 204/285 [03:26<01:12,  1.12it/s]Loading train:  72%|███████▏  | 205/285 [03:26<01:09,  1.16it/s]Loading train:  72%|███████▏  | 206/285 [03:27<01:07,  1.17it/s]Loading train:  73%|███████▎  | 207/285 [03:28<01:14,  1.04it/s]Loading train:  73%|███████▎  | 208/285 [03:29<01:14,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:31<01:16,  1.01s/it]Loading train:  74%|███████▎  | 210/285 [03:31<01:12,  1.03it/s]Loading train:  74%|███████▍  | 211/285 [03:32<01:11,  1.03it/s]Loading train:  74%|███████▍  | 212/285 [03:33<01:08,  1.06it/s]Loading train:  75%|███████▍  | 213/285 [03:34<01:07,  1.07it/s]Loading train:  75%|███████▌  | 214/285 [03:35<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [03:36<01:09,  1.01it/s]Loading train:  76%|███████▌  | 216/285 [03:37<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [03:38<01:09,  1.02s/it]Loading train:  76%|███████▋  | 218/285 [03:39<01:08,  1.03s/it]Loading train:  77%|███████▋  | 219/285 [03:41<01:09,  1.05s/it]Loading train:  77%|███████▋  | 220/285 [03:41<01:02,  1.04it/s]Loading train:  78%|███████▊  | 221/285 [03:42<00:58,  1.09it/s]Loading train:  78%|███████▊  | 222/285 [03:43<00:59,  1.06it/s]Loading train:  78%|███████▊  | 223/285 [03:44<00:56,  1.09it/s]Loading train:  79%|███████▊  | 224/285 [03:45<00:56,  1.08it/s]Loading train:  79%|███████▉  | 225/285 [03:46<00:58,  1.02it/s]Loading train:  79%|███████▉  | 226/285 [03:47<01:00,  1.03s/it]Loading train:  80%|███████▉  | 227/285 [03:48<00:59,  1.02s/it]Loading train:  80%|████████  | 228/285 [03:49<00:58,  1.02s/it]Loading train:  80%|████████  | 229/285 [03:50<00:55,  1.00it/s]Loading train:  81%|████████  | 230/285 [03:51<00:51,  1.06it/s]Loading train:  81%|████████  | 231/285 [03:52<00:51,  1.05it/s]Loading train:  81%|████████▏ | 232/285 [03:53<00:51,  1.04it/s]Loading train:  82%|████████▏ | 233/285 [03:54<00:45,  1.13it/s]Loading train:  82%|████████▏ | 234/285 [03:55<00:47,  1.07it/s]Loading train:  82%|████████▏ | 235/285 [03:56<00:46,  1.08it/s]Loading train:  83%|████████▎ | 236/285 [03:57<00:46,  1.06it/s]Loading train:  83%|████████▎ | 237/285 [03:58<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [03:58<00:44,  1.06it/s]Loading train:  84%|████████▍ | 239/285 [03:59<00:42,  1.07it/s]Loading train:  84%|████████▍ | 240/285 [04:00<00:41,  1.08it/s]Loading train:  85%|████████▍ | 241/285 [04:01<00:40,  1.08it/s]Loading train:  85%|████████▍ | 242/285 [04:02<00:38,  1.11it/s]Loading train:  85%|████████▌ | 243/285 [04:03<00:37,  1.12it/s]Loading train:  86%|████████▌ | 244/285 [04:04<00:40,  1.02it/s]Loading train:  86%|████████▌ | 245/285 [04:05<00:37,  1.07it/s]Loading train:  86%|████████▋ | 246/285 [04:06<00:37,  1.05it/s]Loading train:  87%|████████▋ | 247/285 [04:07<00:37,  1.01it/s]Loading train:  87%|████████▋ | 248/285 [04:08<00:36,  1.00it/s]Loading train:  87%|████████▋ | 249/285 [04:09<00:34,  1.05it/s]Loading train:  88%|████████▊ | 250/285 [04:10<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [04:11<00:30,  1.12it/s]Loading train:  88%|████████▊ | 252/285 [04:11<00:27,  1.18it/s]Loading train:  89%|████████▉ | 253/285 [04:12<00:29,  1.09it/s]Loading train:  89%|████████▉ | 254/285 [04:14<00:31,  1.03s/it]Loading train:  89%|████████▉ | 255/285 [04:15<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [04:15<00:26,  1.09it/s]Loading train:  90%|█████████ | 257/285 [04:16<00:25,  1.10it/s]Loading train:  91%|█████████ | 258/285 [04:17<00:27,  1.01s/it]Loading train:  91%|█████████ | 259/285 [04:18<00:25,  1.01it/s]Loading train:  91%|█████████ | 260/285 [04:19<00:23,  1.08it/s]Loading train:  92%|█████████▏| 261/285 [04:20<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:21<00:20,  1.13it/s]Loading train:  92%|█████████▏| 263/285 [04:22<00:18,  1.16it/s]Loading train:  93%|█████████▎| 264/285 [04:23<00:20,  1.01it/s]Loading train:  93%|█████████▎| 265/285 [04:24<00:20,  1.00s/it]Loading train:  93%|█████████▎| 266/285 [04:25<00:17,  1.10it/s]Loading train:  94%|█████████▎| 267/285 [04:25<00:15,  1.13it/s]Loading train:  94%|█████████▍| 268/285 [04:27<00:16,  1.05it/s]Loading train:  94%|█████████▍| 269/285 [04:28<00:15,  1.03it/s]Loading train:  95%|█████████▍| 270/285 [04:28<00:14,  1.06it/s]Loading train:  95%|█████████▌| 271/285 [04:29<00:12,  1.09it/s]Loading train:  95%|█████████▌| 272/285 [04:30<00:11,  1.09it/s]Loading train:  96%|█████████▌| 273/285 [04:31<00:10,  1.13it/s]Loading train:  96%|█████████▌| 274/285 [04:32<00:09,  1.18it/s]Loading train:  96%|█████████▋| 275/285 [04:33<00:08,  1.13it/s]Loading train:  97%|█████████▋| 276/285 [04:34<00:08,  1.06it/s]Loading train:  97%|█████████▋| 277/285 [04:35<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [04:36<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:37<00:05,  1.08it/s]Loading train:  98%|█████████▊| 280/285 [04:38<00:04,  1.06it/s]Loading train:  99%|█████████▊| 281/285 [04:38<00:03,  1.08it/s]Loading train:  99%|█████████▉| 282/285 [04:39<00:02,  1.10it/s]Loading train:  99%|█████████▉| 283/285 [04:40<00:01,  1.06it/s]Loading train: 100%|█████████▉| 284/285 [04:42<00:01,  1.02s/it]Loading train: 100%|██████████| 285/285 [04:43<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 63.26it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:03, 73.39it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:02, 84.13it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:03, 75.35it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:03, 75.05it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 86.42it/s]concatenating: train:  28%|██▊       | 79/285 [00:00<00:02, 99.49it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:01, 119.81it/s]concatenating: train:  43%|████▎     | 123/285 [00:00<00:01, 136.59it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:00, 151.57it/s]concatenating: train:  57%|█████▋    | 163/285 [00:01<00:00, 152.62it/s]concatenating: train:  65%|██████▌   | 186/285 [00:01<00:00, 169.67it/s]concatenating: train:  72%|███████▏  | 205/285 [00:01<00:00, 161.14it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 155.86it/s]concatenating: train:  84%|████████▍ | 240/285 [00:01<00:00, 149.85it/s]concatenating: train:  94%|█████████▍| 268/285 [00:01<00:00, 173.74it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 154.99it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.45s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 76.90it/s]2019-07-11 11:42:18.962853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 11:42:18.962962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 11:42:18.962977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 11:42:18.962986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 11:42:18.963401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.52it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.11it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  5.00it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.30it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.36it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.07it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.40it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.05it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.69it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.07it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.75it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.97it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.59it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.64it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.40it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.43it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.03it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.40it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.19it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 30)   12180       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 30)   8130        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 75)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   988         concatenate_8[0][0]              
==================================================================================================
Total params: 151,888
Trainable params: 53,248
Non-trainable params: 98,640
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 2.7259 - acc: 0.6442 - mDice: 0.1081 - val_loss: 2.0230 - val_acc: 0.9036 - val_mDice: 0.2441

Epoch 00001: val_mDice improved from -inf to 0.24411, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 1.0784 - acc: 0.8798 - mDice: 0.3456 - val_loss: 2.1547 - val_acc: 0.9102 - val_mDice: 0.2149

Epoch 00002: val_mDice did not improve from 0.24411
Epoch 3/300
 - 11s - loss: 0.6352 - acc: 0.8959 - mDice: 0.5155 - val_loss: 1.3677 - val_acc: 0.9098 - val_mDice: 0.4554

Epoch 00003: val_mDice improved from 0.24411 to 0.45544, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5137 - acc: 0.9103 - mDice: 0.5825 - val_loss: 1.1194 - val_acc: 0.9399 - val_mDice: 0.5618

Epoch 00004: val_mDice improved from 0.45544 to 0.56182, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.4676 - acc: 0.9207 - mDice: 0.6108 - val_loss: 1.0446 - val_acc: 0.9407 - val_mDice: 0.5783

Epoch 00005: val_mDice improved from 0.56182 to 0.57833, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4428 - acc: 0.9261 - mDice: 0.6268 - val_loss: 1.0602 - val_acc: 0.9431 - val_mDice: 0.5825

Epoch 00006: val_mDice improved from 0.57833 to 0.58246, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4230 - acc: 0.9293 - mDice: 0.6397 - val_loss: 0.9989 - val_acc: 0.9474 - val_mDice: 0.5910

Epoch 00007: val_mDice improved from 0.58246 to 0.59103, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 11s - loss: 0.4140 - acc: 0.9316 - mDice: 0.6459 - val_loss: 1.0329 - val_acc: 0.9366 - val_mDice: 0.5664

Epoch 00008: val_mDice did not improve from 0.59103
Epoch 9/300
 - 11s - loss: 0.4023 - acc: 0.9332 - mDice: 0.6535 - val_loss: 0.9811 - val_acc: 0.9366 - val_mDice: 0.5693

Epoch 00009: val_mDice did not improve from 0.59103
Epoch 10/300
 - 11s - loss: 0.3952 - acc: 0.9345 - mDice: 0.6584 - val_loss: 0.9445 - val_acc: 0.9434 - val_mDice: 0.5756

Epoch 00010: val_mDice did not improve from 0.59103
Epoch 11/300
 - 11s - loss: 0.3850 - acc: 0.9354 - mDice: 0.6654 - val_loss: 0.9931 - val_acc: 0.9420 - val_mDice: 0.5780

Epoch 00011: val_mDice did not improve from 0.59103
Epoch 12/300
 - 11s - loss: 0.3787 - acc: 0.9360 - mDice: 0.6696 - val_loss: 0.9521 - val_acc: 0.9419 - val_mDice: 0.5653

Epoch 00012: val_mDice did not improve from 0.59103
Epoch 13/300
 - 11s - loss: 0.3743 - acc: 0.9366 - mDice: 0.6726 - val_loss: 0.9067 - val_acc: 0.9486 - val_mDice: 0.5793

Epoch 00013: val_mDice did not improve from 0.59103
Epoch 14/300
 - 10s - loss: 0.3675 - acc: 0.9372 - mDice: 0.6773 - val_loss: 0.9396 - val_acc: 0.9427 - val_mDice: 0.5727

Epoch 00014: val_mDice did not improve from 0.59103
Epoch 15/300
 - 11s - loss: 0.3635 - acc: 0.9378 - mDice: 0.6802 - val_loss: 0.8896 - val_acc: 0.9476 - val_mDice: 0.5827

Epoch 00015: val_mDice did not improve from 0.59103
Epoch 16/300
 - 11s - loss: 0.3610 - acc: 0.9380 - mDice: 0.6819 - val_loss: 0.9025 - val_acc: 0.9304 - val_mDice: 0.5568

Epoch 00016: val_mDice did not improve from 0.59103
Epoch 17/300
 - 11s - loss: 0.3572 - acc: 0.9383 - mDice: 0.6846 - val_loss: 0.9253 - val_acc: 0.9391 - val_mDice: 0.5556

Epoch 00017: val_mDice did not improve from 0.59103
Epoch 18/300
 - 11s - loss: 0.3528 - acc: 0.9387 - mDice: 0.6878 - val_loss: 0.8939 - val_acc: 0.9435 - val_mDice: 0.5840

Epoch 00018: val_mDice did not improve from 0.59103
Epoch 19/300
 - 10s - loss: 0.3512 - acc: 0.9391 - mDice: 0.6889 - val_loss: 0.9001 - val_acc: 0.9401 - val_mDice: 0.5711

Epoch 00019: val_mDice did not improve from 0.59103
Epoch 20/300
 - 11s - loss: 0.3465 - acc: 0.9394 - mDice: 0.6923 - val_loss: 0.8586 - val_acc: 0.9416 - val_mDice: 0.5745

Epoch 00020: val_mDice did not improve from 0.59103
Epoch 21/300
 - 11s - loss: 0.3449 - acc: 0.9396 - mDice: 0.6935 - val_loss: 0.8298 - val_acc: 0.9408 - val_mDice: 0.5821

Epoch 00021: val_mDice did not improve from 0.59103
Epoch 22/300
 - 10s - loss: 0.3407 - acc: 0.9399 - mDice: 0.6965 - val_loss: 0.8844 - val_acc: 0.9474 - val_mDice: 0.5806

Epoch 00022: val_mDice did not improve from 0.59103
Epoch 23/300
 - 11s - loss: 0.3394 - acc: 0.9402 - mDice: 0.6974 - val_loss: 0.8700 - val_acc: 0.9466 - val_mDice: 0.5762

Epoch 00023: val_mDice did not improve from 0.59103
Epoch 24/300
 - 10s - loss: 0.3369 - acc: 0.9403 - mDice: 0.6992 - val_loss: 0.8672 - val_acc: 0.9457 - val_mDice: 0.5692

Epoch 00024: val_mDice did not improve from 0.59103
Epoch 25/300
 - 11s - loss: 0.3350 - acc: 0.9404 - mDice: 0.7006 - val_loss: 0.8255 - val_acc: 0.9459 - val_mDice: 0.5853

Epoch 00025: val_mDice did not improve from 0.59103
Epoch 26/300
 - 10s - loss: 0.3328 - acc: 0.9406 - mDice: 0.7021 - val_loss: 0.8507 - val_acc: 0.9468 - val_mDice: 0.5784

Epoch 00026: val_mDice did not improve from 0.59103
Epoch 27/300
 - 11s - loss: 0.3298 - acc: 0.9410 - mDice: 0.7044 - val_loss: 0.8300 - val_acc: 0.9420 - val_mDice: 0.5794

Epoch 00027: val_mDice did not improve from 0.59103
Epoch 28/300
 - 11s - loss: 0.3293 - acc: 0.9411 - mDice: 0.7047 - val_loss: 0.8338 - val_acc: 0.9464 - val_mDice: 0.5684

Epoch 00028: val_mDice did not improve from 0.59103
Epoch 29/300
 - 10s - loss: 0.3265 - acc: 0.9413 - mDice: 0.7067 - val_loss: 0.8030 - val_acc: 0.9449 - val_mDice: 0.5853

Epoch 00029: val_mDice did not improve from 0.59103
Epoch 30/300
 - 11s - loss: 0.3230 - acc: 0.9415 - mDice: 0.7093 - val_loss: 0.8271 - val_acc: 0.9477 - val_mDice: 0.5763

Epoch 00030: val_mDice did not improve from 0.59103
Epoch 31/300
 - 11s - loss: 0.3244 - acc: 0.9414 - mDice: 0.7084 - val_loss: 0.8195 - val_acc: 0.9424 - val_mDice: 0.5794

Epoch 00031: val_mDice did not improve from 0.59103
Epoch 32/300
 - 10s - loss: 0.3215 - acc: 0.9417 - mDice: 0.7105 - val_loss: 0.8006 - val_acc: 0.9464 - val_mDice: 0.5841

Epoch 00032: val_mDice did not improve from 0.59103
Epoch 33/300
 - 11s - loss: 0.3185 - acc: 0.9420 - mDice: 0.7127 - val_loss: 0.8352 - val_acc: 0.9406 - val_mDice: 0.5748

Epoch 00033: val_mDice did not improve from 0.59103
Epoch 34/300
 - 10s - loss: 0.3179 - acc: 0.9421 - mDice: 0.7131 - val_loss: 0.7916 - val_acc: 0.9448 - val_mDice: 0.5815

Epoch 00034: val_mDice did not improve from 0.59103
Epoch 35/300
 - 10s - loss: 0.3178 - acc: 0.9420 - mDice: 0.7132 - val_loss: 0.8061 - val_acc: 0.9463 - val_mDice: 0.5699

Epoch 00035: val_mDice did not improve from 0.59103
Epoch 36/300
 - 11s - loss: 0.3159 - acc: 0.9422 - mDice: 0.7147 - val_loss: 0.8624 - val_acc: 0.9396 - val_mDice: 0.5492

Epoch 00036: val_mDice did not improve from 0.59103
Epoch 37/300
 - 10s - loss: 0.3142 - acc: 0.9425 - mDice: 0.7159 - val_loss: 0.7936 - val_acc: 0.9437 - val_mDice: 0.5788

Epoch 00037: val_mDice did not improve from 0.59103
Epoch 38/300
 - 11s - loss: 0.3123 - acc: 0.9426 - mDice: 0.7174 - val_loss: 0.8079 - val_acc: 0.9466 - val_mDice: 0.5729

Epoch 00038: val_mDice did not improve from 0.59103
Epoch 39/300
 - 11s - loss: 0.3112 - acc: 0.9427 - mDice: 0.7182 - val_loss: 0.7730 - val_acc: 0.9455 - val_mDice: 0.5869

Epoch 00039: val_mDice did not improve from 0.59103
Epoch 40/300
 - 11s - loss: 0.3115 - acc: 0.9426 - mDice: 0.7179 - val_loss: 0.7830 - val_acc: 0.9442 - val_mDice: 0.5793

Epoch 00040: val_mDice did not improve from 0.59103
Epoch 41/300
 - 11s - loss: 0.3110 - acc: 0.9428 - mDice: 0.7183 - val_loss: 0.8054 - val_acc: 0.9476 - val_mDice: 0.5711

Epoch 00041: val_mDice did not improve from 0.59103
Epoch 42/300
 - 11s - loss: 0.3090 - acc: 0.9430 - mDice: 0.7198 - val_loss: 0.7733 - val_acc: 0.9481 - val_mDice: 0.5759

Epoch 00042: val_mDice did not improve from 0.59103
Epoch 43/300
 - 11s - loss: 0.3082 - acc: 0.9429 - mDice: 0.7205 - val_loss: 0.8150 - val_acc: 0.9461 - val_mDice: 0.5627

Epoch 00043: val_mDice did not improve from 0.59103
Epoch 44/300
 - 10s - loss: 0.3052 - acc: 0.9434 - mDice: 0.7227 - val_loss: 0.7897 - val_acc: 0.9373 - val_mDice: 0.5615

Epoch 00044: val_mDice did not improve from 0.59103
Epoch 45/300
 - 11s - loss: 0.3042 - acc: 0.9435 - mDice: 0.7234 - val_loss: 0.7485 - val_acc: 0.9471 - val_mDice: 0.5735

Epoch 00045: val_mDice did not improve from 0.59103
Epoch 46/300
 - 10s - loss: 0.3031 - acc: 0.9436 - mDice: 0.7243 - val_loss: 0.7766 - val_acc: 0.9464 - val_mDice: 0.5754

Epoch 00046: val_mDice did not improve from 0.59103
Epoch 47/300
 - 10s - loss: 0.3025 - acc: 0.9435 - mDice: 0.7247 - val_loss: 0.7659 - val_acc: 0.9461 - val_mDice: 0.5720

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.09s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:11,  1.94s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:23,  1.78s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:08,  1.73s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:43,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:10,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:51,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:12,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:57,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:12,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:34,  1.87s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:42,  1.91s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:20,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:32,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:46,  1.95s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:47,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:19,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:18,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<07:57,  1.79s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:06,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:14,  1.87s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:53,  1.80s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:05,  1.85s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:41,  1.77s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:04,  1.86s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:11,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:48,  1.82s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:58,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:58,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:07,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:14,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:43,  1.83s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:55,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<08:00,  1.91s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:02,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:39,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:58,  1.94s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:38,  1.86s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:50,  1.92s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:26,  1.83s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:08,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:15,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:23,  1.84s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:17,  1.83s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:02,  1.78s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:13,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:23,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:16,  1.86s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<07:31,  1.93s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:06,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:06,  1.84s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:18,  1.90s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:07,  1.86s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:10,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:48,  1.79s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:55,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:48<07:13,  1.92s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:23,  1.97s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<07:01,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<07:02,  1.89s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<07:06,  1.92s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:56,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:54,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:59,  1.93s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:40,  1.85s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:45,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:51,  1.91s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:55,  1.94s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:40,  1.88s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:38,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:37,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:40,  1.91s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:39,  1.91s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:22,  1.84s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:12,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:11,  1.80s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:14,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:00,  1.76s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:03,  1.79s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:53,  1.75s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:47,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:07,  1.85s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:10,  1.87s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:55,  1.81s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:53,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:00,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<05:51,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<06:04,  1.89s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:49,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:59,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<06:02,  1.92s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:59,  1.91s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:57,  1.92s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<06:00,  1.95s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:52,  1.92s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:54,  1.94s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:42,  1.88s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:40,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:42,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:27,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:26,  1.84s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:24,  1.83s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:23,  1.84s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:26,  1.86s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:11,  1.79s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:13,  1.81s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:27,  1.91s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:17,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:19,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:16,  1.87s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<04:57,  1.78s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:07,  1.85s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:01,  1.83s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:51,  1.78s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:37,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:30,  1.67s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:30,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:05,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:01,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<03:54,  1.51s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<03:48,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<03:52,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<03:54,  1.54s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<03:50,  1.53s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:46,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<03:44,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<03:45,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:59,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<04:01,  1.67s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<03:53,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:45,  1.58s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:47,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:48,  1.62s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:43,  1.60s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:43,  1.61s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:35,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:26<03:36,  1.58s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:33,  1.57s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:31,  1.58s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:27,  1.56s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:23,  1.54s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:23,  1.55s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:40<03:19,  1.56s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:16,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:43<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:44<03:10,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:15,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<03:17,  1.61s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<03:22,  1.66s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:51<03:12,  1.59s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<03:08,  1.57s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<03:12,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<03:05,  1.61s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<03:00,  1.59s/it]predicting train subjects:  60%|██████    | 172/285 [05:03<02:54,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:05<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:06<02:48,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:08<02:51,  1.56s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:54,  1.60s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:11<02:48,  1.56s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:14<02:41,  1.52s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:52,  1.65s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:56,  1.72s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:47,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:22<02:40,  1.59s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:24<02:36,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:26<02:49,  1.71s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:30<02:57,  1.83s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:31<02:44,  1.71s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:39,  1.68s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:35<02:37,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:36<02:38,  1.70s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:38<02:32,  1.65s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:28,  1.64s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:41<02:24,  1.61s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:33,  1.72s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:37,  1.79s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:38,  1.82s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:21,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:21,  1.70s/it]predicting train subjects:  71%|███████   | 203/285 [05:55<02:21,  1.73s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:13,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:58<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:59<02:03,  1.56s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:01<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:03<02:13,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:17,  1.81s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:08<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<02:02,  1.67s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<02:02,  1.70s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:13<01:56,  1.64s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<02:00,  1.72s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:57,  1.72s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:58,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:49,  1.69s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:44,  1.64s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:45,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:29<01:41,  1.64s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:36,  1.59s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:31,  1.52s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:37,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:35<01:40,  1.74s/it]predicting train subjects:  80%|████████  | 228/285 [06:37<01:42,  1.80s/it]predicting train subjects:  80%|████████  | 229/285 [06:39<01:39,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:40<01:31,  1.66s/it]predicting train subjects:  81%|████████  | 231/285 [06:42<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:44<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:45<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:49<01:24,  1.68s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:51<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:52<01:26,  1.79s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:54<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:56<01:23,  1.81s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:57<01:15,  1.67s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:59<01:11,  1.61s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:00<01:06,  1.54s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:02<01:03,  1.50s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:06,  1.63s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:05<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:07<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:09<01:06,  1.76s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:11<01:05,  1.77s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:12<01:00,  1.68s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:14<00:56,  1.62s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:15<00:53,  1.57s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:17<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:19<00:53,  1.68s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:21<00:54,  1.75s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:22<00:52,  1.74s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:24<00:47,  1.63s/it]predicting train subjects:  90%|█████████ | 257/285 [07:25<00:44,  1.58s/it]predicting train subjects:  91%|█████████ | 258/285 [07:27<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:29<00:43,  1.67s/it]predicting train subjects:  91%|█████████ | 260/285 [07:30<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:32<00:38,  1.59s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:33<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:35<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:36<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:38<00:34,  1.72s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:40<00:31,  1.67s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:41<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:43<00:28,  1.68s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:45<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:46<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:48<00:22,  1.63s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:50<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:51<00:18,  1.58s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:53<00:16,  1.55s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:55<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:56<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:59<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:01<00:10,  1.68s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:03<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:04<00:06,  1.60s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:06<00:04,  1.55s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:08<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:10<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [08:12<00:00,  1.79s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:15,  1.96s/it]Loading train:   1%|          | 2/285 [00:03<08:25,  1.79s/it]Loading train:   1%|          | 3/285 [00:05<08:15,  1.76s/it]Loading train:   1%|▏         | 4/285 [00:06<08:00,  1.71s/it]Loading train:   2%|▏         | 5/285 [00:08<08:08,  1.74s/it]Loading train:   2%|▏         | 6/285 [00:09<07:32,  1.62s/it]Loading train:   2%|▏         | 7/285 [00:11<07:47,  1.68s/it]Loading train:   3%|▎         | 8/285 [00:13<07:30,  1.63s/it]Loading train:   3%|▎         | 9/285 [00:15<08:14,  1.79s/it]Loading train:   4%|▎         | 10/285 [00:16<07:46,  1.70s/it]Loading train:   4%|▍         | 11/285 [00:17<06:59,  1.53s/it]Loading train:   4%|▍         | 12/285 [00:19<06:41,  1.47s/it]Loading train:   5%|▍         | 13/285 [00:20<06:05,  1.34s/it]Loading train:   5%|▍         | 14/285 [00:21<05:49,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:22<05:46,  1.28s/it]Loading train:   6%|▌         | 16/285 [00:24<05:52,  1.31s/it]Loading train:   6%|▌         | 17/285 [00:25<05:34,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:26<05:25,  1.22s/it]Loading train:   7%|▋         | 19/285 [00:27<05:10,  1.17s/it]Loading train:   7%|▋         | 20/285 [00:28<05:08,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:30<05:51,  1.33s/it]Loading train:   8%|▊         | 22/285 [00:31<05:39,  1.29s/it]Loading train:   8%|▊         | 23/285 [00:32<05:35,  1.28s/it]Loading train:   8%|▊         | 24/285 [00:33<05:11,  1.19s/it]Loading train:   9%|▉         | 25/285 [00:34<05:14,  1.21s/it]Loading train:   9%|▉         | 26/285 [00:36<05:16,  1.22s/it]Loading train:   9%|▉         | 27/285 [00:37<04:57,  1.15s/it]Loading train:  10%|▉         | 28/285 [00:38<04:57,  1.16s/it]Loading train:  10%|█         | 29/285 [00:39<04:57,  1.16s/it]Loading train:  11%|█         | 30/285 [00:41<05:19,  1.25s/it]Loading train:  11%|█         | 31/285 [00:42<05:20,  1.26s/it]Loading train:  11%|█         | 32/285 [00:43<05:05,  1.21s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:03,  1.21s/it]Loading train:  12%|█▏        | 34/285 [00:45<04:53,  1.17s/it]Loading train:  12%|█▏        | 35/285 [00:46<05:03,  1.21s/it]Loading train:  13%|█▎        | 36/285 [00:48<05:06,  1.23s/it]Loading train:  13%|█▎        | 37/285 [00:49<04:59,  1.21s/it]Loading train:  13%|█▎        | 38/285 [00:50<05:00,  1.22s/it]Loading train:  14%|█▎        | 39/285 [00:51<04:52,  1.19s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:53,  1.20s/it]Loading train:  14%|█▍        | 41/285 [00:54<04:47,  1.18s/it]Loading train:  15%|█▍        | 42/285 [00:55<04:32,  1.12s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:32,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:38,  1.16s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:27,  1.12s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:46,  1.20s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:36,  1.16s/it]Loading train:  17%|█▋        | 48/285 [01:02<04:37,  1.17s/it]Loading train:  17%|█▋        | 49/285 [01:03<04:54,  1.25s/it]Loading train:  18%|█▊        | 50/285 [01:04<04:46,  1.22s/it]Loading train:  18%|█▊        | 51/285 [01:06<04:58,  1.27s/it]Loading train:  18%|█▊        | 52/285 [01:07<04:46,  1.23s/it]Loading train:  19%|█▊        | 53/285 [01:08<04:40,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:09<04:52,  1.26s/it]Loading train:  19%|█▉        | 55/285 [01:10<04:36,  1.20s/it]Loading train:  20%|█▉        | 56/285 [01:11<04:26,  1.16s/it]Loading train:  20%|██        | 57/285 [01:12<04:12,  1.11s/it]Loading train:  20%|██        | 58/285 [01:14<04:14,  1.12s/it]Loading train:  21%|██        | 59/285 [01:15<04:24,  1.17s/it]Loading train:  21%|██        | 60/285 [01:16<04:35,  1.23s/it]Loading train:  21%|██▏       | 61/285 [01:17<04:24,  1.18s/it]Loading train:  22%|██▏       | 62/285 [01:18<04:24,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:20<04:15,  1.15s/it]Loading train:  22%|██▏       | 64/285 [01:21<04:43,  1.28s/it]Loading train:  23%|██▎       | 65/285 [01:23<05:29,  1.50s/it]Loading train:  23%|██▎       | 66/285 [01:25<05:48,  1.59s/it]Loading train:  24%|██▎       | 67/285 [01:26<05:19,  1.47s/it]Loading train:  24%|██▍       | 68/285 [01:28<05:13,  1.44s/it]Loading train:  24%|██▍       | 69/285 [01:29<04:51,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:30<04:48,  1.34s/it]Loading train:  25%|██▍       | 71/285 [01:31<04:42,  1.32s/it]Loading train:  25%|██▌       | 72/285 [01:32<04:23,  1.24s/it]Loading train:  26%|██▌       | 73/285 [01:33<04:18,  1.22s/it]Loading train:  26%|██▌       | 74/285 [01:35<04:09,  1.18s/it]Loading train:  26%|██▋       | 75/285 [01:36<04:07,  1.18s/it]Loading train:  27%|██▋       | 76/285 [01:37<04:11,  1.20s/it]Loading train:  27%|██▋       | 77/285 [01:38<04:12,  1.21s/it]Loading train:  27%|██▋       | 78/285 [01:39<04:04,  1.18s/it]Loading train:  28%|██▊       | 79/285 [01:41<04:03,  1.18s/it]Loading train:  28%|██▊       | 80/285 [01:42<03:58,  1.16s/it]Loading train:  28%|██▊       | 81/285 [01:43<03:50,  1.13s/it]Loading train:  29%|██▉       | 82/285 [01:44<03:49,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:45<03:51,  1.15s/it]Loading train:  29%|██▉       | 84/285 [01:46<03:44,  1.12s/it]Loading train:  30%|██▉       | 85/285 [01:47<03:51,  1.16s/it]Loading train:  30%|███       | 86/285 [01:49<03:53,  1.17s/it]Loading train:  31%|███       | 87/285 [01:50<03:48,  1.16s/it]Loading train:  31%|███       | 88/285 [01:51<03:41,  1.12s/it]Loading train:  31%|███       | 89/285 [01:52<03:37,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:53<03:43,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:54<03:36,  1.12s/it]Loading train:  32%|███▏      | 92/285 [01:55<03:38,  1.13s/it]Loading train:  33%|███▎      | 93/285 [01:56<03:30,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:57<03:31,  1.11s/it]Loading train:  33%|███▎      | 95/285 [01:59<03:46,  1.19s/it]Loading train:  34%|███▎      | 96/285 [02:00<03:51,  1.23s/it]Loading train:  34%|███▍      | 97/285 [02:01<03:46,  1.20s/it]Loading train:  34%|███▍      | 98/285 [02:02<03:50,  1.23s/it]Loading train:  35%|███▍      | 99/285 [02:04<03:41,  1.19s/it]Loading train:  35%|███▌      | 100/285 [02:05<03:51,  1.25s/it]Loading train:  35%|███▌      | 101/285 [02:06<03:57,  1.29s/it]Loading train:  36%|███▌      | 102/285 [02:08<03:55,  1.28s/it]Loading train:  36%|███▌      | 103/285 [02:09<03:52,  1.28s/it]Loading train:  36%|███▋      | 104/285 [02:10<03:55,  1.30s/it]Loading train:  37%|███▋      | 105/285 [02:11<03:50,  1.28s/it]Loading train:  37%|███▋      | 106/285 [02:13<03:46,  1.27s/it]Loading train:  38%|███▊      | 107/285 [02:14<03:44,  1.26s/it]Loading train:  38%|███▊      | 108/285 [02:15<03:41,  1.25s/it]Loading train:  38%|███▊      | 109/285 [02:16<03:32,  1.21s/it]Loading train:  39%|███▊      | 110/285 [02:18<03:34,  1.23s/it]Loading train:  39%|███▉      | 111/285 [02:19<03:28,  1.20s/it]Loading train:  39%|███▉      | 112/285 [02:20<03:33,  1.23s/it]Loading train:  40%|███▉      | 113/285 [02:21<03:36,  1.26s/it]Loading train:  40%|████      | 114/285 [02:23<03:32,  1.24s/it]Loading train:  40%|████      | 115/285 [02:24<03:26,  1.22s/it]Loading train:  41%|████      | 116/285 [02:25<03:23,  1.21s/it]Loading train:  41%|████      | 117/285 [02:26<03:28,  1.24s/it]Loading train:  41%|████▏     | 118/285 [02:27<03:20,  1.20s/it]Loading train:  42%|████▏     | 119/285 [02:28<03:18,  1.19s/it]Loading train:  42%|████▏     | 120/285 [02:30<03:19,  1.21s/it]Loading train:  42%|████▏     | 121/285 [02:31<03:33,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:33<03:31,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:34<03:34,  1.32s/it]Loading train:  44%|████▎     | 124/285 [02:35<03:24,  1.27s/it]Loading train:  44%|████▍     | 125/285 [02:36<03:10,  1.19s/it]Loading train:  44%|████▍     | 126/285 [02:37<03:05,  1.17s/it]Loading train:  45%|████▍     | 127/285 [02:38<02:57,  1.12s/it]Loading train:  45%|████▍     | 128/285 [02:39<02:57,  1.13s/it]Loading train:  45%|████▌     | 129/285 [02:40<02:51,  1.10s/it]Loading train:  46%|████▌     | 130/285 [02:41<02:51,  1.11s/it]Loading train:  46%|████▌     | 131/285 [02:42<02:43,  1.06s/it]Loading train:  46%|████▋     | 132/285 [02:44<02:44,  1.08s/it]Loading train:  47%|████▋     | 133/285 [02:45<02:39,  1.05s/it]Loading train:  47%|████▋     | 134/285 [02:45<02:33,  1.02s/it]Loading train:  47%|████▋     | 135/285 [02:46<02:25,  1.03it/s]Loading train:  48%|████▊     | 136/285 [02:47<02:26,  1.01it/s]Loading train:  48%|████▊     | 137/285 [02:48<02:25,  1.01it/s]Loading train:  48%|████▊     | 138/285 [02:49<02:24,  1.02it/s]Loading train:  49%|████▉     | 139/285 [02:50<02:26,  1.00s/it]Loading train:  49%|████▉     | 140/285 [02:51<02:27,  1.01s/it]Loading train:  49%|████▉     | 141/285 [02:52<02:19,  1.03it/s]Loading train:  50%|████▉     | 142/285 [02:53<02:20,  1.02it/s]Loading train:  50%|█████     | 143/285 [02:54<02:18,  1.02it/s]Loading train:  51%|█████     | 144/285 [02:55<02:23,  1.02s/it]Loading train:  51%|█████     | 145/285 [02:57<02:28,  1.06s/it]Loading train:  51%|█████     | 146/285 [02:58<02:27,  1.06s/it]Loading train:  52%|█████▏    | 147/285 [02:59<02:24,  1.05s/it]Loading train:  52%|█████▏    | 148/285 [03:00<02:22,  1.04s/it]Loading train:  52%|█████▏    | 149/285 [03:01<02:17,  1.01s/it]Loading train:  53%|█████▎    | 150/285 [03:01<02:11,  1.03it/s]Loading train:  53%|█████▎    | 151/285 [03:03<02:16,  1.02s/it]Loading train:  53%|█████▎    | 152/285 [03:04<02:13,  1.00s/it]Loading train:  54%|█████▎    | 153/285 [03:04<02:07,  1.04it/s]Loading train:  54%|█████▍    | 154/285 [03:05<02:02,  1.07it/s]Loading train:  54%|█████▍    | 155/285 [03:06<02:03,  1.05it/s]Loading train:  55%|█████▍    | 156/285 [03:07<02:07,  1.02it/s]Loading train:  55%|█████▌    | 157/285 [03:08<02:07,  1.00it/s]Loading train:  55%|█████▌    | 158/285 [03:09<02:05,  1.01it/s]Loading train:  56%|█████▌    | 159/285 [03:10<02:05,  1.00it/s]Loading train:  56%|█████▌    | 160/285 [03:11<02:03,  1.01it/s]Loading train:  56%|█████▋    | 161/285 [03:12<02:03,  1.00it/s]Loading train:  57%|█████▋    | 162/285 [03:13<02:04,  1.01s/it]Loading train:  57%|█████▋    | 163/285 [03:14<02:04,  1.02s/it]Loading train:  58%|█████▊    | 164/285 [03:15<02:00,  1.00it/s]Loading train:  58%|█████▊    | 165/285 [03:16<02:04,  1.04s/it]Loading train:  58%|█████▊    | 166/285 [03:18<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [03:19<02:00,  1.02s/it]Loading train:  59%|█████▉    | 168/285 [03:20<02:02,  1.05s/it]Loading train:  59%|█████▉    | 169/285 [03:21<02:01,  1.05s/it]Loading train:  60%|█████▉    | 170/285 [03:22<01:57,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:23<01:55,  1.01s/it]Loading train:  60%|██████    | 172/285 [03:24<01:54,  1.01s/it]Loading train:  61%|██████    | 173/285 [03:25<01:51,  1.00it/s]Loading train:  61%|██████    | 174/285 [03:26<01:50,  1.00it/s]Loading train:  61%|██████▏   | 175/285 [03:27<01:48,  1.01it/s]Loading train:  62%|██████▏   | 176/285 [03:28<01:53,  1.05s/it]Loading train:  62%|██████▏   | 177/285 [03:29<01:50,  1.03s/it]Loading train:  62%|██████▏   | 178/285 [03:30<01:51,  1.05s/it]Loading train:  63%|██████▎   | 179/285 [03:31<01:47,  1.01s/it]Loading train:  63%|██████▎   | 180/285 [03:32<01:50,  1.05s/it]Loading train:  64%|██████▎   | 181/285 [03:33<02:01,  1.17s/it]Loading train:  64%|██████▍   | 182/285 [03:34<01:56,  1.14s/it]Loading train:  64%|██████▍   | 183/285 [03:36<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [03:36<01:49,  1.08s/it]Loading train:  65%|██████▍   | 185/285 [03:37<01:46,  1.06s/it]Loading train:  65%|██████▌   | 186/285 [03:39<01:51,  1.13s/it]Loading train:  66%|██████▌   | 187/285 [03:40<01:54,  1.17s/it]Loading train:  66%|██████▌   | 188/285 [03:41<01:58,  1.22s/it]Loading train:  66%|██████▋   | 189/285 [03:42<01:49,  1.14s/it]Loading train:  67%|██████▋   | 190/285 [03:43<01:44,  1.10s/it]Loading train:  67%|██████▋   | 191/285 [03:44<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [03:46<01:44,  1.13s/it]Loading train:  68%|██████▊   | 193/285 [03:47<01:44,  1.13s/it]Loading train:  68%|██████▊   | 194/285 [03:48<01:44,  1.15s/it]Loading train:  68%|██████▊   | 195/285 [03:49<01:36,  1.07s/it]Loading train:  69%|██████▉   | 196/285 [03:50<01:37,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:51<01:36,  1.09s/it]Loading train:  69%|██████▉   | 198/285 [03:52<01:37,  1.13s/it]Loading train:  70%|██████▉   | 199/285 [03:53<01:32,  1.08s/it]Loading train:  70%|███████   | 200/285 [03:54<01:28,  1.04s/it]Loading train:  71%|███████   | 201/285 [03:56<01:34,  1.12s/it]Loading train:  71%|███████   | 202/285 [03:57<01:30,  1.09s/it]Loading train:  71%|███████   | 203/285 [03:58<01:28,  1.08s/it]Loading train:  72%|███████▏  | 204/285 [03:59<01:23,  1.03s/it]Loading train:  72%|███████▏  | 205/285 [04:00<01:23,  1.04s/it]Loading train:  72%|███████▏  | 206/285 [04:01<01:23,  1.06s/it]Loading train:  73%|███████▎  | 207/285 [04:02<01:26,  1.11s/it]Loading train:  73%|███████▎  | 208/285 [04:03<01:33,  1.21s/it]Loading train:  73%|███████▎  | 209/285 [04:05<01:32,  1.22s/it]Loading train:  74%|███████▎  | 210/285 [04:06<01:23,  1.12s/it]Loading train:  74%|███████▍  | 211/285 [04:06<01:19,  1.07s/it]Loading train:  74%|███████▍  | 212/285 [04:08<01:17,  1.06s/it]Loading train:  75%|███████▍  | 213/285 [04:09<01:14,  1.04s/it]Loading train:  75%|███████▌  | 214/285 [04:09<01:11,  1.01s/it]Loading train:  75%|███████▌  | 215/285 [04:11<01:16,  1.09s/it]Loading train:  76%|███████▌  | 216/285 [04:12<01:18,  1.14s/it]Loading train:  76%|███████▌  | 217/285 [04:13<01:19,  1.18s/it]Loading train:  76%|███████▋  | 218/285 [04:14<01:19,  1.19s/it]Loading train:  77%|███████▋  | 219/285 [04:16<01:17,  1.17s/it]Loading train:  77%|███████▋  | 220/285 [04:17<01:11,  1.11s/it]Loading train:  78%|███████▊  | 221/285 [04:17<01:07,  1.05s/it]Loading train:  78%|███████▊  | 222/285 [04:18<01:05,  1.04s/it]Loading train:  78%|███████▊  | 223/285 [04:19<01:03,  1.03s/it]Loading train:  79%|███████▊  | 224/285 [04:21<01:04,  1.06s/it]Loading train:  79%|███████▉  | 225/285 [04:22<01:04,  1.08s/it]Loading train:  79%|███████▉  | 226/285 [04:23<01:04,  1.10s/it]Loading train:  80%|███████▉  | 227/285 [04:24<01:07,  1.17s/it]Loading train:  80%|████████  | 228/285 [04:25<01:05,  1.14s/it]Loading train:  80%|████████  | 229/285 [04:26<01:01,  1.10s/it]Loading train:  81%|████████  | 230/285 [04:27<01:00,  1.09s/it]Loading train:  81%|████████  | 231/285 [04:28<00:57,  1.07s/it]Loading train:  81%|████████▏ | 232/285 [04:29<00:56,  1.07s/it]Loading train:  82%|████████▏ | 233/285 [04:31<00:59,  1.13s/it]Loading train:  82%|████████▏ | 234/285 [04:32<00:58,  1.15s/it]Loading train:  82%|████████▏ | 235/285 [04:33<00:54,  1.10s/it]Loading train:  83%|████████▎ | 236/285 [04:34<00:56,  1.15s/it]Loading train:  83%|████████▎ | 237/285 [04:36<00:58,  1.23s/it]Loading train:  84%|████████▎ | 238/285 [04:37<00:57,  1.21s/it]Loading train:  84%|████████▍ | 239/285 [04:38<00:53,  1.17s/it]Loading train:  84%|████████▍ | 240/285 [04:39<00:50,  1.13s/it]Loading train:  85%|████████▍ | 241/285 [04:40<00:47,  1.09s/it]Loading train:  85%|████████▍ | 242/285 [04:41<00:45,  1.05s/it]Loading train:  85%|████████▌ | 243/285 [04:42<00:42,  1.01s/it]Loading train:  86%|████████▌ | 244/285 [04:43<00:44,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:44<00:42,  1.06s/it]Loading train:  86%|████████▋ | 246/285 [04:45<00:42,  1.10s/it]Loading train:  87%|████████▋ | 247/285 [04:46<00:42,  1.13s/it]Loading train:  87%|████████▋ | 248/285 [04:47<00:40,  1.10s/it]Loading train:  87%|████████▋ | 249/285 [04:49<00:39,  1.11s/it]Loading train:  88%|████████▊ | 250/285 [04:49<00:36,  1.04s/it]Loading train:  88%|████████▊ | 251/285 [04:50<00:35,  1.04s/it]Loading train:  88%|████████▊ | 252/285 [04:52<00:36,  1.11s/it]Loading train:  89%|████████▉ | 253/285 [04:53<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [04:55<00:39,  1.28s/it]Loading train:  89%|████████▉ | 255/285 [04:56<00:37,  1.27s/it]Loading train:  90%|████████▉ | 256/285 [04:57<00:34,  1.19s/it]Loading train:  90%|█████████ | 257/285 [04:58<00:32,  1.15s/it]Loading train:  91%|█████████ | 258/285 [04:59<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [05:00<00:29,  1.13s/it]Loading train:  91%|█████████ | 260/285 [05:01<00:28,  1.13s/it]Loading train:  92%|█████████▏| 261/285 [05:02<00:26,  1.09s/it]Loading train:  92%|█████████▏| 262/285 [05:03<00:24,  1.07s/it]Loading train:  92%|█████████▏| 263/285 [05:04<00:23,  1.07s/it]Loading train:  93%|█████████▎| 264/285 [05:06<00:24,  1.16s/it]Loading train:  93%|█████████▎| 265/285 [05:07<00:24,  1.21s/it]Loading train:  93%|█████████▎| 266/285 [05:08<00:22,  1.20s/it]Loading train:  94%|█████████▎| 267/285 [05:09<00:20,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [05:10<00:19,  1.16s/it]Loading train:  94%|█████████▍| 269/285 [05:11<00:18,  1.16s/it]Loading train:  95%|█████████▍| 270/285 [05:13<00:17,  1.19s/it]Loading train:  95%|█████████▌| 271/285 [05:14<00:15,  1.14s/it]Loading train:  95%|█████████▌| 272/285 [05:15<00:15,  1.23s/it]Loading train:  96%|█████████▌| 273/285 [05:16<00:13,  1.15s/it]Loading train:  96%|█████████▌| 274/285 [05:17<00:12,  1.14s/it]Loading train:  96%|█████████▋| 275/285 [05:19<00:11,  1.17s/it]Loading train:  97%|█████████▋| 276/285 [05:20<00:10,  1.19s/it]Loading train:  97%|█████████▋| 277/285 [05:21<00:08,  1.11s/it]Loading train:  98%|█████████▊| 278/285 [05:22<00:08,  1.21s/it]Loading train:  98%|█████████▊| 279/285 [05:23<00:06,  1.16s/it]Loading train:  98%|█████████▊| 280/285 [05:24<00:05,  1.12s/it]Loading train:  99%|█████████▊| 281/285 [05:25<00:04,  1.07s/it]Loading train:  99%|█████████▉| 282/285 [05:26<00:03,  1.11s/it]Loading train:  99%|█████████▉| 283/285 [05:28<00:02,  1.19s/it]Loading train: 100%|█████████▉| 284/285 [05:29<00:01,  1.18s/it]Loading train: 100%|██████████| 285/285 [05:30<00:00,  1.25s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 111.91it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:02, 103.68it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:02, 109.69it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:02, 104.10it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:02, 94.12it/s] concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 98.26it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:01, 114.77it/s]concatenating: train:  33%|███▎      | 95/285 [00:00<00:01, 117.95it/s]concatenating: train:  38%|███▊      | 108/285 [00:00<00:01, 116.02it/s]concatenating: train:  43%|████▎     | 122/285 [00:01<00:01, 119.81it/s]concatenating: train:  47%|████▋     | 135/285 [00:01<00:01, 108.14it/s]concatenating: train:  52%|█████▏    | 147/285 [00:01<00:01, 101.17it/s]concatenating: train:  59%|█████▉    | 169/285 [00:01<00:00, 119.93it/s]concatenating: train:  68%|██████▊   | 195/285 [00:01<00:00, 142.13it/s]concatenating: train:  76%|███████▋  | 218/285 [00:01<00:00, 160.51it/s]concatenating: train:  83%|████████▎ | 237/285 [00:01<00:00, 142.74it/s]concatenating: train:  89%|████████▉ | 254/285 [00:01<00:00, 134.20it/s]concatenating: train:  95%|█████████▍| 270/285 [00:02<00:00, 131.26it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 129.34it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.99s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.77s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 55.01it/s]2019-07-11 12:05:22.006935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 12:05:22.007031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 12:05:22.007045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 12:05:22.007054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 12:05:22.007441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.39it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.11it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.19it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.70it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.96it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.89it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.21it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.74it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.22it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.76it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.13it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.46it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.17it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.24it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.72it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.31it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.69it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.04it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.28it/s]
Epoch 00047: val_mDice did not improve from 0.59103
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [2.023016021365211, 2.154741332644508, 1.367657570611863, 1.11942153885251, 1.0446251574016752, 1.0601565099897838, 0.9989014353070941, 1.0328678006217593, 0.9811191047940936, 0.9444733517510551, 0.9930653401783535, 0.9521318844386509, 0.9067093985421317, 0.9396008593695504, 0.8895936466398693, 0.9025263559250605, 0.9253033683413551, 0.8938650403703962, 0.9000956501279559, 0.8585977781386602, 0.8297943103881109, 0.8843569131124587, 0.8700081791196551, 0.867225243931725, 0.8255146174203782, 0.8506856362024943, 0.8299630880355835, 0.8337750207810175, 0.8029803094409761, 0.8270581165949503, 0.8195203542709351, 0.8005782252266294, 0.8352369070053101, 0.791647405851455, 0.8060605639503116, 0.8623782226017543, 0.7936330579576039, 0.8078520695368449, 0.7729838575635638, 0.7829662731715611, 0.805351972579956, 0.7733017319724673, 0.8149529071081252, 0.7897332963489351, 0.7485496259870983, 0.7765515418279738, 0.7658520028704688], 'val_acc': [0.9035554045722598, 0.9102312553496588, 0.9097527237165541, 0.9399450307800656, 0.9407440367199126, 0.943072327545711, 0.9474267618996757, 0.9366208996091571, 0.9365613375391278, 0.9434020036742801, 0.9420306597437177, 0.9419139084361848, 0.9486240971656072, 0.9427197660718646, 0.9475503734179905, 0.930425797189985, 0.9391002825328282, 0.9435302359717233, 0.9401030455316816, 0.9416323077111017, 0.9407966988427299, 0.9473763732683091, 0.9465705213092622, 0.9457096996761504, 0.9459088615008763, 0.9468131604648772, 0.9419505454245067, 0.9464468587012518, 0.9448901301338559, 0.9476763038408189, 0.9423672273045495, 0.9463782026654198, 0.9405792412303743, 0.9448077054250807, 0.9462614683877855, 0.9396245337667919, 0.9437477049373445, 0.9466483337538583, 0.9454670520055861, 0.9441872522944496, 0.947648789201464, 0.9481433175858998, 0.9461424095290047, 0.9373260140419006, 0.9470535431589399, 0.9464239875475565, 0.9460599706286476], 'val_mDice': [0.2441052006823676, 0.21486123620707076, 0.45543877425647916, 0.5618161472181479, 0.578333987721375, 0.5824568688514686, 0.5910281159338497, 0.5663949192634651, 0.5692680873686359, 0.5756261659165224, 0.5779615161674363, 0.5652836140777383, 0.5792502260633877, 0.5727079269431886, 0.582713244748967, 0.55684445053339, 0.5555980883183933, 0.5840011916699863, 0.5711047959824403, 0.5745021800200144, 0.5820843258074352, 0.5806237554975918, 0.576236112841538, 0.5691840831367743, 0.5852998338994526, 0.5784428797307468, 0.5794083479614485, 0.5683781249182565, 0.5853242645306247, 0.5762785087738719, 0.5793698939184347, 0.5840871302144868, 0.5748466677254155, 0.5815222864704472, 0.5698993092491513, 0.549224371711413, 0.5787534344763983, 0.5729095359288511, 0.5868669590424924, 0.5793085777688594, 0.571114898792335, 0.5759244188666344, 0.5627474039793015, 0.5615404088582311, 0.5734973789325782, 0.5754063257149288, 0.5719998464697883], 'loss': [2.725897774476639, 1.0784056468783993, 0.6351703238758435, 0.5137437897850512, 0.46761474572948025, 0.44276989218194474, 0.4230286461529714, 0.41396445380094676, 0.40226035300123, 0.3952413213972368, 0.3849640067071383, 0.37870502598326583, 0.37434212945319795, 0.36746243545033236, 0.36352215177846914, 0.36104348188125035, 0.35724792240073694, 0.3527803124376223, 0.3512234388690292, 0.346501521305103, 0.34486729279519596, 0.3406603638034624, 0.33944615955547675, 0.3369067513129144, 0.3349991319139086, 0.3328457695970835, 0.3298345912576112, 0.3293368323175163, 0.32654734861076234, 0.3229673323326541, 0.32440743020372814, 0.3215150883978264, 0.31845317838140047, 0.3178722189413644, 0.31782332075936087, 0.3158502774372344, 0.3141908118358025, 0.3122859081195595, 0.31118055555846663, 0.3114978093528233, 0.31104678370048483, 0.30898925948745143, 0.3082467623188566, 0.30516865769631374, 0.3042356687082085, 0.30308065754911767, 0.3025401304952667], 'acc': [0.644197261540881, 0.8798282217124489, 0.8958982154195516, 0.9102779626616491, 0.9206525243981073, 0.9261453354062201, 0.9293412212487105, 0.9315720667194626, 0.9331593134740149, 0.934527474583195, 0.9353918241746674, 0.9360254359930174, 0.9365568365438471, 0.9371611997987899, 0.9377886546538334, 0.938039951904077, 0.938293564967712, 0.9386642458169061, 0.9390507520497684, 0.9394370752169674, 0.9396032835560679, 0.9398684168059587, 0.9401515742154486, 0.9402605542356117, 0.9403698547097422, 0.9406428889707033, 0.9410129892060769, 0.9411010878587565, 0.9412793046549747, 0.9415201489604091, 0.9413899734504241, 0.9417147017154984, 0.9420148938497827, 0.9420554904274014, 0.941990841048656, 0.942233057536439, 0.9424547167993681, 0.9425931457887616, 0.9426706560618252, 0.9426278789907102, 0.9428438864761818, 0.9429647995829468, 0.9428752624669101, 0.943377907206747, 0.9434810683335186, 0.9435704616491841, 0.9435347320832612], 'mDice': [0.10809422903020005, 0.34562594040938144, 0.5155096647710453, 0.5825061759140672, 0.6107583190748084, 0.626775416296894, 0.6396940537723521, 0.6458557459208141, 0.6535337665578821, 0.658414730658898, 0.6654044617249691, 0.6695556348404812, 0.6725824631683073, 0.6773207217069956, 0.6802083048053805, 0.681944389758782, 0.6846076710182324, 0.68778593856888, 0.688933770149136, 0.6922775068240794, 0.6935445513136014, 0.6964762061231049, 0.6974045469141751, 0.6992225773605235, 0.7005550159018968, 0.7021070217750701, 0.7044169954741555, 0.7046797040778823, 0.7067126837083777, 0.7093424500471277, 0.7083608988095782, 0.7105032266484811, 0.7127334284074555, 0.7131282486896283, 0.713176444612396, 0.7146601996854801, 0.7159181010270362, 0.7173829991532034, 0.7181963954607095, 0.717941644680346, 0.7182924309883684, 0.7198492180572578, 0.7204642218157163, 0.7227352612598199, 0.7233572214560309, 0.7243339853500939, 0.7246988588430208]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 30)   16230       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 30)   8130        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 90)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 254,643
Trainable params: 79,783
Non-trainable params: 174,860
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 21s - loss: 1.9894 - acc: 0.5911 - mDice: 0.2307 - val_loss: 1.9205 - val_acc: 0.9162 - val_mDice: 0.2766

Epoch 00001: val_mDice improved from -inf to 0.27659, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 16s - loss: 0.6841 - acc: 0.9083 - mDice: 0.4955 - val_loss: 0.6116 - val_acc: 0.9324 - val_mDice: 0.5342

Epoch 00002: val_mDice improved from 0.27659 to 0.53419, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.5248 - acc: 0.9155 - mDice: 0.5800 - val_loss: 0.5108 - val_acc: 0.9447 - val_mDice: 0.5890

Epoch 00003: val_mDice improved from 0.53419 to 0.58896, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4596 - acc: 0.9210 - mDice: 0.6200 - val_loss: 0.5185 - val_acc: 0.9469 - val_mDice: 0.5893

Epoch 00004: val_mDice improved from 0.58896 to 0.58930, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 16s - loss: 0.4266 - acc: 0.9252 - mDice: 0.6411 - val_loss: 0.5559 - val_acc: 0.9448 - val_mDice: 0.5719

Epoch 00005: val_mDice did not improve from 0.58930
Epoch 6/300
 - 15s - loss: 0.4037 - acc: 0.9294 - mDice: 0.6561 - val_loss: 0.5183 - val_acc: 0.9480 - val_mDice: 0.5908

Epoch 00006: val_mDice improved from 0.58930 to 0.59077, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 16s - loss: 0.3816 - acc: 0.9344 - mDice: 0.6711 - val_loss: 0.5033 - val_acc: 0.9493 - val_mDice: 0.5984

Epoch 00007: val_mDice improved from 0.59077 to 0.59837, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 16s - loss: 0.3671 - acc: 0.9415 - mDice: 0.6806 - val_loss: 0.4658 - val_acc: 0.9520 - val_mDice: 0.6180

Epoch 00008: val_mDice improved from 0.59837 to 0.61798, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 16s - loss: 0.3528 - acc: 0.9470 - mDice: 0.6897 - val_loss: 0.4800 - val_acc: 0.9512 - val_mDice: 0.6092

Epoch 00009: val_mDice did not improve from 0.61798
Epoch 10/300
 - 16s - loss: 0.3439 - acc: 0.9487 - mDice: 0.6958 - val_loss: 0.4871 - val_acc: 0.9509 - val_mDice: 0.6068

Epoch 00010: val_mDice did not improve from 0.61798
Epoch 11/300
 - 16s - loss: 0.3356 - acc: 0.9495 - mDice: 0.7015 - val_loss: 0.4694 - val_acc: 0.9522 - val_mDice: 0.6156

Epoch 00011: val_mDice did not improve from 0.61798
Epoch 12/300
 - 16s - loss: 0.3256 - acc: 0.9503 - mDice: 0.7088 - val_loss: 0.4752 - val_acc: 0.9517 - val_mDice: 0.6133

Epoch 00012: val_mDice did not improve from 0.61798
Epoch 13/300
 - 16s - loss: 0.3197 - acc: 0.9508 - mDice: 0.7130 - val_loss: 0.4682 - val_acc: 0.9506 - val_mDice: 0.6146

Epoch 00013: val_mDice did not improve from 0.61798
Epoch 14/300
 - 16s - loss: 0.3155 - acc: 0.9512 - mDice: 0.7161 - val_loss: 0.4853 - val_acc: 0.9523 - val_mDice: 0.6106

Epoch 00014: val_mDice did not improve from 0.61798
Epoch 15/300
 - 15s - loss: 0.3100 - acc: 0.9517 - mDice: 0.7201 - val_loss: 0.4856 - val_acc: 0.9514 - val_mDice: 0.6105

Epoch 00015: val_mDice did not improve from 0.61798
Epoch 16/300
 - 16s - loss: 0.3050 - acc: 0.9520 - mDice: 0.7238 - val_loss: 0.4743 - val_acc: 0.9522 - val_mDice: 0.6160

Epoch 00016: val_mDice did not improve from 0.61798
Epoch 17/300
 - 16s - loss: 0.3007 - acc: 0.9524 - mDice: 0.7270 - val_loss: 0.5446 - val_acc: 0.9473 - val_mDice: 0.5833

Epoch 00017: val_mDice did not improve from 0.61798
Epoch 18/300
 - 15s - loss: 0.2959 - acc: 0.9527 - mDice: 0.7306 - val_loss: 0.4698 - val_acc: 0.9519 - val_mDice: 0.6152

Epoch 00018: val_mDice did not improve from 0.61798
Epoch 19/300
 - 16s - loss: 0.2913 - acc: 0.9532 - mDice: 0.7341 - val_loss: 0.4738 - val_acc: 0.9518 - val_mDice: 0.6133

Epoch 00019: val_mDice did not improve from 0.61798
Epoch 20/300
 - 15s - loss: 0.2932 - acc: 0.9530 - mDice: 0.7329 - val_loss: 0.4616 - val_acc: 0.9529 - val_mDice: 0.6195

Epoch 00020: val_mDice improved from 0.61798 to 0.61950, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 16s - loss: 0.2847 - acc: 0.9536 - mDice: 0.7391 - val_loss: 0.4725 - val_acc: 0.9523 - val_mDice: 0.6150

Epoch 00021: val_mDice did not improve from 0.61950
Epoch 22/300
 - 15s - loss: 0.2816 - acc: 0.9537 - mDice: 0.7413 - val_loss: 0.4653 - val_acc: 0.9534 - val_mDice: 0.6216

Epoch 00022: val_mDice improved from 0.61950 to 0.62164, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 15s - loss: 0.2807 - acc: 0.9539 - mDice: 0.7422 - val_loss: 0.4682 - val_acc: 0.9517 - val_mDice: 0.6167

Epoch 00023: val_mDice did not improve from 0.62164
Epoch 24/300
 - 15s - loss: 0.2790 - acc: 0.9540 - mDice: 0.7434 - val_loss: 0.4714 - val_acc: 0.9534 - val_mDice: 0.6210

Epoch 00024: val_mDice did not improve from 0.62164
Epoch 25/300
 - 15s - loss: 0.2754 - acc: 0.9544 - mDice: 0.7463 - val_loss: 0.4779 - val_acc: 0.9542 - val_mDice: 0.6151

Epoch 00025: val_mDice did not improve from 0.62164
Epoch 26/300
 - 16s - loss: 0.2741 - acc: 0.9544 - mDice: 0.7473 - val_loss: 0.4814 - val_acc: 0.9527 - val_mDice: 0.6126

Epoch 00026: val_mDice did not improve from 0.62164
Epoch 27/300
 - 15s - loss: 0.2696 - acc: 0.9547 - mDice: 0.7506 - val_loss: 0.4726 - val_acc: 0.9539 - val_mDice: 0.6152

Epoch 00027: val_mDice did not improve from 0.62164
Epoch 28/300
 - 16s - loss: 0.2690 - acc: 0.9548 - mDice: 0.7513 - val_loss: 0.4752 - val_acc: 0.9543 - val_mDice: 0.6156

Epoch 00028: val_mDice did not improve from 0.62164
Epoch 29/300
 - 15s - loss: 0.2653 - acc: 0.9550 - mDice: 0.7540 - val_loss: 0.4522 - val_acc: 0.9534 - val_mDice: 0.6262

Epoch 00029: val_mDice improved from 0.62164 to 0.62619, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 17s - loss: 0.2649 - acc: 0.9551 - mDice: 0.7545 - val_loss: 0.4546 - val_acc: 0.9534 - val_mDice: 0.6245

Epoch 00030: val_mDice did not improve from 0.62619
Epoch 31/300
 - 15s - loss: 0.2644 - acc: 0.9551 - mDice: 0.7547 - val_loss: 0.4712 - val_acc: 0.9539 - val_mDice: 0.6164

Epoch 00031: val_mDice did not improve from 0.62619
Epoch 32/300
 - 15s - loss: 0.2613 - acc: 0.9553 - mDice: 0.7571 - val_loss: 0.4635 - val_acc: 0.9537 - val_mDice: 0.6207

Epoch 00032: val_mDice did not improve from 0.62619
Epoch 33/300
 - 15s - loss: 0.2604 - acc: 0.9554 - mDice: 0.7580 - val_loss: 0.4743 - val_acc: 0.9537 - val_mDice: 0.6134

Epoch 00033: val_mDice did not improve from 0.62619
Epoch 34/300
 - 16s - loss: 0.2579 - acc: 0.9556 - mDice: 0.7599 - val_loss: 0.4856 - val_acc: 0.9535 - val_mDice: 0.6097

Epoch 00034: val_mDice did not improve from 0.62619
Epoch 35/300
 - 15s - loss: 0.2549 - acc: 0.9558 - mDice: 0.7622 - val_loss: 0.4728 - val_acc: 0.9521 - val_mDice: 0.6173

Epoch 00035: val_mDice did not improve from 0.62619
Epoch 36/300
 - 15s - loss: 0.2556 - acc: 0.9559 - mDice: 0.7617 - val_loss: 0.4452 - val_acc: 0.9523 - val_mDice: 0.6283

Epoch 00036: val_mDice improved from 0.62619 to 0.62833, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 15s - loss: 0.2520 - acc: 0.9561 - mDice: 0.7647 - val_loss: 0.4818 - val_acc: 0.9543 - val_mDice: 0.6117

Epoch 00037: val_mDice did not improve from 0.62833
Epoch 38/300
 - 16s - loss: 0.2769 - acc: 0.9542 - mDice: 0.7462 - val_loss: 0.5003 - val_acc: 0.9533 - val_mDice: 0.6034

Epoch 00038: val_mDice did not improve from 0.62833
Epoch 39/300
 - 15s - loss: 0.2588 - acc: 0.9556 - mDice: 0.7592 - val_loss: 0.4846 - val_acc: 0.9526 - val_mDice: 0.6093

Epoch 00039: val_mDice did not improve from 0.62833
Epoch 40/300
 - 15s - loss: 0.2520 - acc: 0.9561 - mDice: 0.7646 - val_loss: 0.4704 - val_acc: 0.9541 - val_mDice: 0.6172

Epoch 00040: val_mDice did not improve from 0.62833
Epoch 41/300
 - 15s - loss: 0.2498 - acc: 0.9563 - mDice: 0.7664 - val_loss: 0.4719 - val_acc: 0.9542 - val_mDice: 0.6171

Epoch 00041: val_mDice did not improve from 0.62833
Epoch 42/300
 - 16s - loss: 0.2477 - acc: 0.9564 - mDice: 0.7680 - val_loss: 0.4800 - val_acc: 0.9545 - val_mDice: 0.6111

Epoch 00042: val_mDice did not improve from 0.62833
Epoch 43/300
 - 15s - loss: 0.2484 - acc: 0.9564 - mDice: 0.7676 - val_loss: 0.4684 - val_acc: 0.9533 - val_mDice: 0.6198

Epoch 00043: val_mDice did not improve from 0.62833
Epoch 44/300
 - 15s - loss: 0.2453 - acc: 0.9566 - mDice: 0.7700 - val_loss: 0.4764 - val_acc: 0.9539 - val_mDice: 0.6198

Epoch 00044: val_mDice did not improve from 0.62833
Epoch 45/300
 - 16s - loss: 0.2440 - acc: 0.9566 - mDice: 0.7710 - val_loss: 0.4650 - val_acc: 0.9534 - val_mDice: 0.6196

Epoch 00045: val_mDice did not improve from 0.62833
Epoch 46/300
 - 15s - loss: 0.2440 - acc: 0.9567 - mDice: 0.7710 - val_loss: 0.4631 - val_acc: 0.9544 - val_mDice: 0.6218

Epoch 00046: val_mDice did not improve from 0.62833
Epoch 47/300
 - 15s - loss: 0.2412 - acc: 0.9569 - mDice: 0.7733 - val_loss: 0.4763 - val_acc: 0.9537 - val_mDice: 0.6136

Epoch 00047: val_mDice did not improve from 0.62833
Epoch 48/300
 - 15s - loss: 0.2417 - acc: 0.9568 - mDice: 0.7729 - val_loss: 0.4943 - val_acc: 0.9540 - val_mDice: 0.6057

Epoch 00048: val_mDice did not improve from 0.62833
Epoch 49/300
 - 16s - loss: 0.2406 - acc: 0.9570 - mDice: 0.7738 - val_loss: 0.4792 - val_acc: 0.9543 - val_mDice: 0.6124

Epoch 00049: val_mDice did not improve from 0.62833
Epoch 50/300
 - 15s - loss: 0.2396 - acc: 0.9570 - mDice: 0.7746 - val_loss: 0.4733 - val_acc: 0.9544 - val_mDice: 0.6149

Epoch 00050: val_mDice did not improve from 0.62833
Epoch 51/300
 - 15s - loss: 0.2399 - acc: 0.9570 - mDice: 0.7743 - val_loss: 0.4433 - val_acc: 0.9535 - val_mDice: 0.6320

Epoch 00051: val_mDice improved from 0.62833 to 0.63197, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 52/300
 - 16s - loss: 0.2383 - acc: 0.9572 - mDice: 0.7756 - val_loss: 0.4558 - val_acc: 0.9535 - val_mDice: 0.6271

Epoch 00052: val_mDice did not improve from 0.63197
Epoch 53/300
 - 16s - loss: 0.2374 - acc: 0.9572 - mDice: 0.7764 - val_loss: 0.4615 - val_acc: 0.9531 - val_mDice: 0.6220

Epoch 00053: val_mDice did not improve from 0.63197
Epoch 54/300
 - 15s - loss: 0.2373 - acc: 0.9572 - mDice: 0.7764 - val_loss: 0.4767 - val_acc: 0.9550 - val_mDice: 0.6128

Epoch 00054: val_mDice did not improve from 0.63197
Epoch 55/300
 - 16s - loss: 0.2374 - acc: 0.9572 - mDice: 0.7763 - val_loss: 0.4738 - val_acc: 0.9541 - val_mDice: 0.6152

Epoch 00055: val_mDice did not improve from 0.63197
Epoch 56/300
 - 15s - loss: 0.2359 - acc: 0.9573 - mDice: 0.7776 - val_loss: 0.4780 - val_acc: 0.9548 - val_mDice: 0.6162

Epoch 00056: val_mDice did not improve from 0.63197
Epoch 57/300
 - 15s - loss: 0.2345 - acc: 0.9574 - mDice: 0.7787 - val_loss: 0.4768 - val_acc: 0.9523 - val_mDice: 0.6139

Epoch 00057: val_mDice did not improve from 0.63197
Epoch 58/300
 - 16s - loss: 0.2333 - acc: 0.9575 - mDice: 0.7797 - val_loss: 0.4563 - val_acc: 0.9540 - val_mDice: 0.6236

Epoch 00058: val_mDice did not improve from 0.63197
Epoch 59/300
 - 15s - loss: 0.2331 - acc: 0.9575 - mDice: 0.7798 - val_loss: 0.4949 - val_acc: 0.9542 - val_mDice: 0.6099

Epoch 00059: val_mDice did not improve from 0.63197
Epoch 60/300
 - 16s - loss: 0.2316 - acc: 0.9576 - mDice: 0.7810 - val_loss: 0.4731 - val_acc: 0.9538 - val_mDice: 0.6157

Epoch 00060: val_mDice did not improve from 0.63197
Epoch 61/300
 - 16s - loss: 0.2323 - acc: 0.9576 - mDice: 0.7806 - val_loss: 0.4618 - val_acc: 0.9545 - val_mDice: 0.6213

Epoch 00061: val_mDice did not improve from 0.63197
Epoch 62/300
 - 16s - loss: 0.2309 - acc: 0.9577 - mDice: 0.7817 - val_loss: 0.4836 - val_acc: 0.9533 - val_mDice: 0.6106

Epoch 00062: val_mDice did not improve from 0.63197
Epoch 63/300
 - 16s - loss: 0.2317 - acc: 0.9577 - mDice: 0.7810 - val_loss: 0.4765 - val_acc: 0.9528 - val_mDice: 0.6162

Epoch 00063: val_mDice did not improve from 0.63197
Epoch 64/300
 - 16s - loss: 0.2296 - acc: 0.9578 - mDice: 0.7828 - val_loss: 0.5018 - val_acc: 0.9530 - val_mDice: 0.6041

Epoch 00064: val_mDice did not improve from 0.63197
Epoch 65/300
 - 16s - loss: 0.2294 - acc: 0.9578 - mDice: 0.7829 - val_loss: 0.4763 - val_acc: 0.9530 - val_mDice: 0.6116

Epoch 00065: val_mDice did not improve from 0.63197
Epoch 66/300
 - 16s - loss: 0.2285 - acc: 0.9579 - mDice: 0.7836 - val_loss: 0.4838 - val_acc: 0.9546 - val_mDice: 0.6119

Epoch 00066: val_mDice did not improve from 0.63197
Epoch 67/300
 - 16s - loss: 0.2284 - acc: 0.9579 - mDice: 0.7838 - val_loss: 0.4792 - val_acc: 0.9530 - val_mDice: 0.6115

Epoch 00067: val_mDice did not improve from 0.63197
Epoch 68/300
 - 16s - loss: 0.2278 - acc: 0.9579 - mDice: 0.7842 - val_loss: 0.4670 - val_acc: 0.9538 - val_mDice: 0.6199

Epoch 00068: val_mDice did not improve from 0.63197
Epoch 69/300
 - 16s - loss: 0.2266 - acc: 0.9580 - mDice: 0.7853 - val_loss: 0.4830 - val_acc: 0.9518 - val_mDice: 0.6095

Epoch 00069: val_mDice did not improve from 0.63197
Epoch 70/300
 - 16s - loss: 0.2278 - acc: 0.9578 - mDice: 0.7842 - val_loss: 0.4718 - val_acc: 0.9537 - val_mDice: 0.6175

Epoch 00070: val_mDice did not improve from 0.63197
Epoch 71/300
 - 16s - loss: 0.2266 - acc: 0.9580 - mDice: 0.7852 - val_loss: 0.4770 - val_acc: 0.9533 - val_mDice: 0.6128

Epoch 00071: val_mDice did not improve from 0.63197
Epoch 72/300
 - 16s - loss: 0.2252 - acc: 0.9581 - mDice: 0.7864 - val_loss: 0.4972 - val_acc: 0.9544 - val_mDice: 0.6049

Epoch 00072: val_mDice did not improve from 0.63197
Epoch 73/300
 - 16s - loss: 0.2269 - acc: 0.9580 - mDice: 0.7850 - val_loss: 0.4608 - val_acc: 0.9531 - val_mDice: 0.6223

Epoch 00073: val_mDice did not improve from 0.63197
Epoch 74/300
 - 16s - loss: 0.2248 - acc: 0.9582 - mDice: 0.7867 - val_loss: 0.4787 - val_acc: 0.9542 - val_mDice: 0.6141

Epoch 00074: val_mDice did not improve from 0.63197
Epoch 75/300
 - 16s - loss: 0.2244 - acc: 0.9582 - mDice: 0.7870 - val_loss: 0.4668 - val_acc: 0.9519 - val_mDice: 0.6175

Epoch 00075: val_mDice did not improve from 0.63197
Epoch 76/300
 - 16s - loss: 0.2248 - acc: 0.9582 - mDice: 0.7867 - val_loss: 0.4795 - val_acc: 0.9518 - val_mDice: 0.6103

Epoch 00076: val_mDice did not improve from 0.63197
Epoch 77/300
 - 16s - loss: 0.2224 - acc: 0.9584 - mDice: 0.7886 - val_loss: 0.4769 - val_acc: 0.9531 - val_mDice: 0.6141

Epoch 00077: val_mDice did not improve from 0.63197
Epoch 78/300
 - 16s - loss: 0.2222 - acc: 0.9584 - mDice: 0.7888 - val_loss: 0.4800 - val_acc: 0.9537 - val_mDice: 0.6142

Epoch 00078: val_mDice did not improve from 0.63197
Epoch 79/300
 - 16s - loss: 0.2223 - acc: 0.9584 - mDice: 0.7888 - val_loss: 0.4866 - val_acc: 0.9541 - val_mDice: 0.6105

Epoch 00079: val_mDice did not improve from 0.63197
Epoch 80/300
 - 16s - loss: 0.2232 - acc: 0.9582 - mDice: 0.7881 - val_loss: 0.4719 - val_acc: 0.9524 - val_mDice: 0.6172

Epoch 00080: val_mDice did not improve from 0.63197
Epoch 81/300
 - 16s - loss: 0.2214 - acc: 0.9584 - mDice: 0.7896 - val_loss: 0.4721 - val_acc: 0.9529 - val_mDice: 0.6147

Epoch 00081: val_mDice did not improve from 0.63197
Epoch 82/300
 - 16s - loss: 0.2214 - acc: 0.9584 - mDice: 0.7895 - val_loss: 0.4839 - val_acc: 0.9534 - val_mDice: 0.6108

Epoch 00082: val_mDice did not improve from 0.63197
Epoch 83/300
 - 16s - loss: 0.2190 - acc: 0.9585 - mDice: 0.7915 - val_loss: 0.4588 - val_acc: 0.9526 - val_mDice: 0.6229

Epoch 00083: val_mDice did not improve from 0.63197
Epoch 84/300
 - 16s - loss: 0.2200 - acc: 0.9585 - mDice: 0.7907 - val_loss: 0.4788 - val_acc: 0.9543 - val_mDice: 0.6168

Epoch 00084: val_mDice did not improve from 0.63197
Epoch 85/300
 - 16s - loss: 0.2193 - acc: 0.9587 - mDice: 0.7913 - val_loss: 0.4704 - val_acc: 0.9536 - val_mDice: 0.6165

Epoch 00085: val_mDice did not improve from 0.63197
Epoch 86/300
 - 16s - loss: 0.2193 - acc: 0.9586 - mDice: 0.7913 - val_loss: 0.4892 - val_acc: 0.9536 - val_mDice: 0.6102

Epoch 00086: val_mDice did not improve from 0.63197
Epoch 87/300
 - 16s - loss: 0.2194 - acc: 0.9586 - mDice: 0.7912 - val_loss: 0.4754 - val_acc: 0.9524 - val_mDice: 0.6144

Epoch 00087: val_mDice did not improve from 0.63197
Epoch 88/300
 - 16s - loss: 0.2174 - acc: 0.9587 - mDice: 0.7929 - val_loss: 0.4724 - val_acc: 0.9521 - val_mDice: 0.6140

Epoch 00088: val_mDice did not improve from 0.63197
Epoch 89/300
 - 16s - loss: 0.2184 - acc: 0.9587 - mDice: 0.7921 - val_loss: 0.4863 - val_acc: 0.9531 - val_mDice: 0.6114

Epoch 00089: val_mDice did not improve from 0.63197
Epoch 90/300
 - 16s - loss: 0.2179 - acc: 0.9586 - mDice: 0.7924 - val_loss: 0.4792 - val_acc: 0.9537 - val_mDice: 0.6129

Epoch 00090: val_mDice did not improve from 0.63197
Epoch 91/300
 - 16s - loss: 0.2180 - acc: 0.9587 - mDice: 0.7924 - val_loss: 0.4943 - val_acc: 0.9536 - val_mDice: 0.6068

Epoch 00091: val_mDice did not improve from 0.63197
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
{'val_loss': [1.9204868937337864, 0.61158533336064, 0.5108307896379652, 0.5185186396763978, 0.5559256113441297, 0.5183158406998192, 0.5033443949742025, 0.46576986266248055, 0.47996124708452703, 0.4870557991486022, 0.4693786688357092, 0.47524423073123956, 0.4681809774324215, 0.4852646256292332, 0.4855770272249616, 0.4742748104660205, 0.5445599099777264, 0.4698236428159575, 0.4738138401308539, 0.4616193857938884, 0.47245357855738207, 0.4653072510351682, 0.4682050700294239, 0.47140307100125534, 0.4778679482763706, 0.48142824825627845, 0.4726033340619263, 0.47518897256371695, 0.4521602185744813, 0.45456673912495876, 0.4711889508050247, 0.46347371526270603, 0.4742925636595188, 0.48555838728750217, 0.4727662139098737, 0.44521270550829073, 0.48179066780559177, 0.5002752715648886, 0.484625934222557, 0.47042902488282273, 0.4718887556198589, 0.4800040362267521, 0.46838251405588077, 0.4763689280888222, 0.4649959286497958, 0.4630787442516348, 0.4762910244851139, 0.4942929018809143, 0.4792223179806544, 0.47329909208766574, 0.4432577587372764, 0.4557822653035212, 0.46146027136115386, 0.4766809241065766, 0.4738303296392856, 0.47801613907574275, 0.47680604058271014, 0.4562933228535359, 0.49490461602557306, 0.4730533537917963, 0.46177727283712205, 0.48356758116343834, 0.4764984979309849, 0.5017944501098974, 0.47634448918550376, 0.48381863392931124, 0.47920822564450055, 0.4670240635978443, 0.4829608395112959, 0.4718361456966933, 0.4770455646781282, 0.4972234231799674, 0.4607941761363152, 0.4787009201902251, 0.46683989323717257, 0.47945678866775343, 0.4768586991219547, 0.4799903025174274, 0.48656864872191874, 0.4719232963450128, 0.472051963459846, 0.4838774750352572, 0.45882289036692187, 0.4787940276401669, 0.4704017542593972, 0.48917718672885574, 0.47543331231484864, 0.4724471852100095, 0.48628475213184036, 0.4791599135825088, 0.49427058976455773], 'val_acc': [0.9161639549878723, 0.9323679498454046, 0.9446691820741365, 0.9469294461458089, 0.9447559734296532, 0.9479934419999575, 0.9492723578847321, 0.951983007638814, 0.9511999611082024, 0.9509293163954878, 0.9521834054472726, 0.9516586121900121, 0.9506380068523258, 0.9522598499026378, 0.9514065791108754, 0.9521978527474004, 0.9472744794531242, 0.9518796981379972, 0.951840438323314, 0.9529395652882879, 0.9522763886931223, 0.9534292197760257, 0.9516751423228387, 0.9533837737317857, 0.9542308366498468, 0.9526544479684457, 0.9539271526496503, 0.9543135069602029, 0.9534126876452782, 0.9534209553755861, 0.9539044023226093, 0.9536833306930584, 0.9537370634478564, 0.953513950608962, 0.9521172889118088, 0.9522557165369642, 0.9542845710695789, 0.9533176791734536, 0.9526110617808123, 0.9541172391875496, 0.9541998555540373, 0.9545201083135338, 0.9533135344862272, 0.9538899616822184, 0.9533982373482688, 0.9543713431118587, 0.9536874757132716, 0.9539726143442718, 0.9542824972275249, 0.9543630517394849, 0.9534726086275538, 0.9535139186422252, 0.9531317013602018, 0.9549518940169052, 0.9540986188963139, 0.9548424042802949, 0.9523177103623331, 0.9539994773918024, 0.9541626529320658, 0.9537783824531726, 0.9544953161111757, 0.9532660209266833, 0.9527577488116046, 0.9529705650313607, 0.9530077286938715, 0.9546358072557929, 0.9529994836066689, 0.9537701506854436, 0.9517660507276737, 0.953664760349849, 0.9533031819252994, 0.954371334121214, 0.9531399907346544, 0.9542267169366335, 0.9518817643213539, 0.9518135526326782, 0.9531337658786241, 0.9536585651296478, 0.9541234397355405, 0.9524044710830604, 0.9529271811746353, 0.9533651610992474, 0.9526255237323612, 0.9542618513773273, 0.9536337626046975, 0.9536006833587944, 0.9524313417892882, 0.9520656426525649, 0.953102769132433, 0.9537122729104325, 0.9536275607247592], 'val_mDice': [0.2765895472059037, 0.5341878506724395, 0.5889638665668125, 0.5893044295257697, 0.5718737094761939, 0.5907714596673763, 0.5983667829849201, 0.6179773654351687, 0.6092439896567574, 0.6067667240537079, 0.6155930983953636, 0.613299128396551, 0.6145549503118632, 0.6106018773670303, 0.6105071759090743, 0.6160322401110686, 0.5833290479036682, 0.6151673027922987, 0.6133098895323343, 0.6194983004857708, 0.6150201645643352, 0.6216410461750776, 0.6166880224004138, 0.6209763661443188, 0.615056037902832, 0.6126434140365217, 0.6151596927110043, 0.6155902160612564, 0.6261889981157953, 0.6245384073124252, 0.6164239525129009, 0.6207035094000107, 0.6133540216104945, 0.6096978400672615, 0.6173410039374282, 0.6283272794505071, 0.6117170679502647, 0.603431267112327, 0.6092793215586486, 0.6171682094062507, 0.617088663844423, 0.6110886908110293, 0.6197765376314771, 0.6198441379563102, 0.6195734313080431, 0.6217855861067106, 0.6135605007576543, 0.6056736025064351, 0.6123818315607209, 0.6149447850008917, 0.6319695764413759, 0.6271202750712134, 0.6220357870922408, 0.6128497490003788, 0.6152282979901277, 0.6161981761122549, 0.6139466905727067, 0.6235717355206026, 0.6099229408376043, 0.6157225383726578, 0.6213133321794052, 0.610562691475426, 0.6162115874903162, 0.6040715888225833, 0.6116306878334983, 0.6118972244875391, 0.6115378967210567, 0.6199280546364172, 0.6095135611528791, 0.6174676368356417, 0.6127908109952618, 0.6049290176210457, 0.6223349115036053, 0.6140886328739827, 0.6175392200160958, 0.6103303305929599, 0.6141078991596925, 0.6142440022037016, 0.6105380674314232, 0.6171991785145339, 0.6146583580437985, 0.6107823702210154, 0.6228911547021493, 0.6168257770591608, 0.6164780322399885, 0.610166085498959, 0.6144056586579904, 0.6139996531289383, 0.6114145630564769, 0.6128936073633545, 0.6067768088932144], 'loss': [1.9894219287749009, 0.6841218377223144, 0.5248312893000039, 0.45955045391002985, 0.42657261998894547, 0.4037001168479211, 0.38156820888139087, 0.3671422144532509, 0.35281968041446937, 0.3439164264913309, 0.3356048516910078, 0.32560592099807534, 0.31972166918752554, 0.31547654493462385, 0.3100106680041324, 0.30503392411073005, 0.3006567009526604, 0.29591774125840886, 0.2913269899449936, 0.2931742348443591, 0.28474242957898793, 0.28163511619920545, 0.2807316267050843, 0.2790383223624188, 0.27537622572575693, 0.2741058937384343, 0.2696407816342023, 0.2689818056179258, 0.2652694989046716, 0.2648960010583128, 0.26437233755008227, 0.2613176598306588, 0.26040164701144336, 0.2578928151731105, 0.25494696696491115, 0.2555990135143489, 0.25199355895233194, 0.2768679901322056, 0.2588036223669002, 0.2520128048988451, 0.24975004110985036, 0.24774833759394913, 0.2483933625962829, 0.24525731267002462, 0.2440237269811034, 0.24403255150459813, 0.24117042605124178, 0.24173364491544774, 0.24061394545057554, 0.2395657320231902, 0.23989719543138377, 0.23833092593557856, 0.23735059990023782, 0.2372572864558233, 0.2374239677471907, 0.23585741439160943, 0.23449585058659772, 0.2333156406915134, 0.2331177962156794, 0.23162993027957318, 0.23226940491952497, 0.23086568180963266, 0.23173029596370184, 0.2295798865738313, 0.22942365790126332, 0.22847693342849207, 0.22839229882581516, 0.2278370667656979, 0.22657904000163084, 0.22782336065718034, 0.226552677495561, 0.22519274096373776, 0.22691746088623657, 0.22476446223436866, 0.22437616426758009, 0.22484928190652975, 0.22243322419948836, 0.22222884376238883, 0.22225854566810657, 0.22317011145525176, 0.22135855985323424, 0.221368769932323, 0.21895313395143537, 0.21999576674908908, 0.21929038066414341, 0.21928729416709095, 0.21935748540071562, 0.2173634565062892, 0.2183582561098603, 0.2178723668959281, 0.21795155063095412], 'acc': [0.591139781103512, 0.9083110126597995, 0.9154507778684374, 0.9210201880360642, 0.9251704157570675, 0.9293857791228892, 0.9343986754180832, 0.9415353790885658, 0.9470279693577546, 0.9486506890253358, 0.949492593420194, 0.9503056966305999, 0.9508437198378747, 0.9511732791323371, 0.9516885072036698, 0.9519743565529833, 0.9523552974437383, 0.9527381529547564, 0.9531529336529849, 0.9530471861735778, 0.9535559258081315, 0.9537419185426252, 0.9539321335232938, 0.9540299220052941, 0.9543699166638536, 0.9543700359835162, 0.9547452750266244, 0.9547726292507847, 0.9549559605198874, 0.955064484288273, 0.9550937098697421, 0.9553378872684154, 0.9554487257655374, 0.9556165669493007, 0.9558044285155104, 0.9558511805050021, 0.9561083878828585, 0.9542415307196752, 0.9555771719149194, 0.9561222877210797, 0.9562921633122307, 0.9564169217484377, 0.9564005054878802, 0.9565749741166735, 0.9566496988798718, 0.9567144122994237, 0.9568753074173911, 0.9568134710216216, 0.9569735563688889, 0.9569919492143879, 0.9569880203752501, 0.9571706870660356, 0.9572127406409243, 0.9571950552211751, 0.9572265769400294, 0.9573095196323531, 0.9574377226625663, 0.957509832709815, 0.9574969207842517, 0.9575860287965133, 0.9576299180133196, 0.9577131608389385, 0.9576502588311933, 0.9578206578141678, 0.9578190054984909, 0.9578909773490546, 0.9578914764133792, 0.9578901680588015, 0.9580099111476967, 0.9578489590156027, 0.9580082387636186, 0.9580711806419725, 0.9580194363081924, 0.9581515057129406, 0.9582349553450241, 0.9582086497711126, 0.958353325647503, 0.9583984668994611, 0.9583646456703538, 0.9582406332222609, 0.9584017673496276, 0.9583805384936399, 0.9585231214000485, 0.9585361734992713, 0.9586571649517942, 0.9585841096445442, 0.9585945260147534, 0.958678776866879, 0.9586782137797449, 0.9585667490264467, 0.9586666310627563], 'mDice': [0.23066968396350673, 0.4955395660098618, 0.5799904792996107, 0.6199507047444295, 0.6410898654966415, 0.6561449563040348, 0.6710880151904426, 0.6805628503786245, 0.6897216014700787, 0.6957795629670928, 0.7015426864512871, 0.7088125500048722, 0.7129642636575612, 0.7160717866518264, 0.7201101174931609, 0.7238203616815159, 0.7269623984887211, 0.7305775632539363, 0.7341222543679033, 0.7329475675998616, 0.7390635709709075, 0.7413282464496009, 0.7422037337328976, 0.7434297910242271, 0.7463222391484227, 0.7473465447513881, 0.7506328705777582, 0.7513169988971165, 0.7540458824488989, 0.7544754493289131, 0.7546933859198787, 0.7571469127018398, 0.7579593745284815, 0.7599494128658077, 0.7621804630079207, 0.7617347956930823, 0.7646736602989406, 0.7462444902537637, 0.7592344723536775, 0.7645795818351919, 0.7664309633264458, 0.768040465656744, 0.7675614443280314, 0.7699774973020205, 0.7710020538054483, 0.7710394726963801, 0.773314524934375, 0.7728568748330299, 0.7737751503855786, 0.7745752296126504, 0.7743134579168452, 0.7755853983514625, 0.7764424052407789, 0.7764405535882896, 0.7763409881503239, 0.7776468008875126, 0.7787050368654579, 0.7796898399015624, 0.7798220493923208, 0.7810056438588101, 0.7805682440078322, 0.7817109750315849, 0.7810006457816203, 0.7827500151130967, 0.7829460262713378, 0.7836271050247606, 0.7837945982902296, 0.7842024191747362, 0.7852560751422948, 0.7841785290578723, 0.7852428949909606, 0.7864330207416613, 0.7849700683069984, 0.7866917381254938, 0.7870354575273564, 0.7867299576586325, 0.7886232645038581, 0.7888334157368072, 0.788802016781901, 0.7880654209651274, 0.7895578663175541, 0.7895203464873041, 0.791508331536974, 0.7906955808448178, 0.791314778929929, 0.7912914594672396, 0.7912252938187101, 0.7928783921957548, 0.7920651230298644, 0.792420932611124, 0.7924084826483393]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.60s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.34s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:22,  2.19s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:27,  2.01s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:12,  1.96s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:42,  1.86s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:16,  1.99s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:38,  1.86s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<08:56,  1.93s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:00,  1.95s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:33,  2.08s/it]predicting train subjects:   4%|▎         | 10/285 [00:20<10:08,  2.21s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:27,  2.07s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:48,  2.16s/it]predicting train subjects:   5%|▍         | 13/285 [00:26<09:21,  2.06s/it]predicting train subjects:   5%|▍         | 14/285 [00:28<09:19,  2.07s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:40,  2.15s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:49,  2.19s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:32,  2.13s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:22,  2.11s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:03,  2.04s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:14,  2.09s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:30,  2.16s/it]predicting train subjects:   8%|▊         | 22/285 [00:45<09:11,  2.10s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:05,  2.08s/it]predicting train subjects:   8%|▊         | 24/285 [00:49<08:47,  2.02s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:13,  2.13s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:19,  2.16s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<08:47,  2.05s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<08:48,  2.06s/it]predicting train subjects:  10%|█         | 29/285 [00:59<08:57,  2.10s/it]predicting train subjects:  11%|█         | 30/285 [01:02<09:19,  2.19s/it]predicting train subjects:  11%|█         | 31/285 [01:04<09:26,  2.23s/it]predicting train subjects:  11%|█         | 32/285 [01:06<09:02,  2.14s/it]predicting train subjects:  12%|█▏        | 33/285 [01:08<08:44,  2.08s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<08:48,  2.10s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<09:06,  2.19s/it]predicting train subjects:  13%|█▎        | 36/285 [01:14<08:35,  2.07s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:40,  2.10s/it]predicting train subjects:  13%|█▎        | 38/285 [01:19<08:52,  2.15s/it]predicting train subjects:  14%|█▎        | 39/285 [01:20<08:25,  2.06s/it]predicting train subjects:  14%|█▍        | 40/285 [01:22<08:21,  2.05s/it]predicting train subjects:  14%|█▍        | 41/285 [01:24<08:02,  1.98s/it]predicting train subjects:  15%|█▍        | 42/285 [01:26<07:54,  1.95s/it]predicting train subjects:  15%|█▌        | 43/285 [01:28<08:03,  2.00s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<08:21,  2.08s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<08:04,  2.02s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<08:15,  2.08s/it]predicting train subjects:  16%|█▋        | 47/285 [01:36<07:50,  1.98s/it]predicting train subjects:  17%|█▋        | 48/285 [01:38<07:50,  1.98s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<08:20,  2.12s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<08:10,  2.09s/it]predicting train subjects:  18%|█▊        | 51/285 [01:45<08:21,  2.14s/it]predicting train subjects:  18%|█▊        | 52/285 [01:47<08:04,  2.08s/it]predicting train subjects:  19%|█▊        | 53/285 [01:49<07:50,  2.03s/it]predicting train subjects:  19%|█▉        | 54/285 [01:51<08:04,  2.10s/it]predicting train subjects:  19%|█▉        | 55/285 [01:53<07:41,  2.01s/it]predicting train subjects:  20%|█▉        | 56/285 [01:55<07:42,  2.02s/it]predicting train subjects:  20%|██        | 57/285 [01:57<07:30,  1.98s/it]predicting train subjects:  20%|██        | 58/285 [01:59<07:26,  1.97s/it]predicting train subjects:  21%|██        | 59/285 [02:01<07:51,  2.09s/it]predicting train subjects:  21%|██        | 60/285 [02:04<08:14,  2.20s/it]predicting train subjects:  21%|██▏       | 61/285 [02:06<07:45,  2.08s/it]predicting train subjects:  22%|██▏       | 62/285 [02:08<07:39,  2.06s/it]predicting train subjects:  22%|██▏       | 63/285 [02:10<07:38,  2.06s/it]predicting train subjects:  22%|██▏       | 64/285 [02:12<07:27,  2.02s/it]predicting train subjects:  23%|██▎       | 65/285 [02:14<07:36,  2.07s/it]predicting train subjects:  23%|██▎       | 66/285 [02:16<07:35,  2.08s/it]predicting train subjects:  24%|██▎       | 67/285 [02:18<07:32,  2.08s/it]predicting train subjects:  24%|██▍       | 68/285 [02:20<07:11,  1.99s/it]predicting train subjects:  24%|██▍       | 69/285 [02:22<07:10,  1.99s/it]predicting train subjects:  25%|██▍       | 70/285 [02:24<07:12,  2.01s/it]predicting train subjects:  25%|██▍       | 71/285 [02:26<07:07,  2.00s/it]predicting train subjects:  25%|██▌       | 72/285 [02:28<07:01,  1.98s/it]predicting train subjects:  26%|██▌       | 73/285 [02:30<07:00,  1.98s/it]predicting train subjects:  26%|██▌       | 74/285 [02:32<07:06,  2.02s/it]predicting train subjects:  26%|██▋       | 75/285 [02:34<07:04,  2.02s/it]predicting train subjects:  27%|██▋       | 76/285 [02:36<06:54,  1.98s/it]predicting train subjects:  27%|██▋       | 77/285 [02:38<06:57,  2.01s/it]predicting train subjects:  27%|██▋       | 78/285 [02:40<06:47,  1.97s/it]predicting train subjects:  28%|██▊       | 79/285 [02:42<06:47,  1.98s/it]predicting train subjects:  28%|██▊       | 80/285 [02:44<06:52,  2.01s/it]predicting train subjects:  28%|██▊       | 81/285 [02:46<06:54,  2.03s/it]predicting train subjects:  29%|██▉       | 82/285 [02:48<06:56,  2.05s/it]predicting train subjects:  29%|██▉       | 83/285 [02:50<06:47,  2.02s/it]predicting train subjects:  29%|██▉       | 84/285 [02:52<06:39,  1.99s/it]predicting train subjects:  30%|██▉       | 85/285 [02:54<06:41,  2.01s/it]predicting train subjects:  30%|███       | 86/285 [02:56<06:48,  2.05s/it]predicting train subjects:  31%|███       | 87/285 [02:58<06:48,  2.06s/it]predicting train subjects:  31%|███       | 88/285 [03:00<06:39,  2.03s/it]predicting train subjects:  31%|███       | 89/285 [03:02<06:38,  2.03s/it]predicting train subjects:  32%|███▏      | 90/285 [03:04<06:42,  2.06s/it]predicting train subjects:  32%|███▏      | 91/285 [03:06<06:36,  2.05s/it]predicting train subjects:  32%|███▏      | 92/285 [03:08<06:41,  2.08s/it]predicting train subjects:  33%|███▎      | 93/285 [03:10<06:30,  2.03s/it]predicting train subjects:  33%|███▎      | 94/285 [03:12<06:37,  2.08s/it]predicting train subjects:  33%|███▎      | 95/285 [03:15<06:41,  2.11s/it]predicting train subjects:  34%|███▎      | 96/285 [03:17<06:40,  2.12s/it]predicting train subjects:  34%|███▍      | 97/285 [03:19<06:41,  2.14s/it]predicting train subjects:  34%|███▍      | 98/285 [03:21<06:41,  2.15s/it]predicting train subjects:  35%|███▍      | 99/285 [03:23<06:41,  2.16s/it]predicting train subjects:  35%|███▌      | 100/285 [03:25<06:37,  2.15s/it]predicting train subjects:  35%|███▌      | 101/285 [03:28<06:38,  2.17s/it]predicting train subjects:  36%|███▌      | 102/285 [03:30<06:35,  2.16s/it]predicting train subjects:  36%|███▌      | 103/285 [03:32<06:20,  2.09s/it]predicting train subjects:  36%|███▋      | 104/285 [03:34<06:23,  2.12s/it]predicting train subjects:  37%|███▋      | 105/285 [03:36<06:19,  2.11s/it]predicting train subjects:  37%|███▋      | 106/285 [03:38<06:01,  2.02s/it]predicting train subjects:  38%|███▊      | 107/285 [03:40<06:08,  2.07s/it]predicting train subjects:  38%|███▊      | 108/285 [03:42<05:58,  2.03s/it]predicting train subjects:  38%|███▊      | 109/285 [03:44<06:09,  2.10s/it]predicting train subjects:  39%|███▊      | 110/285 [03:46<06:08,  2.11s/it]predicting train subjects:  39%|███▉      | 111/285 [03:48<05:53,  2.03s/it]predicting train subjects:  39%|███▉      | 112/285 [03:50<05:54,  2.05s/it]predicting train subjects:  40%|███▉      | 113/285 [03:52<06:02,  2.11s/it]predicting train subjects:  40%|████      | 114/285 [03:54<05:56,  2.08s/it]predicting train subjects:  40%|████      | 115/285 [03:57<05:54,  2.09s/it]predicting train subjects:  41%|████      | 116/285 [03:59<05:52,  2.08s/it]predicting train subjects:  41%|████      | 117/285 [04:01<05:49,  2.08s/it]predicting train subjects:  41%|████▏     | 118/285 [04:03<05:41,  2.05s/it]predicting train subjects:  42%|████▏     | 119/285 [04:05<05:39,  2.05s/it]predicting train subjects:  42%|████▏     | 120/285 [04:07<05:29,  2.00s/it]predicting train subjects:  42%|████▏     | 121/285 [04:08<05:18,  1.94s/it]predicting train subjects:  43%|████▎     | 122/285 [04:10<05:05,  1.87s/it]predicting train subjects:  43%|████▎     | 123/285 [04:12<04:52,  1.81s/it]predicting train subjects:  44%|████▎     | 124/285 [04:14<04:47,  1.79s/it]predicting train subjects:  44%|████▍     | 125/285 [04:15<04:44,  1.78s/it]predicting train subjects:  44%|████▍     | 126/285 [04:17<04:34,  1.72s/it]predicting train subjects:  45%|████▍     | 127/285 [04:19<04:35,  1.75s/it]predicting train subjects:  45%|████▍     | 128/285 [04:21<04:45,  1.82s/it]predicting train subjects:  45%|████▌     | 129/285 [04:23<04:45,  1.83s/it]predicting train subjects:  46%|████▌     | 130/285 [04:24<04:48,  1.86s/it]predicting train subjects:  46%|████▌     | 131/285 [04:26<04:39,  1.81s/it]predicting train subjects:  46%|████▋     | 132/285 [04:28<04:46,  1.87s/it]predicting train subjects:  47%|████▋     | 133/285 [04:30<04:44,  1.87s/it]predicting train subjects:  47%|████▋     | 134/285 [04:32<04:35,  1.83s/it]predicting train subjects:  47%|████▋     | 135/285 [04:34<04:37,  1.85s/it]predicting train subjects:  48%|████▊     | 136/285 [04:35<04:34,  1.84s/it]predicting train subjects:  48%|████▊     | 137/285 [04:38<04:40,  1.90s/it]predicting train subjects:  48%|████▊     | 138/285 [04:39<04:26,  1.81s/it]predicting train subjects:  49%|████▉     | 139/285 [04:41<04:24,  1.81s/it]predicting train subjects:  49%|████▉     | 140/285 [04:43<04:23,  1.82s/it]predicting train subjects:  49%|████▉     | 141/285 [04:44<04:12,  1.75s/it]predicting train subjects:  50%|████▉     | 142/285 [04:46<04:09,  1.74s/it]predicting train subjects:  50%|█████     | 143/285 [04:48<04:00,  1.69s/it]predicting train subjects:  51%|█████     | 144/285 [04:50<04:06,  1.75s/it]predicting train subjects:  51%|█████     | 145/285 [04:51<03:59,  1.71s/it]predicting train subjects:  51%|█████     | 146/285 [04:53<04:00,  1.73s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:55<03:53,  1.69s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:56<04:02,  1.77s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:58<04:00,  1.77s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:00<04:04,  1.81s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:02<04:03,  1.82s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:04<03:53,  1.75s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:06<03:58,  1.81s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:07<04:00,  1.83s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:09<03:56,  1.82s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:11<04:02,  1.88s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:13<03:59,  1.87s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:15<03:56,  1.86s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:17<03:48,  1.81s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:18<03:44,  1.80s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:20<03:50,  1.86s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:22<03:46,  1.84s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:24<03:45,  1.85s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:26<03:35,  1.78s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:27<03:34,  1.79s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:29<03:35,  1.81s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:33,  1.81s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:33<03:26,  1.76s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:34<03:19,  1.72s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:36<03:13,  1.69s/it]predicting train subjects:  60%|██████    | 171/285 [05:38<03:13,  1.70s/it]predicting train subjects:  60%|██████    | 172/285 [05:39<03:09,  1.68s/it]predicting train subjects:  61%|██████    | 173/285 [05:41<03:12,  1.72s/it]predicting train subjects:  61%|██████    | 174/285 [05:43<03:05,  1.67s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:45<03:07,  1.71s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:46<03:11,  1.76s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:48<03:07,  1.74s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:50<03:03,  1.71s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:52<03:01,  1.71s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:54<03:13,  1.84s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:55<03:06,  1.80s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:57<03:07,  1.82s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:59<02:57,  1.74s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:00<02:52,  1.71s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:02<02:44,  1.64s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:04<02:54,  1.77s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:06<03:04,  1.88s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:08<03:03,  1.90s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:10<02:51,  1.78s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:11<02:46,  1.75s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:13<02:47,  1.78s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:15<02:51,  1.84s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:17<02:44,  1.79s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:18<02:39,  1.75s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:20<02:35,  1.72s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:22<02:45,  1.86s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:24<02:47,  1.90s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:26<02:48,  1.93s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:28<02:35,  1.80s/it]predicting train subjects:  70%|███████   | 200/285 [06:29<02:29,  1.76s/it]predicting train subjects:  71%|███████   | 201/285 [06:31<02:34,  1.83s/it]predicting train subjects:  71%|███████   | 202/285 [06:33<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [06:35<02:33,  1.87s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:37<02:26,  1.80s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:38<02:17,  1.72s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:40<02:13,  1.68s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:42<02:22,  1.83s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:44<02:26,  1.90s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:46<02:26,  1.93s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:48<02:20,  1.87s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:50<02:13,  1.81s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:52<02:14,  1.84s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:53<02:14,  1.86s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:55<02:06,  1.79s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:57<02:10,  1.87s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:59<02:01,  1.77s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:01<02:06,  1.86s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:03<02:06,  1.89s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:05<02:09,  1.96s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:06<02:02,  1.88s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:08<01:56,  1.81s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:10<01:54,  1.82s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:12<01:49,  1.76s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:13<01:44,  1.71s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:15<01:40,  1.67s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:17<01:45,  1.79s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:19<01:49,  1.89s/it]predicting train subjects:  80%|████████  | 228/285 [07:21<01:52,  1.98s/it]predicting train subjects:  80%|████████  | 229/285 [07:23<01:49,  1.95s/it]predicting train subjects:  81%|████████  | 230/285 [07:25<01:42,  1.86s/it]predicting train subjects:  81%|████████  | 231/285 [07:26<01:38,  1.83s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:28<01:38,  1.85s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:30<01:34,  1.83s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:32<01:35,  1.86s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:34<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:36<01:32,  1.88s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:38<01:34,  1.97s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:40<01:33,  2.00s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:42<01:30,  1.97s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:43<01:22,  1.84s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:45<01:17,  1.77s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:47<01:14,  1.74s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:48<01:10,  1.69s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:50<01:12,  1.76s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:52<01:09,  1.73s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:54<01:11,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:56<01:11,  1.88s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:58<01:09,  1.88s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:59<01:04,  1.79s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:01<01:01,  1.77s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:03<00:58,  1.73s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:04<00:55,  1.67s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:06<00:56,  1.78s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:08<00:56,  1.82s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:10<00:56,  1.88s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:12<00:51,  1.77s/it]predicting train subjects:  90%|█████████ | 257/285 [08:13<00:49,  1.75s/it]predicting train subjects:  91%|█████████ | 258/285 [08:16<00:49,  1.85s/it]predicting train subjects:  91%|█████████ | 259/285 [08:17<00:48,  1.86s/it]predicting train subjects:  91%|█████████ | 260/285 [08:19<00:45,  1.82s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:21<00:41,  1.75s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:22<00:39,  1.70s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:24<00:37,  1.69s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:26<00:38,  1.83s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:28<00:38,  1.93s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:30<00:34,  1.82s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:31<00:31,  1.75s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:34<00:31,  1.84s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:35<00:29,  1.85s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:37<00:26,  1.76s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:39<00:24,  1.72s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:40<00:22,  1.76s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:42<00:21,  1.75s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:44<00:18,  1.70s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:46<00:17,  1.76s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:48<00:16,  1.88s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:49<00:14,  1.80s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:51<00:12,  1.74s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:53<00:10,  1.78s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:55<00:08,  1.73s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:56<00:06,  1.75s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:58<00:05,  1.71s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:00<00:03,  1.84s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:02<00:01,  1.92s/it]predicting train subjects: 100%|██████████| 285/285 [09:04<00:00,  2.00s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:24,  1.99s/it]Loading train:   1%|          | 2/285 [00:03<08:37,  1.83s/it]Loading train:   1%|          | 3/285 [00:05<08:20,  1.78s/it]Loading train:   1%|▏         | 4/285 [00:06<07:36,  1.63s/it]Loading train:   2%|▏         | 5/285 [00:08<07:46,  1.67s/it]Loading train:   2%|▏         | 6/285 [00:09<07:20,  1.58s/it]Loading train:   2%|▏         | 7/285 [00:11<07:36,  1.64s/it]Loading train:   3%|▎         | 8/285 [00:12<07:22,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:14<07:52,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:16<07:20,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<07:02,  1.54s/it]Loading train:   4%|▍         | 12/285 [00:19<06:58,  1.53s/it]Loading train:   5%|▍         | 13/285 [00:20<06:17,  1.39s/it]Loading train:   5%|▍         | 14/285 [00:21<06:14,  1.38s/it]Loading train:   5%|▌         | 15/285 [00:22<06:04,  1.35s/it]Loading train:   6%|▌         | 16/285 [00:23<05:39,  1.26s/it]Loading train:   6%|▌         | 17/285 [00:25<05:36,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:26<05:16,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:27<05:08,  1.16s/it]Loading train:   7%|▋         | 20/285 [00:28<05:23,  1.22s/it]Loading train:   7%|▋         | 21/285 [00:30<05:46,  1.31s/it]Loading train:   8%|▊         | 22/285 [00:31<05:40,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:32<05:31,  1.27s/it]Loading train:   8%|▊         | 24/285 [00:33<05:11,  1.19s/it]Loading train:   9%|▉         | 25/285 [00:34<05:06,  1.18s/it]Loading train:   9%|▉         | 26/285 [00:35<05:03,  1.17s/it]Loading train:   9%|▉         | 27/285 [00:37<05:11,  1.21s/it]Loading train:  10%|▉         | 28/285 [00:38<05:08,  1.20s/it]Loading train:  10%|█         | 29/285 [00:39<05:25,  1.27s/it]Loading train:  11%|█         | 30/285 [00:41<05:27,  1.28s/it]Loading train:  11%|█         | 31/285 [00:42<05:42,  1.35s/it]Loading train:  11%|█         | 32/285 [00:43<05:07,  1.21s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:02,  1.20s/it]Loading train:  12%|█▏        | 34/285 [00:45<04:59,  1.19s/it]Loading train:  12%|█▏        | 35/285 [00:47<05:06,  1.23s/it]Loading train:  13%|█▎        | 36/285 [00:48<04:51,  1.17s/it]Loading train:  13%|█▎        | 37/285 [00:49<04:46,  1.16s/it]Loading train:  13%|█▎        | 38/285 [00:50<04:39,  1.13s/it]Loading train:  14%|█▎        | 39/285 [00:51<04:32,  1.11s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:20,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:53<04:12,  1.03s/it]Loading train:  15%|█▍        | 42/285 [00:54<04:15,  1.05s/it]Loading train:  15%|█▌        | 43/285 [00:55<04:29,  1.11s/it]Loading train:  15%|█▌        | 44/285 [00:56<04:40,  1.16s/it]Loading train:  16%|█▌        | 45/285 [00:57<04:32,  1.13s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:47,  1.20s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:38,  1.17s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:51,  1.23s/it]Loading train:  17%|█▋        | 49/285 [01:03<04:52,  1.24s/it]Loading train:  18%|█▊        | 50/285 [01:04<04:36,  1.17s/it]Loading train:  18%|█▊        | 51/285 [01:05<04:36,  1.18s/it]Loading train:  18%|█▊        | 52/285 [01:06<04:37,  1.19s/it]Loading train:  19%|█▊        | 53/285 [01:07<04:42,  1.22s/it]Loading train:  19%|█▉        | 54/285 [01:08<04:37,  1.20s/it]Loading train:  19%|█▉        | 55/285 [01:09<04:18,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:10<04:07,  1.08s/it]Loading train:  20%|██        | 57/285 [01:11<03:59,  1.05s/it]Loading train:  20%|██        | 58/285 [01:13<04:15,  1.13s/it]Loading train:  21%|██        | 59/285 [01:14<04:15,  1.13s/it]Loading train:  21%|██        | 60/285 [01:15<04:14,  1.13s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:10,  1.12s/it]Loading train:  22%|██▏       | 62/285 [01:17<04:20,  1.17s/it]Loading train:  22%|██▏       | 63/285 [01:19<04:31,  1.22s/it]Loading train:  22%|██▏       | 64/285 [01:20<04:53,  1.33s/it]Loading train:  23%|██▎       | 65/285 [01:22<05:08,  1.40s/it]Loading train:  23%|██▎       | 66/285 [01:23<05:20,  1.46s/it]Loading train:  24%|██▎       | 67/285 [01:25<05:17,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:26<04:55,  1.36s/it]Loading train:  24%|██▍       | 69/285 [01:27<04:41,  1.30s/it]Loading train:  25%|██▍       | 70/285 [01:28<04:35,  1.28s/it]Loading train:  25%|██▍       | 71/285 [01:30<04:35,  1.29s/it]Loading train:  25%|██▌       | 72/285 [01:31<04:42,  1.33s/it]Loading train:  26%|██▌       | 73/285 [01:32<04:23,  1.24s/it]Loading train:  26%|██▌       | 74/285 [01:33<04:12,  1.20s/it]Loading train:  26%|██▋       | 75/285 [01:34<04:10,  1.19s/it]Loading train:  27%|██▋       | 76/285 [01:36<04:10,  1.20s/it]Loading train:  27%|██▋       | 77/285 [01:37<04:15,  1.23s/it]Loading train:  27%|██▋       | 78/285 [01:38<04:07,  1.20s/it]Loading train:  28%|██▊       | 79/285 [01:39<04:19,  1.26s/it]Loading train:  28%|██▊       | 80/285 [01:40<04:03,  1.19s/it]Loading train:  28%|██▊       | 81/285 [01:41<03:42,  1.09s/it]Loading train:  29%|██▉       | 82/285 [01:42<03:38,  1.08s/it]Loading train:  29%|██▉       | 83/285 [01:43<03:30,  1.04s/it]Loading train:  29%|██▉       | 84/285 [01:44<03:16,  1.02it/s]Loading train:  30%|██▉       | 85/285 [01:46<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:47<03:53,  1.17s/it]Loading train:  31%|███       | 87/285 [01:48<03:57,  1.20s/it]Loading train:  31%|███       | 88/285 [01:49<03:45,  1.14s/it]Loading train:  31%|███       | 89/285 [01:50<03:45,  1.15s/it]Loading train:  32%|███▏      | 90/285 [01:52<03:52,  1.19s/it]Loading train:  32%|███▏      | 91/285 [01:53<03:41,  1.14s/it]Loading train:  32%|███▏      | 92/285 [01:54<03:32,  1.10s/it]Loading train:  33%|███▎      | 93/285 [01:55<03:29,  1.09s/it]Loading train:  33%|███▎      | 94/285 [01:56<03:37,  1.14s/it]Loading train:  33%|███▎      | 95/285 [01:57<03:49,  1.21s/it]Loading train:  34%|███▎      | 96/285 [01:59<03:49,  1.21s/it]Loading train:  34%|███▍      | 97/285 [02:00<03:41,  1.18s/it]Loading train:  34%|███▍      | 98/285 [02:01<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [02:02<03:20,  1.08s/it]Loading train:  35%|███▌      | 100/285 [02:03<03:15,  1.06s/it]Loading train:  35%|███▌      | 101/285 [02:04<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [02:05<03:25,  1.12s/it]Loading train:  36%|███▌      | 103/285 [02:06<03:27,  1.14s/it]Loading train:  36%|███▋      | 104/285 [02:07<03:33,  1.18s/it]Loading train:  37%|███▋      | 105/285 [02:09<03:35,  1.20s/it]Loading train:  37%|███▋      | 106/285 [02:10<03:18,  1.11s/it]Loading train:  38%|███▊      | 107/285 [02:11<03:18,  1.11s/it]Loading train:  38%|███▊      | 108/285 [02:12<03:03,  1.03s/it]Loading train:  38%|███▊      | 109/285 [02:13<03:13,  1.10s/it]Loading train:  39%|███▊      | 110/285 [02:14<03:09,  1.08s/it]Loading train:  39%|███▉      | 111/285 [02:15<03:00,  1.04s/it]Loading train:  39%|███▉      | 112/285 [02:16<03:01,  1.05s/it]Loading train:  40%|███▉      | 113/285 [02:17<03:01,  1.05s/it]Loading train:  40%|████      | 114/285 [02:18<03:06,  1.09s/it]Loading train:  40%|████      | 115/285 [02:19<03:02,  1.07s/it]Loading train:  41%|████      | 116/285 [02:20<03:07,  1.11s/it]Loading train:  41%|████      | 117/285 [02:22<03:13,  1.15s/it]Loading train:  41%|████▏     | 118/285 [02:23<03:09,  1.13s/it]Loading train:  42%|████▏     | 119/285 [02:24<03:26,  1.24s/it]Loading train:  42%|████▏     | 120/285 [02:25<03:03,  1.11s/it]Loading train:  42%|████▏     | 121/285 [02:27<03:26,  1.26s/it]Loading train:  43%|████▎     | 122/285 [02:28<03:29,  1.28s/it]Loading train:  43%|████▎     | 123/285 [02:29<03:38,  1.35s/it]Loading train:  44%|████▎     | 124/285 [02:31<03:24,  1.27s/it]Loading train:  44%|████▍     | 125/285 [02:31<03:09,  1.18s/it]Loading train:  44%|████▍     | 126/285 [02:33<03:12,  1.21s/it]Loading train:  45%|████▍     | 127/285 [02:34<03:02,  1.15s/it]Loading train:  45%|████▍     | 128/285 [02:35<03:09,  1.21s/it]Loading train:  45%|████▌     | 129/285 [02:36<03:00,  1.16s/it]Loading train:  46%|████▌     | 130/285 [02:37<02:56,  1.14s/it]Loading train:  46%|████▌     | 131/285 [02:38<02:44,  1.07s/it]Loading train:  46%|████▋     | 132/285 [02:39<02:46,  1.09s/it]Loading train:  47%|████▋     | 133/285 [02:40<02:42,  1.07s/it]Loading train:  47%|████▋     | 134/285 [02:41<02:31,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:42<02:36,  1.04s/it]Loading train:  48%|████▊     | 136/285 [02:43<02:32,  1.02s/it]Loading train:  48%|████▊     | 137/285 [02:44<02:34,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:45<02:27,  1.01s/it]Loading train:  49%|████▉     | 139/285 [02:46<02:30,  1.03s/it]Loading train:  49%|████▉     | 140/285 [02:48<02:49,  1.17s/it]Loading train:  49%|████▉     | 141/285 [02:49<02:42,  1.13s/it]Loading train:  50%|████▉     | 142/285 [02:50<02:34,  1.08s/it]Loading train:  50%|█████     | 143/285 [02:51<02:35,  1.09s/it]Loading train:  51%|█████     | 144/285 [02:52<02:28,  1.05s/it]Loading train:  51%|█████     | 145/285 [02:53<02:23,  1.03s/it]Loading train:  51%|█████     | 146/285 [02:54<02:33,  1.10s/it]Loading train:  52%|█████▏    | 147/285 [02:55<02:29,  1.08s/it]Loading train:  52%|█████▏    | 148/285 [02:57<02:37,  1.15s/it]Loading train:  52%|█████▏    | 149/285 [02:58<02:37,  1.16s/it]Loading train:  53%|█████▎    | 150/285 [02:59<02:25,  1.08s/it]Loading train:  53%|█████▎    | 151/285 [03:00<02:37,  1.18s/it]Loading train:  53%|█████▎    | 152/285 [03:01<02:25,  1.10s/it]Loading train:  54%|█████▎    | 153/285 [03:02<02:13,  1.01s/it]Loading train:  54%|█████▍    | 154/285 [03:03<02:19,  1.07s/it]Loading train:  54%|█████▍    | 155/285 [03:04<02:15,  1.04s/it]Loading train:  55%|█████▍    | 156/285 [03:05<02:14,  1.05s/it]Loading train:  55%|█████▌    | 157/285 [03:06<02:03,  1.03it/s]Loading train:  55%|█████▌    | 158/285 [03:07<02:04,  1.02it/s]Loading train:  56%|█████▌    | 159/285 [03:08<02:11,  1.05s/it]Loading train:  56%|█████▌    | 160/285 [03:09<02:08,  1.03s/it]Loading train:  56%|█████▋    | 161/285 [03:10<02:05,  1.01s/it]Loading train:  57%|█████▋    | 162/285 [03:11<02:04,  1.01s/it]Loading train:  57%|█████▋    | 163/285 [03:12<02:06,  1.04s/it]Loading train:  58%|█████▊    | 164/285 [03:13<02:05,  1.04s/it]Loading train:  58%|█████▊    | 165/285 [03:14<01:57,  1.02it/s]Loading train:  58%|█████▊    | 166/285 [03:15<01:58,  1.01it/s]Loading train:  59%|█████▊    | 167/285 [03:16<02:01,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [03:17<01:54,  1.03it/s]Loading train:  59%|█████▉    | 169/285 [03:18<01:54,  1.01it/s]Loading train:  60%|█████▉    | 170/285 [03:19<01:50,  1.04it/s]Loading train:  60%|██████    | 171/285 [03:20<01:47,  1.06it/s]Loading train:  60%|██████    | 172/285 [03:21<01:52,  1.00it/s]Loading train:  61%|██████    | 173/285 [03:22<01:48,  1.04it/s]Loading train:  61%|██████    | 174/285 [03:23<01:49,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [03:24<02:03,  1.12s/it]Loading train:  62%|██████▏   | 176/285 [03:25<02:01,  1.12s/it]Loading train:  62%|██████▏   | 177/285 [03:26<01:54,  1.06s/it]Loading train:  62%|██████▏   | 178/285 [03:27<01:48,  1.02s/it]Loading train:  63%|██████▎   | 179/285 [03:28<01:41,  1.05it/s]Loading train:  63%|██████▎   | 180/285 [03:29<01:48,  1.03s/it]Loading train:  64%|██████▎   | 181/285 [03:30<01:50,  1.06s/it]Loading train:  64%|██████▍   | 182/285 [03:31<01:42,  1.01it/s]Loading train:  64%|██████▍   | 183/285 [03:32<01:43,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [03:33<01:40,  1.01it/s]Loading train:  65%|██████▍   | 185/285 [03:34<01:38,  1.02it/s]Loading train:  65%|██████▌   | 186/285 [03:35<01:42,  1.04s/it]Loading train:  66%|██████▌   | 187/285 [03:36<01:41,  1.03s/it]Loading train:  66%|██████▌   | 188/285 [03:37<01:41,  1.05s/it]Loading train:  66%|██████▋   | 189/285 [03:38<01:35,  1.00it/s]Loading train:  67%|██████▋   | 190/285 [03:39<01:36,  1.02s/it]Loading train:  67%|██████▋   | 191/285 [03:41<01:43,  1.10s/it]Loading train:  67%|██████▋   | 192/285 [03:42<01:40,  1.08s/it]Loading train:  68%|██████▊   | 193/285 [03:43<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [03:44<01:36,  1.06s/it]Loading train:  68%|██████▊   | 195/285 [03:45<01:29,  1.01it/s]Loading train:  69%|██████▉   | 196/285 [03:46<01:33,  1.05s/it]Loading train:  69%|██████▉   | 197/285 [03:47<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [03:48<01:33,  1.07s/it]Loading train:  70%|██████▉   | 199/285 [03:49<01:25,  1.00it/s]Loading train:  70%|███████   | 200/285 [03:50<01:32,  1.09s/it]Loading train:  71%|███████   | 201/285 [03:51<01:34,  1.12s/it]Loading train:  71%|███████   | 202/285 [03:53<01:36,  1.16s/it]Loading train:  71%|███████   | 203/285 [03:54<01:35,  1.17s/it]Loading train:  72%|███████▏  | 204/285 [03:55<01:30,  1.12s/it]Loading train:  72%|███████▏  | 205/285 [03:56<01:31,  1.15s/it]Loading train:  72%|███████▏  | 206/285 [03:57<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [03:58<01:34,  1.21s/it]Loading train:  73%|███████▎  | 208/285 [04:00<01:37,  1.26s/it]Loading train:  73%|███████▎  | 209/285 [04:01<01:37,  1.29s/it]Loading train:  74%|███████▎  | 210/285 [04:02<01:25,  1.14s/it]Loading train:  74%|███████▍  | 211/285 [04:03<01:25,  1.16s/it]Loading train:  74%|███████▍  | 212/285 [04:04<01:20,  1.10s/it]Loading train:  75%|███████▍  | 213/285 [04:05<01:20,  1.11s/it]Loading train:  75%|███████▌  | 214/285 [04:06<01:16,  1.07s/it]Loading train:  75%|███████▌  | 215/285 [04:07<01:16,  1.10s/it]Loading train:  76%|███████▌  | 216/285 [04:08<01:12,  1.05s/it]Loading train:  76%|███████▌  | 217/285 [04:09<01:12,  1.07s/it]Loading train:  76%|███████▋  | 218/285 [04:11<01:19,  1.18s/it]Loading train:  77%|███████▋  | 219/285 [04:12<01:25,  1.30s/it]Loading train:  77%|███████▋  | 220/285 [04:13<01:15,  1.17s/it]Loading train:  78%|███████▊  | 221/285 [04:14<01:11,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [04:15<01:10,  1.11s/it]Loading train:  78%|███████▊  | 223/285 [04:16<01:02,  1.01s/it]Loading train:  79%|███████▊  | 224/285 [04:17<01:02,  1.03s/it]Loading train:  79%|███████▉  | 225/285 [04:19<01:07,  1.12s/it]Loading train:  79%|███████▉  | 226/285 [04:20<01:07,  1.14s/it]Loading train:  80%|███████▉  | 227/285 [04:21<01:05,  1.14s/it]Loading train:  80%|████████  | 228/285 [04:22<01:08,  1.19s/it]Loading train:  80%|████████  | 229/285 [04:23<01:08,  1.21s/it]Loading train:  81%|████████  | 230/285 [04:25<01:04,  1.17s/it]Loading train:  81%|████████  | 231/285 [04:25<00:58,  1.09s/it]Loading train:  81%|████████▏ | 232/285 [04:27<00:58,  1.09s/it]Loading train:  82%|████████▏ | 233/285 [04:27<00:54,  1.04s/it]Loading train:  82%|████████▏ | 234/285 [04:29<00:56,  1.11s/it]Loading train:  82%|████████▏ | 235/285 [04:30<00:52,  1.05s/it]Loading train:  83%|████████▎ | 236/285 [04:31<00:51,  1.05s/it]Loading train:  83%|████████▎ | 237/285 [04:32<00:49,  1.04s/it]Loading train:  84%|████████▎ | 238/285 [04:33<00:50,  1.08s/it]Loading train:  84%|████████▍ | 239/285 [04:34<00:52,  1.14s/it]Loading train:  84%|████████▍ | 240/285 [04:35<00:49,  1.11s/it]Loading train:  85%|████████▍ | 241/285 [04:36<00:49,  1.13s/it]Loading train:  85%|████████▍ | 242/285 [04:37<00:47,  1.11s/it]Loading train:  85%|████████▌ | 243/285 [04:38<00:44,  1.06s/it]Loading train:  86%|████████▌ | 244/285 [04:40<00:54,  1.32s/it]Loading train:  86%|████████▌ | 245/285 [04:41<00:51,  1.28s/it]Loading train:  86%|████████▋ | 246/285 [04:43<00:51,  1.32s/it]Loading train:  87%|████████▋ | 247/285 [04:44<00:48,  1.28s/it]Loading train:  87%|████████▋ | 248/285 [04:45<00:44,  1.20s/it]Loading train:  87%|████████▋ | 249/285 [04:46<00:42,  1.19s/it]Loading train:  88%|████████▊ | 250/285 [04:47<00:42,  1.20s/it]Loading train:  88%|████████▊ | 251/285 [04:49<00:40,  1.19s/it]Loading train:  88%|████████▊ | 252/285 [04:50<00:38,  1.18s/it]Loading train:  89%|████████▉ | 253/285 [04:51<00:38,  1.19s/it]Loading train:  89%|████████▉ | 254/285 [04:52<00:35,  1.16s/it]Loading train:  89%|████████▉ | 255/285 [04:53<00:35,  1.18s/it]Loading train:  90%|████████▉ | 256/285 [04:54<00:32,  1.11s/it]Loading train:  90%|█████████ | 257/285 [04:55<00:31,  1.14s/it]Loading train:  91%|█████████ | 258/285 [04:57<00:32,  1.20s/it]Loading train:  91%|█████████ | 259/285 [04:58<00:32,  1.25s/it]Loading train:  91%|█████████ | 260/285 [04:59<00:28,  1.16s/it]Loading train:  92%|█████████▏| 261/285 [05:00<00:27,  1.13s/it]Loading train:  92%|█████████▏| 262/285 [05:01<00:24,  1.06s/it]Loading train:  92%|█████████▏| 263/285 [05:02<00:23,  1.08s/it]Loading train:  93%|█████████▎| 264/285 [05:03<00:23,  1.12s/it]Loading train:  93%|█████████▎| 265/285 [05:05<00:24,  1.24s/it]Loading train:  93%|█████████▎| 266/285 [05:06<00:23,  1.22s/it]Loading train:  94%|█████████▎| 267/285 [05:07<00:22,  1.25s/it]Loading train:  94%|█████████▍| 268/285 [05:09<00:20,  1.23s/it]Loading train:  94%|█████████▍| 269/285 [05:10<00:18,  1.17s/it]Loading train:  95%|█████████▍| 270/285 [05:11<00:17,  1.18s/it]Loading train:  95%|█████████▌| 271/285 [05:12<00:16,  1.15s/it]Loading train:  95%|█████████▌| 272/285 [05:13<00:15,  1.18s/it]Loading train:  96%|█████████▌| 273/285 [05:14<00:14,  1.20s/it]Loading train:  96%|█████████▌| 274/285 [05:15<00:12,  1.12s/it]Loading train:  96%|█████████▋| 275/285 [05:17<00:12,  1.29s/it]Loading train:  97%|█████████▋| 276/285 [05:18<00:11,  1.28s/it]Loading train:  97%|█████████▋| 277/285 [05:19<00:09,  1.23s/it]Loading train:  98%|█████████▊| 278/285 [05:21<00:08,  1.23s/it]Loading train:  98%|█████████▊| 279/285 [05:22<00:07,  1.22s/it]Loading train:  98%|█████████▊| 280/285 [05:23<00:06,  1.24s/it]Loading train:  99%|█████████▊| 281/285 [05:24<00:04,  1.20s/it]Loading train:  99%|█████████▉| 282/285 [05:25<00:03,  1.11s/it]Loading train:  99%|█████████▉| 283/285 [05:27<00:02,  1.20s/it]Loading train: 100%|█████████▉| 284/285 [05:28<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [05:29<00:00,  1.25s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 55.25it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:06, 41.13it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:06, 39.34it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:05, 44.48it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:04, 51.88it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:03, 61.60it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:04, 48.60it/s]concatenating: train:  19%|█▊        | 53/285 [00:01<00:05, 46.19it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:03, 57.26it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:03, 67.46it/s]concatenating: train:  33%|███▎      | 93/285 [00:01<00:02, 79.77it/s]concatenating: train:  37%|███▋      | 106/285 [00:01<00:02, 89.48it/s]concatenating: train:  42%|████▏     | 119/285 [00:01<00:01, 97.81it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:01, 84.33it/s]concatenating: train:  49%|████▉     | 141/285 [00:01<00:01, 77.59it/s]concatenating: train:  53%|█████▎    | 150/285 [00:02<00:02, 57.94it/s]concatenating: train:  55%|█████▌    | 158/285 [00:02<00:02, 55.83it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:02, 52.02it/s]concatenating: train:  60%|██████    | 172/285 [00:02<00:02, 56.10it/s]concatenating: train:  64%|██████▍   | 183/285 [00:02<00:01, 65.01it/s]concatenating: train:  68%|██████▊   | 193/285 [00:02<00:01, 71.80it/s]concatenating: train:  71%|███████   | 202/285 [00:03<00:01, 51.15it/s]concatenating: train:  73%|███████▎  | 209/285 [00:03<00:01, 53.04it/s]concatenating: train:  77%|███████▋  | 219/285 [00:03<00:01, 61.74it/s]concatenating: train:  81%|████████  | 231/285 [00:03<00:00, 72.26it/s]concatenating: train:  86%|████████▌ | 244/285 [00:03<00:00, 82.74it/s]concatenating: train:  90%|█████████ | 257/285 [00:03<00:00, 92.07it/s]concatenating: train:  95%|█████████▍| 270/285 [00:03<00:00, 99.98it/s]concatenating: train:  99%|█████████▉| 282/285 [00:03<00:00, 67.61it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 69.43it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.61s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.57s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 34.14it/s]2019-07-11 12:44:36.516964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 12:44:36.517071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 12:44:36.517087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 12:44:36.517096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 12:44:36.517387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.73it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.57it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.32it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.56it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.14it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.88it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.58it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.18it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.67it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.90it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.45it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.68it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.63it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.28it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.14it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.51it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.48it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.22it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.18it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.29it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.66it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 30)   16230       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 30)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 30)   8130        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 90)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 254,643
Trainable params: 79,783
Non-trainable params: 174,860
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 2.4578 - acc: 0.6640 - mDice: 0.1431 - val_loss: 1.5664 - val_acc: 0.9049 - val_mDice: 0.2870

Epoch 00001: val_mDice improved from -inf to 0.28700, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.8719 - acc: 0.8912 - mDice: 0.4092 - val_loss: 1.8434 - val_acc: 0.9057 - val_mDice: 0.3097

Epoch 00002: val_mDice improved from 0.28700 to 0.30974, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6205 - acc: 0.9009 - mDice: 0.5226 - val_loss: 1.0009 - val_acc: 0.9286 - val_mDice: 0.4601

Epoch 00003: val_mDice improved from 0.30974 to 0.46014, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5057 - acc: 0.9127 - mDice: 0.5879 - val_loss: 0.9243 - val_acc: 0.9329 - val_mDice: 0.4988

Epoch 00004: val_mDice improved from 0.46014 to 0.49876, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4570 - acc: 0.9224 - mDice: 0.6189 - val_loss: 0.7975 - val_acc: 0.9405 - val_mDice: 0.5637

Epoch 00005: val_mDice improved from 0.49876 to 0.56371, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4301 - acc: 0.9316 - mDice: 0.6361 - val_loss: 0.8272 - val_acc: 0.9317 - val_mDice: 0.5476

Epoch 00006: val_mDice did not improve from 0.56371
Epoch 7/300
 - 13s - loss: 0.4104 - acc: 0.9366 - mDice: 0.6487 - val_loss: 0.8381 - val_acc: 0.9339 - val_mDice: 0.5363

Epoch 00007: val_mDice did not improve from 0.56371
Epoch 8/300
 - 14s - loss: 0.3989 - acc: 0.9383 - mDice: 0.6564 - val_loss: 0.8447 - val_acc: 0.9314 - val_mDice: 0.5423

Epoch 00008: val_mDice did not improve from 0.56371
Epoch 9/300
 - 13s - loss: 0.3869 - acc: 0.9394 - mDice: 0.6643 - val_loss: 0.7936 - val_acc: 0.9384 - val_mDice: 0.5672

Epoch 00009: val_mDice improved from 0.56371 to 0.56722, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.3781 - acc: 0.9402 - mDice: 0.6704 - val_loss: 0.7767 - val_acc: 0.9408 - val_mDice: 0.5809

Epoch 00010: val_mDice improved from 0.56722 to 0.58091, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3677 - acc: 0.9410 - mDice: 0.6775 - val_loss: 0.7931 - val_acc: 0.9396 - val_mDice: 0.5681

Epoch 00011: val_mDice did not improve from 0.58091
Epoch 12/300
 - 13s - loss: 0.3603 - acc: 0.9417 - mDice: 0.6827 - val_loss: 0.8195 - val_acc: 0.9392 - val_mDice: 0.5577

Epoch 00012: val_mDice did not improve from 0.58091
Epoch 13/300
 - 14s - loss: 0.3569 - acc: 0.9421 - mDice: 0.6853 - val_loss: 0.8596 - val_acc: 0.9361 - val_mDice: 0.5412

Epoch 00013: val_mDice did not improve from 0.58091
Epoch 14/300
 - 13s - loss: 0.3507 - acc: 0.9426 - mDice: 0.6895 - val_loss: 0.8518 - val_acc: 0.9407 - val_mDice: 0.5444

Epoch 00014: val_mDice did not improve from 0.58091
Epoch 15/300
 - 14s - loss: 0.3445 - acc: 0.9431 - mDice: 0.6939 - val_loss: 0.8233 - val_acc: 0.9402 - val_mDice: 0.5581

Epoch 00015: val_mDice did not improve from 0.58091
Epoch 16/300
 - 13s - loss: 0.3400 - acc: 0.9433 - mDice: 0.6972 - val_loss: 0.7977 - val_acc: 0.9400 - val_mDice: 0.5765

Epoch 00016: val_mDice did not improve from 0.58091
Epoch 17/300
 - 13s - loss: 0.3356 - acc: 0.9437 - mDice: 0.7004 - val_loss: 0.8081 - val_acc: 0.9403 - val_mDice: 0.5697

Epoch 00017: val_mDice did not improve from 0.58091
Epoch 18/300
 - 13s - loss: 0.3316 - acc: 0.9440 - mDice: 0.7032 - val_loss: 0.8015 - val_acc: 0.9405 - val_mDice: 0.5742

Epoch 00018: val_mDice did not improve from 0.58091
Epoch 19/300
 - 13s - loss: 0.3288 - acc: 0.9443 - mDice: 0.7053 - val_loss: 0.8002 - val_acc: 0.9388 - val_mDice: 0.5751

Epoch 00019: val_mDice did not improve from 0.58091
Epoch 20/300
 - 13s - loss: 0.3276 - acc: 0.9444 - mDice: 0.7062 - val_loss: 0.7900 - val_acc: 0.9397 - val_mDice: 0.5789

Epoch 00020: val_mDice did not improve from 0.58091
Epoch 21/300
 - 13s - loss: 0.3234 - acc: 0.9447 - mDice: 0.7093 - val_loss: 0.8416 - val_acc: 0.9405 - val_mDice: 0.5552

Epoch 00021: val_mDice did not improve from 0.58091
Epoch 22/300
 - 13s - loss: 0.3193 - acc: 0.9450 - mDice: 0.7123 - val_loss: 0.8126 - val_acc: 0.9390 - val_mDice: 0.5685

Epoch 00022: val_mDice did not improve from 0.58091
Epoch 23/300
 - 13s - loss: 0.3157 - acc: 0.9453 - mDice: 0.7150 - val_loss: 0.8418 - val_acc: 0.9405 - val_mDice: 0.5462

Epoch 00023: val_mDice did not improve from 0.58091
Epoch 24/300
 - 14s - loss: 0.3156 - acc: 0.9454 - mDice: 0.7150 - val_loss: 0.8069 - val_acc: 0.9377 - val_mDice: 0.5755

Epoch 00024: val_mDice did not improve from 0.58091
Epoch 25/300
 - 13s - loss: 0.3135 - acc: 0.9457 - mDice: 0.7167 - val_loss: 0.8608 - val_acc: 0.9402 - val_mDice: 0.5394

Epoch 00025: val_mDice did not improve from 0.58091
Epoch 26/300
 - 13s - loss: 0.3090 - acc: 0.9459 - mDice: 0.7199 - val_loss: 0.8121 - val_acc: 0.9416 - val_mDice: 0.5741

Epoch 00026: val_mDice did not improve from 0.58091
Epoch 27/300
 - 14s - loss: 0.3059 - acc: 0.9462 - mDice: 0.7223 - val_loss: 0.7911 - val_acc: 0.9407 - val_mDice: 0.5711

Epoch 00027: val_mDice did not improve from 0.58091
Epoch 28/300
 - 13s - loss: 0.3064 - acc: 0.9463 - mDice: 0.7219 - val_loss: 0.7913 - val_acc: 0.9425 - val_mDice: 0.5802

Epoch 00028: val_mDice did not improve from 0.58091
Epoch 29/300
 - 13s - loss: 0.3023 - acc: 0.9466 - mDice: 0.7250 - val_loss: 0.8215 - val_acc: 0.9391 - val_mDice: 0.5690

Epoch 00029: val_mDice did not improve from 0.58091
Epoch 30/300
 - 13s - loss: 0.3026 - acc: 0.9466 - mDice: 0.7248 - val_loss: 0.8158 - val_acc: 0.9352 - val_mDice: 0.5625

Epoch 00030: val_mDice did not improve from 0.58091
Epoch 31/300
 - 14s - loss: 0.2989 - acc: 0.9468 - mDice: 0.7275 - val_loss: 0.8381 - val_acc: 0.9409 - val_mDice: 0.5532

Epoch 00031: val_mDice did not improve from 0.58091
Epoch 32/300
 - 13s - loss: 0.2982 - acc: 0.9470 - mDice: 0.7281 - val_loss: 0.8244 - val_acc: 0.9421 - val_mDice: 0.5511

Epoch 00032: val_mDice did not improve from 0.58091
Epoch 33/300
 - 14s - loss: 0.2968 - acc: 0.9471 - mDice: 0.7292 - val_loss: 0.7889 - val_acc: 0.9410 - val_mDice: 0.5756

Epoch 00033: val_mDice did not improve from 0.58091
Epoch 34/300
 - 13s - loss: 0.2943 - acc: 0.9472 - mDice: 0.7311 - val_loss: 0.8001 - val_acc: 0.9389 - val_mDice: 0.5714

Epoch 00034: val_mDice did not improve from 0.58091
Epoch 35/300
 - 13s - loss: 0.2928 - acc: 0.9474 - mDice: 0.7323 - val_loss: 0.7747 - val_acc: 0.9422 - val_mDice: 0.5823

Epoch 00035: val_mDice improved from 0.58091 to 0.58226, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 14s - loss: 0.2907 - acc: 0.9477 - mDice: 0.7339 - val_loss: 0.7816 - val_acc: 0.9426 - val_mDice: 0.5766

Epoch 00036: val_mDice did not improve from 0.58226
Epoch 37/300
 - 13s - loss: 0.2910 - acc: 0.9475 - mDice: 0.7336 - val_loss: 0.8041 - val_acc: 0.9419 - val_mDice: 0.5604

Epoch 00037: val_mDice did not improve from 0.58226
Epoch 38/300
 - 13s - loss: 0.2889 - acc: 0.9477 - mDice: 0.7351 - val_loss: 0.7815 - val_acc: 0.9414 - val_mDice: 0.5699

Epoch 00038: val_mDice did not improve from 0.58226
Epoch 39/300
 - 13s - loss: 0.2866 - acc: 0.9480 - mDice: 0.7369 - val_loss: 0.8086 - val_acc: 0.9402 - val_mDice: 0.5598

Epoch 00039: val_mDice did not improve from 0.58226
Epoch 40/300
 - 13s - loss: 0.2855 - acc: 0.9480 - mDice: 0.7378 - val_loss: 0.7781 - val_acc: 0.9378 - val_mDice: 0.5764

Epoch 00040: val_mDice did not improve from 0.58226
Epoch 41/300
 - 13s - loss: 0.2853 - acc: 0.9480 - mDice: 0.7379 - val_loss: 0.7836 - val_acc: 0.9380 - val_mDice: 0.5722

Epoch 00041: val_mDice did not improve from 0.58226
Epoch 42/300
 - 13s - loss: 0.2825 - acc: 0.9483 - mDice: 0.7402 - val_loss: 0.7956 - val_acc: 0.9421 - val_mDice: 0.5669

Epoch 00042: val_mDice did not improve from 0.58226
Epoch 43/300
 - 13s - loss: 0.2801 - acc: 0.9485 - mDice: 0.7419 - val_loss: 0.7936 - val_acc: 0.9414 - val_mDice: 0.5636

Epoch 00043: val_mDice did not improve from 0.58226
Epoch 44/300
 - 13s - loss: 0.2813 - acc: 0.9484 - mDice: 0.7410 - val_loss: 0.7730 - val_acc: 0.9399 - val_mDice: 0.5762

Epoch 00044: val_mDice did not improve from 0.58226
Epoch 45/300
 - 13s - loss: 0.2801 - acc: 0.9484 - mDice: 0.7419 - val_loss: 0.7655 - val_acc: 0.9432 - val_mDice: 0.5798

Epoch 00045: val_mDice did not improve from 0.58226
Epoch 46/300
 - 13s - loss: 0.2780 - acc: 0.9487 - mDice: 0.7436 - val_loss: 0.7835 - val_acc: 0.9425 - val_mDice: 0.5754

Epoch 00046: val_mDice did not improve from 0.58226
Epoch 47/300
 - 13s - loss: 0.2793 - acc: 0.9485 - mDice: 0.7427 - val_loss: 0.7525 - val_acc: 0.9408 - val_mDice: 0.5806

Epoch 00047: val_mDice did not improve from 0.58226
Epoch 48/300
 - 13s - loss: 0.2776 - acc: 0.9488 - mDice: 0.7440 - val_loss: 0.7648 - val_acc: 0.9397 - val_mDice: 0.5728

Epoch 00048: val_mDice did not improve from 0.58226
Epoch 49/300
 - 13s - loss: 0.2765 - acc: 0.9488 - mDice: 0.7448 - val_loss: 0.7853 - val_acc: 0.9409 - val_mDice: 0.5662

Epoch 00049: val_mDice did not improve from 0.58226
Epoch 50/300
 - 13s - loss: 0.2748 - acc: 0.9490 - mDice: 0.7461 - val_loss: 0.7800 - val_acc: 0.9435 - val_mDice: 0.5700

Epoch 00050: val_mDice did not improve from 0.58226
Epoch 51/300
 - 13s - loss: 0.2733 - acc: 0.9491 - mDice: 0.7473 - val_loss: 0.7684 - val_acc: 0.9397 - val_mDice: 0.5721

Epoch 00051: val_mDice did not improve from 0.58226
Epoch 52/300
 - 13s - loss: 0.2725 - acc: 0.9493 - mDice: 0.7479 - val_loss: 0.7607 - val_acc: 0.9422 - val_mDice: 0.5710

Epoch 00052: val_mDice did not improve from 0.58226
Epoch 53/300
 - 13s - loss: 0.2716 - acc: 0.9492 - mDice: 0.7486 - val_loss: 0.7671 - val_acc: 0.9407 - val_mDice: 0.5797

Epoch 00053: val_mDice did not improve from 0.58226
Epoch 54/300
 - 13s - loss: 0.2730 - acc: 0.9493 - mDice: 0.7476 - val_loss: 0.8082 - val_acc: 0.9377 - val_mDice: 0.5595

Epoch 00054: val_mDice did not improve from 0.58226
Epoch 55/300
 - 13s - loss: 0.2706 - acc: 0.9494 - mDice: 0.7494 - val_loss: 0.7923 - val_acc: 0.9414 - val_mDice: 0.5556

Epoch 00055: val_mDice did not improve from 0.58226
Epoch 56/300
 - 13s - loss: 0.2699 - acc: 0.9495 - mDice: 0.7500 - val_loss: 0.8052 - val_acc: 0.9423 - val_mDice: 0.5542

Epoch 00056: val_mDice did not improve from 0.58226
Epoch 57/300
 - 13s - loss: 0.2688 - acc: 0.9495 - mDice: 0.7508 - val_loss: 0.7623 - val_acc: 0.9412 - val_mDice: 0.5684

Epoch 00057: val_mDice did not improve from 0.58226
Epoch 58/300
 - 13s - loss: 0.2680 - acc: 0.9496 - mDice: 0.7514 - val_loss: 0.7872 - val_acc: 0.9406 - val_mDice: 0.5730

Epoch 00058: val_mDice did not improve from 0.58226
Epoch 59/300
 - 13s - loss: 0.2668 - acc: 0.9497 - mDice: 0.7523 - val_loss: 0.7609 - val_acc: 0.9425 - val_mDice: 0.5771

Epoch 00059: val_mDice did not improve from 0.58226
Epoch 60/300
 - 13s - loss: 0.2671 - acc: 0.9497 - mDice: 0.7522 - val_loss: 0.7607 - val_acc: 0.9406 - val_mDice: 0.5792

Epoch 00060: val_mDice did not improve from 0.58226
Epoch 61/300
 - 13s - loss: 0.2650 - acc: 0.9499 - mDice: 0.7539 - val_loss: 0.7506 - val_acc: 0.9416 - val_mDice: 0.5843

Epoch 00061: val_mDice improved from 0.58226 to 0.58428, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 13s - loss: 0.2652 - acc: 0.9499 - mDice: 0.7536 - val_loss: 0.7629 - val_acc: 0.9432 - val_mDice: 0.5735

Epoch 00062: val_mDice did not improve from 0.58428
Epoch 63/300
 - 13s - loss: 0.2655 - acc: 0.9498 - mDice: 0.7535 - val_loss: 0.7590 - val_acc: 0.9415 - val_mDice: 0.5782

Epoch 00063: val_mDice did not improve from 0.58428
Epoch 64/300
 - 13s - loss: 0.2643 - acc: 0.9498 - mDice: 0.7544 - val_loss: 0.7637 - val_acc: 0.9420 - val_mDice: 0.5692

Epoch 00064: val_mDice did not improve from 0.58428
Epoch 65/300
 - 13s - loss: 0.2629 - acc: 0.9501 - mDice: 0.7555 - val_loss: 0.7596 - val_acc: 0.9431 - val_mDice: 0.5776

Epoch 00065: val_mDice did not improve from 0.58428
Epoch 66/300
 - 13s - loss: 0.2624 - acc: 0.9501 - mDice: 0.7559 - val_loss: 0.7685 - val_acc: 0.9404 - val_mDice: 0.5711

Epoch 00066: val_mDice did not improve from 0.58428
Epoch 67/300
 - 13s - loss: 0.2637 - acc: 0.9500 - mDice: 0.7549 - val_loss: 0.7652 - val_acc: 0.9416 - val_mDice: 0.5780

Epoch 00067: val_mDice did not improve from 0.58428
Epoch 68/300
 - 13s - loss: 0.2614 - acc: 0.9501 - mDice: 0.7566 - val_loss: 0.7589 - val_acc: 0.9420 - val_mDice: 0.5787

Epoch 00068: val_mDice did not improve from 0.58428
Epoch 69/300
 - 13s - loss: 0.2614 - acc: 0.9502 - mDice: 0.7566 - val_loss: 0.7687 - val_acc: 0.9410 - val_mDice: 0.5574

Epoch 00069: val_mDice did not improve from 0.58428
Epoch 70/300
 - 13s - loss: 0.2603 - acc: 0.9502 - mDice: 0.7576 - val_loss: 0.7695 - val_acc: 0.9418 - val_mDice: 0.5749

Epoch 00070: val_mDice did not improve from 0.58428
Epoch 71/300
 - 13s - loss: 0.2590 - acc: 0.9503 - mDice: 0.7586 - val_loss: 0.7195 - val_acc: 0.9419 - val_mDice: 0.5878

Epoch 00071: val_mDice improved from 0.58428 to 0.58779, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 13s - loss: 0.2582 - acc: 0.9504 - mDice: 0.7592 - val_loss: 0.7811 - val_acc: 0.9402 - val_mDice: 0.5592

Epoch 00072: val_mDice did not improve from 0.58779
Epoch 73/300
 - 13s - loss: 0.2581 - acc: 0.9503 - mDice: 0.7592 - val_loss: 0.7891 - val_acc: 0.9418 - val_mDice: 0.5620

Epoch 00073: val_mDice did not improve from 0.58779
Epoch 74/300
 - 13s - loss: 0.2578 - acc: 0.9505 - mDice: 0.7596 - val_loss: 0.7670 - val_acc: 0.9397 - val_mDice: 0.5781

Epoch 00074: val_mDice did not improve from 0.58779
Epoch 75/300
 - 13s - loss: 0.2561 - acc: 0.9507 - mDice: 0.7609 - val_loss: 0.7452 - val_acc: 0.9424 - val_mDice: 0.5718

Epoch 00075: val_mDice did not improve from 0.58779
Epoch 76/300
 - 13s - loss: 0.2558 - acc: 0.9507 - mDice: 0.7611 - val_loss: 0.7374 - val_acc: 0.9411 - val_mDice: 0.5781

Epoch 00076: val_mDice did not improve from 0.58779
Epoch 77/300
 - 13s - loss: 0.2552 - acc: 0.9507 - mDice: 0.7616 - val_loss: 0.7539 - val_acc: 0.9413 - val_mDice: 0.5724

Epoch 00077: val_mDice did not improve from 0.58779
Epoch 78/300
 - 13s - loss: 0.2551 - acc: 0.9508 - mDice: 0.7617 - val_loss: 0.7809 - val_acc: 0.9397 - val_mDice: 0.5714

Epoch 00078: val_mDice did not improve from 0.58779
Epoch 79/300
 - 13s - loss: 0.2566 - acc: 0.9506 - mDice: 0.7605 - val_loss: 0.7549 - val_acc: 0.9415 - val_mDice: 0.5744

Epoch 00079: val_mDice did not improve from 0.58779
Epoch 80/300
 - 13s - loss: 0.2548 - acc: 0.9508 - mDice: 0.7620 - val_loss: 0.7619 - val_acc: 0.9412 - val_mDice: 0.5729

Epoch 00080: val_mDice did not improve from 0.58779
Epoch 81/300
 - 13s - loss: 0.2542 - acc: 0.9507 - mDice: 0.7624 - val_loss: 0.7718 - val_acc: 0.9415 - val_mDice: 0.5687

Epoch 00081: val_mDice did not improve from 0.58779
Epoch 82/300
 - 13s - loss: 0.2554 - acc: 0.9508 - mDice: 0.7615 - val_loss: 0.7388 - val_acc: 0.9413 - val_mDice: 0.5835

Epoch 00082: val_mDice did not improve from 0.58779
Epoch 83/300
 - 13s - loss: 0.2536 - acc: 0.9509 - mDice: 0.7629 - val_loss: 0.7546 - val_acc: 0.9420 - val_mDice: 0.5704

Epoch 00083: val_mDice did not improve from 0.58779
Epoch 84/300
 - 13s - loss: 0.2551 - acc: 0.9508 - mDice: 0.7618 - val_loss: 0.7769 - val_acc: 0.9411 - val_mDice: 0.5659

Epoch 00084: val_mDice did not improve from 0.58779
Epoch 85/300
 - 13s - loss: 0.2512 - acc: 0.9511 - mDice: 0.7648 - val_loss: 0.7637 - val_acc: 0.9412 - val_mDice: 0.5707

Epoch 00085: val_mDice did not improve from 0.58779
Epoch 86/300
 - 13s - loss: 0.2516 - acc: 0.9511 - mDice: 0.7648 - val_loss: 0.7394 - val_acc: 0.9384 - val_mDice: 0.5687

Epoch 00086: val_mDice did not improve from 0.58779
Epoch 87/300
 - 13s - loss: 0.3782 - acc: 0.9404 - mDice: 0.6746 - val_loss: 0.6885 - val_acc: 0.9417 - val_mDice: 0.5658

Epoch 00087: val_mDice did not improve from 0.58779
Epoch 88/300
 - 13s - loss: 0.2904 - acc: 0.9480 - mDice: 0.7343 - val_loss: 0.6889 - val_acc: 0.9441 - val_mDice: 0.5790

Epoch 00088: val_mDice did not improve from 0.58779
Epoch 89/300
 - 13s - loss: 0.2732 - acc: 0.9493 - mDice: 0.7476 - val_loss: 0.7186 - val_acc: 0.9441 - val_mDice: 0.5781

Epoch 00089: val_mDice did not improve from 0.58779
Epoch 90/300
 - 13s - loss: 0.2636 - acc: 0.9501 - mDice: 0.7550 - val_loss: 0.7434 - val_acc: 0.9422 - val_mDice: 0.5791

Epoch 00090: val_mDice did not improve from 0.58779
Epoch 91/300
 - 12s - loss: 0.2585 - acc: 0.9505 - mDice: 0.7590 - val_loss: 0.7129 - val_acc: 0.9423 - val_mDice: 0.5811

Epoch 00091: val_mDice did not improve from 0.58779
Epoch 92/300
 - 12s - loss: 0.2551 - acc: 0.9508 - mDice: 0.7617 - val_loss: 0.7033 - val_acc: 0.9422 - val_mDice: 0.5818

Epoch 00092: val_mDice did not improve from 0.58779
Epoch 93/300
 - 13s - loss: 0.2537 - acc: 0.9510 - mDice: 0.7628 - val_loss: 0.7438 - val_acc: 0.9401 - val_mDice: 0.5726

Epoch 00093: val_mDice did not improve from 0.58779
Epoch 94/300
 - 12s - loss: 0.2508 - acc: 0.9512 - mDice: 0.7652 - val_loss: 0.7256 - val_acc: 0.9422 - val_mDice: 0.5690

Epoch 00094: val_mDice did not improve from 0.58779
Epoch 95/300
 - 12s - loss: 0.2515 - acc: 0.9511 - mDice: 0.7646 - val_loss: 0.7192 - val_acc: 0.9409 - val_mDice: 0.5751

Epoch 00095: val_mDice did not improve from 0.58779
Epoch 96/300
 - 12s - loss: 0.2495 - acc: 0.9513 - mDice: 0.7662 - val_loss: 0.7357 - val_acc: 0.9415 - val_mDice: 0.5597

Epoch 00096: val_mDice did not improve from 0.58779
Epoch 97/300
 - 12s - loss: 0.2486 - acc: 0.9513 - mDice: 0.7668 - val_loss: 0.7059 - val_acc: 0.9427 - val_mDice: 0.5753

Epoch 00097: val_mDice did not improve from 0.58779
Epoch 98/300
 - 13s - loss: 0.2504 - acc: 0.9513 - mDice: 0.7656 - val_loss: 0.7607 - val_acc: 0.9404 - val_mDice: 0.5655

Epoch 00098: val_mDice did not improve from 0.58779
Epoch 99/300
 - 13s - loss: 0.2476 - acc: 0.9514 - mDice: 0.7678 - val_loss: 0.6919 - val_acc: 0.9406 - val_mDice: 0.5790

Epoch 00099: val_mDice did not improve from 0.58779
Epoch 100/300
 - 12s - loss: 0.2483 - acc: 0.9514 - mDice: 0.7671 - val_loss: 0.7227 - val_acc: 0.9412 - val_mDice: 0.5709

Epoch 00100: val_mDice did not improve from 0.58779
Epoch 101/300
 - 12s - loss: 0.2472 - acc: 0.9514 - mDice: 0.7681 - val_loss: 0.7177 - val_acc: 0.9416 - val_mDice: 0.5761

Epoch 00101: val_mDice did not improve from 0.58779
Epoch 102/300
 - 13s - loss: 0.2480 - acc: 0.9514 - mDice: 0.7675 - val_loss: 0.7285 - val_acc: 0.9404 - val_mDice: 0.5690

Epoch 00102: val_mDice did not improve from 0.58779
Epoch 103/300
 - 13s - loss: 0.2463 - acc: 0.9514 - mDice: 0.7688 - val_loss: 0.7370 - val_acc: 0.9403 - val_mDice: 0.5672

Epoch 00103: val_mDice did not improve from 0.58779
Epoch 104/300
 - 12s - loss: 0.2460 - acc: 0.9516 - mDice: 0.7690 - val_loss: 0.7048 - val_acc: 0.9410 - val_mDice: 0.5710

Epoch 00104: val_mDice did not improve from 0.58779
Epoch 105/300
 - 12s - loss: 0.2446 - acc: 0.9517 - mDice: 0.7702 - val_loss: 0.6825 - val_acc: 0.9421 - val_mDice: 0.5764

Epoch 00105: val_mDice did not improve from 0.58779
Epoch 106/300
 - 13s - loss: 0.2448 - acc: 0.9516 - mDice: 0.7700 - val_loss: 0.6744 - val_acc: 0.9411 - val_mDice: 0.5737

Epoch 00106: val_mDice did not improve from 0.58779
Epoch 107/300
 - 12s - loss: 0.2449 - acc: 0.9517 - mDice: 0.7700 - val_loss: 0.6924 - val_acc: 0.9397 - val_mDice: 0.5733

Epoch 00107: val_mDice did not improve from 0.58779
Epoch 108/300
 - 13s - loss: 0.2433 - acc: 0.9517 - mDice: 0.7712 - val_loss: 0.7357 - val_acc: 0.9398 - val_mDice: 0.5675

Epoch 00108: val_mDice did not improve from 0.58779
Epoch 109/300
 - 13s - loss: 0.2450 - acc: 0.9516 - mDice: 0.7698 - val_loss: 0.7033 - val_acc: 0.9420 - val_mDice: 0.5708

Epoch 00109: val_mDice did not improve from 0.58779
Epoch 110/300
 - 12s - loss: 0.2439 - acc: 0.9517 - mDice: 0.7707 - val_loss: 0.7109 - val_acc: 0.9411 - val_mDice: 0.5622

Epoch 00110: val_mDice did not improve from 0.58779
Epoch 111/300
 - 13s - loss: 0.2433 - acc: 0.9517 - mDice: 0.7713 - val_loss: 0.7024 - val_acc: 0.9403 - val_mDice: 0.5804

Epoch 00111: val_mDice did not improve from 0.58779
Restoring model weights from the end of the best epoch
Epoch 00111: early stopping
{'val_loss': [1.5664256169245794, 1.8433731840207026, 1.0008654502721934, 0.9242728214997512, 0.7975082443310664, 0.8272134203177232, 0.8381295135388007, 0.8446582211897924, 0.7935607135295868, 0.7766736413423831, 0.7931043551518366, 0.8195052032287304, 0.8595523513280429, 0.8518004600818341, 0.8233102697592515, 0.7976506283650031, 0.8081365067225236, 0.8015137750368851, 0.8002162942519555, 0.7899778863558402, 0.8416320314774146, 0.8126208713421454, 0.8417582993323987, 0.8068755910946772, 0.8607803560220278, 0.8120830769722278, 0.7910502644685599, 0.7913105361736738, 0.8215477604132432, 0.8157913982868195, 0.8380969992050757, 0.8243831923374763, 0.7888595989117255, 0.800056319970351, 0.7746540823808084, 0.7815812700069867, 0.8041196740590609, 0.7815023958683014, 0.8086198018147395, 0.778097329231409, 0.7835787144991068, 0.7955500758611239, 0.7935722837081323, 0.7730198594240042, 0.7654630461564431, 0.7834515204796424, 0.7524584130598948, 0.764756264594885, 0.7853242686161628, 0.7800459861755371, 0.7684105405440698, 0.7607024747591752, 0.7670945456394782, 0.8082380180175488, 0.7922722376309909, 0.8052276968955994, 0.7623207798370948, 0.787237265935311, 0.7609291626856878, 0.7607131978640189, 0.7506380058251895, 0.7628927276684687, 0.7590300784661219, 0.7637114364367265, 0.7596099548614942, 0.7684500377911788, 0.7651637208003265, 0.758880921281301, 0.7687307871305026, 0.7695290102408483, 0.7195235662735425, 0.7810501547960135, 0.789079276415018, 0.7670302677613038, 0.7451777893763322, 0.7373692462077508, 0.7539203327435714, 0.7808777048037603, 0.7548661828041077, 0.7618922820458045, 0.7718330300771273, 0.7388383734684724, 0.7546121386381296, 0.7768544646409842, 0.7637224472486056, 0.739427176805643, 0.6885370359970973, 0.6888652638747141, 0.718586286673179, 0.743362246797635, 0.7128865959552618, 0.7033248360340412, 0.7437612185111413, 0.7256216544371384, 0.7191541011516864, 0.7357189586529365, 0.7059135207763085, 0.7607077085054837, 0.6918726483216653, 0.7226857130344098, 0.7176552735842191, 0.7284510204425225, 0.7369915590836451, 0.7047624335839198, 0.6824710346185244, 0.6743977688826047, 0.6923913359642029, 0.7356533270615798, 0.7033196091651917, 0.7109269820726835, 0.7023960684354489], 'val_acc': [0.9049093929620889, 0.9057322717629946, 0.9285988257481501, 0.9328703100864704, 0.9404955896047446, 0.9316729788596814, 0.9339219469290513, 0.9313748410114875, 0.9383506110081306, 0.9408053090939155, 0.9395640950936538, 0.9392289244211637, 0.9361131672675793, 0.9406804648729471, 0.9401673353635348, 0.9399639322207525, 0.9402967668496646, 0.9404631830178775, 0.9388475578564864, 0.9397420241282537, 0.9404516472266271, 0.939044001010748, 0.9404886479561145, 0.9376872319441575, 0.9401904757206256, 0.941635074523779, 0.9407059229337252, 0.9424533339647146, 0.9391341622059162, 0.9351539405492636, 0.940920882500135, 0.9420950343975654, 0.9410225313443404, 0.9389237944896405, 0.9421504965195289, 0.9426104632707742, 0.9418893410609319, 0.9413969952326554, 0.9402020000494443, 0.937777367921976, 0.9379738500485053, 0.9421250843084775, 0.9413715509267954, 0.939938499377324, 0.9431883578117077, 0.9425157079329858, 0.9407567221384782, 0.9397281981431521, 0.9408700259832236, 0.9434703175838177, 0.9396704114400424, 0.9421597673342779, 0.9407012623090011, 0.9377149595664098, 0.9413877840225513, 0.9422522233082697, 0.9411751352823697, 0.940597279713704, 0.9424925813308129, 0.9406458047720102, 0.9415726776306446, 0.9432068375440744, 0.9414801964393029, 0.9419979751110077, 0.9430750768918258, 0.9404100248446832, 0.9415680330533248, 0.9420211062981532, 0.9410179509566381, 0.9418292137292715, 0.94188009087856, 0.9402112594017615, 0.9418269349978521, 0.9396819426463201, 0.9424163171878228, 0.941142758497825, 0.9413184248484098, 0.939675007875149, 0.9415079332315005, 0.9412351892544673, 0.9414871678902552, 0.9412814401663266, 0.9420465024618002, 0.9410687914261451, 0.9411913064809946, 0.9384106947825506, 0.9417067193067991, 0.944108282144253, 0.9441475318028376, 0.9421620689905607, 0.9422846046777872, 0.9422406485447516, 0.9401233998628763, 0.9421528302706205, 0.9409370261889237, 0.941489442036702, 0.9427098884032323, 0.9404493593252622, 0.9406088338448451, 0.9411774323536799, 0.941577264895806, 0.9403522404340597, 0.9403060560043042, 0.9409832381285154, 0.9420557572291448, 0.941149672636619, 0.9397258850244375, 0.9397674913589771, 0.941977166212522, 0.9411265620818505, 0.9402598050924448], 'val_mDice': [0.28700418999561894, 0.30973991407797885, 0.4601355922909883, 0.4987552280609424, 0.5637143070881183, 0.5476005318073126, 0.5363026891763394, 0.5422527881769034, 0.5672247719306213, 0.5809060197610122, 0.568104743384398, 0.557705086011153, 0.5411888211965561, 0.5443503042826285, 0.5580800416377875, 0.5764694930269167, 0.5696600933487599, 0.5741846211827718, 0.5750948568949332, 0.5789347061744103, 0.5551939216943887, 0.5685404900174874, 0.5462223234084936, 0.5754857647877473, 0.5393698868843225, 0.5740672023250506, 0.5711316265738927, 0.5801872714207723, 0.5690195675079639, 0.562492698431015, 0.553224581365402, 0.5511254267050669, 0.5756281751852769, 0.5713987923585452, 0.5822567160312946, 0.576593052309293, 0.5604378065237632, 0.5699191614985466, 0.5597652626725343, 0.5764473888736504, 0.5721637904644012, 0.5668566221228013, 0.5635833379167777, 0.5762289046094968, 0.5797948298545984, 0.5754460961772845, 0.5805866959003302, 0.5728225816900914, 0.5662461651059297, 0.5700393812014506, 0.5721395348127072, 0.5709566605778841, 0.5796738083545978, 0.5595155495863694, 0.5555884574468319, 0.5541855715788327, 0.5684204898201503, 0.5729661927773402, 0.5770962811433352, 0.5792264909698412, 0.5842842975488076, 0.5735471283014004, 0.5782157893364246, 0.569198319545159, 0.5776430597672095, 0.5711282004530613, 0.5780165671156003, 0.5787149507265824, 0.5574316199009235, 0.5748960226774216, 0.5877946626681548, 0.5592261953995779, 0.5619874997780874, 0.5780831781717447, 0.571761398934401, 0.5780645585977114, 0.5723717419000772, 0.5714082144773923, 0.5744329249629607, 0.5728911912212005, 0.5687371435073706, 0.5835192341070908, 0.5703888340638235, 0.5658985857780163, 0.5706542890805465, 0.568697629066614, 0.5657570416537615, 0.5789612846878859, 0.5780812845780299, 0.5791035982278677, 0.581119859447846, 0.5818449654258214, 0.5726169577011695, 0.5689663164890729, 0.575149807219322, 0.5597041283662503, 0.5753413731089005, 0.5655039199269735, 0.5789842708752706, 0.5708575655634587, 0.5760930363948529, 0.5690376403240057, 0.5672290107378593, 0.5709947198629379, 0.5764370755507395, 0.5736834148948009, 0.5733025486652668, 0.5675051963100066, 0.5707659652599921, 0.5622451265270894, 0.5804094804021028], 'loss': [2.457805257765754, 0.871863359439904, 0.6205037969466802, 0.5057255136541233, 0.45696778428199425, 0.43005237402725094, 0.41044234578914884, 0.39893806919305735, 0.38692096332545917, 0.3780716076873935, 0.3676694057600795, 0.36032792465180846, 0.35687315888392973, 0.35065143454737807, 0.3445376839533752, 0.3399544208018771, 0.3355817661990783, 0.33158004822891973, 0.3288263727557029, 0.3276269851460466, 0.32338354697880967, 0.31931891368948906, 0.31565586571586557, 0.3156182424758046, 0.3134626846471572, 0.3089946151455863, 0.30588764132284035, 0.3064082703813134, 0.3022946949997017, 0.30260948101159096, 0.29893414068351776, 0.298202048222715, 0.2967638949714419, 0.2942787045720296, 0.2927615869961068, 0.2906771312420256, 0.2909530578977363, 0.28891417633439415, 0.2866055850177676, 0.2855365707388798, 0.28531918931214073, 0.28247229131145646, 0.28014043823089324, 0.2813194229969358, 0.28008291875096825, 0.2779587416161605, 0.27931152201277143, 0.2775793986397235, 0.2764560113717937, 0.27481187989293326, 0.2732698870224123, 0.272515162807719, 0.2715809202596599, 0.2730161109957255, 0.27058391936929377, 0.2699072954702628, 0.2687983603195149, 0.26803024973605905, 0.2668464850381128, 0.2670853737946818, 0.2650089032627126, 0.2651977389102645, 0.26549494074112834, 0.26434701874083966, 0.2628675122922014, 0.26238701428026223, 0.26370757328983513, 0.26140681588043974, 0.26144779965049236, 0.2602954509402733, 0.2589976558312162, 0.25822397939538555, 0.25812041441760775, 0.25775470844298437, 0.2560949335071441, 0.2558012089253923, 0.2551919224901436, 0.25507371086240044, 0.25658091055910426, 0.2547548227008722, 0.25419660326652416, 0.2554133981287639, 0.25361539075913975, 0.2550540814815407, 0.25119350021487724, 0.2516255467005962, 0.3782049152207509, 0.2904121421320812, 0.2731716974265547, 0.26359084167461116, 0.25848855565122647, 0.25507997622692663, 0.2536601412261114, 0.2508420091303448, 0.25147247405704354, 0.2495090006465436, 0.24864818308171582, 0.2503921815986883, 0.24755151051332905, 0.24833757888014155, 0.24723628953402962, 0.24797405432667513, 0.2463113485689391, 0.24598412467062852, 0.24461777007888738, 0.2448298846082275, 0.2448511807244389, 0.24334433534637231, 0.2449936414187128, 0.24388214630124358, 0.24329943113481822], 'acc': [0.6640243805772449, 0.8911572924995405, 0.9008692006535782, 0.9126861587470498, 0.9224053629812561, 0.9315577371472484, 0.9365983840604115, 0.9383064387557714, 0.9394018604154463, 0.940233927656779, 0.9409824443855135, 0.9416999175552292, 0.9420951550477195, 0.942598578928362, 0.94307724215014, 0.9433248765319298, 0.9437000956150985, 0.944013174522586, 0.9442651747206002, 0.9443785508631297, 0.944732089500239, 0.945029318585537, 0.9453313087368214, 0.9453652517927272, 0.9457368815196986, 0.9458752873747989, 0.9462341870602389, 0.946283852873743, 0.9465768166730888, 0.9465988126010415, 0.9467784724177926, 0.9469559435682587, 0.9471440264453728, 0.9472052360563868, 0.9473828600086893, 0.9476990420407368, 0.9474814260983329, 0.9477253804223998, 0.9479747686968357, 0.9479626400064171, 0.9480454875821943, 0.9483410300643837, 0.9485131088662475, 0.9483960287647692, 0.9484259619227329, 0.9486805140768746, 0.9485472289660337, 0.9488113144276756, 0.9488368741504867, 0.9489516442930039, 0.9490922682236714, 0.9492569654935358, 0.9491762443463059, 0.9493012367486184, 0.9494156776555931, 0.949470414728803, 0.94953395207078, 0.949575896161097, 0.9497213498600336, 0.9497317040932967, 0.9498922088088381, 0.949886070217559, 0.9498417517042331, 0.9498494685625201, 0.950053340865602, 0.950091606354918, 0.9500219706546598, 0.9501306889330473, 0.950192831714336, 0.9502070613544189, 0.9503480828546086, 0.9503912508163375, 0.9503292418005589, 0.950477467382085, 0.950707697625377, 0.9506870148136399, 0.9506795432837393, 0.9508311584582245, 0.9506011738841367, 0.9508334888332743, 0.9507154120704537, 0.950790008913269, 0.9508643463057455, 0.9507539187543651, 0.9510501519204242, 0.9510988127775192, 0.940379429339571, 0.947952972158321, 0.9493357576447022, 0.9500915814422323, 0.9504566027275324, 0.9507720112844574, 0.9509552682577371, 0.9511790432294972, 0.9511262376919934, 0.9512567949352213, 0.9513236318007943, 0.9512589212923068, 0.9514328388119826, 0.9513869255954331, 0.9514165484552332, 0.951423930201618, 0.9514151938581867, 0.9515725546114935, 0.9517171655008628, 0.9516230341880885, 0.9516595917237065, 0.9517259233817836, 0.9516152518597913, 0.9517329971827474, 0.9517364955790575], 'mDice': [0.14307259351776433, 0.409245732618216, 0.522578728382607, 0.5879072843635367, 0.6188793504171064, 0.6360855515313458, 0.6487160021447612, 0.6563978561184827, 0.6643125436671664, 0.670407793469769, 0.6775236246133548, 0.6827141951890182, 0.6852670931226816, 0.6895439515119988, 0.6938943753963267, 0.6971552872211414, 0.7003590775340903, 0.703209317462708, 0.7052594322477947, 0.7061631396656094, 0.7092969877786064, 0.7122637809812611, 0.7149808093387351, 0.7149938483811233, 0.71672796781989, 0.7198628066134257, 0.722262310831131, 0.7218944886827298, 0.7250160461508633, 0.7247549168663162, 0.7274917057604299, 0.7281119415189006, 0.7292494143571602, 0.7310973574267997, 0.7322970472127103, 0.7339106248685666, 0.7336187722068821, 0.7350907809046332, 0.7368612007319482, 0.7377968828671315, 0.7378775085413861, 0.7401570113813658, 0.7418963295896918, 0.74100028267978, 0.741945385460175, 0.7435551149581484, 0.7426509213251875, 0.7439883820060478, 0.7447751295596243, 0.7460972341094456, 0.7472622940365068, 0.7478827209718045, 0.7486381752952971, 0.7476442362960278, 0.7494326132223151, 0.7499986465793248, 0.7507973550859659, 0.7514176083415854, 0.7523230875724688, 0.7521841222208869, 0.7539000415740434, 0.7536291967488892, 0.7534745547380722, 0.7543808730130352, 0.7555299166558711, 0.7559444007426734, 0.7548852139575603, 0.756649793656585, 0.7566187592171923, 0.7575656350200097, 0.7585726724629207, 0.7592126236271508, 0.7592444851270277, 0.759559429363605, 0.7609395273363063, 0.7611315052997227, 0.7616306835354161, 0.7617147454891787, 0.7604941058662406, 0.7619894864505742, 0.7623703302651503, 0.7614888990539956, 0.7628691060609245, 0.7617726812203915, 0.7648350244835823, 0.764848725355761, 0.6745974129442248, 0.7342935452863187, 0.7475647049878978, 0.7549806002771063, 0.7590181877073696, 0.76170488791548, 0.7628448307706588, 0.7651621505012044, 0.7646459753878561, 0.7662083098537245, 0.7668391446461265, 0.7655637764319452, 0.7677774826429058, 0.7671181155253762, 0.7680991787504998, 0.7674535297659241, 0.768794034098629, 0.7690348718743103, 0.7701602555570222, 0.7699861746261802, 0.7700349299063116, 0.771161849110876, 0.7698402422430726, 0.770678078530185, 0.7712651264136495]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.39s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:07,  1.93s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:29,  1.80s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:23,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:17,  1.78s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:53,  1.70s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:57,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:28,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:51,  1.93s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:30,  1.86s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:42,  1.91s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:29,  1.87s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:24,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:45,  1.95s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:54,  1.99s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:35,  1.92s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:37,  1.94s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:25,  1.90s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:19,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:24,  1.91s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:05,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:05,  1.85s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:51,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:07,  1.88s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:17,  1.92s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:47,  1.81s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:46,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:56,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:04,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:11,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:38,  1.81s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:30,  1.79s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:36,  1.82s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:50,  1.88s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:38,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:53,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:42,  1.88s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:51,  1.93s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:37,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:19,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:23,  1.83s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:31,  1.87s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:05,  1.77s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:24,  1.86s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:13,  1.82s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:21,  1.86s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:41,  1.96s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:43,  1.97s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:55,  2.03s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:33,  1.95s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:21,  1.90s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:29,  1.94s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:11,  1.88s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:09,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:56,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:56,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:09,  1.90s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:16,  1.94s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:55,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:48,  1.83s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:53,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:38,  1.80s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:45,  1.85s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:49,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:46,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:29,  1.80s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:34,  1.83s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:32,  1.83s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:22,  1.79s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:17,  1.77s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:17,  1.78s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:18,  1.79s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:20,  1.81s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:21,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:19,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:12,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:09,  1.79s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:16,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:11,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:02,  1.79s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<06:02,  1.80s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:59,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<06:12,  1.86s/it]predicting train subjects:  30%|███       | 86/285 [02:39<06:13,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:19,  1.92s/it]predicting train subjects:  31%|███       | 88/285 [02:42<06:04,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:59,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:03,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:56,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<06:04,  1.89s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:57,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:59,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:59,  1.90s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:51,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:47,  1.86s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:58,  1.93s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:57,  1.93s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:53,  1.92s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:37,  1.85s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:45,  1.91s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:45,  1.92s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:29,  1.84s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:36,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:13,  1.78s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:25,  1.86s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:11,  1.79s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:14,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:19,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:17,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:20,  1.90s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:09,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:00,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<04:49,  1.75s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:40,  1.71s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:29,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:29,  1.66s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:31,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:30,  1.69s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:28,  1.69s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:21,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:24,  1.69s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:27,  1.72s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [04:00<04:13,  1.65s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:14,  1.67s/it]predicting train subjects:  47%|████▋     | 133/285 [04:03<04:17,  1.70s/it]predicting train subjects:  47%|████▋     | 134/285 [04:05<04:13,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:06<03:57,  1.58s/it]predicting train subjects:  48%|████▊     | 136/285 [04:08<03:51,  1.55s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:11<03:44,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<03:45,  1.55s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:37,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:35,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:29,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:21<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:29,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:24<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:26<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:29<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:32<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:15,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:39<03:13,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:08,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:42<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:44<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<03:20,  1.64s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:50<03:16,  1.62s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<03:16,  1.64s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<03:21,  1.69s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<03:17,  1.67s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<03:10,  1.64s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<03:05,  1.61s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<03:02,  1.60s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<03:01,  1.60s/it]predicting train subjects:  61%|██████    | 173/285 [05:05<02:57,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:51,  1.55s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:08<02:56,  1.61s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<03:00,  1.66s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:56,  1.63s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:53,  1.66s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:56,  1.69s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:59,  1.74s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:22<02:51,  1.68s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:23<02:43,  1.62s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:25<02:37,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:27<02:47,  1.69s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:51,  1.75s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:30<02:55,  1.81s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:32<02:45,  1.72s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:38,  1.67s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:35<02:37,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:37<02:41,  1.73s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:38<02:30,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:24,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:41<02:18,  1.54s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:28,  1.67s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:34,  1.76s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:34,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:55<02:17,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:08,  1.59s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:58<02:07,  1.60s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:00<02:07,  1.61s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<02:17,  1.77s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<02:17,  1.79s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:05,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:08<02:00,  1.63s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<01:58,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:13<01:54,  1.61s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<01:58,  1.70s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:18<01:55,  1.69s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:20<01:53,  1.70s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:57,  1.78s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:23<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:40,  1.57s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:43,  1.65s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:30,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:34,  1.59s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:35<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:36<01:33,  1.65s/it]predicting train subjects:  80%|████████  | 229/285 [06:38<01:31,  1.63s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:41<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:43<01:29,  1.70s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:44<01:23,  1.61s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:36,  1.88s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:48<01:28,  1.77s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:50<01:32,  1.89s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:52<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:54<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:56<01:24,  1.83s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:57<01:20,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:59<01:18,  1.79s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:01<01:19,  1.86s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:03<01:18,  1.86s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:06<01:22,  2.02s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:08<01:22,  2.07s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:10<01:28,  2.26s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:13<01:28,  2.32s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:15<01:22,  2.24s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:17<01:14,  2.07s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:18<01:08,  1.95s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:20<01:02,  1.83s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:22<01:00,  1.84s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:24<01:05,  2.03s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:27<01:07,  2.17s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:29<01:07,  2.24s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:31<01:03,  2.19s/it]predicting train subjects:  90%|█████████ | 257/285 [07:33<01:00,  2.17s/it]predicting train subjects:  91%|█████████ | 258/285 [07:35<00:56,  2.11s/it]predicting train subjects:  91%|█████████ | 259/285 [07:37<00:54,  2.11s/it]predicting train subjects:  91%|█████████ | 260/285 [07:39<00:48,  1.95s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:41<00:45,  1.90s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:43<00:43,  1.88s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:44<00:41,  1.88s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:47<00:44,  2.12s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:50<00:44,  2.24s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:52<00:41,  2.20s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:54<00:38,  2.12s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:56<00:35,  2.06s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:58<00:32,  2.02s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:59<00:28,  1.90s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:01<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:03<00:24,  1.91s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:05<00:22,  1.84s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:07<00:20,  1.88s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:09<00:20,  2.10s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:12<00:19,  2.22s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:14<00:17,  2.23s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:16<00:14,  2.04s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:17<00:11,  1.98s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:19<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:21<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:23<00:05,  1.83s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:25<00:04,  2.05s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:27<00:02,  2.12s/it]predicting train subjects: 100%|██████████| 285/285 [08:30<00:00,  2.29s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:03,  2.34s/it]Loading train:   1%|          | 2/285 [00:04<10:23,  2.20s/it]Loading train:   1%|          | 3/285 [00:06<10:28,  2.23s/it]Loading train:   1%|▏         | 4/285 [00:08<09:56,  2.12s/it]Loading train:   2%|▏         | 5/285 [00:10<09:45,  2.09s/it]Loading train:   2%|▏         | 6/285 [00:11<08:58,  1.93s/it]Loading train:   2%|▏         | 7/285 [00:13<09:02,  1.95s/it]Loading train:   3%|▎         | 8/285 [00:15<08:42,  1.89s/it]Loading train:   3%|▎         | 9/285 [00:17<08:56,  1.94s/it]Loading train:   4%|▎         | 10/285 [00:19<08:52,  1.94s/it]Loading train:   4%|▍         | 11/285 [00:21<08:52,  1.94s/it]Loading train:   4%|▍         | 12/285 [00:23<08:57,  1.97s/it]Loading train:   5%|▍         | 13/285 [00:25<08:07,  1.79s/it]Loading train:   5%|▍         | 14/285 [00:27<08:18,  1.84s/it]Loading train:   5%|▌         | 15/285 [00:29<08:49,  1.96s/it]Loading train:   6%|▌         | 16/285 [00:30<08:15,  1.84s/it]Loading train:   6%|▌         | 17/285 [00:32<07:52,  1.76s/it]Loading train:   6%|▋         | 18/285 [00:33<07:19,  1.65s/it]Loading train:   7%|▋         | 19/285 [00:35<06:57,  1.57s/it]Loading train:   7%|▋         | 20/285 [00:36<06:22,  1.44s/it]Loading train:   7%|▋         | 21/285 [00:37<06:16,  1.43s/it]Loading train:   8%|▊         | 22/285 [00:38<06:01,  1.37s/it]Loading train:   8%|▊         | 23/285 [00:40<05:43,  1.31s/it]Loading train:   8%|▊         | 24/285 [00:40<05:01,  1.15s/it]Loading train:   9%|▉         | 25/285 [00:42<05:55,  1.37s/it]Loading train:   9%|▉         | 26/285 [00:44<06:31,  1.51s/it]Loading train:   9%|▉         | 27/285 [00:46<06:56,  1.62s/it]Loading train:  10%|▉         | 28/285 [00:48<07:54,  1.85s/it]Loading train:  10%|█         | 29/285 [00:50<08:10,  1.92s/it]Loading train:  11%|█         | 30/285 [00:53<08:24,  1.98s/it]Loading train:  11%|█         | 31/285 [00:55<08:26,  1.99s/it]Loading train:  11%|█         | 32/285 [00:56<07:44,  1.84s/it]Loading train:  12%|█▏        | 33/285 [00:58<07:31,  1.79s/it]Loading train:  12%|█▏        | 34/285 [00:59<07:16,  1.74s/it]Loading train:  12%|█▏        | 35/285 [01:01<06:51,  1.64s/it]Loading train:  13%|█▎        | 36/285 [01:02<06:26,  1.55s/it]Loading train:  13%|█▎        | 37/285 [01:04<06:34,  1.59s/it]Loading train:  13%|█▎        | 38/285 [01:06<06:48,  1.66s/it]Loading train:  14%|█▎        | 39/285 [01:07<07:00,  1.71s/it]Loading train:  14%|█▍        | 40/285 [01:09<07:09,  1.75s/it]Loading train:  14%|█▍        | 41/285 [01:11<06:57,  1.71s/it]Loading train:  15%|█▍        | 42/285 [01:12<06:18,  1.56s/it]Loading train:  15%|█▌        | 43/285 [01:14<06:18,  1.56s/it]Loading train:  15%|█▌        | 44/285 [01:16<06:58,  1.74s/it]Loading train:  16%|█▌        | 45/285 [01:18<07:10,  1.79s/it]Loading train:  16%|█▌        | 46/285 [01:20<07:08,  1.79s/it]Loading train:  16%|█▋        | 47/285 [01:21<06:10,  1.56s/it]Loading train:  17%|█▋        | 48/285 [01:22<06:12,  1.57s/it]Loading train:  17%|█▋        | 49/285 [01:24<06:07,  1.56s/it]Loading train:  18%|█▊        | 50/285 [01:25<05:34,  1.42s/it]Loading train:  18%|█▊        | 51/285 [01:27<05:55,  1.52s/it]Loading train:  18%|█▊        | 52/285 [01:29<06:30,  1.68s/it]Loading train:  19%|█▊        | 53/285 [01:31<06:46,  1.75s/it]Loading train:  19%|█▉        | 54/285 [01:33<07:06,  1.84s/it]Loading train:  19%|█▉        | 55/285 [01:34<06:35,  1.72s/it]Loading train:  20%|█▉        | 56/285 [01:36<06:48,  1.78s/it]Loading train:  20%|██        | 57/285 [01:38<06:50,  1.80s/it]Loading train:  20%|██        | 58/285 [01:40<07:15,  1.92s/it]Loading train:  21%|██        | 59/285 [01:42<06:57,  1.85s/it]Loading train:  21%|██        | 60/285 [01:43<06:21,  1.70s/it]Loading train:  21%|██▏       | 61/285 [01:44<05:55,  1.59s/it]Loading train:  22%|██▏       | 62/285 [01:46<05:49,  1.57s/it]Loading train:  22%|██▏       | 63/285 [01:47<05:46,  1.56s/it]Loading train:  22%|██▏       | 64/285 [01:49<05:51,  1.59s/it]Loading train:  23%|██▎       | 65/285 [01:51<06:30,  1.78s/it]Loading train:  23%|██▎       | 66/285 [01:54<07:05,  1.94s/it]Loading train:  24%|██▎       | 67/285 [01:55<06:41,  1.84s/it]Loading train:  24%|██▍       | 68/285 [01:57<06:18,  1.74s/it]Loading train:  24%|██▍       | 69/285 [01:58<06:08,  1.71s/it]Loading train:  25%|██▍       | 70/285 [02:00<06:18,  1.76s/it]Loading train:  25%|██▍       | 71/285 [02:02<06:25,  1.80s/it]Loading train:  25%|██▌       | 72/285 [02:04<06:21,  1.79s/it]Loading train:  26%|██▌       | 73/285 [02:06<06:22,  1.81s/it]Loading train:  26%|██▌       | 74/285 [02:07<05:48,  1.65s/it]Loading train:  26%|██▋       | 75/285 [02:09<05:46,  1.65s/it]Loading train:  27%|██▋       | 76/285 [02:10<05:27,  1.57s/it]Loading train:  27%|██▋       | 77/285 [02:11<05:12,  1.50s/it]Loading train:  27%|██▋       | 78/285 [02:13<05:09,  1.49s/it]Loading train:  28%|██▊       | 79/285 [02:15<05:25,  1.58s/it]Loading train:  28%|██▊       | 80/285 [02:16<05:28,  1.60s/it]Loading train:  28%|██▊       | 81/285 [02:18<05:19,  1.57s/it]Loading train:  29%|██▉       | 82/285 [02:19<05:11,  1.53s/it]Loading train:  29%|██▉       | 83/285 [02:21<05:25,  1.61s/it]Loading train:  29%|██▉       | 84/285 [02:22<05:12,  1.55s/it]Loading train:  30%|██▉       | 85/285 [02:24<05:35,  1.68s/it]Loading train:  30%|███       | 86/285 [02:26<05:43,  1.73s/it]Loading train:  31%|███       | 87/285 [02:28<05:30,  1.67s/it]Loading train:  31%|███       | 88/285 [02:29<05:01,  1.53s/it]Loading train:  31%|███       | 89/285 [02:31<05:01,  1.54s/it]Loading train:  32%|███▏      | 90/285 [02:32<05:02,  1.55s/it]Loading train:  32%|███▏      | 91/285 [02:33<04:44,  1.47s/it]Loading train:  32%|███▏      | 92/285 [02:35<04:37,  1.44s/it]Loading train:  33%|███▎      | 93/285 [02:36<04:21,  1.36s/it]Loading train:  33%|███▎      | 94/285 [02:37<04:26,  1.39s/it]Loading train:  33%|███▎      | 95/285 [02:39<04:42,  1.48s/it]Loading train:  34%|███▎      | 96/285 [02:41<04:48,  1.53s/it]Loading train:  34%|███▍      | 97/285 [02:43<05:33,  1.78s/it]Loading train:  34%|███▍      | 98/285 [02:45<05:19,  1.71s/it]Loading train:  35%|███▍      | 99/285 [02:46<05:22,  1.73s/it]Loading train:  35%|███▌      | 100/285 [02:49<05:52,  1.91s/it]Loading train:  35%|███▌      | 101/285 [02:51<05:55,  1.93s/it]Loading train:  36%|███▌      | 102/285 [02:53<06:12,  2.03s/it]Loading train:  36%|███▌      | 103/285 [02:55<05:44,  1.89s/it]Loading train:  36%|███▋      | 104/285 [02:56<05:31,  1.83s/it]Loading train:  37%|███▋      | 105/285 [02:58<05:36,  1.87s/it]Loading train:  37%|███▋      | 106/285 [03:00<05:17,  1.77s/it]Loading train:  38%|███▊      | 107/285 [03:02<05:27,  1.84s/it]Loading train:  38%|███▊      | 108/285 [03:05<06:18,  2.14s/it]Loading train:  38%|███▊      | 109/285 [03:07<06:30,  2.22s/it]Loading train:  39%|███▊      | 110/285 [03:09<06:37,  2.27s/it]Loading train:  39%|███▉      | 111/285 [03:11<06:24,  2.21s/it]Loading train:  39%|███▉      | 112/285 [03:14<06:21,  2.20s/it]Loading train:  40%|███▉      | 113/285 [03:15<05:51,  2.04s/it]Loading train:  40%|████      | 114/285 [03:17<05:47,  2.03s/it]Loading train:  40%|████      | 115/285 [03:19<05:04,  1.79s/it]Loading train:  41%|████      | 116/285 [03:21<05:17,  1.88s/it]Loading train:  41%|████      | 117/285 [03:23<05:17,  1.89s/it]Loading train:  41%|████▏     | 118/285 [03:24<05:04,  1.83s/it]Loading train:  42%|████▏     | 119/285 [03:27<05:24,  1.95s/it]Loading train:  42%|████▏     | 120/285 [03:29<05:45,  2.09s/it]Loading train:  42%|████▏     | 121/285 [03:32<06:16,  2.29s/it]Loading train:  43%|████▎     | 122/285 [03:34<06:16,  2.31s/it]Loading train:  43%|████▎     | 123/285 [03:37<06:51,  2.54s/it]Loading train:  44%|████▎     | 124/285 [03:39<06:19,  2.35s/it]Loading train:  44%|████▍     | 125/285 [03:41<05:40,  2.13s/it]Loading train:  44%|████▍     | 126/285 [03:43<05:28,  2.07s/it]Loading train:  45%|████▍     | 127/285 [03:44<05:08,  1.96s/it]Loading train:  45%|████▍     | 128/285 [03:46<05:06,  1.95s/it]Loading train:  45%|████▌     | 129/285 [03:48<04:51,  1.87s/it]Loading train:  46%|████▌     | 130/285 [03:50<05:07,  1.98s/it]Loading train:  46%|████▌     | 131/285 [03:53<05:31,  2.15s/it]Loading train:  46%|████▋     | 132/285 [03:55<05:46,  2.27s/it]Loading train:  47%|████▋     | 133/285 [03:58<05:57,  2.35s/it]Loading train:  47%|████▋     | 134/285 [04:00<06:02,  2.40s/it]Loading train:  47%|████▋     | 135/285 [04:03<06:09,  2.46s/it]Loading train:  48%|████▊     | 136/285 [04:04<05:26,  2.19s/it]Loading train:  48%|████▊     | 137/285 [04:06<05:15,  2.13s/it]Loading train:  48%|████▊     | 138/285 [04:08<05:00,  2.04s/it]Loading train:  49%|████▉     | 139/285 [04:10<04:49,  1.98s/it]Loading train:  49%|████▉     | 140/285 [04:12<04:39,  1.93s/it]Loading train:  49%|████▉     | 141/285 [04:14<04:44,  1.97s/it]Loading train:  50%|████▉     | 142/285 [04:16<04:43,  1.98s/it]Loading train:  50%|█████     | 143/285 [04:19<05:19,  2.25s/it]Loading train:  51%|█████     | 144/285 [04:21<05:15,  2.23s/it]Loading train:  51%|█████     | 145/285 [04:23<05:15,  2.25s/it]Loading train:  51%|█████     | 146/285 [04:26<05:15,  2.27s/it]Loading train:  52%|█████▏    | 147/285 [04:27<04:47,  2.09s/it]Loading train:  52%|█████▏    | 148/285 [04:29<04:21,  1.91s/it]Loading train:  52%|█████▏    | 149/285 [04:30<03:49,  1.69s/it]Loading train:  53%|█████▎    | 150/285 [04:31<03:37,  1.61s/it]Loading train:  53%|█████▎    | 151/285 [04:33<03:23,  1.52s/it]Loading train:  53%|█████▎    | 152/285 [04:34<03:14,  1.47s/it]Loading train:  54%|█████▎    | 153/285 [04:36<03:19,  1.51s/it]Loading train:  54%|█████▍    | 154/285 [04:38<03:54,  1.79s/it]Loading train:  54%|█████▍    | 155/285 [04:40<04:07,  1.90s/it]Loading train:  55%|█████▍    | 156/285 [04:43<04:20,  2.02s/it]Loading train:  55%|█████▌    | 157/285 [04:44<04:09,  1.95s/it]Loading train:  55%|█████▌    | 158/285 [04:48<05:00,  2.36s/it]Loading train:  56%|█████▌    | 159/285 [04:50<04:42,  2.24s/it]Loading train:  56%|█████▌    | 160/285 [04:51<04:08,  1.99s/it]Loading train:  56%|█████▋    | 161/285 [04:53<04:09,  2.02s/it]Loading train:  57%|█████▋    | 162/285 [04:55<03:49,  1.86s/it]Loading train:  57%|█████▋    | 163/285 [04:57<04:01,  1.98s/it]Loading train:  58%|█████▊    | 164/285 [04:58<03:37,  1.80s/it]Loading train:  58%|█████▊    | 165/285 [05:00<03:47,  1.89s/it]Loading train:  58%|█████▊    | 166/285 [05:03<03:55,  1.98s/it]Loading train:  59%|█████▊    | 167/285 [05:05<04:20,  2.20s/it]Loading train:  59%|█████▉    | 168/285 [05:07<04:18,  2.21s/it]Loading train:  59%|█████▉    | 169/285 [05:10<04:40,  2.42s/it]Loading train:  60%|█████▉    | 170/285 [05:13<04:40,  2.44s/it]Loading train:  60%|██████    | 171/285 [05:14<04:08,  2.18s/it]Loading train:  60%|██████    | 172/285 [05:17<04:12,  2.24s/it]Loading train:  61%|██████    | 173/285 [05:19<03:52,  2.07s/it]Loading train:  61%|██████    | 174/285 [05:20<03:43,  2.01s/it]Loading train:  61%|██████▏   | 175/285 [05:22<03:36,  1.97s/it]Loading train:  62%|██████▏   | 176/285 [05:24<03:21,  1.85s/it]Loading train:  62%|██████▏   | 177/285 [05:25<03:08,  1.74s/it]Loading train:  62%|██████▏   | 178/285 [05:27<03:18,  1.86s/it]Loading train:  63%|██████▎   | 179/285 [05:30<03:24,  1.93s/it]Loading train:  63%|██████▎   | 180/285 [05:32<03:25,  1.96s/it]Loading train:  64%|██████▎   | 181/285 [05:34<03:41,  2.13s/it]Loading train:  64%|██████▍   | 182/285 [05:36<03:47,  2.21s/it]Loading train:  64%|██████▍   | 183/285 [05:38<03:36,  2.12s/it]Loading train:  65%|██████▍   | 184/285 [05:40<03:31,  2.09s/it]Loading train:  65%|██████▍   | 185/285 [05:42<03:22,  2.03s/it]Loading train:  65%|██████▌   | 186/285 [05:44<03:17,  1.99s/it]Loading train:  66%|██████▌   | 187/285 [05:46<03:05,  1.89s/it]Loading train:  66%|██████▌   | 188/285 [05:48<02:58,  1.84s/it]Loading train:  66%|██████▋   | 189/285 [05:50<03:03,  1.91s/it]Loading train:  67%|██████▋   | 190/285 [05:52<03:25,  2.16s/it]Loading train:  67%|██████▋   | 191/285 [05:55<03:33,  2.27s/it]Loading train:  67%|██████▋   | 192/285 [05:58<03:51,  2.49s/it]Loading train:  68%|██████▊   | 193/285 [06:00<03:48,  2.48s/it]Loading train:  68%|██████▊   | 194/285 [06:02<03:29,  2.30s/it]Loading train:  68%|██████▊   | 195/285 [06:04<03:05,  2.06s/it]Loading train:  69%|██████▉   | 196/285 [06:06<03:14,  2.19s/it]Loading train:  69%|██████▉   | 197/285 [06:08<02:58,  2.03s/it]Loading train:  69%|██████▉   | 198/285 [06:10<02:47,  1.93s/it]Loading train:  70%|██████▉   | 199/285 [06:11<02:31,  1.76s/it]Loading train:  70%|███████   | 200/285 [06:12<02:23,  1.69s/it]Loading train:  71%|███████   | 201/285 [06:15<02:34,  1.84s/it]Loading train:  71%|███████   | 202/285 [06:17<02:52,  2.08s/it]Loading train:  71%|███████   | 203/285 [06:20<03:02,  2.22s/it]Loading train:  72%|███████▏  | 204/285 [06:23<03:15,  2.42s/it]Loading train:  72%|███████▏  | 205/285 [06:25<03:13,  2.42s/it]Loading train:  72%|███████▏  | 206/285 [06:27<02:50,  2.16s/it]Loading train:  73%|███████▎  | 207/285 [06:29<02:48,  2.16s/it]Loading train:  73%|███████▎  | 208/285 [06:31<02:55,  2.29s/it]Loading train:  73%|███████▎  | 209/285 [06:34<02:51,  2.26s/it]Loading train:  74%|███████▎  | 210/285 [06:35<02:33,  2.05s/it]Loading train:  74%|███████▍  | 211/285 [06:37<02:27,  1.99s/it]Loading train:  74%|███████▍  | 212/285 [06:40<02:45,  2.26s/it]Loading train:  75%|███████▍  | 213/285 [06:42<02:43,  2.27s/it]Loading train:  75%|███████▌  | 214/285 [06:45<02:51,  2.42s/it]Loading train:  75%|███████▌  | 215/285 [06:48<03:03,  2.62s/it]Loading train:  76%|███████▌  | 216/285 [06:50<02:52,  2.49s/it]Loading train:  76%|███████▌  | 217/285 [06:53<02:53,  2.56s/it]Loading train:  76%|███████▋  | 218/285 [06:56<02:54,  2.61s/it]Loading train:  77%|███████▋  | 219/285 [06:58<02:43,  2.48s/it]Loading train:  77%|███████▋  | 220/285 [06:59<02:21,  2.17s/it]Loading train:  78%|███████▊  | 221/285 [07:01<02:09,  2.03s/it]Loading train:  78%|███████▊  | 222/285 [07:03<02:12,  2.10s/it]Loading train:  78%|███████▊  | 223/285 [07:05<02:09,  2.10s/it]Loading train:  79%|███████▊  | 224/285 [07:08<02:14,  2.21s/it]Loading train:  79%|███████▉  | 225/285 [07:10<02:17,  2.30s/it]Loading train:  79%|███████▉  | 226/285 [07:13<02:14,  2.29s/it]Loading train:  80%|███████▉  | 227/285 [07:15<02:15,  2.33s/it]Loading train:  80%|████████  | 228/285 [07:17<02:10,  2.28s/it]Loading train:  80%|████████  | 229/285 [07:19<01:57,  2.10s/it]Loading train:  81%|████████  | 230/285 [07:21<01:52,  2.05s/it]Loading train:  81%|████████  | 231/285 [07:23<01:46,  1.97s/it]Loading train:  81%|████████▏ | 232/285 [07:24<01:38,  1.85s/it]Loading train:  82%|████████▏ | 233/285 [07:27<01:47,  2.07s/it]Loading train:  82%|████████▏ | 234/285 [07:30<01:58,  2.32s/it]Loading train:  82%|████████▏ | 235/285 [07:32<01:57,  2.35s/it]Loading train:  83%|████████▎ | 236/285 [07:35<01:57,  2.40s/it]Loading train:  83%|████████▎ | 237/285 [07:37<01:50,  2.31s/it]Loading train:  84%|████████▎ | 238/285 [07:39<01:51,  2.37s/it]Loading train:  84%|████████▍ | 239/285 [07:41<01:40,  2.18s/it]Loading train:  84%|████████▍ | 240/285 [07:42<01:26,  1.91s/it]Loading train:  85%|████████▍ | 241/285 [07:45<01:31,  2.09s/it]Loading train:  85%|████████▍ | 242/285 [07:47<01:26,  2.02s/it]Loading train:  85%|████████▌ | 243/285 [07:50<01:37,  2.32s/it]Loading train:  86%|████████▌ | 244/285 [07:52<01:39,  2.42s/it]Loading train:  86%|████████▌ | 245/285 [07:54<01:33,  2.33s/it]Loading train:  86%|████████▋ | 246/285 [07:57<01:37,  2.51s/it]Loading train:  87%|████████▋ | 247/285 [08:00<01:39,  2.63s/it]Loading train:  87%|████████▋ | 248/285 [08:03<01:36,  2.60s/it]Loading train:  87%|████████▋ | 249/285 [08:05<01:26,  2.41s/it]Loading train:  88%|████████▊ | 250/285 [08:06<01:16,  2.20s/it]Loading train:  88%|████████▊ | 251/285 [08:08<01:10,  2.06s/it]Loading train:  88%|████████▊ | 252/285 [08:10<01:01,  1.87s/it]Loading train:  89%|████████▉ | 253/285 [08:12<01:03,  1.98s/it]Loading train:  89%|████████▉ | 254/285 [08:14<01:05,  2.11s/it]Loading train:  89%|████████▉ | 255/285 [08:17<01:05,  2.19s/it]Loading train:  90%|████████▉ | 256/285 [08:19<01:02,  2.14s/it]Loading train:  90%|█████████ | 257/285 [08:21<00:58,  2.09s/it]Loading train:  91%|█████████ | 258/285 [08:23<01:01,  2.26s/it]Loading train:  91%|█████████ | 259/285 [08:26<01:01,  2.37s/it]Loading train:  91%|█████████ | 260/285 [08:27<00:52,  2.10s/it]Loading train:  92%|█████████▏| 261/285 [08:29<00:47,  1.96s/it]Loading train:  92%|█████████▏| 262/285 [08:31<00:43,  1.88s/it]Loading train:  92%|█████████▏| 263/285 [08:33<00:41,  1.88s/it]Loading train:  93%|█████████▎| 264/285 [08:35<00:40,  1.93s/it]Loading train:  93%|█████████▎| 265/285 [08:37<00:39,  1.97s/it]Loading train:  93%|█████████▎| 266/285 [08:39<00:38,  2.05s/it]Loading train:  94%|█████████▎| 267/285 [08:41<00:36,  2.01s/it]Loading train:  94%|█████████▍| 268/285 [08:43<00:36,  2.13s/it]Loading train:  94%|█████████▍| 269/285 [08:46<00:35,  2.23s/it]Loading train:  95%|█████████▍| 270/285 [08:49<00:35,  2.38s/it]Loading train:  95%|█████████▌| 271/285 [08:51<00:33,  2.37s/it]Loading train:  95%|█████████▌| 272/285 [08:53<00:28,  2.23s/it]Loading train:  96%|█████████▌| 273/285 [08:54<00:24,  2.02s/it]Loading train:  96%|█████████▌| 274/285 [08:56<00:20,  1.84s/it]Loading train:  96%|█████████▋| 275/285 [08:58<00:18,  1.90s/it]Loading train:  97%|█████████▋| 276/285 [09:00<00:17,  1.94s/it]Loading train:  97%|█████████▋| 277/285 [09:02<00:15,  1.99s/it]Loading train:  98%|█████████▊| 278/285 [09:04<00:15,  2.15s/it]Loading train:  98%|█████████▊| 279/285 [09:07<00:14,  2.38s/it]Loading train:  98%|█████████▊| 280/285 [09:10<00:11,  2.34s/it]Loading train:  99%|█████████▊| 281/285 [09:12<00:09,  2.38s/it]Loading train:  99%|█████████▉| 282/285 [09:14<00:06,  2.23s/it]Loading train:  99%|█████████▉| 283/285 [09:16<00:04,  2.18s/it]Loading train: 100%|█████████▉| 284/285 [09:18<00:02,  2.26s/it]Loading train: 100%|██████████| 285/285 [09:20<00:00,  2.16s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:19, 14.43it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:15, 18.11it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:11, 24.18it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:08, 31.58it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:08, 29.29it/s]concatenating: train:  15%|█▌        | 44/285 [00:01<00:10, 23.06it/s]concatenating: train:  17%|█▋        | 49/285 [00:01<00:11, 20.87it/s]concatenating: train:  19%|█▊        | 53/285 [00:01<00:11, 20.54it/s]concatenating: train:  20%|██        | 57/285 [00:01<00:09, 23.88it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:08, 25.98it/s]concatenating: train:  23%|██▎       | 65/285 [00:02<00:08, 24.98it/s]concatenating: train:  24%|██▍       | 69/285 [00:02<00:07, 27.96it/s]concatenating: train:  26%|██▌       | 73/285 [00:02<00:09, 23.38it/s]concatenating: train:  27%|██▋       | 77/285 [00:02<00:08, 25.51it/s]concatenating: train:  28%|██▊       | 80/285 [00:02<00:08, 23.02it/s]concatenating: train:  29%|██▉       | 84/285 [00:02<00:07, 25.38it/s]concatenating: train:  31%|███       | 87/285 [00:02<00:07, 25.52it/s]concatenating: train:  32%|███▏      | 90/285 [00:02<00:07, 26.28it/s]concatenating: train:  33%|███▎      | 95/285 [00:03<00:06, 29.85it/s]concatenating: train:  35%|███▍      | 99/285 [00:03<00:07, 26.28it/s]concatenating: train:  36%|███▌      | 102/285 [00:03<00:08, 22.78it/s]concatenating: train:  38%|███▊      | 107/285 [00:03<00:06, 26.70it/s]concatenating: train:  39%|███▉      | 112/285 [00:03<00:05, 30.36it/s]concatenating: train:  41%|████▏     | 118/285 [00:03<00:04, 34.90it/s]concatenating: train:  44%|████▍     | 125/285 [00:03<00:03, 40.23it/s]concatenating: train:  46%|████▌     | 131/285 [00:04<00:03, 39.68it/s]concatenating: train:  48%|████▊     | 136/285 [00:04<00:05, 27.28it/s]concatenating: train:  50%|████▉     | 142/285 [00:04<00:04, 32.00it/s]concatenating: train:  53%|█████▎    | 150/285 [00:04<00:03, 38.61it/s]concatenating: train:  55%|█████▍    | 156/285 [00:05<00:05, 23.74it/s]concatenating: train:  56%|█████▌    | 160/285 [00:05<00:05, 23.26it/s]concatenating: train:  58%|█████▊    | 164/285 [00:05<00:06, 19.57it/s]concatenating: train:  59%|█████▊    | 167/285 [00:05<00:06, 19.32it/s]concatenating: train:  60%|██████    | 171/285 [00:05<00:05, 22.55it/s]concatenating: train:  62%|██████▏   | 177/285 [00:05<00:03, 27.00it/s]concatenating: train:  64%|██████▍   | 183/285 [00:06<00:03, 31.13it/s]concatenating: train:  66%|██████▌   | 188/285 [00:06<00:02, 33.80it/s]concatenating: train:  68%|██████▊   | 193/285 [00:06<00:03, 25.45it/s]concatenating: train:  69%|██████▉   | 197/285 [00:06<00:03, 23.86it/s]concatenating: train:  70%|███████   | 200/285 [00:06<00:03, 23.29it/s]concatenating: train:  71%|███████   | 203/285 [00:06<00:03, 23.56it/s]concatenating: train:  72%|███████▏  | 206/285 [00:07<00:03, 24.68it/s]concatenating: train:  73%|███████▎  | 209/285 [00:07<00:03, 20.18it/s]concatenating: train:  74%|███████▍  | 212/285 [00:07<00:03, 19.81it/s]concatenating: train:  75%|███████▌  | 215/285 [00:07<00:03, 20.25it/s]concatenating: train:  76%|███████▋  | 218/285 [00:07<00:03, 20.52it/s]concatenating: train:  78%|███████▊  | 221/285 [00:07<00:02, 21.88it/s]concatenating: train:  79%|███████▊  | 224/285 [00:07<00:02, 22.32it/s]concatenating: train:  80%|███████▉  | 227/285 [00:08<00:03, 16.53it/s]concatenating: train:  80%|████████  | 229/285 [00:08<00:03, 16.39it/s]concatenating: train:  81%|████████▏ | 232/285 [00:08<00:02, 18.55it/s]concatenating: train:  82%|████████▏ | 235/285 [00:08<00:02, 20.27it/s]concatenating: train:  84%|████████▍ | 240/285 [00:08<00:01, 24.24it/s]concatenating: train:  86%|████████▋ | 246/285 [00:08<00:01, 29.34it/s]concatenating: train:  89%|████████▉ | 253/285 [00:08<00:00, 35.51it/s]concatenating: train:  93%|█████████▎| 264/285 [00:09<00:00, 44.56it/s]concatenating: train:  95%|█████████▌| 271/285 [00:09<00:00, 23.29it/s]concatenating: train:  97%|█████████▋| 276/285 [00:10<00:00, 19.27it/s]concatenating: train:  98%|█████████▊| 280/285 [00:10<00:00, 17.72it/s]concatenating: train: 100%|█████████▉| 284/285 [00:10<00:00, 16.53it/s]concatenating: train: 100%|██████████| 285/285 [00:10<00:00, 26.84it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]Loading test:  67%|██████▋   | 2/3 [00:04<00:02,  2.30s/it]Loading test: 100%|██████████| 3/3 [00:06<00:00,  2.22s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 22.40it/s]2019-07-11 13:27:53.786721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 13:27:53.786860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 13:27:53.786892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 13:27:53.786907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 13:27:53.787437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:22,  1.92it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:01<00:18,  2.24it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:17,  2.27it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:02<00:12,  2.86it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:02<00:15,  2.26it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:03<00:14,  2.34it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:03<00:14,  2.22it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:04<00:09,  2.79it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:05<00:10,  2.44it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:05<00:08,  2.79it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:06<00:09,  2.35it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:06<00:06,  2.99it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:07<00:05,  3.28it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:07<00:05,  2.77it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:08<00:05,  2.68it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:09<00:05,  2.35it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:09<00:02,  3.00it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:09<00:01,  3.55it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:10<00:02,  2.79it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:10<00:01,  3.39it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:11<00:00,  3.01it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:11<00:00,  3.94it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2040        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   4080        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   8130        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   24360       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   32460       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   8130        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   2040        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 40)   16240       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 40)   14440       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 85)   0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_8[0][0]              
==================================================================================================
Total params: 163,958
Trainable params: 65,258
Non-trainable params: 98,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 23s - loss: 2.3107 - acc: 0.7960 - mDice: 0.1897 - val_loss: 1.3247 - val_acc: 0.9152 - val_mDice: 0.4734

Epoch 00001: val_mDice improved from -inf to 0.47337, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.5654 - acc: 0.8980 - mDice: 0.5529 - val_loss: 1.0465 - val_acc: 0.9331 - val_mDice: 0.5742

Epoch 00002: val_mDice improved from 0.47337 to 0.57425, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.4784 - acc: 0.9171 - mDice: 0.6046 - val_loss: 1.0725 - val_acc: 0.9408 - val_mDice: 0.5533

Epoch 00003: val_mDice did not improve from 0.57425
Epoch 4/300
 - 13s - loss: 0.4469 - acc: 0.9283 - mDice: 0.6241 - val_loss: 1.0867 - val_acc: 0.9401 - val_mDice: 0.5354

Epoch 00004: val_mDice did not improve from 0.57425
Epoch 5/300
 - 13s - loss: 0.4257 - acc: 0.9312 - mDice: 0.6378 - val_loss: 1.2735 - val_acc: 0.9286 - val_mDice: 0.4295

Epoch 00005: val_mDice did not improve from 0.57425
Epoch 6/300
 - 13s - loss: 0.4099 - acc: 0.9326 - mDice: 0.6482 - val_loss: 0.9755 - val_acc: 0.9461 - val_mDice: 0.5877

Epoch 00006: val_mDice improved from 0.57425 to 0.58774, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4003 - acc: 0.9338 - mDice: 0.6548 - val_loss: 0.9794 - val_acc: 0.9469 - val_mDice: 0.5897

Epoch 00007: val_mDice improved from 0.58774 to 0.58972, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.3903 - acc: 0.9348 - mDice: 0.6617 - val_loss: 0.9979 - val_acc: 0.9448 - val_mDice: 0.5537

Epoch 00008: val_mDice did not improve from 0.58972
Epoch 9/300
 - 13s - loss: 0.3845 - acc: 0.9354 - mDice: 0.6656 - val_loss: 0.9608 - val_acc: 0.9428 - val_mDice: 0.5868

Epoch 00009: val_mDice did not improve from 0.58972
Epoch 10/300
 - 13s - loss: 0.3754 - acc: 0.9364 - mDice: 0.6720 - val_loss: 0.9661 - val_acc: 0.9467 - val_mDice: 0.5736

Epoch 00010: val_mDice did not improve from 0.58972
Epoch 11/300
 - 13s - loss: 0.3701 - acc: 0.9369 - mDice: 0.6757 - val_loss: 0.8965 - val_acc: 0.9465 - val_mDice: 0.5870

Epoch 00011: val_mDice did not improve from 0.58972
Epoch 12/300
 - 13s - loss: 0.3653 - acc: 0.9374 - mDice: 0.6790 - val_loss: 0.9396 - val_acc: 0.9457 - val_mDice: 0.5743

Epoch 00012: val_mDice did not improve from 0.58972
Epoch 13/300
 - 13s - loss: 0.3622 - acc: 0.9377 - mDice: 0.6812 - val_loss: 0.9135 - val_acc: 0.9466 - val_mDice: 0.5860

Epoch 00013: val_mDice did not improve from 0.58972
Epoch 14/300
 - 13s - loss: 0.3548 - acc: 0.9385 - mDice: 0.6865 - val_loss: 0.9253 - val_acc: 0.9444 - val_mDice: 0.5837

Epoch 00014: val_mDice did not improve from 0.58972
Epoch 15/300
 - 13s - loss: 0.3524 - acc: 0.9387 - mDice: 0.6882 - val_loss: 0.9685 - val_acc: 0.9461 - val_mDice: 0.5699

Epoch 00015: val_mDice did not improve from 0.58972
Epoch 16/300
 - 13s - loss: 0.3512 - acc: 0.9387 - mDice: 0.6890 - val_loss: 0.9329 - val_acc: 0.9445 - val_mDice: 0.5659

Epoch 00016: val_mDice did not improve from 0.58972
Epoch 17/300
 - 13s - loss: 0.3463 - acc: 0.9394 - mDice: 0.6926 - val_loss: 0.8968 - val_acc: 0.9423 - val_mDice: 0.5833

Epoch 00017: val_mDice did not improve from 0.58972
Epoch 18/300
 - 13s - loss: 0.3432 - acc: 0.9397 - mDice: 0.6948 - val_loss: 0.9047 - val_acc: 0.9446 - val_mDice: 0.5839

Epoch 00018: val_mDice did not improve from 0.58972
Epoch 19/300
 - 13s - loss: 0.3402 - acc: 0.9399 - mDice: 0.6970 - val_loss: 0.9070 - val_acc: 0.9460 - val_mDice: 0.5707

Epoch 00019: val_mDice did not improve from 0.58972
Epoch 20/300
 - 13s - loss: 0.3375 - acc: 0.9403 - mDice: 0.6989 - val_loss: 0.8865 - val_acc: 0.9419 - val_mDice: 0.5843

Epoch 00020: val_mDice did not improve from 0.58972
Epoch 21/300
 - 13s - loss: 0.3344 - acc: 0.9404 - mDice: 0.7011 - val_loss: 0.9065 - val_acc: 0.9451 - val_mDice: 0.5673

Epoch 00021: val_mDice did not improve from 0.58972
Epoch 22/300
 - 13s - loss: 0.3320 - acc: 0.9409 - mDice: 0.7030 - val_loss: 0.9416 - val_acc: 0.9432 - val_mDice: 0.5440

Epoch 00022: val_mDice did not improve from 0.58972
Epoch 23/300
 - 13s - loss: 0.3305 - acc: 0.9409 - mDice: 0.7040 - val_loss: 0.9144 - val_acc: 0.9449 - val_mDice: 0.5777

Epoch 00023: val_mDice did not improve from 0.58972
Epoch 24/300
 - 13s - loss: 0.3256 - acc: 0.9415 - mDice: 0.7076 - val_loss: 0.9034 - val_acc: 0.9453 - val_mDice: 0.5708

Epoch 00024: val_mDice did not improve from 0.58972
Epoch 25/300
 - 13s - loss: 0.3237 - acc: 0.9417 - mDice: 0.7090 - val_loss: 0.8872 - val_acc: 0.9453 - val_mDice: 0.5700

Epoch 00025: val_mDice did not improve from 0.58972
Epoch 26/300
 - 13s - loss: 0.3243 - acc: 0.9417 - mDice: 0.7086 - val_loss: 0.9127 - val_acc: 0.9461 - val_mDice: 0.5743

Epoch 00026: val_mDice did not improve from 0.58972
Epoch 27/300
 - 13s - loss: 0.3225 - acc: 0.9416 - mDice: 0.7098 - val_loss: 0.8871 - val_acc: 0.9453 - val_mDice: 0.5739

Epoch 00027: val_mDice did not improve from 0.58972
Epoch 28/300
 - 13s - loss: 0.3206 - acc: 0.9418 - mDice: 0.7112 - val_loss: 0.8205 - val_acc: 0.9455 - val_mDice: 0.5826

Epoch 00028: val_mDice did not improve from 0.58972
Epoch 29/300
 - 13s - loss: 0.3181 - acc: 0.9420 - mDice: 0.7132 - val_loss: 0.8429 - val_acc: 0.9467 - val_mDice: 0.5851

Epoch 00029: val_mDice did not improve from 0.58972
Epoch 30/300
 - 13s - loss: 0.3165 - acc: 0.9421 - mDice: 0.7143 - val_loss: 0.8927 - val_acc: 0.9455 - val_mDice: 0.5677

Epoch 00030: val_mDice did not improve from 0.58972
Epoch 31/300
 - 13s - loss: 0.3153 - acc: 0.9424 - mDice: 0.7152 - val_loss: 0.8449 - val_acc: 0.9445 - val_mDice: 0.5829

Epoch 00031: val_mDice did not improve from 0.58972
Epoch 32/300
 - 13s - loss: 0.3141 - acc: 0.9425 - mDice: 0.7161 - val_loss: 0.8645 - val_acc: 0.9431 - val_mDice: 0.5723

Epoch 00032: val_mDice did not improve from 0.58972
Epoch 33/300
 - 12s - loss: 0.3118 - acc: 0.9426 - mDice: 0.7178 - val_loss: 0.8378 - val_acc: 0.9430 - val_mDice: 0.5704

Epoch 00033: val_mDice did not improve from 0.58972
Epoch 34/300
 - 13s - loss: 0.3101 - acc: 0.9428 - mDice: 0.7191 - val_loss: 0.8677 - val_acc: 0.9440 - val_mDice: 0.5615

Epoch 00034: val_mDice did not improve from 0.58972
Epoch 35/300
 - 13s - loss: 0.3108 - acc: 0.9429 - mDice: 0.7186 - val_loss: 0.8405 - val_acc: 0.9429 - val_mDice: 0.5863

Epoch 00035: val_mDice did not improve from 0.58972
Epoch 36/300
 - 13s - loss: 0.3087 - acc: 0.9430 - mDice: 0.7202 - val_loss: 0.8594 - val_acc: 0.9462 - val_mDice: 0.5601

Epoch 00036: val_mDice did not improve from 0.58972
Epoch 37/300
 - 13s - loss: 0.3057 - acc: 0.9433 - mDice: 0.7223 - val_loss: 0.8499 - val_acc: 0.9456 - val_mDice: 0.5761

Epoch 00037: val_mDice did not improve from 0.58972
Epoch 38/300
 - 13s - loss: 0.3052 - acc: 0.9434 - mDice: 0.7228 - val_loss: 0.8454 - val_acc: 0.9445 - val_mDice: 0.5713

Epoch 00038: val_mDice did not improve from 0.58972
Epoch 39/300
 - 13s - loss: 0.3043 - acc: 0.9434 - mDice: 0.7235 - val_loss: 0.8496 - val_acc: 0.9440 - val_mDice: 0.5636

Epoch 00039: val_mDice did not improve from 0.58972
Epoch 40/300
 - 12s - loss: 0.3019 - acc: 0.9435 - mDice: 0.7253 - val_loss: 0.9354 - val_acc: 0.9435 - val_mDice: 0.5356

Epoch 00040: val_mDice did not improve from 0.58972
Epoch 41/300
 - 13s - loss: 0.3007 - acc: 0.9438 - mDice: 0.7261 - val_loss: 0.8019 - val_acc: 0.9449 - val_mDice: 0.5766

Epoch 00041: val_mDice did not improve from 0.58972
Epoch 42/300
 - 13s - loss: 0.3012 - acc: 0.9436 - mDice: 0.7257 - val_loss: 0.8122 - val_acc: 0.9447 - val_mDice: 0.5691

Epoch 00042: val_mDice did not improve from 0.58972
Epoch 43/300
 - 13s - loss: 0.2990 - acc: 0.9439 - mDice: 0.7274 - val_loss: 0.8151 - val_acc: 0.9423 - val_mDice: 0.5704

Epoch 00043: val_mDice did not improve from 0.58972
Epoch 44/300
 - 13s - loss: 0.2982 - acc: 0.9440 - mDice: 0.7281 - val_loss: 0.8478 - val_acc: 0.9445 - val_mDice: 0.5651

Epoch 00044: val_mDice did not improve from 0.58972
Epoch 45/300
 - 13s - loss: 0.2976 - acc: 0.9440 - mDice: 0.7285 - val_loss: 0.8568 - val_acc: 0.9443 - val_mDice: 0.5701

Epoch 00045: val_mDice did not improve from 0.58972
Epoch 46/300
 - 13s - loss: 0.2974 - acc: 0.9441 - mDice: 0.7287 - val_loss: 0.8101 - val_acc: 0.9446 - val_mDice: 0.5643

Epoch 00046: val_mDice did not improve from 0.58972
Epoch 47/300
 - 13s - loss: 0.2967 - acc: 0.9441 - mDice: 0.7292 - val_loss: 0.8468 - val_acc: 0.9419 - val_mDice: 0.5618

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.44s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:05<00:03,  3.04s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.64s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:20,  1.98s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:32,  1.81s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:29,  1.81s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:05,  1.73s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:59,  1.93s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<09:07,  1.96s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:34,  2.28s/it]predicting train subjects:   3%|▎         | 8/285 [00:16<10:42,  2.32s/it]predicting train subjects:   3%|▎         | 9/285 [00:19<10:57,  2.38s/it]predicting train subjects:   4%|▎         | 10/285 [00:21<10:42,  2.34s/it]predicting train subjects:   4%|▍         | 11/285 [00:23<09:50,  2.15s/it]predicting train subjects:   4%|▍         | 12/285 [00:25<10:03,  2.21s/it]predicting train subjects:   5%|▍         | 13/285 [00:27<09:48,  2.16s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<10:11,  2.26s/it]predicting train subjects:   5%|▌         | 15/285 [00:32<10:52,  2.42s/it]predicting train subjects:   6%|▌         | 16/285 [00:35<11:03,  2.47s/it]predicting train subjects:   6%|▌         | 17/285 [00:37<10:32,  2.36s/it]predicting train subjects:   6%|▋         | 18/285 [00:39<10:09,  2.28s/it]predicting train subjects:   7%|▋         | 19/285 [00:41<09:22,  2.12s/it]predicting train subjects:   7%|▋         | 20/285 [00:43<09:21,  2.12s/it]predicting train subjects:   7%|▋         | 21/285 [00:46<09:56,  2.26s/it]predicting train subjects:   8%|▊         | 22/285 [00:48<09:43,  2.22s/it]predicting train subjects:   8%|▊         | 23/285 [00:50<10:01,  2.29s/it]predicting train subjects:   8%|▊         | 24/285 [00:52<09:44,  2.24s/it]predicting train subjects:   9%|▉         | 25/285 [00:55<10:04,  2.32s/it]predicting train subjects:   9%|▉         | 26/285 [00:57<09:46,  2.27s/it]predicting train subjects:   9%|▉         | 27/285 [00:59<09:03,  2.11s/it]predicting train subjects:  10%|▉         | 28/285 [01:01<09:05,  2.12s/it]predicting train subjects:  10%|█         | 29/285 [01:03<09:01,  2.12s/it]predicting train subjects:  11%|█         | 30/285 [01:05<09:19,  2.20s/it]predicting train subjects:  11%|█         | 31/285 [01:08<09:37,  2.27s/it]predicting train subjects:  11%|█         | 32/285 [01:10<09:26,  2.24s/it]predicting train subjects:  12%|█▏        | 33/285 [01:12<09:31,  2.27s/it]predicting train subjects:  12%|█▏        | 34/285 [01:14<09:29,  2.27s/it]predicting train subjects:  12%|█▏        | 35/285 [01:17<09:21,  2.24s/it]predicting train subjects:  13%|█▎        | 36/285 [01:18<08:40,  2.09s/it]predicting train subjects:  13%|█▎        | 37/285 [01:20<08:33,  2.07s/it]predicting train subjects:  13%|█▎        | 38/285 [01:23<08:51,  2.15s/it]predicting train subjects:  14%|█▎        | 39/285 [01:25<09:05,  2.22s/it]predicting train subjects:  14%|█▍        | 40/285 [01:28<09:23,  2.30s/it]predicting train subjects:  14%|█▍        | 41/285 [01:30<09:11,  2.26s/it]predicting train subjects:  15%|█▍        | 42/285 [01:32<09:00,  2.22s/it]predicting train subjects:  15%|█▌        | 43/285 [01:34<08:53,  2.21s/it]predicting train subjects:  15%|█▌        | 44/285 [01:36<08:59,  2.24s/it]predicting train subjects:  16%|█▌        | 45/285 [01:38<08:25,  2.11s/it]predicting train subjects:  16%|█▌        | 46/285 [01:41<08:39,  2.17s/it]predicting train subjects:  16%|█▋        | 47/285 [01:43<08:28,  2.13s/it]predicting train subjects:  17%|█▋        | 48/285 [01:45<08:58,  2.27s/it]predicting train subjects:  17%|█▋        | 49/285 [01:48<09:18,  2.37s/it]predicting train subjects:  18%|█▊        | 50/285 [01:50<09:27,  2.42s/it]predicting train subjects:  18%|█▊        | 51/285 [01:53<09:13,  2.37s/it]predicting train subjects:  18%|█▊        | 52/285 [01:54<08:36,  2.22s/it]predicting train subjects:  19%|█▊        | 53/285 [01:56<08:24,  2.18s/it]predicting train subjects:  19%|█▉        | 54/285 [01:59<08:24,  2.18s/it]predicting train subjects:  19%|█▉        | 55/285 [02:01<08:12,  2.14s/it]predicting train subjects:  20%|█▉        | 56/285 [02:03<08:26,  2.21s/it]predicting train subjects:  20%|██        | 57/285 [02:05<08:26,  2.22s/it]predicting train subjects:  20%|██        | 58/285 [02:08<08:53,  2.35s/it]predicting train subjects:  21%|██        | 59/285 [02:10<08:49,  2.34s/it]predicting train subjects:  21%|██        | 60/285 [02:13<08:49,  2.35s/it]predicting train subjects:  21%|██▏       | 61/285 [02:15<08:13,  2.20s/it]predicting train subjects:  22%|██▏       | 62/285 [02:17<08:20,  2.24s/it]predicting train subjects:  22%|██▏       | 63/285 [02:19<08:24,  2.27s/it]predicting train subjects:  22%|██▏       | 64/285 [02:22<08:26,  2.29s/it]predicting train subjects:  23%|██▎       | 65/285 [02:24<08:43,  2.38s/it]predicting train subjects:  23%|██▎       | 66/285 [02:26<08:39,  2.37s/it]predicting train subjects:  24%|██▎       | 67/285 [02:29<08:23,  2.31s/it]predicting train subjects:  24%|██▍       | 68/285 [02:30<07:51,  2.17s/it]predicting train subjects:  24%|██▍       | 69/285 [02:33<07:45,  2.15s/it]predicting train subjects:  25%|██▍       | 70/285 [02:35<07:44,  2.16s/it]predicting train subjects:  25%|██▍       | 71/285 [02:37<08:04,  2.26s/it]predicting train subjects:  25%|██▌       | 72/285 [02:40<08:07,  2.29s/it]predicting train subjects:  26%|██▌       | 73/285 [02:42<08:12,  2.32s/it]predicting train subjects:  26%|██▌       | 74/285 [02:45<08:24,  2.39s/it]predicting train subjects:  26%|██▋       | 75/285 [02:47<08:17,  2.37s/it]predicting train subjects:  27%|██▋       | 76/285 [02:49<07:55,  2.27s/it]predicting train subjects:  27%|██▋       | 77/285 [02:51<07:30,  2.17s/it]predicting train subjects:  27%|██▋       | 78/285 [02:53<07:02,  2.04s/it]predicting train subjects:  28%|██▊       | 79/285 [02:55<07:09,  2.08s/it]predicting train subjects:  28%|██▊       | 80/285 [02:57<07:12,  2.11s/it]predicting train subjects:  28%|██▊       | 81/285 [02:59<07:10,  2.11s/it]predicting train subjects:  29%|██▉       | 82/285 [03:01<07:17,  2.16s/it]predicting train subjects:  29%|██▉       | 83/285 [03:03<07:12,  2.14s/it]predicting train subjects:  29%|██▉       | 84/285 [03:05<06:49,  2.04s/it]predicting train subjects:  30%|██▉       | 85/285 [03:07<06:46,  2.03s/it]predicting train subjects:  30%|███       | 86/285 [03:09<06:50,  2.06s/it]predicting train subjects:  31%|███       | 87/285 [03:12<06:55,  2.10s/it]predicting train subjects:  31%|███       | 88/285 [03:14<06:51,  2.09s/it]predicting train subjects:  31%|███       | 89/285 [03:16<07:02,  2.16s/it]predicting train subjects:  32%|███▏      | 90/285 [03:18<07:16,  2.24s/it]predicting train subjects:  32%|███▏      | 91/285 [03:20<07:00,  2.17s/it]predicting train subjects:  32%|███▏      | 92/285 [03:23<07:05,  2.20s/it]predicting train subjects:  33%|███▎      | 93/285 [03:25<06:46,  2.12s/it]predicting train subjects:  33%|███▎      | 94/285 [03:27<06:42,  2.11s/it]predicting train subjects:  33%|███▎      | 95/285 [03:29<06:47,  2.14s/it]predicting train subjects:  34%|███▎      | 96/285 [03:31<06:48,  2.16s/it]predicting train subjects:  34%|███▍      | 97/285 [03:34<07:03,  2.25s/it]predicting train subjects:  34%|███▍      | 98/285 [03:36<07:07,  2.29s/it]predicting train subjects:  35%|███▍      | 99/285 [03:38<06:56,  2.24s/it]predicting train subjects:  35%|███▌      | 100/285 [03:41<07:05,  2.30s/it]predicting train subjects:  35%|███▌      | 101/285 [03:42<06:33,  2.14s/it]predicting train subjects:  36%|███▌      | 102/285 [03:44<06:28,  2.12s/it]predicting train subjects:  36%|███▌      | 103/285 [03:46<06:10,  2.03s/it]predicting train subjects:  36%|███▋      | 104/285 [03:48<06:05,  2.02s/it]predicting train subjects:  37%|███▋      | 105/285 [03:50<06:17,  2.10s/it]predicting train subjects:  37%|███▋      | 106/285 [03:53<06:15,  2.10s/it]predicting train subjects:  38%|███▊      | 107/285 [03:55<06:29,  2.19s/it]predicting train subjects:  38%|███▊      | 108/285 [03:57<06:31,  2.21s/it]predicting train subjects:  38%|███▊      | 109/285 [03:59<06:23,  2.18s/it]predicting train subjects:  39%|███▊      | 110/285 [04:01<06:20,  2.17s/it]predicting train subjects:  39%|███▉      | 111/285 [04:03<06:00,  2.07s/it]predicting train subjects:  39%|███▉      | 112/285 [04:05<05:56,  2.06s/it]predicting train subjects:  40%|███▉      | 113/285 [04:08<06:00,  2.09s/it]predicting train subjects:  40%|████      | 114/285 [04:10<06:08,  2.15s/it]predicting train subjects:  40%|████      | 115/285 [04:12<06:20,  2.24s/it]predicting train subjects:  41%|████      | 116/285 [04:15<06:22,  2.27s/it]predicting train subjects:  41%|████      | 117/285 [04:17<06:13,  2.22s/it]predicting train subjects:  41%|████▏     | 118/285 [04:19<05:49,  2.09s/it]predicting train subjects:  42%|████▏     | 119/285 [04:21<05:55,  2.14s/it]predicting train subjects:  42%|████▏     | 120/285 [04:23<05:37,  2.04s/it]predicting train subjects:  42%|████▏     | 121/285 [04:24<05:21,  1.96s/it]predicting train subjects:  43%|████▎     | 122/285 [04:26<05:11,  1.91s/it]predicting train subjects:  43%|████▎     | 123/285 [04:28<05:17,  1.96s/it]predicting train subjects:  44%|████▎     | 124/285 [04:30<05:16,  1.97s/it]predicting train subjects:  44%|████▍     | 125/285 [04:32<05:10,  1.94s/it]predicting train subjects:  44%|████▍     | 126/285 [04:34<04:52,  1.84s/it]predicting train subjects:  45%|████▍     | 127/285 [04:35<04:45,  1.81s/it]predicting train subjects:  45%|████▍     | 128/285 [04:37<04:42,  1.80s/it]predicting train subjects:  45%|████▌     | 129/285 [04:39<04:33,  1.75s/it]predicting train subjects:  46%|████▌     | 130/285 [04:41<04:32,  1.76s/it]predicting train subjects:  46%|████▌     | 131/285 [04:42<04:25,  1.73s/it]predicting train subjects:  46%|████▋     | 132/285 [04:44<04:34,  1.79s/it]predicting train subjects:  47%|████▋     | 133/285 [04:46<04:37,  1.82s/it]predicting train subjects:  47%|████▋     | 134/285 [04:48<04:35,  1.83s/it]predicting train subjects:  47%|████▋     | 135/285 [04:50<04:34,  1.83s/it]predicting train subjects:  48%|████▊     | 136/285 [04:52<04:30,  1.82s/it]predicting train subjects:  48%|████▊     | 137/285 [04:54<04:46,  1.93s/it]predicting train subjects:  48%|████▊     | 138/285 [04:55<04:33,  1.86s/it]predicting train subjects:  49%|████▉     | 139/285 [04:57<04:30,  1.86s/it]predicting train subjects:  49%|████▉     | 140/285 [04:59<04:32,  1.88s/it]predicting train subjects:  49%|████▉     | 141/285 [05:01<04:17,  1.79s/it]predicting train subjects:  50%|████▉     | 142/285 [05:03<04:14,  1.78s/it]predicting train subjects:  50%|█████     | 143/285 [05:04<04:12,  1.78s/it]predicting train subjects:  51%|█████     | 144/285 [05:06<04:21,  1.85s/it]predicting train subjects:  51%|█████     | 145/285 [05:08<04:18,  1.85s/it]predicting train subjects:  51%|█████     | 146/285 [05:10<04:24,  1.90s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:12<04:14,  1.85s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:14<04:11,  1.84s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:15<03:59,  1.76s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:17<03:50,  1.70s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:19<03:55,  1.76s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:21<03:52,  1.75s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:22<03:57,  1.80s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:25<04:10,  1.91s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:27<04:08,  1.91s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:29<04:12,  1.96s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:30<04:00,  1.88s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:32<03:47,  1.79s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:33<03:37,  1.72s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:35<03:30,  1.69s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:37<03:30,  1.70s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:39<03:30,  1.71s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:41<03:40,  1.80s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:42<03:40,  1.82s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:44<03:39,  1.83s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:46<03:42,  1.87s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:48<03:42,  1.89s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:50<03:31,  1.81s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:51<03:22,  1.75s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:53<03:14,  1.69s/it]predicting train subjects:  60%|██████    | 171/285 [05:55<03:10,  1.67s/it]predicting train subjects:  60%|██████    | 172/285 [05:56<03:11,  1.69s/it]predicting train subjects:  61%|██████    | 173/285 [05:58<03:14,  1.74s/it]predicting train subjects:  61%|██████    | 174/285 [06:00<03:17,  1.78s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:02<03:28,  1.89s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:04<03:29,  1.92s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:06<03:21,  1.86s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:07<03:08,  1.77s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:09<03:01,  1.71s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:11<03:16,  1.87s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:13<03:14,  1.87s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:15<03:18,  1.93s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:17<03:14,  1.91s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:19<03:12,  1.90s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:21<03:03,  1.84s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:23<03:13,  1.95s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:25<03:12,  1.96s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:27<03:11,  1.98s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:28<02:54,  1.82s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:30<02:49,  1.79s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:32<02:54,  1.86s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:34<03:01,  1.95s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:36<02:55,  1.90s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:38<02:54,  1.92s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:40<02:48,  1.87s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:42<02:57,  1.99s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:44<02:58,  2.03s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:46<02:59,  2.06s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:48<02:43,  1.90s/it]predicting train subjects:  70%|███████   | 200/285 [06:50<02:38,  1.86s/it]predicting train subjects:  71%|███████   | 201/285 [06:52<02:50,  2.03s/it]predicting train subjects:  71%|███████   | 202/285 [06:54<02:53,  2.09s/it]predicting train subjects:  71%|███████   | 203/285 [06:56<02:51,  2.09s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:58<02:39,  1.96s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:00<02:33,  1.92s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:01<02:23,  1.82s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:03<02:30,  1.92s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:06<02:31,  1.96s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:08<02:33,  2.02s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:09<02:26,  1.95s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:11<02:22,  1.92s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:13<02:22,  1.95s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:15<02:21,  1.97s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:17<02:14,  1.90s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:19<02:18,  1.98s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:21<02:07,  1.84s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:23<02:10,  1.91s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:25<02:10,  1.95s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:27<02:13,  2.02s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:29<02:08,  1.98s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:31<02:04,  1.95s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:33<02:06,  2.01s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:35<01:57,  1.90s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:36<01:53,  1.86s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:38<01:46,  1.78s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:40<01:48,  1.84s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:42<01:49,  1.89s/it]predicting train subjects:  80%|████████  | 228/285 [07:44<01:55,  2.03s/it]predicting train subjects:  80%|████████  | 229/285 [07:47<01:57,  2.09s/it]predicting train subjects:  81%|████████  | 230/285 [07:48<01:49,  1.99s/it]predicting train subjects:  81%|████████  | 231/285 [07:50<01:44,  1.93s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:53<01:50,  2.09s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:54<01:43,  1.99s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:56<01:42,  2.02s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:58<01:35,  1.91s/it]predicting train subjects:  83%|████████▎ | 236/285 [08:00<01:36,  1.96s/it]predicting train subjects:  83%|████████▎ | 237/285 [08:03<01:40,  2.09s/it]predicting train subjects:  84%|████████▎ | 238/285 [08:05<01:40,  2.14s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:07<01:39,  2.15s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:09<01:31,  2.03s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:11<01:28,  2.01s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:12<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:14<01:16,  1.81s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:16<01:18,  1.92s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:18<01:11,  1.78s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:20<01:15,  1.92s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:22<01:17,  2.03s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:24<01:15,  2.05s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:26<01:12,  2.01s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:28<01:10,  2.03s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:30<01:05,  1.91s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:31<00:59,  1.79s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:33<01:00,  1.89s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:36<01:00,  1.95s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:37<00:57,  1.93s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:39<00:55,  1.92s/it]predicting train subjects:  90%|█████████ | 257/285 [08:41<00:55,  1.96s/it]predicting train subjects:  91%|█████████ | 258/285 [08:44<00:56,  2.11s/it]predicting train subjects:  91%|█████████ | 259/285 [08:46<00:54,  2.09s/it]predicting train subjects:  91%|█████████ | 260/285 [08:48<00:49,  2.00s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:49<00:46,  1.93s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:51<00:41,  1.81s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:53<00:38,  1.76s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:55<00:38,  1.83s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:57<00:38,  1.94s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:59<00:35,  1.87s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:01<00:34,  1.94s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:03<00:35,  2.06s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:05<00:34,  2.14s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:07<00:30,  2.00s/it]predicting train subjects:  95%|█████████▌| 271/285 [09:09<00:26,  1.91s/it]predicting train subjects:  95%|█████████▌| 272/285 [09:11<00:24,  1.90s/it]predicting train subjects:  96%|█████████▌| 273/285 [09:12<00:21,  1.78s/it]predicting train subjects:  96%|█████████▌| 274/285 [09:14<00:18,  1.71s/it]predicting train subjects:  96%|█████████▋| 275/285 [09:16<00:19,  1.91s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:19<00:18,  2.10s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:20<00:16,  2.06s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:22<00:14,  2.03s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:25<00:12,  2.04s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:26<00:09,  1.96s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:28<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:29<00:05,  1.75s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:32<00:03,  1.86s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:34<00:01,  1.98s/it]predicting train subjects: 100%|██████████| 285/285 [09:36<00:00,  2.17s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:31,  2.44s/it]Loading train:   1%|          | 2/285 [00:04<10:28,  2.22s/it]Loading train:   1%|          | 3/285 [00:06<10:09,  2.16s/it]Loading train:   1%|▏         | 4/285 [00:07<09:05,  1.94s/it]Loading train:   2%|▏         | 5/285 [00:09<09:01,  1.93s/it]Loading train:   2%|▏         | 6/285 [00:10<08:20,  1.79s/it]Loading train:   2%|▏         | 7/285 [00:13<08:49,  1.90s/it]Loading train:   3%|▎         | 8/285 [00:15<09:02,  1.96s/it]Loading train:   3%|▎         | 9/285 [00:17<09:50,  2.14s/it]Loading train:   4%|▎         | 10/285 [00:19<09:50,  2.15s/it]Loading train:   4%|▍         | 11/285 [00:21<09:30,  2.08s/it]Loading train:   4%|▍         | 12/285 [00:23<08:39,  1.90s/it]Loading train:   5%|▍         | 13/285 [00:24<07:47,  1.72s/it]Loading train:   5%|▍         | 14/285 [00:26<08:02,  1.78s/it]Loading train:   5%|▌         | 15/285 [00:28<07:50,  1.74s/it]Loading train:   6%|▌         | 16/285 [00:29<07:29,  1.67s/it]Loading train:   6%|▌         | 17/285 [00:31<07:03,  1.58s/it]Loading train:   6%|▋         | 18/285 [00:32<06:34,  1.48s/it]Loading train:   7%|▋         | 19/285 [00:33<06:03,  1.37s/it]Loading train:   7%|▋         | 20/285 [00:35<06:16,  1.42s/it]Loading train:   7%|▋         | 21/285 [00:36<06:52,  1.56s/it]Loading train:   8%|▊         | 22/285 [00:38<06:38,  1.51s/it]Loading train:   8%|▊         | 23/285 [00:40<06:59,  1.60s/it]Loading train:   8%|▊         | 24/285 [00:41<06:45,  1.55s/it]Loading train:   9%|▉         | 25/285 [00:43<06:51,  1.58s/it]Loading train:   9%|▉         | 26/285 [00:44<06:33,  1.52s/it]Loading train:   9%|▉         | 27/285 [00:45<05:58,  1.39s/it]Loading train:  10%|▉         | 28/285 [00:47<06:13,  1.46s/it]Loading train:  10%|█         | 29/285 [00:48<06:29,  1.52s/it]Loading train:  11%|█         | 30/285 [00:50<06:52,  1.62s/it]Loading train:  11%|█         | 31/285 [00:52<07:04,  1.67s/it]Loading train:  11%|█         | 32/285 [00:54<06:50,  1.62s/it]Loading train:  12%|█▏        | 33/285 [00:55<06:38,  1.58s/it]Loading train:  12%|█▏        | 34/285 [00:57<06:31,  1.56s/it]Loading train:  12%|█▏        | 35/285 [00:58<06:31,  1.57s/it]Loading train:  13%|█▎        | 36/285 [01:00<06:34,  1.59s/it]Loading train:  13%|█▎        | 37/285 [01:01<06:26,  1.56s/it]Loading train:  13%|█▎        | 38/285 [01:03<06:22,  1.55s/it]Loading train:  14%|█▎        | 39/285 [01:05<06:33,  1.60s/it]Loading train:  14%|█▍        | 40/285 [01:06<06:28,  1.59s/it]Loading train:  14%|█▍        | 41/285 [01:08<06:29,  1.60s/it]Loading train:  15%|█▍        | 42/285 [01:09<06:13,  1.54s/it]Loading train:  15%|█▌        | 43/285 [01:11<06:19,  1.57s/it]Loading train:  15%|█▌        | 44/285 [01:13<06:44,  1.68s/it]Loading train:  16%|█▌        | 45/285 [01:14<06:21,  1.59s/it]Loading train:  16%|█▌        | 46/285 [01:16<06:10,  1.55s/it]Loading train:  16%|█▋        | 47/285 [01:17<05:42,  1.44s/it]Loading train:  17%|█▋        | 48/285 [01:18<05:37,  1.43s/it]Loading train:  17%|█▋        | 49/285 [01:20<05:58,  1.52s/it]Loading train:  18%|█▊        | 50/285 [01:21<05:42,  1.46s/it]Loading train:  18%|█▊        | 51/285 [01:22<05:27,  1.40s/it]Loading train:  18%|█▊        | 52/285 [01:24<05:23,  1.39s/it]Loading train:  19%|█▊        | 53/285 [01:25<05:22,  1.39s/it]Loading train:  19%|█▉        | 54/285 [01:27<05:19,  1.38s/it]Loading train:  19%|█▉        | 55/285 [01:28<05:08,  1.34s/it]Loading train:  20%|█▉        | 56/285 [01:29<05:19,  1.39s/it]Loading train:  20%|██        | 57/285 [01:30<04:47,  1.26s/it]Loading train:  20%|██        | 58/285 [01:31<04:32,  1.20s/it]Loading train:  21%|██        | 59/285 [01:33<04:47,  1.27s/it]Loading train:  21%|██        | 60/285 [01:34<05:03,  1.35s/it]Loading train:  21%|██▏       | 61/285 [01:36<05:19,  1.43s/it]Loading train:  22%|██▏       | 62/285 [01:38<05:32,  1.49s/it]Loading train:  22%|██▏       | 63/285 [01:39<05:24,  1.46s/it]Loading train:  22%|██▏       | 64/285 [01:41<05:33,  1.51s/it]Loading train:  23%|██▎       | 65/285 [01:43<06:33,  1.79s/it]Loading train:  23%|██▎       | 66/285 [01:46<07:42,  2.11s/it]Loading train:  24%|██▎       | 67/285 [01:48<07:24,  2.04s/it]Loading train:  24%|██▍       | 68/285 [01:50<07:11,  1.99s/it]Loading train:  24%|██▍       | 69/285 [01:52<07:23,  2.05s/it]Loading train:  25%|██▍       | 70/285 [01:54<07:25,  2.07s/it]Loading train:  25%|██▍       | 71/285 [01:57<08:02,  2.25s/it]Loading train:  25%|██▌       | 72/285 [01:58<07:03,  1.99s/it]Loading train:  26%|██▌       | 73/285 [01:59<06:01,  1.71s/it]Loading train:  26%|██▌       | 74/285 [02:00<05:17,  1.50s/it]Loading train:  26%|██▋       | 75/285 [02:01<04:55,  1.41s/it]Loading train:  27%|██▋       | 76/285 [02:03<04:49,  1.39s/it]Loading train:  27%|██▋       | 77/285 [02:04<04:43,  1.36s/it]Loading train:  27%|██▋       | 78/285 [02:05<04:18,  1.25s/it]Loading train:  28%|██▊       | 79/285 [02:06<04:12,  1.23s/it]Loading train:  28%|██▊       | 80/285 [02:07<04:24,  1.29s/it]Loading train:  28%|██▊       | 81/285 [02:09<04:19,  1.27s/it]Loading train:  29%|██▉       | 82/285 [02:10<04:06,  1.21s/it]Loading train:  29%|██▉       | 83/285 [02:11<03:50,  1.14s/it]Loading train:  29%|██▉       | 84/285 [02:12<03:46,  1.13s/it]Loading train:  30%|██▉       | 85/285 [02:13<03:41,  1.11s/it]Loading train:  30%|███       | 86/285 [02:14<03:48,  1.15s/it]Loading train:  31%|███       | 87/285 [02:16<04:03,  1.23s/it]Loading train:  31%|███       | 88/285 [02:17<04:19,  1.32s/it]Loading train:  31%|███       | 89/285 [02:18<04:01,  1.23s/it]Loading train:  32%|███▏      | 90/285 [02:19<04:02,  1.24s/it]Loading train:  32%|███▏      | 91/285 [02:20<03:48,  1.18s/it]Loading train:  32%|███▏      | 92/285 [02:22<03:42,  1.15s/it]Loading train:  33%|███▎      | 93/285 [02:23<03:52,  1.21s/it]Loading train:  33%|███▎      | 94/285 [02:24<04:04,  1.28s/it]Loading train:  33%|███▎      | 95/285 [02:25<03:58,  1.26s/it]Loading train:  34%|███▎      | 96/285 [02:27<04:04,  1.29s/it]Loading train:  34%|███▍      | 97/285 [02:28<04:20,  1.39s/it]Loading train:  34%|███▍      | 98/285 [02:30<04:21,  1.40s/it]Loading train:  35%|███▍      | 99/285 [02:31<04:02,  1.30s/it]Loading train:  35%|███▌      | 100/285 [02:32<04:04,  1.32s/it]Loading train:  35%|███▌      | 101/285 [02:34<04:07,  1.35s/it]Loading train:  36%|███▌      | 102/285 [02:35<04:09,  1.36s/it]Loading train:  36%|███▌      | 103/285 [02:36<04:04,  1.34s/it]Loading train:  36%|███▋      | 104/285 [02:38<04:09,  1.38s/it]Loading train:  37%|███▋      | 105/285 [02:39<04:04,  1.36s/it]Loading train:  37%|███▋      | 106/285 [02:40<03:52,  1.30s/it]Loading train:  38%|███▊      | 107/285 [02:42<03:57,  1.34s/it]Loading train:  38%|███▊      | 108/285 [02:43<04:04,  1.38s/it]Loading train:  38%|███▊      | 109/285 [02:45<04:01,  1.37s/it]Loading train:  39%|███▊      | 110/285 [02:46<04:14,  1.45s/it]Loading train:  39%|███▉      | 111/285 [02:47<03:58,  1.37s/it]Loading train:  39%|███▉      | 112/285 [02:49<03:59,  1.38s/it]Loading train:  40%|███▉      | 113/285 [02:50<04:06,  1.43s/it]Loading train:  40%|████      | 114/285 [02:52<03:53,  1.37s/it]Loading train:  40%|████      | 115/285 [02:53<03:43,  1.31s/it]Loading train:  41%|████      | 116/285 [02:54<04:00,  1.42s/it]Loading train:  41%|████      | 117/285 [02:56<03:58,  1.42s/it]Loading train:  41%|████▏     | 118/285 [02:57<03:51,  1.39s/it]Loading train:  42%|████▏     | 119/285 [02:59<03:58,  1.44s/it]Loading train:  42%|████▏     | 120/285 [03:00<03:53,  1.42s/it]Loading train:  42%|████▏     | 121/285 [03:02<03:54,  1.43s/it]Loading train:  43%|████▎     | 122/285 [03:03<03:45,  1.38s/it]Loading train:  43%|████▎     | 123/285 [03:04<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [03:06<03:35,  1.34s/it]Loading train:  44%|████▍     | 125/285 [03:07<03:21,  1.26s/it]Loading train:  44%|████▍     | 126/285 [03:08<03:09,  1.19s/it]Loading train:  45%|████▍     | 127/285 [03:09<03:02,  1.15s/it]Loading train:  45%|████▍     | 128/285 [03:10<02:56,  1.13s/it]Loading train:  45%|████▌     | 129/285 [03:11<02:59,  1.15s/it]Loading train:  46%|████▌     | 130/285 [03:12<02:52,  1.11s/it]Loading train:  46%|████▌     | 131/285 [03:13<02:45,  1.08s/it]Loading train:  46%|████▋     | 132/285 [03:14<02:55,  1.14s/it]Loading train:  47%|████▋     | 133/285 [03:16<03:10,  1.25s/it]Loading train:  47%|████▋     | 134/285 [03:17<03:01,  1.20s/it]Loading train:  47%|████▋     | 135/285 [03:18<02:53,  1.16s/it]Loading train:  48%|████▊     | 136/285 [03:19<02:52,  1.16s/it]Loading train:  48%|████▊     | 137/285 [03:20<02:45,  1.12s/it]Loading train:  48%|████▊     | 138/285 [03:21<02:47,  1.14s/it]Loading train:  49%|████▉     | 139/285 [03:22<02:48,  1.15s/it]Loading train:  49%|████▉     | 140/285 [03:24<02:51,  1.18s/it]Loading train:  49%|████▉     | 141/285 [03:25<02:48,  1.17s/it]Loading train:  50%|████▉     | 142/285 [03:26<02:51,  1.20s/it]Loading train:  50%|█████     | 143/285 [03:27<02:41,  1.13s/it]Loading train:  51%|█████     | 144/285 [03:28<02:38,  1.12s/it]Loading train:  51%|█████     | 145/285 [03:29<02:42,  1.16s/it]Loading train:  51%|█████     | 146/285 [03:31<02:48,  1.21s/it]Loading train:  52%|█████▏    | 147/285 [03:32<02:55,  1.27s/it]Loading train:  52%|█████▏    | 148/285 [03:33<02:53,  1.27s/it]Loading train:  52%|█████▏    | 149/285 [03:35<02:42,  1.20s/it]Loading train:  53%|█████▎    | 150/285 [03:36<02:37,  1.17s/it]Loading train:  53%|█████▎    | 151/285 [03:37<02:50,  1.27s/it]Loading train:  53%|█████▎    | 152/285 [03:39<02:55,  1.32s/it]Loading train:  54%|█████▎    | 153/285 [03:40<02:45,  1.26s/it]Loading train:  54%|█████▍    | 154/285 [03:41<02:54,  1.33s/it]Loading train:  54%|█████▍    | 155/285 [03:43<02:55,  1.35s/it]Loading train:  55%|█████▍    | 156/285 [03:44<02:53,  1.34s/it]Loading train:  55%|█████▌    | 157/285 [03:45<02:38,  1.24s/it]Loading train:  55%|█████▌    | 158/285 [03:46<02:28,  1.17s/it]Loading train:  56%|█████▌    | 159/285 [03:47<02:26,  1.16s/it]Loading train:  56%|█████▌    | 160/285 [03:48<02:24,  1.15s/it]Loading train:  56%|█████▋    | 161/285 [03:49<02:23,  1.16s/it]Loading train:  57%|█████▋    | 162/285 [03:50<02:19,  1.13s/it]Loading train:  57%|█████▋    | 163/285 [03:51<02:15,  1.11s/it]Loading train:  58%|█████▊    | 164/285 [03:53<02:12,  1.09s/it]Loading train:  58%|█████▊    | 165/285 [03:54<02:10,  1.09s/it]Loading train:  58%|█████▊    | 166/285 [03:55<02:13,  1.12s/it]Loading train:  59%|█████▊    | 167/285 [03:56<02:19,  1.19s/it]Loading train:  59%|█████▉    | 168/285 [03:57<02:21,  1.21s/it]Loading train:  59%|█████▉    | 169/285 [03:59<02:19,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [04:00<02:17,  1.19s/it]Loading train:  60%|██████    | 171/285 [04:01<02:10,  1.15s/it]Loading train:  60%|██████    | 172/285 [04:02<02:14,  1.19s/it]Loading train:  61%|██████    | 173/285 [04:04<02:30,  1.34s/it]Loading train:  61%|██████    | 174/285 [04:05<02:36,  1.41s/it]Loading train:  61%|██████▏   | 175/285 [04:07<02:35,  1.41s/it]Loading train:  62%|██████▏   | 176/285 [04:08<02:31,  1.39s/it]Loading train:  62%|██████▏   | 177/285 [04:09<02:16,  1.27s/it]Loading train:  62%|██████▏   | 178/285 [04:10<02:10,  1.22s/it]Loading train:  63%|██████▎   | 179/285 [04:11<02:02,  1.15s/it]Loading train:  63%|██████▎   | 180/285 [04:13<02:08,  1.22s/it]Loading train:  64%|██████▎   | 181/285 [04:14<02:05,  1.21s/it]Loading train:  64%|██████▍   | 182/285 [04:15<02:11,  1.28s/it]Loading train:  64%|██████▍   | 183/285 [04:17<02:11,  1.29s/it]Loading train:  65%|██████▍   | 184/285 [04:18<02:04,  1.23s/it]Loading train:  65%|██████▍   | 185/285 [04:19<01:57,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [04:20<01:57,  1.19s/it]Loading train:  66%|██████▌   | 187/285 [04:21<01:56,  1.19s/it]Loading train:  66%|██████▌   | 188/285 [04:22<01:58,  1.22s/it]Loading train:  66%|██████▋   | 189/285 [04:24<02:00,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [04:25<01:58,  1.24s/it]Loading train:  67%|██████▋   | 191/285 [04:26<01:59,  1.27s/it]Loading train:  67%|██████▋   | 192/285 [04:27<01:57,  1.26s/it]Loading train:  68%|██████▊   | 193/285 [04:29<01:49,  1.19s/it]Loading train:  68%|██████▊   | 194/285 [04:30<01:53,  1.25s/it]Loading train:  68%|██████▊   | 195/285 [04:31<01:51,  1.24s/it]Loading train:  69%|██████▉   | 196/285 [04:33<01:58,  1.33s/it]Loading train:  69%|██████▉   | 197/285 [04:34<01:54,  1.30s/it]Loading train:  69%|██████▉   | 198/285 [04:35<01:48,  1.25s/it]Loading train:  70%|██████▉   | 199/285 [04:36<01:39,  1.16s/it]Loading train:  70%|███████   | 200/285 [04:37<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:39<01:43,  1.23s/it]Loading train:  71%|███████   | 202/285 [04:40<01:45,  1.27s/it]Loading train:  71%|███████   | 203/285 [04:41<01:44,  1.28s/it]Loading train:  72%|███████▏  | 204/285 [04:42<01:38,  1.22s/it]Loading train:  72%|███████▏  | 205/285 [04:43<01:33,  1.17s/it]Loading train:  72%|███████▏  | 206/285 [04:45<01:35,  1.21s/it]Loading train:  73%|███████▎  | 207/285 [04:46<01:42,  1.32s/it]Loading train:  73%|███████▎  | 208/285 [04:48<01:45,  1.37s/it]Loading train:  73%|███████▎  | 209/285 [04:49<01:49,  1.44s/it]Loading train:  74%|███████▎  | 210/285 [04:50<01:39,  1.32s/it]Loading train:  74%|███████▍  | 211/285 [04:52<01:35,  1.28s/it]Loading train:  74%|███████▍  | 212/285 [04:53<01:40,  1.37s/it]Loading train:  75%|███████▍  | 213/285 [04:54<01:38,  1.36s/it]Loading train:  75%|███████▌  | 214/285 [04:56<01:32,  1.30s/it]Loading train:  75%|███████▌  | 215/285 [04:57<01:29,  1.28s/it]Loading train:  76%|███████▌  | 216/285 [04:58<01:33,  1.36s/it]Loading train:  76%|███████▌  | 217/285 [05:00<01:35,  1.40s/it]Loading train:  76%|███████▋  | 218/285 [05:01<01:34,  1.41s/it]Loading train:  77%|███████▋  | 219/285 [05:03<01:34,  1.43s/it]Loading train:  77%|███████▋  | 220/285 [05:04<01:26,  1.33s/it]Loading train:  78%|███████▊  | 221/285 [05:05<01:23,  1.30s/it]Loading train:  78%|███████▊  | 222/285 [05:06<01:20,  1.28s/it]Loading train:  78%|███████▊  | 223/285 [05:08<01:21,  1.31s/it]Loading train:  79%|███████▊  | 224/285 [05:09<01:15,  1.24s/it]Loading train:  79%|███████▉  | 225/285 [05:10<01:14,  1.24s/it]Loading train:  79%|███████▉  | 226/285 [05:12<01:16,  1.30s/it]Loading train:  80%|███████▉  | 227/285 [05:13<01:22,  1.42s/it]Loading train:  80%|████████  | 228/285 [05:15<01:19,  1.39s/it]Loading train:  80%|████████  | 229/285 [05:16<01:16,  1.37s/it]Loading train:  81%|████████  | 230/285 [05:17<01:17,  1.41s/it]Loading train:  81%|████████  | 231/285 [05:19<01:11,  1.33s/it]Loading train:  81%|████████▏ | 232/285 [05:20<01:07,  1.28s/it]Loading train:  82%|████████▏ | 233/285 [05:21<01:07,  1.30s/it]Loading train:  82%|████████▏ | 234/285 [05:22<01:06,  1.30s/it]Loading train:  82%|████████▏ | 235/285 [05:23<01:00,  1.20s/it]Loading train:  83%|████████▎ | 236/285 [05:25<01:00,  1.23s/it]Loading train:  83%|████████▎ | 237/285 [05:26<01:02,  1.31s/it]Loading train:  84%|████████▎ | 238/285 [05:28<01:03,  1.36s/it]Loading train:  84%|████████▍ | 239/285 [05:29<01:01,  1.34s/it]Loading train:  84%|████████▍ | 240/285 [05:30<00:58,  1.30s/it]Loading train:  85%|████████▍ | 241/285 [05:31<00:53,  1.21s/it]Loading train:  85%|████████▍ | 242/285 [05:32<00:52,  1.21s/it]Loading train:  85%|████████▌ | 243/285 [05:33<00:48,  1.15s/it]Loading train:  86%|████████▌ | 244/285 [05:34<00:46,  1.13s/it]Loading train:  86%|████████▌ | 245/285 [05:35<00:43,  1.09s/it]Loading train:  86%|████████▋ | 246/285 [05:37<00:43,  1.12s/it]Loading train:  87%|████████▋ | 247/285 [05:38<00:47,  1.24s/it]Loading train:  87%|████████▋ | 248/285 [05:40<00:51,  1.38s/it]Loading train:  87%|████████▋ | 249/285 [05:41<00:46,  1.30s/it]Loading train:  88%|████████▊ | 250/285 [05:42<00:43,  1.25s/it]Loading train:  88%|████████▊ | 251/285 [05:43<00:40,  1.20s/it]Loading train:  88%|████████▊ | 252/285 [05:44<00:40,  1.24s/it]Loading train:  89%|████████▉ | 253/285 [05:46<00:41,  1.30s/it]Loading train:  89%|████████▉ | 254/285 [05:47<00:42,  1.36s/it]Loading train:  89%|████████▉ | 255/285 [05:49<00:39,  1.32s/it]Loading train:  90%|████████▉ | 256/285 [05:50<00:37,  1.29s/it]Loading train:  90%|█████████ | 257/285 [05:51<00:34,  1.24s/it]Loading train:  91%|█████████ | 258/285 [05:52<00:34,  1.30s/it]Loading train:  91%|█████████ | 259/285 [05:54<00:32,  1.25s/it]Loading train:  91%|█████████ | 260/285 [05:55<00:30,  1.24s/it]Loading train:  92%|█████████▏| 261/285 [05:56<00:30,  1.28s/it]Loading train:  92%|█████████▏| 262/285 [05:57<00:29,  1.27s/it]Loading train:  92%|█████████▏| 263/285 [05:58<00:25,  1.18s/it]Loading train:  93%|█████████▎| 264/285 [06:00<00:27,  1.33s/it]Loading train:  93%|█████████▎| 265/285 [06:01<00:25,  1.26s/it]Loading train:  93%|█████████▎| 266/285 [06:02<00:24,  1.27s/it]Loading train:  94%|█████████▎| 267/285 [06:04<00:21,  1.22s/it]Loading train:  94%|█████████▍| 268/285 [06:05<00:22,  1.33s/it]Loading train:  94%|█████████▍| 269/285 [06:07<00:22,  1.43s/it]Loading train:  95%|█████████▍| 270/285 [06:08<00:21,  1.41s/it]Loading train:  95%|█████████▌| 271/285 [06:10<00:21,  1.55s/it]Loading train:  95%|█████████▌| 272/285 [06:12<00:20,  1.61s/it]Loading train:  96%|█████████▌| 273/285 [06:13<00:18,  1.56s/it]Loading train:  96%|█████████▌| 274/285 [06:15<00:16,  1.49s/it]Loading train:  96%|█████████▋| 275/285 [06:16<00:15,  1.58s/it]Loading train:  97%|█████████▋| 276/285 [06:18<00:14,  1.59s/it]Loading train:  97%|█████████▋| 277/285 [06:19<00:12,  1.56s/it]Loading train:  98%|█████████▊| 278/285 [06:21<00:10,  1.55s/it]Loading train:  98%|█████████▊| 279/285 [06:23<00:09,  1.62s/it]Loading train:  98%|█████████▊| 280/285 [06:24<00:08,  1.63s/it]Loading train:  99%|█████████▊| 281/285 [06:26<00:06,  1.55s/it]Loading train:  99%|█████████▉| 282/285 [06:27<00:04,  1.53s/it]Loading train:  99%|█████████▉| 283/285 [06:29<00:03,  1.64s/it]Loading train: 100%|█████████▉| 284/285 [06:31<00:01,  1.64s/it]Loading train: 100%|██████████| 285/285 [06:33<00:00,  1.73s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 37.43it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:08, 34.29it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:11, 23.92it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:10, 26.64it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:08, 31.80it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:06, 37.74it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:05, 46.85it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:04, 51.61it/s]concatenating: train:  19%|█▊        | 53/285 [00:01<00:04, 52.97it/s]concatenating: train:  21%|██        | 60/285 [00:01<00:04, 50.19it/s]concatenating: train:  23%|██▎       | 66/285 [00:01<00:04, 51.23it/s]concatenating: train:  25%|██▌       | 72/285 [00:01<00:06, 30.59it/s]concatenating: train:  27%|██▋       | 77/285 [00:01<00:06, 30.51it/s]concatenating: train:  28%|██▊       | 81/285 [00:01<00:06, 31.08it/s]concatenating: train:  30%|██▉       | 85/285 [00:02<00:06, 32.38it/s]concatenating: train:  31%|███       | 89/285 [00:02<00:06, 32.03it/s]concatenating: train:  33%|███▎      | 93/285 [00:02<00:05, 32.41it/s]concatenating: train:  35%|███▍      | 99/285 [00:02<00:04, 37.32it/s]concatenating: train:  39%|███▊      | 110/285 [00:02<00:03, 46.31it/s]concatenating: train:  41%|████      | 117/285 [00:02<00:03, 49.25it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:03, 53.14it/s]concatenating: train:  47%|████▋     | 133/285 [00:02<00:02, 59.68it/s]concatenating: train:  49%|████▉     | 140/285 [00:02<00:02, 62.10it/s]concatenating: train:  52%|█████▏    | 147/285 [00:03<00:02, 58.20it/s]concatenating: train:  54%|█████▍    | 154/285 [00:03<00:03, 40.67it/s]concatenating: train:  56%|█████▌    | 160/285 [00:03<00:03, 36.02it/s]concatenating: train:  60%|█████▉    | 170/285 [00:03<00:02, 44.11it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:02, 50.97it/s]concatenating: train:  65%|██████▌   | 186/285 [00:03<00:01, 55.76it/s]concatenating: train:  68%|██████▊   | 193/285 [00:04<00:01, 55.43it/s]concatenating: train:  70%|███████   | 200/285 [00:04<00:01, 58.53it/s]concatenating: train:  73%|███████▎  | 208/285 [00:04<00:01, 63.65it/s]concatenating: train:  75%|███████▌  | 215/285 [00:04<00:01, 38.99it/s]concatenating: train:  78%|███████▊  | 221/285 [00:04<00:01, 41.22it/s]concatenating: train:  80%|████████  | 228/285 [00:04<00:01, 45.91it/s]concatenating: train:  82%|████████▏ | 234/285 [00:05<00:01, 44.55it/s]concatenating: train:  84%|████████▍ | 240/285 [00:05<00:00, 47.82it/s]concatenating: train:  86%|████████▋ | 246/285 [00:05<00:00, 49.90it/s]concatenating: train:  90%|████████▉ | 256/285 [00:05<00:00, 58.27it/s]concatenating: train:  92%|█████████▏| 263/285 [00:05<00:00, 60.16it/s]concatenating: train:  95%|█████████▍| 270/285 [00:05<00:00, 45.05it/s]concatenating: train:  97%|█████████▋| 276/285 [00:05<00:00, 36.07it/s]concatenating: train: 100%|█████████▉| 284/285 [00:06<00:00, 42.78it/s]concatenating: train: 100%|██████████| 285/285 [00:06<00:00, 47.19it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.03s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.75s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 45.45it/s]2019-07-11 13:55:33.850122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 13:55:33.850246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 13:55:33.850267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 13:55:33.850279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 13:55:33.850766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:13,  3.19it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  3.88it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:12,  3.28it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:08,  4.26it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.71it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:07,  4.28it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:07,  4.02it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  5.19it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:05,  4.44it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:04,  5.11it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.31it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.41it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.96it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.53it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  4.91it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.51it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.87it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.98it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.39it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.06it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.11it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.91it/s]
Epoch 00047: val_mDice did not improve from 0.58972
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [1.324713150660197, 1.046513557434082, 1.0724537486121768, 1.0867312408628917, 1.2735252266838437, 0.9754996753874279, 0.9794340985161918, 0.9978667781466529, 0.9607649190085275, 0.9661060458137876, 0.896529373668489, 0.939579827444894, 0.9134651195435297, 0.92526832648686, 0.9685122739701044, 0.93294586454119, 0.8967619680223011, 0.904665816397894, 0.9069776932398478, 0.8864630176907494, 0.90651992389134, 0.9416098027002244, 0.9143613917487008, 0.9034170196169898, 0.8872242655072894, 0.9126871426900228, 0.8871450935091291, 0.8204976547332037, 0.8428942930130732, 0.8927328870410011, 0.8448743649891445, 0.8645346335002354, 0.8377773932048252, 0.8676710355849493, 0.8404520239148822, 0.8593596163250151, 0.8498798381714594, 0.8454354660851615, 0.8495938777923584, 0.9354409149714878, 0.8018667584373838, 0.8122041622797648, 0.8150525490442911, 0.8477937039874849, 0.8568219287054879, 0.8100947198413667, 0.84677977789016], 'val_acc': [0.9152220884958903, 0.9331250162351699, 0.9408379111971173, 0.9400709498496282, 0.9286080655597505, 0.9461286749158587, 0.946884152435121, 0.9448099647249494, 0.9428434031350272, 0.9467147390047709, 0.9465476416406178, 0.9456593507812137, 0.9465911246481395, 0.9443727022125608, 0.9460851436569577, 0.9445398307981945, 0.9422550173032851, 0.9446268251964024, 0.946041654972803, 0.9418772714478629, 0.9450938730012803, 0.9431913864044916, 0.9448809311503455, 0.9452747078168959, 0.9453273671013969, 0.9461080375171843, 0.9452884424300421, 0.9455334487415495, 0.9466826830591474, 0.9454899458658128, 0.9445375289235797, 0.943106662659418, 0.9429510037104288, 0.9439698031970433, 0.9428983671324593, 0.946185915243058, 0.945595227536701, 0.9445100511823382, 0.9440407639458066, 0.9434500904310317, 0.9448580458050683, 0.9447344541549683, 0.9423306101844424, 0.9444871516454787, 0.9443040092786154, 0.9445924702144805, 0.9418566652706691], 'val_mDice': [0.47336760340701967, 0.5742495292354197, 0.5532519097129504, 0.5354379236343361, 0.4294873858314185, 0.5877405138952392, 0.5897228504930224, 0.5537430722089041, 0.5867783837020397, 0.5735746607893989, 0.5869777096169335, 0.5743339554894538, 0.5860059875107947, 0.5837094029855161, 0.5698849101151738, 0.5659300457863581, 0.5832949426202547, 0.583901719678016, 0.5706652445452554, 0.5843100139782542, 0.5673303930532365, 0.5440307004111153, 0.5776892070259366, 0.5708458168166024, 0.5699533740324634, 0.5743094888471422, 0.573860876262188, 0.5826177174846331, 0.5850877917948223, 0.5676994749477932, 0.582902709643046, 0.5723397973037901, 0.5703664088533038, 0.561455834479559, 0.5863137720596223, 0.5601093746012166, 0.5761197333534559, 0.5712657313616503, 0.5635814840594927, 0.5355640216952279, 0.5765561367429438, 0.5691122531536079, 0.5704456195235252, 0.5651387490686917, 0.5700917284758318, 0.5643357964498656, 0.5617708067099253], 'loss': [2.310657376759954, 0.5653844403064571, 0.47840488931451064, 0.4469382872247319, 0.4257496943162635, 0.409923072906503, 0.4003404423591602, 0.39031102157682496, 0.38452400559861466, 0.37542289690817854, 0.37011891175424155, 0.36530569203791186, 0.36221515242364427, 0.3548251258251362, 0.3523694475836576, 0.3511580668399852, 0.3462964762135096, 0.3432154467748451, 0.34017249213860906, 0.33748517704419095, 0.33438978871789904, 0.33195713657691156, 0.3305112777163993, 0.32556633082156883, 0.32371527375985554, 0.3242937258231242, 0.3225477297847984, 0.32060180567973423, 0.31805974019844685, 0.31650802996982746, 0.31528719147322193, 0.3141255979653335, 0.311779489183049, 0.3100576246488018, 0.31083483327232575, 0.3086691378673791, 0.30569352413823386, 0.30521945781461396, 0.30428304114000676, 0.3018724140299063, 0.30069731974247815, 0.30116754945519114, 0.29898825712417254, 0.29818760494931207, 0.29757518365085756, 0.297358745063043, 0.2967189170674412], 'acc': [0.7959736615264257, 0.8979842118130315, 0.9170908717399436, 0.9282849314402633, 0.9311795100808167, 0.9325690794386384, 0.9338151233973521, 0.9348396216143021, 0.935432031408817, 0.9363667130562205, 0.9369039742937891, 0.9374007563474254, 0.9376796271292166, 0.9385361774868191, 0.938741060104907, 0.9386977067406476, 0.9394147116277911, 0.9397146219528776, 0.9399319551159748, 0.9402902355216155, 0.9404268816690903, 0.9408504879150589, 0.9408910371031356, 0.9414722785821925, 0.9416877292290529, 0.9416884022547787, 0.9416381645253198, 0.9418392936135846, 0.9420274948715267, 0.9421352051300467, 0.9424464685599285, 0.9425004350442704, 0.9426380783026449, 0.9427941413152785, 0.9428729960195402, 0.942981738977081, 0.9433196958995449, 0.9433525125254596, 0.9434308767525567, 0.9435092222950282, 0.9437812595714924, 0.9435714848220337, 0.9438919748716647, 0.9440413856749961, 0.9439957844215895, 0.9441108756932262, 0.9441212361342005], 'mDice': [0.18965001849065127, 0.5528972519600072, 0.6045583257882932, 0.6241265177519905, 0.6378205755162796, 0.6482260352686832, 0.6548101797668328, 0.6617092715767691, 0.6655887253417292, 0.6720048294537141, 0.675678254391891, 0.6789804536620155, 0.681191661441995, 0.6864790796934811, 0.6881918436602542, 0.6890489943160334, 0.6925775158697179, 0.6947956726756518, 0.6969530528304617, 0.6988963709416269, 0.7010842960465039, 0.7030258875994502, 0.7039587690303016, 0.707594295181887, 0.7090314173597303, 0.7085518461444003, 0.7097855513096315, 0.7112236915122849, 0.7131992690775099, 0.7142529085074543, 0.7152080434536644, 0.7160708702481595, 0.7177698276901098, 0.7191434081910271, 0.7185554391206609, 0.7201735342838228, 0.722320996165988, 0.7227780321831645, 0.7234886285540271, 0.725251142266676, 0.7261180233376229, 0.7256731193994589, 0.7274337137092486, 0.7280527244925108, 0.7284947832885081, 0.7286686370293254, 0.7291808271192047]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 40)   21640       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 40)   14440       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 100)  0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 268,513
Trainable params: 93,593
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 26s - loss: 1.8929 - acc: 0.6548 - mDice: 0.2543 - val_loss: 1.0145 - val_acc: 0.9243 - val_mDice: 0.3773

Epoch 00001: val_mDice improved from -inf to 0.37732, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 0.5579 - acc: 0.9167 - mDice: 0.5593 - val_loss: 0.5169 - val_acc: 0.9465 - val_mDice: 0.5876

Epoch 00002: val_mDice improved from 0.37732 to 0.58756, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 18s - loss: 0.4404 - acc: 0.9301 - mDice: 0.6312 - val_loss: 0.5128 - val_acc: 0.9488 - val_mDice: 0.5898

Epoch 00003: val_mDice improved from 0.58756 to 0.58981, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 18s - loss: 0.4002 - acc: 0.9379 - mDice: 0.6579 - val_loss: 0.4789 - val_acc: 0.9522 - val_mDice: 0.6117

Epoch 00004: val_mDice improved from 0.58981 to 0.61169, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 18s - loss: 0.3758 - acc: 0.9429 - mDice: 0.6740 - val_loss: 0.4910 - val_acc: 0.9507 - val_mDice: 0.6044

Epoch 00005: val_mDice did not improve from 0.61169
Epoch 6/300
 - 18s - loss: 0.3578 - acc: 0.9466 - mDice: 0.6864 - val_loss: 0.4687 - val_acc: 0.9523 - val_mDice: 0.6180

Epoch 00006: val_mDice improved from 0.61169 to 0.61802, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 18s - loss: 0.3466 - acc: 0.9486 - mDice: 0.6939 - val_loss: 0.4789 - val_acc: 0.9462 - val_mDice: 0.6100

Epoch 00007: val_mDice did not improve from 0.61802
Epoch 8/300
 - 18s - loss: 0.3357 - acc: 0.9498 - mDice: 0.7016 - val_loss: 0.4841 - val_acc: 0.9471 - val_mDice: 0.6096

Epoch 00008: val_mDice did not improve from 0.61802
Epoch 9/300
 - 18s - loss: 0.3271 - acc: 0.9505 - mDice: 0.7076 - val_loss: 0.4449 - val_acc: 0.9539 - val_mDice: 0.6319

Epoch 00009: val_mDice improved from 0.61802 to 0.63188, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 18s - loss: 0.3206 - acc: 0.9511 - mDice: 0.7125 - val_loss: 0.4716 - val_acc: 0.9496 - val_mDice: 0.6172

Epoch 00010: val_mDice did not improve from 0.63188
Epoch 11/300
 - 18s - loss: 0.3135 - acc: 0.9517 - mDice: 0.7175 - val_loss: 0.5020 - val_acc: 0.9501 - val_mDice: 0.6074

Epoch 00011: val_mDice did not improve from 0.63188
Epoch 12/300
 - 18s - loss: 0.3132 - acc: 0.9519 - mDice: 0.7184 - val_loss: 0.5317 - val_acc: 0.9496 - val_mDice: 0.5832

Epoch 00012: val_mDice did not improve from 0.63188
Epoch 13/300
 - 18s - loss: 0.3087 - acc: 0.9521 - mDice: 0.7210 - val_loss: 0.4640 - val_acc: 0.9514 - val_mDice: 0.6204

Epoch 00013: val_mDice did not improve from 0.63188
Epoch 14/300
 - 18s - loss: 0.2984 - acc: 0.9528 - mDice: 0.7287 - val_loss: 0.4911 - val_acc: 0.9516 - val_mDice: 0.6100

Epoch 00014: val_mDice did not improve from 0.63188
Epoch 15/300
 - 18s - loss: 0.2964 - acc: 0.9530 - mDice: 0.7303 - val_loss: 0.4576 - val_acc: 0.9511 - val_mDice: 0.6238

Epoch 00015: val_mDice did not improve from 0.63188
Epoch 16/300
 - 18s - loss: 0.2922 - acc: 0.9534 - mDice: 0.7336 - val_loss: 0.5434 - val_acc: 0.9525 - val_mDice: 0.6092

Epoch 00016: val_mDice did not improve from 0.63188
Epoch 17/300
 - 18s - loss: 0.2878 - acc: 0.9536 - mDice: 0.7369 - val_loss: 0.4642 - val_acc: 0.9523 - val_mDice: 0.6213

Epoch 00017: val_mDice did not improve from 0.63188
Epoch 18/300
 - 18s - loss: 0.2831 - acc: 0.9539 - mDice: 0.7403 - val_loss: 0.4609 - val_acc: 0.9548 - val_mDice: 0.6236

Epoch 00018: val_mDice did not improve from 0.63188
Epoch 19/300
 - 18s - loss: 0.2808 - acc: 0.9541 - mDice: 0.7421 - val_loss: 0.4855 - val_acc: 0.9512 - val_mDice: 0.6180

Epoch 00019: val_mDice did not improve from 0.63188
Epoch 20/300
 - 18s - loss: 0.2789 - acc: 0.9543 - mDice: 0.7436 - val_loss: 0.5927 - val_acc: 0.9547 - val_mDice: 0.6126

Epoch 00020: val_mDice did not improve from 0.63188
Epoch 21/300
 - 18s - loss: 0.2756 - acc: 0.9545 - mDice: 0.7462 - val_loss: 0.4634 - val_acc: 0.9511 - val_mDice: 0.6216

Epoch 00021: val_mDice did not improve from 0.63188
Epoch 22/300
 - 18s - loss: 0.2721 - acc: 0.9548 - mDice: 0.7488 - val_loss: 0.4846 - val_acc: 0.9523 - val_mDice: 0.6200

Epoch 00022: val_mDice did not improve from 0.63188
Epoch 23/300
 - 18s - loss: 0.2726 - acc: 0.9548 - mDice: 0.7487 - val_loss: 0.4685 - val_acc: 0.9514 - val_mDice: 0.6228

Epoch 00023: val_mDice did not improve from 0.63188
Epoch 24/300
 - 18s - loss: 0.2698 - acc: 0.9551 - mDice: 0.7507 - val_loss: 0.4778 - val_acc: 0.9545 - val_mDice: 0.6220

Epoch 00024: val_mDice did not improve from 0.63188
Epoch 25/300
 - 18s - loss: 0.2668 - acc: 0.9551 - mDice: 0.7531 - val_loss: 0.5667 - val_acc: 0.9538 - val_mDice: 0.6108

Epoch 00025: val_mDice did not improve from 0.63188
Epoch 26/300
 - 18s - loss: 0.2645 - acc: 0.9553 - mDice: 0.7548 - val_loss: 0.5103 - val_acc: 0.9532 - val_mDice: 0.6193

Epoch 00026: val_mDice did not improve from 0.63188
Epoch 27/300
 - 18s - loss: 0.2624 - acc: 0.9555 - mDice: 0.7565 - val_loss: 0.5062 - val_acc: 0.9552 - val_mDice: 0.6150

Epoch 00027: val_mDice did not improve from 0.63188
Epoch 28/300
 - 18s - loss: 0.2615 - acc: 0.9556 - mDice: 0.7572 - val_loss: 0.5094 - val_acc: 0.9553 - val_mDice: 0.6242

Epoch 00028: val_mDice did not improve from 0.63188
Epoch 29/300
 - 18s - loss: 0.2590 - acc: 0.9558 - mDice: 0.7593 - val_loss: 0.4645 - val_acc: 0.9544 - val_mDice: 0.6244

Epoch 00029: val_mDice did not improve from 0.63188
Epoch 30/300
 - 18s - loss: 0.2564 - acc: 0.9560 - mDice: 0.7612 - val_loss: 0.4575 - val_acc: 0.9537 - val_mDice: 0.6252

Epoch 00030: val_mDice did not improve from 0.63188
Epoch 31/300
 - 18s - loss: 0.2556 - acc: 0.9561 - mDice: 0.7619 - val_loss: 0.4779 - val_acc: 0.9531 - val_mDice: 0.6220

Epoch 00031: val_mDice did not improve from 0.63188
Epoch 32/300
 - 18s - loss: 0.2534 - acc: 0.9561 - mDice: 0.7635 - val_loss: 0.4831 - val_acc: 0.9527 - val_mDice: 0.6225

Epoch 00032: val_mDice did not improve from 0.63188
Epoch 33/300
 - 17s - loss: 0.2536 - acc: 0.9561 - mDice: 0.7635 - val_loss: 0.5044 - val_acc: 0.9499 - val_mDice: 0.6025

Epoch 00033: val_mDice did not improve from 0.63188
Epoch 34/300
 - 18s - loss: 0.2542 - acc: 0.9561 - mDice: 0.7630 - val_loss: 0.5241 - val_acc: 0.9545 - val_mDice: 0.6192

Epoch 00034: val_mDice did not improve from 0.63188
Epoch 35/300
 - 18s - loss: 0.2489 - acc: 0.9565 - mDice: 0.7671 - val_loss: 0.4642 - val_acc: 0.9528 - val_mDice: 0.6257

Epoch 00035: val_mDice did not improve from 0.63188
Epoch 36/300
 - 18s - loss: 0.2463 - acc: 0.9566 - mDice: 0.7691 - val_loss: 0.4515 - val_acc: 0.9534 - val_mDice: 0.6263

Epoch 00036: val_mDice did not improve from 0.63188
Epoch 37/300
 - 18s - loss: 0.2463 - acc: 0.9566 - mDice: 0.7692 - val_loss: 0.4613 - val_acc: 0.9552 - val_mDice: 0.6251

Epoch 00037: val_mDice did not improve from 0.63188
Epoch 38/300
 - 18s - loss: 0.2463 - acc: 0.9566 - mDice: 0.7693 - val_loss: 0.5346 - val_acc: 0.9552 - val_mDice: 0.6083

Epoch 00038: val_mDice did not improve from 0.63188
Epoch 39/300
 - 17s - loss: 0.2445 - acc: 0.9568 - mDice: 0.7707 - val_loss: 0.4484 - val_acc: 0.9528 - val_mDice: 0.6276

Epoch 00039: val_mDice did not improve from 0.63188
Epoch 40/300
 - 18s - loss: 0.2428 - acc: 0.9569 - mDice: 0.7720 - val_loss: 0.4699 - val_acc: 0.9558 - val_mDice: 0.6256

Epoch 00040: val_mDice did not improve from 0.63188
Epoch 41/300
 - 18s - loss: 0.2429 - acc: 0.9569 - mDice: 0.7719 - val_loss: 0.5131 - val_acc: 0.9528 - val_mDice: 0.6030

Epoch 00041: val_mDice did not improve from 0.63188
Epoch 42/300
 - 18s - loss: 0.2411 - acc: 0.9570 - mDice: 0.7733 - val_loss: 0.4592 - val_acc: 0.9555 - val_mDice: 0.6275

Epoch 00042: val_mDice did not improve from 0.63188
Epoch 43/300
 - 18s - loss: 0.2408 - acc: 0.9571 - mDice: 0.7736 - val_loss: 0.4728 - val_acc: 0.9561 - val_mDice: 0.6216

Epoch 00043: val_mDice did not improve from 0.63188
Epoch 44/300
 - 18s - loss: 0.2400 - acc: 0.9571 - mDice: 0.7743 - val_loss: 0.4418 - val_acc: 0.9550 - val_mDice: 0.6362

Epoch 00044: val_mDice improved from 0.63188 to 0.63620, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 18s - loss: 0.2402 - acc: 0.9571 - mDice: 0.7741 - val_loss: 0.4645 - val_acc: 0.9540 - val_mDice: 0.6288

Epoch 00045: val_mDice did not improve from 0.63620
Epoch 46/300
 - 18s - loss: 0.2392 - acc: 0.9573 - mDice: 0.7750 - val_loss: 0.4576 - val_acc: 0.9543 - val_mDice: 0.6273

Epoch 00046: val_mDice did not improve from 0.63620
Epoch 47/300
 - 18s - loss: 0.2372 - acc: 0.9573 - mDice: 0.7765 - val_loss: 0.4718 - val_acc: 0.9550 - val_mDice: 0.6198

Epoch 00047: val_mDice did not improve from 0.63620
Epoch 48/300
 - 18s - loss: 0.2350 - acc: 0.9575 - mDice: 0.7783 - val_loss: 0.4811 - val_acc: 0.9509 - val_mDice: 0.6113

Epoch 00048: val_mDice did not improve from 0.63620
Epoch 49/300
 - 18s - loss: 0.2347 - acc: 0.9575 - mDice: 0.7785 - val_loss: 0.4540 - val_acc: 0.9542 - val_mDice: 0.6250

Epoch 00049: val_mDice did not improve from 0.63620
Epoch 50/300
 - 18s - loss: 0.2354 - acc: 0.9575 - mDice: 0.7783 - val_loss: 0.4635 - val_acc: 0.9554 - val_mDice: 0.6227

Epoch 00050: val_mDice did not improve from 0.63620
Epoch 51/300
 - 18s - loss: 0.2323 - acc: 0.9576 - mDice: 0.7805 - val_loss: 0.4353 - val_acc: 0.9545 - val_mDice: 0.6373

Epoch 00051: val_mDice improved from 0.63620 to 0.63732, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 52/300
 - 18s - loss: 0.2326 - acc: 0.9577 - mDice: 0.7803 - val_loss: 0.4565 - val_acc: 0.9544 - val_mDice: 0.6269

Epoch 00052: val_mDice did not improve from 0.63732
Epoch 53/300
 - 18s - loss: 0.2319 - acc: 0.9577 - mDice: 0.7809 - val_loss: 0.4488 - val_acc: 0.9532 - val_mDice: 0.6280

Epoch 00053: val_mDice did not improve from 0.63732
Epoch 54/300
 - 18s - loss: 0.2306 - acc: 0.9578 - mDice: 0.7820 - val_loss: 0.4386 - val_acc: 0.9548 - val_mDice: 0.6368

Epoch 00054: val_mDice did not improve from 0.63732
Epoch 55/300
 - 18s - loss: 0.2312 - acc: 0.9578 - mDice: 0.7814 - val_loss: 0.4527 - val_acc: 0.9556 - val_mDice: 0.6295

Epoch 00055: val_mDice did not improve from 0.63732
Epoch 56/300
 - 18s - loss: 0.2299 - acc: 0.9579 - mDice: 0.7826 - val_loss: 0.4521 - val_acc: 0.9568 - val_mDice: 0.6305

Epoch 00056: val_mDice did not improve from 0.63732
Epoch 57/300
 - 18s - loss: 0.2296 - acc: 0.9580 - mDice: 0.7827 - val_loss: 0.4538 - val_acc: 0.9550 - val_mDice: 0.6271

Epoch 00057: val_mDice did not improve from 0.63732
Epoch 58/300
 - 18s - loss: 0.2292 - acc: 0.9579 - mDice: 0.7830 - val_loss: 0.4473 - val_acc: 0.9528 - val_mDice: 0.6312

Epoch 00058: val_mDice did not improve from 0.63732
Epoch 59/300
 - 18s - loss: 0.2274 - acc: 0.9581 - mDice: 0.7845 - val_loss: 0.4628 - val_acc: 0.9553 - val_mDice: 0.6263

Epoch 00059: val_mDice did not improve from 0.63732
Epoch 60/300
 - 18s - loss: 0.2269 - acc: 0.9581 - mDice: 0.7850 - val_loss: 0.4682 - val_acc: 0.9541 - val_mDice: 0.6202

Epoch 00060: val_mDice did not improve from 0.63732
Epoch 61/300
 - 18s - loss: 0.2273 - acc: 0.9581 - mDice: 0.7847 - val_loss: 0.4755 - val_acc: 0.9547 - val_mDice: 0.6202

Epoch 00061: val_mDice did not improve from 0.63732
Epoch 62/300
 - 18s - loss: 0.2271 - acc: 0.9580 - mDice: 0.7848 - val_loss: 0.4483 - val_acc: 0.9562 - val_mDice: 0.6314

Epoch 00062: val_mDice did not improve from 0.63732
Epoch 63/300
 - 18s - loss: 0.2266 - acc: 0.9581 - mDice: 0.7852 - val_loss: 0.4679 - val_acc: 0.9531 - val_mDice: 0.6218

Epoch 00063: val_mDice did not improve from 0.63732
Epoch 64/300
 - 18s - loss: 0.2255 - acc: 0.9582 - mDice: 0.7861 - val_loss: 0.4506 - val_acc: 0.9538 - val_mDice: 0.6283

Epoch 00064: val_mDice did not improve from 0.63732
Epoch 65/300
 - 18s - loss: 0.2247 - acc: 0.9582 - mDice: 0.7868 - val_loss: 0.4526 - val_acc: 0.9552 - val_mDice: 0.6292

Epoch 00065: val_mDice did not improve from 0.63732
Epoch 66/300
 - 18s - loss: 0.2239 - acc: 0.9583 - mDice: 0.7875 - val_loss: 0.4693 - val_acc: 0.9545 - val_mDice: 0.6186

Epoch 00066: val_mDice did not improve from 0.63732
Epoch 67/300
 - 18s - loss: 0.2232 - acc: 0.9583 - mDice: 0.7880 - val_loss: 0.4435 - val_acc: 0.9554 - val_mDice: 0.6326

Epoch 00067: val_mDice did not improve from 0.63732
Epoch 68/300
 - 18s - loss: 0.2233 - acc: 0.9583 - mDice: 0.7880 - val_loss: 0.4522 - val_acc: 0.9552 - val_mDice: 0.6294

Epoch 00068: val_mDice did not improve from 0.63732
Epoch 69/300
 - 18s - loss: 0.2235 - acc: 0.9583 - mDice: 0.7878 - val_loss: 0.4545 - val_acc: 0.9553 - val_mDice: 0.6292

Epoch 00069: val_mDice did not improve from 0.63732
Epoch 70/300
 - 18s - loss: 0.2224 - acc: 0.9584 - mDice: 0.7887 - val_loss: 0.4675 - val_acc: 0.9555 - val_mDice: 0.6210

Epoch 00070: val_mDice did not improve from 0.63732
Epoch 71/300
 - 18s - loss: 0.2229 - acc: 0.9584 - mDice: 0.7883 - val_loss: 0.4650 - val_acc: 0.9560 - val_mDice: 0.6251

Epoch 00071: val_mDice did not improve from 0.63732
Epoch 72/300
 - 18s - loss: 0.2224 - acc: 0.9584 - mDice: 0.7887 - val_loss: 0.4488 - val_acc: 0.9539 - val_mDice: 0.6334

Epoch 00072: val_mDice did not improve from 0.63732
Epoch 73/300
 - 18s - loss: 0.2216 - acc: 0.9585 - mDice: 0.7893 - val_loss: 0.4443 - val_acc: 0.9558 - val_mDice: 0.6336

Epoch 00073: val_mDice did not improve from 0.63732
Epoch 74/300
 - 18s - loss: 0.2203 - acc: 0.9585 - mDice: 0.7904 - val_loss: 0.4623 - val_acc: 0.9555 - val_mDice: 0.6292

Epoch 00074: val_mDice did not improve from 0.63732
Epoch 75/300
 - 18s - loss: 0.2218 - acc: 0.9585 - mDice: 0.7892 - val_loss: 0.4739 - val_acc: 0.9555 - val_mDice: 0.6160

Epoch 00075: val_mDice did not improve from 0.63732
Epoch 76/300
 - 18s - loss: 0.2206 - acc: 0.9586 - mDice: 0.7902 - val_loss: 0.4719 - val_acc: 0.9553 - val_mDice: 0.6200

Epoch 00076: val_mDice did not improve from 0.63732
Epoch 77/300
 - 18s - loss: 0.2202 - acc: 0.9586 - mDice: 0.7905 - val_loss: 0.4454 - val_acc: 0.9552 - val_mDice: 0.6343

Epoch 00077: val_mDice did not improve from 0.63732
Epoch 78/300
 - 18s - loss: 0.2190 - acc: 0.9587 - mDice: 0.7915 - val_loss: 0.4478 - val_acc: 0.9546 - val_mDice: 0.6315

Epoch 00078: val_mDice did not improve from 0.63732
Epoch 79/300
 - 18s - loss: 0.2172 - acc: 0.9588 - mDice: 0.7929 - val_loss: 0.4676 - val_acc: 0.9553 - val_mDice: 0.6229

Epoch 00079: val_mDice did not improve from 0.63732
Epoch 80/300
 - 18s - loss: 0.2199 - acc: 0.9586 - mDice: 0.7908 - val_loss: 0.4706 - val_acc: 0.9561 - val_mDice: 0.6239

Epoch 00080: val_mDice did not improve from 0.63732
Epoch 81/300
 - 18s - loss: 0.2165 - acc: 0.9588 - mDice: 0.7936 - val_loss: 0.4594 - val_acc: 0.9535 - val_mDice: 0.6250

Epoch 00081: val_mDice did not improve from 0.63732
Epoch 82/300
 - 18s - loss: 0.2166 - acc: 0.9588 - mDice: 0.7934 - val_loss: 0.4592 - val_acc: 0.9530 - val_mDice: 0.6237

Epoch 00082: val_mDice did not improve from 0.63732
Epoch 83/300
 - 18s - loss: 0.2180 - acc: 0.9587 - mDice: 0.7923 - val_loss: 0.4459 - val_acc: 0.9544 - val_mDice: 0.6313

Epoch 00083: val_mDice did not improve from 0.63732
Epoch 84/300
 - 18s - loss: 0.2163 - acc: 0.9589 - mDice: 0.7937 - val_loss: 0.4566 - val_acc: 0.9535 - val_mDice: 0.6249

Epoch 00084: val_mDice did not improve from 0.63732
Epoch 85/300
 - 18s - loss: 0.2164 - acc: 0.9589 - mDice: 0.7937 - val_loss: 0.4586 - val_acc: 0.9533 - val_mDice: 0.6266

Epoch 00085: val_mDice did not improve from 0.63732
Epoch 86/300
 - 18s - loss: 0.2170 - acc: 0.9589 - mDice: 0.7932 - val_loss: 0.4684 - val_acc: 0.9563 - val_mDice: 0.6218

Epoch 00086: val_mDice did not improve from 0.63732
Epoch 87/300
 - 18s - loss: 0.2194 - acc: 0.9588 - mDice: 0.7912 - val_loss: 0.4488 - val_acc: 0.9549 - val_mDice: 0.6283

Epoch 00087: val_mDice did not improve from 0.63732
Epoch 88/300
 - 18s - loss: 0.2158 - acc: 0.9589 - mDice: 0.7941 - val_loss: 0.4468 - val_acc: 0.9552 - val_mDice: 0.6290

Epoch 00088: val_mDice did not improve from 0.63732
Epoch 89/300
 - 18s - loss: 0.2156 - acc: 0.9589 - mDice: 0.7943 - val_loss: 0.4544 - val_acc: 0.9541 - val_mDice: 0.6278

Epoch 00089: val_mDice did not improve from 0.63732
Epoch 90/300
 - 18s - loss: 0.2130 - acc: 0.9591 - mDice: 0.7965 - val_loss: 0.4547 - val_acc: 0.9553 - val_mDice: 0.6275

Epoch 00090: val_mDice did not improve from 0.63732
Epoch 91/300
 - 18s - loss: 0.2138 - acc: 0.9591 - mDice: 0.7959 - val_loss: 0.4511 - val_acc: 0.9559 - val_mDice: 0.6285

Epoch 00091: val_mDice did not improve from 0.63732
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
{'val_loss': [1.014503815320617, 0.5169100508343574, 0.5128077681504148, 0.47893875371144473, 0.49099877460042857, 0.46874917718951264, 0.4789295749291361, 0.4841140465363444, 0.4448566929588105, 0.4716474830105318, 0.5020326519145646, 0.5317404569860277, 0.46400657146336644, 0.4911039471626282, 0.4575888577786238, 0.5434477375872309, 0.46423573633811993, 0.46092280429168786, 0.4855065785306792, 0.5926632468260866, 0.46342141235340906, 0.48464115671605373, 0.4685180630097842, 0.47784525622202695, 0.5667079490656294, 0.5102640573538881, 0.5061680824396997, 0.5093546509742737, 0.46449061412385056, 0.4575089895525458, 0.47786699826490947, 0.48314562256775756, 0.504396153228909, 0.5241297296971582, 0.46415474994222544, 0.45154295520409526, 0.46125089522846585, 0.534627684001816, 0.4484069027714223, 0.469887880639657, 0.5131395299341426, 0.4592366804623737, 0.47284783331375546, 0.4418025399719537, 0.46454607607932064, 0.4576478001125698, 0.47175764671251097, 0.4810982836025387, 0.4539567468552616, 0.4635101759899928, 0.4353220972268941, 0.4565038777596458, 0.4488470344570096, 0.43858960820309945, 0.45266022196029154, 0.4521032212166813, 0.45381693533678963, 0.4473063626102895, 0.46279529353093835, 0.46823281282819185, 0.47552171066486637, 0.4482993853158791, 0.4679026953334915, 0.4505865174298846, 0.45258466724576896, 0.469294826744655, 0.44351439369457396, 0.45217879890729595, 0.4544682566014082, 0.4674704128137514, 0.46499299270480704, 0.44878093157400634, 0.4442903742443916, 0.46232896144163677, 0.4738951734990381, 0.47185163457966384, 0.4453646494023627, 0.4478436675151633, 0.4676161521639904, 0.4705985111897218, 0.45943620850920014, 0.4591650153671563, 0.445943692875974, 0.4566117908035577, 0.4585742530876032, 0.4683986089749043, 0.44880186678976985, 0.4467733995208527, 0.4544384429574679, 0.4546680440449848, 0.4510988416618475], 'val_acc': [0.9243310023952462, 0.9465203681471628, 0.9487558200372664, 0.9522040589561676, 0.9507247825574608, 0.9523300804905386, 0.9462352534912152, 0.9470699512758735, 0.9538858293155053, 0.949646287457237, 0.9500987706237665, 0.949631821509846, 0.9514334175173796, 0.9516152439836684, 0.9511193986045582, 0.9524602440482411, 0.9523197628932292, 0.9547556189185414, 0.9511834219847312, 0.954712247715316, 0.9510904713715921, 0.9522846227917592, 0.9514106904994176, 0.9544911754197914, 0.9538403559663442, 0.9531627080959981, 0.955164706573806, 0.9553279087530168, 0.9543754931268745, 0.9536998728134113, 0.9530821376006696, 0.952728833233178, 0.9498838828928644, 0.9544787899741913, 0.9527660205377547, 0.9533713766316462, 0.9552390831808805, 0.9552349581398778, 0.9527846231806878, 0.9557597260901382, 0.9527598472946849, 0.9554973337903369, 0.9560882392542323, 0.9549808242467529, 0.9540428359415278, 0.9542845890508683, 0.9549891146201661, 0.9508693947472386, 0.9541647510821593, 0.9553733581271251, 0.9544891009117638, 0.9543940578093076, 0.9531937144988076, 0.9547928175446707, 0.9555593122983111, 0.9567906939783576, 0.9550242087694519, 0.9528279910540448, 0.9552742049680741, 0.9540531695222055, 0.9547163894056608, 0.9562080615725597, 0.9530883131746474, 0.9538341837222349, 0.9551977618446563, 0.954451915938095, 0.9553795689977082, 0.9552018998721459, 0.9552680174065702, 0.9554622120031432, 0.955970477458485, 0.9539333282236281, 0.9557721012131462, 0.9554828928169592, 0.9555303814024899, 0.9552638717203833, 0.9552019115266853, 0.954631650914027, 0.9553031122218297, 0.9560964833424744, 0.9535056658963251, 0.9530180782579177, 0.9544374633101778, 0.9534953492979764, 0.953325935249222, 0.9563340827739438, 0.954945725768638, 0.9552142749951539, 0.95412342608308, 0.9552679937645043, 0.9559043669167844], 'val_mDice': [0.3773202726294875, 0.5875641067600783, 0.5898109464672024, 0.6116945244080527, 0.6043941062255944, 0.6180210902704207, 0.6100243892749595, 0.6095952325027082, 0.6318787659346724, 0.6172394239702704, 0.6074020602849609, 0.5832360686536607, 0.6203958042507065, 0.6099923705921493, 0.6237612573128173, 0.6091992135820442, 0.6212558559865259, 0.6236256460903743, 0.6179774933021162, 0.6125580432028744, 0.6216136153849809, 0.6199904287327601, 0.6227882444525564, 0.6219928104784236, 0.6108316339594025, 0.619275716762969, 0.6149964698866093, 0.6241748739221242, 0.6243648452465761, 0.6252291508893061, 0.6220430355498244, 0.6225176553486446, 0.6025451198636487, 0.6192028735603035, 0.6256879834489449, 0.626306587757345, 0.6251365012962725, 0.6082545618771175, 0.6275724648763348, 0.6255506833172377, 0.6030389849700075, 0.6275197493963401, 0.6215719683876251, 0.6361968590560572, 0.6287618063015645, 0.6273109070415603, 0.6197876364159185, 0.6113388075508885, 0.625024887436595, 0.6226933525261267, 0.6373174200510846, 0.6269410965162948, 0.627974295083371, 0.636753096260838, 0.6295158150475785, 0.6304969268138182, 0.6271074667323235, 0.6312416012726683, 0.6263185406530369, 0.6202200491335139, 0.6201827326300424, 0.6314374707930581, 0.6218447818436437, 0.6282920341251949, 0.6292075807821818, 0.6185756698667004, 0.6326177513133214, 0.629403271821624, 0.6292282076521293, 0.6209559613765951, 0.6251124350052306, 0.6333904459489791, 0.6336127572885438, 0.6291683885638274, 0.6159697101768835, 0.6199742116075654, 0.6343381238383288, 0.6315089710597885, 0.6228681453113449, 0.6238582886797089, 0.6249935979949696, 0.6237353339541558, 0.631287936724764, 0.6248725010030096, 0.6266049732709064, 0.6218161090126251, 0.6283081953086, 0.6289570518046118, 0.627846928282157, 0.6274722821219674, 0.6285359316697999], 'loss': [1.8929239125866222, 0.5579498861195845, 0.4403877085891725, 0.40021989321008783, 0.3757984460951891, 0.3578239584302183, 0.3466139817204093, 0.33571331242994057, 0.32706216267073157, 0.32056522362242984, 0.31346806886571277, 0.3131986670206201, 0.3086929864031863, 0.2983634891618954, 0.2963531148988147, 0.2921516978609543, 0.28779525192408095, 0.28311405360721426, 0.2808379029147954, 0.2788573357801955, 0.27555253600530144, 0.2721241378838068, 0.2726069294505828, 0.26979351310219407, 0.2667713195327372, 0.26450680945928656, 0.26242494956774814, 0.26145861229714884, 0.2589607444647565, 0.2563640223346851, 0.2555651323259425, 0.2533733058950297, 0.2535518808670277, 0.2541905351745609, 0.2489256548142032, 0.24633005137413935, 0.246327250991393, 0.24625206223000862, 0.24453953881096485, 0.24283202605000523, 0.24289405973744116, 0.24107949691029534, 0.24080886320639044, 0.23997682566074274, 0.2402202128060639, 0.23920269988700005, 0.2372253979108126, 0.23502179648672195, 0.23472576099383236, 0.23537200548752585, 0.232271844450863, 0.2325978484707755, 0.23192714410931656, 0.23056142976078733, 0.23123894782326956, 0.22987838210470568, 0.229633796768383, 0.22924045675051874, 0.2274250287227229, 0.22687310031764577, 0.22730733489043625, 0.22711434329453978, 0.22663525729863435, 0.2255464699546416, 0.22468760486918007, 0.22386832029742487, 0.2232227111461992, 0.22328678526933413, 0.22351614814471799, 0.22237224032608657, 0.22288157486927274, 0.22236331285789418, 0.22160264541430058, 0.22025444965841437, 0.22183478966880407, 0.2206372530376864, 0.22016113964611198, 0.21901888440853953, 0.2172066645453188, 0.21992114218262623, 0.21647021246984838, 0.21661215433821973, 0.21798326596589293, 0.21630879185485538, 0.2164109046268902, 0.21699714138158416, 0.2193751256974017, 0.21583882119652884, 0.2155770177717439, 0.21295492891476867, 0.21376214853059453], 'acc': [0.6547649991217457, 0.916728650187428, 0.930103429443767, 0.9379495841622788, 0.9429030210342966, 0.9466041244944224, 0.9486322789713939, 0.9498428575555378, 0.9505089264596173, 0.9511238533091905, 0.9517329370889144, 0.9518716548868309, 0.9520736979046235, 0.9528021024376029, 0.9529596728623079, 0.9533856910406443, 0.9536244907051148, 0.9539267768768189, 0.954125556841401, 0.9543327129352691, 0.9545197911034234, 0.9547511982726905, 0.9548485812282038, 0.9550519353923608, 0.9551171729763468, 0.9553438700704324, 0.9554710249503215, 0.9555826490886669, 0.955752826945908, 0.9559817988786438, 0.956058821499747, 0.956114191919635, 0.956140032378646, 0.956083958188301, 0.9564797432683247, 0.9565801302057408, 0.9565869381430232, 0.9566296972543363, 0.9567689581943437, 0.9568719645969931, 0.9568597572242361, 0.9569581102736667, 0.9570616161821325, 0.9571448659709866, 0.957123394398367, 0.9572521788311332, 0.9572869024143766, 0.9574946673287396, 0.95745272931434, 0.9575131782765521, 0.9576353556540698, 0.9576916109631961, 0.9577075418229521, 0.9578062597264341, 0.9577666776618253, 0.9578564891329026, 0.9579846550258609, 0.9579444905978053, 0.958076559616248, 0.9580590765425975, 0.9580689081666023, 0.9580209455967443, 0.958066007318492, 0.9581735024952913, 0.9582406565142018, 0.9582615816530192, 0.9583447270517769, 0.9583397505525008, 0.9583360251826688, 0.9583952829447079, 0.9583871267887315, 0.9584385256518999, 0.9585040466606627, 0.9585136349966931, 0.9584789314136792, 0.9585673745165048, 0.95858060676063, 0.9586902414393524, 0.9587685710516028, 0.958613012966186, 0.9588340696611473, 0.9587731418393548, 0.9587286695384309, 0.9588537093672538, 0.9588773764528277, 0.9588732267606428, 0.9587916937063192, 0.958869521446227, 0.958867163818118, 0.9590608877694449, 0.9590681396430045], 'mDice': [0.2543006630796089, 0.5593425850288832, 0.6311563864024881, 0.6578609621425475, 0.6740069723416242, 0.6863519581799985, 0.6938592391325481, 0.701619900319514, 0.707634287490531, 0.7124766620420486, 0.7175408434318591, 0.7183717943622061, 0.7210149220129314, 0.7287253111018172, 0.7303259938827079, 0.7335648791156727, 0.7368516800684202, 0.7403012762063989, 0.7421410810381919, 0.7435593350015041, 0.7461853154856982, 0.7487541242925101, 0.7486622309828888, 0.7506817947428157, 0.7530514125139403, 0.7548294875020718, 0.7564599234244577, 0.7571909911952879, 0.7592541119039633, 0.7612154960476504, 0.7618662041293582, 0.763510460285091, 0.7635397967232137, 0.7629774932176756, 0.7671155094074583, 0.7691091404950123, 0.7692250298795393, 0.7693094504430763, 0.770657861539854, 0.7720111440348798, 0.771907763919126, 0.7733081117200148, 0.7736473443149631, 0.7743331670637751, 0.7741311235071027, 0.7749770521033362, 0.7765337537170061, 0.778345639244299, 0.7784986325542844, 0.7783046314694394, 0.7805151716438711, 0.7803260485828978, 0.780857112239398, 0.7820137216403239, 0.7814099438004385, 0.7825569435698451, 0.7827202528560936, 0.7830401423268183, 0.7845175854748523, 0.7850249757577661, 0.7846639076028993, 0.7847919325236175, 0.7851926467691487, 0.7860945538234155, 0.7868251890263833, 0.7874811122726624, 0.7880348989006662, 0.7879561879043907, 0.7877950834478729, 0.7887197398333032, 0.7882675492265543, 0.7887299149444528, 0.7893396088009754, 0.7904327511884802, 0.7891904153755551, 0.7901656208692257, 0.790514224920584, 0.7914656081962388, 0.7929338596854151, 0.7907603079830793, 0.793584680811758, 0.793443026070527, 0.7923459904618879, 0.7936927282364175, 0.7936720088912306, 0.7931789916089259, 0.7912169014516138, 0.7941154872181044, 0.7943269520158842, 0.7965170623436647, 0.7958691518853792]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.57s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.35s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:15,  1.96s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:47,  1.86s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:59,  1.91s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:31,  1.82s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:01,  1.93s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:41,  1.87s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:00,  1.94s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<08:44,  1.89s/it]predicting train subjects:   3%|▎         | 9/285 [00:17<09:11,  2.00s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:42,  2.12s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<09:28,  2.07s/it]predicting train subjects:   4%|▍         | 12/285 [00:24<09:55,  2.18s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:24,  2.07s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:20,  2.07s/it]predicting train subjects:   5%|▌         | 15/285 [00:30<09:39,  2.15s/it]predicting train subjects:   6%|▌         | 16/285 [00:32<09:58,  2.23s/it]predicting train subjects:   6%|▌         | 17/285 [00:34<09:42,  2.17s/it]predicting train subjects:   6%|▋         | 18/285 [00:36<09:40,  2.17s/it]predicting train subjects:   7%|▋         | 19/285 [00:38<09:17,  2.10s/it]predicting train subjects:   7%|▋         | 20/285 [00:40<09:03,  2.05s/it]predicting train subjects:   7%|▋         | 21/285 [00:43<09:21,  2.13s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<08:54,  2.03s/it]predicting train subjects:   8%|▊         | 23/285 [00:47<09:03,  2.08s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<08:40,  1.99s/it]predicting train subjects:   9%|▉         | 25/285 [00:51<09:14,  2.13s/it]predicting train subjects:   9%|▉         | 26/285 [00:53<09:21,  2.17s/it]predicting train subjects:   9%|▉         | 27/285 [00:55<09:06,  2.12s/it]predicting train subjects:  10%|▉         | 28/285 [00:57<08:59,  2.10s/it]predicting train subjects:  10%|█         | 29/285 [00:59<09:02,  2.12s/it]predicting train subjects:  11%|█         | 30/285 [01:02<09:14,  2.17s/it]predicting train subjects:  11%|█         | 31/285 [01:04<09:25,  2.23s/it]predicting train subjects:  11%|█         | 32/285 [01:06<09:02,  2.15s/it]predicting train subjects:  12%|█▏        | 33/285 [01:08<09:01,  2.15s/it]predicting train subjects:  12%|█▏        | 34/285 [01:10<08:53,  2.13s/it]predicting train subjects:  12%|█▏        | 35/285 [01:12<09:02,  2.17s/it]predicting train subjects:  13%|█▎        | 36/285 [01:14<08:36,  2.08s/it]predicting train subjects:  13%|█▎        | 37/285 [01:16<08:25,  2.04s/it]predicting train subjects:  13%|█▎        | 38/285 [01:19<08:42,  2.11s/it]predicting train subjects:  14%|█▎        | 39/285 [01:21<08:35,  2.09s/it]predicting train subjects:  14%|█▍        | 40/285 [01:23<08:45,  2.15s/it]predicting train subjects:  14%|█▍        | 41/285 [01:25<08:20,  2.05s/it]predicting train subjects:  15%|█▍        | 42/285 [01:26<07:56,  1.96s/it]predicting train subjects:  15%|█▌        | 43/285 [01:28<07:55,  1.96s/it]predicting train subjects:  15%|█▌        | 44/285 [01:31<08:10,  2.04s/it]predicting train subjects:  16%|█▌        | 45/285 [01:32<07:55,  1.98s/it]predicting train subjects:  16%|█▌        | 46/285 [01:35<08:19,  2.09s/it]predicting train subjects:  16%|█▋        | 47/285 [01:37<07:57,  2.01s/it]predicting train subjects:  17%|█▋        | 48/285 [01:39<08:07,  2.06s/it]predicting train subjects:  17%|█▋        | 49/285 [01:41<08:29,  2.16s/it]predicting train subjects:  18%|█▊        | 50/285 [01:43<08:25,  2.15s/it]predicting train subjects:  18%|█▊        | 51/285 [01:46<08:36,  2.21s/it]predicting train subjects:  18%|█▊        | 52/285 [01:48<08:12,  2.11s/it]predicting train subjects:  19%|█▊        | 53/285 [01:50<08:16,  2.14s/it]predicting train subjects:  19%|█▉        | 54/285 [01:52<08:29,  2.21s/it]predicting train subjects:  19%|█▉        | 55/285 [01:54<08:12,  2.14s/it]predicting train subjects:  20%|█▉        | 56/285 [01:56<08:20,  2.19s/it]predicting train subjects:  20%|██        | 57/285 [01:58<07:55,  2.08s/it]predicting train subjects:  20%|██        | 58/285 [02:00<07:54,  2.09s/it]predicting train subjects:  21%|██        | 59/285 [02:03<08:04,  2.14s/it]predicting train subjects:  21%|██        | 60/285 [02:05<08:16,  2.21s/it]predicting train subjects:  21%|██▏       | 61/285 [02:07<07:59,  2.14s/it]predicting train subjects:  22%|██▏       | 62/285 [02:09<08:02,  2.16s/it]predicting train subjects:  22%|██▏       | 63/285 [02:11<07:55,  2.14s/it]predicting train subjects:  22%|██▏       | 64/285 [02:13<07:48,  2.12s/it]predicting train subjects:  23%|██▎       | 65/285 [02:16<07:55,  2.16s/it]predicting train subjects:  23%|██▎       | 66/285 [02:18<07:57,  2.18s/it]predicting train subjects:  24%|██▎       | 67/285 [02:20<07:51,  2.16s/it]predicting train subjects:  24%|██▍       | 68/285 [02:22<07:44,  2.14s/it]predicting train subjects:  24%|██▍       | 69/285 [02:24<07:38,  2.12s/it]predicting train subjects:  25%|██▍       | 70/285 [02:26<07:29,  2.09s/it]predicting train subjects:  25%|██▍       | 71/285 [02:28<07:26,  2.09s/it]predicting train subjects:  25%|██▌       | 72/285 [02:30<07:23,  2.08s/it]predicting train subjects:  26%|██▌       | 73/285 [02:33<07:30,  2.13s/it]predicting train subjects:  26%|██▌       | 74/285 [02:35<07:29,  2.13s/it]predicting train subjects:  26%|██▋       | 75/285 [02:37<07:22,  2.11s/it]predicting train subjects:  27%|██▋       | 76/285 [02:39<07:16,  2.09s/it]predicting train subjects:  27%|██▋       | 77/285 [02:41<07:10,  2.07s/it]predicting train subjects:  27%|██▋       | 78/285 [02:43<06:56,  2.01s/it]predicting train subjects:  28%|██▊       | 79/285 [02:45<06:58,  2.03s/it]predicting train subjects:  28%|██▊       | 80/285 [02:47<06:57,  2.03s/it]predicting train subjects:  28%|██▊       | 81/285 [02:49<06:45,  1.99s/it]predicting train subjects:  29%|██▉       | 82/285 [02:51<06:50,  2.02s/it]predicting train subjects:  29%|██▉       | 83/285 [02:53<06:47,  2.02s/it]predicting train subjects:  29%|██▉       | 84/285 [02:55<06:39,  1.99s/it]predicting train subjects:  30%|██▉       | 85/285 [02:57<06:51,  2.06s/it]predicting train subjects:  30%|███       | 86/285 [02:59<06:51,  2.07s/it]predicting train subjects:  31%|███       | 87/285 [03:01<07:04,  2.14s/it]predicting train subjects:  31%|███       | 88/285 [03:03<06:49,  2.08s/it]predicting train subjects:  31%|███       | 89/285 [03:05<06:45,  2.07s/it]predicting train subjects:  32%|███▏      | 90/285 [03:07<06:49,  2.10s/it]predicting train subjects:  32%|███▏      | 91/285 [03:09<06:40,  2.07s/it]predicting train subjects:  32%|███▏      | 92/285 [03:12<06:42,  2.09s/it]predicting train subjects:  33%|███▎      | 93/285 [03:14<06:35,  2.06s/it]predicting train subjects:  33%|███▎      | 94/285 [03:16<06:32,  2.05s/it]predicting train subjects:  33%|███▎      | 95/285 [03:18<06:39,  2.10s/it]predicting train subjects:  34%|███▎      | 96/285 [03:20<06:35,  2.09s/it]predicting train subjects:  34%|███▍      | 97/285 [03:22<06:37,  2.11s/it]predicting train subjects:  34%|███▍      | 98/285 [03:24<06:33,  2.10s/it]predicting train subjects:  35%|███▍      | 99/285 [03:26<06:35,  2.13s/it]predicting train subjects:  35%|███▌      | 100/285 [03:29<06:38,  2.15s/it]predicting train subjects:  35%|███▌      | 101/285 [03:31<06:28,  2.11s/it]predicting train subjects:  36%|███▌      | 102/285 [03:33<06:27,  2.12s/it]predicting train subjects:  36%|███▌      | 103/285 [03:35<06:22,  2.10s/it]predicting train subjects:  36%|███▋      | 104/285 [03:37<06:22,  2.11s/it]predicting train subjects:  37%|███▋      | 105/285 [03:39<06:22,  2.13s/it]predicting train subjects:  37%|███▋      | 106/285 [03:41<06:22,  2.14s/it]predicting train subjects:  38%|███▊      | 107/285 [03:43<06:14,  2.10s/it]predicting train subjects:  38%|███▊      | 108/285 [03:45<06:03,  2.05s/it]predicting train subjects:  38%|███▊      | 109/285 [03:47<06:08,  2.10s/it]predicting train subjects:  39%|███▊      | 110/285 [03:50<06:13,  2.13s/it]predicting train subjects:  39%|███▉      | 111/285 [03:52<06:05,  2.10s/it]predicting train subjects:  39%|███▉      | 112/285 [03:54<05:58,  2.07s/it]predicting train subjects:  40%|███▉      | 113/285 [03:56<05:52,  2.05s/it]predicting train subjects:  40%|████      | 114/285 [03:58<05:49,  2.05s/it]predicting train subjects:  40%|████      | 115/285 [04:00<05:45,  2.03s/it]predicting train subjects:  41%|████      | 116/285 [04:02<05:41,  2.02s/it]predicting train subjects:  41%|████      | 117/285 [04:04<05:35,  2.00s/it]predicting train subjects:  41%|████▏     | 118/285 [04:05<05:29,  1.97s/it]predicting train subjects:  42%|████▏     | 119/285 [04:08<05:38,  2.04s/it]predicting train subjects:  42%|████▏     | 120/285 [04:10<05:44,  2.09s/it]predicting train subjects:  42%|████▏     | 121/285 [04:12<05:29,  2.01s/it]predicting train subjects:  43%|████▎     | 122/285 [04:13<05:17,  1.95s/it]predicting train subjects:  43%|████▎     | 123/285 [04:15<05:03,  1.87s/it]predicting train subjects:  44%|████▎     | 124/285 [04:17<05:05,  1.90s/it]predicting train subjects:  44%|████▍     | 125/285 [04:19<04:58,  1.87s/it]predicting train subjects:  44%|████▍     | 126/285 [04:21<04:53,  1.85s/it]predicting train subjects:  45%|████▍     | 127/285 [04:22<04:44,  1.80s/it]predicting train subjects:  45%|████▍     | 128/285 [04:24<04:39,  1.78s/it]predicting train subjects:  45%|████▌     | 129/285 [04:26<04:32,  1.75s/it]predicting train subjects:  46%|████▌     | 130/285 [04:28<04:36,  1.78s/it]predicting train subjects:  46%|████▌     | 131/285 [04:29<04:31,  1.76s/it]predicting train subjects:  46%|████▋     | 132/285 [04:31<04:36,  1.81s/it]predicting train subjects:  47%|████▋     | 133/285 [04:33<04:25,  1.75s/it]predicting train subjects:  47%|████▋     | 134/285 [04:35<04:27,  1.77s/it]predicting train subjects:  47%|████▋     | 135/285 [04:37<04:26,  1.78s/it]predicting train subjects:  48%|████▊     | 136/285 [04:38<04:18,  1.73s/it]predicting train subjects:  48%|████▊     | 137/285 [04:40<04:30,  1.83s/it]predicting train subjects:  48%|████▊     | 138/285 [04:42<04:18,  1.76s/it]predicting train subjects:  49%|████▉     | 139/285 [04:44<04:22,  1.80s/it]predicting train subjects:  49%|████▉     | 140/285 [04:46<04:28,  1.85s/it]predicting train subjects:  49%|████▉     | 141/285 [04:47<04:21,  1.81s/it]predicting train subjects:  50%|████▉     | 142/285 [04:49<04:19,  1.81s/it]predicting train subjects:  50%|█████     | 143/285 [04:51<04:21,  1.84s/it]predicting train subjects:  51%|█████     | 144/285 [04:53<04:27,  1.90s/it]predicting train subjects:  51%|█████     | 145/285 [04:55<04:19,  1.85s/it]predicting train subjects:  51%|█████     | 146/285 [04:57<04:23,  1.90s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:59<04:10,  1.81s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:00<04:10,  1.83s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:02<04:09,  1.84s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:04<04:03,  1.81s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:06<04:05,  1.83s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:08<03:57,  1.78s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:09<03:48,  1.73s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:11<03:46,  1.73s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:13<03:45,  1.74s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:15<03:50,  1.79s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:16<03:44,  1.75s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:18<03:41,  1.75s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:20<03:41,  1.76s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:22<03:39,  1.76s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:23<03:39,  1.77s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:25<03:34,  1.74s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:27<03:36,  1.77s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:29<03:34,  1.77s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:30<03:29,  1.75s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:32<03:39,  1.85s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:34<03:45,  1.91s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:36<03:40,  1.88s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:38<03:31,  1.82s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:40<03:22,  1.76s/it]predicting train subjects:  60%|██████    | 171/285 [05:41<03:24,  1.79s/it]predicting train subjects:  60%|██████    | 172/285 [05:43<03:19,  1.76s/it]predicting train subjects:  61%|██████    | 173/285 [05:45<03:14,  1.74s/it]predicting train subjects:  61%|██████    | 174/285 [05:46<03:09,  1.71s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:48<03:18,  1.81s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:50<03:21,  1.84s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:52<03:19,  1.85s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:54<03:14,  1.81s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:56<03:04,  1.74s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:58<03:12,  1.83s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:59<03:10,  1.83s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:01<03:14,  1.88s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:03<03:09,  1.86s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:05<03:00,  1.79s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:06<02:53,  1.74s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:09<03:08,  1.90s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:11<03:12,  1.97s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:13<03:19,  2.05s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:15<03:03,  1.92s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:17<03:00,  1.90s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:19<02:59,  1.91s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:21<02:59,  1.94s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:22<02:50,  1.85s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:24<02:41,  1.77s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:25<02:33,  1.70s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:27<02:38,  1.78s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:29<02:45,  1.88s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:31<02:44,  1.89s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:33<02:37,  1.83s/it]predicting train subjects:  70%|███████   | 200/285 [06:35<02:32,  1.80s/it]predicting train subjects:  71%|███████   | 201/285 [06:37<02:31,  1.81s/it]predicting train subjects:  71%|███████   | 202/285 [06:38<02:30,  1.82s/it]predicting train subjects:  71%|███████   | 203/285 [06:40<02:32,  1.86s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:42<02:27,  1.81s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:44<02:21,  1.77s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:45<02:13,  1.69s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:47<02:20,  1.80s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:49<02:27,  1.91s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:52<02:29,  1.97s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:53<02:20,  1.88s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:55<02:13,  1.80s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:57<02:11,  1.81s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:58<02:10,  1.81s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:00<02:05,  1.76s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:02<02:06,  1.81s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:04<02:01,  1.76s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:06<02:05,  1.84s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:08<02:06,  1.88s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:10<02:08,  1.95s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:11<01:58,  1.83s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:13<01:50,  1.72s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:15<01:52,  1.78s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:16<01:49,  1.76s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:18<01:44,  1.72s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:20<01:39,  1.65s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:22<01:44,  1.76s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:24<01:48,  1.88s/it]predicting train subjects:  80%|████████  | 228/285 [07:26<01:49,  1.92s/it]predicting train subjects:  80%|████████  | 229/285 [07:28<01:47,  1.93s/it]predicting train subjects:  81%|████████  | 230/285 [07:29<01:41,  1.85s/it]predicting train subjects:  81%|████████  | 231/285 [07:31<01:35,  1.77s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:33<01:36,  1.83s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:35<01:31,  1.76s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:36<01:32,  1.82s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:38<01:29,  1.78s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:40<01:31,  1.87s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:42<01:32,  1.93s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:44<01:29,  1.91s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:46<01:29,  1.94s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:48<01:24,  1.88s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:50<01:20,  1.84s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:51<01:18,  1.83s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:53<01:13,  1.76s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:55<01:15,  1.83s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:57<01:10,  1.76s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:59<01:12,  1.86s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:01<01:12,  1.90s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:03<01:09,  1.87s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:04<01:04,  1.80s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:06<01:01,  1.77s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:08<00:59,  1.75s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:09<00:56,  1.72s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:11<00:59,  1.85s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:14<00:59,  1.93s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:15<00:57,  1.92s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:17<00:53,  1.84s/it]predicting train subjects:  90%|█████████ | 257/285 [08:19<00:50,  1.79s/it]predicting train subjects:  91%|█████████ | 258/285 [08:21<00:48,  1.81s/it]predicting train subjects:  91%|█████████ | 259/285 [08:23<00:47,  1.84s/it]predicting train subjects:  91%|█████████ | 260/285 [08:24<00:43,  1.75s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:26<00:42,  1.76s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:27<00:39,  1.73s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:29<00:37,  1.70s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:31<00:38,  1.84s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:33<00:37,  1.87s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:35<00:34,  1.82s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:37<00:31,  1.75s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:39<00:31,  1.83s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:40<00:28,  1.81s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:42<00:26,  1.78s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:44<00:24,  1.73s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:46<00:23,  1.79s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:47<00:21,  1.77s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:49<00:19,  1.73s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:51<00:18,  1.85s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:53<00:17,  1.89s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:55<00:14,  1.81s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:56<00:12,  1.78s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:58<00:10,  1.82s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:00<00:08,  1.77s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:02<00:07,  1.80s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:03<00:05,  1.73s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:05<00:03,  1.84s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:08<00:01,  1.92s/it]predicting train subjects: 100%|██████████| 285/285 [09:10<00:00,  1.93s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:16,  1.96s/it]Loading train:   1%|          | 2/285 [00:03<08:23,  1.78s/it]Loading train:   1%|          | 3/285 [00:04<08:09,  1.73s/it]Loading train:   1%|▏         | 4/285 [00:06<07:34,  1.62s/it]Loading train:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]Loading train:   2%|▏         | 6/285 [00:09<07:30,  1.61s/it]Loading train:   2%|▏         | 7/285 [00:11<07:48,  1.69s/it]Loading train:   3%|▎         | 8/285 [00:13<07:45,  1.68s/it]Loading train:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]Loading train:   4%|▎         | 10/285 [00:16<07:10,  1.57s/it]Loading train:   4%|▍         | 11/285 [00:17<06:28,  1.42s/it]Loading train:   4%|▍         | 12/285 [00:18<06:12,  1.36s/it]Loading train:   5%|▍         | 13/285 [00:19<05:41,  1.26s/it]Loading train:   5%|▍         | 14/285 [00:20<05:43,  1.27s/it]Loading train:   5%|▌         | 15/285 [00:21<05:39,  1.26s/it]Loading train:   6%|▌         | 16/285 [00:23<05:26,  1.21s/it]Loading train:   6%|▌         | 17/285 [00:24<05:09,  1.16s/it]Loading train:   6%|▋         | 18/285 [00:25<05:17,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:26<05:14,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:27<05:05,  1.15s/it]Loading train:   7%|▋         | 21/285 [00:28<05:22,  1.22s/it]Loading train:   8%|▊         | 22/285 [00:30<05:19,  1.21s/it]Loading train:   8%|▊         | 23/285 [00:31<05:21,  1.23s/it]Loading train:   8%|▊         | 24/285 [00:32<05:01,  1.16s/it]Loading train:   9%|▉         | 25/285 [00:33<05:12,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:34<05:15,  1.22s/it]Loading train:   9%|▉         | 27/285 [00:36<05:11,  1.21s/it]Loading train:  10%|▉         | 28/285 [00:37<04:59,  1.16s/it]Loading train:  10%|█         | 29/285 [00:38<04:46,  1.12s/it]Loading train:  11%|█         | 30/285 [00:39<04:58,  1.17s/it]Loading train:  11%|█         | 31/285 [00:40<05:06,  1.21s/it]Loading train:  11%|█         | 32/285 [00:42<05:15,  1.25s/it]Loading train:  12%|█▏        | 33/285 [00:43<05:20,  1.27s/it]Loading train:  12%|█▏        | 34/285 [00:44<05:09,  1.23s/it]Loading train:  12%|█▏        | 35/285 [00:45<05:14,  1.26s/it]Loading train:  13%|█▎        | 36/285 [00:47<05:30,  1.33s/it]Loading train:  13%|█▎        | 37/285 [00:48<05:00,  1.21s/it]Loading train:  13%|█▎        | 38/285 [00:49<04:56,  1.20s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:32,  1.11s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:48,  1.18s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:49,  1.19s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:33,  1.13s/it]Loading train:  15%|█▌        | 43/285 [00:55<04:36,  1.14s/it]Loading train:  15%|█▌        | 44/285 [00:56<04:38,  1.15s/it]Loading train:  16%|█▌        | 45/285 [00:57<04:20,  1.09s/it]Loading train:  16%|█▌        | 46/285 [00:58<04:33,  1.14s/it]Loading train:  16%|█▋        | 47/285 [00:59<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [01:00<04:25,  1.12s/it]Loading train:  17%|█▋        | 49/285 [01:02<04:41,  1.19s/it]Loading train:  18%|█▊        | 50/285 [01:03<04:44,  1.21s/it]Loading train:  18%|█▊        | 51/285 [01:04<04:43,  1.21s/it]Loading train:  18%|█▊        | 52/285 [01:05<04:34,  1.18s/it]Loading train:  19%|█▊        | 53/285 [01:06<04:36,  1.19s/it]Loading train:  19%|█▉        | 54/285 [01:08<05:01,  1.31s/it]Loading train:  19%|█▉        | 55/285 [01:09<04:48,  1.25s/it]Loading train:  20%|█▉        | 56/285 [01:10<04:46,  1.25s/it]Loading train:  20%|██        | 57/285 [01:11<04:36,  1.21s/it]Loading train:  20%|██        | 58/285 [01:12<04:26,  1.18s/it]Loading train:  21%|██        | 59/285 [01:14<04:48,  1.28s/it]Loading train:  21%|██        | 60/285 [01:15<04:47,  1.28s/it]Loading train:  21%|██▏       | 61/285 [01:16<04:41,  1.26s/it]Loading train:  22%|██▏       | 62/285 [01:18<04:59,  1.34s/it]Loading train:  22%|██▏       | 63/285 [01:19<04:39,  1.26s/it]Loading train:  22%|██▏       | 64/285 [01:21<05:06,  1.39s/it]Loading train:  23%|██▎       | 65/285 [01:22<05:26,  1.48s/it]Loading train:  23%|██▎       | 66/285 [01:24<05:47,  1.59s/it]Loading train:  24%|██▎       | 67/285 [01:25<05:13,  1.44s/it]Loading train:  24%|██▍       | 68/285 [01:27<04:58,  1.37s/it]Loading train:  24%|██▍       | 69/285 [01:28<04:46,  1.33s/it]Loading train:  25%|██▍       | 70/285 [01:29<04:37,  1.29s/it]Loading train:  25%|██▍       | 71/285 [01:30<04:22,  1.23s/it]Loading train:  25%|██▌       | 72/285 [01:31<04:13,  1.19s/it]Loading train:  26%|██▌       | 73/285 [01:33<04:46,  1.35s/it]Loading train:  26%|██▌       | 74/285 [01:34<04:33,  1.30s/it]Loading train:  26%|██▋       | 75/285 [01:35<04:22,  1.25s/it]Loading train:  27%|██▋       | 76/285 [01:36<04:10,  1.20s/it]Loading train:  27%|██▋       | 77/285 [01:37<04:07,  1.19s/it]Loading train:  27%|██▋       | 78/285 [01:38<03:46,  1.10s/it]Loading train:  28%|██▊       | 79/285 [01:39<03:44,  1.09s/it]Loading train:  28%|██▊       | 80/285 [01:41<03:51,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:42<03:47,  1.11s/it]Loading train:  29%|██▉       | 82/285 [01:43<04:04,  1.20s/it]Loading train:  29%|██▉       | 83/285 [01:44<03:49,  1.14s/it]Loading train:  29%|██▉       | 84/285 [01:45<03:42,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:46<03:38,  1.09s/it]Loading train:  30%|███       | 86/285 [01:47<03:46,  1.14s/it]Loading train:  31%|███       | 87/285 [01:49<03:47,  1.15s/it]Loading train:  31%|███       | 88/285 [01:50<03:40,  1.12s/it]Loading train:  31%|███       | 89/285 [01:51<03:50,  1.17s/it]Loading train:  32%|███▏      | 90/285 [01:52<04:01,  1.24s/it]Loading train:  32%|███▏      | 91/285 [01:53<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:54<03:35,  1.12s/it]Loading train:  33%|███▎      | 93/285 [01:55<03:30,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:57<03:34,  1.13s/it]Loading train:  33%|███▎      | 95/285 [01:58<03:32,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:59<03:26,  1.09s/it]Loading train:  34%|███▍      | 97/285 [02:00<03:32,  1.13s/it]Loading train:  34%|███▍      | 98/285 [02:01<03:40,  1.18s/it]Loading train:  35%|███▍      | 99/285 [02:03<03:43,  1.20s/it]Loading train:  35%|███▌      | 100/285 [02:04<03:36,  1.17s/it]Loading train:  35%|███▌      | 101/285 [02:05<03:25,  1.12s/it]Loading train:  36%|███▌      | 102/285 [02:06<03:30,  1.15s/it]Loading train:  36%|███▌      | 103/285 [02:07<03:26,  1.13s/it]Loading train:  36%|███▋      | 104/285 [02:08<03:25,  1.14s/it]Loading train:  37%|███▋      | 105/285 [02:09<03:22,  1.12s/it]Loading train:  37%|███▋      | 106/285 [02:10<03:07,  1.05s/it]Loading train:  38%|███▊      | 107/285 [02:11<03:01,  1.02s/it]Loading train:  38%|███▊      | 108/285 [02:12<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [02:13<03:04,  1.05s/it]Loading train:  39%|███▊      | 110/285 [02:14<03:13,  1.11s/it]Loading train:  39%|███▉      | 111/285 [02:15<03:04,  1.06s/it]Loading train:  39%|███▉      | 112/285 [02:16<03:07,  1.09s/it]Loading train:  40%|███▉      | 113/285 [02:18<03:28,  1.21s/it]Loading train:  40%|████      | 114/285 [02:19<03:21,  1.18s/it]Loading train:  40%|████      | 115/285 [02:20<03:16,  1.15s/it]Loading train:  41%|████      | 116/285 [02:21<03:12,  1.14s/it]Loading train:  41%|████      | 117/285 [02:22<03:06,  1.11s/it]Loading train:  41%|████▏     | 118/285 [02:23<02:52,  1.04s/it]Loading train:  42%|████▏     | 119/285 [02:24<03:05,  1.12s/it]Loading train:  42%|████▏     | 120/285 [02:25<02:53,  1.05s/it]Loading train:  42%|████▏     | 121/285 [02:27<03:23,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:29<03:32,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:30<03:35,  1.33s/it]Loading train:  44%|████▎     | 124/285 [02:31<03:28,  1.30s/it]Loading train:  44%|████▍     | 125/285 [02:32<03:14,  1.21s/it]Loading train:  44%|████▍     | 126/285 [02:33<03:05,  1.17s/it]Loading train:  45%|████▍     | 127/285 [02:34<02:52,  1.09s/it]Loading train:  45%|████▍     | 128/285 [02:35<02:48,  1.07s/it]Loading train:  45%|████▌     | 129/285 [02:36<02:45,  1.06s/it]Loading train:  46%|████▌     | 130/285 [02:37<02:49,  1.09s/it]Loading train:  46%|████▌     | 131/285 [02:38<02:40,  1.04s/it]Loading train:  46%|████▋     | 132/285 [02:39<02:40,  1.05s/it]Loading train:  47%|████▋     | 133/285 [02:40<02:36,  1.03s/it]Loading train:  47%|████▋     | 134/285 [02:41<02:33,  1.02s/it]Loading train:  47%|████▋     | 135/285 [02:42<02:24,  1.04it/s]Loading train:  48%|████▊     | 136/285 [02:43<02:17,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:44<02:39,  1.08s/it]Loading train:  48%|████▊     | 138/285 [02:45<02:30,  1.03s/it]Loading train:  49%|████▉     | 139/285 [02:46<02:32,  1.04s/it]Loading train:  49%|████▉     | 140/285 [02:48<02:36,  1.08s/it]Loading train:  49%|████▉     | 141/285 [02:49<02:28,  1.03s/it]Loading train:  50%|████▉     | 142/285 [02:49<02:23,  1.00s/it]Loading train:  50%|█████     | 143/285 [02:50<02:21,  1.00it/s]Loading train:  51%|█████     | 144/285 [02:51<02:21,  1.00s/it]Loading train:  51%|█████     | 145/285 [02:52<02:18,  1.01it/s]Loading train:  51%|█████     | 146/285 [02:54<02:25,  1.05s/it]Loading train:  52%|█████▏    | 147/285 [02:55<02:28,  1.08s/it]Loading train:  52%|█████▏    | 148/285 [02:56<02:22,  1.04s/it]Loading train:  52%|█████▏    | 149/285 [02:57<02:19,  1.02s/it]Loading train:  53%|█████▎    | 150/285 [02:58<02:10,  1.03it/s]Loading train:  53%|█████▎    | 151/285 [02:59<02:11,  1.02it/s]Loading train:  53%|█████▎    | 152/285 [03:00<02:15,  1.02s/it]Loading train:  54%|█████▎    | 153/285 [03:01<02:16,  1.03s/it]Loading train:  54%|█████▍    | 154/285 [03:02<02:15,  1.04s/it]Loading train:  54%|█████▍    | 155/285 [03:03<02:14,  1.03s/it]Loading train:  55%|█████▍    | 156/285 [03:04<02:17,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [03:05<02:08,  1.01s/it]Loading train:  55%|█████▌    | 158/285 [03:06<02:10,  1.03s/it]Loading train:  56%|█████▌    | 159/285 [03:07<02:04,  1.01it/s]Loading train:  56%|█████▌    | 160/285 [03:08<02:10,  1.04s/it]Loading train:  56%|█████▋    | 161/285 [03:09<02:05,  1.01s/it]Loading train:  57%|█████▋    | 162/285 [03:10<02:02,  1.01it/s]Loading train:  57%|█████▋    | 163/285 [03:11<02:04,  1.02s/it]Loading train:  58%|█████▊    | 164/285 [03:12<02:09,  1.07s/it]Loading train:  58%|█████▊    | 165/285 [03:13<02:04,  1.04s/it]Loading train:  58%|█████▊    | 166/285 [03:14<02:01,  1.02s/it]Loading train:  59%|█████▊    | 167/285 [03:15<01:57,  1.00it/s]Loading train:  59%|█████▉    | 168/285 [03:16<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [03:17<01:54,  1.01it/s]Loading train:  60%|█████▉    | 170/285 [03:18<01:52,  1.02it/s]Loading train:  60%|██████    | 171/285 [03:19<02:04,  1.09s/it]Loading train:  60%|██████    | 172/285 [03:20<01:57,  1.04s/it]Loading train:  61%|██████    | 173/285 [03:21<01:53,  1.01s/it]Loading train:  61%|██████    | 174/285 [03:22<01:47,  1.03it/s]Loading train:  61%|██████▏   | 175/285 [03:23<01:46,  1.03it/s]Loading train:  62%|██████▏   | 176/285 [03:24<01:49,  1.01s/it]Loading train:  62%|██████▏   | 177/285 [03:25<01:46,  1.02it/s]Loading train:  62%|██████▏   | 178/285 [03:26<01:49,  1.03s/it]Loading train:  63%|██████▎   | 179/285 [03:27<01:49,  1.03s/it]Loading train:  63%|██████▎   | 180/285 [03:28<01:56,  1.11s/it]Loading train:  64%|██████▎   | 181/285 [03:30<01:59,  1.15s/it]Loading train:  64%|██████▍   | 182/285 [03:31<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [03:32<01:54,  1.13s/it]Loading train:  65%|██████▍   | 184/285 [03:33<01:44,  1.03s/it]Loading train:  65%|██████▍   | 185/285 [03:33<01:36,  1.04it/s]Loading train:  65%|██████▌   | 186/285 [03:35<01:40,  1.02s/it]Loading train:  66%|██████▌   | 187/285 [03:36<01:48,  1.11s/it]Loading train:  66%|██████▌   | 188/285 [03:37<01:52,  1.16s/it]Loading train:  66%|██████▋   | 189/285 [03:38<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [03:39<01:41,  1.07s/it]Loading train:  67%|██████▋   | 191/285 [03:40<01:42,  1.09s/it]Loading train:  67%|██████▋   | 192/285 [03:41<01:42,  1.10s/it]Loading train:  68%|██████▊   | 193/285 [03:43<01:40,  1.09s/it]Loading train:  68%|██████▊   | 194/285 [03:44<01:37,  1.08s/it]Loading train:  68%|██████▊   | 195/285 [03:45<01:35,  1.06s/it]Loading train:  69%|██████▉   | 196/285 [03:46<01:50,  1.24s/it]Loading train:  69%|██████▉   | 197/285 [03:48<01:48,  1.24s/it]Loading train:  69%|██████▉   | 198/285 [03:49<01:51,  1.29s/it]Loading train:  70%|██████▉   | 199/285 [03:50<01:41,  1.18s/it]Loading train:  70%|███████   | 200/285 [03:51<01:33,  1.10s/it]Loading train:  71%|███████   | 201/285 [03:52<01:35,  1.13s/it]Loading train:  71%|███████   | 202/285 [03:53<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [03:54<01:30,  1.10s/it]Loading train:  72%|███████▏  | 204/285 [03:55<01:24,  1.04s/it]Loading train:  72%|███████▏  | 205/285 [03:56<01:22,  1.04s/it]Loading train:  72%|███████▏  | 206/285 [03:57<01:16,  1.04it/s]Loading train:  73%|███████▎  | 207/285 [03:58<01:21,  1.05s/it]Loading train:  73%|███████▎  | 208/285 [03:59<01:21,  1.06s/it]Loading train:  73%|███████▎  | 209/285 [04:00<01:23,  1.10s/it]Loading train:  74%|███████▎  | 210/285 [04:01<01:17,  1.03s/it]Loading train:  74%|███████▍  | 211/285 [04:02<01:13,  1.01it/s]Loading train:  74%|███████▍  | 212/285 [04:03<01:11,  1.03it/s]Loading train:  75%|███████▍  | 213/285 [04:04<01:14,  1.04s/it]Loading train:  75%|███████▌  | 214/285 [04:05<01:11,  1.01s/it]Loading train:  75%|███████▌  | 215/285 [04:06<01:16,  1.09s/it]Loading train:  76%|███████▌  | 216/285 [04:07<01:12,  1.05s/it]Loading train:  76%|███████▌  | 217/285 [04:09<01:15,  1.11s/it]Loading train:  76%|███████▋  | 218/285 [04:10<01:16,  1.15s/it]Loading train:  77%|███████▋  | 219/285 [04:11<01:16,  1.16s/it]Loading train:  77%|███████▋  | 220/285 [04:12<01:09,  1.07s/it]Loading train:  78%|███████▊  | 221/285 [04:13<01:07,  1.05s/it]Loading train:  78%|███████▊  | 222/285 [04:14<01:04,  1.02s/it]Loading train:  78%|███████▊  | 223/285 [04:15<01:02,  1.01s/it]Loading train:  79%|███████▊  | 224/285 [04:16<01:00,  1.01it/s]Loading train:  79%|███████▉  | 225/285 [04:17<01:00,  1.01s/it]Loading train:  79%|███████▉  | 226/285 [04:18<01:02,  1.07s/it]Loading train:  80%|███████▉  | 227/285 [04:19<01:04,  1.10s/it]Loading train:  80%|████████  | 228/285 [04:20<01:03,  1.12s/it]Loading train:  80%|████████  | 229/285 [04:22<01:03,  1.13s/it]Loading train:  81%|████████  | 230/285 [04:22<00:57,  1.05s/it]Loading train:  81%|████████  | 231/285 [04:24<00:57,  1.06s/it]Loading train:  81%|████████▏ | 232/285 [04:25<00:54,  1.03s/it]Loading train:  82%|████████▏ | 233/285 [04:25<00:51,  1.01it/s]Loading train:  82%|████████▏ | 234/285 [04:27<00:55,  1.09s/it]Loading train:  82%|████████▏ | 235/285 [04:28<00:55,  1.12s/it]Loading train:  83%|████████▎ | 236/285 [04:29<00:58,  1.19s/it]Loading train:  83%|████████▎ | 237/285 [04:31<00:57,  1.20s/it]Loading train:  84%|████████▎ | 238/285 [04:32<00:56,  1.19s/it]Loading train:  84%|████████▍ | 239/285 [04:33<00:53,  1.16s/it]Loading train:  84%|████████▍ | 240/285 [04:34<00:48,  1.08s/it]Loading train:  85%|████████▍ | 241/285 [04:35<00:45,  1.04s/it]Loading train:  85%|████████▍ | 242/285 [04:36<00:43,  1.01s/it]Loading train:  85%|████████▌ | 243/285 [04:36<00:39,  1.05it/s]Loading train:  86%|████████▌ | 244/285 [04:38<00:41,  1.01s/it]Loading train:  86%|████████▌ | 245/285 [04:38<00:37,  1.06it/s]Loading train:  86%|████████▋ | 246/285 [04:40<00:41,  1.07s/it]Loading train:  87%|████████▋ | 247/285 [04:41<00:41,  1.09s/it]Loading train:  87%|████████▋ | 248/285 [04:42<00:40,  1.11s/it]Loading train:  87%|████████▋ | 249/285 [04:43<00:38,  1.06s/it]Loading train:  88%|████████▊ | 250/285 [04:44<00:35,  1.02s/it]Loading train:  88%|████████▊ | 251/285 [04:45<00:32,  1.04it/s]Loading train:  88%|████████▊ | 252/285 [04:45<00:30,  1.10it/s]Loading train:  89%|████████▉ | 253/285 [04:47<00:32,  1.03s/it]Loading train:  89%|████████▉ | 254/285 [04:48<00:33,  1.07s/it]Loading train:  89%|████████▉ | 255/285 [04:49<00:33,  1.11s/it]Loading train:  90%|████████▉ | 256/285 [04:50<00:29,  1.00s/it]Loading train:  90%|█████████ | 257/285 [04:51<00:27,  1.01it/s]Loading train:  91%|█████████ | 258/285 [04:52<00:28,  1.05s/it]Loading train:  91%|█████████ | 259/285 [04:53<00:26,  1.02s/it]Loading train:  91%|█████████ | 260/285 [04:54<00:24,  1.03it/s]Loading train:  92%|█████████▏| 261/285 [04:55<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [04:56<00:22,  1.04it/s]Loading train:  92%|█████████▏| 263/285 [04:57<00:21,  1.02it/s]Loading train:  93%|█████████▎| 264/285 [04:58<00:22,  1.08s/it]Loading train:  93%|█████████▎| 265/285 [04:59<00:21,  1.07s/it]Loading train:  93%|█████████▎| 266/285 [05:00<00:19,  1.02s/it]Loading train:  94%|█████████▎| 267/285 [05:01<00:17,  1.02it/s]Loading train:  94%|█████████▍| 268/285 [05:02<00:17,  1.02s/it]Loading train:  94%|█████████▍| 269/285 [05:03<00:15,  1.00it/s]Loading train:  95%|█████████▍| 270/285 [05:04<00:14,  1.06it/s]Loading train:  95%|█████████▌| 271/285 [05:05<00:13,  1.05it/s]Loading train:  95%|█████████▌| 272/285 [05:06<00:13,  1.01s/it]Loading train:  96%|█████████▌| 273/285 [05:07<00:11,  1.00it/s]Loading train:  96%|█████████▌| 274/285 [05:08<00:11,  1.01s/it]Loading train:  96%|█████████▋| 275/285 [05:09<00:10,  1.10s/it]Loading train:  97%|█████████▋| 276/285 [05:11<00:10,  1.14s/it]Loading train:  97%|█████████▋| 277/285 [05:11<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [05:12<00:07,  1.06s/it]Loading train:  98%|█████████▊| 279/285 [05:13<00:06,  1.04s/it]Loading train:  98%|█████████▊| 280/285 [05:14<00:05,  1.02s/it]Loading train:  99%|█████████▊| 281/285 [05:15<00:03,  1.03it/s]Loading train:  99%|█████████▉| 282/285 [05:16<00:02,  1.06it/s]Loading train:  99%|█████████▉| 283/285 [05:18<00:02,  1.06s/it]Loading train: 100%|█████████▉| 284/285 [05:18<00:01,  1.03s/it]Loading train: 100%|██████████| 285/285 [05:20<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:01, 138.02it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:02, 101.31it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:02, 96.51it/s] concatenating: train:  13%|█▎        | 37/285 [00:00<00:02, 85.39it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:03, 65.08it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:04, 50.84it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:04, 52.38it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:03, 56.59it/s]concatenating: train:  25%|██▍       | 71/285 [00:01<00:03, 60.42it/s]concatenating: train:  31%|███       | 87/285 [00:01<00:02, 74.25it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 84.54it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:01, 96.52it/s]concatenating: train:  45%|████▌     | 129/285 [00:01<00:01, 99.01it/s]concatenating: train:  49%|████▉     | 141/285 [00:01<00:01, 82.61it/s]concatenating: train:  54%|█████▎    | 153/285 [00:01<00:01, 89.96it/s]concatenating: train:  58%|█████▊    | 164/285 [00:01<00:01, 83.93it/s]concatenating: train:  61%|██████    | 174/285 [00:02<00:01, 78.90it/s]concatenating: train:  66%|██████▌   | 187/285 [00:02<00:01, 88.71it/s]concatenating: train:  70%|███████   | 200/285 [00:02<00:00, 97.17it/s]concatenating: train:  75%|███████▍  | 213/285 [00:02<00:00, 104.15it/s]concatenating: train:  79%|███████▉  | 225/285 [00:02<00:00, 79.93it/s] concatenating: train:  82%|████████▏ | 235/285 [00:02<00:00, 75.13it/s]concatenating: train:  86%|████████▋ | 246/285 [00:02<00:00, 82.16it/s]concatenating: train:  90%|████████▉ | 256/285 [00:03<00:00, 70.23it/s]concatenating: train:  93%|█████████▎| 264/285 [00:03<00:00, 59.29it/s]concatenating: train:  95%|█████████▌| 271/285 [00:03<00:00, 59.38it/s]concatenating: train:  99%|█████████▊| 281/285 [00:03<00:00, 66.98it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 77.93it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.76s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.63s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.55s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 62.39it/s]2019-07-11 14:38:13.158837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 14:38:13.158923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 14:38:13.158937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 14:38:13.158945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 14:38:13.159331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.26it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.75it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.07it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.42it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.17it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.21it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.78it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.99it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.19it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.32it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.48it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.59it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.16it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.57it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.89it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.58it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.93it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.18it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.67it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3620        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_3[0][0]               
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   7240        dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   14440       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_2[0][0]                  
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   43280       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   57680       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_3[0][0]                  
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   14440       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   3620        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 40)   21640       dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 40)   0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 40)   14440       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 100)  0           dropout_6[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 268,513
Trainable params: 93,593
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2.4459 - acc: 0.6406 - mDice: 0.1508 - val_loss: 2.1158 - val_acc: 0.9067 - val_mDice: 0.1829

Epoch 00001: val_mDice improved from -inf to 0.18290, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.7561 - acc: 0.9061 - mDice: 0.4588 - val_loss: 1.2512 - val_acc: 0.9243 - val_mDice: 0.3899

Epoch 00002: val_mDice improved from 0.18290 to 0.38991, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.5444 - acc: 0.9239 - mDice: 0.5657 - val_loss: 0.8947 - val_acc: 0.9398 - val_mDice: 0.5282

Epoch 00003: val_mDice improved from 0.38991 to 0.52820, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4751 - acc: 0.9324 - mDice: 0.6074 - val_loss: 0.8108 - val_acc: 0.9359 - val_mDice: 0.5607

Epoch 00004: val_mDice improved from 0.52820 to 0.56067, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 0.4401 - acc: 0.9358 - mDice: 0.6296 - val_loss: 0.8355 - val_acc: 0.9388 - val_mDice: 0.5604

Epoch 00005: val_mDice did not improve from 0.56067
Epoch 6/300
 - 15s - loss: 0.4184 - acc: 0.9375 - mDice: 0.6434 - val_loss: 0.8138 - val_acc: 0.9412 - val_mDice: 0.5722

Epoch 00006: val_mDice improved from 0.56067 to 0.57224, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 0.4049 - acc: 0.9388 - mDice: 0.6526 - val_loss: 0.8470 - val_acc: 0.9410 - val_mDice: 0.5627

Epoch 00007: val_mDice did not improve from 0.57224
Epoch 8/300
 - 15s - loss: 0.3890 - acc: 0.9402 - mDice: 0.6632 - val_loss: 0.8271 - val_acc: 0.9362 - val_mDice: 0.5724

Epoch 00008: val_mDice improved from 0.57224 to 0.57238, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 15s - loss: 0.3826 - acc: 0.9406 - mDice: 0.6676 - val_loss: 0.8517 - val_acc: 0.9412 - val_mDice: 0.5563

Epoch 00009: val_mDice did not improve from 0.57238
Epoch 10/300
 - 15s - loss: 0.3679 - acc: 0.9419 - mDice: 0.6777 - val_loss: 0.8206 - val_acc: 0.9413 - val_mDice: 0.5757

Epoch 00010: val_mDice improved from 0.57238 to 0.57574, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 15s - loss: 0.3617 - acc: 0.9422 - mDice: 0.6819 - val_loss: 0.8310 - val_acc: 0.9384 - val_mDice: 0.5616

Epoch 00011: val_mDice did not improve from 0.57574
Epoch 12/300
 - 15s - loss: 0.3572 - acc: 0.9428 - mDice: 0.6853 - val_loss: 0.7969 - val_acc: 0.9431 - val_mDice: 0.5853

Epoch 00012: val_mDice improved from 0.57574 to 0.58526, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 15s - loss: 0.3502 - acc: 0.9433 - mDice: 0.6902 - val_loss: 0.8059 - val_acc: 0.9393 - val_mDice: 0.5762

Epoch 00013: val_mDice did not improve from 0.58526
Epoch 14/300
 - 15s - loss: 0.3431 - acc: 0.9437 - mDice: 0.6950 - val_loss: 0.7808 - val_acc: 0.9406 - val_mDice: 0.5853

Epoch 00014: val_mDice improved from 0.58526 to 0.58534, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 15s - loss: 0.3388 - acc: 0.9440 - mDice: 0.6982 - val_loss: 0.7829 - val_acc: 0.9408 - val_mDice: 0.5898

Epoch 00015: val_mDice improved from 0.58534 to 0.58980, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 15s - loss: 0.3346 - acc: 0.9445 - mDice: 0.7013 - val_loss: 0.7662 - val_acc: 0.9411 - val_mDice: 0.5901

Epoch 00016: val_mDice improved from 0.58980 to 0.59013, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 15s - loss: 0.3308 - acc: 0.9449 - mDice: 0.7041 - val_loss: 0.8097 - val_acc: 0.9346 - val_mDice: 0.5657

Epoch 00017: val_mDice did not improve from 0.59013
Epoch 18/300
 - 15s - loss: 0.3255 - acc: 0.9453 - mDice: 0.7080 - val_loss: 0.7633 - val_acc: 0.9414 - val_mDice: 0.5905

Epoch 00018: val_mDice improved from 0.59013 to 0.59046, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 15s - loss: 0.3225 - acc: 0.9455 - mDice: 0.7101 - val_loss: 0.7647 - val_acc: 0.9413 - val_mDice: 0.5938

Epoch 00019: val_mDice improved from 0.59046 to 0.59385, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA1_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 15s - loss: 0.3196 - acc: 0.9458 - mDice: 0.7122 - val_loss: 0.7905 - val_acc: 0.9402 - val_mDice: 0.5851

Epoch 00020: val_mDice did not improve from 0.59385
Epoch 21/300
 - 15s - loss: 0.3159 - acc: 0.9460 - mDice: 0.7149 - val_loss: 0.7833 - val_acc: 0.9353 - val_mDice: 0.5716

Epoch 00021: val_mDice did not improve from 0.59385
Epoch 22/300
 - 15s - loss: 0.3158 - acc: 0.9461 - mDice: 0.7151 - val_loss: 0.8004 - val_acc: 0.9426 - val_mDice: 0.5784

Epoch 00022: val_mDice did not improve from 0.59385
Epoch 23/300
 - 15s - loss: 0.3110 - acc: 0.9463 - mDice: 0.7185 - val_loss: 0.8203 - val_acc: 0.9442 - val_mDice: 0.5708

Epoch 00023: val_mDice did not improve from 0.59385
Epoch 24/300
 - 15s - loss: 0.3086 - acc: 0.9466 - mDice: 0.7204 - val_loss: 0.7787 - val_acc: 0.9431 - val_mDice: 0.5846

Epoch 00024: val_mDice did not improve from 0.59385
Epoch 25/300
 - 15s - loss: 0.3072 - acc: 0.9468 - mDice: 0.7215 - val_loss: 0.7965 - val_acc: 0.9459 - val_mDice: 0.5788

Epoch 00025: val_mDice did not improve from 0.59385
Epoch 26/300
 - 15s - loss: 0.3042 - acc: 0.9469 - mDice: 0.7237 - val_loss: 0.7771 - val_acc: 0.9452 - val_mDice: 0.5914

Epoch 00026: val_mDice did not improve from 0.59385
Epoch 27/300
 - 15s - loss: 0.3035 - acc: 0.9469 - mDice: 0.7241 - val_loss: 0.7927 - val_acc: 0.9389 - val_mDice: 0.5859

Epoch 00027: val_mDice did not improve from 0.59385
Epoch 28/300
 - 15s - loss: 0.3002 - acc: 0.9473 - mDice: 0.7266 - val_loss: 0.7698 - val_acc: 0.9425 - val_mDice: 0.5873

Epoch 00028: val_mDice did not improve from 0.59385
Epoch 29/300
 - 15s - loss: 0.2985 - acc: 0.9476 - mDice: 0.7280 - val_loss: 0.8189 - val_acc: 0.9419 - val_mDice: 0.5715

Epoch 00029: val_mDice did not improve from 0.59385
Epoch 30/300
 - 15s - loss: 0.2957 - acc: 0.9477 - mDice: 0.7301 - val_loss: 0.7760 - val_acc: 0.9433 - val_mDice: 0.5870

Epoch 00030: val_mDice did not improve from 0.59385
Epoch 31/300
 - 15s - loss: 0.2946 - acc: 0.9478 - mDice: 0.7309 - val_loss: 0.7848 - val_acc: 0.9418 - val_mDice: 0.5852

Epoch 00031: val_mDice did not improve from 0.59385
Epoch 32/300
 - 15s - loss: 0.2917 - acc: 0.9479 - mDice: 0.7330 - val_loss: 0.7957 - val_acc: 0.9404 - val_mDice: 0.5816

Epoch 00032: val_mDice did not improve from 0.59385
Epoch 33/300
 - 15s - loss: 0.2912 - acc: 0.9480 - mDice: 0.7335 - val_loss: 0.7639 - val_acc: 0.9436 - val_mDice: 0.5892

Epoch 00033: val_mDice did not improve from 0.59385
Epoch 34/300
 - 15s - loss: 0.2920 - acc: 0.9479 - mDice: 0.7329 - val_loss: 0.7947 - val_acc: 0.9455 - val_mDice: 0.5844

Epoch 00034: val_mDice did not improve from 0.59385
Epoch 35/300
 - 15s - loss: 0.2868 - acc: 0.9483 - mDice: 0.7368 - val_loss: 0.7913 - val_acc: 0.9425 - val_mDice: 0.5862

Epoch 00035: val_mDice did not improve from 0.59385
Epoch 36/300
 - 15s - loss: 0.2875 - acc: 0.9483 - mDice: 0.7364 - val_loss: 0.7987 - val_acc: 0.9407 - val_mDice: 0.5819

Epoch 00036: val_mDice did not improve from 0.59385
Epoch 37/300
 - 15s - loss: 0.2866 - acc: 0.9484 - mDice: 0.7371 - val_loss: 0.7800 - val_acc: 0.9428 - val_mDice: 0.5812

Epoch 00037: val_mDice did not improve from 0.59385
Epoch 38/300
 - 15s - loss: 0.2846 - acc: 0.9485 - mDice: 0.7386 - val_loss: 0.7799 - val_acc: 0.9394 - val_mDice: 0.5709

Epoch 00038: val_mDice did not improve from 0.59385
Epoch 39/300
 - 15s - loss: 0.2807 - acc: 0.9488 - mDice: 0.7415 - val_loss: 0.8076 - val_acc: 0.9441 - val_mDice: 0.5826

Epoch 00039: val_mDice did not improve from 0.59385
Epoch 40/300
 - 15s - loss: 0.2812 - acc: 0.9488 - mDice: 0.7412 - val_loss: 0.8138 - val_acc: 0.9396 - val_mDice: 0.5739

Epoch 00040: val_mDice did not improve from 0.59385
Epoch 41/300
 - 14s - loss: 0.2801 - acc: 0.9488 - mDice: 0.7419 - val_loss: 0.7550 - val_acc: 0.9449 - val_mDice: 0.5917

Epoch 00041: val_mDice did not improve from 0.59385
Epoch 42/300
 - 15s - loss: 0.2777 - acc: 0.9491 - mDice: 0.7439 - val_loss: 0.7857 - val_acc: 0.9415 - val_mDice: 0.5829

Epoch 00042: val_mDice did not improve from 0.59385
Epoch 43/300
 - 14s - loss: 0.2791 - acc: 0.9490 - mDice: 0.7428 - val_loss: 0.8033 - val_acc: 0.9421 - val_mDice: 0.5786

Epoch 00043: val_mDice did not improve from 0.59385
Epoch 44/300
 - 15s - loss: 0.2756 - acc: 0.9492 - mDice: 0.7455 - val_loss: 0.8215 - val_acc: 0.9420 - val_mDice: 0.5719

Epoch 00044: val_mDice did not improve from 0.59385
Epoch 45/300
 - 15s - loss: 0.2755 - acc: 0.9492 - mDice: 0.7456 - val_loss: 0.8134 - val_acc: 0.9427 - val_mDice: 0.5835

Epoch 00045: val_mDice did not improve from 0.59385
Epoch 46/300
 - 15s - loss: 0.2751 - acc: 0.9493 - mDice: 0.7459 - val_loss: 0.7762 - val_acc: 0.9414 - val_mDice: 0.5860

Epoch 00046: val_mDice did not improve from 0.59385
Epoch 47/300
 - 15s - loss: 0.2728 - acc: 0.9494 - mDice: 0.7477 - val_loss: 0.7609 - val_acc: 0.9411 - val_mDice: 0.5796

Epoch 00047: val_mDice did not improve from 0.59385
Epoch 48/300
 - 14s - loss: 0.2725 - acc: 0.9495 - mDice: 0.7480 - val_loss: 0.7703 - val_acc: 0.9424 - val_mDice: 0.5867

Epoch 00048: val_mDice did not improve from 0.59385
Epoch 49/300
 - 14s - loss: 0.2719 - acc: 0.9495 - mDice: 0.7484 - val_loss: 0.7910 - val_acc: 0.9410 - val_mDice: 0.5869

Epoch 00049: val_mDice did not improve from 0.59385
Epoch 50/300
 - 15s - loss: 0.2706 - acc: 0.9496 - mDice: 0.7494 - val_loss: 0.7607 - val_acc: 0.9443 - val_mDice: 0.5854

Epoch 00050: val_mDice did not improve from 0.59385
Epoch 51/300
 - 14s - loss: 0.2698 - acc: 0.9497 - mDice: 0.7501 - val_loss: 0.7718 - val_acc: 0.9400 - val_mDice: 0.5764

Epoch 00051: val_mDice did not improve from 0.59385
Epoch 52/300
 - 15s - loss: 0.2693 - acc: 0.9497 - mDice: 0.7504 - val_loss: 0.7988 - val_acc: 0.9396 - val_mDice: 0.5709

Epoch 00052: val_mDice did not improve from 0.59385
Epoch 53/300
 - 15s - loss: 0.2657 - acc: 0.9500 - mDice: 0.7533 - val_loss: 0.7526 - val_acc: 0.9435 - val_mDice: 0.5907

Epoch 00053: val_mDice did not improve from 0.59385
Epoch 54/300
 - 15s - loss: 0.2661 - acc: 0.9500 - mDice: 0.7530 - val_loss: 0.7877 - val_acc: 0.9438 - val_mDice: 0.5856

Epoch 00054: val_mDice did not improve from 0.59385
Epoch 55/300
 - 15s - loss: 0.2678 - acc: 0.9499 - mDice: 0.7516 - val_loss: 0.7563 - val_acc: 0.9434 - val_mDice: 0.5784

Epoch 00055: val_mDice did not improve from 0.59385
Epoch 56/300
 - 15s - loss: 0.2649 - acc: 0.9501 - mDice: 0.7539 - val_loss: 0.7630 - val_acc: 0.9435 - val_mDice: 0.5713

Epoch 00056: val_mDice did not improve from 0.59385
Epoch 57/300
 - 15s - loss: 0.2660 - acc: 0.9500 - mDice: 0.7530 - val_loss: 0.7639 - val_acc: 0.9398 - val_mDice: 0.5777

Epoch 00057: val_mDice did not improve from 0.59385
Epoch 58/300
 - 15s - loss: 0.2634 - acc: 0.9501 - mDice: 0.7550 - val_loss: 0.7457 - val_acc: 0.9451 - val_mDice: 0.5789

Epoch 00058: val_mDice did not improve from 0.59385
Epoch 59/300
 - 15s - loss: 0.2623 - acc: 0.9502 - mDice: 0.7559 - val_loss: 0.7598 - val_acc: 0.9434 - val_mDice: 0.5766

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.22s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.08s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:21,  1.98s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:38,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:22,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:54,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:17,  1.78s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:56,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:21,  1.80s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:08,  1.76s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:27,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:24,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:47,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:19,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:24,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:31,  1.90s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:42,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:21,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:24,  1.89s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:15,  1.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:06,  1.83s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:16,  1.88s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<07:48,  1.78s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<07:51,  1.80s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:35,  1.75s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<07:55,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:06,  1.88s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:40,  1.78s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:50,  1.83s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:54,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:05,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:03,  1.90s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:38,  1.81s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:49,  1.87s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:02,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:45,  1.89s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:34,  1.86s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:28,  1.84s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:26,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:32,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:22,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:27,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:10,  1.81s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:16,  1.84s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:31,  1.91s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:30,  1.92s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:34,  1.94s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:24,  1.91s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:30,  1.94s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:31,  1.95s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:07,  1.86s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:11,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:58,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:47<07:07,  1.88s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:04,  1.88s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:13,  1.93s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:58,  1.87s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<07:08,  1.92s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<07:01,  1.90s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:49,  1.85s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:50,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:49,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:50,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:47,  1.88s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:43,  1.87s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:43,  1.88s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:34,  1.84s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:28,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:31,  1.84s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:27,  1.84s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:32,  1.87s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:29,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:20,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:10,  1.79s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:11,  1.80s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:16,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:09,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:11,  1.83s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:57,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:50,  1.75s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<05:58,  1.79s/it]predicting train subjects:  30%|███       | 86/285 [02:39<06:03,  1.83s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:12,  1.88s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:55,  1.81s/it]predicting train subjects:  31%|███       | 89/285 [02:44<06:01,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:05,  1.87s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:54,  1.83s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:49,  1.82s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:56,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:57,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:56,  1.90s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:58,  1.92s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<06:00,  1.94s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:52,  1.91s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:35,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:41,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:32,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:35,  1.85s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:20,  1.79s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:22,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:16,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:26,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:28,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:21,  1.85s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:20,  1.85s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:22,  1.88s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:26,  1.91s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:19,  1.89s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:14,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<04:56,  1.77s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:01,  1.82s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<04:58,  1.81s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:53,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:43,  1.74s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:32,  1.68s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:30,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:24,  1.66s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:16,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:11,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:18,  1.65s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:06,  1.58s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<04:07,  1.60s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<04:01,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<04:01,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:02<03:59,  1.58s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<03:54,  1.55s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:49,  1.53s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<03:48,  1.53s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<03:56,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<03:48,  1.55s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<03:54,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<03:58,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:57,  1.65s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:47,  1.60s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:46,  1.60s/it]predicting train subjects:  51%|█████     | 145/285 [04:22<03:42,  1.59s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:49,  1.65s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:25<03:44,  1.63s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:47,  1.66s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:28<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:37,  1.61s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:38,  1.63s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:33<03:29,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:31,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:32,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:27,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:28,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:41<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:29,  1.65s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:24,  1.63s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:20,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:28,  1.68s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:17,  1.60s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<03:15,  1.60s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:17,  1.63s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<03:11,  1.59s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:56<03:08,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:59<03:06,  1.60s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<03:05,  1.60s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:02<02:55,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<02:52,  1.51s/it]predicting train subjects:  60%|██████    | 172/285 [05:05<02:47,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:49,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [05:08<02:46,  1.50s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:10<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:11<02:59,  1.65s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:13<02:52,  1.60s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:14<02:45,  1.55s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:16<02:43,  1.55s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:18<02:50,  1.62s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:19<02:51,  1.65s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:21<02:56,  1.72s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:23<02:51,  1.68s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:24<02:43,  1.62s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:26<02:36,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:44,  1.66s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:29<02:51,  1.75s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:31<02:53,  1.79s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:43,  1.70s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:34<02:37,  1.65s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:36<02:37,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:38<02:40,  1.73s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:39<02:30,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:41<02:26,  1.61s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:42<02:16,  1.51s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:44<02:26,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:46<02:32,  1.73s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:48<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:49<02:19,  1.62s/it]predicting train subjects:  70%|███████   | 200/285 [05:51<02:13,  1.58s/it]predicting train subjects:  71%|███████   | 201/285 [05:53<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:54<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:19,  1.71s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:58<02:14,  1.66s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:03,  1.56s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<02:07,  1.64s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<02:08,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:04,  1.66s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<01:59,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:11<02:01,  1.67s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<02:01,  1.68s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<01:56,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<01:59,  1.70s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:57,  1.73s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:23<01:58,  1.79s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:25<01:51,  1.71s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:26<01:46,  1.67s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:28<01:48,  1.73s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:29<01:40,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:31<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:32<01:33,  1.56s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:34<01:37,  1.65s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:36<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [06:38<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [06:40<01:39,  1.78s/it]predicting train subjects:  81%|████████  | 230/285 [06:41<01:32,  1.68s/it]predicting train subjects:  81%|████████  | 231/285 [06:43<01:27,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:44<01:27,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:46<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:48<01:26,  1.70s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:49<01:21,  1.63s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:51<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:53<01:23,  1.74s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:55<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:57<01:23,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:58<01:17,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:00<01:12,  1.65s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:01<01:08,  1.59s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:03<01:05,  1.55s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:06<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:08<01:04,  1.66s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:09<01:04,  1.71s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:11<01:05,  1.76s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:13<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:15<00:59,  1.69s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:16<00:55,  1.62s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:17<00:51,  1.55s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:19<00:52,  1.64s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:21<00:53,  1.74s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:23<00:52,  1.73s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:24<00:47,  1.64s/it]predicting train subjects:  90%|█████████ | 257/285 [07:26<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:28<00:44,  1.65s/it]predicting train subjects:  91%|█████████ | 259/285 [07:29<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:31<00:39,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:32<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:34<00:35,  1.53s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:35<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:37<00:33,  1.62s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:39<00:33,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:40<00:30,  1.60s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:42<00:28,  1.59s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:44<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:45<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:47<00:24,  1.66s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:48<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:50<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:52<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:53<00:17,  1.56s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:55<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:57<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:12,  1.60s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:00<00:11,  1.57s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:02<00:09,  1.66s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:03<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:05<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:06<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:08<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:10<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:12<00:00,  1.77s/it]

Epoch 00059: val_mDice did not improve from 0.59385
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [2.1157845992308397, 1.2511749542676485, 0.894719314116698, 0.8108146626215714, 0.8354793511904203, 0.8137595240886395, 0.8469901933119848, 0.8270835693065937, 0.8517158031463623, 0.8206073573002448, 0.8309591229145343, 0.7968778724853809, 0.8059058670814221, 0.7807671530888631, 0.7828997385043365, 0.766243488742755, 0.809697531736814, 0.763265820649954, 0.764711183997301, 0.7905042309027451, 0.7832737817214086, 0.800407581604444, 0.8202917644610772, 0.778653505903024, 0.7964711074645703, 0.7771411606898675, 0.7926998012340986, 0.7698212758852885, 0.8189258804688087, 0.7760223161715728, 0.7848171500059274, 0.7957423340815765, 0.763912958594469, 0.7947152921786675, 0.7913309003298099, 0.7987137895364028, 0.7800444009212347, 0.7798882883328658, 0.8075936012543165, 0.8138143764092372, 0.7550250864945925, 0.7856542021036148, 0.8032600444096786, 0.8215168393575228, 0.8134084103199152, 0.7761507160388507, 0.7609215481923177, 0.7702747617776577, 0.7910485221789434, 0.7606961303032361, 0.7717920450063852, 0.798759400844574, 0.7526240944862366, 0.7877382521445935, 0.7562925632183368, 0.7629780723498418, 0.7638915777206421, 0.7456715061114385, 0.7598088956796206], 'val_acc': [0.9067330773060138, 0.9243227541446686, 0.9397536195241488, 0.9358704823714036, 0.9388151650245373, 0.9412467663104718, 0.9410271850916055, 0.9362218242425185, 0.9412467456780947, 0.9413438187195704, 0.9384129895613744, 0.9431097576251397, 0.9393329253563514, 0.9406018876112424, 0.9407567244309646, 0.9410919065658863, 0.9346153690264776, 0.9413854204691373, 0.9413415033083695, 0.9401788872021896, 0.9352672145916865, 0.9425665713273562, 0.9442284749104426, 0.9431420793900123, 0.9459019188697522, 0.9451529933856084, 0.9388914291675274, 0.9425133925217849, 0.9419494362977835, 0.9433154509617732, 0.9418222858355596, 0.9403568804264069, 0.9435974244888012, 0.9454789161682129, 0.9424879734332745, 0.9407405578173124, 0.9427907810761378, 0.9394115392978375, 0.944142949122649, 0.9396426471380087, 0.9449033645483164, 0.9414524756945096, 0.9421482292505411, 0.9419679206151229, 0.9426960051059723, 0.9413692721953759, 0.9410595183189099, 0.942360845895914, 0.9409694190208728, 0.944260821892665, 0.9399523872595567, 0.9396472894228421, 0.9434911425297077, 0.9438493779072394, 0.9433686205973992, 0.9435050051945907, 0.9397651392679948, 0.9451345251156733, 0.9434379706015954], 'val_mDice': [0.18289846926927567, 0.38991062199840176, 0.5281981940452869, 0.5606715438457636, 0.5603983448101924, 0.5722422439318436, 0.5627053236732116, 0.5723807983673536, 0.5563339671263328, 0.5757414996623993, 0.5616061996955138, 0.5852613357397226, 0.5761820903191199, 0.5853390407103759, 0.5898009802286441, 0.5901338291855959, 0.565703890644587, 0.5904644979880407, 0.5938459955728971, 0.5850871451772176, 0.5716384179317034, 0.5783755681835688, 0.5707658225527177, 0.5845848402151694, 0.5788216269933261, 0.591445097556481, 0.5858711502872981, 0.5872882524361978, 0.5714525225070807, 0.586971422800651, 0.5851599476658381, 0.5815910593821452, 0.5892254853477845, 0.5843895650826968, 0.5862042772082182, 0.581948802448236, 0.5811928550784404, 0.5708576274605898, 0.582609358888406, 0.5739117144392087, 0.5917025059461594, 0.5828715958274328, 0.5785925823908585, 0.5718625130561682, 0.5835471537250739, 0.5860020420872248, 0.5795913883126699, 0.5866568713234022, 0.5869288948866037, 0.5854210842114228, 0.5763999292483697, 0.5709301347915943, 0.5906506845584283, 0.5855868837008109, 0.5783792757070981, 0.5713389871212152, 0.5776918931649282, 0.5789488290364926, 0.5765622006012843], 'loss': [2.4459275855334672, 0.7560773641269585, 0.5444360215384879, 0.47508128180469106, 0.4400905282044668, 0.41837649450171954, 0.404887230234877, 0.388964645610594, 0.38257109739293826, 0.3679127850364761, 0.3617247198655532, 0.35717268917961426, 0.35017088669357643, 0.34309206828358185, 0.3387548571185719, 0.33460354659045677, 0.33076805678623733, 0.32554189063884187, 0.3224639580070142, 0.3196333008345495, 0.31588348191646176, 0.31577769423733887, 0.31099010459899373, 0.30860490938795454, 0.3072159858874858, 0.3042017132068575, 0.3035100332201819, 0.30022128942619003, 0.29846022071999334, 0.2956735036733306, 0.2946235236125075, 0.291737202691337, 0.291207458602319, 0.29195001483909055, 0.2868170209182955, 0.2875223729120765, 0.2865948034896189, 0.2845713306916856, 0.28074262216226825, 0.28119190750631756, 0.2800998970430561, 0.2777074233012194, 0.27912211210088056, 0.275565181385489, 0.2754908226616629, 0.27508624766977424, 0.2727829672737688, 0.2725037441508286, 0.2718613792293617, 0.27057543553616037, 0.26976647763897393, 0.26926329222363565, 0.26565276579554314, 0.26609777025297804, 0.2678273566150362, 0.264908914530639, 0.26602218000445543, 0.26343600754696955, 0.26229473017826077], 'acc': [0.6406444418348423, 0.9061140986778722, 0.9239381693291904, 0.9323525366765112, 0.9357598445121514, 0.9375396400132127, 0.9387528451234666, 0.9402073258943777, 0.9406303881741336, 0.9419302333602934, 0.9422062873444543, 0.9427743423724981, 0.9432593649365767, 0.9437463188274732, 0.9440429267062699, 0.9445253380339029, 0.944867524995824, 0.9452513659790874, 0.9454870083988851, 0.9457899134482095, 0.9460151771343382, 0.946127132049931, 0.9463224003843349, 0.946556227113514, 0.9468072053746941, 0.9469073468343937, 0.9469297599233979, 0.9472596653380936, 0.9475621019882502, 0.9477365775147036, 0.9477825103447708, 0.9479101404573802, 0.9480213863124247, 0.9478945122547479, 0.9482690449692408, 0.948308019332205, 0.9483574798414323, 0.9485141730644953, 0.9488119984765911, 0.948753670909292, 0.9487897637562592, 0.9491194898732791, 0.9489689169472724, 0.9491613457687312, 0.9491830503633846, 0.9493346679400861, 0.9494398856728122, 0.9495177453738192, 0.9495400252745049, 0.9496019669732605, 0.9496844397043704, 0.9497215502884163, 0.9499577229493308, 0.9500286417133659, 0.9499153352021226, 0.9500519200179626, 0.9499950327359145, 0.9501240409674993, 0.9502049803700844], 'mDice': [0.15084502047760442, 0.45880557778773684, 0.565744027142198, 0.6074315986267856, 0.6295941881969451, 0.6434342726552486, 0.6526344058138301, 0.6631914181846936, 0.6676151028069075, 0.6776692957210989, 0.6818999481258341, 0.6852939503610459, 0.6901687801428456, 0.6950106759589393, 0.6981937009932249, 0.7012566004106834, 0.7040648692584088, 0.707953917246886, 0.7100975922439675, 0.7122295436951042, 0.7149263982632982, 0.7151456449696535, 0.7184553371851794, 0.7203610730569191, 0.721474005036344, 0.7236634431252079, 0.7241092519017809, 0.7266290170080183, 0.728006715518593, 0.7300644667619358, 0.7309403211760651, 0.733030910664771, 0.7335335036424828, 0.7329125701419148, 0.7367930941604593, 0.7363850931768146, 0.7370528848718961, 0.7385544546149835, 0.7415404382209809, 0.7411731639372778, 0.7419444653674112, 0.7438685505040334, 0.7428479959832163, 0.7455156856518571, 0.7455997820282229, 0.7459027894108561, 0.7477387648924771, 0.7479729340226626, 0.7484135567553751, 0.7494274522175728, 0.7500713151022153, 0.7503512714672801, 0.7532704126061982, 0.7529666242284616, 0.7516476863382444, 0.7539002276166146, 0.752986587859559, 0.755015045165312, 0.7558993920951843]}
