2019-08-16 21:23:54.898710: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-16 21:23:55.224592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:05:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-08-16 21:23:55.224653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 21:23:55.585114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 21:23:55.585182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 21:23:55.585195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 21:23:55.585672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:41,  1.65it/s]Loading train:   1%|          | 2/266 [00:00<02:20,  1.88it/s]Loading train:   1%|          | 3/266 [00:01<02:02,  2.15it/s]Loading train:   2%|▏         | 4/266 [00:01<01:49,  2.40it/s]Loading train:   2%|▏         | 5/266 [00:01<01:43,  2.52it/s]Loading train:   2%|▏         | 6/266 [00:02<01:40,  2.59it/s]Loading train:   3%|▎         | 7/266 [00:02<01:38,  2.64it/s]Loading train:   3%|▎         | 8/266 [00:03<01:36,  2.68it/s]Loading train:   3%|▎         | 9/266 [00:03<01:37,  2.64it/s]Loading train:   4%|▍         | 10/266 [00:03<01:36,  2.67it/s]Loading train:   4%|▍         | 11/266 [00:04<01:42,  2.49it/s]Loading train:   5%|▍         | 12/266 [00:04<01:39,  2.56it/s]Loading train:   5%|▍         | 13/266 [00:04<01:36,  2.63it/s]Loading train:   5%|▌         | 14/266 [00:05<01:33,  2.69it/s]Loading train:   6%|▌         | 15/266 [00:05<01:32,  2.72it/s]Loading train:   6%|▌         | 16/266 [00:06<01:31,  2.74it/s]Loading train:   6%|▋         | 17/266 [00:06<01:30,  2.77it/s]Loading train:   7%|▋         | 18/266 [00:06<01:29,  2.78it/s]Loading train:   7%|▋         | 19/266 [00:07<01:28,  2.80it/s]Loading train:   8%|▊         | 20/266 [00:07<01:27,  2.82it/s]Loading train:   8%|▊         | 21/266 [00:07<01:26,  2.82it/s]Loading train:   8%|▊         | 22/266 [00:08<01:31,  2.66it/s]Loading train:   9%|▊         | 23/266 [00:08<01:37,  2.50it/s]Loading train:   9%|▉         | 24/266 [00:08<01:31,  2.63it/s]Loading train:   9%|▉         | 25/266 [00:09<01:28,  2.73it/s]Loading train:  10%|▉         | 26/266 [00:09<01:25,  2.80it/s]Loading train:  10%|█         | 27/266 [00:10<01:24,  2.84it/s]Loading train:  11%|█         | 28/266 [00:10<01:22,  2.88it/s]Loading train:  11%|█         | 29/266 [00:10<01:21,  2.90it/s]Loading train:  11%|█▏        | 30/266 [00:11<01:49,  2.15it/s]Loading train:  12%|█▏        | 31/266 [00:11<01:53,  2.07it/s]Loading train:  12%|█▏        | 32/266 [00:12<01:53,  2.07it/s]Loading train:  12%|█▏        | 33/266 [00:12<01:53,  2.05it/s]Loading train:  13%|█▎        | 34/266 [00:13<01:51,  2.07it/s]Loading train:  13%|█▎        | 35/266 [00:13<01:48,  2.12it/s]Loading train:  14%|█▎        | 36/266 [00:14<01:48,  2.12it/s]Loading train:  14%|█▍        | 37/266 [00:14<01:47,  2.13it/s]Loading train:  14%|█▍        | 38/266 [00:15<01:51,  2.05it/s]Loading train:  15%|█▍        | 39/266 [00:15<01:50,  2.05it/s]Loading train:  15%|█▌        | 40/266 [00:16<01:54,  1.98it/s]Loading train:  15%|█▌        | 41/266 [00:16<01:56,  1.93it/s]Loading train:  16%|█▌        | 42/266 [00:17<01:50,  2.04it/s]Loading train:  16%|█▌        | 43/266 [00:17<01:49,  2.04it/s]Loading train:  17%|█▋        | 44/266 [00:18<01:51,  2.00it/s]Loading train:  17%|█▋        | 45/266 [00:18<01:47,  2.05it/s]Loading train:  17%|█▋        | 46/266 [00:19<01:42,  2.15it/s]Loading train:  18%|█▊        | 47/266 [00:19<01:42,  2.13it/s]Loading train:  18%|█▊        | 48/266 [00:20<01:40,  2.18it/s]Loading train:  18%|█▊        | 49/266 [00:20<01:37,  2.23it/s]Loading train:  19%|█▉        | 50/266 [00:20<01:35,  2.25it/s]Loading train:  19%|█▉        | 51/266 [00:21<01:52,  1.91it/s]Loading train:  20%|█▉        | 52/266 [00:22<01:58,  1.81it/s]Loading train:  20%|█▉        | 53/266 [00:22<01:47,  1.98it/s]Loading train:  20%|██        | 54/266 [00:23<01:57,  1.80it/s]Loading train:  21%|██        | 55/266 [00:24<02:05,  1.69it/s]Loading train:  21%|██        | 56/266 [00:24<02:08,  1.64it/s]Loading train:  21%|██▏       | 57/266 [00:25<01:59,  1.75it/s]Loading train:  22%|██▏       | 58/266 [00:25<01:52,  1.85it/s]Loading train:  22%|██▏       | 59/266 [00:26<02:12,  1.57it/s]Loading train:  23%|██▎       | 60/266 [00:27<02:19,  1.48it/s]Loading train:  23%|██▎       | 61/266 [00:28<02:25,  1.41it/s]Loading train:  23%|██▎       | 62/266 [00:28<02:20,  1.45it/s]Loading train:  24%|██▎       | 63/266 [00:29<02:04,  1.63it/s]Loading train:  24%|██▍       | 64/266 [00:29<02:01,  1.67it/s]Loading train:  24%|██▍       | 65/266 [00:30<01:54,  1.75it/s]Loading train:  25%|██▍       | 66/266 [00:30<01:49,  1.83it/s]Loading train:  25%|██▌       | 67/266 [00:31<02:00,  1.65it/s]Loading train:  26%|██▌       | 68/266 [00:32<02:05,  1.58it/s]Loading train:  26%|██▌       | 69/266 [00:32<01:56,  1.69it/s]Loading train:  26%|██▋       | 70/266 [00:33<01:49,  1.79it/s]Loading train:  27%|██▋       | 71/266 [00:33<01:52,  1.73it/s]Loading train:  27%|██▋       | 72/266 [00:34<01:53,  1.71it/s]Loading train:  27%|██▋       | 73/266 [00:35<02:10,  1.48it/s]Loading train:  28%|██▊       | 74/266 [00:35<02:12,  1.45it/s]Loading train:  28%|██▊       | 75/266 [00:36<02:15,  1.41it/s]Loading train:  29%|██▊       | 76/266 [00:37<02:20,  1.35it/s]Loading train:  29%|██▉       | 77/266 [00:38<02:10,  1.45it/s]Loading train:  29%|██▉       | 78/266 [00:38<02:01,  1.54it/s]Loading train:  30%|██▉       | 79/266 [00:39<02:10,  1.44it/s]Loading train:  30%|███       | 80/266 [00:40<02:03,  1.51it/s]Loading train:  30%|███       | 81/266 [00:40<02:08,  1.44it/s]Loading train:  31%|███       | 82/266 [00:41<02:14,  1.37it/s]Loading train:  31%|███       | 83/266 [00:42<02:22,  1.29it/s]Loading train:  32%|███▏      | 84/266 [00:43<02:32,  1.19it/s]Loading train:  32%|███▏      | 85/266 [00:44<02:50,  1.06it/s]Loading train:  32%|███▏      | 86/266 [00:45<02:41,  1.11it/s]Loading train:  33%|███▎      | 87/266 [00:46<02:27,  1.21it/s]Loading train:  33%|███▎      | 88/266 [00:46<02:26,  1.22it/s]Loading train:  33%|███▎      | 89/266 [00:47<02:26,  1.21it/s]Loading train:  34%|███▍      | 90/266 [00:48<02:22,  1.23it/s]Loading train:  34%|███▍      | 91/266 [00:49<02:12,  1.32it/s]Loading train:  35%|███▍      | 92/266 [00:50<02:21,  1.23it/s]Loading train:  35%|███▍      | 93/266 [00:51<02:32,  1.13it/s]Loading train:  35%|███▌      | 94/266 [00:52<02:39,  1.08it/s]Loading train:  36%|███▌      | 95/266 [00:53<02:33,  1.11it/s]Loading train:  36%|███▌      | 96/266 [00:53<02:15,  1.26it/s]Loading train:  36%|███▋      | 97/266 [00:54<02:34,  1.09it/s]Loading train:  37%|███▋      | 98/266 [00:55<02:39,  1.05it/s]Loading train:  37%|███▋      | 99/266 [00:56<02:09,  1.29it/s]Loading train:  38%|███▊      | 100/266 [00:57<02:17,  1.21it/s]Loading train:  38%|███▊      | 101/266 [00:58<02:29,  1.10it/s]Loading train:  38%|███▊      | 102/266 [00:59<02:47,  1.02s/it]Loading train:  39%|███▊      | 103/266 [01:00<02:44,  1.01s/it]Loading train:  39%|███▉      | 104/266 [01:01<02:38,  1.02it/s]Loading train:  39%|███▉      | 105/266 [01:02<02:33,  1.05it/s]Loading train:  40%|███▉      | 106/266 [01:03<02:26,  1.09it/s]Loading train:  40%|████      | 107/266 [01:03<02:18,  1.15it/s]Loading train:  41%|████      | 108/266 [01:04<02:07,  1.23it/s]Loading train:  41%|████      | 109/266 [01:05<01:58,  1.32it/s]Loading train:  41%|████▏     | 110/266 [01:05<01:53,  1.37it/s]Loading train:  42%|████▏     | 111/266 [01:06<01:54,  1.36it/s]Loading train:  42%|████▏     | 112/266 [01:07<01:48,  1.42it/s]Loading train:  42%|████▏     | 113/266 [01:07<01:43,  1.48it/s]Loading train:  43%|████▎     | 114/266 [01:08<01:54,  1.33it/s]Loading train:  43%|████▎     | 115/266 [01:09<01:54,  1.31it/s]Loading train:  44%|████▎     | 116/266 [01:10<01:51,  1.35it/s]Loading train:  44%|████▍     | 117/266 [01:11<02:01,  1.22it/s]Loading train:  44%|████▍     | 118/266 [01:12<02:12,  1.12it/s]Loading train:  45%|████▍     | 119/266 [01:13<02:13,  1.10it/s]Loading train:  45%|████▌     | 120/266 [01:14<02:29,  1.02s/it]Loading train:  45%|████▌     | 121/266 [01:15<02:23,  1.01it/s]Loading train:  46%|████▌     | 122/266 [01:16<02:23,  1.00it/s]Loading train:  46%|████▌     | 123/266 [01:17<02:14,  1.06it/s]Loading train:  47%|████▋     | 124/266 [01:18<02:09,  1.10it/s]Loading train:  47%|████▋     | 125/266 [01:19<02:27,  1.04s/it]Loading train:  47%|████▋     | 126/266 [01:20<02:24,  1.03s/it]Loading train:  48%|████▊     | 127/266 [01:21<02:27,  1.06s/it]Loading train:  48%|████▊     | 128/266 [01:22<02:17,  1.01it/s]Loading train:  48%|████▊     | 129/266 [01:23<02:13,  1.03it/s]Loading train:  49%|████▉     | 130/266 [01:24<02:19,  1.02s/it]Loading train:  49%|████▉     | 131/266 [01:25<02:20,  1.04s/it]Loading train:  50%|████▉     | 132/266 [01:26<02:14,  1.00s/it]Loading train:  50%|█████     | 133/266 [01:27<02:13,  1.00s/it]Loading train:  50%|█████     | 134/266 [01:28<02:13,  1.01s/it]Loading train:  51%|█████     | 135/266 [01:29<02:18,  1.06s/it]Loading train:  51%|█████     | 136/266 [01:30<02:03,  1.06it/s]Loading train:  52%|█████▏    | 137/266 [01:31<01:57,  1.10it/s]Loading train:  52%|█████▏    | 138/266 [01:32<01:53,  1.13it/s]Loading train:  52%|█████▏    | 139/266 [01:32<01:45,  1.21it/s]Loading train:  53%|█████▎    | 140/266 [01:33<01:55,  1.09it/s]Loading train:  53%|█████▎    | 141/266 [01:34<01:47,  1.17it/s]Loading train:  53%|█████▎    | 142/266 [01:35<01:56,  1.07it/s]Loading train:  54%|█████▍    | 143/266 [01:36<02:00,  1.02it/s]Loading train:  54%|█████▍    | 144/266 [01:37<01:58,  1.03it/s]Loading train:  55%|█████▍    | 145/266 [01:38<02:05,  1.04s/it]Loading train:  55%|█████▍    | 146/266 [01:40<02:06,  1.05s/it]Loading train:  55%|█████▌    | 147/266 [01:41<02:08,  1.08s/it]Loading train:  56%|█████▌    | 148/266 [01:41<01:57,  1.01it/s]Loading train:  56%|█████▌    | 149/266 [01:42<01:54,  1.02it/s]Loading train:  56%|█████▋    | 150/266 [01:43<01:46,  1.09it/s]Loading train:  57%|█████▋    | 151/266 [01:44<01:36,  1.20it/s]Loading train:  57%|█████▋    | 152/266 [01:44<01:27,  1.30it/s]Loading train:  58%|█████▊    | 153/266 [01:45<01:18,  1.44it/s]Loading train:  58%|█████▊    | 154/266 [01:46<01:18,  1.43it/s]Loading train:  58%|█████▊    | 155/266 [01:47<01:22,  1.34it/s]Loading train:  59%|█████▊    | 156/266 [01:47<01:26,  1.27it/s]Loading train:  59%|█████▉    | 157/266 [01:49<01:39,  1.10it/s]Loading train:  59%|█████▉    | 158/266 [01:50<01:45,  1.03it/s]Loading train:  60%|█████▉    | 159/266 [01:51<01:53,  1.06s/it]Loading train:  60%|██████    | 160/266 [01:52<01:45,  1.00it/s]Loading train:  61%|██████    | 161/266 [01:53<01:41,  1.03it/s]Loading train:  61%|██████    | 162/266 [01:54<01:41,  1.03it/s]Loading train:  61%|██████▏   | 163/266 [01:55<01:45,  1.02s/it]Loading train:  62%|██████▏   | 164/266 [01:56<01:43,  1.02s/it]Loading train:  62%|██████▏   | 165/266 [01:57<01:43,  1.03s/it]Loading train:  62%|██████▏   | 166/266 [01:58<01:44,  1.04s/it]Loading train:  63%|██████▎   | 167/266 [01:59<01:43,  1.04s/it]Loading train:  63%|██████▎   | 168/266 [02:00<01:45,  1.08s/it]Loading train:  64%|██████▎   | 169/266 [02:01<01:42,  1.06s/it]Loading train:  64%|██████▍   | 170/266 [02:02<01:44,  1.09s/it]Loading train:  64%|██████▍   | 171/266 [02:03<01:39,  1.05s/it]Loading train:  65%|██████▍   | 172/266 [02:05<01:41,  1.08s/it]Loading train:  65%|██████▌   | 173/266 [02:05<01:36,  1.04s/it]Loading train:  65%|██████▌   | 174/266 [02:06<01:26,  1.06it/s]Loading train:  66%|██████▌   | 175/266 [02:07<01:28,  1.03it/s]Loading train:  66%|██████▌   | 176/266 [02:08<01:19,  1.14it/s]Loading train:  67%|██████▋   | 177/266 [02:08<01:09,  1.27it/s]Loading train:  67%|██████▋   | 178/266 [02:09<01:11,  1.23it/s]Loading train:  67%|██████▋   | 179/266 [02:10<01:14,  1.17it/s]Loading train:  68%|██████▊   | 180/266 [02:11<01:11,  1.21it/s]Loading train:  68%|██████▊   | 181/266 [02:12<01:11,  1.18it/s]Loading train:  68%|██████▊   | 182/266 [02:13<01:08,  1.23it/s]Loading train:  69%|██████▉   | 183/266 [02:13<01:05,  1.27it/s]Loading train:  69%|██████▉   | 184/266 [02:14<01:04,  1.27it/s]Loading train:  70%|██████▉   | 185/266 [02:15<00:59,  1.36it/s]Loading train:  70%|██████▉   | 186/266 [02:16<01:03,  1.26it/s]Loading train:  70%|███████   | 187/266 [02:17<01:05,  1.21it/s]Loading train:  71%|███████   | 188/266 [02:18<01:07,  1.16it/s]Loading train:  71%|███████   | 189/266 [02:18<01:06,  1.15it/s]Loading train:  71%|███████▏  | 190/266 [02:19<00:59,  1.28it/s]Loading train:  72%|███████▏  | 191/266 [02:20<00:57,  1.30it/s]Loading train:  72%|███████▏  | 192/266 [02:20<00:55,  1.33it/s]Loading train:  73%|███████▎  | 193/266 [02:21<00:54,  1.34it/s]Loading train:  73%|███████▎  | 194/266 [02:22<00:55,  1.29it/s]Loading train:  73%|███████▎  | 195/266 [02:23<01:01,  1.16it/s]Loading train:  74%|███████▎  | 196/266 [02:24<01:05,  1.06it/s]Loading train:  74%|███████▍  | 197/266 [02:25<01:06,  1.03it/s]Loading train:  74%|███████▍  | 198/266 [02:27<01:13,  1.08s/it]Loading train:  75%|███████▍  | 199/266 [02:27<01:01,  1.09it/s]Loading train:  75%|███████▌  | 200/266 [02:28<01:02,  1.05it/s]Loading train:  76%|███████▌  | 201/266 [02:29<01:03,  1.03it/s]Loading train:  76%|███████▌  | 202/266 [02:30<01:02,  1.03it/s]Loading train:  76%|███████▋  | 203/266 [02:31<01:01,  1.03it/s]Loading train:  77%|███████▋  | 204/266 [02:32<01:00,  1.03it/s]Loading train:  77%|███████▋  | 205/266 [02:33<00:57,  1.07it/s]Loading train:  77%|███████▋  | 206/266 [02:34<00:59,  1.01it/s]Loading train:  78%|███████▊  | 207/266 [02:35<00:52,  1.12it/s]Loading train:  78%|███████▊  | 208/266 [02:36<00:51,  1.14it/s]Loading train:  79%|███████▊  | 209/266 [02:37<00:51,  1.12it/s]Loading train:  79%|███████▉  | 210/266 [02:38<00:51,  1.08it/s]Loading train:  79%|███████▉  | 211/266 [02:39<00:52,  1.05it/s]Loading train:  80%|███████▉  | 212/266 [02:40<00:52,  1.02it/s]Loading train:  80%|████████  | 213/266 [02:40<00:49,  1.08it/s]Loading train:  80%|████████  | 214/266 [02:42<00:51,  1.00it/s]Loading train:  81%|████████  | 215/266 [02:43<00:51,  1.01s/it]Loading train:  81%|████████  | 216/266 [02:44<00:51,  1.02s/it]Loading train:  82%|████████▏ | 217/266 [02:45<00:53,  1.09s/it]Loading train:  82%|████████▏ | 218/266 [02:46<00:49,  1.03s/it]Loading train:  82%|████████▏ | 219/266 [02:47<00:50,  1.07s/it]Loading train:  83%|████████▎ | 220/266 [02:48<00:50,  1.11s/it]Loading train:  83%|████████▎ | 221/266 [02:49<00:48,  1.08s/it]Loading train:  83%|████████▎ | 222/266 [02:50<00:46,  1.05s/it]Loading train:  84%|████████▍ | 223/266 [02:51<00:44,  1.02s/it]Loading train:  84%|████████▍ | 224/266 [02:52<00:40,  1.04it/s]Loading train:  85%|████████▍ | 225/266 [02:53<00:40,  1.01it/s]Loading train:  85%|████████▍ | 226/266 [02:54<00:39,  1.02it/s]Loading train:  85%|████████▌ | 227/266 [02:55<00:39,  1.00s/it]Loading train:  86%|████████▌ | 228/266 [02:56<00:37,  1.00it/s]Loading train:  86%|████████▌ | 229/266 [02:57<00:37,  1.01s/it]Loading train:  86%|████████▋ | 230/266 [02:58<00:37,  1.05s/it]Loading train:  87%|████████▋ | 231/266 [02:59<00:37,  1.08s/it]Loading train:  87%|████████▋ | 232/266 [03:00<00:37,  1.09s/it]Loading train:  88%|████████▊ | 233/266 [03:02<00:36,  1.11s/it]Loading train:  88%|████████▊ | 234/266 [03:02<00:30,  1.06it/s]Loading train:  88%|████████▊ | 235/266 [03:03<00:28,  1.07it/s]Loading train:  89%|████████▊ | 236/266 [03:04<00:27,  1.09it/s]Loading train:  89%|████████▉ | 237/266 [03:05<00:27,  1.06it/s]Loading train:  89%|████████▉ | 238/266 [03:06<00:26,  1.05it/s]Loading train:  90%|████████▉ | 239/266 [03:07<00:26,  1.01it/s]Loading train:  90%|█████████ | 240/266 [03:08<00:26,  1.00s/it]Loading train:  91%|█████████ | 241/266 [03:09<00:26,  1.04s/it]Loading train:  91%|█████████ | 242/266 [03:10<00:24,  1.03s/it]Loading train:  91%|█████████▏| 243/266 [03:11<00:24,  1.07s/it]Loading train:  92%|█████████▏| 244/266 [03:12<00:24,  1.09s/it]Loading train:  92%|█████████▏| 245/266 [03:13<00:22,  1.06s/it]Loading train:  92%|█████████▏| 246/266 [03:15<00:21,  1.07s/it]Loading train:  93%|█████████▎| 247/266 [03:16<00:20,  1.08s/it]Loading train:  93%|█████████▎| 248/266 [03:17<00:18,  1.05s/it]Loading train:  94%|█████████▎| 249/266 [03:17<00:16,  1.01it/s]Loading train:  94%|█████████▍| 250/266 [03:19<00:16,  1.03s/it]Loading train:  94%|█████████▍| 251/266 [03:20<00:15,  1.06s/it]Loading train:  95%|█████████▍| 252/266 [03:21<00:14,  1.02s/it]Loading train:  95%|█████████▌| 253/266 [03:22<00:13,  1.07s/it]Loading train:  95%|█████████▌| 254/266 [03:23<00:12,  1.04s/it]Loading train:  96%|█████████▌| 255/266 [03:24<00:10,  1.07it/s]Loading train:  96%|█████████▌| 256/266 [03:24<00:09,  1.09it/s]Loading train:  97%|█████████▋| 257/266 [03:25<00:07,  1.14it/s]Loading train:  97%|█████████▋| 258/266 [03:26<00:06,  1.19it/s]Loading train:  97%|█████████▋| 259/266 [03:27<00:05,  1.27it/s]Loading train:  98%|█████████▊| 260/266 [03:28<00:04,  1.21it/s]Loading train:  98%|█████████▊| 261/266 [03:28<00:04,  1.15it/s]Loading train:  98%|█████████▊| 262/266 [03:30<00:03,  1.08it/s]Loading train:  99%|█████████▉| 263/266 [03:31<00:02,  1.01it/s]Loading train:  99%|█████████▉| 264/266 [03:32<00:02,  1.01s/it]Loading train: 100%|█████████▉| 265/266 [03:33<00:01,  1.06s/it]Loading train: 100%|██████████| 266/266 [03:34<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:36,  7.16it/s]concatenating: train:   1%|          | 2/266 [00:00<00:36,  7.31it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:29,  8.91it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:24, 10.42it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:26,  9.69it/s]concatenating: train:   5%|▍         | 12/266 [00:01<00:27,  9.29it/s]concatenating: train:   5%|▍         | 13/266 [00:01<00:29,  8.61it/s]concatenating: train:   6%|▌         | 15/266 [00:01<00:24, 10.25it/s]concatenating: train:   7%|▋         | 19/266 [00:01<00:19, 12.84it/s]concatenating: train:   8%|▊         | 22/266 [00:01<00:15, 15.32it/s]concatenating: train:   9%|▉         | 25/266 [00:01<00:18, 13.35it/s]concatenating: train:  10%|█         | 27/266 [00:01<00:17, 13.72it/s]concatenating: train:  11%|█         | 29/266 [00:02<00:18, 12.83it/s]concatenating: train:  12%|█▏        | 31/266 [00:02<00:18, 12.63it/s]concatenating: train:  12%|█▏        | 33/266 [00:02<00:17, 13.39it/s]concatenating: train:  14%|█▎        | 36/266 [00:02<00:16, 14.15it/s]concatenating: train:  14%|█▍        | 38/266 [00:02<00:20, 11.31it/s]concatenating: train:  15%|█▌        | 40/266 [00:03<00:22, 10.22it/s]concatenating: train:  16%|█▌        | 42/266 [00:03<00:22,  9.79it/s]concatenating: train:  17%|█▋        | 44/266 [00:03<00:23,  9.25it/s]concatenating: train:  17%|█▋        | 46/266 [00:03<00:20, 10.67it/s]concatenating: train:  18%|█▊        | 48/266 [00:03<00:17, 12.41it/s]concatenating: train:  19%|█▉        | 51/266 [00:03<00:14, 14.88it/s]concatenating: train:  20%|██        | 54/266 [00:04<00:13, 15.47it/s]concatenating: train:  21%|██        | 56/266 [00:04<00:14, 14.17it/s]concatenating: train:  22%|██▏       | 58/266 [00:04<00:15, 13.43it/s]concatenating: train:  23%|██▎       | 60/266 [00:04<00:14, 13.90it/s]concatenating: train:  23%|██▎       | 62/266 [00:04<00:13, 15.02it/s]concatenating: train:  24%|██▍       | 65/266 [00:04<00:11, 17.30it/s]concatenating: train:  26%|██▌       | 68/266 [00:04<00:10, 19.20it/s]concatenating: train:  27%|██▋       | 71/266 [00:05<00:12, 15.43it/s]concatenating: train:  27%|██▋       | 73/266 [00:05<00:14, 13.16it/s]concatenating: train:  28%|██▊       | 75/266 [00:05<00:17, 11.21it/s]concatenating: train:  29%|██▉       | 77/266 [00:05<00:17, 10.54it/s]concatenating: train:  30%|███       | 81/266 [00:05<00:14, 13.21it/s]concatenating: train:  32%|███▏      | 84/266 [00:06<00:12, 14.25it/s]concatenating: train:  32%|███▏      | 86/266 [00:06<00:14, 12.73it/s]concatenating: train:  33%|███▎      | 88/266 [00:06<00:15, 11.45it/s]concatenating: train:  34%|███▍      | 90/266 [00:06<00:17, 10.11it/s]concatenating: train:  35%|███▍      | 92/266 [00:06<00:15, 11.03it/s]concatenating: train:  45%|████▌     | 120/266 [00:07<00:09, 15.49it/s]concatenating: train:  49%|████▉     | 130/266 [00:07<00:07, 17.12it/s]concatenating: train:  52%|█████▏    | 138/266 [00:08<00:08, 14.99it/s]concatenating: train:  63%|██████▎   | 167/266 [00:08<00:04, 20.93it/s]concatenating: train:  69%|██████▉   | 184/266 [00:08<00:02, 28.37it/s]concatenating: train:  74%|███████▍  | 198/266 [00:09<00:03, 21.00it/s]concatenating: train:  80%|████████  | 213/266 [00:09<00:01, 28.09it/s]concatenating: train:  84%|████████▍ | 224/266 [00:10<00:02, 18.89it/s]concatenating: train:  96%|█████████▌| 256/266 [00:10<00:00, 26.31it/s]concatenating: train: 100%|██████████| 266/266 [00:11<00:00, 23.11it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.23it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.12it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.05it/s]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.01s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  5.69it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  6.15it/s]concatenating: validation:  60%|██████    | 3/5 [00:00<00:00,  6.57it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  6.68it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  6.92it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:01<04:29,  1.02s/it]Loading trainS:   1%|          | 2/266 [00:02<04:41,  1.07s/it]Loading trainS:   1%|          | 3/266 [00:03<04:25,  1.01s/it]Loading trainS:   2%|▏         | 4/266 [00:04<04:32,  1.04s/it]Loading trainS:   2%|▏         | 5/266 [00:04<04:11,  1.04it/s]Loading trainS:   2%|▏         | 6/266 [00:05<03:56,  1.10it/s]Loading trainS:   3%|▎         | 7/266 [00:06<04:10,  1.03it/s]Loading trainS:   3%|▎         | 8/266 [00:07<04:21,  1.01s/it]Loading trainS:   3%|▎         | 9/266 [00:08<04:07,  1.04it/s]Loading trainS:   4%|▍         | 10/266 [00:09<03:32,  1.20it/s]Loading trainS:   4%|▍         | 11/266 [00:10<03:44,  1.14it/s]Loading trainS:   5%|▍         | 12/266 [00:11<03:29,  1.21it/s]Loading trainS:   5%|▍         | 13/266 [00:11<03:19,  1.27it/s]Loading trainS:   5%|▌         | 14/266 [00:12<03:08,  1.34it/s]Loading trainS:   6%|▌         | 15/266 [00:13<03:10,  1.32it/s]Loading trainS:   6%|▌         | 16/266 [00:13<03:02,  1.37it/s]Loading trainS:   6%|▋         | 17/266 [00:14<03:02,  1.37it/s]Loading trainS:   7%|▋         | 18/266 [00:15<03:03,  1.35it/s]Loading trainS:   7%|▋         | 19/266 [00:16<03:13,  1.28it/s]Loading trainS:   8%|▊         | 20/266 [00:17<03:35,  1.14it/s]Loading trainS:   8%|▊         | 21/266 [00:18<04:06,  1.01s/it]Loading trainS:   8%|▊         | 22/266 [00:19<04:11,  1.03s/it]Loading trainS:   9%|▊         | 23/266 [00:20<04:20,  1.07s/it]Loading trainS:   9%|▉         | 24/266 [00:21<04:19,  1.07s/it]Loading trainS:   9%|▉         | 25/266 [00:23<04:21,  1.08s/it]Loading trainS:  10%|▉         | 26/266 [00:24<04:22,  1.09s/it]Loading trainS:  10%|█         | 27/266 [00:25<04:33,  1.14s/it]Loading trainS:  11%|█         | 28/266 [00:26<04:21,  1.10s/it]Loading trainS:  11%|█         | 29/266 [00:27<03:59,  1.01s/it]Loading trainS:  11%|█▏        | 30/266 [00:28<03:55,  1.00it/s]Loading trainS:  12%|█▏        | 31/266 [00:29<04:08,  1.06s/it]Loading trainS:  12%|█▏        | 32/266 [00:30<04:08,  1.06s/it]Loading trainS:  12%|█▏        | 33/266 [00:31<04:27,  1.15s/it]Loading trainS:  13%|█▎        | 34/266 [00:33<04:38,  1.20s/it]Loading trainS:  13%|█▎        | 35/266 [00:34<04:38,  1.21s/it]Loading trainS:  14%|█▎        | 36/266 [00:35<04:30,  1.18s/it]Loading trainS:  14%|█▍        | 37/266 [00:36<04:29,  1.18s/it]Loading trainS:  14%|█▍        | 38/266 [00:37<04:37,  1.22s/it]Loading trainS:  15%|█▍        | 39/266 [00:39<04:25,  1.17s/it]Loading trainS:  15%|█▌        | 40/266 [00:39<03:49,  1.02s/it]Loading trainS:  15%|█▌        | 41/266 [00:40<03:08,  1.19it/s]Loading trainS:  16%|█▌        | 42/266 [00:40<03:05,  1.21it/s]Loading trainS:  16%|█▌        | 43/266 [00:41<02:59,  1.24it/s]Loading trainS:  17%|█▋        | 44/266 [00:42<02:54,  1.27it/s]Loading trainS:  17%|█▋        | 45/266 [00:42<02:38,  1.39it/s]Loading trainS:  17%|█▋        | 46/266 [00:43<02:51,  1.28it/s]Loading trainS:  18%|█▊        | 47/266 [00:44<03:10,  1.15it/s]Loading trainS:  18%|█▊        | 48/266 [00:46<03:21,  1.08it/s]Loading trainS:  18%|█▊        | 49/266 [00:46<02:46,  1.30it/s]Loading trainS:  19%|█▉        | 50/266 [00:47<02:47,  1.29it/s]Loading trainS:  19%|█▉        | 51/266 [00:48<03:08,  1.14it/s]Loading trainS:  20%|█▉        | 52/266 [00:49<03:02,  1.17it/s]Loading trainS:  20%|█▉        | 53/266 [00:50<03:07,  1.14it/s]Loading trainS:  20%|██        | 54/266 [00:50<03:08,  1.13it/s]Loading trainS:  21%|██        | 55/266 [00:52<03:19,  1.06it/s]Loading trainS:  21%|██        | 56/266 [00:53<03:23,  1.03it/s]Loading trainS:  21%|██▏       | 57/266 [00:54<03:26,  1.01it/s]Loading trainS:  22%|██▏       | 58/266 [00:55<03:27,  1.00it/s]Loading trainS:  22%|██▏       | 59/266 [00:56<03:22,  1.02it/s]Loading trainS:  23%|██▎       | 60/266 [00:56<03:01,  1.13it/s]Loading trainS:  23%|██▎       | 61/266 [00:57<02:42,  1.26it/s]Loading trainS:  23%|██▎       | 62/266 [00:58<02:40,  1.27it/s]Loading trainS:  24%|██▎       | 63/266 [00:58<02:26,  1.38it/s]Loading trainS:  24%|██▍       | 64/266 [00:59<02:21,  1.43it/s]Loading trainS:  24%|██▍       | 65/266 [01:00<02:21,  1.42it/s]Loading trainS:  25%|██▍       | 66/266 [01:00<02:12,  1.51it/s]Loading trainS:  25%|██▌       | 67/266 [01:01<02:20,  1.42it/s]Loading trainS:  26%|██▌       | 68/266 [01:02<02:42,  1.22it/s]Loading trainS:  26%|██▌       | 69/266 [01:03<02:58,  1.10it/s]Loading trainS:  26%|██▋       | 70/266 [01:04<02:57,  1.10it/s]Loading trainS:  27%|██▋       | 71/266 [01:05<03:04,  1.05it/s]Loading trainS:  27%|██▋       | 72/266 [01:06<03:10,  1.02it/s]Loading trainS:  27%|██▋       | 73/266 [01:07<03:19,  1.04s/it]Loading trainS:  28%|██▊       | 74/266 [01:08<02:50,  1.13it/s]Loading trainS:  28%|██▊       | 75/266 [01:09<03:01,  1.05it/s]Loading trainS:  29%|██▊       | 76/266 [01:10<03:02,  1.04it/s]Loading trainS:  29%|██▉       | 77/266 [01:11<03:03,  1.03it/s]Loading trainS:  29%|██▉       | 78/266 [01:12<03:08,  1.01s/it]Loading trainS:  30%|██▉       | 79/266 [01:13<02:52,  1.08it/s]Loading trainS:  30%|███       | 80/266 [01:13<02:38,  1.17it/s]Loading trainS:  30%|███       | 81/266 [01:14<02:32,  1.22it/s]Loading trainS:  31%|███       | 82/266 [01:15<02:15,  1.36it/s]Loading trainS:  31%|███       | 83/266 [01:16<02:22,  1.28it/s]Loading trainS:  32%|███▏      | 84/266 [01:16<02:12,  1.38it/s]Loading trainS:  32%|███▏      | 85/266 [01:17<02:16,  1.33it/s]Loading trainS:  32%|███▏      | 86/266 [01:18<02:15,  1.33it/s]Loading trainS:  33%|███▎      | 87/266 [01:19<02:27,  1.22it/s]Loading trainS:  33%|███▎      | 88/266 [01:19<02:21,  1.26it/s]Loading trainS:  33%|███▎      | 89/266 [01:20<02:12,  1.34it/s]Loading trainS:  34%|███▍      | 90/266 [01:21<02:08,  1.37it/s]Loading trainS:  34%|███▍      | 91/266 [01:21<02:07,  1.37it/s]Loading trainS:  35%|███▍      | 92/266 [01:22<02:05,  1.39it/s]Loading trainS:  35%|███▍      | 93/266 [01:23<02:12,  1.31it/s]Loading trainS:  35%|███▌      | 94/266 [01:24<02:08,  1.34it/s]Loading trainS:  36%|███▌      | 95/266 [01:25<02:09,  1.32it/s]Loading trainS:  36%|███▌      | 96/266 [01:25<02:16,  1.24it/s]Loading trainS:  36%|███▋      | 97/266 [01:26<02:25,  1.16it/s]Loading trainS:  37%|███▋      | 98/266 [01:28<02:36,  1.07it/s]Loading trainS:  37%|███▋      | 99/266 [01:28<02:32,  1.10it/s]Loading trainS:  38%|███▊      | 100/266 [01:30<02:45,  1.00it/s]Loading trainS:  38%|███▊      | 101/266 [01:31<02:51,  1.04s/it]Loading trainS:  38%|███▊      | 102/266 [01:32<02:48,  1.03s/it]Loading trainS:  39%|███▊      | 103/266 [01:33<02:42,  1.00it/s]Loading trainS:  39%|███▉      | 104/266 [01:34<02:51,  1.06s/it]Loading trainS:  39%|███▉      | 105/266 [01:35<02:55,  1.09s/it]Loading trainS:  40%|███▉      | 106/266 [01:36<02:45,  1.03s/it]Loading trainS:  40%|████      | 107/266 [01:37<02:39,  1.00s/it]Loading trainS:  41%|████      | 108/266 [01:38<02:36,  1.01it/s]Loading trainS:  41%|████      | 109/266 [01:39<02:26,  1.07it/s]Loading trainS:  41%|████▏     | 110/266 [01:40<02:36,  1.00s/it]Loading trainS:  42%|████▏     | 111/266 [01:41<02:39,  1.03s/it]Loading trainS:  42%|████▏     | 112/266 [01:42<02:44,  1.07s/it]Loading trainS:  42%|████▏     | 113/266 [01:43<02:42,  1.06s/it]Loading trainS:  43%|████▎     | 114/266 [01:44<02:41,  1.06s/it]Loading trainS:  43%|████▎     | 115/266 [01:45<02:30,  1.00it/s]Loading trainS:  44%|████▎     | 116/266 [01:46<02:28,  1.01it/s]Loading trainS:  44%|████▍     | 117/266 [01:47<02:34,  1.04s/it]Loading trainS:  44%|████▍     | 118/266 [01:48<02:36,  1.05s/it]Loading trainS:  45%|████▍     | 119/266 [01:49<02:44,  1.12s/it]Loading trainS:  45%|████▌     | 120/266 [01:50<02:29,  1.03s/it]Loading trainS:  45%|████▌     | 121/266 [01:52<02:38,  1.10s/it]Loading trainS:  46%|████▌     | 122/266 [01:53<02:33,  1.07s/it]Loading trainS:  46%|████▌     | 123/266 [01:53<02:19,  1.03it/s]Loading trainS:  47%|████▋     | 124/266 [01:54<02:22,  1.00s/it]Loading trainS:  47%|████▋     | 125/266 [01:56<02:31,  1.08s/it]Loading trainS:  47%|████▋     | 126/266 [01:56<02:12,  1.05it/s]Loading trainS:  48%|████▊     | 127/266 [01:57<02:07,  1.09it/s]Loading trainS:  48%|████▊     | 128/266 [01:58<02:14,  1.02it/s]Loading trainS:  48%|████▊     | 129/266 [01:59<02:16,  1.00it/s]Loading trainS:  49%|████▉     | 130/266 [02:00<02:17,  1.01s/it]Loading trainS:  49%|████▉     | 131/266 [02:02<02:27,  1.09s/it]Loading trainS:  50%|████▉     | 132/266 [02:03<02:30,  1.13s/it]Loading trainS:  50%|█████     | 133/266 [02:04<02:28,  1.12s/it]Loading trainS:  50%|█████     | 134/266 [02:05<02:30,  1.14s/it]Loading trainS:  51%|█████     | 135/266 [02:06<02:16,  1.04s/it]Loading trainS:  51%|█████     | 136/266 [02:07<02:05,  1.04it/s]Loading trainS:  52%|█████▏    | 137/266 [02:07<01:51,  1.16it/s]Loading trainS:  52%|█████▏    | 138/266 [02:08<01:49,  1.17it/s]Loading trainS:  52%|█████▏    | 139/266 [02:09<01:43,  1.23it/s]Loading trainS:  53%|█████▎    | 140/266 [02:10<01:39,  1.26it/s]Loading trainS:  53%|█████▎    | 141/266 [02:11<01:43,  1.20it/s]Loading trainS:  53%|█████▎    | 142/266 [02:11<01:45,  1.17it/s]Loading trainS:  54%|█████▍    | 143/266 [02:12<01:43,  1.18it/s]Loading trainS:  54%|█████▍    | 144/266 [02:13<01:46,  1.15it/s]Loading trainS:  55%|█████▍    | 145/266 [02:14<01:52,  1.08it/s]Loading trainS:  55%|█████▍    | 146/266 [02:15<01:57,  1.02it/s]Loading trainS:  55%|█████▌    | 147/266 [02:17<02:02,  1.03s/it]Loading trainS:  56%|█████▌    | 148/266 [02:18<02:06,  1.08s/it]Loading trainS:  56%|█████▌    | 149/266 [02:19<02:01,  1.04s/it]Loading trainS:  56%|█████▋    | 150/266 [02:20<01:57,  1.01s/it]Loading trainS:  57%|█████▋    | 151/266 [02:21<02:03,  1.08s/it]Loading trainS:  57%|█████▋    | 152/266 [02:22<01:58,  1.04s/it]Loading trainS:  58%|█████▊    | 153/266 [02:23<01:56,  1.03s/it]Loading trainS:  58%|█████▊    | 154/266 [02:24<01:53,  1.01s/it]Loading trainS:  58%|█████▊    | 155/266 [02:25<01:50,  1.00it/s]Loading trainS:  59%|█████▊    | 156/266 [02:26<01:49,  1.00it/s]Loading trainS:  59%|█████▉    | 157/266 [02:27<01:46,  1.02it/s]Loading trainS:  59%|█████▉    | 158/266 [02:28<01:48,  1.00s/it]Loading trainS:  60%|█████▉    | 159/266 [02:29<01:46,  1.01it/s]Loading trainS:  60%|██████    | 160/266 [02:30<01:40,  1.05it/s]Loading trainS:  61%|██████    | 161/266 [02:30<01:37,  1.08it/s]Loading trainS:  61%|██████    | 162/266 [02:31<01:20,  1.30it/s]Loading trainS:  61%|██████▏   | 163/266 [02:32<01:29,  1.15it/s]Loading trainS:  62%|██████▏   | 164/266 [02:33<01:33,  1.09it/s]Loading trainS:  62%|██████▏   | 165/266 [02:34<01:27,  1.15it/s]Loading trainS:  62%|██████▏   | 166/266 [02:34<01:14,  1.34it/s]Loading trainS:  63%|██████▎   | 167/266 [02:35<01:08,  1.45it/s]Loading trainS:  63%|██████▎   | 168/266 [02:35<01:06,  1.48it/s]Loading trainS:  64%|██████▎   | 169/266 [02:36<01:01,  1.57it/s]Loading trainS:  64%|██████▍   | 170/266 [02:37<01:06,  1.43it/s]Loading trainS:  64%|██████▍   | 171/266 [02:38<01:15,  1.26it/s]Loading trainS:  65%|██████▍   | 172/266 [02:38<01:12,  1.30it/s]Loading trainS:  65%|██████▌   | 173/266 [02:39<01:07,  1.38it/s]Loading trainS:  65%|██████▌   | 174/266 [02:40<01:02,  1.47it/s]Loading trainS:  66%|██████▌   | 175/266 [02:41<01:09,  1.30it/s]Loading trainS:  66%|██████▌   | 176/266 [02:42<01:18,  1.15it/s]Loading trainS:  67%|██████▋   | 177/266 [02:42<01:12,  1.22it/s]Loading trainS:  67%|██████▋   | 178/266 [02:43<01:14,  1.18it/s]Loading trainS:  67%|██████▋   | 179/266 [02:44<01:19,  1.10it/s]Loading trainS:  68%|██████▊   | 180/266 [02:45<01:14,  1.15it/s]Loading trainS:  68%|██████▊   | 181/266 [02:46<01:10,  1.21it/s]Loading trainS:  68%|██████▊   | 182/266 [02:47<01:08,  1.23it/s]Loading trainS:  69%|██████▉   | 183/266 [02:48<01:14,  1.11it/s]Loading trainS:  69%|██████▉   | 184/266 [02:49<01:18,  1.04it/s]Loading trainS:  70%|██████▉   | 185/266 [02:50<01:21,  1.01s/it]Loading trainS:  70%|██████▉   | 186/266 [02:51<01:23,  1.04s/it]Loading trainS:  70%|███████   | 187/266 [02:52<01:15,  1.05it/s]Loading trainS:  71%|███████   | 188/266 [02:53<01:12,  1.08it/s]Loading trainS:  71%|███████   | 189/266 [02:54<01:07,  1.14it/s]Loading trainS:  71%|███████▏  | 190/266 [02:54<01:05,  1.16it/s]Loading trainS:  72%|███████▏  | 191/266 [02:55<01:05,  1.14it/s]Loading trainS:  72%|███████▏  | 192/266 [02:56<01:10,  1.05it/s]Loading trainS:  73%|███████▎  | 193/266 [02:57<01:10,  1.04it/s]Loading trainS:  73%|███████▎  | 194/266 [02:59<01:15,  1.05s/it]Loading trainS:  73%|███████▎  | 195/266 [03:00<01:13,  1.03s/it]Loading trainS:  74%|███████▎  | 196/266 [03:00<01:07,  1.04it/s]Loading trainS:  74%|███████▍  | 197/266 [03:01<01:06,  1.03it/s]Loading trainS:  74%|███████▍  | 198/266 [03:03<01:09,  1.02s/it]Loading trainS:  75%|███████▍  | 199/266 [03:04<01:07,  1.01s/it]Loading trainS:  75%|███████▌  | 200/266 [03:04<01:03,  1.04it/s]Loading trainS:  76%|███████▌  | 201/266 [03:06<01:05,  1.01s/it]Loading trainS:  76%|███████▌  | 202/266 [03:06<00:58,  1.10it/s]Loading trainS:  76%|███████▋  | 203/266 [03:07<00:57,  1.09it/s]Loading trainS:  77%|███████▋  | 204/266 [03:08<00:54,  1.13it/s]Loading trainS:  77%|███████▋  | 205/266 [03:09<00:53,  1.14it/s]Loading trainS:  77%|███████▋  | 206/266 [03:10<00:58,  1.02it/s]Loading trainS:  78%|███████▊  | 207/266 [03:11<01:02,  1.05s/it]Loading trainS:  78%|███████▊  | 208/266 [03:12<01:03,  1.09s/it]Loading trainS:  79%|███████▊  | 209/266 [03:13<00:54,  1.05it/s]Loading trainS:  79%|███████▉  | 210/266 [03:14<00:54,  1.03it/s]Loading trainS:  79%|███████▉  | 211/266 [03:15<00:55,  1.00s/it]Loading trainS:  80%|███████▉  | 212/266 [03:16<00:56,  1.05s/it]Loading trainS:  80%|████████  | 213/266 [03:17<00:55,  1.04s/it]Loading trainS:  80%|████████  | 214/266 [03:18<00:47,  1.11it/s]Loading trainS:  81%|████████  | 215/266 [03:19<00:44,  1.13it/s]Loading trainS:  81%|████████  | 216/266 [03:19<00:39,  1.28it/s]Loading trainS:  82%|████████▏ | 217/266 [03:20<00:42,  1.17it/s]Loading trainS:  82%|████████▏ | 218/266 [03:21<00:43,  1.11it/s]Loading trainS:  82%|████████▏ | 219/266 [03:22<00:38,  1.22it/s]Loading trainS:  83%|████████▎ | 220/266 [03:23<00:36,  1.28it/s]Loading trainS:  83%|████████▎ | 221/266 [03:24<00:40,  1.12it/s]Loading trainS:  83%|████████▎ | 222/266 [03:25<00:44,  1.00s/it]Loading trainS:  84%|████████▍ | 223/266 [03:26<00:39,  1.08it/s]Loading trainS:  84%|████████▍ | 224/266 [03:27<00:36,  1.16it/s]Loading trainS:  85%|████████▍ | 225/266 [03:28<00:37,  1.08it/s]Loading trainS:  85%|████████▍ | 226/266 [03:29<00:38,  1.04it/s]Loading trainS:  85%|████████▌ | 227/266 [03:30<00:38,  1.02it/s]Loading trainS:  86%|████████▌ | 228/266 [03:31<00:40,  1.07s/it]Loading trainS:  86%|████████▌ | 229/266 [03:32<00:39,  1.06s/it]Loading trainS:  86%|████████▋ | 230/266 [03:33<00:37,  1.03s/it]Loading trainS:  87%|████████▋ | 231/266 [03:34<00:36,  1.05s/it]Loading trainS:  87%|████████▋ | 232/266 [03:35<00:36,  1.08s/it]Loading trainS:  88%|████████▊ | 233/266 [03:36<00:33,  1.02s/it]Loading trainS:  88%|████████▊ | 234/266 [03:37<00:32,  1.02s/it]Loading trainS:  88%|████████▊ | 235/266 [03:38<00:31,  1.03s/it]Loading trainS:  89%|████████▊ | 236/266 [03:39<00:31,  1.03s/it]Loading trainS:  89%|████████▉ | 237/266 [03:40<00:26,  1.08it/s]Loading trainS:  89%|████████▉ | 238/266 [03:41<00:27,  1.01it/s]Loading trainS:  90%|████████▉ | 239/266 [03:42<00:27,  1.02s/it]Loading trainS:  90%|█████████ | 240/266 [03:43<00:27,  1.06s/it]Loading trainS:  91%|█████████ | 241/266 [03:44<00:27,  1.11s/it]Loading trainS:  91%|█████████ | 242/266 [03:45<00:25,  1.07s/it]Loading trainS:  91%|█████████▏| 243/266 [03:46<00:24,  1.05s/it]Loading trainS:  92%|█████████▏| 244/266 [03:47<00:21,  1.04it/s]Loading trainS:  92%|█████████▏| 245/266 [03:48<00:21,  1.01s/it]Loading trainS:  92%|█████████▏| 246/266 [03:49<00:20,  1.02s/it]Loading trainS:  93%|█████████▎| 247/266 [03:50<00:19,  1.03s/it]Loading trainS:  93%|█████████▎| 248/266 [03:52<00:18,  1.05s/it]Loading trainS:  94%|█████████▎| 249/266 [03:53<00:17,  1.04s/it]Loading trainS:  94%|█████████▍| 250/266 [03:54<00:16,  1.05s/it]Loading trainS:  94%|█████████▍| 251/266 [03:55<00:17,  1.14s/it]Loading trainS:  95%|█████████▍| 252/266 [03:56<00:15,  1.12s/it]Loading trainS:  95%|█████████▌| 253/266 [03:57<00:14,  1.12s/it]Loading trainS:  95%|█████████▌| 254/266 [03:58<00:13,  1.12s/it]Loading trainS:  96%|█████████▌| 255/266 [03:59<00:12,  1.13s/it]Loading trainS:  96%|█████████▌| 256/266 [04:01<00:11,  1.19s/it]Loading trainS:  97%|█████████▋| 257/266 [04:02<00:10,  1.14s/it]Loading trainS:  97%|█████████▋| 258/266 [04:03<00:08,  1.08s/it]Loading trainS:  97%|█████████▋| 259/266 [04:04<00:07,  1.09s/it]Loading trainS:  98%|█████████▊| 260/266 [04:05<00:06,  1.08s/it]Loading trainS:  98%|█████████▊| 261/266 [04:06<00:05,  1.10s/it]Loading trainS:  98%|█████████▊| 262/266 [04:07<00:03,  1.07it/s]Loading trainS:  99%|█████████▉| 263/266 [04:07<00:02,  1.16it/s]Loading trainS:  99%|█████████▉| 264/266 [04:08<00:01,  1.20it/s]Loading trainS: 100%|█████████▉| 265/266 [04:09<00:00,  1.21it/s]Loading trainS: 100%|██████████| 266/266 [04:10<00:00,  1.21it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.43it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.34it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.48it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.47it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.38it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.75it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.22it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.79it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.60it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:10,  3.30it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:08,  3.77it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.84it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.90it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:05,  4.68it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:05,  4.49it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.50it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:03,  5.28it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:02,  5.89it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.88it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:02,  4.99it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.54it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  4.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  4.51it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  4.56it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:00,  4.50it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:07<00:00,  3.88it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:07<00:00,  5.98it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 48,482
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 38s - loss: 0.2920 - acc: 0.9685 - mDice: 0.6257 - val_loss: 0.8090 - val_acc: 0.9886 - val_mDice: 0.6796

Epoch 00001: val_mDice improved from -inf to 0.67961, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 32s - loss: 0.1109 - acc: 0.9887 - mDice: 0.8078 - val_loss: 0.7775 - val_acc: 0.9893 - val_mDice: 0.6992

Epoch 00002: val_mDice improved from 0.67961 to 0.69919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 32s - loss: 0.0922 - acc: 0.9904 - mDice: 0.8367 - val_loss: 0.8586 - val_acc: 0.9870 - val_mDice: 0.7076

Epoch 00003: val_mDice improved from 0.69919 to 0.70763, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 32s - loss: 0.0829 - acc: 0.9912 - mDice: 0.8517 - val_loss: 0.7414 - val_acc: 0.9912 - val_mDice: 0.7695

Epoch 00004: val_mDice improved from 0.70763 to 0.76950, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 32s - loss: 0.0760 - acc: 0.9918 - mDice: 0.8630 - val_loss: 0.7183 - val_acc: 0.9912 - val_mDice: 0.7597

Epoch 00005: val_mDice did not improve from 0.76950
Epoch 6/300
 - 32s - loss: 0.0707 - acc: 0.9923 - mDice: 0.8719 - val_loss: 0.8568 - val_acc: 0.9877 - val_mDice: 0.7154

Epoch 00006: val_mDice did not improve from 0.76950
Epoch 7/300
 - 32s - loss: 0.0680 - acc: 0.9926 - mDice: 0.8765 - val_loss: 0.7479 - val_acc: 0.9916 - val_mDice: 0.7840

Epoch 00007: val_mDice improved from 0.76950 to 0.78401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 32s - loss: 0.0643 - acc: 0.9929 - mDice: 0.8828 - val_loss: 0.7147 - val_acc: 0.9920 - val_mDice: 0.7877

Epoch 00008: val_mDice improved from 0.78401 to 0.78773, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 32s - loss: 0.0634 - acc: 0.9930 - mDice: 0.8843 - val_loss: 0.7480 - val_acc: 0.9920 - val_mDice: 0.7809

Epoch 00009: val_mDice did not improve from 0.78773
Epoch 10/300
 - 32s - loss: 0.0616 - acc: 0.9932 - mDice: 0.8875 - val_loss: 0.8202 - val_acc: 0.9895 - val_mDice: 0.7533

Epoch 00010: val_mDice did not improve from 0.78773
Epoch 11/300
 - 32s - loss: 0.0598 - acc: 0.9933 - mDice: 0.8906 - val_loss: 0.8255 - val_acc: 0.9893 - val_mDice: 0.7451

Epoch 00011: val_mDice did not improve from 0.78773
Epoch 12/300
 - 32s - loss: 0.0584 - acc: 0.9934 - mDice: 0.8929 - val_loss: 0.7322 - val_acc: 0.9924 - val_mDice: 0.7945

Epoch 00012: val_mDice improved from 0.78773 to 0.79450, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 33s - loss: 0.0573 - acc: 0.9935 - mDice: 0.8949 - val_loss: 0.4075 - val_acc: 0.9924 - val_mDice: 0.7865

Epoch 00013: val_mDice did not improve from 0.79450
Epoch 14/300
 - 33s - loss: 0.0565 - acc: 0.9936 - mDice: 0.8962 - val_loss: 0.8688 - val_acc: 0.9874 - val_mDice: 0.7213

Epoch 00014: val_mDice did not improve from 0.79450
Epoch 15/300
 - 33s - loss: 0.0556 - acc: 0.9937 - mDice: 0.8978 - val_loss: 0.7562 - val_acc: 0.9919 - val_mDice: 0.7931

Epoch 00015: val_mDice did not improve from 0.79450
Epoch 16/300
 - 33s - loss: 0.0543 - acc: 0.9938 - mDice: 0.9002 - val_loss: 0.8489 - val_acc: 0.9887 - val_mDice: 0.7390

Epoch 00016: val_mDice did not improve from 0.79450
Epoch 17/300
 - 33s - loss: 0.0536 - acc: 0.9939 - mDice: 0.9012 - val_loss: 0.7092 - val_acc: 0.9930 - val_mDice: 0.8055

Epoch 00017: val_mDice improved from 0.79450 to 0.80546, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 33s - loss: 0.0526 - acc: 0.9940 - mDice: 0.9030 - val_loss: 0.7126 - val_acc: 0.9933 - val_mDice: 0.8106

Epoch 00018: val_mDice improved from 0.80546 to 0.81059, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 33s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9036 - val_loss: 0.6819 - val_acc: 0.9925 - val_mDice: 0.8006

Epoch 00019: val_mDice did not improve from 0.81059
Epoch 20/300
 - 33s - loss: 0.0517 - acc: 0.9940 - mDice: 0.9047 - val_loss: 0.7274 - val_acc: 0.9933 - val_mDice: 0.8144

Epoch 00020: val_mDice improved from 0.81059 to 0.81440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 33s - loss: 0.0512 - acc: 0.9941 - mDice: 0.9056 - val_loss: 0.4629 - val_acc: 0.9898 - val_mDice: 0.6968

Epoch 00021: val_mDice did not improve from 0.81440
Epoch 22/300
 - 33s - loss: 0.0511 - acc: 0.9941 - mDice: 0.9057 - val_loss: 0.7705 - val_acc: 0.9912 - val_mDice: 0.7716

Epoch 00022: val_mDice did not improve from 0.81440
Epoch 23/300
 - 33s - loss: 0.0495 - acc: 0.9942 - mDice: 0.9086 - val_loss: 0.7497 - val_acc: 0.9919 - val_mDice: 0.7930

Epoch 00023: val_mDice did not improve from 0.81440
Epoch 24/300
 - 33s - loss: 0.0499 - acc: 0.9943 - mDice: 0.9078 - val_loss: 0.4593 - val_acc: 0.9925 - val_mDice: 0.7781

Epoch 00024: val_mDice did not improve from 0.81440
Epoch 25/300
 - 33s - loss: 0.0490 - acc: 0.9943 - mDice: 0.9093 - val_loss: 0.7358 - val_acc: 0.9930 - val_mDice: 0.8105

Epoch 00025: val_mDice did not improve from 0.81440
Epoch 26/300
 - 33s - loss: 0.0487 - acc: 0.9943 - mDice: 0.9099 - val_loss: 0.7621 - val_acc: 0.9925 - val_mDice: 0.8038

Epoch 00026: val_mDice did not improve from 0.81440
Epoch 27/300
 - 33s - loss: 0.0482 - acc: 0.9944 - mDice: 0.9108 - val_loss: 0.7178 - val_acc: 0.9934 - val_mDice: 0.8128

Epoch 00027: val_mDice did not improve from 0.81440
Epoch 28/300
 - 33s - loss: 0.0477 - acc: 0.9944 - mDice: 0.9118 - val_loss: 0.6887 - val_acc: 0.9932 - val_mDice: 0.8041

Epoch 00028: val_mDice did not improve from 0.81440
Epoch 29/300
 - 33s - loss: 0.0480 - acc: 0.9944 - mDice: 0.9112 - val_loss: 0.6997 - val_acc: 0.9929 - val_mDice: 0.8066

Epoch 00029: val_mDice did not improve from 0.81440
Epoch 30/300
 - 33s - loss: 0.0470 - acc: 0.9945 - mDice: 0.9130 - val_loss: 0.3237 - val_acc: 0.9918 - val_mDice: 0.7579

Epoch 00030: val_mDice did not improve from 0.81440
Epoch 31/300
 - 33s - loss: 0.0468 - acc: 0.9945 - mDice: 0.9132 - val_loss: 0.7667 - val_acc: 0.9919 - val_mDice: 0.8008

Epoch 00031: val_mDice did not improve from 0.81440
Epoch 32/300
 - 33s - loss: 0.0463 - acc: 0.9945 - mDice: 0.9142 - val_loss: 0.7012 - val_acc: 0.9930 - val_mDice: 0.7992

Epoch 00032: val_mDice did not improve from 0.81440
Epoch 33/300
 - 33s - loss: 0.0465 - acc: 0.9945 - mDice: 0.9139 - val_loss: 0.6860 - val_acc: 0.9931 - val_mDice: 0.8118

Epoch 00033: val_mDice did not improve from 0.81440
Epoch 34/300
 - 33s - loss: 0.0461 - acc: 0.9946 - mDice: 0.9145 - val_loss: 0.7070 - val_acc: 0.9932 - val_mDice: 0.8099

Epoch 00034: val_mDice did not improve from 0.81440
Epoch 35/300
 - 33s - loss: 0.0459 - acc: 0.9946 - mDice: 0.9148 - val_loss: 0.6797 - val_acc: 0.9914 - val_mDice: 0.7465

Epoch 00035: val_mDice did not improve from 0.81440
Epoch 36/300
 - 33s - loss: 0.0459 - acc: 0.9946 - mDice: 0.9150 - val_loss: 0.6665 - val_acc: 0.9928 - val_mDice: 0.7902

Epoch 00036: val_mDice did not improve from 0.81440
Epoch 37/300
 - 33s - loss: 0.0452 - acc: 0.9947 - mDice: 0.9161 - val_loss: 0.7003 - val_acc: 0.9928 - val_mDice: 0.8053

Epoch 00037: val_mDice did not improve from 0.81440
Epoch 38/300
 - 33s - loss: 0.0453 - acc: 0.9947 - mDice: 0.9160 - val_loss: 0.2808 - val_acc: 0.9927 - val_mDice: 0.7887

Epoch 00038: val_mDice did not improve from 0.81440
Epoch 39/300
 - 32s - loss: 0.0447 - acc: 0.9947 - mDice: 0.9169 - val_loss: 0.8052 - val_acc: 0.9907 - val_mDice: 0.7701

Epoch 00039: val_mDice did not improve from 0.81440
Epoch 40/300
 - 33s - loss: 0.0443 - acc: 0.9947 - mDice: 0.9178 - val_loss: 0.7280 - val_acc: 0.9926 - val_mDice: 0.8060

Epoch 00040: val_mDice did not improve from 0.81440
Epoch 41/300
 - 32s - loss: 0.0442 - acc: 0.9948 - mDice: 0.9178 - val_loss: 0.7091 - val_acc: 0.9933 - val_mDice: 0.8129

Epoch 00041: val_mDice did not improve from 0.81440
Epoch 42/300
 - 32s - loss: 0.0440 - acc: 0.9948 - mDice: 0.9182 - val_loss: 0.7202 - val_acc: 0.9934 - val_mDice: 0.8157

Epoch 00042: val_mDice improved from 0.81440 to 0.81574, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 33s - loss: 0.0443 - acc: 0.9948 - mDice: 0.9178 - val_loss: 0.6801 - val_acc: 0.9934 - val_mDice: 0.8099

Epoch 00043: val_mDice did not improve from 0.81574
Epoch 44/300
 - 33s - loss: 0.0438 - acc: 0.9948 - mDice: 0.9186 - val_loss: 0.7003 - val_acc: 0.9930 - val_mDice: 0.7981

Epoch 00044: val_mDice did not improve from 0.81574
Epoch 45/300
 - 32s - loss: 0.0435 - acc: 0.9948 - mDice: 0.9192 - val_loss: 0.7290 - val_acc: 0.9929 - val_mDice: 0.8127

Epoch 00045: val_mDice did not improve from 0.81574
Epoch 46/300
 - 33s - loss: 0.0435 - acc: 0.9948 - mDice: 0.9191 - val_loss: 0.7531 - val_acc: 0.9931 - val_mDice: 0.8155

Epoch 00046: val_mDice did not improve from 0.81574
Epoch 47/300
 - 33s - loss: 0.0431 - acc: 0.9949 - mDice: 0.9198 - val_loss: 0.7222 - val_acc: 0.9933 - val_mDice: 0.8173

Epoch 00047: val_mDice improved from 0.81574 to 0.81732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 32s - loss: 0.0428 - acc: 0.9949 - mDice: 0.9203 - val_loss: 0.7689 - val_acc: 0.9914 - val_mDice: 0.7888

Epoch 00048: val_mDice did not improve from 0.81732
Epoch 49/300
 - 32s - loss: 0.0428 - acc: 0.9949 - mDice: 0.9204 - val_loss: 0.6598 - val_acc: 0.9934 - val_mDice: 0.8171

Epoch 00049: val_mDice did not improve from 0.81732
Epoch 50/300
 - 32s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9214 - val_loss: 0.7259 - val_acc: 0.9931 - val_mDice: 0.8141

Epoch 00050: val_mDice did not improve from 0.81732
Epoch 51/300
 - 32s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.6772 - val_acc: 0.9935 - val_mDice: 0.8167

Epoch 00051: val_mDice did not improve from 0.81732
Epoch 52/300
 - 32s - loss: 0.0425 - acc: 0.9949 - mDice: 0.9209 - val_loss: 0.0968 - val_acc: 0.9924 - val_mDice: 0.7807

Epoch 00052: val_mDice did not improve from 0.81732
Epoch 53/300
 - 32s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9218 - val_loss: 0.7414 - val_acc: 0.9927 - val_mDice: 0.8110

Epoch 00053: val_mDice did not improve from 0.81732
Epoch 54/300
 - 32s - loss: 0.0419 - acc: 0.9950 - mDice: 0.9220 - val_loss: 0.6828 - val_acc: 0.9937 - val_mDice: 0.8216

Epoch 00054: val_mDice improved from 0.81732 to 0.82156, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 32s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9214 - val_loss: 0.7415 - val_acc: 0.9929 - val_mDice: 0.8128

Epoch 00055: val_mDice did not improve from 0.82156
Epoch 56/300
 - 33s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9227 - val_loss: 0.7252 - val_acc: 0.9932 - val_mDice: 0.8165

Epoch 00056: val_mDice did not improve from 0.82156
Epoch 57/300
 - 32s - loss: 0.0416 - acc: 0.9950 - mDice: 0.9225 - val_loss: 0.6494 - val_acc: 0.9932 - val_mDice: 0.8113

Epoch 00057: val_mDice did not improve from 0.82156
Epoch 58/300
 - 32s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9227 - val_loss: 0.7354 - val_acc: 0.9927 - val_mDice: 0.8078

Epoch 00058: val_mDice did not improve from 0.82156
Epoch 59/300
 - 32s - loss: 0.0413 - acc: 0.9950 - mDice: 0.9232 - val_loss: 0.6463 - val_acc: 0.9937 - val_mDice: 0.8189

Epoch 00059: val_mDice did not improve from 0.82156
Epoch 60/300
 - 32s - loss: 0.0409 - acc: 0.9951 - mDice: 0.9238 - val_loss: 0.6593 - val_acc: 0.9931 - val_mDice: 0.8125

Epoch 00060: val_mDice did not improve from 0.82156
Epoch 61/300
 - 32s - loss: 0.0411 - acc: 0.9950 - mDice: 0.9235 - val_loss: 0.5986 - val_acc: 0.9910 - val_mDice: 0.7338

Epoch 00061: val_mDice did not improve from 0.82156
Epoch 62/300
 - 32s - loss: 0.0408 - acc: 0.9950 - mDice: 0.9240 - val_loss: 0.6275 - val_acc: 0.9929 - val_mDice: 0.7980

Epoch 00062: val_mDice did not improve from 0.82156
Epoch 63/300
 - 32s - loss: 0.0407 - acc: 0.9951 - mDice: 0.9241 - val_loss: 0.6416 - val_acc: 0.9931 - val_mDice: 0.8127

Epoch 00063: val_mDice did not improve from 0.82156
Epoch 64/300
 - 32s - loss: 0.0406 - acc: 0.9951 - mDice: 0.9244 - val_loss: 0.7108 - val_acc: 0.9932 - val_mDice: 0.8124

Epoch 00064: val_mDice did not improve from 0.82156
Epoch 65/300
 - 32s - loss: 0.0405 - acc: 0.9950 - mDice: 0.9245 - val_loss: 0.7142 - val_acc: 0.9933 - val_mDice: 0.8153

Epoch 00065: val_mDice did not improve from 0.82156
Epoch 66/300
 - 32s - loss: 0.0404 - acc: 0.9951 - mDice: 0.9248 - val_loss: 0.5390 - val_acc: 0.9937 - val_mDice: 0.8177

Epoch 00066: val_mDice did not improve from 0.82156
Epoch 67/300
 - 32s - loss: 0.0403 - acc: 0.9951 - mDice: 0.9248 - val_loss: 0.7130 - val_acc: 0.9926 - val_mDice: 0.8075

Epoch 00067: val_mDice did not improve from 0.82156
Epoch 68/300
 - 32s - loss: 0.0398 - acc: 0.9951 - mDice: 0.9257 - val_loss: 0.6632 - val_acc: 0.9934 - val_mDice: 0.8178

Epoch 00068: val_mDice did not improve from 0.82156
Epoch 69/300
 - 32s - loss: 0.0402 - acc: 0.9951 - mDice: 0.9251 - val_loss: 0.6630 - val_acc: 0.9935 - val_mDice: 0.8127

Epoch 00069: val_mDice did not improve from 0.82156
Epoch 70/300
 - 32s - loss: 0.0399 - acc: 0.9952 - mDice: 0.9256 - val_loss: 0.7741 - val_acc: 0.9920 - val_mDice: 0.7990

Epoch 00070: val_mDice did not improve from 0.82156
Epoch 71/300
 - 32s - loss: 0.0400 - acc: 0.9951 - mDice: 0.9255 - val_loss: 0.6568 - val_acc: 0.9935 - val_mDice: 0.8165

Epoch 00071: val_mDice did not improve from 0.82156
Epoch 72/300
 - 32s - loss: 0.0397 - acc: 0.9951 - mDice: 0.9259 - val_loss: 0.6255 - val_acc: 0.9930 - val_mDice: 0.7942

Epoch 00072: val_mDice did not improve from 0.82156
Epoch 73/300
 - 32s - loss: 0.0396 - acc: 0.9952 - mDice: 0.9262 - val_loss: 0.6831 - val_acc: 0.9935 - val_mDice: 0.8180

Epoch 00073: val_mDice did not improve from 0.82156
Epoch 74/300
 - 32s - loss: 0.0406 - acc: 0.9951 - mDice: 0.9243 - val_loss: 0.7747 - val_acc: 0.9912 - val_mDice: 0.7870

Epoch 00074: val_mDice did not improve from 0.82156
Epoch 75/300
 - 32s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.7326 - val_acc: 0.9923 - val_mDice: 0.7954

Epoch 00075: val_mDice did not improve from 0.82156
Epoch 76/300
 - 32s - loss: 0.0393 - acc: 0.9952 - mDice: 0.9267 - val_loss: 0.7572 - val_acc: 0.9916 - val_mDice: 0.7940

Epoch 00076: val_mDice did not improve from 0.82156
Epoch 77/300
 - 32s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.7360 - val_acc: 0.9923 - val_mDice: 0.8056

Epoch 00077: val_mDice did not improve from 0.82156
Epoch 78/300
 - 32s - loss: 0.0395 - acc: 0.9952 - mDice: 0.9263 - val_loss: 0.6709 - val_acc: 0.9932 - val_mDice: 0.8059

Epoch 00078: val_mDice did not improve from 0.82156
Epoch 79/300
 - 32s - loss: 0.0390 - acc: 0.9952 - mDice: 0.9272 - val_loss: 0.7097 - val_acc: 0.9933 - val_mDice: 0.8145

Epoch 00079: val_mDice did not improve from 0.82156
Epoch 80/300
 - 32s - loss: 0.0389 - acc: 0.9952 - mDice: 0.9275 - val_loss: 0.5995 - val_acc: 0.9934 - val_mDice: 0.8114

Epoch 00080: val_mDice did not improve from 0.82156
Epoch 81/300
 - 33s - loss: 0.0395 - acc: 0.9952 - mDice: 0.9264 - val_loss: 0.7213 - val_acc: 0.9930 - val_mDice: 0.8134

Epoch 00081: val_mDice did not improve from 0.82156
Epoch 82/300
 - 32s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.6414 - val_acc: 0.9933 - val_mDice: 0.8170

Epoch 00082: val_mDice did not improve from 0.82156
Epoch 83/300
 - 32s - loss: 0.0388 - acc: 0.9952 - mDice: 0.9276 - val_loss: 0.7452 - val_acc: 0.9923 - val_mDice: 0.8044

Epoch 00083: val_mDice did not improve from 0.82156
Epoch 84/300
 - 32s - loss: 0.0389 - acc: 0.9952 - mDice: 0.9274 - val_loss: 0.7407 - val_acc: 0.9925 - val_mDice: 0.8101

Epoch 00084: val_mDice did not improve from 0.82156
Epoch 85/300
 - 32s - loss: 0.0386 - acc: 0.9952 - mDice: 0.9279 - val_loss: 0.6289 - val_acc: 0.9930 - val_mDice: 0.8027

Epoch 00085: val_mDice did not improve from 0.82156
Epoch 86/300
 - 32s - loss: 0.0387 - acc: 0.9952 - mDice: 0.9278 - val_loss: 0.6917 - val_acc: 0.9930 - val_mDice: 0.8050

Epoch 00086: val_mDice did not improve from 0.82156
Epoch 87/300
 - 32s - loss: 0.0386 - acc: 0.9952 - mDice: 0.9280 - val_loss: 0.6271 - val_acc: 0.9934 - val_mDice: 0.8190

Epoch 00087: val_mDice did not improve from 0.82156
Epoch 88/300
 - 32s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9288 - val_loss: 0.6944 - val_acc: 0.9932 - val_mDice: 0.8168

Epoch 00088: val_mDice did not improve from 0.82156
Epoch 89/300
 - 32s - loss: 0.0383 - acc: 0.9953 - mDice: 0.9284 - val_loss: 0.6329 - val_acc: 0.9933 - val_mDice: 0.8142

Epoch 00089: val_mDice did not improve from 0.82156
Epoch 90/300
 - 32s - loss: 0.0386 - acc: 0.9952 - mDice: 0.9280 - val_loss: 0.7939 - val_acc: 0.9901 - val_mDice: 0.7724

Epoch 00090: val_mDice did not improve from 0.82156
Epoch 91/300
 - 32s - loss: 0.0384 - acc: 0.9953 - mDice: 0.9283 - val_loss: 0.6341 - val_acc: 0.9934 - val_mDice: 0.8141

Epoch 00091: val_mDice did not improve from 0.82156
Epoch 92/300
 - 32s - loss: 0.0384 - acc: 0.9953 - mDice: 0.9284 - val_loss: 0.6803 - val_acc: 0.9930 - val_mDice: 0.8120

Epoch 00092: val_mDice did not improve from 0.82156
Epoch 93/300
 - 32s - loss: 0.0377 - acc: 0.9953 - mDice: 0.9296 - val_loss: 0.6959 - val_acc: 0.9932 - val_mDice: 0.8144

Epoch 00093: val_mDice did not improve from 0.82156
Epoch 94/300
 - 32s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9287 - val_loss: 0.7758 - val_acc: 0.9911 - val_mDice: 0.7937

Epoch 00094: val_mDice did not improve from 0.82156
Restoring model weights from the end of the best epoch
Epoch 00094: early stopping
{'val_loss': [0.8090230796951801, 0.7774660086724907, 0.8586063955444843, 0.7414415120147169, 0.718303089030087, 0.8568240315653384, 0.7479480154579505, 0.7146893998142332, 0.7479700288968161, 0.820169567479752, 0.8254726030863822, 0.7321687705116346, 0.40748564049135894, 0.8687739309389144, 0.756150180590339, 0.8489197113085538, 0.7091951814945787, 0.7125979933189228, 0.6818678823765367, 0.7273562538903207, 0.46290321997366846, 0.7705233107553795, 0.749662492191419, 0.45934775937348604, 0.7358230889076367, 0.7620968682458624, 0.7178383582504466, 0.6887489804066718, 0.6997259230120108, 0.3237092988565564, 0.7666940082563087, 0.701184852863662, 0.6860059442697093, 0.7069667916512117, 0.6797033285256475, 0.6664742007851601, 0.7002554485807195, 0.28075455769430846, 0.8052285648882389, 0.7280100341886282, 0.7090767845511436, 0.7202424213755876, 0.6801216936437413, 0.7003244056832045, 0.7290188943734393, 0.7531480095349252, 0.722163152997382, 0.7688875838648528, 0.6598498447565362, 0.7258648568531498, 0.6771707062143832, 0.09683337528258562, 0.7414417056133971, 0.6827969148289412, 0.7414873440284282, 0.7251558997668326, 0.6493528531864285, 0.7353932607220486, 0.6463282339973375, 0.6593257678905502, 0.5985923724947497, 0.6274992355611175, 0.6416447433875874, 0.7108187647536397, 0.7141770848538727, 0.5390043581137434, 0.7130069291451946, 0.6632314232410863, 0.6630456181010231, 0.7741295915329829, 0.6567690862575546, 0.62547935731709, 0.6830821410985664, 0.774675328633748, 0.732577366521582, 0.7572346780216321, 0.7359719704836607, 0.6708653531968594, 0.7097340949112549, 0.5995262752985582, 0.7213476275792345, 0.641387146548368, 0.7451927347574383, 0.7407250020187348, 0.6289467590395361, 0.6916634272783995, 0.62713830138091, 0.6943601946113631, 0.632944063632749, 0.7939310861984268, 0.6340813661227003, 0.6802911806153134, 0.695926311891526, 0.7757658548653126], 'val_acc': [0.988559128716588, 0.9892533253878355, 0.9870277997106314, 0.9912062045186758, 0.9911760073155165, 0.9877414740622044, 0.9915955830365419, 0.9920445587486029, 0.9919532686471939, 0.9895232301205397, 0.9892712794244289, 0.9924464300274849, 0.9924237187951803, 0.9873987324535847, 0.9919220823794603, 0.988654674962163, 0.9929560348391533, 0.9933107383549213, 0.9925347082316875, 0.9933124743402004, 0.989806329831481, 0.9912363700568676, 0.9918510057032108, 0.992540966719389, 0.9929914548993111, 0.992537971585989, 0.9934005215764046, 0.9931984897702932, 0.9929024130105972, 0.9917916394770145, 0.9918507523834705, 0.9930158909410238, 0.9930598009377718, 0.993203978985548, 0.9913673363626003, 0.992776433005929, 0.9928310588002205, 0.9927028547972441, 0.990689117461443, 0.9926093108952045, 0.9933433998376131, 0.9933855701237917, 0.9934060107916594, 0.9930143896490335, 0.9929218608886003, 0.9930862374603748, 0.9933074992150068, 0.9914339259266853, 0.993439681828022, 0.9931378662586212, 0.9935060385614634, 0.9924112390726805, 0.9927330259233713, 0.9936676695942879, 0.9929305929690599, 0.9932426512241364, 0.99324188567698, 0.9927337765693665, 0.9937228187918663, 0.9931443724781275, 0.9909505173563957, 0.9929171185940504, 0.9931099321693182, 0.9931827634572983, 0.9932585898786783, 0.9937013555318117, 0.9925786256790161, 0.9933753348886967, 0.9934574048966169, 0.9920103996992111, 0.9934534132480621, 0.9929680041968822, 0.9935050364583731, 0.9912470988929272, 0.9922867733985186, 0.9915718715637922, 0.9922650773078203, 0.9932246748358011, 0.9932620823383331, 0.9933591354638338, 0.9930358566343784, 0.9932630974799395, 0.9923137165606022, 0.9925212450325489, 0.9930228777229786, 0.9929637461900711, 0.9933641105890274, 0.993208197876811, 0.9932930264621973, 0.9900844655930996, 0.9933681096881628, 0.9929612781852484, 0.9931533448398113, 0.9911156464368105], 'val_mDice': [0.6796143064275384, 0.6991891050711274, 0.7076294720172882, 0.7694957405328751, 0.7597197499126196, 0.7153506018221378, 0.7840130012482405, 0.7877269294112921, 0.7809063326567411, 0.7533456198871136, 0.7451404072344303, 0.7944994140416384, 0.7865482661873102, 0.7212880626320839, 0.7931048981845379, 0.7390220649540424, 0.8054624684154987, 0.8105946145951748, 0.8006239403039217, 0.8143959101289511, 0.6967507302761078, 0.7716355752199888, 0.792993288487196, 0.7780817430466413, 0.8105015940964222, 0.803768178448081, 0.8127888571470976, 0.8041490707546473, 0.8066013641655445, 0.7579292543232441, 0.8008171804249287, 0.7991916686296463, 0.8117571379989386, 0.809920746833086, 0.7464973302558064, 0.7901584915816784, 0.8053066860884428, 0.7886598911136389, 0.7700968161225319, 0.8060212805867195, 0.8129214681684971, 0.8157436549663544, 0.8098884951323271, 0.7980656530708075, 0.8127374667674303, 0.8155344426631927, 0.8173203840851784, 0.788846779614687, 0.8170753251761198, 0.8141126576811075, 0.8166767936199903, 0.7807117886841297, 0.8110205922275782, 0.8215579390525818, 0.8128319401293993, 0.816492298617959, 0.8113149274140596, 0.8077573031187057, 0.8189311623573303, 0.8124940656125546, 0.7337677665054798, 0.7980291172862053, 0.8126816526055336, 0.812368206679821, 0.8153124898672104, 0.8176535647362471, 0.8075409848242998, 0.8177741896361113, 0.8127408754080534, 0.7990001887083054, 0.8165087457746267, 0.7942262385040522, 0.817959439009428, 0.7869618479162455, 0.7953678537160158, 0.7940194942057133, 0.8056466467678547, 0.8059487212449312, 0.814498895779252, 0.811420688405633, 0.8134393859654665, 0.8169554453343153, 0.8044381067156792, 0.8101440500468016, 0.8026706613600254, 0.8049713261425495, 0.8189846947789192, 0.8168426621705294, 0.8142437599599361, 0.7724053971469402, 0.8140734117478132, 0.8120002597570419, 0.8143864292651415, 0.7936850376427174], 'loss': [0.29199906343108784, 0.11092202449798501, 0.0922072311127291, 0.08286260693410111, 0.07601883943050154, 0.07073789128439205, 0.06802748575714859, 0.06428549578646009, 0.06343910449180257, 0.06155529554032609, 0.05975753462747773, 0.05843700054157372, 0.0573032579171688, 0.05653030858434104, 0.055611540538409145, 0.0542655166771349, 0.05364329392719978, 0.05262302398245357, 0.05227525321937915, 0.05169110418281877, 0.05117405367320709, 0.051076603074553424, 0.04945064336364453, 0.04988904607922542, 0.04904575795203575, 0.048730076171316666, 0.048186485479988675, 0.047664616212588135, 0.04797471467021645, 0.04696015803920512, 0.04684001584988002, 0.04627330186183311, 0.046466869506060875, 0.046096373531645814, 0.04594871619863662, 0.04585685431320998, 0.04523948287266506, 0.04526317198263605, 0.04474806640956361, 0.044266359874290694, 0.04424372257257299, 0.04401926983650365, 0.04425247577989096, 0.04382243117314744, 0.043450440390400594, 0.04352476521595002, 0.043125585418407046, 0.042831433999496175, 0.04279040515382136, 0.042249249099414354, 0.04216065839347634, 0.0424976549675597, 0.04201448649476183, 0.04192498892474717, 0.04224572960576024, 0.041531248004078876, 0.04162829036510502, 0.0415081657340292, 0.04126457359299429, 0.0409137758941317, 0.041092391316190864, 0.04080551850705892, 0.04072803515602006, 0.04059185984875456, 0.040519475691912964, 0.04037412348626119, 0.04032825092460769, 0.03981736442674719, 0.04017795104759799, 0.039916716521428176, 0.039966442027656514, 0.03974281002883055, 0.03958277888959628, 0.04063131397176048, 0.03937482535756845, 0.03926207318138519, 0.03940510774444409, 0.03952840588592141, 0.03900828201441042, 0.038869048749128395, 0.03947139082928145, 0.0393916548235056, 0.0387952043546663, 0.03889094631843233, 0.038623054990220514, 0.03865208388313234, 0.038551902298701826, 0.03815130428439741, 0.038320495528563384, 0.03855866557405921, 0.03842581291886985, 0.038374598232064704, 0.03769250241086273, 0.03819841319446027], 'acc': [0.968532209073928, 0.9886787622678815, 0.9903794455240174, 0.991179025005599, 0.9918161798911296, 0.9923197238913698, 0.9925653239264366, 0.9928950862808622, 0.9929983074329616, 0.9931656241527733, 0.9933273527311146, 0.9934365507325631, 0.9935388691239453, 0.9936346515235799, 0.9937087935036838, 0.9938181930958386, 0.9938856092523695, 0.9939540386463106, 0.9939968971905841, 0.9940494709872502, 0.9940851494536606, 0.9941215323656711, 0.9942490751144708, 0.9942541299789254, 0.9943035358236935, 0.9943357080314665, 0.9943784527334308, 0.994425120116305, 0.9944484482468581, 0.994487300509981, 0.9945116967804218, 0.9945441837563974, 0.9945244301386214, 0.9945803462759576, 0.9945875286737413, 0.9945748480296763, 0.9946503250097805, 0.9946642368460582, 0.9946991006187048, 0.9947463096787847, 0.9947515644788382, 0.9947688469449665, 0.994758320343651, 0.9947878671285235, 0.9948160702916018, 0.9947976186063019, 0.9948582754077515, 0.9948786633956774, 0.994885382564195, 0.9949181103756221, 0.9949355029514114, 0.9948959232858627, 0.9949343302350462, 0.9949518588066544, 0.994935691612889, 0.9950022986434652, 0.9949840207306007, 0.9949675510815243, 0.9950076597720554, 0.9950587836391657, 0.9950355198708258, 0.9950319678647407, 0.9950711927763521, 0.995068389287432, 0.9950483920641501, 0.9950856283606587, 0.9950803606798525, 0.9951298677562573, 0.9951168988187845, 0.9951506913421572, 0.9951223431805832, 0.9951468634040317, 0.9951590773978133, 0.995105584116227, 0.9951749489298263, 0.9952082510150738, 0.9951920224438288, 0.9951649407026341, 0.9952247511208978, 0.995218973057575, 0.9951930008962815, 0.9951815295402245, 0.9952410170186254, 0.9952294665705913, 0.9952329808277606, 0.9952467633579006, 0.9952457102178571, 0.9952803799828213, 0.9952625968639923, 0.9952497384378383, 0.9952810884657756, 0.9952783681892886, 0.995328687244804, 0.9952890504676595], 'mDice': [0.625651550746392, 0.8077910332033218, 0.8366710025216834, 0.8517105190391336, 0.8630009103599735, 0.8718647972221947, 0.8764731968350841, 0.8828341877112837, 0.8842875459987249, 0.8875074029398169, 0.8906051383985797, 0.8929050248287219, 0.8948653446017235, 0.8961942660430451, 0.8978003375937718, 0.9001530161701152, 0.9012279640136591, 0.9030134209332267, 0.9036294949225077, 0.9046522516593211, 0.9055643737544661, 0.9057244918509008, 0.9085999503982763, 0.9078148480518169, 0.9093155584172448, 0.9098693499986726, 0.9108230823754184, 0.9117584267296386, 0.9112302370986637, 0.9129955748502311, 0.9132095200405783, 0.9142238977368983, 0.9138687296765211, 0.9145300627045616, 0.9147864478770429, 0.9149630251794489, 0.9160571028106759, 0.916005258528602, 0.9169231061391386, 0.9177709582500982, 0.9178247163281065, 0.9182284222297916, 0.9178098835041537, 0.9185616650190228, 0.9192288302718741, 0.919092512676438, 0.9198164181785743, 0.920338180473184, 0.9204162120943744, 0.9213842801118654, 0.9215417806939047, 0.9209353060925674, 0.9217991450459779, 0.9219657851938616, 0.9213912487168532, 0.9226663747536841, 0.9225049025715748, 0.9227151051345458, 0.9231515759940871, 0.9237750928632139, 0.9234532877461786, 0.9239787445246197, 0.9241042828136057, 0.9243639869890493, 0.9244950885582679, 0.9247535111472847, 0.9248317019427239, 0.9257453632393517, 0.9250974348298595, 0.9255631362171667, 0.9254800036516674, 0.9258838705696876, 0.9261648230149907, 0.9242944266373124, 0.9265431067773768, 0.9267438328458663, 0.9264785915602787, 0.9262854886121474, 0.9272029579856108, 0.9274587641059279, 0.9263801536480281, 0.9265143625603551, 0.9275875618971086, 0.9274175581899381, 0.9279006473469903, 0.9278457797029313, 0.9280260402150474, 0.9287503877832345, 0.9284479458725132, 0.9280236719570689, 0.928253274256446, 0.928358864850722, 0.9295784560135741, 0.9286719903971408]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.12it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.40it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.77it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.16it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.51it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:37,  2.73it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:31,  2.87it/s]predicting train subjects:   1%|          | 3/266 [00:00<01:27,  3.00it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:25,  3.06it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:24,  3.09it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<01:23,  3.13it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:21,  3.18it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:24,  3.05it/s]predicting train subjects:   3%|▎         | 9/266 [00:02<01:22,  3.13it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:21,  3.14it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:21,  3.15it/s]predicting train subjects:   5%|▍         | 12/266 [00:03<01:19,  3.19it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:19,  3.16it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:21,  3.09it/s]predicting train subjects:   6%|▌         | 15/266 [00:04<01:19,  3.16it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:18,  3.18it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:17,  3.20it/s]predicting train subjects:   7%|▋         | 18/266 [00:05<01:17,  3.20it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:16,  3.24it/s]predicting train subjects:   8%|▊         | 20/266 [00:06<01:15,  3.26it/s]predicting train subjects:   8%|▊         | 21/266 [00:06<01:14,  3.28it/s]predicting train subjects:   8%|▊         | 22/266 [00:06<01:14,  3.29it/s]predicting train subjects:   9%|▊         | 23/266 [00:07<01:17,  3.13it/s]predicting train subjects:   9%|▉         | 24/266 [00:07<01:14,  3.26it/s]predicting train subjects:   9%|▉         | 25/266 [00:07<01:15,  3.19it/s]predicting train subjects:  10%|▉         | 26/266 [00:08<01:13,  3.26it/s]predicting train subjects:  10%|█         | 27/266 [00:08<01:11,  3.32it/s]predicting train subjects:  11%|█         | 28/266 [00:08<01:10,  3.38it/s]predicting train subjects:  11%|█         | 29/266 [00:09<01:09,  3.39it/s]predicting train subjects:  11%|█▏        | 30/266 [00:09<01:09,  3.38it/s]predicting train subjects:  12%|█▏        | 31/266 [00:09<01:08,  3.45it/s]predicting train subjects:  12%|█▏        | 32/266 [00:09<01:07,  3.48it/s]predicting train subjects:  12%|█▏        | 33/266 [00:10<01:05,  3.54it/s]predicting train subjects:  13%|█▎        | 34/266 [00:10<01:04,  3.57it/s]predicting train subjects:  13%|█▎        | 35/266 [00:10<01:04,  3.59it/s]predicting train subjects:  14%|█▎        | 36/266 [00:10<01:04,  3.59it/s]predicting train subjects:  14%|█▍        | 37/266 [00:11<01:03,  3.62it/s]predicting train subjects:  14%|█▍        | 38/266 [00:11<01:03,  3.61it/s]predicting train subjects:  15%|█▍        | 39/266 [00:11<01:02,  3.60it/s]predicting train subjects:  15%|█▌        | 40/266 [00:12<01:02,  3.61it/s]predicting train subjects:  15%|█▌        | 41/266 [00:12<01:02,  3.62it/s]predicting train subjects:  16%|█▌        | 42/266 [00:12<01:00,  3.73it/s]predicting train subjects:  16%|█▌        | 43/266 [00:12<01:00,  3.69it/s]predicting train subjects:  17%|█▋        | 44/266 [00:13<01:00,  3.66it/s]predicting train subjects:  17%|█▋        | 45/266 [00:13<01:00,  3.65it/s]predicting train subjects:  17%|█▋        | 46/266 [00:13<00:57,  3.85it/s]predicting train subjects:  18%|█▊        | 47/266 [00:13<00:55,  3.98it/s]predicting train subjects:  18%|█▊        | 48/266 [00:14<00:53,  4.08it/s]predicting train subjects:  18%|█▊        | 49/266 [00:14<00:52,  4.14it/s]predicting train subjects:  19%|█▉        | 50/266 [00:14<00:51,  4.19it/s]predicting train subjects:  19%|█▉        | 51/266 [00:14<00:52,  4.10it/s]predicting train subjects:  20%|█▉        | 52/266 [00:15<00:51,  4.16it/s]predicting train subjects:  20%|█▉        | 53/266 [00:15<00:51,  4.12it/s]predicting train subjects:  20%|██        | 54/266 [00:15<00:51,  4.12it/s]predicting train subjects:  21%|██        | 55/266 [00:15<00:50,  4.18it/s]predicting train subjects:  21%|██        | 56/266 [00:16<00:50,  4.20it/s]predicting train subjects:  21%|██▏       | 57/266 [00:16<00:49,  4.23it/s]predicting train subjects:  22%|██▏       | 58/266 [00:16<00:48,  4.27it/s]predicting train subjects:  22%|██▏       | 59/266 [00:16<00:48,  4.27it/s]predicting train subjects:  23%|██▎       | 60/266 [00:16<00:47,  4.31it/s]predicting train subjects:  23%|██▎       | 61/266 [00:17<00:46,  4.37it/s]predicting train subjects:  23%|██▎       | 62/266 [00:17<00:46,  4.42it/s]predicting train subjects:  24%|██▎       | 63/266 [00:17<00:46,  4.37it/s]predicting train subjects:  24%|██▍       | 64/266 [00:17<00:45,  4.40it/s]predicting train subjects:  24%|██▍       | 65/266 [00:18<00:45,  4.37it/s]predicting train subjects:  25%|██▍       | 66/266 [00:18<00:45,  4.42it/s]predicting train subjects:  25%|██▌       | 67/266 [00:18<00:45,  4.39it/s]predicting train subjects:  26%|██▌       | 68/266 [00:18<00:44,  4.43it/s]predicting train subjects:  26%|██▌       | 69/266 [00:18<00:44,  4.48it/s]predicting train subjects:  26%|██▋       | 70/266 [00:19<00:43,  4.49it/s]predicting train subjects:  27%|██▋       | 71/266 [00:19<00:44,  4.39it/s]predicting train subjects:  27%|██▋       | 72/266 [00:19<00:45,  4.22it/s]predicting train subjects:  27%|██▋       | 73/266 [00:19<00:45,  4.28it/s]predicting train subjects:  28%|██▊       | 74/266 [00:20<00:44,  4.33it/s]predicting train subjects:  28%|██▊       | 75/266 [00:20<00:43,  4.35it/s]predicting train subjects:  29%|██▊       | 76/266 [00:20<00:43,  4.39it/s]predicting train subjects:  29%|██▉       | 77/266 [00:20<00:42,  4.41it/s]predicting train subjects:  29%|██▉       | 78/266 [00:21<00:48,  3.84it/s]predicting train subjects:  30%|██▉       | 79/266 [00:21<00:54,  3.43it/s]predicting train subjects:  30%|███       | 80/266 [00:21<00:56,  3.29it/s]predicting train subjects:  30%|███       | 81/266 [00:22<00:56,  3.28it/s]predicting train subjects:  31%|███       | 82/266 [00:22<00:57,  3.21it/s]predicting train subjects:  31%|███       | 83/266 [00:22<00:56,  3.25it/s]predicting train subjects:  32%|███▏      | 84/266 [00:23<00:54,  3.35it/s]predicting train subjects:  32%|███▏      | 85/266 [00:23<00:53,  3.37it/s]predicting train subjects:  32%|███▏      | 86/266 [00:23<00:52,  3.45it/s]predicting train subjects:  33%|███▎      | 87/266 [00:23<00:52,  3.43it/s]predicting train subjects:  33%|███▎      | 88/266 [00:24<00:52,  3.41it/s]predicting train subjects:  33%|███▎      | 89/266 [00:24<00:52,  3.35it/s]predicting train subjects:  34%|███▍      | 90/266 [00:24<00:51,  3.41it/s]predicting train subjects:  34%|███▍      | 91/266 [00:25<00:53,  3.27it/s]predicting train subjects:  35%|███▍      | 92/266 [00:25<00:52,  3.30it/s]predicting train subjects:  35%|███▍      | 93/266 [00:25<00:51,  3.36it/s]predicting train subjects:  35%|███▌      | 94/266 [00:26<00:50,  3.42it/s]predicting train subjects:  36%|███▌      | 95/266 [00:26<00:49,  3.44it/s]predicting train subjects:  36%|███▌      | 96/266 [00:26<00:52,  3.25it/s]predicting train subjects:  36%|███▋      | 97/266 [00:26<00:52,  3.21it/s]predicting train subjects:  37%|███▋      | 98/266 [00:27<00:53,  3.15it/s]predicting train subjects:  37%|███▋      | 99/266 [00:27<00:50,  3.31it/s]predicting train subjects:  38%|███▊      | 100/266 [00:27<00:46,  3.56it/s]predicting train subjects:  38%|███▊      | 101/266 [00:28<00:45,  3.67it/s]predicting train subjects:  38%|███▊      | 102/266 [00:28<00:46,  3.54it/s]predicting train subjects:  39%|███▊      | 103/266 [00:28<00:44,  3.70it/s]predicting train subjects:  39%|███▉      | 104/266 [00:28<00:42,  3.80it/s]predicting train subjects:  39%|███▉      | 105/266 [00:29<00:43,  3.74it/s]predicting train subjects:  40%|███▉      | 106/266 [00:29<00:41,  3.83it/s]predicting train subjects:  40%|████      | 107/266 [00:29<00:43,  3.68it/s]predicting train subjects:  41%|████      | 108/266 [00:29<00:43,  3.59it/s]predicting train subjects:  41%|████      | 109/266 [00:30<00:43,  3.60it/s]predicting train subjects:  41%|████▏     | 110/266 [00:30<00:41,  3.72it/s]predicting train subjects:  42%|████▏     | 111/266 [00:30<00:40,  3.82it/s]predicting train subjects:  42%|████▏     | 112/266 [00:31<00:40,  3.80it/s]predicting train subjects:  42%|████▏     | 113/266 [00:31<00:41,  3.67it/s]predicting train subjects:  43%|████▎     | 114/266 [00:31<00:42,  3.58it/s]predicting train subjects:  43%|████▎     | 115/266 [00:31<00:43,  3.51it/s]predicting train subjects:  44%|████▎     | 116/266 [00:32<00:42,  3.56it/s]predicting train subjects:  44%|████▍     | 117/266 [00:32<00:40,  3.72it/s]predicting train subjects:  44%|████▍     | 118/266 [00:32<00:41,  3.61it/s]predicting train subjects:  45%|████▍     | 119/266 [00:32<00:41,  3.55it/s]predicting train subjects:  45%|████▌     | 120/266 [00:33<00:41,  3.55it/s]predicting train subjects:  45%|████▌     | 121/266 [00:33<00:42,  3.45it/s]predicting train subjects:  46%|████▌     | 122/266 [00:33<00:43,  3.30it/s]predicting train subjects:  46%|████▌     | 123/266 [00:34<00:44,  3.23it/s]predicting train subjects:  47%|████▋     | 124/266 [00:34<00:43,  3.27it/s]predicting train subjects:  47%|████▋     | 125/266 [00:34<00:44,  3.20it/s]predicting train subjects:  47%|████▋     | 126/266 [00:35<00:43,  3.24it/s]predicting train subjects:  48%|████▊     | 127/266 [00:35<00:43,  3.18it/s]predicting train subjects:  48%|████▊     | 128/266 [00:35<00:44,  3.11it/s]predicting train subjects:  48%|████▊     | 129/266 [00:36<00:42,  3.22it/s]predicting train subjects:  49%|████▉     | 130/266 [00:36<00:41,  3.25it/s]predicting train subjects:  49%|████▉     | 131/266 [00:36<00:43,  3.11it/s]predicting train subjects:  50%|████▉     | 132/266 [00:37<00:41,  3.20it/s]predicting train subjects:  50%|█████     | 133/266 [00:37<00:40,  3.27it/s]predicting train subjects:  50%|█████     | 134/266 [00:37<00:39,  3.34it/s]predicting train subjects:  51%|█████     | 135/266 [00:37<00:40,  3.23it/s]predicting train subjects:  51%|█████     | 136/266 [00:38<00:39,  3.26it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:38<00:40,  3.22it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:38<00:37,  3.39it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:39<00:36,  3.46it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:39<00:35,  3.50it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:39<00:35,  3.57it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:39<00:35,  3.48it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:40<00:34,  3.53it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:40<00:33,  3.59it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:40<00:33,  3.67it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:41<00:34,  3.48it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:41<00:33,  3.57it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:41<00:32,  3.63it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:41<00:33,  3.50it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:42<00:32,  3.58it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:42<00:33,  3.45it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:42<00:32,  3.55it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:43<00:31,  3.63it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:43<00:33,  3.37it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:43<00:30,  3.62it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:43<00:28,  3.93it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:44<00:26,  4.16it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:44<00:25,  4.31it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:44<00:23,  4.46it/s]predicting train subjects:  60%|██████    | 160/266 [00:44<00:23,  4.60it/s]predicting train subjects:  61%|██████    | 161/266 [00:44<00:22,  4.60it/s]predicting train subjects:  61%|██████    | 162/266 [00:45<00:22,  4.69it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:45<00:22,  4.67it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:45<00:23,  4.41it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:45<00:23,  4.24it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:46<00:22,  4.35it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:46<00:21,  4.52it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:46<00:21,  4.63it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:46<00:22,  4.38it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:46<00:21,  4.53it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:47<00:20,  4.64it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:47<00:20,  4.64it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:47<00:20,  4.48it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:47<00:22,  4.15it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:48<00:23,  3.92it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:48<00:22,  4.03it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:48<00:21,  4.11it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:48<00:21,  4.14it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:49<00:20,  4.20it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:49<00:20,  4.18it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:49<00:20,  4.21it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:49<00:20,  4.19it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:49<00:19,  4.22it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:50<00:19,  4.17it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:50<00:20,  4.02it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:50<00:20,  3.85it/s]predicting train subjects:  70%|███████   | 187/266 [00:51<00:20,  3.88it/s]predicting train subjects:  71%|███████   | 188/266 [00:51<00:19,  4.01it/s]predicting train subjects:  71%|███████   | 189/266 [00:51<00:18,  4.11it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:51<00:18,  4.18it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:51<00:18,  4.13it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:52<00:20,  3.67it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:52<00:19,  3.78it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:52<00:21,  3.42it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:53<00:20,  3.52it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:53<00:19,  3.59it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:53<00:18,  3.70it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:53<00:17,  3.83it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:54<00:17,  3.91it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:54<00:16,  3.97it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:54<00:17,  3.77it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:54<00:16,  3.88it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:55<00:15,  3.97it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:55<00:15,  4.03it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:55<00:15,  4.06it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:55<00:14,  4.07it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:56<00:14,  4.01it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:56<00:14,  3.99it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:56<00:14,  3.93it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:56<00:14,  3.93it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:57<00:14,  3.73it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:57<00:14,  3.64it/s]predicting train subjects:  80%|████████  | 213/266 [00:57<00:13,  3.84it/s]predicting train subjects:  80%|████████  | 214/266 [00:57<00:12,  4.09it/s]predicting train subjects:  81%|████████  | 215/266 [00:58<00:12,  4.02it/s]predicting train subjects:  81%|████████  | 216/266 [00:58<00:11,  4.18it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:58<00:11,  4.25it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:58<00:11,  4.21it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:59<00:10,  4.28it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:59<00:10,  4.30it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:59<00:10,  4.37it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:59<00:09,  4.46it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:00<00:09,  4.45it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:00<00:09,  4.46it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:00<00:09,  4.50it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:00<00:09,  4.39it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:00<00:08,  4.44it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:01<00:08,  4.48it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:01<00:08,  4.40it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:01<00:08,  4.26it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:01<00:08,  4.11it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:02<00:08,  4.22it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:02<00:07,  4.26it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:02<00:07,  4.09it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:02<00:07,  3.92it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:03<00:07,  3.79it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:03<00:07,  3.68it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:03<00:07,  3.76it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:04<00:07,  3.69it/s]predicting train subjects:  90%|█████████ | 240/266 [01:04<00:06,  3.88it/s]predicting train subjects:  91%|█████████ | 241/266 [01:04<00:06,  3.95it/s]predicting train subjects:  91%|█████████ | 242/266 [01:04<00:05,  4.08it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:04<00:05,  4.20it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:05<00:05,  4.12it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:05<00:05,  3.87it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:05<00:04,  4.03it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:05<00:04,  4.08it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:06<00:04,  4.07it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:06<00:04,  3.79it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:06<00:04,  3.55it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:07<00:04,  3.41it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:07<00:04,  3.21it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:07<00:04,  3.20it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:08<00:03,  3.17it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:08<00:03,  3.26it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:08<00:02,  3.34it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:08<00:02,  3.39it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:09<00:02,  3.47it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:09<00:01,  3.51it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:09<00:01,  3.39it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:10<00:01,  3.40it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:10<00:01,  3.30it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:10<00:00,  3.37it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:11<00:00,  3.43it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:11<00:00,  3.50it/s]predicting train subjects: 100%|██████████| 266/266 [01:11<00:00,  3.52it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:01,  3.55it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  3.71it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  3.85it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:01<00:00,  3.72it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:01<00:00,  3.66it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:20,  3.28it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:22,  3.19it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<01:18,  3.36it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:17,  3.40it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:17,  3.36it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:01<01:19,  3.28it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:02<01:20,  3.22it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:20,  3.20it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:02<01:21,  3.16it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:03<01:20,  3.19it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:03<01:20,  3.16it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:03<01:20,  3.14it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:04<01:19,  3.17it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:04<01:18,  3.21it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:04<01:17,  3.23it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:04<01:18,  3.20it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:05<01:20,  3.11it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:05<01:18,  3.15it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:05<01:17,  3.20it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:06<01:16,  3.24it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:06<01:16,  3.21it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:06<01:15,  3.23it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:07<01:14,  3.25it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:07<01:15,  3.19it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:07<01:15,  3.17it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:08<01:12,  3.30it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:08<01:10,  3.40it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:08<01:12,  3.30it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:08<01:13,  3.24it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:09<01:10,  3.33it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:09<01:09,  3.40it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:09<01:08,  3.40it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:10<01:08,  3.41it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:10<01:06,  3.47it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:10<01:08,  3.35it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:11<01:07,  3.41it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:11<01:06,  3.45it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:11<01:08,  3.33it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:11<01:07,  3.36it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:12<01:06,  3.39it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:12<01:05,  3.42it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:12<01:05,  3.41it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:13<01:01,  3.64it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:13<00:58,  3.82it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:13<00:56,  3.92it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:13<00:58,  3.79it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:14<00:59,  3.68it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:14<00:56,  3.85it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:14<00:54,  4.00it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:14<00:52,  4.10it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:14<00:52,  4.06it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:15<00:55,  3.88it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:15<00:53,  4.00it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:15<00:52,  4.04it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:15<00:50,  4.14it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:16<00:49,  4.20it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:16<00:49,  4.25it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:16<00:48,  4.28it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:16<00:48,  4.30it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:17<00:47,  4.35it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:17<00:47,  4.28it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:17<00:47,  4.34it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:17<00:46,  4.36it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:18<00:47,  4.29it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:18<00:45,  4.37it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:18<00:46,  4.31it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:18<00:46,  4.32it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:18<00:44,  4.41it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:19<00:44,  4.39it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:19<00:44,  4.45it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:19<00:43,  4.51it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:19<00:42,  4.53it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:20<00:43,  4.48it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:20<00:42,  4.49it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:20<00:42,  4.47it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:20<00:42,  4.49it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:20<00:41,  4.52it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:21<00:45,  4.12it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:21<00:49,  3.78it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:21<00:53,  3.50it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:22<00:53,  3.43it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:22<00:55,  3.31it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:22<00:56,  3.23it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:23<00:56,  3.24it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:23<00:55,  3.26it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:23<00:56,  3.17it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:24<00:58,  3.08it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:24<00:57,  3.08it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:24<00:55,  3.20it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:25<00:53,  3.30it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:25<00:52,  3.32it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:25<00:51,  3.40it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:25<00:50,  3.44it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:26<00:49,  3.44it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:26<00:50,  3.40it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:26<00:50,  3.38it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:27<00:50,  3.36it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:27<00:51,  3.28it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:27<00:48,  3.41it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:27<00:46,  3.59it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:28<00:44,  3.71it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:28<00:43,  3.77it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:28<00:42,  3.87it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:28<00:41,  3.94it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:29<00:40,  3.99it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:29<00:40,  3.97it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:29<00:39,  4.01it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:29<00:40,  3.93it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:30<00:40,  3.89it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:30<00:41,  3.78it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:30<00:42,  3.67it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:31<00:42,  3.59it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:31<00:40,  3.75it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:31<00:39,  3.83it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:31<00:38,  3.89it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:32<00:37,  3.95it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:32<00:37,  3.99it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:32<00:37,  3.99it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:32<00:38,  3.78it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:33<00:41,  3.50it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:33<00:43,  3.37it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:33<00:42,  3.38it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:34<00:44,  3.21it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:34<00:46,  3.03it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:34<00:46,  3.03it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:35<00:45,  3.07it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:35<00:43,  3.19it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:35<00:43,  3.16it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:36<00:43,  3.12it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:36<00:43,  3.12it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:36<00:42,  3.18it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:37<00:41,  3.21it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:37<00:41,  3.19it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:37<00:40,  3.26it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:37<00:41,  3.13it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:38<00:40,  3.23it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:38<00:40,  3.20it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:38<00:38,  3.32it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:39<00:37,  3.37it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:39<00:36,  3.48it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:39<00:37,  3.38it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:39<00:35,  3.49it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:40<00:34,  3.58it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:40<00:35,  3.39it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:40<00:37,  3.23it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:41<00:37,  3.22it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:41<00:36,  3.22it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:41<00:36,  3.21it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:42<00:35,  3.33it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:42<00:33,  3.46it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:42<00:32,  3.54it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:42<00:31,  3.62it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:43<00:30,  3.68it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:43<00:32,  3.48it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:43<00:31,  3.56it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:44<00:29,  3.68it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:44<00:27,  3.96it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:44<00:25,  4.18it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:44<00:24,  4.36it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:44<00:23,  4.50it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:45<00:22,  4.60it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:45<00:22,  4.55it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:45<00:22,  4.65it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:45<00:21,  4.74it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:45<00:21,  4.78it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:46<00:20,  4.79it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:46<00:20,  4.82it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:46<00:21,  4.51it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:46<00:21,  4.58it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:46<00:20,  4.68it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:47<00:20,  4.63it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:47<00:19,  4.71it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:47<00:20,  4.47it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:47<00:20,  4.43it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:48<00:20,  4.40it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:48<00:20,  4.35it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:48<00:21,  4.23it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:48<00:22,  3.99it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:49<00:21,  4.04it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:49<00:21,  4.03it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:49<00:22,  3.75it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:49<00:21,  3.82it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:50<00:20,  3.95it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:50<00:20,  4.06it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:50<00:19,  4.13it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:50<00:19,  4.19it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:51<00:19,  4.06it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:51<00:19,  4.00it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:51<00:20,  3.84it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:51<00:19,  3.98it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:52<00:19,  3.84it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:52<00:19,  3.88it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:52<00:18,  3.95it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:53<00:19,  3.61it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:53<00:20,  3.54it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:53<00:19,  3.62it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:53<00:19,  3.60it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:54<00:18,  3.70it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:54<00:17,  3.83it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:54<00:16,  3.93it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:54<00:17,  3.81it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:55<00:16,  3.89it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:55<00:16,  3.73it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:55<00:16,  3.65it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:55<00:16,  3.69it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:56<00:16,  3.66it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:56<00:15,  3.70it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:56<00:15,  3.81it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:57<00:15,  3.65it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:57<00:15,  3.57it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:57<00:14,  3.73it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:57<00:14,  3.84it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:58<00:13,  3.79it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:58<00:13,  3.79it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:58<00:12,  3.96it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:58<00:12,  4.09it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:59<00:11,  4.20it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:59<00:11,  4.31it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:59<00:10,  4.35it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:59<00:10,  4.27it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:59<00:10,  4.15it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:00<00:10,  4.30it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:00<00:10,  4.13it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:00<00:09,  4.30it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:00<00:09,  4.43it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:01<00:08,  4.52it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:01<00:08,  4.61it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:01<00:08,  4.63it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:01<00:08,  4.62it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:01<00:07,  4.54it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:02<00:07,  4.40it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:02<00:08,  4.23it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:02<00:08,  4.03it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:02<00:07,  4.03it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:03<00:07,  3.88it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:03<00:07,  4.01it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:03<00:07,  3.92it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:03<00:06,  4.03it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:04<00:06,  4.02it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:04<00:06,  4.00it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:04<00:06,  4.05it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:04<00:06,  3.97it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:05<00:05,  4.11it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:05<00:05,  4.08it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:05<00:05,  4.18it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:05<00:04,  4.27it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:06<00:04,  4.29it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:06<00:04,  4.32it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:06<00:04,  4.03it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:06<00:04,  3.89it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:07<00:04,  3.62it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:07<00:04,  3.45it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:07<00:03,  3.49it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:08<00:03,  3.35it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:08<00:03,  3.42it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:08<00:03,  3.28it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:09<00:02,  3.24it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:09<00:02,  3.20it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:09<00:02,  3.31it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:09<00:01,  3.40it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:10<00:01,  3.46it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:10<00:01,  3.32it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:10<00:00,  3.39it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:11<00:00,  3.28it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:11<00:00,  3.23it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:11<00:00,  3.19it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 71.03it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 64.28it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 64.19it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 64.34it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 65.82it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 67.20it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 67.59it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 69.83it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 71.76it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 74.42it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 76.68it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 75.39it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 74.21it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 74.35it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 74.32it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 73.36it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 71.95it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 71.70it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 71.55it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 71.27it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 72.06it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 75.54it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 77.54it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 79.31it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 80.03it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 77.96it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 76.73it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:02<00:00, 77.45it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:03<00:00, 78.10it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 234/266 [00:03<00:00, 78.22it/s]saving BB  train1-THALAMUS:  91%|█████████▏| 243/266 [00:03<00:00, 79.49it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 251/266 [00:03<00:00, 78.34it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 259/266 [00:03<00:00, 76.04it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 74.37it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 67.40it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:04, 61.09it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:04, 61.91it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:03, 63.75it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 29/266 [00:00<00:03, 66.34it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:00<00:03, 69.00it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:00<00:03, 71.48it/s]saving BB  train1-THALAMUS Sagittal:  20%|██        | 54/266 [00:00<00:02, 74.07it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▎       | 63/266 [00:00<00:02, 76.72it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 72/266 [00:00<00:02, 79.07it/s]saving BB  train1-THALAMUS Sagittal:  30%|███       | 80/266 [00:01<00:02, 78.74it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 88/266 [00:01<00:02, 77.20it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 96/266 [00:01<00:02, 75.51it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 104/266 [00:01<00:02, 76.59it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 112/266 [00:01<00:02, 76.75it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 120/266 [00:01<00:01, 76.46it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 128/266 [00:01<00:01, 75.83it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 136/266 [00:01<00:01, 75.39it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 144/266 [00:01<00:01, 72.39it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 152/266 [00:02<00:01, 71.86it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████    | 161/266 [00:02<00:01, 74.29it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 170/266 [00:02<00:01, 77.75it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 179/266 [00:02<00:01, 79.55it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 188/266 [00:02<00:00, 81.36it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 197/266 [00:02<00:00, 79.90it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 206/266 [00:02<00:00, 78.96it/s]saving BB  train1-THALAMUS Sagittal:  80%|████████  | 214/266 [00:02<00:00, 78.72it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 223/266 [00:02<00:00, 79.61it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 232/266 [00:03<00:00, 80.43it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████ | 241/266 [00:03<00:00, 81.57it/s]saving BB  train1-THALAMUS Sagittal:  94%|█████████▍| 250/266 [00:03<00:00, 80.52it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 259/266 [00:03<00:00, 77.08it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 76.48it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:05,  1.60s/it]Loading train:   1%|          | 2/266 [00:03<06:59,  1.59s/it]Loading train:   1%|          | 3/266 [00:04<06:23,  1.46s/it]Loading train:   2%|▏         | 4/266 [00:05<05:50,  1.34s/it]Loading train:   2%|▏         | 5/266 [00:06<06:01,  1.38s/it]Loading train:   2%|▏         | 6/266 [00:07<05:40,  1.31s/it]Loading train:   3%|▎         | 7/266 [00:09<05:16,  1.22s/it]Loading train:   3%|▎         | 8/266 [00:10<05:16,  1.23s/it]Loading train:   3%|▎         | 9/266 [00:11<05:01,  1.17s/it]Loading train:   4%|▍         | 10/266 [00:12<04:48,  1.13s/it]Loading train:   4%|▍         | 11/266 [00:13<04:42,  1.11s/it]Loading train:   5%|▍         | 12/266 [00:14<04:30,  1.07s/it]Loading train:   5%|▍         | 13/266 [00:15<04:17,  1.02s/it]Loading train:   5%|▌         | 14/266 [00:16<04:10,  1.00it/s]Loading train:   6%|▌         | 15/266 [00:17<04:04,  1.03it/s]Loading train:   6%|▌         | 16/266 [00:18<04:03,  1.03it/s]Loading train:   6%|▋         | 17/266 [00:19<04:06,  1.01it/s]Loading train:   7%|▋         | 18/266 [00:20<03:59,  1.04it/s]Loading train:   7%|▋         | 19/266 [00:21<04:06,  1.00it/s]Loading train:   8%|▊         | 20/266 [00:22<04:01,  1.02it/s]Loading train:   8%|▊         | 21/266 [00:23<04:03,  1.01it/s]Loading train:   8%|▊         | 22/266 [00:24<04:04,  1.00s/it]Loading train:   9%|▊         | 23/266 [00:25<04:03,  1.00s/it]Loading train:   9%|▉         | 24/266 [00:26<04:11,  1.04s/it]Loading train:   9%|▉         | 25/266 [00:27<04:00,  1.00it/s]Loading train:  10%|▉         | 26/266 [00:28<03:58,  1.01it/s]Loading train:  10%|█         | 27/266 [00:29<03:51,  1.03it/s]Loading train:  11%|█         | 28/266 [00:29<03:42,  1.07it/s]Loading train:  11%|█         | 29/266 [00:30<03:39,  1.08it/s]Loading train:  11%|█▏        | 30/266 [00:31<03:32,  1.11it/s]Loading train:  12%|█▏        | 31/266 [00:32<03:33,  1.10it/s]Loading train:  12%|█▏        | 32/266 [00:33<03:29,  1.12it/s]Loading train:  12%|█▏        | 33/266 [00:34<03:24,  1.14it/s]Loading train:  13%|█▎        | 34/266 [00:35<03:26,  1.12it/s]Loading train:  13%|█▎        | 35/266 [00:36<03:27,  1.11it/s]Loading train:  14%|█▎        | 36/266 [00:36<03:23,  1.13it/s]Loading train:  14%|█▍        | 37/266 [00:37<03:19,  1.15it/s]Loading train:  14%|█▍        | 38/266 [00:38<03:34,  1.06it/s]Loading train:  15%|█▍        | 39/266 [00:39<03:26,  1.10it/s]Loading train:  15%|█▌        | 40/266 [00:40<03:28,  1.08it/s]Loading train:  15%|█▌        | 41/266 [00:41<03:23,  1.10it/s]Loading train:  16%|█▌        | 42/266 [00:42<03:13,  1.16it/s]Loading train:  16%|█▌        | 43/266 [00:43<03:03,  1.21it/s]Loading train:  17%|█▋        | 44/266 [00:43<02:57,  1.25it/s]Loading train:  17%|█▋        | 45/266 [00:44<02:57,  1.25it/s]Loading train:  17%|█▋        | 46/266 [00:45<02:57,  1.24it/s]Loading train:  18%|█▊        | 47/266 [00:46<02:54,  1.26it/s]Loading train:  18%|█▊        | 48/266 [00:46<02:48,  1.30it/s]Loading train:  18%|█▊        | 49/266 [00:47<02:45,  1.31it/s]Loading train:  19%|█▉        | 50/266 [00:48<02:44,  1.31it/s]Loading train:  19%|█▉        | 51/266 [00:49<02:50,  1.26it/s]Loading train:  20%|█▉        | 52/266 [00:50<03:07,  1.14it/s]Loading train:  20%|█▉        | 53/266 [00:51<02:59,  1.19it/s]Loading train:  20%|██        | 54/266 [00:51<02:56,  1.20it/s]Loading train:  21%|██        | 55/266 [00:52<02:48,  1.25it/s]Loading train:  21%|██        | 56/266 [00:53<02:44,  1.27it/s]Loading train:  21%|██▏       | 57/266 [00:54<02:39,  1.31it/s]Loading train:  22%|██▏       | 58/266 [00:54<02:42,  1.28it/s]Loading train:  22%|██▏       | 59/266 [00:55<02:40,  1.29it/s]Loading train:  23%|██▎       | 60/266 [00:56<02:39,  1.29it/s]Loading train:  23%|██▎       | 61/266 [00:57<02:35,  1.32it/s]Loading train:  23%|██▎       | 62/266 [00:57<02:31,  1.35it/s]Loading train:  24%|██▎       | 63/266 [00:58<02:29,  1.35it/s]Loading train:  24%|██▍       | 64/266 [00:59<02:24,  1.39it/s]Loading train:  24%|██▍       | 65/266 [00:59<02:22,  1.41it/s]Loading train:  25%|██▍       | 66/266 [01:00<02:19,  1.43it/s]Loading train:  25%|██▌       | 67/266 [01:01<02:23,  1.39it/s]Loading train:  26%|██▌       | 68/266 [01:02<02:22,  1.39it/s]Loading train:  26%|██▌       | 69/266 [01:02<02:27,  1.34it/s]Loading train:  26%|██▋       | 70/266 [01:03<02:24,  1.35it/s]Loading train:  27%|██▋       | 71/266 [01:04<02:21,  1.37it/s]Loading train:  27%|██▋       | 72/266 [01:05<02:19,  1.39it/s]Loading train:  27%|██▋       | 73/266 [01:05<02:16,  1.41it/s]Loading train:  28%|██▊       | 74/266 [01:06<02:17,  1.39it/s]Loading train:  28%|██▊       | 75/266 [01:07<02:23,  1.33it/s]Loading train:  29%|██▊       | 76/266 [01:08<02:25,  1.31it/s]Loading train:  29%|██▉       | 77/266 [01:08<02:24,  1.30it/s]Loading train:  29%|██▉       | 78/266 [01:09<02:36,  1.20it/s]Loading train:  30%|██▉       | 79/266 [01:10<02:44,  1.13it/s]Loading train:  30%|███       | 80/266 [01:11<02:45,  1.12it/s]Loading train:  30%|███       | 81/266 [01:12<02:46,  1.11it/s]Loading train:  31%|███       | 82/266 [01:13<02:46,  1.11it/s]Loading train:  31%|███       | 83/266 [01:14<02:45,  1.10it/s]Loading train:  32%|███▏      | 84/266 [01:15<02:44,  1.10it/s]Loading train:  32%|███▏      | 85/266 [01:16<02:49,  1.07it/s]Loading train:  32%|███▏      | 86/266 [01:17<02:48,  1.07it/s]Loading train:  33%|███▎      | 87/266 [01:18<02:46,  1.08it/s]Loading train:  33%|███▎      | 88/266 [01:19<02:44,  1.08it/s]Loading train:  33%|███▎      | 89/266 [01:20<02:49,  1.05it/s]Loading train:  34%|███▍      | 90/266 [01:21<02:48,  1.04it/s]Loading train:  34%|███▍      | 91/266 [01:22<02:46,  1.05it/s]Loading train:  35%|███▍      | 92/266 [01:22<02:40,  1.08it/s]Loading train:  35%|███▍      | 93/266 [01:23<02:39,  1.08it/s]Loading train:  35%|███▌      | 94/266 [01:24<02:37,  1.09it/s]Loading train:  36%|███▌      | 95/266 [01:25<02:37,  1.09it/s]Loading train:  36%|███▌      | 96/266 [01:27<02:55,  1.03s/it]Loading train:  36%|███▋      | 97/266 [01:28<03:19,  1.18s/it]Loading train:  37%|███▋      | 98/266 [01:29<03:18,  1.18s/it]Loading train:  37%|███▋      | 99/266 [01:30<03:08,  1.13s/it]Loading train:  38%|███▊      | 100/266 [01:31<03:08,  1.14s/it]Loading train:  38%|███▊      | 101/266 [01:32<02:57,  1.08s/it]Loading train:  38%|███▊      | 102/266 [01:33<02:47,  1.02s/it]Loading train:  39%|███▊      | 103/266 [01:34<02:36,  1.04it/s]Loading train:  39%|███▉      | 104/266 [01:35<02:25,  1.11it/s]Loading train:  39%|███▉      | 105/266 [01:36<02:25,  1.11it/s]Loading train:  40%|███▉      | 106/266 [01:36<02:17,  1.16it/s]Loading train:  40%|████      | 107/266 [01:37<02:13,  1.19it/s]Loading train:  41%|████      | 108/266 [01:38<02:11,  1.20it/s]Loading train:  41%|████      | 109/266 [01:39<02:10,  1.20it/s]Loading train:  41%|████▏     | 110/266 [01:40<02:07,  1.22it/s]Loading train:  42%|████▏     | 111/266 [01:40<02:06,  1.22it/s]Loading train:  42%|████▏     | 112/266 [01:41<02:08,  1.20it/s]Loading train:  42%|████▏     | 113/266 [01:42<02:03,  1.24it/s]Loading train:  43%|████▎     | 114/266 [01:43<02:01,  1.25it/s]Loading train:  43%|████▎     | 115/266 [01:44<01:59,  1.27it/s]Loading train:  44%|████▎     | 116/266 [01:45<02:01,  1.23it/s]Loading train:  44%|████▍     | 117/266 [01:45<01:59,  1.25it/s]Loading train:  44%|████▍     | 118/266 [01:46<02:06,  1.17it/s]Loading train:  45%|████▍     | 119/266 [01:47<02:11,  1.12it/s]Loading train:  45%|████▌     | 120/266 [01:48<02:14,  1.09it/s]Loading train:  45%|████▌     | 121/266 [01:49<02:14,  1.08it/s]Loading train:  46%|████▌     | 122/266 [01:50<02:16,  1.06it/s]Loading train:  46%|████▌     | 123/266 [01:51<02:12,  1.08it/s]Loading train:  47%|████▋     | 124/266 [01:52<02:10,  1.09it/s]Loading train:  47%|████▋     | 125/266 [01:53<02:08,  1.10it/s]Loading train:  47%|████▋     | 126/266 [01:54<02:11,  1.06it/s]Loading train:  48%|████▊     | 127/266 [01:55<02:13,  1.04it/s]Loading train:  48%|████▊     | 128/266 [01:56<02:10,  1.06it/s]Loading train:  48%|████▊     | 129/266 [01:57<02:09,  1.06it/s]Loading train:  49%|████▉     | 130/266 [01:58<02:12,  1.03it/s]Loading train:  49%|████▉     | 131/266 [01:59<02:09,  1.04it/s]Loading train:  50%|████▉     | 132/266 [02:00<02:06,  1.06it/s]Loading train:  50%|█████     | 133/266 [02:01<02:07,  1.04it/s]Loading train:  50%|█████     | 134/266 [02:02<02:04,  1.06it/s]Loading train:  51%|█████     | 135/266 [02:02<02:02,  1.07it/s]Loading train:  51%|█████     | 136/266 [02:03<02:01,  1.07it/s]Loading train:  52%|█████▏    | 137/266 [02:04<02:01,  1.06it/s]Loading train:  52%|█████▏    | 138/266 [02:05<01:55,  1.11it/s]Loading train:  52%|█████▏    | 139/266 [02:06<01:51,  1.14it/s]Loading train:  53%|█████▎    | 140/266 [02:07<01:51,  1.13it/s]Loading train:  53%|█████▎    | 141/266 [02:08<01:49,  1.14it/s]Loading train:  53%|█████▎    | 142/266 [02:09<01:51,  1.11it/s]Loading train:  54%|█████▍    | 143/266 [02:09<01:47,  1.15it/s]Loading train:  54%|█████▍    | 144/266 [02:10<01:44,  1.16it/s]Loading train:  55%|█████▍    | 145/266 [02:11<01:43,  1.17it/s]Loading train:  55%|█████▍    | 146/266 [02:12<01:42,  1.17it/s]Loading train:  55%|█████▌    | 147/266 [02:13<01:47,  1.11it/s]Loading train:  56%|█████▌    | 148/266 [02:14<01:47,  1.09it/s]Loading train:  56%|█████▌    | 149/266 [02:15<01:46,  1.10it/s]Loading train:  56%|█████▋    | 150/266 [02:16<01:42,  1.13it/s]Loading train:  57%|█████▋    | 151/266 [02:17<01:41,  1.13it/s]Loading train:  57%|█████▋    | 152/266 [02:17<01:41,  1.12it/s]Loading train:  58%|█████▊    | 153/266 [02:18<01:43,  1.10it/s]Loading train:  58%|█████▊    | 154/266 [02:19<01:42,  1.09it/s]Loading train:  58%|█████▊    | 155/266 [02:20<01:36,  1.14it/s]Loading train:  59%|█████▊    | 156/266 [02:21<01:29,  1.23it/s]Loading train:  59%|█████▉    | 157/266 [02:22<01:28,  1.23it/s]Loading train:  59%|█████▉    | 158/266 [02:22<01:23,  1.30it/s]Loading train:  60%|█████▉    | 159/266 [02:23<01:20,  1.33it/s]Loading train:  60%|██████    | 160/266 [02:24<01:19,  1.34it/s]Loading train:  61%|██████    | 161/266 [02:24<01:15,  1.39it/s]Loading train:  61%|██████    | 162/266 [02:25<01:14,  1.40it/s]Loading train:  61%|██████▏   | 163/266 [02:26<01:11,  1.43it/s]Loading train:  62%|██████▏   | 164/266 [02:27<01:13,  1.39it/s]Loading train:  62%|██████▏   | 165/266 [02:27<01:12,  1.39it/s]Loading train:  62%|██████▏   | 166/266 [02:28<01:11,  1.40it/s]Loading train:  63%|██████▎   | 167/266 [02:29<01:10,  1.41it/s]Loading train:  63%|██████▎   | 168/266 [02:29<01:10,  1.39it/s]Loading train:  64%|██████▎   | 169/266 [02:30<01:10,  1.37it/s]Loading train:  64%|██████▍   | 170/266 [02:31<01:09,  1.39it/s]Loading train:  64%|██████▍   | 171/266 [02:31<01:05,  1.45it/s]Loading train:  65%|██████▍   | 172/266 [02:32<01:02,  1.49it/s]Loading train:  65%|██████▌   | 173/266 [02:33<01:06,  1.39it/s]Loading train:  65%|██████▌   | 174/266 [02:34<01:07,  1.37it/s]Loading train:  66%|██████▌   | 175/266 [02:34<01:07,  1.35it/s]Loading train:  66%|██████▌   | 176/266 [02:35<01:09,  1.29it/s]Loading train:  67%|██████▋   | 177/266 [02:36<01:08,  1.29it/s]Loading train:  67%|██████▋   | 178/266 [02:37<01:05,  1.34it/s]Loading train:  67%|██████▋   | 179/266 [02:37<01:05,  1.34it/s]Loading train:  68%|██████▊   | 180/266 [02:38<01:05,  1.31it/s]Loading train:  68%|██████▊   | 181/266 [02:39<01:07,  1.27it/s]Loading train:  68%|██████▊   | 182/266 [02:40<01:04,  1.30it/s]Loading train:  69%|██████▉   | 183/266 [02:41<01:03,  1.31it/s]Loading train:  69%|██████▉   | 184/266 [02:41<01:00,  1.34it/s]Loading train:  70%|██████▉   | 185/266 [02:42<01:02,  1.29it/s]Loading train:  70%|██████▉   | 186/266 [02:43<00:59,  1.34it/s]Loading train:  70%|███████   | 187/266 [02:44<00:59,  1.32it/s]Loading train:  71%|███████   | 188/266 [02:44<00:58,  1.33it/s]Loading train:  71%|███████   | 189/266 [02:45<00:57,  1.33it/s]Loading train:  71%|███████▏  | 190/266 [02:46<00:57,  1.31it/s]Loading train:  72%|███████▏  | 191/266 [02:47<01:07,  1.11it/s]Loading train:  72%|███████▏  | 192/266 [02:48<01:09,  1.06it/s]Loading train:  73%|███████▎  | 193/266 [02:49<01:12,  1.00it/s]Loading train:  73%|███████▎  | 194/266 [02:51<01:22,  1.15s/it]Loading train:  73%|███████▎  | 195/266 [02:52<01:14,  1.05s/it]Loading train:  74%|███████▎  | 196/266 [02:52<01:07,  1.03it/s]Loading train:  74%|███████▍  | 197/266 [02:53<01:02,  1.11it/s]Loading train:  74%|███████▍  | 198/266 [02:54<00:59,  1.14it/s]Loading train:  75%|███████▍  | 199/266 [02:55<00:55,  1.20it/s]Loading train:  75%|███████▌  | 200/266 [02:56<00:56,  1.18it/s]Loading train:  76%|███████▌  | 201/266 [02:56<00:55,  1.18it/s]Loading train:  76%|███████▌  | 202/266 [02:57<00:52,  1.21it/s]Loading train:  76%|███████▋  | 203/266 [02:58<00:51,  1.22it/s]Loading train:  77%|███████▋  | 204/266 [02:59<00:49,  1.26it/s]Loading train:  77%|███████▋  | 205/266 [03:00<00:48,  1.25it/s]Loading train:  77%|███████▋  | 206/266 [03:00<00:49,  1.22it/s]Loading train:  78%|███████▊  | 207/266 [03:01<00:49,  1.20it/s]Loading train:  78%|███████▊  | 208/266 [03:02<00:46,  1.24it/s]Loading train:  79%|███████▊  | 209/266 [03:03<00:46,  1.24it/s]Loading train:  79%|███████▉  | 210/266 [03:04<00:45,  1.23it/s]Loading train:  79%|███████▉  | 211/266 [03:04<00:45,  1.21it/s]Loading train:  80%|███████▉  | 212/266 [03:05<00:45,  1.18it/s]Loading train:  80%|████████  | 213/266 [03:06<00:44,  1.20it/s]Loading train:  80%|████████  | 214/266 [03:07<00:41,  1.24it/s]Loading train:  81%|████████  | 215/266 [03:08<00:40,  1.27it/s]Loading train:  81%|████████  | 216/266 [03:08<00:38,  1.31it/s]Loading train:  82%|████████▏ | 217/266 [03:09<00:36,  1.33it/s]Loading train:  82%|████████▏ | 218/266 [03:10<00:37,  1.29it/s]Loading train:  82%|████████▏ | 219/266 [03:11<00:36,  1.29it/s]Loading train:  83%|████████▎ | 220/266 [03:11<00:35,  1.31it/s]Loading train:  83%|████████▎ | 221/266 [03:12<00:34,  1.31it/s]Loading train:  83%|████████▎ | 222/266 [03:13<00:32,  1.34it/s]Loading train:  84%|████████▍ | 223/266 [03:14<00:31,  1.35it/s]Loading train:  84%|████████▍ | 224/266 [03:14<00:30,  1.36it/s]Loading train:  85%|████████▍ | 225/266 [03:15<00:29,  1.40it/s]Loading train:  85%|████████▍ | 226/266 [03:16<00:27,  1.44it/s]Loading train:  85%|████████▌ | 227/266 [03:16<00:26,  1.49it/s]Loading train:  86%|████████▌ | 228/266 [03:17<00:25,  1.49it/s]Loading train:  86%|████████▌ | 229/266 [03:18<00:25,  1.43it/s]Loading train:  86%|████████▋ | 230/266 [03:18<00:25,  1.43it/s]Loading train:  87%|████████▋ | 231/266 [03:19<00:24,  1.44it/s]Loading train:  87%|████████▋ | 232/266 [03:20<00:23,  1.47it/s]Loading train:  88%|████████▊ | 233/266 [03:20<00:21,  1.53it/s]Loading train:  88%|████████▊ | 234/266 [03:21<00:21,  1.50it/s]Loading train:  88%|████████▊ | 235/266 [03:22<00:21,  1.46it/s]Loading train:  89%|████████▊ | 236/266 [03:23<00:21,  1.42it/s]Loading train:  89%|████████▉ | 237/266 [03:23<00:20,  1.45it/s]Loading train:  89%|████████▉ | 238/266 [03:24<00:19,  1.46it/s]Loading train:  90%|████████▉ | 239/266 [03:25<00:18,  1.47it/s]Loading train:  90%|█████████ | 240/266 [03:25<00:17,  1.46it/s]Loading train:  91%|█████████ | 241/266 [03:26<00:17,  1.42it/s]Loading train:  91%|█████████ | 242/266 [03:27<00:16,  1.44it/s]Loading train:  91%|█████████▏| 243/266 [03:27<00:15,  1.44it/s]Loading train:  92%|█████████▏| 244/266 [03:28<00:14,  1.48it/s]Loading train:  92%|█████████▏| 245/266 [03:29<00:14,  1.42it/s]Loading train:  92%|█████████▏| 246/266 [03:29<00:14,  1.41it/s]Loading train:  93%|█████████▎| 247/266 [03:30<00:13,  1.45it/s]Loading train:  93%|█████████▎| 248/266 [03:31<00:12,  1.45it/s]Loading train:  94%|█████████▎| 249/266 [03:32<00:12,  1.35it/s]Loading train:  94%|█████████▍| 250/266 [03:32<00:12,  1.29it/s]Loading train:  94%|█████████▍| 251/266 [03:33<00:12,  1.22it/s]Loading train:  95%|█████████▍| 252/266 [03:34<00:11,  1.20it/s]Loading train:  95%|█████████▌| 253/266 [03:35<00:11,  1.18it/s]Loading train:  95%|█████████▌| 254/266 [03:36<00:10,  1.17it/s]Loading train:  96%|█████████▌| 255/266 [03:37<00:09,  1.17it/s]Loading train:  96%|█████████▌| 256/266 [03:38<00:08,  1.17it/s]Loading train:  97%|█████████▋| 257/266 [03:39<00:07,  1.15it/s]Loading train:  97%|█████████▋| 258/266 [03:39<00:06,  1.17it/s]Loading train:  97%|█████████▋| 259/266 [03:40<00:06,  1.12it/s]Loading train:  98%|█████████▊| 260/266 [03:41<00:05,  1.13it/s]Loading train:  98%|█████████▊| 261/266 [03:42<00:04,  1.14it/s]Loading train:  98%|█████████▊| 262/266 [03:43<00:03,  1.15it/s]Loading train:  99%|█████████▉| 263/266 [03:44<00:02,  1.14it/s]Loading train:  99%|█████████▉| 264/266 [03:45<00:01,  1.13it/s]Loading train: 100%|█████████▉| 265/266 [03:46<00:00,  1.13it/s]Loading train: 100%|██████████| 266/266 [03:47<00:00,  1.14it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:02, 90.87it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:02, 105.55it/s]concatenating: train:  20%|█▉        | 52/266 [00:00<00:01, 127.54it/s]concatenating: train:  29%|██▊       | 76/266 [00:00<00:01, 147.55it/s]concatenating: train:  38%|███▊      | 100/266 [00:00<00:01, 164.98it/s]concatenating: train:  47%|████▋     | 126/266 [00:00<00:00, 184.75it/s]concatenating: train:  56%|█████▌    | 148/266 [00:00<00:00, 192.81it/s]concatenating: train:  65%|██████▌   | 173/266 [00:00<00:00, 205.58it/s]concatenating: train:  74%|███████▍  | 198/266 [00:00<00:00, 216.41it/s]concatenating: train:  84%|████████▍ | 224/266 [00:01<00:00, 226.68it/s]concatenating: train:  93%|█████████▎| 248/266 [00:01<00:00, 178.73it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 205.20it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.21s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.21s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.16s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.15s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 345.09it/s]2019-08-16 22:30:09.705705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 22:30:09.705805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 22:30:09.705822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 22:30:09.705831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 22:30:09.706248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.70it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.72it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.45it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.25it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.07it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.80it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.31it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.17it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.65it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.72it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.36it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.34it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.43it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.36it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.93it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 49,153
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33494853e-02 3.28331586e-02 7.67758257e-02 9.53978241e-03
 2.76103026e-02 7.22345740e-03 8.44347002e-02 1.14114625e-01
 8.96025047e-02 1.36137385e-02 2.90508944e-01 1.90134732e-01
 2.58742770e-04]
Train on 9733 samples, validate on 178 samples
Epoch 1/300
 - 14s - loss: 2.6975 - acc: 0.5218 - mDice: 0.1143 - val_loss: 1.9048 - val_acc: 0.9029 - val_mDice: 0.2107

Epoch 00001: val_mDice improved from -inf to 0.21068, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.1231 - acc: 0.8812 - mDice: 0.3191 - val_loss: 0.8474 - val_acc: 0.9116 - val_mDice: 0.4264

Epoch 00002: val_mDice improved from 0.21068 to 0.42645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.8491 - acc: 0.8899 - mDice: 0.4127 - val_loss: 0.7025 - val_acc: 0.9202 - val_mDice: 0.4838

Epoch 00003: val_mDice improved from 0.42645 to 0.48380, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.7369 - acc: 0.8953 - mDice: 0.4623 - val_loss: 0.6470 - val_acc: 0.9222 - val_mDice: 0.5126

Epoch 00004: val_mDice improved from 0.48380 to 0.51260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6695 - acc: 0.8992 - mDice: 0.4956 - val_loss: 1.2891 - val_acc: 0.9170 - val_mDice: 0.4155

Epoch 00005: val_mDice did not improve from 0.51260
Epoch 6/300
 - 9s - loss: 0.6198 - acc: 0.9034 - mDice: 0.5220 - val_loss: 0.5649 - val_acc: 0.9262 - val_mDice: 0.5559

Epoch 00006: val_mDice improved from 0.51260 to 0.55595, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.5816 - acc: 0.9077 - mDice: 0.5427 - val_loss: 0.5907 - val_acc: 0.9301 - val_mDice: 0.5506

Epoch 00007: val_mDice did not improve from 0.55595
Epoch 8/300
 - 9s - loss: 0.5523 - acc: 0.9122 - mDice: 0.5596 - val_loss: 0.5411 - val_acc: 0.9357 - val_mDice: 0.5735

Epoch 00008: val_mDice improved from 0.55595 to 0.57353, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.5301 - acc: 0.9167 - mDice: 0.5728 - val_loss: 0.5181 - val_acc: 0.9352 - val_mDice: 0.5851

Epoch 00009: val_mDice improved from 0.57353 to 0.58505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.5105 - acc: 0.9200 - mDice: 0.5850 - val_loss: 0.4926 - val_acc: 0.9389 - val_mDice: 0.5994

Epoch 00010: val_mDice improved from 0.58505 to 0.59943, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4926 - acc: 0.9223 - mDice: 0.5957 - val_loss: 0.5446 - val_acc: 0.9300 - val_mDice: 0.5706

Epoch 00011: val_mDice did not improve from 0.59943
Epoch 12/300
 - 9s - loss: 0.4750 - acc: 0.9246 - mDice: 0.6066 - val_loss: 0.5369 - val_acc: 0.9289 - val_mDice: 0.5737

Epoch 00012: val_mDice did not improve from 0.59943
Epoch 13/300
 - 9s - loss: 0.4648 - acc: 0.9259 - mDice: 0.6130 - val_loss: 0.4846 - val_acc: 0.9402 - val_mDice: 0.6063

Epoch 00013: val_mDice improved from 0.59943 to 0.60633, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 9s - loss: 0.4513 - acc: 0.9273 - mDice: 0.6216 - val_loss: 0.5039 - val_acc: 0.9374 - val_mDice: 0.5957

Epoch 00014: val_mDice did not improve from 0.60633
Epoch 15/300
 - 8s - loss: 0.4416 - acc: 0.9285 - mDice: 0.6279 - val_loss: 0.4777 - val_acc: 0.9418 - val_mDice: 0.6097

Epoch 00015: val_mDice improved from 0.60633 to 0.60973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.4308 - acc: 0.9296 - mDice: 0.6352 - val_loss: 0.4849 - val_acc: 0.9426 - val_mDice: 0.6048

Epoch 00016: val_mDice did not improve from 0.60973
Epoch 17/300
 - 9s - loss: 0.4253 - acc: 0.9305 - mDice: 0.6389 - val_loss: 0.5097 - val_acc: 0.9394 - val_mDice: 0.5911

Epoch 00017: val_mDice did not improve from 0.60973
Epoch 18/300
 - 9s - loss: 0.4155 - acc: 0.9317 - mDice: 0.6453 - val_loss: 0.7253 - val_acc: 0.9358 - val_mDice: 0.5998

Epoch 00018: val_mDice did not improve from 0.60973
Epoch 19/300
 - 9s - loss: 0.4084 - acc: 0.9325 - mDice: 0.6501 - val_loss: 0.4655 - val_acc: 0.9446 - val_mDice: 0.6149

Epoch 00019: val_mDice improved from 0.60973 to 0.61490, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 9s - loss: 0.4555 - acc: 0.9292 - mDice: 0.6239 - val_loss: 0.4904 - val_acc: 0.9404 - val_mDice: 0.6063

Epoch 00020: val_mDice did not improve from 0.61490
Epoch 21/300
 - 9s - loss: 0.4097 - acc: 0.9329 - mDice: 0.6495 - val_loss: 0.4949 - val_acc: 0.9402 - val_mDice: 0.6012

Epoch 00021: val_mDice did not improve from 0.61490
Epoch 22/300
 - 9s - loss: 0.4000 - acc: 0.9341 - mDice: 0.6560 - val_loss: 0.4675 - val_acc: 0.9430 - val_mDice: 0.6151

Epoch 00022: val_mDice improved from 0.61490 to 0.61513, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 9s - loss: 0.3902 - acc: 0.9349 - mDice: 0.6626 - val_loss: 0.4840 - val_acc: 0.9396 - val_mDice: 0.6105

Epoch 00023: val_mDice did not improve from 0.61513
Epoch 24/300
 - 9s - loss: 0.3879 - acc: 0.9354 - mDice: 0.6643 - val_loss: 0.4824 - val_acc: 0.9446 - val_mDice: 0.6050

Epoch 00024: val_mDice did not improve from 0.61513
Epoch 25/300
 - 9s - loss: 0.3832 - acc: 0.9362 - mDice: 0.6679 - val_loss: 0.4862 - val_acc: 0.9418 - val_mDice: 0.6091

Epoch 00025: val_mDice did not improve from 0.61513
Epoch 26/300
 - 9s - loss: 0.3793 - acc: 0.9364 - mDice: 0.6701 - val_loss: 0.4480 - val_acc: 0.9481 - val_mDice: 0.6272

Epoch 00026: val_mDice improved from 0.61513 to 0.62720, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 9s - loss: 0.3742 - acc: 0.9371 - mDice: 0.6737 - val_loss: 0.4850 - val_acc: 0.9447 - val_mDice: 0.6134

Epoch 00027: val_mDice did not improve from 0.62720
Epoch 28/300
 - 9s - loss: 0.3719 - acc: 0.9377 - mDice: 0.6757 - val_loss: 0.8685 - val_acc: 0.9348 - val_mDice: 0.5914

Epoch 00028: val_mDice did not improve from 0.62720
Epoch 29/300
 - 9s - loss: 0.3692 - acc: 0.9380 - mDice: 0.6774 - val_loss: 0.5392 - val_acc: 0.9406 - val_mDice: 0.5777

Epoch 00029: val_mDice did not improve from 0.62720
Epoch 30/300
 - 9s - loss: 0.3664 - acc: 0.9384 - mDice: 0.6795 - val_loss: 0.7157 - val_acc: 0.9424 - val_mDice: 0.6165

Epoch 00030: val_mDice did not improve from 0.62720
Epoch 31/300
 - 9s - loss: 0.3639 - acc: 0.9386 - mDice: 0.6810 - val_loss: 0.6158 - val_acc: 0.9407 - val_mDice: 0.5564

Epoch 00031: val_mDice did not improve from 0.62720
Epoch 32/300
 - 9s - loss: 0.3614 - acc: 0.9390 - mDice: 0.6830 - val_loss: 0.4431 - val_acc: 0.9459 - val_mDice: 0.6283

Epoch 00032: val_mDice improved from 0.62720 to 0.62829, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 9s - loss: 0.3585 - acc: 0.9393 - mDice: 0.6849 - val_loss: 0.5222 - val_acc: 0.9344 - val_mDice: 0.5871

Epoch 00033: val_mDice did not improve from 0.62829
Epoch 34/300
 - 9s - loss: 0.3564 - acc: 0.9397 - mDice: 0.6866 - val_loss: 0.4546 - val_acc: 0.9458 - val_mDice: 0.6250

Epoch 00034: val_mDice did not improve from 0.62829
Epoch 35/300
 - 9s - loss: 0.3516 - acc: 0.9402 - mDice: 0.6899 - val_loss: 1.4291 - val_acc: 0.9285 - val_mDice: 0.4392

Epoch 00035: val_mDice did not improve from 0.62829
Epoch 36/300
 - 9s - loss: 0.3494 - acc: 0.9405 - mDice: 0.6915 - val_loss: 0.4797 - val_acc: 0.9449 - val_mDice: 0.6073

Epoch 00036: val_mDice did not improve from 0.62829
Epoch 37/300
 - 9s - loss: 0.3489 - acc: 0.9407 - mDice: 0.6920 - val_loss: 0.4685 - val_acc: 0.9455 - val_mDice: 0.6136

Epoch 00037: val_mDice did not improve from 0.62829
Epoch 38/300
 - 9s - loss: 0.3456 - acc: 0.9407 - mDice: 0.6943 - val_loss: 0.4458 - val_acc: 0.9471 - val_mDice: 0.6286

Epoch 00038: val_mDice improved from 0.62829 to 0.62864, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 9s - loss: 0.3438 - acc: 0.9412 - mDice: 0.6956 - val_loss: 0.4700 - val_acc: 0.9445 - val_mDice: 0.6136

Epoch 00039: val_mDice did not improve from 0.62864
Epoch 40/300
 - 9s - loss: 0.3342 - acc: 0.9414 - mDice: 0.7019 - val_loss: 0.4837 - val_acc: 0.9445 - val_mDice: 0.6044

Epoch 00040: val_mDice did not improve from 0.62864
Epoch 41/300
 - 9s - loss: 0.3294 - acc: 0.9416 - mDice: 0.7053 - val_loss: 0.4765 - val_acc: 0.9425 - val_mDice: 0.6159

Epoch 00041: val_mDice did not improve from 0.62864
Epoch 42/300
 - 9s - loss: 0.3252 - acc: 0.9419 - mDice: 0.7084 - val_loss: 0.4500 - val_acc: 0.9471 - val_mDice: 0.6260

Epoch 00042: val_mDice did not improve from 0.62864
Epoch 43/300
 - 9s - loss: 0.3235 - acc: 0.9423 - mDice: 0.7097 - val_loss: 0.4724 - val_acc: 0.9448 - val_mDice: 0.6207

Epoch 00043: val_mDice did not improve from 0.62864
Epoch 44/300
 - 9s - loss: 0.3239 - acc: 0.9421 - mDice: 0.7094 - val_loss: 0.4496 - val_acc: 0.9456 - val_mDice: 0.6277

Epoch 00044: val_mDice did not improve from 0.62864
Epoch 45/300
 - 9s - loss: 0.3209 - acc: 0.9423 - mDice: 0.7115 - val_loss: 0.8124 - val_acc: 0.9234 - val_mDice: 0.5527

Epoch 00045: val_mDice did not improve from 0.62864
Epoch 46/300
 - 9s - loss: 0.3198 - acc: 0.9426 - mDice: 0.7124 - val_loss: 0.4458 - val_acc: 0.9482 - val_mDice: 0.6307

Epoch 00046: val_mDice improved from 0.62864 to 0.63074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 9s - loss: 0.3174 - acc: 0.9429 - mDice: 0.7143 - val_loss: 0.5000 - val_acc: 0.9411 - val_mDice: 0.6108

Epoch 00047: val_mDice did not improve from 0.63074
Epoch 48/300
 - 9s - loss: 0.3153 - acc: 0.9432 - mDice: 0.7158 - val_loss: 0.4640 - val_acc: 0.9460 - val_mDice: 0.6163

Epoch 00048: val_mDice did not improve from 0.63074
Epoch 49/300
 - 9s - loss: 0.3133 - acc: 0.9434 - mDice: 0.7172 - val_loss: 0.4619 - val_acc: 0.9468 - val_mDice: 0.6195

Epoch 00049: val_mDice did not improve from 0.63074
Epoch 50/300
 - 9s - loss: 0.3120 - acc: 0.9435 - mDice: 0.7184 - val_loss: 0.4681 - val_acc: 0.9453 - val_mDice: 0.6200

Epoch 00050: val_mDice did not improve from 0.63074
Epoch 51/300
 - 9s - loss: 0.3117 - acc: 0.9436 - mDice: 0.7185 - val_loss: 0.6617 - val_acc: 0.9414 - val_mDice: 0.5599

Epoch 00051: val_mDice did not improve from 0.63074
Epoch 52/300
 - 9s - loss: 0.3097 - acc: 0.9437 - mDice: 0.7199 - val_loss: 0.4700 - val_acc: 0.9472 - val_mDice: 0.6135

Epoch 00052: val_mDice did not improve from 0.63074
Epoch 53/300
 - 9s - loss: 0.3091 - acc: 0.9439 - mDice: 0.7204 - val_loss: 0.5425 - val_acc: 0.9385 - val_mDice: 0.5761

Epoch 00053: val_mDice did not improve from 0.63074
Epoch 54/300
 - 9s - loss: 0.3095 - acc: 0.9439 - mDice: 0.7203 - val_loss: 0.4478 - val_acc: 0.9456 - val_mDice: 0.6303

Epoch 00054: val_mDice did not improve from 0.63074
Epoch 55/300
 - 9s - loss: 0.3066 - acc: 0.9441 - mDice: 0.7223 - val_loss: 0.4943 - val_acc: 0.9465 - val_mDice: 0.6019

Epoch 00055: val_mDice did not improve from 0.63074
Epoch 56/300
 - 9s - loss: 0.3034 - acc: 0.9445 - mDice: 0.7248 - val_loss: 0.4644 - val_acc: 0.9432 - val_mDice: 0.6190

Epoch 00056: val_mDice did not improve from 0.63074
Epoch 57/300
 - 9s - loss: 0.3033 - acc: 0.9445 - mDice: 0.7249 - val_loss: 0.4650 - val_acc: 0.9475 - val_mDice: 0.6181

Epoch 00057: val_mDice did not improve from 0.63074
Epoch 58/300
 - 9s - loss: 0.3078 - acc: 0.9442 - mDice: 0.7216 - val_loss: 0.5052 - val_acc: 0.9438 - val_mDice: 0.5982

Epoch 00058: val_mDice did not improve from 0.63074
Epoch 59/300
 - 9s - loss: 0.3018 - acc: 0.9446 - mDice: 0.7261 - val_loss: 0.4778 - val_acc: 0.9447 - val_mDice: 0.6113

Epoch 00059: val_mDice did not improve from 0.63074
Epoch 60/300
 - 9s - loss: 0.3920 - acc: 0.9367 - mDice: 0.6674 - val_loss: 0.4630 - val_acc: 0.9482 - val_mDice: 0.6219

Epoch 00060: val_mDice did not improve from 0.63074
Epoch 61/300
 - 9s - loss: 0.3245 - acc: 0.9430 - mDice: 0.7092 - val_loss: 0.4428 - val_acc: 0.9467 - val_mDice: 0.6326

Epoch 00061: val_mDice improved from 0.63074 to 0.63255, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 9s - loss: 0.3128 - acc: 0.9439 - mDice: 0.7178 - val_loss: 0.4891 - val_acc: 0.9423 - val_mDice: 0.6105

Epoch 00062: val_mDice did not improve from 0.63255
Epoch 63/300
 - 9s - loss: 0.3080 - acc: 0.9443 - mDice: 0.7214 - val_loss: 0.4860 - val_acc: 0.9398 - val_mDice: 0.6115

Epoch 00063: val_mDice did not improve from 0.63255
Epoch 64/300
 - 9s - loss: 0.3049 - acc: 0.9445 - mDice: 0.7237 - val_loss: 0.4695 - val_acc: 0.9462 - val_mDice: 0.6191

Epoch 00064: val_mDice did not improve from 0.63255
Epoch 65/300
 - 9s - loss: 0.3018 - acc: 0.9447 - mDice: 0.7260 - val_loss: 0.4398 - val_acc: 0.9465 - val_mDice: 0.6360

Epoch 00065: val_mDice improved from 0.63255 to 0.63597, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 66/300
 - 9s - loss: 0.3010 - acc: 0.9447 - mDice: 0.7265 - val_loss: 0.4551 - val_acc: 0.9485 - val_mDice: 0.6249

Epoch 00066: val_mDice did not improve from 0.63597
Epoch 67/300
 - 9s - loss: 0.2998 - acc: 0.9450 - mDice: 0.7275 - val_loss: 0.4519 - val_acc: 0.9447 - val_mDice: 0.6280

Epoch 00067: val_mDice did not improve from 0.63597
Epoch 68/300
 - 9s - loss: 0.2996 - acc: 0.9450 - mDice: 0.7279 - val_loss: 0.4536 - val_acc: 0.9490 - val_mDice: 0.6272

Epoch 00068: val_mDice did not improve from 0.63597
Epoch 69/300
 - 9s - loss: 0.2981 - acc: 0.9451 - mDice: 0.7288 - val_loss: 0.4869 - val_acc: 0.9432 - val_mDice: 0.6076

Epoch 00069: val_mDice did not improve from 0.63597
Epoch 70/300
 - 9s - loss: 0.2958 - acc: 0.9454 - mDice: 0.7306 - val_loss: 0.4414 - val_acc: 0.9493 - val_mDice: 0.6336

Epoch 00070: val_mDice did not improve from 0.63597
Epoch 71/300
 - 9s - loss: 0.2958 - acc: 0.9454 - mDice: 0.7306 - val_loss: 0.4980 - val_acc: 0.9460 - val_mDice: 0.6005

Epoch 00071: val_mDice did not improve from 0.63597
Epoch 72/300
 - 9s - loss: 0.2953 - acc: 0.9455 - mDice: 0.7310 - val_loss: 0.4399 - val_acc: 0.9503 - val_mDice: 0.6365

Epoch 00072: val_mDice improved from 0.63597 to 0.63651, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 73/300
 - 10s - loss: 0.2935 - acc: 0.9456 - mDice: 0.7323 - val_loss: 0.4532 - val_acc: 0.9444 - val_mDice: 0.6268

Epoch 00073: val_mDice did not improve from 0.63651
Epoch 74/300
 - 9s - loss: 0.2931 - acc: 0.9457 - mDice: 0.7326 - val_loss: 0.4392 - val_acc: 0.9487 - val_mDice: 0.6340

Epoch 00074: val_mDice did not improve from 0.63651
Epoch 75/300
 - 9s - loss: 0.2924 - acc: 0.9459 - mDice: 0.7332 - val_loss: 0.4881 - val_acc: 0.9466 - val_mDice: 0.6120

Epoch 00075: val_mDice did not improve from 0.63651
Epoch 76/300
 - 9s - loss: 0.2961 - acc: 0.9454 - mDice: 0.7306 - val_loss: 0.4755 - val_acc: 0.9459 - val_mDice: 0.6101

Epoch 00076: val_mDice did not improve from 0.63651
Epoch 77/300
 - 9s - loss: 0.2937 - acc: 0.9456 - mDice: 0.7323 - val_loss: 0.4411 - val_acc: 0.9470 - val_mDice: 0.6336

Epoch 00077: val_mDice did not improve from 0.63651
Epoch 78/300
 - 9s - loss: 0.2910 - acc: 0.9457 - mDice: 0.7342 - val_loss: 0.4845 - val_acc: 0.9469 - val_mDice: 0.6096

Epoch 00078: val_mDice did not improve from 0.63651
Epoch 79/300
 - 9s - loss: 0.2893 - acc: 0.9460 - mDice: 0.7355 - val_loss: 0.4340 - val_acc: 0.9482 - val_mDice: 0.6376

Epoch 00079: val_mDice improved from 0.63651 to 0.63756, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 80/300
 - 9s - loss: 0.2914 - acc: 0.9459 - mDice: 0.7340 - val_loss: 0.4465 - val_acc: 0.9488 - val_mDice: 0.6306

Epoch 00080: val_mDice did not improve from 0.63756
Epoch 81/300
 - 9s - loss: 0.2918 - acc: 0.9459 - mDice: 0.7337 - val_loss: 0.4739 - val_acc: 0.9458 - val_mDice: 0.6113

Epoch 00081: val_mDice did not improve from 0.63756
Epoch 82/300
 - 9s - loss: 0.2893 - acc: 0.9462 - mDice: 0.7356 - val_loss: 0.4352 - val_acc: 0.9499 - val_mDice: 0.6352

Epoch 00082: val_mDice did not improve from 0.63756
Epoch 83/300
 - 9s - loss: 0.2891 - acc: 0.9462 - mDice: 0.7358 - val_loss: 0.6423 - val_acc: 0.9445 - val_mDice: 0.6209

Epoch 00083: val_mDice did not improve from 0.63756
Epoch 84/300
 - 9s - loss: 0.2882 - acc: 0.9462 - mDice: 0.7365 - val_loss: 0.4527 - val_acc: 0.9452 - val_mDice: 0.6265

Epoch 00084: val_mDice did not improve from 0.63756
Epoch 85/300
 - 9s - loss: 0.2862 - acc: 0.9462 - mDice: 0.7378 - val_loss: 0.6006 - val_acc: 0.9383 - val_mDice: 0.6080

Epoch 00085: val_mDice did not improve from 0.63756
Epoch 86/300
 - 9s - loss: 0.2859 - acc: 0.9464 - mDice: 0.7382 - val_loss: 0.4338 - val_acc: 0.9483 - val_mDice: 0.6369

Epoch 00086: val_mDice did not improve from 0.63756
Epoch 87/300
 - 9s - loss: 0.2873 - acc: 0.9463 - mDice: 0.7372 - val_loss: 0.5569 - val_acc: 0.9424 - val_mDice: 0.6149

Epoch 00087: val_mDice did not improve from 0.63756
Epoch 88/300
 - 9s - loss: 0.2861 - acc: 0.9465 - mDice: 0.7382 - val_loss: 0.4601 - val_acc: 0.9468 - val_mDice: 0.6265

Epoch 00088: val_mDice did not improve from 0.63756
Epoch 89/300
 - 9s - loss: 0.2845 - acc: 0.9467 - mDice: 0.7393 - val_loss: 0.4411 - val_acc: 0.9488 - val_mDice: 0.6318

Epoch 00089: val_mDice did not improve from 0.63756
Epoch 90/300
 - 9s - loss: 0.2842 - acc: 0.9465 - mDice: 0.7396 - val_loss: 0.6924 - val_acc: 0.9384 - val_mDice: 0.6004

Epoch 00090: val_mDice did not improve from 0.63756
Epoch 91/300
 - 9s - loss: 0.2840 - acc: 0.9464 - mDice: 0.7397 - val_loss: 0.4650 - val_acc: 0.9475 - val_mDice: 0.6182

Epoch 00091: val_mDice did not improve from 0.63756
Epoch 92/300
 - 9s - loss: 0.2838 - acc: 0.9467 - mDice: 0.7401 - val_loss: 0.4682 - val_acc: 0.9444 - val_mDice: 0.6241

Epoch 00092: val_mDice did not improve from 0.63756
Epoch 93/300
 - 9s - loss: 0.2817 - acc: 0.9469 - mDice: 0.7414 - val_loss: 0.4471 - val_acc: 0.9458 - val_mDice: 0.6290

Epoch 00093: val_mDice did not improve from 0.63756
Epoch 94/300
 - 9s - loss: 0.2814 - acc: 0.9469 - mDice: 0.7416 - val_loss: 0.4713 - val_acc: 0.9494 - val_mDice: 0.6198

Epoch 00094: val_mDice did not improve from 0.63756
Epoch 95/300
 - 9s - loss: 0.2820 - acc: 0.9467 - mDice: 0.7413 - val_loss: 0.4457 - val_acc: 0.9495 - val_mDice: 0.6277

Epoch 00095: val_mDice did not improve from 0.63756
Epoch 96/300
 - 9s - loss: 0.2798 - acc: 0.9470 - mDice: 0.7429 - val_loss: 0.4358 - val_acc: 0.9469 - val_mDice: 0.6373

Epoch 00096: val_mDice did not improve from 0.63756
Epoch 97/300
 - 9s - loss: 0.2798 - acc: 0.9470 - mDice: 0.7429 - val_loss: 0.4505 - val_acc: 0.9459 - val_mDice: 0.6305

Epoch 00097: val_mDice did not improve from 0.63756
Epoch 98/300
 - 9s - loss: 0.2817 - acc: 0.9469 - mDice: 0.7415 - val_loss: 0.4557 - val_acc: 0.9443 - val_mDice: 0.6283

Epoch 00098: val_mDice did not improve from 0.63756
Epoch 99/300
 - 10s - loss: 0.2786 - acc: 0.9473 - mDice: 0.7438 - val_loss: 0.4598 - val_acc: 0.9480 - val_mDice: 0.6264

Epoch 00099: val_mDice did not improve from 0.63756
Epoch 100/300
 - 9s - loss: 0.2779 - acc: 0.9473 - mDice: 0.7444 - val_loss: 0.4446 - val_acc: 0.9489 - val_mDice: 0.6312

Epoch 00100: val_mDice did not improve from 0.63756
Epoch 101/300
 - 9s - loss: 0.2788 - acc: 0.9473 - mDice: 0.7439 - val_loss: 0.4555 - val_acc: 0.9487 - val_mDice: 0.6262

Epoch 00101: val_mDice did not improve from 0.63756
Epoch 102/300
 - 9s - loss: 0.2779 - acc: 0.9473 - mDice: 0.7445 - val_loss: 0.5005 - val_acc: 0.9420 - val_mDice: 0.6006

Epoch 00102: val_mDice did not improve from 0.63756
Epoch 103/300
 - 9s - loss: 0.2771 - acc: 0.9473 - mDice: 0.7450 - val_loss: 0.5970 - val_acc: 0.9381 - val_mDice: 0.5820

Epoch 00103: val_mDice did not improve from 0.63756
Epoch 104/300
 - 9s - loss: 0.2762 - acc: 0.9474 - mDice: 0.7457 - val_loss: 0.4492 - val_acc: 0.9483 - val_mDice: 0.6270

Epoch 00104: val_mDice did not improve from 0.63756
Epoch 105/300
 - 9s - loss: 0.2744 - acc: 0.9474 - mDice: 0.7471 - val_loss: 0.4452 - val_acc: 0.9499 - val_mDice: 0.6284

Epoch 00105: val_mDice did not improve from 0.63756
Epoch 106/300
 - 9s - loss: 0.2758 - acc: 0.9474 - mDice: 0.7460 - val_loss: 0.4935 - val_acc: 0.9391 - val_mDice: 0.6169

Epoch 00106: val_mDice did not improve from 0.63756
Epoch 107/300
 - 9s - loss: 0.2756 - acc: 0.9474 - mDice: 0.7462 - val_loss: 0.4383 - val_acc: 0.9498 - val_mDice: 0.6335

Epoch 00107: val_mDice did not improve from 0.63756
Epoch 108/300
 - 9s - loss: 0.2755 - acc: 0.9476 - mDice: 0.7464 - val_loss: 0.4708 - val_acc: 0.9431 - val_mDice: 0.6215

Epoch 00108: val_mDice did not improve from 0.63756
Epoch 109/300
 - 9s - loss: 0.2731 - acc: 0.9475 - mDice: 0.7481 - val_loss: 0.4873 - val_acc: 0.9477 - val_mDice: 0.6032

Epoch 00109: val_mDice did not improve from 0.63756
Epoch 110/300
 - 9s - loss: 0.2733 - acc: 0.9476 - mDice: 0.7480 - val_loss: 0.4386 - val_acc: 0.9511 - val_mDice: 0.6365

Epoch 00110: val_mDice did not improve from 0.63756
Epoch 111/300
 - 9s - loss: 0.2741 - acc: 0.9476 - mDice: 0.7473 - val_loss: 0.4903 - val_acc: 0.9442 - val_mDice: 0.6249

Epoch 00111: val_mDice did not improve from 0.63756
Epoch 112/300
 - 9s - loss: 0.2735 - acc: 0.9478 - mDice: 0.7479 - val_loss: 0.4448 - val_acc: 0.9496 - val_mDice: 0.6285

Epoch 00112: val_mDice did not improve from 0.63756
Epoch 113/300
 - 9s - loss: 0.2735 - acc: 0.9477 - mDice: 0.7479 - val_loss: 0.7064 - val_acc: 0.9347 - val_mDice: 0.6043

Epoch 00113: val_mDice did not improve from 0.63756
Epoch 114/300
 - 9s - loss: 0.2724 - acc: 0.9477 - mDice: 0.7487 - val_loss: 0.4586 - val_acc: 0.9479 - val_mDice: 0.6199

Epoch 00114: val_mDice did not improve from 0.63756
Epoch 115/300
 - 9s - loss: 0.2737 - acc: 0.9476 - mDice: 0.7477 - val_loss: 0.4422 - val_acc: 0.9474 - val_mDice: 0.6334

Epoch 00115: val_mDice did not improve from 0.63756
Epoch 116/300
 - 9s - loss: 0.2708 - acc: 0.9478 - mDice: 0.7498 - val_loss: 0.4810 - val_acc: 0.9411 - val_mDice: 0.6224

Epoch 00116: val_mDice did not improve from 0.63756
Epoch 117/300
 - 9s - loss: 0.2717 - acc: 0.9478 - mDice: 0.7492 - val_loss: 0.4209 - val_acc: 0.9499 - val_mDice: 0.6467

Epoch 00117: val_mDice improved from 0.63756 to 0.64666, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 118/300
 - 9s - loss: 0.2712 - acc: 0.9480 - mDice: 0.7495 - val_loss: 0.4168 - val_acc: 0.9505 - val_mDice: 0.6484

Epoch 00118: val_mDice improved from 0.64666 to 0.64839, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 119/300
 - 9s - loss: 0.2705 - acc: 0.9480 - mDice: 0.7502 - val_loss: 0.4764 - val_acc: 0.9410 - val_mDice: 0.6162

Epoch 00119: val_mDice did not improve from 0.64839
Epoch 120/300
 - 9s - loss: 0.2702 - acc: 0.9479 - mDice: 0.7505 - val_loss: 0.4330 - val_acc: 0.9483 - val_mDice: 0.6377

Epoch 00120: val_mDice did not improve from 0.64839
Epoch 121/300
 - 10s - loss: 0.2699 - acc: 0.9481 - mDice: 0.7509 - val_loss: 0.4246 - val_acc: 0.9485 - val_mDice: 0.6436

Epoch 00121: val_mDice did not improve from 0.64839
Epoch 122/300
 - 10s - loss: 0.2706 - acc: 0.9479 - mDice: 0.7502 - val_loss: 0.4361 - val_acc: 0.9478 - val_mDice: 0.6408

Epoch 00122: val_mDice did not improve from 0.64839
Epoch 123/300
 - 9s - loss: 0.2700 - acc: 0.9480 - mDice: 0.7506 - val_loss: 0.5962 - val_acc: 0.9429 - val_mDice: 0.5635

Epoch 00123: val_mDice did not improve from 0.64839
Epoch 124/300
 - 10s - loss: 0.2691 - acc: 0.9480 - mDice: 0.7513 - val_loss: 0.4308 - val_acc: 0.9493 - val_mDice: 0.6382

Epoch 00124: val_mDice did not improve from 0.64839
Epoch 125/300
 - 9s - loss: 0.2687 - acc: 0.9480 - mDice: 0.7516 - val_loss: 0.4647 - val_acc: 0.9425 - val_mDice: 0.6196

Epoch 00125: val_mDice did not improve from 0.64839
Epoch 126/300
 - 9s - loss: 0.2695 - acc: 0.9480 - mDice: 0.7509 - val_loss: 0.4903 - val_acc: 0.9388 - val_mDice: 0.6145

Epoch 00126: val_mDice did not improve from 0.64839
Epoch 127/300
 - 9s - loss: 0.2694 - acc: 0.9480 - mDice: 0.7511 - val_loss: 0.4637 - val_acc: 0.9469 - val_mDice: 0.6199

Epoch 00127: val_mDice did not improve from 0.64839
Epoch 128/300
 - 9s - loss: 0.2683 - acc: 0.9482 - mDice: 0.7519 - val_loss: 0.4558 - val_acc: 0.9450 - val_mDice: 0.6264

Epoch 00128: val_mDice did not improve from 0.64839
Epoch 129/300
 - 9s - loss: 0.2669 - acc: 0.9483 - mDice: 0.7530 - val_loss: 0.4450 - val_acc: 0.9453 - val_mDice: 0.6327

Epoch 00129: val_mDice did not improve from 0.64839
Epoch 130/300
 - 9s - loss: 0.2666 - acc: 0.9485 - mDice: 0.7532 - val_loss: 0.4479 - val_acc: 0.9483 - val_mDice: 0.6268

Epoch 00130: val_mDice did not improve from 0.64839
Epoch 131/300
 - 9s - loss: 0.2680 - acc: 0.9482 - mDice: 0.7521 - val_loss: 0.4221 - val_acc: 0.9505 - val_mDice: 0.6430

Epoch 00131: val_mDice did not improve from 0.64839
Epoch 132/300
 - 10s - loss: 0.2673 - acc: 0.9481 - mDice: 0.7527 - val_loss: 0.4517 - val_acc: 0.9492 - val_mDice: 0.6366

Epoch 00132: val_mDice did not improve from 0.64839
Epoch 133/300
 - 9s - loss: 0.2663 - acc: 0.9483 - mDice: 0.7535 - val_loss: 0.4469 - val_acc: 0.9487 - val_mDice: 0.6310

Epoch 00133: val_mDice did not improve from 0.64839
Epoch 134/300
 - 9s - loss: 0.2667 - acc: 0.9483 - mDice: 0.7531 - val_loss: 0.4266 - val_acc: 0.9484 - val_mDice: 0.6411

Epoch 00134: val_mDice did not improve from 0.64839
Epoch 135/300
 - 9s - loss: 0.2657 - acc: 0.9483 - mDice: 0.7539 - val_loss: 0.4683 - val_acc: 0.9446 - val_mDice: 0.6300

Epoch 00135: val_mDice did not improve from 0.64839
Epoch 136/300
 - 9s - loss: 0.2658 - acc: 0.9484 - mDice: 0.7539 - val_loss: 0.4411 - val_acc: 0.9494 - val_mDice: 0.6327

Epoch 00136: val_mDice did not improve from 0.64839
Epoch 137/300
 - 9s - loss: 0.2666 - acc: 0.9484 - mDice: 0.7533 - val_loss: 0.4544 - val_acc: 0.9446 - val_mDice: 0.6254

Epoch 00137: val_mDice did not improve from 0.64839
Epoch 138/300
 - 9s - loss: 0.2660 - acc: 0.9485 - mDice: 0.7538 - val_loss: 0.4262 - val_acc: 0.9498 - val_mDice: 0.6404

Epoch 00138: val_mDice did not improve from 0.64839
Epoch 139/300
 - 9s - loss: 0.2634 - acc: 0.9487 - mDice: 0.7558 - val_loss: 0.4567 - val_acc: 0.9459 - val_mDice: 0.6243

Epoch 00139: val_mDice did not improve from 0.64839
Epoch 140/300
 - 9s - loss: 0.2632 - acc: 0.9486 - mDice: 0.7558 - val_loss: 0.4154 - val_acc: 0.9500 - val_mDice: 0.6488

Epoch 00140: val_mDice improved from 0.64839 to 0.64883, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 141/300
 - 9s - loss: 0.2637 - acc: 0.9486 - mDice: 0.7555 - val_loss: 0.4389 - val_acc: 0.9491 - val_mDice: 0.6340

Epoch 00141: val_mDice did not improve from 0.64883
Epoch 142/300
 - 9s - loss: 0.2652 - acc: 0.9485 - mDice: 0.7544 - val_loss: 0.4313 - val_acc: 0.9500 - val_mDice: 0.6385

Epoch 00142: val_mDice did not improve from 0.64883
Epoch 143/300
 - 9s - loss: 0.2626 - acc: 0.9487 - mDice: 0.7564 - val_loss: 0.4202 - val_acc: 0.9503 - val_mDice: 0.6438

Epoch 00143: val_mDice did not improve from 0.64883
Epoch 144/300
 - 9s - loss: 0.2633 - acc: 0.9486 - mDice: 0.7559 - val_loss: 0.4387 - val_acc: 0.9498 - val_mDice: 0.6333

Epoch 00144: val_mDice did not improve from 0.64883
Epoch 145/300
 - 9s - loss: 0.2645 - acc: 0.9486 - mDice: 0.7550 - val_loss: 0.4596 - val_acc: 0.9484 - val_mDice: 0.6197

Epoch 00145: val_mDice did not improve from 0.64883
Epoch 146/300
 - 9s - loss: 0.2660 - acc: 0.9485 - mDice: 0.7538 - val_loss: 0.4325 - val_acc: 0.9484 - val_mDice: 0.6370

Epoch 00146: val_mDice did not improve from 0.64883
Epoch 147/300
 - 9s - loss: 0.2619 - acc: 0.9488 - mDice: 0.7569 - val_loss: 0.4403 - val_acc: 0.9494 - val_mDice: 0.6335

Epoch 00147: val_mDice did not improve from 0.64883
Epoch 148/300
 - 9s - loss: 0.2610 - acc: 0.9489 - mDice: 0.7576 - val_loss: 0.4803 - val_acc: 0.9420 - val_mDice: 0.6257

Epoch 00148: val_mDice did not improve from 0.64883
Epoch 149/300
 - 9s - loss: 0.2615 - acc: 0.9489 - mDice: 0.7573 - val_loss: 0.4623 - val_acc: 0.9473 - val_mDice: 0.6166

Epoch 00149: val_mDice did not improve from 0.64883
Epoch 150/300
 - 9s - loss: 0.2618 - acc: 0.9488 - mDice: 0.7570 - val_loss: 0.4220 - val_acc: 0.9500 - val_mDice: 0.6433

Epoch 00150: val_mDice did not improve from 0.64883
Epoch 151/300
 - 9s - loss: 0.2612 - acc: 0.9488 - mDice: 0.7574 - val_loss: 0.4496 - val_acc: 0.9467 - val_mDice: 0.6295

Epoch 00151: val_mDice did not improve from 0.64883
Epoch 152/300
 - 9s - loss: 0.2614 - acc: 0.9489 - mDice: 0.7573 - val_loss: 0.7260 - val_acc: 0.9366 - val_mDice: 0.5988

Epoch 00152: val_mDice did not improve from 0.64883
Epoch 153/300
 - 9s - loss: 0.2595 - acc: 0.9490 - mDice: 0.7589 - val_loss: 0.4638 - val_acc: 0.9473 - val_mDice: 0.6171

Epoch 00153: val_mDice did not improve from 0.64883
Epoch 154/300
 - 9s - loss: 0.2603 - acc: 0.9489 - mDice: 0.7583 - val_loss: 0.7219 - val_acc: 0.9352 - val_mDice: 0.5981

Epoch 00154: val_mDice did not improve from 0.64883
Epoch 155/300
 - 9s - loss: 0.2598 - acc: 0.9489 - mDice: 0.7586 - val_loss: 0.4364 - val_acc: 0.9480 - val_mDice: 0.6368

Epoch 00155: val_mDice did not improve from 0.64883
Epoch 156/300
 - 9s - loss: 0.2625 - acc: 0.9488 - mDice: 0.7567 - val_loss: 0.4213 - val_acc: 0.9493 - val_mDice: 0.6436

Epoch 00156: val_mDice did not improve from 0.64883
Epoch 157/300
 - 9s - loss: 0.2670 - acc: 0.9490 - mDice: 0.7583 - val_loss: 0.4789 - val_acc: 0.9430 - val_mDice: 0.6206

Epoch 00157: val_mDice did not improve from 0.64883
Epoch 158/300
 - 9s - loss: 0.2600 - acc: 0.9491 - mDice: 0.7585 - val_loss: 0.4315 - val_acc: 0.9466 - val_mDice: 0.6391

Epoch 00158: val_mDice did not improve from 0.64883
Epoch 159/300
 - 9s - loss: 0.2583 - acc: 0.9491 - mDice: 0.7598 - val_loss: 0.4368 - val_acc: 0.9466 - val_mDice: 0.6348

Epoch 00159: val_mDice did not improve from 0.64883
Epoch 160/300
 - 9s - loss: 0.2581 - acc: 0.9492 - mDice: 0.7599 - val_loss: 0.4553 - val_acc: 0.9479 - val_mDice: 0.6232

Epoch 00160: val_mDice did not improve from 0.64883
Epoch 161/300
 - 9s - loss: 0.2608 - acc: 0.9490 - mDice: 0.7580 - val_loss: 0.4210 - val_acc: 0.9478 - val_mDice: 0.6437

Epoch 00161: val_mDice did not improve from 0.64883
Epoch 162/300
 - 9s - loss: 0.2578 - acc: 0.9493 - mDice: 0.7602 - val_loss: 0.4376 - val_acc: 0.9498 - val_mDice: 0.6338

Epoch 00162: val_mDice did not improve from 0.64883
Epoch 163/300
 - 9s - loss: 0.2579 - acc: 0.9492 - mDice: 0.7602 - val_loss: 0.4325 - val_acc: 0.9453 - val_mDice: 0.6394

Epoch 00163: val_mDice did not improve from 0.64883
Epoch 164/300
 - 9s - loss: 0.2587 - acc: 0.9491 - mDice: 0.7594 - val_loss: 0.4410 - val_acc: 0.9477 - val_mDice: 0.6326

Epoch 00164: val_mDice did not improve from 0.64883
Epoch 165/300
 - 9s - loss: 0.2577 - acc: 0.9491 - mDice: 0.7603 - val_loss: 0.4379 - val_acc: 0.9487 - val_mDice: 0.6385

Epoch 00165: val_mDice did not improve from 0.64883
Epoch 166/300
 - 9s - loss: 0.2563 - acc: 0.9493 - mDice: 0.7614 - val_loss: 0.4681 - val_acc: 0.9481 - val_mDice: 0.6143

Epoch 00166: val_mDice did not improve from 0.64883
Epoch 167/300
 - 9s - loss: 0.2566 - acc: 0.9494 - mDice: 0.7611 - val_loss: 0.4286 - val_acc: 0.9485 - val_mDice: 0.6406

Epoch 00167: val_mDice did not improve from 0.64883
Epoch 168/300
 - 9s - loss: 0.2590 - acc: 0.9491 - mDice: 0.7594 - val_loss: 0.4463 - val_acc: 0.9484 - val_mDice: 0.6278

Epoch 00168: val_mDice did not improve from 0.64883
Epoch 169/300
 - 9s - loss: 0.2614 - acc: 0.9490 - mDice: 0.7575 - val_loss: 0.4400 - val_acc: 0.9474 - val_mDice: 0.6319

Epoch 00169: val_mDice did not improve from 0.64883
Epoch 170/300
 - 9s - loss: 0.2593 - acc: 0.9490 - mDice: 0.7590 - val_loss: 0.4988 - val_acc: 0.9483 - val_mDice: 0.6334

Epoch 00170: val_mDice did not improve from 0.64883
Epoch 171/300
 - 9s - loss: 0.2620 - acc: 0.9492 - mDice: 0.7604 - val_loss: 0.4402 - val_acc: 0.9496 - val_mDice: 0.6322

Epoch 00171: val_mDice did not improve from 0.64883
Epoch 172/300
 - 9s - loss: 0.2559 - acc: 0.9494 - mDice: 0.7618 - val_loss: 0.4410 - val_acc: 0.9492 - val_mDice: 0.6304

Epoch 00172: val_mDice did not improve from 0.64883
Epoch 173/300
 - 9s - loss: 0.2579 - acc: 0.9492 - mDice: 0.7602 - val_loss: 0.4372 - val_acc: 0.9477 - val_mDice: 0.6354

Epoch 00173: val_mDice did not improve from 0.64883
Epoch 174/300
 - 9s - loss: 0.2560 - acc: 0.9495 - mDice: 0.7617 - val_loss: 0.4625 - val_acc: 0.9495 - val_mDice: 0.6245

Epoch 00174: val_mDice did not improve from 0.64883
Epoch 175/300
 - 9s - loss: 0.2597 - acc: 0.9490 - mDice: 0.7589 - val_loss: 0.4631 - val_acc: 0.9487 - val_mDice: 0.6175

Epoch 00175: val_mDice did not improve from 0.64883
Epoch 176/300
 - 9s - loss: 0.2561 - acc: 0.9493 - mDice: 0.7615 - val_loss: 0.4288 - val_acc: 0.9512 - val_mDice: 0.6409

Epoch 00176: val_mDice did not improve from 0.64883
Epoch 177/300
 - 9s - loss: 0.2554 - acc: 0.9495 - mDice: 0.7621 - val_loss: 0.4373 - val_acc: 0.9500 - val_mDice: 0.6365

Epoch 00177: val_mDice did not improve from 0.64883
Epoch 178/300
 - 9s - loss: 0.2540 - acc: 0.9497 - mDice: 0.7633 - val_loss: 0.4375 - val_acc: 0.9465 - val_mDice: 0.6356

Epoch 00178: val_mDice did not improve from 0.64883
Epoch 179/300
 - 9s - loss: 0.2550 - acc: 0.9494 - mDice: 0.7625 - val_loss: 0.5408 - val_acc: 0.9419 - val_mDice: 0.5850

Epoch 00179: val_mDice did not improve from 0.64883
Epoch 180/300
 - 9s - loss: 0.2548 - acc: 0.9494 - mDice: 0.7626 - val_loss: 0.4728 - val_acc: 0.9364 - val_mDice: 0.6149

Epoch 00180: val_mDice did not improve from 0.64883
Restoring model weights from the end of the best epoch
Epoch 00180: early stopping
{'val_loss': [1.904795345295681, 0.8474199316474829, 0.7024988223997395, 0.6469860297910283, 1.2891236188706388, 0.5649026833223493, 0.5907311647125845, 0.5411139448707023, 0.5180613994598389, 0.49257143963588756, 0.5445506766940771, 0.536881889185209, 0.48462376098954274, 0.5039488512478517, 0.4777051421363702, 0.4849108789074287, 0.5097047890839952, 0.7253442795089121, 0.4654642728607306, 0.4904486399688078, 0.4949069796653276, 0.4674580535861883, 0.48397778393177504, 0.4824470720264349, 0.4862160444929359, 0.4479740231894375, 0.48497277297330704, 0.8685462474822998, 0.5391578962293904, 0.7156963897555062, 0.615765829099698, 0.4430941909216763, 0.5221527925368106, 0.4545954773935039, 1.4291345744990231, 0.47965598575184853, 0.46851281905442144, 0.4458237812760171, 0.47000564785485854, 0.4837334909465876, 0.47652538773718844, 0.4499844875228539, 0.47235694460654526, 0.449627911106924, 0.8124392675549796, 0.44580550876896036, 0.5000224066584298, 0.46402595853537654, 0.46190742595811907, 0.46814237417799703, 0.6617441257733977, 0.4699723365601529, 0.5424961156389686, 0.44778947348005316, 0.49434201436096364, 0.464358438266797, 0.46498865726288785, 0.5051823964949405, 0.47780178838901305, 0.46300727865669167, 0.4427501783612069, 0.48905072051487614, 0.4859526271230719, 0.4695448785015706, 0.43977921263555464, 0.45507053377923, 0.45189073849260136, 0.45361220602239116, 0.48690512475003017, 0.4414253891184089, 0.49801701340782506, 0.43986772653761874, 0.4531697717945227, 0.43920807255787797, 0.48808901765373314, 0.4754936042126645, 0.4411108775085278, 0.4845475229654419, 0.4340351079956869, 0.44653723012195545, 0.4738981352093514, 0.43521601731857557, 0.6423210870014148, 0.45265347301290276, 0.6005800969145271, 0.43382332398650353, 0.5568643771530537, 0.4601350627588422, 0.4410603732875224, 0.6924273472153739, 0.4649878599670496, 0.46823111611805607, 0.44711854786015626, 0.47131681810604054, 0.44573948189113916, 0.4358252327093917, 0.4504790105176776, 0.4556721070509278, 0.4597981655865573, 0.4446053849847129, 0.45550727576352235, 0.5005340258057198, 0.5970171227883757, 0.4492089899068468, 0.4451718608315071, 0.4935424331198917, 0.4383493561423227, 0.47077155113220215, 0.4873459195153097, 0.43864231263653614, 0.4902694687414705, 0.44477517015478585, 0.7064249478699116, 0.4585756106992786, 0.44220446703139316, 0.4810342725073354, 0.4208966148703286, 0.4168105825279536, 0.4763708161504081, 0.4329812650600176, 0.42458834708406684, 0.436116733577814, 0.5961896747015836, 0.4308022458231851, 0.4647492973991994, 0.4902829976564043, 0.4636835750569119, 0.45578592948699265, 0.4450419916865531, 0.4478831455278932, 0.4220657572987374, 0.4516883083943571, 0.44688677921723785, 0.4266389414165797, 0.4682819056376982, 0.4411207695355576, 0.454415826650148, 0.42617967456914063, 0.4567051251952568, 0.4154341826947887, 0.4388863501254092, 0.43125677510593713, 0.4202071622516332, 0.43869665399026336, 0.45956464229005106, 0.4324974883138464, 0.4402867404932386, 0.48031833366061866, 0.46233291036627266, 0.4219719871376338, 0.4496332996346977, 0.7260185975706979, 0.46380573377180634, 0.7219180920150843, 0.4364061616779713, 0.4212763024849838, 0.4788734718654933, 0.43149613731362846, 0.4367788809069087, 0.45529648092355623, 0.4210214551245229, 0.4376078823978981, 0.43252072675844255, 0.4409995316789391, 0.437940145141623, 0.4681476378039028, 0.42858793963207287, 0.44626712799072266, 0.43996226151337786, 0.49877416685725867, 0.4401926826894953, 0.4409865616412645, 0.43717206897360555, 0.4625209981805823, 0.4631341916791509, 0.42876931991469996, 0.4372685200042939, 0.4374599955724866, 0.5408329468094901, 0.47281505552570474], 'val_acc': [0.902899529826775, 0.9115991679470191, 0.9202164893739679, 0.9222164750099182, 0.9169701960649383, 0.9261778753794981, 0.9301264098521029, 0.9357148053940763, 0.9352131988225358, 0.938930222157682, 0.9300363706738761, 0.928871098529087, 0.9402086627617311, 0.937352088729987, 0.9417739343107416, 0.9426240894231903, 0.9394485474972243, 0.9357983952157953, 0.9445649037200413, 0.9404195908750042, 0.9401868126365576, 0.9430382338802467, 0.9396324660001176, 0.9445584878492891, 0.9418446810057993, 0.9481044418356391, 0.9446729435009903, 0.9347784766990147, 0.9406485202607144, 0.9424234300516965, 0.9407038481047983, 0.9459359619054901, 0.9344222177280469, 0.9458253577853857, 0.92852383852005, 0.9449006024371372, 0.9454973828926515, 0.947102507178703, 0.9444903255848403, 0.9444993325833524, 0.9425199072012741, 0.9471205345700296, 0.9447681167152491, 0.945636273100135, 0.9233585796999128, 0.9482215013396874, 0.9410948411802228, 0.9460041328762354, 0.9468247013145619, 0.9452619994624277, 0.9414433850331253, 0.9471500964646928, 0.9384556325633874, 0.9456002792615569, 0.9465108795112438, 0.9431784367293454, 0.9475192508001006, 0.9437867878528123, 0.9446909648648808, 0.9481623105788499, 0.9467449610152942, 0.9423437118530273, 0.9397507805502816, 0.946176480041461, 0.9464710080221798, 0.9484697118234099, 0.944662661364909, 0.9489648857813203, 0.9432041671838653, 0.9492555736155992, 0.9460195798552438, 0.9502613564555564, 0.9444067196899586, 0.9486832303947277, 0.9465649014108637, 0.945907668451245, 0.9470446531692248, 0.9469443278366261, 0.9482124956806054, 0.9488066903660807, 0.9458497903320227, 0.9498922242207474, 0.9445430649800247, 0.9452144423227632, 0.9382768387205145, 0.948323112525297, 0.9423552731449685, 0.9467745563957128, 0.9487655263268546, 0.9384247493208124, 0.9474883688969559, 0.944364265779431, 0.94581248787012, 0.9493957624006807, 0.9495128011435605, 0.9469070387690255, 0.9459449642159966, 0.9442999644225902, 0.9480439993772614, 0.9488581385505334, 0.9487076622716496, 0.9420221735922139, 0.938098070996531, 0.9483475216319052, 0.9499025150631251, 0.9391154218255804, 0.9497906116957076, 0.943085820487376, 0.9477173049798172, 0.9510793732793144, 0.9442240870400761, 0.949557815374953, 0.9347192993324794, 0.9478845301638829, 0.9473559186699685, 0.9411051152797227, 0.9498960791009196, 0.9505456023001939, 0.9410459492983443, 0.9482755071661445, 0.9485237310441692, 0.9478279090999218, 0.9428736038422316, 0.9492645812838265, 0.9425186313939898, 0.938769451687845, 0.9468568570158454, 0.9449546176396059, 0.9452543111329668, 0.9483385514677241, 0.950531463274795, 0.9491668169418078, 0.9486909381459269, 0.9483964101652081, 0.9445752092961515, 0.9493751780370648, 0.9445842236615298, 0.9497700346989578, 0.945893528756131, 0.9499565383021751, 0.949128240012051, 0.9500452628296413, 0.9503140764290028, 0.9497957644837626, 0.948445279946488, 0.9484324281135302, 0.9494369137153197, 0.9420041502191779, 0.9473198893364896, 0.9500311144282308, 0.9466832427496321, 0.9365585352597612, 0.9473147311907136, 0.9351527456487163, 0.9480208533533504, 0.9492800028136607, 0.9430163710304861, 0.946571336033639, 0.9465919257549757, 0.9479115163342337, 0.9478382133366017, 0.9498201822966672, 0.9453391660465283, 0.9477481835343865, 0.9486574939127719, 0.9481237309702327, 0.9484735740704483, 0.9484195481525378, 0.9474034791582087, 0.9482870811826727, 0.949640124701382, 0.949150110898393, 0.9476902960391527, 0.9494986540815803, 0.9487321008457227, 0.9512388391441173, 0.9499822553623928, 0.9465263271599673, 0.9418510948674063, 0.9363617521993229], 'val_mDice': [0.21068295669019893, 0.4264484787924906, 0.4837993195887362, 0.5126042466485099, 0.4154998633298981, 0.5559484597002522, 0.5506209744496292, 0.5735300678885384, 0.5850536836667007, 0.5994320947132753, 0.5705944262863545, 0.5737001477332597, 0.6063251682881559, 0.5956504519066114, 0.6097299342744806, 0.6048307519280509, 0.5911285783467668, 0.5998493700884702, 0.6149031781078724, 0.6062832997086343, 0.6011913954541924, 0.6151272955905186, 0.610487608427412, 0.6049728574377767, 0.609103829673167, 0.6271966367625119, 0.6134484611200482, 0.5913638432374161, 0.5776732255903523, 0.6164511629704679, 0.5564008542660916, 0.6282919270268986, 0.5870868496680528, 0.6249826644243819, 0.43920383292637516, 0.6073430635955896, 0.6136167169956679, 0.6286359536513854, 0.613617888327395, 0.6044415530194057, 0.6159199898162585, 0.6260464285196883, 0.6206898649087113, 0.6276532023140554, 0.5526773112543514, 0.6307412151540264, 0.6108288363124548, 0.6163269756885057, 0.619540146227633, 0.6200277122218957, 0.5598559808195307, 0.6134696000077752, 0.5760921440767438, 0.6303171830230885, 0.6019158229399263, 0.6189636259936215, 0.6181105596295903, 0.598158500837476, 0.6113246947192075, 0.6218946783730154, 0.6325549235504665, 0.6104534228196304, 0.6115009155166283, 0.6191427399603169, 0.6359673417016362, 0.6248953516563672, 0.6279720603749993, 0.6271993156229512, 0.6076374274961064, 0.6335761305991183, 0.6004652377594722, 0.6365146127979407, 0.626824493488569, 0.633994167440393, 0.6119757582632344, 0.6100882043999233, 0.6336226811569728, 0.6095834364382069, 0.6375606167182494, 0.63060340586673, 0.6113376436608561, 0.6351822668247009, 0.6209032836924778, 0.6264836714508828, 0.6080318414763118, 0.6369008977761429, 0.6149255231525121, 0.6264919230107511, 0.6317834331748191, 0.6003654639372665, 0.6181954239191634, 0.6241392814711239, 0.6289875005068404, 0.619849504379744, 0.6277370894892832, 0.6373042417376229, 0.6305072823267305, 0.628277216064796, 0.6263552589362926, 0.6312012766184432, 0.626217002279303, 0.6005888172749723, 0.5820153790913271, 0.6269929824250468, 0.6283725506803962, 0.6168774882059419, 0.6335041094362066, 0.6214616553167279, 0.6031680803620414, 0.6364807493231269, 0.6248976648523566, 0.6284870532121551, 0.604295198167308, 0.6198535126246764, 0.6333999459663134, 0.6224304946620812, 0.6466565996073605, 0.6483855033188723, 0.6161778482158532, 0.637665879860353, 0.643552285231901, 0.6407751996865433, 0.5634600433071008, 0.6382408269335714, 0.6195697529932086, 0.6145123939835624, 0.6198552210679215, 0.6264267195476575, 0.6326959106359589, 0.6268203553189052, 0.6429616011930316, 0.6365891527593805, 0.6310240820552526, 0.6411025637990972, 0.6300394240390049, 0.6327250365460857, 0.6253735021259008, 0.6404000058602751, 0.624325082543191, 0.6488277972414253, 0.6339927315711975, 0.638547932833768, 0.6437611921449725, 0.6333029015680377, 0.61972320280718, 0.6369516320442885, 0.633529574683543, 0.6256750031803431, 0.6165872189436066, 0.6433409084095044, 0.6295392754372586, 0.5987668131174666, 0.6170527854662263, 0.5981050763237342, 0.6368290386842878, 0.6436285356457314, 0.6205959373645569, 0.6391396850682376, 0.6348329742303055, 0.6232009998868021, 0.643696233127894, 0.6337766654036018, 0.6394481029403344, 0.6326370493749555, 0.6384863116767969, 0.6143194182535235, 0.6406076831764049, 0.6277983329269323, 0.631939447327946, 0.6333954876728272, 0.6321590609764784, 0.6303684738244903, 0.6354373706860489, 0.6244625576426474, 0.6175122348110328, 0.6408835569124544, 0.6365055113695981, 0.6356137562333868, 0.5849735984641514, 0.6149131394504161], 'loss': [2.697545614992618, 1.1230680950067888, 0.8490546812725057, 0.7368501715739462, 0.669506264415121, 0.6197635649005788, 0.5816152032962698, 0.5522711421013319, 0.5301147126703214, 0.5105203804102143, 0.4926044029731686, 0.47502181919606046, 0.4647985341112158, 0.45127648037689805, 0.44156333736154435, 0.4307554163644239, 0.4252646120163124, 0.4155239211861379, 0.40835531169680106, 0.4554577877192535, 0.40967046846763383, 0.40002435954075416, 0.3901889377160613, 0.3879014886406628, 0.3831602729023342, 0.37928986033126383, 0.3742150416920955, 0.371935013055091, 0.3691946943923502, 0.36637886725140295, 0.36386859868911, 0.3613680951380722, 0.35851086896736944, 0.35636030805511437, 0.3516398858806034, 0.3494417706000576, 0.3488841889714896, 0.34559231053444167, 0.34377140122132127, 0.33422394908124886, 0.32944109733678156, 0.3252444468323035, 0.32351941885640023, 0.32390282346804733, 0.3209080098712235, 0.3197925667943781, 0.31740087367189296, 0.315274871649238, 0.3133451730383394, 0.31199980941679084, 0.3117024123601307, 0.3096843477077135, 0.309146730563972, 0.30946261194386, 0.3065783993645218, 0.3034417781483952, 0.30326585440244724, 0.30780328745760166, 0.3018338400187356, 0.392008070797907, 0.3244520722564318, 0.31283586021318693, 0.3079673455802091, 0.3048712106521679, 0.3018340624690509, 0.3009703099715383, 0.29983232816346167, 0.29959979669280795, 0.29811768309866477, 0.29579084010527407, 0.2958284891528656, 0.2952728326477667, 0.2935200517467613, 0.29305843915991264, 0.29243158379206613, 0.2961139760005882, 0.2936568090436295, 0.2909836944065958, 0.28930247861263897, 0.29138202528160867, 0.29178543629975034, 0.2893304978295905, 0.289108915636648, 0.28821546574186646, 0.28624349444581, 0.2858563760293788, 0.2872566911222069, 0.2860741211970443, 0.284529286743031, 0.2841934763116336, 0.28397303830679527, 0.28378849350804725, 0.2816584623265362, 0.281368236419636, 0.2819708496665925, 0.27977785495353186, 0.279781485567183, 0.2816507214358614, 0.2786432611915346, 0.27789247776368753, 0.27877344636440426, 0.27789644865292534, 0.2771012319190081, 0.2761983795247097, 0.27435107901960315, 0.2757950910350518, 0.2756155640557431, 0.27546023850657525, 0.27306635614890645, 0.2733258873631503, 0.2741041520810821, 0.27352821778555414, 0.2735171285750233, 0.2724105089728345, 0.2736943140587679, 0.270828532407723, 0.2716573403426166, 0.2712072131384635, 0.27050444682479996, 0.27018693469477795, 0.26986700590965157, 0.27057363728567885, 0.269986072311565, 0.2691381154123563, 0.2686753987831189, 0.2694956461394616, 0.2693989384790419, 0.2683212938609893, 0.26691234698768856, 0.2666424622604784, 0.26804526894748804, 0.26729367772452356, 0.26625572447050244, 0.26674983371116145, 0.2657015628735331, 0.2657890759219396, 0.26655091163428163, 0.2659692367479292, 0.2633844756870638, 0.26324231398873565, 0.26365080130108826, 0.2651630298495844, 0.262612712841956, 0.26328287844782583, 0.26449148510473186, 0.26604016244466583, 0.2619498810187085, 0.261025115506176, 0.26148280527392553, 0.2618082986269435, 0.26117779402856306, 0.26144755427374156, 0.25946999140918947, 0.26028172813105604, 0.2598079715188576, 0.26247404039757327, 0.26704509054586867, 0.26003808196495115, 0.2583457474367819, 0.25809888152979166, 0.26080266844267275, 0.2578364931598886, 0.2579009596342224, 0.2587231263819939, 0.25767804823412405, 0.2563430128595536, 0.25662733577241587, 0.25904685999866284, 0.26136190968979106, 0.259338542368911, 0.26196784954711366, 0.2558647354588802, 0.2578508933370924, 0.2560180685667882, 0.2597204665357256, 0.25612999534975595, 0.2553930907299422, 0.253991076427068, 0.2549705845159824, 0.25478310657223635], 'acc': [0.5218314349626075, 0.8812183169388739, 0.8899266805002601, 0.8952682690692441, 0.8991583542748834, 0.9033646623546683, 0.9076648474498997, 0.9122345923740548, 0.9166821423995707, 0.9200293681340583, 0.9223350691645924, 0.9246173888601061, 0.9259413145164859, 0.9272885251900134, 0.9285031905782244, 0.9296487483889596, 0.9304867846116027, 0.9316798815143742, 0.9324894096737932, 0.9292331202711412, 0.932894620463768, 0.9341023214598495, 0.9348684516017243, 0.9354270729403279, 0.9362106776477548, 0.9364166818394588, 0.9371285452990178, 0.9376816583123124, 0.9379511484259093, 0.9383732697327556, 0.9386191923547523, 0.9389541891426365, 0.9392638295891963, 0.9397054741209413, 0.9401750391327954, 0.940452878661113, 0.9406589062035322, 0.9407014812629979, 0.9412208912944079, 0.9414181201979495, 0.941557372533735, 0.9419364463654669, 0.9422547645881415, 0.9420675345735071, 0.9423322718949133, 0.9426109841386032, 0.9429310673091292, 0.943162146892575, 0.9434004217787366, 0.9434767039415219, 0.9435894189642253, 0.943654690949434, 0.9438841689114309, 0.943859027754326, 0.9440665140029988, 0.944468475932589, 0.9444545032088122, 0.944172170973505, 0.9446243058737388, 0.936650885929861, 0.9430029242205054, 0.9438855124440944, 0.9442966719711352, 0.944454808005152, 0.9446941429880605, 0.9446716321576576, 0.9450262475023531, 0.9450284590226803, 0.9451017062783817, 0.9453711726064612, 0.9454255300644526, 0.9454797742289138, 0.9455666875871078, 0.945698053505148, 0.9458708706965712, 0.9453541409206283, 0.9455715803304899, 0.9457354299960641, 0.9459712382493646, 0.9458567811151111, 0.9458811468300564, 0.9461660929920617, 0.9461831443970928, 0.9461849315321043, 0.9461524474967437, 0.9463851516297992, 0.946281419057071, 0.9464917491754402, 0.9466953784897947, 0.9465405595739833, 0.9464434588676879, 0.9467418361185365, 0.9468541733838666, 0.9469290666659567, 0.9466874026926402, 0.9469926716072959, 0.9470175325190753, 0.9468965376867464, 0.9472631008813894, 0.9472983594079382, 0.9473000325022946, 0.9472504252950444, 0.9472614321595508, 0.9474040448794222, 0.947445064853522, 0.9474062787828765, 0.9473867540453561, 0.9476148004364309, 0.9475245465786964, 0.9475930651706671, 0.9475658274463621, 0.9477500274408442, 0.9477002537839645, 0.9476821183803135, 0.9476153184266983, 0.9478170147697103, 0.9478313420226245, 0.9479541235429146, 0.9479996140490917, 0.9479473732878049, 0.9480619718246319, 0.9478850871076518, 0.9479990050136939, 0.9480177294579657, 0.948029252769498, 0.947982796892213, 0.9480444259576436, 0.948156600435481, 0.9482903227670874, 0.9484620541594421, 0.9481556356767705, 0.9481464149551917, 0.9483340248032267, 0.948319043558817, 0.9482999187964496, 0.9483584411389461, 0.9483707658031746, 0.9484611111837093, 0.9486930865944075, 0.9485542851668718, 0.9486091363396953, 0.9485410425923386, 0.9487212652306658, 0.9486116540036368, 0.9486334594991412, 0.948538688444643, 0.948831206956356, 0.9489434300340558, 0.9488829538680833, 0.9488480014484049, 0.9488459563348395, 0.9489025959042132, 0.9489621515204479, 0.9488992075764311, 0.9489288210170702, 0.9487797865810784, 0.9489562949859434, 0.9491000596989246, 0.9490608290032273, 0.9491981940157769, 0.9490190502319309, 0.9493259397768526, 0.9492220680919174, 0.9490930506324003, 0.9491413441674873, 0.949291081672507, 0.9493649168726377, 0.9491173961321056, 0.9489553787964754, 0.9490275901573775, 0.9492470020872097, 0.9494141709102727, 0.9492188000757403, 0.9494782438641227, 0.9489625772714101, 0.9493408513549273, 0.949492804005667, 0.949711815317329, 0.9494248264301084, 0.9494174392204007], 'mDice': [0.11428381784369433, 0.3190981785893183, 0.4127001921001079, 0.4623037248614096, 0.4955792758921172, 0.5220413566199087, 0.5427170487404556, 0.5596156813411738, 0.5728078555389603, 0.5850257702186347, 0.5956723793834329, 0.606566592752413, 0.6130100819418588, 0.6216497835980208, 0.6279423576666274, 0.6351819739463725, 0.6389084366858955, 0.6452905244196746, 0.6500794919693591, 0.6238818709754532, 0.6495128088713696, 0.6560179744584458, 0.6625773285981699, 0.6642816420462716, 0.6678542024452615, 0.6701101569358754, 0.6737482216269265, 0.6756719779003123, 0.6774283606261643, 0.6795397260065842, 0.6810305587289807, 0.6830087066076402, 0.6849440500656135, 0.6865694755017543, 0.6899186053697881, 0.6914785054412712, 0.6920203951320533, 0.694314095242276, 0.6956297646295886, 0.701944636671489, 0.7053004256453945, 0.7083827242826272, 0.7096890867840383, 0.7094000616262717, 0.7115115872894788, 0.7123968416527733, 0.7142658691470919, 0.7158446743813373, 0.7171944863233073, 0.7183920048031033, 0.7185124386793588, 0.7199136855043023, 0.7203951103033491, 0.7202967417077245, 0.7223464697737201, 0.7247699365505124, 0.7248504302808612, 0.721577119866464, 0.7261164055188563, 0.6673558121054315, 0.7092080776375195, 0.7177709982168096, 0.7214336459932844, 0.7236509562996202, 0.7259763742318737, 0.7265254001473885, 0.7275199512899884, 0.7279426655812951, 0.7288471687480625, 0.7305751334208691, 0.7306053286574672, 0.7310058902422816, 0.7322591713689085, 0.7326430029838704, 0.7331760456869956, 0.7305646396658225, 0.7322513330488598, 0.7341968501494793, 0.7354677599086112, 0.7339954705445577, 0.7336931859652038, 0.7355836107125082, 0.7357850395848055, 0.7364576209379005, 0.7377588381983327, 0.7381866858623555, 0.7371713170274782, 0.7381965725294282, 0.739274952659795, 0.7395822041377396, 0.7396562519438965, 0.7401031271521901, 0.74137297415677, 0.7416250875353091, 0.7412866304323213, 0.7428880611745179, 0.7429241987363807, 0.7415071237397123, 0.7438063071343118, 0.7444168285942391, 0.7438556590514328, 0.7444741254743025, 0.745009122870508, 0.7457049253860677, 0.7471312505912526, 0.7460151484553228, 0.7461927551154205, 0.7463690763165058, 0.7480886324782368, 0.7479696636587966, 0.7473422440218066, 0.7478754622931595, 0.7478539088788214, 0.7486839990851986, 0.7476749906470839, 0.7497981190865177, 0.7492378155349595, 0.7495430836167547, 0.7501545809932741, 0.7505202332895632, 0.7508539556415894, 0.7501946250324099, 0.750615883250772, 0.7512621211207049, 0.7515634339110255, 0.7508854402565435, 0.7510739928659721, 0.7518661180613502, 0.752991123574495, 0.7532086073341808, 0.7521125849025977, 0.7527117128057665, 0.753514279726903, 0.7531467629865471, 0.7539489427622575, 0.7538554940208506, 0.7532829612227122, 0.7538345169337621, 0.755764666091596, 0.7558090920672685, 0.7555364844341703, 0.7544279178244891, 0.7563699338243344, 0.7559229084133159, 0.7549666884953962, 0.7538032199022742, 0.7568786985262024, 0.757615518523404, 0.7572837928994199, 0.7570164283745386, 0.757442440940581, 0.7573234785574381, 0.7588691207116472, 0.7583259644236947, 0.7585843586608144, 0.756692480608602, 0.7583466760854761, 0.7584696923499605, 0.7597694430593277, 0.7599204727719796, 0.7579536532358729, 0.7601737741036073, 0.760210948889172, 0.7594348238389734, 0.760313747022988, 0.7614341728135884, 0.7610836699627953, 0.7594273845816055, 0.7575390233565342, 0.7590015998519142, 0.7603761978584461, 0.7618413848817183, 0.7601531179801516, 0.7616978433141235, 0.7589033021045517, 0.7615391565082033, 0.7621476746874356, 0.7632953898580668, 0.7624656719158576, 0.7626254424876867]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.86s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.75s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:04,  2.45s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.29s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.30s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:47,  2.90s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:30,  2.84s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:47,  2.69s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:49,  2.48s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:50,  2.49s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:15,  2.60s/it]predicting train subjects:   3%|▎         | 7/266 [00:18<11:27,  2.65s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:36,  2.70s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:31,  2.69s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:25,  2.68s/it]predicting train subjects:   4%|▍         | 11/266 [00:28<11:12,  2.64s/it]predicting train subjects:   5%|▍         | 12/266 [00:31<11:34,  2.73s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:29,  2.73s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:18,  2.69s/it]predicting train subjects:   6%|▌         | 15/266 [00:39<11:26,  2.73s/it]predicting train subjects:   6%|▌         | 16/266 [00:42<11:23,  2.73s/it]predicting train subjects:   6%|▋         | 17/266 [00:45<11:31,  2.78s/it]predicting train subjects:   7%|▋         | 18/266 [00:48<11:26,  2.77s/it]predicting train subjects:   7%|▋         | 19/266 [00:50<11:23,  2.77s/it]predicting train subjects:   8%|▊         | 20/266 [00:53<11:34,  2.82s/it]predicting train subjects:   8%|▊         | 21/266 [00:56<11:24,  2.79s/it]predicting train subjects:   8%|▊         | 22/266 [00:59<11:25,  2.81s/it]predicting train subjects:   9%|▊         | 23/266 [01:02<11:13,  2.77s/it]predicting train subjects:   9%|▉         | 24/266 [01:04<11:03,  2.74s/it]predicting train subjects:   9%|▉         | 25/266 [01:07<10:30,  2.62s/it]predicting train subjects:  10%|▉         | 26/266 [01:09<10:23,  2.60s/it]predicting train subjects:  10%|█         | 27/266 [01:12<10:18,  2.59s/it]predicting train subjects:  11%|█         | 28/266 [01:14<10:08,  2.56s/it]predicting train subjects:  11%|█         | 29/266 [01:17<09:59,  2.53s/it]predicting train subjects:  11%|█▏        | 30/266 [01:19<09:56,  2.53s/it]predicting train subjects:  12%|█▏        | 31/266 [01:22<10:05,  2.58s/it]predicting train subjects:  12%|█▏        | 32/266 [01:24<09:57,  2.55s/it]predicting train subjects:  12%|█▏        | 33/266 [01:27<09:49,  2.53s/it]predicting train subjects:  13%|█▎        | 34/266 [01:30<09:54,  2.56s/it]predicting train subjects:  13%|█▎        | 35/266 [01:32<09:45,  2.54s/it]predicting train subjects:  14%|█▎        | 36/266 [01:34<09:30,  2.48s/it]predicting train subjects:  14%|█▍        | 37/266 [01:37<09:14,  2.42s/it]predicting train subjects:  14%|█▍        | 38/266 [01:39<09:20,  2.46s/it]predicting train subjects:  15%|█▍        | 39/266 [01:43<10:14,  2.71s/it]predicting train subjects:  15%|█▌        | 40/266 [01:46<10:47,  2.86s/it]predicting train subjects:  15%|█▌        | 41/266 [01:49<11:09,  2.98s/it]predicting train subjects:  16%|█▌        | 42/266 [01:52<10:54,  2.92s/it]predicting train subjects:  16%|█▌        | 43/266 [01:55<10:40,  2.87s/it]predicting train subjects:  17%|█▋        | 44/266 [01:57<10:23,  2.81s/it]predicting train subjects:  17%|█▋        | 45/266 [02:00<10:18,  2.80s/it]predicting train subjects:  17%|█▋        | 46/266 [02:03<10:14,  2.79s/it]predicting train subjects:  18%|█▊        | 47/266 [02:06<10:13,  2.80s/it]predicting train subjects:  18%|█▊        | 48/266 [02:08<10:08,  2.79s/it]predicting train subjects:  18%|█▊        | 49/266 [02:11<10:01,  2.77s/it]predicting train subjects:  19%|█▉        | 50/266 [02:14<09:56,  2.76s/it]predicting train subjects:  19%|█▉        | 51/266 [02:16<09:47,  2.73s/it]predicting train subjects:  20%|█▉        | 52/266 [02:19<09:38,  2.71s/it]predicting train subjects:  20%|█▉        | 53/266 [02:22<09:33,  2.69s/it]predicting train subjects:  20%|██        | 54/266 [02:24<09:12,  2.61s/it]predicting train subjects:  21%|██        | 55/266 [02:27<09:09,  2.60s/it]predicting train subjects:  21%|██        | 56/266 [02:29<09:11,  2.63s/it]predicting train subjects:  21%|██▏       | 57/266 [02:32<08:56,  2.57s/it]predicting train subjects:  22%|██▏       | 58/266 [02:35<08:56,  2.58s/it]predicting train subjects:  22%|██▏       | 59/266 [02:37<09:03,  2.63s/it]predicting train subjects:  23%|██▎       | 60/266 [02:40<08:54,  2.60s/it]predicting train subjects:  23%|██▎       | 61/266 [02:42<08:38,  2.53s/it]predicting train subjects:  23%|██▎       | 62/266 [02:44<08:21,  2.46s/it]predicting train subjects:  24%|██▎       | 63/266 [02:47<08:04,  2.39s/it]predicting train subjects:  24%|██▍       | 64/266 [02:49<08:07,  2.41s/it]predicting train subjects:  24%|██▍       | 65/266 [02:52<08:11,  2.44s/it]predicting train subjects:  25%|██▍       | 66/266 [02:54<08:11,  2.46s/it]predicting train subjects:  25%|██▌       | 67/266 [02:56<08:02,  2.43s/it]predicting train subjects:  26%|██▌       | 68/266 [02:59<07:38,  2.32s/it]predicting train subjects:  26%|██▌       | 69/266 [03:01<07:48,  2.38s/it]predicting train subjects:  26%|██▋       | 70/266 [03:04<07:54,  2.42s/it]predicting train subjects:  27%|██▋       | 71/266 [03:06<07:57,  2.45s/it]predicting train subjects:  27%|██▋       | 72/266 [03:08<07:51,  2.43s/it]predicting train subjects:  27%|██▋       | 73/266 [03:11<07:47,  2.42s/it]predicting train subjects:  28%|██▊       | 74/266 [03:13<07:50,  2.45s/it]predicting train subjects:  28%|██▊       | 75/266 [03:16<07:46,  2.44s/it]predicting train subjects:  29%|██▊       | 76/266 [03:18<07:47,  2.46s/it]predicting train subjects:  29%|██▉       | 77/266 [03:21<07:42,  2.45s/it]predicting train subjects:  29%|██▉       | 78/266 [03:24<08:25,  2.69s/it]predicting train subjects:  30%|██▉       | 79/266 [03:27<08:52,  2.85s/it]predicting train subjects:  30%|███       | 80/266 [03:30<09:10,  2.96s/it]predicting train subjects:  30%|███       | 81/266 [03:34<09:26,  3.06s/it]predicting train subjects:  31%|███       | 82/266 [03:37<09:34,  3.12s/it]predicting train subjects:  31%|███       | 83/266 [03:40<09:42,  3.18s/it]predicting train subjects:  32%|███▏      | 84/266 [03:44<09:39,  3.18s/it]predicting train subjects:  32%|███▏      | 85/266 [03:47<09:36,  3.19s/it]predicting train subjects:  32%|███▏      | 86/266 [03:50<09:35,  3.20s/it]predicting train subjects:  33%|███▎      | 87/266 [03:53<09:35,  3.21s/it]predicting train subjects:  33%|███▎      | 88/266 [03:56<09:27,  3.19s/it]predicting train subjects:  33%|███▎      | 89/266 [04:00<09:24,  3.19s/it]predicting train subjects:  34%|███▍      | 90/266 [04:03<09:22,  3.19s/it]predicting train subjects:  34%|███▍      | 91/266 [04:06<09:20,  3.20s/it]predicting train subjects:  35%|███▍      | 92/266 [04:09<09:19,  3.22s/it]predicting train subjects:  35%|███▍      | 93/266 [04:12<09:20,  3.24s/it]predicting train subjects:  35%|███▌      | 94/266 [04:16<09:25,  3.29s/it]predicting train subjects:  36%|███▌      | 95/266 [04:19<09:19,  3.27s/it]predicting train subjects:  36%|███▌      | 96/266 [04:22<08:55,  3.15s/it]predicting train subjects:  36%|███▋      | 97/266 [04:25<08:58,  3.19s/it]predicting train subjects:  37%|███▋      | 98/266 [04:28<08:52,  3.17s/it]predicting train subjects:  37%|███▋      | 99/266 [04:31<08:08,  2.93s/it]predicting train subjects:  38%|███▊      | 100/266 [04:33<07:52,  2.85s/it]predicting train subjects:  38%|███▊      | 101/266 [04:36<07:35,  2.76s/it]predicting train subjects:  38%|███▊      | 102/266 [04:39<07:41,  2.81s/it]predicting train subjects:  39%|███▊      | 103/266 [04:42<07:42,  2.83s/it]predicting train subjects:  39%|███▉      | 104/266 [04:45<07:43,  2.86s/it]predicting train subjects:  39%|███▉      | 105/266 [04:48<07:41,  2.87s/it]predicting train subjects:  40%|███▉      | 106/266 [04:51<07:41,  2.88s/it]predicting train subjects:  40%|████      | 107/266 [04:53<07:37,  2.88s/it]predicting train subjects:  41%|████      | 108/266 [04:56<07:34,  2.87s/it]predicting train subjects:  41%|████      | 109/266 [04:59<07:35,  2.90s/it]predicting train subjects:  41%|████▏     | 110/266 [05:02<07:34,  2.91s/it]predicting train subjects:  42%|████▏     | 111/266 [05:05<07:36,  2.94s/it]predicting train subjects:  42%|████▏     | 112/266 [05:08<07:32,  2.94s/it]predicting train subjects:  42%|████▏     | 113/266 [05:11<07:26,  2.92s/it]predicting train subjects:  43%|████▎     | 114/266 [05:14<07:19,  2.89s/it]predicting train subjects:  43%|████▎     | 115/266 [05:17<07:22,  2.93s/it]predicting train subjects:  44%|████▎     | 116/266 [05:20<07:20,  2.93s/it]predicting train subjects:  44%|████▍     | 117/266 [05:23<07:19,  2.95s/it]predicting train subjects:  44%|████▍     | 118/266 [05:26<07:16,  2.95s/it]predicting train subjects:  45%|████▍     | 119/266 [05:29<07:31,  3.07s/it]predicting train subjects:  45%|████▌     | 120/266 [05:32<07:39,  3.15s/it]predicting train subjects:  45%|████▌     | 121/266 [05:36<07:41,  3.18s/it]predicting train subjects:  46%|████▌     | 122/266 [05:39<07:42,  3.21s/it]predicting train subjects:  46%|████▌     | 123/266 [05:42<07:42,  3.23s/it]predicting train subjects:  47%|████▋     | 124/266 [05:46<07:43,  3.27s/it]predicting train subjects:  47%|████▋     | 125/266 [05:49<07:39,  3.26s/it]predicting train subjects:  47%|████▋     | 126/266 [05:52<07:36,  3.26s/it]predicting train subjects:  48%|████▊     | 127/266 [05:55<07:32,  3.26s/it]predicting train subjects:  48%|████▊     | 128/266 [05:59<07:27,  3.24s/it]predicting train subjects:  48%|████▊     | 129/266 [06:02<07:21,  3.23s/it]predicting train subjects:  49%|████▉     | 130/266 [06:05<07:17,  3.21s/it]predicting train subjects:  49%|████▉     | 131/266 [06:08<07:16,  3.24s/it]predicting train subjects:  50%|████▉     | 132/266 [06:11<07:17,  3.26s/it]predicting train subjects:  50%|█████     | 133/266 [06:15<07:11,  3.24s/it]predicting train subjects:  50%|█████     | 134/266 [06:18<07:07,  3.24s/it]predicting train subjects:  51%|█████     | 135/266 [06:21<07:04,  3.24s/it]predicting train subjects:  51%|█████     | 136/266 [06:24<06:58,  3.22s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:28<06:54,  3.21s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:31<06:42,  3.14s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:34<06:36,  3.12s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:37<06:31,  3.11s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:40<06:29,  3.11s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:43<06:26,  3.12s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:46<06:24,  3.13s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:49<06:20,  3.12s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:52<06:17,  3.12s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:55<06:14,  3.12s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:58<06:09,  3.11s/it]predicting train subjects:  56%|█████▌    | 148/266 [07:02<06:06,  3.11s/it]predicting train subjects:  56%|█████▌    | 149/266 [07:05<05:59,  3.07s/it]predicting train subjects:  56%|█████▋    | 150/266 [07:08<05:58,  3.09s/it]predicting train subjects:  57%|█████▋    | 151/266 [07:11<05:54,  3.08s/it]predicting train subjects:  57%|█████▋    | 152/266 [07:14<05:51,  3.08s/it]predicting train subjects:  58%|█████▊    | 153/266 [07:17<05:48,  3.08s/it]predicting train subjects:  58%|█████▊    | 154/266 [07:20<05:51,  3.14s/it]predicting train subjects:  58%|█████▊    | 155/266 [07:23<05:24,  2.92s/it]predicting train subjects:  59%|█████▊    | 156/266 [07:25<05:01,  2.74s/it]predicting train subjects:  59%|█████▉    | 157/266 [07:27<04:42,  2.59s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:29<04:28,  2.49s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:32<04:18,  2.42s/it]predicting train subjects:  60%|██████    | 160/266 [07:34<04:06,  2.33s/it]predicting train subjects:  61%|██████    | 161/266 [07:36<04:03,  2.32s/it]predicting train subjects:  61%|██████    | 162/266 [07:38<04:01,  2.32s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:41<03:57,  2.30s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:43<03:53,  2.28s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:45<03:46,  2.24s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:47<03:45,  2.26s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:50<03:43,  2.26s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:52<03:44,  2.29s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:54<03:44,  2.31s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:57<03:41,  2.31s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:59<03:37,  2.29s/it]predicting train subjects:  65%|██████▍   | 172/266 [08:01<03:35,  2.29s/it]predicting train subjects:  65%|██████▌   | 173/266 [08:04<03:43,  2.40s/it]predicting train subjects:  65%|██████▌   | 174/266 [08:06<03:46,  2.46s/it]predicting train subjects:  66%|██████▌   | 175/266 [08:09<03:50,  2.53s/it]predicting train subjects:  66%|██████▌   | 176/266 [08:12<03:51,  2.58s/it]predicting train subjects:  67%|██████▋   | 177/266 [08:14<03:51,  2.60s/it]predicting train subjects:  67%|██████▋   | 178/266 [08:17<03:51,  2.63s/it]predicting train subjects:  67%|██████▋   | 179/266 [08:20<03:49,  2.64s/it]predicting train subjects:  68%|██████▊   | 180/266 [08:23<03:48,  2.66s/it]predicting train subjects:  68%|██████▊   | 181/266 [08:25<03:47,  2.68s/it]predicting train subjects:  68%|██████▊   | 182/266 [08:28<03:45,  2.68s/it]predicting train subjects:  69%|██████▉   | 183/266 [08:31<03:42,  2.68s/it]predicting train subjects:  69%|██████▉   | 184/266 [08:33<03:41,  2.70s/it]predicting train subjects:  70%|██████▉   | 185/266 [08:36<03:36,  2.67s/it]predicting train subjects:  70%|██████▉   | 186/266 [08:39<03:32,  2.66s/it]predicting train subjects:  70%|███████   | 187/266 [08:41<03:33,  2.71s/it]predicting train subjects:  71%|███████   | 188/266 [08:44<03:28,  2.67s/it]predicting train subjects:  71%|███████   | 189/266 [08:47<03:29,  2.72s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:49<03:24,  2.70s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:52<03:25,  2.74s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:55<03:13,  2.62s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:57<03:07,  2.56s/it]predicting train subjects:  73%|███████▎  | 194/266 [09:00<03:14,  2.71s/it]predicting train subjects:  73%|███████▎  | 195/266 [09:03<03:17,  2.78s/it]predicting train subjects:  74%|███████▎  | 196/266 [09:06<03:15,  2.79s/it]predicting train subjects:  74%|███████▍  | 197/266 [09:09<03:13,  2.80s/it]predicting train subjects:  74%|███████▍  | 198/266 [09:12<03:11,  2.82s/it]predicting train subjects:  75%|███████▍  | 199/266 [09:14<03:09,  2.82s/it]predicting train subjects:  75%|███████▌  | 200/266 [09:17<03:04,  2.80s/it]predicting train subjects:  76%|███████▌  | 201/266 [09:20<03:03,  2.82s/it]predicting train subjects:  76%|███████▌  | 202/266 [09:23<03:00,  2.83s/it]predicting train subjects:  76%|███████▋  | 203/266 [09:26<03:01,  2.87s/it]predicting train subjects:  77%|███████▋  | 204/266 [09:29<02:56,  2.85s/it]predicting train subjects:  77%|███████▋  | 205/266 [09:32<02:54,  2.85s/it]predicting train subjects:  77%|███████▋  | 206/266 [09:34<02:51,  2.85s/it]predicting train subjects:  78%|███████▊  | 207/266 [09:37<02:47,  2.84s/it]predicting train subjects:  78%|███████▊  | 208/266 [09:40<02:44,  2.84s/it]predicting train subjects:  79%|███████▊  | 209/266 [09:43<02:41,  2.83s/it]predicting train subjects:  79%|███████▉  | 210/266 [09:46<02:38,  2.82s/it]predicting train subjects:  79%|███████▉  | 211/266 [09:48<02:35,  2.83s/it]predicting train subjects:  80%|███████▉  | 212/266 [09:51<02:33,  2.84s/it]predicting train subjects:  80%|████████  | 213/266 [09:54<02:23,  2.71s/it]predicting train subjects:  80%|████████  | 214/266 [09:56<02:16,  2.62s/it]predicting train subjects:  81%|████████  | 215/266 [09:59<02:11,  2.57s/it]predicting train subjects:  81%|████████  | 216/266 [10:01<02:10,  2.62s/it]predicting train subjects:  82%|████████▏ | 217/266 [10:04<02:09,  2.64s/it]predicting train subjects:  82%|████████▏ | 218/266 [10:06<02:04,  2.59s/it]predicting train subjects:  82%|████████▏ | 219/266 [10:09<01:59,  2.55s/it]predicting train subjects:  83%|████████▎ | 220/266 [10:11<01:54,  2.49s/it]predicting train subjects:  83%|████████▎ | 221/266 [10:14<01:50,  2.46s/it]predicting train subjects:  83%|████████▎ | 222/266 [10:16<01:49,  2.49s/it]predicting train subjects:  84%|████████▍ | 223/266 [10:19<01:47,  2.50s/it]predicting train subjects:  84%|████████▍ | 224/266 [10:21<01:44,  2.48s/it]predicting train subjects:  85%|████████▍ | 225/266 [10:24<01:39,  2.44s/it]predicting train subjects:  85%|████████▍ | 226/266 [10:26<01:41,  2.54s/it]predicting train subjects:  85%|████████▌ | 227/266 [10:29<01:37,  2.51s/it]predicting train subjects:  86%|████████▌ | 228/266 [10:31<01:34,  2.48s/it]predicting train subjects:  86%|████████▌ | 229/266 [10:34<01:32,  2.49s/it]predicting train subjects:  86%|████████▋ | 230/266 [10:36<01:31,  2.54s/it]predicting train subjects:  87%|████████▋ | 231/266 [10:39<01:29,  2.57s/it]predicting train subjects:  87%|████████▋ | 232/266 [10:41<01:26,  2.55s/it]predicting train subjects:  88%|████████▊ | 233/266 [10:44<01:22,  2.51s/it]predicting train subjects:  88%|████████▊ | 234/266 [10:46<01:20,  2.51s/it]predicting train subjects:  88%|████████▊ | 235/266 [10:49<01:17,  2.51s/it]predicting train subjects:  89%|████████▊ | 236/266 [10:51<01:15,  2.52s/it]predicting train subjects:  89%|████████▉ | 237/266 [10:54<01:13,  2.54s/it]predicting train subjects:  89%|████████▉ | 238/266 [10:57<01:10,  2.52s/it]predicting train subjects:  90%|████████▉ | 239/266 [10:59<01:08,  2.54s/it]predicting train subjects:  90%|█████████ | 240/266 [11:02<01:06,  2.56s/it]predicting train subjects:  91%|█████████ | 241/266 [11:04<01:02,  2.51s/it]predicting train subjects:  91%|█████████ | 242/266 [11:07<01:00,  2.51s/it]predicting train subjects:  91%|█████████▏| 243/266 [11:09<00:57,  2.50s/it]predicting train subjects:  92%|█████████▏| 244/266 [11:12<00:54,  2.49s/it]predicting train subjects:  92%|█████████▏| 245/266 [11:14<00:52,  2.50s/it]predicting train subjects:  92%|█████████▏| 246/266 [11:17<00:50,  2.50s/it]predicting train subjects:  93%|█████████▎| 247/266 [11:19<00:47,  2.49s/it]predicting train subjects:  93%|█████████▎| 248/266 [11:22<00:44,  2.49s/it]predicting train subjects:  94%|█████████▎| 249/266 [11:25<00:45,  2.69s/it]predicting train subjects:  94%|█████████▍| 250/266 [11:28<00:45,  2.84s/it]predicting train subjects:  94%|█████████▍| 251/266 [11:31<00:44,  2.96s/it]predicting train subjects:  95%|█████████▍| 252/266 [11:34<00:42,  3.04s/it]predicting train subjects:  95%|█████████▌| 253/266 [11:38<00:40,  3.09s/it]predicting train subjects:  95%|█████████▌| 254/266 [11:41<00:37,  3.13s/it]predicting train subjects:  96%|█████████▌| 255/266 [11:44<00:34,  3.13s/it]predicting train subjects:  96%|█████████▌| 256/266 [11:47<00:31,  3.18s/it]predicting train subjects:  97%|█████████▋| 257/266 [11:50<00:28,  3.21s/it]predicting train subjects:  97%|█████████▋| 258/266 [11:54<00:25,  3.19s/it]predicting train subjects:  97%|█████████▋| 259/266 [11:57<00:22,  3.18s/it]predicting train subjects:  98%|█████████▊| 260/266 [12:00<00:18,  3.16s/it]predicting train subjects:  98%|█████████▊| 261/266 [12:03<00:15,  3.16s/it]predicting train subjects:  98%|█████████▊| 262/266 [12:06<00:12,  3.18s/it]predicting train subjects:  99%|█████████▉| 263/266 [12:09<00:09,  3.19s/it]predicting train subjects:  99%|█████████▉| 264/266 [12:13<00:06,  3.17s/it]predicting train subjects: 100%|█████████▉| 265/266 [12:16<00:03,  3.17s/it]predicting train subjects: 100%|██████████| 266/266 [12:19<00:00,  3.17s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:38,  1.21it/s]Loading train:   1%|          | 2/266 [00:01<03:28,  1.26it/s]Loading train:   1%|          | 3/266 [00:02<03:12,  1.37it/s]Loading train:   2%|▏         | 4/266 [00:02<02:49,  1.55it/s]Loading train:   2%|▏         | 5/266 [00:03<02:50,  1.53it/s]Loading train:   2%|▏         | 6/266 [00:03<02:45,  1.57it/s]Loading train:   3%|▎         | 7/266 [00:04<02:57,  1.46it/s]Loading train:   3%|▎         | 8/266 [00:05<02:48,  1.53it/s]Loading train:   3%|▎         | 9/266 [00:05<02:35,  1.66it/s]Loading train:   4%|▍         | 10/266 [00:06<02:38,  1.61it/s]Loading train:   4%|▍         | 11/266 [00:07<02:50,  1.49it/s]Loading train:   5%|▍         | 12/266 [00:07<02:38,  1.60it/s]Loading train:   5%|▍         | 13/266 [00:08<02:40,  1.57it/s]Loading train:   5%|▌         | 14/266 [00:09<02:44,  1.53it/s]Loading train:   6%|▌         | 15/266 [00:09<02:46,  1.51it/s]Loading train:   6%|▌         | 16/266 [00:10<02:52,  1.45it/s]Loading train:   6%|▋         | 17/266 [00:11<02:52,  1.44it/s]Loading train:   7%|▋         | 18/266 [00:11<02:47,  1.48it/s]Loading train:   7%|▋         | 19/266 [00:12<02:42,  1.52it/s]Loading train:   8%|▊         | 20/266 [00:13<02:42,  1.52it/s]Loading train:   8%|▊         | 21/266 [00:13<02:31,  1.62it/s]Loading train:   8%|▊         | 22/266 [00:14<02:33,  1.59it/s]Loading train:   9%|▊         | 23/266 [00:15<02:46,  1.46it/s]Loading train:   9%|▉         | 24/266 [00:15<02:45,  1.46it/s]Loading train:   9%|▉         | 25/266 [00:16<02:44,  1.47it/s]Loading train:  10%|▉         | 26/266 [00:17<02:43,  1.46it/s]Loading train:  10%|█         | 27/266 [00:17<02:41,  1.48it/s]Loading train:  11%|█         | 28/266 [00:18<02:39,  1.49it/s]Loading train:  11%|█         | 29/266 [00:19<02:34,  1.54it/s]Loading train:  11%|█▏        | 30/266 [00:19<02:31,  1.56it/s]Loading train:  12%|█▏        | 31/266 [00:20<02:33,  1.53it/s]Loading train:  12%|█▏        | 32/266 [00:21<02:39,  1.46it/s]Loading train:  12%|█▏        | 33/266 [00:21<02:35,  1.50it/s]Loading train:  13%|█▎        | 34/266 [00:22<02:36,  1.48it/s]Loading train:  13%|█▎        | 35/266 [00:23<02:33,  1.51it/s]Loading train:  14%|█▎        | 36/266 [00:23<02:29,  1.54it/s]Loading train:  14%|█▍        | 37/266 [00:24<02:28,  1.55it/s]Loading train:  14%|█▍        | 38/266 [00:25<02:35,  1.46it/s]Loading train:  15%|█▍        | 39/266 [00:25<02:34,  1.47it/s]Loading train:  15%|█▌        | 40/266 [00:26<02:42,  1.39it/s]Loading train:  15%|█▌        | 41/266 [00:27<02:42,  1.39it/s]Loading train:  16%|█▌        | 42/266 [00:27<02:32,  1.47it/s]Loading train:  16%|█▌        | 43/266 [00:28<02:30,  1.48it/s]Loading train:  17%|█▋        | 44/266 [00:29<02:25,  1.53it/s]Loading train:  17%|█▋        | 45/266 [00:29<02:29,  1.48it/s]Loading train:  17%|█▋        | 46/266 [00:30<02:21,  1.56it/s]Loading train:  18%|█▊        | 47/266 [00:30<02:13,  1.64it/s]Loading train:  18%|█▊        | 48/266 [00:31<02:14,  1.62it/s]Loading train:  18%|█▊        | 49/266 [00:32<02:21,  1.53it/s]Loading train:  19%|█▉        | 50/266 [00:33<02:27,  1.46it/s]Loading train:  19%|█▉        | 51/266 [00:33<02:23,  1.50it/s]Loading train:  20%|█▉        | 52/266 [00:34<02:25,  1.47it/s]Loading train:  20%|█▉        | 53/266 [00:35<02:19,  1.52it/s]Loading train:  20%|██        | 54/266 [00:35<02:22,  1.49it/s]Loading train:  21%|██        | 55/266 [00:36<02:23,  1.47it/s]Loading train:  21%|██        | 56/266 [00:37<02:17,  1.53it/s]Loading train:  21%|██▏       | 57/266 [00:37<02:08,  1.62it/s]Loading train:  22%|██▏       | 58/266 [00:38<02:07,  1.63it/s]Loading train:  22%|██▏       | 59/266 [00:38<02:01,  1.70it/s]Loading train:  23%|██▎       | 60/266 [00:39<02:02,  1.67it/s]Loading train:  23%|██▎       | 61/266 [00:39<02:02,  1.67it/s]Loading train:  23%|██▎       | 62/266 [00:40<02:08,  1.59it/s]Loading train:  24%|██▎       | 63/266 [00:41<02:21,  1.44it/s]Loading train:  24%|██▍       | 64/266 [00:42<02:27,  1.37it/s]Loading train:  24%|██▍       | 65/266 [00:43<02:31,  1.33it/s]Loading train:  25%|██▍       | 66/266 [00:43<02:22,  1.41it/s]Loading train:  25%|██▌       | 67/266 [00:44<02:20,  1.42it/s]Loading train:  26%|██▌       | 68/266 [00:44<02:12,  1.49it/s]Loading train:  26%|██▌       | 69/266 [00:45<02:17,  1.43it/s]Loading train:  26%|██▋       | 70/266 [00:46<02:16,  1.44it/s]Loading train:  27%|██▋       | 71/266 [00:47<02:08,  1.52it/s]Loading train:  27%|██▋       | 72/266 [00:47<02:05,  1.54it/s]Loading train:  27%|██▋       | 73/266 [00:48<01:53,  1.71it/s]Loading train:  28%|██▊       | 74/266 [00:48<01:54,  1.68it/s]Loading train:  28%|██▊       | 75/266 [00:49<01:58,  1.61it/s]Loading train:  29%|██▊       | 76/266 [00:50<02:00,  1.58it/s]Loading train:  29%|██▉       | 77/266 [00:50<01:49,  1.73it/s]Loading train:  29%|██▉       | 78/266 [00:51<01:56,  1.62it/s]Loading train:  30%|██▉       | 79/266 [00:51<02:00,  1.55it/s]Loading train:  30%|███       | 80/266 [00:52<02:00,  1.54it/s]Loading train:  30%|███       | 81/266 [00:53<02:01,  1.52it/s]Loading train:  31%|███       | 82/266 [00:53<02:01,  1.52it/s]Loading train:  31%|███       | 83/266 [00:54<02:03,  1.49it/s]Loading train:  32%|███▏      | 84/266 [00:55<01:59,  1.53it/s]Loading train:  32%|███▏      | 85/266 [00:55<02:02,  1.48it/s]Loading train:  32%|███▏      | 86/266 [00:56<02:03,  1.46it/s]Loading train:  33%|███▎      | 87/266 [00:57<01:58,  1.51it/s]Loading train:  33%|███▎      | 88/266 [00:57<01:58,  1.50it/s]Loading train:  33%|███▎      | 89/266 [00:58<01:58,  1.49it/s]Loading train:  34%|███▍      | 90/266 [00:59<01:57,  1.50it/s]Loading train:  34%|███▍      | 91/266 [00:59<01:54,  1.53it/s]Loading train:  35%|███▍      | 92/266 [01:00<01:51,  1.56it/s]Loading train:  35%|███▍      | 93/266 [01:01<01:49,  1.58it/s]Loading train:  35%|███▌      | 94/266 [01:01<01:54,  1.51it/s]Loading train:  36%|███▌      | 95/266 [01:02<02:02,  1.40it/s]Loading train:  36%|███▌      | 96/266 [01:03<01:59,  1.42it/s]Loading train:  36%|███▋      | 97/266 [01:04<02:01,  1.39it/s]Loading train:  37%|███▋      | 98/266 [01:04<01:59,  1.40it/s]Loading train:  37%|███▋      | 99/266 [01:05<01:58,  1.41it/s]Loading train:  38%|███▊      | 100/266 [01:06<01:57,  1.42it/s]Loading train:  38%|███▊      | 101/266 [01:06<01:54,  1.44it/s]Loading train:  38%|███▊      | 102/266 [01:07<01:51,  1.47it/s]Loading train:  39%|███▊      | 103/266 [01:08<01:50,  1.47it/s]Loading train:  39%|███▉      | 104/266 [01:08<01:46,  1.53it/s]Loading train:  39%|███▉      | 105/266 [01:09<01:47,  1.50it/s]Loading train:  40%|███▉      | 106/266 [01:10<01:43,  1.55it/s]Loading train:  40%|████      | 107/266 [01:10<01:43,  1.54it/s]Loading train:  41%|████      | 108/266 [01:11<01:47,  1.47it/s]Loading train:  41%|████      | 109/266 [01:12<01:42,  1.53it/s]Loading train:  41%|████▏     | 110/266 [01:12<01:44,  1.49it/s]Loading train:  42%|████▏     | 111/266 [01:13<01:42,  1.52it/s]Loading train:  42%|████▏     | 112/266 [01:14<01:39,  1.55it/s]Loading train:  42%|████▏     | 113/266 [01:14<01:42,  1.50it/s]Loading train:  43%|████▎     | 114/266 [01:15<01:46,  1.42it/s]Loading train:  43%|████▎     | 115/266 [01:16<01:49,  1.38it/s]Loading train:  44%|████▎     | 116/266 [01:17<01:48,  1.39it/s]Loading train:  44%|████▍     | 117/266 [01:17<01:40,  1.48it/s]Loading train:  44%|████▍     | 118/266 [01:18<01:45,  1.41it/s]Loading train:  45%|████▍     | 119/266 [01:19<01:53,  1.29it/s]Loading train:  45%|████▌     | 120/266 [01:20<02:01,  1.20it/s]Loading train:  45%|████▌     | 121/266 [01:21<02:00,  1.21it/s]Loading train:  46%|████▌     | 122/266 [01:21<01:59,  1.21it/s]Loading train:  46%|████▌     | 123/266 [01:22<02:02,  1.17it/s]Loading train:  47%|████▋     | 124/266 [01:23<01:56,  1.22it/s]Loading train:  47%|████▋     | 125/266 [01:24<01:56,  1.21it/s]Loading train:  47%|████▋     | 126/266 [01:25<02:01,  1.15it/s]Loading train:  48%|████▊     | 127/266 [01:26<01:57,  1.18it/s]Loading train:  48%|████▊     | 128/266 [01:27<01:58,  1.16it/s]Loading train:  48%|████▊     | 129/266 [01:27<01:56,  1.18it/s]Loading train:  49%|████▉     | 130/266 [01:28<01:57,  1.16it/s]Loading train:  49%|████▉     | 131/266 [01:29<02:02,  1.10it/s]Loading train:  50%|████▉     | 132/266 [01:30<01:57,  1.14it/s]Loading train:  50%|█████     | 133/266 [01:31<01:55,  1.15it/s]Loading train:  50%|█████     | 134/266 [01:32<02:00,  1.09it/s]Loading train:  51%|█████     | 135/266 [01:33<01:55,  1.13it/s]Loading train:  51%|█████     | 136/266 [01:34<01:58,  1.09it/s]Loading train:  52%|█████▏    | 137/266 [01:35<01:52,  1.15it/s]Loading train:  52%|█████▏    | 138/266 [01:35<01:52,  1.14it/s]Loading train:  52%|█████▏    | 139/266 [01:36<01:49,  1.16it/s]Loading train:  53%|█████▎    | 140/266 [01:37<01:40,  1.25it/s]Loading train:  53%|█████▎    | 141/266 [01:38<01:45,  1.18it/s]Loading train:  53%|█████▎    | 142/266 [01:39<01:40,  1.23it/s]Loading train:  54%|█████▍    | 143/266 [01:39<01:37,  1.26it/s]Loading train:  54%|█████▍    | 144/266 [01:40<01:35,  1.28it/s]Loading train:  55%|█████▍    | 145/266 [01:41<01:38,  1.23it/s]Loading train:  55%|█████▍    | 146/266 [01:42<01:35,  1.26it/s]Loading train:  55%|█████▌    | 147/266 [01:43<01:35,  1.24it/s]Loading train:  56%|█████▌    | 148/266 [01:43<01:31,  1.28it/s]Loading train:  56%|█████▌    | 149/266 [01:44<01:22,  1.42it/s]Loading train:  56%|█████▋    | 150/266 [01:45<01:28,  1.32it/s]Loading train:  57%|█████▋    | 151/266 [01:45<01:26,  1.33it/s]Loading train:  57%|█████▋    | 152/266 [01:46<01:30,  1.26it/s]Loading train:  58%|█████▊    | 153/266 [01:47<01:34,  1.19it/s]Loading train:  58%|█████▊    | 154/266 [01:48<01:32,  1.21it/s]Loading train:  58%|█████▊    | 155/266 [01:49<01:30,  1.22it/s]Loading train:  59%|█████▊    | 156/266 [01:50<01:32,  1.19it/s]Loading train:  59%|█████▉    | 157/266 [01:51<01:29,  1.21it/s]Loading train:  59%|█████▉    | 158/266 [01:51<01:23,  1.29it/s]Loading train:  60%|█████▉    | 159/266 [01:52<01:21,  1.31it/s]Loading train:  60%|██████    | 160/266 [01:53<01:15,  1.40it/s]Loading train:  61%|██████    | 161/266 [01:53<01:15,  1.39it/s]Loading train:  61%|██████    | 162/266 [01:54<01:13,  1.42it/s]Loading train:  61%|██████▏   | 163/266 [01:55<01:11,  1.43it/s]Loading train:  62%|██████▏   | 164/266 [01:55<01:10,  1.44it/s]Loading train:  62%|██████▏   | 165/266 [01:56<01:09,  1.44it/s]Loading train:  62%|██████▏   | 166/266 [01:57<01:08,  1.46it/s]Loading train:  63%|██████▎   | 167/266 [01:58<01:12,  1.37it/s]Loading train:  63%|██████▎   | 168/266 [01:58<01:12,  1.35it/s]Loading train:  64%|██████▎   | 169/266 [01:59<01:08,  1.42it/s]Loading train:  64%|██████▍   | 170/266 [02:00<01:08,  1.40it/s]Loading train:  64%|██████▍   | 171/266 [02:00<01:09,  1.37it/s]Loading train:  65%|██████▍   | 172/266 [02:01<01:06,  1.41it/s]Loading train:  65%|██████▌   | 173/266 [02:02<01:05,  1.42it/s]Loading train:  65%|██████▌   | 174/266 [02:03<01:07,  1.36it/s]Loading train:  66%|██████▌   | 175/266 [02:03<01:08,  1.33it/s]Loading train:  66%|██████▌   | 176/266 [02:04<01:06,  1.36it/s]Loading train:  67%|██████▋   | 177/266 [02:05<01:04,  1.39it/s]Loading train:  67%|██████▋   | 178/266 [02:06<01:05,  1.35it/s]Loading train:  67%|██████▋   | 179/266 [02:06<01:02,  1.38it/s]Loading train:  68%|██████▊   | 180/266 [02:07<00:57,  1.48it/s]Loading train:  68%|██████▊   | 181/266 [02:07<00:54,  1.57it/s]Loading train:  68%|██████▊   | 182/266 [02:08<00:58,  1.43it/s]Loading train:  69%|██████▉   | 183/266 [02:09<00:58,  1.41it/s]Loading train:  69%|██████▉   | 184/266 [02:10<00:58,  1.41it/s]Loading train:  70%|██████▉   | 185/266 [02:10<00:56,  1.43it/s]Loading train:  70%|██████▉   | 186/266 [02:11<00:54,  1.48it/s]Loading train:  70%|███████   | 187/266 [02:12<00:52,  1.50it/s]Loading train:  71%|███████   | 188/266 [02:12<00:53,  1.45it/s]Loading train:  71%|███████   | 189/266 [02:13<00:54,  1.43it/s]Loading train:  71%|███████▏  | 190/266 [02:14<00:54,  1.40it/s]Loading train:  72%|███████▏  | 191/266 [02:15<00:54,  1.38it/s]Loading train:  72%|███████▏  | 192/266 [02:15<00:51,  1.43it/s]Loading train:  73%|███████▎  | 193/266 [02:16<00:52,  1.40it/s]Loading train:  73%|███████▎  | 194/266 [02:17<00:55,  1.30it/s]Loading train:  73%|███████▎  | 195/266 [02:17<00:51,  1.38it/s]Loading train:  74%|███████▎  | 196/266 [02:18<00:50,  1.38it/s]Loading train:  74%|███████▍  | 197/266 [02:19<00:51,  1.33it/s]Loading train:  74%|███████▍  | 198/266 [02:20<00:51,  1.33it/s]Loading train:  75%|███████▍  | 199/266 [02:21<00:52,  1.27it/s]Loading train:  75%|███████▌  | 200/266 [02:21<00:51,  1.29it/s]Loading train:  76%|███████▌  | 201/266 [02:22<00:45,  1.44it/s]Loading train:  76%|███████▌  | 202/266 [02:23<00:44,  1.43it/s]Loading train:  76%|███████▋  | 203/266 [02:23<00:39,  1.62it/s]Loading train:  77%|███████▋  | 204/266 [02:24<00:40,  1.53it/s]Loading train:  77%|███████▋  | 205/266 [02:24<00:37,  1.64it/s]Loading train:  77%|███████▋  | 206/266 [02:25<00:38,  1.57it/s]Loading train:  78%|███████▊  | 207/266 [02:26<00:41,  1.43it/s]Loading train:  78%|███████▊  | 208/266 [02:27<00:41,  1.41it/s]Loading train:  79%|███████▊  | 209/266 [02:27<00:41,  1.39it/s]Loading train:  79%|███████▉  | 210/266 [02:28<00:41,  1.35it/s]Loading train:  79%|███████▉  | 211/266 [02:29<00:41,  1.34it/s]Loading train:  80%|███████▉  | 212/266 [02:30<00:41,  1.30it/s]Loading train:  80%|████████  | 213/266 [02:30<00:40,  1.32it/s]Loading train:  80%|████████  | 214/266 [02:31<00:40,  1.29it/s]Loading train:  81%|████████  | 215/266 [02:32<00:40,  1.26it/s]Loading train:  81%|████████  | 216/266 [02:33<00:35,  1.41it/s]Loading train:  82%|████████▏ | 217/266 [02:33<00:34,  1.40it/s]Loading train:  82%|████████▏ | 218/266 [02:34<00:34,  1.37it/s]Loading train:  82%|████████▏ | 219/266 [02:35<00:33,  1.40it/s]Loading train:  83%|████████▎ | 220/266 [02:35<00:31,  1.45it/s]Loading train:  83%|████████▎ | 221/266 [02:36<00:32,  1.38it/s]Loading train:  83%|████████▎ | 222/266 [02:37<00:29,  1.47it/s]Loading train:  84%|████████▍ | 223/266 [02:37<00:29,  1.44it/s]Loading train:  84%|████████▍ | 224/266 [02:38<00:28,  1.46it/s]Loading train:  85%|████████▍ | 225/266 [02:39<00:27,  1.50it/s]Loading train:  85%|████████▍ | 226/266 [02:39<00:26,  1.51it/s]Loading train:  85%|████████▌ | 227/266 [02:40<00:26,  1.46it/s]Loading train:  86%|████████▌ | 228/266 [02:41<00:28,  1.32it/s]Loading train:  86%|████████▌ | 229/266 [02:42<00:27,  1.33it/s]Loading train:  86%|████████▋ | 230/266 [02:42<00:25,  1.44it/s]Loading train:  87%|████████▋ | 231/266 [02:43<00:24,  1.40it/s]Loading train:  87%|████████▋ | 232/266 [02:44<00:23,  1.46it/s]Loading train:  88%|████████▊ | 233/266 [02:44<00:21,  1.51it/s]Loading train:  88%|████████▊ | 234/266 [02:45<00:20,  1.53it/s]Loading train:  88%|████████▊ | 235/266 [02:46<00:20,  1.49it/s]Loading train:  89%|████████▊ | 236/266 [02:46<00:19,  1.52it/s]Loading train:  89%|████████▉ | 237/266 [02:47<00:19,  1.47it/s]Loading train:  89%|████████▉ | 238/266 [02:48<00:20,  1.37it/s]Loading train:  90%|████████▉ | 239/266 [02:49<00:20,  1.31it/s]Loading train:  90%|█████████ | 240/266 [02:49<00:19,  1.32it/s]Loading train:  91%|█████████ | 241/266 [02:50<00:18,  1.34it/s]Loading train:  91%|█████████ | 242/266 [02:51<00:17,  1.37it/s]Loading train:  91%|█████████▏| 243/266 [02:52<00:16,  1.38it/s]Loading train:  92%|█████████▏| 244/266 [02:52<00:15,  1.43it/s]Loading train:  92%|█████████▏| 245/266 [02:53<00:12,  1.63it/s]Loading train:  92%|█████████▏| 246/266 [02:53<00:11,  1.71it/s]Loading train:  93%|█████████▎| 247/266 [02:54<00:10,  1.73it/s]Loading train:  93%|█████████▎| 248/266 [02:54<00:10,  1.73it/s]Loading train:  94%|█████████▎| 249/266 [02:55<00:10,  1.58it/s]Loading train:  94%|█████████▍| 250/266 [02:56<00:10,  1.57it/s]Loading train:  94%|█████████▍| 251/266 [02:57<00:10,  1.40it/s]Loading train:  95%|█████████▍| 252/266 [02:57<00:09,  1.40it/s]Loading train:  95%|█████████▌| 253/266 [02:58<00:09,  1.37it/s]Loading train:  95%|█████████▌| 254/266 [02:59<00:08,  1.35it/s]Loading train:  96%|█████████▌| 255/266 [02:59<00:07,  1.41it/s]Loading train:  96%|█████████▌| 256/266 [03:00<00:06,  1.46it/s]Loading train:  97%|█████████▋| 257/266 [03:01<00:06,  1.41it/s]Loading train:  97%|█████████▋| 258/266 [03:01<00:05,  1.49it/s]Loading train:  97%|█████████▋| 259/266 [03:02<00:04,  1.54it/s]Loading train:  98%|█████████▊| 260/266 [03:03<00:03,  1.55it/s]Loading train:  98%|█████████▊| 261/266 [03:03<00:03,  1.58it/s]Loading train:  98%|█████████▊| 262/266 [03:04<00:02,  1.55it/s]Loading train:  99%|█████████▉| 263/266 [03:05<00:01,  1.54it/s]Loading train:  99%|█████████▉| 264/266 [03:05<00:01,  1.55it/s]Loading train: 100%|█████████▉| 265/266 [03:06<00:00,  1.57it/s]Loading train: 100%|██████████| 266/266 [03:07<00:00,  1.47it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:25, 10.18it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:22, 11.62it/s]concatenating: train:  14%|█▍        | 37/266 [00:00<00:14, 16.33it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:12, 17.15it/s]concatenating: train:  27%|██▋       | 72/266 [00:01<00:08, 23.79it/s]concatenating: train:  42%|████▏     | 112/266 [00:01<00:04, 33.14it/s]concatenating: train:  56%|█████▋    | 150/266 [00:01<00:02, 45.59it/s]concatenating: train:  66%|██████▌   | 176/266 [00:01<00:01, 45.91it/s]concatenating: train:  82%|████████▏ | 217/266 [00:01<00:00, 62.54it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 133.42it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.27it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.29it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.43it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.44it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.39it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 14.30it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 25.57it/s]2019-08-16 23:13:26.527604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-16 23:13:26.527712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-16 23:13:26.527730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-16 23:13:26.527743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-16 23:13:26.528273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.16it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.86it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.31it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.49it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.89it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.58it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.42it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.12it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.93it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.53it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.01it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:02,  7.01it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  5.40it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.58it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.80it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.17it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  4.96it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  5.91it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.06it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.37it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 108,122
Non-trainable params: 392,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 55s - loss: 0.1081 - acc: 0.9883 - mDice: 0.8416 - val_loss: 0.0613 - val_acc: 0.9943 - val_mDice: 0.8878

Epoch 00001: val_mDice improved from -inf to 0.88779, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 50s - loss: 0.0528 - acc: 0.9942 - mDice: 0.9027 - val_loss: 0.0605 - val_acc: 0.9947 - val_mDice: 0.8893

Epoch 00002: val_mDice improved from 0.88779 to 0.88933, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 49s - loss: 0.0471 - acc: 0.9948 - mDice: 0.9127 - val_loss: 0.0597 - val_acc: 0.9949 - val_mDice: 0.8907

Epoch 00003: val_mDice improved from 0.88933 to 0.89073, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 48s - loss: 0.0444 - acc: 0.9950 - mDice: 0.9175 - val_loss: 0.0619 - val_acc: 0.9940 - val_mDice: 0.8870

Epoch 00004: val_mDice did not improve from 0.89073
Epoch 5/300
 - 48s - loss: 0.0425 - acc: 0.9952 - mDice: 0.9208 - val_loss: 0.0567 - val_acc: 0.9948 - val_mDice: 0.8960

Epoch 00005: val_mDice improved from 0.89073 to 0.89599, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 48s - loss: 0.0404 - acc: 0.9954 - mDice: 0.9245 - val_loss: 0.0589 - val_acc: 0.9946 - val_mDice: 0.8923

Epoch 00006: val_mDice did not improve from 0.89599
Epoch 7/300
 - 48s - loss: 0.0391 - acc: 0.9955 - mDice: 0.9270 - val_loss: 0.0641 - val_acc: 0.9943 - val_mDice: 0.8831

Epoch 00007: val_mDice did not improve from 0.89599
Epoch 8/300
 - 48s - loss: 0.0377 - acc: 0.9956 - mDice: 0.9295 - val_loss: 0.0610 - val_acc: 0.9945 - val_mDice: 0.8886

Epoch 00008: val_mDice did not improve from 0.89599
Epoch 9/300
 - 48s - loss: 0.0367 - acc: 0.9957 - mDice: 0.9312 - val_loss: 0.0612 - val_acc: 0.9941 - val_mDice: 0.8879

Epoch 00009: val_mDice did not improve from 0.89599
Epoch 10/300
 - 48s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9325 - val_loss: 0.0559 - val_acc: 0.9950 - val_mDice: 0.8974

Epoch 00010: val_mDice improved from 0.89599 to 0.89738, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 47s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9339 - val_loss: 0.0589 - val_acc: 0.9946 - val_mDice: 0.8923

Epoch 00011: val_mDice did not improve from 0.89738
Epoch 12/300
 - 48s - loss: 0.0346 - acc: 0.9959 - mDice: 0.9351 - val_loss: 0.0575 - val_acc: 0.9948 - val_mDice: 0.8946

Epoch 00012: val_mDice did not improve from 0.89738
Epoch 13/300
 - 47s - loss: 0.0340 - acc: 0.9960 - mDice: 0.9362 - val_loss: 0.0575 - val_acc: 0.9947 - val_mDice: 0.8946

Epoch 00013: val_mDice did not improve from 0.89738
Epoch 14/300
 - 48s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9370 - val_loss: 0.0574 - val_acc: 0.9947 - val_mDice: 0.8948

Epoch 00014: val_mDice did not improve from 0.89738
Epoch 15/300
 - 47s - loss: 0.0331 - acc: 0.9961 - mDice: 0.9378 - val_loss: 0.0594 - val_acc: 0.9944 - val_mDice: 0.8916

Epoch 00015: val_mDice did not improve from 0.89738
Epoch 16/300
 - 48s - loss: 0.0324 - acc: 0.9961 - mDice: 0.9390 - val_loss: 0.0575 - val_acc: 0.9947 - val_mDice: 0.8948

Epoch 00016: val_mDice did not improve from 0.89738
Epoch 17/300
 - 48s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9397 - val_loss: 0.0573 - val_acc: 0.9950 - val_mDice: 0.8952

Epoch 00017: val_mDice did not improve from 0.89738
Epoch 18/300
 - 49s - loss: 0.0318 - acc: 0.9962 - mDice: 0.9401 - val_loss: 0.0566 - val_acc: 0.9947 - val_mDice: 0.8965

Epoch 00018: val_mDice did not improve from 0.89738
Epoch 19/300
 - 49s - loss: 0.0314 - acc: 0.9962 - mDice: 0.9409 - val_loss: 0.0585 - val_acc: 0.9948 - val_mDice: 0.8931

Epoch 00019: val_mDice did not improve from 0.89738
Epoch 20/300
 - 49s - loss: 0.0312 - acc: 0.9962 - mDice: 0.9413 - val_loss: 0.0571 - val_acc: 0.9947 - val_mDice: 0.8954

Epoch 00020: val_mDice did not improve from 0.89738
Epoch 21/300
 - 49s - loss: 0.0309 - acc: 0.9963 - mDice: 0.9419 - val_loss: 0.0589 - val_acc: 0.9945 - val_mDice: 0.8924

Epoch 00021: val_mDice did not improve from 0.89738
Epoch 22/300
 - 49s - loss: 0.0304 - acc: 0.9963 - mDice: 0.9426 - val_loss: 0.0580 - val_acc: 0.9948 - val_mDice: 0.8937

Epoch 00022: val_mDice did not improve from 0.89738
Epoch 23/300
 - 49s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9428 - val_loss: 0.0570 - val_acc: 0.9948 - val_mDice: 0.8956

Epoch 00023: val_mDice did not improve from 0.89738
Epoch 24/300
 - 49s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9439 - val_loss: 0.0645 - val_acc: 0.9946 - val_mDice: 0.8824

Epoch 00024: val_mDice did not improve from 0.89738
Epoch 25/300
 - 48s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9440 - val_loss: 0.0569 - val_acc: 0.9950 - val_mDice: 0.8957

Epoch 00025: val_mDice did not improve from 0.89738
Epoch 26/300
 - 50s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9445 - val_loss: 0.0617 - val_acc: 0.9948 - val_mDice: 0.8870

Epoch 00026: val_mDice did not improve from 0.89738
Epoch 27/300
 - 49s - loss: 0.0293 - acc: 0.9964 - mDice: 0.9447 - val_loss: 0.0642 - val_acc: 0.9947 - val_mDice: 0.8829

Epoch 00027: val_mDice did not improve from 0.89738
Epoch 28/300
 - 49s - loss: 0.0291 - acc: 0.9964 - mDice: 0.9451 - val_loss: 0.0554 - val_acc: 0.9950 - val_mDice: 0.8982

Epoch 00028: val_mDice improved from 0.89738 to 0.89822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 49s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9455 - val_loss: 0.0598 - val_acc: 0.9946 - val_mDice: 0.8908

Epoch 00029: val_mDice did not improve from 0.89822
Epoch 30/300
 - 48s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9456 - val_loss: 0.0568 - val_acc: 0.9948 - val_mDice: 0.8961

Epoch 00030: val_mDice did not improve from 0.89822
Epoch 31/300
 - 49s - loss: 0.0287 - acc: 0.9965 - mDice: 0.9459 - val_loss: 0.0571 - val_acc: 0.9947 - val_mDice: 0.8952

Epoch 00031: val_mDice did not improve from 0.89822
Epoch 32/300
 - 49s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9464 - val_loss: 0.0583 - val_acc: 0.9948 - val_mDice: 0.8935

Epoch 00032: val_mDice did not improve from 0.89822
Epoch 33/300
 - 49s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9465 - val_loss: 0.0583 - val_acc: 0.9948 - val_mDice: 0.8932

Epoch 00033: val_mDice did not improve from 0.89822
Epoch 34/300
 - 49s - loss: 0.0282 - acc: 0.9965 - mDice: 0.9468 - val_loss: 0.0566 - val_acc: 0.9949 - val_mDice: 0.8964

Epoch 00034: val_mDice did not improve from 0.89822
Epoch 35/300
 - 49s - loss: 0.0281 - acc: 0.9965 - mDice: 0.9470 - val_loss: 0.0567 - val_acc: 0.9949 - val_mDice: 0.8961

Epoch 00035: val_mDice did not improve from 0.89822
Epoch 36/300
 - 49s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9473 - val_loss: 0.0547 - val_acc: 0.9949 - val_mDice: 0.8994

Epoch 00036: val_mDice improved from 0.89822 to 0.89941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 49s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9474 - val_loss: 0.0565 - val_acc: 0.9950 - val_mDice: 0.8964

Epoch 00037: val_mDice did not improve from 0.89941
Epoch 38/300
 - 49s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9476 - val_loss: 0.0591 - val_acc: 0.9950 - val_mDice: 0.8921

Epoch 00038: val_mDice did not improve from 0.89941
Epoch 39/300
 - 49s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9480 - val_loss: 0.0552 - val_acc: 0.9948 - val_mDice: 0.8987

Epoch 00039: val_mDice did not improve from 0.89941
Epoch 40/300
 - 49s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9483 - val_loss: 0.0567 - val_acc: 0.9947 - val_mDice: 0.8961

Epoch 00040: val_mDice did not improve from 0.89941
Epoch 41/300
 - 49s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9483 - val_loss: 0.0569 - val_acc: 0.9948 - val_mDice: 0.8958

Epoch 00041: val_mDice did not improve from 0.89941
Epoch 42/300
 - 49s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9485 - val_loss: 0.0586 - val_acc: 0.9948 - val_mDice: 0.8929

Epoch 00042: val_mDice did not improve from 0.89941
Epoch 43/300
 - 49s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9486 - val_loss: 0.0575 - val_acc: 0.9945 - val_mDice: 0.8947

Epoch 00043: val_mDice did not improve from 0.89941
Epoch 44/300
 - 49s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9487 - val_loss: 0.0574 - val_acc: 0.9949 - val_mDice: 0.8950

Epoch 00044: val_mDice did not improve from 0.89941
Epoch 45/300
 - 49s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9491 - val_loss: 0.0562 - val_acc: 0.9950 - val_mDice: 0.8970

Epoch 00045: val_mDice did not improve from 0.89941
Epoch 46/300
 - 49s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9491 - val_loss: 0.0578 - val_acc: 0.9949 - val_mDice: 0.8943

Epoch 00046: val_mDice did not improve from 0.89941
Epoch 47/300
 - 50s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9492 - val_loss: 0.0571 - val_acc: 0.9949 - val_mDice: 0.8954

Epoch 00047: val_mDice did not improve from 0.89941
Epoch 48/300
 - 51s - loss: 0.0268 - acc: 0.9966 - mDice: 0.9493 - val_loss: 0.0572 - val_acc: 0.9948 - val_mDice: 0.8953

Epoch 00048: val_mDice did not improve from 0.89941
Epoch 49/300
 - 50s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9495 - val_loss: 0.0591 - val_acc: 0.9950 - val_mDice: 0.8918

Epoch 00049: val_mDice did not improve from 0.89941
Epoch 50/300
 - 50s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9499 - val_loss: 0.0561 - val_acc: 0.9949 - val_mDice: 0.8971

Epoch 00050: val_mDice did not improve from 0.89941
Epoch 51/300
 - 50s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9500 - val_loss: 0.0574 - val_acc: 0.9949 - val_mDice: 0.8949

Epoch 00051: val_mDice did not improve from 0.89941
Epoch 52/300
 - 49s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9501 - val_loss: 0.0573 - val_acc: 0.9948 - val_mDice: 0.8950

Epoch 00052: val_mDice did not improve from 0.89941
Epoch 53/300
 - 49s - loss: 0.0263 - acc: 0.9966 - mDice: 0.9502 - val_loss: 0.0569 - val_acc: 0.9948 - val_mDice: 0.8957

Epoch 00053: val_mDice did not improve from 0.89941
Epoch 54/300
 - 50s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9505 - val_loss: 0.0580 - val_acc: 0.9947 - val_mDice: 0.8939

Epoch 00054: val_mDice did not improve from 0.89941
Epoch 55/300
 - 50s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9506 - val_loss: 0.0602 - val_acc: 0.9949 - val_mDice: 0.8900

Epoch 00055: val_mDice did not improve from 0.89941
Epoch 56/300
 - 50s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0597 - val_acc: 0.9947 - val_mDice: 0.8908

Epoch 00056: val_mDice did not improve from 0.89941
Epoch 57/300
 - 50s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9506 - val_loss: 0.0591 - val_acc: 0.9946 - val_mDice: 0.8922

Epoch 00057: val_mDice did not improve from 0.89941
Epoch 58/300
 - 50s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9509 - val_loss: 0.0605 - val_acc: 0.9944 - val_mDice: 0.8898

Epoch 00058: val_mDice did not improve from 0.89941
Epoch 59/300
 - 50s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9508 - val_loss: 0.0559 - val_acc: 0.9948 - val_mDice: 0.8975

Epoch 00059: val_mDice did not improve from 0.89941
Epoch 60/300
 - 50s - loss: 0.0259 - acc: 0.9967 - mDice: 0.9511 - val_loss: 0.0576 - val_acc: 0.9950 - val_mDice: 0.8945

Epoch 00060: val_mDice did not improve from 0.89941
Epoch 61/300
 - 50s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9513 - val_loss: 0.0592 - val_acc: 0.9949 - val_mDice: 0.8916

Epoch 00061: val_mDice did not improve from 0.89941
Epoch 62/300
 - 49s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9512 - val_loss: 0.0604 - val_acc: 0.9945 - val_mDice: 0.8899

Epoch 00062: val_mDice did not improve from 0.89941
Epoch 63/300
 - 49s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9513 - val_loss: 0.0573 - val_acc: 0.9948 - val_mDice: 0.8953

Epoch 00063: val_mDice did not improve from 0.89941
Epoch 64/300
 - 49s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9514 - val_loss: 0.0560 - val_acc: 0.9949 - val_mDice: 0.8973

Epoch 00064: val_mDice did not improve from 0.89941
Epoch 65/300
 - 48s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9514 - val_loss: 0.0580 - val_acc: 0.9949 - val_mDice: 0.8937

Epoch 00065: val_mDice did not improve from 0.89941
Epoch 66/300
 - 48s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9514 - val_loss: 0.0559 - val_acc: 0.9948 - val_mDice: 0.8975

Epoch 00066: val_mDice did not improve from 0.89941
Epoch 67/300
 - 49s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9519 - val_loss: 0.0570 - val_acc: 0.9948 - val_mDice: 0.8957

Epoch 00067: val_mDice did not improve from 0.89941
Epoch 68/300
 - 48s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9519 - val_loss: 0.0586 - val_acc: 0.9948 - val_mDice: 0.8928

Epoch 00068: val_mDice did not improve from 0.89941
Epoch 69/300
 - 48s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9518 - val_loss: 0.0581 - val_acc: 0.9948 - val_mDice: 0.8937

Epoch 00069: val_mDice did not improve from 0.89941
Epoch 70/300
 - 48s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9521 - val_loss: 0.0600 - val_acc: 0.9948 - val_mDice: 0.8903

Epoch 00070: val_mDice did not improve from 0.89941
Epoch 71/300
 - 48s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9522 - val_loss: 0.0583 - val_acc: 0.9947 - val_mDice: 0.8934

Epoch 00071: val_mDice did not improve from 0.89941
Epoch 72/300
 - 48s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9524 - val_loss: 0.0578 - val_acc: 0.9948 - val_mDice: 0.8942

Epoch 00072: val_mDice did not improve from 0.89941
Epoch 73/300
 - 48s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9522 - val_loss: 0.0566 - val_acc: 0.9948 - val_mDice: 0.8964

Epoch 00073: val_mDice did not improve from 0.89941
Epoch 74/300
 - 48s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9524 - val_loss: 0.0578 - val_acc: 0.9949 - val_mDice: 0.8944

Epoch 00074: val_mDice did not improve from 0.89941
Epoch 75/300
 - 49s - loss: 0.0251 - acc: 0.9967 - mDice: 0.9525 - val_loss: 0.0577 - val_acc: 0.9948 - val_mDice: 0.8943

Epoch 00075: val_mDice did not improve from 0.89941
Epoch 76/300
 - 49s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9526 - val_loss: 0.0573 - val_acc: 0.9949 - val_mDice: 0.8949

Epoch 00076: val_mDice did not improve from 0.89941
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [0.06126631982624531, 0.06048192419111729, 0.05971684344112873, 0.06191805079579353, 0.05673118978738785, 0.058858868479728696, 0.06405063644051552, 0.060965868458151815, 0.06123307272791863, 0.0558827131986618, 0.05889331474900246, 0.057470284029841424, 0.05754096768796444, 0.05741831511259079, 0.059438402950763705, 0.0574508037418127, 0.057253452762961385, 0.05655348002910614, 0.058524588122963905, 0.05711115449666977, 0.05893069393932819, 0.05799756050109863, 0.05702882651239634, 0.06447313837707043, 0.05692453309893608, 0.06170456223189831, 0.06418418437242508, 0.05544859915971756, 0.05981436036527157, 0.056772102043032645, 0.057145440578460695, 0.05827259123325348, 0.05829493589699268, 0.056553644686937334, 0.05666462145745754, 0.054738837853074075, 0.056512712687253955, 0.05906838774681091, 0.05522991344332695, 0.05668066553771496, 0.05685138963162899, 0.05855477750301361, 0.05753396935760975, 0.05735357962548733, 0.056201483309268954, 0.05775628089904785, 0.057128673419356346, 0.057217837870121004, 0.059060000255703925, 0.05607848204672337, 0.057392969354987146, 0.05728146806359291, 0.056873242184519765, 0.0580116406083107, 0.06015916615724563, 0.059738616645336154, 0.05905558057129383, 0.06048015095293522, 0.05587183237075806, 0.05755840949714184, 0.059234507754445075, 0.060355795174837114, 0.05729558654129505, 0.05603719726204872, 0.05799855701625347, 0.055853305757045744, 0.05703253634274006, 0.058637692034244536, 0.058087336644530294, 0.06002761721611023, 0.05832415297627449, 0.057796265557408334, 0.05656424760818481, 0.05777874179184437, 0.05774672068655491, 0.057336121797561646], 'val_acc': [0.9943148136138916, 0.9947029709815979, 0.9949176371097564, 0.9940043866634369, 0.9948057949542999, 0.994619631767273, 0.994332355260849, 0.9944914758205414, 0.9940709054470063, 0.9950107157230377, 0.9945684731006622, 0.9948009192943573, 0.9947234451770782, 0.9947499990463257, 0.9943866908550263, 0.9947356283664703, 0.9950197398662567, 0.9946788549423218, 0.9947619378566742, 0.9947351396083832, 0.9944924473762512, 0.9948133587837219, 0.9948318719863891, 0.9946157455444335, 0.9949561417102813, 0.9948062896728516, 0.9947136998176574, 0.9949529767036438, 0.9945791959762573, 0.994816517829895, 0.9947029650211334, 0.9947914242744446, 0.9948057949542999, 0.9948696434497833, 0.9949466288089752, 0.9949349403381348, 0.9949507772922516, 0.9949685752391815, 0.9948177337646484, 0.9946917712688446, 0.9947534084320069, 0.9947841107845307, 0.9945092618465423, 0.9948842644691467, 0.9949663758277894, 0.9949205636978149, 0.994928365945816, 0.9948053002357483, 0.9949646770954133, 0.994926905632019, 0.9949008285999298, 0.9947768032550812, 0.9948026418685914, 0.9946837246417999, 0.9948745131492615, 0.994674950838089, 0.9946062386035919, 0.9943986415863038, 0.9947909355163574, 0.995031189918518, 0.9949442028999329, 0.9945221722126008, 0.9947962939739228, 0.9948988735675812, 0.9949478566646576, 0.9948228478431702, 0.9948301613330841, 0.9947870433330536, 0.9947724163532257, 0.9948084771633148, 0.9947083353996277, 0.9948426008224487, 0.9947602272033691, 0.9948789000511169, 0.9948004305362701, 0.9948550164699554], 'val_mDice': [0.887787115573883, 0.8893312573432922, 0.8907343924045563, 0.8869962513446807, 0.8959862589836121, 0.8922974228858948, 0.8831447243690491, 0.8885952949523925, 0.8879465997219086, 0.8973841369152069, 0.8923302471637726, 0.8945774853229522, 0.8946088492870331, 0.8947954535484314, 0.8916006207466125, 0.8947667479515076, 0.8952496290206909, 0.8964908957481384, 0.8931089758872985, 0.8953897058963776, 0.8924209713935852, 0.8937381982803345, 0.895551997423172, 0.8823923587799072, 0.8957033932209015, 0.8870035171508789, 0.8829288601875305, 0.8982242941856384, 0.8908194482326508, 0.8960925102233886, 0.8952155411243439, 0.8934579491615295, 0.8931731343269348, 0.8963742196559906, 0.8960576057434082, 0.8994148910045624, 0.8964406788349152, 0.8920669555664062, 0.8987185895442963, 0.8960666835308075, 0.8958195269107818, 0.8928995013237, 0.8946756660938263, 0.8949851512908935, 0.8969639241695404, 0.8942729592323303, 0.8954192936420441, 0.8952746868133545, 0.8918032944202423, 0.8971079170703888, 0.8949331223964692, 0.8950205028057099, 0.8957026243209839, 0.8938716948032379, 0.8900127112865448, 0.8907919347286224, 0.8921876013278961, 0.889786547422409, 0.8975266277790069, 0.8945132970809937, 0.8915730834007263, 0.8899317145347595, 0.8953227579593659, 0.8972503483295441, 0.893673038482666, 0.8974913775920867, 0.8956535816192627, 0.8927647411823273, 0.8937084376811981, 0.890337598323822, 0.8933685898780823, 0.894170755147934, 0.8964180111885071, 0.8943991243839264, 0.8943247079849244, 0.8949179291725159], 'loss': [0.1080846442246101, 0.0528013313200929, 0.04708024009028768, 0.04437261416123271, 0.04253698121082124, 0.040425581330388295, 0.039053018198844706, 0.03767478529047207, 0.036707647581521424, 0.0359792195237364, 0.03526033702564912, 0.034560192163668804, 0.033981267978590086, 0.03350725308511616, 0.033077841181701095, 0.03244196382784918, 0.032052854654315066, 0.031806499446126714, 0.03137181693312737, 0.03119609665339779, 0.030855320799885087, 0.03044389372910275, 0.030330300570377142, 0.02977431539201064, 0.02968667692964678, 0.029423179394101075, 0.029313047418205323, 0.02911314828548353, 0.028886653467673117, 0.028851397067849376, 0.028685360446380096, 0.02840186449343939, 0.028342263699741244, 0.028193846213037905, 0.028059099233612207, 0.027924785647394465, 0.02784327103291123, 0.027759692345845993, 0.027532537242193147, 0.02738408869190368, 0.02737938317160078, 0.027245069591905324, 0.027229483354324638, 0.0271390045819291, 0.02696808034584539, 0.02693585062752043, 0.026903158659063856, 0.026828575395088927, 0.02673014620256515, 0.026522778673688158, 0.026450616373345198, 0.026389325694286345, 0.026347336572394513, 0.02620275297059112, 0.026117535339949316, 0.026106247582494857, 0.02612849140154618, 0.02599915150202515, 0.02603226482441451, 0.025891285556911843, 0.025763421802440335, 0.025791377221016945, 0.025778271796698057, 0.02569878076677331, 0.025702745977573663, 0.02569918015544304, 0.025450196060325638, 0.025454863922412054, 0.025491152740979017, 0.02535117885687729, 0.025286340282324613, 0.025180999489640418, 0.02527920725287619, 0.02519146627341708, 0.025145822936110538, 0.025048047341157433], 'acc': [0.9883329501684299, 0.9942348568680653, 0.9947609479231317, 0.9950144328641521, 0.9951954124679808, 0.995381915401483, 0.9955022081955839, 0.9956288771596621, 0.9957076587656386, 0.9957864767835425, 0.9958451595124773, 0.995918919147605, 0.9959553677723008, 0.9959992615553107, 0.9960524912440526, 0.9961057744528118, 0.9961385678307064, 0.9961740540044843, 0.9962114820135501, 0.9962174897323908, 0.9962524548537667, 0.99629608197164, 0.9963073437098978, 0.996354823089146, 0.9963499702568857, 0.9963832722069873, 0.9963869638039538, 0.9964150272603416, 0.9964234294920151, 0.9964335473032632, 0.9964522791751333, 0.9964710839539175, 0.9964793644376679, 0.9964939812506093, 0.9964951527873884, 0.9965170537683875, 0.9965106417167846, 0.9965221039069939, 0.9965325333887508, 0.9965630586850033, 0.9965386274828935, 0.9965662658097434, 0.996561203587071, 0.9965758729935987, 0.9965773105544667, 0.9965907759331138, 0.9965967772244411, 0.996592406679308, 0.996592973199233, 0.9966250475176994, 0.996627533285037, 0.9966302234443194, 0.9966266143635912, 0.996635981989464, 0.9966502565426404, 0.9966458373460441, 0.996651849820563, 0.996658823523537, 0.9966482466668627, 0.9966615839680406, 0.9966724409135153, 0.9966811805065837, 0.9966689888873097, 0.9966742729720705, 0.9966726231328816, 0.9966947325352675, 0.9967111638769884, 0.9967061218845843, 0.9966909800941557, 0.9967105257663201, 0.9967173909533593, 0.9967175005128599, 0.9967205650737339, 0.9967265863504109, 0.9967314877489455, 0.9967330459162035], 'mDice': [0.8416219926799782, 0.9027353298111642, 0.9127164061725359, 0.9174987070471944, 0.9207525438198719, 0.9245312647169186, 0.9269986144193914, 0.9294850792209107, 0.9312303170908404, 0.9325456201197458, 0.9338511154851581, 0.9351197823466274, 0.9361771025892606, 0.9370424992215166, 0.9378183839124095, 0.9389861367602148, 0.9396930584447681, 0.9401438043773224, 0.9409400321396532, 0.9412643195761827, 0.9418905263383761, 0.942641867628928, 0.942849104860296, 0.9438754375389748, 0.9440341674681367, 0.9445224804893909, 0.9447263033012573, 0.945089109092083, 0.9455138628440309, 0.9455724163347959, 0.9458790706890498, 0.9464044471613723, 0.9465177106155342, 0.9467825433378771, 0.9470411935717951, 0.947283830096894, 0.9474389271073034, 0.9475899591712394, 0.9480137779372176, 0.9482814727324648, 0.9483021085816112, 0.9485454922550961, 0.9485797189109795, 0.9487416204516985, 0.949061834099132, 0.949122211857914, 0.9491808775831155, 0.94932056691318, 0.9495051938263206, 0.949889939216469, 0.9500208819211093, 0.9501361546163907, 0.9502183317959225, 0.9504894711122204, 0.9506427522563822, 0.9506633783045291, 0.950628579855519, 0.9508649212232922, 0.9508034948107982, 0.9510664393222272, 0.9513019996427641, 0.9512499821792185, 0.951276647493839, 0.9514240394235105, 0.9514161118545448, 0.9514177431353003, 0.9518832789189129, 0.9518784227131665, 0.9518134273588924, 0.9520692174324001, 0.9521917350299788, 0.9523917813923307, 0.952203812666311, 0.9523715404859842, 0.9524529256565794, 0.9526386311631215]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.00it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.25it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.54it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  1.81it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<02:01,  2.18it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:55,  2.29it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:43,  2.54it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:37,  2.69it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:38,  2.65it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:36,  2.69it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:34,  2.74it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:33,  2.76it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:32,  2.77it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:34,  2.72it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:34,  2.70it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:32,  2.73it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:31,  2.75it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:34,  2.67it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:35,  2.63it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:36,  2.58it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:36,  2.57it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:34,  2.62it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:34,  2.61it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:31,  2.68it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:31,  2.68it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:30,  2.68it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:29,  2.72it/s]predicting train subjects:   9%|▉         | 24/266 [00:08<01:27,  2.75it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:29,  2.70it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:30,  2.66it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:28,  2.69it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:26,  2.76it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:24,  2.81it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:23,  2.84it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:20,  2.91it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:20,  2.89it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:20,  2.88it/s]predicting train subjects:  13%|█▎        | 34/266 [00:12<01:21,  2.85it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:21,  2.83it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:21,  2.83it/s]predicting train subjects:  14%|█▍        | 37/266 [00:13<01:19,  2.86it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:18,  2.89it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:17,  2.92it/s]predicting train subjects:  15%|█▌        | 40/266 [00:14<01:18,  2.88it/s]predicting train subjects:  15%|█▌        | 41/266 [00:14<01:19,  2.85it/s]predicting train subjects:  16%|█▌        | 42/266 [00:15<01:18,  2.86it/s]predicting train subjects:  16%|█▌        | 43/266 [00:15<01:16,  2.93it/s]predicting train subjects:  17%|█▋        | 44/266 [00:15<01:13,  3.01it/s]predicting train subjects:  17%|█▋        | 45/266 [00:16<01:09,  3.17it/s]predicting train subjects:  17%|█▋        | 46/266 [00:16<01:12,  3.04it/s]predicting train subjects:  18%|█▊        | 47/266 [00:16<01:08,  3.18it/s]predicting train subjects:  18%|█▊        | 48/266 [00:17<01:06,  3.28it/s]predicting train subjects:  18%|█▊        | 49/266 [00:17<01:05,  3.31it/s]predicting train subjects:  19%|█▉        | 50/266 [00:17<01:04,  3.32it/s]predicting train subjects:  19%|█▉        | 51/266 [00:17<01:06,  3.23it/s]predicting train subjects:  20%|█▉        | 52/266 [00:18<01:03,  3.35it/s]predicting train subjects:  20%|█▉        | 53/266 [00:18<01:04,  3.32it/s]predicting train subjects:  20%|██        | 54/266 [00:18<01:06,  3.17it/s]predicting train subjects:  21%|██        | 55/266 [00:19<01:05,  3.20it/s]predicting train subjects:  21%|██        | 56/266 [00:19<01:03,  3.32it/s]predicting train subjects:  21%|██▏       | 57/266 [00:19<01:02,  3.34it/s]predicting train subjects:  22%|██▏       | 58/266 [00:20<01:02,  3.30it/s]predicting train subjects:  22%|██▏       | 59/266 [00:20<01:01,  3.34it/s]predicting train subjects:  23%|██▎       | 60/266 [00:20<01:03,  3.25it/s]predicting train subjects:  23%|██▎       | 61/266 [00:21<01:03,  3.24it/s]predicting train subjects:  23%|██▎       | 62/266 [00:21<01:03,  3.21it/s]predicting train subjects:  24%|██▎       | 63/266 [00:21<01:03,  3.21it/s]predicting train subjects:  24%|██▍       | 64/266 [00:21<01:03,  3.20it/s]predicting train subjects:  24%|██▍       | 65/266 [00:22<00:59,  3.36it/s]predicting train subjects:  25%|██▍       | 66/266 [00:22<01:02,  3.23it/s]predicting train subjects:  25%|██▌       | 67/266 [00:22<01:02,  3.19it/s]predicting train subjects:  26%|██▌       | 68/266 [00:23<01:01,  3.23it/s]predicting train subjects:  26%|██▌       | 69/266 [00:23<01:01,  3.21it/s]predicting train subjects:  26%|██▋       | 70/266 [00:23<00:58,  3.34it/s]predicting train subjects:  27%|██▋       | 71/266 [00:24<00:57,  3.41it/s]predicting train subjects:  27%|██▋       | 72/266 [00:24<00:55,  3.47it/s]predicting train subjects:  27%|██▋       | 73/266 [00:24<00:54,  3.53it/s]predicting train subjects:  28%|██▊       | 74/266 [00:24<00:54,  3.51it/s]predicting train subjects:  28%|██▊       | 75/266 [00:25<00:57,  3.32it/s]predicting train subjects:  29%|██▊       | 76/266 [00:25<00:56,  3.39it/s]predicting train subjects:  29%|██▉       | 77/266 [00:25<00:55,  3.38it/s]predicting train subjects:  29%|██▉       | 78/266 [00:26<00:58,  3.22it/s]predicting train subjects:  30%|██▉       | 79/266 [00:26<01:00,  3.07it/s]predicting train subjects:  30%|███       | 80/266 [00:26<01:02,  2.98it/s]predicting train subjects:  30%|███       | 81/266 [00:27<01:04,  2.86it/s]predicting train subjects:  31%|███       | 82/266 [00:27<01:04,  2.84it/s]predicting train subjects:  31%|███       | 83/266 [00:27<01:03,  2.87it/s]predicting train subjects:  32%|███▏      | 84/266 [00:28<01:02,  2.89it/s]predicting train subjects:  32%|███▏      | 85/266 [00:28<01:03,  2.85it/s]predicting train subjects:  32%|███▏      | 86/266 [00:29<01:04,  2.79it/s]predicting train subjects:  33%|███▎      | 87/266 [00:29<01:04,  2.78it/s]predicting train subjects:  33%|███▎      | 88/266 [00:29<01:03,  2.82it/s]predicting train subjects:  33%|███▎      | 89/266 [00:30<01:03,  2.79it/s]predicting train subjects:  34%|███▍      | 90/266 [00:30<01:03,  2.76it/s]predicting train subjects:  34%|███▍      | 91/266 [00:30<01:06,  2.65it/s]predicting train subjects:  35%|███▍      | 92/266 [00:31<01:06,  2.64it/s]predicting train subjects:  35%|███▍      | 93/266 [00:31<01:03,  2.72it/s]predicting train subjects:  35%|███▌      | 94/266 [00:31<01:02,  2.74it/s]predicting train subjects:  36%|███▌      | 95/266 [00:32<01:01,  2.77it/s]predicting train subjects:  36%|███▌      | 96/266 [00:32<01:01,  2.75it/s]predicting train subjects:  36%|███▋      | 97/266 [00:33<01:04,  2.62it/s]predicting train subjects:  37%|███▋      | 98/266 [00:33<01:03,  2.63it/s]predicting train subjects:  37%|███▋      | 99/266 [00:33<01:00,  2.74it/s]predicting train subjects:  38%|███▊      | 100/266 [00:34<00:59,  2.79it/s]predicting train subjects:  38%|███▊      | 101/266 [00:34<00:58,  2.81it/s]predicting train subjects:  38%|███▊      | 102/266 [00:34<00:56,  2.88it/s]predicting train subjects:  39%|███▊      | 103/266 [00:35<00:54,  2.97it/s]predicting train subjects:  39%|███▉      | 104/266 [00:35<00:52,  3.08it/s]predicting train subjects:  39%|███▉      | 105/266 [00:35<00:51,  3.15it/s]predicting train subjects:  40%|███▉      | 106/266 [00:36<00:51,  3.13it/s]predicting train subjects:  40%|████      | 107/266 [00:36<00:52,  3.03it/s]predicting train subjects:  41%|████      | 108/266 [00:36<00:52,  3.00it/s]predicting train subjects:  41%|████      | 109/266 [00:37<00:52,  2.97it/s]predicting train subjects:  41%|████▏     | 110/266 [00:37<00:53,  2.94it/s]predicting train subjects:  42%|████▏     | 111/266 [00:37<00:51,  2.98it/s]predicting train subjects:  42%|████▏     | 112/266 [00:38<00:52,  2.93it/s]predicting train subjects:  42%|████▏     | 113/266 [00:38<00:50,  3.05it/s]predicting train subjects:  43%|████▎     | 114/266 [00:38<00:48,  3.14it/s]predicting train subjects:  43%|████▎     | 115/266 [00:39<00:47,  3.20it/s]predicting train subjects:  44%|████▎     | 116/266 [00:39<00:47,  3.17it/s]predicting train subjects:  44%|████▍     | 117/266 [00:39<00:46,  3.21it/s]predicting train subjects:  44%|████▍     | 118/266 [00:40<00:48,  3.07it/s]predicting train subjects:  45%|████▍     | 119/266 [00:40<00:49,  2.96it/s]predicting train subjects:  45%|████▌     | 120/266 [00:40<00:51,  2.83it/s]predicting train subjects:  45%|████▌     | 121/266 [00:41<00:53,  2.72it/s]predicting train subjects:  46%|████▌     | 122/266 [00:41<00:54,  2.66it/s]predicting train subjects:  46%|████▌     | 123/266 [00:41<00:52,  2.75it/s]predicting train subjects:  47%|████▋     | 124/266 [00:42<00:52,  2.73it/s]predicting train subjects:  47%|████▋     | 125/266 [00:42<00:53,  2.65it/s]predicting train subjects:  47%|████▋     | 126/266 [00:43<00:52,  2.65it/s]predicting train subjects:  48%|████▊     | 127/266 [00:43<00:51,  2.69it/s]predicting train subjects:  48%|████▊     | 128/266 [00:43<00:51,  2.70it/s]predicting train subjects:  48%|████▊     | 129/266 [00:44<00:49,  2.75it/s]predicting train subjects:  49%|████▉     | 130/266 [00:44<00:48,  2.79it/s]predicting train subjects:  49%|████▉     | 131/266 [00:44<00:50,  2.70it/s]predicting train subjects:  50%|████▉     | 132/266 [00:45<00:49,  2.71it/s]predicting train subjects:  50%|█████     | 133/266 [00:45<00:48,  2.75it/s]predicting train subjects:  50%|█████     | 134/266 [00:45<00:48,  2.70it/s]predicting train subjects:  51%|█████     | 135/266 [00:46<00:47,  2.75it/s]predicting train subjects:  51%|█████     | 136/266 [00:46<00:48,  2.68it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:47<00:48,  2.64it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:47<00:48,  2.66it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:47<00:46,  2.72it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:48<00:45,  2.77it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:48<00:44,  2.78it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:48<00:46,  2.69it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:49<00:44,  2.75it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:49<00:45,  2.70it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:50<00:45,  2.68it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:50<00:42,  2.81it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:50<00:41,  2.86it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:51<00:40,  2.91it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:51<00:39,  2.93it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:51<00:40,  2.86it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:52<00:39,  2.90it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:52<00:40,  2.80it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:52<00:39,  2.85it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:53<00:39,  2.86it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:53<00:37,  2.96it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:53<00:36,  3.00it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:54<00:33,  3.24it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:54<00:32,  3.36it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:54<00:30,  3.47it/s]predicting train subjects:  60%|██████    | 160/266 [00:54<00:31,  3.40it/s]predicting train subjects:  61%|██████    | 161/266 [00:55<00:30,  3.46it/s]predicting train subjects:  61%|██████    | 162/266 [00:55<00:30,  3.40it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:55<00:29,  3.54it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:56<00:29,  3.45it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:56<00:28,  3.52it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:56<00:28,  3.57it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:56<00:28,  3.52it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:57<00:28,  3.39it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:57<00:27,  3.54it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:57<00:27,  3.50it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:58<00:27,  3.51it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:58<00:27,  3.40it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:58<00:28,  3.31it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:58<00:27,  3.38it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:59<00:27,  3.32it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:59<00:27,  3.31it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:59<00:26,  3.34it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:00<00:26,  3.28it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:00<00:26,  3.26it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:00<00:26,  3.25it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:01<00:26,  3.22it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:01<00:25,  3.32it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:01<00:24,  3.35it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:01<00:24,  3.38it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:02<00:24,  3.36it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:02<00:24,  3.28it/s]predicting train subjects:  70%|███████   | 187/266 [01:02<00:24,  3.17it/s]predicting train subjects:  71%|███████   | 188/266 [01:03<00:24,  3.19it/s]predicting train subjects:  71%|███████   | 189/266 [01:03<00:24,  3.13it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:03<00:23,  3.25it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:04<00:24,  3.11it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:04<00:24,  3.05it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:04<00:23,  3.07it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:05<00:25,  2.81it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:05<00:24,  2.89it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:05<00:22,  3.08it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:06<00:21,  3.16it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:06<00:21,  3.22it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:06<00:20,  3.29it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:07<00:20,  3.30it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:07<00:20,  3.24it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:07<00:19,  3.21it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:08<00:20,  3.14it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:08<00:19,  3.11it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:08<00:19,  3.11it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:08<00:18,  3.20it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:09<00:18,  3.14it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:09<00:18,  3.14it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:09<00:18,  3.11it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:10<00:18,  3.08it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:10<00:17,  3.14it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:10<00:17,  3.16it/s]predicting train subjects:  80%|████████  | 213/266 [01:11<00:16,  3.23it/s]predicting train subjects:  80%|████████  | 214/266 [01:11<00:15,  3.26it/s]predicting train subjects:  81%|████████  | 215/266 [01:11<00:15,  3.34it/s]predicting train subjects:  81%|████████  | 216/266 [01:12<00:14,  3.36it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:12<00:13,  3.52it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:12<00:13,  3.52it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:12<00:13,  3.50it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:13<00:12,  3.62it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:13<00:12,  3.56it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:13<00:11,  3.69it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:14<00:12,  3.53it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:14<00:12,  3.41it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:14<00:12,  3.41it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:14<00:11,  3.48it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:15<00:11,  3.54it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:15<00:10,  3.51it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:15<00:10,  3.42it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:16<00:10,  3.41it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:16<00:10,  3.42it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:16<00:10,  3.34it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:16<00:09,  3.32it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:17<00:09,  3.31it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:17<00:09,  3.29it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:17<00:09,  3.23it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:18<00:08,  3.27it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:18<00:08,  3.23it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:18<00:08,  3.13it/s]predicting train subjects:  90%|█████████ | 240/266 [01:19<00:08,  3.14it/s]predicting train subjects:  91%|█████████ | 241/266 [01:19<00:07,  3.18it/s]predicting train subjects:  91%|█████████ | 242/266 [01:19<00:07,  3.19it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:20<00:07,  3.27it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:20<00:06,  3.28it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:20<00:06,  3.29it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:20<00:05,  3.39it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:21<00:05,  3.28it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:21<00:05,  3.30it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:21<00:05,  3.04it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:22<00:05,  2.87it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:22<00:05,  2.80it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:23<00:04,  2.80it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:23<00:04,  2.78it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:23<00:04,  2.78it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:24<00:03,  2.81it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:24<00:03,  2.80it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:24<00:03,  2.82it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:25<00:02,  2.84it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:25<00:02,  2.90it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:25<00:02,  2.92it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:26<00:01,  2.94it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:26<00:01,  2.87it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:26<00:01,  2.90it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:27<00:00,  2.91it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:27<00:00,  2.92it/s]predicting train subjects: 100%|██████████| 266/266 [01:27<00:00,  2.93it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 64.88it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 63.02it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 63.25it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 63.18it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 64.15it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 66.72it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 66.47it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 68.97it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 70.88it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 72.76it/s]saving BB  train1-THALAMUS:  29%|██▊       | 76/266 [00:01<00:02, 74.42it/s]saving BB  train1-THALAMUS:  32%|███▏      | 84/266 [00:01<00:02, 74.30it/s]saving BB  train1-THALAMUS:  35%|███▍      | 92/266 [00:01<00:02, 72.78it/s]saving BB  train1-THALAMUS:  38%|███▊      | 100/266 [00:01<00:02, 69.94it/s]saving BB  train1-THALAMUS:  41%|████      | 108/266 [00:01<00:02, 70.73it/s]saving BB  train1-THALAMUS:  44%|████▎     | 116/266 [00:01<00:02, 70.95it/s]saving BB  train1-THALAMUS:  47%|████▋     | 124/266 [00:01<00:02, 70.38it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:01<00:01, 69.85it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 139/266 [00:01<00:01, 69.48it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 147/266 [00:02<00:01, 69.95it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 155/266 [00:02<00:01, 70.50it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 164/266 [00:02<00:01, 73.21it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 173/266 [00:02<00:01, 75.54it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 181/266 [00:02<00:01, 76.67it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 190/266 [00:02<00:00, 77.85it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 198/266 [00:02<00:00, 74.84it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 206/266 [00:02<00:00, 74.39it/s]saving BB  train1-THALAMUS:  80%|████████  | 214/266 [00:02<00:00, 74.30it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 222/266 [00:03<00:00, 74.85it/s]saving BB  train1-THALAMUS:  86%|████████▋ | 230/266 [00:03<00:00, 75.84it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 76.79it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 78.23it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 255/266 [00:03<00:00, 76.98it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 263/266 [00:03<00:00, 71.66it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 72.35it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:01,  1.82s/it]Loading train:   1%|          | 2/266 [00:03<07:41,  1.75s/it]Loading train:   1%|          | 3/266 [00:04<07:09,  1.63s/it]Loading train:   2%|▏         | 4/266 [00:06<06:50,  1.57s/it]Loading train:   2%|▏         | 5/266 [00:07<06:52,  1.58s/it]Loading train:   2%|▏         | 6/266 [00:09<06:45,  1.56s/it]Loading train:   3%|▎         | 7/266 [00:10<06:11,  1.44s/it]Loading train:   3%|▎         | 8/266 [00:11<05:37,  1.31s/it]Loading train:   3%|▎         | 9/266 [00:12<05:19,  1.24s/it]Loading train:   4%|▍         | 10/266 [00:13<05:02,  1.18s/it]Loading train:   4%|▍         | 11/266 [00:14<04:56,  1.16s/it]Loading train:   5%|▍         | 12/266 [00:15<04:59,  1.18s/it]Loading train:   5%|▍         | 13/266 [00:17<05:02,  1.19s/it]Loading train:   5%|▌         | 14/266 [00:18<05:01,  1.20s/it]Loading train:   6%|▌         | 15/266 [00:19<05:03,  1.21s/it]Loading train:   6%|▌         | 16/266 [00:20<04:58,  1.20s/it]Loading train:   6%|▋         | 17/266 [00:22<05:01,  1.21s/it]Loading train:   7%|▋         | 18/266 [00:23<04:54,  1.19s/it]Loading train:   7%|▋         | 19/266 [00:24<04:49,  1.17s/it]Loading train:   8%|▊         | 20/266 [00:25<04:52,  1.19s/it]Loading train:   8%|▊         | 21/266 [00:26<04:55,  1.21s/it]Loading train:   8%|▊         | 22/266 [00:27<04:43,  1.16s/it]Loading train:   9%|▊         | 23/266 [00:28<04:41,  1.16s/it]Loading train:   9%|▉         | 24/266 [00:30<04:41,  1.16s/it]Loading train:   9%|▉         | 25/266 [00:31<04:29,  1.12s/it]Loading train:  10%|▉         | 26/266 [00:32<04:22,  1.10s/it]Loading train:  10%|█         | 27/266 [00:33<04:10,  1.05s/it]Loading train:  11%|█         | 28/266 [00:34<04:04,  1.03s/it]Loading train:  11%|█         | 29/266 [00:35<04:05,  1.03s/it]Loading train:  11%|█▏        | 30/266 [00:36<04:07,  1.05s/it]Loading train:  12%|█▏        | 31/266 [00:37<04:07,  1.05s/it]Loading train:  12%|█▏        | 32/266 [00:38<04:08,  1.06s/it]Loading train:  12%|█▏        | 33/266 [00:39<04:07,  1.06s/it]Loading train:  13%|█▎        | 34/266 [00:40<04:08,  1.07s/it]Loading train:  13%|█▎        | 35/266 [00:41<04:10,  1.08s/it]Loading train:  14%|█▎        | 36/266 [00:42<04:10,  1.09s/it]Loading train:  14%|█▍        | 37/266 [00:43<04:01,  1.05s/it]Loading train:  14%|█▍        | 38/266 [00:44<03:54,  1.03s/it]Loading train:  15%|█▍        | 39/266 [00:45<03:46,  1.00it/s]Loading train:  15%|█▌        | 40/266 [00:46<03:46,  1.00s/it]Loading train:  15%|█▌        | 41/266 [00:47<03:52,  1.03s/it]Loading train:  16%|█▌        | 42/266 [00:48<03:48,  1.02s/it]Loading train:  16%|█▌        | 43/266 [00:49<03:41,  1.01it/s]Loading train:  17%|█▋        | 44/266 [00:50<03:38,  1.02it/s]Loading train:  17%|█▋        | 45/266 [00:51<03:36,  1.02it/s]Loading train:  17%|█▋        | 46/266 [00:52<03:34,  1.03it/s]Loading train:  18%|█▊        | 47/266 [00:53<03:25,  1.06it/s]Loading train:  18%|█▊        | 48/266 [00:54<03:22,  1.07it/s]Loading train:  18%|█▊        | 49/266 [00:55<03:22,  1.07it/s]Loading train:  19%|█▉        | 50/266 [00:56<03:22,  1.07it/s]Loading train:  19%|█▉        | 51/266 [00:57<03:23,  1.06it/s]Loading train:  20%|█▉        | 52/266 [00:58<03:27,  1.03it/s]Loading train:  20%|█▉        | 53/266 [00:59<03:24,  1.04it/s]Loading train:  20%|██        | 54/266 [01:00<03:17,  1.08it/s]Loading train:  21%|██        | 55/266 [01:00<03:15,  1.08it/s]Loading train:  21%|██        | 56/266 [01:01<03:12,  1.09it/s]Loading train:  21%|██▏       | 57/266 [01:02<03:10,  1.10it/s]Loading train:  22%|██▏       | 58/266 [01:03<03:14,  1.07it/s]Loading train:  22%|██▏       | 59/266 [01:04<03:12,  1.07it/s]Loading train:  23%|██▎       | 60/266 [01:05<03:17,  1.04it/s]Loading train:  23%|██▎       | 61/266 [01:06<03:08,  1.09it/s]Loading train:  23%|██▎       | 62/266 [01:07<03:06,  1.09it/s]Loading train:  24%|██▎       | 63/266 [01:08<03:02,  1.11it/s]Loading train:  24%|██▍       | 64/266 [01:09<02:55,  1.15it/s]Loading train:  24%|██▍       | 65/266 [01:09<02:53,  1.16it/s]Loading train:  25%|██▍       | 66/266 [01:10<02:50,  1.17it/s]Loading train:  25%|██▌       | 67/266 [01:11<02:47,  1.19it/s]Loading train:  26%|██▌       | 68/266 [01:12<02:43,  1.21it/s]Loading train:  26%|██▌       | 69/266 [01:13<02:44,  1.20it/s]Loading train:  26%|██▋       | 70/266 [01:14<02:48,  1.16it/s]Loading train:  27%|██▋       | 71/266 [01:14<02:46,  1.17it/s]Loading train:  27%|██▋       | 72/266 [01:15<02:46,  1.16it/s]Loading train:  27%|██▋       | 73/266 [01:16<02:48,  1.15it/s]Loading train:  28%|██▊       | 74/266 [01:17<02:48,  1.14it/s]Loading train:  28%|██▊       | 75/266 [01:18<02:43,  1.17it/s]Loading train:  29%|██▊       | 76/266 [01:19<02:42,  1.17it/s]Loading train:  29%|██▉       | 77/266 [01:19<02:34,  1.23it/s]Loading train:  29%|██▉       | 78/266 [01:21<02:50,  1.10it/s]Loading train:  30%|██▉       | 79/266 [01:22<02:49,  1.10it/s]Loading train:  30%|███       | 80/266 [01:22<02:48,  1.11it/s]Loading train:  30%|███       | 81/266 [01:23<02:50,  1.09it/s]Loading train:  31%|███       | 82/266 [01:24<02:50,  1.08it/s]Loading train:  31%|███       | 83/266 [01:25<02:51,  1.07it/s]Loading train:  32%|███▏      | 84/266 [01:26<02:51,  1.06it/s]Loading train:  32%|███▏      | 85/266 [01:27<02:51,  1.06it/s]Loading train:  32%|███▏      | 86/266 [01:28<02:52,  1.04it/s]Loading train:  33%|███▎      | 87/266 [01:29<02:50,  1.05it/s]Loading train:  33%|███▎      | 88/266 [01:30<02:52,  1.03it/s]Loading train:  33%|███▎      | 89/266 [01:31<02:51,  1.03it/s]Loading train:  34%|███▍      | 90/266 [01:32<02:48,  1.04it/s]Loading train:  34%|███▍      | 91/266 [01:33<02:45,  1.06it/s]Loading train:  35%|███▍      | 92/266 [01:34<02:50,  1.02it/s]Loading train:  35%|███▍      | 93/266 [01:35<02:52,  1.01it/s]Loading train:  35%|███▌      | 94/266 [01:36<02:54,  1.02s/it]Loading train:  36%|███▌      | 95/266 [01:37<02:51,  1.00s/it]Loading train:  36%|███▌      | 96/266 [01:39<03:15,  1.15s/it]Loading train:  36%|███▋      | 97/266 [01:40<03:31,  1.25s/it]Loading train:  37%|███▋      | 98/266 [01:41<03:34,  1.28s/it]Loading train:  37%|███▋      | 99/266 [01:42<03:21,  1.21s/it]Loading train:  38%|███▊      | 100/266 [01:44<03:22,  1.22s/it]Loading train:  38%|███▊      | 101/266 [01:45<03:14,  1.18s/it]Loading train:  38%|███▊      | 102/266 [01:46<03:00,  1.10s/it]Loading train:  39%|███▊      | 103/266 [01:47<02:53,  1.07s/it]Loading train:  39%|███▉      | 104/266 [01:48<02:42,  1.00s/it]Loading train:  39%|███▉      | 105/266 [01:48<02:34,  1.04it/s]Loading train:  40%|███▉      | 106/266 [01:49<02:33,  1.04it/s]Loading train:  40%|████      | 107/266 [01:50<02:29,  1.06it/s]Loading train:  41%|████      | 108/266 [01:51<02:27,  1.07it/s]Loading train:  41%|████      | 109/266 [01:52<02:24,  1.08it/s]Loading train:  41%|████▏     | 110/266 [01:53<02:21,  1.10it/s]Loading train:  42%|████▏     | 111/266 [01:54<02:23,  1.08it/s]Loading train:  42%|████▏     | 112/266 [01:55<02:23,  1.07it/s]Loading train:  42%|████▏     | 113/266 [01:56<02:26,  1.04it/s]Loading train:  43%|████▎     | 114/266 [01:57<02:22,  1.07it/s]Loading train:  43%|████▎     | 115/266 [01:58<02:24,  1.04it/s]Loading train:  44%|████▎     | 116/266 [01:59<02:23,  1.04it/s]Loading train:  44%|████▍     | 117/266 [02:00<02:27,  1.01it/s]Loading train:  44%|████▍     | 118/266 [02:01<02:30,  1.02s/it]Loading train:  45%|████▍     | 119/266 [02:02<02:35,  1.05s/it]Loading train:  45%|████▌     | 120/266 [02:03<02:31,  1.03s/it]Loading train:  45%|████▌     | 121/266 [02:04<02:32,  1.05s/it]Loading train:  46%|████▌     | 122/266 [02:05<02:31,  1.06s/it]Loading train:  46%|████▌     | 123/266 [02:06<02:32,  1.07s/it]Loading train:  47%|████▋     | 124/266 [02:07<02:28,  1.05s/it]Loading train:  47%|████▋     | 125/266 [02:08<02:28,  1.05s/it]Loading train:  47%|████▋     | 126/266 [02:09<02:25,  1.04s/it]Loading train:  48%|████▊     | 127/266 [02:10<02:22,  1.02s/it]Loading train:  48%|████▊     | 128/266 [02:11<02:26,  1.06s/it]Loading train:  48%|████▊     | 129/266 [02:13<02:25,  1.06s/it]Loading train:  49%|████▉     | 130/266 [02:14<02:24,  1.06s/it]Loading train:  49%|████▉     | 131/266 [02:15<02:19,  1.03s/it]Loading train:  50%|████▉     | 132/266 [02:16<02:16,  1.02s/it]Loading train:  50%|█████     | 133/266 [02:17<02:15,  1.02s/it]Loading train:  50%|█████     | 134/266 [02:18<02:16,  1.03s/it]Loading train:  51%|█████     | 135/266 [02:19<02:17,  1.05s/it]Loading train:  51%|█████     | 136/266 [02:20<02:15,  1.04s/it]Loading train:  52%|█████▏    | 137/266 [02:21<02:16,  1.06s/it]Loading train:  52%|█████▏    | 138/266 [02:22<02:11,  1.03s/it]Loading train:  52%|█████▏    | 139/266 [02:23<02:10,  1.02s/it]Loading train:  53%|█████▎    | 140/266 [02:24<02:07,  1.01s/it]Loading train:  53%|█████▎    | 141/266 [02:25<02:04,  1.00it/s]Loading train:  53%|█████▎    | 142/266 [02:26<02:04,  1.00s/it]Loading train:  54%|█████▍    | 143/266 [02:27<02:02,  1.00it/s]Loading train:  54%|█████▍    | 144/266 [02:28<02:04,  1.02s/it]Loading train:  55%|█████▍    | 145/266 [02:29<02:04,  1.03s/it]Loading train:  55%|█████▍    | 146/266 [02:30<02:03,  1.03s/it]Loading train:  55%|█████▌    | 147/266 [02:31<02:03,  1.04s/it]Loading train:  56%|█████▌    | 148/266 [02:32<01:58,  1.00s/it]Loading train:  56%|█████▌    | 149/266 [02:33<01:54,  1.02it/s]Loading train:  56%|█████▋    | 150/266 [02:34<01:52,  1.03it/s]Loading train:  57%|█████▋    | 151/266 [02:35<01:50,  1.04it/s]Loading train:  57%|█████▋    | 152/266 [02:36<01:48,  1.06it/s]Loading train:  58%|█████▊    | 153/266 [02:37<01:47,  1.06it/s]Loading train:  58%|█████▊    | 154/266 [02:37<01:44,  1.08it/s]Loading train:  58%|█████▊    | 155/266 [02:38<01:40,  1.10it/s]Loading train:  59%|█████▊    | 156/266 [02:39<01:38,  1.12it/s]Loading train:  59%|█████▉    | 157/266 [02:40<01:33,  1.16it/s]Loading train:  59%|█████▉    | 158/266 [02:41<01:32,  1.17it/s]Loading train:  60%|█████▉    | 159/266 [02:42<01:30,  1.18it/s]Loading train:  60%|██████    | 160/266 [02:42<01:29,  1.18it/s]Loading train:  61%|██████    | 161/266 [02:43<01:28,  1.18it/s]Loading train:  61%|██████    | 162/266 [02:44<01:28,  1.18it/s]Loading train:  61%|██████▏   | 163/266 [02:45<01:25,  1.20it/s]Loading train:  62%|██████▏   | 164/266 [02:46<01:24,  1.21it/s]Loading train:  62%|██████▏   | 165/266 [02:47<01:21,  1.24it/s]Loading train:  62%|██████▏   | 166/266 [02:47<01:19,  1.26it/s]Loading train:  63%|██████▎   | 167/266 [02:48<01:18,  1.27it/s]Loading train:  63%|██████▎   | 168/266 [02:49<01:14,  1.31it/s]Loading train:  64%|██████▎   | 169/266 [02:50<01:13,  1.31it/s]Loading train:  64%|██████▍   | 170/266 [02:50<01:14,  1.29it/s]Loading train:  64%|██████▍   | 171/266 [02:51<01:15,  1.26it/s]Loading train:  65%|██████▍   | 172/266 [02:52<01:16,  1.24it/s]Loading train:  65%|██████▌   | 173/266 [02:53<01:16,  1.21it/s]Loading train:  65%|██████▌   | 174/266 [02:54<01:14,  1.24it/s]Loading train:  66%|██████▌   | 175/266 [02:54<01:11,  1.28it/s]Loading train:  66%|██████▌   | 176/266 [02:55<01:08,  1.32it/s]Loading train:  67%|██████▋   | 177/266 [02:56<01:06,  1.35it/s]Loading train:  67%|██████▋   | 178/266 [02:57<01:07,  1.30it/s]Loading train:  67%|██████▋   | 179/266 [02:57<01:06,  1.30it/s]Loading train:  68%|██████▊   | 180/266 [02:58<01:06,  1.30it/s]Loading train:  68%|██████▊   | 181/266 [02:59<01:03,  1.34it/s]Loading train:  68%|██████▊   | 182/266 [03:00<01:02,  1.35it/s]Loading train:  69%|██████▉   | 183/266 [03:00<01:00,  1.38it/s]Loading train:  69%|██████▉   | 184/266 [03:01<01:01,  1.33it/s]Loading train:  70%|██████▉   | 185/266 [03:02<01:01,  1.31it/s]Loading train:  70%|██████▉   | 186/266 [03:03<01:01,  1.31it/s]Loading train:  70%|███████   | 187/266 [03:03<01:01,  1.29it/s]Loading train:  71%|███████   | 188/266 [03:04<00:59,  1.31it/s]Loading train:  71%|███████   | 189/266 [03:05<00:59,  1.30it/s]Loading train:  71%|███████▏  | 190/266 [03:06<00:58,  1.31it/s]Loading train:  72%|███████▏  | 191/266 [03:07<01:08,  1.09it/s]Loading train:  72%|███████▏  | 192/266 [03:08<01:12,  1.02it/s]Loading train:  73%|███████▎  | 193/266 [03:09<01:19,  1.09s/it]Loading train:  73%|███████▎  | 194/266 [03:11<01:29,  1.24s/it]Loading train:  73%|███████▎  | 195/266 [03:12<01:22,  1.16s/it]Loading train:  74%|███████▎  | 196/266 [03:13<01:14,  1.06s/it]Loading train:  74%|███████▍  | 197/266 [03:14<01:09,  1.00s/it]Loading train:  74%|███████▍  | 198/266 [03:15<01:08,  1.00s/it]Loading train:  75%|███████▍  | 199/266 [03:16<01:05,  1.03it/s]Loading train:  75%|███████▌  | 200/266 [03:17<01:03,  1.04it/s]Loading train:  76%|███████▌  | 201/266 [03:18<01:03,  1.03it/s]Loading train:  76%|███████▌  | 202/266 [03:18<01:01,  1.05it/s]Loading train:  76%|███████▋  | 203/266 [03:19<01:00,  1.04it/s]Loading train:  77%|███████▋  | 204/266 [03:20<00:57,  1.07it/s]Loading train:  77%|███████▋  | 205/266 [03:21<00:56,  1.09it/s]Loading train:  77%|███████▋  | 206/266 [03:22<00:54,  1.10it/s]Loading train:  78%|███████▊  | 207/266 [03:23<00:52,  1.12it/s]Loading train:  78%|███████▊  | 208/266 [03:24<00:51,  1.12it/s]Loading train:  79%|███████▊  | 209/266 [03:25<00:51,  1.11it/s]Loading train:  79%|███████▉  | 210/266 [03:26<00:49,  1.12it/s]Loading train:  79%|███████▉  | 211/266 [03:26<00:48,  1.13it/s]Loading train:  80%|███████▉  | 212/266 [03:27<00:46,  1.17it/s]Loading train:  80%|████████  | 213/266 [03:28<00:45,  1.17it/s]Loading train:  80%|████████  | 214/266 [03:29<00:45,  1.14it/s]Loading train:  81%|████████  | 215/266 [03:30<00:45,  1.12it/s]Loading train:  81%|████████  | 216/266 [03:31<00:45,  1.11it/s]Loading train:  82%|████████▏ | 217/266 [03:32<00:43,  1.11it/s]Loading train:  82%|████████▏ | 218/266 [03:33<00:43,  1.12it/s]Loading train:  82%|████████▏ | 219/266 [03:34<00:42,  1.11it/s]Loading train:  83%|████████▎ | 220/266 [03:34<00:41,  1.12it/s]Loading train:  83%|████████▎ | 221/266 [03:35<00:39,  1.14it/s]Loading train:  83%|████████▎ | 222/266 [03:36<00:38,  1.14it/s]Loading train:  84%|████████▍ | 223/266 [03:37<00:37,  1.14it/s]Loading train:  84%|████████▍ | 224/266 [03:38<00:36,  1.16it/s]Loading train:  85%|████████▍ | 225/266 [03:39<00:35,  1.16it/s]Loading train:  85%|████████▍ | 226/266 [03:40<00:33,  1.18it/s]Loading train:  85%|████████▌ | 227/266 [03:40<00:32,  1.19it/s]Loading train:  86%|████████▌ | 228/266 [03:41<00:32,  1.18it/s]Loading train:  86%|████████▌ | 229/266 [03:42<00:30,  1.21it/s]Loading train:  86%|████████▋ | 230/266 [03:43<00:29,  1.23it/s]Loading train:  87%|████████▋ | 231/266 [03:44<00:30,  1.15it/s]Loading train:  87%|████████▋ | 232/266 [03:45<00:28,  1.19it/s]Loading train:  88%|████████▊ | 233/266 [03:45<00:28,  1.17it/s]Loading train:  88%|████████▊ | 234/266 [03:46<00:26,  1.20it/s]Loading train:  88%|████████▊ | 235/266 [03:47<00:25,  1.20it/s]Loading train:  89%|████████▊ | 236/266 [03:48<00:25,  1.19it/s]Loading train:  89%|████████▉ | 237/266 [03:49<00:24,  1.17it/s]Loading train:  89%|████████▉ | 238/266 [03:50<00:23,  1.19it/s]Loading train:  90%|████████▉ | 239/266 [03:51<00:22,  1.19it/s]Loading train:  90%|█████████ | 240/266 [03:51<00:21,  1.21it/s]Loading train:  91%|█████████ | 241/266 [03:52<00:20,  1.20it/s]Loading train:  91%|█████████ | 242/266 [03:53<00:20,  1.19it/s]Loading train:  91%|█████████▏| 243/266 [03:54<00:19,  1.20it/s]Loading train:  92%|█████████▏| 244/266 [03:55<00:18,  1.17it/s]Loading train:  92%|█████████▏| 245/266 [03:56<00:18,  1.15it/s]Loading train:  92%|█████████▏| 246/266 [03:56<00:17,  1.15it/s]Loading train:  93%|█████████▎| 247/266 [03:57<00:16,  1.17it/s]Loading train:  93%|█████████▎| 248/266 [03:58<00:15,  1.14it/s]Loading train:  94%|█████████▎| 249/266 [03:59<00:16,  1.03it/s]Loading train:  94%|█████████▍| 250/266 [04:01<00:16,  1.02s/it]Loading train:  94%|█████████▍| 251/266 [04:02<00:15,  1.03s/it]Loading train:  95%|█████████▍| 252/266 [04:03<00:14,  1.03s/it]Loading train:  95%|█████████▌| 253/266 [04:04<00:13,  1.06s/it]Loading train:  95%|█████████▌| 254/266 [04:05<00:12,  1.08s/it]Loading train:  96%|█████████▌| 255/266 [04:06<00:11,  1.06s/it]Loading train:  96%|█████████▌| 256/266 [04:07<00:10,  1.03s/it]Loading train:  97%|█████████▋| 257/266 [04:08<00:09,  1.01s/it]Loading train:  97%|█████████▋| 258/266 [04:09<00:07,  1.00it/s]Loading train:  97%|█████████▋| 259/266 [04:10<00:06,  1.01it/s]Loading train:  98%|█████████▊| 260/266 [04:11<00:06,  1.01s/it]Loading train:  98%|█████████▊| 261/266 [04:12<00:05,  1.02s/it]Loading train:  98%|█████████▊| 262/266 [04:13<00:04,  1.03s/it]Loading train:  99%|█████████▉| 263/266 [04:14<00:03,  1.02s/it]Loading train:  99%|█████████▉| 264/266 [04:15<00:02,  1.03s/it]Loading train: 100%|█████████▉| 265/266 [04:16<00:01,  1.01s/it]Loading train: 100%|██████████| 266/266 [04:17<00:00,  1.01it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:01, 165.91it/s]concatenating: train:  14%|█▍        | 37/266 [00:00<00:01, 172.16it/s]concatenating: train:  25%|██▌       | 67/266 [00:00<00:01, 197.15it/s]concatenating: train:  36%|███▋      | 97/266 [00:00<00:00, 217.11it/s]concatenating: train:  45%|████▌     | 120/266 [00:00<00:00, 220.40it/s]concatenating: train:  53%|█████▎    | 142/266 [00:00<00:00, 218.76it/s]concatenating: train:  62%|██████▏   | 166/266 [00:00<00:00, 222.37it/s]concatenating: train:  74%|███████▍  | 197/266 [00:00<00:00, 242.72it/s]concatenating: train:  83%|████████▎ | 222/266 [00:00<00:00, 237.70it/s]concatenating: train:  94%|█████████▍| 250/266 [00:01<00:00, 247.49it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 246.39it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.35s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.32s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.29s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.23s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.28s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 168.56it/s]2019-08-17 00:21:53.588898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 00:21:53.589005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 00:21:53.589023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 00:21:53.589033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 00:21:53.589487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.91it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.87it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.64it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.23it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.27it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.08it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.26it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.13it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.72it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.41it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.24it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.69it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.65it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.74it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.52it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.97it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.00it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.81it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.90it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 109,123
Non-trainable params: 392,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34793066e-02 3.29004432e-02 7.69331615e-02 9.55933216e-03
 2.76668840e-02 7.23826576e-03 8.42826805e-02 1.14348479e-01
 8.97861260e-02 1.36416370e-02 2.91104280e-01 1.88821166e-01
 2.38237851e-04]
Train on 16939 samples, validate on 312 samples
Epoch 1/300
 - 19s - loss: 1.2177 - acc: 0.7151 - mDice: 0.4304 - val_loss: 1.0136 - val_acc: 0.9530 - val_mDice: 0.5982

Epoch 00001: val_mDice improved from -inf to 0.59816, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.4231 - acc: 0.9347 - mDice: 0.6462 - val_loss: 1.0141 - val_acc: 0.9558 - val_mDice: 0.6056

Epoch 00002: val_mDice improved from 0.59816 to 0.60560, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.4220 - acc: 0.9418 - mDice: 0.6559 - val_loss: 0.9824 - val_acc: 0.9553 - val_mDice: 0.6088

Epoch 00003: val_mDice improved from 0.60560 to 0.60880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.3702 - acc: 0.9470 - mDice: 0.6814 - val_loss: 1.0018 - val_acc: 0.9540 - val_mDice: 0.6027

Epoch 00004: val_mDice did not improve from 0.60880
Epoch 5/300
 - 14s - loss: 0.3414 - acc: 0.9493 - mDice: 0.6991 - val_loss: 0.9694 - val_acc: 0.9539 - val_mDice: 0.6034

Epoch 00005: val_mDice did not improve from 0.60880
Epoch 6/300
 - 14s - loss: 0.3374 - acc: 0.9500 - mDice: 0.7046 - val_loss: 0.8341 - val_acc: 0.9568 - val_mDice: 0.6142

Epoch 00006: val_mDice improved from 0.60880 to 0.61418, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.3303 - acc: 0.9508 - mDice: 0.7134 - val_loss: 1.0548 - val_acc: 0.9559 - val_mDice: 0.5883

Epoch 00007: val_mDice did not improve from 0.61418
Epoch 8/300
 - 14s - loss: 0.3227 - acc: 0.9505 - mDice: 0.7133 - val_loss: 0.8246 - val_acc: 0.9569 - val_mDice: 0.6120

Epoch 00008: val_mDice did not improve from 0.61418
Epoch 9/300
 - 14s - loss: 0.3209 - acc: 0.9517 - mDice: 0.7212 - val_loss: 0.9590 - val_acc: 0.9556 - val_mDice: 0.6075

Epoch 00009: val_mDice did not improve from 0.61418
Epoch 10/300
 - 14s - loss: 0.3115 - acc: 0.9517 - mDice: 0.7220 - val_loss: 0.8648 - val_acc: 0.9508 - val_mDice: 0.5661

Epoch 00010: val_mDice did not improve from 0.61418
Epoch 11/300
 - 14s - loss: 0.3081 - acc: 0.9524 - mDice: 0.7292 - val_loss: 1.1040 - val_acc: 0.9483 - val_mDice: 0.5427

Epoch 00011: val_mDice did not improve from 0.61418
Epoch 12/300
 - 14s - loss: 0.3763 - acc: 0.9475 - mDice: 0.6848 - val_loss: 1.8168 - val_acc: 0.9506 - val_mDice: 0.4625

Epoch 00012: val_mDice did not improve from 0.61418
Epoch 13/300
 - 14s - loss: 0.3357 - acc: 0.9498 - mDice: 0.7065 - val_loss: 0.9982 - val_acc: 0.9558 - val_mDice: 0.6079

Epoch 00013: val_mDice did not improve from 0.61418
Epoch 14/300
 - 14s - loss: 0.2991 - acc: 0.9527 - mDice: 0.7323 - val_loss: 0.9332 - val_acc: 0.9560 - val_mDice: 0.6095

Epoch 00014: val_mDice did not improve from 0.61418
Epoch 15/300
 - 14s - loss: 0.2884 - acc: 0.9533 - mDice: 0.7382 - val_loss: 0.9643 - val_acc: 0.9570 - val_mDice: 0.6154

Epoch 00015: val_mDice improved from 0.61418 to 0.61542, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 0.3380 - acc: 0.9507 - mDice: 0.7159 - val_loss: 0.9956 - val_acc: 0.9552 - val_mDice: 0.5992

Epoch 00016: val_mDice did not improve from 0.61542
Epoch 17/300
 - 14s - loss: 0.2941 - acc: 0.9534 - mDice: 0.7384 - val_loss: 0.8886 - val_acc: 0.9555 - val_mDice: 0.6122

Epoch 00017: val_mDice did not improve from 0.61542
Epoch 18/300
 - 14s - loss: 0.2724 - acc: 0.9544 - mDice: 0.7496 - val_loss: 0.9075 - val_acc: 0.9575 - val_mDice: 0.6133

Epoch 00018: val_mDice did not improve from 0.61542
Epoch 19/300
 - 15s - loss: 0.2875 - acc: 0.9543 - mDice: 0.7473 - val_loss: 0.8365 - val_acc: 0.9573 - val_mDice: 0.6076

Epoch 00019: val_mDice did not improve from 0.61542
Epoch 20/300
 - 15s - loss: 0.2791 - acc: 0.9545 - mDice: 0.7502 - val_loss: 0.8763 - val_acc: 0.9559 - val_mDice: 0.6119

Epoch 00020: val_mDice did not improve from 0.61542
Epoch 21/300
 - 16s - loss: 0.2608 - acc: 0.9552 - mDice: 0.7588 - val_loss: 0.9157 - val_acc: 0.9577 - val_mDice: 0.6084

Epoch 00021: val_mDice did not improve from 0.61542
Epoch 22/300
 - 16s - loss: 0.2813 - acc: 0.9543 - mDice: 0.7496 - val_loss: 0.8502 - val_acc: 0.9557 - val_mDice: 0.5930

Epoch 00022: val_mDice did not improve from 0.61542
Epoch 23/300
 - 15s - loss: 0.2700 - acc: 0.9546 - mDice: 0.7540 - val_loss: 0.8946 - val_acc: 0.9586 - val_mDice: 0.5929

Epoch 00023: val_mDice did not improve from 0.61542
Epoch 24/300
 - 15s - loss: 0.2721 - acc: 0.9548 - mDice: 0.7537 - val_loss: 0.8950 - val_acc: 0.9545 - val_mDice: 0.6006

Epoch 00024: val_mDice did not improve from 0.61542
Epoch 25/300
 - 15s - loss: 0.2664 - acc: 0.9550 - mDice: 0.7557 - val_loss: 0.8654 - val_acc: 0.9558 - val_mDice: 0.5988

Epoch 00025: val_mDice did not improve from 0.61542
Epoch 26/300
 - 15s - loss: 0.2659 - acc: 0.9553 - mDice: 0.7604 - val_loss: 1.0876 - val_acc: 0.9556 - val_mDice: 0.5814

Epoch 00026: val_mDice did not improve from 0.61542
Epoch 27/300
 - 14s - loss: 0.2541 - acc: 0.9557 - mDice: 0.7646 - val_loss: 0.9223 - val_acc: 0.9559 - val_mDice: 0.6005

Epoch 00027: val_mDice did not improve from 0.61542
Epoch 28/300
 - 15s - loss: 0.2621 - acc: 0.9553 - mDice: 0.7591 - val_loss: 0.8487 - val_acc: 0.9560 - val_mDice: 0.6029

Epoch 00028: val_mDice did not improve from 0.61542
Epoch 29/300
 - 14s - loss: 0.2767 - acc: 0.9546 - mDice: 0.7511 - val_loss: 0.8646 - val_acc: 0.9574 - val_mDice: 0.6002

Epoch 00029: val_mDice did not improve from 0.61542
Epoch 30/300
 - 14s - loss: 0.2519 - acc: 0.9561 - mDice: 0.7683 - val_loss: 0.8584 - val_acc: 0.9562 - val_mDice: 0.6021

Epoch 00030: val_mDice did not improve from 0.61542
Epoch 31/300
 - 15s - loss: 0.2503 - acc: 0.9565 - mDice: 0.7726 - val_loss: 0.9137 - val_acc: 0.9528 - val_mDice: 0.5826

Epoch 00031: val_mDice did not improve from 0.61542
Epoch 32/300
 - 14s - loss: 0.2735 - acc: 0.9558 - mDice: 0.7652 - val_loss: 0.8219 - val_acc: 0.9576 - val_mDice: 0.6063

Epoch 00032: val_mDice did not improve from 0.61542
Epoch 33/300
 - 14s - loss: 0.2654 - acc: 0.9554 - mDice: 0.7618 - val_loss: 0.7672 - val_acc: 0.9551 - val_mDice: 0.5980

Epoch 00033: val_mDice did not improve from 0.61542
Epoch 34/300
 - 15s - loss: 0.2420 - acc: 0.9566 - mDice: 0.7738 - val_loss: 0.8483 - val_acc: 0.9548 - val_mDice: 0.6002

Epoch 00034: val_mDice did not improve from 0.61542
Epoch 35/300
 - 14s - loss: 0.2365 - acc: 0.9569 - mDice: 0.7781 - val_loss: 0.8777 - val_acc: 0.9559 - val_mDice: 0.5951

Epoch 00035: val_mDice did not improve from 0.61542
Epoch 36/300
 - 14s - loss: 0.2612 - acc: 0.9558 - mDice: 0.7630 - val_loss: 0.9773 - val_acc: 0.9547 - val_mDice: 0.5790

Epoch 00036: val_mDice did not improve from 0.61542
Epoch 37/300
 - 14s - loss: 0.2537 - acc: 0.9562 - mDice: 0.7674 - val_loss: 0.8299 - val_acc: 0.9545 - val_mDice: 0.6019

Epoch 00037: val_mDice did not improve from 0.61542
Epoch 38/300
 - 15s - loss: 0.2348 - acc: 0.9570 - mDice: 0.7793 - val_loss: 0.7156 - val_acc: 0.9572 - val_mDice: 0.5972

Epoch 00038: val_mDice did not improve from 0.61542
Epoch 39/300
 - 14s - loss: 0.2508 - acc: 0.9570 - mDice: 0.7775 - val_loss: 0.8236 - val_acc: 0.9570 - val_mDice: 0.5918

Epoch 00039: val_mDice did not improve from 0.61542
Epoch 40/300
 - 14s - loss: 0.2635 - acc: 0.9554 - mDice: 0.7621 - val_loss: 0.7070 - val_acc: 0.9567 - val_mDice: 0.5999

Epoch 00040: val_mDice did not improve from 0.61542
Epoch 41/300
 - 14s - loss: 0.2450 - acc: 0.9568 - mDice: 0.7766 - val_loss: 1.0069 - val_acc: 0.9565 - val_mDice: 0.5796

Epoch 00041: val_mDice did not improve from 0.61542
Epoch 42/300
 - 14s - loss: 0.2314 - acc: 0.9572 - mDice: 0.7822 - val_loss: 0.8154 - val_acc: 0.9563 - val_mDice: 0.5958

Epoch 00042: val_mDice did not improve from 0.61542
Epoch 43/300
 - 14s - loss: 0.2437 - acc: 0.9567 - mDice: 0.7757 - val_loss: 0.8405 - val_acc: 0.9565 - val_mDice: 0.5968

Epoch 00043: val_mDice did not improve from 0.61542
Epoch 44/300
 - 15s - loss: 0.2328 - acc: 0.9574 - mDice: 0.7832 - val_loss: 0.7919 - val_acc: 0.9571 - val_mDice: 0.6031

Epoch 00044: val_mDice did not improve from 0.61542
Epoch 45/300
 - 14s - loss: 0.2439 - acc: 0.9568 - mDice: 0.7786 - val_loss: 1.1440 - val_acc: 0.9464 - val_mDice: 0.5482

Epoch 00045: val_mDice did not improve from 0.61542
Epoch 46/300
 - 14s - loss: 0.2546 - acc: 0.9563 - mDice: 0.7717 - val_loss: 0.7469 - val_acc: 0.9561 - val_mDice: 0.6005

Epoch 00046: val_mDice did not improve from 0.61542
Epoch 47/300
 - 14s - loss: 0.2457 - acc: 0.9562 - mDice: 0.7727 - val_loss: 0.7835 - val_acc: 0.9565 - val_mDice: 0.5976

Epoch 00047: val_mDice did not improve from 0.61542
Epoch 48/300
 - 15s - loss: 0.2328 - acc: 0.9574 - mDice: 0.7840 - val_loss: 0.7860 - val_acc: 0.9554 - val_mDice: 0.5985

Epoch 00048: val_mDice did not improve from 0.61542
Epoch 49/300
 - 14s - loss: 0.2482 - acc: 0.9561 - mDice: 0.7720 - val_loss: 0.8457 - val_acc: 0.9568 - val_mDice: 0.6024

Epoch 00049: val_mDice did not improve from 0.61542
Epoch 50/300
 - 14s - loss: 0.2306 - acc: 0.9574 - mDice: 0.7848 - val_loss: 0.7101 - val_acc: 0.9575 - val_mDice: 0.5992

Epoch 00050: val_mDice did not improve from 0.61542
Epoch 51/300
 - 14s - loss: 0.2219 - acc: 0.9579 - mDice: 0.7899 - val_loss: 0.8534 - val_acc: 0.9562 - val_mDice: 0.5870

Epoch 00051: val_mDice did not improve from 0.61542
Epoch 52/300
 - 14s - loss: 0.2269 - acc: 0.9578 - mDice: 0.7886 - val_loss: 0.8814 - val_acc: 0.9569 - val_mDice: 0.5898

Epoch 00052: val_mDice did not improve from 0.61542
Epoch 53/300
 - 14s - loss: 0.2757 - acc: 0.9548 - mDice: 0.7615 - val_loss: 0.9838 - val_acc: 0.9563 - val_mDice: 0.5825

Epoch 00053: val_mDice did not improve from 0.61542
Epoch 54/300
 - 14s - loss: 0.2442 - acc: 0.9563 - mDice: 0.7739 - val_loss: 0.6678 - val_acc: 0.9570 - val_mDice: 0.5946

Epoch 00054: val_mDice did not improve from 0.61542
Epoch 55/300
 - 15s - loss: 0.2305 - acc: 0.9575 - mDice: 0.7857 - val_loss: 0.7922 - val_acc: 0.9549 - val_mDice: 0.5979

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:12,  3.18s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.98s/it]predicting test subjects:  60%|██████    | 3/5 [00:08<00:05,  2.78s/it]predicting test subjects:  80%|████████  | 4/5 [00:10<00:02,  2.61s/it]predicting test subjects: 100%|██████████| 5/5 [00:12<00:00,  2.64s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:10,  3.21s/it]predicting train subjects:   1%|          | 2/266 [00:06<13:48,  3.14s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:58,  2.96s/it]predicting train subjects:   2%|▏         | 4/266 [00:11<12:08,  2.78s/it]predicting train subjects:   2%|▏         | 5/266 [00:14<12:23,  2.85s/it]predicting train subjects:   2%|▏         | 6/266 [00:17<13:00,  3.00s/it]predicting train subjects:   3%|▎         | 7/266 [00:20<13:08,  3.04s/it]predicting train subjects:   3%|▎         | 8/266 [00:23<13:18,  3.10s/it]predicting train subjects:   3%|▎         | 9/266 [00:27<13:34,  3.17s/it]predicting train subjects:   4%|▍         | 10/266 [00:30<13:42,  3.21s/it]predicting train subjects:   4%|▍         | 11/266 [00:33<13:43,  3.23s/it]predicting train subjects:   5%|▍         | 12/266 [00:37<13:44,  3.25s/it]predicting train subjects:   5%|▍         | 13/266 [00:40<13:41,  3.25s/it]predicting train subjects:   5%|▌         | 14/266 [00:43<13:36,  3.24s/it]predicting train subjects:   6%|▌         | 15/266 [00:46<13:26,  3.21s/it]predicting train subjects:   6%|▌         | 16/266 [00:49<13:18,  3.20s/it]predicting train subjects:   6%|▋         | 17/266 [00:52<13:03,  3.14s/it]predicting train subjects:   7%|▋         | 18/266 [00:55<12:57,  3.13s/it]predicting train subjects:   7%|▋         | 19/266 [00:58<12:40,  3.08s/it]predicting train subjects:   8%|▊         | 20/266 [01:02<12:40,  3.09s/it]predicting train subjects:   8%|▊         | 21/266 [01:05<12:31,  3.07s/it]predicting train subjects:   8%|▊         | 22/266 [01:07<12:19,  3.03s/it]predicting train subjects:   9%|▊         | 23/266 [01:10<12:00,  2.97s/it]predicting train subjects:   9%|▉         | 24/266 [01:13<11:48,  2.93s/it]predicting train subjects:   9%|▉         | 25/266 [01:16<11:44,  2.92s/it]predicting train subjects:  10%|▉         | 26/266 [01:19<11:29,  2.87s/it]predicting train subjects:  10%|█         | 27/266 [01:22<11:19,  2.84s/it]predicting train subjects:  11%|█         | 28/266 [01:24<11:12,  2.83s/it]predicting train subjects:  11%|█         | 29/266 [01:27<10:56,  2.77s/it]predicting train subjects:  11%|█▏        | 30/266 [01:30<10:41,  2.72s/it]predicting train subjects:  12%|█▏        | 31/266 [01:32<10:38,  2.72s/it]predicting train subjects:  12%|█▏        | 32/266 [01:35<10:36,  2.72s/it]predicting train subjects:  12%|█▏        | 33/266 [01:38<10:28,  2.70s/it]predicting train subjects:  13%|█▎        | 34/266 [01:40<10:30,  2.72s/it]predicting train subjects:  13%|█▎        | 35/266 [01:43<10:38,  2.77s/it]predicting train subjects:  14%|█▎        | 36/266 [01:46<10:27,  2.73s/it]predicting train subjects:  14%|█▍        | 37/266 [01:48<10:12,  2.67s/it]predicting train subjects:  14%|█▍        | 38/266 [01:51<10:08,  2.67s/it]predicting train subjects:  15%|█▍        | 39/266 [01:54<09:59,  2.64s/it]predicting train subjects:  15%|█▌        | 40/266 [01:57<10:06,  2.68s/it]predicting train subjects:  15%|█▌        | 41/266 [01:59<10:10,  2.71s/it]predicting train subjects:  16%|█▌        | 42/266 [02:02<09:49,  2.63s/it]predicting train subjects:  16%|█▌        | 43/266 [02:04<09:26,  2.54s/it]predicting train subjects:  17%|█▋        | 44/266 [02:06<09:16,  2.51s/it]predicting train subjects:  17%|█▋        | 45/266 [02:09<09:11,  2.50s/it]predicting train subjects:  17%|█▋        | 46/266 [02:11<08:56,  2.44s/it]predicting train subjects:  18%|█▊        | 47/266 [02:14<08:42,  2.39s/it]predicting train subjects:  18%|█▊        | 48/266 [02:16<08:45,  2.41s/it]predicting train subjects:  18%|█▊        | 49/266 [02:18<08:36,  2.38s/it]predicting train subjects:  19%|█▉        | 50/266 [02:21<08:28,  2.36s/it]predicting train subjects:  19%|█▉        | 51/266 [02:23<08:32,  2.38s/it]predicting train subjects:  20%|█▉        | 52/266 [02:25<08:25,  2.36s/it]predicting train subjects:  20%|█▉        | 53/266 [02:28<08:21,  2.35s/it]predicting train subjects:  20%|██        | 54/266 [02:30<08:14,  2.33s/it]predicting train subjects:  21%|██        | 55/266 [02:32<08:22,  2.38s/it]predicting train subjects:  21%|██        | 56/266 [02:35<08:32,  2.44s/it]predicting train subjects:  21%|██▏       | 57/266 [02:38<08:35,  2.47s/it]predicting train subjects:  22%|██▏       | 58/266 [02:40<08:18,  2.40s/it]predicting train subjects:  22%|██▏       | 59/266 [02:42<08:05,  2.34s/it]predicting train subjects:  23%|██▎       | 60/266 [02:44<08:02,  2.34s/it]predicting train subjects:  23%|██▎       | 61/266 [02:47<07:48,  2.28s/it]predicting train subjects:  23%|██▎       | 62/266 [02:49<07:35,  2.23s/it]predicting train subjects:  24%|██▎       | 63/266 [02:51<07:15,  2.14s/it]predicting train subjects:  24%|██▍       | 64/266 [02:53<07:00,  2.08s/it]predicting train subjects:  24%|██▍       | 65/266 [02:54<06:50,  2.04s/it]predicting train subjects:  25%|██▍       | 66/266 [02:56<06:44,  2.02s/it]predicting train subjects:  25%|██▌       | 67/266 [02:58<06:40,  2.01s/it]predicting train subjects:  26%|██▌       | 68/266 [03:00<06:41,  2.03s/it]predicting train subjects:  26%|██▌       | 69/266 [03:02<06:37,  2.02s/it]predicting train subjects:  26%|██▋       | 70/266 [03:05<06:36,  2.02s/it]predicting train subjects:  27%|██▋       | 71/266 [03:07<06:33,  2.02s/it]predicting train subjects:  27%|██▋       | 72/266 [03:09<06:32,  2.02s/it]predicting train subjects:  27%|██▋       | 73/266 [03:10<06:23,  1.99s/it]predicting train subjects:  28%|██▊       | 74/266 [03:12<06:22,  1.99s/it]predicting train subjects:  28%|██▊       | 75/266 [03:14<06:17,  1.98s/it]predicting train subjects:  29%|██▊       | 76/266 [03:16<06:14,  1.97s/it]predicting train subjects:  29%|██▉       | 77/266 [03:18<06:17,  2.00s/it]predicting train subjects:  29%|██▉       | 78/266 [03:21<06:46,  2.16s/it]predicting train subjects:  30%|██▉       | 79/266 [03:23<07:04,  2.27s/it]predicting train subjects:  30%|███       | 80/266 [03:26<07:17,  2.35s/it]predicting train subjects:  30%|███       | 81/266 [03:29<07:25,  2.41s/it]predicting train subjects:  31%|███       | 82/266 [03:31<07:28,  2.44s/it]predicting train subjects:  31%|███       | 83/266 [03:34<07:32,  2.47s/it]predicting train subjects:  32%|███▏      | 84/266 [03:36<07:32,  2.48s/it]predicting train subjects:  32%|███▏      | 85/266 [03:39<07:37,  2.53s/it]predicting train subjects:  32%|███▏      | 86/266 [03:41<07:37,  2.54s/it]predicting train subjects:  33%|███▎      | 87/266 [03:44<07:35,  2.54s/it]predicting train subjects:  33%|███▎      | 88/266 [03:46<07:33,  2.55s/it]predicting train subjects:  33%|███▎      | 89/266 [03:49<07:31,  2.55s/it]predicting train subjects:  34%|███▍      | 90/266 [03:52<07:29,  2.56s/it]predicting train subjects:  34%|███▍      | 91/266 [03:54<07:25,  2.54s/it]predicting train subjects:  35%|███▍      | 92/266 [03:57<07:24,  2.56s/it]predicting train subjects:  35%|███▍      | 93/266 [03:59<07:22,  2.56s/it]predicting train subjects:  35%|███▌      | 94/266 [04:02<07:26,  2.60s/it]predicting train subjects:  36%|███▌      | 95/266 [04:04<07:20,  2.57s/it]predicting train subjects:  36%|███▌      | 96/266 [04:07<07:03,  2.49s/it]predicting train subjects:  36%|███▋      | 97/266 [04:09<07:02,  2.50s/it]predicting train subjects:  37%|███▋      | 98/266 [04:12<06:58,  2.49s/it]predicting train subjects:  37%|███▋      | 99/266 [04:14<06:28,  2.33s/it]predicting train subjects:  38%|███▊      | 100/266 [04:16<06:17,  2.28s/it]predicting train subjects:  38%|███▊      | 101/266 [04:18<06:16,  2.28s/it]predicting train subjects:  38%|███▊      | 102/266 [04:20<06:13,  2.28s/it]predicting train subjects:  39%|███▊      | 103/266 [04:23<06:13,  2.29s/it]predicting train subjects:  39%|███▉      | 104/266 [04:25<06:12,  2.30s/it]predicting train subjects:  39%|███▉      | 105/266 [04:27<06:10,  2.30s/it]predicting train subjects:  40%|███▉      | 106/266 [04:30<06:06,  2.29s/it]predicting train subjects:  40%|████      | 107/266 [04:32<06:01,  2.28s/it]predicting train subjects:  41%|████      | 108/266 [04:34<05:58,  2.27s/it]predicting train subjects:  41%|████      | 109/266 [04:36<05:57,  2.28s/it]predicting train subjects:  41%|████▏     | 110/266 [04:39<05:57,  2.29s/it]predicting train subjects:  42%|████▏     | 111/266 [04:41<05:54,  2.29s/it]predicting train subjects:  42%|████▏     | 112/266 [04:43<05:51,  2.28s/it]predicting train subjects:  42%|████▏     | 113/266 [04:46<05:49,  2.28s/it]predicting train subjects:  43%|████▎     | 114/266 [04:48<05:44,  2.27s/it]predicting train subjects:  43%|████▎     | 115/266 [04:50<05:38,  2.24s/it]predicting train subjects:  44%|████▎     | 116/266 [04:52<05:39,  2.27s/it]predicting train subjects:  44%|████▍     | 117/266 [04:55<05:38,  2.27s/it]predicting train subjects:  44%|████▍     | 118/266 [04:57<05:37,  2.28s/it]predicting train subjects:  45%|████▍     | 119/266 [04:59<05:47,  2.37s/it]predicting train subjects:  45%|████▌     | 120/266 [05:02<05:54,  2.43s/it]predicting train subjects:  45%|████▌     | 121/266 [05:05<05:55,  2.45s/it]predicting train subjects:  46%|████▌     | 122/266 [05:07<05:55,  2.47s/it]predicting train subjects:  46%|████▌     | 123/266 [05:10<05:56,  2.49s/it]predicting train subjects:  47%|████▋     | 124/266 [05:12<06:00,  2.54s/it]predicting train subjects:  47%|████▋     | 125/266 [05:15<05:58,  2.54s/it]predicting train subjects:  47%|████▋     | 126/266 [05:17<05:52,  2.52s/it]predicting train subjects:  48%|████▊     | 127/266 [05:20<05:51,  2.53s/it]predicting train subjects:  48%|████▊     | 128/266 [05:22<05:51,  2.55s/it]predicting train subjects:  48%|████▊     | 129/266 [05:25<05:44,  2.51s/it]predicting train subjects:  49%|████▉     | 130/266 [05:27<05:41,  2.51s/it]predicting train subjects:  49%|████▉     | 131/266 [05:30<05:41,  2.53s/it]predicting train subjects:  50%|████▉     | 132/266 [05:32<05:38,  2.53s/it]predicting train subjects:  50%|█████     | 133/266 [05:35<05:39,  2.55s/it]predicting train subjects:  50%|█████     | 134/266 [05:38<05:37,  2.56s/it]predicting train subjects:  51%|█████     | 135/266 [05:40<05:36,  2.57s/it]predicting train subjects:  51%|█████     | 136/266 [05:43<05:38,  2.60s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:46<05:37,  2.61s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:48<05:31,  2.59s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:51<05:27,  2.58s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:53<05:23,  2.57s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:56<05:17,  2.54s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:58<05:13,  2.53s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:01<05:09,  2.52s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:03<05:04,  2.50s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:06<05:03,  2.50s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:08<05:00,  2.50s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:11<04:55,  2.48s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:13<04:52,  2.48s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:15<04:47,  2.46s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:18<04:45,  2.46s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:20<04:44,  2.47s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:23<04:41,  2.47s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:25<04:37,  2.46s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:28<04:39,  2.49s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:30<04:15,  2.30s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:32<03:58,  2.17s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:33<03:46,  2.08s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:35<03:37,  2.01s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:37<03:31,  1.98s/it]predicting train subjects:  60%|██████    | 160/266 [06:39<03:26,  1.94s/it]predicting train subjects:  61%|██████    | 161/266 [06:41<03:25,  1.96s/it]predicting train subjects:  61%|██████    | 162/266 [06:43<03:21,  1.94s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:45<03:20,  1.94s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:47<03:17,  1.94s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:49<03:15,  1.94s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:51<03:14,  1.94s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:53<03:13,  1.96s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:55<03:11,  1.96s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:57<03:07,  1.94s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:58<03:04,  1.92s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:00<03:00,  1.90s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:02<02:59,  1.91s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:04<03:02,  1.96s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:06<03:05,  2.01s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:08<03:04,  2.02s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:11<03:03,  2.04s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:13<03:04,  2.07s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:15<03:00,  2.05s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:17<02:58,  2.06s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:19<02:56,  2.06s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:21<02:55,  2.06s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:23<02:52,  2.05s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:25<02:49,  2.04s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:27<02:49,  2.07s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:29<02:48,  2.08s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:31<02:44,  2.06s/it]predicting train subjects:  70%|███████   | 187/266 [07:33<02:41,  2.05s/it]predicting train subjects:  71%|███████   | 188/266 [07:35<02:41,  2.07s/it]predicting train subjects:  71%|███████   | 189/266 [07:37<02:40,  2.08s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:40<02:38,  2.09s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:42<02:39,  2.13s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:44<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:46<02:32,  2.09s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:48<02:41,  2.24s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:51<02:39,  2.24s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:53<02:38,  2.26s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:55<02:36,  2.27s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:58<02:34,  2.27s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:00<02:32,  2.27s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:02<02:30,  2.27s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:04<02:27,  2.27s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:07<02:25,  2.28s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:09<02:24,  2.29s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:11<02:22,  2.29s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:13<02:18,  2.27s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:16<02:14,  2.25s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:18<02:11,  2.22s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:20<02:08,  2.21s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:22<02:06,  2.22s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:25<02:05,  2.23s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:27<02:02,  2.22s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:29<02:00,  2.22s/it]predicting train subjects:  80%|████████  | 213/266 [08:31<01:54,  2.15s/it]predicting train subjects:  80%|████████  | 214/266 [08:33<01:50,  2.13s/it]predicting train subjects:  81%|████████  | 215/266 [08:35<01:47,  2.11s/it]predicting train subjects:  81%|████████  | 216/266 [08:37<01:42,  2.06s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:39<01:38,  2.01s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:41<01:35,  2.00s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:43<01:33,  2.00s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:45<01:32,  2.00s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:47<01:30,  2.01s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:49<01:27,  1.98s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:51<01:24,  1.97s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:53<01:22,  1.97s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:55<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:57<01:21,  2.03s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:59<01:17,  1.99s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:01<01:15,  2.00s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:03<01:14,  2.01s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:05<01:11,  2.00s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:07<01:11,  2.03s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:09<01:09,  2.03s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:11<01:07,  2.05s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:13<01:04,  2.03s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:15<01:02,  2.03s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:17<01:00,  2.01s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:19<00:58,  2.01s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:21<00:56,  2.02s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:23<00:55,  2.04s/it]predicting train subjects:  90%|█████████ | 240/266 [09:25<00:52,  2.02s/it]predicting train subjects:  91%|█████████ | 241/266 [09:27<00:49,  2.00s/it]predicting train subjects:  91%|█████████ | 242/266 [09:29<00:47,  1.99s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:31<00:46,  2.01s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:33<00:44,  2.02s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:35<00:42,  2.03s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:37<00:40,  2.02s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:39<00:38,  2.02s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:41<00:36,  2.00s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:44<00:36,  2.17s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:46<00:36,  2.29s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:49<00:35,  2.38s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:52<00:34,  2.44s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:54<00:32,  2.49s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:57<00:30,  2.51s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:59<00:27,  2.54s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:02<00:25,  2.55s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:04<00:23,  2.56s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:07<00:20,  2.58s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:10<00:18,  2.58s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:12<00:15,  2.55s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:15<00:12,  2.56s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:17<00:10,  2.55s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:20<00:07,  2.53s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:22<00:05,  2.52s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:25<00:02,  2.54s/it]predicting train subjects: 100%|██████████| 266/266 [10:27<00:00,  2.53s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:17,  1.65s/it]Loading train:   1%|          | 2/266 [00:03<07:06,  1.61s/it]Loading train:   1%|          | 3/266 [00:04<06:27,  1.47s/it]Loading train:   2%|▏         | 4/266 [00:05<05:55,  1.36s/it]Loading train:   2%|▏         | 5/266 [00:06<05:59,  1.38s/it]Loading train:   2%|▏         | 6/266 [00:07<05:22,  1.24s/it]Loading train:   3%|▎         | 7/266 [00:08<04:57,  1.15s/it]Loading train:   3%|▎         | 8/266 [00:09<04:48,  1.12s/it]Loading train:   3%|▎         | 9/266 [00:10<04:34,  1.07s/it]Loading train:   4%|▍         | 10/266 [00:11<04:18,  1.01s/it]Loading train:   4%|▍         | 11/266 [00:12<04:12,  1.01it/s]Loading train:   5%|▍         | 12/266 [00:13<04:09,  1.02it/s]Loading train:   5%|▍         | 13/266 [00:14<04:00,  1.05it/s]Loading train:   5%|▌         | 14/266 [00:15<03:56,  1.06it/s]Loading train:   6%|▌         | 15/266 [00:16<04:01,  1.04it/s]Loading train:   6%|▌         | 16/266 [00:17<03:55,  1.06it/s]Loading train:   6%|▋         | 17/266 [00:18<03:55,  1.06it/s]Loading train:   7%|▋         | 18/266 [00:19<04:02,  1.02it/s]Loading train:   7%|▋         | 19/266 [00:20<03:54,  1.05it/s]Loading train:   8%|▊         | 20/266 [00:21<03:59,  1.03it/s]Loading train:   8%|▊         | 21/266 [00:22<03:57,  1.03it/s]Loading train:   8%|▊         | 22/266 [00:23<04:05,  1.01s/it]Loading train:   9%|▊         | 23/266 [00:24<04:00,  1.01it/s]Loading train:   9%|▉         | 24/266 [00:25<04:09,  1.03s/it]Loading train:   9%|▉         | 25/266 [00:26<04:03,  1.01s/it]Loading train:  10%|▉         | 26/266 [00:27<03:53,  1.03it/s]Loading train:  10%|█         | 27/266 [00:28<03:49,  1.04it/s]Loading train:  11%|█         | 28/266 [00:28<03:34,  1.11it/s]Loading train:  11%|█         | 29/266 [00:29<03:39,  1.08it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:38,  1.08it/s]Loading train:  12%|█▏        | 31/266 [00:31<03:34,  1.10it/s]Loading train:  12%|█▏        | 32/266 [00:32<03:34,  1.09it/s]Loading train:  12%|█▏        | 33/266 [00:33<03:35,  1.08it/s]Loading train:  13%|█▎        | 34/266 [00:34<03:32,  1.09it/s]Loading train:  13%|█▎        | 35/266 [00:35<03:33,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:36<03:28,  1.10it/s]Loading train:  14%|█▍        | 37/266 [00:37<03:38,  1.05it/s]Loading train:  14%|█▍        | 38/266 [00:38<03:40,  1.03it/s]Loading train:  15%|█▍        | 39/266 [00:39<03:38,  1.04it/s]Loading train:  15%|█▌        | 40/266 [00:39<03:27,  1.09it/s]Loading train:  15%|█▌        | 41/266 [00:40<03:23,  1.11it/s]Loading train:  16%|█▌        | 42/266 [00:41<03:17,  1.13it/s]Loading train:  16%|█▌        | 43/266 [00:42<03:11,  1.16it/s]Loading train:  17%|█▋        | 44/266 [00:43<03:03,  1.21it/s]Loading train:  17%|█▋        | 45/266 [00:44<03:02,  1.21it/s]Loading train:  17%|█▋        | 46/266 [00:44<02:52,  1.28it/s]Loading train:  18%|█▊        | 47/266 [00:45<02:47,  1.31it/s]Loading train:  18%|█▊        | 48/266 [00:46<02:52,  1.26it/s]Loading train:  18%|█▊        | 49/266 [00:47<02:48,  1.29it/s]Loading train:  19%|█▉        | 50/266 [00:47<02:42,  1.33it/s]Loading train:  19%|█▉        | 51/266 [00:48<02:45,  1.30it/s]Loading train:  20%|█▉        | 52/266 [00:49<02:42,  1.32it/s]Loading train:  20%|█▉        | 53/266 [00:50<02:39,  1.34it/s]Loading train:  20%|██        | 54/266 [00:50<02:51,  1.24it/s]Loading train:  21%|██        | 55/266 [00:51<02:47,  1.26it/s]Loading train:  21%|██        | 56/266 [00:52<02:46,  1.26it/s]Loading train:  21%|██▏       | 57/266 [00:53<02:52,  1.21it/s]Loading train:  22%|██▏       | 58/266 [00:54<02:53,  1.20it/s]Loading train:  22%|██▏       | 59/266 [00:55<02:53,  1.19it/s]Loading train:  23%|██▎       | 60/266 [00:55<02:48,  1.22it/s]Loading train:  23%|██▎       | 61/266 [00:56<02:48,  1.22it/s]Loading train:  23%|██▎       | 62/266 [00:57<02:49,  1.21it/s]Loading train:  24%|██▎       | 63/266 [00:58<02:40,  1.26it/s]Loading train:  24%|██▍       | 64/266 [00:58<02:34,  1.30it/s]Loading train:  24%|██▍       | 65/266 [00:59<02:30,  1.34it/s]Loading train:  25%|██▍       | 66/266 [01:00<02:25,  1.37it/s]Loading train:  25%|██▌       | 67/266 [01:01<02:25,  1.37it/s]Loading train:  26%|██▌       | 68/266 [01:01<02:28,  1.34it/s]Loading train:  26%|██▌       | 69/266 [01:02<02:25,  1.35it/s]Loading train:  26%|██▋       | 70/266 [01:03<02:22,  1.38it/s]Loading train:  27%|██▋       | 71/266 [01:04<02:21,  1.38it/s]Loading train:  27%|██▋       | 72/266 [01:04<02:21,  1.37it/s]Loading train:  27%|██▋       | 73/266 [01:05<02:21,  1.37it/s]Loading train:  28%|██▊       | 74/266 [01:06<02:23,  1.34it/s]Loading train:  28%|██▊       | 75/266 [01:07<02:24,  1.32it/s]Loading train:  29%|██▊       | 76/266 [01:07<02:20,  1.36it/s]Loading train:  29%|██▉       | 77/266 [01:08<02:18,  1.37it/s]Loading train:  29%|██▉       | 78/266 [01:09<02:27,  1.27it/s]Loading train:  30%|██▉       | 79/266 [01:10<02:36,  1.20it/s]Loading train:  30%|███       | 80/266 [01:11<02:37,  1.18it/s]Loading train:  30%|███       | 81/266 [01:12<02:34,  1.20it/s]Loading train:  31%|███       | 82/266 [01:12<02:38,  1.16it/s]Loading train:  31%|███       | 83/266 [01:13<02:37,  1.16it/s]Loading train:  32%|███▏      | 84/266 [01:14<02:35,  1.17it/s]Loading train:  32%|███▏      | 85/266 [01:15<02:38,  1.14it/s]Loading train:  32%|███▏      | 86/266 [01:16<02:34,  1.17it/s]Loading train:  33%|███▎      | 87/266 [01:17<02:33,  1.17it/s]Loading train:  33%|███▎      | 88/266 [01:18<02:41,  1.10it/s]Loading train:  33%|███▎      | 89/266 [01:19<02:38,  1.12it/s]Loading train:  34%|███▍      | 90/266 [01:20<02:40,  1.10it/s]Loading train:  34%|███▍      | 91/266 [01:20<02:35,  1.13it/s]Loading train:  35%|███▍      | 92/266 [01:21<02:37,  1.10it/s]Loading train:  35%|███▍      | 93/266 [01:22<02:36,  1.10it/s]Loading train:  35%|███▌      | 94/266 [01:23<02:32,  1.13it/s]Loading train:  36%|███▌      | 95/266 [01:24<02:31,  1.13it/s]Loading train:  36%|███▌      | 96/266 [01:25<02:53,  1.02s/it]Loading train:  36%|███▋      | 97/266 [01:27<03:14,  1.15s/it]
Epoch 00055: val_mDice did not improve from 0.61542
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
{'val_loss': [1.0135642301577787, 1.0140732066371503, 0.9823693000735381, 1.0018474476841779, 0.9693757070180697, 0.8340643829642198, 1.0547873845849283, 0.8246091225972543, 0.9589871980058842, 0.8647802464472942, 1.1039851798843114, 1.8168476128425353, 0.9981652013002298, 0.9332432347612504, 0.964289991137309, 0.9956309275749402, 0.8885725608620888, 0.907487419171211, 0.8364956117211244, 0.8763047034541765, 0.9157282576347009, 0.8502025329149686, 0.8945718296827414, 0.8949509882009946, 0.8653858886697353, 1.0876330477304947, 0.9223413079594954, 0.8486540239208784, 0.8645680334705573, 0.858366381090421, 0.9136638402556762, 0.8218734260552969, 0.7672300373132412, 0.8482669792496241, 0.8776612111773247, 0.9772699278516647, 0.8299391665137731, 0.7156162739564211, 0.823561911781629, 0.707032826084357, 1.0069414193813617, 0.8154225899622991, 0.8404905457909291, 0.7919188896432902, 1.1440050567571933, 0.746948704505578, 0.783518047668995, 0.786033845673769, 0.8457027639334018, 0.7100796777850542, 0.8534436168578955, 0.881381940574218, 0.9837546381048667, 0.6677907714859034, 0.7921664288792855], 'val_acc': [0.9529720949820983, 0.9558228097665005, 0.9552597755040878, 0.9539713232945173, 0.9539262893108221, 0.9568386429395431, 0.9559140793788128, 0.9568682568959701, 0.955642642118992, 0.9508420576651891, 0.9483196830902344, 0.9506073704896829, 0.9558026553728641, 0.9559828310440748, 0.9570365857619506, 0.9552313341544225, 0.955533600388429, 0.9575308618637232, 0.9572855012539105, 0.9558773346436329, 0.9576802028295321, 0.9557421986873333, 0.9586439090661514, 0.9545462078008896, 0.9558062140758221, 0.9555655989127282, 0.9558773312049035, 0.955988748715474, 0.9573601770859498, 0.95615588587064, 0.9528499967776812, 0.9575687906680963, 0.9551116140224994, 0.9548176439144672, 0.9559128972200247, 0.9546920026724155, 0.9545438446295567, 0.9572108162519259, 0.9570116851574335, 0.9567129841217628, 0.9565411129823098, 0.9563324982539202, 0.9564735511174569, 0.9570650309324265, 0.9463864003236477, 0.9560515823272558, 0.956538757452598, 0.9554126831965569, 0.9568042602294531, 0.9574846403721051, 0.9562198936175077, 0.956909750516598, 0.9562507034876407, 0.9570211714658982, 0.9548911394981238], 'val_mDice': [0.598163440441474, 0.6055960168059056, 0.6088030712726789, 0.6026777712962567, 0.6034279660536692, 0.6141765786287112, 0.5882914775075057, 0.6120427908041538, 0.6075402184938773, 0.5661095075118237, 0.542670552738202, 0.4625255608787903, 0.6079475384874221, 0.6094643496550046, 0.6154202646934069, 0.5991832375144347, 0.612179920459405, 0.6133427621844487, 0.6075801192185818, 0.6118945009433306, 0.6083577867501822, 0.5929928330274729, 0.5928943671095066, 0.6005661296538818, 0.598831122693343, 0.5814329125942328, 0.6005180781850448, 0.6028946191072464, 0.6001589252398565, 0.6020716864329118, 0.5825925054840553, 0.6062689534364603, 0.5979834571480751, 0.6001569200784732, 0.5951410010457039, 0.5790086889114135, 0.6018782494924008, 0.597238404246477, 0.5917810948613362, 0.5999122684200605, 0.5796089972823094, 0.5957765101622312, 0.5968258915803372, 0.6031360064561551, 0.5482023952481074, 0.6005414701425112, 0.5975860758469655, 0.598455049479619, 0.6024344341877179, 0.5991891452517265, 0.5870490190692437, 0.5897532403469086, 0.5824632411583875, 0.5946441017664396, 0.5979251265525818], 'loss': [1.2177244585769025, 0.42311175744728763, 0.42204587661647847, 0.3701659908059764, 0.3414403814106583, 0.3374382153147262, 0.33027434490339147, 0.3227494430324531, 0.32093499488902066, 0.3114506418976355, 0.3080709205938276, 0.3763138383470352, 0.3356658573436078, 0.29911220762677426, 0.28843638393263715, 0.33796813873805825, 0.29406479422595283, 0.27235310578847327, 0.2874534248679382, 0.2791313585719756, 0.2608225199098295, 0.28129016865706585, 0.2700291722669843, 0.2720751096566246, 0.2664383178819513, 0.2659104252003731, 0.25405308704877577, 0.2621170612240888, 0.2766723607099002, 0.25192351331465346, 0.2502588214823034, 0.2734799662456369, 0.2653538592538457, 0.24197285761658097, 0.23646849679481716, 0.2612280856233623, 0.25373869595628146, 0.2348202441796635, 0.25075166469214555, 0.2634527133817874, 0.2450233468018018, 0.23138643837279824, 0.24367936873046797, 0.23279086860949444, 0.24391086150161548, 0.25463506137616054, 0.24574403197718622, 0.23278420219733714, 0.24820907027421324, 0.23057567939734935, 0.22193242572641647, 0.22687280683543073, 0.2757282952848802, 0.2441518222246227, 0.23053243335975765], 'acc': [0.7150816970867805, 0.9346887459544662, 0.9418313057857982, 0.9469822708032821, 0.9492715508197906, 0.9499984667196881, 0.9507890038130253, 0.95048950372828, 0.9517304037494019, 0.9517329572871229, 0.9523913854198365, 0.9475361640327085, 0.9498319066121873, 0.9526965181417537, 0.9532598654159344, 0.9507419335721791, 0.9533946374398814, 0.9543591588797159, 0.9542719610459872, 0.9545012893801463, 0.9552077249003045, 0.9542560882083894, 0.9546232669199644, 0.9547734542870945, 0.9549839430916893, 0.9553465378897427, 0.9557065796215916, 0.9553071315802708, 0.9546275033326714, 0.9561190191917841, 0.956512946637464, 0.9558472462806463, 0.9553895264703863, 0.9565859108862429, 0.9569397930257527, 0.9557664455288775, 0.9561550205379796, 0.9570420150337678, 0.9570028245804463, 0.9553620409068929, 0.9568009408300479, 0.9571780970544318, 0.9567263157303383, 0.9573693949052059, 0.9568341035960846, 0.9562994867776134, 0.9561617006074088, 0.9573568413203972, 0.9561334055657581, 0.9573964661462183, 0.9578582501072227, 0.9578079693439445, 0.9547778206132254, 0.956250429336419, 0.9575220715078386], 'mDice': [0.43041189547402303, 0.646198163116138, 0.6558721080722377, 0.6813541996633157, 0.6990901806910631, 0.7045701054848594, 0.7134274432985551, 0.7132876995385513, 0.7212054985488233, 0.7220461372642578, 0.729244416259285, 0.6848366082020764, 0.7064890199170933, 0.7323033224981083, 0.7382313853960067, 0.7159372471258431, 0.7383798556433665, 0.7495545786382373, 0.7472569265495936, 0.7502206383189765, 0.758827427869367, 0.7496077072536644, 0.7539632872852794, 0.7536878503863002, 0.7557212573253628, 0.7603625397071611, 0.7646440000487328, 0.7590648884812383, 0.7511307406829433, 0.7683082161078354, 0.7725793727771951, 0.765158030114691, 0.7618269502141906, 0.7738345570502058, 0.7780643764750665, 0.763017524304951, 0.7673570233700626, 0.7792907104884039, 0.7775156746698008, 0.7621063660812446, 0.7766488451934901, 0.782190807771145, 0.7757121663186745, 0.7832394113252954, 0.7785829505867488, 0.7717313566859001, 0.7727225572653733, 0.7840282084478933, 0.7720133625241419, 0.7848361160673663, 0.7898832292052592, 0.7885784726158648, 0.7614708492470024, 0.773937751653027, 0.7856673123500263]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 1  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Loading train:  37%|███▋      | 98/266 [01:28<03:18,  1.18s/it]Loading train:  37%|███▋      | 99/266 [01:29<03:06,  1.12s/it]Loading train:  38%|███▊      | 100/266 [01:30<03:04,  1.11s/it]Loading train:  38%|███▊      | 101/266 [01:31<02:51,  1.04s/it]Loading train:  38%|███▊      | 102/266 [01:32<02:34,  1.06it/s]Loading train:  39%|███▊      | 103/266 [01:32<02:19,  1.17it/s]Loading train:  39%|███▉      | 104/266 [01:33<02:17,  1.17it/s]Loading train:  39%|███▉      | 105/266 [01:34<02:15,  1.19it/s]Loading train:  40%|███▉      | 106/266 [01:35<02:06,  1.26it/s]Loading train:  40%|████      | 107/266 [01:35<02:01,  1.31it/s]Loading train:  41%|████      | 108/266 [01:36<02:00,  1.32it/s]Loading train:  41%|████      | 109/266 [01:37<01:58,  1.33it/s]Loading train:  41%|████▏     | 110/266 [01:38<01:58,  1.32it/s]Loading train:  42%|████▏     | 111/266 [01:38<01:59,  1.30it/s]Loading train:  42%|████▏     | 112/266 [01:39<01:56,  1.32it/s]Loading train:  42%|████▏     | 113/266 [01:40<01:52,  1.37it/s]Loading train:  43%|████▎     | 114/266 [01:41<01:54,  1.33it/s]Loading train:  43%|████▎     | 115/266 [01:41<01:51,  1.36it/s]Loading train:  44%|████▎     | 116/266 [01:42<01:49,  1.37it/s]Loading train:  44%|████▍     | 117/266 [01:43<01:51,  1.33it/s]Loading train:  44%|████▍     | 118/266 [01:44<01:56,  1.28it/s]Loading train:  45%|████▍     | 119/266 [01:45<02:01,  1.21it/s]Loading train:  45%|████▌     | 120/266 [01:45<02:00,  1.21it/s]Loading train:  45%|████▌     | 121/266 [01:46<02:05,  1.15it/s]Loading train:  46%|████▌     | 122/266 [01:47<02:03,  1.17it/s]Loading train:  46%|████▌     | 123/266 [01:48<02:00,  1.18it/s]Loading train:  47%|████▋     | 124/266 [01:49<02:06,  1.12it/s]Loading train:  47%|████▋     | 125/266 [01:50<02:01,  1.16it/s]Loading train:  47%|████▋     | 126/266 [01:51<01:59,  1.17it/s]Loading train:  48%|████▊     | 127/266 [01:52<02:01,  1.15it/s]Loading train:  48%|████▊     | 128/266 [01:52<01:57,  1.17it/s]Loading train:  48%|████▊     | 129/266 [01:53<01:56,  1.18it/s]Loading train:  49%|████▉     | 130/266 [01:54<01:56,  1.17it/s]Loading train:  49%|████▉     | 131/266 [01:55<01:55,  1.17it/s]Loading train:  50%|████▉     | 132/266 [01:56<01:53,  1.18it/s]Loading train:  50%|█████     | 133/266 [01:57<01:58,  1.12it/s]Loading train:  50%|█████     | 134/266 [01:58<01:58,  1.12it/s]Loading train:  51%|█████     | 135/266 [01:59<01:54,  1.14it/s]Loading train:  51%|█████     | 136/266 [01:59<01:55,  1.13it/s]Loading train:  52%|█████▏    | 137/266 [02:00<01:57,  1.10it/s]Loading train:  52%|█████▏    | 138/266 [02:01<01:56,  1.10it/s]Loading train:  52%|█████▏    | 139/266 [02:02<01:58,  1.07it/s]Loading train:  53%|█████▎    | 140/266 [02:03<01:56,  1.09it/s]Loading train:  53%|█████▎    | 141/266 [02:04<01:52,  1.11it/s]Loading train:  53%|█████▎    | 142/266 [02:05<01:55,  1.07it/s]Loading train:  54%|█████▍    | 143/266 [02:06<01:56,  1.05it/s]Loading train:  54%|█████▍    | 144/266 [02:07<01:53,  1.07it/s]Loading train:  55%|█████▍    | 145/266 [02:08<01:52,  1.08it/s]Loading train:  55%|█████▍    | 146/266 [02:09<01:48,  1.11it/s]Loading train:  55%|█████▌    | 147/266 [02:10<01:46,  1.12it/s]Loading train:  56%|█████▌    | 148/266 [02:10<01:44,  1.13it/s]Loading train:  56%|█████▌    | 149/266 [02:11<01:42,  1.14it/s]Loading train:  56%|█████▋    | 150/266 [02:12<01:46,  1.09it/s]Loading train:  57%|█████▋    | 151/266 [02:13<01:43,  1.11it/s]Loading train:  57%|█████▋    | 152/266 [02:14<01:40,  1.14it/s]Loading train:  58%|█████▊    | 153/266 [02:15<01:41,  1.12it/s]Loading train:  58%|█████▊    | 154/266 [02:16<01:40,  1.12it/s]Loading train:  58%|█████▊    | 155/266 [02:17<01:36,  1.15it/s]Loading train:  59%|█████▊    | 156/266 [02:17<01:32,  1.19it/s]Loading train:  59%|█████▉    | 157/266 [02:18<01:24,  1.29it/s]Loading train:  59%|█████▉    | 158/266 [02:19<01:19,  1.36it/s]Loading train:  60%|█████▉    | 159/266 [02:19<01:16,  1.39it/s]Loading train:  60%|██████    | 160/266 [02:20<01:14,  1.41it/s]Loading train:  61%|██████    | 161/266 [02:21<01:11,  1.47it/s]Loading train:  61%|██████    | 162/266 [02:21<01:09,  1.49it/s]Loading train:  61%|██████▏   | 163/266 [02:22<01:10,  1.46it/s]Loading train:  62%|██████▏   | 164/266 [02:23<01:08,  1.49it/s]Loading train:  62%|██████▏   | 165/266 [02:23<01:06,  1.53it/s]Loading train:  62%|██████▏   | 166/266 [02:24<01:05,  1.53it/s]Loading train:  63%|██████▎   | 167/266 [02:25<01:05,  1.51it/s]Loading train:  63%|██████▎   | 168/266 [02:25<01:05,  1.50it/s]Loading train:  64%|██████▎   | 169/266 [02:26<01:03,  1.52it/s]Loading train:  64%|██████▍   | 170/266 [02:27<01:01,  1.55it/s]Loading train:  64%|██████▍   | 171/266 [02:27<01:02,  1.52it/s]Loading train:  65%|██████▍   | 172/266 [02:28<01:01,  1.53it/s]Loading train:  65%|██████▌   | 173/266 [02:29<01:05,  1.41it/s]Loading train:  65%|██████▌   | 174/266 [02:29<01:05,  1.41it/s]Loading train:  66%|██████▌   | 175/266 [02:30<01:04,  1.40it/s]Loading train:  66%|██████▌   | 176/266 [02:31<01:04,  1.39it/s]Loading train:  67%|██████▋   | 177/266 [02:32<01:03,  1.41it/s]Loading train:  67%|██████▋   | 178/266 [02:32<01:01,  1.42it/s]Loading train:  67%|██████▋   | 179/266 [02:33<01:00,  1.44it/s]Loading train:  68%|██████▊   | 180/266 [02:34<01:00,  1.42it/s]Loading train:  68%|██████▊   | 181/266 [02:34<01:01,  1.37it/s]Loading train:  68%|██████▊   | 182/266 [02:35<01:03,  1.31it/s]Loading train:  69%|██████▉   | 183/266 [02:36<01:02,  1.34it/s]Loading train:  69%|██████▉   | 184/266 [02:37<01:00,  1.36it/s]Loading train:  70%|██████▉   | 185/266 [02:37<00:59,  1.36it/s]Loading train:  70%|██████▉   | 186/266 [02:38<00:57,  1.39it/s]Loading train:  70%|███████   | 187/266 [02:39<00:55,  1.43it/s]Loading train:  71%|███████   | 188/266 [02:39<00:54,  1.43it/s]Loading train:  71%|███████   | 189/266 [02:40<00:52,  1.45it/s]Loading train:  71%|███████▏  | 190/266 [02:41<00:52,  1.45it/s]Loading train:  72%|███████▏  | 191/266 [02:42<01:06,  1.12it/s]Loading train:  72%|███████▏  | 192/266 [02:43<01:14,  1.01s/it]Loading train:  73%|███████▎  | 193/266 [02:45<01:16,  1.05s/it]Loading train:  73%|███████▎  | 194/266 [02:46<01:24,  1.18s/it]Loading train:  73%|███████▎  | 195/266 [02:47<01:16,  1.08s/it]Loading train:  74%|███████▎  | 196/266 [02:48<01:09,  1.00it/s]Loading train:  74%|███████▍  | 197/266 [02:49<01:04,  1.06it/s]Loading train:  74%|███████▍  | 198/266 [02:49<01:01,  1.10it/s]Loading train:  75%|███████▍  | 199/266 [02:50<00:57,  1.16it/s]Loading train:  75%|███████▌  | 200/266 [02:51<00:55,  1.19it/s]Loading train:  76%|███████▌  | 201/266 [02:52<00:53,  1.21it/s]Loading train:  76%|███████▌  | 202/266 [02:52<00:51,  1.25it/s]Loading train:  76%|███████▋  | 203/266 [02:53<00:50,  1.25it/s]Loading train:  77%|███████▋  | 204/266 [02:54<00:48,  1.27it/s]Loading train:  77%|███████▋  | 205/266 [02:55<00:47,  1.29it/s]Loading train:  77%|███████▋  | 206/266 [02:56<00:47,  1.27it/s]Loading train:  78%|███████▊  | 207/266 [02:56<00:45,  1.29it/s]Loading train:  78%|███████▊  | 208/266 [02:57<00:46,  1.25it/s]Loading train:  79%|███████▊  | 209/266 [02:58<00:44,  1.27it/s]Loading train:  79%|███████▉  | 210/266 [02:59<00:46,  1.21it/s]Loading train:  79%|███████▉  | 211/266 [03:00<00:45,  1.22it/s]Loading train:  80%|███████▉  | 212/266 [03:00<00:42,  1.28it/s]Loading train:  80%|████████  | 213/266 [03:01<00:43,  1.22it/s]Loading train:  80%|████████  | 214/266 [03:02<00:41,  1.27it/s]Loading train:  81%|████████  | 215/266 [03:03<00:40,  1.24it/s]Loading train:  81%|████████  | 216/266 [03:04<00:39,  1.28it/s]Loading train:  82%|████████▏ | 217/266 [03:04<00:37,  1.31it/s]Loading train:  82%|████████▏ | 218/266 [03:05<00:37,  1.29it/s]Loading train:  82%|████████▏ | 219/266 [03:06<00:34,  1.35it/s]Loading train:  83%|████████▎ | 220/266 [03:07<00:34,  1.33it/s]Loading train:  83%|████████▎ | 221/266 [03:07<00:34,  1.31it/s]Loading train:  83%|████████▎ | 222/266 [03:08<00:32,  1.34it/s]Loading train:  84%|████████▍ | 223/266 [03:09<00:32,  1.33it/s]Loading train:  84%|████████▍ | 224/266 [03:09<00:30,  1.37it/s]Loading train:  85%|████████▍ | 225/266 [03:10<00:30,  1.35it/s]Loading train:  85%|████████▍ | 226/266 [03:11<00:28,  1.39it/s]Loading train:  85%|████████▌ | 227/266 [03:12<00:27,  1.42it/s]Loading train:  86%|████████▌ | 228/266 [03:12<00:27,  1.41it/s]Loading train:  86%|████████▌ | 229/266 [03:13<00:26,  1.42it/s]Loading train:  86%|████████▋ | 230/266 [03:14<00:25,  1.42it/s]Loading train:  87%|████████▋ | 231/266 [03:14<00:25,  1.39it/s]Loading train:  87%|████████▋ | 232/266 [03:15<00:23,  1.42it/s]Loading train:  88%|████████▊ | 233/266 [03:16<00:22,  1.44it/s]Loading train:  88%|████████▊ | 234/266 [03:16<00:22,  1.44it/s]Loading train:  88%|████████▊ | 235/266 [03:17<00:21,  1.46it/s]Loading train:  89%|████████▊ | 236/266 [03:18<00:20,  1.43it/s]Loading train:  89%|████████▉ | 237/266 [03:19<00:20,  1.39it/s]Loading train:  89%|████████▉ | 238/266 [03:19<00:19,  1.42it/s]Loading train:  90%|████████▉ | 239/266 [03:20<00:18,  1.42it/s]Loading train:  90%|█████████ | 240/266 [03:21<00:18,  1.40it/s]Loading train:  91%|█████████ | 241/266 [03:21<00:17,  1.43it/s]Loading train:  91%|█████████ | 242/266 [03:22<00:16,  1.44it/s]Loading train:  91%|█████████▏| 243/266 [03:23<00:16,  1.42it/s]Loading train:  92%|█████████▏| 244/266 [03:24<00:15,  1.42it/s]Loading train:  92%|█████████▏| 245/266 [03:24<00:14,  1.40it/s]Loading train:  92%|█████████▏| 246/266 [03:25<00:14,  1.35it/s]Loading train:  93%|█████████▎| 247/266 [03:26<00:13,  1.38it/s]Loading train:  93%|█████████▎| 248/266 [03:26<00:13,  1.38it/s]Loading train:  94%|█████████▎| 249/266 [03:28<00:14,  1.18it/s]Loading train:  94%|█████████▍| 250/266 [03:28<00:13,  1.20it/s]Loading train:  94%|█████████▍| 251/266 [03:29<00:12,  1.17it/s]Loading train:  95%|█████████▍| 252/266 [03:30<00:11,  1.17it/s]Loading train:  95%|█████████▌| 253/266 [03:31<00:11,  1.11it/s]Loading train:  95%|█████████▌| 254/266 [03:32<00:10,  1.10it/s]Loading train:  96%|█████████▌| 255/266 [03:33<00:09,  1.12it/s]Loading train:  96%|█████████▌| 256/266 [03:34<00:09,  1.09it/s]Loading train:  97%|█████████▋| 257/266 [03:35<00:07,  1.13it/s]Loading train:  97%|█████████▋| 258/266 [03:36<00:06,  1.15it/s]Loading train:  97%|█████████▋| 259/266 [03:36<00:06,  1.16it/s]Loading train:  98%|█████████▊| 260/266 [03:37<00:05,  1.14it/s]Loading train:  98%|█████████▊| 261/266 [03:38<00:04,  1.08it/s]Loading train:  98%|█████████▊| 262/266 [03:39<00:03,  1.14it/s]Loading train:  99%|█████████▉| 263/266 [03:40<00:02,  1.14it/s]Loading train:  99%|█████████▉| 264/266 [03:41<00:01,  1.18it/s]Loading train: 100%|█████████▉| 265/266 [03:42<00:00,  1.19it/s]Loading train: 100%|██████████| 266/266 [03:43<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:00, 257.73it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:00, 237.45it/s]concatenating: train:  30%|██▉       | 79/266 [00:00<00:00, 255.67it/s]concatenating: train:  43%|████▎     | 114/266 [00:00<00:00, 277.13it/s]concatenating: train:  55%|█████▍    | 146/266 [00:00<00:00, 287.14it/s]concatenating: train:  65%|██████▍   | 172/266 [00:00<00:00, 269.96it/s]concatenating: train:  77%|███████▋  | 205/266 [00:00<00:00, 284.62it/s]concatenating: train:  88%|████████▊ | 233/266 [00:00<00:00, 278.87it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 288.71it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.27s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.23s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.19s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.13s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 134.07it/s]2019-08-17 00:50:04.450251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 00:50:04.450336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 00:50:04.450351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 00:50:04.450359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 00:50:04.450757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.79it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  6.90it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.52it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.17it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:04,  7.28it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:03,  8.28it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.14it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.23it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.86it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.05it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.98it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.52it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.77it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.75it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.80it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.98it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.12it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.39it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.01it/s]Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 192,693
Non-trainable params: 696,560
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33826393e-02 3.28503419e-02 7.68160065e-02 9.54477507e-03
 2.76247525e-02 7.22727032e-03 8.48963464e-02 1.14174347e-01
 8.96493984e-02 1.36208633e-02 2.90660983e-01 1.89281555e-01
 2.70721224e-04]
Train on 10140 samples, validate on 187 samples
Epoch 1/300
 - 19s - loss: 1.5303 - acc: 0.7694 - mDice: 0.3341 - val_loss: 0.9100 - val_acc: 0.9055 - val_mDice: 0.5008

Epoch 00001: val_mDice improved from -inf to 0.50076, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.4813 - acc: 0.8902 - mDice: 0.6067 - val_loss: 0.4811 - val_acc: 0.9186 - val_mDice: 0.6135

Epoch 00002: val_mDice improved from 0.50076 to 0.61346, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.4116 - acc: 0.8963 - mDice: 0.6518 - val_loss: 0.4577 - val_acc: 0.9239 - val_mDice: 0.6271

Epoch 00003: val_mDice improved from 0.61346 to 0.62707, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.3781 - acc: 0.9011 - mDice: 0.6741 - val_loss: 0.4310 - val_acc: 0.9314 - val_mDice: 0.6414

Epoch 00004: val_mDice improved from 0.62707 to 0.64136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 0.3586 - acc: 0.9067 - mDice: 0.6880 - val_loss: 0.4615 - val_acc: 0.9431 - val_mDice: 0.6258

Epoch 00005: val_mDice did not improve from 0.64136
Epoch 6/300
 - 14s - loss: 0.3383 - acc: 0.9221 - mDice: 0.7021 - val_loss: 0.4405 - val_acc: 0.9499 - val_mDice: 0.6348

Epoch 00006: val_mDice did not improve from 0.64136
Epoch 7/300
 - 14s - loss: 0.3196 - acc: 0.9422 - mDice: 0.7135 - val_loss: 0.4471 - val_acc: 0.9466 - val_mDice: 0.6335

Epoch 00007: val_mDice did not improve from 0.64136
Epoch 8/300
 - 14s - loss: 0.3158 - acc: 0.9435 - mDice: 0.7165 - val_loss: 0.4272 - val_acc: 0.9509 - val_mDice: 0.6454

Epoch 00008: val_mDice improved from 0.64136 to 0.64539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute0_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 15s - loss: 0.3017 - acc: 0.9448 - mDice: 0.7266 - val_loss: 0.4741 - val_acc: 0.9400 - val_mDice: 0.6164

Epoch 00009: val_mDice did not improve from 0.64539
Epoch 10/300
 - 14s - loss: 0.2937 - acc: 0.9456 - mDice: 0.7325 - val_loss: 0.4348 - val_acc: 0.9473 - val_mDice: 0.6394

Epoch 00010: val_mDice did not improve from 0.64539
Epoch 11/300
 - 14s - loss: 0.2874 - acc: 0.9462 - mDice: 0.7374 - val_loss: 0.4447 - val_acc: 0.9472 - val_mDice: 0.6346

Epoch 00011: val_mDice did not improve from 0.64539
Epoch 12/300
 - 14s - loss: 0.2817 - acc: 0.9467 - mDice: 0.7417 - val_loss: 0.4422 - val_acc: 0.9434 - val_mDice: 0.6354

Epoch 00012: val_mDice did not improve from 0.64539
Epoch 13/300
 - 14s - loss: 0.2760 - acc: 0.9473 - mDice: 0.7459 - val_loss: 0.4423 - val_acc: 0.9452 - val_mDice: 0.6346

Epoch 00013: val_mDice did not improve from 0.64539
Epoch 14/300
 - 15s - loss: 0.2694 - acc: 0.9479 - mDice: 0.7512 - val_loss: 0.4828 - val_acc: 0.9439 - val_mDice: 0.6129

Epoch 00014: val_mDice did not improve from 0.64539
Epoch 15/300
 - 15s - loss: 0.2777 - acc: 0.9471 - mDice: 0.7453 - val_loss: 0.4915 - val_acc: 0.9492 - val_mDice: 0.6166

Epoch 00015: val_mDice did not improve from 0.64539
Epoch 16/300
 - 14s - loss: 0.2644 - acc: 0.9482 - mDice: 0.7550 - val_loss: 0.4321 - val_acc: 0.9470 - val_mDice: 0.6410

Epoch 00016: val_mDice did not improve from 0.64539
Epoch 17/300
 - 14s - loss: 0.2585 - acc: 0.9488 - mDice: 0.7595 - val_loss: 0.4580 - val_acc: 0.9439 - val_mDice: 0.6252

Epoch 00017: val_mDice did not improve from 0.64539
Epoch 18/300
 - 14s - loss: 0.2543 - acc: 0.9492 - mDice: 0.7630 - val_loss: 0.4722 - val_acc: 0.9430 - val_mDice: 0.6179

Epoch 00018: val_mDice did not improve from 0.64539
Epoch 19/300
 - 14s - loss: 0.2520 - acc: 0.9495 - mDice: 0.7648 - val_loss: 0.4555 - val_acc: 0.9477 - val_mDice: 0.6317

Epoch 00019: val_mDice did not improve from 0.64539
Epoch 20/300
 - 14s - loss: 0.2467 - acc: 0.9498 - mDice: 0.7691 - val_loss: 0.4525 - val_acc: 0.9475 - val_mDice: 0.6329

Epoch 00020: val_mDice did not improve from 0.64539
Epoch 21/300
 - 14s - loss: 0.2485 - acc: 0.9497 - mDice: 0.7676 - val_loss: 0.4489 - val_acc: 0.9490 - val_mDice: 0.6336

Epoch 00021: val_mDice did not improve from 0.64539
Epoch 22/300
 - 15s - loss: 0.2420 - acc: 0.9503 - mDice: 0.7728 - val_loss: 0.4331 - val_acc: 0.9479 - val_mDice: 0.6411

Epoch 00022: val_mDice did not improve from 0.64539
Epoch 23/300
 - 15s - loss: 0.2421 - acc: 0.9503 - mDice: 0.7730 - val_loss: 0.5315 - val_acc: 0.9389 - val_mDice: 0.5879

Epoch 00023: val_mDice did not improve from 0.64539
Epoch 24/300
 - 14s - loss: 0.2412 - acc: 0.9504 - mDice: 0.7735 - val_loss: 0.4728 - val_acc: 0.9496 - val_mDice: 0.6284

Epoch 00024: val_mDice did not improve from 0.64539
Epoch 25/300
 - 14s - loss: 0.2386 - acc: 0.9506 - mDice: 0.7757 - val_loss: 0.4562 - val_acc: 0.9467 - val_mDice: 0.6295

Epoch 00025: val_mDice did not improve from 0.64539
Epoch 26/300
 - 14s - loss: 0.2335 - acc: 0.9512 - mDice: 0.7798 - val_loss: 0.4380 - val_acc: 0.9490 - val_mDice: 0.6395

Epoch 00026: val_mDice did not improve from 0.64539
Epoch 27/300
 - 14s - loss: 0.2322 - acc: 0.9512 - mDice: 0.7808 - val_loss: 0.4577 - val_acc: 0.9514 - val_mDice: 0.6326

Epoch 00027: val_mDice did not improve from 0.64539
Epoch 28/300
 - 14s - loss: 0.2422 - acc: 0.9504 - mDice: 0.7736 - val_loss: 0.4767 - val_acc: 0.9422 - val_mDice: 0.6168

Epoch 00028: val_mDice did not improve from 0.64539
Epoch 29/300
 - 15s - loss: 0.2394 - acc: 0.9507 - mDice: 0.7752 - val_loss: 0.4388 - val_acc: 0.9461 - val_mDice: 0.6372

Epoch 00029: val_mDice did not improve from 0.64539
Epoch 30/300
 - 14s - loss: 0.2267 - acc: 0.9518 - mDice: 0.7854 - val_loss: 0.4392 - val_acc: 0.9472 - val_mDice: 0.6388

Epoch 00030: val_mDice did not improve from 0.64539
Epoch 31/300
 - 14s - loss: 0.2253 - acc: 0.9520 - mDice: 0.7866 - val_loss: 0.4710 - val_acc: 0.9426 - val_mDice: 0.6173

Epoch 00031: val_mDice did not improve from 0.64539
Epoch 32/300
 - 14s - loss: 0.2229 - acc: 0.9521 - mDice: 0.7884 - val_loss: 0.4513 - val_acc: 0.9475 - val_mDice: 0.6312

Epoch 00032: val_mDice did not improve from 0.64539
Epoch 33/300
 - 14s - loss: 0.2199 - acc: 0.9524 - mDice: 0.7911 - val_loss: 0.4586 - val_acc: 0.9472 - val_mDice: 0.6293

Epoch 00033: val_mDice did not improve from 0.64539
Epoch 34/300
 - 15s - loss: 0.2198 - acc: 0.9524 - mDice: 0.7910 - val_loss: 0.4506 - val_acc: 0.9483 - val_mDice: 0.6334

Epoch 00034: val_mDice did not improve from 0.64539
Epoch 35/300
 - 14s - loss: 0.2173 - acc: 0.9525 - mDice: 0.7932 - val_loss: 0.4454 - val_acc: 0.9490 - val_mDice: 0.6362

Epoch 00035: val_mDice did not improve from 0.64539
Epoch 36/300
 - 15s - loss: 0.2171 - acc: 0.9526 - mDice: 0.7934 - val_loss: 0.4604 - val_acc: 0.9483 - val_mDice: 0.6296

Epoch 00036: val_mDice did not improve from 0.64539
Epoch 37/300
 - 15s - loss: 0.2151 - acc: 0.9528 - mDice: 0.7951 - val_loss: 0.4601 - val_acc: 0.9462 - val_mDice: 0.6262

Epoch 00037: val_mDice did not improve from 0.64539
Epoch 38/300
 - 15s - loss: 0.2148 - acc: 0.9528 - mDice: 0.7953 - val_loss: 0.4496 - val_acc: 0.9454 - val_mDice: 0.6294

Epoch 00038: val_mDice did not improve from 0.64539
Epoch 39/300
 - 14s - loss: 0.2242 - acc: 0.9527 - mDice: 0.7930 - val_loss: 0.4878 - val_acc: 0.9458 - val_mDice: 0.6129

Epoch 00039: val_mDice did not improve from 0.64539
Epoch 40/300
 - 15s - loss: 0.2119 - acc: 0.9531 - mDice: 0.7977 - val_loss: 0.4547 - val_acc: 0.9461 - val_mDice: 0.6293

Epoch 00040: val_mDice did not improve from 0.64539
Epoch 41/300
 - 14s - loss: 0.2138 - acc: 0.9531 - mDice: 0.7961 - val_loss: 0.4722 - val_acc: 0.9470 - val_mDice: 0.6194

Epoch 00041: val_mDice did not improve from 0.64539
Epoch 42/300
 - 14s - loss: 0.2105 - acc: 0.9533 - mDice: 0.7989 - val_loss: 0.5628 - val_acc: 0.9462 - val_mDice: 0.5880

Epoch 00042: val_mDice did not improve from 0.64539
Epoch 43/300
 - 15s - loss: 0.2082 - acc: 0.9534 - mDice: 0.8008 - val_loss: 0.4521 - val_acc: 0.9491 - val_mDice: 0.6318

Epoch 00043: val_mDice did not improve from 0.64539
Epoch 44/300
 - 14s - loss: 0.2079 - acc: 0.9535 - mDice: 0.8011 - val_loss: 0.4357 - val_acc: 0.9461 - val_mDice: 0.6384

Epoch 00044: val_mDice did not improve from 0.64539
Epoch 45/300
 - 15s - loss: 0.2070 - acc: 0.9536 - mDice: 0.8019 - val_loss: 0.4523 - val_acc: 0.9476 - val_mDice: 0.6329

Epoch 00045: val_mDice did not improve from 0.64539
Epoch 46/300
 - 15s - loss: 0.2062 - acc: 0.9536 - mDice: 0.8025 - val_loss: 0.4619 - val_acc: 0.9452 - val_mDice: 0.6243

Epoch 00046: val_mDice did not improve from 0.64539
Epoch 47/300
 - 14s - loss: 0.2069 - acc: 0.9535 - mDice: 0.8018 - val_loss: 0.4487 - val_acc: 0.9463 - val_mDice: 0.6315

Epoch 00047: val_mDice did not improve from 0.64539
Epoch 48/300
 - 15s - loss: 0.2047 - acc: 0.9537 - mDice: 0.8037 - val_loss: 0.4410 - val_acc: 0.9479 - val_mDice: 0.6357

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.75s/it]predicting test subjects:  40%|████      | 2/5 [00:04<00:07,  2.57s/it]predicting test subjects:  60%|██████    | 3/5 [00:06<00:04,  2.37s/it]predicting test subjects:  80%|████████  | 4/5 [00:08<00:02,  2.24s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.28s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:13,  2.77s/it]predicting train subjects:   1%|          | 2/266 [00:05<11:53,  2.70s/it]predicting train subjects:   1%|          | 3/266 [00:07<10:59,  2.51s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:12,  2.34s/it]predicting train subjects:   2%|▏         | 5/266 [00:11<10:27,  2.41s/it]predicting train subjects:   2%|▏         | 6/266 [00:14<10:45,  2.48s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<10:54,  2.53s/it]predicting train subjects:   3%|▎         | 8/266 [00:19<11:03,  2.57s/it]predicting train subjects:   3%|▎         | 9/266 [00:22<11:11,  2.61s/it]predicting train subjects:   4%|▍         | 10/266 [00:25<11:16,  2.64s/it]predicting train subjects:   4%|▍         | 11/266 [00:28<11:23,  2.68s/it]predicting train subjects:   5%|▍         | 12/266 [00:30<11:17,  2.67s/it]predicting train subjects:   5%|▍         | 13/266 [00:33<11:13,  2.66s/it]predicting train subjects:   5%|▌         | 14/266 [00:36<11:14,  2.68s/it]predicting train subjects:   6%|▌         | 15/266 [00:38<11:10,  2.67s/it]predicting train subjects:   6%|▌         | 16/266 [00:41<11:09,  2.68s/it]predicting train subjects:   6%|▋         | 17/266 [00:44<11:06,  2.68s/it]predicting train subjects:   7%|▋         | 18/266 [00:46<11:11,  2.71s/it]predicting train subjects:   7%|▋         | 19/266 [00:49<11:06,  2.70s/it]predicting train subjects:   8%|▊         | 20/266 [00:52<10:53,  2.66s/it]predicting train subjects:   8%|▊         | 21/266 [00:54<10:51,  2.66s/it]predicting train subjects:   8%|▊         | 22/266 [00:57<10:47,  2.66s/it]predicting train subjects:   9%|▊         | 23/266 [01:00<10:55,  2.70s/it]predicting train subjects:   9%|▉         | 24/266 [01:02<10:35,  2.63s/it]predicting train subjects:   9%|▉         | 25/266 [01:05<10:34,  2.63s/it]predicting train subjects:  10%|▉         | 26/266 [01:07<10:24,  2.60s/it]predicting train subjects:  10%|█         | 27/266 [01:10<10:14,  2.57s/it]predicting train subjects:  11%|█         | 28/266 [01:12<10:12,  2.57s/it]predicting train subjects:  11%|█         | 29/266 [01:15<10:00,  2.53s/it]predicting train subjects:  11%|█▏        | 30/266 [01:17<09:55,  2.52s/it]predicting train subjects:  12%|█▏        | 31/266 [01:20<09:47,  2.50s/it]predicting train subjects:  12%|█▏        | 32/266 [01:22<09:43,  2.49s/it]predicting train subjects:  12%|█▏        | 33/266 [01:25<09:43,  2.50s/it]predicting train subjects:  13%|█▎        | 34/266 [01:27<09:42,  2.51s/it]predicting train subjects:  13%|█▎        | 35/266 [01:30<09:35,  2.49s/it]predicting train subjects:  14%|█▎        | 36/266 [01:32<09:34,  2.50s/it]predicting train subjects:  14%|█▍        | 37/266 [01:35<09:28,  2.48s/it]predicting train subjects:  14%|█▍        | 38/266 [01:37<09:25,  2.48s/it]predicting train subjects:  15%|█▍        | 39/266 [01:40<09:27,  2.50s/it]predicting train subjects:  15%|█▌        | 40/266 [01:42<09:23,  2.49s/it]predicting train subjects:  15%|█▌        | 41/266 [01:45<09:24,  2.51s/it]predicting train subjects:  16%|█▌        | 42/266 [01:47<08:50,  2.37s/it]predicting train subjects:  16%|█▌        | 43/266 [01:49<08:29,  2.28s/it]predicting train subjects:  17%|█▋        | 44/266 [01:51<08:10,  2.21s/it]predicting train subjects:  17%|█▋        | 45/266 [01:53<08:01,  2.18s/it]predicting train subjects:  17%|█▋        | 46/266 [01:55<07:53,  2.15s/it]predicting train subjects:  18%|█▊        | 47/266 [01:57<07:46,  2.13s/it]predicting train subjects:  18%|█▊        | 48/266 [01:59<07:38,  2.10s/it]predicting train subjects:  18%|█▊        | 49/266 [02:01<07:36,  2.10s/it]predicting train subjects:  19%|█▉        | 50/266 [02:03<07:29,  2.08s/it]predicting train subjects:  19%|█▉        | 51/266 [02:05<07:26,  2.08s/it]predicting train subjects:  20%|█▉        | 52/266 [02:08<07:25,  2.08s/it]predicting train subjects:  20%|█▉        | 53/266 [02:10<07:23,  2.08s/it]predicting train subjects:  20%|██        | 54/266 [02:12<07:24,  2.10s/it]predicting train subjects:  21%|██        | 55/266 [02:14<07:23,  2.10s/it]predicting train subjects:  21%|██        | 56/266 [02:16<07:19,  2.09s/it]predicting train subjects:  21%|██▏       | 57/266 [02:18<07:15,  2.08s/it]predicting train subjects:  22%|██▏       | 58/266 [02:20<07:10,  2.07s/it]predicting train subjects:  22%|██▏       | 59/266 [02:22<07:10,  2.08s/it]predicting train subjects:  23%|██▎       | 60/266 [02:24<06:58,  2.03s/it]predicting train subjects:  23%|██▎       | 61/266 [02:26<06:48,  1.99s/it]predicting train subjects:  23%|██▎       | 62/266 [02:28<06:41,  1.97s/it]predicting train subjects:  24%|██▎       | 63/266 [02:30<06:35,  1.95s/it]predicting train subjects:  24%|██▍       | 64/266 [02:32<06:32,  1.94s/it]predicting train subjects:  24%|██▍       | 65/266 [02:34<06:29,  1.94s/it]predicting train subjects:  25%|██▍       | 66/266 [02:36<06:28,  1.94s/it]predicting train subjects:  25%|██▌       | 67/266 [02:38<06:28,  1.95s/it]predicting train subjects:  26%|██▌       | 68/266 [02:39<06:24,  1.94s/it]predicting train subjects:  26%|██▌       | 69/266 [02:41<06:22,  1.94s/it]predicting train subjects:  26%|██▋       | 70/266 [02:43<06:16,  1.92s/it]predicting train subjects:  27%|██▋       | 71/266 [02:45<06:16,  1.93s/it]predicting train subjects:  27%|██▋       | 72/266 [02:47<06:12,  1.92s/it]predicting train subjects:  27%|██▋       | 73/266 [02:49<06:10,  1.92s/it]predicting train subjects:  28%|██▊       | 74/266 [02:51<06:06,  1.91s/it]predicting train subjects:  28%|██▊       | 75/266 [02:53<06:03,  1.90s/it]predicting train subjects:  29%|██▊       | 76/266 [02:55<05:58,  1.89s/it]predicting train subjects:  29%|██▉       | 77/266 [02:57<05:55,  1.88s/it]predicting train subjects:  29%|██▉       | 78/266 [02:59<06:20,  2.02s/it]predicting train subjects:  30%|██▉       | 79/266 [03:01<06:45,  2.17s/it]predicting train subjects:  30%|███       | 80/266 [03:04<07:01,  2.26s/it]predicting train subjects:  30%|███       | 81/266 [03:06<07:12,  2.34s/it]predicting train subjects:  31%|███       | 82/266 [03:09<07:19,  2.39s/it]predicting train subjects:  31%|███       | 83/266 [03:11<07:26,  2.44s/it]predicting train subjects:  32%|███▏      | 84/266 [03:14<07:26,  2.46s/it]predicting train subjects:  32%|███▏      | 85/266 [03:16<07:25,  2.46s/it]predicting train subjects:  32%|███▏      | 86/266 [03:19<07:25,  2.47s/it]predicting train subjects:  33%|███▎      | 87/266 [03:21<07:20,  2.46s/it]predicting train subjects:  33%|███▎      | 88/266 [03:24<07:16,  2.45s/it]predicting train subjects:  33%|███▎      | 89/266 [03:26<07:14,  2.46s/it]predicting train subjects:  34%|███▍      | 90/266 [03:29<07:13,  2.46s/it]predicting train subjects:  34%|███▍      | 91/266 [03:31<07:10,  2.46s/it]predicting train subjects:  35%|███▍      | 92/266 [03:34<07:08,  2.46s/it]predicting train subjects:  35%|███▍      | 93/266 [03:36<07:00,  2.43s/it]predicting train subjects:  35%|███▌      | 94/266 [03:38<06:57,  2.43s/it]predicting train subjects:  36%|███▌      | 95/266 [03:41<07:00,  2.46s/it]predicting train subjects:  36%|███▌      | 96/266 [03:43<06:46,  2.39s/it]predicting train subjects:  36%|███▋      | 97/266 [03:46<06:51,  2.43s/it]predicting train subjects:  37%|███▋      | 98/266 [03:48<06:49,  2.44s/it]predicting train subjects:  37%|███▋      | 99/266 [03:50<06:14,  2.24s/it]predicting train subjects:  38%|███▊      | 100/266 [03:52<06:03,  2.19s/it]predicting train subjects:  38%|███▊      | 101/266 [03:54<05:57,  2.16s/it]predicting train subjects:  38%|███▊      | 102/266 [03:56<05:52,  2.15s/it]predicting train subjects:  39%|███▊      | 103/266 [03:58<05:51,  2.16s/it]predicting train subjects:  39%|███▉      | 104/266 [04:01<05:48,  2.15s/it]predicting train subjects:  39%|███▉      | 105/266 [04:03<05:42,  2.13s/it]predicting train subjects:  40%|███▉      | 106/266 [04:05<05:41,  2.13s/it]predicting train subjects:  40%|████      | 107/266 [04:07<05:38,  2.13s/it]predicting train subjects:  41%|████      | 108/266 [04:09<05:37,  2.14s/it]predicting train subjects:  41%|████      | 109/266 [04:11<05:36,  2.14s/it]predicting train subjects:  41%|████▏     | 110/266 [04:13<05:33,  2.14s/it]predicting train subjects:  42%|████▏     | 111/266 [04:16<05:32,  2.15s/it]predicting train subjects:  42%|████▏     | 112/266 [04:18<05:28,  2.13s/it]predicting train subjects:  42%|████▏     | 113/266 [04:20<05:26,  2.13s/it]predicting train subjects:  43%|████▎     | 114/266 [04:22<05:22,  2.12s/it]predicting train subjects:  43%|████▎     | 115/266 [04:24<05:17,  2.10s/it]predicting train subjects:  44%|████▎     | 116/266 [04:26<05:18,  2.13s/it]predicting train subjects:  44%|████▍     | 117/266 [04:28<05:21,  2.16s/it]predicting train subjects:  44%|████▍     | 118/266 [04:31<05:21,  2.17s/it]predicting train subjects:  45%|████▍     | 119/266 [04:33<05:27,  2.23s/it]predicting train subjects:  45%|████▌     | 120/266 [04:35<05:33,  2.29s/it]predicting train subjects:  45%|████▌     | 121/266 [04:38<05:46,  2.39s/it]predicting train subjects:  46%|████▌     | 122/266 [04:40<05:47,  2.41s/it]predicting train subjects:  46%|████▌     | 123/266 [04:43<05:50,  2.45s/it]predicting train subjects:  47%|████▋     | 124/266 [04:45<05:46,  2.44s/it]predicting train subjects:  47%|████▋     | 125/266 [04:48<05:45,  2.45s/it]predicting train subjects:  47%|████▋     | 126/266 [04:50<05:45,  2.47s/it]predicting train subjects:  48%|████▊     | 127/266 [04:53<05:42,  2.46s/it]predicting train subjects:  48%|████▊     | 128/266 [04:55<05:39,  2.46s/it]predicting train subjects:  48%|████▊     | 129/266 [04:58<05:38,  2.47s/it]predicting train subjects:  49%|████▉     | 130/266 [05:00<05:36,  2.47s/it]predicting train subjects:  49%|████▉     | 131/266 [05:03<05:29,  2.44s/it]predicting train subjects:  50%|████▉     | 132/266 [05:05<05:27,  2.45s/it]predicting train subjects:  50%|█████     | 133/266 [05:08<05:26,  2.46s/it]predicting train subjects:  50%|█████     | 134/266 [05:10<05:24,  2.46s/it]predicting train subjects:  51%|█████     | 135/266 [05:12<05:24,  2.48s/it]predicting train subjects:  51%|█████     | 136/266 [05:15<05:20,  2.47s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:17<05:16,  2.45s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:20<05:10,  2.43s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:22<05:13,  2.47s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:25<05:09,  2.46s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:27<05:06,  2.46s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:30<05:04,  2.46s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:32<05:01,  2.45s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:35<04:58,  2.45s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:37<05:00,  2.48s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:40<04:57,  2.48s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:42<04:51,  2.45s/it]predicting train subjects:  56%|█████▌    | 148/266 [05:44<04:45,  2.42s/it]predicting train subjects:  56%|█████▌    | 149/266 [05:47<04:42,  2.42s/it]predicting train subjects:  56%|█████▋    | 150/266 [05:49<04:41,  2.43s/it]predicting train subjects:  57%|█████▋    | 151/266 [05:52<04:38,  2.42s/it]predicting train subjects:  57%|█████▋    | 152/266 [05:54<04:35,  2.42s/it]predicting train subjects:  58%|█████▊    | 153/266 [05:56<04:34,  2.43s/it]predicting train subjects:  58%|█████▊    | 154/266 [05:59<04:31,  2.43s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:01<04:11,  2.26s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:03<03:53,  2.12s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:04<03:43,  2.05s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:06<03:33,  1.98s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:08<03:26,  1.93s/it]predicting train subjects:  60%|██████    | 160/266 [06:10<03:17,  1.87s/it]predicting train subjects:  61%|██████    | 161/266 [06:11<03:11,  1.83s/it]predicting train subjects:  61%|██████    | 162/266 [06:13<03:08,  1.81s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:15<03:06,  1.81s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:17<03:03,  1.80s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:19<03:01,  1.80s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:20<03:01,  1.81s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:22<02:59,  1.81s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:24<02:56,  1.80s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:26<02:53,  1.79s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:28<02:53,  1.80s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:30<02:54,  1.84s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:31<02:52,  1.84s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:33<02:56,  1.90s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:36<02:58,  1.94s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:38<02:58,  1.96s/it]predicting train subjects:  66%|██████▌   | 176/266 [06:40<03:01,  2.01s/it]predicting train subjects:  67%|██████▋   | 177/266 [06:42<03:00,  2.03s/it]predicting train subjects:  67%|██████▋   | 178/266 [06:44<03:01,  2.06s/it]predicting train subjects:  67%|██████▋   | 179/266 [06:46<02:57,  2.04s/it]predicting train subjects:  68%|██████▊   | 180/266 [06:48<02:56,  2.05s/it]predicting train subjects:  68%|██████▊   | 181/266 [06:50<02:57,  2.08s/it]predicting train subjects:  68%|██████▊   | 182/266 [06:52<02:53,  2.07s/it]predicting train subjects:  69%|██████▉   | 183/266 [06:54<02:48,  2.03s/it]predicting train subjects:  69%|██████▉   | 184/266 [06:56<02:48,  2.05s/it]predicting train subjects:  70%|██████▉   | 185/266 [06:58<02:46,  2.06s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:00<02:43,  2.05s/it]predicting train subjects:  70%|███████   | 187/266 [07:02<02:41,  2.04s/it]predicting train subjects:  71%|███████   | 188/266 [07:04<02:40,  2.06s/it]predicting train subjects:  71%|███████   | 189/266 [07:06<02:38,  2.06s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:09<02:36,  2.06s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:11<02:37,  2.10s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:13<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:15<02:29,  2.05s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:17<02:37,  2.19s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:19<02:34,  2.18s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:22<02:33,  2.19s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:24<02:33,  2.23s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:26<02:30,  2.21s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:28<02:28,  2.22s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:31<02:25,  2.21s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:33<02:24,  2.23s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:35<02:23,  2.24s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:37<02:21,  2.25s/it]predicting train subjects:  77%|███████▋  | 204/266 [07:39<02:17,  2.22s/it]predicting train subjects:  77%|███████▋  | 205/266 [07:42<02:14,  2.21s/it]predicting train subjects:  77%|███████▋  | 206/266 [07:44<02:13,  2.22s/it]predicting train subjects:  78%|███████▊  | 207/266 [07:46<02:11,  2.23s/it]predicting train subjects:  78%|███████▊  | 208/266 [07:48<02:09,  2.23s/it]predicting train subjects:  79%|███████▊  | 209/266 [07:51<02:06,  2.23s/it]predicting train subjects:  79%|███████▉  | 210/266 [07:53<02:03,  2.21s/it]predicting train subjects:  79%|███████▉  | 211/266 [07:55<02:00,  2.19s/it]predicting train subjects:  80%|███████▉  | 212/266 [07:57<01:57,  2.17s/it]predicting train subjects:  80%|████████  | 213/266 [07:59<01:51,  2.11s/it]predicting train subjects:  80%|████████  | 214/266 [08:01<01:47,  2.07s/it]predicting train subjects:  81%|████████  | 215/266 [08:03<01:44,  2.04s/it]predicting train subjects:  81%|████████  | 216/266 [08:05<01:39,  1.99s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:07<01:36,  1.98s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:09<01:33,  1.96s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:11<01:31,  1.95s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:13<01:29,  1.95s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:15<01:27,  1.95s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:16<01:25,  1.94s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:18<01:24,  1.96s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:20<01:22,  1.95s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:22<01:19,  1.94s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:24<01:17,  1.94s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:26<01:14,  1.92s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:28<01:13,  1.94s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:30<01:11,  1.93s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:32<01:09,  1.94s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:34<01:08,  1.96s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:36<01:06,  1.96s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:38<01:03,  1.94s/it]predicting train subjects:  88%|████████▊ | 234/266 [08:40<01:01,  1.93s/it]predicting train subjects:  88%|████████▊ | 235/266 [08:42<01:00,  1.95s/it]predicting train subjects:  89%|████████▊ | 236/266 [08:44<00:57,  1.93s/it]predicting train subjects:  89%|████████▉ | 237/266 [08:46<00:56,  1.93s/it]predicting train subjects:  89%|████████▉ | 238/266 [08:48<00:54,  1.95s/it]predicting train subjects:  90%|████████▉ | 239/266 [08:50<00:52,  1.96s/it]predicting train subjects:  90%|█████████ | 240/266 [08:51<00:50,  1.96s/it]predicting train subjects:  91%|█████████ | 241/266 [08:53<00:48,  1.95s/it]predicting train subjects:  91%|█████████ | 242/266 [08:55<00:46,  1.95s/it]predicting train subjects:  91%|█████████▏| 243/266 [08:57<00:44,  1.95s/it]predicting train subjects:  92%|█████████▏| 244/266 [08:59<00:42,  1.94s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:01<00:40,  1.94s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:03<00:38,  1.95s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:05<00:37,  1.96s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:07<00:35,  1.96s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:10<00:36,  2.16s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:12<00:36,  2.25s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:15<00:34,  2.32s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:17<00:33,  2.36s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:20<00:31,  2.40s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:22<00:29,  2.43s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:25<00:27,  2.47s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:27<00:24,  2.47s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:30<00:22,  2.46s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:32<00:19,  2.48s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:35<00:17,  2.49s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:37<00:15,  2.50s/it]predicting train subjects:  98%|█████████▊| 261/266 [09:40<00:12,  2.53s/it]predicting train subjects:  98%|█████████▊| 262/266 [09:42<00:10,  2.53s/it]predicting train subjects:  99%|█████████▉| 263/266 [09:45<00:07,  2.51s/it]predicting train subjects:  99%|█████████▉| 264/266 [09:47<00:05,  2.50s/it]predicting train subjects: 100%|█████████▉| 265/266 [09:50<00:02,  2.48s/it]predicting train subjects: 100%|██████████| 266/266 [09:52<00:00,  2.47s/it]

Epoch 00048: val_mDice did not improve from 0.64539
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [0.9100041198220482, 0.4811150124047529, 0.45770910796634656, 0.43102571129161404, 0.4614843045645219, 0.44046009335925873, 0.44709233007329036, 0.42718297067810507, 0.4740926769965473, 0.4348458587167097, 0.44474594287056335, 0.4422384001673224, 0.44230414026561266, 0.4828305185478639, 0.4915228089228033, 0.43209567921046904, 0.4579532702657628, 0.4722386236815529, 0.4554617129226419, 0.45246510470614715, 0.4489100687006578, 0.43311645353541656, 0.5314724555308806, 0.4728300824841076, 0.4562205822072565, 0.4380170331600516, 0.4577019796333211, 0.4767176550339888, 0.4387719830408453, 0.43918844643123645, 0.47097431035602794, 0.4513149736399319, 0.45857013722154544, 0.4505676525161866, 0.44539695213185276, 0.4604099786536579, 0.4601454027196303, 0.4496132814310451, 0.4878030175512487, 0.4547248329708283, 0.4722306911639351, 0.5628326850778916, 0.452136932369222, 0.4357194709267846, 0.452342167895108, 0.4618559618365956, 0.44865463028617086, 0.44101417383408165], 'val_acc': [0.9054688059072443, 0.9185858091568564, 0.9238843254864535, 0.9313765372184508, 0.9430677505100474, 0.9499047832055525, 0.946606284794323, 0.9508809173170896, 0.9399907608083226, 0.947322481137546, 0.9472190294673736, 0.9433741445209891, 0.9452335691069537, 0.9438807693394747, 0.9492005141661128, 0.9470214097895087, 0.9438635187353043, 0.943045209754597, 0.9477296653278371, 0.9474736742157349, 0.9489551604112839, 0.9478622939497392, 0.9389204580516102, 0.9496355385066354, 0.9466845488803272, 0.9490108477240577, 0.9514154103350512, 0.9421592504582941, 0.9460837197176275, 0.9472150576305899, 0.9426433517333658, 0.9474551151780521, 0.947233632924085, 0.9483331065764402, 0.9490400399753754, 0.948331793680548, 0.9461924787511162, 0.9453794784086911, 0.9457959395678923, 0.9460903664323735, 0.9470028650951895, 0.9462349134332994, 0.9491036798864763, 0.9460664911066147, 0.9475612197330291, 0.9451566437348963, 0.9462760578502308, 0.9478781876717022], 'val_mDice': [0.5007581165767608, 0.6134569740550403, 0.6270721220077677, 0.641361121187873, 0.625844716388274, 0.6348474121348743, 0.6335037054225086, 0.6453895256481069, 0.6164346232133753, 0.6394272500818426, 0.6346495897374689, 0.6354216898188871, 0.6346474203833922, 0.612854418588832, 0.6166013960532326, 0.6410113834442301, 0.625214019242455, 0.617908893103268, 0.6316975702576458, 0.6329448672539411, 0.6335751952972004, 0.6411018020966474, 0.5878602065504553, 0.6283600795715251, 0.629489249086635, 0.6395273199055922, 0.6326399448721166, 0.6168173379439084, 0.6372452916946003, 0.6388007462980912, 0.6172894717537784, 0.6311837326396595, 0.6293277469548312, 0.6334214841618258, 0.6361943859467531, 0.6295940095090611, 0.6262452044588996, 0.6293604966790919, 0.612948187532272, 0.6293100201509854, 0.6194234433021137, 0.587960954655938, 0.6318438818110502, 0.6383624736637993, 0.6329128640220765, 0.6243187163602859, 0.6314550211085356, 0.6357419022264328], 'loss': [1.530256134283378, 0.48133395027361914, 0.4116451929835878, 0.3781056638652756, 0.3585945889206798, 0.33829978049624365, 0.31957982606906626, 0.31575473005602345, 0.3017301402207192, 0.2937282548383378, 0.2873667772469906, 0.2816704928404716, 0.27604842438735433, 0.2694474406378744, 0.277689219344062, 0.2643926461361334, 0.2585373264269011, 0.25426343334673424, 0.25195544448183366, 0.2466973743495151, 0.24850695611104456, 0.24199190428682568, 0.2420806636706847, 0.24117738253912746, 0.23862663106864257, 0.2335109128313657, 0.23224864290252004, 0.24222782824401554, 0.2394093301081093, 0.22666225206158336, 0.22530549641191608, 0.22294856158233958, 0.21985711075027548, 0.21982990311094996, 0.2172973371998093, 0.21710720290916677, 0.21510924391551367, 0.214754646419891, 0.2241796448356536, 0.21192239136738183, 0.21379042521148509, 0.2104879004597899, 0.20820677835913098, 0.20788291984291002, 0.20698110732806504, 0.2061827364846094, 0.20694284946372993, 0.20471757525464251], 'acc': [0.7694419226306077, 0.890216800294214, 0.8963493954030249, 0.9011033058636757, 0.9067035464375212, 0.9220742704365146, 0.9422204449214409, 0.9434522588459933, 0.9448326856074248, 0.9455575564439009, 0.9461512529755955, 0.9467293921071867, 0.9472772293894954, 0.9479266937079984, 0.9471122299190574, 0.9482006622842077, 0.9488094743539596, 0.949232153873707, 0.9495250514508234, 0.9498268774392807, 0.949744915468453, 0.9502557464957943, 0.950325747037075, 0.9503836887475301, 0.9506288451203228, 0.9511734041471688, 0.9512038079239208, 0.9503849628408985, 0.9507093397235494, 0.9517930518593308, 0.9519790639068483, 0.9520709333570281, 0.9523819552135656, 0.9523990515773818, 0.9525387874956902, 0.9526437408707786, 0.9527830357499847, 0.9528470727701394, 0.9527092435538651, 0.9530860120963298, 0.9530632903237315, 0.9533254176789722, 0.9534370975616651, 0.9534625834849695, 0.9535899920576423, 0.9536275885984508, 0.9535387531069844, 0.9537448940662707], 'mDice': [0.33409434158898726, 0.6067306533955493, 0.6517620803218857, 0.674089484489881, 0.6880122655359716, 0.7020580578720311, 0.7134603253130377, 0.7165408653502868, 0.7266002821734201, 0.7325445198448453, 0.7373642887354367, 0.7416961010861444, 0.7459020121445552, 0.7511699213196305, 0.7452681818187119, 0.7550453177453028, 0.7595414388814622, 0.7629988975896402, 0.7648087100399552, 0.7691479646830399, 0.7676446744088355, 0.7728389072465238, 0.7730039661452615, 0.7735279620986953, 0.7757297202327548, 0.7797646584830575, 0.780808507161733, 0.773591041447378, 0.7751874120748019, 0.7853508146086623, 0.7865765546200544, 0.7884187141113733, 0.791077738153864, 0.7910116719306103, 0.7932208504314724, 0.7934300034238977, 0.7950695088276496, 0.7952792159551699, 0.7930358166290223, 0.7976685436166955, 0.7961349470257995, 0.7989091472277745, 0.8007811443692834, 0.8010573425354102, 0.8018786301156708, 0.8025381730858391, 0.8018316179220023, 0.8037437576749151]}
