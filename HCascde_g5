*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/147) train vimp2_668_02282013_CD_MS
     Bias Correction
     Rigid Registration
(1/147) train vimp2_765_04162013_AW_MS
     Bias Correction
     Rigid Registration
(2/147) train vimp2_819_05172013_DS_MS
     Bias Correction
     Rigid Registration
(3/147) train vimp2_823_05202013_AJ_MS
     Bias Correction
     Rigid Registration
(4/147) train vimp2_824_05212013_JS_MS
     Bias Correction
     Rigid Registration
(5/147) train vimp2_845_05312013_VZ_MS
     Bias Correction
     Rigid Registration
(6/147) train vimp2_884_06272013_TS_MS
     Bias Correction
     Rigid Registration
(7/147) train vimp2_901_07052013_AS_MS
     Bias Correction
     Rigid Registration
(8/147) train vimp2_943_07242013_PA_MS
     Bias Correction
     Rigid Registration
(9/147) train vimp2_964_08092013_TG_MS
     Bias Correction
     Rigid Registration
(10/147) train vimp2_967_08132013_KW_MS
     Bias Correction
     Rigid Registration
(11/147) train vimp2_972_08152013_DC_MS
     Bias Correction
     Rigid Registration
(12/147) train vimp2_ANON606_20130110_control
     Bias Correction
     Rigid Registration
(13/147) train vimp2_ANON695_03132013_control
     Bias Correction
     Rigid Registration
(14/147) train vimp2_ANON702_03152013_control
     Bias Correction
     Rigid Registration
(15/147) train vimp2_ANON724_03272013_control
     Bias Correction
     Rigid Registration
(16/147) train vimp2_ctrl_902_07052013_SI
     Bias Correction
     Rigid Registration
(17/147) train vimp2_ctrl_918_07112013_TQ
     Bias Correction
     Rigid Registration
(18/147) train vimp2_ctrl_920_07122013_SW
     Bias Correction
     Rigid Registration
(19/147) train vimp2_ctrl_921_07122013_MP
     Bias Correction
     Rigid Registration
(20/147) train vimp2_ctrl_991_08302013_JF
     Bias Correction
     Rigid Registration
(21/147) train vimp2_668_02282013_CD_MS_Aug0_Rot_-2
     Bias Correction
(22/147) train vimp2_668_02282013_CD_MS_Aug1_Rot_-7
     Bias Correction
(23/147) train vimp2_668_02282013_CD_MS_Aug2_Rot_-5
     Bias Correction
(24/147) train vimp2_668_02282013_CD_MS_Aug3_Rot_7
     Bias Correction
(25/147) train vimp2_668_02282013_CD_MS_Aug4_Rot_5
     Bias Correction
(26/147) train vimp2_668_02282013_CD_MS_Aug5_Rot_-1
     Bias Correction
(27/147) train vimp2_765_04162013_AW_MS_Aug0_Rot_1
     Bias Correction
(28/147) train vimp2_765_04162013_AW_MS_Aug1_Rot_4
     Bias Correction
(29/147) train vimp2_765_04162013_AW_MS_Aug2_Rot_-5
     Bias Correction
(30/147) train vimp2_765_04162013_AW_MS_Aug3_Rot_6
     Bias Correction
(31/147) train vimp2_765_04162013_AW_MS_Aug4_Rot_4
     Bias Correction
(32/147) train vimp2_765_04162013_AW_MS_Aug5_Rot_-7
     Bias Correction
(33/147) train vimp2_819_05172013_DS_MS_Aug0_Rot_5
     Bias Correction
(34/147) train vimp2_819_05172013_DS_MS_Aug1_Rot_6
     Bias Correction
(35/147) train vimp2_819_05172013_DS_MS_Aug2_Rot_-6
     Bias Correction
(36/147) train vimp2_819_05172013_DS_MS_Aug3_Rot_-4
     Bias Correction
(37/147) train vimp2_819_05172013_DS_MS_Aug4_Rot_4
     Bias Correction
(38/147) train vimp2_819_05172013_DS_MS_Aug5_Rot_-7
     Bias Correction
(39/147) train vimp2_823_05202013_AJ_MS_Aug0_Rot_1
     Bias Correction
(40/147) train vimp2_823_05202013_AJ_MS_Aug1_Rot_2
     Bias Correction
(41/147) train vimp2_823_05202013_AJ_MS_Aug2_Rot_-7
     Bias Correction
(42/147) train vimp2_823_05202013_AJ_MS_Aug3_Rot_-7
     Bias Correction
(43/147) train vimp2_823_05202013_AJ_MS_Aug4_Rot_1
     Bias Correction
(44/147) train vimp2_823_05202013_AJ_MS_Aug5_Rot_-3
     Bias Correction
(45/147) train vimp2_824_05212013_JS_MS_Aug0_Rot_-4
     Bias Correction
(46/147) train vimp2_824_05212013_JS_MS_Aug1_Rot_2
     Bias Correction
(47/147) train vimp2_824_05212013_JS_MS_Aug2_Rot_1
     Bias Correction
(48/147) train vimp2_824_05212013_JS_MS_Aug3_Rot_6
     Bias Correction
(49/147) train vimp2_824_05212013_JS_MS_Aug4_Rot_-4
     Bias Correction
(50/147) train vimp2_824_05212013_JS_MS_Aug5_Rot_7
     Bias Correction
(51/147) train vimp2_845_05312013_VZ_MS_Aug0_Rot_-5
     Bias Correction
(52/147) train vimp2_845_05312013_VZ_MS_Aug1_Rot_-6
     Bias Correction
(53/147) train vimp2_845_05312013_VZ_MS_Aug2_Rot_-4
     Bias Correction
(54/147) train vimp2_845_05312013_VZ_MS_Aug3_Rot_7
     Bias Correction
(55/147) train vimp2_845_05312013_VZ_MS_Aug4_Rot_2
     Bias Correction
(56/147) train vimp2_845_05312013_VZ_MS_Aug5_Rot_4
     Bias Correction
(57/147) train vimp2_884_06272013_TS_MS_Aug0_Rot_1
     Bias Correction
(58/147) train vimp2_884_06272013_TS_MS_Aug1_Rot_-7
     Bias Correction
(59/147) train vimp2_884_06272013_TS_MS_Aug2_Rot_-5
     Bias Correction
(60/147) train vimp2_884_06272013_TS_MS_Aug3_Rot_-5
     Bias Correction
(61/147) train vimp2_884_06272013_TS_MS_Aug4_Rot_-3
     Bias Correction
(62/147) train vimp2_884_06272013_TS_MS_Aug5_Rot_2
     Bias Correction
(63/147) train vimp2_901_07052013_AS_MS_Aug0_Rot_5
     Bias Correction
(64/147) train vimp2_901_07052013_AS_MS_Aug1_Rot_4
     Bias Correction
(65/147) train vimp2_901_07052013_AS_MS_Aug2_Rot_1
     Bias Correction
(66/147) train vimp2_901_07052013_AS_MS_Aug3_Rot_-1
     Bias Correction
(67/147) train vimp2_901_07052013_AS_MS_Aug4_Rot_3
     Bias Correction
(68/147) train vimp2_901_07052013_AS_MS_Aug5_Rot_7
     Bias Correction
(69/147) train vimp2_943_07242013_PA_MS_Aug0_Rot_-2
     Bias Correction
(70/147) train vimp2_943_07242013_PA_MS_Aug1_Rot_-7
     Bias Correction
(71/147) train vimp2_943_07242013_PA_MS_Aug2_Rot_-4
     Bias Correction
(72/147) train vimp2_943_07242013_PA_MS_Aug3_Rot_5
     Bias Correction
(73/147) train vimp2_943_07242013_PA_MS_Aug4_Rot_3
     Bias Correction
(74/147) train vimp2_943_07242013_PA_MS_Aug5_Rot_-2
     Bias Correction
(75/147) train vimp2_964_08092013_TG_MS_Aug0_Rot_-4
     Bias Correction
(76/147) train vimp2_964_08092013_TG_MS_Aug1_Rot_2
     Bias Correction
(77/147) train vimp2_964_08092013_TG_MS_Aug2_Rot_-4
     Bias Correction
(78/147) train vimp2_964_08092013_TG_MS_Aug3_Rot_5
     Bias Correction
(79/147) train vimp2_964_08092013_TG_MS_Aug4_Rot_6
     Bias Correction
(80/147) train vimp2_964_08092013_TG_MS_Aug5_Rot_-1
     Bias Correction
(81/147) train vimp2_967_08132013_KW_MS_Aug0_Rot_2
     Bias Correction
(82/147) train vimp2_967_08132013_KW_MS_Aug1_Rot_3
     Bias Correction
(83/147) train vimp2_967_08132013_KW_MS_Aug2_Rot_-1
     Bias Correction
(84/147) train vimp2_967_08132013_KW_MS_Aug3_Rot_4
     Bias Correction
(85/147) train vimp2_967_08132013_KW_MS_Aug4_Rot_7
     Bias Correction
(86/147) train vimp2_967_08132013_KW_MS_Aug5_Rot_-5
     Bias Correction
(87/147) train vimp2_972_08152013_DC_MS_Aug0_Rot_-6
     Bias Correction
(88/147) train vimp2_972_08152013_DC_MS_Aug1_Rot_1
     Bias Correction
(89/147) train vimp2_972_08152013_DC_MS_Aug2_Rot_2
     Bias Correction
(90/147) train vimp2_972_08152013_DC_MS_Aug3_Rot_-5
     Bias Correction
(91/147) train vimp2_972_08152013_DC_MS_Aug4_Rot_1
     Bias Correction
(92/147) train vimp2_972_08152013_DC_MS_Aug5_Rot_-4
     Bias Correction
(93/147) train vimp2_ANON606_20130110_control_Aug0_Rot_-2
     Bias Correction
(94/147) train vimp2_ANON606_20130110_control_Aug1_Rot_7
     Bias Correction
(95/147) train vimp2_ANON606_20130110_control_Aug2_Rot_-2
     Bias Correction
(96/147) train vimp2_ANON606_20130110_control_Aug3_Rot_4
     Bias Correction
(97/147) train vimp2_ANON606_20130110_control_Aug4_Rot_-5
     Bias Correction
(98/147) train vimp2_ANON606_20130110_control_Aug5_Rot_-3
     Bias Correction
(99/147) train vimp2_ANON695_03132013_control_Aug0_Rot_7
     Bias Correction
(100/147) train vimp2_ANON695_03132013_control_Aug1_Rot_2
     Bias Correction
(101/147) train vimp2_ANON695_03132013_control_Aug2_Rot_-1
     Bias Correction
(102/147) train vimp2_ANON695_03132013_control_Aug3_Rot_1
     Bias Correction
(103/147) train vimp2_ANON695_03132013_control_Aug4_Rot_-2
     Bias Correction
(104/147) train vimp2_ANON695_03132013_control_Aug5_Rot_2
     Bias Correction
(105/147) train vimp2_ANON702_03152013_control_Aug0_Rot_1
     Bias Correction
(106/147) train vimp2_ANON702_03152013_control_Aug1_Rot_-6
     Bias Correction2019-04-02 22:00:34.537610: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-04-02 22:00:38.201040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-04-02 22:00:38.201109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-04-02 22:00:38.594690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-02 22:00:38.594761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-04-02 22:00:38.594774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-04-02 22:00:38.595238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
Using TensorFlow backend.
Loading Dataset: train:   0%|          | 0/147 [00:00<?, ?it/s]Loading Dataset: train:   1%|          | 1/147 [00:00<00:18,  7.71it/s]Loading Dataset: train:   1%|▏         | 2/147 [00:00<00:18,  7.80it/s]Loading Dataset: train:   2%|▏         | 3/147 [00:00<00:18,  7.98it/s]Loading Dataset: train:   3%|▎         | 5/147 [00:00<00:16,  8.58it/s]Loading Dataset: train:   4%|▍         | 6/147 [00:00<00:16,  8.55it/s]Loading Dataset: train:   5%|▍         | 7/147 [00:00<00:17,  8.12it/s]Loading Dataset: train:   6%|▌         | 9/147 [00:01<00:15,  8.76it/s]Loading Dataset: train:   7%|▋         | 11/147 [00:01<00:14,  9.22it/s]Loading Dataset: train:   9%|▉         | 13/147 [00:01<00:13, 10.09it/s]Loading Dataset: train:  10%|█         | 15/147 [00:01<00:13,  9.98it/s]Loading Dataset: train:  12%|█▏        | 17/147 [00:01<00:12, 10.27it/s]Loading Dataset: train:  13%|█▎        | 19/147 [00:01<00:12, 10.18it/s]Loading Dataset: train:  14%|█▍        | 21/147 [00:02<00:12, 10.43it/s]Loading Dataset: train:  16%|█▌        | 23/147 [00:02<00:12,  9.92it/s]Loading Dataset: train:  17%|█▋        | 25/147 [00:02<00:12,  9.51it/s]Loading Dataset: train:  18%|█▊        | 26/147 [00:02<00:12,  9.51it/s]Loading Dataset: train:  18%|█▊        | 27/147 [00:02<00:13,  9.06it/s]Loading Dataset: train:  19%|█▉        | 28/147 [00:02<00:13,  8.88it/s]Loading Dataset: train:  20%|█▉        | 29/147 [00:03<00:13,  9.06it/s]Loading Dataset: train:  20%|██        | 30/147 [00:03<00:13,  8.97it/s]Loading Dataset: train:  21%|██        | 31/147 [00:03<00:12,  9.07it/s]Loading Dataset: train:  22%|██▏       | 32/147 [00:03<00:12,  9.11it/s]Loading Dataset: train:  22%|██▏       | 33/147 [00:03<00:12,  9.26it/s]Loading Dataset: train:  23%|██▎       | 34/147 [00:03<00:12,  9.14it/s]Loading Dataset: train:  24%|██▍       | 35/147 [00:03<00:12,  9.28it/s]Loading Dataset: train:  24%|██▍       | 36/147 [00:03<00:11,  9.46it/s]Loading Dataset: train:  25%|██▌       | 37/147 [00:03<00:11,  9.58it/s]Loading Dataset: train:  26%|██▌       | 38/147 [00:03<00:11,  9.32it/s]Loading Dataset: train:  27%|██▋       | 39/147 [00:04<00:11,  9.43it/s]Loading Dataset: train:  27%|██▋       | 40/147 [00:04<00:11,  9.45it/s]Loading Dataset: train:  29%|██▊       | 42/147 [00:04<00:10,  9.64it/s]Loading Dataset: train:  30%|██▉       | 44/147 [00:04<00:10,  9.75it/s]Loading Dataset: train:  31%|███       | 45/147 [00:04<00:10,  9.36it/s]Loading Dataset: train:  31%|███▏      | 46/147 [00:04<00:11,  8.90it/s]Loading Dataset: train:  32%|███▏      | 47/147 [00:04<00:11,  8.68it/s]Loading Dataset: train:  33%|███▎      | 48/147 [00:05<00:11,  8.74it/s]Loading Dataset: train:  33%|███▎      | 49/147 [00:05<00:11,  8.76it/s]Loading Dataset: train:  34%|███▍      | 50/147 [00:05<00:11,  8.75it/s]Loading Dataset: train:  35%|███▍      | 51/147 [00:05<00:11,  8.61it/s]Loading Dataset: train:  35%|███▌      | 52/147 [00:05<00:11,  8.26it/s]Loading Dataset: train:  36%|███▌      | 53/147 [00:05<00:11,  8.16it/s]Loading Dataset: train:  37%|███▋      | 54/147 [00:05<00:11,  8.17it/s]Loading Dataset: train:  37%|███▋      | 55/147 [00:05<00:11,  8.18it/s]Loading Dataset: train:  38%|███▊      | 56/147 [00:06<00:11,  7.89it/s]Loading Dataset: train:  39%|███▉      | 57/147 [00:06<00:11,  7.98it/s]Loading Dataset: train:  39%|███▉      | 58/147 [00:06<00:11,  7.46it/s]Loading Dataset: train:  40%|████      | 59/147 [00:06<00:12,  7.29it/s]Loading Dataset: train:  41%|████      | 60/147 [00:06<00:12,  7.13it/s]Loading Dataset: train:  41%|████▏     | 61/147 [00:06<00:11,  7.18it/s]Loading Dataset: train:  42%|████▏     | 62/147 [00:06<00:11,  7.50it/s]Loading Dataset: train:  43%|████▎     | 63/147 [00:07<00:10,  7.68it/s]Loading Dataset: train:  44%|████▍     | 65/147 [00:07<00:09,  8.64it/s]Loading Dataset: train:  46%|████▌     | 67/147 [00:07<00:08,  9.36it/s]Loading Dataset: train:  47%|████▋     | 69/147 [00:07<00:07, 10.10it/s]Loading Dataset: train:  48%|████▊     | 71/147 [00:07<00:07,  9.94it/s]Loading Dataset: train:  50%|████▉     | 73/147 [00:07<00:07, 10.10it/s]Loading Dataset: train:  51%|█████     | 75/147 [00:08<00:07, 10.05it/s]Loading Dataset: train:  52%|█████▏    | 77/147 [00:08<00:06, 10.20it/s]Loading Dataset: train:  54%|█████▎    | 79/147 [00:08<00:06, 10.49it/s]Loading Dataset: train:  55%|█████▌    | 81/147 [00:08<00:06, 10.53it/s]Loading Dataset: train:  56%|█████▋    | 83/147 [00:08<00:06, 10.25it/s]Loading Dataset: train:  58%|█████▊    | 85/147 [00:09<00:05, 10.38it/s]Loading Dataset: train:  59%|█████▉    | 87/147 [00:09<00:05, 10.49it/s]Loading Dataset: train:  61%|██████    | 89/147 [00:09<00:05, 10.53it/s]Loading Dataset: train:  62%|██████▏   | 91/147 [00:09<00:05, 10.58it/s]Loading Dataset: train:  63%|██████▎   | 93/147 [00:09<00:05, 10.64it/s]Loading Dataset: train:  65%|██████▍   | 95/147 [00:09<00:04, 11.27it/s]Loading Dataset: train:  66%|██████▌   | 97/147 [00:10<00:04, 12.15it/s]Loading Dataset: train:  67%|██████▋   | 99/147 [00:10<00:03, 12.74it/s]Loading Dataset: train:  69%|██████▊   | 101/147 [00:10<00:03, 11.93it/s]Loading Dataset: train:  70%|███████   | 103/147 [00:10<00:03, 11.45it/s]Loading Dataset: train:  71%|███████▏  | 105/147 [00:10<00:03, 10.93it/s]Loading Dataset: train:  73%|███████▎  | 107/147 [00:11<00:03, 10.66it/s]Loading Dataset: train:  74%|███████▍  | 109/147 [00:11<00:03, 10.48it/s]Loading Dataset: train:  76%|███████▌  | 111/147 [00:11<00:03, 10.45it/s]Loading Dataset: train:  77%|███████▋  | 113/147 [00:11<00:03, 11.18it/s]Loading Dataset: train:  78%|███████▊  | 115/147 [00:11<00:02, 12.06it/s]Loading Dataset: train:  80%|███████▉  | 117/147 [00:11<00:02, 12.67it/s]Loading Dataset: train:  81%|████████  | 119/147 [00:12<00:02, 11.24it/s]Loading Dataset: train:  82%|████████▏ | 121/147 [00:12<00:02, 10.57it/s]Loading Dataset: train:  84%|████████▎ | 123/147 [00:12<00:02, 10.14it/s]Loading Dataset: train:  85%|████████▌ | 125/147 [00:12<00:02,  9.60it/s]Loading Dataset: train:  86%|████████▌ | 126/147 [00:12<00:02,  9.37it/s]Loading Dataset: train:  86%|████████▋ | 127/147 [00:12<00:02,  9.29it/s]Loading Dataset: train:  87%|████████▋ | 128/147 [00:13<00:02,  9.16it/s]Loading Dataset: train:  88%|████████▊ | 129/147 [00:13<00:02,  8.93it/s]Loading Dataset: train:  88%|████████▊ | 130/147 [00:13<00:01,  9.11it/s]Loading Dataset: train:  90%|████████▉ | 132/147 [00:13<00:01,  9.47it/s]Loading Dataset: train:  91%|█████████ | 134/147 [00:13<00:01,  9.68it/s]Loading Dataset: train:  92%|█████████▏| 135/147 [00:13<00:01,  9.68it/s]Loading Dataset: train:  93%|█████████▎| 137/147 [00:13<00:00, 10.26it/s]Loading Dataset: train:  95%|█████████▍| 139/147 [00:14<00:00, 10.95it/s]Loading Dataset: train:  96%|█████████▌| 141/147 [00:14<00:00, 11.30it/s]Loading Dataset: train:  97%|█████████▋| 143/147 [00:14<00:00, 10.80it/s]Loading Dataset: train:  99%|█████████▊| 145/147 [00:14<00:00, 10.45it/s]Loading Dataset: train: 100%|██████████| 147/147 [00:14<00:00, 10.38it/s]
concatenating train images:   0%|          | 0/133 [00:00<?, ?it/s]concatenating train images:   5%|▌         | 7/133 [00:00<00:01, 69.67it/s]concatenating train images:  11%|█         | 14/133 [00:00<00:01, 68.25it/s]concatenating train images:  16%|█▌        | 21/133 [00:00<00:01, 68.28it/s]concatenating train images:  21%|██        | 28/133 [00:00<00:01, 68.48it/s]concatenating train images:  27%|██▋       | 36/133 [00:00<00:01, 69.73it/s]concatenating train images:  32%|███▏      | 43/133 [00:00<00:01, 69.53it/s]concatenating train images:  38%|███▊      | 50/133 [00:00<00:01, 68.26it/s]concatenating train images:  44%|████▎     | 58/133 [00:00<00:01, 70.43it/s]concatenating train images:  50%|████▉     | 66/133 [00:00<00:00, 71.93it/s]concatenating train images:  56%|█████▌    | 74/133 [00:01<00:00, 73.86it/s]concatenating train images:  62%|██████▏   | 83/133 [00:01<00:00, 76.24it/s]concatenating train images:  69%|██████▉   | 92/133 [00:01<00:00, 77.93it/s]concatenating train images:  76%|███████▌  | 101/133 [00:01<00:00, 78.85it/s]concatenating train images:  82%|████████▏ | 109/133 [00:01<00:00, 78.17it/s]concatenating train images:  88%|████████▊ | 117/133 [00:01<00:00, 78.62it/s]concatenating train images:  95%|█████████▍| 126/133 [00:01<00:00, 80.13it/s]concatenating train images: 100%|██████████| 133/133 [00:01<00:00, 75.15it/s]
concatenating train images:   0%|          | 0/14 [00:00<?, ?it/s]concatenating train images:  43%|████▎     | 6/14 [00:00<00:00, 55.33it/s]concatenating train images:  93%|█████████▎| 13/14 [00:00<00:00, 57.96it/s]concatenating train images: 100%|██████████| 14/14 [00:00<00:00, 61.00it/s]
Loading Dataset: test:   0%|          | 0/9 [00:00<?, ?it/s]Loading Dataset: test:  22%|██▏       | 2/9 [00:00<00:00, 10.63it/s]Loading Dataset: test:  33%|███▎      | 3/9 [00:00<00:00,  9.97it/s]Loading Dataset: test:  56%|█████▌    | 5/9 [00:00<00:00, 10.74it/s]Loading Dataset: test:  67%|██████▋   | 6/9 [00:00<00:00,  9.88it/s]Loading Dataset: test:  78%|███████▊  | 7/9 [00:00<00:00,  9.52it/s]Loading Dataset: test:  89%|████████▉ | 8/9 [00:00<00:00,  8.91it/s]Loading Dataset: test: 100%|██████████| 9/9 [00:00<00:00,  9.80it/s]
(107/147) train vimp2_ANON702_03152013_control_Aug2_Rot_5
     Bias Correction
(108/147) train vimp2_ANON702_03152013_control_Aug3_Rot_-5
     Bias Correction
(109/147) train vimp2_ANON702_03152013_control_Aug4_Rot_4
     Bias Correction
(110/147) train vimp2_ANON702_03152013_control_Aug5_Rot_-3
     Bias Correction
(111/147) train vimp2_ANON724_03272013_control_Aug0_Rot_-7
     Bias Correction
(112/147) train vimp2_ANON724_03272013_control_Aug1_Rot_-4
     Bias Correction
(113/147) train vimp2_ANON724_03272013_control_Aug2_Rot_7
     Bias Correction
(114/147) train vimp2_ANON724_03272013_control_Aug3_Rot_4
     Bias Correction
(115/147) train vimp2_ANON724_03272013_control_Aug4_Rot_0
     Bias Correction
(116/147) train vimp2_ANON724_03272013_control_Aug5_Rot_3
     Bias Correction
(117/147) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2
     Bias Correction
(118/147) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_5
     Bias Correction
(119/147) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-3
     Bias Correction
(120/147) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5
     Bias Correction
(121/147) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1
     Bias Correction
(122/147) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-2
     Bias Correction
(123/147) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7
     Bias Correction
(124/147) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-1
     Bias Correction
(125/147) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-7
     Bias Correction
(126/147) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_5
     Bias Correction
(127/147) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_-4
     Bias Correction
(128/147) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_5
     Bias Correction
(129/147) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-5
     Bias Correction
(130/147) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_4
     Bias Correction
(131/147) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_3
     Bias Correction
(132/147) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-3
     Bias Correction
(133/147) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5
     Bias Correction
(134/147) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_6
     Bias Correction
(135/147) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_5
     Bias Correction
(136/147) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_4
     Bias Correction
(137/147) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-4
     Bias Correction
(138/147) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_5
     Bias Correction
(139/147) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_4
     Bias Correction
(140/147) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_2
     Bias Correction
(141/147) train vimp2_ctrl_991_08302013_JF_Aug0_Rot_-2
     Bias Correction
(142/147) train vimp2_ctrl_991_08302013_JF_Aug1_Rot_-7
     Bias Correction
(143/147) train vimp2_ctrl_991_08302013_JF_Aug2_Rot_1
     Bias Correction
(144/147) train vimp2_ctrl_991_08302013_JF_Aug3_Rot_-7
     Bias Correction
(145/147) train vimp2_ctrl_991_08302013_JF_Aug4_Rot_-5
     Bias Correction
(146/147) train vimp2_ctrl_991_08302013_JF_Aug5_Rot_3
     Bias Correction
(0/9) test vimp2_869_06142013_BL_MS
     Bias Correction
     Rigid Registration
(1/9) test vimp2_915_07112013_LC_MS
     Bias Correction
     Rigid Registration
(2/9) test vimp2_988_08302013_CB_MS
     Bias Correction
     Rigid Registration
(3/9) test vimp2_ANON624_20130117_control
     Bias Correction
     Rigid Registration
(4/9) test vimp2_ANON714_03222013_control
     Bias Correction
     Rigid Registration
(5/9) test vimp2_ctrl_911_07082013_TTO
     Bias Correction
     Rigid Registration
(6/9) test vimp2_K
     Bias Correction
     Rigid Registration
(7/9) test vimp2_L
     Bias Correction
     Rigid Registration
(8/9) test vimp2_M
     Bias Correction
     Rigid Registration
slicingDim [2, 1, 0] Nuclei_Indexes [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14] GPU:   5
************ stage 1 ************
---------------------------------------------------------------
 Nucleus: 1  | GPU: 5  | slicingDim 2  | Dropout 0.3  | Learning_Rate 0.001  | num_Layers 3  | Multiply_By_Thalmaus False
SubExperiment: sE11_HCascade_wRot7_6cnts_sd2_Dt0.3_LR0.001_NL3_FM64_WoET_Init_From_3T_AutoDim_BestEpch
---------------------------------------------------------------
InputDimensions [116, 112, 72]
num_Layers 3
InputDimensions [116, 112, 72]
dataset error in label values 1-THALAMUS min 0.0 max 2.0 vimp2_K
smallFuncs error in label values min 0.0 max 2.0
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 116, 112, 1)  0                                            
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 116, 112, 1)  4           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 116, 112, 64) 640         batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 116, 112, 64) 36928       conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 58, 56, 64)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 58, 56, 64)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 58, 56, 64)   256         dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 58, 56, 128)  73856       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 58, 56, 128)  147584      conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 29, 28, 128)  0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 29, 28, 128)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 29, 28, 256)  295168      dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 29, 28, 256)  590080      conv2d_5[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 29, 28, 256)  0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 29, 28, 256)  1024        dropout_3[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 58, 56, 128)  131200      batch_normalization_3[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 58, 56, 256)  0           conv2d_transpose_1[0][0]         
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 58, 56, 128)  295040      concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 58, 56, 128)  147584      conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 58, 56, 128)  0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 58, 56, 128)  512         dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 116, 112, 64) 32832       batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 116, 112, 128 0           conv2d_transpose_2[0][0]         
                                                                 conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 116, 112, 64) 73792       concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 116, 112, 64) 36928       conv2d_9[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 116, 112, 64) 0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 116, 112, 2)  130         dropout_5[0][0]                  
==================================================================================================
Total params: 1,863,558
Trainable params: 1,862,660
Non-trainable params: 898
__________________________________________________________________________________________________
address /array/ssd/msmajdi/experiments/keras/exp7_cascadeV1/models/sE8_HCascade_sd2_NL3_FM64_MpByTH_SRI/1-THALAMUS/model_weights.h5
exist True
------------------------------------------
initialized from Model_3T /array/ssd/msmajdi/experiments/keras/exp7_cascadeV1/models/sE8_HCascade_sd2_NL3_FM64_MpByTH_SRI/1-THALAMUS
------------------------------------------
Train on 8321 samples, validate on 884 samples
Epoch 1/70

 100/8321 [..............................] - ETA: 9:11 - loss: 0.0218 - acc: 0.9945 - Dice_Calculator: 0.8792
 200/8321 [..............................] - ETA: 4:49 - loss: 0.0255 - acc: 0.9933 - Dice_Calculator: 0.8468
 300/8321 [>.............................] - ETA: 3:22 - loss: 0.0221 - acc: 0.9937 - Dice_Calculator: 0.8360
 400/8321 [>.............................] - ETA: 2:38 - loss: 0.0216 - acc: 0.9936 - Dice_Calculator: 0.8398
 500/8321 [>.............................] - ETA: 2:11 - loss: 0.0207 - acc: 0.9937 - Dice_Calculator: 0.8367
 600/8321 [=>............................] - ETA: 1:53 - loss: 0.0209 - acc: 0.9935 - Dice_Calculator: 0.8329
 700/8321 [=>............................] - ETA: 1:40 - loss: 0.0201 - acc: 0.9936 - Dice_Calculator: 0.8327
 800/8321 [=>............................] - ETA: 1:31 - loss: 0.0201 - acc: 0.9934 - Dice_Calculator: 0.8330
 900/8321 [==>...........................] - ETA: 1:23 - loss: 0.0194 - acc: 0.9936 - Dice_Calculator: 0.8331
1000/8321 [==>...........................] - ETA: 1:17 - loss: 0.0193 - acc: 0.9935 - Dice_Calculator: 0.8333
1100/8321 [==>...........................] - ETA: 1:12 - loss: 0.0185 - acc: 0.9937 - Dice_Calculator: 0.8329
1200/8321 [===>..........................] - ETA: 1:07 - loss: 0.0182 - acc: 0.9938 - Dice_Calculator: 0.8314
1300/8321 [===>..........................] - ETA: 1:04 - loss: 0.0180 - acc: 0.9937 - Dice_Calculator: 0.8307
1400/8321 [====>.........................] - ETA: 1:00 - loss: 0.0177 - acc: 0.9938 - Dice_Calculator: 0.8306
1500/8321 [====>.........................] - ETA: 57s - loss: 0.0175 - acc: 0.9938 - Dice_Calculator: 0.8309 
1600/8321 [====>.........................] - ETA: 55s - loss: 0.0172 - acc: 0.9939 - Dice_Calculator: 0.8317
1700/8321 [=====>........................] - ETA: 52s - loss: 0.0172 - acc: 0.9939 - Dice_Calculator: 0.8316
1800/8321 [=====>........................] - ETA: 50s - loss: 0.0169 - acc: 0.9939 - Dice_Calculator: 0.8326
1900/8321 [=====>........................] - ETA: 48s - loss: 0.0167 - acc: 0.9940 - Dice_Calculator: 0.8324
2000/8321 [======>.......................] - ETA: 46s - loss: 0.0166 - acc: 0.9940 - Dice_Calculator: 0.8325
2100/8321 [======>.......................] - ETA: 45s - loss: 0.0165 - acc: 0.9940 - Dice_Calculator: 0.8332
2200/8321 [======>.......................] - ETA: 43s - loss: 0.0164 - acc: 0.9940 - Dice_Calculator: 0.8326
2300/8321 [=======>......................] - ETA: 42s - loss: 0.0162 - acc: 0.9941 - Dice_Calculator: 0.8331
2400/8321 [=======>......................] - ETA: 40s - loss: 0.0161 - acc: 0.9941 - Dice_Calculator: 0.8331
2500/8321 [========>.....................] - ETA: 39s - loss: 0.0160 - acc: 0.9941 - Dice_Calculator: 0.8326
2600/8321 [========>.....................] - ETA: 38s - loss: 0.0159 - acc: 0.9941 - Dice_Calculator: 0.8326
2700/8321 [========>.....................] - ETA: 37s - loss: 0.0159 - acc: 0.9941 - Dice_Calculator: 0.8329
2800/8321 [=========>....................] - ETA: 36s - loss: 0.0157 - acc: 0.9941 - Dice_Calculator: 0.8332
2900/8321 [=========>....................] - ETA: 34s - loss: 0.0155 - acc: 0.9942 - Dice_Calculator: 0.8339
3000/8321 [=========>....................] - ETA: 33s - loss: 0.0155 - acc: 0.9942 - Dice_Calculator: 0.8344
3100/8321 [==========>...................] - ETA: 32s - loss: 0.0153 - acc: 0.9942 - Dice_Calculator: 0.8353
3200/8321 [==========>...................] - ETA: 31s - loss: 0.0152 - acc: 0.9943 - Dice_Calculator: 0.8358
3300/8321 [==========>...................] - ETA: 31s - loss: 0.0151 - acc: 0.9943 - Dice_Calculator: 0.8367
3400/8321 [===========>..................] - ETA: 30s - loss: 0.0151 - acc: 0.9943 - Dice_Calculator: 0.8372
3500/8321 [===========>..................] - ETA: 29s - loss: 0.0150 - acc: 0.9943 - Dice_Calculator: 0.8378
3600/8321 [===========>..................] - ETA: 28s - loss: 0.0149 - acc: 0.9943 - Dice_Calculator: 0.8387
3700/8321 [============>.................] - ETA: 27s - loss: 0.0148 - acc: 0.9943 - Dice_Calculator: 0.8393