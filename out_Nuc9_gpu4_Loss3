Using TensorFlow backend.
Loading Dataset: 0it [00:00, ?it/s]Loading Dataset: 2it [00:00, 11.97it/s]Loading Dataset: 4it [00:00, 13.34it/s]Loading Dataset: 7it [00:00, 15.15it/s]Loading Dataset: 9it [00:00, 15.63it/s]Loading Dataset: 11it [00:00, 15.65it/s]Loading Dataset: 13it [00:00, 15.54it/s]Loading Dataset: 15it [00:00, 15.87it/s]Loading Dataset: 17it [00:01, 13.73it/s]Loading Dataset: 19it [00:01, 13.95it/s]Loading Dataset: 21it [00:01, 13.52it/s]Loading Dataset: 23it [00:01, 12.97it/s]Loading Dataset: 25it [00:01, 11.97it/s]Loading Dataset: 27it [00:01, 12.20it/s]Loading Dataset: 29it [00:02, 12.54it/s]Loading Dataset: 31it [00:02, 11.26it/s]Loading Dataset: 33it [00:02, 11.26it/s]Loading Dataset: 35it [00:02, 11.04it/s]Loading Dataset: 37it [00:02, 10.54it/s]Loading Dataset: 39it [00:03, 10.41it/s]Loading Dataset: 41it [00:03,  9.69it/s]Loading Dataset: 42it [00:03,  9.66it/s]Loading Dataset: 44it [00:03,  9.47it/s]Loading Dataset: 45it [00:03,  8.84it/s]Loading Dataset: 46it [00:03,  8.12it/s]Loading Dataset: 47it [00:04,  7.69it/s]Loading Dataset: 48it [00:04,  7.70it/s]Loading Dataset: 49it [00:04,  7.43it/s]Loading Dataset: 50it [00:04,  7.27it/s]Loading Dataset: 51it [00:04,  7.20it/s]Loading Dataset: 52it [00:04,  7.30it/s]Loading Dataset: 53it [00:04,  7.30it/s]Loading Dataset: 54it [00:05,  7.06it/s]Loading Dataset: 55it [00:05,  6.40it/s]Loading Dataset: 56it [00:05,  6.22it/s]Loading Dataset: 57it [00:05,  6.23it/s]Loading Dataset: 58it [00:05,  6.30it/s]Loading Dataset: 59it [00:05,  6.41it/s]Loading Dataset: 60it [00:06,  6.27it/s]Loading Dataset: 61it [00:06,  6.30it/s]Loading Dataset: 62it [00:06,  6.21it/s]Loading Dataset: 63it [00:06,  6.29it/s]Loading Dataset: 64it [00:06,  6.14it/s]Loading Dataset: 65it [00:06,  6.17it/s]Loading Dataset: 66it [00:07,  6.16it/s]Loading Dataset: 67it [00:07,  6.09it/s]
Loading Dataset: 0it [00:00, ?it/s]Loading Dataset: 3it [00:00, 24.48it/s]Loading Dataset: 5it [00:00, 22.78it/s]Loading Dataset: 8it [00:00, 22.45it/s]Loading Dataset: 11it [00:00, 22.40it/s]Loading Dataset: 14it [00:00, 22.14it/s]Loading Dataset: 16it [00:00, 20.01it/s]Loading Dataset: 20it [00:00, 22.70it/s]Loading Dataset: 23it [00:01, 22.28it/s]Loading Dataset: 26it [00:01, 21.61it/s]Loading Dataset: 28it [00:01, 22.28it/s]2019-01-10 23:30:33.396629: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-10 23:30:34.633398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-01-10 23:30:34.633491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-01-10 23:30:35.014348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-10 23:30:35.014441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-01-10 23:30:35.014457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-01-10 23:30:35.014948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
WARNING: subject:  vimp2_1510_09022015  size is out of the training network input dimensions
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 96, 96, 1)    0                                            
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 96, 96, 1)    4           input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 96, 96, 64)   640         batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 96, 96, 64)   36928       conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 48, 48, 64)   0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 48, 48, 64)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 48, 64)   256         dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 48, 48, 128)  73856       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 48, 48, 128)  147584      conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 24, 24, 128)  0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 24, 24, 128)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 24, 128)  512         dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 24, 24, 256)  295168      batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 24, 24, 256)  590080      conv2d_5[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 256)  0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 256)  0           max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 12, 12, 256)  1024        dropout_3[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 12, 12, 512)  1180160     batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 12, 12, 512)  2359808     conv2d_7[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 512)    0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 6, 6, 512)    0           max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 6, 6, 1024)   4719616     dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 6, 6, 1024)   9438208     conv2d_9[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 6, 6, 1024)   0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 6, 6, 1024)   4096        dropout_5[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 12, 12, 512)  2097664     batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 12, 12, 1024) 0           conv2d_transpose_1[0][0]         
                                                                 conv2d_8[0][0]                   
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 12, 12, 512)  4719104     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 12, 12, 512)  2359808     conv2d_11[0][0]                  
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 12, 12, 512)  0           conv2d_12[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 12, 512)  2048        dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 24, 24, 256)  524544      batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 24, 24, 512)  0           conv2d_transpose_2[0][0]         
                                                                 conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 24, 24, 256)  1179904     concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 24, 24, 256)  590080      conv2d_13[0][0]                  
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 24, 24, 256)  0           conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 24, 256)  1024        dropout_7[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 48, 48, 128)  131200      batch_normalization_7[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 48, 48, 256)  0           conv2d_transpose_3[0][0]         
Training:   0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 0:   0%|          | 0/2528 [00:00<?, ?it/s][A
                                                                 conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 48, 48, 128)  295040      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 48, 48, 128)  147584      conv2d_15[0][0]                  
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 48, 48, 128)  0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 48, 48, 128)  512         dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 96, 96, 64)   32832       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 96, 96, 128)  0           conv2d_transpose_4[0][0]         
                                                                 conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 96, 96, 64)   73792       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 96, 96, 64)   36928       conv2d_17[0][0]                  
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 96, 96, 64)   0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 96, 96, 2)    130         dropout_9[0][0]                  
==================================================================================================
Total params: 31,040,134
Trainable params: 31,035,396
Non-trainable params: 4,738
__________________________________________________________________________________________________
Train on 2528 samples, validate on 281 samples
Epoch 1/100

  40/2528 [..............................] - ETA: 9:58 - loss: 1.3315 - acc: 0.9730 - Dice_Calculator: 0.0453
Epoch: 0 - loss: 1.331, acc: 0.973, Dice_Calculator: 0.045:   2%|▏         | 40/2528 [00:09<09:58,  4.16it/s][A
  80/2528 [..............................] - ETA: 5:01 - loss: 1.2888 - acc: 0.9750 - Dice_Calculator: 0.0448
Epoch: 0 - loss: 1.289, acc: 0.975, Dice_Calculator: 0.045:   3%|▎         | 80/2528 [00:09<06:56,  5.88it/s][A
 120/2528 [>.............................] - ETA: 3:21 - loss: 1.2624 - acc: 0.9754 - Dice_Calculator: 0.0453
Epoch: 0 - loss: 1.262, acc: 0.975, Dice_Calculator: 0.045:   5%|▍         | 120/2528 [00:10<04:50,  8.29it/s][A
 160/2528 [>.............................] - ETA: 2:31 - loss: 1.2284 - acc: 0.9758 - Dice_Calculator: 0.0437
Epoch: 0 - loss: 1.228, acc: 0.976, Dice_Calculator: 0.044:   6%|▋         | 160/2528 [00:10<03:23, 11.64it/s][A
 200/2528 [=>............................] - ETA: 2:01 - loss: 1.1855 - acc: 0.9784 - Dice_Calculator: 0.0422
Epoch: 0 - loss: 1.185, acc: 0.978, Dice_Calculator: 0.042:   8%|▊         | 200/2528 [00:10<02:23, 16.23it/s][A
 240/2528 [=>............................] - ETA: 1:41 - loss: 1.1203 - acc: 0.9816 - Dice_Calculator: 0.0705
Epoch: 0 - loss: 1.120, acc: 0.982, Dice_Calculator: 0.071:   9%|▉         | 240/2528 [00:10<01:42, 22.41it/s][A
 280/2528 [==>...........................] - ETA: 1:27 - loss: 0.9948 - acc: 0.9842 - Dice_Calculator: 0.1689
Epoch: 0 - loss: 0.995, acc: 0.984, Dice_Calculator: 0.169:  11%|█         | 280/2528 [00:10<01:13, 30.55it/s][A
 320/2528 [==>...........................] - ETA: 1:16 - loss: 0.9188 - acc: 0.9861 - Dice_Calculator: 0.2246
Epoch: 0 - loss: 0.919, acc: 0.986, Dice_Calculator: 0.225:  13%|█▎        | 320/2528 [00:11<00:53, 41.00it/s][A
 360/2528 [===>..........................] - ETA: 1:07 - loss: 0.8397 - acc: 0.9877 - Dice_Calculator: 0.2879
Epoch: 0 - loss: 0.840, acc: 0.988, Dice_Calculator: 0.288:  14%|█▍        | 360/2528 [00:11<00:40, 53.85it/s][A
 400/2528 [===>..........................] - ETA: 1:00 - loss: 0.7775 - acc: 0.9889 - Dice_Calculator: 0.3375
Epoch: 0 - loss: 0.777, acc: 0.989, Dice_Calculator: 0.337:  16%|█▌        | 400/2528 [00:11<00:30, 69.05it/s][A
 440/2528 [====>.........................] - ETA: 55s - loss: 0.7321 - acc: 0.9898 - Dice_Calculator: 0.3725 
Epoch: 0 - loss: 0.732, acc: 0.990, Dice_Calculator: 0.372:  17%|█▋        | 440/2528 [00:11<00:24, 85.97it/s][A
 480/2528 [====>.........................] - ETA: 50s - loss: 0.6944 - acc: 0.9907 - Dice_Calculator: 0.4017
Epoch: 0 - loss: 0.694, acc: 0.991, Dice_Calculator: 0.402:  19%|█▉        | 480/2528 [00:11<00:19, 103.95it/s][A
 520/2528 [=====>........................] - ETA: 46s - loss: 0.6536 - acc: 0.9913 - Dice_Calculator: 0.4352
Epoch: 0 - loss: 0.654, acc: 0.991, Dice_Calculator: 0.435:  21%|██        | 520/2528 [00:12<00:16, 121.48it/s][A
 560/2528 [=====>........................] - ETA: 42s - loss: 0.6191 - acc: 0.9920 - Dice_Calculator: 0.4634
Epoch: 0 - loss: 0.619, acc: 0.992, Dice_Calculator: 0.463:  22%|██▏       | 560/2528 [00:12<00:14, 138.13it/s][A
 600/2528 [======>.......................] - ETA: 39s - loss: 0.5949 - acc: 0.9925 - Dice_Calculator: 0.4822
Epoch: 0 - loss: 0.595, acc: 0.992, Dice_Calculator: 0.482:  24%|██▎       | 600/2528 [00:12<00:12, 152.41it/s][A
 640/2528 [======>.......................] - ETA: 37s - loss: 0.5686 - acc: 0.9929 - Dice_Calculator: 0.5038
Epoch: 0 - loss: 0.569, acc: 0.993, Dice_Calculator: 0.504:  25%|██▌       | 640/2528 [00:12<00:11, 164.25it/s][A
 680/2528 [=======>......................] - ETA: 34s - loss: 0.5447 - acc: 0.9933 - Dice_Calculator: 0.5235
Epoch: 0 - loss: 0.545, acc: 0.993, Dice_Calculator: 0.523:  27%|██▋       | 680/2528 [00:12<00:10, 173.85it/s][A
 720/2528 [=======>......................] - ETA: 32s - loss: 0.5240 - acc: 0.9937 - Dice_Calculator: 0.5404
Epoch: 0 - loss: 0.524, acc: 0.994, Dice_Calculator: 0.540:  28%|██▊       | 720/2528 [00:13<00:09, 181.40it/s][A
 760/2528 [========>.....................] - ETA: 30s - loss: 0.5020 - acc: 0.9940 - Dice_Calculator: 0.5590
Epoch: 0 - loss: 0.502, acc: 0.994, Dice_Calculator: 0.559:  30%|███       | 760/2528 [00:13<00:09, 186.75it/s][A
 800/2528 [========>.....................] - ETA: 29s - loss: 0.4835 - acc: 0.9943 - Dice_Calculator: 0.5746
Epoch: 0 - loss: 0.483, acc: 0.994, Dice_Calculator: 0.575:  32%|███▏      | 800/2528 [00:13<00:09, 191.11it/s][A
 840/2528 [========>.....................] - ETA: 27s - loss: 0.4689 - acc: 0.9946 - Dice_Calculator: 0.5864
Epoch: 0 - loss: 0.469, acc: 0.995, Dice_Calculator: 0.586:  33%|███▎      | 840/2528 [00:13<00:08, 193.84it/s][A
 880/2528 [=========>....................] - ETA: 25s - loss: 0.4537 - acc: 0.9948 - Dice_Calculator: 0.5992
Epoch: 0 - loss: 0.454, acc: 0.995, Dice_Calculator: 0.599:  35%|███▍      | 880/2528 [00:13<00:08, 196.39it/s][A
 920/2528 [=========>....................] - ETA: 24s - loss: 0.4398 - acc: 0.9950 - Dice_Calculator: 0.6108
Epoch: 0 - loss: 0.440, acc: 0.995, Dice_Calculator: 0.611:  36%|███▋      | 920/2528 [00:14<00:08, 197.69it/s][A
 960/2528 [==========>...................] - ETA: 23s - loss: 0.4281 - acc: 0.9952 - Dice_Calculator: 0.6205
Epoch: 0 - loss: 0.428, acc: 0.995, Dice_Calculator: 0.620:  38%|███▊      | 960/2528 [00:14<00:07, 199.15it/s][A
1000/2528 [==========>...................] - ETA: 22s - loss: 0.4170 - acc: 0.9954 - Dice_Calculator: 0.6298
Epoch: 0 - loss: 0.417, acc: 0.995, Dice_Calculator: 0.630:  40%|███▉      | 1000/2528 [00:14<00:07, 199.67it/s][A
1040/2528 [===========>..................] - ETA: 20s - loss: 0.4051 - acc: 0.9956 - Dice_Calculator: 0.6399
Epoch: 0 - loss: 0.405, acc: 0.996, Dice_Calculator: 0.640:  41%|████      | 1040/2528 [00:14<00:07, 200.01it/s][A
1080/2528 [===========>..................] - ETA: 19s - loss: 0.3951 - acc: 0.9957 - Dice_Calculator: 0.6483
Epoch: 0 - loss: 0.395, acc: 0.996, Dice_Calculator: 0.648:  43%|████▎     | 1080/2528 [00:14<00:07, 199.99it/s][A
1120/2528 [============>.................] - ETA: 18s - loss: 0.3862 - acc: 0.9959 - Dice_Calculator: 0.6557
Epoch: 0 - loss: 0.386, acc: 0.996, Dice_Calculator: 0.656:  44%|████▍     | 1120/2528 [00:15<00:07, 200.59it/s][A
1160/2528 [============>.................] - ETA: 17s - loss: 0.3787 - acc: 0.9960 - Dice_Calculator: 0.6618
Epoch: 0 - loss: 0.379, acc: 0.996, Dice_Calculator: 0.662:  46%|████▌     | 1160/2528 [00:15<00:06, 200.70it/s][A
1200/2528 [=============>................] - ETA: 17s - loss: 0.3728 - acc: 0.9961 - Dice_Calculator: 0.6664
Epoch: 0 - loss: 0.373, acc: 0.996, Dice_Calculator: 0.666:  47%|████▋     | 1200/2528 [00:15<00:06, 201.24it/s][A
1240/2528 [=============>................] - ETA: 16s - loss: 0.3660 - acc: 0.9962 - Dice_Calculator: 0.6720
Epoch: 0 - loss: 0.366, acc: 0.996, Dice_Calculator: 0.672:  49%|████▉     | 1240/2528 [00:15<00:06, 201.20it/s][A
1280/2528 [==============>...............] - ETA: 15s - loss: 0.3584 - acc: 0.9964 - Dice_Calculator: 0.6784
Epoch: 0 - loss: 0.358, acc: 0.996, Dice_Calculator: 0.678:  51%|█████     | 1280/2528 [00:15<00:06, 201.72it/s][A
1320/2528 [==============>...............] - ETA: 14s - loss: 0.3513 - acc: 0.9965 - Dice_Calculator: 0.6844
Epoch: 0 - loss: 0.351, acc: 0.996, Dice_Calculator: 0.684:  52%|█████▏    | 1320/2528 [00:16<00:05, 201.45it/s][A
1360/2528 [===============>..............] - ETA: 13s - loss: 0.3454 - acc: 0.9966 - Dice_Calculator: 0.6893
Epoch: 0 - loss: 0.345, acc: 0.997, Dice_Calculator: 0.689:  54%|█████▍    | 1360/2528 [00:16<00:05, 201.99it/s][A
1400/2528 [===============>..............] - ETA: 13s - loss: 0.3387 - acc: 0.9967 - Dice_Calculator: 0.6950
Epoch: 0 - loss: 0.339, acc: 0.997, Dice_Calculator: 0.695:  55%|█████▌    | 1400/2528 [00:16<00:05, 201.69it/s][A
1440/2528 [================>.............] - ETA: 12s - loss: 0.3348 - acc: 0.9967 - Dice_Calculator: 0.6980
Epoch: 0 - loss: 0.335, acc: 0.997, Dice_Calculator: 0.698:  57%|█████▋    | 1440/2528 [00:16<00:05, 200.65it/s][A
1480/2528 [================>.............] - ETA: 11s - loss: 0.3306 - acc: 0.9968 - Dice_Calculator: 0.7014
Epoch: 0 - loss: 0.331, acc: 0.997, Dice_Calculator: 0.701:  59%|█████▊    | 1480/2528 [00:16<00:05, 200.77it/s][A
1520/2528 [=================>............] - ETA: 11s - loss: 0.3249 - acc: 0.9969 - Dice_Calculator: 0.7063
Epoch: 0 - loss: 0.325, acc: 0.997, Dice_Calculator: 0.706:  60%|██████    | 1520/2528 [00:17<00:05, 201.08it/s][A
1560/2528 [=================>............] - ETA: 10s - loss: 0.3204 - acc: 0.9970 - Dice_Calculator: 0.7100
Epoch: 0 - loss: 0.320, acc: 0.997, Dice_Calculator: 0.710:  62%|██████▏   | 1560/2528 [00:17<00:04, 200.81it/s][A
1600/2528 [=================>............] - ETA: 10s - loss: 0.3153 - acc: 0.9971 - Dice_Calculator: 0.7143
Epoch: 0 - loss: 0.315, acc: 0.997, Dice_Calculator: 0.714:  63%|██████▎   | 1600/2528 [00:17<00:04, 200.80it/s][A
1640/2528 [==================>...........] - ETA: 9s - loss: 0.3115 - acc: 0.9971 - Dice_Calculator: 0.7175 
Epoch: 0 - loss: 0.311, acc: 0.997, Dice_Calculator: 0.718:  65%|██████▍   | 1640/2528 [00:17<00:04, 200.77it/s][A
1680/2528 [==================>...........] - ETA: 8s - loss: 0.3064 - acc: 0.9972 - Dice_Calculator: 0.7219
Epoch: 0 - loss: 0.306, acc: 0.997, Dice_Calculator: 0.722:  66%|██████▋   | 1680/2528 [00:17<00:04, 201.25it/s][A
1720/2528 [===================>..........] - ETA: 8s - loss: 0.3226 - acc: 0.9972 - Dice_Calculator: 0.7051
Epoch: 0 - loss: 0.323, acc: 0.997, Dice_Calculator: 0.705:  68%|██████▊   | 1720/2528 [00:18<00:04, 200.98it/s][A
1760/2528 [===================>..........] - ETA: 7s - loss: 0.3188 - acc: 0.9973 - Dice_Calculator: 0.7083
Epoch: 0 - loss: 0.319, acc: 0.997, Dice_Calculator: 0.708:  70%|██████▉   | 1760/2528 [00:18<00:03, 201.41it/s][A
1800/2528 [====================>.........] - ETA: 7s - loss: 0.3143 - acc: 0.9974 - Dice_Calculator: 0.7123
Epoch: 0 - loss: 0.314, acc: 0.997, Dice_Calculator: 0.712:  71%|███████   | 1800/2528 [00:18<00:03, 201.32it/s][A
1840/2528 [====================>.........] - ETA: 6s - loss: 0.3144 - acc: 0.9974 - Dice_Calculator: 0.7116
Epoch: 0 - loss: 0.314, acc: 0.997, Dice_Calculator: 0.712:  73%|███████▎  | 1840/2528 [00:18<00:03, 201.85it/s][A