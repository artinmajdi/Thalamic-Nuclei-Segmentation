*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-07 01:37:54.689078: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-07 01:37:55.055545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 14.65GiB
2019-07-07 01:37:55.055612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 01:37:55.433371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 01:37:55.433448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 01:37:55.433461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 01:37:55.433920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:55,  1.25s/it]Loading train:   1%|          | 2/285 [00:02<05:53,  1.25s/it]Loading train:   1%|          | 3/285 [00:03<05:31,  1.18s/it]Loading train:   1%|▏         | 4/285 [00:04<05:56,  1.27s/it]Loading train:   2%|▏         | 5/285 [00:06<05:36,  1.20s/it]Loading train:   2%|▏         | 6/285 [00:07<05:53,  1.27s/it]Loading train:   2%|▏         | 7/285 [00:09<06:17,  1.36s/it]Loading train:   3%|▎         | 8/285 [00:10<06:34,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:11<06:12,  1.35s/it]Loading train:   4%|▎         | 10/285 [00:12<05:43,  1.25s/it]Loading train:   4%|▍         | 11/285 [00:14<05:39,  1.24s/it]Loading train:   4%|▍         | 12/285 [00:15<05:31,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:16<05:20,  1.18s/it]Loading train:   5%|▍         | 14/285 [00:17<05:14,  1.16s/it]Loading train:   5%|▌         | 15/285 [00:18<05:00,  1.11s/it]Loading train:   6%|▌         | 16/285 [00:19<04:58,  1.11s/it]Loading train:   6%|▌         | 17/285 [00:20<04:41,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:21<04:50,  1.09s/it]Loading train:   7%|▋         | 19/285 [00:22<04:37,  1.04s/it]Loading train:   7%|▋         | 20/285 [00:23<04:43,  1.07s/it]Loading train:   7%|▋         | 21/285 [00:24<04:36,  1.05s/it]Loading train:   8%|▊         | 22/285 [00:25<04:52,  1.11s/it]Loading train:   8%|▊         | 23/285 [00:26<04:36,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:27<04:28,  1.03s/it]Loading train:   9%|▉         | 25/285 [00:28<04:24,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:29<04:23,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:30<04:29,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:31<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:32<04:18,  1.01s/it]Loading train:  11%|█         | 30/285 [00:33<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:34<04:18,  1.02s/it]Loading train:  11%|█         | 32/285 [00:35<04:13,  1.00s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:04,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:37<03:55,  1.06it/s]Loading train:  12%|█▏        | 35/285 [00:38<03:59,  1.04it/s]Loading train:  13%|█▎        | 36/285 [00:39<03:58,  1.04it/s]Loading train:  13%|█▎        | 37/285 [00:40<04:12,  1.02s/it]Loading train:  13%|█▎        | 38/285 [00:41<04:07,  1.00s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:16,  1.04s/it]Loading train:  14%|█▍        | 40/285 [00:43<04:08,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:44<04:15,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:45<04:00,  1.01it/s]Loading train:  15%|█▌        | 43/285 [00:46<03:53,  1.04it/s]Loading train:  15%|█▌        | 44/285 [00:47<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:53,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:34,  1.11it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:27,  1.14it/s]Loading train:  17%|█▋        | 49/285 [00:51<03:21,  1.17it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:15,  1.20it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:08,  1.24it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:06,  1.25it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:04,  1.26it/s]Loading train:  19%|█▉        | 54/285 [00:55<03:16,  1.18it/s]Loading train:  19%|█▉        | 55/285 [00:56<03:06,  1.23it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:01,  1.26it/s]Loading train:  20%|██        | 57/285 [00:58<03:10,  1.20it/s]Loading train:  20%|██        | 58/285 [00:59<03:10,  1.19it/s]Loading train:  21%|██        | 59/285 [01:00<03:12,  1.17it/s]Loading train:  21%|██        | 60/285 [01:00<03:07,  1.20it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:04,  1.21it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:15,  1.14it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:04,  1.21it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:42,  1.01s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:20,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:31,  1.24s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:00,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:46,  1.04s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:30,  1.02it/s]Loading train:  25%|██▍       | 70/285 [01:11<03:13,  1.11it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:19,  1.07it/s]Loading train:  25%|██▌       | 72/285 [01:12<03:15,  1.09it/s]Loading train:  26%|██▌       | 73/285 [01:13<03:11,  1.11it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:12,  1.10it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:04,  1.14it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:10,  1.10it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:13,  1.08it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:16,  1.06it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:15,  1.05it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:10,  1.07it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:11,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:15,  1.04it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:08,  1.07it/s]Loading train:  29%|██▉       | 84/285 [01:24<03:19,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:25<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:26<03:44,  1.13s/it]Loading train:  31%|███       | 87/285 [01:28<03:59,  1.21s/it]Loading train:  31%|███       | 88/285 [01:29<04:01,  1.23s/it]Loading train:  31%|███       | 89/285 [01:30<03:59,  1.22s/it]Loading train:  32%|███▏      | 90/285 [01:31<03:58,  1.22s/it]Loading train:  32%|███▏      | 91/285 [01:33<03:49,  1.18s/it]Loading train:  32%|███▏      | 92/285 [01:34<03:56,  1.23s/it]Loading train:  33%|███▎      | 93/285 [01:35<03:55,  1.23s/it]Loading train:  33%|███▎      | 94/285 [01:36<03:55,  1.23s/it]Loading train:  33%|███▎      | 95/285 [01:38<03:52,  1.22s/it]Loading train:  34%|███▎      | 96/285 [01:39<03:51,  1.22s/it]Loading train:  34%|███▍      | 97/285 [01:40<03:58,  1.27s/it]Loading train:  34%|███▍      | 98/285 [01:41<03:57,  1.27s/it]Loading train:  35%|███▍      | 99/285 [01:43<03:54,  1.26s/it]Loading train:  35%|███▌      | 100/285 [01:44<03:51,  1.25s/it]Loading train:  35%|███▌      | 101/285 [01:45<03:48,  1.24s/it]Loading train:  36%|███▌      | 102/285 [01:46<03:50,  1.26s/it]Loading train:  36%|███▌      | 103/285 [01:47<03:40,  1.21s/it]Loading train:  36%|███▋      | 104/285 [01:49<03:50,  1.27s/it]Loading train:  37%|███▋      | 105/285 [01:50<03:37,  1.21s/it]Loading train:  37%|███▋      | 106/285 [01:51<03:34,  1.20s/it]Loading train:  38%|███▊      | 107/285 [01:52<03:24,  1.15s/it]Loading train:  38%|███▊      | 108/285 [01:53<03:16,  1.11s/it]Loading train:  38%|███▊      | 109/285 [01:54<03:13,  1.10s/it]Loading train:  39%|███▊      | 110/285 [01:55<03:18,  1.13s/it]Loading train:  39%|███▉      | 111/285 [01:57<03:24,  1.18s/it]Loading train:  39%|███▉      | 112/285 [01:58<03:23,  1.17s/it]Loading train:  40%|███▉      | 113/285 [01:59<03:30,  1.22s/it]Loading train:  40%|████      | 114/285 [02:00<03:26,  1.21s/it]Loading train:  40%|████      | 115/285 [02:02<03:34,  1.26s/it]Loading train:  41%|████      | 116/285 [02:03<03:36,  1.28s/it]Loading train:  41%|████      | 117/285 [02:04<03:33,  1.27s/it]Loading train:  41%|████▏     | 118/285 [02:06<03:35,  1.29s/it]Loading train:  42%|████▏     | 119/285 [02:07<03:38,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:09<03:42,  1.35s/it]Loading train:  42%|████▏     | 121/285 [02:10<03:45,  1.38s/it]Loading train:  43%|████▎     | 122/285 [02:11<03:48,  1.40s/it]Loading train:  43%|████▎     | 123/285 [02:13<04:05,  1.52s/it]Loading train:  44%|████▎     | 124/285 [02:15<03:59,  1.49s/it]Loading train:  44%|████▍     | 125/285 [02:16<03:47,  1.42s/it]Loading train:  44%|████▍     | 126/285 [02:17<03:45,  1.42s/it]Loading train:  45%|████▍     | 127/285 [02:19<03:40,  1.40s/it]Loading train:  45%|████▍     | 128/285 [02:20<03:21,  1.29s/it]Loading train:  45%|████▌     | 129/285 [02:21<03:22,  1.30s/it]Loading train:  46%|████▌     | 130/285 [02:22<03:17,  1.27s/it]Loading train:  46%|████▌     | 131/285 [02:24<03:19,  1.29s/it]Loading train:  46%|████▋     | 132/285 [02:25<03:13,  1.27s/it]Loading train:  47%|████▋     | 133/285 [02:26<03:13,  1.27s/it]Loading train:  47%|████▋     | 134/285 [02:27<03:15,  1.30s/it]Loading train:  47%|████▋     | 135/285 [02:29<03:04,  1.23s/it]Loading train:  48%|████▊     | 136/285 [02:30<03:01,  1.22s/it]Loading train:  48%|████▊     | 137/285 [02:31<03:00,  1.22s/it]Loading train:  48%|████▊     | 138/285 [02:32<03:00,  1.23s/it]Loading train:  49%|████▉     | 139/285 [02:34<03:12,  1.32s/it]Loading train:  49%|████▉     | 140/285 [02:35<03:08,  1.30s/it]Loading train:  49%|████▉     | 141/285 [02:36<02:57,  1.24s/it]Loading train:  50%|████▉     | 142/285 [02:37<02:47,  1.17s/it]Loading train:  50%|█████     | 143/285 [02:38<02:48,  1.19s/it]Loading train:  51%|█████     | 144/285 [02:39<02:46,  1.18s/it]Loading train:  51%|█████     | 145/285 [02:41<02:40,  1.15s/it]Loading train:  51%|█████     | 146/285 [02:42<02:34,  1.11s/it]Loading train:  52%|█████▏    | 147/285 [02:43<02:40,  1.17s/it]Loading train:  52%|█████▏    | 148/285 [02:44<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [02:45<02:36,  1.15s/it]Loading train:  53%|█████▎    | 150/285 [02:46<02:27,  1.09s/it]Loading train:  53%|█████▎    | 151/285 [02:47<02:32,  1.14s/it]Loading train:  53%|█████▎    | 152/285 [02:48<02:33,  1.15s/it]Loading train:  54%|█████▎    | 153/285 [02:50<02:32,  1.15s/it]Loading train:  54%|█████▍    | 154/285 [02:50<02:18,  1.05s/it]Loading train:  54%|█████▍    | 155/285 [02:52<02:21,  1.09s/it]Loading train:  55%|█████▍    | 156/285 [02:53<02:17,  1.07s/it]Loading train:  55%|█████▌    | 157/285 [02:54<02:23,  1.12s/it]Loading train:  55%|█████▌    | 158/285 [02:55<02:22,  1.12s/it]Loading train:  56%|█████▌    | 159/285 [02:56<02:19,  1.10s/it]Loading train:  56%|█████▌    | 160/285 [02:57<02:17,  1.10s/it]Loading train:  56%|█████▋    | 161/285 [02:58<02:13,  1.07s/it]Loading train:  57%|█████▋    | 162/285 [02:59<02:13,  1.09s/it]Loading train:  57%|█████▋    | 163/285 [03:00<02:13,  1.09s/it]Loading train:  58%|█████▊    | 164/285 [03:02<02:13,  1.10s/it]Loading train:  58%|█████▊    | 165/285 [03:03<02:08,  1.07s/it]Loading train:  58%|█████▊    | 166/285 [03:04<02:16,  1.15s/it]Loading train:  59%|█████▊    | 167/285 [03:05<02:16,  1.16s/it]Loading train:  59%|█████▉    | 168/285 [03:06<02:18,  1.19s/it]Loading train:  59%|█████▉    | 169/285 [03:07<02:18,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [03:09<02:19,  1.21s/it]Loading train:  60%|██████    | 171/285 [03:10<02:18,  1.21s/it]Loading train:  60%|██████    | 172/285 [03:11<02:20,  1.25s/it]Loading train:  61%|██████    | 173/285 [03:13<02:18,  1.24s/it]Loading train:  61%|██████    | 174/285 [03:14<02:15,  1.22s/it]Loading train:  61%|██████▏   | 175/285 [03:15<02:16,  1.24s/it]Loading train:  62%|██████▏   | 176/285 [03:16<02:12,  1.22s/it]Loading train:  62%|██████▏   | 177/285 [03:17<02:12,  1.23s/it]Loading train:  62%|██████▏   | 178/285 [03:18<02:04,  1.16s/it]Loading train:  63%|██████▎   | 179/285 [03:20<02:03,  1.16s/it]Loading train:  63%|██████▎   | 180/285 [03:21<01:59,  1.14s/it]Loading train:  64%|██████▎   | 181/285 [03:22<02:02,  1.17s/it]Loading train:  64%|██████▍   | 182/285 [03:23<01:54,  1.11s/it]Loading train:  64%|██████▍   | 183/285 [03:24<01:53,  1.12s/it]Loading train:  65%|██████▍   | 184/285 [03:25<01:45,  1.04s/it]Loading train:  65%|██████▍   | 185/285 [03:26<01:50,  1.11s/it]Loading train:  65%|██████▌   | 186/285 [03:27<01:43,  1.05s/it]Loading train:  66%|██████▌   | 187/285 [03:28<01:35,  1.02it/s]Loading train:  66%|██████▌   | 188/285 [03:29<01:34,  1.02it/s]Loading train:  66%|██████▋   | 189/285 [03:30<01:36,  1.00s/it]Loading train:  67%|██████▋   | 190/285 [03:31<01:35,  1.01s/it]Loading train:  67%|██████▋   | 191/285 [03:32<01:34,  1.00s/it]Loading train:  67%|██████▋   | 192/285 [03:33<01:30,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [03:34<01:24,  1.08it/s]Loading train:  68%|██████▊   | 194/285 [03:35<01:26,  1.05it/s]Loading train:  68%|██████▊   | 195/285 [03:36<01:31,  1.02s/it]Loading train:  69%|██████▉   | 196/285 [03:37<01:32,  1.03s/it]Loading train:  69%|██████▉   | 197/285 [03:38<01:32,  1.05s/it]Loading train:  69%|██████▉   | 198/285 [03:39<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [03:40<01:27,  1.02s/it]Loading train:  70%|███████   | 200/285 [03:41<01:24,  1.00it/s]Loading train:  71%|███████   | 201/285 [03:42<01:25,  1.02s/it]Loading train:  71%|███████   | 202/285 [03:43<01:26,  1.04s/it]Loading train:  71%|███████   | 203/285 [03:44<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:45<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:46<01:27,  1.09s/it]Loading train:  72%|███████▏  | 206/285 [03:47<01:26,  1.09s/it]Loading train:  73%|███████▎  | 207/285 [03:49<01:28,  1.13s/it]Loading train:  73%|███████▎  | 208/285 [03:50<01:23,  1.09s/it]Loading train:  73%|███████▎  | 209/285 [03:51<01:23,  1.09s/it]Loading train:  74%|███████▎  | 210/285 [03:52<01:20,  1.07s/it]Loading train:  74%|███████▍  | 211/285 [03:53<01:15,  1.03s/it]Loading train:  74%|███████▍  | 212/285 [03:54<01:12,  1.00it/s]Loading train:  75%|███████▍  | 213/285 [03:55<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:55<01:08,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [03:57<01:10,  1.01s/it]Loading train:  76%|███████▌  | 216/285 [03:58<01:11,  1.04s/it]Loading train:  76%|███████▌  | 217/285 [03:59<01:13,  1.08s/it]Loading train:  76%|███████▋  | 218/285 [04:00<01:09,  1.04s/it]Loading train:  77%|███████▋  | 219/285 [04:01<01:07,  1.02s/it]Loading train:  77%|███████▋  | 220/285 [04:02<01:05,  1.01s/it]Loading train:  78%|███████▊  | 221/285 [04:03<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [04:04<01:05,  1.03s/it]Loading train:  78%|███████▊  | 223/285 [04:05<01:05,  1.05s/it]Loading train:  79%|███████▊  | 224/285 [04:06<01:02,  1.03s/it]Loading train:  79%|███████▉  | 225/285 [04:07<01:04,  1.08s/it]Loading train:  79%|███████▉  | 226/285 [04:08<00:58,  1.01it/s]Loading train:  80%|███████▉  | 227/285 [04:09<00:59,  1.03s/it]Loading train:  80%|████████  | 228/285 [04:10<00:57,  1.01s/it]Loading train:  80%|████████  | 229/285 [04:11<00:55,  1.01it/s]Loading train:  81%|████████  | 230/285 [04:12<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [04:13<00:52,  1.03it/s]Loading train:  81%|████████▏ | 232/285 [04:14<00:54,  1.04s/it]Loading train:  82%|████████▏ | 233/285 [04:15<00:59,  1.15s/it]Loading train:  82%|████████▏ | 234/285 [04:17<00:56,  1.11s/it]Loading train:  82%|████████▏ | 235/285 [04:18<01:01,  1.24s/it]Loading train:  83%|████████▎ | 236/285 [04:19<00:59,  1.21s/it]Loading train:  83%|████████▎ | 237/285 [04:20<00:57,  1.21s/it]Loading train:  84%|████████▎ | 238/285 [04:22<00:58,  1.23s/it]Loading train:  84%|████████▍ | 239/285 [04:23<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [04:24<00:54,  1.21s/it]Loading train:  85%|████████▍ | 241/285 [04:25<00:53,  1.22s/it]Loading train:  85%|████████▍ | 242/285 [04:26<00:52,  1.21s/it]Loading train:  85%|████████▌ | 243/285 [04:28<00:51,  1.23s/it]Loading train:  86%|████████▌ | 244/285 [04:29<00:50,  1.23s/it]Loading train:  86%|████████▌ | 245/285 [04:30<00:50,  1.27s/it]Loading train:  86%|████████▋ | 246/285 [04:31<00:46,  1.20s/it]Loading train:  87%|████████▋ | 247/285 [04:33<00:46,  1.22s/it]Loading train:  87%|████████▋ | 248/285 [04:34<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:35<00:44,  1.24s/it]Loading train:  88%|████████▊ | 250/285 [04:36<00:40,  1.14s/it]Loading train:  88%|████████▊ | 251/285 [04:37<00:38,  1.13s/it]Loading train:  88%|████████▊ | 252/285 [04:38<00:35,  1.07s/it]Loading train:  89%|████████▉ | 253/285 [04:39<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [04:40<00:32,  1.05s/it]Loading train:  89%|████████▉ | 255/285 [04:41<00:33,  1.11s/it]Loading train:  90%|████████▉ | 256/285 [04:43<00:32,  1.12s/it]Loading train:  90%|█████████ | 257/285 [04:44<00:30,  1.08s/it]Loading train:  91%|█████████ | 258/285 [04:45<00:29,  1.08s/it]Loading train:  91%|█████████ | 259/285 [04:46<00:27,  1.07s/it]Loading train:  91%|█████████ | 260/285 [04:47<00:28,  1.15s/it]Loading train:  92%|█████████▏| 261/285 [04:48<00:27,  1.15s/it]Loading train:  92%|█████████▏| 262/285 [04:49<00:25,  1.13s/it]Loading train:  92%|█████████▏| 263/285 [04:50<00:25,  1.16s/it]Loading train:  93%|█████████▎| 264/285 [04:51<00:23,  1.13s/it]Loading train:  93%|█████████▎| 265/285 [04:53<00:22,  1.11s/it]Loading train:  93%|█████████▎| 266/285 [04:54<00:21,  1.13s/it]Loading train:  94%|█████████▎| 267/285 [04:55<00:19,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [04:56<00:20,  1.19s/it]Loading train:  94%|█████████▍| 269/285 [04:57<00:19,  1.21s/it]Loading train:  95%|█████████▍| 270/285 [04:59<00:19,  1.28s/it]Loading train:  95%|█████████▌| 271/285 [05:00<00:17,  1.26s/it]Loading train:  95%|█████████▌| 272/285 [05:02<00:17,  1.32s/it]Loading train:  96%|█████████▌| 273/285 [05:03<00:15,  1.30s/it]Loading train:  96%|█████████▌| 274/285 [05:04<00:14,  1.34s/it]Loading train:  96%|█████████▋| 275/285 [05:05<00:13,  1.31s/it]Loading train:  97%|█████████▋| 276/285 [05:07<00:12,  1.40s/it]Loading train:  97%|█████████▋| 277/285 [05:08<00:10,  1.32s/it]Loading train:  98%|█████████▊| 278/285 [05:09<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [05:11<00:07,  1.29s/it]Loading train:  98%|█████████▊| 280/285 [05:12<00:06,  1.31s/it]Loading train:  99%|█████████▊| 281/285 [05:13<00:05,  1.31s/it]Loading train:  99%|█████████▉| 282/285 [05:15<00:04,  1.34s/it]Loading train:  99%|█████████▉| 283/285 [05:16<00:02,  1.36s/it]Loading train: 100%|█████████▉| 284/285 [05:18<00:01,  1.36s/it]Loading train: 100%|██████████| 285/285 [05:19<00:00,  1.30s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.90it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:05, 46.47it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:05, 49.36it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:04, 57.80it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:04, 54.02it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:04, 55.07it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:03, 61.77it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:02, 77.28it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:02, 87.86it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:02, 88.97it/s]concatenating: train:  36%|███▌      | 103/285 [00:01<00:02, 86.83it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:01, 101.76it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 125.67it/s]concatenating: train:  62%|██████▏   | 178/285 [00:01<00:00, 150.88it/s]concatenating: train:  72%|███████▏  | 206/285 [00:01<00:00, 174.27it/s]concatenating: train:  80%|████████  | 229/285 [00:01<00:00, 125.16it/s]concatenating: train:  89%|████████▉ | 255/285 [00:02<00:00, 147.64it/s]concatenating: train:  99%|█████████▉| 283/285 [00:02<00:00, 171.56it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 132.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.47s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 407.32it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 19s - loss: 27787.3390 - acc: 0.8390 - mDice: 0.0885 - val_loss: 30671.2683 - val_acc: 0.8679 - val_mDice: 0.1284

Epoch 00001: val_mDice improved from -inf to 0.12838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 8s - loss: 15289.7070 - acc: 0.8474 - mDice: 0.1662 - val_loss: 19768.1091 - val_acc: 0.9008 - val_mDice: 0.2089

Epoch 00002: val_mDice improved from 0.12838 to 0.20893, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 8689.6876 - acc: 0.8576 - mDice: 0.2187 - val_loss: 14526.0316 - val_acc: 0.8961 - val_mDice: 0.2755

Epoch 00003: val_mDice improved from 0.20893 to 0.27549, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 7547.4749 - acc: 0.8652 - mDice: 0.2561 - val_loss: 13462.2575 - val_acc: 0.9020 - val_mDice: 0.3131

Epoch 00004: val_mDice improved from 0.27549 to 0.31308, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 8s - loss: 6713.2059 - acc: 0.8722 - mDice: 0.2881 - val_loss: 9187.3343 - val_acc: 0.9060 - val_mDice: 0.3328

Epoch 00005: val_mDice improved from 0.31308 to 0.33282, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 5865.7096 - acc: 0.8779 - mDice: 0.3254 - val_loss: 4495.8438 - val_acc: 0.9101 - val_mDice: 0.3854

Epoch 00006: val_mDice improved from 0.33282 to 0.38544, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 8s - loss: 5269.1414 - acc: 0.8833 - mDice: 0.3596 - val_loss: 4060.0122 - val_acc: 0.9178 - val_mDice: 0.4134

Epoch 00007: val_mDice improved from 0.38544 to 0.41341, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 8s - loss: 4917.2146 - acc: 0.8880 - mDice: 0.3841 - val_loss: 3977.7297 - val_acc: 0.9141 - val_mDice: 0.4244

Epoch 00008: val_mDice improved from 0.41341 to 0.42442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 8s - loss: 4642.9020 - acc: 0.8922 - mDice: 0.4037 - val_loss: 3701.7197 - val_acc: 0.9204 - val_mDice: 0.4471

Epoch 00009: val_mDice improved from 0.42442 to 0.44715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 8s - loss: 4409.6581 - acc: 0.8954 - mDice: 0.4213 - val_loss: 3545.9821 - val_acc: 0.9198 - val_mDice: 0.4648

Epoch 00010: val_mDice improved from 0.44715 to 0.46485, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 8s - loss: 4201.2165 - acc: 0.8980 - mDice: 0.4376 - val_loss: 3465.8376 - val_acc: 0.9214 - val_mDice: 0.4713

Epoch 00011: val_mDice improved from 0.46485 to 0.47132, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 8s - loss: 4019.4050 - acc: 0.9002 - mDice: 0.4521 - val_loss: 3302.1457 - val_acc: 0.9221 - val_mDice: 0.4875

Epoch 00012: val_mDice improved from 0.47132 to 0.48747, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 8s - loss: 3850.2035 - acc: 0.9023 - mDice: 0.4660 - val_loss: 3133.2772 - val_acc: 0.9267 - val_mDice: 0.5000

Epoch 00013: val_mDice improved from 0.48747 to 0.50003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 11s - loss: 3711.2831 - acc: 0.9044 - mDice: 0.4786 - val_loss: 3237.3275 - val_acc: 0.9249 - val_mDice: 0.4931

Epoch 00014: val_mDice did not improve from 0.50003
Epoch 15/300
 - 10s - loss: 3600.0438 - acc: 0.9064 - mDice: 0.4885 - val_loss: 3114.5793 - val_acc: 0.9265 - val_mDice: 0.5044

Epoch 00015: val_mDice improved from 0.50003 to 0.50438, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 3491.1899 - acc: 0.9076 - mDice: 0.4985 - val_loss: 3093.9120 - val_acc: 0.9298 - val_mDice: 0.5067

Epoch 00016: val_mDice improved from 0.50438 to 0.50673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 3386.1212 - acc: 0.9092 - mDice: 0.5084 - val_loss: 2987.0071 - val_acc: 0.9318 - val_mDice: 0.5142

Epoch 00017: val_mDice improved from 0.50673 to 0.51423, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 10s - loss: 3321.6775 - acc: 0.9105 - mDice: 0.5148 - val_loss: 3114.7634 - val_acc: 0.9279 - val_mDice: 0.5047

Epoch 00018: val_mDice did not improve from 0.51423
Epoch 19/300
 - 11s - loss: 3238.5494 - acc: 0.9116 - mDice: 0.5232 - val_loss: 3076.4390 - val_acc: 0.9294 - val_mDice: 0.5068

Epoch 00019: val_mDice did not improve from 0.51423
Epoch 20/300
 - 10s - loss: 3164.9900 - acc: 0.9126 - mDice: 0.5304 - val_loss: 3032.9103 - val_acc: 0.9318 - val_mDice: 0.5087

Epoch 00020: val_mDice did not improve from 0.51423
Epoch 21/300
 - 11s - loss: 3090.5052 - acc: 0.9140 - mDice: 0.5380 - val_loss: 2990.6617 - val_acc: 0.9337 - val_mDice: 0.5122

Epoch 00021: val_mDice did not improve from 0.51423
Epoch 22/300
 - 11s - loss: 3041.7297 - acc: 0.9148 - mDice: 0.5430 - val_loss: 3086.3189 - val_acc: 0.9294 - val_mDice: 0.5085

Epoch 00022: val_mDice did not improve from 0.51423
Epoch 23/300
 - 11s - loss: 2987.4409 - acc: 0.9155 - mDice: 0.5488 - val_loss: 2956.6185 - val_acc: 0.9335 - val_mDice: 0.5170

Epoch 00023: val_mDice improved from 0.51423 to 0.51701, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 10s - loss: 2939.7525 - acc: 0.9165 - mDice: 0.5541 - val_loss: 2976.8828 - val_acc: 0.9319 - val_mDice: 0.5168

Epoch 00024: val_mDice did not improve from 0.51701
Epoch 25/300
 - 11s - loss: 2875.6453 - acc: 0.9173 - mDice: 0.5610 - val_loss: 2962.0333 - val_acc: 0.9347 - val_mDice: 0.5180

Epoch 00025: val_mDice improved from 0.51701 to 0.51800, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 11s - loss: 2839.2512 - acc: 0.9182 - mDice: 0.5651 - val_loss: 2975.7082 - val_acc: 0.9300 - val_mDice: 0.5164

Epoch 00026: val_mDice did not improve from 0.51800
Epoch 27/300
 - 11s - loss: 2780.5530 - acc: 0.9187 - mDice: 0.5713 - val_loss: 2917.3491 - val_acc: 0.9368 - val_mDice: 0.5220

Epoch 00027: val_mDice improved from 0.51800 to 0.52200, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 11s - loss: 2766.8228 - acc: 0.9191 - mDice: 0.5730 - val_loss: 2948.0283 - val_acc: 0.9329 - val_mDice: 0.5206

Epoch 00028: val_mDice did not improve from 0.52200
Epoch 29/300
 - 10s - loss: 2724.0888 - acc: 0.9199 - mDice: 0.5778 - val_loss: 2942.1432 - val_acc: 0.9326 - val_mDice: 0.5216

Epoch 00029: val_mDice did not improve from 0.52200
Epoch 30/300
 - 10s - loss: 2674.2334 - acc: 0.9207 - mDice: 0.5833 - val_loss: 2874.3741 - val_acc: 0.9362 - val_mDice: 0.5264

Epoch 00030: val_mDice improved from 0.52200 to 0.52639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 11s - loss: 2634.6527 - acc: 0.9214 - mDice: 0.5880 - val_loss: 2839.7885 - val_acc: 0.9354 - val_mDice: 0.5313

Epoch 00031: val_mDice improved from 0.52639 to 0.53126, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 10s - loss: 2615.1892 - acc: 0.9217 - mDice: 0.5902 - val_loss: 2937.0408 - val_acc: 0.9368 - val_mDice: 0.5195

Epoch 00032: val_mDice did not improve from 0.53126
Epoch 33/300
 - 11s - loss: 2582.2754 - acc: 0.9223 - mDice: 0.5940 - val_loss: 2856.7880 - val_acc: 0.9348 - val_mDice: 0.5297

Epoch 00033: val_mDice did not improve from 0.53126
Epoch 34/300
 - 11s - loss: 2545.6008 - acc: 0.9229 - mDice: 0.5983 - val_loss: 2775.2747 - val_acc: 0.9385 - val_mDice: 0.5364

Epoch 00034: val_mDice improved from 0.53126 to 0.53638, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 2523.8668 - acc: 0.9232 - mDice: 0.6008 - val_loss: 2845.5596 - val_acc: 0.9367 - val_mDice: 0.5316

Epoch 00035: val_mDice did not improve from 0.53638
Epoch 36/300
 - 10s - loss: 2493.7352 - acc: 0.9238 - mDice: 0.6045 - val_loss: 2799.4239 - val_acc: 0.9392 - val_mDice: 0.5370

Epoch 00036: val_mDice improved from 0.53638 to 0.53696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 10s - loss: 2453.0632 - acc: 0.9244 - mDice: 0.6093 - val_loss: 2773.2274 - val_acc: 0.9352 - val_mDice: 0.5403

Epoch 00037: val_mDice improved from 0.53696 to 0.54028, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 38/300
 - 9s - loss: 2438.9359 - acc: 0.9248 - mDice: 0.6110 - val_loss: 2809.9361 - val_acc: 0.9357 - val_mDice: 0.5346

Epoch 00038: val_mDice did not improve from 0.54028
Epoch 39/300
 - 8s - loss: 2414.5560 - acc: 0.9252 - mDice: 0.6139 - val_loss: 2758.0654 - val_acc: 0.9392 - val_mDice: 0.5390

Epoch 00039: val_mDice did not improve from 0.54028
Epoch 40/300
 - 9s - loss: 2381.2728 - acc: 0.9257 - mDice: 0.6179 - val_loss: 2910.4223 - val_acc: 0.9344 - val_mDice: 0.5248

Epoch 00040: val_mDice did not improve from 0.54028
Epoch 41/300
 - 8s - loss: 2356.8350 - acc: 0.9260 - mDice: 0.6209 - val_loss: 2749.1109 - val_acc: 0.9404 - val_mDice: 0.5413

Epoch 00041: val_mDice improved from 0.54028 to 0.54133, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 42/300
 - 9s - loss: 2330.8823 - acc: 0.9264 - mDice: 0.6240 - val_loss: 2678.9690 - val_acc: 0.9399 - val_mDice: 0.5473

Epoch 00042: val_mDice improved from 0.54133 to 0.54732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 43/300
 - 9s - loss: 2324.3408 - acc: 0.9268 - mDice: 0.6251 - val_loss: 2793.4946 - val_acc: 0.9375 - val_mDice: 0.5391

Epoch 00043: val_mDice did not improve from 0.54732
Epoch 44/300
 - 8s - loss: 2294.5042 - acc: 0.9273 - mDice: 0.6286 - val_loss: 2680.9764 - val_acc: 0.9410 - val_mDice: 0.5469

Epoch 00044: val_mDice did not improve from 0.54732
Epoch 45/300
 - 9s - loss: 2282.8298 - acc: 0.9274 - mDice: 0.6303 - val_loss: 2772.4276 - val_acc: 0.9363 - val_mDice: 0.5398

Epoch 00045: val_mDice did not improve from 0.54732
Epoch 46/300
 - 8s - loss: 2245.5819 - acc: 0.9283 - mDice: 0.6348 - val_loss: 2703.7773 - val_acc: 0.9415 - val_mDice: 0.5449

Epoch 00046: val_mDice did not improve from 0.54732
Epoch 47/300
 - 8s - loss: 2225.3946 - acc: 0.9285 - mDice: 0.6374 - val_loss: 2622.7610 - val_acc: 0.9410 - val_mDice: 0.5555

Epoch 00047: val_mDice improved from 0.54732 to 0.55546, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 8s - loss: 2215.6988 - acc: 0.9287 - mDice: 0.6384 - val_loss: 2642.9926 - val_acc: 0.9413 - val_mDice: 0.5511

Epoch 00048: val_mDice did not improve from 0.55546
Epoch 49/300
 - 8s - loss: 2181.9312 - acc: 0.9294 - mDice: 0.6428 - val_loss: 2726.2370 - val_acc: 0.9407 - val_mDice: 0.5417

Epoch 00049: val_mDice did not improve from 0.55546
Epoch 50/300
 - 8s - loss: 2177.2327 - acc: 0.9294 - mDice: 0.6435 - val_loss: 2594.1162 - val_acc: 0.9414 - val_mDice: 0.5570

Epoch 00050: val_mDice improved from 0.55546 to 0.55696, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 51/300
 - 8s - loss: 2164.5149 - acc: 0.9299 - mDice: 0.6451 - val_loss: 2764.6725 - val_acc: 0.9401 - val_mDice: 0.5374

Epoch 00051: val_mDice did not improve from 0.55696
Epoch 52/300
 - 8s - loss: 2138.4281 - acc: 0.9302 - mDice: 0.6486 - val_loss: 2629.7385 - val_acc: 0.9409 - val_mDice: 0.5530

Epoch 00052: val_mDice did not improve from 0.55696
Epoch 53/300
 - 8s - loss: 2116.9429 - acc: 0.9305 - mDice: 0.6512 - val_loss: 2613.7332 - val_acc: 0.9421 - val_mDice: 0.5542

Epoch 00053: val_mDice did not improve from 0.55696
Epoch 54/300
 - 8s - loss: 2099.4043 - acc: 0.9309 - mDice: 0.6535 - val_loss: 2632.6622 - val_acc: 0.9431 - val_mDice: 0.5522

Epoch 00054: val_mDice did not improve from 0.55696
Epoch 55/300
 - 8s - loss: 2086.2629 - acc: 0.9312 - mDice: 0.6552 - val_loss: 2697.8299 - val_acc: 0.9406 - val_mDice: 0.5474

Epoch 00055: val_mDice did not improve from 0.55696
Epoch 56/300
 - 8s - loss: 2063.6428 - acc: 0.9315 - mDice: 0.6581 - val_loss: 2656.9251 - val_acc: 0.9435 - val_mDice: 0.5488

Epoch 00056: val_mDice did not improve from 0.55696
Epoch 57/300
 - 8s - loss: 2057.0156 - acc: 0.9317 - mDice: 0.6590 - val_loss: 2601.3353 - val_acc: 0.9430 - val_mDice: 0.5552

Epoch 00057: val_mDice did not improve from 0.55696
Epoch 58/300
 - 8s - loss: 2049.1625 - acc: 0.9318 - mDice: 0.6601 - val_loss: 2602.0282 - val_acc: 0.9432 - val_mDice: 0.5563

Epoch 00058: val_mDice did not improve from 0.55696
Epoch 59/300
 - 8s - loss: 2035.2393 - acc: 0.9322 - mDice: 0.6620 - val_loss: 2639.8744 - val_acc: 0.9432 - val_mDice: 0.5496

Epoch 00059: val_mDice did not improve from 0.55696
Epoch 60/300
 - 8s - loss: 2018.7882 - acc: 0.9324 - mDice: 0.6641 - val_loss: 2670.5048 - val_acc: 0.9426 - val_mDice: 0.5484

Epoch 00060: val_mDice did not improve from 0.55696
Epoch 61/300
 - 8s - loss: 2004.8367 - acc: 0.9327 - mDice: 0.6660 - val_loss: 2615.8373 - val_acc: 0.9448 - val_mDice: 0.5511

Epoch 00061: val_mDice did not improve from 0.55696
Epoch 62/300
 - 8s - loss: 2000.7095 - acc: 0.9327 - mDice: 0.6665 - val_loss: 2624.0046 - val_acc: 0.9421 - val_mDice: 0.5523

Epoch 00062: val_mDice did not improve from 0.55696
Epoch 63/300
 - 8s - loss: 1976.3444 - acc: 0.9330 - mDice: 0.6696 - val_loss: 2794.7179 - val_acc: 0.9438 - val_mDice: 0.5308

Epoch 00063: val_mDice did not improve from 0.55696
Epoch 64/300
 - 8s - loss: 1972.5471 - acc: 0.9330 - mDice: 0.6701 - val_loss: 2614.7530 - val_acc: 0.9444 - val_mDice: 0.5518

Epoch 00064: val_mDice did not improve from 0.55696
Epoch 65/300
 - 8s - loss: 1957.3238 - acc: 0.9335 - mDice: 0.6723 - val_loss: 2639.3158 - val_acc: 0.9430 - val_mDice: 0.5505

Epoch 00065: val_mDice did not improve from 0.55696
Epoch 66/300
 - 8s - loss: 1946.4386 - acc: 0.9337 - mDice: 0.6737 - val_loss: 2557.7734 - val_acc: 0.9437 - val_mDice: 0.5592

Epoch 00066: val_mDice improved from 0.55696 to 0.55921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 67/300
 - 8s - loss: 1927.6172 - acc: 0.9338 - mDice: 0.6762 - val_loss: 2614.0175 - val_acc: 0.9442 - val_mDice: 0.5532

Epoch 00067: val_mDice did not improve from 0.55921
Epoch 68/300
 - 8s - loss: 1924.4211 - acc: 0.9341 - mDice: 0.6767 - val_loss: 2647.7047 - val_acc: 0.9439 - val_mDice: 0.5484

Epoch 00068: val_mDice did not improve from 0.55921
Epoch 69/300
 - 8s - loss: 1910.0880 - acc: 0.9343 - mDice: 0.6786 - val_loss: 2611.6575 - val_acc: 0.9450 - val_mDice: 0.5527

Epoch 00069: val_mDice did not improve from 0.55921
Epoch 70/300
 - 8s - loss: 1908.8068 - acc: 0.9343 - mDice: 0.6787 - val_loss: 2839.2771 - val_acc: 0.9446 - val_mDice: 0.5273

Epoch 00070: val_mDice did not improve from 0.55921
Epoch 71/300
 - 8s - loss: 1894.1542 - acc: 0.9344 - mDice: 0.6806 - val_loss: 2750.0268 - val_acc: 0.9443 - val_mDice: 0.5352

Epoch 00071: val_mDice did not improve from 0.55921
Epoch 72/300
 - 8s - loss: 1877.0925 - acc: 0.9348 - mDice: 0.6832 - val_loss: 2553.2117 - val_acc: 0.9430 - val_mDice: 0.5610

Epoch 00072: val_mDice improved from 0.55921 to 0.56100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 73/300
 - 8s - loss: 1870.2567 - acc: 0.9350 - mDice: 0.6840 - val_loss: 2539.6671 - val_acc: 0.9443 - val_mDice: 0.5606

Epoch 00073: val_mDice did not improve from 0.56100
Epoch 74/300
 - 8s - loss: 1855.4398 - acc: 0.9352 - mDice: 0.6859 - val_loss: 2483.5676 - val_acc: 0.9451 - val_mDice: 0.5661

Epoch 00074: val_mDice improved from 0.56100 to 0.56606, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 75/300
 - 8s - loss: 1854.7411 - acc: 0.9353 - mDice: 0.6860 - val_loss: 2509.4583 - val_acc: 0.9454 - val_mDice: 0.5634

Epoch 00075: val_mDice did not improve from 0.56606
Epoch 76/300
 - 8s - loss: 1842.9622 - acc: 0.9356 - mDice: 0.6877 - val_loss: 2614.1904 - val_acc: 0.9457 - val_mDice: 0.5530

Epoch 00076: val_mDice did not improve from 0.56606
Epoch 77/300
 - 8s - loss: 1835.9089 - acc: 0.9354 - mDice: 0.6886 - val_loss: 2539.2930 - val_acc: 0.9447 - val_mDice: 0.5609

Epoch 00077: val_mDice did not improve from 0.56606
Epoch 78/300
 - 8s - loss: 1829.1680 - acc: 0.9357 - mDice: 0.6896 - val_loss: 2798.9853 - val_acc: 0.9447 - val_mDice: 0.5323

Epoch 00078: val_mDice did not improve from 0.56606
Epoch 79/300
 - 8s - loss: 1820.9634 - acc: 0.9358 - mDice: 0.6907 - val_loss: 2665.9200 - val_acc: 0.9439 - val_mDice: 0.5500

Epoch 00079: val_mDice did not improve from 0.56606
Epoch 80/300
 - 8s - loss: 1805.5148 - acc: 0.9361 - mDice: 0.6928 - val_loss: 2523.2774 - val_acc: 0.9446 - val_mDice: 0.5639

Epoch 00080: val_mDice did not improve from 0.56606
Epoch 81/300
 - 8s - loss: 1805.4324 - acc: 0.9361 - mDice: 0.6928 - val_loss: 2584.5313 - val_acc: 0.9435 - val_mDice: 0.5592

Epoch 00081: val_mDice did not improve from 0.56606
Epoch 82/300
 - 8s - loss: 1789.0537 - acc: 0.9362 - mDice: 0.6951 - val_loss: 2652.4601 - val_acc: 0.9453 - val_mDice: 0.5466

Epoch 00082: val_mDice did not improve from 0.56606
Epoch 83/300
 - 8s - loss: 1796.3767 - acc: 0.9362 - mDice: 0.6941 - val_loss: 2523.7037 - val_acc: 0.9461 - val_mDice: 0.5625

Epoch 00083: val_mDice did not improve from 0.56606
Epoch 84/300
 - 8s - loss: 1780.2194 - acc: 0.9364 - mDice: 0.6964 - val_loss: 2516.3810 - val_acc: 0.9460 - val_mDice: 0.5630

Epoch 00084: val_mDice did not improve from 0.56606
Epoch 85/300
 - 8s - loss: 1763.6559 - acc: 0.9368 - mDice: 0.6986 - val_loss: 2520.8781 - val_acc: 0.9457 - val_mDice: 0.5629

Epoch 00085: val_mDice did not improve from 0.56606
Epoch 86/300
 - 8s - loss: 1767.3701 - acc: 0.9367 - mDice: 0.6982 - val_loss: 2668.1878 - val_acc: 0.9418 - val_mDice: 0.5491

Epoch 00086: val_mDice did not improve from 0.56606
Epoch 87/300
 - 8s - loss: 1756.9996 - acc: 0.9368 - mDice: 0.6997 - val_loss: 2494.3898 - val_acc: 0.9449 - val_mDice: 0.5680

Epoch 00087: val_mDice improved from 0.56606 to 0.56804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 88/300
 - 8s - loss: 1747.7895 - acc: 0.9370 - mDice: 0.7009 - val_loss: 2446.9040 - val_acc: 0.9463 - val_mDice: 0.5718

Epoch 00088: val_mDice improved from 0.56804 to 0.57180, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 89/300
 - 8s - loss: 1745.9140 - acc: 0.9370 - mDice: 0.7012 - val_loss: 2604.4758 - val_acc: 0.9416 - val_mDice: 0.5554

Epoch 00089: val_mDice did not improve from 0.57180
Epoch 90/300
 - 8s - loss: 1740.1141 - acc: 0.9371 - mDice: 0.7020 - val_loss: 2490.9921 - val_acc: 0.9450 - val_mDice: 0.5671

Epoch 00090: val_mDice did not improve from 0.57180
Epoch 91/300
 - 8s - loss: 1727.3253 - acc: 0.9373 - mDice: 0.7037 - val_loss: 2582.8388 - val_acc: 0.9445 - val_mDice: 0.5571

Epoch 00091: val_mDice did not improve from 0.57180
Epoch 92/300
 - 8s - loss: 1719.6368 - acc: 0.9375 - mDice: 0.7049 - val_loss: 2654.2640 - val_acc: 0.9464 - val_mDice: 0.5489

Epoch 00092: val_mDice did not improve from 0.57180
Epoch 93/300
 - 8s - loss: 1719.8663 - acc: 0.9374 - mDice: 0.7048 - val_loss: 3023.9844 - val_acc: 0.9439 - val_mDice: 0.5104

Epoch 00093: val_mDice did not improve from 0.57180
Epoch 94/300
 - 8s - loss: 1707.7818 - acc: 0.9375 - mDice: 0.7065 - val_loss: 2602.9973 - val_acc: 0.9445 - val_mDice: 0.5556

Epoch 00094: val_mDice did not improve from 0.57180
Epoch 95/300
 - 8s - loss: 1702.3338 - acc: 0.9378 - mDice: 0.7072 - val_loss: 2572.4174 - val_acc: 0.9438 - val_mDice: 0.5596

Epoch 00095: val_mDice did not improve from 0.57180
Epoch 96/300
 - 8s - loss: 1702.1814 - acc: 0.9378 - mDice: 0.7073 - val_loss: 2547.0269 - val_acc: 0.9452 - val_mDice: 0.5601

Epoch 00096: val_mDice did not improve from 0.57180
Epoch 97/300
 - 8s - loss: 1689.0168 - acc: 0.9378 - mDice: 0.7092 - val_loss: 2580.2785 - val_acc: 0.9434 - val_mDice: 0.5579

Epoch 00097: val_mDice did not improve from 0.57180
Epoch 98/300
 - 8s - loss: 1683.2676 - acc: 0.9379 - mDice: 0.7100 - val_loss: 2635.0842 - val_acc: 0.9457 - val_mDice: 0.5523

Epoch 00098: val_mDice did not improve from 0.57180
Epoch 99/300
 - 8s - loss: 1674.3897 - acc: 0.9381 - mDice: 0.7111 - val_loss: 2806.8333 - val_acc: 0.9457 - val_mDice: 0.5329

Epoch 00099: val_mDice did not improve from 0.57180
Epoch 100/300
 - 8s - loss: 1668.2812 - acc: 0.9383 - mDice: 0.7121 - val_loss: 2819.2291 - val_acc: 0.9399 - val_mDice: 0.5327

Epoch 00100: val_mDice did not improve from 0.57180
Epoch 101/300
 - 8s - loss: 1670.9317 - acc: 0.9384 - mDice: 0.7117 - val_loss: 2616.6965 - val_acc: 0.9446 - val_mDice: 0.5525

Epoch 00101: val_mDice did not improve from 0.57180
Epoch 102/300
 - 8s - loss: 1666.3047 - acc: 0.9383 - mDice: 0.7124 - val_loss: 2562.5319 - val_acc: 0.9453 - val_mDice: 0.5585

Epoch 00102: val_mDice did not improve from 0.57180
Epoch 103/300
 - 8s - loss: 1664.1383 - acc: 0.9382 - mDice: 0.7126 - val_loss: 2542.1431 - val_acc: 0.9468 - val_mDice: 0.5634

Epoch 00103: val_mDice did not improve from 0.57180
Epoch 104/300
 - 8s - loss: 1651.5728 - acc: 0.9385 - mDice: 0.7144 - val_loss: 2551.9017 - val_acc: 0.9449 - val_mDice: 0.5592

Epoch 00104: val_mDice did not improve from 0.57180
Epoch 105/300
 - 8s - loss: 1648.0238 - acc: 0.9385 - mDice: 0.7149 - val_loss: 2497.2265 - val_acc: 0.9470 - val_mDice: 0.5648

Epoch 00105: val_mDice did not improve from 0.57180
Epoch 106/300
 - 8s - loss: 1635.5340 - acc: 0.9388 - mDice: 0.7167 - val_loss: 2581.7701 - val_acc: 0.9458 - val_mDice: 0.5562

Epoch 00106: val_mDice did not improve from 0.57180
Epoch 107/300
 - 8s - loss: 1629.4106 - acc: 0.9391 - mDice: 0.7176 - val_loss: 2638.6104 - val_acc: 0.9466 - val_mDice: 0.5489

Epoch 00107: val_mDice did not improve from 0.57180
Epoch 108/300
 - 8s - loss: 1634.9243 - acc: 0.9388 - mDice: 0.7168 - val_loss: 2462.6951 - val_acc: 0.9451 - val_mDice: 0.5706

Epoch 00108: val_mDice did not improve from 0.57180
Epoch 109/300
 - 8s - loss: 1630.3324 - acc: 0.9388 - mDice: 0.7175 - val_loss: 2700.7313 - val_acc: 0.9458 - val_mDice: 0.5453

Epoch 00109: val_mDice did not improve from 0.57180
Epoch 110/300
 - 8s - loss: 1615.7246 - acc: 0.9393 - mDice: 0.7196 - val_loss: 2465.9841 - val_acc: 0.9458 - val_mDice: 0.5687

Epoch 00110: val_mDice did not improve from 0.57180
Epoch 111/300
 - 8s - loss: 1622.3891 - acc: 0.9390 - mDice: 0.7186 - val_loss: 2620.0356 - val_acc: 0.9436 - val_mDice: 0.5534

Epoch 00111: val_mDice did not improve from 0.57180
Epoch 112/300
 - 8s - loss: 1619.1895 - acc: 0.9391 - mDice: 0.7191 - val_loss: 2645.5105 - val_acc: 0.9438 - val_mDice: 0.5521

Epoch 00112: val_mDice did not improve from 0.57180
Epoch 113/300
 - 8s - loss: 1606.7071 - acc: 0.9395 - mDice: 0.7209 - val_loss: 2606.4857 - val_acc: 0.9446 - val_mDice: 0.5534

Epoch 00113: val_mDice did not improve from 0.57180
Epoch 114/300
 - 8s - loss: 1607.7032 - acc: 0.9394 - mDice: 0.7208 - val_loss: 2728.2311 - val_acc: 0.9417 - val_mDice: 0.5411

Epoch 00114: val_mDice did not improve from 0.57180
Epoch 115/300
 - 8s - loss: 1602.4492 - acc: 0.9396 - mDice: 0.7215 - val_loss: 2513.8077 - val_acc: 0.9447 - val_mDice: 0.5642

Epoch 00115: val_mDice did not improve from 0.57180
Epoch 116/300
 - 8s - loss: 1590.9928 - acc: 0.9397 - mDice: 0.7231 - val_loss: 2699.0496 - val_acc: 0.9440 - val_mDice: 0.5444

Epoch 00116: val_mDice did not improve from 0.57180
Epoch 117/300
 - 8s - loss: 1594.5398 - acc: 0.9394 - mDice: 0.7226 - val_loss: 2951.2177 - val_acc: 0.9441 - val_mDice: 0.5160

Epoch 00117: val_mDice did not improve from 0.57180
Epoch 118/300
 - 8s - loss: 1594.3784 - acc: 0.9396 - mDice: 0.7226 - val_loss: 2606.2453 - val_acc: 0.9448 - val_mDice: 0.5522

Epoch 00118: val_mDice did not improve from 0.57180
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
{'val_loss': [30671.26828729539, 19768.10906110491, 14526.031552269345, 13462.257486979166, 9187.334344773066, 4495.843784877232, 4060.012201218378, 3977.7296549479165, 3701.71969749814, 3545.982131231399, 3465.837599981399, 3302.145728701637, 3133.2771577380954, 3237.3275088355654, 3114.5792701357886, 3093.9120279947915, 2987.007144019717, 3114.763404482887, 3076.439028785342, 3032.910313197545, 2990.661699567522, 3086.318894159226, 2956.6185186476932, 2976.882795061384, 2962.0332786923364, 2975.708234514509, 2917.349057152158, 2948.028265090216, 2942.1431884765625, 2874.3740960984005, 2839.7884637741818, 2937.0408296130954, 2856.7879551478795, 2775.274658203125, 2845.559634254092, 2799.4239211309523, 2773.2273995535716, 2809.9361339750744, 2758.065420968192, 2910.4223022460938, 2749.11092703683, 2678.968962169829, 2793.494634719122, 2680.9764084588915, 2772.42764718192, 2703.77725655692, 2622.7610299246653, 2642.9925653366818, 2726.2369762602307, 2594.116193498884, 2764.6724853515625, 2629.738534109933, 2613.733224051339, 2632.662150065104, 2697.8299066452755, 2656.925057547433, 2601.3353097098216, 2602.0282360258557, 2639.8744230724515, 2670.5047752743676, 2615.837299891881, 2624.004616873605, 2794.717931111654, 2614.7530408586777, 2639.3158089773997, 2557.773390997024, 2614.01749819801, 2647.7046726771764, 2611.6575215657554, 2839.2770545596168, 2750.0267573765345, 2553.211707705543, 2539.6671360560827, 2483.5675920758927, 2509.4583195277623, 2614.190442766462, 2539.2929571242557, 2798.985326857794, 2665.9200381324404, 2523.27737281436, 2584.531319754464, 2652.4601077125185, 2523.7037426176526, 2516.3809967041016, 2520.8781077067056, 2668.1878473191036, 2494.389828636533, 2446.9039786202566, 2604.4758097330728, 2490.9920668829054, 2582.838827950614, 2654.2640351795017, 3023.9844498407274, 2602.997317359561, 2572.4174049014136, 2547.0269324893043, 2580.2785208565847, 2635.084243774414, 2806.833300635928, 2819.229066394624, 2616.696501958938, 2562.5318559919083, 2542.143053327288, 2551.9016861688524, 2497.226514543806, 2581.7701183500744, 2638.610368274507, 2462.695060366676, 2700.7312614804223, 2465.984114147368, 2620.035642351423, 2645.510511125837, 2606.4857308523997, 2728.2310660226003, 2513.8077022007533, 2699.049593970889, 2951.217724754697, 2606.24533589681], 'val_acc': [0.8679235378901163, 0.9007761222975594, 0.8960806074596587, 0.9019620021184286, 0.9059775500070482, 0.9101007495607648, 0.9178410910424732, 0.9141117249216352, 0.9203914716130212, 0.919764206522987, 0.9213942459651402, 0.9221245220729283, 0.9266735088257563, 0.9249450280552819, 0.9265453247796922, 0.9298053752808344, 0.9317742728051686, 0.9279487104642958, 0.9293979008992513, 0.9317925827843803, 0.9336882091703869, 0.9294116213208153, 0.9334592762447539, 0.931932250658671, 0.9347023992311387, 0.9300251830191839, 0.9367559552192688, 0.9328914767219907, 0.9325938849222093, 0.9361607375599089, 0.935407505148933, 0.9367605135554359, 0.9348053903806777, 0.9385302180335635, 0.936675835223425, 0.9391895617757525, 0.9351831532659984, 0.9356570527667091, 0.9391918494587853, 0.934411625067393, 0.94043497244517, 0.93987637758255, 0.9374748269716898, 0.9409569587026324, 0.9363118069512504, 0.9415270430701119, 0.9409660980814979, 0.9413484391712007, 0.9407211712428502, 0.9414057022049314, 0.9400801062583923, 0.9409386430467878, 0.942074199517568, 0.9430769142650423, 0.9406410001573109, 0.9435050232069833, 0.9430425876662845, 0.9431547806376502, 0.9432326271420434, 0.9425847303299677, 0.9448374765259879, 0.9420650005340576, 0.9437912134897142, 0.9444253728503272, 0.9430448725110009, 0.943676749865214, 0.9442032689139956, 0.9439377131916228, 0.9449564814567566, 0.9445924702144805, 0.9442513982454935, 0.9429555904297602, 0.9443497998373849, 0.945064073517209, 0.9454464117685953, 0.9457119845208668, 0.9447161016010103, 0.9447023953710284, 0.9438988140651158, 0.9446245289984203, 0.943473009836106, 0.9452541413761321, 0.9460531189328149, 0.9460439738773164, 0.9457257361639113, 0.9418223216420128, 0.9448557609603518, 0.9462591579982212, 0.9416163194747198, 0.9449793980235145, 0.9444574316342672, 0.946449149222601, 0.9439331718853542, 0.9444986411503383, 0.9438347248804002, 0.9451556546347482, 0.9434455292565482, 0.945741784004938, 0.9456753645624433, 0.9399176041285197, 0.9446062133425758, 0.9452609959102812, 0.9468086134819758, 0.9449061495917184, 0.9469917785553705, 0.9458356386139279, 0.9465728061539787, 0.9450755601837522, 0.9458104343641371, 0.945826442468734, 0.9435508307956514, 0.9438301069395882, 0.9446062360491071, 0.9417491072700137, 0.9447183836074102, 0.9440453222819737, 0.9441231489181519, 0.9448076770419166], 'val_mDice': [0.1283830688113258, 0.20893147574471577, 0.27549197365130695, 0.3130829625186466, 0.33282096063097316, 0.3854368103756791, 0.4134106689265796, 0.42441886840831666, 0.4471481116045089, 0.4648481321831544, 0.4713207490387417, 0.48747385949605987, 0.500028974066178, 0.4931107858816783, 0.5043800114875748, 0.5067272674114931, 0.5142325915041424, 0.504671723360107, 0.5068408655268806, 0.5086833698054155, 0.5122414756388891, 0.5084836793442568, 0.5170063245154563, 0.5167923676116126, 0.518003618433362, 0.5164483677418459, 0.5219975844735191, 0.5205792823717708, 0.5215510229269663, 0.5263948857429481, 0.5312636292406491, 0.5194739640823433, 0.529686301237061, 0.5363781053040709, 0.531638039542096, 0.5369554834351653, 0.5402806213214284, 0.5345796921423503, 0.5389847434347584, 0.5248300786174479, 0.5413277819752693, 0.5473248369636989, 0.5390825463192803, 0.5469300239568665, 0.5398214959672519, 0.5449165245961576, 0.5554559805563518, 0.5510531060752415, 0.5417128884721369, 0.5569600388407707, 0.5373925818573861, 0.552974155261403, 0.5542182776899565, 0.5521540604531765, 0.547358565919456, 0.5488469242340043, 0.5552420456494603, 0.5562638881660643, 0.5496486870660668, 0.5483723637603578, 0.551139367833024, 0.5523447598375025, 0.5308416900890214, 0.5517508548994859, 0.5505214360143457, 0.5592061203150522, 0.5531971791670436, 0.5483631974174863, 0.5526948925994691, 0.5272831283509731, 0.5351530448311851, 0.5610005394333885, 0.5606056854483628, 0.5660621350010236, 0.5634442039188885, 0.5529550099301905, 0.5608866262648787, 0.5323178420464197, 0.549995195120573, 0.5639472374958652, 0.5592272930911609, 0.5466389294181552, 0.5625028792946112, 0.5630037809411684, 0.5629384808597111, 0.5491399119297663, 0.5680437645032292, 0.5717975444027356, 0.5553986270512853, 0.5671426238758224, 0.5571277272843179, 0.5489129459574109, 0.5103860447804133, 0.555590220505283, 0.5596105885647592, 0.5600560406843821, 0.5579094338629927, 0.5522667359383333, 0.5329318364106473, 0.5327398713145938, 0.5525151581636497, 0.5585423147394544, 0.5633564137277149, 0.5592437987881047, 0.564783150596278, 0.5561565770989373, 0.548879956205686, 0.5705855545543489, 0.5453031481731505, 0.5686539972112292, 0.5534482435101554, 0.5521235004777, 0.5534019122521082, 0.5411202673401151, 0.5641938980136599, 0.5444369420763993, 0.5159568981755347, 0.5522217048066003], 'loss': [27787.339023264292, 15289.706969120518, 8689.68757559087, 7547.474877849672, 6713.2059401245, 5865.709603457637, 5269.141414609239, 4917.214596691172, 4642.902028678216, 4409.658086396882, 4201.2165471803755, 4019.4049917838465, 3850.2035372667697, 3711.2830646515627, 3600.0438447757015, 3491.189866380193, 3386.121164163413, 3321.6774567221087, 3238.54944438357, 3164.9900477512138, 3090.5051971311996, 3041.7297492246994, 2987.4408878924323, 2939.752537706948, 2875.645273320772, 2839.2511717761577, 2780.553041209921, 2766.8227712742646, 2724.08884301819, 2674.233403097211, 2634.652735142205, 2615.189179425803, 2582.2754327271377, 2545.600841962742, 2523.8667861294234, 2493.7352084764193, 2453.06324338867, 2438.9359457274495, 2414.5559727330647, 2381.2728282780645, 2356.8350302448202, 2330.882281951875, 2324.3408483884364, 2294.5042107550653, 2282.8297871048567, 2245.5818817627, 2225.3945595612754, 2215.6987754890906, 2181.9311569093256, 2177.2327124244657, 2164.5148657730188, 2138.428142452736, 2116.942852737312, 2099.404255737752, 2086.2628918911237, 2063.6427921657737, 2057.0156390262014, 2049.1625158524316, 2035.239328743659, 2018.7882181273874, 2004.8367051991834, 2000.7094784691221, 1976.3444095374027, 1972.54712563598, 1957.3238055418744, 1946.4385890074495, 1927.6172184470718, 1924.4210747063723, 1910.087995797976, 1908.8067570942455, 1894.1542126236566, 1877.0924597542157, 1870.2566787075486, 1855.4397782457572, 1854.7410665099874, 1842.9621753828683, 1835.908939830044, 1829.167978822507, 1820.9633976156963, 1805.5147857813101, 1805.4324062061328, 1789.053685167885, 1796.3767454148442, 1780.2194097962756, 1763.6558600904305, 1767.3700729673117, 1756.9995655172336, 1747.7895061845193, 1745.9140118550583, 1740.1141295527732, 1727.3253227014727, 1719.6368178041635, 1719.866279844744, 1707.7818192143143, 1702.3338111184662, 1702.1814300907768, 1689.0168462914723, 1683.2675980817428, 1674.3896607927948, 1668.2812203002247, 1670.9316564162434, 1666.3047383802807, 1664.1383135714511, 1651.5728425819657, 1648.0237746230434, 1635.5339996532045, 1629.4106251628546, 1634.9242617605462, 1630.332358677079, 1615.7246186002867, 1622.3890577132058, 1619.18945493711, 1606.707144471568, 1607.7031668903328, 1602.4492437665301, 1590.9928271277277, 1594.5397598563718, 1594.3784121088102], 'acc': [0.8390160612410058, 0.8473563263796418, 0.8575521657548246, 0.8651778995818385, 0.8722226710615532, 0.8779035228305822, 0.883253621473601, 0.8879987482898654, 0.8922426696799959, 0.8954108154380714, 0.8980107199761916, 0.9002484489388151, 0.9023385940430962, 0.9043681912852409, 0.9063530226812809, 0.907587014263665, 0.909240275856983, 0.9104778638620562, 0.9115604761824894, 0.9125689791994148, 0.9140472736734633, 0.914769912021156, 0.9154884043469786, 0.9164626146870494, 0.9172748338056939, 0.9182242072913283, 0.9186825905895104, 0.9191156976687694, 0.9198507291631293, 0.9206784545214668, 0.9214218497644023, 0.9216590580830851, 0.9223218713855614, 0.9229411120379801, 0.9231693550803561, 0.923814227373264, 0.9244372929156068, 0.924776508315395, 0.9252014110974087, 0.9256905206301917, 0.9260096398419398, 0.9263856974161956, 0.9268376404595141, 0.9273177859685268, 0.9273949477606848, 0.928311047571023, 0.9284531627635356, 0.9286622654065614, 0.929363859120375, 0.9294485736150652, 0.9298624693025899, 0.9302146116248992, 0.9305205979810552, 0.9309392883204439, 0.9312103737037214, 0.9314862128648084, 0.9316546487192301, 0.9318188924492498, 0.9321995340998701, 0.9323990911515389, 0.9327057705625119, 0.9326960387798962, 0.9330279080307459, 0.93303487964832, 0.9335221172597152, 0.933710571518518, 0.9338420027824227, 0.9340784931219633, 0.9343124798136179, 0.9343427441840414, 0.9344116127488699, 0.934840504686934, 0.9349992036221918, 0.9352370618808608, 0.9352604631332389, 0.9355657069536448, 0.9354038077419333, 0.9356726928899025, 0.935839576920678, 0.9360991236054417, 0.9361112426075145, 0.9361730685394026, 0.9361924611352325, 0.9363764197191614, 0.9367892750775352, 0.9367151480891329, 0.9368498679275615, 0.9369981450245792, 0.9370327894917936, 0.9371028108267695, 0.9372829272380702, 0.9374615123374443, 0.9374173014798742, 0.9375374900345539, 0.9377664982962292, 0.9377661300850025, 0.9378195589324608, 0.9379084720785319, 0.9381424842805607, 0.9382589461028013, 0.9383567312514366, 0.9383168983992662, 0.9381840121362258, 0.9384837167006088, 0.9385243132207719, 0.9388159993229424, 0.939061757822774, 0.9388334705279424, 0.938836134649872, 0.939251654451928, 0.9390307540881604, 0.9390562258521463, 0.9394629115839558, 0.9394438172066996, 0.9396048608326328, 0.9396645747928094, 0.9394324170800793, 0.9395801802234933], 'mDice': [0.08849827495066215, 0.16619384769118312, 0.2186623905460936, 0.25614189737353776, 0.2880954411888435, 0.3253802152780386, 0.3596185976274905, 0.38414455258205077, 0.40369872169410054, 0.42131087363788977, 0.43764065992908024, 0.45210898600494287, 0.46599248917502245, 0.47862014516323365, 0.48845269640033956, 0.4984644771610493, 0.5083737882065685, 0.5148473167341294, 0.5232362281340773, 0.5304459573125389, 0.5380112620385507, 0.5430123205471756, 0.5488017678306768, 0.5540639037499429, 0.5610496291012026, 0.5650549829178563, 0.5713393055728481, 0.5729516014925014, 0.5777966517783416, 0.5833384434060368, 0.5880419105975091, 0.5901691347780038, 0.5940112670722301, 0.5982555269804308, 0.6008496790670443, 0.6045040758974823, 0.6092983859224725, 0.6110337708918878, 0.613929212794314, 0.6179318354955776, 0.6208792836858699, 0.6239660026734335, 0.6251256271711269, 0.6286389616176024, 0.630289920439995, 0.6348239539881674, 0.6373556294559812, 0.6383547182599772, 0.6428010908652299, 0.6434527195003282, 0.6451147932272691, 0.6485625206217592, 0.6511762609641768, 0.6534768195080578, 0.6551635758206177, 0.6580790364261948, 0.6589882117556956, 0.6600622998420181, 0.6619994424546365, 0.6641078320040463, 0.6659664263356644, 0.6665492234534327, 0.6696032096890555, 0.6701158876131329, 0.672333021809284, 0.6736859912147912, 0.6761741297815447, 0.6767009614013583, 0.6785569449759917, 0.678740407026915, 0.6806358195049859, 0.6831552751817661, 0.6839500306221201, 0.6859320478561597, 0.6860397722717883, 0.6877090562072498, 0.6886106380291106, 0.6895720030913491, 0.6907306238247615, 0.6928354367852234, 0.6927883806361016, 0.6950752662283988, 0.694114782940291, 0.6964122517411824, 0.698638812687118, 0.6981854743757113, 0.6996962824882698, 0.7008752184656973, 0.7012075186120491, 0.7019706001993271, 0.7037203549212612, 0.7048838112380479, 0.7047850774941886, 0.7064576325031381, 0.7072270737233042, 0.7072528044405714, 0.7091621877325737, 0.7099922678478425, 0.7110895608141171, 0.7120536018801443, 0.7116508627870949, 0.7123652187666039, 0.7126390016651208, 0.7144380629993436, 0.7149219423538231, 0.7166877533168216, 0.7175625075787415, 0.7168013941742952, 0.7175080303238471, 0.719634470508488, 0.7186157056447373, 0.7191181881983477, 0.7208519711507316, 0.7207760852679872, 0.7215275663343128, 0.7230583579181269, 0.722617936497459, 0.7226356153017481]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:18,  1.33s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:51,  1.46s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:56,  1.48s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:14,  1.55s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:05,  1.75s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:12,  1.78s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:01,  1.75s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:14,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:26,  1.85s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:30,  1.87s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:32,  1.89s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:30,  1.89s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:36,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:26,  1.88s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:53,  2.00s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:38,  1.95s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:35,  1.95s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:32,  1.94s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:16,  1.90s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:20,  1.92s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:27,  1.95s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:24,  1.95s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:28,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:20,  1.95s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:06,  1.90s/it]predicting train subjects:  11%|█         | 30/285 [00:55<07:58,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:57<07:53,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [00:59<08:03,  1.91s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:52,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:44,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:35,  1.82s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:31,  1.83s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:38,  1.87s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:30,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:35,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:25,  1.83s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:32,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:22,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<06:56,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<06:47,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<06:28,  1.64s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<06:17,  1.60s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<06:08,  1.57s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<06:34,  1.69s/it]predicting train subjects:  18%|█▊        | 52/285 [01:34<06:26,  1.66s/it]predicting train subjects:  19%|█▊        | 53/285 [01:36<06:11,  1.60s/it]predicting train subjects:  19%|█▉        | 54/285 [01:37<06:13,  1.62s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:04,  1.59s/it]predicting train subjects:  20%|█▉        | 56/285 [01:40<06:08,  1.61s/it]predicting train subjects:  20%|██        | 57/285 [01:42<06:12,  1.63s/it]predicting train subjects:  20%|██        | 58/285 [01:44<06:00,  1.59s/it]predicting train subjects:  21%|██        | 59/285 [01:45<05:54,  1.57s/it]predicting train subjects:  21%|██        | 60/285 [01:47<05:57,  1.59s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<05:47,  1.55s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<05:41,  1.53s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<05:33,  1.50s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<05:35,  1.52s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:00,  1.64s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:02,  1.66s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:02,  1.66s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<05:52,  1.63s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<05:58,  1.66s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<05:50,  1.63s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<05:45,  1.61s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<05:41,  1.60s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<05:36,  1.59s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<05:36,  1.59s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<05:31,  1.58s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<05:30,  1.58s/it]predicting train subjects:  27%|██▋       | 77/285 [02:14<05:28,  1.58s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:26,  1.57s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:23,  1.57s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:35,  1.64s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:28,  1.61s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:39,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:46,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:44,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:57,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:31<06:04,  1.84s/it]predicting train subjects:  31%|███       | 88/285 [02:33<06:14,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:35<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<06:18,  1.94s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<06:12,  1.92s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<06:06,  1.90s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<06:10,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<06:08,  1.93s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<06:06,  1.93s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<06:10,  1.96s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<06:03,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<06:04,  1.95s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [02:57<05:54,  1.91s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:48,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:00<05:41,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:33,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:30,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:06<05:28,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:07<05:23,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:09<05:23,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:11<05:29,  1.86s/it]predicting train subjects:  38%|███▊      | 109/285 [03:13<05:28,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:15<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:17<05:19,  1.83s/it]predicting train subjects:  39%|███▉      | 112/285 [03:19<05:19,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:20<05:15,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:22<05:09,  1.81s/it]predicting train subjects:  40%|████      | 115/285 [03:24<05:04,  1.79s/it]predicting train subjects:  41%|████      | 116/285 [03:26<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:28<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:29<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:31<04:54,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:33<04:51,  1.77s/it]predicting train subjects:  42%|████▏     | 121/285 [03:34<04:42,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:36<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:37<04:10,  1.54s/it]predicting train subjects:  44%|████▎     | 124/285 [03:39<04:11,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:40<04:11,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:42<04:11,  1.58s/it]predicting train subjects:  45%|████▍     | 127/285 [03:43<04:06,  1.56s/it]predicting train subjects:  45%|████▍     | 128/285 [03:45<04:05,  1.56s/it]predicting train subjects:  45%|████▌     | 129/285 [03:47<04:09,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [03:48<04:06,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [03:50<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [03:51<03:58,  1.56s/it]predicting train subjects:  47%|████▋     | 133/285 [03:53<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [03:54<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 135/285 [03:56<03:53,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [03:58<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 137/285 [03:59<03:49,  1.55s/it]predicting train subjects:  48%|████▊     | 138/285 [04:01<03:51,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:02<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:04<03:49,  1.58s/it]predicting train subjects:  49%|████▉     | 141/285 [04:06<03:49,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:07<03:37,  1.52s/it]predicting train subjects:  50%|█████     | 143/285 [04:08<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:10<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [04:11<03:19,  1.42s/it]predicting train subjects:  51%|█████     | 146/285 [04:12<03:14,  1.40s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:14<03:12,  1.39s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:15<03:15,  1.43s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:17<03:11,  1.40s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:18<03:09,  1.40s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:19<03:08,  1.40s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:21<03:03,  1.38s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:22<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:24<03:09,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:25<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:27<03:02,  1.42s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:28<03:00,  1.41s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:29<02:59,  1.41s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:31<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:32<02:53,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:34<02:52,  1.40s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<02:51,  1.40s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:36<02:47,  1.37s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:38<02:44,  1.36s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:39<02:45,  1.38s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:40<02:44,  1.38s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:42<02:44,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:43<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:45<02:39,  1.38s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:46<02:39,  1.38s/it]predicting train subjects:  60%|██████    | 171/285 [04:47<02:38,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:49<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:50<02:37,  1.41s/it]predicting train subjects:  61%|██████    | 174/285 [04:52<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:53<02:33,  1.39s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:32,  1.40s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:56<02:31,  1.40s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:57<02:27,  1.38s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:25,  1.37s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:23,  1.37s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:26,  1.41s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:24,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:04<02:22,  1.39s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:20,  1.39s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:08<02:19,  1.41s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:10<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:11<02:15,  1.40s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:13<02:14,  1.40s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:14<02:12,  1.40s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:15<02:11,  1.40s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:17<02:09,  1.39s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:18<02:07,  1.38s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:05,  1.38s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:21<02:03,  1.37s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:08,  1.45s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:14,  1.53s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:26<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:28<02:20,  1.64s/it]predicting train subjects:  70%|███████   | 200/285 [05:29<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:31<02:21,  1.68s/it]predicting train subjects:  71%|███████   | 202/285 [05:33<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:34<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:36<02:16,  1.68s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:38<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:39<02:12,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:41<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:43<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:44<02:05,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:46<02:04,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:48<02:02,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:49<02:00,  1.64s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:51<01:59,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:52<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:54<01:48,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:55<01:43,  1.49s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:57<01:40,  1.48s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:58<01:37,  1.45s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:00<01:36,  1.46s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:01<01:34,  1.46s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:02<01:32,  1.44s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:04<01:29,  1.42s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:05<01:27,  1.41s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:07<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:08<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:23,  1.42s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:11<01:22,  1.43s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:22,  1.44s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:21,  1.45s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:19<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:21<01:27,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:23<01:29,  1.76s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:25<01:31,  1.83s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:26<01:30,  1.85s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:28<01:29,  1.86s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:30<01:27,  1.85s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:32<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:34<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:36<01:24,  1.91s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:38<01:22,  1.91s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:42<01:18,  1.92s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:44<01:16,  1.92s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:45<01:14,  1.90s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:47<01:11,  1.88s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:49<01:09,  1.87s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:51<01:07,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:52<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:54<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:55<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:57<00:47,  1.50s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:58<00:44,  1.44s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:42,  1.42s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:01<00:40,  1.41s/it]predicting train subjects:  90%|█████████ | 257/285 [07:02<00:38,  1.38s/it]predicting train subjects:  91%|█████████ | 258/285 [07:03<00:37,  1.38s/it]predicting train subjects:  91%|█████████ | 259/285 [07:05<00:35,  1.37s/it]predicting train subjects:  91%|█████████ | 260/285 [07:06<00:34,  1.37s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:33,  1.38s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:09<00:31,  1.37s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:10<00:30,  1.37s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:28,  1.35s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:13<00:26,  1.33s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:25,  1.34s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:15<00:24,  1.35s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:25,  1.53s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:25,  1.72s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:23<00:25,  1.81s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:25<00:23,  1.82s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:27<00:21,  1.83s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:29<00:20,  1.83s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:31<00:18,  1.82s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:32<00:16,  1.80s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:34<00:14,  1.82s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:36<00:12,  1.82s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:38<00:10,  1.80s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:09,  1.82s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:41<00:07,  1.82s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:05,  1.82s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.80s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.81s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:51,  1.45s/it]Loading train:   1%|          | 2/285 [00:03<07:00,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<06:59,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:06<07:29,  1.60s/it]Loading train:   2%|▏         | 5/285 [00:07<07:07,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:09<07:22,  1.59s/it]Loading train:   2%|▏         | 7/285 [00:11<07:55,  1.71s/it]Loading train:   3%|▎         | 8/285 [00:13<07:48,  1.69s/it]Loading train:   3%|▎         | 9/285 [00:14<07:29,  1.63s/it]Loading train:   4%|▎         | 10/285 [00:15<06:57,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:17<06:32,  1.43s/it]Loading train:   4%|▍         | 12/285 [00:18<06:22,  1.40s/it]Loading train:   5%|▍         | 13/285 [00:19<05:58,  1.32s/it]Loading train:   5%|▍         | 14/285 [00:20<05:48,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:22<05:47,  1.29s/it]Loading train:   6%|▌         | 16/285 [00:23<05:45,  1.28s/it]Loading train:   6%|▌         | 17/285 [00:24<05:35,  1.25s/it]Loading train:   6%|▋         | 18/285 [00:25<05:32,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:27<05:46,  1.30s/it]Loading train:   7%|▋         | 20/285 [00:28<05:44,  1.30s/it]Loading train:   7%|▋         | 21/285 [00:29<05:40,  1.29s/it]Loading train:   8%|▊         | 22/285 [00:30<05:33,  1.27s/it]Loading train:   8%|▊         | 23/285 [00:32<05:28,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:33<05:25,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:34<05:11,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:35<05:11,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:36<05:17,  1.23s/it]Loading train:  10%|▉         | 28/285 [00:38<05:02,  1.18s/it]Loading train:  10%|█         | 29/285 [00:39<05:01,  1.18s/it]Loading train:  11%|█         | 30/285 [00:40<04:50,  1.14s/it]Loading train:  11%|█         | 31/285 [00:41<04:45,  1.12s/it]Loading train:  11%|█         | 32/285 [00:42<04:56,  1.17s/it]Loading train:  12%|█▏        | 33/285 [00:43<04:46,  1.14s/it]Loading train:  12%|█▏        | 34/285 [00:44<04:45,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:46<04:52,  1.17s/it]Loading train:  13%|█▎        | 36/285 [00:47<04:43,  1.14s/it]Loading train:  13%|█▎        | 37/285 [00:48<04:35,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:49<04:34,  1.11s/it]Loading train:  14%|█▎        | 39/285 [00:50<04:28,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:51<04:28,  1.10s/it]Loading train:  14%|█▍        | 41/285 [00:52<04:19,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:53<04:22,  1.08s/it]Loading train:  15%|█▌        | 43/285 [00:54<04:13,  1.05s/it]Loading train:  15%|█▌        | 44/285 [00:55<04:06,  1.02s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:12,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:11,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:06,  1.03s/it]Loading train:  17%|█▋        | 48/285 [00:59<03:52,  1.02it/s]Loading train:  17%|█▋        | 49/285 [01:00<03:45,  1.05it/s]Loading train:  18%|█▊        | 50/285 [01:01<03:48,  1.03it/s]Loading train:  18%|█▊        | 51/285 [01:02<03:44,  1.04it/s]Loading train:  18%|█▊        | 52/285 [01:03<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [01:04<03:48,  1.01it/s]Loading train:  19%|█▉        | 54/285 [01:05<03:47,  1.01it/s]Loading train:  19%|█▉        | 55/285 [01:06<03:46,  1.02it/s]Loading train:  20%|█▉        | 56/285 [01:07<03:48,  1.00it/s]Loading train:  20%|██        | 57/285 [01:08<03:44,  1.02it/s]Loading train:  20%|██        | 58/285 [01:09<03:37,  1.05it/s]Loading train:  21%|██        | 59/285 [01:10<03:36,  1.04it/s]Loading train:  21%|██        | 60/285 [01:11<03:49,  1.02s/it]Loading train:  21%|██▏       | 61/285 [01:12<03:46,  1.01s/it]Loading train:  22%|██▏       | 62/285 [01:13<03:40,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:14<03:43,  1.01s/it]Loading train:  22%|██▏       | 64/285 [01:16<04:28,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:17<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:19<05:12,  1.43s/it]Loading train:  24%|██▎       | 67/285 [01:20<04:47,  1.32s/it]Loading train:  24%|██▍       | 68/285 [01:21<04:30,  1.24s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:17,  1.19s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:06,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:08,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:59,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:26<03:52,  1.10s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:50,  1.09s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:40,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:29<03:38,  1.04s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:35,  1.04s/it]Loading train:  27%|██▋       | 78/285 [01:31<03:30,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:33<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:34<03:35,  1.05s/it]Loading train:  28%|██▊       | 81/285 [01:35<03:33,  1.05s/it]Loading train:  29%|██▉       | 82/285 [01:36<03:36,  1.07s/it]Loading train:  29%|██▉       | 83/285 [01:37<03:30,  1.04s/it]Loading train:  29%|██▉       | 84/285 [01:38<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:39<03:40,  1.10s/it]Loading train:  30%|███       | 86/285 [01:40<03:40,  1.11s/it]Loading train:  31%|███       | 87/285 [01:41<03:38,  1.10s/it]Loading train:  31%|███       | 88/285 [01:42<03:40,  1.12s/it]Loading train:  31%|███       | 89/285 [01:43<03:37,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:45<03:34,  1.10s/it]Loading train:  32%|███▏      | 91/285 [01:46<03:36,  1.11s/it]Loading train:  32%|███▏      | 92/285 [01:47<03:32,  1.10s/it]Loading train:  33%|███▎      | 93/285 [01:48<03:32,  1.11s/it]Loading train:  33%|███▎      | 94/285 [01:49<03:27,  1.09s/it]Loading train:  33%|███▎      | 95/285 [01:50<03:32,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:31,  1.12s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:29,  1.11s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:28,  1.12s/it]Loading train:  35%|███▍      | 99/285 [01:55<03:28,  1.12s/it]Loading train:  35%|███▌      | 100/285 [01:56<03:31,  1.14s/it]Loading train:  35%|███▌      | 101/285 [01:57<03:27,  1.13s/it]Loading train:  36%|███▌      | 102/285 [01:58<03:26,  1.13s/it]Loading train:  36%|███▌      | 103/285 [01:59<03:28,  1.15s/it]Loading train:  36%|███▋      | 104/285 [02:00<03:28,  1.15s/it]Loading train:  37%|███▋      | 105/285 [02:01<03:25,  1.14s/it]Loading train:  37%|███▋      | 106/285 [02:03<03:19,  1.11s/it]Loading train:  38%|███▊      | 107/285 [02:04<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:05<03:15,  1.11s/it]Loading train:  38%|███▊      | 109/285 [02:06<03:17,  1.12s/it]Loading train:  39%|███▊      | 110/285 [02:07<03:11,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:08<03:05,  1.07s/it]Loading train:  39%|███▉      | 112/285 [02:09<03:02,  1.06s/it]Loading train:  40%|███▉      | 113/285 [02:10<03:05,  1.08s/it]Loading train:  40%|████      | 114/285 [02:11<03:05,  1.09s/it]Loading train:  40%|████      | 115/285 [02:12<03:01,  1.07s/it]Loading train:  41%|████      | 116/285 [02:13<02:59,  1.06s/it]Loading train:  41%|████      | 117/285 [02:14<02:58,  1.06s/it]Loading train:  41%|████▏     | 118/285 [02:15<02:54,  1.04s/it]Loading train:  42%|████▏     | 119/285 [02:16<02:58,  1.08s/it]Loading train:  42%|████▏     | 120/285 [02:17<02:52,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:19<03:14,  1.19s/it]Loading train:  43%|████▎     | 122/285 [02:20<03:16,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:22<03:24,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:23<03:11,  1.19s/it]Loading train:  44%|████▍     | 125/285 [02:24<03:00,  1.13s/it]Loading train:  44%|████▍     | 126/285 [02:25<02:53,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:26<02:47,  1.06s/it]Loading train:  45%|████▍     | 128/285 [02:27<02:43,  1.04s/it]Loading train:  45%|████▌     | 129/285 [02:28<02:43,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:29<02:40,  1.04s/it]Loading train:  46%|████▌     | 131/285 [02:30<02:35,  1.01s/it]Loading train:  46%|████▋     | 132/285 [02:31<02:35,  1.01s/it]Loading train:  47%|████▋     | 133/285 [02:32<02:34,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:33<02:32,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:34<02:28,  1.01it/s]Loading train:  48%|████▊     | 136/285 [02:35<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:35<02:23,  1.03it/s]Loading train:  48%|████▊     | 138/285 [02:36<02:22,  1.04it/s]Loading train:  49%|████▉     | 139/285 [02:37<02:16,  1.07it/s]Loading train:  49%|████▉     | 140/285 [02:38<02:24,  1.01it/s]Loading train:  49%|████▉     | 141/285 [02:40<02:26,  1.02s/it]Loading train:  50%|████▉     | 142/285 [02:41<02:26,  1.03s/it]Loading train:  50%|█████     | 143/285 [02:41<02:20,  1.01it/s]Loading train:  51%|█████     | 144/285 [02:42<02:19,  1.01it/s]Loading train:  51%|█████     | 145/285 [02:43<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:44<02:12,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:45<02:09,  1.07it/s]Loading train:  52%|█████▏    | 148/285 [02:46<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [02:47<02:03,  1.10it/s]Loading train:  53%|█████▎    | 150/285 [02:48<02:04,  1.08it/s]Loading train:  53%|█████▎    | 151/285 [02:49<02:02,  1.10it/s]Loading train:  53%|█████▎    | 152/285 [02:50<02:07,  1.04it/s]Loading train:  54%|█████▎    | 153/285 [02:51<02:05,  1.05it/s]Loading train:  54%|█████▍    | 154/285 [02:52<02:06,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [02:53<02:03,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [02:54<02:07,  1.01it/s]Loading train:  55%|█████▌    | 157/285 [02:55<02:02,  1.05it/s]Loading train:  55%|█████▌    | 158/285 [02:56<02:03,  1.03it/s]Loading train:  56%|█████▌    | 159/285 [02:57<02:00,  1.05it/s]Loading train:  56%|█████▌    | 160/285 [02:58<02:05,  1.00s/it]Loading train:  56%|█████▋    | 161/285 [02:59<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [02:59<01:56,  1.06it/s]Loading train:  57%|█████▋    | 163/285 [03:00<01:56,  1.04it/s]Loading train:  58%|█████▊    | 164/285 [03:01<01:53,  1.07it/s]Loading train:  58%|█████▊    | 165/285 [03:02<01:48,  1.10it/s]Loading train:  58%|█████▊    | 166/285 [03:03<01:47,  1.11it/s]Loading train:  59%|█████▊    | 167/285 [03:04<01:47,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:05<01:46,  1.10it/s]Loading train:  59%|█████▉    | 169/285 [03:06<01:42,  1.13it/s]Loading train:  60%|█████▉    | 170/285 [03:07<01:41,  1.14it/s]Loading train:  60%|██████    | 171/285 [03:08<01:44,  1.09it/s]Loading train:  60%|██████    | 172/285 [03:08<01:41,  1.11it/s]Loading train:  61%|██████    | 173/285 [03:09<01:40,  1.12it/s]Loading train:  61%|██████    | 174/285 [03:10<01:38,  1.13it/s]Loading train:  61%|██████▏   | 175/285 [03:11<01:38,  1.12it/s]Loading train:  62%|██████▏   | 176/285 [03:12<01:35,  1.14it/s]Loading train:  62%|██████▏   | 177/285 [03:13<01:33,  1.15it/s]Loading train:  62%|██████▏   | 178/285 [03:14<01:37,  1.10it/s]Loading train:  63%|██████▎   | 179/285 [03:15<01:35,  1.11it/s]Loading train:  63%|██████▎   | 180/285 [03:16<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:16<01:29,  1.16it/s]Loading train:  64%|██████▍   | 182/285 [03:17<01:33,  1.10it/s]Loading train:  64%|██████▍   | 183/285 [03:18<01:34,  1.08it/s]Loading train:  65%|██████▍   | 184/285 [03:19<01:36,  1.05it/s]Loading train:  65%|██████▍   | 185/285 [03:20<01:34,  1.06it/s]Loading train:  65%|██████▌   | 186/285 [03:21<01:32,  1.07it/s]Loading train:  66%|██████▌   | 187/285 [03:22<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [03:23<01:26,  1.12it/s]Loading train:  66%|██████▋   | 189/285 [03:24<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [03:25<01:25,  1.11it/s]Loading train:  67%|██████▋   | 191/285 [03:26<01:31,  1.03it/s]Loading train:  67%|██████▋   | 192/285 [03:27<01:28,  1.05it/s]Loading train:  68%|██████▊   | 193/285 [03:28<01:24,  1.08it/s]Loading train:  68%|██████▊   | 194/285 [03:28<01:20,  1.14it/s]Loading train:  68%|██████▊   | 195/285 [03:29<01:17,  1.16it/s]Loading train:  69%|██████▉   | 196/285 [03:30<01:25,  1.04it/s]Loading train:  69%|██████▉   | 197/285 [03:31<01:25,  1.03it/s]Loading train:  69%|██████▉   | 198/285 [03:33<01:28,  1.02s/it]Loading train:  70%|██████▉   | 199/285 [03:33<01:25,  1.01it/s]Loading train:  70%|███████   | 200/285 [03:34<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:35<01:25,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:37<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:38<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:39<01:21,  1.01s/it]Loading train:  72%|███████▏  | 205/285 [03:39<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [03:40<01:16,  1.03it/s]Loading train:  73%|███████▎  | 207/285 [03:41<01:18,  1.00s/it]Loading train:  73%|███████▎  | 208/285 [03:43<01:18,  1.02s/it]Loading train:  73%|███████▎  | 209/285 [03:43<01:16,  1.00s/it]Loading train:  74%|███████▎  | 210/285 [03:44<01:14,  1.01it/s]Loading train:  74%|███████▍  | 211/285 [03:45<01:11,  1.04it/s]Loading train:  74%|███████▍  | 212/285 [03:46<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:47<01:11,  1.00it/s]Loading train:  75%|███████▌  | 214/285 [03:48<01:11,  1.00s/it]Loading train:  75%|███████▌  | 215/285 [03:49<01:08,  1.02it/s]Loading train:  76%|███████▌  | 216/285 [03:50<01:05,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [03:51<01:03,  1.07it/s]Loading train:  76%|███████▋  | 218/285 [03:52<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:53<01:01,  1.08it/s]Loading train:  77%|███████▋  | 220/285 [03:54<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:55<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:55<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [03:56<00:52,  1.18it/s]Loading train:  79%|███████▊  | 224/285 [03:57<00:51,  1.18it/s]Loading train:  79%|███████▉  | 225/285 [03:58<00:50,  1.19it/s]Loading train:  79%|███████▉  | 226/285 [03:59<00:50,  1.16it/s]Loading train:  80%|███████▉  | 227/285 [04:00<00:49,  1.18it/s]Loading train:  80%|████████  | 228/285 [04:01<00:50,  1.14it/s]Loading train:  80%|████████  | 229/285 [04:01<00:48,  1.15it/s]Loading train:  81%|████████  | 230/285 [04:02<00:48,  1.14it/s]Loading train:  81%|████████  | 231/285 [04:03<00:47,  1.15it/s]Loading train:  81%|████████▏ | 232/285 [04:04<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [04:05<00:52,  1.00s/it]Loading train:  82%|████████▏ | 234/285 [04:06<00:51,  1.01s/it]Loading train:  82%|████████▏ | 235/285 [04:08<00:51,  1.04s/it]Loading train:  83%|████████▎ | 236/285 [04:09<00:52,  1.07s/it]Loading train:  83%|████████▎ | 237/285 [04:10<00:51,  1.07s/it]Loading train:  84%|████████▎ | 238/285 [04:11<00:49,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [04:12<00:49,  1.07s/it]Loading train:  84%|████████▍ | 240/285 [04:13<00:48,  1.07s/it]Loading train:  85%|████████▍ | 241/285 [04:14<00:46,  1.05s/it]Loading train:  85%|████████▍ | 242/285 [04:15<00:45,  1.06s/it]Loading train:  85%|████████▌ | 243/285 [04:16<00:43,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:17<00:42,  1.04s/it]Loading train:  86%|████████▌ | 245/285 [04:18<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:19<00:40,  1.04s/it]Loading train:  87%|████████▋ | 247/285 [04:20<00:39,  1.04s/it]Loading train:  87%|████████▋ | 248/285 [04:21<00:37,  1.02s/it]Loading train:  87%|████████▋ | 249/285 [04:22<00:35,  1.01it/s]Loading train:  88%|████████▊ | 250/285 [04:23<00:34,  1.02it/s]Loading train:  88%|████████▊ | 251/285 [04:24<00:32,  1.05it/s]Loading train:  88%|████████▊ | 252/285 [04:25<00:31,  1.06it/s]Loading train:  89%|████████▉ | 253/285 [04:26<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:27<00:29,  1.04it/s]Loading train:  89%|████████▉ | 255/285 [04:28<00:27,  1.09it/s]Loading train:  90%|████████▉ | 256/285 [04:29<00:26,  1.11it/s]Loading train:  90%|█████████ | 257/285 [04:29<00:25,  1.09it/s]Loading train:  91%|█████████ | 258/285 [04:30<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:31<00:23,  1.10it/s]Loading train:  91%|█████████ | 260/285 [04:32<00:22,  1.13it/s]Loading train:  92%|█████████▏| 261/285 [04:33<00:21,  1.11it/s]Loading train:  92%|█████████▏| 262/285 [04:34<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:35<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:36<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:37<00:17,  1.12it/s]Loading train:  93%|█████████▎| 266/285 [04:38<00:17,  1.06it/s]Loading train:  94%|█████████▎| 267/285 [04:38<00:16,  1.12it/s]Loading train:  94%|█████████▍| 268/285 [04:40<00:16,  1.02it/s]Loading train:  94%|█████████▍| 269/285 [04:41<00:16,  1.00s/it]Loading train:  95%|█████████▍| 270/285 [04:42<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [04:43<00:14,  1.05s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:13,  1.04s/it]Loading train:  96%|█████████▌| 273/285 [04:45<00:12,  1.06s/it]Loading train:  96%|█████████▌| 274/285 [04:46<00:11,  1.09s/it]Loading train:  96%|█████████▋| 275/285 [04:47<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [04:48<00:09,  1.09s/it]Loading train:  97%|█████████▋| 277/285 [04:49<00:08,  1.11s/it]Loading train:  98%|█████████▊| 278/285 [04:51<00:07,  1.10s/it]Loading train:  98%|█████████▊| 279/285 [04:52<00:06,  1.09s/it]Loading train:  98%|█████████▊| 280/285 [04:53<00:05,  1.08s/it]Loading train:  99%|█████████▊| 281/285 [04:54<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [04:55<00:03,  1.05s/it]Loading train:  99%|█████████▉| 283/285 [04:56<00:02,  1.04s/it]Loading train: 100%|█████████▉| 284/285 [04:57<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:58<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:02, 96.17it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:02, 108.51it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:02, 113.79it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:01, 129.19it/s]concatenating: train:  27%|██▋       | 78/285 [00:00<00:01, 143.61it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:01, 159.62it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 172.54it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:00, 185.91it/s]concatenating: train:  59%|█████▉    | 168/285 [00:00<00:00, 197.11it/s]concatenating: train:  66%|██████▋   | 189/285 [00:01<00:00, 194.16it/s]concatenating: train:  74%|███████▍  | 211/285 [00:01<00:00, 200.41it/s]concatenating: train:  82%|████████▏ | 233/285 [00:01<00:00, 200.83it/s]concatenating: train:  89%|████████▉ | 255/285 [00:01<00:00, 204.84it/s]concatenating: train:  97%|█████████▋| 276/285 [00:01<00:00, 168.71it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 179.46it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 63.45it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 20)   0           batch_normalization_7[0][0]      2019-07-07 02:14:02.087335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 02:14:02.087428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 02:14:02.087444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 02:14:02.087454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 02:14:02.087919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 20335.6073 - acc: 0.8618 - mDice: 0.1329 - val_loss: 16431.0250 - val_acc: 0.8990 - val_mDice: 0.2200

Epoch 00001: val_mDice improved from -inf to 0.22003, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 9107.9683 - acc: 0.8783 - mDice: 0.2224 - val_loss: 5529.0034 - val_acc: 0.9089 - val_mDice: 0.3425

Epoch 00002: val_mDice improved from 0.22003 to 0.34245, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 6557.3488 - acc: 0.8899 - mDice: 0.2973 - val_loss: 4412.4517 - val_acc: 0.9160 - val_mDice: 0.4003

Epoch 00003: val_mDice improved from 0.34245 to 0.40033, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 5684.6932 - acc: 0.8982 - mDice: 0.3422 - val_loss: 4090.6350 - val_acc: 0.9216 - val_mDice: 0.4256

Epoch 00004: val_mDice improved from 0.40033 to 0.42558, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 5150.1218 - acc: 0.9035 - mDice: 0.3741 - val_loss: 4247.4097 - val_acc: 0.9237 - val_mDice: 0.4167

Epoch 00005: val_mDice did not improve from 0.42558
Epoch 6/300
 - 11s - loss: 4747.1854 - acc: 0.9081 - mDice: 0.4005 - val_loss: 4260.8907 - val_acc: 0.9244 - val_mDice: 0.4150

Epoch 00006: val_mDice did not improve from 0.42558
Epoch 7/300
 - 11s - loss: 4432.7173 - acc: 0.9120 - mDice: 0.4228 - val_loss: 3884.4062 - val_acc: 0.9262 - val_mDice: 0.4405

Epoch 00007: val_mDice improved from 0.42558 to 0.44051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 4155.7907 - acc: 0.9157 - mDice: 0.4436 - val_loss: 3779.5696 - val_acc: 0.9320 - val_mDice: 0.4490

Epoch 00008: val_mDice improved from 0.44051 to 0.44896, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 3946.7416 - acc: 0.9186 - mDice: 0.4619 - val_loss: 3317.4754 - val_acc: 0.9342 - val_mDice: 0.4852

Epoch 00009: val_mDice improved from 0.44896 to 0.48524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 3755.4497 - acc: 0.9212 - mDice: 0.4800 - val_loss: 3087.6330 - val_acc: 0.9386 - val_mDice: 0.5071

Epoch 00010: val_mDice improved from 0.48524 to 0.50711, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 3557.7665 - acc: 0.9236 - mDice: 0.4944 - val_loss: 2864.8374 - val_acc: 0.9416 - val_mDice: 0.5308

Epoch 00011: val_mDice improved from 0.50711 to 0.53078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 3399.7446 - acc: 0.9257 - mDice: 0.5091 - val_loss: 2664.3233 - val_acc: 0.9452 - val_mDice: 0.5546

Epoch 00012: val_mDice improved from 0.53078 to 0.55461, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 11s - loss: 3251.3193 - acc: 0.9274 - mDice: 0.5230 - val_loss: 3075.9892 - val_acc: 0.9403 - val_mDice: 0.5109

Epoch 00013: val_mDice did not improve from 0.55461
Epoch 14/300
 - 11s - loss: 3169.9597 - acc: 0.9287 - mDice: 0.5320 - val_loss: 2953.0416 - val_acc: 0.9404 - val_mDice: 0.5312

Epoch 00014: val_mDice did not improve from 0.55461
Epoch 15/300
 - 11s - loss: 3115.8808 - acc: 0.9295 - mDice: 0.5383 - val_loss: 2750.4107 - val_acc: 0.9447 - val_mDice: 0.5463

Epoch 00015: val_mDice did not improve from 0.55461
Epoch 16/300
 - 11s - loss: 2988.8172 - acc: 0.9309 - mDice: 0.5506 - val_loss: 2719.5806 - val_acc: 0.9468 - val_mDice: 0.5531

Epoch 00016: val_mDice did not improve from 0.55461
Epoch 17/300
 - 11s - loss: 2902.1955 - acc: 0.9321 - mDice: 0.5598 - val_loss: 2476.4900 - val_acc: 0.9490 - val_mDice: 0.5814

Epoch 00017: val_mDice improved from 0.55461 to 0.58145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 2817.0420 - acc: 0.9332 - mDice: 0.5689 - val_loss: 2703.7221 - val_acc: 0.9487 - val_mDice: 0.5584

Epoch 00018: val_mDice did not improve from 0.58145
Epoch 19/300
 - 11s - loss: 2748.9969 - acc: 0.9341 - mDice: 0.5768 - val_loss: 2572.5222 - val_acc: 0.9500 - val_mDice: 0.5713

Epoch 00019: val_mDice did not improve from 0.58145
Epoch 20/300
 - 11s - loss: 2715.3370 - acc: 0.9346 - mDice: 0.5811 - val_loss: 2430.6354 - val_acc: 0.9498 - val_mDice: 0.5860

Epoch 00020: val_mDice improved from 0.58145 to 0.58603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 21/300
 - 11s - loss: 2634.0275 - acc: 0.9355 - mDice: 0.5894 - val_loss: 2516.0659 - val_acc: 0.9504 - val_mDice: 0.5788

Epoch 00021: val_mDice did not improve from 0.58603
Epoch 22/300
 - 11s - loss: 2591.9647 - acc: 0.9361 - mDice: 0.5947 - val_loss: 2392.9839 - val_acc: 0.9491 - val_mDice: 0.5894

Epoch 00022: val_mDice improved from 0.58603 to 0.58941, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 11s - loss: 2548.6012 - acc: 0.9366 - mDice: 0.5997 - val_loss: 2492.0886 - val_acc: 0.9500 - val_mDice: 0.5789

Epoch 00023: val_mDice did not improve from 0.58941
Epoch 24/300
 - 11s - loss: 2492.1613 - acc: 0.9373 - mDice: 0.6063 - val_loss: 2506.3650 - val_acc: 0.9512 - val_mDice: 0.5806

Epoch 00024: val_mDice did not improve from 0.58941
Epoch 25/300
 - 11s - loss: 2472.2335 - acc: 0.9377 - mDice: 0.6092 - val_loss: 2442.7826 - val_acc: 0.9504 - val_mDice: 0.5850

Epoch 00025: val_mDice did not improve from 0.58941
Epoch 26/300
 - 11s - loss: 2410.0359 - acc: 0.9384 - mDice: 0.6162 - val_loss: 2300.5199 - val_acc: 0.9512 - val_mDice: 0.6026

Epoch 00026: val_mDice improved from 0.58941 to 0.60260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 2389.2025 - acc: 0.9388 - mDice: 0.6189 - val_loss: 2516.9459 - val_acc: 0.9507 - val_mDice: 0.5814

Epoch 00027: val_mDice did not improve from 0.60260
Epoch 28/300
 - 11s - loss: 2374.1743 - acc: 0.9392 - mDice: 0.6213 - val_loss: 2511.3860 - val_acc: 0.9508 - val_mDice: 0.5785

Epoch 00028: val_mDice did not improve from 0.60260
Epoch 29/300
 - 12s - loss: 2322.3896 - acc: 0.9398 - mDice: 0.6272 - val_loss: 2414.5818 - val_acc: 0.9518 - val_mDice: 0.5951

Epoch 00029: val_mDice did not improve from 0.60260
Epoch 30/300
 - 11s - loss: 2280.4703 - acc: 0.9403 - mDice: 0.6319 - val_loss: 2210.8236 - val_acc: 0.9515 - val_mDice: 0.6112

Epoch 00030: val_mDice improved from 0.60260 to 0.61120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 31/300
 - 11s - loss: 2279.3495 - acc: 0.9404 - mDice: 0.6322 - val_loss: 2362.8287 - val_acc: 0.9507 - val_mDice: 0.5942

Epoch 00031: val_mDice did not improve from 0.61120
Epoch 32/300
 - 11s - loss: 2246.5106 - acc: 0.9410 - mDice: 0.6363 - val_loss: 2530.7707 - val_acc: 0.9517 - val_mDice: 0.5831

Epoch 00032: val_mDice did not improve from 0.61120
Epoch 33/300
 - 11s - loss: 2229.6901 - acc: 0.9411 - mDice: 0.6390 - val_loss: 2455.3121 - val_acc: 0.9498 - val_mDice: 0.5857

Epoch 00033: val_mDice did not improve from 0.61120
Epoch 34/300
 - 11s - loss: 2202.1467 - acc: 0.9414 - mDice: 0.6422 - val_loss: 2331.1099 - val_acc: 0.9517 - val_mDice: 0.6021

Epoch 00034: val_mDice did not improve from 0.61120
Epoch 35/300
 - 12s - loss: 2177.3028 - acc: 0.9420 - mDice: 0.6453 - val_loss: 2444.8965 - val_acc: 0.9506 - val_mDice: 0.5858

Epoch 00035: val_mDice did not improve from 0.61120
Epoch 36/300
 - 11s - loss: 2150.7841 - acc: 0.9422 - mDice: 0.6482 - val_loss: 2454.9842 - val_acc: 0.9517 - val_mDice: 0.5864

Epoch 00036: val_mDice did not improve from 0.61120
Epoch 37/300
 - 12s - loss: 2103.6328 - acc: 0.9427 - mDice: 0.6542 - val_loss: 2251.0844 - val_acc: 0.9511 - val_mDice: 0.6075

Epoch 00037: val_mDice did not improve from 0.61120
Epoch 38/300
 - 11s - loss: 2165.1363 - acc: 0.9422 - mDice: 0.6471 - val_loss: 2331.4292 - val_acc: 0.9501 - val_mDice: 0.5962

Epoch 00038: val_mDice did not improve from 0.61120
Epoch 39/300
 - 12s - loss: 2092.9946 - acc: 0.9431 - mDice: 0.6556 - val_loss: 2445.4783 - val_acc: 0.9515 - val_mDice: 0.5888

Epoch 00039: val_mDice did not improve from 0.61120
Epoch 40/300
 - 11s - loss: 2076.1177 - acc: 0.9433 - mDice: 0.6580 - val_loss: 2584.3701 - val_acc: 0.9531 - val_mDice: 0.5800

Epoch 00040: val_mDice did not improve from 0.61120
Epoch 41/300
 - 11s - loss: 2060.3301 - acc: 0.9437 - mDice: 0.6600 - val_loss: 2260.2713 - val_acc: 0.9501 - val_mDice: 0.6063

Epoch 00041: val_mDice did not improve from 0.61120
Epoch 42/300
 - 12s - loss: 2030.1134 - acc: 0.9438 - mDice: 0.6637 - val_loss: 2222.2073 - val_acc: 0.9522 - val_mDice: 0.6119

Epoch 00042: val_mDice improved from 0.61120 to 0.61187, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 43/300
 - 11s - loss: 2016.9310 - acc: 0.9441 - mDice: 0.6657 - val_loss: 2215.5547 - val_acc: 0.9513 - val_mDice: 0.6123

Epoch 00043: val_mDice improved from 0.61187 to 0.61232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 44/300
 - 11s - loss: 1992.9591 - acc: 0.9445 - mDice: 0.6688 - val_loss: 2340.0417 - val_acc: 0.9518 - val_mDice: 0.5979

Epoch 00044: val_mDice did not improve from 0.61232
Epoch 45/300
 - 11s - loss: 1967.4450 - acc: 0.9448 - mDice: 0.6717 - val_loss: 2650.7930 - val_acc: 0.9511 - val_mDice: 0.5711

Epoch 00045: val_mDice did not improve from 0.61232
Epoch 46/300
 - 11s - loss: 1954.7236 - acc: 0.9449 - mDice: 0.6734 - val_loss: 2372.8085 - val_acc: 0.9514 - val_mDice: 0.5947

Epoch 00046: val_mDice did not improve from 0.61232
Epoch 47/300
 - 11s - loss: 1940.1272 - acc: 0.9452 - mDice: 0.6755 - val_loss: 2377.6829 - val_acc: 0.9502 - val_mDice: 0.5923

Epoch 00047: val_mDice did not improve from 0.61232
Epoch 48/300
 - 12s - loss: 1934.7556 - acc: 0.9451 - mDice: 0.6765 - val_loss: 2448.4969 - val_acc: 0.9525 - val_mDice: 0.5937

Epoch 00048: val_mDice did not improve from 0.61232
Epoch 49/300
 - 11s - loss: 1907.3007 - acc: 0.9455 - mDice: 0.6798 - val_loss: 2553.5554 - val_acc: 0.9514 - val_mDice: 0.5823

Epoch 00049: val_mDice did not improve from 0.61232
Epoch 50/300
 - 11s - loss: 1892.1435 - acc: 0.9458 - mDice: 0.6817 - val_loss: 2335.7125 - val_acc: 0.9520 - val_mDice: 0.5992

Epoch 00050: val_mDice did not improve from 0.61232
Epoch 51/300
 - 11s - loss: 1895.4963 - acc: 0.9457 - mDice: 0.6815 - val_loss: 2278.0056 - val_acc: 0.9516 - val_mDice: 0.6047

Epoch 00051: val_mDice did not improve from 0.61232
Epoch 52/300
 - 12s - loss: 1872.8019 - acc: 0.9460 - mDice: 0.6845 - val_loss: 2376.8845 - val_acc: 0.9528 - val_mDice: 0.5978

Epoch 00052: val_mDice did not improve from 0.61232
Epoch 53/300
 - 11s - loss: 1866.1856 - acc: 0.9462 - mDice: 0.6854 - val_loss: 2396.0938 - val_acc: 0.9526 - val_mDice: 0.5913

Epoch 00053: val_mDice did not improve from 0.61232
Epoch 54/300
 - 11s - loss: 1849.1329 - acc: 0.9463 - mDice: 0.6877 - val_loss: 2249.9990 - val_acc: 0.9534 - val_mDice: 0.6079

Epoch 00054: val_mDice did not improve from 0.61232
Epoch 55/300
 - 16s - loss: 1841.9164 - acc: 0.9464 - mDice: 0.6887 - val_loss: 2405.8876 - val_acc: 0.9517 - val_mDice: 0.5921

Epoch 00055: val_mDice did not improve from 0.61232
Epoch 56/300
 - 15s - loss: 1859.0134 - acc: 0.9463 - mDice: 0.6867 - val_loss: 2365.4922 - val_acc: 0.9503 - val_mDice: 0.5930

Epoch 00056: val_mDice did not improve from 0.61232
Epoch 57/300
 - 16s - loss: 1821.2913 - acc: 0.9468 - mDice: 0.6914 - val_loss: 2254.1443 - val_acc: 0.9537 - val_mDice: 0.6116

Epoch 00057: val_mDice did not improve from 0.61232
Epoch 58/300
 - 17s - loss: 1801.3088 - acc: 0.9470 - mDice: 0.6942 - val_loss: 2340.8263 - val_acc: 0.9519 - val_mDice: 0.5966

Epoch 00058: val_mDice did not improve from 0.61232
Epoch 59/300
 - 15s - loss: 1791.6363 - acc: 0.9471 - mDice: 0.6954 - val_loss: 2450.3300 - val_acc: 0.9512 - val_mDice: 0.5854

Epoch 00059: val_mDice did not improve from 0.61232
Epoch 60/300
 - 16s - loss: 1787.2128 - acc: 0.9472 - mDice: 0.6960 - val_loss: 2439.5242 - val_acc: 0.9524 - val_mDice: 0.5869

Epoch 00060: val_mDice did not improve from 0.61232
Epoch 61/300
 - 17s - loss: 1772.9230 - acc: 0.9474 - mDice: 0.6980 - val_loss: 2327.1178 - val_acc: 0.9522 - val_mDice: 0.6012

Epoch 00061: val_mDice did not improve from 0.61232
Epoch 62/300
 - 16s - loss: 1758.2861 - acc: 0.9477 - mDice: 0.7000 - val_loss: 2409.6023 - val_acc: 0.9522 - val_mDice: 0.5897

Epoch 00062: val_mDice did not improve from 0.61232
Epoch 63/300
 - 17s - loss: 1765.2212 - acc: 0.9476 - mDice: 0.6993 - val_loss: 2423.5370 - val_acc: 0.9525 - val_mDice: 0.5921

Epoch 00063: val_mDice did not improve from 0.61232
Epoch 64/300
 - 16s - loss: 1745.4344 - acc: 0.9478 - mDice: 0.7019 - val_loss: 2445.9418 - val_acc: 0.9537 - val_mDice: 0.5897

Epoch 00064: val_mDice did not improve from 0.61232
Epoch 65/300
 - 15s - loss: 1748.4085 - acc: 0.9478 - mDice: 0.7013 - val_loss: 2316.2890 - val_acc: 0.9527 - val_mDice: 0.6034

Epoch 00065: val_mDice did not improve from 0.61232
Epoch 66/300
 - 15s - loss: 1738.0352 - acc: 0.9478 - mDice: 0.7027 - val_loss: 2300.3605 - val_acc: 0.9528 - val_mDice: 0.6042

Epoch 00066: val_mDice did not improve from 0.61232
Epoch 67/300
 - 16s - loss: 1718.3518 - acc: 0.9482 - mDice: 0.7055 - val_loss: 2331.5786 - val_acc: 0.9527 - val_mDice: 0.5985

Epoch 00067: val_mDice did not improve from 0.61232
Epoch 68/300
 - 16s - loss: 1728.8829 - acc: 0.9480 - mDice: 0.7041 - val_loss: 2447.3230 - val_acc: 0.9527 - val_mDice: 0.5922

Epoch 00068: val_mDice did not improve from 0.61232
Epoch 69/300
 - 15s - loss: 1716.3285 - acc: 0.9482 - mDice: 0.7059 - val_loss: 2420.6820 - val_acc: 0.9522 - val_mDice: 0.5927

Epoch 00069: val_mDice did not improve from 0.61232
Epoch 70/300
 - 17s - loss: 1709.7516 - acc: 0.9484 - mDice: 0.7068 - val_loss: 2326.5226 - val_acc: 0.9524 - val_mDice: 0.6011

Epoch 00070: val_mDice did not improve from 0.61232
Epoch 71/300
 - 17s - loss: 1709.2893 - acc: 0.9484 - mDice: 0.7071 - val_loss: 2252.9288 - val_acc: 0.9526 - val_mDice: 0.6076

Epoch 00071: val_mDice did not improve from 0.61232
Epoch 72/300
 - 16s - loss: 1694.6136 - acc: 0.9486 - mDice: 0.7089 - val_loss: 2279.0050 - val_acc: 0.9528 - val_mDice: 0.6050

Epoch 00072: val_mDice did not improve from 0.61232
Epoch 73/300
 - 15s - loss: 1679.2693 - acc: 0.9487 - mDice: 0.7110 - val_loss: 2327.7290 - val_acc: 0.9536 - val_mDice: 0.6041

Epoch 00073: val_mDice did not improve from 0.61232
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [16431.024954172484, 5529.003398873952, 4412.451717440643, 4090.6350438634777, 4247.409708886174, 4260.890731385301, 3884.406188623865, 3779.569589625524, 3317.4753758947277, 3087.6330252706007, 2864.837415982891, 2664.3232912884077, 3075.9892359898745, 2953.0416116554643, 2750.4106922682436, 2719.580555494937, 2476.4899615921786, 2703.722143418296, 2572.5222481668993, 2430.6353889337465, 2516.0658606843576, 2392.9838935383204, 2492.0886421416726, 2506.3650175126572, 2442.7826466480446, 2300.5199499716305, 2516.9459248974335, 2511.3860149703214, 2414.5818252989698, 2210.823561343401, 2362.828730577863, 2530.7706783017634, 2455.3121099205655, 2331.109941024354, 2444.896483011086, 2454.9842099663933, 2251.0844030966305, 2331.4292374083448, 2445.478297398743, 2584.3700953648745, 2260.2713452557614, 2222.2073476780724, 2215.554667041288, 2340.0416880346543, 2650.7929728417425, 2372.8085200986384, 2377.682870875524, 2448.496856177985, 2553.555383096194, 2335.7125278238477, 2278.0056220539454, 2376.884507845234, 2396.0938441100734, 2249.998956605709, 2405.8875507376047, 2365.4921943195704, 2254.1443062041726, 2340.8262605294167, 2450.329992198411, 2439.5241508270774, 2327.1178217200595, 2409.6023372032123, 2423.536997534043, 2445.941827699459, 2316.289022946491, 2300.3604852260823, 2331.578601006023, 2447.323034872556, 2420.6819843313547, 2326.522578234113, 2252.9287818610337, 2279.005041026536, 2327.729044823673], 'val_acc': [0.8989785516728236, 0.9088521999353804, 0.9159945023126442, 0.9216079602028404, 0.9237421864237865, 0.9243930038793127, 0.9262255939691426, 0.9319919284495561, 0.9341509338863735, 0.9386301456882967, 0.9416011155650602, 0.9452104818221577, 0.940307752380158, 0.9404461973206291, 0.9446795316381827, 0.9468364658968409, 0.9489665414367974, 0.9487041714471146, 0.950036790450858, 0.9497702481360409, 0.9504396512521712, 0.9490512582842864, 0.9499520569540268, 0.9512288833463658, 0.9504416984552778, 0.9511710495256179, 0.9506999570564185, 0.950766069929027, 0.9517846503737253, 0.9514809240841998, 0.9506503786454653, 0.9516834147149624, 0.9497764410253343, 0.9516999308623415, 0.9506007999015254, 0.951689611600098, 0.9511007959616251, 0.9501359715808038, 0.9514871316249144, 0.9530966175335079, 0.9501297300754312, 0.9521875278243805, 0.9513362915822248, 0.9518197621713137, 0.9511317870470398, 0.9513631816016895, 0.9502041253297688, 0.9525056837657311, 0.9514251397974665, 0.9519623434743402, 0.9516007687126458, 0.9528238740047263, 0.9525738604907883, 0.9533548411710302, 0.9517123236336522, 0.9502908930432197, 0.9536957454415007, 0.9518982927892461, 0.9511917240126839, 0.9523817320775719, 0.9521937443557398, 0.9522185265684927, 0.9524540335106451, 0.9536502784190897, 0.9526916469275618, 0.952801143323909, 0.9526751201246038, 0.9526585873278826, 0.9522474607941824, 0.9523920756478549, 0.9526275912476652, 0.9528424743167515, 0.953590389403551], 'val_mDice': [0.22003160342157885, 0.3424508438430019, 0.40032639799837294, 0.4255830382501613, 0.4166969295653551, 0.4149560891716174, 0.4405061466067863, 0.4489614034498204, 0.48523822410146616, 0.5071118718751982, 0.5307769142715625, 0.5546079521072643, 0.5109496909146868, 0.5312326670358967, 0.5462920432650177, 0.5530811271853953, 0.5814464378623323, 0.5584345749636602, 0.571273819361319, 0.5860295075944016, 0.5787677385287577, 0.5894067776935726, 0.5788744291779715, 0.5805893154117648, 0.5850463486250552, 0.6025995225879733, 0.5813613657178826, 0.5785275927469051, 0.5951420198605714, 0.611200572392128, 0.5942087100204809, 0.5831120959873306, 0.5857327124259991, 0.6020533169448042, 0.585782658787413, 0.586402942015472, 0.6075134237385329, 0.5961650283642987, 0.5887508798577932, 0.5800077935170861, 0.6063284664180691, 0.6118713290997724, 0.6123181904494429, 0.597850250132257, 0.5710611033706026, 0.594748187331514, 0.5922657491108558, 0.5936805948864814, 0.582326022939309, 0.5991907346182029, 0.6046541396466047, 0.5978038494147402, 0.5912568808933876, 0.6078959124048329, 0.5921073376133456, 0.5929980268025531, 0.6116078549257203, 0.5966001459340143, 0.5853799734701658, 0.5869310997717874, 0.6011917367993787, 0.5896819157307375, 0.5920709791130194, 0.589745538860726, 0.6034210400874388, 0.6042305450865676, 0.5984861837419052, 0.5921925968964007, 0.5927136174127376, 0.601117643564107, 0.6076499117153317, 0.6050362300606413, 0.6040948795872694], 'loss': [20335.60725888411, 9107.968269537207, 6557.348801494379, 5684.693243121992, 5150.121761443562, 4747.185445753631, 4432.717337492043, 4155.79068913794, 3946.7415900129904, 3755.4496610911674, 3557.7664693002703, 3399.7445541921184, 3251.3193473394163, 3169.959678442557, 3115.880841477648, 2988.8171854629463, 2902.195536157066, 2817.0419629813086, 2748.9969059653445, 2715.3370085022793, 2634.0275324766467, 2591.964700172283, 2548.601233300414, 2492.16133009557, 2472.2335211061636, 2410.035879297705, 2389.202453802759, 2374.174319431248, 2322.3896309124552, 2280.470303040731, 2279.3495004617675, 2246.5106348366294, 2229.690078136169, 2202.146675661261, 2177.3027945358986, 2150.7841255566527, 2103.632819361095, 2165.136274813229, 2092.9945671829896, 2076.117663694554, 2060.3301312120566, 2030.113414017504, 2016.9309815543454, 1992.959106458609, 1967.445023137314, 1954.7236072030646, 1940.1271944400771, 1934.7556430776553, 1907.3007067519395, 1892.1434740962288, 1895.4962985656482, 1872.8019133638916, 1866.1855962921686, 1849.1329433926699, 1841.9164354482136, 1859.0134006091164, 1821.2913314880002, 1801.308813132178, 1791.63629050333, 1787.2127596126597, 1772.9229753547345, 1758.286067080286, 1765.2212455238005, 1745.434413531164, 1748.4085449763913, 1738.0352427250589, 1718.3518342246198, 1728.8829283208656, 1716.3285193899594, 1709.7516014606474, 1709.2892995534862, 1694.613624391171, 1679.2692604129347], 'acc': [0.8617572263658232, 0.878295429991933, 0.8899184837462589, 0.8981860815735335, 0.9034940363255651, 0.9081287697167784, 0.9119757231196887, 0.9156598274558856, 0.9186351468546069, 0.9211596305233598, 0.9236299329402368, 0.9256697482750064, 0.9274419805990716, 0.9286939298091816, 0.9294662450459857, 0.9309492387398156, 0.9320889609512255, 0.9331642090673703, 0.9340824897684931, 0.9346413014566293, 0.9354617767529799, 0.936075071436434, 0.9366280229501582, 0.9373390668975029, 0.9376859915366224, 0.9383889538654476, 0.9388277620916292, 0.9392222382554717, 0.9397677977284694, 0.9403090874202552, 0.9403977533433635, 0.9409623445557402, 0.941140538291418, 0.9414242543132014, 0.9419580328036651, 0.9421966920055587, 0.9427124615990968, 0.9422231758123233, 0.9430540238880565, 0.9433153029536313, 0.943688147556002, 0.9438277502431569, 0.944138959357762, 0.9444875327611462, 0.9447906653765895, 0.9448859776964141, 0.945242807529609, 0.94511819011109, 0.9455153039776742, 0.9457938843715893, 0.9457161168693476, 0.946004184231468, 0.9461658223217709, 0.9463147116242382, 0.9464387045785185, 0.946278255156303, 0.9467721899917498, 0.9470217055396885, 0.9471279128036314, 0.947210775722275, 0.9474139287804059, 0.9477380660324144, 0.9476476524443767, 0.9477591762569474, 0.9477781280992883, 0.9478469517364604, 0.9482283368491639, 0.9479848831887144, 0.9481868854594071, 0.9483829044963298, 0.9484032881713745, 0.9486399124432322, 0.948700274301701], 'mDice': [0.1328939734732142, 0.2224019592746879, 0.2972618932769057, 0.3422097818477891, 0.3740721132285091, 0.4005160705176231, 0.4227522754680876, 0.4436387397301404, 0.46191635911783213, 0.47998363779791103, 0.4943625380820058, 0.5090996185540309, 0.5230256377576152, 0.5319984935284517, 0.5383390554980018, 0.5506013764527932, 0.5597550035347562, 0.5688860252605895, 0.5767611950468727, 0.5811228228513923, 0.5893710331228341, 0.5946720346283351, 0.5996795604934192, 0.6062944042456059, 0.6092215271746889, 0.6161919789281548, 0.6189225641485588, 0.6213047958252691, 0.6272348768018597, 0.6319446661530623, 0.6322203260752041, 0.6362679945566213, 0.6390195315092336, 0.6422305346690949, 0.6452887483615968, 0.648242674240859, 0.6542246671168609, 0.6470941781582159, 0.6555670531550093, 0.6579817013831175, 0.6600184332966694, 0.6636585836758262, 0.6656691844242213, 0.6687930043528889, 0.6716567040541536, 0.6734421372212367, 0.6754916632274781, 0.6765049670647773, 0.6798402177801216, 0.6817353207634839, 0.6814815275426667, 0.6845499118891983, 0.6854148599019946, 0.6876579193525874, 0.6886997136030378, 0.6866880852856295, 0.6914202682878852, 0.6941548251526579, 0.6954473965529373, 0.6960483428913942, 0.697976690522012, 0.6999952106147048, 0.6992953832577623, 0.7018710206480926, 0.701317315459102, 0.7027204555270784, 0.705520637206383, 0.7040832391992048, 0.7058755134641523, 0.7068470658887726, 0.7070641153927794, 0.7089022037984369, 0.7109688347795223]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.48s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:06<00:03,  3.20s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.83s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:16,  2.17s/it]predicting train subjects:   1%|          | 2/285 [00:05<11:16,  2.39s/it]predicting train subjects:   1%|          | 3/285 [00:07<10:46,  2.29s/it]predicting train subjects:   1%|▏         | 4/285 [00:10<11:46,  2.51s/it]predicting train subjects:   2%|▏         | 5/285 [00:12<11:12,  2.40s/it]predicting train subjects:   2%|▏         | 6/285 [00:14<11:18,  2.43s/it]predicting train subjects:   2%|▏         | 7/285 [00:17<11:53,  2.57s/it]predicting train subjects:   3%|▎         | 8/285 [00:20<11:31,  2.50s/it]predicting train subjects:   3%|▎         | 9/285 [00:22<11:12,  2.44s/it]predicting train subjects:   4%|▎         | 10/285 [00:25<11:33,  2.52s/it]predicting train subjects:   4%|▍         | 11/285 [00:28<12:25,  2.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:31<12:53,  2.84s/it]predicting train subjects:   5%|▍         | 13/285 [00:34<13:48,  3.05s/it]predicting train subjects:   5%|▍         | 14/285 [00:38<13:57,  3.09s/it]predicting train subjects:   5%|▌         | 15/285 [00:40<13:35,  3.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:44<13:42,  3.06s/it]predicting train subjects:   6%|▌         | 17/285 [00:47<13:32,  3.03s/it]predicting train subjects:   6%|▋         | 18/285 [00:49<13:06,  2.95s/it]predicting train subjects:   7%|▋         | 19/285 [00:52<12:39,  2.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:55<12:38,  2.86s/it]predicting train subjects:   7%|▋         | 21/285 [00:58<13:33,  3.08s/it]predicting train subjects:   8%|▊         | 22/285 [01:01<12:29,  2.85s/it]predicting train subjects:   8%|▊         | 23/285 [01:04<12:28,  2.86s/it]predicting train subjects:   8%|▊         | 24/285 [01:06<12:29,  2.87s/it]predicting train subjects:   9%|▉         | 25/285 [01:09<11:50,  2.73s/it]predicting train subjects:   9%|▉         | 26/285 [01:11<11:05,  2.57s/it]predicting train subjects:   9%|▉         | 27/285 [01:13<10:34,  2.46s/it]predicting train subjects:  10%|▉         | 28/285 [01:15<10:03,  2.35s/it]predicting train subjects:  10%|█         | 29/285 [01:17<09:33,  2.24s/it]predicting train subjects:  11%|█         | 30/285 [01:19<09:03,  2.13s/it]predicting train subjects:  11%|█         | 31/285 [01:21<08:41,  2.05s/it]predicting train subjects:  11%|█         | 32/285 [01:23<08:28,  2.01s/it]predicting train subjects:  12%|█▏        | 33/285 [01:25<08:34,  2.04s/it]predicting train subjects:  12%|█▏        | 34/285 [01:27<08:27,  2.02s/it]predicting train subjects:  12%|█▏        | 35/285 [01:29<08:32,  2.05s/it]predicting train subjects:  13%|█▎        | 36/285 [01:31<08:23,  2.02s/it]predicting train subjects:  13%|█▎        | 37/285 [01:33<08:21,  2.02s/it]predicting train subjects:  13%|█▎        | 38/285 [01:35<08:14,  2.00s/it]predicting train subjects:  14%|█▎        | 39/285 [01:37<08:16,  2.02s/it]predicting train subjects:  14%|█▍        | 40/285 [01:39<08:06,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:41<07:57,  1.96s/it]predicting train subjects:  15%|█▍        | 42/285 [01:43<07:53,  1.95s/it]predicting train subjects:  15%|█▌        | 43/285 [01:45<07:57,  1.97s/it]predicting train subjects:  15%|█▌        | 44/285 [01:47<07:49,  1.95s/it]predicting train subjects:  16%|█▌        | 45/285 [01:49<07:54,  1.98s/it]predicting train subjects:  16%|█▌        | 46/285 [01:51<07:31,  1.89s/it]predicting train subjects:  16%|█▋        | 47/285 [01:52<07:28,  1.89s/it]predicting train subjects:  17%|█▋        | 48/285 [01:54<07:14,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:56<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:58<07:00,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:59<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 52/285 [02:01<06:41,  1.72s/it]predicting train subjects:  19%|█▊        | 53/285 [02:03<06:31,  1.69s/it]predicting train subjects:  19%|█▉        | 54/285 [02:04<06:28,  1.68s/it]predicting train subjects:  19%|█▉        | 55/285 [02:06<06:27,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [02:08<06:18,  1.65s/it]predicting train subjects:  20%|██        | 57/285 [02:09<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [02:11<06:14,  1.65s/it]predicting train subjects:  21%|██        | 59/285 [02:12<06:07,  1.63s/it]predicting train subjects:  21%|██        | 60/285 [02:14<06:04,  1.62s/it]predicting train subjects:  21%|██▏       | 61/285 [02:16<06:03,  1.62s/it]predicting train subjects:  22%|██▏       | 62/285 [02:17<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 63/285 [02:19<06:07,  1.66s/it]predicting train subjects:  22%|██▏       | 64/285 [02:21<06:11,  1.68s/it]predicting train subjects:  23%|██▎       | 65/285 [02:23<06:22,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [02:25<06:30,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [02:26<06:29,  1.79s/it]predicting train subjects:  24%|██▍       | 68/285 [02:28<06:33,  1.81s/it]predicting train subjects:  24%|██▍       | 69/285 [02:30<06:24,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:32<06:17,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:33<06:14,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:35<06:08,  1.73s/it]predicting train subjects:  26%|██▌       | 73/285 [02:37<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:38<06:07,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:40<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:42<06:01,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:44<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:45<05:49,  1.69s/it]predicting train subjects:  28%|██▊       | 79/285 [02:47<05:47,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:49<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:50<05:43,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:52<05:47,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:54<05:48,  1.73s/it]predicting train subjects:  29%|██▉       | 84/285 [02:56<05:47,  1.73s/it]predicting train subjects:  30%|██▉       | 85/285 [02:57<05:49,  1.75s/it]predicting train subjects:  30%|███       | 86/285 [02:59<05:55,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [03:01<06:00,  1.82s/it]predicting train subjects:  31%|███       | 88/285 [03:03<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [03:05<05:56,  1.82s/it]predicting train subjects:  32%|███▏      | 90/285 [03:07<06:00,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [03:09<05:58,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [03:10<05:57,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [03:12<05:56,  1.86s/it]predicting train subjects:  33%|███▎      | 94/285 [03:14<05:50,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [03:16<05:42,  1.80s/it]predicting train subjects:  34%|███▎      | 96/285 [03:18<05:38,  1.79s/it]predicting train subjects:  34%|███▍      | 97/285 [03:19<05:42,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [03:21<05:43,  1.83s/it]predicting train subjects:  35%|███▍      | 99/285 [03:23<05:43,  1.85s/it]predicting train subjects:  35%|███▌      | 100/285 [03:25<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [03:27<05:40,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [03:29<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:31<05:38,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:32<05:36,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:34<05:30,  1.84s/it]predicting train subjects:  37%|███▋      | 106/285 [03:36<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:38<05:22,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:40<05:19,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:41<05:17,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:43<05:12,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:45<05:14,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:47<05:11,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:49<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:50<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:52<05:04,  1.79s/it]predicting train subjects:  41%|████      | 116/285 [03:54<05:01,  1.78s/it]predicting train subjects:  41%|████      | 117/285 [03:56<05:05,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:58<05:06,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [04:00<05:05,  1.84s/it]predicting train subjects:  42%|████▏     | 120/285 [04:01<05:01,  1.83s/it]predicting train subjects:  42%|████▏     | 121/285 [04:03<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [04:04<04:33,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [04:06<04:17,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [04:07<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [04:09<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [04:11<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [04:13<04:21,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [04:14<04:19,  1.65s/it]predicting train subjects:  45%|████▌     | 129/285 [04:16<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:17<04:17,  1.66s/it]predicting train subjects:  46%|████▌     | 131/285 [04:19<04:13,  1.65s/it]predicting train subjects:  46%|████▋     | 132/285 [04:21<04:11,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [04:22<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:24<04:09,  1.65s/it]predicting train subjects:  47%|████▋     | 135/285 [04:26<04:07,  1.65s/it]predicting train subjects:  48%|████▊     | 136/285 [04:27<04:02,  1.63s/it]predicting train subjects:  48%|████▊     | 137/285 [04:29<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:30<03:56,  1.61s/it]predicting train subjects:  49%|████▉     | 139/285 [04:32<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:34<03:51,  1.60s/it]predicting train subjects:  49%|████▉     | 141/285 [04:35<03:48,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:37<03:41,  1.55s/it]predicting train subjects:  50%|█████     | 143/285 [04:38<03:36,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:40<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:41<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:43<03:26,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:44<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:45<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:47<03:21,  1.48s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:48<03:20,  1.48s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:50<03:16,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:51<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:53<03:13,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:54<03:14,  1.49s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:56<03:11,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:57<03:08,  1.46s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:59<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:00<03:09,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:02<03:11,  1.52s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:03<03:09,  1.51s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:05<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:06<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:08<02:57,  1.46s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:09<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:11<02:59,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:12<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:14<02:55,  1.49s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:15<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:17<02:51,  1.48s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:18<02:50,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [05:20<02:50,  1.49s/it]predicting train subjects:  60%|██████    | 172/285 [05:21<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [05:23<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:24<02:46,  1.50s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:25<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:27<02:39,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:28<02:37,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:30<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:31<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:33<02:31,  1.45s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:34<02:30,  1.45s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:36<02:30,  1.46s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:37<02:31,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:39<02:30,  1.49s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:40<02:27,  1.48s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:42<02:25,  1.47s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:43<02:25,  1.48s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:45<02:24,  1.49s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:46<02:24,  1.50s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:48<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:49<02:19,  1.48s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:51<02:18,  1.48s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:52<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:53<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:55<02:12,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:57<02:16,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:59<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:00<02:26,  1.68s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:02<02:26,  1.70s/it]predicting train subjects:  70%|███████   | 200/285 [06:04<02:24,  1.71s/it]predicting train subjects:  71%|███████   | 201/285 [06:05<02:23,  1.71s/it]predicting train subjects:  71%|███████   | 202/285 [06:07<02:19,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [06:09<02:15,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:10<02:13,  1.65s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:12<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:14<02:13,  1.70s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:16<02:12,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:17<02:12,  1.72s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:19<02:13,  1.76s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:21<02:12,  1.76s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:23<02:08,  1.73s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:24<02:06,  1.73s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:26<02:06,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:28<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:29<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:30<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:32<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:33<01:40,  1.50s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:35<01:38,  1.49s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:36<01:34,  1.45s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:38<01:32,  1.45s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:39<01:30,  1.44s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:41<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:42<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:44<01:27,  1.47s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:45<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:47<01:26,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:48<01:23,  1.46s/it]predicting train subjects:  80%|████████  | 229/285 [06:49<01:22,  1.47s/it]predicting train subjects:  81%|████████  | 230/285 [06:51<01:20,  1.46s/it]predicting train subjects:  81%|████████  | 231/285 [06:52<01:19,  1.47s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:54<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:56<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:58<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:00<01:26,  1.73s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:01<01:25,  1.75s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:03<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:05<01:23,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:07<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:09<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:11<01:21,  1.85s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:13<01:20,  1.86s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:14<01:16,  1.83s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:16<01:16,  1.85s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:18<01:13,  1.85s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:20<01:10,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:22<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:24<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:25<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:27<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:28<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:30<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:31<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:33<00:46,  1.51s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:34<00:45,  1.50s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:36<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [07:37<00:41,  1.48s/it]predicting train subjects:  91%|█████████ | 258/285 [07:39<00:40,  1.49s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:37,  1.46s/it]predicting train subjects:  91%|█████████ | 260/285 [07:41<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:44<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:47<00:30,  1.44s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:49<00:29,  1.45s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:50<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:51<00:25,  1.42s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:53<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:55<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:57<00:25,  1.73s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:59<00:25,  1.79s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:01<00:24,  1.85s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:03<00:22,  1.90s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:05<00:21,  1.92s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:07<00:19,  1.90s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:09<00:17,  1.90s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:11<00:15,  1.90s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:13<00:13,  1.91s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:14<00:11,  1.89s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:16<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:18<00:07,  1.89s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:20<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:22<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:24<00:01,  1.86s/it]predicting train subjects: 100%|██████████| 285/285 [08:26<00:00,  1.85s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:27,  1.15s/it]Loading train:   1%|          | 2/285 [00:02<06:01,  1.28s/it]Loading train:   1%|          | 3/285 [00:04<06:00,  1.28s/it]Loading train:   1%|▏         | 4/285 [00:05<06:33,  1.40s/it]Loading train:   2%|▏         | 5/285 [00:06<06:15,  1.34s/it]Loading train:   2%|▏         | 6/285 [00:08<06:29,  1.40s/it]Loading train:   2%|▏         | 7/285 [00:10<06:58,  1.50s/it]Loading train:   3%|▎         | 8/285 [00:11<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:13<06:50,  1.49s/it]Loading train:   4%|▎         | 10/285 [00:14<06:16,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:15<06:00,  1.32s/it]Loading train:   4%|▍         | 12/285 [00:16<05:39,  1.24s/it]Loading train:   5%|▍         | 13/285 [00:17<05:16,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:18<05:09,  1.14s/it]Loading train:   5%|▌         | 15/285 [00:19<04:53,  1.09s/it]Loading train:   6%|▌         | 16/285 [00:20<04:45,  1.06s/it]Loading train:   6%|▌         | 17/285 [00:21<04:45,  1.07s/it]Loading train:   6%|▋         | 18/285 [00:22<04:43,  1.06s/it]Loading train:   7%|▋         | 19/285 [00:23<04:48,  1.08s/it]Loading train:   7%|▋         | 20/285 [00:25<04:59,  1.13s/it]Loading train:   7%|▋         | 21/285 [00:26<04:48,  1.09s/it]Loading train:   8%|▊         | 22/285 [00:27<04:47,  1.09s/it]Loading train:   8%|▊         | 23/285 [00:28<04:38,  1.06s/it]Loading train:   8%|▊         | 24/285 [00:29<04:38,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:30<04:33,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:31<04:25,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:32<04:28,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:33<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:34<04:33,  1.07s/it]Loading train:  11%|█         | 30/285 [00:35<04:19,  1.02s/it]Loading train:  11%|█         | 31/285 [00:36<04:23,  1.04s/it]Loading train:  11%|█         | 32/285 [00:37<04:13,  1.00s/it]Loading train:  12%|█▏        | 33/285 [00:38<04:29,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:39<04:14,  1.01s/it]Loading train:  12%|█▏        | 35/285 [00:40<04:10,  1.00s/it]Loading train:  13%|█▎        | 36/285 [00:41<04:08,  1.00it/s]Loading train:  13%|█▎        | 37/285 [00:42<04:17,  1.04s/it]Loading train:  13%|█▎        | 38/285 [00:43<04:06,  1.00it/s]Loading train:  14%|█▎        | 39/285 [00:44<04:08,  1.01s/it]Loading train:  14%|█▍        | 40/285 [00:45<04:09,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:46<03:57,  1.03it/s]Loading train:  15%|█▍        | 42/285 [00:47<03:50,  1.05it/s]Loading train:  15%|█▌        | 43/285 [00:48<03:57,  1.02it/s]Loading train:  15%|█▌        | 44/285 [00:49<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:50<03:54,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:51<03:57,  1.01it/s]Loading train:  16%|█▋        | 47/285 [00:52<03:45,  1.06it/s]Loading train:  17%|█▋        | 48/285 [00:53<03:49,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:53<03:36,  1.09it/s]Loading train:  18%|█▊        | 50/285 [00:54<03:29,  1.12it/s]Loading train:  18%|█▊        | 51/285 [00:55<03:28,  1.12it/s]Loading train:  18%|█▊        | 52/285 [00:56<03:35,  1.08it/s]Loading train:  19%|█▊        | 53/285 [00:57<03:41,  1.05it/s]Loading train:  19%|█▉        | 54/285 [00:58<03:41,  1.04it/s]Loading train:  19%|█▉        | 55/285 [00:59<03:44,  1.02it/s]Loading train:  20%|█▉        | 56/285 [01:00<03:46,  1.01it/s]Loading train:  20%|██        | 57/285 [01:01<03:35,  1.06it/s]Loading train:  20%|██        | 58/285 [01:02<03:33,  1.06it/s]Loading train:  21%|██        | 59/285 [01:03<03:35,  1.05it/s]Loading train:  21%|██        | 60/285 [01:04<03:34,  1.05it/s]Loading train:  21%|██▏       | 61/285 [01:05<03:30,  1.07it/s]Loading train:  22%|██▏       | 62/285 [01:06<03:33,  1.05it/s]Loading train:  22%|██▏       | 63/285 [01:07<03:28,  1.06it/s]Loading train:  22%|██▏       | 64/285 [01:08<04:05,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:10<04:33,  1.25s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:50,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:24,  1.21s/it]Loading train:  24%|██▍       | 68/285 [01:13<04:12,  1.16s/it]Loading train:  24%|██▍       | 69/285 [01:14<03:50,  1.07s/it]Loading train:  25%|██▍       | 70/285 [01:15<03:55,  1.09s/it]Loading train:  25%|██▍       | 71/285 [01:16<03:37,  1.02s/it]Loading train:  25%|██▌       | 72/285 [01:17<03:38,  1.03s/it]Loading train:  26%|██▌       | 73/285 [01:18<03:24,  1.04it/s]Loading train:  26%|██▌       | 74/285 [01:19<03:24,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:19,  1.05it/s]Loading train:  27%|██▋       | 76/285 [01:21<03:12,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:22<03:07,  1.11it/s]Loading train:  27%|██▋       | 78/285 [01:22<03:03,  1.13it/s]Loading train:  28%|██▊       | 79/285 [01:23<02:55,  1.17it/s]Loading train:  28%|██▊       | 80/285 [01:24<02:59,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:25<03:01,  1.12it/s]Loading train:  29%|██▉       | 82/285 [01:26<03:06,  1.09it/s]Loading train:  29%|██▉       | 83/285 [01:27<02:59,  1.12it/s]Loading train:  29%|██▉       | 84/285 [01:28<02:56,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:29<02:58,  1.12it/s]Loading train:  30%|███       | 86/285 [01:30<03:06,  1.07it/s]Loading train:  31%|███       | 87/285 [01:31<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:32<03:13,  1.02it/s]Loading train:  31%|███       | 89/285 [01:33<03:06,  1.05it/s]Loading train:  32%|███▏      | 90/285 [01:34<03:13,  1.01it/s]Loading train:  32%|███▏      | 91/285 [01:35<03:11,  1.01it/s]Loading train:  32%|███▏      | 92/285 [01:36<03:08,  1.02it/s]Loading train:  33%|███▎      | 93/285 [01:37<03:08,  1.02it/s]Loading train:  33%|███▎      | 94/285 [01:38<03:03,  1.04it/s]Loading train:  33%|███▎      | 95/285 [01:39<03:08,  1.01it/s]Loading train:  34%|███▎      | 96/285 [01:40<03:01,  1.04it/s]Loading train:  34%|███▍      | 97/285 [01:41<03:07,  1.00it/s]Loading train:  34%|███▍      | 98/285 [01:42<03:02,  1.03it/s]Loading train:  35%|███▍      | 99/285 [01:43<03:06,  1.00s/it]Loading train:  35%|███▌      | 100/285 [01:44<03:04,  1.00it/s]Loading train:  35%|███▌      | 101/285 [01:45<03:06,  1.02s/it]Loading train:  36%|███▌      | 102/285 [01:46<03:05,  1.01s/it]Loading train:  36%|███▌      | 103/285 [01:47<03:12,  1.06s/it]Loading train:  36%|███▋      | 104/285 [01:48<03:15,  1.08s/it]Loading train:  37%|███▋      | 105/285 [01:49<03:11,  1.06s/it]Loading train:  37%|███▋      | 106/285 [01:50<03:09,  1.06s/it]Loading train:  38%|███▊      | 107/285 [01:51<03:06,  1.05s/it]Loading train:  38%|███▊      | 108/285 [01:52<03:08,  1.07s/it]Loading train:  38%|███▊      | 109/285 [01:53<03:01,  1.03s/it]Loading train:  39%|███▊      | 110/285 [01:54<02:54,  1.01it/s]Loading train:  39%|███▉      | 111/285 [01:55<02:52,  1.01it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:52,  1.00it/s]Loading train:  40%|███▉      | 113/285 [01:57<02:45,  1.04it/s]Loading train:  40%|████      | 114/285 [01:58<02:48,  1.02it/s]Loading train:  40%|████      | 115/285 [01:59<02:45,  1.02it/s]Loading train:  41%|████      | 116/285 [02:00<02:45,  1.02it/s]Loading train:  41%|████      | 117/285 [02:01<02:43,  1.03it/s]Loading train:  41%|████▏     | 118/285 [02:02<02:45,  1.01it/s]Loading train:  42%|████▏     | 119/285 [02:03<02:43,  1.01it/s]Loading train:  42%|████▏     | 120/285 [02:04<02:40,  1.03it/s]Loading train:  42%|████▏     | 121/285 [02:05<02:57,  1.08s/it]Loading train:  43%|████▎     | 122/285 [02:06<03:09,  1.16s/it]Loading train:  43%|████▎     | 123/285 [02:08<03:12,  1.19s/it]Loading train:  44%|████▎     | 124/285 [02:09<03:08,  1.17s/it]Loading train:  44%|████▍     | 125/285 [02:10<02:47,  1.05s/it]Loading train:  44%|████▍     | 126/285 [02:10<02:33,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:11<02:28,  1.07it/s]Loading train:  45%|████▍     | 128/285 [02:12<02:22,  1.10it/s]Loading train:  45%|████▌     | 129/285 [02:13<02:25,  1.07it/s]Loading train:  46%|████▌     | 130/285 [02:14<02:22,  1.09it/s]Loading train:  46%|████▌     | 131/285 [02:15<02:28,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:16<02:18,  1.10it/s]Loading train:  47%|████▋     | 133/285 [02:17<02:21,  1.07it/s]Loading train:  47%|████▋     | 134/285 [02:18<02:14,  1.12it/s]Loading train:  47%|████▋     | 135/285 [02:18<02:13,  1.12it/s]Loading train:  48%|████▊     | 136/285 [02:19<02:12,  1.13it/s]Loading train:  48%|████▊     | 137/285 [02:20<02:16,  1.09it/s]Loading train:  48%|████▊     | 138/285 [02:21<02:11,  1.12it/s]Loading train:  49%|████▉     | 139/285 [02:22<02:13,  1.09it/s]Loading train:  49%|████▉     | 140/285 [02:23<02:06,  1.15it/s]Loading train:  49%|████▉     | 141/285 [02:24<02:04,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:25<02:05,  1.14it/s]Loading train:  50%|█████     | 143/285 [02:26<02:08,  1.11it/s]Loading train:  51%|█████     | 144/285 [02:26<02:03,  1.14it/s]Loading train:  51%|█████     | 145/285 [02:27<02:05,  1.11it/s]Loading train:  51%|█████     | 146/285 [02:28<02:06,  1.10it/s]Loading train:  52%|█████▏    | 147/285 [02:29<01:56,  1.19it/s]Loading train:  52%|█████▏    | 148/285 [02:30<01:55,  1.18it/s]Loading train:  52%|█████▏    | 149/285 [02:31<01:50,  1.23it/s]Loading train:  53%|█████▎    | 150/285 [02:31<01:48,  1.24it/s]Loading train:  53%|█████▎    | 151/285 [02:32<01:52,  1.19it/s]Loading train:  53%|█████▎    | 152/285 [02:33<01:47,  1.24it/s]Loading train:  54%|█████▎    | 153/285 [02:34<01:53,  1.17it/s]Loading train:  54%|█████▍    | 154/285 [02:35<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:36<01:51,  1.17it/s]Loading train:  55%|█████▍    | 156/285 [02:37<01:54,  1.13it/s]Loading train:  55%|█████▌    | 157/285 [02:37<01:50,  1.15it/s]Loading train:  55%|█████▌    | 158/285 [02:39<01:55,  1.10it/s]Loading train:  56%|█████▌    | 159/285 [02:39<01:47,  1.17it/s]Loading train:  56%|█████▌    | 160/285 [02:40<01:47,  1.16it/s]Loading train:  56%|█████▋    | 161/285 [02:41<01:46,  1.16it/s]Loading train:  57%|█████▋    | 162/285 [02:42<01:41,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [02:43<01:46,  1.14it/s]Loading train:  58%|█████▊    | 164/285 [02:44<01:43,  1.17it/s]Loading train:  58%|█████▊    | 165/285 [02:44<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:45<01:39,  1.20it/s]Loading train:  59%|█████▊    | 167/285 [02:46<01:38,  1.20it/s]Loading train:  59%|█████▉    | 168/285 [02:47<01:37,  1.20it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:36,  1.20it/s]Loading train:  60%|█████▉    | 170/285 [02:48<01:35,  1.21it/s]Loading train:  60%|██████    | 171/285 [02:49<01:31,  1.25it/s]Loading train:  60%|██████    | 172/285 [02:50<01:33,  1.21it/s]Loading train:  61%|██████    | 173/285 [02:51<01:33,  1.20it/s]Loading train:  61%|██████    | 174/285 [02:52<01:35,  1.16it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:32,  1.20it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:39,  1.10it/s]Loading train:  62%|██████▏   | 177/285 [02:54<01:31,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [02:56<01:38,  1.09it/s]Loading train:  63%|██████▎   | 179/285 [02:56<01:32,  1.15it/s]Loading train:  63%|██████▎   | 180/285 [02:57<01:28,  1.19it/s]Loading train:  64%|██████▎   | 181/285 [02:58<01:28,  1.17it/s]Loading train:  64%|██████▍   | 182/285 [02:59<01:23,  1.23it/s]Loading train:  64%|██████▍   | 183/285 [03:00<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:00<01:23,  1.20it/s]Loading train:  65%|██████▍   | 185/285 [03:01<01:23,  1.20it/s]Loading train:  65%|██████▌   | 186/285 [03:02<01:16,  1.29it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:15,  1.29it/s]Loading train:  66%|██████▌   | 188/285 [03:03<01:15,  1.28it/s]Loading train:  66%|██████▋   | 189/285 [03:04<01:12,  1.32it/s]Loading train:  67%|██████▋   | 190/285 [03:05<01:13,  1.28it/s]Loading train:  67%|██████▋   | 191/285 [03:06<01:11,  1.32it/s]Loading train:  67%|██████▋   | 192/285 [03:07<01:14,  1.26it/s]Loading train:  68%|██████▊   | 193/285 [03:07<01:11,  1.29it/s]Loading train:  68%|██████▊   | 194/285 [03:08<01:13,  1.23it/s]Loading train:  68%|██████▊   | 195/285 [03:09<01:13,  1.23it/s]Loading train:  69%|██████▉   | 196/285 [03:10<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [03:11<01:17,  1.14it/s]Loading train:  69%|██████▉   | 198/285 [03:12<01:13,  1.18it/s]Loading train:  70%|██████▉   | 199/285 [03:13<01:14,  1.16it/s]Loading train:  70%|███████   | 200/285 [03:13<01:12,  1.17it/s]Loading train:  71%|███████   | 201/285 [03:14<01:15,  1.11it/s]Loading train:  71%|███████   | 202/285 [03:15<01:12,  1.14it/s]Loading train:  71%|███████   | 203/285 [03:16<01:15,  1.09it/s]Loading train:  72%|███████▏  | 204/285 [03:17<01:14,  1.08it/s]Loading train:  72%|███████▏  | 205/285 [03:18<01:15,  1.06it/s]Loading train:  72%|███████▏  | 206/285 [03:19<01:15,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:20<01:14,  1.05it/s]Loading train:  73%|███████▎  | 208/285 [03:21<01:09,  1.10it/s]Loading train:  73%|███████▎  | 209/285 [03:22<01:10,  1.08it/s]Loading train:  74%|███████▎  | 210/285 [03:23<01:08,  1.10it/s]Loading train:  74%|███████▍  | 211/285 [03:24<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:25<01:05,  1.11it/s]Loading train:  75%|███████▍  | 213/285 [03:25<01:04,  1.12it/s]Loading train:  75%|███████▌  | 214/285 [03:26<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:27<00:57,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:28<00:55,  1.23it/s]Loading train:  76%|███████▌  | 217/285 [03:28<00:53,  1.27it/s]Loading train:  76%|███████▋  | 218/285 [03:29<00:51,  1.31it/s]Loading train:  77%|███████▋  | 219/285 [03:30<00:50,  1.31it/s]Loading train:  77%|███████▋  | 220/285 [03:31<00:48,  1.33it/s]Loading train:  78%|███████▊  | 221/285 [03:32<00:51,  1.25it/s]Loading train:  78%|███████▊  | 222/285 [03:32<00:48,  1.29it/s]Loading train:  78%|███████▊  | 223/285 [03:33<00:50,  1.24it/s]Loading train:  79%|███████▊  | 224/285 [03:34<00:47,  1.28it/s]Loading train:  79%|███████▉  | 225/285 [03:35<00:48,  1.23it/s]Loading train:  79%|███████▉  | 226/285 [03:36<00:47,  1.24it/s]Loading train:  80%|███████▉  | 227/285 [03:36<00:47,  1.21it/s]Loading train:  80%|████████  | 228/285 [03:37<00:45,  1.25it/s]Loading train:  80%|████████  | 229/285 [03:38<00:46,  1.21it/s]Loading train:  81%|████████  | 230/285 [03:39<00:43,  1.27it/s]Loading train:  81%|████████  | 231/285 [03:40<00:42,  1.27it/s]Loading train:  81%|████████▏ | 232/285 [03:41<00:46,  1.15it/s]Loading train:  82%|████████▏ | 233/285 [03:42<00:50,  1.04it/s]Loading train:  82%|████████▏ | 234/285 [03:43<00:49,  1.04it/s]Loading train:  82%|████████▏ | 235/285 [03:45<01:02,  1.24s/it]Loading train:  83%|████████▎ | 236/285 [03:47<01:12,  1.47s/it]Loading train:  83%|████████▎ | 237/285 [03:49<01:21,  1.71s/it]Loading train:  84%|████████▎ | 238/285 [03:51<01:24,  1.79s/it]Loading train:  84%|████████▍ | 239/285 [03:53<01:27,  1.90s/it]Loading train:  84%|████████▍ | 240/285 [03:55<01:28,  1.97s/it]Loading train:  85%|████████▍ | 241/285 [03:57<01:28,  2.00s/it]Loading train:  85%|████████▍ | 242/285 [03:59<01:26,  2.01s/it]Loading train:  85%|████████▌ | 243/285 [04:01<01:23,  2.00s/it]Loading train:  86%|████████▌ | 244/285 [04:03<01:14,  1.82s/it]Loading train:  86%|████████▌ | 245/285 [04:04<01:06,  1.67s/it]Loading train:  86%|████████▋ | 246/285 [04:05<01:01,  1.57s/it]Loading train:  87%|████████▋ | 247/285 [04:07<00:56,  1.49s/it]Loading train:  87%|████████▋ | 248/285 [04:09<01:00,  1.62s/it]Loading train:  87%|████████▋ | 249/285 [04:11<01:02,  1.74s/it]Loading train:  88%|████████▊ | 250/285 [04:12<01:00,  1.73s/it]Loading train:  88%|████████▊ | 251/285 [04:14<00:55,  1.64s/it]Loading train:  88%|████████▊ | 252/285 [04:15<00:49,  1.49s/it]Loading train:  89%|████████▉ | 253/285 [04:16<00:47,  1.47s/it]Loading train:  89%|████████▉ | 254/285 [04:18<00:43,  1.41s/it]Loading train:  89%|████████▉ | 255/285 [04:19<00:40,  1.35s/it]Loading train:  90%|████████▉ | 256/285 [04:20<00:40,  1.41s/it]Loading train:  90%|█████████ | 257/285 [04:22<00:41,  1.48s/it]Loading train:  91%|█████████ | 258/285 [04:24<00:43,  1.60s/it]Loading train:  91%|█████████ | 259/285 [04:25<00:35,  1.38s/it]Loading train:  91%|█████████ | 260/285 [04:26<00:36,  1.45s/it]Loading train:  92%|█████████▏| 261/285 [04:28<00:38,  1.60s/it]Loading train:  92%|█████████▏| 262/285 [04:29<00:32,  1.43s/it]Loading train:  92%|█████████▏| 263/285 [04:30<00:29,  1.32s/it]Loading train:  93%|█████████▎| 264/285 [04:32<00:28,  1.37s/it]Loading train:  93%|█████████▎| 265/285 [04:34<00:29,  1.47s/it]Loading train:  93%|█████████▎| 266/285 [04:35<00:26,  1.39s/it]Loading train:  94%|█████████▎| 267/285 [04:36<00:25,  1.42s/it]Loading train:  94%|█████████▍| 268/285 [04:38<00:26,  1.54s/it]Loading train:  94%|█████████▍| 269/285 [04:39<00:24,  1.51s/it]Loading train:  95%|█████████▍| 270/285 [04:41<00:23,  1.56s/it]Loading train:  95%|█████████▌| 271/285 [04:43<00:22,  1.61s/it]Loading train:  95%|█████████▌| 272/285 [04:44<00:20,  1.60s/it]Loading train:  96%|█████████▌| 273/285 [04:46<00:18,  1.51s/it]Loading train:  96%|█████████▌| 274/285 [04:48<00:17,  1.59s/it]Loading train:  96%|█████████▋| 275/285 [04:49<00:16,  1.68s/it]Loading train:  97%|█████████▋| 276/285 [04:52<00:16,  1.79s/it]Loading train:  97%|█████████▋| 277/285 [04:54<00:15,  1.90s/it]Loading train:  98%|█████████▊| 278/285 [04:55<00:12,  1.73s/it]Loading train:  98%|█████████▊| 279/285 [04:56<00:09,  1.57s/it]Loading train:  98%|█████████▊| 280/285 [04:57<00:07,  1.46s/it]Loading train:  99%|█████████▊| 281/285 [04:59<00:05,  1.45s/it]Loading train:  99%|█████████▉| 282/285 [05:00<00:04,  1.45s/it]Loading train:  99%|█████████▉| 283/285 [05:02<00:03,  1.59s/it]Loading train: 100%|█████████▉| 284/285 [05:04<00:01,  1.56s/it]Loading train: 100%|██████████| 285/285 [05:05<00:00,  1.55s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:08, 33.11it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:06, 42.61it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:04, 52.31it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:06, 41.38it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:06, 35.18it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:05, 41.90it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:05, 42.13it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:05, 39.98it/s]concatenating: train:  24%|██▍       | 68/285 [00:01<00:04, 44.09it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:05, 41.60it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:05, 38.87it/s]concatenating: train:  29%|██▉       | 84/285 [00:01<00:04, 40.67it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:04, 41.78it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:03, 49.75it/s]concatenating: train:  38%|███▊      | 107/285 [00:02<00:03, 56.21it/s]concatenating: train:  40%|████      | 114/285 [00:02<00:03, 44.61it/s]concatenating: train:  42%|████▏     | 120/285 [00:02<00:03, 45.68it/s]concatenating: train:  45%|████▍     | 128/285 [00:02<00:03, 51.62it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 61.03it/s]concatenating: train:  52%|█████▏    | 149/285 [00:02<00:01, 68.57it/s]concatenating: train:  63%|██████▎   | 179/285 [00:02<00:01, 89.16it/s]concatenating: train:  72%|███████▏  | 205/285 [00:02<00:00, 108.84it/s]concatenating: train:  78%|███████▊  | 222/285 [00:03<00:00, 76.12it/s] concatenating: train:  83%|████████▎ | 236/285 [00:03<00:00, 76.57it/s]concatenating: train:  87%|████████▋ | 248/285 [00:03<00:00, 72.29it/s]concatenating: train:  91%|█████████ | 259/285 [00:04<00:00, 52.45it/s]concatenating: train:  94%|█████████▎| 267/285 [00:04<00:00, 50.17it/s]concatenating: train:  96%|█████████▌| 274/285 [00:04<00:00, 51.00it/s]concatenating: train:  99%|█████████▊| 281/285 [00:04<00:00, 54.48it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 62.92it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.79s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.74s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 38.85it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 20)   0           batch_normalization_7[0][0]      2019-07-07 02:43:45.097204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 02:43:45.097316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 02:43:45.097331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 02:43:45.097341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 02:43:45.097834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 30553.1453 - acc: 0.8543 - mDice: 0.1025 - val_loss: 14853.6922 - val_acc: 0.8913 - val_mDice: 0.1867

Epoch 00001: val_mDice improved from -inf to 0.18673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 13622.2037 - acc: 0.8665 - mDice: 0.1975 - val_loss: 9493.0820 - val_acc: 0.8949 - val_mDice: 0.2845

Epoch 00002: val_mDice improved from 0.18673 to 0.28453, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 11332.2245 - acc: 0.8729 - mDice: 0.2521 - val_loss: 8503.7979 - val_acc: 0.8996 - val_mDice: 0.3206

Epoch 00003: val_mDice improved from 0.28453 to 0.32057, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 9935.7984 - acc: 0.8804 - mDice: 0.2938 - val_loss: 7712.7743 - val_acc: 0.9012 - val_mDice: 0.3540

Epoch 00004: val_mDice improved from 0.32057 to 0.35401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 8799.5749 - acc: 0.8900 - mDice: 0.3335 - val_loss: 6933.9478 - val_acc: 0.9138 - val_mDice: 0.3939

Epoch 00005: val_mDice improved from 0.35401 to 0.39394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 7958.2196 - acc: 0.8982 - mDice: 0.3674 - val_loss: 6340.8853 - val_acc: 0.9188 - val_mDice: 0.4229

Epoch 00006: val_mDice improved from 0.39394 to 0.42288, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 9s - loss: 7275.4992 - acc: 0.9040 - mDice: 0.3975 - val_loss: 6142.7412 - val_acc: 0.9167 - val_mDice: 0.4362

Epoch 00007: val_mDice improved from 0.42288 to 0.43619, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 6791.9970 - acc: 0.9078 - mDice: 0.4208 - val_loss: 5879.6371 - val_acc: 0.9199 - val_mDice: 0.4483

Epoch 00008: val_mDice improved from 0.43619 to 0.44830, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 6440.3538 - acc: 0.9105 - mDice: 0.4390 - val_loss: 5697.5239 - val_acc: 0.9214 - val_mDice: 0.4602

Epoch 00009: val_mDice improved from 0.44830 to 0.46018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 6139.3421 - acc: 0.9128 - mDice: 0.4550 - val_loss: 5462.3984 - val_acc: 0.9233 - val_mDice: 0.4752

Epoch 00010: val_mDice improved from 0.46018 to 0.47524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 5857.1248 - acc: 0.9149 - mDice: 0.4710 - val_loss: 5197.5940 - val_acc: 0.9280 - val_mDice: 0.4920

Epoch 00011: val_mDice improved from 0.47524 to 0.49201, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 5672.3860 - acc: 0.9160 - mDice: 0.4815 - val_loss: 5112.5873 - val_acc: 0.9280 - val_mDice: 0.4981

Epoch 00012: val_mDice improved from 0.49201 to 0.49809, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 5441.0727 - acc: 0.9175 - mDice: 0.4948 - val_loss: 5276.2392 - val_acc: 0.9242 - val_mDice: 0.4858

Epoch 00013: val_mDice did not improve from 0.49809
Epoch 14/300
 - 9s - loss: 5295.2317 - acc: 0.9184 - mDice: 0.5038 - val_loss: 4972.8472 - val_acc: 0.9297 - val_mDice: 0.5041

Epoch 00014: val_mDice improved from 0.49809 to 0.50412, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 9s - loss: 5123.5435 - acc: 0.9198 - mDice: 0.5141 - val_loss: 5037.3316 - val_acc: 0.9280 - val_mDice: 0.5005

Epoch 00015: val_mDice did not improve from 0.50412
Epoch 16/300
 - 9s - loss: 4976.7529 - acc: 0.9207 - mDice: 0.5232 - val_loss: 4718.6595 - val_acc: 0.9310 - val_mDice: 0.5214

Epoch 00016: val_mDice improved from 0.50412 to 0.52142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 12s - loss: 4868.7649 - acc: 0.9216 - mDice: 0.5304 - val_loss: 4744.1168 - val_acc: 0.9317 - val_mDice: 0.5179

Epoch 00017: val_mDice did not improve from 0.52142
Epoch 18/300
 - 13s - loss: 4746.3746 - acc: 0.9225 - mDice: 0.5386 - val_loss: 4647.9180 - val_acc: 0.9302 - val_mDice: 0.5233

Epoch 00018: val_mDice improved from 0.52142 to 0.52327, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 12s - loss: 4699.8400 - acc: 0.9231 - mDice: 0.5421 - val_loss: 4600.6656 - val_acc: 0.9306 - val_mDice: 0.5257

Epoch 00019: val_mDice improved from 0.52327 to 0.52573, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 11s - loss: 4561.8031 - acc: 0.9242 - mDice: 0.5513 - val_loss: 4578.6181 - val_acc: 0.9320 - val_mDice: 0.5287

Epoch 00020: val_mDice improved from 0.52573 to 0.52868, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 13s - loss: 4516.9714 - acc: 0.9247 - mDice: 0.5546 - val_loss: 4562.6196 - val_acc: 0.9312 - val_mDice: 0.5298

Epoch 00021: val_mDice improved from 0.52868 to 0.52977, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 11s - loss: 4402.1274 - acc: 0.9254 - mDice: 0.5623 - val_loss: 4505.6668 - val_acc: 0.9331 - val_mDice: 0.5337

Epoch 00022: val_mDice improved from 0.52977 to 0.53373, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 14s - loss: 4315.8804 - acc: 0.9262 - mDice: 0.5683 - val_loss: 4486.8841 - val_acc: 0.9355 - val_mDice: 0.5346

Epoch 00023: val_mDice improved from 0.53373 to 0.53459, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 24/300
 - 11s - loss: 4259.8186 - acc: 0.9266 - mDice: 0.5727 - val_loss: 4468.1380 - val_acc: 0.9339 - val_mDice: 0.5344

Epoch 00024: val_mDice did not improve from 0.53459
Epoch 25/300
 - 11s - loss: 4188.7865 - acc: 0.9273 - mDice: 0.5774 - val_loss: 4451.1290 - val_acc: 0.9336 - val_mDice: 0.5378

Epoch 00025: val_mDice improved from 0.53459 to 0.53776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 13s - loss: 4123.3431 - acc: 0.9277 - mDice: 0.5825 - val_loss: 4445.3135 - val_acc: 0.9339 - val_mDice: 0.5378

Epoch 00026: val_mDice did not improve from 0.53776
Epoch 27/300
 - 11s - loss: 4081.8221 - acc: 0.9279 - mDice: 0.5853 - val_loss: 4390.3997 - val_acc: 0.9332 - val_mDice: 0.5408

Epoch 00027: val_mDice improved from 0.53776 to 0.54083, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 12s - loss: 4013.4429 - acc: 0.9288 - mDice: 0.5909 - val_loss: 4506.9100 - val_acc: 0.9296 - val_mDice: 0.5317

Epoch 00028: val_mDice did not improve from 0.54083
Epoch 29/300
 - 12s - loss: 3963.7011 - acc: 0.9290 - mDice: 0.5944 - val_loss: 4427.9848 - val_acc: 0.9330 - val_mDice: 0.5369

Epoch 00029: val_mDice did not improve from 0.54083
Epoch 30/300
 - 12s - loss: 3907.6848 - acc: 0.9297 - mDice: 0.5988 - val_loss: 4222.0631 - val_acc: 0.9340 - val_mDice: 0.5520

Epoch 00030: val_mDice improved from 0.54083 to 0.55203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 12s - loss: 3868.1621 - acc: 0.9299 - mDice: 0.6017 - val_loss: 4518.3459 - val_acc: 0.9303 - val_mDice: 0.5303

Epoch 00031: val_mDice did not improve from 0.55203
Epoch 32/300
 - 12s - loss: 3808.9020 - acc: 0.9303 - mDice: 0.6061 - val_loss: 4197.1990 - val_acc: 0.9337 - val_mDice: 0.5544

Epoch 00032: val_mDice improved from 0.55203 to 0.55436, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 33/300
 - 12s - loss: 3791.1260 - acc: 0.9307 - mDice: 0.6080 - val_loss: 4297.0455 - val_acc: 0.9325 - val_mDice: 0.5462

Epoch 00033: val_mDice did not improve from 0.55436
Epoch 34/300
 - 13s - loss: 3740.1833 - acc: 0.9313 - mDice: 0.6116 - val_loss: 4221.9743 - val_acc: 0.9341 - val_mDice: 0.5530

Epoch 00034: val_mDice did not improve from 0.55436
Epoch 35/300
 - 13s - loss: 3704.1357 - acc: 0.9315 - mDice: 0.6143 - val_loss: 4365.9570 - val_acc: 0.9338 - val_mDice: 0.5422

Epoch 00035: val_mDice did not improve from 0.55436
Epoch 36/300
 - 12s - loss: 3668.9775 - acc: 0.9320 - mDice: 0.6174 - val_loss: 4142.7516 - val_acc: 0.9363 - val_mDice: 0.5599

Epoch 00036: val_mDice improved from 0.55436 to 0.55989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 37/300
 - 14s - loss: 3626.9445 - acc: 0.9323 - mDice: 0.6205 - val_loss: 4356.9565 - val_acc: 0.9330 - val_mDice: 0.5445

Epoch 00037: val_mDice did not improve from 0.55989
Epoch 38/300
 - 12s - loss: 3572.0108 - acc: 0.9326 - mDice: 0.6248 - val_loss: 4162.5369 - val_acc: 0.9354 - val_mDice: 0.5565

Epoch 00038: val_mDice did not improve from 0.55989
Epoch 39/300
 - 13s - loss: 3558.6701 - acc: 0.9330 - mDice: 0.6262 - val_loss: 4318.7855 - val_acc: 0.9324 - val_mDice: 0.5473

Epoch 00039: val_mDice did not improve from 0.55989
Epoch 40/300
 - 12s - loss: 3547.1982 - acc: 0.9331 - mDice: 0.6267 - val_loss: 4197.9330 - val_acc: 0.9338 - val_mDice: 0.5542

Epoch 00040: val_mDice did not improve from 0.55989
Epoch 41/300
 - 12s - loss: 3509.3353 - acc: 0.9333 - mDice: 0.6301 - val_loss: 4135.5361 - val_acc: 0.9349 - val_mDice: 0.5594

Epoch 00041: val_mDice did not improve from 0.55989
Epoch 42/300
 - 12s - loss: 3473.3359 - acc: 0.9337 - mDice: 0.6328 - val_loss: 4145.1405 - val_acc: 0.9352 - val_mDice: 0.5580

Epoch 00042: val_mDice did not improve from 0.55989
Epoch 43/300
 - 11s - loss: 3454.8506 - acc: 0.9339 - mDice: 0.6344 - val_loss: 4136.9490 - val_acc: 0.9339 - val_mDice: 0.5598

Epoch 00043: val_mDice did not improve from 0.55989
Epoch 44/300
 - 10s - loss: 3427.1906 - acc: 0.9342 - mDice: 0.6368 - val_loss: 4164.7440 - val_acc: 0.9393 - val_mDice: 0.5586

Epoch 00044: val_mDice did not improve from 0.55989
Epoch 45/300
 - 11s - loss: 3385.5242 - acc: 0.9346 - mDice: 0.6400 - val_loss: 4210.3590 - val_acc: 0.9356 - val_mDice: 0.5553

Epoch 00045: val_mDice did not improve from 0.55989
Epoch 46/300
 - 12s - loss: 3372.3829 - acc: 0.9350 - mDice: 0.6413 - val_loss: 3967.2078 - val_acc: 0.9404 - val_mDice: 0.5716

Epoch 00046: val_mDice improved from 0.55989 to 0.57158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 47/300
 - 10s - loss: 3339.5694 - acc: 0.9349 - mDice: 0.6438 - val_loss: 4169.1865 - val_acc: 0.9364 - val_mDice: 0.5583

Epoch 00047: val_mDice did not improve from 0.57158
Epoch 48/300
 - 12s - loss: 3315.8601 - acc: 0.9352 - mDice: 0.6458 - val_loss: 4217.2384 - val_acc: 0.9368 - val_mDice: 0.5534

Epoch 00048: val_mDice did not improve from 0.57158
Epoch 49/300
 - 10s - loss: 3287.7560 - acc: 0.9357 - mDice: 0.6483 - val_loss: 4180.3759 - val_acc: 0.9351 - val_mDice: 0.5570

Epoch 00049: val_mDice did not improve from 0.57158
Epoch 50/300
 - 11s - loss: 3270.1150 - acc: 0.9360 - mDice: 0.6497 - val_loss: 4063.3085 - val_acc: 0.9362 - val_mDice: 0.5646

Epoch 00050: val_mDice did not improve from 0.57158
Epoch 51/300
 - 11s - loss: 3251.0704 - acc: 0.9361 - mDice: 0.6512 - val_loss: 4204.5322 - val_acc: 0.9342 - val_mDice: 0.5557

Epoch 00051: val_mDice did not improve from 0.57158
Epoch 52/300
 - 9s - loss: 3226.4138 - acc: 0.9361 - mDice: 0.6533 - val_loss: 4068.0604 - val_acc: 0.9376 - val_mDice: 0.5638

Epoch 00052: val_mDice did not improve from 0.57158
Epoch 53/300
 - 9s - loss: 3208.6790 - acc: 0.9364 - mDice: 0.6551 - val_loss: 3989.1908 - val_acc: 0.9361 - val_mDice: 0.5706

Epoch 00053: val_mDice did not improve from 0.57158
Epoch 54/300
 - 9s - loss: 3186.5666 - acc: 0.9365 - mDice: 0.6567 - val_loss: 4093.3937 - val_acc: 0.9390 - val_mDice: 0.5634

Epoch 00054: val_mDice did not improve from 0.57158
Epoch 55/300
 - 8s - loss: 3165.8373 - acc: 0.9368 - mDice: 0.6584 - val_loss: 4219.6363 - val_acc: 0.9353 - val_mDice: 0.5533

Epoch 00055: val_mDice did not improve from 0.57158
Epoch 56/300
 - 9s - loss: 3152.0415 - acc: 0.9370 - mDice: 0.6595 - val_loss: 4063.9647 - val_acc: 0.9373 - val_mDice: 0.5651

Epoch 00056: val_mDice did not improve from 0.57158
Epoch 57/300
 - 8s - loss: 3145.1877 - acc: 0.9372 - mDice: 0.6602 - val_loss: 3976.6060 - val_acc: 0.9408 - val_mDice: 0.5726

Epoch 00057: val_mDice improved from 0.57158 to 0.57261, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 58/300
 - 8s - loss: 3132.1400 - acc: 0.9372 - mDice: 0.6613 - val_loss: 4083.5058 - val_acc: 0.9372 - val_mDice: 0.5631

Epoch 00058: val_mDice did not improve from 0.57261
Epoch 59/300
 - 9s - loss: 3084.1043 - acc: 0.9376 - mDice: 0.6654 - val_loss: 3947.8193 - val_acc: 0.9389 - val_mDice: 0.5745

Epoch 00059: val_mDice improved from 0.57261 to 0.57454, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 60/300
 - 8s - loss: 3066.8550 - acc: 0.9379 - mDice: 0.6670 - val_loss: 4003.0403 - val_acc: 0.9387 - val_mDice: 0.5693

Epoch 00060: val_mDice did not improve from 0.57454
Epoch 61/300
 - 9s - loss: 3045.0810 - acc: 0.9381 - mDice: 0.6687 - val_loss: 4004.7823 - val_acc: 0.9398 - val_mDice: 0.5679

Epoch 00061: val_mDice did not improve from 0.57454
Epoch 62/300
 - 8s - loss: 3020.6789 - acc: 0.9382 - mDice: 0.6708 - val_loss: 4132.3248 - val_acc: 0.9383 - val_mDice: 0.5595

Epoch 00062: val_mDice did not improve from 0.57454
Epoch 63/300
 - 8s - loss: 3029.4104 - acc: 0.9383 - mDice: 0.6702 - val_loss: 4172.0747 - val_acc: 0.9352 - val_mDice: 0.5568

Epoch 00063: val_mDice did not improve from 0.57454
Epoch 64/300
 - 8s - loss: 3016.9948 - acc: 0.9383 - mDice: 0.6712 - val_loss: 4409.6915 - val_acc: 0.9339 - val_mDice: 0.5423

Epoch 00064: val_mDice did not improve from 0.57454
Epoch 65/300
 - 8s - loss: 3004.3768 - acc: 0.9386 - mDice: 0.6725 - val_loss: 4128.0700 - val_acc: 0.9358 - val_mDice: 0.5606

Epoch 00065: val_mDice did not improve from 0.57454
Epoch 66/300
 - 8s - loss: 2990.5106 - acc: 0.9386 - mDice: 0.6735 - val_loss: 3859.6185 - val_acc: 0.9398 - val_mDice: 0.5808

Epoch 00066: val_mDice improved from 0.57454 to 0.58080, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 67/300
 - 8s - loss: 2982.1479 - acc: 0.9389 - mDice: 0.6744 - val_loss: 4098.8154 - val_acc: 0.9392 - val_mDice: 0.5629

Epoch 00067: val_mDice did not improve from 0.58080
Epoch 68/300
 - 8s - loss: 2985.4305 - acc: 0.9389 - mDice: 0.6743 - val_loss: 4630.0466 - val_acc: 0.9423 - val_mDice: 0.5403

Epoch 00068: val_mDice did not improve from 0.58080
Epoch 69/300
 - 8s - loss: 2949.9417 - acc: 0.9392 - mDice: 0.6771 - val_loss: 4083.0328 - val_acc: 0.9379 - val_mDice: 0.5627

Epoch 00069: val_mDice did not improve from 0.58080
Epoch 70/300
 - 8s - loss: 2919.4382 - acc: 0.9393 - mDice: 0.6798 - val_loss: 4161.8172 - val_acc: 0.9365 - val_mDice: 0.5578

Epoch 00070: val_mDice did not improve from 0.58080
Epoch 71/300
 - 8s - loss: 2903.2773 - acc: 0.9394 - mDice: 0.6812 - val_loss: 4119.5279 - val_acc: 0.9368 - val_mDice: 0.5603

Epoch 00071: val_mDice did not improve from 0.58080
Epoch 72/300
 - 8s - loss: 2886.7181 - acc: 0.9396 - mDice: 0.6826 - val_loss: 4089.3034 - val_acc: 0.9394 - val_mDice: 0.5626

Epoch 00072: val_mDice did not improve from 0.58080
Epoch 73/300
 - 9s - loss: 2876.4634 - acc: 0.9396 - mDice: 0.6835 - val_loss: 4284.9895 - val_acc: 0.9345 - val_mDice: 0.5479

Epoch 00073: val_mDice did not improve from 0.58080
Epoch 74/300
 - 8s - loss: 2885.6910 - acc: 0.9398 - mDice: 0.6827 - val_loss: 4090.5845 - val_acc: 0.9362 - val_mDice: 0.5624

Epoch 00074: val_mDice did not improve from 0.58080
Epoch 75/300
 - 9s - loss: 2869.5637 - acc: 0.9398 - mDice: 0.6843 - val_loss: 4021.8916 - val_acc: 0.9415 - val_mDice: 0.5679

Epoch 00075: val_mDice did not improve from 0.58080
Epoch 76/300
 - 8s - loss: 2855.1830 - acc: 0.9400 - mDice: 0.6855 - val_loss: 4009.0834 - val_acc: 0.9382 - val_mDice: 0.5696

Epoch 00076: val_mDice did not improve from 0.58080
Epoch 77/300
 - 9s - loss: 2853.0276 - acc: 0.9400 - mDice: 0.6856 - val_loss: 4155.2880 - val_acc: 0.9378 - val_mDice: 0.5585

Epoch 00077: val_mDice did not improve from 0.58080
Epoch 78/300
 - 8s - loss: 2856.5365 - acc: 0.9400 - mDice: 0.6855 - val_loss: 4141.0360 - val_acc: 0.9388 - val_mDice: 0.5594

Epoch 00078: val_mDice did not improve from 0.58080
Epoch 79/300
 - 9s - loss: 2813.6098 - acc: 0.9404 - mDice: 0.6892 - val_loss: 4179.9490 - val_acc: 0.9409 - val_mDice: 0.5601

Epoch 00079: val_mDice did not improve from 0.58080
Epoch 80/300
 - 8s - loss: 2822.1714 - acc: 0.9404 - mDice: 0.6885 - val_loss: 3980.4118 - val_acc: 0.9404 - val_mDice: 0.5693

Epoch 00080: val_mDice did not improve from 0.58080
Epoch 81/300
 - 8s - loss: 2796.0332 - acc: 0.9406 - mDice: 0.6908 - val_loss: 3931.7941 - val_acc: 0.9404 - val_mDice: 0.5742

Epoch 00081: val_mDice did not improve from 0.58080
Epoch 82/300
 - 8s - loss: 2797.5405 - acc: 0.9407 - mDice: 0.6905 - val_loss: 4088.2532 - val_acc: 0.9387 - val_mDice: 0.5636

Epoch 00082: val_mDice did not improve from 0.58080
Epoch 83/300
 - 8s - loss: 2796.8313 - acc: 0.9405 - mDice: 0.6906 - val_loss: 3875.2316 - val_acc: 0.9386 - val_mDice: 0.5784

Epoch 00083: val_mDice did not improve from 0.58080
Epoch 84/300
 - 8s - loss: 2778.0047 - acc: 0.9407 - mDice: 0.6923 - val_loss: 4014.0332 - val_acc: 0.9383 - val_mDice: 0.5699

Epoch 00084: val_mDice did not improve from 0.58080
Epoch 85/300
 - 8s - loss: 2741.1234 - acc: 0.9412 - mDice: 0.6957 - val_loss: 4124.9777 - val_acc: 0.9388 - val_mDice: 0.5607

Epoch 00085: val_mDice did not improve from 0.58080
Epoch 86/300
 - 8s - loss: 2738.7205 - acc: 0.9411 - mDice: 0.6959 - val_loss: 4150.0970 - val_acc: 0.9401 - val_mDice: 0.5585

Epoch 00086: val_mDice did not improve from 0.58080
Epoch 87/300
 - 8s - loss: 2746.1704 - acc: 0.9412 - mDice: 0.6954 - val_loss: 4115.3344 - val_acc: 0.9393 - val_mDice: 0.5622

Epoch 00087: val_mDice did not improve from 0.58080
Epoch 88/300
 - 9s - loss: 2726.2977 - acc: 0.9413 - mDice: 0.6971 - val_loss: 3925.2613 - val_acc: 0.9421 - val_mDice: 0.5755

Epoch 00088: val_mDice did not improve from 0.58080
Epoch 89/300
 - 8s - loss: 2720.8643 - acc: 0.9414 - mDice: 0.6977 - val_loss: 3883.9819 - val_acc: 0.9400 - val_mDice: 0.5781

Epoch 00089: val_mDice did not improve from 0.58080
Epoch 90/300
 - 9s - loss: 2728.5886 - acc: 0.9413 - mDice: 0.6969 - val_loss: 4063.2042 - val_acc: 0.9391 - val_mDice: 0.5662

Epoch 00090: val_mDice did not improve from 0.58080
Epoch 91/300
 - 8s - loss: 2713.0194 - acc: 0.9413 - mDice: 0.6983 - val_loss: 4200.2706 - val_acc: 0.9420 - val_mDice: 0.5561

Epoch 00091: val_mDice did not improve from 0.58080
Epoch 92/300
 - 9s - loss: 2699.4896 - acc: 0.9415 - mDice: 0.6994 - val_loss: 4110.0347 - val_acc: 0.9391 - val_mDice: 0.5603

Epoch 00092: val_mDice did not improve from 0.58080
Epoch 93/300
 - 8s - loss: 2691.8113 - acc: 0.9416 - mDice: 0.7002 - val_loss: 4092.4860 - val_acc: 0.9392 - val_mDice: 0.5635

Epoch 00093: val_mDice did not improve from 0.58080
Epoch 94/300
 - 9s - loss: 2674.0541 - acc: 0.9419 - mDice: 0.7019 - val_loss: 4133.8417 - val_acc: 0.9393 - val_mDice: 0.5615

Epoch 00094: val_mDice did not improve from 0.58080
Epoch 95/300
 - 8s - loss: 2686.9320 - acc: 0.9417 - mDice: 0.7006 - val_loss: 4028.6623 - val_acc: 0.9417 - val_mDice: 0.5692

Epoch 00095: val_mDice did not improve from 0.58080
Epoch 96/300
 - 8s - loss: 2660.0350 - acc: 0.9418 - mDice: 0.7030 - val_loss: 3934.6984 - val_acc: 0.9439 - val_mDice: 0.5740

Epoch 00096: val_mDice did not improve from 0.58080
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
{'val_loss': [14853.692232572115, 9493.082040640023, 8503.7978515625, 7712.774282602163, 6933.947763296274, 6340.885319636418, 6142.741248497596, 5879.637099045974, 5697.523897611178, 5462.398423414964, 5197.593961275541, 5112.587266188401, 5276.239206167368, 4972.84721491887, 5037.331613393931, 4718.6594801682695, 4744.116750863882, 4647.917996920072, 4600.665607158954, 4578.61807016226, 4562.619624211238, 4505.666832557092, 4486.884098933293, 4468.1380286583535, 4451.129009540265, 4445.3135000375605, 4390.399733323317, 4506.9099848820615, 4427.984750600962, 4222.063100961538, 4518.3459237905645, 4197.199009821965, 4297.045480581431, 4221.9742760291465, 4365.95698429988, 4142.751647949219, 4356.956538273738, 4162.536919227014, 4318.785536545974, 4197.932978703426, 4135.536081167368, 4145.140479454627, 4136.949049729567, 4164.744032639724, 4210.358971228967, 3967.207754281851, 4169.1865234375, 4217.238445575421, 4180.375901442308, 4063.3085327148438, 4204.532221867488, 4068.0604060246396, 3989.1907724233774, 4093.393728402945, 4219.636258638822, 4063.9647310697114, 3976.605966421274, 4083.5057936448316, 3947.8192514272837, 4003.040269118089, 4004.7823345477764, 4132.324782151442, 4172.074725811298, 4409.691518930288, 4128.070035494291, 3859.6185349684497, 4098.815354567308, 4630.046626164363, 4083.03276179387, 4161.817180926983, 4119.5279212364785, 4089.3033541165864, 4284.989469088041, 4090.5845336914062, 4021.89157808744, 4009.0834303635816, 4155.287959172176, 4141.036006047176, 4179.9490309495195, 3980.411794809195, 3931.7941378079927, 4088.253178523137, 3875.2316237229566, 4014.033207820012, 4124.977698692908, 4150.096961388221, 4115.334435096154, 3925.2613290640024, 3883.981914813702, 4063.2042424128604, 4200.2706298828125, 4110.034719613882, 4092.4859619140625, 4133.8417405348555, 4028.662273700421, 3934.6983924278848], 'val_acc': [0.891343870988259, 0.8949334117082449, 0.8996024269324082, 0.9011742014151353, 0.9138383154685681, 0.9187684723964105, 0.9166836394713476, 0.9199057060938615, 0.9214127247150128, 0.9233473814450778, 0.9280371941052951, 0.9279562624601218, 0.9241817524799933, 0.929726793215825, 0.9279678463935852, 0.9309587547412286, 0.9316845696706039, 0.93023298566158, 0.9306305555196909, 0.9319873245862814, 0.9311714286987598, 0.9331384117786701, 0.9355052892978375, 0.9339335262775421, 0.9335706371527451, 0.9338665191943829, 0.9332354573103098, 0.9295673232812148, 0.9330436128836411, 0.9339889746445876, 0.9302838582258958, 0.9336515573354868, 0.9325397748213547, 0.9340629806885352, 0.933771740931731, 0.9362726463721349, 0.9330112590239599, 0.9354012539753547, 0.9323617930595691, 0.9338295253423544, 0.9348974021581503, 0.9351539153319138, 0.9338595339885125, 0.9393005669116974, 0.9356347047365628, 0.9404238989719977, 0.9363766885720767, 0.9367719109241779, 0.9351261922946343, 0.9361824943469121, 0.9342340116317456, 0.9375854982779577, 0.9360762009253869, 0.9389816247499906, 0.9353157098476703, 0.9373197234593905, 0.9407590398421655, 0.9372249520741976, 0.9389122541134174, 0.9387273673827832, 0.939806750187507, 0.9382743354027088, 0.9352163489048297, 0.9338734127007998, 0.935778028689898, 0.9398298836671389, 0.9391549504720248, 0.9422660905581254, 0.9379160243731278, 0.9364622028974386, 0.9368134897488815, 0.9394415433590229, 0.9344651423967801, 0.9361871458016909, 0.9414848135067866, 0.9381749377800868, 0.9378120417778308, 0.9387943698809698, 0.9409116346102494, 0.9404308612530048, 0.9404239287743201, 0.9386787918897775, 0.938639528476275, 0.9383113223772782, 0.9387666330887721, 0.940070276076977, 0.9392843704957229, 0.9421019966785724, 0.9400148208324726, 0.939129535968487, 0.9420141554795779, 0.9391018175161802, 0.9391942391028771, 0.9393236728814932, 0.9417229271852053, 0.9439187324964083], 'val_mDice': [0.18673037723279917, 0.284531715970773, 0.3205681818609054, 0.3540123514831066, 0.39393872767686844, 0.4228819746237535, 0.4361940650985791, 0.4483027939613049, 0.46017611427949023, 0.4752445713831828, 0.49201373068185955, 0.49809375634560216, 0.48579026013612747, 0.5041216978659997, 0.5004660544487146, 0.5214191692379805, 0.5179087972411742, 0.5232716695620463, 0.5257348785033593, 0.5286767585919454, 0.5297742784023285, 0.5337315545632288, 0.5345919722547898, 0.5344033166766167, 0.5377563599210519, 0.5377546268013808, 0.5408265057664651, 0.5316949142859533, 0.5368984931936631, 0.5520305080482593, 0.5302504719449923, 0.5543606074956747, 0.5462190560423411, 0.552994423187696, 0.5421508596493647, 0.5598906381772115, 0.5445024967193604, 0.556528774018471, 0.5473406074138788, 0.5542480687682445, 0.5594370021269872, 0.5579806382839496, 0.559758532505769, 0.5585518419169463, 0.5553010243635911, 0.5715810765440648, 0.5582558031265552, 0.5533862916322855, 0.556987654704314, 0.5645910954246154, 0.555710989695329, 0.5638168746462235, 0.5706246649989715, 0.5634442092134402, 0.5533188280577843, 0.565138018475129, 0.5726094108361465, 0.5631132317850223, 0.5745398780474296, 0.5692856019506087, 0.5678702524075141, 0.5595242730700053, 0.5567533683318359, 0.5423347892669531, 0.5606086537815057, 0.580796636067904, 0.5628554144730935, 0.5402698413683817, 0.5627313875235044, 0.5577735270445163, 0.5602615985732812, 0.5625528595768489, 0.5478975130961492, 0.5623606208425301, 0.5678526100057822, 0.5696487506994834, 0.5585030815922297, 0.5594168328321897, 0.5601331327970211, 0.5692860160309535, 0.5742269169825774, 0.5636266693472862, 0.5783589917879838, 0.5698972378785794, 0.5606648876116826, 0.5584592876526026, 0.562231254692261, 0.5755401471486459, 0.5780731393740728, 0.5662167823085418, 0.5560734521311063, 0.5603399193630769, 0.5634625685902742, 0.5614542674559814, 0.569191442659268, 0.5740163807685559], 'loss': [30553.145317102262, 13622.203678307362, 11332.224502694351, 9935.798400028929, 8799.574948154735, 7958.219616346844, 7275.499170579341, 6791.996987678903, 6440.353756005458, 6139.342108631073, 5857.124768378252, 5672.385950122451, 5441.07270975244, 5295.23166509085, 5123.543510889442, 4976.752881998683, 4868.764923199839, 4746.374614774329, 4699.839985476751, 4561.80311235053, 4516.971438541498, 4402.127404108552, 4315.880441546209, 4259.818626268009, 4188.7864566146145, 4123.343141269587, 4081.822067191787, 4013.442944326931, 3963.701134993847, 3907.6848052666105, 3868.162062935819, 3808.902035765352, 3791.1259992923683, 3740.1832828720503, 3704.1356717462986, 3668.97752008154, 3626.9445494226366, 3572.010800143598, 3558.6700753438276, 3547.198177690514, 3509.3352941287726, 3473.335854145892, 3454.8505586594065, 3427.1906477208618, 3385.524180875893, 3372.3828610331657, 3339.5694413685133, 3315.8600680864815, 3287.755979081136, 3270.1150115232213, 3251.0703651198137, 3226.413792105758, 3208.6790054576, 3186.5665759753556, 3165.8372583654022, 3152.0415384795165, 3145.1876589402077, 3132.1399652371488, 3084.1042854346374, 3066.8550360043814, 3045.0810188195655, 3020.6789136149728, 3029.4103972158737, 3016.9948032811526, 3004.3768310997193, 2990.5106081612093, 2982.147868622848, 2985.430503219693, 2949.9417370320643, 2919.438152929255, 2903.277262354781, 2886.718110557809, 2876.4634341716896, 2885.6909582498142, 2869.5637028817373, 2855.1829522701137, 2853.027577780956, 2856.536546397031, 2813.609822257159, 2822.1714326513215, 2796.0331951881217, 2797.540459356789, 2796.831300201599, 2778.004691167851, 2741.1234388892353, 2738.7204675179264, 2746.1704373330217, 2726.2977105787754, 2720.864290066622, 2728.588635171723, 2713.019373165399, 2699.489605627893, 2691.811304829981, 2674.0541006213325, 2686.931970168686, 2660.0349809744584], 'acc': [0.8543225990102089, 0.8665251285016378, 0.8728672651075673, 0.8804116135240315, 0.8899522868731382, 0.8982477633537297, 0.9040323796334284, 0.9077814299110599, 0.9105237822223499, 0.9127820638738237, 0.9148544550579676, 0.9160446245314329, 0.9174913473370264, 0.9183714563673101, 0.9197551256603479, 0.9206530115299424, 0.921648980099524, 0.9225026405100606, 0.9231081183222973, 0.9242029379162414, 0.924678141897283, 0.9253712745485937, 0.9262384354523998, 0.926605478853996, 0.9272978077853483, 0.9277221774039075, 0.9279286461233553, 0.9287675843625384, 0.928970235487769, 0.9297471275895127, 0.9299087178648854, 0.9303012748139707, 0.9307229640265513, 0.9312698854892597, 0.9314903615146153, 0.9319711095576774, 0.9322726804700207, 0.9325888629253418, 0.9329641026609731, 0.9330654888039617, 0.9333166447796637, 0.9337045049399102, 0.9339486108619569, 0.9342454645308931, 0.9346079999182614, 0.9350164330974228, 0.9348997982524807, 0.9352412091611574, 0.9356610582101986, 0.935958526632085, 0.936052013623212, 0.9361256857887137, 0.9363965098569613, 0.9365401898518398, 0.9368002616390579, 0.9369588645085257, 0.9371585461207886, 0.9372313931607721, 0.9375803418664335, 0.9378940839065152, 0.9380551692217597, 0.9382258528637554, 0.9382647148942547, 0.9382768195350265, 0.9386243508561977, 0.9386240854910199, 0.9389106284854136, 0.9388733144221156, 0.9392146389994313, 0.9392528366385093, 0.9394117941674321, 0.9396467428964673, 0.939584450210294, 0.9397761498134778, 0.9397755736114244, 0.939960065626146, 0.9400189932197659, 0.9399970907198815, 0.9404270034054928, 0.9404417241970837, 0.9406302739396852, 0.9407124787494836, 0.9404879915343762, 0.9407010650729315, 0.9411846489623982, 0.9411345665705311, 0.9411809242410457, 0.9413165815046086, 0.9413739307267766, 0.941279469441853, 0.9413281316622194, 0.9415486974930792, 0.9415864707809483, 0.9419020550184822, 0.9416893390418308, 0.941846916736695], 'mDice': [0.10253436351096203, 0.19746332290943705, 0.25209547868708804, 0.2938366715817679, 0.3334671692782021, 0.36737970748225185, 0.3975009212197715, 0.4207581808940188, 0.43898543798757483, 0.4550099627322776, 0.47100044957201587, 0.4814575452992785, 0.49476039236479996, 0.5037927027009438, 0.5141208708687571, 0.5231767146281515, 0.5304364506899074, 0.5385916002955723, 0.5421194432571806, 0.5512649106614366, 0.5545796943053893, 0.5623064177244954, 0.5683488949060023, 0.5726649188296135, 0.5774429766968873, 0.5824941185955894, 0.5853051446762338, 0.5908865674355808, 0.5944214446797732, 0.5988297477305446, 0.60173676688546, 0.6060929691110998, 0.607961599917844, 0.6115667267632003, 0.614347044297781, 0.6173599838858699, 0.6204888795691531, 0.6248279356773979, 0.6261802051303286, 0.6267187753847733, 0.6300649302181454, 0.6327733710046779, 0.6343571066548549, 0.6368462808741466, 0.6400082318652855, 0.6413219730143594, 0.6437652667356155, 0.6458033217304606, 0.6482980916126951, 0.6496510096529935, 0.6511750384515187, 0.6533004305057725, 0.6550775351839224, 0.6566971478334248, 0.6584288441562063, 0.6594673102108478, 0.6602420187475804, 0.6612834245321068, 0.6654218797873694, 0.6670089154888604, 0.6687110832374518, 0.6707942638847536, 0.6702063433701598, 0.6712376883875826, 0.6724664903287352, 0.6734853223726163, 0.6743717222188239, 0.6743332607592426, 0.6771349148656636, 0.6797690150824176, 0.681204070758415, 0.6826364430380321, 0.6834674076566526, 0.6827326649549998, 0.6842799965200483, 0.68547398199908, 0.68562581556085, 0.685496220177064, 0.6891827831670255, 0.6884736074827853, 0.690769240264247, 0.6905441281156304, 0.6905994906610617, 0.6923482603531179, 0.6956778689744804, 0.6958689194570814, 0.6953637714119049, 0.6970539750356268, 0.697650871373164, 0.6968822524104074, 0.6982798864895772, 0.6994092124398757, 0.7001805286241239, 0.7018747358956284, 0.7006485932847181, 0.7030128966857176]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.76s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:24,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:46,  1.44s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:46,  1.44s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:07,  1.52s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:47,  1.45s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:21,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:30,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:19,  1.59s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:44,  1.69s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:50,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:59,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<08:05,  1.79s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:04,  1.79s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:04,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:06,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<08:07,  1.82s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<08:04,  1.82s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<08:02,  1.81s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<08:06,  1.84s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:04,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<08:03,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<08:01,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:52,  1.81s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:55,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:48,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:44,  1.80s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:36,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:32,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:30,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:28,  1.76s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:28,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:22,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:18,  1.75s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:15,  1.74s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:09,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:03,  1.71s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<06:59,  1.71s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<06:53,  1.69s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:54,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:55,  1.71s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:55,  1.72s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<06:58,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<07:07,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:50,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:29,  1.64s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:21,  1.61s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:13,  1.58s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:03,  1.55s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<05:52,  1.51s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<05:48,  1.50s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<05:48,  1.50s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<05:43,  1.49s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<05:41,  1.48s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<05:35,  1.46s/it]predicting train subjects:  20%|██        | 57/285 [01:35<05:31,  1.45s/it]predicting train subjects:  20%|██        | 58/285 [01:37<05:30,  1.46s/it]predicting train subjects:  21%|██        | 59/285 [01:38<05:30,  1.46s/it]predicting train subjects:  21%|██        | 60/285 [01:40<05:33,  1.48s/it]predicting train subjects:  21%|██▏       | 61/285 [01:41<05:37,  1.50s/it]predicting train subjects:  22%|██▏       | 62/285 [01:43<05:36,  1.51s/it]predicting train subjects:  22%|██▏       | 63/285 [01:45<05:34,  1.50s/it]predicting train subjects:  22%|██▏       | 64/285 [01:46<05:33,  1.51s/it]predicting train subjects:  23%|██▎       | 65/285 [01:48<05:42,  1.56s/it]predicting train subjects:  23%|██▎       | 66/285 [01:49<05:47,  1.59s/it]predicting train subjects:  24%|██▎       | 67/285 [01:51<05:40,  1.56s/it]predicting train subjects:  24%|██▍       | 68/285 [01:52<05:31,  1.53s/it]predicting train subjects:  24%|██▍       | 69/285 [01:54<05:26,  1.51s/it]predicting train subjects:  25%|██▍       | 70/285 [01:55<05:30,  1.54s/it]predicting train subjects:  25%|██▍       | 71/285 [01:57<05:25,  1.52s/it]predicting train subjects:  25%|██▌       | 72/285 [01:58<05:24,  1.52s/it]predicting train subjects:  26%|██▌       | 73/285 [02:00<05:19,  1.51s/it]predicting train subjects:  26%|██▌       | 74/285 [02:01<05:14,  1.49s/it]predicting train subjects:  26%|██▋       | 75/285 [02:03<05:12,  1.49s/it]predicting train subjects:  27%|██▋       | 76/285 [02:04<05:10,  1.49s/it]predicting train subjects:  27%|██▋       | 77/285 [02:06<05:10,  1.49s/it]predicting train subjects:  27%|██▋       | 78/285 [02:07<05:08,  1.49s/it]predicting train subjects:  28%|██▊       | 79/285 [02:09<05:09,  1.50s/it]predicting train subjects:  28%|██▊       | 80/285 [02:10<05:08,  1.51s/it]predicting train subjects:  28%|██▊       | 81/285 [02:12<05:08,  1.51s/it]predicting train subjects:  29%|██▉       | 82/285 [02:13<05:05,  1.51s/it]predicting train subjects:  29%|██▉       | 83/285 [02:15<05:04,  1.51s/it]predicting train subjects:  29%|██▉       | 84/285 [02:16<05:04,  1.51s/it]predicting train subjects:  30%|██▉       | 85/285 [02:18<05:14,  1.57s/it]predicting train subjects:  30%|███       | 86/285 [02:20<05:25,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:22<05:27,  1.65s/it]predicting train subjects:  31%|███       | 88/285 [02:23<05:28,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:25<05:28,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:27<05:30,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:28<05:28,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:30<05:24,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:32<05:21,  1.68s/it]predicting train subjects:  33%|███▎      | 94/285 [02:33<05:16,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:35<05:13,  1.65s/it]predicting train subjects:  34%|███▎      | 96/285 [02:37<05:13,  1.66s/it]predicting train subjects:  34%|███▍      | 97/285 [02:38<05:14,  1.67s/it]predicting train subjects:  34%|███▍      | 98/285 [02:40<05:13,  1.68s/it]predicting train subjects:  35%|███▍      | 99/285 [02:42<05:13,  1.69s/it]predicting train subjects:  35%|███▌      | 100/285 [02:43<05:13,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:45<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:47<05:09,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:48<05:06,  1.68s/it]predicting train subjects:  36%|███▋      | 104/285 [02:50<05:03,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:52<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [02:53<04:57,  1.66s/it]predicting train subjects:  38%|███▊      | 107/285 [02:55<04:56,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [02:57<04:54,  1.66s/it]predicting train subjects:  38%|███▊      | 109/285 [02:58<04:50,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:00<04:49,  1.66s/it]predicting train subjects:  39%|███▉      | 111/285 [03:02<04:50,  1.67s/it]predicting train subjects:  39%|███▉      | 112/285 [03:03<04:44,  1.65s/it]predicting train subjects:  40%|███▉      | 113/285 [03:05<04:42,  1.64s/it]predicting train subjects:  40%|████      | 114/285 [03:07<04:40,  1.64s/it]predicting train subjects:  40%|████      | 115/285 [03:08<04:36,  1.63s/it]predicting train subjects:  41%|████      | 116/285 [03:10<04:35,  1.63s/it]predicting train subjects:  41%|████      | 117/285 [03:12<04:34,  1.63s/it]predicting train subjects:  41%|████▏     | 118/285 [03:13<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:15<04:32,  1.64s/it]predicting train subjects:  42%|████▏     | 120/285 [03:17<04:37,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:18<04:27,  1.63s/it]predicting train subjects:  43%|████▎     | 122/285 [03:19<04:11,  1.54s/it]predicting train subjects:  43%|████▎     | 123/285 [03:21<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:22<03:56,  1.47s/it]predicting train subjects:  44%|████▍     | 125/285 [03:24<03:56,  1.48s/it]predicting train subjects:  44%|████▍     | 126/285 [03:25<03:57,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:27<03:55,  1.49s/it]predicting train subjects:  45%|████▍     | 128/285 [03:28<03:53,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:30<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:31<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:33<03:51,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [03:34<03:49,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:36<03:50,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [03:37<03:49,  1.52s/it]predicting train subjects:  47%|████▋     | 135/285 [03:39<03:46,  1.51s/it]predicting train subjects:  48%|████▊     | 136/285 [03:40<03:44,  1.50s/it]predicting train subjects:  48%|████▊     | 137/285 [03:42<03:42,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:43<03:42,  1.51s/it]predicting train subjects:  49%|████▉     | 139/285 [03:45<03:38,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:46<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [03:48<03:36,  1.51s/it]predicting train subjects:  50%|████▉     | 142/285 [03:49<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:50<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:52<03:15,  1.39s/it]predicting train subjects:  51%|█████     | 145/285 [03:53<03:12,  1.37s/it]predicting train subjects:  51%|█████     | 146/285 [03:54<03:09,  1.36s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:56<03:06,  1.35s/it]predicting train subjects:  52%|█████▏    | 148/285 [03:57<03:04,  1.35s/it]predicting train subjects:  52%|█████▏    | 149/285 [03:58<03:01,  1.34s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:00<02:59,  1.33s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:01<03:00,  1.35s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:03<02:59,  1.35s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:04<02:57,  1.35s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:05<02:54,  1.33s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:06<02:52,  1.32s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:08<02:49,  1.31s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:09<02:47,  1.31s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:10<02:46,  1.31s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:12<02:47,  1.33s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:13<02:46,  1.33s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:14<02:48,  1.36s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:16<02:44,  1.34s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:17<02:42,  1.33s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:18<02:41,  1.33s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:20<02:41,  1.34s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:21<02:40,  1.34s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:23<02:40,  1.36s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:24<02:37,  1.35s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:25<02:36,  1.35s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:27<02:40,  1.39s/it]predicting train subjects:  60%|██████    | 171/285 [04:28<02:37,  1.38s/it]predicting train subjects:  60%|██████    | 172/285 [04:29<02:33,  1.36s/it]predicting train subjects:  61%|██████    | 173/285 [04:31<02:30,  1.35s/it]predicting train subjects:  61%|██████    | 174/285 [04:32<02:27,  1.33s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:33<02:26,  1.34s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:35<02:27,  1.35s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:36<02:25,  1.35s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:37<02:21,  1.33s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:39<02:20,  1.32s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:40<02:17,  1.31s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:41<02:16,  1.31s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:43<02:14,  1.31s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:44<02:13,  1.31s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:45<02:12,  1.31s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:46<02:10,  1.30s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:48<02:08,  1.30s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:49<02:07,  1.30s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:50<02:04,  1.28s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:52<02:02,  1.28s/it]predicting train subjects:  67%|██████▋   | 190/285 [04:53<02:02,  1.29s/it]predicting train subjects:  67%|██████▋   | 191/285 [04:54<01:59,  1.28s/it]predicting train subjects:  67%|██████▋   | 192/285 [04:55<01:59,  1.29s/it]predicting train subjects:  68%|██████▊   | 193/285 [04:57<01:58,  1.28s/it]predicting train subjects:  68%|██████▊   | 194/285 [04:58<01:58,  1.30s/it]predicting train subjects:  68%|██████▊   | 195/285 [04:59<01:58,  1.32s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:01<02:02,  1.38s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:02<02:06,  1.43s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:04<02:08,  1.47s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:06<02:08,  1.49s/it]predicting train subjects:  70%|███████   | 200/285 [05:07<02:07,  1.50s/it]predicting train subjects:  71%|███████   | 201/285 [05:09<02:08,  1.53s/it]predicting train subjects:  71%|███████   | 202/285 [05:10<02:07,  1.53s/it]predicting train subjects:  71%|███████   | 203/285 [05:12<02:06,  1.55s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:13<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:15<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:16<02:01,  1.54s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:18<01:59,  1.53s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:19<01:57,  1.53s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:21<01:56,  1.54s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:23<01:55,  1.54s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:24<01:54,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:26<01:52,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:27<01:51,  1.55s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:28<01:44,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:30<01:38,  1.41s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:31<01:34,  1.38s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:32<01:33,  1.37s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:34<01:30,  1.35s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:35<01:29,  1.35s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:36<01:28,  1.35s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:38<01:26,  1.35s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:39<01:25,  1.35s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:40<01:24,  1.36s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:42<01:22,  1.36s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:43<01:21,  1.35s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:45<01:19,  1.35s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:46<01:20,  1.38s/it]predicting train subjects:  80%|████████  | 228/285 [05:47<01:17,  1.36s/it]predicting train subjects:  80%|████████  | 229/285 [05:49<01:15,  1.35s/it]predicting train subjects:  81%|████████  | 230/285 [05:50<01:13,  1.34s/it]predicting train subjects:  81%|████████  | 231/285 [05:51<01:12,  1.35s/it]predicting train subjects:  81%|████████▏ | 232/285 [05:53<01:17,  1.47s/it]predicting train subjects:  82%|████████▏ | 233/285 [05:55<01:19,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [05:56<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [05:58<01:19,  1.60s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:00<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:01<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:03<01:18,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:05<01:15,  1.65s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:07<01:15,  1.68s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:08<01:13,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:10<01:11,  1.67s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:12<01:10,  1.68s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:13<01:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:15<01:07,  1.68s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:17<01:05,  1.68s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:18<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:20<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:22<01:00,  1.67s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:23<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:24<00:49,  1.47s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:25<00:46,  1.40s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:27<00:44,  1.38s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:28<00:42,  1.36s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:29<00:40,  1.35s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:31<00:38,  1.32s/it]predicting train subjects:  90%|█████████ | 257/285 [06:32<00:36,  1.30s/it]predicting train subjects:  91%|█████████ | 258/285 [06:33<00:34,  1.29s/it]predicting train subjects:  91%|█████████ | 259/285 [06:34<00:33,  1.29s/it]predicting train subjects:  91%|█████████ | 260/285 [06:36<00:32,  1.28s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:37<00:30,  1.27s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:38<00:29,  1.28s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:40<00:28,  1.29s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:41<00:26,  1.28s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:42<00:25,  1.27s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:43<00:24,  1.27s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:45<00:22,  1.27s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:46<00:23,  1.40s/it]predicting train subjects:  94%|█████████▍| 269/285 [06:48<00:23,  1.48s/it]predicting train subjects:  95%|█████████▍| 270/285 [06:50<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [06:51<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [06:53<00:21,  1.65s/it]predicting train subjects:  96%|█████████▌| 273/285 [06:55<00:20,  1.67s/it]predicting train subjects:  96%|█████████▌| 274/285 [06:56<00:18,  1.68s/it]predicting train subjects:  96%|█████████▋| 275/285 [06:58<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:00<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:02<00:13,  1.70s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:03<00:11,  1.71s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:05<00:10,  1.71s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:07<00:08,  1.73s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:09<00:06,  1.75s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:10<00:05,  1.73s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:12<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:14<00:01,  1.72s/it]predicting train subjects: 100%|██████████| 285/285 [07:15<00:00,  1.69s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:35,  1.18s/it]Loading train:   1%|          | 2/285 [00:02<05:50,  1.24s/it]Loading train:   1%|          | 3/285 [00:03<05:46,  1.23s/it]Loading train:   1%|▏         | 4/285 [00:05<06:12,  1.32s/it]Loading train:   2%|▏         | 5/285 [00:06<05:43,  1.23s/it]Loading train:   2%|▏         | 6/285 [00:07<06:07,  1.32s/it]Loading train:   2%|▏         | 7/285 [00:09<06:31,  1.41s/it]Loading train:   3%|▎         | 8/285 [00:10<06:37,  1.43s/it]Loading train:   3%|▎         | 9/285 [00:12<06:20,  1.38s/it]Loading train:   4%|▎         | 10/285 [00:13<05:54,  1.29s/it]Loading train:   4%|▍         | 11/285 [00:14<05:31,  1.21s/it]Loading train:   4%|▍         | 12/285 [00:15<05:06,  1.12s/it]Loading train:   5%|▍         | 13/285 [00:16<04:50,  1.07s/it]Loading train:   5%|▍         | 14/285 [00:17<04:43,  1.05s/it]Loading train:   5%|▌         | 15/285 [00:18<04:29,  1.00it/s]Loading train:   6%|▌         | 16/285 [00:18<04:17,  1.04it/s]Loading train:   6%|▌         | 17/285 [00:19<04:16,  1.04it/s]Loading train:   6%|▋         | 18/285 [00:20<04:16,  1.04it/s]Loading train:   7%|▋         | 19/285 [00:21<04:11,  1.06it/s]Loading train:   7%|▋         | 20/285 [00:22<04:12,  1.05it/s]Loading train:   7%|▋         | 21/285 [00:23<04:12,  1.05it/s]Loading train:   8%|▊         | 22/285 [00:24<04:16,  1.02it/s]Loading train:   8%|▊         | 23/285 [00:25<04:22,  1.00s/it]Loading train:   8%|▊         | 24/285 [00:26<04:16,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:27<04:20,  1.00s/it]Loading train:   9%|▉         | 26/285 [00:28<04:14,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:29<04:11,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:30<04:23,  1.03s/it]Loading train:  10%|█         | 29/285 [00:31<04:13,  1.01it/s]Loading train:  11%|█         | 30/285 [00:32<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:33<03:58,  1.06it/s]Loading train:  11%|█         | 32/285 [00:34<03:52,  1.09it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:44,  1.12it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:36,  1.16it/s]Loading train:  12%|█▏        | 35/285 [00:36<03:35,  1.16it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:35,  1.15it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:32,  1.17it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:36,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:37,  1.13it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:39,  1.12it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:38,  1.12it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:38,  1.11it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:42,  1.09it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:43,  1.08it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:44,  1.07it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:38,  1.09it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:23,  1.17it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:15,  1.21it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:12,  1.23it/s]Loading train:  18%|█▊        | 50/285 [00:49<03:08,  1.24it/s]Loading train:  18%|█▊        | 51/285 [00:50<03:09,  1.23it/s]Loading train:  18%|█▊        | 52/285 [00:51<03:02,  1.28it/s]Loading train:  19%|█▊        | 53/285 [00:52<03:00,  1.29it/s]Loading train:  19%|█▉        | 54/285 [00:52<02:54,  1.32it/s]Loading train:  19%|█▉        | 55/285 [00:53<02:54,  1.32it/s]Loading train:  20%|█▉        | 56/285 [00:54<02:47,  1.37it/s]Loading train:  20%|██        | 57/285 [00:55<02:47,  1.36it/s]Loading train:  20%|██        | 58/285 [00:55<02:48,  1.35it/s]Loading train:  21%|██        | 59/285 [00:56<02:49,  1.34it/s]Loading train:  21%|██        | 60/285 [00:57<02:53,  1.30it/s]Loading train:  21%|██▏       | 61/285 [00:58<02:48,  1.33it/s]Loading train:  22%|██▏       | 62/285 [00:58<02:50,  1.31it/s]Loading train:  22%|██▏       | 63/285 [00:59<02:47,  1.32it/s]Loading train:  22%|██▏       | 64/285 [01:01<03:27,  1.07it/s]Loading train:  23%|██▎       | 65/285 [01:02<04:16,  1.16s/it]Loading train:  23%|██▎       | 66/285 [01:04<04:25,  1.21s/it]Loading train:  24%|██▎       | 67/285 [01:04<04:03,  1.12s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:06<03:27,  1.04it/s]Loading train:  25%|██▍       | 70/285 [01:07<03:16,  1.09it/s]Loading train:  25%|██▍       | 71/285 [01:08<03:06,  1.15it/s]Loading train:  25%|██▌       | 72/285 [01:08<03:02,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:55,  1.21it/s]Loading train:  26%|██▌       | 74/285 [01:10<02:50,  1.24it/s]Loading train:  26%|██▋       | 75/285 [01:11<02:51,  1.23it/s]Loading train:  27%|██▋       | 76/285 [01:12<02:50,  1.23it/s]Loading train:  27%|██▋       | 77/285 [01:13<02:56,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:49,  1.22it/s]Loading train:  28%|██▊       | 79/285 [01:14<02:50,  1.21it/s]Loading train:  28%|██▊       | 80/285 [01:15<02:44,  1.25it/s]Loading train:  28%|██▊       | 81/285 [01:16<02:43,  1.25it/s]Loading train:  29%|██▉       | 82/285 [01:17<02:44,  1.23it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:46,  1.21it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:42,  1.24it/s]Loading train:  30%|██▉       | 85/285 [01:19<03:01,  1.10it/s]Loading train:  30%|███       | 86/285 [01:20<03:01,  1.10it/s]Loading train:  31%|███       | 87/285 [01:21<03:02,  1.08it/s]Loading train:  31%|███       | 88/285 [01:22<03:01,  1.09it/s]Loading train:  31%|███       | 89/285 [01:23<03:00,  1.08it/s]Loading train:  32%|███▏      | 90/285 [01:24<03:04,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:25<03:05,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:26<03:10,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:27<03:05,  1.03it/s]Loading train:  33%|███▎      | 94/285 [01:28<02:59,  1.06it/s]Loading train:  33%|███▎      | 95/285 [01:29<03:00,  1.05it/s]Loading train:  34%|███▎      | 96/285 [01:30<03:02,  1.03it/s]Loading train:  34%|███▍      | 97/285 [01:31<03:04,  1.02it/s]Loading train:  34%|███▍      | 98/285 [01:32<03:05,  1.01it/s]Loading train:  35%|███▍      | 99/285 [01:33<03:10,  1.02s/it]Loading train:  35%|███▌      | 100/285 [01:34<03:09,  1.02s/it]Loading train:  35%|███▌      | 101/285 [01:35<03:00,  1.02it/s]Loading train:  36%|███▌      | 102/285 [01:36<02:59,  1.02it/s]Loading train:  36%|███▌      | 103/285 [01:37<03:00,  1.01it/s]Loading train:  36%|███▋      | 104/285 [01:38<02:59,  1.01it/s]Loading train:  37%|███▋      | 105/285 [01:39<02:50,  1.05it/s]Loading train:  37%|███▋      | 106/285 [01:40<02:46,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:40<02:42,  1.10it/s]Loading train:  38%|███▊      | 108/285 [01:41<02:37,  1.13it/s]Loading train:  38%|███▊      | 109/285 [01:42<02:37,  1.12it/s]Loading train:  39%|███▊      | 110/285 [01:43<02:34,  1.13it/s]Loading train:  39%|███▉      | 111/285 [01:44<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:45<02:31,  1.14it/s]Loading train:  40%|███▉      | 113/285 [01:46<02:27,  1.16it/s]Loading train:  40%|████      | 114/285 [01:46<02:27,  1.16it/s]Loading train:  40%|████      | 115/285 [01:47<02:25,  1.16it/s]Loading train:  41%|████      | 116/285 [01:48<02:23,  1.17it/s]Loading train:  41%|████      | 117/285 [01:49<02:21,  1.18it/s]Loading train:  41%|████▏     | 118/285 [01:50<02:24,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:51<02:23,  1.15it/s]Loading train:  42%|████▏     | 120/285 [01:52<02:22,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:53<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:54<02:43,  1.01s/it]Loading train:  43%|████▎     | 123/285 [01:55<02:49,  1.05s/it]Loading train:  44%|████▎     | 124/285 [01:56<02:39,  1.01it/s]Loading train:  44%|████▍     | 125/285 [01:57<02:29,  1.07it/s]Loading train:  44%|████▍     | 126/285 [01:58<02:23,  1.10it/s]Loading train:  45%|████▍     | 127/285 [01:58<02:21,  1.12it/s]Loading train:  45%|████▍     | 128/285 [01:59<02:14,  1.17it/s]Loading train:  45%|████▌     | 129/285 [02:00<02:09,  1.21it/s]Loading train:  46%|████▌     | 130/285 [02:01<02:06,  1.22it/s]Loading train:  46%|████▌     | 131/285 [02:02<02:04,  1.24it/s]Loading train:  46%|████▋     | 132/285 [02:02<02:01,  1.26it/s]Loading train:  47%|████▋     | 133/285 [02:03<02:00,  1.27it/s]Loading train:  47%|████▋     | 134/285 [02:04<02:01,  1.25it/s]Loading train:  47%|████▋     | 135/285 [02:05<02:02,  1.23it/s]Loading train:  48%|████▊     | 136/285 [02:06<01:59,  1.24it/s]Loading train:  48%|████▊     | 137/285 [02:06<01:57,  1.26it/s]Loading train:  48%|████▊     | 138/285 [02:07<01:53,  1.30it/s]Loading train:  49%|████▉     | 139/285 [02:08<01:53,  1.29it/s]Loading train:  49%|████▉     | 140/285 [02:09<01:51,  1.30it/s]Loading train:  49%|████▉     | 141/285 [02:09<01:51,  1.29it/s]Loading train:  50%|████▉     | 142/285 [02:10<01:54,  1.25it/s]Loading train:  50%|█████     | 143/285 [02:11<01:48,  1.31it/s]Loading train:  51%|█████     | 144/285 [02:12<01:45,  1.34it/s]Loading train:  51%|█████     | 145/285 [02:12<01:42,  1.37it/s]Loading train:  51%|█████     | 146/285 [02:13<01:37,  1.42it/s]Loading train:  52%|█████▏    | 147/285 [02:14<01:36,  1.43it/s]Loading train:  52%|█████▏    | 148/285 [02:14<01:36,  1.41it/s]Loading train:  52%|█████▏    | 149/285 [02:15<01:33,  1.45it/s]Loading train:  53%|█████▎    | 150/285 [02:16<01:33,  1.45it/s]Loading train:  53%|█████▎    | 151/285 [02:16<01:33,  1.44it/s]Loading train:  53%|█████▎    | 152/285 [02:17<01:34,  1.40it/s]Loading train:  54%|█████▎    | 153/285 [02:18<01:33,  1.42it/s]Loading train:  54%|█████▍    | 154/285 [02:19<01:35,  1.37it/s]Loading train:  54%|█████▍    | 155/285 [02:19<01:34,  1.38it/s]Loading train:  55%|█████▍    | 156/285 [02:20<01:32,  1.39it/s]Loading train:  55%|█████▌    | 157/285 [02:21<01:29,  1.44it/s]Loading train:  55%|█████▌    | 158/285 [02:21<01:27,  1.45it/s]Loading train:  56%|█████▌    | 159/285 [02:22<01:26,  1.46it/s]Loading train:  56%|█████▌    | 160/285 [02:23<01:29,  1.40it/s]Loading train:  56%|█████▋    | 161/285 [02:24<01:31,  1.35it/s]Loading train:  57%|█████▋    | 162/285 [02:24<01:32,  1.33it/s]Loading train:  57%|█████▋    | 163/285 [02:25<01:30,  1.34it/s]Loading train:  58%|█████▊    | 164/285 [02:26<01:30,  1.34it/s]Loading train:  58%|█████▊    | 165/285 [02:27<01:30,  1.33it/s]Loading train:  58%|█████▊    | 166/285 [02:27<01:27,  1.36it/s]Loading train:  59%|█████▊    | 167/285 [02:28<01:26,  1.36it/s]Loading train:  59%|█████▉    | 168/285 [02:29<01:25,  1.37it/s]Loading train:  59%|█████▉    | 169/285 [02:30<01:22,  1.41it/s]Loading train:  60%|█████▉    | 170/285 [02:30<01:22,  1.39it/s]Loading train:  60%|██████    | 171/285 [02:31<01:22,  1.38it/s]Loading train:  60%|██████    | 172/285 [02:32<01:23,  1.35it/s]Loading train:  61%|██████    | 173/285 [02:32<01:22,  1.35it/s]Loading train:  61%|██████    | 174/285 [02:33<01:22,  1.34it/s]Loading train:  61%|██████▏   | 175/285 [02:34<01:23,  1.32it/s]Loading train:  62%|██████▏   | 176/285 [02:35<01:22,  1.32it/s]Loading train:  62%|██████▏   | 177/285 [02:36<01:22,  1.31it/s]Loading train:  62%|██████▏   | 178/285 [02:36<01:26,  1.24it/s]Loading train:  63%|██████▎   | 179/285 [02:37<01:22,  1.29it/s]Loading train:  63%|██████▎   | 180/285 [02:38<01:21,  1.29it/s]Loading train:  64%|██████▎   | 181/285 [02:39<01:17,  1.33it/s]Loading train:  64%|██████▍   | 182/285 [02:39<01:13,  1.40it/s]Loading train:  64%|██████▍   | 183/285 [02:40<01:13,  1.38it/s]Loading train:  65%|██████▍   | 184/285 [02:41<01:10,  1.42it/s]Loading train:  65%|██████▍   | 185/285 [02:41<01:06,  1.49it/s]Loading train:  65%|██████▌   | 186/285 [02:42<01:05,  1.50it/s]Loading train:  66%|██████▌   | 187/285 [02:43<01:06,  1.47it/s]Loading train:  66%|██████▌   | 188/285 [02:43<01:05,  1.49it/s]Loading train:  66%|██████▋   | 189/285 [02:44<01:03,  1.52it/s]Loading train:  67%|██████▋   | 190/285 [02:45<01:02,  1.52it/s]Loading train:  67%|██████▋   | 191/285 [02:45<01:01,  1.53it/s]Loading train:  67%|██████▋   | 192/285 [02:46<01:02,  1.49it/s]Loading train:  68%|██████▊   | 193/285 [02:47<01:00,  1.51it/s]Loading train:  68%|██████▊   | 194/285 [02:47<01:00,  1.50it/s]Loading train:  68%|██████▊   | 195/285 [02:48<01:00,  1.49it/s]Loading train:  69%|██████▉   | 196/285 [02:49<01:04,  1.38it/s]Loading train:  69%|██████▉   | 197/285 [02:50<01:06,  1.32it/s]Loading train:  69%|██████▉   | 198/285 [02:50<01:07,  1.29it/s]Loading train:  70%|██████▉   | 199/285 [02:51<01:06,  1.29it/s]Loading train:  70%|███████   | 200/285 [02:52<01:04,  1.32it/s]Loading train:  71%|███████   | 201/285 [02:53<01:05,  1.29it/s]Loading train:  71%|███████   | 202/285 [02:54<01:04,  1.29it/s]Loading train:  71%|███████   | 203/285 [02:54<01:01,  1.33it/s]Loading train:  72%|███████▏  | 204/285 [02:55<01:01,  1.31it/s]Loading train:  72%|███████▏  | 205/285 [02:56<01:01,  1.31it/s]Loading train:  72%|███████▏  | 206/285 [02:57<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [02:57<01:00,  1.29it/s]Loading train:  73%|███████▎  | 208/285 [02:58<01:01,  1.26it/s]Loading train:  73%|███████▎  | 209/285 [02:59<01:00,  1.26it/s]Loading train:  74%|███████▎  | 210/285 [03:00<00:59,  1.25it/s]Loading train:  74%|███████▍  | 211/285 [03:00<00:57,  1.29it/s]Loading train:  74%|███████▍  | 212/285 [03:01<00:56,  1.30it/s]Loading train:  75%|███████▍  | 213/285 [03:02<00:54,  1.32it/s]Loading train:  75%|███████▌  | 214/285 [03:03<00:53,  1.32it/s]Loading train:  75%|███████▌  | 215/285 [03:03<00:51,  1.36it/s]Loading train:  76%|███████▌  | 216/285 [03:04<00:50,  1.38it/s]Loading train:  76%|███████▌  | 217/285 [03:05<00:48,  1.39it/s]Loading train:  76%|███████▋  | 218/285 [03:06<00:47,  1.41it/s]Loading train:  77%|███████▋  | 219/285 [03:06<00:47,  1.40it/s]Loading train:  77%|███████▋  | 220/285 [03:07<00:46,  1.39it/s]Loading train:  78%|███████▊  | 221/285 [03:08<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:08<00:45,  1.39it/s]Loading train:  78%|███████▊  | 223/285 [03:09<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:10<00:42,  1.45it/s]Loading train:  79%|███████▉  | 225/285 [03:10<00:41,  1.46it/s]Loading train:  79%|███████▉  | 226/285 [03:11<00:40,  1.47it/s]Loading train:  80%|███████▉  | 227/285 [03:12<00:39,  1.48it/s]Loading train:  80%|████████  | 228/285 [03:12<00:39,  1.43it/s]Loading train:  80%|████████  | 229/285 [03:13<00:39,  1.42it/s]Loading train:  81%|████████  | 230/285 [03:14<00:38,  1.44it/s]Loading train:  81%|████████  | 231/285 [03:15<00:38,  1.42it/s]Loading train:  81%|████████▏ | 232/285 [03:16<00:41,  1.29it/s]Loading train:  82%|████████▏ | 233/285 [03:16<00:41,  1.24it/s]Loading train:  82%|████████▏ | 234/285 [03:17<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:18<00:42,  1.17it/s]Loading train:  83%|████████▎ | 236/285 [03:19<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:20<00:41,  1.16it/s]Loading train:  84%|████████▎ | 238/285 [03:21<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [03:22<00:40,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:23<00:40,  1.11it/s]Loading train:  85%|████████▍ | 241/285 [03:24<00:40,  1.10it/s]Loading train:  85%|████████▍ | 242/285 [03:25<00:39,  1.09it/s]Loading train:  85%|████████▌ | 243/285 [03:26<00:38,  1.09it/s]Loading train:  86%|████████▌ | 244/285 [03:27<00:38,  1.06it/s]Loading train:  86%|████████▌ | 245/285 [03:28<00:38,  1.04it/s]Loading train:  86%|████████▋ | 246/285 [03:28<00:37,  1.04it/s]Loading train:  87%|████████▋ | 247/285 [03:29<00:36,  1.04it/s]Loading train:  87%|████████▋ | 248/285 [03:30<00:35,  1.06it/s]Loading train:  87%|████████▋ | 249/285 [03:31<00:33,  1.08it/s]Loading train:  88%|████████▊ | 250/285 [03:32<00:29,  1.17it/s]Loading train:  88%|████████▊ | 251/285 [03:33<00:27,  1.25it/s]Loading train:  88%|████████▊ | 252/285 [03:33<00:24,  1.32it/s]Loading train:  89%|████████▉ | 253/285 [03:34<00:23,  1.36it/s]Loading train:  89%|████████▉ | 254/285 [03:35<00:22,  1.37it/s]Loading train:  89%|████████▉ | 255/285 [03:35<00:21,  1.38it/s]Loading train:  90%|████████▉ | 256/285 [03:36<00:21,  1.37it/s]Loading train:  90%|█████████ | 257/285 [03:37<00:20,  1.38it/s]Loading train:  91%|█████████ | 258/285 [03:38<00:19,  1.40it/s]Loading train:  91%|█████████ | 259/285 [03:38<00:18,  1.43it/s]Loading train:  91%|█████████ | 260/285 [03:39<00:17,  1.41it/s]Loading train:  92%|█████████▏| 261/285 [03:40<00:16,  1.41it/s]Loading train:  92%|█████████▏| 262/285 [03:40<00:16,  1.42it/s]Loading train:  92%|█████████▏| 263/285 [03:41<00:15,  1.42it/s]Loading train:  93%|█████████▎| 264/285 [03:42<00:14,  1.44it/s]Loading train:  93%|█████████▎| 265/285 [03:42<00:14,  1.40it/s]Loading train:  93%|█████████▎| 266/285 [03:43<00:13,  1.38it/s]Loading train:  94%|█████████▎| 267/285 [03:44<00:12,  1.40it/s]Loading train:  94%|█████████▍| 268/285 [03:45<00:14,  1.20it/s]Loading train:  94%|█████████▍| 269/285 [03:46<00:13,  1.19it/s]Loading train:  95%|█████████▍| 270/285 [03:47<00:12,  1.16it/s]Loading train:  95%|█████████▌| 271/285 [03:48<00:12,  1.16it/s]Loading train:  95%|█████████▌| 272/285 [03:49<00:11,  1.15it/s]Loading train:  96%|█████████▌| 273/285 [03:49<00:10,  1.17it/s]Loading train:  96%|█████████▌| 274/285 [03:50<00:09,  1.13it/s]Loading train:  96%|█████████▋| 275/285 [03:51<00:08,  1.13it/s]Loading train:  97%|█████████▋| 276/285 [03:52<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [03:53<00:06,  1.16it/s]Loading train:  98%|█████████▊| 278/285 [03:54<00:06,  1.14it/s]Loading train:  98%|█████████▊| 279/285 [03:55<00:05,  1.14it/s]Loading train:  98%|█████████▊| 280/285 [03:56<00:04,  1.13it/s]Loading train:  99%|█████████▊| 281/285 [03:57<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [03:57<00:02,  1.08it/s]Loading train:  99%|█████████▉| 283/285 [03:58<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [03:59<00:00,  1.09it/s]Loading train: 100%|██████████| 285/285 [04:00<00:00,  1.06it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:01, 176.88it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:01, 157.55it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:01, 166.73it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:01, 176.33it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:01, 181.71it/s]concatenating: train:  41%|████      | 116/285 [00:00<00:00, 195.41it/s]concatenating: train:  48%|████▊     | 138/285 [00:00<00:00, 202.00it/s]concatenating: train:  58%|█████▊    | 164/285 [00:00<00:00, 215.34it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 226.98it/s]concatenating: train:  76%|███████▌  | 216/285 [00:01<00:00, 234.01it/s]concatenating: train:  84%|████████▍ | 240/285 [00:01<00:00, 235.22it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 220.85it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 216.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.23s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.23s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 177.34it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-07 03:11:54.446966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 03:11:54.447073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 03:11:54.447088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 03:11:54.447097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 03:11:54.447547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 11264.6255 - acc: 0.8499 - mDice: 0.1986 - val_loss: 5993.8310 - val_acc: 0.9009 - val_mDice: 0.3014

Epoch 00001: val_mDice improved from -inf to 0.30137, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 5331.2567 - acc: 0.8732 - mDice: 0.3539 - val_loss: 4329.1613 - val_acc: 0.9126 - val_mDice: 0.3956

Epoch 00002: val_mDice improved from 0.30137 to 0.39556, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 4178.3703 - acc: 0.8898 - mDice: 0.4352 - val_loss: 3947.4153 - val_acc: 0.9197 - val_mDice: 0.4300

Epoch 00003: val_mDice improved from 0.39556 to 0.42996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 3658.2075 - acc: 0.9009 - mDice: 0.4804 - val_loss: 3690.9791 - val_acc: 0.9263 - val_mDice: 0.4501

Epoch 00004: val_mDice improved from 0.42996 to 0.45013, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 3326.7688 - acc: 0.9080 - mDice: 0.5125 - val_loss: 3446.9498 - val_acc: 0.9268 - val_mDice: 0.4729

Epoch 00005: val_mDice improved from 0.45013 to 0.47290, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 3094.2429 - acc: 0.9126 - mDice: 0.5364 - val_loss: 3306.3645 - val_acc: 0.9295 - val_mDice: 0.4841

Epoch 00006: val_mDice improved from 0.47290 to 0.48406, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 2895.8515 - acc: 0.9164 - mDice: 0.5574 - val_loss: 3144.4927 - val_acc: 0.9283 - val_mDice: 0.5026

Epoch 00007: val_mDice improved from 0.48406 to 0.50260, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 9s - loss: 2748.3138 - acc: 0.9194 - mDice: 0.5738 - val_loss: 3085.1709 - val_acc: 0.9341 - val_mDice: 0.5069

Epoch 00008: val_mDice improved from 0.50260 to 0.50687, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 10s - loss: 2623.9220 - acc: 0.9218 - mDice: 0.5882 - val_loss: 3044.4565 - val_acc: 0.9360 - val_mDice: 0.5103

Epoch 00009: val_mDice improved from 0.50687 to 0.51034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 2525.5971 - acc: 0.9238 - mDice: 0.5999 - val_loss: 2863.4117 - val_acc: 0.9356 - val_mDice: 0.5314

Epoch 00010: val_mDice improved from 0.51034 to 0.53144, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 2432.0007 - acc: 0.9255 - mDice: 0.6111 - val_loss: 2838.6495 - val_acc: 0.9345 - val_mDice: 0.5356

Epoch 00011: val_mDice improved from 0.53144 to 0.53562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 2372.7466 - acc: 0.9269 - mDice: 0.6181 - val_loss: 2876.0695 - val_acc: 0.9351 - val_mDice: 0.5295

Epoch 00012: val_mDice did not improve from 0.53562
Epoch 13/300
 - 9s - loss: 2285.2993 - acc: 0.9286 - mDice: 0.6293 - val_loss: 2759.6186 - val_acc: 0.9417 - val_mDice: 0.5424

Epoch 00013: val_mDice improved from 0.53562 to 0.54237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 9s - loss: 2246.6636 - acc: 0.9295 - mDice: 0.6342 - val_loss: 2737.3918 - val_acc: 0.9401 - val_mDice: 0.5441

Epoch 00014: val_mDice improved from 0.54237 to 0.54407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 9s - loss: 2184.0265 - acc: 0.9308 - mDice: 0.6423 - val_loss: 2848.1087 - val_acc: 0.9327 - val_mDice: 0.5336

Epoch 00015: val_mDice did not improve from 0.54407
Epoch 16/300
 - 9s - loss: 2122.6540 - acc: 0.9318 - mDice: 0.6499 - val_loss: 2781.6149 - val_acc: 0.9438 - val_mDice: 0.5390

Epoch 00016: val_mDice did not improve from 0.54407
Epoch 17/300
 - 9s - loss: 2078.3886 - acc: 0.9328 - mDice: 0.6559 - val_loss: 2812.2233 - val_acc: 0.9431 - val_mDice: 0.5375

Epoch 00017: val_mDice did not improve from 0.54407
Epoch 18/300
 - 9s - loss: 2044.7928 - acc: 0.9334 - mDice: 0.6603 - val_loss: 2680.6311 - val_acc: 0.9408 - val_mDice: 0.5507

Epoch 00018: val_mDice improved from 0.54407 to 0.55069, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 9s - loss: 1988.9711 - acc: 0.9345 - mDice: 0.6676 - val_loss: 2713.4148 - val_acc: 0.9430 - val_mDice: 0.5485

Epoch 00019: val_mDice did not improve from 0.55069
Epoch 20/300
 - 9s - loss: 1961.6188 - acc: 0.9351 - mDice: 0.6713 - val_loss: 2715.3718 - val_acc: 0.9427 - val_mDice: 0.5469

Epoch 00020: val_mDice did not improve from 0.55069
Epoch 21/300
 - 9s - loss: 1940.2153 - acc: 0.9356 - mDice: 0.6742 - val_loss: 2771.0273 - val_acc: 0.9457 - val_mDice: 0.5410

Epoch 00021: val_mDice did not improve from 0.55069
Epoch 22/300
 - 9s - loss: 1900.9407 - acc: 0.9365 - mDice: 0.6795 - val_loss: 2596.9426 - val_acc: 0.9447 - val_mDice: 0.5592

Epoch 00022: val_mDice improved from 0.55069 to 0.55916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 9s - loss: 1884.8914 - acc: 0.9367 - mDice: 0.6818 - val_loss: 2627.3536 - val_acc: 0.9447 - val_mDice: 0.5542

Epoch 00023: val_mDice did not improve from 0.55916
Epoch 24/300
 - 9s - loss: 1852.6671 - acc: 0.9374 - mDice: 0.6861 - val_loss: 2727.8422 - val_acc: 0.9458 - val_mDice: 0.5475

Epoch 00024: val_mDice did not improve from 0.55916
Epoch 25/300
 - 9s - loss: 1820.8458 - acc: 0.9379 - mDice: 0.6905 - val_loss: 2722.7857 - val_acc: 0.9467 - val_mDice: 0.5445

Epoch 00025: val_mDice did not improve from 0.55916
Epoch 26/300
 - 9s - loss: 1803.3343 - acc: 0.9383 - mDice: 0.6930 - val_loss: 2761.4022 - val_acc: 0.9405 - val_mDice: 0.5426

Epoch 00026: val_mDice did not improve from 0.55916
Epoch 27/300
 - 9s - loss: 1782.3317 - acc: 0.9387 - mDice: 0.6959 - val_loss: 2882.3060 - val_acc: 0.9445 - val_mDice: 0.5257

Epoch 00027: val_mDice did not improve from 0.55916
Epoch 28/300
 - 9s - loss: 1773.2887 - acc: 0.9389 - mDice: 0.6972 - val_loss: 2744.7892 - val_acc: 0.9459 - val_mDice: 0.5392

Epoch 00028: val_mDice did not improve from 0.55916
Epoch 29/300
 - 9s - loss: 1732.7380 - acc: 0.9397 - mDice: 0.7028 - val_loss: 2749.6021 - val_acc: 0.9474 - val_mDice: 0.5414

Epoch 00029: val_mDice did not improve from 0.55916
Epoch 30/300
 - 9s - loss: 1724.9204 - acc: 0.9400 - mDice: 0.7039 - val_loss: 2755.0078 - val_acc: 0.9448 - val_mDice: 0.5401

Epoch 00030: val_mDice did not improve from 0.55916
Epoch 31/300
 - 9s - loss: 1701.1107 - acc: 0.9405 - mDice: 0.7074 - val_loss: 2719.9767 - val_acc: 0.9465 - val_mDice: 0.5456

Epoch 00031: val_mDice did not improve from 0.55916
Epoch 32/300
 - 9s - loss: 1678.1400 - acc: 0.9410 - mDice: 0.7106 - val_loss: 3133.9798 - val_acc: 0.9438 - val_mDice: 0.4964

Epoch 00032: val_mDice did not improve from 0.55916
Epoch 33/300
 - 9s - loss: 1662.9708 - acc: 0.9412 - mDice: 0.7127 - val_loss: 2849.6821 - val_acc: 0.9476 - val_mDice: 0.5273

Epoch 00033: val_mDice did not improve from 0.55916
Epoch 34/300
 - 9s - loss: 1647.9581 - acc: 0.9416 - mDice: 0.7149 - val_loss: 2807.2221 - val_acc: 0.9473 - val_mDice: 0.5316

Epoch 00034: val_mDice did not improve from 0.55916
Epoch 35/300
 - 9s - loss: 1634.7128 - acc: 0.9417 - mDice: 0.7168 - val_loss: 2708.6054 - val_acc: 0.9466 - val_mDice: 0.5482

Epoch 00035: val_mDice did not improve from 0.55916
Epoch 36/300
 - 9s - loss: 1611.5811 - acc: 0.9422 - mDice: 0.7202 - val_loss: 2757.3533 - val_acc: 0.9457 - val_mDice: 0.5409

Epoch 00036: val_mDice did not improve from 0.55916
Epoch 37/300
 - 9s - loss: 1604.4233 - acc: 0.9422 - mDice: 0.7211 - val_loss: 2765.9633 - val_acc: 0.9460 - val_mDice: 0.5383

Epoch 00037: val_mDice did not improve from 0.55916
Epoch 38/300
 - 9s - loss: 1586.6725 - acc: 0.9427 - mDice: 0.7237 - val_loss: 2709.2776 - val_acc: 0.9443 - val_mDice: 0.5454

Epoch 00038: val_mDice did not improve from 0.55916
Epoch 39/300
 - 9s - loss: 1570.7924 - acc: 0.9432 - mDice: 0.7261 - val_loss: 2827.9229 - val_acc: 0.9447 - val_mDice: 0.5336

Epoch 00039: val_mDice did not improve from 0.55916
Epoch 40/300
 - 9s - loss: 1554.9702 - acc: 0.9433 - mDice: 0.7284 - val_loss: 2827.0686 - val_acc: 0.9456 - val_mDice: 0.5310

Epoch 00040: val_mDice did not improve from 0.55916
Epoch 41/300
 - 9s - loss: 1541.4967 - acc: 0.9437 - mDice: 0.7304 - val_loss: 2747.8659 - val_acc: 0.9479 - val_mDice: 0.5444

Epoch 00041: val_mDice did not improve from 0.55916
Epoch 42/300
 - 9s - loss: 1528.1453 - acc: 0.9440 - mDice: 0.7323 - val_loss: 3022.2418 - val_acc: 0.9461 - val_mDice: 0.5099

Epoch 00042: val_mDice did not improve from 0.55916
Epoch 43/300
 - 9s - loss: 1523.3024 - acc: 0.9439 - mDice: 0.7330 - val_loss: 2974.9256 - val_acc: 0.9470 - val_mDice: 0.5178

Epoch 00043: val_mDice did not improve from 0.55916
Epoch 44/300
 - 9s - loss: 1496.0196 - acc: 0.9445 - mDice: 0.7370 - val_loss: 2637.6157 - val_acc: 0.9465 - val_mDice: 0.5519

Epoch 00044: val_mDice did not improve from 0.55916
Epoch 45/300
 - 9s - loss: 1490.5618 - acc: 0.9447 - mDice: 0.7379 - val_loss: 2702.8950 - val_acc: 0.9483 - val_mDice: 0.5466

Epoch 00045: val_mDice did not improve from 0.55916
Epoch 46/300
 - 9s - loss: 1480.0952 - acc: 0.9449 - mDice: 0.7395 - val_loss: 2814.7988 - val_acc: 0.9496 - val_mDice: 0.5358

Epoch 00046: val_mDice did not improve from 0.55916
Epoch 47/300
 - 9s - loss: 1460.0270 - acc: 0.9453 - mDice: 0.7424 - val_loss: 2731.0482 - val_acc: 0.9471 - val_mDice: 0.5416

Epoch 00047: val_mDice did not improve from 0.55916
Epoch 48/300
 - 9s - loss: 1454.1746 - acc: 0.9453 - mDice: 0.7432 - val_loss: 2682.3808 - val_acc: 0.9469 - val_mDice: 0.5487

Epoch 00048: val_mDice did not improve from 0.55916
Epoch 49/300
 - 9s - loss: 1450.1173 - acc: 0.9454 - mDice: 0.7438 - val_loss: 2646.9587 - val_acc: 0.9473 - val_mDice: 0.5528

Epoch 00049: val_mDice did not improve from 0.55916
Epoch 50/300
 - 9s - loss: 1439.2979 - acc: 0.9455 - mDice: 0.7455 - val_loss: 2842.8944 - val_acc: 0.9470 - val_mDice: 0.5299

Epoch 00050: val_mDice did not improve from 0.55916
Epoch 51/300
 - 9s - loss: 1424.9270 - acc: 0.9459 - mDice: 0.7476 - val_loss: 3035.3110 - val_acc: 0.9474 - val_mDice: 0.5103

Epoch 00051: val_mDice did not improve from 0.55916
Epoch 52/300
 - 9s - loss: 1423.5380 - acc: 0.9458 - mDice: 0.7479 - val_loss: 3063.2801 - val_acc: 0.9472 - val_mDice: 0.5095

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.05s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:27,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:47,  1.44s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:50,  1.46s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:02,  1.51s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:38,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:09,  1.77s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:46,  1.69s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:00,  1.75s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:22,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:28,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:32,  1.90s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:28,  1.89s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:27,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:25,  1.90s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:32,  1.93s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:30,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:26,  1.93s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:28,  1.94s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<08:24,  1.93s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:21,  1.93s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:17,  1.93s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:13,  1.92s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:09,  1.91s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:09,  1.92s/it]predicting train subjects:  11%|█         | 31/285 [00:57<07:58,  1.88s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:52,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:43,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<07:40,  1.84s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:40,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:36,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:33,  1.84s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:32,  1.85s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:29,  1.85s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:29,  1.86s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:18,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:01,  1.76s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<06:39,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<06:24,  1.62s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<06:18,  1.60s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<06:11,  1.58s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<06:06,  1.57s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:04,  1.56s/it]predicting train subjects:  19%|█▊        | 53/285 [01:35<06:02,  1.56s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<05:55,  1.54s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<05:54,  1.54s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<05:54,  1.55s/it]predicting train subjects:  20%|██        | 57/285 [01:41<05:55,  1.56s/it]predicting train subjects:  20%|██        | 58/285 [01:42<05:53,  1.56s/it]predicting train subjects:  21%|██        | 59/285 [01:44<05:50,  1.55s/it]predicting train subjects:  21%|██        | 60/285 [01:46<05:49,  1.55s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<05:47,  1.55s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<05:45,  1.55s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<05:47,  1.56s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<05:50,  1.59s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:08,  1.68s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:10,  1.69s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:04,  1.67s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<05:58,  1.65s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<05:56,  1.65s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<05:56,  1.66s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<05:49,  1.63s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<05:46,  1.63s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<05:49,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<05:46,  1.64s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<05:40,  1.62s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<05:37,  1.61s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:41,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:45,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:48,  1.69s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:35,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:35,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:47,  1.74s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:55,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:35<06:01,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<06:01,  1.86s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<06:01,  1.86s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:59,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:54,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:51,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:53,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:51,  1.87s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:49,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:46,  1.86s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:42,  1.85s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:39,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:32,  1.83s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:29,  1.82s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:23,  1.80s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:15,  1.77s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<05:12,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:09,  1.76s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:03,  1.76s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:01,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:00,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:22<04:58,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:23<04:56,  1.75s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:54,  1.76s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:53,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:51,  1.76s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:50,  1.76s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:43,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:29,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:15,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:14,  1.58s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:15,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:15,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:45<04:11,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<04:11,  1.62s/it]predicting train subjects:  46%|████▌     | 131/285 [03:48<04:07,  1.61s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<04:06,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [03:51<04:05,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [03:53<04:07,  1.64s/it]predicting train subjects:  47%|████▋     | 135/285 [03:54<04:04,  1.63s/it]predicting train subjects:  48%|████▊     | 136/285 [03:56<03:59,  1.61s/it]predicting train subjects:  48%|████▊     | 137/285 [03:57<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [03:59<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:01<03:51,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:02<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:04<03:48,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:05<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [04:07<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:08<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:09<03:22,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:11<03:18,  1.43s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:12<03:16,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:14<03:13,  1.41s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:15<03:11,  1.41s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:17<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:18<03:11,  1.43s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:19<03:09,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:21<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:07,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:24<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:04,  1.43s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:27<03:02,  1.43s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:00,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:31<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<02:56,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:34<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<02:53,  1.42s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<02:50,  1.41s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<02:45,  1.38s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<02:46,  1.40s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<02:43,  1.39s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:43<02:42,  1.40s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:42,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:36,  1.39s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:35,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:50<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<02:35,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:34,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:59<02:29,  1.42s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:00<02:26,  1.41s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:02<02:24,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:03<02:23,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:05<02:21,  1.40s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:06<02:19,  1.40s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:07<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:09<02:15,  1.38s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:11,  1.36s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:10,  1.36s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:08,  1.35s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:05,  1.34s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:15<02:04,  1.34s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:03,  1.34s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:18<02:02,  1.34s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:19<02:00,  1.34s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:21<02:07,  1.43s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:23<02:11,  1.50s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:24<02:13,  1.53s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:26<02:12,  1.55s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:14,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:29<02:15,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:31<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<02:13,  1.65s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:36<02:12,  1.66s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:38<02:11,  1.67s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:41<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:05,  1.65s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:44<02:03,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:46<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:47<01:58,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:49<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:51<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:52<01:48,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:54<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:45,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:57<01:44,  1.56s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:42,  1.55s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:39,  1.54s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:34,  1.50s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:06<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:28,  1.51s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:10<01:25,  1.48s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:24,  1.48s/it]predicting train subjects:  80%|████████  | 229/285 [06:13<01:22,  1.47s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:21,  1.49s/it]predicting train subjects:  81%|████████  | 231/285 [06:16<01:20,  1.49s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:25,  1.62s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:28,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:22<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:24<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:26<01:30,  1.84s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:28<01:29,  1.85s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:29<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:31<01:25,  1.87s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:33<01:23,  1.86s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:35<01:22,  1.87s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:37<01:20,  1.87s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:39<01:19,  1.89s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:41<01:17,  1.88s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<01:15,  1.89s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:44<01:12,  1.85s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:46<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:48<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:50<01:05,  1.83s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:51<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:53<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:54<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:46,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:44,  1.43s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:58<00:42,  1.43s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:59<00:41,  1.43s/it]predicting train subjects:  90%|█████████ | 257/285 [07:01<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [07:02<00:38,  1.42s/it]predicting train subjects:  91%|█████████ | 259/285 [07:04<00:37,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:05<00:35,  1.44s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:07<00:33,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:08<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:09<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:11<00:29,  1.42s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:12<00:28,  1.41s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:14<00:26,  1.42s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:15<00:25,  1.42s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:17<00:26,  1.54s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:19<00:25,  1.62s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:21<00:25,  1.70s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:22<00:24,  1.77s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:24<00:23,  1.81s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:26<00:21,  1.83s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:28<00:20,  1.86s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:30<00:18,  1.86s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:32<00:17,  1.89s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:34<00:15,  1.89s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:36<00:13,  1.88s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:38<00:11,  1.89s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:09,  1.88s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:41<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:43<00:05,  1.86s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.91s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:57,  1.47s/it]Loading train:   1%|          | 2/285 [00:03<07:03,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<06:58,  1.48s/it]Loading train:   1%|▏         | 4/285 [00:06<07:18,  1.56s/it]Loading train:   2%|▏         | 5/285 [00:07<07:06,  1.52s/it]Loading train:   2%|▏         | 6/285 [00:09<07:27,  1.61s/it]Loading train:   2%|▏         | 7/285 [00:11<07:56,  1.71s/it]Loading train:   3%|▎         | 8/285 [00:13<08:15,  1.79s/it]Loading train:   3%|▎         | 9/285 [00:14<07:53,  1.71s/it]Loading train:   4%|▎         | 10/285 [00:16<07:20,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<06:58,  1.53s/it]Loading train:   4%|▍         | 12/285 [00:18<06:23,  1.41s/it]Loading train:   5%|▍         | 13/285 [00:20<06:18,  1.39s/it]Loading train:   5%|▍         | 14/285 [00:21<06:05,  1.35s/it]Loading train:   5%|▌         | 15/285 [00:22<05:50,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:23<05:48,  1.29s/it]Loading train:   6%|▌         | 17/285 [00:25<05:45,  1.29s/it]Loading train:   6%|▋         | 18/285 [00:26<05:40,  1.28s/it]Loading train:   7%|▋         | 19/285 [00:27<05:37,  1.27s/it]Loading train:   7%|▋         | 20/285 [00:28<05:32,  1.25s/it]Loading train:   7%|▋         | 21/285 [00:30<05:39,  1.29s/it]Loading train:   8%|▊         | 22/285 [00:31<05:40,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:32<05:26,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:34<05:44,  1.32s/it]Loading train:   9%|▉         | 25/285 [00:35<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:36<05:31,  1.28s/it]Loading train:   9%|▉         | 27/285 [00:38<05:42,  1.33s/it]Loading train:  10%|▉         | 28/285 [00:39<05:39,  1.32s/it]Loading train:  10%|█         | 29/285 [00:40<05:22,  1.26s/it]Loading train:  11%|█         | 30/285 [00:41<05:13,  1.23s/it]Loading train:  11%|█         | 31/285 [00:42<05:05,  1.20s/it]Loading train:  11%|█         | 32/285 [00:43<05:00,  1.19s/it]Loading train:  12%|█▏        | 33/285 [00:44<04:52,  1.16s/it]Loading train:  12%|█▏        | 34/285 [00:46<04:47,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:47<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:48<04:34,  1.10s/it]Loading train:  13%|█▎        | 37/285 [00:49<04:31,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:50<04:31,  1.10s/it]Loading train:  14%|█▎        | 39/285 [00:51<04:40,  1.14s/it]Loading train:  14%|█▍        | 40/285 [00:52<04:26,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:53<04:37,  1.14s/it]Loading train:  15%|█▍        | 42/285 [00:54<04:31,  1.12s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:32,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:57<04:21,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:58<04:26,  1.11s/it]Loading train:  16%|█▌        | 46/285 [00:59<04:17,  1.08s/it]Loading train:  16%|█▋        | 47/285 [01:00<04:10,  1.05s/it]Loading train:  17%|█▋        | 48/285 [01:01<04:07,  1.04s/it]Loading train:  17%|█▋        | 49/285 [01:02<03:56,  1.00s/it]Loading train:  18%|█▊        | 50/285 [01:03<04:00,  1.02s/it]Loading train:  18%|█▊        | 51/285 [01:04<03:52,  1.01it/s]Loading train:  18%|█▊        | 52/285 [01:05<03:57,  1.02s/it]Loading train:  19%|█▊        | 53/285 [01:06<03:55,  1.02s/it]Loading train:  19%|█▉        | 54/285 [01:07<04:07,  1.07s/it]Loading train:  19%|█▉        | 55/285 [01:08<03:59,  1.04s/it]Loading train:  20%|█▉        | 56/285 [01:09<03:59,  1.04s/it]Loading train:  20%|██        | 57/285 [01:10<03:52,  1.02s/it]Loading train:  20%|██        | 58/285 [01:11<03:50,  1.01s/it]Loading train:  21%|██        | 59/285 [01:12<03:47,  1.01s/it]Loading train:  21%|██        | 60/285 [01:13<03:58,  1.06s/it]Loading train:  21%|██▏       | 61/285 [01:14<04:04,  1.09s/it]Loading train:  22%|██▏       | 62/285 [01:15<03:55,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:16<03:55,  1.06s/it]Loading train:  22%|██▏       | 64/285 [01:18<04:30,  1.22s/it]Loading train:  23%|██▎       | 65/285 [01:20<05:15,  1.43s/it]Loading train:  23%|██▎       | 66/285 [01:21<05:23,  1.48s/it]Loading train:  24%|██▎       | 67/285 [01:23<05:21,  1.48s/it]Loading train:  24%|██▍       | 68/285 [01:24<04:49,  1.33s/it]Loading train:  24%|██▍       | 69/285 [01:25<04:36,  1.28s/it]Loading train:  25%|██▍       | 70/285 [01:26<04:27,  1.25s/it]Loading train:  25%|██▍       | 71/285 [01:27<04:25,  1.24s/it]Loading train:  25%|██▌       | 72/285 [01:28<04:11,  1.18s/it]Loading train:  26%|██▌       | 73/285 [01:30<04:10,  1.18s/it]Loading train:  26%|██▌       | 74/285 [01:31<04:01,  1.14s/it]Loading train:  26%|██▋       | 75/285 [01:32<03:51,  1.10s/it]Loading train:  27%|██▋       | 76/285 [01:33<03:49,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:34<03:47,  1.09s/it]Loading train:  27%|██▋       | 78/285 [01:35<03:41,  1.07s/it]Loading train:  28%|██▊       | 79/285 [01:36<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:37<03:39,  1.07s/it]Loading train:  28%|██▊       | 81/285 [01:38<03:40,  1.08s/it]Loading train:  29%|██▉       | 82/285 [01:39<03:43,  1.10s/it]Loading train:  29%|██▉       | 83/285 [01:40<03:39,  1.09s/it]Loading train:  29%|██▉       | 84/285 [01:41<03:38,  1.09s/it]Loading train:  30%|██▉       | 85/285 [01:43<03:53,  1.17s/it]Loading train:  30%|███       | 86/285 [01:44<03:49,  1.15s/it]Loading train:  31%|███       | 87/285 [01:45<03:40,  1.11s/it]Loading train:  31%|███       | 88/285 [01:46<03:49,  1.16s/it]Loading train:  31%|███       | 89/285 [01:47<03:41,  1.13s/it]Loading train:  32%|███▏      | 90/285 [01:48<03:41,  1.14s/it]Loading train:  32%|███▏      | 91/285 [01:50<03:43,  1.15s/it]Loading train:  32%|███▏      | 92/285 [01:51<03:43,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:52<03:41,  1.16s/it]Loading train:  33%|███▎      | 94/285 [01:53<03:37,  1.14s/it]Loading train:  33%|███▎      | 95/285 [01:54<03:43,  1.18s/it]Loading train:  34%|███▎      | 96/285 [01:55<03:32,  1.13s/it]Loading train:  34%|███▍      | 97/285 [01:57<03:35,  1.15s/it]Loading train:  34%|███▍      | 98/285 [01:58<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:59<03:32,  1.14s/it]Loading train:  35%|███▌      | 100/285 [02:00<03:29,  1.14s/it]Loading train:  35%|███▌      | 101/285 [02:01<03:33,  1.16s/it]Loading train:  36%|███▌      | 102/285 [02:02<03:35,  1.18s/it]Loading train:  36%|███▌      | 103/285 [02:04<03:41,  1.22s/it]Loading train:  36%|███▋      | 104/285 [02:05<03:37,  1.20s/it]Loading train:  37%|███▋      | 105/285 [02:06<03:26,  1.14s/it]Loading train:  37%|███▋      | 106/285 [02:07<03:27,  1.16s/it]Loading train:  38%|███▊      | 107/285 [02:08<03:27,  1.17s/it]Loading train:  38%|███▊      | 108/285 [02:09<03:29,  1.18s/it]Loading train:  38%|███▊      | 109/285 [02:10<03:21,  1.15s/it]Loading train:  39%|███▊      | 110/285 [02:12<03:21,  1.15s/it]Loading train:  39%|███▉      | 111/285 [02:13<03:21,  1.16s/it]Loading train:  39%|███▉      | 112/285 [02:14<03:20,  1.16s/it]Loading train:  40%|███▉      | 113/285 [02:15<03:13,  1.12s/it]Loading train:  40%|████      | 114/285 [02:16<03:12,  1.13s/it]Loading train:  40%|████      | 115/285 [02:17<03:08,  1.11s/it]Loading train:  41%|████      | 116/285 [02:18<03:15,  1.16s/it]Loading train:  41%|████      | 117/285 [02:20<03:10,  1.14s/it]Loading train:  41%|████▏     | 118/285 [02:21<03:13,  1.16s/it]Loading train:  42%|████▏     | 119/285 [02:22<03:17,  1.19s/it]Loading train:  42%|████▏     | 120/285 [02:23<03:15,  1.19s/it]Loading train:  42%|████▏     | 121/285 [02:25<03:34,  1.31s/it]Loading train:  43%|████▎     | 122/285 [02:26<03:36,  1.33s/it]Loading train:  43%|████▎     | 123/285 [02:28<03:37,  1.34s/it]Loading train:  44%|████▎     | 124/285 [02:28<03:13,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:29<02:57,  1.11s/it]Loading train:  44%|████▍     | 126/285 [02:30<02:49,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:31<02:40,  1.01s/it]Loading train:  45%|████▍     | 128/285 [02:32<02:41,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:33<02:44,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:34<02:35,  1.00s/it]Loading train:  46%|████▌     | 131/285 [02:35<02:32,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:36<02:34,  1.01s/it]Loading train:  47%|████▋     | 133/285 [02:37<02:39,  1.05s/it]Loading train:  47%|████▋     | 134/285 [02:38<02:31,  1.01s/it]Loading train:  47%|████▋     | 135/285 [02:39<02:35,  1.04s/it]Loading train:  48%|████▊     | 136/285 [02:40<02:34,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:42<02:35,  1.05s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:28,  1.01s/it]Loading train:  49%|████▉     | 139/285 [02:43<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:44<02:27,  1.01s/it]Loading train:  49%|████▉     | 141/285 [02:45<02:22,  1.01it/s]Loading train:  50%|████▉     | 142/285 [02:46<02:18,  1.03it/s]Loading train:  50%|█████     | 143/285 [02:47<02:17,  1.04it/s]Loading train:  51%|█████     | 144/285 [02:48<02:14,  1.05it/s]Loading train:  51%|█████     | 145/285 [02:49<02:19,  1.00it/s]Loading train:  51%|█████     | 146/285 [02:50<02:20,  1.01s/it]Loading train:  52%|█████▏    | 147/285 [02:51<02:17,  1.01it/s]Loading train:  52%|█████▏    | 148/285 [02:52<02:19,  1.02s/it]Loading train:  52%|█████▏    | 149/285 [02:53<02:15,  1.00it/s]Loading train:  53%|█████▎    | 150/285 [02:54<02:12,  1.02it/s]Loading train:  53%|█████▎    | 151/285 [02:55<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:56<02:11,  1.01it/s]Loading train:  54%|█████▎    | 153/285 [02:57<02:09,  1.02it/s]Loading train:  54%|█████▍    | 154/285 [02:58<02:09,  1.01it/s]Loading train:  54%|█████▍    | 155/285 [02:59<02:04,  1.05it/s]Loading train:  55%|█████▍    | 156/285 [03:00<02:09,  1.01s/it]Loading train:  55%|█████▌    | 157/285 [03:01<02:10,  1.02s/it]Loading train:  55%|█████▌    | 158/285 [03:02<02:05,  1.01it/s]Loading train:  56%|█████▌    | 159/285 [03:03<02:07,  1.01s/it]Loading train:  56%|█████▌    | 160/285 [03:04<02:05,  1.00s/it]Loading train:  56%|█████▋    | 161/285 [03:05<01:57,  1.06it/s]Loading train:  57%|█████▋    | 162/285 [03:06<01:54,  1.07it/s]Loading train:  57%|█████▋    | 163/285 [03:07<01:49,  1.12it/s]Loading train:  58%|█████▊    | 164/285 [03:08<01:46,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [03:09<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [03:10<01:50,  1.07it/s]Loading train:  59%|█████▊    | 167/285 [03:10<01:47,  1.09it/s]Loading train:  59%|█████▉    | 168/285 [03:12<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [03:13<01:52,  1.03it/s]Loading train:  60%|█████▉    | 170/285 [03:14<01:51,  1.03it/s]Loading train:  60%|██████    | 171/285 [03:14<01:43,  1.10it/s]Loading train:  60%|██████    | 172/285 [03:15<01:45,  1.07it/s]Loading train:  61%|██████    | 173/285 [03:16<01:46,  1.05it/s]Loading train:  61%|██████    | 174/285 [03:17<01:48,  1.02it/s]Loading train:  61%|██████▏   | 175/285 [03:18<01:49,  1.01it/s]Loading train:  62%|██████▏   | 176/285 [03:19<01:47,  1.01it/s]Loading train:  62%|██████▏   | 177/285 [03:20<01:48,  1.00s/it]Loading train:  62%|██████▏   | 178/285 [03:21<01:45,  1.01it/s]Loading train:  63%|██████▎   | 179/285 [03:22<01:46,  1.00s/it]Loading train:  63%|██████▎   | 180/285 [03:23<01:41,  1.04it/s]Loading train:  64%|██████▎   | 181/285 [03:24<01:43,  1.01it/s]Loading train:  64%|██████▍   | 182/285 [03:25<01:37,  1.05it/s]Loading train:  64%|██████▍   | 183/285 [03:26<01:43,  1.02s/it]Loading train:  65%|██████▍   | 184/285 [03:27<01:42,  1.01s/it]Loading train:  65%|██████▍   | 185/285 [03:28<01:41,  1.02s/it]Loading train:  65%|██████▌   | 186/285 [03:29<01:37,  1.02it/s]Loading train:  66%|██████▌   | 187/285 [03:30<01:32,  1.05it/s]Loading train:  66%|██████▌   | 188/285 [03:31<01:34,  1.03it/s]Loading train:  66%|██████▋   | 189/285 [03:32<01:28,  1.08it/s]Loading train:  67%|██████▋   | 190/285 [03:33<01:30,  1.05it/s]Loading train:  67%|██████▋   | 191/285 [03:34<01:27,  1.07it/s]Loading train:  67%|██████▋   | 192/285 [03:35<01:31,  1.01it/s]Loading train:  68%|██████▊   | 193/285 [03:36<01:27,  1.06it/s]Loading train:  68%|██████▊   | 194/285 [03:37<01:28,  1.03it/s]Loading train:  68%|██████▊   | 195/285 [03:38<01:25,  1.05it/s]Loading train:  69%|██████▉   | 196/285 [03:39<01:30,  1.02s/it]Loading train:  69%|██████▉   | 197/285 [03:40<01:36,  1.09s/it]Loading train:  69%|██████▉   | 198/285 [03:41<01:37,  1.12s/it]Loading train:  70%|██████▉   | 199/285 [03:42<01:34,  1.10s/it]Loading train:  70%|███████   | 200/285 [03:43<01:30,  1.06s/it]Loading train:  71%|███████   | 201/285 [03:44<01:30,  1.07s/it]Loading train:  71%|███████   | 202/285 [03:46<01:34,  1.14s/it]Loading train:  71%|███████   | 203/285 [03:47<01:30,  1.10s/it]Loading train:  72%|███████▏  | 204/285 [03:48<01:26,  1.06s/it]Loading train:  72%|███████▏  | 205/285 [03:49<01:23,  1.04s/it]Loading train:  72%|███████▏  | 206/285 [03:50<01:21,  1.03s/it]Loading train:  73%|███████▎  | 207/285 [03:51<01:20,  1.04s/it]Loading train:  73%|███████▎  | 208/285 [03:52<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [03:53<01:19,  1.04s/it]Loading train:  74%|███████▎  | 210/285 [03:54<01:22,  1.10s/it]Loading train:  74%|███████▍  | 211/285 [03:55<01:20,  1.08s/it]Loading train:  74%|███████▍  | 212/285 [03:56<01:16,  1.05s/it]Loading train:  75%|███████▍  | 213/285 [03:57<01:15,  1.05s/it]Loading train:  75%|███████▌  | 214/285 [03:58<01:12,  1.03s/it]Loading train:  75%|███████▌  | 215/285 [03:59<01:13,  1.04s/it]Loading train:  76%|███████▌  | 216/285 [04:00<01:10,  1.02s/it]Loading train:  76%|███████▌  | 217/285 [04:01<01:05,  1.04it/s]Loading train:  76%|███████▋  | 218/285 [04:02<01:08,  1.02s/it]Loading train:  77%|███████▋  | 219/285 [04:03<01:04,  1.03it/s]Loading train:  77%|███████▋  | 220/285 [04:04<01:04,  1.02it/s]Loading train:  78%|███████▊  | 221/285 [04:05<01:00,  1.05it/s]Loading train:  78%|███████▊  | 222/285 [04:06<01:01,  1.03it/s]Loading train:  78%|███████▊  | 223/285 [04:07<01:00,  1.02it/s]Loading train:  79%|███████▊  | 224/285 [04:08<00:57,  1.07it/s]Loading train:  79%|███████▉  | 225/285 [04:09<00:59,  1.01it/s]Loading train:  79%|███████▉  | 226/285 [04:10<00:56,  1.04it/s]Loading train:  80%|███████▉  | 227/285 [04:11<00:55,  1.05it/s]Loading train:  80%|████████  | 228/285 [04:12<00:54,  1.05it/s]Loading train:  80%|████████  | 229/285 [04:13<00:53,  1.06it/s]Loading train:  81%|████████  | 230/285 [04:14<00:51,  1.06it/s]Loading train:  81%|████████  | 231/285 [04:14<00:49,  1.10it/s]Loading train:  81%|████████▏ | 232/285 [04:16<00:52,  1.02it/s]Loading train:  82%|████████▏ | 233/285 [04:17<00:54,  1.06s/it]Loading train:  82%|████████▏ | 234/285 [04:18<00:55,  1.08s/it]Loading train:  82%|████████▏ | 235/285 [04:19<00:55,  1.11s/it]Loading train:  83%|████████▎ | 236/285 [04:20<00:53,  1.09s/it]Loading train:  83%|████████▎ | 237/285 [04:21<00:54,  1.13s/it]Loading train:  84%|████████▎ | 238/285 [04:23<00:53,  1.13s/it]Loading train:  84%|████████▍ | 239/285 [04:24<00:51,  1.13s/it]Loading train:  84%|████████▍ | 240/285 [04:25<00:52,  1.17s/it]Loading train:  85%|████████▍ | 241/285 [04:26<00:49,  1.11s/it]Loading train:  85%|████████▍ | 242/285 [04:27<00:48,  1.14s/it]Loading train:  85%|████████▌ | 243/285 [04:28<00:46,  1.10s/it]Loading train:  86%|████████▌ | 244/285 [04:29<00:44,  1.07s/it]Loading train:  86%|████████▌ | 245/285 [04:30<00:41,  1.04s/it]Loading train:  86%|████████▋ | 246/285 [04:31<00:41,  1.05s/it]Loading train:  87%|████████▋ | 247/285 [04:32<00:39,  1.05s/it]Loading train:  87%|████████▋ | 248/285 [04:33<00:39,  1.07s/it]Loading train:  87%|████████▋ | 249/285 [04:34<00:39,  1.09s/it]Loading train:  88%|████████▊ | 250/285 [04:35<00:37,  1.07s/it]Loading train:  88%|████████▊ | 251/285 [04:36<00:34,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:37<00:32,  1.02it/s]Loading train:  89%|████████▉ | 253/285 [04:38<00:30,  1.06it/s]Loading train:  89%|████████▉ | 254/285 [04:39<00:30,  1.01it/s]Loading train:  89%|████████▉ | 255/285 [04:40<00:30,  1.00s/it]Loading train:  90%|████████▉ | 256/285 [04:41<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [04:42<00:26,  1.04it/s]Loading train:  91%|█████████ | 258/285 [04:43<00:26,  1.02it/s]Loading train:  91%|█████████ | 259/285 [04:44<00:25,  1.01it/s]Loading train:  91%|█████████ | 260/285 [04:45<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [04:46<00:22,  1.05it/s]Loading train:  92%|█████████▏| 262/285 [04:47<00:21,  1.08it/s]Loading train:  92%|█████████▏| 263/285 [04:48<00:19,  1.11it/s]Loading train:  93%|█████████▎| 264/285 [04:49<00:19,  1.07it/s]Loading train:  93%|█████████▎| 265/285 [04:50<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:51<00:17,  1.08it/s]Loading train:  94%|█████████▎| 267/285 [04:52<00:16,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [04:53<00:17,  1.00s/it]Loading train:  94%|█████████▍| 269/285 [04:54<00:17,  1.07s/it]Loading train:  95%|█████████▍| 270/285 [04:55<00:15,  1.06s/it]Loading train:  95%|█████████▌| 271/285 [04:56<00:15,  1.08s/it]Loading train:  95%|█████████▌| 272/285 [04:57<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [04:58<00:13,  1.13s/it]Loading train:  96%|█████████▌| 274/285 [05:00<00:13,  1.20s/it]Loading train:  96%|█████████▋| 275/285 [05:01<00:11,  1.18s/it]Loading train:  97%|█████████▋| 276/285 [05:02<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:03<00:09,  1.20s/it]Loading train:  98%|█████████▊| 278/285 [05:04<00:08,  1.19s/it]Loading train:  98%|█████████▊| 279/285 [05:06<00:06,  1.15s/it]Loading train:  98%|█████████▊| 280/285 [05:07<00:05,  1.16s/it]Loading train:  99%|█████████▊| 281/285 [05:08<00:04,  1.18s/it]Loading train:  99%|█████████▉| 282/285 [05:09<00:03,  1.15s/it]Loading train:  99%|█████████▉| 283/285 [05:10<00:02,  1.15s/it]Loading train: 100%|█████████▉| 284/285 [05:11<00:01,  1.14s/it]Loading train: 100%|██████████| 285/285 [05:12<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:12, 21.92it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:09, 28.58it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:06, 38.71it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:04, 51.53it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:03, 67.32it/s]concatenating: train:  38%|███▊      | 108/285 [00:00<00:02, 86.11it/s]concatenating: train:  47%|████▋     | 133/285 [00:00<00:01, 107.12it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 128.21it/s]concatenating: train:  64%|██████▎   | 181/285 [00:00<00:00, 147.68it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 169.49it/s]concatenating: train:  82%|████████▏ | 235/285 [00:01<00:00, 190.59it/s]concatenating: train:  92%|█████████▏| 262/285 [00:01<00:00, 208.36it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 205.35it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.81s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.69s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 33.26it/s]
Epoch 00052: val_mDice did not improve from 0.55916
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [5993.830984933035, 4329.16130719866, 3947.415329706101, 3690.979073660714, 3446.94979422433, 3306.3644670758927, 3144.492716471354, 3085.170892624628, 3044.4564906529017, 2863.4117373511904, 2838.6495419456846, 2876.069516136533, 2759.618611653646, 2737.3917875744046, 2848.108689081101, 2781.614920479911, 2812.223347981771, 2680.631103515625, 2713.414800734747, 2715.371820359003, 2771.0272681826636, 2596.942563011533, 2627.3536493210568, 2727.84219796317, 2722.7857113792784, 2761.402169363839, 2882.3060491652714, 2744.7891918364026, 2749.602106003534, 2755.00778343564, 2719.9766613188244, 3133.97975449335, 2849.682091122582, 2807.2220509847007, 2708.6054019019716, 2757.353294735863, 2765.9632771809897, 2709.277550106957, 2827.922884986514, 2827.06857081822, 2747.8659232003347, 3022.2417740594774, 2974.925559634254, 2637.6156630743117, 2702.894971575056, 2814.798780168806, 2731.0482468377977, 2682.3808085123696, 2646.958743140811, 2842.8943713960193, 3035.3109690348306, 3063.280124482654], 'val_acc': [0.9008631223724002, 0.9126213164556594, 0.9197183819044203, 0.9262614562397912, 0.9268315207390558, 0.9295489646139599, 0.9282646803628831, 0.9341071304820833, 0.9360256592432658, 0.9356364692960467, 0.9344574042728969, 0.9351075830913725, 0.941689548038301, 0.9401167404083979, 0.9327449741817656, 0.9437774675233024, 0.9431387384732565, 0.9407852490743002, 0.9430448611577352, 0.9427426542554583, 0.94572343145098, 0.9446726356233869, 0.9446520266078767, 0.9457784039633614, 0.9467262086414155, 0.9405036653791156, 0.9445466853323436, 0.9459386666615804, 0.9473855296770731, 0.9448030959992182, 0.9464697752680097, 0.9438484680084955, 0.947603029864175, 0.9472619209970746, 0.9465842502457755, 0.9457097280593145, 0.9460118895485288, 0.9443475263459342, 0.9446519982247126, 0.9456410351253691, 0.9479418510482425, 0.9461469934100196, 0.9470123733792987, 0.9464858145940871, 0.9483493736812046, 0.9495650075730824, 0.9470993791307721, 0.9468727140199571, 0.9473122727303278, 0.94695740654355, 0.9473992586135864, 0.9471703200113206], 'val_mDice': [0.30137479518141064, 0.3955573056425367, 0.4299550331419423, 0.450130191942056, 0.4729017095551604, 0.484061197865577, 0.5026001011331876, 0.5068687205868108, 0.51033791970639, 0.5314359301257701, 0.5356153725158601, 0.5295079361115184, 0.5423670333056223, 0.5440674472068038, 0.5335816916610513, 0.5389807788389069, 0.5375071735609145, 0.5506857250417981, 0.5484779785786357, 0.5469459132069633, 0.5409712009131908, 0.5591592072021394, 0.5542407677996726, 0.5474973212750185, 0.5445363904748645, 0.5425938110621202, 0.5257448160222599, 0.5392128264620191, 0.5413822247868493, 0.540124040274393, 0.5456062596113909, 0.4963551514915058, 0.5272786074451038, 0.53156307552542, 0.5481837604727063, 0.5409193063775698, 0.5383221539003509, 0.5453975220166501, 0.5336435364470595, 0.5310219565317744, 0.5444364505154746, 0.5098663914416518, 0.5177848438421885, 0.5518830360046455, 0.5465779190971738, 0.5358134117864427, 0.5416393258741924, 0.5487412969980922, 0.5527610115352131, 0.5299375266546295, 0.51033906070959, 0.5094733695898738], 'loss': [11264.625524805855, 5331.25672584594, 4178.3702727936125, 3658.207496703372, 3326.7688458959146, 3094.2429188863834, 2895.8515324236823, 2748.313809802451, 2623.9219999885154, 2525.5970751981367, 2432.000737622866, 2372.7466236862438, 2285.2992903306945, 2246.663625381437, 2184.0265472217957, 2122.653994746858, 2078.3886146641016, 2044.7928326299523, 1988.971124711192, 1961.6187927469666, 1940.2153073206605, 1900.9406615904998, 1884.8913746251521, 1852.6670983959673, 1820.8458296667525, 1803.3342805961342, 1782.331713048208, 1773.288662400254, 1732.7379713792068, 1724.9203646181636, 1701.1106695289532, 1678.1400392413575, 1662.9708067918068, 1647.9581037837231, 1634.7127671897215, 1611.5810577233724, 1604.4232958824346, 1586.6724663832433, 1570.7924000063636, 1554.9701851204409, 1541.496697300267, 1528.1452639542817, 1523.3023638573598, 1496.0196016163457, 1490.561834273183, 1480.0951975934051, 1460.0270223946661, 1454.17460825008, 1450.117309005499, 1439.297861376134, 1424.9269515435224, 1423.5379772815077], 'acc': [0.8499416767206407, 0.873239311772963, 0.8898466583021762, 0.9008745724281089, 0.9079885139776972, 0.9125753314319961, 0.9164061689505532, 0.9194001351129992, 0.9218022872171169, 0.9237530081401286, 0.9255338347047791, 0.9269136922631117, 0.928568185099706, 0.929504305026608, 0.9307844806480481, 0.9317982485580701, 0.9328133800550534, 0.9333882290709793, 0.9344678976321142, 0.9351294761750196, 0.9356190480201351, 0.9364768022031069, 0.9366802030821308, 0.9373985067346042, 0.9378706805389327, 0.9383399341638226, 0.9387411552402172, 0.9389085446981559, 0.9397367074904655, 0.9399990629938404, 0.9404603136580919, 0.9409624772056211, 0.9411709015369875, 0.9415931910109792, 0.9416803852634346, 0.9422260137543826, 0.9422174833495194, 0.9427085168586431, 0.9431988614842408, 0.9433392558870964, 0.943693625862621, 0.9439685544182576, 0.9439191085675881, 0.9445195124975307, 0.9447497015562916, 0.9449105133021156, 0.9452707425394752, 0.9452519503682248, 0.945353792459261, 0.9455198894949899, 0.9459259053726337, 0.9458357646719486], 'mDice': [0.19863934248559434, 0.35386299340049726, 0.43517355028779053, 0.4804365441809276, 0.5125149356990231, 0.536436841589926, 0.5574347273288077, 0.5737936200722348, 0.5882177331416805, 0.5999238197803957, 0.6110595907345888, 0.6181416383868862, 0.629302254641518, 0.634185742270126, 0.6422550365923456, 0.6498684641228767, 0.655900988800346, 0.6602719160134746, 0.6675960965208955, 0.6712712608529167, 0.6741603470869048, 0.6795139508783323, 0.6817932131204482, 0.6861496942682672, 0.6905356214550711, 0.693021677145729, 0.6959089513617442, 0.6972136915775767, 0.7028106919873857, 0.7039445317938352, 0.7074257266850101, 0.7105614172830871, 0.7127143429243566, 0.7149254532478116, 0.7168045151502567, 0.7201531830150221, 0.7211004092970495, 0.7237368060693544, 0.7261293847045619, 0.7283800767064209, 0.7303934516487541, 0.7322687237667674, 0.7330038305282225, 0.737032195955015, 0.7379319816741591, 0.7394526509597901, 0.742424763499231, 0.7432419938091508, 0.743805311756693, 0.7454501763804928, 0.7476452267512389, 0.7479301415727114]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 15)   4200        concatenate_6[0][0]              2019-07-07 03:33:42.277855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 03:33:42.277991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 03:33:42.278010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 03:33:42.278023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 03:33:42.278616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 9706.4526 - acc: 0.8845 - mDice: 0.2389 - val_loss: 4470.8405 - val_acc: 0.9200 - val_mDice: 0.3965

Epoch 00001: val_mDice improved from -inf to 0.39647, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 4585.8371 - acc: 0.9133 - mDice: 0.4176 - val_loss: 3111.5789 - val_acc: 0.9375 - val_mDice: 0.5086

Epoch 00002: val_mDice improved from 0.39647 to 0.50857, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 3387.6737 - acc: 0.9265 - mDice: 0.5119 - val_loss: 2686.6688 - val_acc: 0.9440 - val_mDice: 0.5515

Epoch 00003: val_mDice improved from 0.50857 to 0.55151, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 2960.9505 - acc: 0.9323 - mDice: 0.5547 - val_loss: 2508.8673 - val_acc: 0.9464 - val_mDice: 0.5724

Epoch 00004: val_mDice improved from 0.55151 to 0.57242, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 2694.2704 - acc: 0.9359 - mDice: 0.5836 - val_loss: 2482.6959 - val_acc: 0.9472 - val_mDice: 0.5756

Epoch 00005: val_mDice improved from 0.57242 to 0.57564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 2529.4289 - acc: 0.9381 - mDice: 0.6027 - val_loss: 2394.5046 - val_acc: 0.9487 - val_mDice: 0.5872

Epoch 00006: val_mDice improved from 0.57564 to 0.58716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 19s - loss: 2391.4567 - acc: 0.9399 - mDice: 0.6188 - val_loss: 2353.8873 - val_acc: 0.9494 - val_mDice: 0.5918

Epoch 00007: val_mDice improved from 0.58716 to 0.59183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 2284.7785 - acc: 0.9415 - mDice: 0.6318 - val_loss: 2337.4380 - val_acc: 0.9502 - val_mDice: 0.5950

Epoch 00008: val_mDice improved from 0.59183 to 0.59499, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 19s - loss: 2214.2781 - acc: 0.9425 - mDice: 0.6406 - val_loss: 2300.1939 - val_acc: 0.9504 - val_mDice: 0.5994

Epoch 00009: val_mDice improved from 0.59499 to 0.59942, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 2121.2848 - acc: 0.9438 - mDice: 0.6519 - val_loss: 2204.7238 - val_acc: 0.9515 - val_mDice: 0.6117

Epoch 00010: val_mDice improved from 0.59942 to 0.61171, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 2064.2427 - acc: 0.9448 - mDice: 0.6594 - val_loss: 2198.3447 - val_acc: 0.9510 - val_mDice: 0.6123

Epoch 00011: val_mDice improved from 0.61171 to 0.61232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 20s - loss: 2018.2604 - acc: 0.9454 - mDice: 0.6654 - val_loss: 2178.0310 - val_acc: 0.9524 - val_mDice: 0.6150

Epoch 00012: val_mDice improved from 0.61232 to 0.61500, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 1981.6182 - acc: 0.9463 - mDice: 0.6705 - val_loss: 2183.5159 - val_acc: 0.9521 - val_mDice: 0.6142

Epoch 00013: val_mDice did not improve from 0.61500
Epoch 14/300
 - 20s - loss: 1944.0748 - acc: 0.9469 - mDice: 0.6755 - val_loss: 2280.7403 - val_acc: 0.9514 - val_mDice: 0.6023

Epoch 00014: val_mDice did not improve from 0.61500
Epoch 15/300
 - 19s - loss: 1895.2661 - acc: 0.9474 - mDice: 0.6818 - val_loss: 2169.3594 - val_acc: 0.9517 - val_mDice: 0.6168

Epoch 00015: val_mDice improved from 0.61500 to 0.61675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 17s - loss: 1856.3797 - acc: 0.9480 - mDice: 0.6870 - val_loss: 2131.3575 - val_acc: 0.9523 - val_mDice: 0.6215

Epoch 00016: val_mDice improved from 0.61675 to 0.62146, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 18s - loss: 1816.1269 - acc: 0.9488 - mDice: 0.6925 - val_loss: 2194.3211 - val_acc: 0.9526 - val_mDice: 0.6136

Epoch 00017: val_mDice did not improve from 0.62146
Epoch 18/300
 - 16s - loss: 1784.1005 - acc: 0.9491 - mDice: 0.6970 - val_loss: 2292.4356 - val_acc: 0.9508 - val_mDice: 0.6011

Epoch 00018: val_mDice did not improve from 0.62146
Epoch 19/300
 - 14s - loss: 1760.7768 - acc: 0.9495 - mDice: 0.7006 - val_loss: 2208.2289 - val_acc: 0.9520 - val_mDice: 0.6117

Epoch 00019: val_mDice did not improve from 0.62146
Epoch 20/300
 - 14s - loss: 1730.1281 - acc: 0.9499 - mDice: 0.7044 - val_loss: 2182.8448 - val_acc: 0.9515 - val_mDice: 0.6151

Epoch 00020: val_mDice did not improve from 0.62146
Epoch 21/300
 - 14s - loss: 1706.4562 - acc: 0.9503 - mDice: 0.7077 - val_loss: 2161.2344 - val_acc: 0.9528 - val_mDice: 0.6181

Epoch 00021: val_mDice did not improve from 0.62146
Epoch 22/300
 - 14s - loss: 1675.6995 - acc: 0.9508 - mDice: 0.7120 - val_loss: 2301.3879 - val_acc: 0.9518 - val_mDice: 0.6024

Epoch 00022: val_mDice did not improve from 0.62146
Epoch 23/300
 - 14s - loss: 1654.4063 - acc: 0.9510 - mDice: 0.7151 - val_loss: 2182.1011 - val_acc: 0.9517 - val_mDice: 0.6154

Epoch 00023: val_mDice did not improve from 0.62146
Epoch 24/300
 - 13s - loss: 1640.7076 - acc: 0.9514 - mDice: 0.7172 - val_loss: 2223.6154 - val_acc: 0.9519 - val_mDice: 0.6103

Epoch 00024: val_mDice did not improve from 0.62146
Epoch 25/300
 - 14s - loss: 1612.8364 - acc: 0.9518 - mDice: 0.7209 - val_loss: 2221.9975 - val_acc: 0.9530 - val_mDice: 0.6112

Epoch 00025: val_mDice did not improve from 0.62146
Epoch 26/300
 - 14s - loss: 1592.8775 - acc: 0.9520 - mDice: 0.7238 - val_loss: 2124.4960 - val_acc: 0.9515 - val_mDice: 0.6227

Epoch 00026: val_mDice improved from 0.62146 to 0.62268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 14s - loss: 1573.7303 - acc: 0.9522 - mDice: 0.7265 - val_loss: 2159.9355 - val_acc: 0.9533 - val_mDice: 0.6198

Epoch 00027: val_mDice did not improve from 0.62268
Epoch 28/300
 - 14s - loss: 1556.6028 - acc: 0.9526 - mDice: 0.7291 - val_loss: 2128.9725 - val_acc: 0.9528 - val_mDice: 0.6231

Epoch 00028: val_mDice improved from 0.62268 to 0.62308, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 13s - loss: 1539.1012 - acc: 0.9527 - mDice: 0.7314 - val_loss: 2223.1319 - val_acc: 0.9511 - val_mDice: 0.6134

Epoch 00029: val_mDice did not improve from 0.62308
Epoch 30/300
 - 13s - loss: 1516.4767 - acc: 0.9531 - mDice: 0.7348 - val_loss: 2180.8689 - val_acc: 0.9530 - val_mDice: 0.6161

Epoch 00030: val_mDice did not improve from 0.62308
Epoch 31/300
 - 12s - loss: 1509.9486 - acc: 0.9533 - mDice: 0.7360 - val_loss: 2160.7433 - val_acc: 0.9525 - val_mDice: 0.6195

Epoch 00031: val_mDice did not improve from 0.62308
Epoch 32/300
 - 13s - loss: 1494.3638 - acc: 0.9535 - mDice: 0.7380 - val_loss: 2202.7467 - val_acc: 0.9527 - val_mDice: 0.6153

Epoch 00032: val_mDice did not improve from 0.62308
Epoch 33/300
 - 13s - loss: 1473.4219 - acc: 0.9538 - mDice: 0.7411 - val_loss: 2225.9047 - val_acc: 0.9503 - val_mDice: 0.6123

Epoch 00033: val_mDice did not improve from 0.62308
Epoch 34/300
 - 13s - loss: 1469.0580 - acc: 0.9538 - mDice: 0.7419 - val_loss: 2300.6929 - val_acc: 0.9517 - val_mDice: 0.6050

Epoch 00034: val_mDice did not improve from 0.62308
Epoch 35/300
 - 12s - loss: 1450.9583 - acc: 0.9542 - mDice: 0.7446 - val_loss: 2265.1207 - val_acc: 0.9514 - val_mDice: 0.6083

Epoch 00035: val_mDice did not improve from 0.62308
Epoch 36/300
 - 12s - loss: 1439.9300 - acc: 0.9543 - mDice: 0.7460 - val_loss: 2309.9425 - val_acc: 0.9499 - val_mDice: 0.5993

Epoch 00036: val_mDice did not improve from 0.62308
Epoch 37/300
 - 12s - loss: 1424.0380 - acc: 0.9546 - mDice: 0.7485 - val_loss: 2274.1590 - val_acc: 0.9514 - val_mDice: 0.6051

Epoch 00037: val_mDice did not improve from 0.62308
Epoch 38/300
 - 13s - loss: 1418.1006 - acc: 0.9547 - mDice: 0.7494 - val_loss: 2255.0354 - val_acc: 0.9513 - val_mDice: 0.6082

Epoch 00038: val_mDice did not improve from 0.62308
Epoch 39/300
 - 12s - loss: 1392.7484 - acc: 0.9551 - mDice: 0.7532 - val_loss: 2355.4896 - val_acc: 0.9525 - val_mDice: 0.5986

Epoch 00039: val_mDice did not improve from 0.62308
Epoch 40/300
 - 12s - loss: 1384.3404 - acc: 0.9551 - mDice: 0.7546 - val_loss: 2167.3682 - val_acc: 0.9515 - val_mDice: 0.6162

Epoch 00040: val_mDice did not improve from 0.62308
Epoch 41/300
 - 13s - loss: 1372.9974 - acc: 0.9553 - mDice: 0.7562 - val_loss: 2243.1127 - val_acc: 0.9519 - val_mDice: 0.6086

Epoch 00041: val_mDice did not improve from 0.62308
Epoch 42/300
 - 12s - loss: 1365.8185 - acc: 0.9553 - mDice: 0.7573 - val_loss: 2227.3632 - val_acc: 0.9518 - val_mDice: 0.6141

Epoch 00042: val_mDice did not improve from 0.62308
Epoch 43/300
 - 12s - loss: 1356.1167 - acc: 0.9555 - mDice: 0.7588 - val_loss: 2238.1669 - val_acc: 0.9508 - val_mDice: 0.6110

Epoch 00043: val_mDice did not improve from 0.62308
Epoch 44/300
 - 12s - loss: 1342.6165 - acc: 0.9557 - mDice: 0.7608 - val_loss: 2232.5275 - val_acc: 0.9528 - val_mDice: 0.6114

Epoch 00044: val_mDice did not improve from 0.62308
Epoch 45/300
 - 12s - loss: 1344.6595 - acc: 0.9558 - mDice: 0.7605 - val_loss: 2294.3649 - val_acc: 0.9518 - val_mDice: 0.6026

Epoch 00045: val_mDice did not improve from 0.62308
Epoch 46/300
 - 12s - loss: 1333.2178 - acc: 0.9558 - mDice: 0.7621 - val_loss: 2360.4640 - val_acc: 0.9526 - val_mDice: 0.5999

Epoch 00046: val_mDice did not improve from 0.62308
Epoch 47/300
 - 12s - loss: 1312.7447 - acc: 0.9561 - mDice: 0.7653 - val_loss: 2176.7836 - val_acc: 0.9525 - val_mDice: 0.6163

Epoch 00047: val_mDice did not improve from 0.62308
Epoch 48/300
 - 12s - loss: 1307.0546 - acc: 0.9562 - mDice: 0.7663 - val_loss: 2256.0716 - val_acc: 0.9518 - val_mDice: 0.6099

Epoch 00048: val_mDice did not improve from 0.62308
Epoch 49/300
 - 12s - loss: 1294.4787 - acc: 0.9563 - mDice: 0.7681 - val_loss: 2302.3055 - val_acc: 0.9515 - val_mDice: 0.6048

Epoch 00049: val_mDice did not improve from 0.62308
Epoch 50/300
 - 12s - loss: 1289.5595 - acc: 0.9565 - mDice: 0.7689 - val_loss: 2164.1307 - val_acc: 0.9521 - val_mDice: 0.6167

Epoch 00050: val_mDice did not improve from 0.62308
Epoch 51/300
 - 12s - loss: 1289.8500 - acc: 0.9564 - mDice: 0.7690 - val_loss: 2290.2059 - val_acc: 0.9522 - val_mDice: 0.6043

Epoch 00051: val_mDice did not improve from 0.62308
Epoch 52/300
 - 12s - loss: 1278.4520 - acc: 0.9567 - mDice: 0.7707 - val_loss: 2254.4384 - val_acc: 0.9501 - val_mDice: 0.6053

Epoch 00052: val_mDice did not improve from 0.62308
Epoch 53/300
 - 12s - loss: 1268.8915 - acc: 0.9568 - mDice: 0.7722 - val_loss: 2350.9069 - val_acc: 0.9523 - val_mDice: 0.5964

Epoch 00053: val_mDice did not improve from 0.62308
Epoch 54/300
 - 12s - loss: 1265.7194 - acc: 0.9568 - mDice: 0.7726 - val_loss: 2360.4184 - val_acc: 0.9532 - val_mDice: 0.5999

Epoch 00054: val_mDice did not improve from 0.62308
Epoch 55/300
 - 12s - loss: 1258.8677 - acc: 0.9571 - mDice: 0.7737 - val_loss: 2318.7081 - val_acc: 0.9520 - val_mDice: 0.6005

Epoch 00055: val_mDice did not improve from 0.62308
Epoch 56/300
 - 12s - loss: 1251.4762 - acc: 0.9570 - mDice: 0.7748 - val_loss: 2220.4517 - val_acc: 0.9530 - val_mDice: 0.6108

Epoch 00056: val_mDice did not improve from 0.62308
Epoch 57/300
 - 12s - loss: 1239.9491 - acc: 0.9572 - mDice: 0.7766 - val_loss: 2223.5842 - val_acc: 0.9516 - val_mDice: 0.6092

Epoch 00057: val_mDice did not improve from 0.62308
Epoch 58/300
 - 12s - loss: 1246.1213 - acc: 0.9572 - mDice: 0.7757 - val_loss: 2289.0189 - val_acc: 0.9524 - val_mDice: 0.6049

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.19s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:27,  1.57s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:46,  1.65s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:38,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:55,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:50,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:18,  1.79s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:24,  1.82s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:05,  1.76s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:26,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:41,  1.90s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:53,  1.95s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:57,  1.98s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<09:02,  2.00s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<09:06,  2.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:06,  2.03s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:07,  2.04s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:09,  2.06s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:09,  2.07s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<09:02,  2.05s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:53,  2.02s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:48,  2.01s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:43,  2.00s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<08:41,  2.00s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:41,  2.01s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:42,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:46,  2.04s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:28,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:15,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:03,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:00,  1.89s/it]predicting train subjects:  11%|█         | 32/285 [01:01<07:55,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<07:50,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<07:42,  1.84s/it]predicting train subjects:  12%|█▏        | 35/285 [01:06<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:33,  1.83s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<07:36,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:32,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:33,  1.86s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:32,  1.86s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:34,  1.88s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<07:29,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:11,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:28<06:57,  1.75s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<06:35,  1.67s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<06:25,  1.64s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<06:21,  1.63s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<06:22,  1.64s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<06:12,  1.61s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<06:14,  1.63s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<06:09,  1.61s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:06,  1.61s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:05,  1.61s/it]predicting train subjects:  21%|██        | 59/285 [01:48<06:02,  1.60s/it]predicting train subjects:  21%|██        | 60/285 [01:49<05:59,  1.60s/it]predicting train subjects:  21%|██▏       | 61/285 [01:51<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<05:59,  1.61s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<05:56,  1.61s/it]predicting train subjects:  22%|██▏       | 64/285 [01:56<05:58,  1.62s/it]predicting train subjects:  23%|██▎       | 65/285 [01:58<06:09,  1.68s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<06:18,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [02:03<06:12,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:05<06:11,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:06<06:09,  1.72s/it]predicting train subjects:  25%|██▍       | 71/285 [02:08<06:08,  1.72s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:07,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<06:01,  1.71s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:03,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:18<05:54,  1.70s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<05:57,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<05:54,  1.72s/it]predicting train subjects:  28%|██▊       | 80/285 [02:23<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:47,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:30<05:45,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:36<05:55,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:38<05:59,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:40<06:01,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:41<05:58,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:43<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:45<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:47<05:56,  1.86s/it]predicting train subjects:  33%|███▎      | 94/285 [02:49<05:57,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:51<05:57,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [02:53<05:56,  1.89s/it]predicting train subjects:  34%|███▍      | 97/285 [02:55<05:52,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [02:56<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [02:58<05:50,  1.89s/it]predicting train subjects:  35%|███▌      | 100/285 [03:00<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:02<05:40,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [03:04<05:40,  1.86s/it]predicting train subjects:  36%|███▌      | 103/285 [03:06<05:39,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:08<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:28,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:11<05:26,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:13<05:21,  1.81s/it]predicting train subjects:  38%|███▊      | 108/285 [03:15<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:17<05:17,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:18<05:12,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:20<05:09,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:22<05:08,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:24<05:06,  1.78s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:06,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:06,  1.80s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:31<05:00,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:33<04:59,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<04:56,  1.79s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:57,  1.80s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:18,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:13,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:12,  1.59s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<04:12,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:49<04:13,  1.62s/it]predicting train subjects:  45%|████▌     | 129/285 [03:51<04:18,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:52<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [03:54<04:15,  1.66s/it]predicting train subjects:  46%|████▋     | 132/285 [03:55<04:09,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [03:57<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [03:59<04:01,  1.60s/it]predicting train subjects:  47%|████▋     | 135/285 [04:00<03:59,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [04:02<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<03:56,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:05<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:07<03:59,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:08<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:10<03:57,  1.65s/it]predicting train subjects:  50%|████▉     | 142/285 [04:11<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:13<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:16<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:32,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:19<03:28,  1.51s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:22<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:25<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:18,  1.49s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:28<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:19,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:31<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:16,  1.52s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:34<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:36<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:37<03:13,  1.54s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:39<03:10,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:40<03:05,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:43<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:46<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<02:52,  1.45s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<02:50,  1.45s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:50<02:50,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:53<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:45,  1.45s/it]predicting train subjects:  60%|██████    | 172/285 [04:56<02:43,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:57<02:41,  1.44s/it]predicting train subjects:  61%|██████    | 174/285 [04:59<02:40,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:00<02:36,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:02<02:35,  1.43s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:03<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:04<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:06<02:30,  1.42s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:07<02:30,  1.44s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:09<02:31,  1.46s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:10<02:29,  1.45s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:12<02:26,  1.43s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:13<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:15<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:16<02:21,  1.43s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:17<02:19,  1.42s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:19<02:18,  1.43s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:20<02:19,  1.45s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:22<02:18,  1.46s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:23<02:18,  1.47s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:25<02:18,  1.49s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:26<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:28<02:12,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:29<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:31<02:18,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:33<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:35<02:25,  1.67s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:36<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [05:38<02:26,  1.72s/it]predicting train subjects:  71%|███████   | 201/285 [05:40<02:26,  1.74s/it]predicting train subjects:  71%|███████   | 202/285 [05:42<02:24,  1.74s/it]predicting train subjects:  71%|███████   | 203/285 [05:43<02:24,  1.77s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:45<02:23,  1.77s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:47<02:20,  1.75s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<02:20,  1.77s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:50<02:16,  1.75s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:52<02:17,  1.79s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:54<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:56<02:12,  1.77s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:58<02:10,  1.77s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:59<02:11,  1.80s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:01<02:07,  1.77s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:03<02:02,  1.73s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:04<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:06<01:51,  1.61s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:07<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:09<01:45,  1.57s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:10<01:44,  1.58s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:12<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:13<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:15<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:17<01:36,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:18<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:20<01:33,  1.56s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:21<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:23<01:27,  1.52s/it]predicting train subjects:  80%|████████  | 228/285 [06:24<01:26,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:27<01:24,  1.53s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:31<01:27,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:33<01:30,  1.74s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:35<01:30,  1.78s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:36<01:30,  1.81s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:38<01:30,  1.85s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:40<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:42<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:44<01:26,  1.88s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:46<01:25,  1.89s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:48<01:23,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:50<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:52<01:20,  1.92s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:54<01:18,  1.90s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:56<01:16,  1.91s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:57<01:14,  1.91s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:59<01:12,  1.92s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:01<01:10,  1.91s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:03<01:08,  1.89s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:05<01:01,  1.77s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:06<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:08<00:53,  1.63s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:09<00:50,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:11<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:12<00:46,  1.54s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:14<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:15<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [07:17<00:40,  1.51s/it]predicting train subjects:  91%|█████████ | 259/285 [07:18<00:38,  1.48s/it]predicting train subjects:  91%|█████████ | 260/285 [07:20<00:37,  1.50s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:21<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:23<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:24<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:26<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:27<00:30,  1.51s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:29<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:30<00:27,  1.53s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:32<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:34<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:36<00:26,  1.79s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:38<00:25,  1.84s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:40<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:22,  1.87s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:20,  1.87s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:46<00:19,  1.91s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:48<00:17,  1.90s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:50<00:15,  1.93s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:51<00:13,  1.94s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:53<00:11,  1.93s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:55<00:09,  1.93s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:57<00:07,  1.92s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:59<00:05,  1.93s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.92s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:03<00:01,  1.94s/it]predicting train subjects: 100%|██████████| 285/285 [08:05<00:00,  1.93s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:59,  1.48s/it]Loading train:   1%|          | 2/285 [00:03<07:12,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<07:02,  1.50s/it]Loading train:   1%|▏         | 4/285 [00:06<07:20,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:07<07:12,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:09<07:28,  1.61s/it]Loading train:   2%|▏         | 7/285 [00:11<07:41,  1.66s/it]Loading train:   3%|▎         | 8/285 [00:12<07:38,  1.66s/it]Loading train:   3%|▎         | 9/285 [00:14<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<06:59,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:17<06:48,  1.49s/it]Loading train:   4%|▍         | 12/285 [00:18<06:35,  1.45s/it]Loading train:   5%|▍         | 13/285 [00:19<06:20,  1.40s/it]Loading train:   5%|▍         | 14/285 [00:21<06:17,  1.39s/it]Loading train:   5%|▌         | 15/285 [00:22<05:57,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:23<05:50,  1.30s/it]Loading train:   6%|▌         | 17/285 [00:25<05:59,  1.34s/it]Loading train:   6%|▋         | 18/285 [00:26<05:58,  1.34s/it]Loading train:   7%|▋         | 19/285 [00:27<05:59,  1.35s/it]Loading train:   7%|▋         | 20/285 [00:29<06:07,  1.39s/it]Loading train:   7%|▋         | 21/285 [00:30<05:56,  1.35s/it]Loading train:   8%|▊         | 22/285 [00:31<05:57,  1.36s/it]Loading train:   8%|▊         | 23/285 [00:33<06:02,  1.38s/it]Loading train:   8%|▊         | 24/285 [00:34<05:52,  1.35s/it]Loading train:   9%|▉         | 25/285 [00:35<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:37<05:57,  1.38s/it]Loading train:   9%|▉         | 27/285 [00:38<05:50,  1.36s/it]Loading train:  10%|▉         | 28/285 [00:40<05:48,  1.36s/it]Loading train:  10%|█         | 29/285 [00:41<05:48,  1.36s/it]Loading train:  11%|█         | 30/285 [00:42<05:50,  1.37s/it]Loading train:  11%|█         | 31/285 [00:43<05:28,  1.29s/it]Loading train:  11%|█         | 32/285 [00:45<05:24,  1.28s/it]Loading train:  12%|█▏        | 33/285 [00:46<05:04,  1.21s/it]Loading train:  12%|█▏        | 34/285 [00:47<05:04,  1.22s/it]Loading train:  12%|█▏        | 35/285 [00:48<05:24,  1.30s/it]Loading train:  13%|█▎        | 36/285 [00:50<05:19,  1.28s/it]Loading train:  13%|█▎        | 37/285 [00:51<05:29,  1.33s/it]Loading train:  13%|█▎        | 38/285 [00:52<05:30,  1.34s/it]Loading train:  14%|█▎        | 39/285 [00:54<05:16,  1.29s/it]Loading train:  14%|█▍        | 40/285 [00:55<05:22,  1.32s/it]Loading train:  14%|█▍        | 41/285 [00:56<05:22,  1.32s/it]Loading train:  15%|█▍        | 42/285 [00:58<05:25,  1.34s/it]Loading train:  15%|█▌        | 43/285 [00:59<05:18,  1.31s/it]Loading train:  15%|█▌        | 44/285 [01:00<05:10,  1.29s/it]Loading train:  16%|█▌        | 45/285 [01:01<05:06,  1.28s/it]Loading train:  16%|█▌        | 46/285 [01:03<04:53,  1.23s/it]Loading train:  16%|█▋        | 47/285 [01:04<04:49,  1.22s/it]Loading train:  17%|█▋        | 48/285 [01:05<04:47,  1.22s/it]Loading train:  17%|█▋        | 49/285 [01:06<04:41,  1.19s/it]Loading train:  18%|█▊        | 50/285 [01:07<04:45,  1.21s/it]Loading train:  18%|█▊        | 51/285 [01:09<04:47,  1.23s/it]Loading train:  18%|█▊        | 52/285 [01:10<04:38,  1.19s/it]Loading train:  19%|█▊        | 53/285 [01:11<04:39,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:12<04:43,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:14<04:45,  1.24s/it]Loading train:  20%|█▉        | 56/285 [01:15<04:39,  1.22s/it]Loading train:  20%|██        | 57/285 [01:16<04:41,  1.23s/it]Loading train:  20%|██        | 58/285 [01:17<04:34,  1.21s/it]Loading train:  21%|██        | 59/285 [01:18<04:31,  1.20s/it]Loading train:  21%|██        | 60/285 [01:20<04:32,  1.21s/it]Loading train:  21%|██▏       | 61/285 [01:21<04:33,  1.22s/it]Loading train:  22%|██▏       | 62/285 [01:22<04:41,  1.26s/it]Loading train:  22%|██▏       | 63/285 [01:23<04:39,  1.26s/it]Loading train:  22%|██▏       | 64/285 [01:25<05:01,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:27<05:17,  1.44s/it]
Epoch 00058: val_mDice did not improve from 0.62308
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [4470.840482061802, 3111.578896975384, 2686.6688402911136, 2508.867319799668, 2482.6958607934707, 2394.504571840084, 2353.8873025052376, 2337.438025106931, 2300.1938803901885, 2204.7237678399965, 2198.344737473813, 2178.0309717615223, 2183.515893691079, 2280.7403066624474, 2169.3593722721716, 2131.3574764315645, 2194.3210517414454, 2292.4355523306563, 2208.2289302548884, 2182.84475656861, 2161.23440500611, 2301.387883532647, 2182.1010933135476, 2223.61541713949, 2221.9974535723636, 2124.495965542074, 2159.935507321491, 2128.9724653020253, 2223.1319300475734, 2180.8689278543993, 2160.7432977260823, 2202.7467279700595, 2225.904723780115, 2300.692886096805, 2265.1206545696577, 2309.9425055647694, 2274.1590091982366, 2255.0354181215084, 2355.4896315249653, 2167.368174973813, 2243.1127043143333, 2227.3631966873254, 2238.166889893942, 2232.5274883248953, 2294.364926130412, 2360.4640063067386, 2176.783589112692, 2256.071639588425, 2302.3055194876047, 2164.130718891847, 2290.205885562151, 2254.4384492842178, 2350.9068733087465, 2360.4183629211766, 2318.708073280377, 2220.4517201684707, 2223.58421351257, 2289.018864296002], 'val_acc': [0.9199985155846153, 0.9375144576227199, 0.9439646631645757, 0.9463901959318023, 0.9472269342598303, 0.9486587117504142, 0.9493983594398925, 0.9501979387672254, 0.9504355428605106, 0.9514912846368119, 0.9510429474894561, 0.9523838002588496, 0.9520821424835887, 0.9514417025630034, 0.9516544741625227, 0.9522970178939777, 0.9525904119347727, 0.950840468513233, 0.951952008561715, 0.9515367313470254, 0.9528073491996893, 0.951774311465258, 0.9516937686078375, 0.9518507815606101, 0.9530490733391745, 0.9515450017412281, 0.9533155836872549, 0.9527908260595865, 0.9510801314641644, 0.9530387614026415, 0.952513979133947, 0.9527123260764436, 0.950272291732234, 0.9516793113181045, 0.9514044952792162, 0.9499375830149518, 0.951421012092569, 0.9513260072835997, 0.9525036348976903, 0.9514850897495973, 0.9519313597146359, 0.9517867182220161, 0.9508115492719512, 0.9528465993577542, 0.9518362936360876, 0.9525656297220199, 0.9524850355846256, 0.9518218646502362, 0.9515491351069019, 0.9520986985893889, 0.9521647998074579, 0.950129762375155, 0.9523052939489567, 0.953166834801935, 0.9520429292870634, 0.9529602267888672, 0.9516379560172225, 0.9524230590745724], 'val_mDice': [0.3964745938444937, 0.5085717805937016, 0.5515131490856575, 0.5724215564115087, 0.5756365833335748, 0.5871640070856616, 0.5918337120024185, 0.5949860185218256, 0.5994234428059455, 0.6117148472610132, 0.612316040353402, 0.61500321353614, 0.614217268022079, 0.602261071764557, 0.6167527363952978, 0.621460474070224, 0.6136163886032957, 0.6011438769335188, 0.6116741582668027, 0.6151118112009997, 0.6180692151938071, 0.6024000394943706, 0.615440767237594, 0.6103139552990151, 0.6111782522840873, 0.6226821335334352, 0.6197579146763466, 0.6230813744347855, 0.6133509661232293, 0.6160964912542418, 0.6195082684468957, 0.6153152048920786, 0.6123181068697455, 0.6049635217176469, 0.6083426622039113, 0.5992724266132163, 0.6050708500366637, 0.6082090359160354, 0.5986131149963294, 0.6162099455321968, 0.6086401053647089, 0.6141404399658714, 0.611002667656158, 0.6114097540605001, 0.6025602531166716, 0.5998712308579983, 0.6162784798851226, 0.6098717514363081, 0.6048114276465091, 0.6166747805126552, 0.6043379000445318, 0.6053315028132007, 0.5964034026561502, 0.5999060303139288, 0.6005006422543658, 0.6108226709525678, 0.6092379186406481, 0.6048631777976479], 'loss': [9706.452574902412, 4585.837054861208, 3387.6737090597408, 2960.9505245652726, 2694.2703578457204, 2529.428906146286, 2391.456660371922, 2284.778533338858, 2214.2781259679996, 2121.284834709311, 2064.2427397051133, 2018.2603512114672, 1981.618164960027, 1944.074828649475, 1895.2660830578614, 1856.379748595656, 1816.1268962217919, 1784.100533801157, 1760.7767745716549, 1730.1281491760517, 1706.4562149658668, 1675.6995088573012, 1654.4062591481265, 1640.7075991385657, 1612.8364279486113, 1592.877526033068, 1573.7303084417156, 1556.6028034207504, 1539.1011725744063, 1516.4767119880985, 1509.9486233306266, 1494.363762477353, 1473.4218970791628, 1469.0580258215443, 1450.9582652498204, 1439.9299626784364, 1424.0379906467322, 1418.1005592344113, 1392.7483643867904, 1384.3404016627198, 1372.997443457664, 1365.8185163192204, 1356.1166788581852, 1342.616532149096, 1344.6594588217033, 1333.217834469332, 1312.7446546320316, 1307.0545981495309, 1294.4787433707995, 1289.5595328823024, 1289.849976131102, 1278.4520156434025, 1268.8915278323238, 1265.7193861205583, 1258.8677082118902, 1251.4762046427113, 1239.9490629027569, 1246.121292635322], 'acc': [0.8844713494705093, 0.9133373038596456, 0.9265236195788963, 0.9322821824426362, 0.9358685003452251, 0.9381300141774883, 0.9399487132191444, 0.9414784964097948, 0.9425395445187142, 0.9437905867130536, 0.9447623052879341, 0.9454313959407168, 0.9462653832052289, 0.9468741268479521, 0.9474479442139829, 0.9480061528632197, 0.9487576213162694, 0.9491344546058924, 0.9494996204380636, 0.949911943153192, 0.9502601543612148, 0.9508121190660108, 0.9510465301652404, 0.9513845074755273, 0.9517655455626588, 0.9520086977555987, 0.9522280839298372, 0.9525656377163518, 0.952687294536034, 0.9530799165997044, 0.9533278619332171, 0.953459771618553, 0.9537766602822206, 0.9538407718607442, 0.9541761137211962, 0.954274262132666, 0.9546201572842304, 0.9546680126657128, 0.9550530240917626, 0.9550545519976359, 0.9552582890715619, 0.955327997692114, 0.9554710667297333, 0.9556793887970605, 0.9557605822792332, 0.9557812272427837, 0.9561198102214433, 0.956226885033085, 0.9563469670254008, 0.9564675345645999, 0.9564136764782588, 0.9566623280331574, 0.9568171166762062, 0.9568342807038301, 0.9570593003204501, 0.9570298352621199, 0.9572150166969233, 0.9571538270087901], 'mDice': [0.238894883259002, 0.4176061819528911, 0.5118697691207864, 0.554746133700337, 0.5836314486526247, 0.602713405199738, 0.618784034481353, 0.6317927962288047, 0.6405718639248708, 0.6519119695610525, 0.6593837205098024, 0.6654256307431461, 0.6705495289653535, 0.6755099679206907, 0.6818128546743402, 0.6870239064568924, 0.6925374960809756, 0.6969506883892603, 0.70061089490521, 0.704443966282147, 0.707744481737438, 0.7120217460704573, 0.7150857592030266, 0.7171652006542012, 0.7208827596676582, 0.7237685417617357, 0.7265200967408494, 0.7291472186957054, 0.7313508300387543, 0.7347813931453411, 0.7359925006367102, 0.7380461904855993, 0.7411350985509846, 0.7418842252891091, 0.7445923696512958, 0.7460469527705798, 0.7485107458772031, 0.7494223323706403, 0.7532415167548209, 0.7546141642409013, 0.7562056219069424, 0.7572798486901462, 0.7588377233249132, 0.7608036327210136, 0.7604668354340144, 0.7621486340951481, 0.765348601874284, 0.7663072309400006, 0.7681221116323447, 0.7689157994891633, 0.7689605114195226, 0.7706566308521314, 0.7721727727954213, 0.7725738765990693, 0.773715802286518, 0.7747589992961361, 0.776638228041071, 0.775663053549217]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGNLoading train:  23%|██▎       | 66/285 [01:28<05:31,  1.51s/it]Loading train:  24%|██▎       | 67/285 [01:29<05:02,  1.39s/it]Loading train:  24%|██▍       | 68/285 [01:31<04:47,  1.32s/it]Loading train:  24%|██▍       | 69/285 [01:32<04:30,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:33<04:10,  1.17s/it]Loading train:  25%|██▍       | 71/285 [01:34<04:09,  1.17s/it]Loading train:  25%|██▌       | 72/285 [01:35<04:05,  1.15s/it]Loading train:  26%|██▌       | 73/285 [01:36<03:58,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:37<03:58,  1.13s/it]Loading train:  26%|██▋       | 75/285 [01:38<04:00,  1.14s/it]Loading train:  27%|██▋       | 76/285 [01:39<03:55,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:40<03:50,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:41<03:40,  1.06s/it]Loading train:  28%|██▊       | 79/285 [01:42<03:35,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:43<03:32,  1.04s/it]Loading train:  28%|██▊       | 81/285 [01:45<03:35,  1.06s/it]Loading train:  29%|██▉       | 82/285 [01:46<03:31,  1.04s/it]Loading train:  29%|██▉       | 83/285 [01:47<03:28,  1.03s/it]Loading train:  29%|██▉       | 84/285 [01:48<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:49<03:38,  1.09s/it]Loading train:  30%|███       | 86/285 [01:50<03:46,  1.14s/it]Loading train:  31%|███       | 87/285 [01:51<03:45,  1.14s/it]Loading train:  31%|███       | 88/285 [01:52<03:47,  1.16s/it]Loading train:  31%|███       | 89/285 [01:54<03:56,  1.21s/it]Loading train:  32%|███▏      | 90/285 [01:55<03:45,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:56<03:39,  1.13s/it]Loading train:  32%|███▏      | 92/285 [01:57<03:44,  1.17s/it]Loading train:  33%|███▎      | 93/285 [01:58<03:49,  1.19s/it]Loading train:  33%|███▎      | 94/285 [01:59<03:43,  1.17s/it]Loading train:  33%|███▎      | 95/285 [02:01<03:47,  1.20s/it]Loading train:  34%|███▎      | 96/285 [02:02<03:50,  1.22s/it]Loading train:  34%|███▍      | 97/285 [02:04<04:15,  1.36s/it]Loading train:  34%|███▍      | 98/285 [02:05<04:19,  1.39s/it]Loading train:  35%|███▍      | 99/285 [02:07<04:18,  1.39s/it]Loading train:  35%|███▌      | 100/285 [02:08<04:20,  1.41s/it]Loading train:  35%|███▌      | 101/285 [02:09<04:07,  1.35s/it]Loading train:  36%|███▌      | 102/285 [02:10<04:03,  1.33s/it]Loading train:  36%|███▌      | 103/285 [02:12<04:26,  1.46s/it]Loading train:  36%|███▋      | 104/285 [02:13<04:12,  1.40s/it]Loading train:  37%|███▋      | 105/285 [02:15<04:03,  1.35s/it]Loading train:  37%|███▋      | 106/285 [02:16<04:02,  1.35s/it]Loading train:  38%|███▊      | 107/285 [02:17<03:57,  1.33s/it]Loading train:  38%|███▊      | 108/285 [02:19<03:49,  1.30s/it]Loading train:  38%|███▊      | 109/285 [02:20<03:36,  1.23s/it]Loading train:  39%|███▊      | 110/285 [02:21<03:41,  1.27s/it]Loading train:  39%|███▉      | 111/285 [02:22<03:46,  1.30s/it]Loading train:  39%|███▉      | 112/285 [02:24<03:40,  1.27s/it]Loading train:  40%|███▉      | 113/285 [02:25<03:47,  1.32s/it]Loading train:  40%|████      | 114/285 [02:26<03:37,  1.27s/it]Loading train:  40%|████      | 115/285 [02:27<03:32,  1.25s/it]Loading train:  41%|████      | 116/285 [02:29<03:36,  1.28s/it]Loading train:  41%|████      | 117/285 [02:30<03:28,  1.24s/it]Loading train:  41%|████▏     | 118/285 [02:31<03:31,  1.26s/it]Loading train:  42%|████▏     | 119/285 [02:33<03:39,  1.32s/it]Loading train:  42%|████▏     | 120/285 [02:34<03:39,  1.33s/it]Loading train:  42%|████▏     | 121/285 [02:36<03:50,  1.41s/it]Loading train:  43%|████▎     | 122/285 [02:37<03:50,  1.42s/it]Loading train:  43%|████▎     | 123/285 [02:38<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [02:39<03:30,  1.31s/it]Loading train:  44%|████▍     | 125/285 [02:41<03:25,  1.28s/it]Loading train:  44%|████▍     | 126/285 [02:42<03:14,  1.22s/it]Loading train:  45%|████▍     | 127/285 [02:43<03:09,  1.20s/it]Loading train:  45%|████▍     | 128/285 [02:44<03:08,  1.20s/it]Loading train:  45%|████▌     | 129/285 [02:45<03:02,  1.17s/it]Loading train:  46%|████▌     | 130/285 [02:47<03:05,  1.20s/it]Loading train:  46%|████▌     | 131/285 [02:48<02:58,  1.16s/it]Loading train:  46%|████▋     | 132/285 [02:49<02:56,  1.15s/it]Loading train:  47%|████▋     | 133/285 [02:50<02:57,  1.17s/it]Loading train:  47%|████▋     | 134/285 [02:51<02:53,  1.15s/it]Loading train:  47%|████▋     | 135/285 [02:52<02:52,  1.15s/it]Loading train:  48%|████▊     | 136/285 [02:53<02:44,  1.10s/it]Loading train:  48%|████▊     | 137/285 [02:54<02:53,  1.17s/it]Loading train:  48%|████▊     | 138/285 [02:56<02:52,  1.18s/it]Loading train:  49%|████▉     | 139/285 [02:57<02:48,  1.16s/it]Loading train:  49%|████▉     | 140/285 [02:58<02:45,  1.14s/it]Loading train:  49%|████▉     | 141/285 [02:59<02:40,  1.11s/it]Loading train:  50%|████▉     | 142/285 [03:00<02:41,  1.13s/it]Loading train:  50%|█████     | 143/285 [03:02<02:51,  1.21s/it]Loading train:  51%|█████     | 144/285 [03:03<02:47,  1.19s/it]Loading train:  51%|█████     | 145/285 [03:04<02:45,  1.18s/it]Loading train:  51%|█████     | 146/285 [03:05<02:37,  1.13s/it]Loading train:  52%|█████▏    | 147/285 [03:06<02:36,  1.13s/it]Loading train:  52%|█████▏    | 148/285 [03:07<02:34,  1.13s/it]Loading train:  52%|█████▏    | 149/285 [03:08<02:39,  1.17s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:35,  1.15s/it]Loading train:  53%|█████▎    | 151/285 [03:11<02:34,  1.15s/it]Loading train:  53%|█████▎    | 152/285 [03:12<02:40,  1.21s/it]Loading train:  54%|█████▎    | 153/285 [03:14<02:53,  1.31s/it]Loading train:  54%|█████▍    | 154/285 [03:15<02:50,  1.30s/it]Loading train:  54%|█████▍    | 155/285 [03:16<02:44,  1.26s/it]Loading train:  55%|█████▍    | 156/285 [03:17<02:39,  1.23s/it]Loading train:  55%|█████▌    | 157/285 [03:18<02:33,  1.20s/it]Loading train:  55%|█████▌    | 158/285 [03:19<02:27,  1.16s/it]Loading train:  56%|█████▌    | 159/285 [03:20<02:14,  1.07s/it]Loading train:  56%|█████▌    | 160/285 [03:21<02:15,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [03:22<02:11,  1.06s/it]Loading train:  57%|█████▋    | 162/285 [03:23<02:10,  1.06s/it]Loading train:  57%|█████▋    | 163/285 [03:24<02:12,  1.08s/it]Loading train:  58%|█████▊    | 164/285 [03:26<02:12,  1.09s/it]Loading train:  58%|█████▊    | 165/285 [03:27<02:10,  1.08s/it]Loading train:  58%|█████▊    | 166/285 [03:28<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [03:29<01:59,  1.01s/it]Loading train:  59%|█████▉    | 168/285 [03:30<02:02,  1.05s/it]Loading train:  59%|█████▉    | 169/285 [03:31<01:58,  1.02s/it]Loading train:  60%|█████▉    | 170/285 [03:32<01:57,  1.02s/it]Loading train:  60%|██████    | 171/285 [03:33<01:58,  1.04s/it]Loading train:  60%|██████    | 172/285 [03:34<01:56,  1.03s/it]Loading train:  61%|██████    | 173/285 [03:35<01:57,  1.05s/it]Loading train:  61%|██████    | 174/285 [03:36<01:58,  1.07s/it]Loading train:  61%|██████▏   | 175/285 [03:37<01:58,  1.08s/it]Loading train:  62%|██████▏   | 176/285 [03:38<01:58,  1.09s/it]Loading train:  62%|██████▏   | 177/285 [03:39<01:57,  1.09s/it]Loading train:  62%|██████▏   | 178/285 [03:40<01:54,  1.07s/it]Loading train:  63%|██████▎   | 179/285 [03:41<01:52,  1.06s/it]Loading train:  63%|██████▎   | 180/285 [03:42<01:52,  1.07s/it]Loading train:  64%|██████▎   | 181/285 [03:44<01:51,  1.07s/it]Loading train:  64%|██████▍   | 182/285 [03:45<01:48,  1.06s/it]Loading train:  64%|██████▍   | 183/285 [03:46<01:54,  1.13s/it]Loading train:  65%|██████▍   | 184/285 [03:47<01:46,  1.05s/it]Loading train:  65%|██████▍   | 185/285 [03:48<01:46,  1.06s/it]Loading train:  65%|██████▌   | 186/285 [03:49<01:45,  1.07s/it]Loading train:  66%|██████▌   | 187/285 [03:50<01:49,  1.11s/it]Loading train:  66%|██████▌   | 188/285 [03:51<01:52,  1.16s/it]Loading train:  66%|██████▋   | 189/285 [03:52<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [03:53<01:44,  1.09s/it]Loading train:  67%|██████▋   | 191/285 [03:54<01:40,  1.07s/it]Loading train:  67%|██████▋   | 192/285 [03:56<01:40,  1.08s/it]Loading train:  68%|██████▊   | 193/285 [03:57<01:40,  1.09s/it]Loading train:  68%|██████▊   | 194/285 [03:58<01:39,  1.09s/it]Loading train:  68%|██████▊   | 195/285 [03:59<01:39,  1.10s/it]Loading train:  69%|██████▉   | 196/285 [04:00<01:39,  1.11s/it]Loading train:  69%|██████▉   | 197/285 [04:01<01:35,  1.09s/it]Loading train:  69%|██████▉   | 198/285 [04:02<01:36,  1.11s/it]Loading train:  70%|██████▉   | 199/285 [04:03<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [04:04<01:30,  1.06s/it]Loading train:  71%|███████   | 201/285 [04:05<01:31,  1.09s/it]Loading train:  71%|███████   | 202/285 [04:07<01:35,  1.15s/it]Loading train:  71%|███████   | 203/285 [04:08<01:41,  1.24s/it]Loading train:  72%|███████▏  | 204/285 [04:09<01:38,  1.22s/it]Loading train:  72%|███████▏  | 205/285 [04:10<01:34,  1.18s/it]Loading train:  72%|███████▏  | 206/285 [04:11<01:31,  1.15s/it]Loading train:  73%|███████▎  | 207/285 [04:13<01:30,  1.16s/it]Loading train:  73%|███████▎  | 208/285 [04:14<01:28,  1.15s/it]Loading train:  73%|███████▎  | 209/285 [04:15<01:25,  1.12s/it]Loading train:  74%|███████▎  | 210/285 [04:16<01:27,  1.17s/it]Loading train:  74%|███████▍  | 211/285 [04:17<01:23,  1.13s/it]Loading train:  74%|███████▍  | 212/285 [04:18<01:24,  1.15s/it]Loading train:  75%|███████▍  | 213/285 [04:20<01:23,  1.16s/it]Loading train:  75%|███████▌  | 214/285 [04:21<01:18,  1.11s/it]Loading train:  75%|███████▌  | 215/285 [04:22<01:17,  1.11s/it]Loading train:  76%|███████▌  | 216/285 [04:23<01:13,  1.06s/it]Loading train:  76%|███████▌  | 217/285 [04:24<01:11,  1.05s/it]Loading train:  76%|███████▋  | 218/285 [04:25<01:16,  1.14s/it]Loading train:  77%|███████▋  | 219/285 [04:26<01:11,  1.08s/it]Loading train:  77%|███████▋  | 220/285 [04:27<01:09,  1.07s/it]Loading train:  78%|███████▊  | 221/285 [04:28<01:11,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [04:29<01:05,  1.04s/it]Loading train:  78%|███████▊  | 223/285 [04:30<01:09,  1.12s/it]Loading train:  79%|███████▊  | 224/285 [04:32<01:09,  1.14s/it]Loading train:  79%|███████▉  | 225/285 [04:33<01:08,  1.15s/it]Loading train:  79%|███████▉  | 226/285 [04:34<01:07,  1.15s/it]Loading train:  80%|███████▉  | 227/285 [04:35<01:06,  1.15s/it]Loading train:  80%|████████  | 228/285 [04:36<01:05,  1.15s/it]Loading train:  80%|████████  | 229/285 [04:37<01:05,  1.17s/it]Loading train:  81%|████████  | 230/285 [04:38<01:02,  1.14s/it]Loading train:  81%|████████  | 231/285 [04:40<01:00,  1.13s/it]Loading train:  81%|████████▏ | 232/285 [04:41<01:03,  1.19s/it]Loading train:  82%|████████▏ | 233/285 [04:42<01:02,  1.19s/it]Loading train:  82%|████████▏ | 234/285 [04:43<00:59,  1.16s/it]Loading train:  82%|████████▏ | 235/285 [04:44<00:59,  1.18s/it]Loading train:  83%|████████▎ | 236/285 [04:46<01:00,  1.23s/it]Loading train:  83%|████████▎ | 237/285 [04:47<00:58,  1.22s/it]Loading train:  84%|████████▎ | 238/285 [04:48<01:00,  1.28s/it]Loading train:  84%|████████▍ | 239/285 [04:50<01:01,  1.34s/it]Loading train:  84%|████████▍ | 240/285 [04:51<00:58,  1.31s/it]Loading train:  85%|████████▍ | 241/285 [04:53<00:59,  1.35s/it]Loading train:  85%|████████▍ | 242/285 [04:54<00:57,  1.33s/it]Loading train:  85%|████████▌ | 243/285 [04:55<00:54,  1.31s/it]Loading train:  86%|████████▌ | 244/285 [04:56<00:52,  1.29s/it]Loading train:  86%|████████▌ | 245/285 [04:58<00:50,  1.26s/it]Loading train:  86%|████████▋ | 246/285 [04:59<00:49,  1.27s/it]Loading train:  87%|████████▋ | 247/285 [05:00<00:48,  1.28s/it]Loading train:  87%|████████▋ | 248/285 [05:01<00:47,  1.29s/it]Loading train:  87%|████████▋ | 249/285 [05:03<00:45,  1.28s/it]Loading train:  88%|████████▊ | 250/285 [05:04<00:45,  1.29s/it]Loading train:  88%|████████▊ | 251/285 [05:05<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [05:06<00:38,  1.17s/it]Loading train:  89%|████████▉ | 253/285 [05:07<00:34,  1.08s/it]Loading train:  89%|████████▉ | 254/285 [05:08<00:32,  1.06s/it]Loading train:  89%|████████▉ | 255/285 [05:09<00:30,  1.02s/it]Loading train:  90%|████████▉ | 256/285 [05:10<00:28,  1.00it/s]Loading train:  90%|█████████ | 257/285 [05:11<00:27,  1.03it/s]Loading train:  91%|█████████ | 258/285 [05:12<00:27,  1.02s/it]Loading train:  91%|█████████ | 259/285 [05:13<00:26,  1.03s/it]Loading train:  91%|█████████ | 260/285 [05:14<00:24,  1.00it/s]Loading train:  92%|█████████▏| 261/285 [05:15<00:23,  1.01it/s]Loading train:  92%|█████████▏| 262/285 [05:16<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [05:17<00:22,  1.00s/it]Loading train:  93%|█████████▎| 264/285 [05:18<00:20,  1.02it/s]Loading train:  93%|█████████▎| 265/285 [05:19<00:19,  1.00it/s]Loading train:  93%|█████████▎| 266/285 [05:20<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [05:21<00:19,  1.08s/it]Loading train:  94%|█████████▍| 268/285 [05:22<00:19,  1.13s/it]Loading train:  94%|█████████▍| 269/285 [05:24<00:18,  1.15s/it]Loading train:  95%|█████████▍| 270/285 [05:25<00:17,  1.16s/it]Loading train:  95%|█████████▌| 271/285 [05:26<00:16,  1.15s/it]Loading train:  95%|█████████▌| 272/285 [05:27<00:15,  1.17s/it]Loading train:  96%|█████████▌| 273/285 [05:28<00:14,  1.21s/it]Loading train:  96%|█████████▌| 274/285 [05:30<00:13,  1.26s/it]Loading train:  96%|█████████▋| 275/285 [05:31<00:12,  1.27s/it]Loading train:  97%|█████████▋| 276/285 [05:32<00:11,  1.31s/it]Loading train:  97%|█████████▋| 277/285 [05:34<00:10,  1.29s/it]Loading train:  98%|█████████▊| 278/285 [05:35<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [05:36<00:07,  1.26s/it]Loading train:  98%|█████████▊| 280/285 [05:37<00:06,  1.21s/it]Loading train:  99%|█████████▊| 281/285 [05:39<00:05,  1.27s/it]Loading train:  99%|█████████▉| 282/285 [05:40<00:03,  1.23s/it]Loading train:  99%|█████████▉| 283/285 [05:41<00:02,  1.21s/it]Loading train: 100%|█████████▉| 284/285 [05:42<00:01,  1.22s/it]Loading train: 100%|██████████| 285/285 [05:43<00:00,  1.20s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 111.95it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:03, 84.46it/s] concatenating: train:   8%|▊         | 24/285 [00:00<00:03, 73.86it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:03, 77.39it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:03, 69.72it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:03, 76.40it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:02, 79.92it/s]concatenating: train:  24%|██▎       | 67/285 [00:00<00:02, 81.56it/s]concatenating: train:  27%|██▋       | 77/285 [00:00<00:02, 84.84it/s]concatenating: train:  31%|███       | 89/285 [00:01<00:02, 93.01it/s]concatenating: train:  35%|███▍      | 99/285 [00:01<00:01, 95.00it/s]concatenating: train:  40%|████      | 115/285 [00:01<00:01, 107.65it/s]concatenating: train:  46%|████▋     | 132/285 [00:01<00:01, 119.52it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 98.98it/s] concatenating: train:  55%|█████▌    | 157/285 [00:01<00:01, 98.31it/s]concatenating: train:  59%|█████▉    | 168/285 [00:01<00:01, 101.47it/s]concatenating: train:  63%|██████▎   | 179/285 [00:01<00:01, 77.66it/s] concatenating: train:  66%|██████▋   | 189/285 [00:02<00:01, 77.08it/s]concatenating: train:  69%|██████▉   | 198/285 [00:02<00:01, 74.83it/s]concatenating: train:  73%|███████▎  | 209/285 [00:02<00:00, 82.03it/s]concatenating: train:  77%|███████▋  | 220/285 [00:02<00:00, 87.96it/s]concatenating: train:  84%|████████▎ | 238/285 [00:02<00:00, 99.82it/s]concatenating: train:  87%|████████▋ | 249/285 [00:02<00:00, 92.23it/s]concatenating: train:  91%|█████████ | 260/285 [00:02<00:00, 84.43it/s]concatenating: train:  95%|█████████▌| 271/285 [00:02<00:00, 89.87it/s]concatenating: train:  99%|█████████▊| 281/285 [00:03<00:00, 89.72it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 91.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.67s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.58s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.50s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 53.33it/s]
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 106)  0           concatenate_5[0][0]              2019-07-07 04:02:10.499986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 04:02:10.500092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 04:02:10.500107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 04:02:10.500117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 04:02:10.500564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 18s - loss: 35182.2133 - acc: 0.8538 - mDice: 0.0816 - val_loss: 23964.5316 - val_acc: 0.8777 - val_mDice: 0.1712

Epoch 00001: val_mDice improved from -inf to 0.17120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 9s - loss: 17606.9831 - acc: 0.8535 - mDice: 0.1643 - val_loss: 13531.4885 - val_acc: 0.8774 - val_mDice: 0.2538

Epoch 00002: val_mDice improved from 0.17120 to 0.25383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 12369.9831 - acc: 0.8662 - mDice: 0.2508 - val_loss: 9545.3951 - val_acc: 0.8846 - val_mDice: 0.3081

Epoch 00003: val_mDice improved from 0.25383 to 0.30812, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 9s - loss: 9510.0574 - acc: 0.8835 - mDice: 0.3173 - val_loss: 6936.0481 - val_acc: 0.9056 - val_mDice: 0.3886

Epoch 00004: val_mDice improved from 0.30812 to 0.38857, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 7838.9143 - acc: 0.8966 - mDice: 0.3760 - val_loss: 6214.4809 - val_acc: 0.9141 - val_mDice: 0.4259

Epoch 00005: val_mDice improved from 0.38857 to 0.42592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 7024.7749 - acc: 0.9038 - mDice: 0.4134 - val_loss: 5739.1333 - val_acc: 0.9185 - val_mDice: 0.4532

Epoch 00006: val_mDice improved from 0.42592 to 0.45318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 6481.5096 - acc: 0.9083 - mDice: 0.4405 - val_loss: 5473.3916 - val_acc: 0.9199 - val_mDice: 0.4699

Epoch 00007: val_mDice improved from 0.45318 to 0.46989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 6087.5589 - acc: 0.9116 - mDice: 0.4618 - val_loss: 5412.7571 - val_acc: 0.9207 - val_mDice: 0.4734

Epoch 00008: val_mDice improved from 0.46989 to 0.47338, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 5752.6902 - acc: 0.9143 - mDice: 0.4796 - val_loss: 5236.4036 - val_acc: 0.9226 - val_mDice: 0.4840

Epoch 00009: val_mDice improved from 0.47338 to 0.48400, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 5488.7308 - acc: 0.9166 - mDice: 0.4949 - val_loss: 4874.1891 - val_acc: 0.9250 - val_mDice: 0.5078

Epoch 00010: val_mDice improved from 0.48400 to 0.50784, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 9s - loss: 5264.1564 - acc: 0.9184 - mDice: 0.5079 - val_loss: 5016.1881 - val_acc: 0.9235 - val_mDice: 0.4968

Epoch 00011: val_mDice did not improve from 0.50784
Epoch 12/300
 - 9s - loss: 5054.3287 - acc: 0.9201 - mDice: 0.5208 - val_loss: 4740.3021 - val_acc: 0.9275 - val_mDice: 0.5159

Epoch 00012: val_mDice improved from 0.50784 to 0.51590, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 9s - loss: 4882.2008 - acc: 0.9218 - mDice: 0.5317 - val_loss: 4765.0481 - val_acc: 0.9277 - val_mDice: 0.5120

Epoch 00013: val_mDice did not improve from 0.51590
Epoch 14/300
 - 9s - loss: 4743.0097 - acc: 0.9230 - mDice: 0.5410 - val_loss: 4676.0959 - val_acc: 0.9289 - val_mDice: 0.5197

Epoch 00014: val_mDice improved from 0.51590 to 0.51973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 10s - loss: 4610.3007 - acc: 0.9240 - mDice: 0.5497 - val_loss: 4609.7249 - val_acc: 0.9280 - val_mDice: 0.5228

Epoch 00015: val_mDice improved from 0.51973 to 0.52276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 9s - loss: 4467.9351 - acc: 0.9252 - mDice: 0.5592 - val_loss: 4599.1383 - val_acc: 0.9277 - val_mDice: 0.5243

Epoch 00016: val_mDice improved from 0.52276 to 0.52432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 9s - loss: 4376.6877 - acc: 0.9260 - mDice: 0.5658 - val_loss: 4492.4696 - val_acc: 0.9305 - val_mDice: 0.5333

Epoch 00017: val_mDice improved from 0.52432 to 0.53329, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 18/300
 - 9s - loss: 4245.1909 - acc: 0.9271 - mDice: 0.5748 - val_loss: 4586.8251 - val_acc: 0.9289 - val_mDice: 0.5243

Epoch 00018: val_mDice did not improve from 0.53329
Epoch 19/300
 - 9s - loss: 4169.1302 - acc: 0.9280 - mDice: 0.5803 - val_loss: 4423.5085 - val_acc: 0.9327 - val_mDice: 0.5362

Epoch 00019: val_mDice improved from 0.53329 to 0.53615, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 9s - loss: 4068.8904 - acc: 0.9290 - mDice: 0.5877 - val_loss: 4419.7812 - val_acc: 0.9321 - val_mDice: 0.5371

Epoch 00020: val_mDice improved from 0.53615 to 0.53705, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 21/300
 - 9s - loss: 3983.2400 - acc: 0.9297 - mDice: 0.5939 - val_loss: 4446.1854 - val_acc: 0.9321 - val_mDice: 0.5352

Epoch 00021: val_mDice did not improve from 0.53705
Epoch 22/300
 - 10s - loss: 3905.3205 - acc: 0.9305 - mDice: 0.5997 - val_loss: 4379.4799 - val_acc: 0.9330 - val_mDice: 0.5380

Epoch 00022: val_mDice improved from 0.53705 to 0.53804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 9s - loss: 3852.7360 - acc: 0.9311 - mDice: 0.6040 - val_loss: 4415.5635 - val_acc: 0.9347 - val_mDice: 0.5372

Epoch 00023: val_mDice did not improve from 0.53804
Epoch 24/300
 - 9s - loss: 3763.2474 - acc: 0.9319 - mDice: 0.6108 - val_loss: 4350.0382 - val_acc: 0.9330 - val_mDice: 0.5401

Epoch 00024: val_mDice improved from 0.53804 to 0.54007, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 9s - loss: 3721.3375 - acc: 0.9322 - mDice: 0.6140 - val_loss: 4345.0474 - val_acc: 0.9336 - val_mDice: 0.5421

Epoch 00025: val_mDice improved from 0.54007 to 0.54208, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 9s - loss: 3655.2717 - acc: 0.9327 - mDice: 0.6192 - val_loss: 4292.3912 - val_acc: 0.9340 - val_mDice: 0.5456

Epoch 00026: val_mDice improved from 0.54208 to 0.54557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 10s - loss: 3573.3500 - acc: 0.9337 - mDice: 0.6255 - val_loss: 4277.8786 - val_acc: 0.9352 - val_mDice: 0.5469

Epoch 00027: val_mDice improved from 0.54557 to 0.54686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 9s - loss: 3544.4845 - acc: 0.9339 - mDice: 0.6279 - val_loss: 4301.1021 - val_acc: 0.9343 - val_mDice: 0.5444

Epoch 00028: val_mDice did not improve from 0.54686
Epoch 29/300
 - 9s - loss: 3492.9698 - acc: 0.9346 - mDice: 0.6320 - val_loss: 4233.7531 - val_acc: 0.9347 - val_mDice: 0.5502

Epoch 00029: val_mDice improved from 0.54686 to 0.55017, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 9s - loss: 3446.1536 - acc: 0.9351 - mDice: 0.6358 - val_loss: 4335.1810 - val_acc: 0.9359 - val_mDice: 0.5436

Epoch 00030: val_mDice did not improve from 0.55017
Epoch 31/300
 - 9s - loss: 3383.5982 - acc: 0.9354 - mDice: 0.6408 - val_loss: 4243.6366 - val_acc: 0.9373 - val_mDice: 0.5504

Epoch 00031: val_mDice improved from 0.55017 to 0.55037, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 9s - loss: 3342.4920 - acc: 0.9361 - mDice: 0.6443 - val_loss: 4313.8407 - val_acc: 0.9340 - val_mDice: 0.5442

Epoch 00032: val_mDice did not improve from 0.55037
Epoch 33/300
 - 9s - loss: 3310.2625 - acc: 0.9363 - mDice: 0.6467 - val_loss: 4251.6393 - val_acc: 0.9357 - val_mDice: 0.5503

Epoch 00033: val_mDice did not improve from 0.55037
Epoch 34/300
 - 10s - loss: 3264.9378 - acc: 0.9367 - mDice: 0.6507 - val_loss: 4164.8849 - val_acc: 0.9370 - val_mDice: 0.5551

Epoch 00034: val_mDice improved from 0.55037 to 0.55514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 3233.2519 - acc: 0.9372 - mDice: 0.6535 - val_loss: 4201.9582 - val_acc: 0.9366 - val_mDice: 0.5529

Epoch 00035: val_mDice did not improve from 0.55514
Epoch 36/300
 - 9s - loss: 3184.6190 - acc: 0.9376 - mDice: 0.6574 - val_loss: 4253.5902 - val_acc: 0.9359 - val_mDice: 0.5508

Epoch 00036: val_mDice did not improve from 0.55514
Epoch 37/300
 - 9s - loss: 3157.1374 - acc: 0.9378 - mDice: 0.6598 - val_loss: 4198.9854 - val_acc: 0.9366 - val_mDice: 0.5533

Epoch 00037: val_mDice did not improve from 0.55514
Epoch 38/300
 - 9s - loss: 3118.6817 - acc: 0.9383 - mDice: 0.6630 - val_loss: 4194.8060 - val_acc: 0.9376 - val_mDice: 0.5533

Epoch 00038: val_mDice did not improve from 0.55514
Epoch 39/300
 - 9s - loss: 3087.2198 - acc: 0.9385 - mDice: 0.6658 - val_loss: 4133.8493 - val_acc: 0.9380 - val_mDice: 0.5572

Epoch 00039: val_mDice improved from 0.55514 to 0.55716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 40/300
 - 9s - loss: 3052.3188 - acc: 0.9389 - mDice: 0.6686 - val_loss: 4112.7844 - val_acc: 0.9399 - val_mDice: 0.5587

Epoch 00040: val_mDice improved from 0.55716 to 0.55870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 9s - loss: 3016.5685 - acc: 0.9393 - mDice: 0.6719 - val_loss: 4137.0283 - val_acc: 0.9398 - val_mDice: 0.5582

Epoch 00041: val_mDice did not improve from 0.55870
Epoch 42/300
 - 10s - loss: 3002.5520 - acc: 0.9396 - mDice: 0.6731 - val_loss: 4218.6137 - val_acc: 0.9382 - val_mDice: 0.5532

Epoch 00042: val_mDice did not improve from 0.55870
Epoch 43/300
 - 9s - loss: 2956.7902 - acc: 0.9398 - mDice: 0.6769 - val_loss: 4542.8087 - val_acc: 0.9374 - val_mDice: 0.5342

Epoch 00043: val_mDice did not improve from 0.55870
Epoch 44/300
 - 9s - loss: 2925.3537 - acc: 0.9401 - mDice: 0.6797 - val_loss: 4028.9533 - val_acc: 0.9380 - val_mDice: 0.5659

Epoch 00044: val_mDice improved from 0.55870 to 0.56592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 45/300
 - 9s - loss: 2903.6901 - acc: 0.9403 - mDice: 0.6818 - val_loss: 4121.4085 - val_acc: 0.9396 - val_mDice: 0.5591

Epoch 00045: val_mDice did not improve from 0.56592
Epoch 46/300
 - 10s - loss: 2873.8643 - acc: 0.9406 - mDice: 0.6843 - val_loss: 4172.1289 - val_acc: 0.9385 - val_mDice: 0.5561

Epoch 00046: val_mDice did not improve from 0.56592
Epoch 47/300
 - 9s - loss: 2846.3165 - acc: 0.9410 - mDice: 0.6867 - val_loss: 4137.6409 - val_acc: 0.9381 - val_mDice: 0.5594

Epoch 00047: val_mDice did not improve from 0.56592
Epoch 48/300
 - 9s - loss: 2817.2382 - acc: 0.9413 - mDice: 0.6893 - val_loss: 4201.8562 - val_acc: 0.9363 - val_mDice: 0.5554

Epoch 00048: val_mDice did not improve from 0.56592
Epoch 49/300
 - 9s - loss: 2799.0813 - acc: 0.9416 - mDice: 0.6909 - val_loss: 4129.8505 - val_acc: 0.9389 - val_mDice: 0.5600

Epoch 00049: val_mDice did not improve from 0.56592
Epoch 50/300
 - 10s - loss: 2781.6502 - acc: 0.9417 - mDice: 0.6925 - val_loss: 4043.1856 - val_acc: 0.9391 - val_mDice: 0.5657

Epoch 00050: val_mDice did not improve from 0.56592
Epoch 51/300
 - 9s - loss: 2756.6437 - acc: 0.9419 - mDice: 0.6948 - val_loss: 4094.9669 - val_acc: 0.9359 - val_mDice: 0.5627

Epoch 00051: val_mDice did not improve from 0.56592
Epoch 52/300
 - 9s - loss: 2733.1661 - acc: 0.9422 - mDice: 0.6969 - val_loss: 3977.8800 - val_acc: 0.9363 - val_mDice: 0.5702

Epoch 00052: val_mDice improved from 0.56592 to 0.57024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 53/300
 - 9s - loss: 2716.0670 - acc: 0.9425 - mDice: 0.6984 - val_loss: 4171.4292 - val_acc: 0.9363 - val_mDice: 0.5550

Epoch 00053: val_mDice did not improve from 0.57024
Epoch 54/300
 - 9s - loss: 2675.3632 - acc: 0.9428 - mDice: 0.7020 - val_loss: 4154.9411 - val_acc: 0.9398 - val_mDice: 0.5584

Epoch 00054: val_mDice did not improve from 0.57024
Epoch 55/300
 - 9s - loss: 2671.6402 - acc: 0.9429 - mDice: 0.7024 - val_loss: 4097.6407 - val_acc: 0.9335 - val_mDice: 0.5597

Epoch 00055: val_mDice did not improve from 0.57024
Epoch 56/300
 - 10s - loss: 2643.3645 - acc: 0.9433 - mDice: 0.7050 - val_loss: 3977.0378 - val_acc: 0.9393 - val_mDice: 0.5705

Epoch 00056: val_mDice improved from 0.57024 to 0.57055, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 57/300
 - 9s - loss: 2637.6700 - acc: 0.9434 - mDice: 0.7055 - val_loss: 4160.8235 - val_acc: 0.9396 - val_mDice: 0.5592

Epoch 00057: val_mDice did not improve from 0.57055
Epoch 58/300
 - 9s - loss: 2602.3499 - acc: 0.9436 - mDice: 0.7087 - val_loss: 4207.4754 - val_acc: 0.9334 - val_mDice: 0.5526

Epoch 00058: val_mDice did not improve from 0.57055
Epoch 59/300
 - 9s - loss: 2593.3417 - acc: 0.9438 - mDice: 0.7095 - val_loss: 4040.5695 - val_acc: 0.9356 - val_mDice: 0.5654

Epoch 00059: val_mDice did not improve from 0.57055
Epoch 60/300
 - 9s - loss: 2571.7476 - acc: 0.9441 - mDice: 0.7116 - val_loss: 3946.6861 - val_acc: 0.9397 - val_mDice: 0.5716

Epoch 00060: val_mDice improved from 0.57055 to 0.57155, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 61/300
 - 9s - loss: 2559.2886 - acc: 0.9441 - mDice: 0.7127 - val_loss: 4220.3821 - val_acc: 0.9359 - val_mDice: 0.5536

Epoch 00061: val_mDice did not improve from 0.57155
Epoch 62/300
 - 10s - loss: 2548.8114 - acc: 0.9443 - mDice: 0.7136 - val_loss: 4021.1275 - val_acc: 0.9398 - val_mDice: 0.5681

Epoch 00062: val_mDice did not improve from 0.57155
Epoch 63/300
 - 10s - loss: 2516.4439 - acc: 0.9447 - mDice: 0.7167 - val_loss: 4162.6188 - val_acc: 0.9407 - val_mDice: 0.5583

Epoch 00063: val_mDice did not improve from 0.57155
Epoch 64/300
 - 10s - loss: 2504.0329 - acc: 0.9449 - mDice: 0.7177 - val_loss: 4078.0953 - val_acc: 0.9391 - val_mDice: 0.5648

Epoch 00064: val_mDice did not improve from 0.57155
Epoch 65/300
 - 10s - loss: 2497.9898 - acc: 0.9449 - mDice: 0.7185 - val_loss: 4058.5907 - val_acc: 0.9397 - val_mDice: 0.5668

Epoch 00065: val_mDice did not improve from 0.57155
Epoch 66/300
 - 10s - loss: 2476.9944 - acc: 0.9451 - mDice: 0.7205 - val_loss: 4149.5166 - val_acc: 0.9387 - val_mDice: 0.5583

Epoch 00066: val_mDice did not improve from 0.57155
Epoch 67/300
 - 10s - loss: 2453.0461 - acc: 0.9454 - mDice: 0.7226 - val_loss: 4211.9398 - val_acc: 0.9370 - val_mDice: 0.5556

Epoch 00067: val_mDice did not improve from 0.57155
Epoch 68/300
 - 10s - loss: 2443.7653 - acc: 0.9454 - mDice: 0.7235 - val_loss: 4154.5649 - val_acc: 0.9409 - val_mDice: 0.5608

Epoch 00068: val_mDice did not improve from 0.57155
Epoch 69/300
 - 10s - loss: 2429.0722 - acc: 0.9457 - mDice: 0.7248 - val_loss: 4137.3292 - val_acc: 0.9414 - val_mDice: 0.5629

Epoch 00069: val_mDice did not improve from 0.57155
Epoch 70/300
 - 9s - loss: 2424.8798 - acc: 0.9458 - mDice: 0.7253 - val_loss: 4287.9023 - val_acc: 0.9361 - val_mDice: 0.5498

Epoch 00070: val_mDice did not improve from 0.57155
Epoch 71/300
 - 10s - loss: 2408.4483 - acc: 0.9459 - mDice: 0.7269 - val_loss: 4147.3679 - val_acc: 0.9402 - val_mDice: 0.5589

Epoch 00071: val_mDice did not improve from 0.57155
Epoch 72/300
 - 10s - loss: 2395.0113 - acc: 0.9460 - mDice: 0.7283 - val_loss: 4373.9620 - val_acc: 0.9406 - val_mDice: 0.5473

Epoch 00072: val_mDice did not improve from 0.57155
Epoch 73/300
 - 10s - loss: 2384.0940 - acc: 0.9460 - mDice: 0.7291 - val_loss: 4011.4742 - val_acc: 0.9395 - val_mDice: 0.5703

Epoch 00073: val_mDice did not improve from 0.57155
Epoch 74/300
 - 10s - loss: 2378.2309 - acc: 0.9463 - mDice: 0.7297 - val_loss: 3986.4069 - val_acc: 0.9377 - val_mDice: 0.5696

Epoch 00074: val_mDice did not improve from 0.57155
Epoch 75/300
 - 10s - loss: 2362.2874 - acc: 0.9463 - mDice: 0.7312 - val_loss: 4388.5327 - val_acc: 0.9365 - val_mDice: 0.5430

Epoch 00075: val_mDice did not improve from 0.57155
Epoch 76/300
 - 10s - loss: 2341.2802 - acc: 0.9466 - mDice: 0.7332 - val_loss: 4199.2224 - val_acc: 0.9422 - val_mDice: 0.5579

Epoch 00076: val_mDice did not improve from 0.57155
Epoch 77/300
 - 10s - loss: 2332.2416 - acc: 0.9467 - mDice: 0.7339 - val_loss: 4017.4941 - val_acc: 0.9418 - val_mDice: 0.5695

Epoch 00077: val_mDice did not improve from 0.57155
Epoch 78/300
 - 10s - loss: 2317.5061 - acc: 0.9470 - mDice: 0.7355 - val_loss: 4161.4385 - val_acc: 0.9408 - val_mDice: 0.5570

Epoch 00078: val_mDice did not improve from 0.57155
Epoch 79/300
 - 10s - loss: 2305.2907 - acc: 0.9468 - mDice: 0.7366 - val_loss: 4073.0745 - val_acc: 0.9414 - val_mDice: 0.5646

Epoch 00079: val_mDice did not improve from 0.57155
Epoch 80/300
 - 10s - loss: 2302.3750 - acc: 0.9471 - mDice: 0.7369 - val_loss: 4048.1584 - val_acc: 0.9416 - val_mDice: 0.5650

Epoch 00080: val_mDice did not improve from 0.57155
Epoch 81/300
 - 10s - loss: 2284.2786 - acc: 0.9473 - mDice: 0.7387 - val_loss: 4280.7492 - val_acc: 0.9405 - val_mDice: 0.5519

Epoch 00081: val_mDice did not improve from 0.57155
Epoch 82/300
 - 10s - loss: 2284.6962 - acc: 0.9473 - mDice: 0.7387 - val_loss: 3913.9324 - val_acc: 0.9387 - val_mDice: 0.5766

Epoch 00082: val_mDice improved from 0.57155 to 0.57656, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 83/300
 - 10s - loss: 2261.5439 - acc: 0.9474 - mDice: 0.7408 - val_loss: 4052.5315 - val_acc: 0.9400 - val_mDice: 0.5666

Epoch 00083: val_mDice did not improve from 0.57656
Epoch 84/300
 - 9s - loss: 2267.3472 - acc: 0.9475 - mDice: 0.7403 - val_loss: 4156.2413 - val_acc: 0.9399 - val_mDice: 0.5593

Epoch 00084: val_mDice did not improve from 0.57656
Epoch 85/300
 - 10s - loss: 2247.7557 - acc: 0.9478 - mDice: 0.7422 - val_loss: 4108.7673 - val_acc: 0.9414 - val_mDice: 0.5650

Epoch 00085: val_mDice did not improve from 0.57656
Epoch 86/300
 - 9s - loss: 2238.0372 - acc: 0.9478 - mDice: 0.7431 - val_loss: 3908.2989 - val_acc: 0.9430 - val_mDice: 0.5764

Epoch 00086: val_mDice did not improve from 0.57656
Epoch 87/300
 - 9s - loss: 2220.0990 - acc: 0.9480 - mDice: 0.7448 - val_loss: 4220.5090 - val_acc: 0.9418 - val_mDice: 0.5578

Epoch 00087: val_mDice did not improve from 0.57656
Epoch 88/300
 - 10s - loss: 2227.5792 - acc: 0.9479 - mDice: 0.7442 - val_loss: 4130.6395 - val_acc: 0.9397 - val_mDice: 0.5627

Epoch 00088: val_mDice did not improve from 0.57656
Epoch 89/300
 - 10s - loss: 2197.1223 - acc: 0.9482 - mDice: 0.7471 - val_loss: 4344.4954 - val_acc: 0.9432 - val_mDice: 0.5514

Epoch 00089: val_mDice did not improve from 0.57656
Epoch 90/300
 - 10s - loss: 2194.8060 - acc: 0.9482 - mDice: 0.7473 - val_loss: 3901.2621 - val_acc: 0.9444 - val_mDice: 0.5764

Epoch 00090: val_mDice did not improve from 0.57656
Epoch 91/300
 - 10s - loss: 2196.7832 - acc: 0.9481 - mDice: 0.7471 - val_loss: 4046.0296 - val_acc: 0.9449 - val_mDice: 0.5687

Epoch 00091: val_mDice did not improve from 0.57656
Epoch 92/300
 - 9s - loss: 2180.0014 - acc: 0.9484 - mDice: 0.7488 - val_loss: 4057.1201 - val_acc: 0.9424 - val_mDice: 0.5683

Epoch 00092: val_mDice did not improve from 0.57656
Epoch 93/300
 - 10s - loss: 2163.8115 - acc: 0.9486 - mDice: 0.7503 - val_loss: 4047.7879 - val_acc: 0.9417 - val_mDice: 0.5683

Epoch 00093: val_mDice did not improve from 0.57656
Epoch 94/300
 - 10s - loss: 2168.4300 - acc: 0.9485 - mDice: 0.7499 - val_loss: 4159.1601 - val_acc: 0.9427 - val_mDice: 0.5617

Epoch 00094: val_mDice did not improve from 0.57656
Epoch 95/300
 - 10s - loss: 2155.1756 - acc: 0.9487 - mDice: 0.7512 - val_loss: 4927.5848 - val_acc: 0.9430 - val_mDice: 0.5298

Epoch 00095: val_mDice did not improve from 0.57656
Epoch 96/300
 - 10s - loss: 2149.2792 - acc: 0.9487 - mDice: 0.7518 - val_loss: 4198.3389 - val_acc: 0.9368 - val_mDice: 0.5568

Epoch 00096: val_mDice did not improve from 0.57656
Epoch 97/300
 - 10s - loss: 2143.9286 - acc: 0.9489 - mDice: 0.7523 - val_loss: 4153.7815 - val_acc: 0.9415 - val_mDice: 0.5608

Epoch 00097: val_mDice did not improve from 0.57656
Epoch 98/300
 - 10s - loss: 2134.3359 - acc: 0.9489 - mDice: 0.7532 - val_loss: 3973.9043 - val_acc: 0.9391 - val_mDice: 0.5725

Epoch 00098: val_mDice did not improve from 0.57656
Epoch 99/300
 - 10s - loss: 2143.4762 - acc: 0.9489 - mDice: 0.7523 - val_loss: 4262.9646 - val_acc: 0.9418 - val_mDice: 0.5549

Epoch 00099: val_mDice did not improve from 0.57656
Epoch 100/300
 - 10s - loss: 2119.3910 - acc: 0.9491 - mDice: 0.7548 - val_loss: 4150.5133 - val_acc: 0.9406 - val_mDice: 0.5614

Epoch 00100: val_mDice did not improve from 0.57656
Epoch 101/300
 - 10s - loss: 2117.8431 - acc: 0.9491 - mDice: 0.7549 - val_loss: 4261.0090 - val_acc: 0.9398 - val_mDice: 0.5547

Epoch 00101: val_mDice did not improve from 0.57656
Epoch 102/300
 - 10s - loss: 2105.2964 - acc: 0.9493 - mDice: 0.7561 - val_loss: 4173.1357 - val_acc: 0.9437 - val_mDice: 0.5600

Epoch 00102: val_mDice did not improve from 0.57656
Epoch 103/300
 - 10s - loss: 2088.5565 - acc: 0.9495 - mDice: 0.7578 - val_loss: 4155.4495 - val_acc: 0.9415 - val_mDice: 0.5599

Epoch 00103: val_mDice did not improve from 0.57656
Epoch 104/300
 - 10s - loss: 2094.6520 - acc: 0.9494 - mDice: 0.7572 - val_loss: 4124.1963 - val_acc: 0.9439 - val_mDice: 0.5603

Epoch 00104: val_mDice did not improve from 0.57656
Epoch 105/300
 - 10s - loss: 2090.8337 - acc: 0.9497 - mDice: 0.7576 - val_loss: 4112.5474 - val_acc: 0.9419 - val_mDice: 0.5635

Epoch 00105: val_mDice did not improve from 0.57656
Epoch 106/300
 - 9s - loss: 2077.8218 - acc: 0.9496 - mDice: 0.7588 - val_loss: 3979.8836 - val_acc: 0.9416 - val_mDice: 0.5716

Epoch 00106: val_mDice did not improve from 0.57656
Epoch 107/300
 - 10s - loss: 2080.1438 - acc: 0.9496 - mDice: 0.7587 - val_loss: 4095.8861 - val_acc: 0.9410 - val_mDice: 0.5624

Epoch 00107: val_mDice did not improve from 0.57656
Epoch 108/300
 - 9s - loss: 2062.2250 - acc: 0.9498 - mDice: 0.7605 - val_loss: 4203.4091 - val_acc: 0.9428 - val_mDice: 0.5574

Epoch 00108: val_mDice did not improve from 0.57656
Epoch 109/300
 - 10s - loss: 2049.6089 - acc: 0.9498 - mDice: 0.7616 - val_loss: 4136.8634 - val_acc: 0.9427 - val_mDice: 0.5602

Epoch 00109: val_mDice did not improve from 0.57656
Epoch 110/300
 - 9s - loss: 2068.6789 - acc: 0.9498 - mDice: 0.7597 - val_loss: 4082.4513 - val_acc: 0.9419 - val_mDice: 0.5649

Epoch 00110: val_mDice did not improve from 0.57656
Epoch 111/300
 - 10s - loss: 2049.6859 - acc: 0.9500 - mDice: 0.7617 - val_loss: 4274.5212 - val_acc: 0.9431 - val_mDice: 0.5521

Epoch 00111: val_mDice did not improve from 0.57656
Epoch 112/300
 - 10s - loss: 2042.2683 - acc: 0.9500 - mDice: 0.7624 - val_loss: 4156.4415 - val_acc: 0.9432 - val_mDice: 0.5636

Epoch 00112: val_mDice did not improve from 0.57656
Restoring model weights from the end of the best epoch
Epoch 00112: early stopping
{'val_loss': [23964.531634990984, 13531.488459660457, 9545.395066481371, 6936.048105093149, 6214.480928861178, 5739.133343036358, 5473.391620342548, 5412.757075383113, 5236.403583233173, 4874.189126821665, 5016.188131479116, 4740.302102895884, 4765.048081618089, 4676.095939049354, 4609.724915724534, 4599.138288057768, 4492.469615055965, 4586.825077937199, 4423.5085050142725, 4419.78116431603, 4446.185411893404, 4379.479947603666, 4415.563496516301, 4350.0381587101865, 4345.0473867563105, 4292.391237699068, 4277.878615159255, 4301.102111816406, 4233.753063495343, 4335.181025578426, 4243.636627197266, 4313.840721717248, 4251.639324481671, 4164.884850135217, 4201.958233173077, 4253.590184138371, 4198.985438420223, 4194.805966890775, 4133.849315936749, 4112.7844003530645, 4137.028334397536, 4218.61367563101, 4542.8086829552285, 4028.9533174954927, 4121.408531775842, 4172.128943810096, 4137.640878530649, 4201.856182391827, 4129.850473257212, 4043.1856126051684, 4094.9668579101562, 3977.8799649752104, 4171.429166353666, 4154.941129244291, 4097.640742375301, 3977.0378136268027, 4160.823519193209, 4207.475388746995, 4040.5694580078125, 3946.6860774113584, 4220.3821364182695, 4021.127478966346, 4162.618835449219, 4078.0952993539663, 4058.5906865046572, 4149.5166250375605, 4211.939781775842, 4154.564889761118, 4137.329209547776, 4287.902348445012, 4147.367915226863, 4373.961975097656, 4011.4742384690503, 3986.4068744365986, 4388.53271484375, 4199.222444974459, 4017.494147667518, 4161.438462477464, 4073.074493408203, 4048.158367450421, 4280.749206542969, 3913.932412954477, 4052.531541090745, 4156.241271972656, 4108.767254169171, 3908.2988703801084, 4220.508958082933, 4130.639540452224, 4344.495431753306, 3901.2620966984678, 4046.0296067457934, 4057.120114839994, 4047.7878934420073, 4159.160095214844, 4927.58483182467, 4198.338921180139, 4153.781484750601, 3973.904296875, 4262.964594914363, 4150.513300969051, 4261.008990948017, 4173.135699932392, 4155.4495192307695, 4124.19634775015, 4112.547424316406, 3979.883591871995, 4095.8861318734976, 4203.409076397235, 4136.863408015324, 4082.4512775127705, 4274.521165114183, 4156.4414625901445], 'val_acc': [0.8777389778540685, 0.8774454593658447, 0.884638481415235, 0.9056397676467896, 0.9140648154112009, 0.9185280960339767, 0.9199403776572301, 0.9206661513218513, 0.922616972373082, 0.9249676443063296, 0.9234559788153722, 0.9274685703791105, 0.9277158700502836, 0.9289201291707846, 0.9279886117348304, 0.9276650272882901, 0.9305404149568998, 0.9289062321186066, 0.9326784243950477, 0.9321237321083362, 0.9320959563438709, 0.9330066648813394, 0.9347217105902158, 0.9330459420497601, 0.9336330661406884, 0.9340328940978417, 0.9351585599092337, 0.9342709894363697, 0.9346592953571906, 0.9358889850286337, 0.9373012162171878, 0.9340097950055049, 0.9356762996086707, 0.9369868750755603, 0.9365962537435385, 0.9358542882479154, 0.9366355492518499, 0.9376410131271069, 0.9380362194318038, 0.9398714739542741, 0.9397559326428634, 0.9381795365076798, 0.937368250810183, 0.9380292869531192, 0.9396126086895282, 0.9384846664392031, 0.9381495072291448, 0.9363234845491556, 0.9388914291675274, 0.9391433894634247, 0.9359143834847671, 0.9363350638976464, 0.9363004060891958, 0.9398483473521012, 0.9334527552127838, 0.9393306374549866, 0.9396264805243566, 0.9333557028036851, 0.9356369972229004, 0.9396935334572425, 0.9359444242257339, 0.9398252551372235, 0.9406596651444068, 0.9391410602973058, 0.9397189250359168, 0.9386556859199817, 0.9370492811386402, 0.940900050676786, 0.9413507695381458, 0.9360576707583207, 0.9402066537967095, 0.9406250142134153, 0.9395039861018841, 0.937703393972837, 0.9364506258414342, 0.9422037028349363, 0.9418361714253058, 0.9407567588182596, 0.9414478632119986, 0.9416350676463201, 0.9405348461407882, 0.9387273719677558, 0.940024027457604, 0.9398506925656245, 0.9414386199070857, 0.9430357538736783, 0.9417621837212489, 0.9397281798032614, 0.9431536885408255, 0.9443694307253911, 0.944864096549841, 0.9424232588364527, 0.9416674650632418, 0.9427052392409399, 0.9430265128612518, 0.9367973093803112, 0.941503304701585, 0.9391087064376245, 0.941838454741698, 0.9405695406290201, 0.9397651621928582, 0.9437130162349114, 0.9414640504580277, 0.9439349334973556, 0.9418893112586095, 0.9415726776306446, 0.94102720113901, 0.9428161795322711, 0.9427306904242589, 0.9419471163016099, 0.9431421160697937, 0.9432091139830076], 'val_mDice': [0.17119676139778817, 0.25382523181346744, 0.3081178223857513, 0.38857249170541763, 0.4259161725640297, 0.4531762869312213, 0.4698947392977201, 0.47337755388938463, 0.4840021546070392, 0.5078374691880666, 0.49683033904204, 0.5159035135920231, 0.5120469251504312, 0.5197271429575406, 0.5227571645608315, 0.5243156133936002, 0.5332941882885419, 0.5243389228215585, 0.5361530173283356, 0.5370538951112673, 0.5351967227000457, 0.5380403147293971, 0.5372107092004555, 0.5400712650555831, 0.5420813784003258, 0.5455696628643916, 0.5468609441931431, 0.5444039501822912, 0.5501739187882497, 0.5436340415707002, 0.5503714262292936, 0.5441563622309611, 0.5503310870665771, 0.5551445380999491, 0.5528890874523383, 0.5508288855736072, 0.5533276102863826, 0.5533390366114103, 0.5571570511047657, 0.558698409738449, 0.5582491778410398, 0.553204052723371, 0.5341776030567976, 0.5659234071007142, 0.5590553295153838, 0.5560950828859439, 0.5594274814312274, 0.5553797790064261, 0.5600185703772765, 0.5657443283842161, 0.5626549577483764, 0.5702367167060192, 0.5549617753579066, 0.5583773490328056, 0.5596547854634432, 0.5705480237419789, 0.5592131815277613, 0.5525599345564842, 0.565435508122811, 0.571551100565837, 0.5535921420042331, 0.5681157587812498, 0.5583393997870959, 0.5648032747782193, 0.5667616289395553, 0.5583197159262804, 0.5555788691227252, 0.5608104283993061, 0.5628557600654088, 0.5498448816629556, 0.5588516452564642, 0.5472779786930635, 0.5702694356441498, 0.5696106478571892, 0.5430163781230266, 0.5578542827413633, 0.5695455469764196, 0.557044661962069, 0.5646284024875897, 0.5649864556124577, 0.5519420951604843, 0.5765572952536436, 0.5666325957729266, 0.5592947109387472, 0.5649869453448516, 0.5764269490654652, 0.5578117880683678, 0.5627463230719933, 0.551382335046163, 0.576396657870366, 0.5686991191827334, 0.5682937118869561, 0.5683136261426486, 0.5616735231417876, 0.5297955968059026, 0.5567540778563573, 0.5607966035604477, 0.5725402746063012, 0.5549242324554003, 0.561412248473901, 0.5546572666901809, 0.5599538191006734, 0.5599337581258553, 0.560281637769479, 0.5634994638653902, 0.5715755648337878, 0.5624245932469001, 0.5573805891550504, 0.5602493286132812, 0.5648526572264158, 0.5520585391383904, 0.5635700334723179], 'loss': [35182.213256104165, 17606.98311289001, 12369.98306272444, 9510.057391870223, 7838.914307541264, 7024.774890883123, 6481.509558388044, 6087.558895959302, 5752.690205360926, 5488.730808605998, 5264.156444357823, 5054.32869879689, 4882.20082303513, 4743.00972950939, 4610.300653719566, 4467.935052739599, 4376.687702553635, 4245.190863029792, 4169.130243293124, 4068.8904430372168, 3983.2399614927435, 3905.3204836888935, 3852.7360474409616, 3763.2474062394626, 3721.3375256299246, 3655.2716830333725, 3573.349974482655, 3544.484543926039, 3492.969805289577, 3446.1535756097865, 3383.5981724848225, 3342.4920028353004, 3310.262537317963, 3264.9377868871875, 3233.25186425448, 3184.6190351376968, 3157.1374107782312, 3118.6816591331244, 3087.219770130895, 3052.318775695221, 3016.5684557208206, 3002.5520392170497, 2956.790161279166, 2925.3537073371967, 2903.690094188341, 2873.8642709505666, 2846.316458824782, 2817.238186615393, 2799.081319711684, 2781.6501640243127, 2756.6437112973053, 2733.1660967725434, 2716.067036280517, 2675.363157704892, 2671.64022821238, 2643.3644670533768, 2637.6699643738866, 2602.349899211779, 2593.3417278072725, 2571.747565190928, 2559.2886046265626, 2548.811391156197, 2516.4439011879604, 2504.0329432907465, 2497.9898177170394, 2476.994441922406, 2453.0461076783768, 2443.765252349496, 2429.0722234413365, 2424.8798373415057, 2408.448288435295, 2395.011275478167, 2384.093983473686, 2378.23086006624, 2362.287429501383, 2341.2801599908025, 2332.2415598336593, 2317.5060844671175, 2305.2906936354207, 2302.3749929581313, 2284.278623546279, 2284.6961609185055, 2261.5439052959987, 2267.347216451255, 2247.755697310702, 2238.0371761517276, 2220.0989554381554, 2227.5791887668383, 2197.122318449709, 2194.8060150188703, 2196.783190296528, 2180.0014290152185, 2163.8114635450293, 2168.4300269844853, 2155.175598769349, 2149.2791958346, 2143.928586559301, 2134.335896498425, 2143.476196221515, 2119.3909730686973, 2117.843112437892, 2105.2963655987733, 2088.5565461254887, 2094.651973187852, 2090.8337322018037, 2077.8218200677966, 2080.1437709139554, 2062.22501224756, 2049.6089032173245, 2068.6788565201105, 2049.6859176566786, 2042.2682659427453], 'acc': [0.8538106144667441, 0.8535263814807851, 0.8661881067826939, 0.8834596627655477, 0.8965511485888906, 0.9038257573095732, 0.908284233618649, 0.9116385799486413, 0.914268754026189, 0.9166338041096301, 0.918399388055943, 0.9200573397509497, 0.9218058294226605, 0.9229865374022455, 0.9240065612806602, 0.925215844259066, 0.9260213541047859, 0.9271402943291523, 0.9279772828428505, 0.9290463864489982, 0.9297078629376911, 0.930475041285373, 0.9310601377282692, 0.9318588864184345, 0.9321577787113445, 0.9327313947708396, 0.9337251650982542, 0.9338992863995205, 0.9346369375472775, 0.9350640306742795, 0.9353925380596406, 0.9360805246362297, 0.9363454299791926, 0.9366872644969747, 0.9371710267386225, 0.9375869257747165, 0.9378471755513096, 0.9383330656397467, 0.9384606301394224, 0.938899032889087, 0.9393159989928953, 0.9395952689398108, 0.939775037664357, 0.9401070298517936, 0.940313407930184, 0.9405897300830244, 0.9410242755276949, 0.9413208610884193, 0.9415522637616156, 0.9417184450843398, 0.9419246927449308, 0.9421804401967553, 0.9424637635068833, 0.9427650763706386, 0.9428771605991211, 0.9432659936074367, 0.9434247489928935, 0.943641904259502, 0.9438469031744752, 0.9440905007776889, 0.9440684225092424, 0.9442643543610348, 0.9447092760821875, 0.9448730428478522, 0.9449301289751292, 0.9451431791566675, 0.9453631446698622, 0.945360040374428, 0.9457343758103549, 0.9458079789657385, 0.94592762921862, 0.9460400695357938, 0.9459915662629792, 0.9463471876105006, 0.946320050786059, 0.9466064150159917, 0.9466751833897856, 0.9469533907820749, 0.9468172938744762, 0.9471121036202708, 0.9472664920790965, 0.9472710614075556, 0.9473970492673538, 0.9474981661532447, 0.947811975482864, 0.9477668367968729, 0.9479619052745887, 0.9478689948153388, 0.9481728728171767, 0.9482427746741895, 0.9481229697779558, 0.9483711566364789, 0.9485832768195473, 0.948490408072005, 0.9486502723138425, 0.9486959409496062, 0.9488924737127463, 0.9489116973788121, 0.9488777317409749, 0.9490841992895487, 0.9491341909084287, 0.9493005051336242, 0.9495220887620301, 0.9494174047995348, 0.9496572156250614, 0.9496413418136926, 0.9495948970367314, 0.9497562018166847, 0.9498144652112805, 0.949824061438154, 0.9499537983273136, 0.949986874831841], 'mDice': [0.0815525643254716, 0.16426236103499695, 0.2507909406026351, 0.3173386709920751, 0.37603820785488423, 0.4133923988159563, 0.4404739328969023, 0.4618051848727751, 0.4796334283577058, 0.49487935358842755, 0.5079365252464513, 0.5208222710409035, 0.5316715078260212, 0.5409831621325193, 0.549734430010552, 0.5592441116599242, 0.5658288980051456, 0.5747664206408162, 0.5802990921438812, 0.587661526469873, 0.5939287687319842, 0.5997207883505279, 0.6040214732499577, 0.6108176347009482, 0.614028953267982, 0.6192266053295021, 0.625498540296135, 0.6279099358850923, 0.6320460693627103, 0.6357668796324877, 0.6407692593797308, 0.6442894468412599, 0.6467371411531556, 0.650696502563688, 0.6535455520595229, 0.6574435335215768, 0.6597864739813291, 0.6630182121387764, 0.665780080559838, 0.6686091207714744, 0.671854177156102, 0.673089345420824, 0.6769272335877577, 0.6797019485056119, 0.6817789865432823, 0.6842991369990727, 0.6867481820325861, 0.6892522518830272, 0.6909142546819539, 0.6925260777470371, 0.6948081267382467, 0.6969244439234914, 0.6983719767211911, 0.7019868515013417, 0.7024056349558814, 0.7050343811825326, 0.70551155223229, 0.7087088221939883, 0.7094944763214377, 0.7116307029092619, 0.712740721016982, 0.7136238026385882, 0.7166600393642086, 0.7177461103122964, 0.7184824043178673, 0.720461267975548, 0.722605956812291, 0.7234707335028208, 0.7248038729156481, 0.7252536944596296, 0.7268899851077093, 0.7282564582930691, 0.7290823183507813, 0.7296890066985571, 0.731200804044584, 0.7332116759022388, 0.7339117008195332, 0.735544973190207, 0.7366062049154183, 0.7369439454686869, 0.7387263573349528, 0.7386519681986304, 0.7408480051972599, 0.7403396882221925, 0.7422366537291835, 0.7431473460439759, 0.7448485259320214, 0.7441807325548389, 0.7470542197076638, 0.7473337755183018, 0.7471497816198659, 0.7488181633086461, 0.7503478064326401, 0.7499221825604068, 0.7511713691251608, 0.7517909327303584, 0.7523184593649772, 0.7532161063597363, 0.752283703387031, 0.7548070391099809, 0.7548789255383554, 0.7561058472258946, 0.7577564675056174, 0.7572032241136135, 0.7576264154973708, 0.7588253927870693, 0.7586589332800185, 0.7604553979898548, 0.7616082241776397, 0.7597095592099121, 0.7616599938927305, 0.7623978814911185]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:42,  1.42s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:15,  1.54s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:16,  1.55s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:39,  1.63s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:19,  1.57s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:48,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:21,  1.81s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:07,  1.76s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:28,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:45,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:41,  1.91s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:56,  1.97s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:58,  1.99s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:55,  1.98s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:37,  1.92s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:45,  1.96s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:43,  1.96s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:45,  1.97s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:55,  2.02s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<09:00,  2.05s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<09:07,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<09:05,  2.08s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<09:17,  2.14s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<09:02,  2.09s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:47,  2.04s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:28,  1.97s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:23,  1.96s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:15,  1.94s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:14,  1.95s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:17,  1.97s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<08:20,  1.99s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<08:12,  1.96s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:04,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<07:51,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<08:03,  1.95s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<07:54,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:15<07:56,  1.94s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:47,  1.91s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:40,  1.89s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:35,  1.87s/it]predicting train subjects:  15%|█▌        | 43/285 [01:22<07:40,  1.90s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:26<07:35,  1.90s/it]predicting train subjects:  16%|█▌        | 46/285 [01:28<07:27,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:03,  1.79s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<06:59,  1.78s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<06:55,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<06:53,  1.77s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<06:42,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<06:38,  1.72s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<06:31,  1.70s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<06:29,  1.70s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:28,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:48<06:22,  1.68s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:20,  1.68s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:21,  1.69s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:20,  1.70s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:28,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:26,  1.74s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:42,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:45,  1.85s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:37,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:24,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:18,  1.76s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:06,  1.71s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:03,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<05:59,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<05:59,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<05:59,  1.73s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<05:54,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<05:49,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:26<05:44,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<05:44,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:31<05:45,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:33<05:39,  1.69s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:37<05:56,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:01,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:41<06:00,  1.83s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:02,  1.85s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<06:11,  1.91s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<06:07,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:48<06:01,  1.87s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<06:05,  1.90s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<06:05,  1.91s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<06:06,  1.93s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<06:13,  1.98s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<06:07,  1.96s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:58,  1.92s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<06:06,  1.98s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<06:04,  1.98s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<06:06,  2.00s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:59,  1.98s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:53,  1.95s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:42,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:42,  1.91s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:44,  1.94s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:34,  1.89s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:35,  1.91s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:36,  1.92s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:30,  1.90s/it]predicting train subjects:  39%|███▉      | 112/285 [03:27<05:39,  1.96s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:36,  1.95s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:30,  1.93s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:23,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:21,  1.90s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:17,  1.89s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<05:16,  1.90s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:15,  1.91s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<05:01,  1.84s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:55,  1.81s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:35,  1.70s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:37,  1.72s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:37,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:34,  1.73s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:29,  1.71s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:32,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [03:58<04:24,  1.69s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:22,  1.70s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:23,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:03<04:20,  1.70s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:16,  1.69s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:15,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:08<04:20,  1.73s/it]predicting train subjects:  48%|████▊     | 136/285 [04:10<04:21,  1.75s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<04:24,  1.79s/it]predicting train subjects:  48%|████▊     | 138/285 [04:13<04:19,  1.76s/it]predicting train subjects:  49%|████▉     | 139/285 [04:15<04:19,  1.77s/it]predicting train subjects:  49%|████▉     | 140/285 [04:17<04:19,  1.79s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<04:13,  1.76s/it]predicting train subjects:  50%|████▉     | 142/285 [04:20<04:05,  1.72s/it]predicting train subjects:  50%|█████     | 143/285 [04:22<03:55,  1.66s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:54,  1.66s/it]predicting train subjects:  51%|█████     | 145/285 [04:25<03:46,  1.62s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:30<03:39,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:21,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:34<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:15,  1.47s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:37<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:06,  1.43s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:39<03:04,  1.42s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:00,  1.40s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<02:56,  1.38s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<02:53,  1.37s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<02:51,  1.36s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<02:50,  1.36s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<02:49,  1.37s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<02:46,  1.36s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<02:45,  1.36s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<02:45,  1.37s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<02:42,  1.35s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<02:41,  1.36s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<02:41,  1.37s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<02:36,  1.34s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:58<02:33,  1.33s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<02:32,  1.32s/it]predicting train subjects:  60%|██████    | 171/285 [05:01<02:30,  1.32s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:29,  1.32s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:27,  1.32s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:27,  1.33s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:26,  1.33s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:25,  1.33s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:24,  1.34s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:21,  1.33s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:11<02:19,  1.31s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:13<02:16,  1.30s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:14<02:13,  1.29s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:15<02:11,  1.28s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:17<02:11,  1.28s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:18<02:08,  1.27s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:19<02:07,  1.27s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:20<02:06,  1.28s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:22<02:06,  1.29s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:03,  1.27s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:01,  1.26s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:25<01:59,  1.25s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<01:58,  1.26s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:28<01:57,  1.26s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:29<01:57,  1.28s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:30<01:56,  1.28s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:32<01:56,  1.30s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:33<02:03,  1.39s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:35<02:06,  1.44s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:37<02:09,  1.49s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:38<02:09,  1.50s/it]predicting train subjects:  70%|███████   | 200/285 [05:40<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:41<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 202/285 [05:43<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:44<02:07,  1.55s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:46<02:05,  1.55s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:48<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<02:04,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:51<02:02,  1.57s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:52<02:00,  1.57s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:54<01:57,  1.54s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:55<01:53,  1.52s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:57<01:51,  1.51s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:58<01:51,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:00<01:50,  1.53s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:01<01:44,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:03<01:40,  1.43s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:04<01:36,  1.40s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:05<01:34,  1.39s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:07<01:32,  1.38s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:08<01:30,  1.37s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:09<01:29,  1.37s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:11<01:26,  1.35s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:12<01:25,  1.35s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:13<01:23,  1.35s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:15<01:22,  1.35s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:16<01:20,  1.34s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:18,  1.34s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:19<01:17,  1.34s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:16,  1.34s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:15,  1.35s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:15,  1.37s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:14,  1.37s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:18,  1.48s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:29<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:23,  1.66s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:23,  1.69s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:36<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:38<01:19,  1.73s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:40<01:17,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:42<01:15,  1.73s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:43<01:14,  1.72s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:45<01:11,  1.71s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:47<01:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:48<01:08,  1.71s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:50<01:05,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:52<01:03,  1.68s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:53<01:03,  1.71s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:55<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:56<00:55,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:58<00:50,  1.48s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:59<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:00<00:44,  1.38s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:01<00:41,  1.34s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:03<00:39,  1.32s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:04<00:38,  1.32s/it]predicting train subjects:  90%|█████████ | 257/285 [07:05<00:37,  1.32s/it]predicting train subjects:  91%|█████████ | 258/285 [07:07<00:35,  1.31s/it]predicting train subjects:  91%|█████████ | 259/285 [07:08<00:33,  1.28s/it]predicting train subjects:  91%|█████████ | 260/285 [07:09<00:32,  1.30s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:11<00:31,  1.30s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:12<00:29,  1.29s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:13<00:28,  1.30s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:14<00:27,  1.29s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:16<00:25,  1.26s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:17<00:23,  1.25s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:18<00:22,  1.24s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:20<00:23,  1.37s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:21<00:23,  1.47s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:23<00:23,  1.54s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:25<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:26<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:28<00:19,  1.62s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:30<00:18,  1.68s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:32<00:16,  1.69s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:33<00:15,  1.70s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:35<00:13,  1.69s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:37<00:11,  1.71s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:39<00:10,  1.73s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:40<00:08,  1.74s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:42<00:06,  1.74s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:44<00:05,  1.73s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:45<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:47<00:01,  1.70s/it]predicting train subjects: 100%|██████████| 285/285 [07:49<00:00,  1.70s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:56,  1.47s/it]Loading train:   1%|          | 2/285 [00:02<06:46,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:26,  1.37s/it]Loading train:   1%|▏         | 4/285 [00:05<06:43,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:06<06:07,  1.31s/it]Loading train:   2%|▏         | 6/285 [00:08<06:26,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:44,  1.45s/it]Loading train:   3%|▎         | 8/285 [00:11<06:49,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:12<06:39,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<05:56,  1.30s/it]Loading train:   4%|▍         | 11/285 [00:14<05:30,  1.21s/it]Loading train:   4%|▍         | 12/285 [00:15<05:13,  1.15s/it]Loading train:   5%|▍         | 13/285 [00:16<05:00,  1.11s/it]Loading train:   5%|▍         | 14/285 [00:17<04:48,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:42,  1.05s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.03s/it]Loading train:   6%|▌         | 17/285 [00:20<04:31,  1.01s/it]Loading train:   6%|▋         | 18/285 [00:21<04:30,  1.01s/it]Loading train:   7%|▋         | 19/285 [00:22<04:33,  1.03s/it]Loading train:   7%|▋         | 20/285 [00:23<04:24,  1.00it/s]Loading train:   7%|▋         | 21/285 [00:24<04:30,  1.02s/it]Loading train:   8%|▊         | 22/285 [00:25<04:26,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:26<04:35,  1.05s/it]Loading train:   8%|▊         | 24/285 [00:27<04:27,  1.03s/it]Loading train:   9%|▉         | 25/285 [00:28<04:27,  1.03s/it]Loading train:   9%|▉         | 26/285 [00:29<04:27,  1.03s/it]Loading train:   9%|▉         | 27/285 [00:30<04:29,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:32<04:29,  1.05s/it]Loading train:  10%|█         | 29/285 [00:33<04:25,  1.04s/it]Loading train:  11%|█         | 30/285 [00:34<04:24,  1.04s/it]Loading train:  11%|█         | 31/285 [00:34<04:11,  1.01it/s]Loading train:  11%|█         | 32/285 [00:36<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:15,  1.02s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:08,  1.01it/s]Loading train:  12%|█▏        | 35/285 [00:38<04:06,  1.02it/s]Loading train:  13%|█▎        | 36/285 [00:39<03:57,  1.05it/s]Loading train:  13%|█▎        | 37/285 [00:40<04:01,  1.03it/s]Loading train:  13%|█▎        | 38/285 [00:41<04:07,  1.00s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:05,  1.00it/s]Loading train:  14%|█▍        | 40/285 [00:43<04:06,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:45<04:14,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:46<04:05,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:47<04:06,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:48<03:58,  1.01it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:52,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:43,  1.07it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:30,  1.13it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:17,  1.20it/s]Loading train:  17%|█▋        | 49/285 [00:52<03:12,  1.23it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:07,  1.25it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:22,  1.15it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:20,  1.16it/s]Loading train:  19%|█▊        | 53/285 [00:55<03:24,  1.14it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:14,  1.18it/s]Loading train:  19%|█▉        | 55/285 [00:57<03:12,  1.19it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:08,  1.22it/s]Loading train:  20%|██        | 57/285 [00:58<03:10,  1.20it/s]Loading train:  20%|██        | 58/285 [00:59<03:03,  1.24it/s]Loading train:  21%|██        | 59/285 [01:00<02:58,  1.27it/s]Loading train:  21%|██        | 60/285 [01:01<02:58,  1.26it/s]Loading train:  21%|██▏       | 61/285 [01:01<02:58,  1.25it/s]Loading train:  22%|██▏       | 62/285 [01:02<02:57,  1.26it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:01,  1.22it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:36,  1.02it/s]Loading train:  23%|██▎       | 65/285 [01:06<04:17,  1.17s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:26,  1.22s/it]Loading train:  24%|██▎       | 67/285 [01:08<03:59,  1.10s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:46,  1.04s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:29,  1.03it/s]Loading train:  25%|██▍       | 70/285 [01:11<03:21,  1.07it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:11,  1.12it/s]Loading train:  25%|██▌       | 72/285 [01:12<03:03,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:13<03:10,  1.12it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:02,  1.16it/s]Loading train:  26%|██▋       | 75/285 [01:15<02:56,  1.19it/s]Loading train:  27%|██▋       | 76/285 [01:16<02:59,  1.17it/s]Loading train:  27%|██▋       | 77/285 [01:17<02:55,  1.19it/s]Loading train:  27%|██▋       | 78/285 [01:17<02:50,  1.22it/s]Loading train:  28%|██▊       | 79/285 [01:18<02:44,  1.25it/s]Loading train:  28%|██▊       | 80/285 [01:19<02:46,  1.23it/s]Loading train:  28%|██▊       | 81/285 [01:20<02:41,  1.26it/s]Loading train:  29%|██▉       | 82/285 [01:21<02:41,  1.26it/s]Loading train:  29%|██▉       | 83/285 [01:21<02:43,  1.23it/s]Loading train:  29%|██▉       | 84/285 [01:22<02:41,  1.24it/s]Loading train:  30%|██▉       | 85/285 [01:23<02:50,  1.17it/s]Loading train:  30%|███       | 86/285 [01:24<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:25<03:09,  1.05it/s]Loading train:  31%|███       | 88/285 [01:26<03:13,  1.02it/s]Loading train:  31%|███       | 89/285 [01:27<03:17,  1.01s/it]Loading train:  32%|███▏      | 90/285 [01:28<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:29<03:10,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:30<03:14,  1.01s/it]Loading train:  33%|███▎      | 93/285 [01:31<03:11,  1.00it/s]Loading train:  33%|███▎      | 94/285 [01:32<03:13,  1.01s/it]Loading train:  33%|███▎      | 95/285 [01:33<03:08,  1.01it/s]Loading train:  34%|███▎      | 96/285 [01:34<03:08,  1.00it/s]Loading train:  34%|███▍      | 97/285 [01:35<03:06,  1.01it/s]Loading train:  34%|███▍      | 98/285 [01:36<03:06,  1.00it/s]Loading train:  35%|███▍      | 99/285 [01:37<03:04,  1.01it/s]Loading train:  35%|███▌      | 100/285 [01:38<03:05,  1.00s/it]Loading train:  35%|███▌      | 101/285 [01:39<03:06,  1.01s/it]Loading train:  36%|███▌      | 102/285 [01:40<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:41<03:03,  1.01s/it]Loading train:  36%|███▋      | 104/285 [01:42<03:05,  1.03s/it]Loading train:  37%|███▋      | 105/285 [01:43<02:58,  1.01it/s]Loading train:  37%|███▋      | 106/285 [01:44<03:01,  1.01s/it]Loading train:  38%|███▊      | 107/285 [01:45<02:51,  1.04it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:49,  1.04it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:44,  1.07it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:43,  1.07it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:40,  1.09it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:36,  1.10it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:38,  1.09it/s]Loading train:  40%|████      | 114/285 [01:52<02:37,  1.08it/s]Loading train:  40%|████      | 115/285 [01:53<02:35,  1.09it/s]Loading train:  41%|████      | 116/285 [01:53<02:29,  1.13it/s]Loading train:  41%|████      | 117/285 [01:54<02:27,  1.14it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:24,  1.15it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:22,  1.16it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:48,  1.03s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:44,  1.02s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:29,  1.07it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:27,  1.08it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:18,  1.14it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:13,  1.18it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:10,  1.19it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:11,  1.18it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:04,  1.24it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:04,  1.23it/s]Loading train:  47%|████▋     | 133/285 [02:08<02:03,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:09<02:02,  1.23it/s]Loading train:  47%|████▋     | 135/285 [02:10<02:01,  1.24it/s]Loading train:  48%|████▊     | 136/285 [02:11<02:02,  1.21it/s]Loading train:  48%|████▊     | 137/285 [02:12<01:57,  1.26it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:55,  1.28it/s]Loading train:  49%|████▉     | 139/285 [02:13<01:59,  1.23it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:55,  1.25it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:57,  1.22it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:54,  1.25it/s]Loading train:  50%|█████     | 143/285 [02:17<01:54,  1.24it/s]Loading train:  51%|█████     | 144/285 [02:17<01:52,  1.26it/s]Loading train:  51%|█████     | 145/285 [02:18<01:53,  1.23it/s]Loading train:  51%|█████     | 146/285 [02:19<01:53,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:20<01:52,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:21<01:47,  1.27it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:43,  1.31it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:48,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:43,  1.30it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:46,  1.24it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:42,  1.29it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:44,  1.26it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:39,  1.31it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:37,  1.33it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:37,  1.31it/s]Loading train:  55%|█████▌    | 158/285 [02:28<01:33,  1.36it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:37,  1.29it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:38,  1.27it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:43,  1.20it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:40,  1.22it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:37,  1.25it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:34,  1.29it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:29,  1.34it/s]Loading train:  58%|█████▊    | 166/285 [02:35<01:35,  1.25it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:31,  1.28it/s]Loading train:  59%|█████▉    | 168/285 [02:36<01:29,  1.30it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:31,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [02:38<01:27,  1.31it/s]Loading train:  60%|██████    | 171/285 [02:38<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:39<01:27,  1.29it/s]Loading train:  61%|██████    | 173/285 [02:40<01:23,  1.34it/s]Loading train:  61%|██████    | 174/285 [02:41<01:20,  1.37it/s]Loading train:  61%|██████▏   | 175/285 [02:41<01:23,  1.32it/s]Loading train:  62%|██████▏   | 176/285 [02:42<01:21,  1.34it/s]Loading train:  62%|██████▏   | 177/285 [02:43<01:19,  1.36it/s]Loading train:  62%|██████▏   | 178/285 [02:44<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [02:44<01:23,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [02:45<01:20,  1.31it/s]Loading train:  64%|██████▎   | 181/285 [02:46<01:21,  1.27it/s]Loading train:  64%|██████▍   | 182/285 [02:47<01:18,  1.32it/s]Loading train:  64%|██████▍   | 183/285 [02:47<01:17,  1.32it/s]Loading train:  65%|██████▍   | 184/285 [02:48<01:16,  1.31it/s]Loading train:  65%|██████▍   | 185/285 [02:49<01:15,  1.32it/s]Loading train:  65%|██████▌   | 186/285 [02:50<01:12,  1.36it/s]Loading train:  66%|██████▌   | 187/285 [02:50<01:10,  1.39it/s]Loading train:  66%|██████▌   | 188/285 [02:51<01:07,  1.44it/s]Loading train:  66%|██████▋   | 189/285 [02:52<01:05,  1.46it/s]Loading train:  67%|██████▋   | 190/285 [02:52<01:07,  1.42it/s]Loading train:  67%|██████▋   | 191/285 [02:53<01:02,  1.50it/s]Loading train:  67%|██████▋   | 192/285 [02:54<01:01,  1.51it/s]Loading train:  68%|██████▊   | 193/285 [02:55<01:08,  1.34it/s]Loading train:  68%|██████▊   | 194/285 [02:55<01:07,  1.34it/s]Loading train:  68%|██████▊   | 195/285 [02:56<01:06,  1.36it/s]Loading train:  69%|██████▉   | 196/285 [02:57<01:09,  1.28it/s]Loading train:  69%|██████▉   | 197/285 [02:58<01:08,  1.28it/s]Loading train:  69%|██████▉   | 198/285 [02:59<01:11,  1.22it/s]Loading train:  70%|██████▉   | 199/285 [02:59<01:08,  1.26it/s]Loading train:  70%|███████   | 200/285 [03:00<01:07,  1.26it/s]Loading train:  71%|███████   | 201/285 [03:01<01:08,  1.22it/s]Loading train:  71%|███████   | 202/285 [03:02<01:07,  1.23it/s]Loading train:  71%|███████   | 203/285 [03:03<01:06,  1.24it/s]Loading train:  72%|███████▏  | 204/285 [03:03<01:03,  1.27it/s]Loading train:  72%|███████▏  | 205/285 [03:04<01:01,  1.30it/s]Loading train:  72%|███████▏  | 206/285 [03:05<01:01,  1.29it/s]Loading train:  73%|███████▎  | 207/285 [03:06<01:02,  1.26it/s]Loading train:  73%|███████▎  | 208/285 [03:07<01:02,  1.24it/s]Loading train:  73%|███████▎  | 209/285 [03:07<01:03,  1.20it/s]Loading train:  74%|███████▎  | 210/285 [03:08<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [03:09<01:01,  1.20it/s]Loading train:  74%|███████▍  | 212/285 [03:10<00:59,  1.23it/s]Loading train:  75%|███████▍  | 213/285 [03:11<00:58,  1.23it/s]Loading train:  75%|███████▌  | 214/285 [03:12<01:00,  1.17it/s]Loading train:  75%|███████▌  | 215/285 [03:12<00:56,  1.24it/s]Loading train:  76%|███████▌  | 216/285 [03:13<00:54,  1.28it/s]Loading train:  76%|███████▌  | 217/285 [03:14<00:53,  1.26it/s]Loading train:  76%|███████▋  | 218/285 [03:15<00:52,  1.28it/s]Loading train:  77%|███████▋  | 219/285 [03:15<00:50,  1.30it/s]Loading train:  77%|███████▋  | 220/285 [03:16<00:51,  1.26it/s]Loading train:  78%|███████▊  | 221/285 [03:17<00:48,  1.31it/s]Loading train:  78%|███████▊  | 222/285 [03:18<00:46,  1.34it/s]Loading train:  78%|███████▊  | 223/285 [03:18<00:46,  1.34it/s]Loading train:  79%|███████▊  | 224/285 [03:19<00:47,  1.28it/s]Loading train:  79%|███████▉  | 225/285 [03:20<00:45,  1.31it/s]Loading train:  79%|███████▉  | 226/285 [03:21<00:43,  1.35it/s]Loading train:  80%|███████▉  | 227/285 [03:21<00:44,  1.31it/s]Loading train:  80%|████████  | 228/285 [03:22<00:43,  1.32it/s]Loading train:  80%|████████  | 229/285 [03:23<00:42,  1.32it/s]Loading train:  81%|████████  | 230/285 [03:24<00:41,  1.32it/s]Loading train:  81%|████████  | 231/285 [03:25<00:43,  1.25it/s]Loading train:  81%|████████▏ | 232/285 [03:26<00:44,  1.20it/s]Loading train:  82%|████████▏ | 233/285 [03:26<00:44,  1.16it/s]Loading train:  82%|████████▏ | 234/285 [03:27<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:28<00:45,  1.10it/s]Loading train:  83%|████████▎ | 236/285 [03:29<00:46,  1.05it/s]Loading train:  83%|████████▎ | 237/285 [03:30<00:44,  1.07it/s]Loading train:  84%|████████▎ | 238/285 [03:31<00:43,  1.09it/s]Loading train:  84%|████████▍ | 239/285 [03:32<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:33<00:42,  1.06it/s]Loading train:  85%|████████▍ | 241/285 [03:34<00:41,  1.07it/s]Loading train:  85%|████████▍ | 242/285 [03:35<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [03:36<00:40,  1.05it/s]Loading train:  86%|████████▌ | 244/285 [03:37<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [03:38<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [03:39<00:36,  1.06it/s]Loading train:  87%|████████▋ | 247/285 [03:40<00:35,  1.06it/s]Loading train:  87%|████████▋ | 248/285 [03:41<00:36,  1.02it/s]Loading train:  87%|████████▋ | 249/285 [03:42<00:33,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [03:43<00:31,  1.11it/s]Loading train:  88%|████████▊ | 251/285 [03:43<00:29,  1.17it/s]Loading train:  88%|████████▊ | 252/285 [03:44<00:27,  1.21it/s]Loading train:  89%|████████▉ | 253/285 [03:45<00:24,  1.29it/s]Loading train:  89%|████████▉ | 254/285 [03:45<00:23,  1.30it/s]Loading train:  89%|████████▉ | 255/285 [03:46<00:21,  1.37it/s]Loading train:  90%|████████▉ | 256/285 [03:47<00:20,  1.40it/s]Loading train:  90%|█████████ | 257/285 [03:48<00:20,  1.37it/s]Loading train:  91%|█████████ | 258/285 [03:48<00:19,  1.36it/s]Loading train:  91%|█████████ | 259/285 [03:49<00:18,  1.40it/s]Loading train:  91%|█████████ | 260/285 [03:50<00:19,  1.30it/s]Loading train:  92%|█████████▏| 261/285 [03:51<00:18,  1.27it/s]Loading train:  92%|█████████▏| 262/285 [03:52<00:18,  1.23it/s]Loading train:  92%|█████████▏| 263/285 [03:52<00:17,  1.26it/s]Loading train:  93%|█████████▎| 264/285 [03:53<00:15,  1.32it/s]Loading train:  93%|█████████▎| 265/285 [03:54<00:15,  1.29it/s]Loading train:  93%|█████████▎| 266/285 [03:54<00:14,  1.33it/s]Loading train:  94%|█████████▎| 267/285 [03:55<00:13,  1.34it/s]Loading train:  94%|█████████▍| 268/285 [03:56<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [03:57<00:13,  1.18it/s]Loading train:  95%|█████████▍| 270/285 [03:58<00:13,  1.12it/s]Loading train:  95%|█████████▌| 271/285 [03:59<00:12,  1.13it/s]Loading train:  95%|█████████▌| 272/285 [04:00<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [04:01<00:11,  1.07it/s]Loading train:  96%|█████████▌| 274/285 [04:02<00:10,  1.04it/s]Loading train:  96%|█████████▋| 275/285 [04:03<00:10,  1.01s/it]Loading train:  97%|█████████▋| 276/285 [04:04<00:09,  1.03s/it]Loading train:  97%|█████████▋| 277/285 [04:05<00:08,  1.04s/it]Loading train:  98%|█████████▊| 278/285 [04:06<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:07<00:06,  1.05s/it]Loading train:  98%|█████████▊| 280/285 [04:08<00:05,  1.03s/it]Loading train:  99%|█████████▊| 281/285 [04:09<00:04,  1.02s/it]Loading train:  99%|█████████▉| 282/285 [04:10<00:03,  1.04s/it]Loading train:  99%|█████████▉| 283/285 [04:11<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [04:12<00:00,  1.01it/s]Loading train: 100%|██████████| 285/285 [04:13<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 60.51it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:03, 76.86it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:02, 99.54it/s]concatenating: train:  32%|███▏      | 92/285 [00:00<00:01, 125.45it/s]concatenating: train:  44%|████▎     | 124/285 [00:00<00:01, 153.42it/s]concatenating: train:  55%|█████▌    | 157/285 [00:00<00:00, 182.51it/s]concatenating: train:  68%|██████▊   | 194/285 [00:00<00:00, 214.93it/s]concatenating: train:  81%|████████  | 230/285 [00:00<00:00, 244.37it/s]concatenating: train:  93%|█████████▎| 264/285 [00:00<00:00, 265.83it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 289.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.31s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 514.13it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________2019-07-07 04:33:06.126880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 04:33:06.126990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 04:33:06.127006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 04:33:06.127016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 04:33:06.127471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_3 (Dropout)             (None, 13, 20, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 20s - loss: 14027.0852 - acc: 0.8640 - mDice: 0.1664 - val_loss: 9137.4275 - val_acc: 0.8971 - val_mDice: 0.2655

Epoch 00001: val_mDice improved from -inf to 0.26548, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 6418.7477 - acc: 0.8767 - mDice: 0.3213 - val_loss: 4851.3806 - val_acc: 0.9056 - val_mDice: 0.3733

Epoch 00002: val_mDice improved from 0.26548 to 0.37330, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 4395.4019 - acc: 0.8891 - mDice: 0.4270 - val_loss: 4202.6926 - val_acc: 0.9153 - val_mDice: 0.4184

Epoch 00003: val_mDice improved from 0.37330 to 0.41840, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 3553.2984 - acc: 0.9014 - mDice: 0.4931 - val_loss: 3703.8902 - val_acc: 0.9260 - val_mDice: 0.4531

Epoch 00004: val_mDice improved from 0.41840 to 0.45305, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 3125.1539 - acc: 0.9102 - mDice: 0.5340 - val_loss: 3447.8843 - val_acc: 0.9283 - val_mDice: 0.4759

Epoch 00005: val_mDice improved from 0.45305 to 0.47586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 2876.0141 - acc: 0.9152 - mDice: 0.5607 - val_loss: 3263.1103 - val_acc: 0.9332 - val_mDice: 0.4896

Epoch 00006: val_mDice improved from 0.47586 to 0.48964, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 11s - loss: 2695.1156 - acc: 0.9191 - mDice: 0.5807 - val_loss: 3148.1996 - val_acc: 0.9337 - val_mDice: 0.5002

Epoch 00007: val_mDice improved from 0.48964 to 0.50018, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 2569.4723 - acc: 0.9220 - mDice: 0.5952 - val_loss: 3091.8203 - val_acc: 0.9341 - val_mDice: 0.5052

Epoch 00008: val_mDice improved from 0.50018 to 0.50523, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 2449.5549 - acc: 0.9243 - mDice: 0.6093 - val_loss: 3032.4577 - val_acc: 0.9360 - val_mDice: 0.5102

Epoch 00009: val_mDice improved from 0.50523 to 0.51021, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 2352.9550 - acc: 0.9265 - mDice: 0.6215 - val_loss: 2926.5014 - val_acc: 0.9362 - val_mDice: 0.5199

Epoch 00010: val_mDice improved from 0.51021 to 0.51987, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 2277.2264 - acc: 0.9279 - mDice: 0.6306 - val_loss: 2994.2425 - val_acc: 0.9356 - val_mDice: 0.5123

Epoch 00011: val_mDice did not improve from 0.51987
Epoch 12/300
 - 11s - loss: 2206.4507 - acc: 0.9294 - mDice: 0.6396 - val_loss: 2954.3256 - val_acc: 0.9381 - val_mDice: 0.5167

Epoch 00012: val_mDice did not improve from 0.51987
Epoch 13/300
 - 11s - loss: 2137.6187 - acc: 0.9306 - mDice: 0.6484 - val_loss: 2944.2693 - val_acc: 0.9373 - val_mDice: 0.5175

Epoch 00013: val_mDice did not improve from 0.51987
Epoch 14/300
 - 11s - loss: 2068.3425 - acc: 0.9320 - mDice: 0.6574 - val_loss: 2896.5174 - val_acc: 0.9367 - val_mDice: 0.5231

Epoch 00014: val_mDice improved from 0.51987 to 0.52311, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 11s - loss: 2011.7551 - acc: 0.9332 - mDice: 0.6648 - val_loss: 2953.0848 - val_acc: 0.9387 - val_mDice: 0.5172

Epoch 00015: val_mDice did not improve from 0.52311
Epoch 16/300
 - 11s - loss: 1959.5435 - acc: 0.9343 - mDice: 0.6717 - val_loss: 2925.1795 - val_acc: 0.9391 - val_mDice: 0.5206

Epoch 00016: val_mDice did not improve from 0.52311
Epoch 17/300
 - 11s - loss: 1921.9489 - acc: 0.9349 - mDice: 0.6767 - val_loss: 2803.0872 - val_acc: 0.9393 - val_mDice: 0.5323

Epoch 00017: val_mDice improved from 0.52311 to 0.53234, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 1875.1819 - acc: 0.9360 - mDice: 0.6830 - val_loss: 2780.1454 - val_acc: 0.9398 - val_mDice: 0.5346

Epoch 00018: val_mDice improved from 0.53234 to 0.53458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 1837.2538 - acc: 0.9367 - mDice: 0.6882 - val_loss: 2876.0346 - val_acc: 0.9405 - val_mDice: 0.5241

Epoch 00019: val_mDice did not improve from 0.53458
Epoch 20/300
 - 11s - loss: 1795.6654 - acc: 0.9376 - mDice: 0.6941 - val_loss: 2894.7588 - val_acc: 0.9386 - val_mDice: 0.5240

Epoch 00020: val_mDice did not improve from 0.53458
Epoch 21/300
 - 11s - loss: 1752.2049 - acc: 0.9383 - mDice: 0.7001 - val_loss: 2680.2441 - val_acc: 0.9410 - val_mDice: 0.5454

Epoch 00021: val_mDice improved from 0.53458 to 0.54539, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 11s - loss: 1728.5980 - acc: 0.9390 - mDice: 0.7034 - val_loss: 2689.5132 - val_acc: 0.9401 - val_mDice: 0.5448

Epoch 00022: val_mDice did not improve from 0.54539
Epoch 23/300
 - 11s - loss: 1702.3489 - acc: 0.9396 - mDice: 0.7072 - val_loss: 2769.2043 - val_acc: 0.9408 - val_mDice: 0.5360

Epoch 00023: val_mDice did not improve from 0.54539
Epoch 24/300
 - 11s - loss: 1662.8743 - acc: 0.9404 - mDice: 0.7127 - val_loss: 2798.0257 - val_acc: 0.9403 - val_mDice: 0.5334

Epoch 00024: val_mDice did not improve from 0.54539
Epoch 25/300
 - 11s - loss: 1633.9931 - acc: 0.9407 - mDice: 0.7169 - val_loss: 2742.8403 - val_acc: 0.9412 - val_mDice: 0.5408

Epoch 00025: val_mDice did not improve from 0.54539
Epoch 26/300
 - 11s - loss: 1615.2815 - acc: 0.9415 - mDice: 0.7195 - val_loss: 2681.7558 - val_acc: 0.9427 - val_mDice: 0.5475

Epoch 00026: val_mDice improved from 0.54539 to 0.54745, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 1587.2670 - acc: 0.9419 - mDice: 0.7236 - val_loss: 2743.6736 - val_acc: 0.9440 - val_mDice: 0.5380

Epoch 00027: val_mDice did not improve from 0.54745
Epoch 28/300
 - 11s - loss: 1564.9591 - acc: 0.9424 - mDice: 0.7269 - val_loss: 2726.8950 - val_acc: 0.9397 - val_mDice: 0.5419

Epoch 00028: val_mDice did not improve from 0.54745
Epoch 29/300
 - 11s - loss: 1541.9362 - acc: 0.9428 - mDice: 0.7303 - val_loss: 2938.4613 - val_acc: 0.9417 - val_mDice: 0.5161

Epoch 00029: val_mDice did not improve from 0.54745
Epoch 30/300
 - 11s - loss: 1517.8809 - acc: 0.9432 - mDice: 0.7338 - val_loss: 2763.3543 - val_acc: 0.9436 - val_mDice: 0.5376

Epoch 00030: val_mDice did not improve from 0.54745
Epoch 31/300
 - 11s - loss: 1490.1668 - acc: 0.9438 - mDice: 0.7378 - val_loss: 2835.8615 - val_acc: 0.9428 - val_mDice: 0.5270

Epoch 00031: val_mDice did not improve from 0.54745
Epoch 32/300
 - 11s - loss: 1471.7743 - acc: 0.9443 - mDice: 0.7406 - val_loss: 2788.3150 - val_acc: 0.9431 - val_mDice: 0.5335

Epoch 00032: val_mDice did not improve from 0.54745
Epoch 33/300
 - 11s - loss: 1453.0968 - acc: 0.9447 - mDice: 0.7434 - val_loss: 2939.8424 - val_acc: 0.9428 - val_mDice: 0.5167

Epoch 00033: val_mDice did not improve from 0.54745
Epoch 34/300
 - 11s - loss: 1434.1806 - acc: 0.9449 - mDice: 0.7462 - val_loss: 2773.4422 - val_acc: 0.9438 - val_mDice: 0.5390

Epoch 00034: val_mDice did not improve from 0.54745
Epoch 35/300
 - 12s - loss: 1417.1528 - acc: 0.9454 - mDice: 0.7488 - val_loss: 2779.1117 - val_acc: 0.9441 - val_mDice: 0.5366

Epoch 00035: val_mDice did not improve from 0.54745
Epoch 36/300
 - 11s - loss: 1405.4252 - acc: 0.9456 - mDice: 0.7505 - val_loss: 2778.6673 - val_acc: 0.9435 - val_mDice: 0.5373

Epoch 00036: val_mDice did not improve from 0.54745
Epoch 37/300
 - 11s - loss: 1388.1507 - acc: 0.9459 - mDice: 0.7532 - val_loss: 2828.9680 - val_acc: 0.9448 - val_mDice: 0.5298

Epoch 00037: val_mDice did not improve from 0.54745
Epoch 38/300
 - 12s - loss: 1368.5993 - acc: 0.9463 - mDice: 0.7561 - val_loss: 2647.3247 - val_acc: 0.9450 - val_mDice: 0.5491

Epoch 00038: val_mDice improved from 0.54745 to 0.54915, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 39/300
 - 11s - loss: 1354.6129 - acc: 0.9468 - mDice: 0.7583 - val_loss: 3092.5715 - val_acc: 0.9422 - val_mDice: 0.4993

Epoch 00039: val_mDice did not improve from 0.54915
Epoch 40/300
 - 11s - loss: 1346.1605 - acc: 0.9470 - mDice: 0.7596 - val_loss: 2905.7638 - val_acc: 0.9433 - val_mDice: 0.5243

Epoch 00040: val_mDice did not improve from 0.54915
Epoch 41/300
 - 11s - loss: 1330.8878 - acc: 0.9473 - mDice: 0.7620 - val_loss: 2700.7934 - val_acc: 0.9455 - val_mDice: 0.5443

Epoch 00041: val_mDice did not improve from 0.54915
Epoch 42/300
 - 12s - loss: 1311.3625 - acc: 0.9476 - mDice: 0.7649 - val_loss: 2881.6225 - val_acc: 0.9451 - val_mDice: 0.5242

Epoch 00042: val_mDice did not improve from 0.54915
Epoch 43/300
 - 12s - loss: 1305.2355 - acc: 0.9478 - mDice: 0.7659 - val_loss: 2649.0483 - val_acc: 0.9445 - val_mDice: 0.5500

Epoch 00043: val_mDice improved from 0.54915 to 0.54997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 44/300
 - 14s - loss: 1293.2782 - acc: 0.9480 - mDice: 0.7678 - val_loss: 2822.8284 - val_acc: 0.9446 - val_mDice: 0.5315

Epoch 00044: val_mDice did not improve from 0.54997
Epoch 45/300
 - 13s - loss: 1282.8747 - acc: 0.9483 - mDice: 0.7694 - val_loss: 2816.4571 - val_acc: 0.9439 - val_mDice: 0.5318

Epoch 00045: val_mDice did not improve from 0.54997
Epoch 46/300
 - 14s - loss: 1271.6568 - acc: 0.9485 - mDice: 0.7711 - val_loss: 2893.3554 - val_acc: 0.9429 - val_mDice: 0.5225

Epoch 00046: val_mDice did not improve from 0.54997
Epoch 47/300
 - 13s - loss: 1257.0630 - acc: 0.9488 - mDice: 0.7734 - val_loss: 3141.6350 - val_acc: 0.9433 - val_mDice: 0.4958

Epoch 00047: val_mDice did not improve from 0.54997
Epoch 48/300
 - 14s - loss: 1247.2403 - acc: 0.9490 - mDice: 0.7750 - val_loss: 2896.4874 - val_acc: 0.9439 - val_mDice: 0.5209

Epoch 00048: val_mDice did not improve from 0.54997
Epoch 49/300
 - 14s - loss: 1241.8080 - acc: 0.9491 - mDice: 0.7758 - val_loss: 2866.5678 - val_acc: 0.9440 - val_mDice: 0.5260

Epoch 00049: val_mDice did not improve from 0.54997
Epoch 50/300
 - 13s - loss: 1227.0583 - acc: 0.9495 - mDice: 0.7782 - val_loss: 3049.4957 - val_acc: 0.9429 - val_mDice: 0.5102

Epoch 00050: val_mDice did not improve from 0.54997
Epoch 51/300
 - 14s - loss: 1220.1294 - acc: 0.9495 - mDice: 0.7793 - val_loss: 2733.6716 - val_acc: 0.9440 - val_mDice: 0.5412

Epoch 00051: val_mDice did not improve from 0.54997
Epoch 52/300
 - 14s - loss: 1211.2600 - acc: 0.9497 - mDice: 0.7807 - val_loss: 3074.4628 - val_acc: 0.9416 - val_mDice: 0.5053

Epoch 00052: val_mDice did not improve from 0.54997
Epoch 53/300
 - 14s - loss: 1195.7076 - acc: 0.9501 - mDice: 0.7831 - val_loss: 2926.3606 - val_acc: 0.9446 - val_mDice: 0.5206

Epoch 00053: val_mDice did not improve from 0.54997
Epoch 54/300
 - 14s - loss: 1185.8500 - acc: 0.9503 - mDice: 0.7846 - val_loss: 2979.9384 - val_acc: 0.9430 - val_mDice: 0.5176

Epoch 00054: val_mDice did not improve from 0.54997
Epoch 55/300
 - 13s - loss: 1178.6089 - acc: 0.9505 - mDice: 0.7858 - val_loss: 3030.0283 - val_acc: 0.9457 - val_mDice: 0.5098

Epoch 00055: val_mDice did not improve from 0.54997
Epoch 56/300
 - 14s - loss: 1171.2324 - acc: 0.9507 - mDice: 0.7870 - val_loss: 2886.7381 - val_acc: 0.9446 - val_mDice: 0.5246

Epoch 00056: val_mDice did not improve from 0.54997
Epoch 57/300
 - 14s - loss: 1160.6618 - acc: 0.9508 - mDice: 0.7887 - val_loss: 2983.1345 - val_acc: 0.9439 - val_mDice: 0.5150

Epoch 00057: val_mDice did not improve from 0.54997
Epoch 58/300
 - 13s - loss: 1155.0082 - acc: 0.9510 - mDice: 0.7896 - val_loss: 3094.6819 - val_acc: 0.9445 - val_mDice: 0.5071

Epoch 00058: val_mDice did not improve from 0.54997
Epoch 59/300
 - 14s - loss: 1149.8248 - acc: 0.9512 - mDice: 0.7904 - val_loss: 2804.7844 - val_acc: 0.9418 - val_mDice: 0.5355

Epoch 00059: val_mDice did not improve from 0.54997
Epoch 60/300
 - 13s - loss: 1138.8742 - acc: 0.9514 - mDice: 0.7922 - val_loss: 2987.7357 - val_acc: 0.9443 - val_mDice: 0.5134

Epoch 00060: val_mDice did not improve from 0.54997
Epoch 61/300
 - 14s - loss: 1131.8717 - acc: 0.9515 - mDice: 0.7933 - val_loss: 2925.0686 - val_acc: 0.9446 - val_mDice: 0.5188

Epoch 00061: val_mDice did not improve from 0.54997
Epoch 62/300
 - 14s - loss: 1128.7470 - acc: 0.9516 - mDice: 0.7938 - val_loss: 2967.1533 - val_acc: 0.9432 - val_mDice: 0.5196

Epoch 00062: val_mDice did not improve from 0.54997
Epoch 63/300
 - 15s - loss: 1120.0174 - acc: 0.9518 - mDice: 0.7951 - val_loss: 2805.7469 - val_acc: 0.9437 - val_mDice: 0.5318

Epoch 00063: val_mDice did not improve from 0.54997
Epoch 64/300
 - 16s - loss: 1115.1459 - acc: 0.9520 - mDice: 0.7959 - val_loss: 2932.8023 - val_acc: 0.9450 - val_mDice: 0.5212

Epoch 00064: val_mDice did not improve from 0.54997
Epoch 65/300
 - 16s - loss: 1108.7037 - acc: 0.9520 - mDice: 0.7970 - val_loss: 3073.6645 - val_acc: 0.9437 - val_mDice: 0.5090

Epoch 00065: val_mDice did not improve from 0.54997
Epoch 66/300
 - 15s - loss: 1098.1676 - acc: 0.9522 - mDice: 0.7987 - val_loss: 3070.9748 - val_acc: 0.9450 - val_mDice: 0.5089

Epoch 00066: val_mDice did not improve from 0.54997
Epoch 67/300
 - 16s - loss: 1098.7933 - acc: 0.9523 - mDice: 0.7986 - val_loss: 2982.1676 - val_acc: 0.9430 - val_mDice: 0.5167

Epoch 00067: val_mDice did not improve from 0.54997
Epoch 68/300
 - 17s - loss: 1081.2721 - acc: 0.9526 - mDice: 0.8014 - val_loss: 2852.4753 - val_acc: 0.9434 - val_mDice: 0.5325

Epoch 00068: val_mDice did not improve from 0.54997
Epoch 69/300
 - 15s - loss: 1080.5489 - acc: 0.9526 - mDice: 0.8016 - val_loss: 3056.4866 - val_acc: 0.9399 - val_mDice: 0.5109

Epoch 00069: val_mDice did not improve from 0.54997
Epoch 70/300
 - 16s - loss: 1067.7460 - acc: 0.9528 - mDice: 0.8037 - val_loss: 3044.6611 - val_acc: 0.9393 - val_mDice: 0.5143

Epoch 00070: val_mDice did not improve from 0.54997
Epoch 71/300
 - 16s - loss: 1074.7978 - acc: 0.9527 - mDice: 0.8025 - val_loss: 3139.7970 - val_acc: 0.9383 - val_mDice: 0.5048

Epoch 00071: val_mDice did not improve from 0.54997
Epoch 72/300
 - 13s - loss: 1070.7699 - acc: 0.9528 - mDice: 0.8032 - val_loss: 2865.1529 - val_acc: 0.9455 - val_mDice: 0.5304

Epoch 00072: val_mDice did not improve from 0.54997
Epoch 73/300
 - 13s - loss: 1058.5922 - acc: 0.9531 - mDice: 0.8052 - val_loss: 2997.6795 - val_acc: 0.9436 - val_mDice: 0.5206

Epoch 00073: val_mDice did not improve from 0.54997
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [9137.427548363095, 4851.380615234375, 4202.69255719866, 3703.890159970238, 3447.88427734375, 3263.110345749628, 3148.1995558965773, 3091.8203241257443, 3032.4576648530506, 2926.5013718377977, 2994.242518833705, 2954.3255615234375, 2944.2693074544272, 2896.517374674479, 2953.084803989955, 2925.1795421781994, 2803.087184361049, 2780.145443870908, 2876.0345924014136, 2894.7588471912204, 2680.244137718564, 2689.51319812593, 2769.204313732329, 2798.025721958705, 2742.84030296689, 2681.7557634626114, 2743.673614501953, 2726.894981747582, 2938.4612819126673, 2763.3543061755954, 2835.8614945184618, 2788.314954485212, 2939.8424050467356, 2773.4422433035716, 2779.1117204938614, 2778.667285737537, 2828.968038649786, 2647.324737548828, 3092.5714903331937, 2905.7637706938244, 2700.793377830869, 2881.6224728538878, 2649.048338390532, 2822.828370593843, 2816.4570908319383, 2893.3554324195497, 3141.63503519694, 2896.4873780750095, 2866.5677679152714, 3049.495651971726, 2733.671638125465, 3074.4627583821616, 2926.3605680919827, 2979.9384242466517, 3030.028336297898, 2886.7381453741164, 2983.134547642299, 3094.6818963913693, 2804.7844034830728, 2987.7356610979355, 2925.06855628604, 2967.1533203125, 2805.74685160319, 2932.802308582124, 3073.664504278274, 3070.974849155971, 2982.1676388695128, 2852.4752575102307, 3056.486569359189, 3044.661077590216, 3139.7970203218006, 2865.152864002046, 2997.6795102074034], 'val_acc': [0.8971291439873832, 0.905595220270611, 0.9153204957644144, 0.9259844422340393, 0.9283150150662377, 0.9331982731819153, 0.9336561390331813, 0.9340521749996004, 0.9360096397854033, 0.9362339661234901, 0.9356295750254676, 0.9381456091290429, 0.9373283074015663, 0.9366941395260039, 0.9386561456180754, 0.9391071285520282, 0.9393497932524908, 0.9398076988401867, 0.9404738999548412, 0.9385714474178496, 0.9410050341061184, 0.9400664085433597, 0.9408424894014994, 0.9402792794363839, 0.9412499722980318, 0.9427472267832074, 0.9439995345615205, 0.9397298324675787, 0.9417445290656317, 0.9436149398485819, 0.9428205149514335, 0.9430608834539141, 0.9427930343718756, 0.9437889314833141, 0.9441391939208621, 0.943498188541049, 0.9447710769517081, 0.9450343620209467, 0.9422161352066767, 0.9433356324831644, 0.9455219649133229, 0.9451076246443249, 0.9445054758162725, 0.9445925127892267, 0.9439194145656767, 0.9428777666318984, 0.9433264476912362, 0.9439469036601839, 0.9440407611074901, 0.9429166402135577, 0.9439583392370314, 0.9416437489645821, 0.9445512606984093, 0.943028864406404, 0.9456845209712074, 0.9446039568810236, 0.9438598865554446, 0.944489442166828, 0.9417788414728074, 0.9442582329114279, 0.9445627076285226, 0.943184514840444, 0.9437408645947775, 0.945036646865663, 0.9436927437782288, 0.9449702103932699, 0.9429716269175211, 0.9434432217053005, 0.9399404610906329, 0.9393040481067839, 0.938298986071632, 0.9454624340647743, 0.9435737133026123], 'val_mDice': [0.26548338929812115, 0.3732998014560768, 0.4184045028828439, 0.45305261707731653, 0.4758615766962369, 0.4896364392978804, 0.500178146042994, 0.5052324489113831, 0.5102125434648423, 0.5198665463498661, 0.5122609830328396, 0.5167438214023908, 0.5175343908014751, 0.5231071444494384, 0.5171717231472334, 0.5205914007411117, 0.5323368074993292, 0.5345809417111533, 0.5241313378016154, 0.5240241594257808, 0.545394785347439, 0.5448087109696298, 0.535965241137005, 0.5334355692778315, 0.540798035405931, 0.5474514413092818, 0.537969990500382, 0.5418741899941649, 0.5161208061590081, 0.5376347789452189, 0.5270200455117793, 0.5335310135214102, 0.5166667896722045, 0.5390267173449198, 0.5365747993900662, 0.5372827294326964, 0.5297770980922949, 0.5491471645377931, 0.4992902342762266, 0.5243270579902899, 0.5443025430043539, 0.5242187244196733, 0.5499733166680449, 0.5315306080239159, 0.5318298464020094, 0.5224666137780462, 0.4957978842513902, 0.5208932878006072, 0.526004250560488, 0.510160295736222, 0.5412385845113368, 0.5052696633197012, 0.5205731182580903, 0.5175761365819544, 0.5097523363573211, 0.5245784696723733, 0.5150080839438098, 0.5071317771715778, 0.5354970668752989, 0.5134154018901643, 0.5187782400420734, 0.5196044530187335, 0.5317955348818075, 0.5211898432601065, 0.5089542787699473, 0.5089274524223237, 0.5166703189412752, 0.5325417248975663, 0.5109213886871224, 0.514323737294901, 0.5047649216084253, 0.5304187711860452, 0.5206287104104247], 'loss': [14027.085232801053, 6418.74765611821, 4395.401925505621, 3553.2984406629553, 3125.1538881383144, 2876.0140800704057, 2695.1156000681917, 2569.472349015003, 2449.5549006229517, 2352.9550163955937, 2277.2263526953275, 2206.450650010882, 2137.61873603028, 2068.3424983262694, 2011.755103678103, 1959.5434565370383, 1921.948867177145, 1875.1819297388981, 1837.253761681284, 1795.665380068636, 1752.2048651197179, 1728.5980101762443, 1702.3489063469597, 1662.8743259421842, 1633.9930697621835, 1615.2815412554824, 1587.2669871889007, 1564.9590903010605, 1541.936185773177, 1517.8808680354732, 1490.166818060212, 1471.774335553427, 1453.0968167606704, 1434.1805790580718, 1417.1528113684903, 1405.4252325807759, 1388.1506738554244, 1368.5993205435086, 1354.6128873161344, 1346.1605121648586, 1330.8877781988776, 1311.3624711662721, 1305.2354673374957, 1293.2781817213934, 1282.8746646537656, 1271.6567668631653, 1257.0630275828544, 1247.2403067887944, 1241.8079620531948, 1227.0582580625241, 1220.12939117767, 1211.259960968094, 1195.707604100301, 1185.8500123458812, 1178.6088863186737, 1171.2323690767068, 1160.6617526952898, 1155.0081805701152, 1149.8248409155776, 1138.8741545565952, 1131.8716889104335, 1128.7469755650393, 1120.0173582713544, 1115.145877259348, 1108.7036611256583, 1098.167616988874, 1098.7932841865595, 1081.2721402293482, 1080.5489186834272, 1067.7460255370058, 1074.7978260988257, 1070.7699357388174, 1058.5921673691064], 'acc': [0.8640380801436573, 0.8767314904890287, 0.8890712562613067, 0.9014358663917484, 0.9102359480289727, 0.9152293650198929, 0.9190642766371522, 0.921996859185425, 0.9242806311331205, 0.9264735432173996, 0.9278688827001316, 0.9294464430736397, 0.9305591519246195, 0.9319717564954219, 0.9331915672284595, 0.9342642158172207, 0.9348514127506097, 0.936011742908922, 0.9367016121696272, 0.9375797561742402, 0.9382978548244265, 0.9390415268893966, 0.9395899146605668, 0.9404312834496992, 0.9407435445995121, 0.9414864359091352, 0.9418861730401631, 0.9423941468742052, 0.9428414092464715, 0.9432498849562099, 0.9438168510136771, 0.9442861726547405, 0.944687396316646, 0.9448964973738917, 0.9454237496620753, 0.9456290261856227, 0.9459261137533216, 0.9462768438695736, 0.946809955477048, 0.9469843227348048, 0.9472791174254667, 0.9475641294851316, 0.9478087519574354, 0.9479621982951373, 0.9482631560624025, 0.948467853948609, 0.9488324849780686, 0.9489903311658645, 0.9491253315724457, 0.9494652845208209, 0.9495025228185416, 0.9497307901417379, 0.9501248499849341, 0.9503472270546379, 0.9505370980929795, 0.9507026837835979, 0.9508365510699145, 0.9509582942750657, 0.9512443492608836, 0.9514070197937, 0.9514506954849858, 0.9515818706224345, 0.9517532731725091, 0.952042645035577, 0.9520283259705631, 0.9522235909247412, 0.9522827483450766, 0.9526087298245244, 0.9525995794601102, 0.952827217918107, 0.9527118742316588, 0.9528263639296, 0.9530658176898129], 'mDice': [0.16642261734036598, 0.32129724534325044, 0.4269776880419367, 0.49312469065016995, 0.5340058466407728, 0.5606954197835803, 0.5806525622646956, 0.5951925834893307, 0.6092916306374687, 0.6214619662367771, 0.6306442814983797, 0.639615681041797, 0.6483650920890719, 0.6574362559150312, 0.66475988254856, 0.6716742919478225, 0.6767009459227663, 0.6829748041302983, 0.6881919066777734, 0.6940650577395321, 0.7001009995201454, 0.7033712488046289, 0.7071631862429127, 0.7127438941189428, 0.7168781848824367, 0.7195125305057376, 0.7235535273828648, 0.7268781816658313, 0.7302785266082319, 0.7337844468206484, 0.7378309368972308, 0.7406206096967612, 0.7433808595660291, 0.7461940265699276, 0.7488456308807232, 0.7505221755972988, 0.7532141221174046, 0.7561386204970143, 0.7582914473028203, 0.7595790999804891, 0.761960735136267, 0.7649146335672409, 0.7659193440648386, 0.7677540141469325, 0.7694027935789802, 0.7710996997225416, 0.7734023853834824, 0.7749722918518159, 0.7757903417457108, 0.7781789704556867, 0.7792808167709651, 0.780664442200088, 0.7830721898784015, 0.7846434871907269, 0.7857770707213352, 0.7870232141590173, 0.7886565562983296, 0.7895628285587282, 0.7903976673010757, 0.7921523211639879, 0.7932594118951165, 0.7938124885420269, 0.7951361434478532, 0.7959278622113926, 0.7970378765922901, 0.7986866001313376, 0.7986460230542167, 0.8014322928502561, 0.8015984770694128, 0.8037008495259106, 0.8025360538455271, 0.8032048631546377, 0.8051953095334422]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:05<00:02,  2.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.61s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:36,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:04<09:10,  1.95s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:54,  1.90s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<09:39,  2.06s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:06,  1.95s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<09:41,  2.08s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<10:10,  2.19s/it]predicting train subjects:   3%|▎         | 8/285 [00:17<10:42,  2.32s/it]predicting train subjects:   3%|▎         | 9/285 [00:19<10:18,  2.24s/it]predicting train subjects:   4%|▎         | 10/285 [00:22<10:41,  2.33s/it]predicting train subjects:   4%|▍         | 11/285 [00:24<10:56,  2.39s/it]predicting train subjects:   4%|▍         | 12/285 [00:26<10:51,  2.39s/it]predicting train subjects:   5%|▍         | 13/285 [00:29<11:12,  2.47s/it]predicting train subjects:   5%|▍         | 14/285 [00:32<11:23,  2.52s/it]predicting train subjects:   5%|▌         | 15/285 [00:34<11:32,  2.56s/it]predicting train subjects:   6%|▌         | 16/285 [00:37<11:35,  2.58s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<11:19,  2.54s/it]predicting train subjects:   6%|▋         | 18/285 [00:42<11:13,  2.52s/it]predicting train subjects:   7%|▋         | 19/285 [00:45<11:16,  2.54s/it]predicting train subjects:   7%|▋         | 20/285 [00:47<11:10,  2.53s/it]predicting train subjects:   7%|▋         | 21/285 [00:50<11:11,  2.54s/it]predicting train subjects:   8%|▊         | 22/285 [00:52<11:08,  2.54s/it]predicting train subjects:   8%|▊         | 23/285 [00:55<10:52,  2.49s/it]predicting train subjects:   8%|▊         | 24/285 [00:57<11:06,  2.55s/it]predicting train subjects:   9%|▉         | 25/285 [01:00<11:26,  2.64s/it]predicting train subjects:   9%|▉         | 26/285 [01:03<11:09,  2.58s/it]predicting train subjects:   9%|▉         | 27/285 [01:05<11:08,  2.59s/it]predicting train subjects:  10%|▉         | 28/285 [01:07<10:39,  2.49s/it]predicting train subjects:  10%|█         | 29/285 [01:09<10:05,  2.37s/it]predicting train subjects:  11%|█         | 30/285 [01:12<09:48,  2.31s/it]predicting train subjects:  11%|█         | 31/285 [01:14<09:40,  2.28s/it]predicting train subjects:  11%|█         | 32/285 [01:16<09:28,  2.25s/it]predicting train subjects:  12%|█▏        | 33/285 [01:18<09:21,  2.23s/it]predicting train subjects:  12%|█▏        | 34/285 [01:20<09:09,  2.19s/it]predicting train subjects:  12%|█▏        | 35/285 [01:23<09:08,  2.19s/it]predicting train subjects:  13%|█▎        | 36/285 [01:25<09:07,  2.20s/it]predicting train subjects:  13%|█▎        | 37/285 [01:27<08:50,  2.14s/it]predicting train subjects:  13%|█▎        | 38/285 [01:29<08:45,  2.13s/it]predicting train subjects:  14%|█▎        | 39/285 [01:31<08:47,  2.15s/it]predicting train subjects:  14%|█▍        | 40/285 [01:33<08:37,  2.11s/it]predicting train subjects:  14%|█▍        | 41/285 [01:35<08:32,  2.10s/it]predicting train subjects:  15%|█▍        | 42/285 [01:37<08:32,  2.11s/it]predicting train subjects:  15%|█▌        | 43/285 [01:39<08:33,  2.12s/it]predicting train subjects:  15%|█▌        | 44/285 [01:41<08:21,  2.08s/it]predicting train subjects:  16%|█▌        | 45/285 [01:44<08:25,  2.11s/it]predicting train subjects:  16%|█▌        | 46/285 [01:45<08:05,  2.03s/it]predicting train subjects:  16%|█▋        | 47/285 [01:47<07:39,  1.93s/it]predicting train subjects:  17%|█▋        | 48/285 [01:49<07:22,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:51<07:10,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:52<07:05,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:54<07:07,  1.83s/it]predicting train subjects:  18%|█▊        | 52/285 [01:56<06:59,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:58<06:53,  1.78s/it]predicting train subjects:  19%|█▉        | 54/285 [01:59<06:49,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [02:01<06:38,  1.73s/it]predicting train subjects:  20%|█▉        | 56/285 [02:03<06:58,  1.83s/it]predicting train subjects:  20%|██        | 57/285 [02:05<06:52,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [02:07<06:45,  1.79s/it]predicting train subjects:  21%|██        | 59/285 [02:08<06:46,  1.80s/it]predicting train subjects:  21%|██        | 60/285 [02:10<06:35,  1.76s/it]predicting train subjects:  21%|██▏       | 61/285 [02:12<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [02:14<06:40,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [02:16<06:44,  1.82s/it]predicting train subjects:  22%|██▏       | 64/285 [02:18<06:44,  1.83s/it]predicting train subjects:  23%|██▎       | 65/285 [02:20<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 66/285 [02:22<07:03,  1.94s/it]predicting train subjects:  24%|██▎       | 67/285 [02:23<06:57,  1.92s/it]predicting train subjects:  24%|██▍       | 68/285 [02:25<06:40,  1.85s/it]predicting train subjects:  24%|██▍       | 69/285 [02:27<06:45,  1.88s/it]predicting train subjects:  25%|██▍       | 70/285 [02:29<06:38,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:31<06:43,  1.89s/it]predicting train subjects:  25%|██▌       | 72/285 [02:33<06:43,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:35<06:41,  1.89s/it]predicting train subjects:  26%|██▌       | 74/285 [02:36<06:31,  1.86s/it]predicting train subjects:  26%|██▋       | 75/285 [02:38<06:22,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:40<06:17,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:42<06:17,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:44<06:20,  1.84s/it]predicting train subjects:  28%|██▊       | 79/285 [02:46<06:21,  1.85s/it]predicting train subjects:  28%|██▊       | 80/285 [02:48<06:33,  1.92s/it]predicting train subjects:  28%|██▊       | 81/285 [02:50<06:35,  1.94s/it]predicting train subjects:  29%|██▉       | 82/285 [02:52<06:31,  1.93s/it]predicting train subjects:  29%|██▉       | 83/285 [02:53<06:23,  1.90s/it]predicting train subjects:  29%|██▉       | 84/285 [02:55<06:27,  1.93s/it]predicting train subjects:  30%|██▉       | 85/285 [02:58<06:40,  2.00s/it]predicting train subjects:  30%|███       | 86/285 [03:00<06:49,  2.06s/it]predicting train subjects:  31%|███       | 87/285 [03:02<06:56,  2.10s/it]predicting train subjects:  31%|███       | 88/285 [03:04<07:06,  2.16s/it]predicting train subjects:  31%|███       | 89/285 [03:06<07:00,  2.15s/it]predicting train subjects:  32%|███▏      | 90/285 [03:08<06:53,  2.12s/it]predicting train subjects:  32%|███▏      | 91/285 [03:11<06:58,  2.16s/it]predicting train subjects:  32%|███▏      | 92/285 [03:13<07:00,  2.18s/it]predicting train subjects:  33%|███▎      | 93/285 [03:15<06:58,  2.18s/it]predicting train subjects:  33%|███▎      | 94/285 [03:17<06:53,  2.17s/it]predicting train subjects:  33%|███▎      | 95/285 [03:19<06:46,  2.14s/it]predicting train subjects:  34%|███▎      | 96/285 [03:21<06:40,  2.12s/it]predicting train subjects:  34%|███▍      | 97/285 [03:23<06:35,  2.10s/it]predicting train subjects:  34%|███▍      | 98/285 [03:26<06:34,  2.11s/it]predicting train subjects:  35%|███▍      | 99/285 [03:28<06:32,  2.11s/it]predicting train subjects:  35%|███▌      | 100/285 [03:30<06:29,  2.11s/it]predicting train subjects:  35%|███▌      | 101/285 [03:32<06:28,  2.11s/it]predicting train subjects:  36%|███▌      | 102/285 [03:34<06:29,  2.13s/it]predicting train subjects:  36%|███▌      | 103/285 [03:36<06:19,  2.08s/it]predicting train subjects:  36%|███▋      | 104/285 [03:38<06:27,  2.14s/it]predicting train subjects:  37%|███▋      | 105/285 [03:40<06:22,  2.13s/it]predicting train subjects:  37%|███▋      | 106/285 [03:42<06:12,  2.08s/it]predicting train subjects:  38%|███▊      | 107/285 [03:44<06:10,  2.08s/it]predicting train subjects:  38%|███▊      | 108/285 [03:47<06:12,  2.11s/it]predicting train subjects:  38%|███▊      | 109/285 [03:49<06:07,  2.09s/it]predicting train subjects:  39%|███▊      | 110/285 [03:51<05:56,  2.04s/it]predicting train subjects:  39%|███▉      | 111/285 [03:53<05:53,  2.03s/it]predicting train subjects:  39%|███▉      | 112/285 [03:55<05:47,  2.01s/it]predicting train subjects:  40%|███▉      | 113/285 [03:57<05:49,  2.03s/it]predicting train subjects:  40%|████      | 114/285 [03:59<05:49,  2.05s/it]predicting train subjects:  40%|████      | 115/285 [04:01<05:55,  2.09s/it]predicting train subjects:  41%|████      | 116/285 [04:03<06:02,  2.14s/it]predicting train subjects:  41%|████      | 117/285 [04:05<06:06,  2.18s/it]predicting train subjects:  41%|████▏     | 118/285 [04:07<05:57,  2.14s/it]predicting train subjects:  42%|████▏     | 119/285 [04:10<05:56,  2.15s/it]predicting train subjects:  42%|████▏     | 120/285 [04:12<05:49,  2.12s/it]predicting train subjects:  42%|████▏     | 121/285 [04:14<05:40,  2.08s/it]predicting train subjects:  43%|████▎     | 122/285 [04:15<05:23,  1.98s/it]predicting train subjects:  43%|████▎     | 123/285 [04:17<05:09,  1.91s/it]predicting train subjects:  44%|████▎     | 124/285 [04:19<05:10,  1.93s/it]predicting train subjects:  44%|████▍     | 125/285 [04:21<05:06,  1.91s/it]predicting train subjects:  44%|████▍     | 126/285 [04:23<05:03,  1.91s/it]predicting train subjects:  45%|████▍     | 127/285 [04:25<05:02,  1.92s/it]predicting train subjects:  45%|████▍     | 128/285 [04:27<05:06,  1.95s/it]predicting train subjects:  45%|████▌     | 129/285 [04:29<05:08,  1.98s/it]predicting train subjects:  46%|████▌     | 130/285 [04:31<05:00,  1.94s/it]predicting train subjects:  46%|████▌     | 131/285 [04:33<05:01,  1.96s/it]predicting train subjects:  46%|████▋     | 132/285 [04:35<04:57,  1.94s/it]predicting train subjects:  47%|████▋     | 133/285 [04:37<04:57,  1.96s/it]predicting train subjects:  47%|████▋     | 134/285 [04:39<04:49,  1.92s/it]predicting train subjects:  47%|████▋     | 135/285 [04:40<04:41,  1.88s/it]predicting train subjects:  48%|████▊     | 136/285 [04:42<04:39,  1.88s/it]predicting train subjects:  48%|████▊     | 137/285 [04:44<04:42,  1.91s/it]predicting train subjects:  48%|████▊     | 138/285 [04:46<04:44,  1.93s/it]predicting train subjects:  49%|████▉     | 139/285 [04:48<04:39,  1.91s/it]predicting train subjects:  49%|████▉     | 140/285 [04:50<04:29,  1.86s/it]predicting train subjects:  49%|████▉     | 141/285 [04:52<04:33,  1.90s/it]predicting train subjects:  50%|████▉     | 142/285 [04:54<04:27,  1.87s/it]predicting train subjects:  50%|█████     | 143/285 [04:55<04:19,  1.83s/it]predicting train subjects:  51%|█████     | 144/285 [04:57<04:15,  1.81s/it]predicting train subjects:  51%|█████     | 145/285 [04:59<04:10,  1.79s/it]predicting train subjects:  51%|█████     | 146/285 [05:01<04:05,  1.77s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:02<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:04<03:58,  1.74s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:05<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:07<03:44,  1.66s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:09<03:40,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:10<03:35,  1.62s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:12<03:38,  1.65s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:14<03:37,  1.66s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:15<03:37,  1.67s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:17<03:37,  1.68s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:19<03:37,  1.70s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:20<03:35,  1.70s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:22<03:31,  1.68s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:24<03:36,  1.73s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:26<03:27,  1.68s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:27<03:25,  1.67s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:29<03:26,  1.70s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:31<03:21,  1.67s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:32<03:18,  1.65s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:34<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:36<03:18,  1.68s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:37<03:13,  1.65s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:39<03:13,  1.66s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:41<03:12,  1.67s/it]predicting train subjects:  60%|██████    | 171/285 [05:42<03:13,  1.69s/it]predicting train subjects:  60%|██████    | 172/285 [05:44<03:12,  1.70s/it]predicting train subjects:  61%|██████    | 173/285 [05:46<03:05,  1.65s/it]predicting train subjects:  61%|██████    | 174/285 [05:47<03:02,  1.64s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:49<03:00,  1.64s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:50<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:52<02:58,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:54<02:58,  1.67s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:56<02:59,  1.69s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:57<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:59<02:50,  1.64s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:00<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:02<02:45,  1.62s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:03<02:43,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:05<02:42,  1.63s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:07<02:42,  1.64s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:08<02:37,  1.60s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:10<02:37,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:11<02:31,  1.58s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:13<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:15<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:16<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:18<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:19<02:22,  1.57s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:21<02:27,  1.64s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:23<02:34,  1.73s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:25<02:42,  1.84s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:27<02:44,  1.89s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:29<02:43,  1.90s/it]predicting train subjects:  70%|███████   | 200/285 [06:31<02:44,  1.94s/it]predicting train subjects:  71%|███████   | 201/285 [06:33<02:43,  1.94s/it]predicting train subjects:  71%|███████   | 202/285 [06:35<02:36,  1.88s/it]predicting train subjects:  71%|███████   | 203/285 [06:37<02:32,  1.86s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:38<02:29,  1.85s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:41<02:35,  1.94s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:42<02:31,  1.92s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:44<02:27,  1.89s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:46<02:28,  1.93s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:48<02:25,  1.91s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:50<02:22,  1.90s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:52<02:18,  1.87s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:54<02:17,  1.88s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:56<02:15,  1.88s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:57<02:09,  1.82s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:59<01:59,  1.71s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:00<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:02<01:51,  1.64s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:04<01:50,  1.66s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:05<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:07<01:49,  1.69s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:09<01:49,  1.70s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:10<01:45,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:12<01:44,  1.68s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:14<01:40,  1.64s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:15<01:39,  1.66s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:17<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:19<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [07:20<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [07:22<01:34,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [07:24<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [07:25<01:30,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:27<01:34,  1.79s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:30<01:38,  1.88s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:32<01:39,  1.94s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:34<01:39,  1.98s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:36<01:36,  1.97s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:38<01:36,  2.01s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:40<01:36,  2.05s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:42<01:37,  2.11s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:44<01:35,  2.12s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:46<01:32,  2.11s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:48<01:30,  2.10s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:51<01:31,  2.18s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:53<01:30,  2.21s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:55<01:26,  2.16s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:57<01:26,  2.21s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:59<01:21,  2.14s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:02<01:18,  2.13s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:04<01:16,  2.12s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:05<01:08,  1.94s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:07<01:01,  1.80s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:08<00:56,  1.71s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:10<00:53,  1.67s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:11<00:53,  1.71s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:13<00:50,  1.69s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:15<00:49,  1.71s/it]predicting train subjects:  90%|█████████ | 257/285 [08:17<00:47,  1.69s/it]predicting train subjects:  91%|█████████ | 258/285 [08:18<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [08:20<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [08:21<00:40,  1.62s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:23<00:40,  1.70s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:25<00:38,  1.68s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:26<00:35,  1.60s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:28<00:32,  1.54s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:29<00:29,  1.50s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:31<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:32<00:28,  1.57s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:34<00:29,  1.74s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:37<00:29,  1.87s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:39<00:29,  1.94s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:41<00:27,  1.95s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:43<00:25,  1.98s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:45<00:24,  2.01s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:47<00:21,  1.99s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:49<00:19,  1.95s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:50<00:17,  1.91s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:52<00:15,  1.90s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:54<00:13,  1.89s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:56<00:11,  1.93s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:58<00:09,  1.91s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:00<00:07,  1.88s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:02<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:04<00:03,  1.87s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:05<00:01,  1.87s/it]predicting train subjects: 100%|██████████| 285/285 [09:07<00:00,  1.85s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:41,  1.41s/it]Loading train:   1%|          | 2/285 [00:02<06:47,  1.44s/it]Loading train:   1%|          | 3/285 [00:04<06:32,  1.39s/it]Loading train:   1%|▏         | 4/285 [00:05<06:49,  1.46s/it]Loading train:   2%|▏         | 5/285 [00:07<06:38,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:08<06:58,  1.50s/it]Loading train:   2%|▏         | 7/285 [00:10<07:27,  1.61s/it]Loading train:   3%|▎         | 8/285 [00:12<07:32,  1.63s/it]Loading train:   3%|▎         | 9/285 [00:13<07:06,  1.54s/it]Loading train:   4%|▎         | 10/285 [00:14<06:26,  1.40s/it]Loading train:   4%|▍         | 11/285 [00:16<06:14,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<05:57,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:18<05:55,  1.31s/it]Loading train:   5%|▍         | 14/285 [00:19<05:46,  1.28s/it]Loading train:   5%|▌         | 15/285 [00:21<06:09,  1.37s/it]Loading train:   6%|▌         | 16/285 [00:22<05:55,  1.32s/it]Loading train:   6%|▌         | 17/285 [00:23<05:49,  1.31s/it]Loading train:   6%|▋         | 18/285 [00:25<05:40,  1.28s/it]Loading train:   7%|▋         | 19/285 [00:26<05:35,  1.26s/it]Loading train:   7%|▋         | 20/285 [00:27<05:33,  1.26s/it]Loading train:   7%|▋         | 21/285 [00:28<05:32,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:30<05:32,  1.26s/it]Loading train:   8%|▊         | 23/285 [00:31<05:30,  1.26s/it]Loading train:   8%|▊         | 24/285 [00:32<05:27,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:33<05:25,  1.25s/it]Loading train:   9%|▉         | 26/285 [00:34<05:21,  1.24s/it]Loading train:   9%|▉         | 27/285 [00:36<05:23,  1.25s/it]Loading train:  10%|▉         | 28/285 [00:37<05:10,  1.21s/it]Loading train:  10%|█         | 29/285 [00:38<04:55,  1.15s/it]Loading train:  11%|█         | 30/285 [00:39<04:40,  1.10s/it]Loading train:  11%|█         | 31/285 [00:40<04:35,  1.09s/it]Loading train:  11%|█         | 32/285 [00:41<04:30,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:25,  1.05s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:35,  1.10s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:30,  1.09s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:29,  1.09s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:22,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:19,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:13,  1.03s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:13,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:13,  1.04s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:17,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:19,  1.08s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:13,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:17,  1.08s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:02,  1.02s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:03,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:59<03:55,  1.00it/s]Loading train:  18%|█▊        | 50/285 [01:00<03:47,  1.03it/s]Loading train:  18%|█▊        | 51/285 [01:01<03:45,  1.04it/s]Loading train:  18%|█▊        | 52/285 [01:02<03:54,  1.01s/it]Loading train:  19%|█▊        | 53/285 [01:03<03:48,  1.02it/s]Loading train:  19%|█▉        | 54/285 [01:04<03:43,  1.03it/s]Loading train:  19%|█▉        | 55/285 [01:05<03:41,  1.04it/s]Loading train:  20%|█▉        | 56/285 [01:06<03:41,  1.03it/s]Loading train:  20%|██        | 57/285 [01:07<03:40,  1.03it/s]Loading train:  20%|██        | 58/285 [01:07<03:39,  1.03it/s]Loading train:  21%|██        | 59/285 [01:08<03:38,  1.04it/s]Loading train:  21%|██        | 60/285 [01:09<03:43,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:10<03:35,  1.04it/s]Loading train:  22%|██▏       | 62/285 [01:11<03:41,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:12<03:32,  1.04it/s]Loading train:  22%|██▏       | 64/285 [01:14<04:15,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:16<04:55,  1.34s/it]Loading train:  23%|██▎       | 66/285 [01:17<05:08,  1.41s/it]Loading train:  24%|██▎       | 67/285 [01:18<04:38,  1.28s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:19,  1.20s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:10,  1.16s/it]Loading train:  25%|██▍       | 70/285 [01:21<03:58,  1.11s/it]Loading train:  25%|██▍       | 71/285 [01:23<04:02,  1.13s/it]Loading train:  25%|██▌       | 72/285 [01:24<03:51,  1.09s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:48,  1.08s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:41,  1.05s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:39,  1.05s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:32,  1.02s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:32,  1.02s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:31,  1.02s/it]Loading train:  28%|██▊       | 79/285 [01:31<03:24,  1.01it/s]Loading train:  28%|██▊       | 80/285 [01:31<03:22,  1.01it/s]Loading train:  28%|██▊       | 81/285 [01:32<03:21,  1.01it/s]Loading train:  29%|██▉       | 82/285 [01:34<03:23,  1.00s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:27,  1.03s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:25,  1.02s/it]Loading train:  30%|██▉       | 85/285 [01:37<03:27,  1.04s/it]Loading train:  30%|███       | 86/285 [01:38<03:35,  1.08s/it]Loading train:  31%|███       | 87/285 [01:39<03:31,  1.07s/it]Loading train:  31%|███       | 88/285 [01:40<03:31,  1.07s/it]Loading train:  31%|███       | 89/285 [01:41<03:28,  1.06s/it]Loading train:  32%|███▏      | 90/285 [01:42<03:27,  1.06s/it]Loading train:  32%|███▏      | 91/285 [01:43<03:29,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:44<03:30,  1.09s/it]Loading train:  33%|███▎      | 93/285 [01:45<03:30,  1.10s/it]Loading train:  33%|███▎      | 94/285 [01:46<03:26,  1.08s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:25,  1.08s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:25,  1.09s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:28,  1.11s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:24,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:22,  1.09s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:19,  1.08s/it]Loading train:  36%|███▌      | 102/285 [01:55<03:17,  1.08s/it]Loading train:  36%|███▌      | 103/285 [01:56<03:20,  1.10s/it]Loading train:  36%|███▋      | 104/285 [01:57<03:18,  1.10s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:18,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:15,  1.09s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:13,  1.09s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:08,  1.07s/it]Loading train:  39%|███▊      | 110/285 [02:04<03:02,  1.04s/it]Loading train:  39%|███▉      | 111/285 [02:05<02:56,  1.01s/it]Loading train:  39%|███▉      | 112/285 [02:06<02:56,  1.02s/it]Loading train:  40%|███▉      | 113/285 [02:07<02:56,  1.03s/it]Loading train:  40%|████      | 114/285 [02:08<02:56,  1.03s/it]Loading train:  40%|████      | 115/285 [02:09<02:56,  1.04s/it]Loading train:  41%|████      | 116/285 [02:10<02:51,  1.02s/it]Loading train:  41%|████      | 117/285 [02:11<02:51,  1.02s/it]Loading train:  41%|████▏     | 118/285 [02:12<02:50,  1.02s/it]Loading train:  42%|████▏     | 119/285 [02:13<02:57,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:14<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:16<03:16,  1.20s/it]Loading train:  43%|████▎     | 122/285 [02:17<03:22,  1.24s/it]Loading train:  43%|████▎     | 123/285 [02:18<03:24,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:19<03:07,  1.16s/it]Loading train:  44%|████▍     | 125/285 [02:20<02:57,  1.11s/it]Loading train:  44%|████▍     | 126/285 [02:21<02:43,  1.03s/it]Loading train:  45%|████▍     | 127/285 [02:22<02:38,  1.00s/it]Loading train:  45%|████▍     | 128/285 [02:23<02:35,  1.01it/s]Loading train:  45%|████▌     | 129/285 [02:24<02:32,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:25<02:28,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:26<02:24,  1.06it/s]Loading train:  46%|████▋     | 132/285 [02:27<02:22,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:28<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:29<02:19,  1.08it/s]Loading train:  47%|████▋     | 135/285 [02:30<02:22,  1.05it/s]Loading train:  48%|████▊     | 136/285 [02:30<02:18,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:31<02:16,  1.09it/s]Loading train:  48%|████▊     | 138/285 [02:32<02:21,  1.04it/s]Loading train:  49%|████▉     | 139/285 [02:33<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:34<02:19,  1.04it/s]Loading train:  49%|████▉     | 141/285 [02:35<02:17,  1.05it/s]Loading train:  50%|████▉     | 142/285 [02:36<02:14,  1.06it/s]Loading train:  50%|█████     | 143/285 [02:37<02:14,  1.06it/s]Loading train:  51%|█████     | 144/285 [02:38<02:11,  1.07it/s]Loading train:  51%|█████     | 145/285 [02:39<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:40<02:11,  1.05it/s]Loading train:  52%|█████▏    | 147/285 [02:41<02:07,  1.08it/s]Loading train:  52%|█████▏    | 148/285 [02:42<02:02,  1.11it/s]Loading train:  52%|█████▏    | 149/285 [02:43<02:01,  1.12it/s]Loading train:  53%|█████▎    | 150/285 [02:43<02:00,  1.12it/s]Loading train:  53%|█████▎    | 151/285 [02:45<02:06,  1.06it/s]Loading train:  53%|█████▎    | 152/285 [02:45<02:02,  1.08it/s]Loading train:  54%|█████▎    | 153/285 [02:46<02:08,  1.03it/s]Loading train:  54%|█████▍    | 154/285 [02:47<02:06,  1.04it/s]Loading train:  54%|█████▍    | 155/285 [02:48<02:05,  1.03it/s]Loading train:  55%|█████▍    | 156/285 [02:49<02:04,  1.03it/s]Loading train:  55%|█████▌    | 157/285 [02:50<02:01,  1.06it/s]Loading train:  55%|█████▌    | 158/285 [02:51<02:01,  1.05it/s]Loading train:  56%|█████▌    | 159/285 [02:52<01:54,  1.10it/s]Loading train:  56%|█████▌    | 160/285 [02:53<01:57,  1.07it/s]Loading train:  56%|█████▋    | 161/285 [02:54<01:50,  1.12it/s]Loading train:  57%|█████▋    | 162/285 [02:55<01:48,  1.13it/s]Loading train:  57%|█████▋    | 163/285 [02:55<01:43,  1.18it/s]Loading train:  58%|█████▊    | 164/285 [02:56<01:45,  1.14it/s]Loading train:  58%|█████▊    | 165/285 [02:57<01:52,  1.06it/s]Loading train:  58%|█████▊    | 166/285 [02:58<01:52,  1.06it/s]Loading train:  59%|█████▊    | 167/285 [02:59<01:51,  1.06it/s]Loading train:  59%|█████▉    | 168/285 [03:00<01:48,  1.08it/s]Loading train:  59%|█████▉    | 169/285 [03:01<01:48,  1.07it/s]Loading train:  60%|█████▉    | 170/285 [03:02<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [03:03<01:41,  1.12it/s]Loading train:  60%|██████    | 172/285 [03:04<01:39,  1.14it/s]Loading train:  61%|██████    | 173/285 [03:05<01:39,  1.13it/s]Loading train:  61%|██████    | 174/285 [03:06<01:38,  1.13it/s]Loading train:  61%|██████▏   | 175/285 [03:06<01:37,  1.13it/s]Loading train:  62%|██████▏   | 176/285 [03:07<01:34,  1.15it/s]Loading train:  62%|██████▏   | 177/285 [03:08<01:32,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [03:09<01:31,  1.17it/s]Loading train:  63%|██████▎   | 179/285 [03:10<01:29,  1.19it/s]Loading train:  63%|██████▎   | 180/285 [03:11<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [03:12<01:29,  1.17it/s]Loading train:  64%|██████▍   | 182/285 [03:12<01:28,  1.17it/s]Loading train:  64%|██████▍   | 183/285 [03:13<01:30,  1.13it/s]Loading train:  65%|██████▍   | 184/285 [03:14<01:28,  1.14it/s]Loading train:  65%|██████▍   | 185/285 [03:15<01:26,  1.15it/s]Loading train:  65%|██████▌   | 186/285 [03:16<01:26,  1.14it/s]Loading train:  66%|██████▌   | 187/285 [03:17<01:28,  1.10it/s]Loading train:  66%|██████▌   | 188/285 [03:18<01:23,  1.16it/s]Loading train:  66%|██████▋   | 189/285 [03:19<01:27,  1.10it/s]Loading train:  67%|██████▋   | 190/285 [03:20<01:26,  1.10it/s]Loading train:  67%|██████▋   | 191/285 [03:21<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [03:21<01:24,  1.10it/s]Loading train:  68%|██████▊   | 193/285 [03:22<01:20,  1.14it/s]Loading train:  68%|██████▊   | 194/285 [03:23<01:19,  1.15it/s]Loading train:  68%|██████▊   | 195/285 [03:24<01:16,  1.18it/s]Loading train:  69%|██████▉   | 196/285 [03:25<01:20,  1.10it/s]Loading train:  69%|██████▉   | 197/285 [03:26<01:23,  1.06it/s]Loading train:  69%|██████▉   | 198/285 [03:27<01:23,  1.04it/s]Loading train:  70%|██████▉   | 199/285 [03:28<01:23,  1.03it/s]Loading train:  70%|███████   | 200/285 [03:29<01:23,  1.02it/s]Loading train:  71%|███████   | 201/285 [03:30<01:23,  1.01it/s]Loading train:  71%|███████   | 202/285 [03:31<01:22,  1.00it/s]Loading train:  71%|███████   | 203/285 [03:32<01:20,  1.02it/s]Loading train:  72%|███████▏  | 204/285 [03:33<01:21,  1.01s/it]Loading train:  72%|███████▏  | 205/285 [03:34<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [03:35<01:19,  1.01s/it]Loading train:  73%|███████▎  | 207/285 [03:36<01:19,  1.02s/it]Loading train:  73%|███████▎  | 208/285 [03:37<01:17,  1.00s/it]Loading train:  73%|███████▎  | 209/285 [03:38<01:18,  1.03s/it]Loading train:  74%|███████▎  | 210/285 [03:39<01:14,  1.00it/s]Loading train:  74%|███████▍  | 211/285 [03:40<01:14,  1.00s/it]Loading train:  74%|███████▍  | 212/285 [03:41<01:13,  1.00s/it]Loading train:  75%|███████▍  | 213/285 [03:42<01:12,  1.01s/it]Loading train:  75%|███████▌  | 214/285 [03:43<01:09,  1.02it/s]Loading train:  75%|███████▌  | 215/285 [03:44<01:06,  1.05it/s]Loading train:  76%|███████▌  | 216/285 [03:45<01:02,  1.10it/s]Loading train:  76%|███████▌  | 217/285 [03:46<01:01,  1.10it/s]Loading train:  76%|███████▋  | 218/285 [03:46<00:59,  1.12it/s]Loading train:  77%|███████▋  | 219/285 [03:47<00:57,  1.15it/s]Loading train:  77%|███████▋  | 220/285 [03:48<00:56,  1.15it/s]Loading train:  78%|███████▊  | 221/285 [03:49<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [03:50<00:55,  1.14it/s]Loading train:  78%|███████▊  | 223/285 [03:51<00:54,  1.15it/s]Loading train:  79%|███████▊  | 224/285 [03:52<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [03:52<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:53<00:49,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:54<00:50,  1.15it/s]Loading train:  80%|████████  | 228/285 [03:55<00:49,  1.16it/s]Loading train:  80%|████████  | 229/285 [03:56<00:49,  1.13it/s]Loading train:  81%|████████  | 230/285 [03:57<00:49,  1.11it/s]Loading train:  81%|████████  | 231/285 [03:58<00:49,  1.09it/s]Loading train:  81%|████████▏ | 232/285 [03:59<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [04:00<00:50,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [04:01<00:53,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [04:02<00:54,  1.08s/it]Loading train:  83%|████████▎ | 236/285 [04:03<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:04<00:51,  1.07s/it]Loading train:  84%|████████▎ | 238/285 [04:05<00:50,  1.08s/it]Loading train:  84%|████████▍ | 239/285 [04:06<00:48,  1.06s/it]Loading train:  84%|████████▍ | 240/285 [04:08<00:47,  1.06s/it]Loading train:  85%|████████▍ | 241/285 [04:09<00:47,  1.08s/it]Loading train:  85%|████████▍ | 242/285 [04:10<00:47,  1.10s/it]Loading train:  85%|████████▌ | 243/285 [04:11<00:45,  1.09s/it]Loading train:  86%|████████▌ | 244/285 [04:12<00:45,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:13<00:43,  1.09s/it]Loading train:  86%|████████▋ | 246/285 [04:14<00:41,  1.07s/it]Loading train:  87%|████████▋ | 247/285 [04:15<00:40,  1.07s/it]Loading train:  87%|████████▋ | 248/285 [04:16<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:17<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:18<00:35,  1.02s/it]Loading train:  88%|████████▊ | 251/285 [04:19<00:32,  1.04it/s]Loading train:  88%|████████▊ | 252/285 [04:20<00:31,  1.05it/s]Loading train:  89%|████████▉ | 253/285 [04:21<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [04:22<00:28,  1.10it/s]Loading train:  89%|████████▉ | 255/285 [04:22<00:26,  1.12it/s]Loading train:  90%|████████▉ | 256/285 [04:23<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [04:24<00:25,  1.09it/s]Loading train:  91%|█████████ | 258/285 [04:25<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:26<00:23,  1.08it/s]Loading train:  91%|█████████ | 260/285 [04:27<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:28<00:21,  1.13it/s]Loading train:  92%|█████████▏| 262/285 [04:29<00:20,  1.12it/s]Loading train:  92%|█████████▏| 263/285 [04:30<00:19,  1.12it/s]Loading train:  93%|█████████▎| 264/285 [04:31<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:32<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:33<00:17,  1.09it/s]Loading train:  94%|█████████▎| 267/285 [04:33<00:16,  1.10it/s]Loading train:  94%|█████████▍| 268/285 [04:35<00:16,  1.02it/s]Loading train:  94%|█████████▍| 269/285 [04:36<00:15,  1.01it/s]Loading train:  95%|█████████▍| 270/285 [04:37<00:15,  1.00s/it]Loading train:  95%|█████████▌| 271/285 [04:38<00:14,  1.02s/it]Loading train:  95%|█████████▌| 272/285 [04:39<00:13,  1.03s/it]Loading train:  96%|█████████▌| 273/285 [04:40<00:12,  1.04s/it]Loading train:  96%|█████████▌| 274/285 [04:41<00:11,  1.05s/it]Loading train:  96%|█████████▋| 275/285 [04:42<00:10,  1.08s/it]Loading train:  97%|█████████▋| 276/285 [04:43<00:09,  1.08s/it]Loading train:  97%|█████████▋| 277/285 [04:44<00:08,  1.08s/it]Loading train:  98%|█████████▊| 278/285 [04:45<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [04:46<00:06,  1.08s/it]Loading train:  98%|█████████▊| 280/285 [04:47<00:05,  1.07s/it]Loading train:  99%|█████████▊| 281/285 [04:49<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [04:50<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [04:51<00:02,  1.06s/it]Loading train: 100%|█████████▉| 284/285 [04:52<00:01,  1.10s/it]Loading train: 100%|██████████| 285/285 [04:53<00:00,  1.09s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 50.07it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:05, 53.74it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:04, 60.63it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 74.33it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 94.10it/s]concatenating: train:  32%|███▏      | 91/285 [00:00<00:01, 117.42it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:01, 141.35it/s]concatenating: train:  52%|█████▏    | 148/285 [00:00<00:00, 167.42it/s]concatenating: train:  62%|██████▏   | 176/285 [00:00<00:00, 189.32it/s]concatenating: train:  73%|███████▎  | 207/285 [00:01<00:00, 212.89it/s]concatenating: train:  82%|████████▏ | 234/285 [00:01<00:00, 227.23it/s]concatenating: train:  93%|█████████▎| 264/285 [00:01<00:00, 244.34it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 209.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 49.01it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 40)   0           batch_normalization_7[0][0]      2019-07-07 05:03:12.056688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:03:12.056812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:03:12.056828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:03:12.056838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:03:12.057282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 23s - loss: 10029.7998 - acc: 0.8822 - mDice: 0.2382 - val_loss: 4153.3172 - val_acc: 0.9258 - val_mDice: 0.4123

Epoch 00001: val_mDice improved from -inf to 0.41235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 4418.9824 - acc: 0.9146 - mDice: 0.4281 - val_loss: 3191.5350 - val_acc: 0.9406 - val_mDice: 0.4993

Epoch 00002: val_mDice improved from 0.41235 to 0.49934, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 3274.7248 - acc: 0.9272 - mDice: 0.5209 - val_loss: 2685.2489 - val_acc: 0.9451 - val_mDice: 0.5518

Epoch 00003: val_mDice improved from 0.49934 to 0.55181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 2769.0733 - acc: 0.9338 - mDice: 0.5738 - val_loss: 2586.2874 - val_acc: 0.9475 - val_mDice: 0.5649

Epoch 00004: val_mDice improved from 0.55181 to 0.56487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 2526.3682 - acc: 0.9374 - mDice: 0.6020 - val_loss: 2367.6953 - val_acc: 0.9497 - val_mDice: 0.5909

Epoch 00005: val_mDice improved from 0.56487 to 0.59094, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 15s - loss: 2354.9389 - acc: 0.9401 - mDice: 0.6230 - val_loss: 2237.0244 - val_acc: 0.9502 - val_mDice: 0.6080

Epoch 00006: val_mDice improved from 0.59094 to 0.60796, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 2221.8990 - acc: 0.9421 - mDice: 0.6395 - val_loss: 2274.6148 - val_acc: 0.9503 - val_mDice: 0.6030

Epoch 00007: val_mDice did not improve from 0.60796
Epoch 8/300
 - 14s - loss: 2120.2555 - acc: 0.9437 - mDice: 0.6522 - val_loss: 2250.1281 - val_acc: 0.9518 - val_mDice: 0.6087

Epoch 00008: val_mDice improved from 0.60796 to 0.60872, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 15s - loss: 2041.1894 - acc: 0.9449 - mDice: 0.6632 - val_loss: 2207.8986 - val_acc: 0.9509 - val_mDice: 0.6120

Epoch 00009: val_mDice improved from 0.60872 to 0.61196, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 1967.4946 - acc: 0.9459 - mDice: 0.6722 - val_loss: 2198.3109 - val_acc: 0.9508 - val_mDice: 0.6148

Epoch 00010: val_mDice improved from 0.61196 to 0.61480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 15s - loss: 1898.7978 - acc: 0.9469 - mDice: 0.6811 - val_loss: 2232.4985 - val_acc: 0.9527 - val_mDice: 0.6136

Epoch 00011: val_mDice did not improve from 0.61480
Epoch 12/300
 - 15s - loss: 1838.0605 - acc: 0.9478 - mDice: 0.6892 - val_loss: 2205.1452 - val_acc: 0.9532 - val_mDice: 0.6143

Epoch 00012: val_mDice did not improve from 0.61480
Epoch 13/300
 - 15s - loss: 1791.2464 - acc: 0.9485 - mDice: 0.6957 - val_loss: 2271.0226 - val_acc: 0.9521 - val_mDice: 0.6078

Epoch 00013: val_mDice did not improve from 0.61480
Epoch 14/300
 - 14s - loss: 1736.6819 - acc: 0.9491 - mDice: 0.7030 - val_loss: 2248.0803 - val_acc: 0.9528 - val_mDice: 0.6127

Epoch 00014: val_mDice did not improve from 0.61480
Epoch 15/300
 - 15s - loss: 1703.8355 - acc: 0.9498 - mDice: 0.7078 - val_loss: 2196.4527 - val_acc: 0.9531 - val_mDice: 0.6149

Epoch 00015: val_mDice improved from 0.61480 to 0.61487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 14s - loss: 1660.1094 - acc: 0.9504 - mDice: 0.7137 - val_loss: 2267.5184 - val_acc: 0.9526 - val_mDice: 0.6089

Epoch 00016: val_mDice did not improve from 0.61487
Epoch 17/300
 - 15s - loss: 1631.0939 - acc: 0.9508 - mDice: 0.7179 - val_loss: 2219.1175 - val_acc: 0.9521 - val_mDice: 0.6125

Epoch 00017: val_mDice did not improve from 0.61487
Epoch 18/300
 - 15s - loss: 1598.9399 - acc: 0.9514 - mDice: 0.7226 - val_loss: 2245.5599 - val_acc: 0.9530 - val_mDice: 0.6109

Epoch 00018: val_mDice did not improve from 0.61487
Epoch 19/300
 - 14s - loss: 1581.7860 - acc: 0.9519 - mDice: 0.7270 - val_loss: 2257.9546 - val_acc: 0.9523 - val_mDice: 0.6104

Epoch 00019: val_mDice did not improve from 0.61487
Epoch 20/300
 - 15s - loss: 1527.2151 - acc: 0.9524 - mDice: 0.7328 - val_loss: 2268.6934 - val_acc: 0.9528 - val_mDice: 0.6100

Epoch 00020: val_mDice did not improve from 0.61487
Epoch 21/300
 - 15s - loss: 1503.8744 - acc: 0.9528 - mDice: 0.7362 - val_loss: 2311.9170 - val_acc: 0.9535 - val_mDice: 0.6082

Epoch 00021: val_mDice did not improve from 0.61487
Epoch 22/300
 - 15s - loss: 1485.9442 - acc: 0.9532 - mDice: 0.7392 - val_loss: 2264.5125 - val_acc: 0.9532 - val_mDice: 0.6107

Epoch 00022: val_mDice did not improve from 0.61487
Epoch 23/300
 - 15s - loss: 1448.1143 - acc: 0.9538 - mDice: 0.7446 - val_loss: 2289.1624 - val_acc: 0.9538 - val_mDice: 0.6072

Epoch 00023: val_mDice did not improve from 0.61487
Epoch 24/300
 - 15s - loss: 1431.3873 - acc: 0.9541 - mDice: 0.7471 - val_loss: 2361.4851 - val_acc: 0.9528 - val_mDice: 0.5997

Epoch 00024: val_mDice did not improve from 0.61487
Epoch 25/300
 - 15s - loss: 1409.1778 - acc: 0.9544 - mDice: 0.7504 - val_loss: 2161.2637 - val_acc: 0.9542 - val_mDice: 0.6198

Epoch 00025: val_mDice improved from 0.61487 to 0.61977, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 26/300
 - 15s - loss: 1387.5121 - acc: 0.9547 - mDice: 0.7537 - val_loss: 2231.8724 - val_acc: 0.9528 - val_mDice: 0.6129

Epoch 00026: val_mDice did not improve from 0.61977
Epoch 27/300
 - 15s - loss: 1358.8836 - acc: 0.9551 - mDice: 0.7579 - val_loss: 2202.8161 - val_acc: 0.9540 - val_mDice: 0.6175

Epoch 00027: val_mDice did not improve from 0.61977
Epoch 28/300
 - 15s - loss: 1345.2466 - acc: 0.9554 - mDice: 0.7600 - val_loss: 2315.7921 - val_acc: 0.9527 - val_mDice: 0.6014

Epoch 00028: val_mDice did not improve from 0.61977
Epoch 29/300
 - 15s - loss: 1322.2689 - acc: 0.9557 - mDice: 0.7636 - val_loss: 2269.6846 - val_acc: 0.9536 - val_mDice: 0.6106

Epoch 00029: val_mDice did not improve from 0.61977
Epoch 30/300
 - 15s - loss: 1298.7406 - acc: 0.9560 - mDice: 0.7671 - val_loss: 2446.3424 - val_acc: 0.9539 - val_mDice: 0.5975

Epoch 00030: val_mDice did not improve from 0.61977
Epoch 31/300
 - 15s - loss: 1289.2248 - acc: 0.9562 - mDice: 0.7685 - val_loss: 2292.6970 - val_acc: 0.9549 - val_mDice: 0.6082

Epoch 00031: val_mDice did not improve from 0.61977
Epoch 32/300
 - 14s - loss: 1274.8394 - acc: 0.9565 - mDice: 0.7709 - val_loss: 2551.1218 - val_acc: 0.9532 - val_mDice: 0.5927

Epoch 00032: val_mDice did not improve from 0.61977
Epoch 33/300
 - 15s - loss: 1266.8367 - acc: 0.9566 - mDice: 0.7721 - val_loss: 2290.9236 - val_acc: 0.9532 - val_mDice: 0.6066

Epoch 00033: val_mDice did not improve from 0.61977
Epoch 34/300
 - 14s - loss: 1240.3197 - acc: 0.9570 - mDice: 0.7762 - val_loss: 2350.6375 - val_acc: 0.9531 - val_mDice: 0.6052

Epoch 00034: val_mDice did not improve from 0.61977
Epoch 35/300
 - 14s - loss: 1223.5329 - acc: 0.9573 - mDice: 0.7788 - val_loss: 2260.4663 - val_acc: 0.9539 - val_mDice: 0.6123

Epoch 00035: val_mDice did not improve from 0.61977
Epoch 36/300
 - 15s - loss: 1217.1113 - acc: 0.9574 - mDice: 0.7799 - val_loss: 2128.6518 - val_acc: 0.9539 - val_mDice: 0.6240

Epoch 00036: val_mDice improved from 0.61977 to 0.62404, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 37/300
 - 15s - loss: 1203.2647 - acc: 0.9576 - mDice: 0.7821 - val_loss: 2427.2849 - val_acc: 0.9533 - val_mDice: 0.5948

Epoch 00037: val_mDice did not improve from 0.62404
Epoch 38/300
 - 14s - loss: 1192.2024 - acc: 0.9578 - mDice: 0.7838 - val_loss: 2227.2984 - val_acc: 0.9537 - val_mDice: 0.6121

Epoch 00038: val_mDice did not improve from 0.62404
Epoch 39/300
 - 15s - loss: 1175.7439 - acc: 0.9580 - mDice: 0.7864 - val_loss: 2338.3160 - val_acc: 0.9535 - val_mDice: 0.6065

Epoch 00039: val_mDice did not improve from 0.62404
Epoch 40/300
 - 15s - loss: 1161.0946 - acc: 0.9583 - mDice: 0.7887 - val_loss: 2346.3634 - val_acc: 0.9519 - val_mDice: 0.6005

Epoch 00040: val_mDice did not improve from 0.62404
Epoch 41/300
 - 14s - loss: 1157.6491 - acc: 0.9584 - mDice: 0.7893 - val_loss: 2253.2231 - val_acc: 0.9521 - val_mDice: 0.6105

Epoch 00041: val_mDice did not improve from 0.62404
Epoch 42/300
 - 15s - loss: 1157.7040 - acc: 0.9585 - mDice: 0.7894 - val_loss: 2393.6324 - val_acc: 0.9528 - val_mDice: 0.5981

Epoch 00042: val_mDice did not improve from 0.62404
Epoch 43/300
 - 19s - loss: 1131.4447 - acc: 0.9588 - mDice: 0.7934 - val_loss: 2350.0906 - val_acc: 0.9526 - val_mDice: 0.6048

Epoch 00043: val_mDice did not improve from 0.62404
Epoch 44/300
 - 19s - loss: 1130.8068 - acc: 0.9589 - mDice: 0.7936 - val_loss: 2415.7757 - val_acc: 0.9526 - val_mDice: 0.6042

Epoch 00044: val_mDice did not improve from 0.62404
Epoch 45/300
 - 19s - loss: 1118.8881 - acc: 0.9590 - mDice: 0.7954 - val_loss: 2242.9168 - val_acc: 0.9539 - val_mDice: 0.6116

Epoch 00045: val_mDice did not improve from 0.62404
Epoch 46/300
 - 19s - loss: 1109.4724 - acc: 0.9593 - mDice: 0.7970 - val_loss: 2328.6636 - val_acc: 0.9537 - val_mDice: 0.6006

Epoch 00046: val_mDice did not improve from 0.62404
Epoch 47/300
 - 19s - loss: 1100.7187 - acc: 0.9593 - mDice: 0.7984 - val_loss: 2223.1070 - val_acc: 0.9536 - val_mDice: 0.6126

Epoch 00047: val_mDice did not improve from 0.62404
Epoch 48/300
 - 19s - loss: 1095.6203 - acc: 0.9594 - mDice: 0.7992 - val_loss: 2449.6907 - val_acc: 0.9518 - val_mDice: 0.5918

Epoch 00048: val_mDice did not improve from 0.62404
Epoch 49/300
 - 20s - loss: 1079.5673 - acc: 0.9597 - mDice: 0.8018 - val_loss: 2578.2405 - val_acc: 0.9506 - val_mDice: 0.5832

Epoch 00049: val_mDice did not improve from 0.62404
Epoch 50/300
 - 19s - loss: 1084.6151 - acc: 0.9597 - mDice: 0.8010 - val_loss: 2265.0566 - val_acc: 0.9539 - val_mDice: 0.6104

Epoch 00050: val_mDice did not improve from 0.62404
Epoch 51/300
 - 19s - loss: 1075.5073 - acc: 0.9598 - mDice: 0.8025 - val_loss: 2189.6545 - val_acc: 0.9542 - val_mDice: 0.6158

Epoch 00051: val_mDice did not improve from 0.62404
Epoch 52/300
 - 20s - loss: 1068.0262 - acc: 0.9600 - mDice: 0.8037 - val_loss: 2384.4389 - val_acc: 0.9538 - val_mDice: 0.5983

Epoch 00052: val_mDice did not improve from 0.62404
Epoch 53/300
 - 19s - loss: 1054.3068 - acc: 0.9601 - mDice: 0.8059 - val_loss: 2342.9675 - val_acc: 0.9543 - val_mDice: 0.6040

Epoch 00053: val_mDice did not improve from 0.62404
Epoch 54/300
 - 20s - loss: 1054.7899 - acc: 0.9601 - mDice: 0.8058 - val_loss: 2509.2979 - val_acc: 0.9534 - val_mDice: 0.5850

Epoch 00054: val_mDice did not improve from 0.62404
Epoch 55/300
 - 20s - loss: 1045.9112 - acc: 0.9603 - mDice: 0.8074 - val_loss: 2273.4656 - val_acc: 0.9536 - val_mDice: 0.6084

Epoch 00055: val_mDice did not improve from 0.62404
Epoch 56/300
 - 19s - loss: 1046.7922 - acc: 0.9603 - mDice: 0.8073 - val_loss: 2185.8573 - val_acc: 0.9542 - val_mDice: 0.6176

Epoch 00056: val_mDice did not improve from 0.62404
Epoch 57/300
 - 19s - loss: 1033.7523 - acc: 0.9605 - mDice: 0.8093 - val_loss: 2285.3032 - val_acc: 0.9527 - val_mDice: 0.6077

Epoch 00057: val_mDice did not improve from 0.62404
Epoch 58/300
 - 18s - loss: 1031.3912 - acc: 0.9606 - mDice: 0.8098 - val_loss: 2225.0536 - val_acc: 0.9532 - val_mDice: 0.6122

Epoch 00058: val_mDice did not improve from 0.62404
Epoch 59/300
 - 19s - loss: 1012.7983 - acc: 0.9608 - mDice: 0.8127 - val_loss: 2350.4780 - val_acc: 0.9527 - val_mDice: 0.6038

Epoch 00059: val_mDice did not improve from 0.62404
Epoch 60/300
 - 20s - loss: 1013.9499 - acc: 0.9608 - mDice: 0.8125 - val_loss: 2321.1661 - val_acc: 0.9540 - val_mDice: 0.6031

Epoch 00060: val_mDice did not improve from 0.62404
Epoch 61/300
 - 20s - loss: 1012.5818 - acc: 0.9609 - mDice: 0.8128 - val_loss: 2317.3522 - val_acc: 0.9526 - val_mDice: 0.6007

Epoch 00061: val_mDice did not improve from 0.62404
Epoch 62/300
 - 16s - loss: 1004.0215 - acc: 0.9610 - mDice: 0.8141 - val_loss: 2381.2459 - val_acc: 0.9538 - val_mDice: 0.5999

Epoch 00062: val_mDice did not improve from 0.62404
Epoch 63/300
 - 15s - loss: 1008.9988 - acc: 0.9610 - mDice: 0.8134 - val_loss: 2256.7088 - val_acc: 0.9549 - val_mDice: 0.6095

Epoch 00063: val_mDice did not improve from 0.62404
Epoch 64/300
 - 15s - loss: 995.3543 - acc: 0.9612 - mDice: 0.8157 - val_loss: 2302.7939 - val_acc: 0.9521 - val_mDice: 0.6032

Epoch 00064: val_mDice did not improve from 0.62404
Epoch 65/300
 - 14s - loss: 997.3269 - acc: 0.9611 - mDice: 0.8153 - val_loss: 2277.8714 - val_acc: 0.9527 - val_mDice: 0.6058

Epoch 00065: val_mDice did not improve from 0.62404
Epoch 66/300
 - 14s - loss: 994.4424 - acc: 0.9613 - mDice: 0.8159 - val_loss: 2449.4554 - val_acc: 0.9546 - val_mDice: 0.5950

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.10s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:08,  1.51s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:27,  1.58s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:24,  1.58s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:47,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:30,  1.61s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:56,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:36,  1.86s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:44,  1.89s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:27,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:50,  1.93s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:04,  1.99s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:14,  2.03s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<09:14,  2.04s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<09:08,  2.02s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:05,  2.02s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:08,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<09:06,  2.04s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<09:09,  2.06s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<09:13,  2.08s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<09:18,  2.11s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:15,  2.10s/it]predicting train subjects:   8%|▊         | 22/285 [00:43<09:05,  2.08s/it]predicting train subjects:   8%|▊         | 23/285 [00:45<09:08,  2.09s/it]predicting train subjects:   8%|▊         | 24/285 [00:47<09:17,  2.14s/it]predicting train subjects:   9%|▉         | 25/285 [00:49<09:15,  2.14s/it]predicting train subjects:   9%|▉         | 26/285 [00:51<09:10,  2.12s/it]predicting train subjects:   9%|▉         | 27/285 [00:53<09:08,  2.12s/it]predicting train subjects:  10%|▉         | 28/285 [00:55<08:51,  2.07s/it]predicting train subjects:  10%|█         | 29/285 [00:57<08:33,  2.01s/it]predicting train subjects:  11%|█         | 30/285 [00:59<08:28,  1.99s/it]predicting train subjects:  11%|█         | 31/285 [01:01<08:23,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [01:03<08:09,  1.93s/it]predicting train subjects:  12%|█▏        | 33/285 [01:05<08:01,  1.91s/it]predicting train subjects:  12%|█▏        | 34/285 [01:07<07:57,  1.90s/it]predicting train subjects:  12%|█▏        | 35/285 [01:09<08:00,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<07:53,  1.90s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<07:39,  1.86s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<07:36,  1.87s/it]predicting train subjects:  15%|█▍        | 42/285 [01:22<07:34,  1.87s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:33,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:36,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:36,  1.90s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:17,  1.83s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:05,  1.79s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<06:52,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<06:44,  1.71s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<06:41,  1.71s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<06:37,  1.70s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<06:35,  1.70s/it]predicting train subjects:  19%|█▊        | 53/285 [01:41<06:34,  1.70s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<06:30,  1.69s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<06:23,  1.67s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:15,  1.65s/it]predicting train subjects:  20%|██        | 58/285 [01:49<06:13,  1.64s/it]predicting train subjects:  21%|██        | 59/285 [01:50<06:07,  1.62s/it]predicting train subjects:  21%|██        | 60/285 [01:52<06:07,  1.63s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<06:08,  1.64s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:08,  1.65s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:11,  1.67s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:19,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:30,  1.78s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<06:35,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:28,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:26,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:22,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:19,  1.77s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:13,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:11,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:06,  1.74s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:13,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:06,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:05,  1.76s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:04,  1.77s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<05:59,  1.75s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<05:59,  1.76s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:01,  1.78s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:58,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:58,  1.78s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<06:04,  1.82s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:08,  1.85s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:13,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:42<06:13,  1.89s/it]predicting train subjects:  31%|███       | 89/285 [02:44<06:13,  1.91s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<06:10,  1.90s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<06:08,  1.90s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<06:02,  1.88s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:55,  1.85s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:51,  1.84s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:50,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:53,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:55,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:54,  1.91s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:54,  1.92s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:48,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:46,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:43,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:37,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:34,  1.86s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:33,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:32,  1.87s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:30,  1.87s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:29,  1.87s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:28,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:26<05:39,  1.95s/it]predicting train subjects:  39%|███▉      | 112/285 [03:28<05:32,  1.92s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:25,  1.89s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:22,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:20,  1.89s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:17,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:14,  1.87s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<05:09,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<05:03,  1.84s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:54,  1.79s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:39,  1.72s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:28,  1.66s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:26,  1.66s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:33,  1.71s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:30,  1.70s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:27,  1.69s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:26,  1.70s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:21,  1.68s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:20,  1.68s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:17,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:14,  1.66s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:10,  1.66s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<04:11,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<04:10,  1.68s/it]predicting train subjects:  48%|████▊     | 137/285 [04:11<04:04,  1.65s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<04:01,  1.65s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<04:01,  1.66s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<03:59,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:59,  1.66s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:52,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:39,  1.56s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:37,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:35,  1.55s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:26<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:32,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:29,  1.54s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:31<03:26,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:24,  1.53s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:21,  1.52s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:20,  1.52s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:16,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:05,  1.50s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:01,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<03:00,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<02:56,  1.51s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<02:55,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:54,  1.51s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<02:51,  1.51s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:47,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:45,  1.49s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:09<02:43,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:43,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:34,  1.48s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:19<02:31,  1.47s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:29,  1.47s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:22<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:23<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:25<02:23,  1.45s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:21,  1.44s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:20,  1.45s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:19,  1.46s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:17,  1.45s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:17,  1.46s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:16,  1.47s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:37<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:17,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:42<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:23,  1.65s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:22,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:47<02:21,  1.67s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:21,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:52<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:54<02:17,  1.70s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:55<02:15,  1.69s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:57<02:15,  1.72s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:59<02:15,  1.73s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:00<02:13,  1.73s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:02<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:04<02:09,  1.73s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:06<02:07,  1.72s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:07<02:05,  1.72s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:09<02:04,  1.73s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:11<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:12<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:14<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:15<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:17<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<01:41,  1.53s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:20<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:21<01:40,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:23<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:24<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:26<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:28<01:35,  1.59s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:29<01:33,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:31<01:31,  1.58s/it]predicting train subjects:  80%|████████  | 228/285 [06:32<01:29,  1.58s/it]predicting train subjects:  80%|████████  | 229/285 [06:34<01:27,  1.56s/it]predicting train subjects:  81%|████████  | 230/285 [06:35<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:37<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:39<01:27,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:41<01:28,  1.70s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:43<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:45<01:31,  1.84s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:46<01:30,  1.86s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:48<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:50<01:28,  1.88s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:52<01:27,  1.90s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:54<01:25,  1.90s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:56<01:22,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:58<01:21,  1.90s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:00<01:19,  1.88s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:16,  1.86s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:03<01:14,  1.86s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:05<01:12,  1.85s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:09,  1.84s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:09<01:08,  1.84s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<01:06,  1.86s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:12<01:01,  1.75s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:14<00:57,  1.69s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:15<00:53,  1.63s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:17<00:51,  1.60s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:18<00:48,  1.56s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:20<00:45,  1.53s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:21<00:43,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:23<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:24<00:42,  1.56s/it]predicting train subjects:  91%|█████████ | 259/285 [07:26<00:40,  1.54s/it]predicting train subjects:  91%|█████████ | 260/285 [07:27<00:38,  1.54s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:29<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:30<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:32<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:33<00:31,  1.50s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:35<00:29,  1.48s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:36<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:38<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:40<00:28,  1.66s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:42<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:44<00:26,  1.78s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:46<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:48<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:50<00:22,  1.91s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:52<00:21,  1.94s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:54<00:19,  1.94s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:55<00:17,  1.94s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:58<00:15,  1.97s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:59<00:13,  1.96s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:01<00:11,  1.96s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:03<00:09,  1.94s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:05<00:07,  1.97s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:07<00:05,  1.95s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:09<00:03,  1.97s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:11<00:01,  1.96s/it]predicting train subjects: 100%|██████████| 285/285 [08:13<00:00,  1.95s/it]
Epoch 00066: val_mDice did not improve from 0.62404
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
{'val_loss': [4153.317186408869, 3191.5349543907123, 2685.2488624956354, 2586.287420347416, 2367.6953056804296, 2237.024426337727, 2274.614837475995, 2250.1281301828735, 2207.8986489066865, 2198.310917859637, 2232.4985174253666, 2205.1451641061453, 2271.022642338076, 2248.0803181738825, 2196.452702186627, 2267.5184251156597, 2219.117538025925, 2245.559878557088, 2257.9546171220322, 2268.6934439376746, 2311.9170003709846, 2264.512487997556, 2289.1623957969623, 2361.485070596194, 2161.2636909697976, 2231.872364917947, 2202.816096641498, 2315.7920972088864, 2269.6846125938373, 2446.3423683550104, 2292.696956016498, 2551.121805713163, 2290.92356898132, 2350.6375493736905, 2260.466322232891, 2128.651774997818, 2427.2848657362956, 2227.2984284981667, 2338.31602435405, 2346.3634258248953, 2253.2231104333973, 2393.6324346957927, 2350.09059117493, 2415.7756784108765, 2242.916787600384, 2328.663624683572, 2223.1069608720322, 2449.69073520426, 2578.2404703321404, 2265.0566447167425, 2189.654489186889, 2384.4389184706706, 2342.9674720124826, 2509.2978542903284, 2273.4655679883904, 2185.8573250370987, 2285.303202197538, 2225.0536427417946, 2350.4779782428423, 2321.1661151907297, 2317.35223354574, 2381.2459191689945, 2256.70883161662, 2302.79386893331, 2277.8714060863304, 2449.455363183048], 'val_acc': [0.9258227055299215, 0.9406197094384519, 0.9451009994112579, 0.947476948439742, 0.9497413398833249, 0.9502392710920152, 0.950315684912591, 0.9517536453028631, 0.9508900415963967, 0.9508012236829576, 0.9527474402049401, 0.9531813094069838, 0.952063572806353, 0.9527825520025285, 0.9531358626967702, 0.9525573639896329, 0.9521152213965048, 0.9530201427763401, 0.9523114831753949, 0.9527846255115957, 0.953495335312529, 0.9532494867980147, 0.953842430141385, 0.9527742932628653, 0.9542453049281456, 0.9528321244197184, 0.9539540120343256, 0.9526895674247315, 0.9535718070728153, 0.9539498610203493, 0.9549415700928459, 0.9532474132889476, 0.9531792155857193, 0.9531420376047742, 0.953861041441976, 0.9539188686029871, 0.9532742666798597, 0.95367507461729, 0.9534829561936788, 0.9518652475080011, 0.9520676891896978, 0.9527990578273156, 0.9526048582359399, 0.9526048682255452, 0.9538589842492642, 0.9537350042572235, 0.9536296395616158, 0.9517660600513054, 0.9505615600660526, 0.9538734382091287, 0.9541750696784291, 0.9538403749465942, 0.9542845667407499, 0.9533610430509685, 0.9536048463602972, 0.9541998442324846, 0.9526689145818102, 0.9532329480075303, 0.952697863791908, 0.9539891348204799, 0.9525718099578133, 0.953768042212758, 0.9548568609040543, 0.9521152350489653, 0.9527309140679556, 0.9545944589476346], 'val_mDice': [0.41234637105931116, 0.4993438484282467, 0.551810487022613, 0.5648661605472671, 0.5909384592285369, 0.6079571053968461, 0.6030336385332672, 0.608717037978785, 0.611959214317066, 0.6147983906655338, 0.61360516794567, 0.6142607001618966, 0.6077952747904388, 0.6127445224943108, 0.6148679036667893, 0.6089277350702765, 0.6125263728243012, 0.610881712183606, 0.6104413883646107, 0.60999033737449, 0.6081665950780474, 0.6107306979887979, 0.6072456423796755, 0.5997116758836715, 0.6197684673623666, 0.6128689783245491, 0.6175106254369853, 0.6013669807817683, 0.610559720233832, 0.5975290283810493, 0.608184630644388, 0.5927013015613876, 0.6066391534645464, 0.605221897863143, 0.6123069717897384, 0.6240402077163398, 0.5948213222306534, 0.6120871022426883, 0.6064729923642548, 0.600533795090361, 0.6105476944140216, 0.5980517224892558, 0.6048262602124135, 0.6041770753913751, 0.6115756977203838, 0.6006024399949186, 0.6125594417476121, 0.5917819478658325, 0.5831739676065285, 0.6104070870569964, 0.6157679278091346, 0.5983133922076093, 0.6039899927277804, 0.5850441918692775, 0.6083778978726051, 0.6175578992460027, 0.6076575930558104, 0.6121521428976645, 0.6037613486444484, 0.6030649879125244, 0.6006521113092007, 0.5998836242952826, 0.6094804615947788, 0.6031526586862915, 0.6057796991071221, 0.5950195682781368], 'loss': [10029.799823409247, 4418.982362066464, 3274.724773097211, 2769.073311017844, 2526.3681541298683, 2354.938897655548, 2221.8990417550276, 2120.255537262553, 2041.189435167813, 1967.4946153635658, 1898.7977848662756, 1838.0604738694938, 1791.2464497291303, 1736.6819010308077, 1703.835544170452, 1660.1094353337555, 1631.0939351298907, 1598.9398920688616, 1581.7860317576146, 1527.2150540372384, 1503.8744041085938, 1485.9441817789373, 1448.1142914564637, 1431.3872807082394, 1409.1778063101224, 1387.5121372867582, 1358.8835980687668, 1345.2465511064606, 1322.2689281517848, 1298.7405942700073, 1289.2248311439348, 1274.83941095586, 1266.8367157755292, 1240.3197036077497, 1223.5329196261564, 1217.11127619808, 1203.264706101944, 1192.202420687339, 1175.7438969763527, 1161.0946116657547, 1157.6490543436742, 1157.7039681102162, 1131.444696999292, 1130.806829684064, 1118.8880633849749, 1109.472354365151, 1100.7186929970667, 1095.6203449931347, 1079.5673034146073, 1084.61508107075, 1075.5072532276931, 1068.026216067232, 1054.3068339921936, 1054.7899227297116, 1045.9112299348876, 1046.7921964147695, 1033.7522851933477, 1031.391208149848, 1012.7982674432433, 1013.9499029480849, 1012.5817903205269, 1004.0215426012294, 1008.998757978948, 995.3542809030095, 997.3269152899179, 994.4424466599073], 'acc': [0.8822276211240687, 0.9146194071605064, 0.9271958915796826, 0.9338375877518584, 0.9374145981039813, 0.9400740141384508, 0.942105207358315, 0.9436726596975994, 0.9449302868303939, 0.9459002361786625, 0.9469158998969774, 0.9477799815404688, 0.9485102412870887, 0.9491388441547512, 0.9497570335186551, 0.9503843086905017, 0.950838141724809, 0.9514010617347476, 0.9518841633245606, 0.9524085948127176, 0.9528135229517877, 0.9531576445397323, 0.9538389004125398, 0.9540997734809193, 0.9543910228045871, 0.9546946402819522, 0.9551177784824065, 0.9553686416387415, 0.9557032784919101, 0.9560112467285309, 0.9562116161838518, 0.9565063918424415, 0.9566046808301075, 0.9569596404454319, 0.9573086944354087, 0.9574342405807088, 0.9576151906960307, 0.9578254516559335, 0.9580352902412415, 0.9583306264126783, 0.9584061588300131, 0.9584718007198911, 0.9587570250108997, 0.9588806366071249, 0.9590020333621426, 0.9592642578662633, 0.9593333013468945, 0.9594391466232369, 0.9596997609384426, 0.9596685815056154, 0.9597743483262607, 0.9599645858262594, 0.9601215120786598, 0.960144048708144, 0.9602544439085026, 0.9603221027668405, 0.9604788454268066, 0.9605766946463977, 0.9607980103607265, 0.9607862893464187, 0.9608773292652968, 0.960953744516985, 0.9610354412381773, 0.9612267677979132, 0.9611483768572521, 0.9612976644080836], 'mDice': [0.23820467600845951, 0.42807347756423925, 0.5209251530782946, 0.573836112163937, 0.6019701980231705, 0.6229546382227116, 0.6394812015983041, 0.6522020327876735, 0.6631788083407284, 0.672178935344998, 0.6811157209435214, 0.689161748721458, 0.6957192184566562, 0.7029557504085705, 0.7077552365760684, 0.7137240083199052, 0.7179217732658405, 0.7226145244438101, 0.726985190345937, 0.7327758625963727, 0.7362269461041319, 0.7391593043311127, 0.7445838543579383, 0.7471120116900375, 0.7504434901075642, 0.7536813939788309, 0.757935383887821, 0.7600420233529545, 0.7636004356600141, 0.7670758882578367, 0.7685296624374639, 0.7709269508428093, 0.7721455847020438, 0.7761954747379414, 0.7788282327711449, 0.7798654711049767, 0.7821082690463178, 0.7838485355691696, 0.7864386237275983, 0.7887026269732851, 0.7893217531958603, 0.7893793992432405, 0.7934115925558992, 0.7935842152975671, 0.7954227378844799, 0.7970094248708456, 0.7984345469571661, 0.7992456882395105, 0.8018219289446726, 0.8010106319098501, 0.802453863481818, 0.803744519976163, 0.8059376424437066, 0.8058444333390715, 0.8073535897160309, 0.807264908967237, 0.8092710092971348, 0.8097819504242604, 0.8127402690759211, 0.8125231892907679, 0.812774072427855, 0.8141108101330112, 0.8133960682272839, 0.815704086320176, 0.8153188384005813, 0.8158894832874005]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:45,  1.22s/it]Loading train:   1%|          | 2/285 [00:02<06:13,  1.32s/it]Loading train:   1%|          | 3/285 [00:03<06:01,  1.28s/it]Loading train:   1%|▏         | 4/285 [00:05<06:29,  1.39s/it]Loading train:   2%|▏         | 5/285 [00:06<06:09,  1.32s/it]Loading train:   2%|▏         | 6/285 [00:08<06:25,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:39,  1.44s/it]Loading train:   3%|▎         | 8/285 [00:11<06:53,  1.49s/it]Loading train:   3%|▎         | 9/285 [00:12<06:40,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:14<06:16,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:15<05:49,  1.28s/it]Loading train:   4%|▍         | 12/285 [00:16<05:33,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:13,  1.15s/it]Loading train:   5%|▍         | 14/285 [00:18<05:04,  1.12s/it]Loading train:   5%|▌         | 15/285 [00:19<04:51,  1.08s/it]Loading train:   6%|▌         | 16/285 [00:20<04:48,  1.07s/it]Loading train:   6%|▌         | 17/285 [00:21<04:45,  1.06s/it]Loading train:   6%|▋         | 18/285 [00:22<04:37,  1.04s/it]Loading train:   7%|▋         | 19/285 [00:23<04:40,  1.05s/it]Loading train:   7%|▋         | 20/285 [00:24<04:29,  1.02s/it]Loading train:   7%|▋         | 21/285 [00:25<04:33,  1.04s/it]Loading train:   8%|▊         | 22/285 [00:26<04:29,  1.02s/it]Loading train:   8%|▊         | 23/285 [00:27<04:35,  1.05s/it]Loading train:   8%|▊         | 24/285 [00:28<04:30,  1.04s/it]Loading train:   9%|▉         | 25/285 [00:29<04:31,  1.05s/it]Loading train:   9%|▉         | 26/285 [00:30<04:34,  1.06s/it]Loading train:   9%|▉         | 27/285 [00:31<04:25,  1.03s/it]Loading train:  10%|▉         | 28/285 [00:32<04:22,  1.02s/it]Loading train:  10%|█         | 29/285 [00:33<04:13,  1.01it/s]Loading train:  11%|█         | 30/285 [00:34<04:08,  1.03it/s]Loading train:  11%|█         | 31/285 [00:35<04:05,  1.03it/s]Loading train:  11%|█         | 32/285 [00:36<04:00,  1.05it/s]Loading train:  12%|█▏        | 33/285 [00:37<04:03,  1.03it/s]Loading train:  12%|█▏        | 34/285 [00:38<04:08,  1.01it/s]Loading train:  12%|█▏        | 35/285 [00:39<04:07,  1.01it/s]Loading train:  13%|█▎        | 36/285 [00:40<03:59,  1.04it/s]Loading train:  13%|█▎        | 37/285 [00:41<04:10,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:02,  1.02it/s]Loading train:  14%|█▎        | 39/285 [00:43<04:02,  1.01it/s]Loading train:  14%|█▍        | 40/285 [00:44<03:54,  1.04it/s]Loading train:  14%|█▍        | 41/285 [00:45<03:58,  1.02it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:54,  1.04it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:51,  1.05it/s]Loading train:  15%|█▌        | 44/285 [00:48<03:55,  1.02it/s]Loading train:  16%|█▌        | 45/285 [00:49<04:01,  1.01s/it]Loading train:  16%|█▌        | 46/285 [00:50<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:40,  1.08it/s]Loading train:  17%|█▋        | 48/285 [00:51<03:33,  1.11it/s]Loading train:  17%|█▋        | 49/285 [00:52<03:28,  1.13it/s]Loading train:  18%|█▊        | 50/285 [00:53<03:32,  1.11it/s]Loading train:  18%|█▊        | 51/285 [00:54<03:26,  1.13it/s]Loading train:  18%|█▊        | 52/285 [00:55<03:25,  1.13it/s]Loading train:  19%|█▊        | 53/285 [00:56<03:17,  1.18it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:14,  1.19it/s]Loading train:  19%|█▉        | 55/285 [00:57<03:16,  1.17it/s]Loading train:  20%|█▉        | 56/285 [00:58<03:11,  1.19it/s]Loading train:  20%|██        | 57/285 [00:59<03:17,  1.15it/s]Loading train:  20%|██        | 58/285 [01:00<03:08,  1.20it/s]Loading train:  21%|██        | 59/285 [01:00<03:02,  1.24it/s]Loading train:  21%|██        | 60/285 [01:01<03:06,  1.21it/s]Loading train:  21%|██▏       | 61/285 [01:02<03:09,  1.18it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:18,  1.13it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:20,  1.11it/s]Loading train:  22%|██▏       | 64/285 [01:06<03:53,  1.05s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:23,  1.20s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:22,  1.20s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:03,  1.12s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:41,  1.02s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:26,  1.05it/s]Loading train:  25%|██▍       | 70/285 [01:12<03:21,  1.07it/s]Loading train:  25%|██▍       | 71/285 [01:13<03:15,  1.09it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:09,  1.13it/s]Loading train:  26%|██▌       | 73/285 [01:14<02:56,  1.20it/s]Loading train:  26%|██▌       | 74/285 [01:15<02:57,  1.19it/s]Loading train:  26%|██▋       | 75/285 [01:16<02:55,  1.20it/s]Loading train:  27%|██▋       | 76/285 [01:17<02:49,  1.23it/s]Loading train:  27%|██▋       | 77/285 [01:17<02:55,  1.18it/s]Loading train:  27%|██▋       | 78/285 [01:18<02:50,  1.21it/s]Loading train:  28%|██▊       | 79/285 [01:19<02:45,  1.25it/s]Loading train:  28%|██▊       | 80/285 [01:20<02:48,  1.21it/s]Loading train:  28%|██▊       | 81/285 [01:21<02:46,  1.23it/s]Loading train:  29%|██▉       | 82/285 [01:22<02:52,  1.18it/s]Loading train:  29%|██▉       | 83/285 [01:22<02:49,  1.19it/s]Loading train:  29%|██▉       | 84/285 [01:23<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:24<03:00,  1.11it/s]Loading train:  30%|███       | 86/285 [01:25<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:26<03:07,  1.06it/s]Loading train:  31%|███       | 88/285 [01:27<03:06,  1.05it/s]Loading train:  31%|███       | 89/285 [01:28<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:03,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:30<03:08,  1.03it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:03,  1.05it/s]Loading train:  33%|███▎      | 93/285 [01:32<03:12,  1.00s/it]Loading train:  33%|███▎      | 94/285 [01:33<03:10,  1.00it/s]Loading train:  33%|███▎      | 95/285 [01:34<03:12,  1.01s/it]Loading train:  34%|███▎      | 96/285 [01:35<03:03,  1.03it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:59,  1.05it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:57,  1.05it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:56,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:54,  1.06it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:53,  1.06it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:51,  1.07it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:44,  1.10it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:48,  1.08it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:41,  1.12it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:53,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:52,  1.03it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:56,  1.00it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:51,  1.03it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:49,  1.03it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:52,  1.01it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:56,  1.02s/it]Loading train:  40%|███▉      | 113/285 [01:51<02:52,  1.00s/it]Loading train:  40%|████      | 114/285 [01:52<02:45,  1.03it/s]Loading train:  40%|████      | 115/285 [01:53<02:39,  1.07it/s]Loading train:  41%|████      | 116/285 [01:54<02:41,  1.05it/s]Loading train:  41%|████      | 117/285 [01:55<02:38,  1.06it/s]Loading train:  41%|████▏     | 118/285 [01:56<02:36,  1.07it/s]Loading train:  42%|████▏     | 119/285 [01:57<02:35,  1.07it/s]Loading train:  42%|████▏     | 120/285 [01:58<02:31,  1.09it/s]Loading train:  42%|████▏     | 121/285 [01:59<02:45,  1.01s/it]Loading train:  43%|████▎     | 122/285 [02:00<02:56,  1.09s/it]Loading train:  43%|████▎     | 123/285 [02:02<03:01,  1.12s/it]Loading train:  44%|████▎     | 124/285 [02:02<02:50,  1.06s/it]Loading train:  44%|████▍     | 125/285 [02:03<02:43,  1.02s/it]Loading train:  44%|████▍     | 126/285 [02:04<02:32,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:05<02:26,  1.08it/s]Loading train:  45%|████▍     | 128/285 [02:06<02:22,  1.10it/s]Loading train:  45%|████▌     | 129/285 [02:07<02:15,  1.15it/s]Loading train:  46%|████▌     | 130/285 [02:08<02:19,  1.11it/s]Loading train:  46%|████▌     | 131/285 [02:08<02:14,  1.15it/s]Loading train:  46%|████▋     | 132/285 [02:09<02:13,  1.14it/s]Loading train:  47%|████▋     | 133/285 [02:10<02:10,  1.16it/s]Loading train:  47%|████▋     | 134/285 [02:11<02:10,  1.15it/s]Loading train:  47%|████▋     | 135/285 [02:12<02:10,  1.15it/s]Loading train:  48%|████▊     | 136/285 [02:13<02:10,  1.14it/s]Loading train:  48%|████▊     | 137/285 [02:14<02:11,  1.13it/s]Loading train:  48%|████▊     | 138/285 [02:15<02:09,  1.14it/s]Loading train:  49%|████▉     | 139/285 [02:16<02:09,  1.13it/s]Loading train:  49%|████▉     | 140/285 [02:16<02:04,  1.16it/s]Loading train:  49%|████▉     | 141/285 [02:17<02:08,  1.12it/s]Loading train:  50%|████▉     | 142/285 [02:18<02:02,  1.16it/s]Loading train:  50%|█████     | 143/285 [02:19<02:03,  1.15it/s]Loading train:  51%|█████     | 144/285 [02:20<01:54,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:20<01:52,  1.25it/s]Loading train:  51%|█████     | 146/285 [02:21<01:47,  1.29it/s]Loading train:  52%|█████▏    | 147/285 [02:22<01:43,  1.34it/s]Loading train:  52%|█████▏    | 148/285 [02:23<01:49,  1.25it/s]Loading train:  52%|█████▏    | 149/285 [02:24<01:49,  1.25it/s]Loading train:  53%|█████▎    | 150/285 [02:25<01:55,  1.17it/s]Loading train:  53%|█████▎    | 151/285 [02:25<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:26<01:56,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:27<01:49,  1.21it/s]Loading train:  54%|█████▍    | 154/285 [02:28<01:47,  1.22it/s]Loading train:  54%|█████▍    | 155/285 [02:29<01:47,  1.21it/s]Loading train:  55%|█████▍    | 156/285 [02:29<01:44,  1.24it/s]Loading train:  55%|█████▌    | 157/285 [02:30<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:31<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:32<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [02:33<01:46,  1.17it/s]Loading train:  56%|█████▋    | 161/285 [02:34<01:43,  1.19it/s]Loading train:  57%|█████▋    | 162/285 [02:35<01:39,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [02:35<01:37,  1.25it/s]Loading train:  58%|█████▊    | 164/285 [02:36<01:38,  1.23it/s]Loading train:  58%|█████▊    | 165/285 [02:37<01:31,  1.31it/s]Loading train:  58%|█████▊    | 166/285 [02:38<01:36,  1.24it/s]Loading train:  59%|█████▊    | 167/285 [02:38<01:31,  1.28it/s]Loading train:  59%|█████▉    | 168/285 [02:39<01:33,  1.25it/s]Loading train:  59%|█████▉    | 169/285 [02:40<01:30,  1.28it/s]Loading train:  60%|█████▉    | 170/285 [02:41<01:30,  1.27it/s]Loading train:  60%|██████    | 171/285 [02:42<01:32,  1.24it/s]Loading train:  60%|██████    | 172/285 [02:42<01:29,  1.27it/s]Loading train:  61%|██████    | 173/285 [02:43<01:27,  1.28it/s]Loading train:  61%|██████    | 174/285 [02:44<01:28,  1.25it/s]Loading train:  61%|██████▏   | 175/285 [02:45<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [02:46<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [02:47<01:29,  1.21it/s]Loading train:  62%|██████▏   | 178/285 [02:47<01:24,  1.26it/s]Loading train:  63%|██████▎   | 179/285 [02:48<01:23,  1.27it/s]Loading train:  63%|██████▎   | 180/285 [02:49<01:22,  1.27it/s]Loading train:  64%|██████▎   | 181/285 [02:50<01:25,  1.22it/s]Loading train:  64%|██████▍   | 182/285 [02:50<01:23,  1.24it/s]Loading train:  64%|██████▍   | 183/285 [02:51<01:19,  1.28it/s]Loading train:  65%|██████▍   | 184/285 [02:52<01:15,  1.34it/s]Loading train:  65%|██████▍   | 185/285 [02:53<01:14,  1.33it/s]Loading train:  65%|██████▌   | 186/285 [02:53<01:18,  1.26it/s]Loading train:  66%|██████▌   | 187/285 [02:54<01:16,  1.29it/s]Loading train:  66%|██████▌   | 188/285 [02:55<01:18,  1.24it/s]Loading train:  66%|██████▋   | 189/285 [02:56<01:15,  1.28it/s]Loading train:  67%|██████▋   | 190/285 [02:57<01:12,  1.30it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:12,  1.29it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:09,  1.35it/s]Loading train:  68%|██████▊   | 193/285 [02:59<01:09,  1.33it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:06,  1.37it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:11,  1.25it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:12,  1.23it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:16,  1.15it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:17,  1.13it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:17,  1.11it/s]Loading train:  70%|███████   | 200/285 [03:05<01:15,  1.13it/s]Loading train:  71%|███████   | 201/285 [03:06<01:12,  1.16it/s]Loading train:  71%|███████   | 202/285 [03:07<01:10,  1.17it/s]Loading train:  71%|███████   | 203/285 [03:07<01:08,  1.19it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:09,  1.17it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:08,  1.17it/s]Loading train:  72%|███████▏  | 206/285 [03:10<01:07,  1.17it/s]Loading train:  73%|███████▎  | 207/285 [03:11<01:05,  1.19it/s]Loading train:  73%|███████▎  | 208/285 [03:12<01:05,  1.18it/s]Loading train:  73%|███████▎  | 209/285 [03:13<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:02,  1.20it/s]Loading train:  74%|███████▍  | 211/285 [03:14<01:06,  1.11it/s]Loading train:  74%|███████▍  | 212/285 [03:15<01:04,  1.13it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:03,  1.14it/s]Loading train:  75%|███████▌  | 214/285 [03:17<01:00,  1.18it/s]Loading train:  75%|███████▌  | 215/285 [03:18<00:58,  1.21it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:56,  1.23it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:55,  1.23it/s]Loading train:  76%|███████▋  | 218/285 [03:20<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [03:21<00:52,  1.25it/s]Loading train:  77%|███████▋  | 220/285 [03:22<00:50,  1.28it/s]Loading train:  78%|███████▊  | 221/285 [03:23<00:51,  1.23it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:49,  1.27it/s]Loading train:  78%|███████▊  | 223/285 [03:24<00:51,  1.21it/s]Loading train:  79%|███████▊  | 224/285 [03:25<00:49,  1.23it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:48,  1.25it/s]Loading train:  79%|███████▉  | 226/285 [03:26<00:46,  1.28it/s]Loading train:  80%|███████▉  | 227/285 [03:27<00:44,  1.30it/s]Loading train:  80%|████████  | 228/285 [03:28<00:44,  1.29it/s]Loading train:  80%|████████  | 229/285 [03:29<00:43,  1.29it/s]Loading train:  81%|████████  | 230/285 [03:30<00:43,  1.26it/s]Loading train:  81%|████████  | 231/285 [03:30<00:41,  1.29it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:45,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [03:32<00:47,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [03:33<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:34<00:48,  1.04it/s]Loading train:  83%|████████▎ | 236/285 [03:35<00:46,  1.06it/s]Loading train:  83%|████████▎ | 237/285 [03:36<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [03:37<00:46,  1.02it/s]Loading train:  84%|████████▍ | 239/285 [03:38<00:44,  1.04it/s]Loading train:  84%|████████▍ | 240/285 [03:39<00:45,  1.01s/it]Loading train:  85%|████████▍ | 241/285 [03:40<00:43,  1.01it/s]Loading train:  85%|████████▍ | 242/285 [03:41<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [03:42<00:41,  1.00it/s]Loading train:  86%|████████▌ | 244/285 [03:43<00:40,  1.01it/s]Loading train:  86%|████████▌ | 245/285 [03:44<00:40,  1.02s/it]Loading train:  86%|████████▋ | 246/285 [03:45<00:40,  1.03s/it]Loading train:  87%|████████▋ | 247/285 [03:46<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [03:47<00:37,  1.03s/it]Loading train:  87%|████████▋ | 249/285 [03:48<00:36,  1.01s/it]Loading train:  88%|████████▊ | 250/285 [03:49<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [03:50<00:30,  1.12it/s]Loading train:  88%|████████▊ | 252/285 [03:51<00:28,  1.16it/s]Loading train:  89%|████████▉ | 253/285 [03:52<00:26,  1.21it/s]Loading train:  89%|████████▉ | 254/285 [03:52<00:24,  1.26it/s]Loading train:  89%|████████▉ | 255/285 [03:53<00:23,  1.28it/s]Loading train:  90%|████████▉ | 256/285 [03:54<00:22,  1.29it/s]Loading train:  90%|█████████ | 257/285 [03:54<00:21,  1.32it/s]Loading train:  91%|█████████ | 258/285 [03:55<00:20,  1.29it/s]Loading train:  91%|█████████ | 259/285 [03:56<00:19,  1.34it/s]Loading train:  91%|█████████ | 260/285 [03:57<00:19,  1.27it/s]Loading train:  92%|█████████▏| 261/285 [03:58<00:18,  1.32it/s]Loading train:  92%|█████████▏| 262/285 [03:58<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [03:59<00:16,  1.33it/s]Loading train:  93%|█████████▎| 264/285 [04:00<00:15,  1.35it/s]Loading train:  93%|█████████▎| 265/285 [04:00<00:14,  1.38it/s]Loading train:  93%|█████████▎| 266/285 [04:01<00:13,  1.39it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:13,  1.32it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [04:04<00:13,  1.20it/s]Loading train:  95%|█████████▍| 270/285 [04:05<00:12,  1.16it/s]Loading train:  95%|█████████▌| 271/285 [04:06<00:12,  1.12it/s]Loading train:  95%|█████████▌| 272/285 [04:07<00:11,  1.11it/s]Loading train:  96%|█████████▌| 273/285 [04:08<00:10,  1.13it/s]Loading train:  96%|█████████▌| 274/285 [04:08<00:09,  1.10it/s]Loading train:  96%|█████████▋| 275/285 [04:09<00:09,  1.09it/s]Loading train:  97%|█████████▋| 276/285 [04:10<00:08,  1.07it/s]Loading train:  97%|█████████▋| 277/285 [04:11<00:07,  1.06it/s]Loading train:  98%|█████████▊| 278/285 [04:12<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:13<00:05,  1.09it/s]Loading train:  98%|█████████▊| 280/285 [04:14<00:04,  1.09it/s]Loading train:  99%|█████████▊| 281/285 [04:15<00:03,  1.06it/s]Loading train:  99%|█████████▉| 282/285 [04:16<00:02,  1.06it/s]Loading train:  99%|█████████▉| 283/285 [04:17<00:01,  1.03it/s]Loading train: 100%|█████████▉| 284/285 [04:18<00:00,  1.05it/s]Loading train: 100%|██████████| 285/285 [04:19<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:01, 188.34it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:01, 176.37it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:01, 158.66it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:01, 186.71it/s]concatenating: train:  40%|████      | 114/285 [00:00<00:00, 212.47it/s]concatenating: train:  50%|████▉     | 142/285 [00:00<00:00, 228.00it/s]concatenating: train:  60%|██████    | 172/285 [00:00<00:00, 244.36it/s]concatenating: train:  72%|███████▏  | 205/285 [00:00<00:00, 263.95it/s]concatenating: train:  82%|████████▏ | 233/285 [00:00<00:00, 258.93it/s]concatenating: train:  93%|█████████▎| 266/285 [00:01<00:00, 274.80it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 260.70it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 66.37it/s]  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________2019-07-07 05:34:09.666011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:34:09.666120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:34:09.666135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:34:09.666144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:34:09.666598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

conv2d_8 (Conv2D)               (None, 40, 26, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 14497.3191 - acc: 0.8612 - mDice: 0.2461 - val_loss: 7626.6654 - val_acc: 0.8891 - val_mDice: 0.3543

Epoch 00001: val_mDice improved from -inf to 0.35433, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 6545.1558 - acc: 0.9028 - mDice: 0.4313 - val_loss: 5727.4298 - val_acc: 0.9198 - val_mDice: 0.4561

Epoch 00002: val_mDice improved from 0.35433 to 0.45610, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 5119.0406 - acc: 0.9191 - mDice: 0.5137 - val_loss: 5029.5702 - val_acc: 0.9263 - val_mDice: 0.4987

Epoch 00003: val_mDice improved from 0.45610 to 0.49866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 4474.6435 - acc: 0.9249 - mDice: 0.5570 - val_loss: 4615.7100 - val_acc: 0.9292 - val_mDice: 0.5242

Epoch 00004: val_mDice improved from 0.49866 to 0.52422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 11s - loss: 4095.7038 - acc: 0.9289 - mDice: 0.5845 - val_loss: 4520.4781 - val_acc: 0.9303 - val_mDice: 0.5320

Epoch 00005: val_mDice improved from 0.52422 to 0.53201, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 3780.3297 - acc: 0.9318 - mDice: 0.6083 - val_loss: 4349.1500 - val_acc: 0.9315 - val_mDice: 0.5419

Epoch 00006: val_mDice improved from 0.53201 to 0.54188, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 12s - loss: 3578.4887 - acc: 0.9338 - mDice: 0.6245 - val_loss: 4293.8077 - val_acc: 0.9328 - val_mDice: 0.5470

Epoch 00007: val_mDice improved from 0.54188 to 0.54695, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 11s - loss: 3427.6790 - acc: 0.9354 - mDice: 0.6368 - val_loss: 4193.6003 - val_acc: 0.9318 - val_mDice: 0.5521

Epoch 00008: val_mDice improved from 0.54695 to 0.55206, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 3276.8113 - acc: 0.9370 - mDice: 0.6493 - val_loss: 4184.7063 - val_acc: 0.9314 - val_mDice: 0.5534

Epoch 00009: val_mDice improved from 0.55206 to 0.55344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 11s - loss: 3151.7978 - acc: 0.9382 - mDice: 0.6599 - val_loss: 4070.1601 - val_acc: 0.9328 - val_mDice: 0.5621

Epoch 00010: val_mDice improved from 0.55344 to 0.56213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 11s - loss: 3054.2634 - acc: 0.9393 - mDice: 0.6683 - val_loss: 4058.0683 - val_acc: 0.9343 - val_mDice: 0.5645

Epoch 00011: val_mDice improved from 0.56213 to 0.56452, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 2983.1007 - acc: 0.9400 - mDice: 0.6746 - val_loss: 3991.7298 - val_acc: 0.9344 - val_mDice: 0.5687

Epoch 00012: val_mDice improved from 0.56452 to 0.56870, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 11s - loss: 2909.8081 - acc: 0.9408 - mDice: 0.6810 - val_loss: 3955.3906 - val_acc: 0.9357 - val_mDice: 0.5716

Epoch 00013: val_mDice improved from 0.56870 to 0.57158, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 11s - loss: 2824.5845 - acc: 0.9417 - mDice: 0.6884 - val_loss: 3944.9911 - val_acc: 0.9364 - val_mDice: 0.5727

Epoch 00014: val_mDice improved from 0.57158 to 0.57272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 11s - loss: 2787.6748 - acc: 0.9421 - mDice: 0.6919 - val_loss: 3864.0141 - val_acc: 0.9360 - val_mDice: 0.5790

Epoch 00015: val_mDice improved from 0.57272 to 0.57900, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 11s - loss: 2703.7189 - acc: 0.9429 - mDice: 0.6992 - val_loss: 4000.5964 - val_acc: 0.9348 - val_mDice: 0.5700

Epoch 00016: val_mDice did not improve from 0.57900
Epoch 17/300
 - 11s - loss: 2647.1640 - acc: 0.9435 - mDice: 0.7044 - val_loss: 4102.3782 - val_acc: 0.9362 - val_mDice: 0.5619

Epoch 00017: val_mDice did not improve from 0.57900
Epoch 18/300
 - 11s - loss: 2602.5005 - acc: 0.9440 - mDice: 0.7085 - val_loss: 3847.1424 - val_acc: 0.9403 - val_mDice: 0.5820

Epoch 00018: val_mDice improved from 0.57900 to 0.58199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 2543.2240 - acc: 0.9447 - mDice: 0.7139 - val_loss: 4061.3364 - val_acc: 0.9383 - val_mDice: 0.5661

Epoch 00019: val_mDice did not improve from 0.58199
Epoch 20/300
 - 11s - loss: 2504.2972 - acc: 0.9450 - mDice: 0.7176 - val_loss: 4205.9476 - val_acc: 0.9338 - val_mDice: 0.5527

Epoch 00020: val_mDice did not improve from 0.58199
Epoch 21/300
 - 11s - loss: 2465.3796 - acc: 0.9455 - mDice: 0.7212 - val_loss: 4269.3324 - val_acc: 0.9358 - val_mDice: 0.5510

Epoch 00021: val_mDice did not improve from 0.58199
Epoch 22/300
 - 11s - loss: 2415.9986 - acc: 0.9460 - mDice: 0.7258 - val_loss: 4017.2929 - val_acc: 0.9384 - val_mDice: 0.5670

Epoch 00022: val_mDice did not improve from 0.58199
Epoch 23/300
 - 11s - loss: 2387.6959 - acc: 0.9463 - mDice: 0.7285 - val_loss: 3996.6988 - val_acc: 0.9360 - val_mDice: 0.5685

Epoch 00023: val_mDice did not improve from 0.58199
Epoch 24/300
 - 11s - loss: 2349.5448 - acc: 0.9468 - mDice: 0.7321 - val_loss: 4067.8968 - val_acc: 0.9380 - val_mDice: 0.5628

Epoch 00024: val_mDice did not improve from 0.58199
Epoch 25/300
 - 11s - loss: 2320.0565 - acc: 0.9471 - mDice: 0.7350 - val_loss: 4076.0170 - val_acc: 0.9342 - val_mDice: 0.5620

Epoch 00025: val_mDice did not improve from 0.58199
Epoch 26/300
 - 11s - loss: 2281.7069 - acc: 0.9475 - mDice: 0.7386 - val_loss: 3990.2145 - val_acc: 0.9392 - val_mDice: 0.5697

Epoch 00026: val_mDice did not improve from 0.58199
Epoch 27/300
 - 11s - loss: 2250.9859 - acc: 0.9480 - mDice: 0.7416 - val_loss: 4160.0039 - val_acc: 0.9370 - val_mDice: 0.5564

Epoch 00027: val_mDice did not improve from 0.58199
Epoch 28/300
 - 12s - loss: 2228.8931 - acc: 0.9483 - mDice: 0.7438 - val_loss: 4030.8382 - val_acc: 0.9389 - val_mDice: 0.5682

Epoch 00028: val_mDice did not improve from 0.58199
Epoch 29/300
 - 11s - loss: 2198.5980 - acc: 0.9485 - mDice: 0.7467 - val_loss: 4072.1644 - val_acc: 0.9373 - val_mDice: 0.5629

Epoch 00029: val_mDice did not improve from 0.58199
Epoch 30/300
 - 11s - loss: 2157.0223 - acc: 0.9489 - mDice: 0.7508 - val_loss: 4020.1963 - val_acc: 0.9397 - val_mDice: 0.5673

Epoch 00030: val_mDice did not improve from 0.58199
Epoch 31/300
 - 11s - loss: 2142.8494 - acc: 0.9491 - mDice: 0.7522 - val_loss: 4059.7914 - val_acc: 0.9387 - val_mDice: 0.5656

Epoch 00031: val_mDice did not improve from 0.58199
Epoch 32/300
 - 11s - loss: 2124.8638 - acc: 0.9494 - mDice: 0.7540 - val_loss: 4157.6902 - val_acc: 0.9398 - val_mDice: 0.5567

Epoch 00032: val_mDice did not improve from 0.58199
Epoch 33/300
 - 11s - loss: 2094.7840 - acc: 0.9496 - mDice: 0.7568 - val_loss: 4205.8146 - val_acc: 0.9381 - val_mDice: 0.5542

Epoch 00033: val_mDice did not improve from 0.58199
Epoch 34/300
 - 11s - loss: 2071.8791 - acc: 0.9498 - mDice: 0.7591 - val_loss: 4228.7093 - val_acc: 0.9346 - val_mDice: 0.5503

Epoch 00034: val_mDice did not improve from 0.58199
Epoch 35/300
 - 11s - loss: 2055.9369 - acc: 0.9501 - mDice: 0.7608 - val_loss: 3934.9374 - val_acc: 0.9406 - val_mDice: 0.5747

Epoch 00035: val_mDice did not improve from 0.58199
Epoch 36/300
 - 11s - loss: 2028.8514 - acc: 0.9505 - mDice: 0.7635 - val_loss: 4085.0213 - val_acc: 0.9422 - val_mDice: 0.5654

Epoch 00036: val_mDice did not improve from 0.58199
Epoch 37/300
 - 11s - loss: 2012.4115 - acc: 0.9506 - mDice: 0.7652 - val_loss: 4221.3534 - val_acc: 0.9403 - val_mDice: 0.5564

Epoch 00037: val_mDice did not improve from 0.58199
Epoch 38/300
 - 11s - loss: 1992.1830 - acc: 0.9509 - mDice: 0.7672 - val_loss: 4284.9755 - val_acc: 0.9370 - val_mDice: 0.5589

Epoch 00038: val_mDice did not improve from 0.58199
Epoch 39/300
 - 11s - loss: 1977.3094 - acc: 0.9511 - mDice: 0.7687 - val_loss: 4087.8529 - val_acc: 0.9381 - val_mDice: 0.5645

Epoch 00039: val_mDice did not improve from 0.58199
Epoch 40/300
 - 11s - loss: 1951.6450 - acc: 0.9514 - mDice: 0.7713 - val_loss: 4088.5957 - val_acc: 0.9404 - val_mDice: 0.5628

Epoch 00040: val_mDice did not improve from 0.58199
Epoch 41/300
 - 11s - loss: 1939.7640 - acc: 0.9515 - mDice: 0.7725 - val_loss: 4085.9418 - val_acc: 0.9392 - val_mDice: 0.5656

Epoch 00041: val_mDice did not improve from 0.58199
Epoch 42/300
 - 11s - loss: 1927.1269 - acc: 0.9518 - mDice: 0.7738 - val_loss: 4146.0480 - val_acc: 0.9421 - val_mDice: 0.5595

Epoch 00042: val_mDice did not improve from 0.58199
Epoch 43/300
 - 11s - loss: 1914.8289 - acc: 0.9520 - mDice: 0.7750 - val_loss: 4155.8852 - val_acc: 0.9415 - val_mDice: 0.5600

Epoch 00043: val_mDice did not improve from 0.58199
Epoch 44/300
 - 11s - loss: 1888.0016 - acc: 0.9522 - mDice: 0.7777 - val_loss: 4022.0589 - val_acc: 0.9401 - val_mDice: 0.5714

Epoch 00044: val_mDice did not improve from 0.58199
Epoch 45/300
 - 11s - loss: 1873.3680 - acc: 0.9523 - mDice: 0.7792 - val_loss: 4239.4913 - val_acc: 0.9379 - val_mDice: 0.5571

Epoch 00045: val_mDice did not improve from 0.58199
Epoch 46/300
 - 11s - loss: 1863.3746 - acc: 0.9523 - mDice: 0.7802 - val_loss: 3955.4720 - val_acc: 0.9400 - val_mDice: 0.5741

Epoch 00046: val_mDice did not improve from 0.58199
Epoch 47/300
 - 11s - loss: 1845.3674 - acc: 0.9526 - mDice: 0.7821 - val_loss: 4130.7665 - val_acc: 0.9436 - val_mDice: 0.5624

Epoch 00047: val_mDice did not improve from 0.58199
Epoch 48/300
 - 12s - loss: 1832.6219 - acc: 0.9529 - mDice: 0.7834 - val_loss: 4100.8052 - val_acc: 0.9412 - val_mDice: 0.5644

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:17,  1.33s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:49,  1.45s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:49,  1.45s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:13,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:00,  1.50s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:22,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:45,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:03,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:10,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:19,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:27,  1.86s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:34,  1.90s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:38,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:39,  1.93s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:31,  1.91s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:31,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:28,  1.91s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:31,  1.93s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:25,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:23,  1.91s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:25,  1.93s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<08:22,  1.92s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:15,  1.91s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:11,  1.91s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:03,  1.88s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:57,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:54<07:49,  1.84s/it]predicting train subjects:  11%|█         | 31/285 [00:56<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:36,  1.80s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:36,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:30,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:32,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:24,  1.79s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:20,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:20,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:19,  1.79s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:17,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:16,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:26,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:33,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:14,  1.82s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<06:48,  1.71s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<06:38,  1.68s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<06:45,  1.72s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<06:33,  1.67s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<06:18,  1.62s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:08,  1.58s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:07,  1.58s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<06:01,  1.57s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:01,  1.57s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<05:59,  1.57s/it]predicting train subjects:  20%|██        | 57/285 [01:40<05:56,  1.56s/it]predicting train subjects:  20%|██        | 58/285 [01:42<05:56,  1.57s/it]predicting train subjects:  21%|██        | 59/285 [01:44<05:53,  1.56s/it]predicting train subjects:  21%|██        | 60/285 [01:45<05:55,  1.58s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<05:54,  1.58s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<05:53,  1.58s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<05:50,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<05:51,  1.59s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:04,  1.66s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:09,  1.69s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:02,  1.66s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<05:56,  1.64s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<05:50,  1.62s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<05:49,  1.63s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<05:46,  1.62s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<05:41,  1.60s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<05:38,  1.60s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<05:35,  1.59s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<05:33,  1.59s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<05:29,  1.58s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:25,  1.57s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:24,  1.57s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:20,  1.57s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:19,  1.57s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:18,  1.57s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:20,  1.59s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:19,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:32,  1.66s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:36,  1.69s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:39,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:39,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:36,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:34,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:31,  1.71s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:31,  1.72s/it]predicting train subjects:  33%|███▎      | 93/285 [02:39<05:33,  1.74s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:34,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:34,  1.76s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:33,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:46<05:30,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:26,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:28,  1.76s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:28,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:26,  1.79s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<05:26,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<05:23,  1.79s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<05:19,  1.78s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:06<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:08<05:15,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:10<05:14,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:11<05:12,  1.80s/it]predicting train subjects:  39%|███▉      | 112/285 [03:13<05:10,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:15<05:07,  1.79s/it]predicting train subjects:  40%|████      | 114/285 [03:17<05:05,  1.79s/it]predicting train subjects:  40%|████      | 115/285 [03:19<05:03,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:20<04:57,  1.76s/it]predicting train subjects:  41%|████      | 117/285 [03:22<04:56,  1.76s/it]predicting train subjects:  41%|████▏     | 118/285 [03:24<04:54,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:26<04:50,  1.75s/it]predicting train subjects:  42%|████▏     | 120/285 [03:27<04:45,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:29<04:39,  1.70s/it]predicting train subjects:  43%|████▎     | 122/285 [03:30<04:28,  1.65s/it]predicting train subjects:  43%|████▎     | 123/285 [03:32<04:16,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [03:33<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:35<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<04:17,  1.62s/it]predicting train subjects:  45%|████▍     | 127/285 [03:38<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<04:10,  1.59s/it]predicting train subjects:  45%|████▌     | 129/285 [03:41<04:05,  1.57s/it]predicting train subjects:  46%|████▌     | 130/285 [03:43<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<04:07,  1.61s/it]predicting train subjects:  46%|████▋     | 132/285 [03:46<04:04,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<04:02,  1.59s/it]predicting train subjects:  47%|████▋     | 134/285 [03:49<03:59,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<04:00,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:58,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:57,  1.62s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:01<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:04<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:34,  1.52s/it]predicting train subjects:  51%|█████     | 145/285 [04:07<03:31,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:10<03:29,  1.52s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:13<03:23,  1.49s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:16<03:18,  1.48s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:11,  1.46s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:06,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:07,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:26<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:29<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<02:59,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<02:55,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<02:52,  1.41s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:52,  1.42s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:49,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<02:47,  1.41s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:38<02:44,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:46,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:41<02:43,  1.41s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:40,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:47<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:50<02:36,  1.42s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:34,  1.42s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:53<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:55<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:25,  1.39s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:58<02:25,  1.39s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:00<02:23,  1.40s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:01<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:02<02:21,  1.40s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:04<02:20,  1.40s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:05<02:18,  1.40s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:07<02:17,  1.40s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:08<02:13,  1.38s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:09<02:10,  1.36s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:11<02:08,  1.36s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:12<02:07,  1.35s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:05,  1.35s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:15<02:05,  1.37s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:16<02:03,  1.36s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:02,  1.36s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:19<02:08,  1.44s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:21<02:13,  1.51s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:22<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:17,  1.60s/it]predicting train subjects:  70%|███████   | 200/285 [05:26<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:17,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:31<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:10,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:34<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:35<02:07,  1.61s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:37<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:39<02:05,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:40<02:05,  1.66s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:42<02:06,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:44<02:04,  1.68s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:46<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:47<01:59,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:49<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:50<01:49,  1.57s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:52<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:42,  1.51s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:55<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:56<01:37,  1.48s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:36,  1.48s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:59<01:33,  1.47s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:00<01:31,  1.45s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:02<01:29,  1.44s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:03<01:26,  1.42s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:05<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:06<01:24,  1.43s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:07<01:23,  1.43s/it]predicting train subjects:  80%|████████  | 228/285 [06:09<01:22,  1.44s/it]predicting train subjects:  80%|████████  | 229/285 [06:10<01:20,  1.44s/it]predicting train subjects:  81%|████████  | 230/285 [06:12<01:19,  1.44s/it]predicting train subjects:  81%|████████  | 231/285 [06:13<01:18,  1.45s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:15<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:17<01:25,  1.64s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:19<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:20<01:24,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:22<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:24<01:24,  1.75s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:26<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:28<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:29<01:19,  1.76s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:31<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:33<01:14,  1.73s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<01:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:36<01:12,  1.76s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:38<01:10,  1.76s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:07,  1.74s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:06,  1.74s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:43<01:04,  1.74s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<01:02,  1.75s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:46<00:56,  1.62s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:49<00:47,  1.45s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:50<00:45,  1.44s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:52<00:44,  1.42s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:53<00:41,  1.39s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:54<00:39,  1.38s/it]predicting train subjects:  90%|█████████ | 257/285 [06:56<00:38,  1.36s/it]predicting train subjects:  91%|█████████ | 258/285 [06:57<00:36,  1.36s/it]predicting train subjects:  91%|█████████ | 259/285 [06:58<00:35,  1.35s/it]predicting train subjects:  91%|█████████ | 260/285 [07:00<00:33,  1.35s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:01<00:32,  1.34s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:03<00:31,  1.36s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:04<00:29,  1.35s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:05<00:28,  1.35s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:07<00:26,  1.34s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:08<00:25,  1.33s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:09<00:24,  1.34s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:11<00:25,  1.47s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:13<00:25,  1.57s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:15<00:24,  1.63s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:16<00:23,  1.68s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:18<00:22,  1.71s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:20<00:20,  1.72s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:22<00:19,  1.73s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:23<00:17,  1.77s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:25<00:16,  1.78s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:27<00:14,  1.78s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:29<00:12,  1.78s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:31<00:10,  1.77s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:32<00:08,  1.77s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:34<00:07,  1.76s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:36<00:05,  1.77s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:38<00:03,  1.78s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:39<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 285/285 [07:41<00:00,  1.79s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<05:46,  1.22s/it]Loading train:   1%|          | 2/285 [00:02<06:00,  1.27s/it]Loading train:   1%|          | 3/285 [00:03<05:55,  1.26s/it]Loading train:   1%|▏         | 4/285 [00:05<06:16,  1.34s/it]Loading train:   2%|▏         | 5/285 [00:06<05:49,  1.25s/it]Loading train:   2%|▏         | 6/285 [00:07<06:06,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:28,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:33,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:12<06:12,  1.35s/it]Loading train:   4%|▎         | 10/285 [00:13<05:42,  1.25s/it]Loading train:   4%|▍         | 11/285 [00:14<05:22,  1.18s/it]Loading train:   4%|▍         | 12/285 [00:15<05:09,  1.13s/it]Loading train:   5%|▍         | 13/285 [00:16<04:52,  1.07s/it]Loading train:   5%|▍         | 14/285 [00:17<04:46,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:38,  1.03s/it]Loading train:   6%|▌         | 16/285 [00:19<04:31,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:20<04:33,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:21<04:27,  1.00s/it]Loading train:   7%|▋         | 19/285 [00:22<04:24,  1.00it/s]Loading train:   7%|▋         | 20/285 [00:23<04:27,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:24<04:26,  1.01s/it]Loading train:   8%|▊         | 22/285 [00:25<04:24,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:26<04:25,  1.01s/it]Loading train:   8%|▊         | 24/285 [00:27<04:15,  1.02it/s]Loading train:   9%|▉         | 25/285 [00:27<04:11,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:28<04:09,  1.04it/s]Loading train:   9%|▉         | 27/285 [00:29<04:10,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:30<04:08,  1.03it/s]Loading train:  10%|█         | 29/285 [00:31<03:59,  1.07it/s]Loading train:  11%|█         | 30/285 [00:32<03:49,  1.11it/s]Loading train:  11%|█         | 31/285 [00:33<03:45,  1.13it/s]Loading train:  11%|█         | 32/285 [00:34<03:45,  1.12it/s]Loading train:  12%|█▏        | 33/285 [00:35<03:48,  1.10it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:47,  1.10it/s]Loading train:  12%|█▏        | 35/285 [00:37<03:48,  1.09it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:47,  1.09it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:45,  1.10it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:42,  1.11it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:39,  1.12it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:35,  1.14it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:39,  1.11it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:34,  1.13it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:40,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:41,  1.09it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:41,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:30,  1.14it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:14,  1.23it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:05,  1.28it/s]Loading train:  17%|█▋        | 49/285 [00:48<02:59,  1.32it/s]Loading train:  18%|█▊        | 50/285 [00:49<02:53,  1.35it/s]Loading train:  18%|█▊        | 51/285 [00:50<02:49,  1.38it/s]Loading train:  18%|█▊        | 52/285 [00:51<02:47,  1.39it/s]Loading train:  19%|█▊        | 53/285 [00:51<02:49,  1.37it/s]Loading train:  19%|█▉        | 54/285 [00:52<02:45,  1.40it/s]Loading train:  19%|█▉        | 55/285 [00:53<02:50,  1.35it/s]Loading train:  20%|█▉        | 56/285 [00:54<02:46,  1.37it/s]Loading train:  20%|██        | 57/285 [00:54<02:50,  1.34it/s]Loading train:  20%|██        | 58/285 [00:55<02:51,  1.32it/s]Loading train:  21%|██        | 59/285 [00:56<02:51,  1.32it/s]Loading train:  21%|██        | 60/285 [00:57<02:52,  1.30it/s]Loading train:  21%|██▏       | 61/285 [00:57<02:51,  1.30it/s]Loading train:  22%|██▏       | 62/285 [00:58<02:49,  1.32it/s]Loading train:  22%|██▏       | 63/285 [00:59<02:53,  1.28it/s]Loading train:  22%|██▏       | 64/285 [01:00<03:26,  1.07it/s]Loading train:  23%|██▎       | 65/285 [01:02<04:04,  1.11s/it]
Epoch 00048: val_mDice did not improve from 0.58199
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [7626.665414663462, 5727.429818960337, 5029.570199819712, 4615.709979717548, 4520.4781165489785, 4349.1499586838945, 4293.8076735276445, 4193.6003183218145, 4184.706251878005, 4070.1601280799277, 4058.0682936448316, 3991.7298208383413, 3955.390587439904, 3944.9910560021035, 3864.0140944260816, 4000.596430851863, 4102.3781503530645, 3847.1423997145434, 4061.336444561298, 4205.947645920974, 4269.3324303260215, 4017.29294527494, 3996.69877741887, 4067.896784855769, 4076.0169818584736, 3990.2144822340747, 4160.003887469952, 4030.8382333608774, 4072.1643676757812, 4020.196274977464, 4059.7913677509014, 4157.690190241887, 4205.814626840444, 4228.70933180589, 3934.9373732346753, 4085.021259014423, 4221.353365384615, 4284.975524902344, 4087.8529146634614, 4088.595670259916, 4085.9418053260215, 4146.048044057993, 4155.8851647010215, 4022.058851975661, 4239.491342397837, 3955.4719895582934, 4130.766535832332, 4100.805180476262], 'val_acc': [0.8890809783568749, 0.9197716231529529, 0.9263082513442407, 0.9292067472751324, 0.9303115996030661, 0.931501927284094, 0.9328032296437484, 0.9317538646551279, 0.9313887059688568, 0.9328471834842975, 0.9342524982415713, 0.9343773057827582, 0.9357225551055028, 0.9363789581335508, 0.9360253467009618, 0.9348326738064106, 0.9361686385594882, 0.9403360738204076, 0.9383182456860175, 0.9337624678244958, 0.9357733772351191, 0.9384245620324061, 0.9360045378024762, 0.9379784625310165, 0.934166995378641, 0.9391965453441327, 0.9370053869027358, 0.9388914337525001, 0.9373358694406656, 0.9396796684998733, 0.9387342838140634, 0.9398368230232825, 0.9380847674149734, 0.9345737879092877, 0.9405810557878934, 0.9422429570784936, 0.9403060330794408, 0.9369752980195559, 0.9381055717284863, 0.9404169550308814, 0.9391619127530318, 0.942083484851397, 0.9415379785574399, 0.9400772108481481, 0.9378721576470596, 0.9400356022211221, 0.9436136002723987, 0.9411727900688465], 'val_mDice': [0.3543315971126923, 0.4561029913333746, 0.49866027442308575, 0.5242186119923224, 0.5320140971587255, 0.5418835545961673, 0.5469525152674088, 0.5520631739726434, 0.5534374771209863, 0.5621297267767099, 0.5645162572081273, 0.5687017710163043, 0.5715768274206382, 0.5727156526767291, 0.5790027173665854, 0.5699656410859182, 0.5619171198744041, 0.5819856621898137, 0.5661370972028146, 0.552664753049612, 0.5510249103491123, 0.5669673589559702, 0.5684583164178408, 0.5628102691127703, 0.5619555299098675, 0.5697155291071305, 0.5563765827279824, 0.5682107261740245, 0.5629303627289258, 0.5673296600580215, 0.5655859422225219, 0.5566900108869259, 0.5541744447098329, 0.5502511618229059, 0.5747180222891844, 0.565391464302173, 0.5563568962881198, 0.5588933630631521, 0.5645491618376511, 0.5627931740421516, 0.5656203521558871, 0.5594945807869618, 0.5599895159785564, 0.5713887352209824, 0.5570741272889651, 0.5741424669439976, 0.5624461013537186, 0.5643851891733133], 'loss': [14497.319120324604, 6545.1558412676595, 5119.040571339949, 4474.643450303479, 4095.7037960433504, 3780.3296716442565, 3578.4887152677707, 3427.678973271026, 3276.8113367801375, 3151.7978109436963, 3054.263401503274, 2983.100728486084, 2909.8080822435304, 2824.584539269737, 2787.6748382137744, 2703.718917034698, 2647.164045601767, 2602.500525151145, 2543.223995229497, 2504.2971898745336, 2465.3795725649975, 2415.998647499665, 2387.69586749043, 2349.5447985888254, 2320.056530904695, 2281.7069201731083, 2250.9858987342604, 2228.893134927965, 2198.5980440368626, 2157.022312129477, 2142.849350379466, 2124.863789992635, 2094.7839702946403, 2071.8791029663707, 2055.9368568426744, 2028.8514204861701, 2012.411527641231, 1992.1830090947842, 1977.3094380593416, 1951.6450442425232, 1939.7640355303754, 1927.1268998747391, 1914.8289224817602, 1888.0015731680649, 1873.368001981315, 1863.3745809328311, 1845.367422133258, 1832.621879371475], 'acc': [0.8611911745580659, 0.9027598678026759, 0.9191445730098178, 0.9249108779818482, 0.9289268060912618, 0.9318009346632855, 0.933845723817613, 0.9354183457494277, 0.9369708574380007, 0.9382471327443938, 0.9393360821026383, 0.9399669395869128, 0.94083669947971, 0.941671267878819, 0.9421167465293252, 0.9429381954860151, 0.9435438021109089, 0.9440499088547166, 0.9446904118360325, 0.9449757996228176, 0.9455289757582662, 0.9459776875773315, 0.946292472162733, 0.9468366503880427, 0.9471130350809591, 0.947519181966012, 0.9479881566542492, 0.9482666928148309, 0.9485076530375715, 0.9489095425964182, 0.9491177417250628, 0.9494226166246167, 0.9496026980055662, 0.949834347540829, 0.9500779050099919, 0.9504934264254022, 0.9506105088136584, 0.9508557225696321, 0.9511111595803693, 0.9514429712222972, 0.9515173063994575, 0.9517720616040806, 0.9519533602159908, 0.952174171314769, 0.9523019103901441, 0.9523460516177189, 0.9525769485721924, 0.952856128202377], 'mDice': [0.24607170577211088, 0.4312856767952228, 0.5136625940571256, 0.5569819768372468, 0.5844574236489415, 0.6083086933650336, 0.624454492134306, 0.636823796092458, 0.6493088629790407, 0.6599267987453837, 0.6682747045610374, 0.6745981949397936, 0.6810190841235392, 0.6884040711639134, 0.6919417253754779, 0.6992146884296737, 0.7043835794552988, 0.7084710799624183, 0.7139226735699147, 0.7175754320519245, 0.7211565987206051, 0.7258145526074884, 0.7285041143387806, 0.7320943828890335, 0.7349875562197387, 0.7385840214762116, 0.7415845482087515, 0.7438175227274196, 0.7467005005250456, 0.7507930679601859, 0.7521512262618686, 0.7539938598950938, 0.7567876396853799, 0.759137058768184, 0.7607791341451616, 0.7634870160124041, 0.7651853269452397, 0.7671510409431507, 0.7686621702257188, 0.7712675566043535, 0.7724957411924456, 0.773807162784688, 0.7750206259270387, 0.777743130661207, 0.7792311804734131, 0.7802385219643282, 0.7821366005384492, 0.7834257816604326]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0     Loading train:  23%|██▎       | 66/285 [01:03<04:10,  1.15s/it]Loading train:  24%|██▎       | 67/285 [01:04<03:49,  1.05s/it]Loading train:  24%|██▍       | 68/285 [01:05<03:32,  1.02it/s]Loading train:  24%|██▍       | 69/285 [01:05<03:19,  1.08it/s]Loading train:  25%|██▍       | 70/285 [01:06<03:07,  1.15it/s]Loading train:  25%|██▍       | 71/285 [01:07<03:00,  1.19it/s]Loading train:  25%|██▌       | 72/285 [01:08<02:56,  1.20it/s]Loading train:  26%|██▌       | 73/285 [01:09<02:49,  1.25it/s]Loading train:  26%|██▌       | 74/285 [01:09<02:51,  1.23it/s]Loading train:  26%|██▋       | 75/285 [01:10<02:49,  1.24it/s]Loading train:  27%|██▋       | 76/285 [01:11<02:45,  1.26it/s]Loading train:  27%|██▋       | 77/285 [01:12<02:52,  1.21it/s]Loading train:  27%|██▋       | 78/285 [01:13<02:47,  1.24it/s]Loading train:  28%|██▊       | 79/285 [01:13<02:43,  1.26it/s]Loading train:  28%|██▊       | 80/285 [01:14<02:43,  1.25it/s]Loading train:  28%|██▊       | 81/285 [01:15<02:41,  1.26it/s]Loading train:  29%|██▉       | 82/285 [01:16<02:43,  1.24it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:41,  1.25it/s]Loading train:  29%|██▉       | 84/285 [01:17<02:40,  1.25it/s]Loading train:  30%|██▉       | 85/285 [01:18<02:52,  1.16it/s]Loading train:  30%|███       | 86/285 [01:19<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:20<02:59,  1.10it/s]Loading train:  31%|███       | 88/285 [01:21<03:02,  1.08it/s]Loading train:  31%|███       | 89/285 [01:22<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:23<03:02,  1.07it/s]Loading train:  32%|███▏      | 91/285 [01:24<03:04,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:25<03:06,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:26<03:10,  1.01it/s]Loading train:  33%|███▎      | 94/285 [01:27<03:08,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:28<03:03,  1.04it/s]Loading train:  34%|███▎      | 96/285 [01:29<03:00,  1.05it/s]Loading train:  34%|███▍      | 97/285 [01:30<02:56,  1.06it/s]Loading train:  34%|███▍      | 98/285 [01:31<02:59,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:32<03:00,  1.03it/s]Loading train:  35%|███▌      | 100/285 [01:33<03:00,  1.03it/s]Loading train:  35%|███▌      | 101/285 [01:34<02:59,  1.02it/s]Loading train:  36%|███▌      | 102/285 [01:35<02:53,  1.05it/s]Loading train:  36%|███▌      | 103/285 [01:36<02:49,  1.07it/s]Loading train:  36%|███▋      | 104/285 [01:37<02:45,  1.09it/s]Loading train:  37%|███▋      | 105/285 [01:37<02:46,  1.08it/s]Loading train:  37%|███▋      | 106/285 [01:38<02:47,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:39<02:42,  1.09it/s]Loading train:  38%|███▊      | 108/285 [01:40<02:41,  1.09it/s]Loading train:  38%|███▊      | 109/285 [01:41<02:36,  1.12it/s]Loading train:  39%|███▊      | 110/285 [01:42<02:32,  1.15it/s]Loading train:  39%|███▉      | 111/285 [01:43<02:26,  1.19it/s]Loading train:  39%|███▉      | 112/285 [01:43<02:24,  1.19it/s]Loading train:  40%|███▉      | 113/285 [01:44<02:24,  1.19it/s]Loading train:  40%|████      | 114/285 [01:45<02:26,  1.16it/s]Loading train:  40%|████      | 115/285 [01:46<02:27,  1.16it/s]Loading train:  41%|████      | 116/285 [01:47<02:24,  1.17it/s]Loading train:  41%|████      | 117/285 [01:48<02:19,  1.20it/s]Loading train:  41%|████▏     | 118/285 [01:49<02:20,  1.19it/s]Loading train:  42%|████▏     | 119/285 [01:50<02:24,  1.15it/s]Loading train:  42%|████▏     | 120/285 [01:50<02:21,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:52<02:39,  1.03it/s]Loading train:  43%|████▎     | 122/285 [01:53<02:47,  1.02s/it]Loading train:  43%|████▎     | 123/285 [01:54<02:49,  1.04s/it]Loading train:  44%|████▎     | 124/285 [01:55<02:36,  1.03it/s]Loading train:  44%|████▍     | 125/285 [01:55<02:25,  1.10it/s]Loading train:  44%|████▍     | 126/285 [01:56<02:16,  1.16it/s]Loading train:  45%|████▍     | 127/285 [01:57<02:09,  1.22it/s]Loading train:  45%|████▍     | 128/285 [01:58<02:04,  1.26it/s]Loading train:  45%|████▌     | 129/285 [01:58<02:04,  1.26it/s]Loading train:  46%|████▌     | 130/285 [01:59<02:01,  1.27it/s]Loading train:  46%|████▌     | 131/285 [02:00<01:59,  1.29it/s]Loading train:  46%|████▋     | 132/285 [02:01<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:01<01:56,  1.31it/s]Loading train:  47%|████▋     | 134/285 [02:02<01:57,  1.28it/s]Loading train:  47%|████▋     | 135/285 [02:03<01:57,  1.27it/s]Loading train:  48%|████▊     | 136/285 [02:04<02:00,  1.23it/s]Loading train:  48%|████▊     | 137/285 [02:05<02:02,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:06<02:01,  1.21it/s]Loading train:  49%|████▉     | 139/285 [02:06<01:58,  1.24it/s]Loading train:  49%|████▉     | 140/285 [02:07<01:56,  1.24it/s]Loading train:  49%|████▉     | 141/285 [02:08<01:53,  1.27it/s]Loading train:  50%|████▉     | 142/285 [02:09<01:52,  1.28it/s]Loading train:  50%|█████     | 143/285 [02:09<01:49,  1.29it/s]Loading train:  51%|█████     | 144/285 [02:10<01:46,  1.33it/s]Loading train:  51%|█████     | 145/285 [02:11<01:46,  1.32it/s]Loading train:  51%|█████     | 146/285 [02:12<01:43,  1.35it/s]Loading train:  52%|█████▏    | 147/285 [02:12<01:41,  1.36it/s]Loading train:  52%|█████▏    | 148/285 [02:13<01:38,  1.39it/s]Loading train:  52%|█████▏    | 149/285 [02:14<01:37,  1.39it/s]Loading train:  53%|█████▎    | 150/285 [02:14<01:37,  1.39it/s]Loading train:  53%|█████▎    | 151/285 [02:15<01:37,  1.37it/s]Loading train:  53%|█████▎    | 152/285 [02:16<01:34,  1.40it/s]Loading train:  54%|█████▎    | 153/285 [02:17<01:33,  1.41it/s]Loading train:  54%|█████▍    | 154/285 [02:17<01:33,  1.40it/s]Loading train:  54%|█████▍    | 155/285 [02:18<01:33,  1.39it/s]Loading train:  55%|█████▍    | 156/285 [02:19<01:31,  1.41it/s]Loading train:  55%|█████▌    | 157/285 [02:19<01:28,  1.45it/s]Loading train:  55%|█████▌    | 158/285 [02:20<01:30,  1.41it/s]Loading train:  56%|█████▌    | 159/285 [02:21<01:28,  1.43it/s]Loading train:  56%|█████▌    | 160/285 [02:22<01:29,  1.39it/s]Loading train:  56%|█████▋    | 161/285 [02:22<01:29,  1.39it/s]Loading train:  57%|█████▋    | 162/285 [02:23<01:29,  1.37it/s]Loading train:  57%|█████▋    | 163/285 [02:24<01:27,  1.40it/s]Loading train:  58%|█████▊    | 164/285 [02:24<01:26,  1.41it/s]Loading train:  58%|█████▊    | 165/285 [02:25<01:25,  1.40it/s]Loading train:  58%|█████▊    | 166/285 [02:26<01:27,  1.36it/s]Loading train:  59%|█████▊    | 167/285 [02:27<01:26,  1.36it/s]Loading train:  59%|█████▉    | 168/285 [02:27<01:28,  1.32it/s]Loading train:  59%|█████▉    | 169/285 [02:28<01:24,  1.37it/s]Loading train:  60%|█████▉    | 170/285 [02:29<01:23,  1.37it/s]Loading train:  60%|██████    | 171/285 [02:29<01:19,  1.44it/s]Loading train:  60%|██████    | 172/285 [02:30<01:16,  1.48it/s]Loading train:  61%|██████    | 173/285 [02:31<01:17,  1.45it/s]Loading train:  61%|██████    | 174/285 [02:32<01:16,  1.46it/s]Loading train:  61%|██████▏   | 175/285 [02:32<01:14,  1.47it/s]Loading train:  62%|██████▏   | 176/285 [02:33<01:15,  1.45it/s]Loading train:  62%|██████▏   | 177/285 [02:34<01:13,  1.47it/s]Loading train:  62%|██████▏   | 178/285 [02:34<01:15,  1.42it/s]Loading train:  63%|██████▎   | 179/285 [02:35<01:14,  1.43it/s]Loading train:  63%|██████▎   | 180/285 [02:36<01:11,  1.46it/s]Loading train:  64%|██████▎   | 181/285 [02:36<01:10,  1.48it/s]Loading train:  64%|██████▍   | 182/285 [02:37<01:11,  1.43it/s]Loading train:  64%|██████▍   | 183/285 [02:38<01:11,  1.43it/s]Loading train:  65%|██████▍   | 184/285 [02:38<01:09,  1.45it/s]Loading train:  65%|██████▍   | 185/285 [02:39<01:09,  1.45it/s]Loading train:  65%|██████▌   | 186/285 [02:40<01:09,  1.42it/s]Loading train:  66%|██████▌   | 187/285 [02:41<01:08,  1.43it/s]Loading train:  66%|██████▌   | 188/285 [02:41<01:06,  1.46it/s]Loading train:  66%|██████▋   | 189/285 [02:42<01:05,  1.47it/s]Loading train:  67%|██████▋   | 190/285 [02:43<01:03,  1.49it/s]Loading train:  67%|██████▋   | 191/285 [02:43<01:02,  1.50it/s]Loading train:  67%|██████▋   | 192/285 [02:44<01:01,  1.52it/s]Loading train:  68%|██████▊   | 193/285 [02:45<01:01,  1.49it/s]Loading train:  68%|██████▊   | 194/285 [02:45<01:00,  1.51it/s]Loading train:  68%|██████▊   | 195/285 [02:46<01:00,  1.50it/s]Loading train:  69%|██████▉   | 196/285 [02:47<01:03,  1.41it/s]Loading train:  69%|██████▉   | 197/285 [02:47<01:03,  1.39it/s]Loading train:  69%|██████▉   | 198/285 [02:48<01:04,  1.34it/s]Loading train:  70%|██████▉   | 199/285 [02:49<01:04,  1.32it/s]Loading train:  70%|███████   | 200/285 [02:50<01:07,  1.26it/s]Loading train:  71%|███████   | 201/285 [02:51<01:05,  1.27it/s]Loading train:  71%|███████   | 202/285 [02:51<01:05,  1.26it/s]Loading train:  71%|███████   | 203/285 [02:52<01:04,  1.27it/s]Loading train:  72%|███████▏  | 204/285 [02:53<01:03,  1.28it/s]Loading train:  72%|███████▏  | 205/285 [02:54<01:02,  1.29it/s]Loading train:  72%|███████▏  | 206/285 [02:54<01:00,  1.31it/s]Loading train:  73%|███████▎  | 207/285 [02:55<00:57,  1.35it/s]Loading train:  73%|███████▎  | 208/285 [02:56<00:58,  1.31it/s]Loading train:  73%|███████▎  | 209/285 [02:57<00:58,  1.29it/s]Loading train:  74%|███████▎  | 210/285 [02:58<00:58,  1.28it/s]Loading train:  74%|███████▍  | 211/285 [02:58<00:58,  1.27it/s]Loading train:  74%|███████▍  | 212/285 [02:59<00:57,  1.28it/s]Loading train:  75%|███████▍  | 213/285 [03:00<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:01<00:54,  1.30it/s]Loading train:  75%|███████▌  | 215/285 [03:01<00:52,  1.33it/s]Loading train:  76%|███████▌  | 216/285 [03:02<00:51,  1.34it/s]Loading train:  76%|███████▌  | 217/285 [03:03<00:49,  1.36it/s]Loading train:  76%|███████▋  | 218/285 [03:04<00:48,  1.39it/s]Loading train:  77%|███████▋  | 219/285 [03:04<00:47,  1.38it/s]Loading train:  77%|███████▋  | 220/285 [03:05<00:47,  1.38it/s]Loading train:  78%|███████▊  | 221/285 [03:06<00:46,  1.39it/s]Loading train:  78%|███████▊  | 222/285 [03:06<00:44,  1.40it/s]Loading train:  78%|███████▊  | 223/285 [03:07<00:43,  1.42it/s]Loading train:  79%|███████▊  | 224/285 [03:08<00:43,  1.41it/s]Loading train:  79%|███████▉  | 225/285 [03:09<00:43,  1.37it/s]Loading train:  79%|███████▉  | 226/285 [03:09<00:43,  1.36it/s]Loading train:  80%|███████▉  | 227/285 [03:10<00:42,  1.38it/s]Loading train:  80%|████████  | 228/285 [03:11<00:40,  1.39it/s]Loading train:  80%|████████  | 229/285 [03:11<00:39,  1.41it/s]Loading train:  81%|████████  | 230/285 [03:12<00:39,  1.39it/s]Loading train:  81%|████████  | 231/285 [03:13<00:39,  1.38it/s]Loading train:  81%|████████▏ | 232/285 [03:14<00:40,  1.30it/s]Loading train:  82%|████████▏ | 233/285 [03:15<00:41,  1.26it/s]Loading train:  82%|████████▏ | 234/285 [03:16<00:42,  1.20it/s]Loading train:  82%|████████▏ | 235/285 [03:16<00:42,  1.18it/s]Loading train:  83%|████████▎ | 236/285 [03:17<00:41,  1.17it/s]Loading train:  83%|████████▎ | 237/285 [03:18<00:41,  1.15it/s]Loading train:  84%|████████▎ | 238/285 [03:19<00:40,  1.15it/s]Loading train:  84%|████████▍ | 239/285 [03:20<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:21<00:40,  1.12it/s]Loading train:  85%|████████▍ | 241/285 [03:22<00:39,  1.11it/s]Loading train:  85%|████████▍ | 242/285 [03:23<00:38,  1.12it/s]Loading train:  85%|████████▌ | 243/285 [03:24<00:37,  1.13it/s]Loading train:  86%|████████▌ | 244/285 [03:24<00:36,  1.14it/s]Loading train:  86%|████████▌ | 245/285 [03:25<00:35,  1.12it/s]Loading train:  86%|████████▋ | 246/285 [03:26<00:35,  1.11it/s]Loading train:  87%|████████▋ | 247/285 [03:27<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [03:28<00:33,  1.11it/s]Loading train:  87%|████████▋ | 249/285 [03:29<00:32,  1.12it/s]Loading train:  88%|████████▊ | 250/285 [03:30<00:29,  1.18it/s]Loading train:  88%|████████▊ | 251/285 [03:30<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:31<00:26,  1.24it/s]Loading train:  89%|████████▉ | 253/285 [03:32<00:24,  1.30it/s]Loading train:  89%|████████▉ | 254/285 [03:33<00:23,  1.33it/s]Loading train:  89%|████████▉ | 255/285 [03:33<00:22,  1.35it/s]Loading train:  90%|████████▉ | 256/285 [03:34<00:20,  1.41it/s]Loading train:  90%|█████████ | 257/285 [03:35<00:19,  1.44it/s]Loading train:  91%|█████████ | 258/285 [03:35<00:18,  1.45it/s]Loading train:  91%|█████████ | 259/285 [03:36<00:17,  1.46it/s]Loading train:  91%|█████████ | 260/285 [03:37<00:17,  1.44it/s]Loading train:  92%|█████████▏| 261/285 [03:37<00:16,  1.46it/s]Loading train:  92%|█████████▏| 262/285 [03:38<00:16,  1.43it/s]Loading train:  92%|█████████▏| 263/285 [03:39<00:15,  1.39it/s]Loading train:  93%|█████████▎| 264/285 [03:39<00:14,  1.42it/s]Loading train:  93%|█████████▎| 265/285 [03:40<00:13,  1.43it/s]Loading train:  93%|█████████▎| 266/285 [03:41<00:13,  1.42it/s]Loading train:  94%|█████████▎| 267/285 [03:42<00:12,  1.45it/s]Loading train:  94%|█████████▍| 268/285 [03:42<00:12,  1.32it/s]Loading train:  94%|█████████▍| 269/285 [03:43<00:12,  1.28it/s]Loading train:  95%|█████████▍| 270/285 [03:44<00:11,  1.26it/s]Loading train:  95%|█████████▌| 271/285 [03:45<00:11,  1.18it/s]Loading train:  95%|█████████▌| 272/285 [03:46<00:11,  1.15it/s]Loading train:  96%|█████████▌| 273/285 [03:47<00:10,  1.14it/s]Loading train:  96%|█████████▌| 274/285 [03:48<00:09,  1.13it/s]Loading train:  96%|█████████▋| 275/285 [03:49<00:08,  1.11it/s]Loading train:  97%|█████████▋| 276/285 [03:50<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [03:51<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [03:52<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [03:52<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [03:53<00:04,  1.11it/s]Loading train:  99%|█████████▊| 281/285 [03:54<00:03,  1.13it/s]Loading train:  99%|█████████▉| 282/285 [03:55<00:02,  1.14it/s]Loading train:  99%|█████████▉| 283/285 [03:56<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [03:57<00:00,  1.13it/s]Loading train: 100%|██████████| 285/285 [03:58<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:00, 319.45it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:00, 274.84it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:00, 237.03it/s]concatenating: train:  35%|███▌      | 100/285 [00:00<00:00, 249.29it/s]concatenating: train:  45%|████▌     | 129/285 [00:00<00:00, 259.48it/s]concatenating: train:  56%|█████▌    | 159/285 [00:00<00:00, 267.88it/s]concatenating: train:  67%|██████▋   | 192/285 [00:00<00:00, 283.37it/s]concatenating: train:  78%|███████▊  | 222/285 [00:00<00:00, 286.70it/s]concatenating: train:  89%|████████▉ | 253/285 [00:00<00:00, 292.67it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 298.79it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.21s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 186.10it/s] 11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________2019-07-07 05:55:51.260916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 05:55:51.261021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 05:55:51.261036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 05:55:51.261046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 05:55:51.261456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 23s - loss: 14372.7842 - acc: 0.8448 - mDice: 0.1664 - val_loss: 6130.5326 - val_acc: 0.8798 - val_mDice: 0.2821

Epoch 00001: val_mDice improved from -inf to 0.28206, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 5476.3305 - acc: 0.8653 - mDice: 0.3428 - val_loss: 4694.0142 - val_acc: 0.9022 - val_mDice: 0.3728

Epoch 00002: val_mDice improved from 0.28206 to 0.37280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 4215.3463 - acc: 0.8838 - mDice: 0.4313 - val_loss: 3872.1978 - val_acc: 0.9190 - val_mDice: 0.4367

Epoch 00003: val_mDice improved from 0.37280 to 0.43672, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 3508.0512 - acc: 0.8984 - mDice: 0.4929 - val_loss: 3496.0254 - val_acc: 0.9269 - val_mDice: 0.4693

Epoch 00004: val_mDice improved from 0.43672 to 0.46927, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 3090.4308 - acc: 0.9081 - mDice: 0.5346 - val_loss: 3222.9522 - val_acc: 0.9307 - val_mDice: 0.4953

Epoch 00005: val_mDice improved from 0.46927 to 0.49531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 2805.2622 - acc: 0.9147 - mDice: 0.5658 - val_loss: 3014.5822 - val_acc: 0.9333 - val_mDice: 0.5160

Epoch 00006: val_mDice improved from 0.49531 to 0.51596, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 2593.6344 - acc: 0.9194 - mDice: 0.5905 - val_loss: 2896.5492 - val_acc: 0.9349 - val_mDice: 0.5278

Epoch 00007: val_mDice improved from 0.51596 to 0.52782, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 2441.3098 - acc: 0.9231 - mDice: 0.6090 - val_loss: 2866.1715 - val_acc: 0.9368 - val_mDice: 0.5303

Epoch 00008: val_mDice improved from 0.52782 to 0.53027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 2316.7440 - acc: 0.9260 - mDice: 0.6245 - val_loss: 2793.4471 - val_acc: 0.9379 - val_mDice: 0.5391

Epoch 00009: val_mDice improved from 0.53027 to 0.53906, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 13s - loss: 2214.3801 - acc: 0.9286 - mDice: 0.6376 - val_loss: 2731.6619 - val_acc: 0.9388 - val_mDice: 0.5451

Epoch 00010: val_mDice improved from 0.53906 to 0.54506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 2118.6382 - acc: 0.9308 - mDice: 0.6501 - val_loss: 2738.9454 - val_acc: 0.9408 - val_mDice: 0.5438

Epoch 00011: val_mDice did not improve from 0.54506
Epoch 12/300
 - 13s - loss: 2037.5952 - acc: 0.9327 - mDice: 0.6609 - val_loss: 2674.3463 - val_acc: 0.9400 - val_mDice: 0.5518

Epoch 00012: val_mDice improved from 0.54506 to 0.55181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 14s - loss: 1973.9757 - acc: 0.9342 - mDice: 0.6693 - val_loss: 2757.5329 - val_acc: 0.9414 - val_mDice: 0.5409

Epoch 00013: val_mDice did not improve from 0.55181
Epoch 14/300
 - 13s - loss: 1919.6954 - acc: 0.9357 - mDice: 0.6767 - val_loss: 2592.3195 - val_acc: 0.9414 - val_mDice: 0.5602

Epoch 00014: val_mDice improved from 0.55181 to 0.56020, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 13s - loss: 1856.9670 - acc: 0.9368 - mDice: 0.6852 - val_loss: 2611.8389 - val_acc: 0.9421 - val_mDice: 0.5579

Epoch 00015: val_mDice did not improve from 0.56020
Epoch 16/300
 - 13s - loss: 1789.3924 - acc: 0.9380 - mDice: 0.6945 - val_loss: 2700.2362 - val_acc: 0.9422 - val_mDice: 0.5478

Epoch 00016: val_mDice did not improve from 0.56020
Epoch 17/300
 - 13s - loss: 1747.4653 - acc: 0.9390 - mDice: 0.7005 - val_loss: 2727.2561 - val_acc: 0.9433 - val_mDice: 0.5465

Epoch 00017: val_mDice did not improve from 0.56020
Epoch 18/300
 - 13s - loss: 1700.9251 - acc: 0.9402 - mDice: 0.7071 - val_loss: 2692.5296 - val_acc: 0.9446 - val_mDice: 0.5499

Epoch 00018: val_mDice did not improve from 0.56020
Epoch 19/300
 - 14s - loss: 1670.0684 - acc: 0.9408 - mDice: 0.7115 - val_loss: 2665.3193 - val_acc: 0.9447 - val_mDice: 0.5532

Epoch 00019: val_mDice did not improve from 0.56020
Epoch 20/300
 - 14s - loss: 1625.4844 - acc: 0.9417 - mDice: 0.7179 - val_loss: 2876.4996 - val_acc: 0.9407 - val_mDice: 0.5282

Epoch 00020: val_mDice did not improve from 0.56020
Epoch 21/300
 - 13s - loss: 1583.3570 - acc: 0.9426 - mDice: 0.7240 - val_loss: 2798.7012 - val_acc: 0.9398 - val_mDice: 0.5381

Epoch 00021: val_mDice did not improve from 0.56020
Epoch 22/300
 - 13s - loss: 1551.6234 - acc: 0.9431 - mDice: 0.7287 - val_loss: 2795.0823 - val_acc: 0.9450 - val_mDice: 0.5369

Epoch 00022: val_mDice did not improve from 0.56020
Epoch 23/300
 - 13s - loss: 1513.3802 - acc: 0.9439 - mDice: 0.7343 - val_loss: 2694.1120 - val_acc: 0.9421 - val_mDice: 0.5506

Epoch 00023: val_mDice did not improve from 0.56020
Epoch 24/300
 - 13s - loss: 1487.8486 - acc: 0.9445 - mDice: 0.7379 - val_loss: 2802.2559 - val_acc: 0.9434 - val_mDice: 0.5373

Epoch 00024: val_mDice did not improve from 0.56020
Epoch 25/300
 - 14s - loss: 1454.0092 - acc: 0.9452 - mDice: 0.7431 - val_loss: 2703.5610 - val_acc: 0.9467 - val_mDice: 0.5475

Epoch 00025: val_mDice did not improve from 0.56020
Epoch 26/300
 - 14s - loss: 1432.5149 - acc: 0.9457 - mDice: 0.7464 - val_loss: 2759.6656 - val_acc: 0.9423 - val_mDice: 0.5415

Epoch 00026: val_mDice did not improve from 0.56020
Epoch 27/300
 - 14s - loss: 1405.4753 - acc: 0.9463 - mDice: 0.7504 - val_loss: 2692.8480 - val_acc: 0.9442 - val_mDice: 0.5511

Epoch 00027: val_mDice did not improve from 0.56020
Epoch 28/300
 - 13s - loss: 1379.7815 - acc: 0.9469 - mDice: 0.7543 - val_loss: 2965.0169 - val_acc: 0.9411 - val_mDice: 0.5186

Epoch 00028: val_mDice did not improve from 0.56020
Epoch 29/300
 - 13s - loss: 1355.3128 - acc: 0.9473 - mDice: 0.7580 - val_loss: 2889.3865 - val_acc: 0.9416 - val_mDice: 0.5276

Epoch 00029: val_mDice did not improve from 0.56020
Epoch 30/300
 - 13s - loss: 1333.9418 - acc: 0.9477 - mDice: 0.7613 - val_loss: 2929.9001 - val_acc: 0.9432 - val_mDice: 0.5236

Epoch 00030: val_mDice did not improve from 0.56020
Epoch 31/300
 - 13s - loss: 1323.8407 - acc: 0.9481 - mDice: 0.7629 - val_loss: 2848.0177 - val_acc: 0.9409 - val_mDice: 0.5307

Epoch 00031: val_mDice did not improve from 0.56020
Epoch 32/300
 - 13s - loss: 1293.8125 - acc: 0.9487 - mDice: 0.7675 - val_loss: 2695.0216 - val_acc: 0.9459 - val_mDice: 0.5494

Epoch 00032: val_mDice did not improve from 0.56020
Epoch 33/300
 - 13s - loss: 1273.9612 - acc: 0.9490 - mDice: 0.7705 - val_loss: 2818.0033 - val_acc: 0.9437 - val_mDice: 0.5366

Epoch 00033: val_mDice did not improve from 0.56020
Epoch 34/300
 - 14s - loss: 1258.0625 - acc: 0.9493 - mDice: 0.7730 - val_loss: 2861.5330 - val_acc: 0.9462 - val_mDice: 0.5321

Epoch 00034: val_mDice did not improve from 0.56020
Epoch 35/300
 - 14s - loss: 1238.6802 - acc: 0.9497 - mDice: 0.7761 - val_loss: 2670.0235 - val_acc: 0.9464 - val_mDice: 0.5531

Epoch 00035: val_mDice did not improve from 0.56020
Epoch 36/300
 - 14s - loss: 1224.7871 - acc: 0.9500 - mDice: 0.7783 - val_loss: 3084.4864 - val_acc: 0.9367 - val_mDice: 0.5078

Epoch 00036: val_mDice did not improve from 0.56020
Epoch 37/300
 - 14s - loss: 1195.8148 - acc: 0.9506 - mDice: 0.7829 - val_loss: 2904.4088 - val_acc: 0.9440 - val_mDice: 0.5283

Epoch 00037: val_mDice did not improve from 0.56020
Epoch 38/300
 - 14s - loss: 1185.5240 - acc: 0.9508 - mDice: 0.7845 - val_loss: 2835.4048 - val_acc: 0.9442 - val_mDice: 0.5357

Epoch 00038: val_mDice did not improve from 0.56020
Epoch 39/300
 - 14s - loss: 1167.0075 - acc: 0.9512 - mDice: 0.7874 - val_loss: 2724.4802 - val_acc: 0.9418 - val_mDice: 0.5453

Epoch 00039: val_mDice did not improve from 0.56020
Epoch 40/300
 - 14s - loss: 1156.6052 - acc: 0.9514 - mDice: 0.7891 - val_loss: 2645.3117 - val_acc: 0.9478 - val_mDice: 0.5562

Epoch 00040: val_mDice did not improve from 0.56020
Epoch 41/300
 - 14s - loss: 1145.9939 - acc: 0.9517 - mDice: 0.7908 - val_loss: 2818.5483 - val_acc: 0.9469 - val_mDice: 0.5356

Epoch 00041: val_mDice did not improve from 0.56020
Epoch 42/300
 - 14s - loss: 1128.5044 - acc: 0.9521 - mDice: 0.7936 - val_loss: 2969.6072 - val_acc: 0.9458 - val_mDice: 0.5201

Epoch 00042: val_mDice did not improve from 0.56020
Epoch 43/300
 - 14s - loss: 1111.1635 - acc: 0.9524 - mDice: 0.7963 - val_loss: 2741.1824 - val_acc: 0.9448 - val_mDice: 0.5440

Epoch 00043: val_mDice did not improve from 0.56020
Epoch 44/300
 - 14s - loss: 1099.4677 - acc: 0.9527 - mDice: 0.7982 - val_loss: 2867.0531 - val_acc: 0.9453 - val_mDice: 0.5308

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:26,  1.36s/it]predicting train subjects:   1%|          | 2/285 [00:03<06:50,  1.45s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:51,  1.46s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:06,  1.52s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:39,  1.65s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:24,  1.82s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:13,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:24,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:37,  1.89s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:48,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:55,  1.97s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:55,  1.98s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:58,  2.00s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:45,  1.95s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:42,  1.95s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:51,  1.99s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:44,  1.98s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:35,  1.95s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:26,  1.93s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:27,  1.94s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<08:28,  1.95s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:38,  2.00s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:38,  2.00s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:33,  1.99s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:29,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:13,  1.93s/it]predicting train subjects:  11%|█         | 30/285 [00:56<07:59,  1.88s/it]predicting train subjects:  11%|█         | 31/285 [00:58<07:51,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [01:00<07:51,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:02<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<07:37,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:34,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:39,  1.85s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:34,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:13<07:36,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:29,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:26,  1.83s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:27,  1.84s/it]predicting train subjects:  15%|█▌        | 43/285 [01:20<07:27,  1.85s/it]predicting train subjects:  15%|█▌        | 44/285 [01:22<07:31,  1.87s/it]predicting train subjects:  16%|█▌        | 45/285 [01:24<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:04,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<06:29,  1.64s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<06:21,  1.62s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<06:27,  1.65s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<06:21,  1.63s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<06:23,  1.65s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<06:21,  1.64s/it]predicting train subjects:  19%|█▉        | 54/285 [01:38<06:19,  1.64s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<06:14,  1.63s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<06:10,  1.62s/it]predicting train subjects:  20%|██        | 57/285 [01:43<06:07,  1.61s/it]predicting train subjects:  20%|██        | 58/285 [01:45<06:10,  1.63s/it]predicting train subjects:  21%|██        | 59/285 [01:46<05:58,  1.59s/it]predicting train subjects:  21%|██        | 60/285 [01:48<05:54,  1.58s/it]predicting train subjects:  21%|██▏       | 61/285 [01:49<05:55,  1.59s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<05:57,  1.60s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<05:51,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<05:59,  1.63s/it]predicting train subjects:  23%|██▎       | 65/285 [01:56<06:14,  1.70s/it]predicting train subjects:  23%|██▎       | 66/285 [01:58<06:19,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:17,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [02:01<06:13,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:03<06:06,  1.70s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:01,  1.68s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:02,  1.69s/it]predicting train subjects:  25%|██▌       | 72/285 [02:08<06:03,  1.71s/it]predicting train subjects:  26%|██▌       | 73/285 [02:10<06:00,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<05:56,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<05:53,  1.68s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<05:51,  1.68s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<05:48,  1.67s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:42,  1.66s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:37,  1.64s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<05:35,  1.64s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:34,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:32,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:48,  1.75s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:58,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:35<06:02,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:37<06:03,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:59,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<06:03,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:43<06:11,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [02:45<06:11,  1.93s/it]predicting train subjects:  33%|███▎      | 94/285 [02:47<06:06,  1.92s/it]predicting train subjects:  33%|███▎      | 95/285 [02:49<06:03,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [02:51<06:02,  1.92s/it]predicting train subjects:  34%|███▍      | 97/285 [02:53<06:00,  1.92s/it]predicting train subjects:  34%|███▍      | 98/285 [02:55<05:53,  1.89s/it]predicting train subjects:  35%|███▍      | 99/285 [02:56<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [02:58<05:48,  1.88s/it]predicting train subjects:  35%|███▌      | 101/285 [03:00<05:47,  1.89s/it]predicting train subjects:  36%|███▌      | 102/285 [03:02<05:46,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:04<05:40,  1.87s/it]predicting train subjects:  36%|███▋      | 104/285 [03:06<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:07<05:26,  1.81s/it]predicting train subjects:  37%|███▋      | 106/285 [03:09<05:25,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:11<05:24,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:13<05:21,  1.81s/it]predicting train subjects:  38%|███▊      | 109/285 [03:15<05:19,  1.81s/it]predicting train subjects:  39%|███▊      | 110/285 [03:16<05:15,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:18<05:14,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:20<05:11,  1.80s/it]predicting train subjects:  40%|███▉      | 113/285 [03:22<05:12,  1.82s/it]predicting train subjects:  40%|████      | 114/285 [03:24<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:26<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:28<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:29<05:08,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:31<05:07,  1.84s/it]predicting train subjects:  42%|████▏     | 119/285 [03:33<05:04,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:35<05:03,  1.84s/it]predicting train subjects:  42%|████▏     | 121/285 [03:36<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:38<04:34,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:39<04:21,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:41<04:20,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:43<04:20,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:44<04:19,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<04:20,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [03:48<04:20,  1.66s/it]predicting train subjects:  45%|████▌     | 129/285 [03:49<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<04:18,  1.67s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<04:17,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<04:15,  1.67s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<04:13,  1.66s/it]predicting train subjects:  47%|████▋     | 134/285 [03:58<04:10,  1.66s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<04:12,  1.68s/it]predicting train subjects:  48%|████▊     | 136/285 [04:01<04:06,  1.66s/it]predicting train subjects:  48%|████▊     | 137/285 [04:03<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:04<04:01,  1.64s/it]predicting train subjects:  49%|████▉     | 139/285 [04:06<04:01,  1.65s/it]predicting train subjects:  49%|████▉     | 140/285 [04:08<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:09<03:56,  1.64s/it]predicting train subjects:  50%|████▉     | 142/285 [04:11<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:12<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:14<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:15<03:35,  1.54s/it]predicting train subjects:  51%|█████     | 146/285 [04:17<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:18<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:20<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:21<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:23<03:20,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:26<03:19,  1.50s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:29<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:11,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:31<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:33<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:05,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:03,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:00,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<02:54,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:46<02:55,  1.47s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:48<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:49<02:50,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:50<02:48,  1.46s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:52<02:47,  1.46s/it]predicting train subjects:  60%|██████    | 171/285 [04:53<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:55<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:56<02:38,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:58<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:59<02:33,  1.39s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:00<02:34,  1.41s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:02<02:32,  1.41s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:03<02:29,  1.40s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:05<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<02:27,  1.40s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:07<02:25,  1.40s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:25,  1.41s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:10<02:22,  1.40s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:12<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:13<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:14<02:17,  1.39s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:16<02:18,  1.41s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:17<02:16,  1.41s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:19<02:14,  1.41s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:20<02:13,  1.41s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:21<02:11,  1.40s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:23<02:10,  1.40s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:24<02:10,  1.42s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:26<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:27<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:29<02:12,  1.49s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:30<02:18,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:32<02:18,  1.59s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:34<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:35<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:37<02:16,  1.63s/it]predicting train subjects:  71%|███████   | 202/285 [05:39<02:15,  1.64s/it]predicting train subjects:  71%|███████   | 203/285 [05:40<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:42<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:44<02:13,  1.67s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:45<02:12,  1.68s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:47<02:11,  1.68s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:49<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:51<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:52<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:54<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:56<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:57<02:01,  1.69s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:59<01:56,  1.64s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:00<01:50,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:02<01:47,  1.55s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:03<01:44,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:05<01:42,  1.53s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:06<01:39,  1.51s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:08<01:37,  1.50s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:09<01:35,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:11<01:34,  1.51s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:12<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:14<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:15<01:29,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:17<01:27,  1.48s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:18<01:26,  1.50s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:25,  1.51s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:23,  1.49s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:21,  1.48s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:19,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:28<01:26,  1.67s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:30<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:27,  1.75s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:27,  1.78s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:27,  1.81s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:37<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:39<01:25,  1.86s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:41<01:24,  1.87s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:43<01:23,  1.89s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:45<01:22,  1.92s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:47<01:20,  1.91s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:48<01:16,  1.87s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:50<01:16,  1.91s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:52<01:13,  1.89s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:54<01:10,  1.86s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:56<01:08,  1.86s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<01:06,  1.85s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:59<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:02<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:04<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:05<00:46,  1.52s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:06<00:44,  1.49s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:08<00:42,  1.46s/it]predicting train subjects:  90%|█████████ | 257/285 [07:09<00:40,  1.44s/it]predicting train subjects:  91%|█████████ | 258/285 [07:11<00:39,  1.45s/it]predicting train subjects:  91%|█████████ | 259/285 [07:12<00:36,  1.42s/it]predicting train subjects:  91%|█████████ | 260/285 [07:14<00:35,  1.43s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:15<00:34,  1.42s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:16<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:18<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:19<00:29,  1.39s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:20<00:27,  1.39s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:22<00:26,  1.38s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:23<00:24,  1.37s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:25<00:26,  1.56s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:27<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:29<00:25,  1.70s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:31<00:24,  1.74s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:33<00:23,  1.79s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:34<00:21,  1.82s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:36<00:20,  1.84s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:38<00:18,  1.88s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:40<00:16,  1.88s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:42<00:15,  1.88s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:44<00:13,  1.86s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:46<00:11,  1.86s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:48<00:09,  1.87s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:50<00:07,  1.87s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:51<00:05,  1.88s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:53<00:03,  1.88s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:55<00:01,  1.90s/it]predicting train subjects: 100%|██████████| 285/285 [07:57<00:00,  1.89s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<06:27,  1.36s/it]Loading train:   1%|          | 2/285 [00:02<06:45,  1.43s/it]Loading train:   1%|          | 3/285 [00:04<06:31,  1.39s/it]Loading train:   1%|▏         | 4/285 [00:05<06:47,  1.45s/it]Loading train:   2%|▏         | 5/285 [00:07<06:26,  1.38s/it]Loading train:   2%|▏         | 6/285 [00:08<06:48,  1.47s/it]Loading train:   2%|▏         | 7/285 [00:10<07:22,  1.59s/it]Loading train:   3%|▎         | 8/285 [00:12<07:24,  1.60s/it]Loading train:   3%|▎         | 9/285 [00:13<06:56,  1.51s/it]Loading train:   4%|▎         | 10/285 [00:14<06:27,  1.41s/it]Loading train:   4%|▍         | 11/285 [00:15<06:05,  1.33s/it]Loading train:   4%|▍         | 12/285 [00:17<05:53,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:18<05:38,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:19<05:32,  1.23s/it]Loading train:   5%|▌         | 15/285 [00:20<05:26,  1.21s/it]Loading train:   6%|▌         | 16/285 [00:21<05:20,  1.19s/it]Loading train:   6%|▌         | 17/285 [00:22<05:17,  1.19s/it]Loading train:   6%|▋         | 18/285 [00:24<05:18,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:25<05:12,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:26<05:07,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:27<05:07,  1.16s/it]Loading train:   8%|▊         | 22/285 [00:28<04:56,  1.13s/it]Loading train:   8%|▊         | 23/285 [00:29<05:00,  1.15s/it]Loading train:   8%|▊         | 24/285 [00:30<05:01,  1.15s/it]Loading train:   9%|▉         | 25/285 [00:32<04:59,  1.15s/it]Loading train:   9%|▉         | 26/285 [00:33<05:00,  1.16s/it]Loading train:   9%|▉         | 27/285 [00:34<05:05,  1.18s/it]Loading train:  10%|▉         | 28/285 [00:35<04:57,  1.16s/it]Loading train:  10%|█         | 29/285 [00:36<04:46,  1.12s/it]Loading train:  11%|█         | 30/285 [00:37<04:34,  1.08s/it]Loading train:  11%|█         | 31/285 [00:38<04:36,  1.09s/it]Loading train:  11%|█         | 32/285 [00:39<04:31,  1.07s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:30,  1.07s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:26,  1.06s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:21,  1.05s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:18,  1.04s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:13,  1.02s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:09,  1.01s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:18,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:18,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:19,  1.07s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:20,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:21,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:16,  1.07s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:09,  1.05s/it]Loading train:  16%|█▋        | 47/285 [00:55<03:59,  1.01s/it]Loading train:  17%|█▋        | 48/285 [00:56<03:51,  1.03it/s]Loading train:  17%|█▋        | 49/285 [00:57<03:42,  1.06it/s]Loading train:  18%|█▊        | 50/285 [00:58<03:37,  1.08it/s]Loading train:  18%|█▊        | 51/285 [00:58<03:37,  1.07it/s]Loading train:  18%|█▊        | 52/285 [00:59<03:38,  1.07it/s]Loading train:  19%|█▊        | 53/285 [01:00<03:38,  1.06it/s]Loading train:  19%|█▉        | 54/285 [01:01<03:32,  1.09it/s]Loading train:  19%|█▉        | 55/285 [01:02<03:34,  1.07it/s]Loading train:  20%|█▉        | 56/285 [01:03<03:32,  1.08it/s]Loading train:  20%|██        | 57/285 [01:04<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:05<03:38,  1.04it/s]Loading train:  21%|██        | 59/285 [01:06<03:40,  1.02it/s]Loading train:  21%|██        | 60/285 [01:07<03:34,  1.05it/s]Loading train:  21%|██▏       | 61/285 [01:08<03:33,  1.05it/s]Loading train:  22%|██▏       | 62/285 [01:09<03:27,  1.07it/s]Loading train:  22%|██▏       | 63/285 [01:10<03:25,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:11<04:02,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:13<04:37,  1.26s/it]Loading train:  23%|██▎       | 66/285 [01:14<04:52,  1.33s/it]Loading train:  24%|██▎       | 67/285 [01:15<04:20,  1.20s/it]Loading train:  24%|██▍       | 68/285 [01:16<03:59,  1.10s/it]Loading train:  24%|██▍       | 69/285 [01:17<03:43,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:18<03:31,  1.02it/s]Loading train:  25%|██▍       | 71/285 [01:19<03:27,  1.03it/s]Loading train:  25%|██▌       | 72/285 [01:20<03:23,  1.04it/s]Loading train:  26%|██▌       | 73/285 [01:21<03:21,  1.05it/s]Loading train:  26%|██▌       | 74/285 [01:22<03:27,  1.01it/s]Loading train:  26%|██▋       | 75/285 [01:23<03:20,  1.05it/s]Loading train:  27%|██▋       | 76/285 [01:24<03:23,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:25<03:22,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:26<03:21,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:27<03:20,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:28<03:16,  1.04it/s]Loading train:  28%|██▊       | 81/285 [01:28<03:12,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:29<03:13,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:30<03:15,  1.03it/s]Loading train:  29%|██▉       | 84/285 [01:31<03:14,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:32<03:19,  1.00it/s]Loading train:  30%|███       | 86/285 [01:34<03:23,  1.02s/it]Loading train:  31%|███       | 87/285 [01:35<03:24,  1.04s/it]Loading train:  31%|███       | 88/285 [01:36<03:25,  1.04s/it]Loading train:  31%|███       | 89/285 [01:37<03:21,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:38<03:20,  1.03s/it]Loading train:  32%|███▏      | 91/285 [01:39<03:17,  1.02s/it]Loading train:  32%|███▏      | 92/285 [01:40<03:17,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:41<03:17,  1.03s/it]Loading train:  33%|███▎      | 94/285 [01:42<03:21,  1.06s/it]Loading train:  33%|███▎      | 95/285 [01:43<03:17,  1.04s/it]Loading train:  34%|███▎      | 96/285 [01:44<03:17,  1.04s/it]Loading train:  34%|███▍      | 97/285 [01:45<03:22,  1.08s/it]Loading train:  34%|███▍      | 98/285 [01:46<03:21,  1.08s/it]Loading train:  35%|███▍      | 99/285 [01:47<03:15,  1.05s/it]Loading train:  35%|███▌      | 100/285 [01:48<03:09,  1.02s/it]Loading train:  35%|███▌      | 101/285 [01:49<03:09,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:50<03:08,  1.03s/it]Loading train:  36%|███▌      | 103/285 [01:51<03:08,  1.04s/it]Loading train:  36%|███▋      | 104/285 [01:52<03:07,  1.04s/it]Loading train:  37%|███▋      | 105/285 [01:53<03:01,  1.01s/it]Loading train:  37%|███▋      | 106/285 [01:54<02:55,  1.02it/s]Loading train:  38%|███▊      | 107/285 [01:55<02:57,  1.00it/s]Loading train:  38%|███▊      | 108/285 [01:56<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [01:57<02:58,  1.01s/it]Loading train:  39%|███▊      | 110/285 [01:58<02:57,  1.01s/it]Loading train:  39%|███▉      | 111/285 [01:59<02:56,  1.02s/it]Loading train:  39%|███▉      | 112/285 [02:00<02:57,  1.02s/it]Loading train:  40%|███▉      | 113/285 [02:01<03:02,  1.06s/it]Loading train:  40%|████      | 114/285 [02:03<03:04,  1.08s/it]Loading train:  40%|████      | 115/285 [02:04<03:04,  1.09s/it]Loading train:  41%|████      | 116/285 [02:05<03:01,  1.07s/it]Loading train:  41%|████      | 117/285 [02:06<03:03,  1.09s/it]Loading train:  41%|████▏     | 118/285 [02:07<03:02,  1.09s/it]Loading train:  42%|████▏     | 119/285 [02:08<02:59,  1.08s/it]Loading train:  42%|████▏     | 120/285 [02:09<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [02:10<03:08,  1.15s/it]Loading train:  43%|████▎     | 122/285 [02:12<03:10,  1.17s/it]Loading train:  43%|████▎     | 123/285 [02:13<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:14<03:04,  1.14s/it]Loading train:  44%|████▍     | 125/285 [02:15<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [02:16<02:50,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:17<02:37,  1.00it/s]Loading train:  45%|████▍     | 128/285 [02:18<02:32,  1.03it/s]Loading train:  45%|████▌     | 129/285 [02:19<02:33,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:20<02:31,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:20<02:27,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:21<02:26,  1.05it/s]Loading train:  47%|████▋     | 133/285 [02:22<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:23<02:28,  1.01it/s]Loading train:  47%|████▋     | 135/285 [02:24<02:26,  1.02it/s]Loading train:  48%|████▊     | 136/285 [02:25<02:24,  1.03it/s]Loading train:  48%|████▊     | 137/285 [02:26<02:18,  1.06it/s]Loading train:  48%|████▊     | 138/285 [02:27<02:17,  1.07it/s]Loading train:  49%|████▉     | 139/285 [02:28<02:13,  1.09it/s]Loading train:  49%|████▉     | 140/285 [02:29<02:15,  1.07it/s]Loading train:  49%|████▉     | 141/285 [02:30<02:13,  1.08it/s]Loading train:  50%|████▉     | 142/285 [02:31<02:13,  1.07it/s]Loading train:  50%|█████     | 143/285 [02:32<02:09,  1.09it/s]Loading train:  51%|█████     | 144/285 [02:33<02:11,  1.07it/s]Loading train:  51%|█████     | 145/285 [02:34<02:09,  1.08it/s]Loading train:  51%|█████     | 146/285 [02:35<02:07,  1.09it/s]Loading train:  52%|█████▏    | 147/285 [02:35<02:02,  1.12it/s]Loading train:  52%|█████▏    | 148/285 [02:36<02:05,  1.09it/s]Loading train:  52%|█████▏    | 149/285 [02:37<02:06,  1.07it/s]Loading train:  53%|█████▎    | 150/285 [02:38<02:03,  1.09it/s]Loading train:  53%|█████▎    | 151/285 [02:39<01:59,  1.13it/s]Loading train:  53%|█████▎    | 152/285 [02:40<01:55,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:41<01:57,  1.12it/s]Loading train:  54%|█████▍    | 154/285 [02:42<01:56,  1.12it/s]Loading train:  54%|█████▍    | 155/285 [02:43<01:55,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:43<01:55,  1.11it/s]Loading train:  55%|█████▌    | 157/285 [02:44<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:45<01:46,  1.19it/s]Loading train:  56%|█████▌    | 159/285 [02:46<01:44,  1.20it/s]Loading train:  56%|█████▌    | 160/285 [02:47<01:45,  1.19it/s]Loading train:  56%|█████▋    | 161/285 [02:48<01:45,  1.17it/s]Loading train:  57%|█████▋    | 162/285 [02:48<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:49<01:46,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:50<01:44,  1.16it/s]Loading train:  58%|█████▊    | 165/285 [02:51<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [02:52<01:41,  1.17it/s]Loading train:  59%|█████▊    | 167/285 [02:53<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [02:54<01:41,  1.15it/s]Loading train:  59%|█████▉    | 169/285 [02:55<01:41,  1.14it/s]Loading train:  60%|█████▉    | 170/285 [02:55<01:41,  1.13it/s]Loading train:  60%|██████    | 171/285 [02:56<01:39,  1.14it/s]Loading train:  60%|██████    | 172/285 [02:57<01:39,  1.14it/s]Loading train:  61%|██████    | 173/285 [02:58<01:37,  1.15it/s]Loading train:  61%|██████    | 174/285 [02:59<01:35,  1.17it/s]Loading train:  61%|██████▏   | 175/285 [03:00<01:32,  1.19it/s]Loading train:  62%|██████▏   | 176/285 [03:01<01:32,  1.18it/s]Loading train:  62%|██████▏   | 177/285 [03:01<01:31,  1.18it/s]Loading train:  62%|██████▏   | 178/285 [03:02<01:32,  1.16it/s]Loading train:  63%|██████▎   | 179/285 [03:03<01:32,  1.15it/s]Loading train:  63%|██████▎   | 180/285 [03:04<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [03:05<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [03:06<01:27,  1.18it/s]Loading train:  64%|██████▍   | 183/285 [03:07<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [03:07<01:25,  1.18it/s]Loading train:  65%|██████▍   | 185/285 [03:08<01:24,  1.19it/s]Loading train:  65%|██████▌   | 186/285 [03:09<01:22,  1.20it/s]Loading train:  66%|██████▌   | 187/285 [03:10<01:20,  1.21it/s]Loading train:  66%|██████▌   | 188/285 [03:11<01:22,  1.18it/s]Loading train:  66%|██████▋   | 189/285 [03:12<01:22,  1.17it/s]Loading train:  67%|██████▋   | 190/285 [03:12<01:20,  1.18it/s]Loading train:  67%|██████▋   | 191/285 [03:13<01:19,  1.18it/s]Loading train:  67%|██████▋   | 192/285 [03:14<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [03:15<01:14,  1.23it/s]Loading train:  68%|██████▊   | 194/285 [03:16<01:13,  1.24it/s]Loading train:  68%|██████▊   | 195/285 [03:17<01:14,  1.20it/s]Loading train:  69%|██████▉   | 196/285 [03:17<01:18,  1.14it/s]Loading train:  69%|██████▉   | 197/285 [03:18<01:17,  1.13it/s]Loading train:  69%|██████▉   | 198/285 [03:19<01:19,  1.09it/s]Loading train:  70%|██████▉   | 199/285 [03:20<01:19,  1.08it/s]Loading train:  70%|███████   | 200/285 [03:21<01:18,  1.09it/s]Loading train:  71%|███████   | 201/285 [03:22<01:17,  1.09it/s]Loading train:  71%|███████   | 202/285 [03:23<01:16,  1.08it/s]Loading train:  71%|███████   | 203/285 [03:24<01:16,  1.07it/s]Loading train:  72%|███████▏  | 204/285 [03:25<01:17,  1.05it/s]Loading train:  72%|███████▏  | 205/285 [03:26<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:27<01:15,  1.05it/s]Loading train:  73%|███████▎  | 207/285 [03:28<01:13,  1.06it/s]Loading train:  73%|███████▎  | 208/285 [03:29<01:14,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:30<01:12,  1.05it/s]Loading train:  74%|███████▎  | 210/285 [03:31<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:32<01:08,  1.09it/s]Loading train:  74%|███████▍  | 212/285 [03:33<01:08,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [03:34<01:07,  1.07it/s]Loading train:  75%|███████▌  | 214/285 [03:34<01:05,  1.08it/s]Loading train:  75%|███████▌  | 215/285 [03:35<01:03,  1.10it/s]Loading train:  76%|███████▌  | 216/285 [03:36<01:01,  1.12it/s]Loading train:  76%|███████▌  | 217/285 [03:37<00:59,  1.13it/s]Loading train:  76%|███████▋  | 218/285 [03:38<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:39<00:58,  1.12it/s]Loading train:  77%|███████▋  | 220/285 [03:40<00:56,  1.14it/s]Loading train:  78%|███████▊  | 221/285 [03:41<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:41<00:54,  1.17it/s]Loading train:  78%|███████▊  | 223/285 [03:42<00:53,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [03:43<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [03:44<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:45<00:50,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:46<00:48,  1.20it/s]Loading train:  80%|████████  | 228/285 [03:46<00:48,  1.17it/s]Loading train:  80%|████████  | 229/285 [03:47<00:47,  1.17it/s]Loading train:  81%|████████  | 230/285 [03:48<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [03:49<00:46,  1.17it/s]Loading train:  81%|████████▏ | 232/285 [03:50<00:48,  1.09it/s]Loading train:  82%|████████▏ | 233/285 [03:51<00:48,  1.08it/s]Loading train:  82%|████████▏ | 234/285 [03:52<00:47,  1.08it/s]Loading train:  82%|████████▏ | 235/285 [03:53<00:47,  1.06it/s]Loading train:  83%|████████▎ | 236/285 [03:54<00:47,  1.03it/s]Loading train:  83%|████████▎ | 237/285 [03:55<00:46,  1.03it/s]Loading train:  84%|████████▎ | 238/285 [03:56<00:47,  1.01s/it]Loading train:  84%|████████▍ | 239/285 [03:57<00:47,  1.03s/it]Loading train:  84%|████████▍ | 240/285 [03:58<00:46,  1.03s/it]Loading train:  85%|████████▍ | 241/285 [03:59<00:46,  1.05s/it]Loading train:  85%|████████▍ | 242/285 [04:00<00:45,  1.07s/it]Loading train:  85%|████████▌ | 243/285 [04:01<00:44,  1.05s/it]Loading train:  86%|████████▌ | 244/285 [04:02<00:42,  1.04s/it]Loading train:  86%|████████▌ | 245/285 [04:03<00:41,  1.03s/it]Loading train:  86%|████████▋ | 246/285 [04:04<00:39,  1.02s/it]Loading train:  87%|████████▋ | 247/285 [04:06<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:07<00:38,  1.05s/it]Loading train:  87%|████████▋ | 249/285 [04:08<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:09<00:35,  1.01s/it]Loading train:  88%|████████▊ | 251/285 [04:09<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [04:10<00:30,  1.08it/s]Loading train:  89%|████████▉ | 253/285 [04:11<00:28,  1.12it/s]Loading train:  89%|████████▉ | 254/285 [04:12<00:27,  1.12it/s]Loading train:  89%|████████▉ | 255/285 [04:13<00:26,  1.14it/s]Loading train:  90%|████████▉ | 256/285 [04:14<00:25,  1.16it/s]Loading train:  90%|█████████ | 257/285 [04:15<00:24,  1.14it/s]Loading train:  91%|█████████ | 258/285 [04:15<00:23,  1.16it/s]Loading train:  91%|█████████ | 259/285 [04:16<00:22,  1.14it/s]Loading train:  91%|█████████ | 260/285 [04:17<00:21,  1.16it/s]Loading train:  92%|█████████▏| 261/285 [04:18<00:20,  1.15it/s]Loading train:  92%|█████████▏| 262/285 [04:19<00:20,  1.14it/s]Loading train:  92%|█████████▏| 263/285 [04:20<00:19,  1.14it/s]Loading train:  93%|█████████▎| 264/285 [04:21<00:18,  1.16it/s]Loading train:  93%|█████████▎| 265/285 [04:21<00:16,  1.18it/s]Loading train:  93%|█████████▎| 266/285 [04:22<00:16,  1.16it/s]Loading train:  94%|█████████▎| 267/285 [04:23<00:15,  1.16it/s]Loading train:  94%|█████████▍| 268/285 [04:24<00:16,  1.06it/s]Loading train:  94%|█████████▍| 269/285 [04:25<00:15,  1.02it/s]Loading train:  95%|█████████▍| 270/285 [04:26<00:15,  1.02s/it]Loading train:  95%|█████████▌| 271/285 [04:28<00:14,  1.02s/it]Loading train:  95%|█████████▌| 272/285 [04:29<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [04:30<00:13,  1.09s/it]Loading train:  96%|█████████▌| 274/285 [04:31<00:12,  1.13s/it]Loading train:  96%|█████████▋| 275/285 [04:32<00:10,  1.09s/it]Loading train:  97%|█████████▋| 276/285 [04:33<00:09,  1.05s/it]Loading train:  97%|█████████▋| 277/285 [04:34<00:08,  1.07s/it]Loading train:  98%|█████████▊| 278/285 [04:35<00:07,  1.04s/it]Loading train:  98%|█████████▊| 279/285 [04:36<00:06,  1.07s/it]Loading train:  98%|█████████▊| 280/285 [04:37<00:05,  1.07s/it]Loading train:  99%|█████████▊| 281/285 [04:38<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [04:39<00:03,  1.04s/it]Loading train:  99%|█████████▉| 283/285 [04:40<00:02,  1.04s/it]Loading train: 100%|█████████▉| 284/285 [04:41<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:42<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:02, 96.84it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:02, 114.12it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:01, 139.20it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:01, 160.81it/s]concatenating: train:  40%|███▉      | 113/285 [00:00<00:00, 182.57it/s]concatenating: train:  50%|████▉     | 142/285 [00:00<00:00, 204.06it/s]concatenating: train:  60%|█████▉    | 170/285 [00:00<00:00, 220.87it/s]concatenating: train:  70%|███████   | 200/285 [00:00<00:00, 237.10it/s]concatenating: train:  79%|███████▉  | 226/285 [00:00<00:00, 243.02it/s]concatenating: train:  89%|████████▉ | 254/285 [00:01<00:00, 252.84it/s]concatenating: train:  99%|█████████▊| 281/285 [00:01<00:00, 251.97it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 248.41it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.40s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 62.12it/s]
Epoch 00044: val_mDice did not improve from 0.56020
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [6130.532586960566, 4694.014171781994, 3872.1978120349704, 3496.0253789992557, 3222.952194940476, 3014.5821591331846, 2896.5492350260415, 2866.1715146019346, 2793.447062174479, 2731.661859421503, 2738.9454345703125, 2674.3463367280506, 2757.5328776041665, 2592.3194986979165, 2611.8388671875, 2700.2362467447915, 2727.256074451265, 2692.5296165829614, 2665.319318498884, 2876.499575660342, 2798.7011602492557, 2795.082345145089, 2694.111996605283, 2802.255868094308, 2703.5609770275296, 2759.6655883789062, 2692.8479933965773, 2965.0169387090773, 2889.3865327380954, 2929.9001116071427, 2848.0176827566966, 2695.021641322545, 2818.003339494978, 2861.5330171130954, 2670.0235217866443, 3084.4863717215403, 2904.4088367280506, 2835.404753185454, 2724.480178106399, 2645.311703636533, 2818.548316592262, 2969.607195172991, 2741.1824457077755, 2867.0530511765255], 'val_acc': [0.8797779281934103, 0.9021817502521333, 0.9190178570293245, 0.9269345033736456, 0.930734898362841, 0.9332967258635021, 0.9348786473274231, 0.9368383685747782, 0.937877723148891, 0.9388095424288795, 0.9408035704067775, 0.9399542184103102, 0.9413667519887289, 0.9414377127374921, 0.9421016687438601, 0.9422092579659962, 0.9433150092760721, 0.9445764876547313, 0.9447229873566401, 0.9406616233644032, 0.9397504329681396, 0.9450206047012693, 0.9421039649418422, 0.9434272221156529, 0.946721613407135, 0.9423489116487049, 0.9441849617731004, 0.9410966038703918, 0.9415682242030189, 0.9432188527924674, 0.9409340676807222, 0.9458905799048287, 0.9437202527409508, 0.9461698617253985, 0.9463896297273182, 0.9367284604481289, 0.9439858056250072, 0.9442239176659357, 0.9417605314935956, 0.9477930608249846, 0.9468658367792765, 0.9457966940743583, 0.9448283116022745, 0.9452999205816359], 'val_mDice': [0.28206480755692437, 0.37280098987477167, 0.43672379532030653, 0.4692673223714034, 0.4953105009737469, 0.5159564529146466, 0.527823401703721, 0.5302735004751455, 0.539064300202188, 0.5450569863120714, 0.5437846645003274, 0.5518061798952875, 0.5408648131858735, 0.5601968364346595, 0.5579259897626582, 0.5478378417236465, 0.5464888864329883, 0.5498702827663648, 0.5532400161027908, 0.528214288254579, 0.5381271665294965, 0.5369413230745566, 0.5506294417594161, 0.5372862083216509, 0.5475361372033755, 0.5414708774714243, 0.5511491878756455, 0.5185599309347925, 0.5276019670778797, 0.5235665133666425, 0.5307350293511436, 0.5493571073526428, 0.5366464526880355, 0.5320747500019414, 0.5530780225637413, 0.5077516752339545, 0.5283381073247819, 0.5357004780144918, 0.545315171813681, 0.5562034119807538, 0.5355664190082323, 0.5200792781653858, 0.5440269002602214, 0.5307587353246552], 'loss': [14372.784153988487, 5476.330509595427, 4215.346286341982, 3508.0512395490678, 3090.4307968407347, 2805.262241249533, 2593.6343698554906, 2441.309816029896, 2316.7439717693046, 2214.3801436857243, 2118.638165449117, 2037.5951546911149, 1973.9757066193126, 1919.6953868435737, 1856.9669883703023, 1789.3924190594048, 1747.4653408564607, 1700.9250511579805, 1670.0683698240493, 1625.484352807537, 1583.3570375900313, 1551.623352297887, 1513.3801592533957, 1487.8486452148625, 1454.0091582151745, 1432.5149103462156, 1405.4753487040732, 1379.78147800814, 1355.3127800180478, 1333.941826482993, 1323.840702195882, 1293.8125179563617, 1273.9612047509097, 1258.062549915391, 1238.6801996799202, 1224.787127719671, 1195.8148023444655, 1185.5240353315305, 1167.0075199383864, 1156.6051517837375, 1145.9938890358974, 1128.5043930486147, 1111.163471281494, 1099.4677342064974], 'acc': [0.8447885609256847, 0.8653246438271144, 0.8837673410368214, 0.8984235966391754, 0.9081212651621566, 0.9147339278571013, 0.9193727676983809, 0.923081301599425, 0.9259648518638618, 0.9285731659658111, 0.9308394861055841, 0.9326508325006269, 0.9342409981935728, 0.9357218614014353, 0.9367805164122779, 0.9380356884080825, 0.9390457212890484, 0.9402257025942813, 0.9408142465788527, 0.9417039746031127, 0.9425921948033765, 0.9431296684550301, 0.943913246134193, 0.9444894846611361, 0.9451597988525061, 0.9457040586314358, 0.9462580021714254, 0.9468593810688032, 0.9473000156389901, 0.9476751487609484, 0.9481480855782735, 0.948667645764668, 0.9489802718622183, 0.9492904785191, 0.9497248799625747, 0.9499972883000731, 0.9505899519457944, 0.9507890475010031, 0.9511844051787453, 0.9513743916572761, 0.9516858436341044, 0.9520919291826487, 0.9523586364800883, 0.9526570006351791], 'mDice': [0.1664411054540972, 0.34277820014323895, 0.431269501109148, 0.4929491240715783, 0.5346230168964952, 0.5658345478266357, 0.5904995245650391, 0.6090499269426822, 0.6245461978824102, 0.6376110790022679, 0.6501299162257584, 0.6608909154204888, 0.6693084258575396, 0.6767198206809805, 0.6852229646297004, 0.6945322189851374, 0.7004853730167707, 0.7071276681717821, 0.7114674711999623, 0.7178551864826268, 0.7239790483318084, 0.7286531938301338, 0.7342573423732194, 0.7379416319729621, 0.7430527417536115, 0.7463740994527157, 0.7503827699053051, 0.7542519901031838, 0.7579950842642247, 0.7613249528791856, 0.7628778921332873, 0.7674929103755712, 0.77051991264508, 0.7730177804434117, 0.7760889402170367, 0.7783209885593919, 0.7828538289689733, 0.7845283324993804, 0.7874010279846485, 0.7890590753586554, 0.7908037021850974, 0.79358984972669, 0.7963121830670158, 0.7982384042747223]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     2019-07-07 06:19:16.093986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 06:19:16.094093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 06:19:16.094108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 06:19:16.094118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 06:19:16.094535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 26s - loss: 10583.9450 - acc: 0.8875 - mDice: 0.2589 - val_loss: 3910.5546 - val_acc: 0.9305 - val_mDice: 0.4380

Epoch 00001: val_mDice improved from -inf to 0.43798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 3646.7433 - acc: 0.9211 - mDice: 0.4874 - val_loss: 3065.3637 - val_acc: 0.9413 - val_mDice: 0.5129

Epoch 00002: val_mDice improved from 0.43798 to 0.51289, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 17s - loss: 2807.8618 - acc: 0.9325 - mDice: 0.5703 - val_loss: 2610.3739 - val_acc: 0.9461 - val_mDice: 0.5622

Epoch 00003: val_mDice improved from 0.51289 to 0.56216, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 18s - loss: 2430.1096 - acc: 0.9382 - mDice: 0.6135 - val_loss: 2650.3100 - val_acc: 0.9476 - val_mDice: 0.5592

Epoch 00004: val_mDice did not improve from 0.56216
Epoch 5/300
 - 17s - loss: 2210.6741 - acc: 0.9420 - mDice: 0.6408 - val_loss: 2407.0807 - val_acc: 0.9500 - val_mDice: 0.5899

Epoch 00005: val_mDice improved from 0.56216 to 0.58992, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 17s - loss: 2044.5221 - acc: 0.9447 - mDice: 0.6616 - val_loss: 2298.9053 - val_acc: 0.9517 - val_mDice: 0.6036

Epoch 00006: val_mDice improved from 0.58992 to 0.60361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 17s - loss: 1928.0584 - acc: 0.9467 - mDice: 0.6772 - val_loss: 2346.4722 - val_acc: 0.9531 - val_mDice: 0.5993

Epoch 00007: val_mDice did not improve from 0.60361
Epoch 8/300
 - 18s - loss: 1833.3772 - acc: 0.9481 - mDice: 0.6899 - val_loss: 2276.5374 - val_acc: 0.9531 - val_mDice: 0.6063

Epoch 00008: val_mDice improved from 0.60361 to 0.60632, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 17s - loss: 1751.7823 - acc: 0.9494 - mDice: 0.7013 - val_loss: 2264.0385 - val_acc: 0.9544 - val_mDice: 0.6093

Epoch 00009: val_mDice improved from 0.60632 to 0.60928, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 17s - loss: 1688.2370 - acc: 0.9505 - mDice: 0.7101 - val_loss: 2313.9261 - val_acc: 0.9543 - val_mDice: 0.6033

Epoch 00010: val_mDice did not improve from 0.60928
Epoch 11/300
 - 17s - loss: 1620.4434 - acc: 0.9515 - mDice: 0.7196 - val_loss: 2383.7270 - val_acc: 0.9539 - val_mDice: 0.5994

Epoch 00011: val_mDice did not improve from 0.60928
Epoch 12/300
 - 17s - loss: 1568.1209 - acc: 0.9523 - mDice: 0.7270 - val_loss: 2195.3975 - val_acc: 0.9529 - val_mDice: 0.6169

Epoch 00012: val_mDice improved from 0.60928 to 0.61686, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 18s - loss: 1521.4999 - acc: 0.9529 - mDice: 0.7338 - val_loss: 2218.9232 - val_acc: 0.9533 - val_mDice: 0.6183

Epoch 00013: val_mDice improved from 0.61686 to 0.61828, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 17s - loss: 1475.8104 - acc: 0.9536 - mDice: 0.7404 - val_loss: 2340.3293 - val_acc: 0.9554 - val_mDice: 0.6088

Epoch 00014: val_mDice did not improve from 0.61828
Epoch 15/300
 - 17s - loss: 1436.5103 - acc: 0.9542 - mDice: 0.7463 - val_loss: 2342.1005 - val_acc: 0.9537 - val_mDice: 0.6030

Epoch 00015: val_mDice did not improve from 0.61828
Epoch 16/300
 - 17s - loss: 1393.0812 - acc: 0.9549 - mDice: 0.7527 - val_loss: 2307.5514 - val_acc: 0.9556 - val_mDice: 0.6058

Epoch 00016: val_mDice did not improve from 0.61828
Epoch 17/300
 - 17s - loss: 1362.0314 - acc: 0.9554 - mDice: 0.7574 - val_loss: 2380.5951 - val_acc: 0.9538 - val_mDice: 0.5982

Epoch 00017: val_mDice did not improve from 0.61828
Epoch 18/300
 - 17s - loss: 1328.2248 - acc: 0.9559 - mDice: 0.7625 - val_loss: 2278.3471 - val_acc: 0.9548 - val_mDice: 0.6089

Epoch 00018: val_mDice did not improve from 0.61828
Epoch 19/300
 - 18s - loss: 1301.7105 - acc: 0.9564 - mDice: 0.7666 - val_loss: 2217.8049 - val_acc: 0.9542 - val_mDice: 0.6169

Epoch 00019: val_mDice did not improve from 0.61828
Epoch 20/300
 - 17s - loss: 1265.2610 - acc: 0.9569 - mDice: 0.7722 - val_loss: 2285.6424 - val_acc: 0.9547 - val_mDice: 0.6092

Epoch 00020: val_mDice did not improve from 0.61828
Epoch 21/300
 - 18s - loss: 1243.1724 - acc: 0.9573 - mDice: 0.7756 - val_loss: 2262.9982 - val_acc: 0.9550 - val_mDice: 0.6125

Epoch 00021: val_mDice did not improve from 0.61828
Epoch 22/300
 - 18s - loss: 1219.7639 - acc: 0.9577 - mDice: 0.7794 - val_loss: 2261.6991 - val_acc: 0.9535 - val_mDice: 0.6120

Epoch 00022: val_mDice did not improve from 0.61828
Epoch 23/300
 - 17s - loss: 1199.0580 - acc: 0.9580 - mDice: 0.7826 - val_loss: 2225.2752 - val_acc: 0.9521 - val_mDice: 0.6126

Epoch 00023: val_mDice did not improve from 0.61828
Epoch 24/300
 - 18s - loss: 1183.5992 - acc: 0.9584 - mDice: 0.7851 - val_loss: 2246.4125 - val_acc: 0.9555 - val_mDice: 0.6132

Epoch 00024: val_mDice did not improve from 0.61828
Epoch 25/300
 - 18s - loss: 1155.6793 - acc: 0.9587 - mDice: 0.7895 - val_loss: 2269.0209 - val_acc: 0.9559 - val_mDice: 0.6124

Epoch 00025: val_mDice did not improve from 0.61828
Epoch 26/300
 - 17s - loss: 1134.8008 - acc: 0.9591 - mDice: 0.7927 - val_loss: 2220.1570 - val_acc: 0.9552 - val_mDice: 0.6160

Epoch 00026: val_mDice did not improve from 0.61828
Epoch 27/300
 - 17s - loss: 1125.6139 - acc: 0.9593 - mDice: 0.7942 - val_loss: 2191.3841 - val_acc: 0.9542 - val_mDice: 0.6176

Epoch 00027: val_mDice did not improve from 0.61828
Epoch 28/300
 - 17s - loss: 1111.4359 - acc: 0.9596 - mDice: 0.7966 - val_loss: 2117.8524 - val_acc: 0.9544 - val_mDice: 0.6258

Epoch 00028: val_mDice improved from 0.61828 to 0.62577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 17s - loss: 1083.1164 - acc: 0.9600 - mDice: 0.8011 - val_loss: 2120.9402 - val_acc: 0.9554 - val_mDice: 0.6258

Epoch 00029: val_mDice improved from 0.62577 to 0.62577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 18s - loss: 1077.8427 - acc: 0.9602 - mDice: 0.8020 - val_loss: 2402.8134 - val_acc: 0.9533 - val_mDice: 0.5994

Epoch 00030: val_mDice did not improve from 0.62577
Epoch 31/300
 - 18s - loss: 1054.4436 - acc: 0.9605 - mDice: 0.8058 - val_loss: 2322.5642 - val_acc: 0.9548 - val_mDice: 0.6081

Epoch 00031: val_mDice did not improve from 0.62577
Epoch 32/300
 - 17s - loss: 1044.0967 - acc: 0.9608 - mDice: 0.8075 - val_loss: 2186.0629 - val_acc: 0.9559 - val_mDice: 0.6229

Epoch 00032: val_mDice did not improve from 0.62577
Epoch 33/300
 - 17s - loss: 1029.2578 - acc: 0.9610 - mDice: 0.8100 - val_loss: 2196.3775 - val_acc: 0.9546 - val_mDice: 0.6172

Epoch 00033: val_mDice did not improve from 0.62577
Epoch 34/300
 - 17s - loss: 1020.4825 - acc: 0.9612 - mDice: 0.8113 - val_loss: 2235.1885 - val_acc: 0.9558 - val_mDice: 0.6178

Epoch 00034: val_mDice did not improve from 0.62577
Epoch 35/300
 - 17s - loss: 1011.6297 - acc: 0.9613 - mDice: 0.8128 - val_loss: 2315.3863 - val_acc: 0.9561 - val_mDice: 0.6062

Epoch 00035: val_mDice did not improve from 0.62577
Epoch 36/300
 - 17s - loss: 992.9660 - acc: 0.9617 - mDice: 0.8159 - val_loss: 2234.2743 - val_acc: 0.9561 - val_mDice: 0.6128

Epoch 00036: val_mDice did not improve from 0.62577
Epoch 37/300
 - 18s - loss: 985.6099 - acc: 0.9618 - mDice: 0.8172 - val_loss: 2180.4933 - val_acc: 0.9544 - val_mDice: 0.6198

Epoch 00037: val_mDice did not improve from 0.62577
Epoch 38/300
 - 17s - loss: 972.9315 - acc: 0.9619 - mDice: 0.8192 - val_loss: 2239.3510 - val_acc: 0.9560 - val_mDice: 0.6133

Epoch 00038: val_mDice did not improve from 0.62577
Epoch 39/300
 - 17s - loss: 965.8585 - acc: 0.9622 - mDice: 0.8204 - val_loss: 2317.1453 - val_acc: 0.9557 - val_mDice: 0.6079

Epoch 00039: val_mDice did not improve from 0.62577
Epoch 40/300
 - 17s - loss: 955.3288 - acc: 0.9623 - mDice: 0.8222 - val_loss: 2227.6007 - val_acc: 0.9546 - val_mDice: 0.6158

Epoch 00040: val_mDice did not improve from 0.62577
Epoch 41/300
 - 17s - loss: 944.5222 - acc: 0.9626 - mDice: 0.8240 - val_loss: 2152.3356 - val_acc: 0.9540 - val_mDice: 0.6220

Epoch 00041: val_mDice did not improve from 0.62577
Epoch 42/300
 - 17s - loss: 935.4749 - acc: 0.9627 - mDice: 0.8254 - val_loss: 2175.2178 - val_acc: 0.9556 - val_mDice: 0.6190

Epoch 00042: val_mDice did not improve from 0.62577
Epoch 43/300
 - 18s - loss: 924.7470 - acc: 0.9630 - mDice: 0.8273 - val_loss: 2212.1227 - val_acc: 0.9546 - val_mDice: 0.6201

Epoch 00043: val_mDice did not improve from 0.62577
Epoch 44/300
 - 17s - loss: 924.7367 - acc: 0.9630 - mDice: 0.8273 - val_loss: 2114.7467 - val_acc: 0.9571 - val_mDice: 0.6284

Epoch 00044: val_mDice improved from 0.62577 to 0.62838, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 45/300
 - 17s - loss: 910.3534 - acc: 0.9632 - mDice: 0.8297 - val_loss: 2076.6909 - val_acc: 0.9554 - val_mDice: 0.6296

Epoch 00045: val_mDice improved from 0.62838 to 0.62959, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 46/300
 - 17s - loss: 907.3494 - acc: 0.9633 - mDice: 0.8303 - val_loss: 2257.1013 - val_acc: 0.9556 - val_mDice: 0.6137

Epoch 00046: val_mDice did not improve from 0.62959
Epoch 47/300
 - 17s - loss: 896.0261 - acc: 0.9635 - mDice: 0.8322 - val_loss: 2149.5420 - val_acc: 0.9565 - val_mDice: 0.6244

Epoch 00047: val_mDice did not improve from 0.62959
Epoch 48/300
 - 17s - loss: 888.1493 - acc: 0.9636 - mDice: 0.8335 - val_loss: 2095.2033 - val_acc: 0.9541 - val_mDice: 0.6287

Epoch 00048: val_mDice did not improve from 0.62959
Epoch 49/300
 - 17s - loss: 884.4155 - acc: 0.9637 - mDice: 0.8341 - val_loss: 2219.8126 - val_acc: 0.9554 - val_mDice: 0.6138

Epoch 00049: val_mDice did not improve from 0.62959
Epoch 50/300
 - 18s - loss: 882.3677 - acc: 0.9638 - mDice: 0.8345 - val_loss: 2259.8640 - val_acc: 0.9550 - val_mDice: 0.6100

Epoch 00050: val_mDice did not improve from 0.62959
Epoch 51/300
 - 17s - loss: 867.2254 - acc: 0.9640 - mDice: 0.8370 - val_loss: 2175.0760 - val_acc: 0.9551 - val_mDice: 0.6189

Epoch 00051: val_mDice did not improve from 0.62959
Epoch 52/300
 - 17s - loss: 866.2505 - acc: 0.9641 - mDice: 0.8372 - val_loss: 2201.9336 - val_acc: 0.9541 - val_mDice: 0.6163

Epoch 00052: val_mDice did not improve from 0.62959
Epoch 53/300
 - 17s - loss: 1036.6645 - acc: 0.9614 - mDice: 0.8146 - val_loss: 2572.1696 - val_acc: 0.9555 - val_mDice: 0.5797

Epoch 00053: val_mDice did not improve from 0.62959
Epoch 54/300
 - 17s - loss: 945.4534 - acc: 0.9625 - mDice: 0.8237 - val_loss: 2185.0452 - val_acc: 0.9529 - val_mDice: 0.6172

Epoch 00054: val_mDice did not improve from 0.62959
Epoch 55/300
 - 17s - loss: 897.6545 - acc: 0.9634 - mDice: 0.8318 - val_loss: 2150.2927 - val_acc: 0.9559 - val_mDice: 0.6244

Epoch 00055: val_mDice did not improve from 0.62959
Epoch 56/300
 - 18s - loss: 870.2561 - acc: 0.9639 - mDice: 0.8364 - val_loss: 2187.2728 - val_acc: 0.9556 - val_mDice: 0.6175

Epoch 00056: val_mDice did not improve from 0.62959
Epoch 57/300
 - 18s - loss: 857.2455 - acc: 0.9642 - mDice: 0.8387 - val_loss: 2102.1244 - val_acc: 0.9546 - val_mDice: 0.6300

Epoch 00057: val_mDice improved from 0.62959 to 0.62997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 58/300
 - 17s - loss: 848.1657 - acc: 0.9644 - mDice: 0.8403 - val_loss: 2102.1843 - val_acc: 0.9559 - val_mDice: 0.6286

Epoch 00058: val_mDice did not improve from 0.62997
Epoch 59/300
 - 17s - loss: 839.6670 - acc: 0.9646 - mDice: 0.8417 - val_loss: 2193.0791 - val_acc: 0.9552 - val_mDice: 0.6167

Epoch 00059: val_mDice did not improve from 0.62997
Epoch 60/300
 - 18s - loss: 834.6935 - acc: 0.9646 - mDice: 0.8426 - val_loss: 2286.2983 - val_acc: 0.9531 - val_mDice: 0.6065

Epoch 00060: val_mDice did not improve from 0.62997
Epoch 61/300
 - 17s - loss: 829.3586 - acc: 0.9648 - mDice: 0.8435 - val_loss: 2214.5762 - val_acc: 0.9559 - val_mDice: 0.6178

Epoch 00061: val_mDice did not improve from 0.62997
Epoch 62/300
 - 17s - loss: 828.1760 - acc: 0.9648 - mDice: 0.8437 - val_loss: 2176.3631 - val_acc: 0.9556 - val_mDice: 0.6213

Epoch 00062: val_mDice did not improve from 0.62997
Epoch 63/300
 - 18s - loss: 824.6702 - acc: 0.9649 - mDice: 0.8444 - val_loss: 2145.7351 - val_acc: 0.9548 - val_mDice: 0.6237

Epoch 00063: val_mDice did not improve from 0.62997
Epoch 64/300
 - 17s - loss: 816.8336 - acc: 0.9650 - mDice: 0.8457 - val_loss: 2161.3037 - val_acc: 0.9560 - val_mDice: 0.6218

Epoch 00064: val_mDice did not improve from 0.62997
Epoch 65/300
 - 17s - loss: 816.1360 - acc: 0.9650 - mDice: 0.8458 - val_loss: 2190.4944 - val_acc: 0.9555 - val_mDice: 0.6182

Epoch 00065: val_mDice did not improve from 0.62997
Epoch 66/300
 - 17s - loss: 808.7455 - acc: 0.9651 - mDice: 0.8471 - val_loss: 2206.1088 - val_acc: 0.9543 - val_mDice: 0.6183

Epoch 00066: val_mDice did not improve from 0.62997
Epoch 67/300
 - 17s - loss: 808.0559 - acc: 0.9652 - mDice: 0.8472 - val_loss: 2232.2205 - val_acc: 0.9545 - val_mDice: 0.6136

Epoch 00067: val_mDice did not improve from 0.62997
Epoch 68/300
 - 17s - loss: 797.7621 - acc: 0.9653 - mDice: 0.8490 - val_loss: 2191.5854 - val_acc: 0.9564 - val_mDice: 0.6191

Epoch 00068: val_mDice did not improve from 0.62997
Epoch 69/300
 - 18s - loss: 801.7418 - acc: 0.9654 - mDice: 0.8483 - val_loss: 2191.5322 - val_acc: 0.9554 - val_mDice: 0.6182

Epoch 00069: val_mDice did not improve from 0.62997
Epoch 70/300
 - 18s - loss: 797.0488 - acc: 0.9653 - mDice: 0.8491 - val_loss: 2328.0725 - val_acc: 0.9554 - val_mDice: 0.6076

Epoch 00070: val_mDice did not improve from 0.62997
Epoch 71/300
 - 18s - loss: 795.3636 - acc: 0.9654 - mDice: 0.8494 - val_loss: 2208.6624 - val_acc: 0.9547 - val_mDice: 0.6154

Epoch 00071: val_mDice did not improve from 0.62997
Epoch 72/300
 - 17s - loss: 790.8050 - acc: 0.9656 - mDice: 0.8502 - val_loss: 2226.7016 - val_acc: 0.9556 - val_mDice: 0.6142

Epoch 00072: val_mDice did not improve from 0.62997
Epoch 73/300
 - 18s - loss: 784.3400 - acc: 0.9657 - mDice: 0.8513 - val_loss: 2251.5990 - val_acc: 0.9543 - val_mDice: 0.6122

Epoch 00073: val_mDice did not improve from 0.62997
Epoch 74/300
 - 17s - loss: 779.9297 - acc: 0.9657 - mDice: 0.8521 - val_loss: 2210.1918 - val_acc: 0.9552 - val_mDice: 0.6157

Epoch 00074: val_mDice did not improve from 0.62997
Epoch 75/300
 - 18s - loss: 782.8669 - acc: 0.9657 - mDice: 0.8515 - val_loss: 2052.1882 - val_acc: 0.9553 - val_mDice: 0.6335

Epoch 00075: val_mDice improved from 0.62997 to 0.63354, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 76/300
 - 18s - loss: 781.8656 - acc: 0.9657 - mDice: 0.8518 - val_loss: 2159.3480 - val_acc: 0.9571 - val_mDice: 0.6223

Epoch 00076: val_mDice did not improve from 0.63354
Epoch 77/300
 - 18s - loss: 777.1953 - acc: 0.9658 - mDice: 0.8525 - val_loss: 2189.3779 - val_acc: 0.9553 - val_mDice: 0.6175

Epoch 00077: val_mDice did not improve from 0.63354
Epoch 78/300
 - 18s - loss: 771.1333 - acc: 0.9659 - mDice: 0.8537 - val_loss: 2299.3885 - val_acc: 0.9560 - val_mDice: 0.6063

Epoch 00078: val_mDice did not improve from 0.63354
Epoch 79/300
 - 17s - loss: 770.1847 - acc: 0.9660 - mDice: 0.8538 - val_loss: 2175.4401 - val_acc: 0.9548 - val_mDice: 0.6218

Epoch 00079: val_mDice did not improve from 0.63354
Epoch 80/300
 - 18s - loss: 764.8891 - acc: 0.9660 - mDice: 0.8547 - val_loss: 2273.3883 - val_acc: 0.9542 - val_mDice: 0.6069

Epoch 00080: val_mDice did not improve from 0.63354
Epoch 81/300
 - 18s - loss: 764.3410 - acc: 0.9660 - mDice: 0.8548 - val_loss: 2089.8313 - val_acc: 0.9553 - val_mDice: 0.6306

Epoch 00081: val_mDice did not improve from 0.63354
Epoch 82/300
 - 18s - loss: 764.3547 - acc: 0.9661 - mDice: 0.8548 - val_loss: 2207.9153 - val_acc: 0.9562 - val_mDice: 0.6171

Epoch 00082: val_mDice did not improve from 0.63354
Epoch 83/300
 - 18s - loss: 756.4215 - acc: 0.9662 - mDice: 0.8562 - val_loss: 2125.2249 - val_acc: 0.9559 - val_mDice: 0.6266

Epoch 00083: val_mDice did not improve from 0.63354
Epoch 84/300
 - 18s - loss: 758.7283 - acc: 0.9662 - mDice: 0.8558 - val_loss: 2237.5983 - val_acc: 0.9549 - val_mDice: 0.6161

Epoch 00084: val_mDice did not improve from 0.63354
Epoch 85/300
 - 17s - loss: 755.6647 - acc: 0.9662 - mDice: 0.8563 - val_loss: 2371.4963 - val_acc: 0.9561 - val_mDice: 0.5992

Epoch 00085: val_mDice did not improve from 0.63354
Epoch 86/300
 - 18s - loss: 756.1609 - acc: 0.9663 - mDice: 0.8562 - val_loss: 2183.7345 - val_acc: 0.9550 - val_mDice: 0.6182

Epoch 00086: val_mDice did not improve from 0.63354
Epoch 87/300
 - 18s - loss: 748.6903 - acc: 0.9663 - mDice: 0.8575 - val_loss: 2170.9594 - val_acc: 0.9551 - val_mDice: 0.6201

Epoch 00087: val_mDice did not improve from 0.63354
Epoch 88/300
 - 17s - loss: 743.3766 - acc: 0.9664 - mDice: 0.8584 - val_loss: 2122.2699 - val_acc: 0.9555 - val_mDice: 0.6245

Epoch 00088: val_mDice did not improve from 0.63354
Epoch 89/300
 - 18s - loss: 743.2106 - acc: 0.9664 - mDice: 0.8585 - val_loss: 2235.6227 - val_acc: 0.9550 - val_mDice: 0.6109

Epoch 00089: val_mDice did not improve from 0.63354
Epoch 90/300
 - 18s - loss: 741.8720 - acc: 0.9664 - mDice: 0.8587 - val_loss: 2263.9085 - val_acc: 0.9546 - val_mDice: 0.6115

Epoch 00090: val_mDice did not improve from 0.63354
Epoch 91/300
 - 18s - loss: 739.4918 - acc: 0.9665 - mDice: 0.8591 - val_loss: 2179.3608 - val_acc: 0.9554 - val_mDice: 0.6211

Epoch 00091: val_mDice did not improve from 0.63354
Epoch 92/300
 - 18s - loss: 736.2854 - acc: 0.9665 - mDice: 0.8597 - val_loss: 2290.4480 - val_acc: 0.9542 - val_mDice: 0.6068

Epoch 00092: val_mDice did not improve from 0.63354
Epoch 93/300
 - 18s - loss: 730.4967 - acc: 0.9666 - mDice: 0.8607 - val_loss: 2288.0288 - val_acc: 0.9556 - val_mDice: 0.6101

Epoch 00093: val_mDice did not improve from 0.63354
Epoch 94/300
 - 18s - loss: 731.8930 - acc: 0.9666 - mDice: 0.8605 - val_loss: 2286.2059 - val_acc: 0.9547 - val_mDice: 0.6080

Epoch 00094: val_mDice did not improve from 0.63354
Epoch 95/300
 - 18s - loss: 727.9944 - acc: 0.9667 - mDice: 0.8611 - val_loss: 2308.3841 - val_acc: 0.9560 - val_mDice: 0.6079

Epoch 00095: val_mDice did not improve from 0.63354
Epoch 96/300
 - 18s - loss: 727.2283 - acc: 0.9667 - mDice: 0.8613 - val_loss: 2286.0438 - val_acc: 0.9548 - val_mDice: 0.6081

Epoch 00096: val_mDice did not improve from 0.63354
Epoch 97/300
 - 18s - loss: 728.0296 - acc: 0.9667 - mDice: 0.8611 - val_loss: 2293.4188 - val_acc: 0.9552 - val_mDice: 0.6093

Epoch 00097: val_mDice did not improve from 0.63354
Epoch 98/300
 - 18s - loss: 725.4822 - acc: 0.9667 - mDice: 0.8616 - val_loss: 2319.2907 - val_acc: 0.9556 - val_mDice: 0.6056

Epoch 00098: val_mDice did not improve from 0.63354
Epoch 99/300
 - 18s - loss: 723.3170 - acc: 0.9668 - mDice: 0.8620 - val_loss: 2268.4025 - val_acc: 0.9552 - val_mDice: 0.6082

Epoch 00099: val_mDice did not improve from 0.63354
Epoch 100/300
 - 18s - loss: 715.0390 - acc: 0.9669 - mDice: 0.8634 - val_loss: 2268.8889 - val_acc: 0.9547 - val_mDice: 0.6098

Epoch 00100: val_mDice did not improve from 0.63354
Epoch 101/300
 - 18s - loss: 716.9336 - acc: 0.9669 - mDice: 0.8631 - val_loss: 2278.8177 - val_acc: 0.9550 - val_mDice: 0.6082

Epoch 00101: val_mDice did not improve from 0.63354
Epoch 102/300
 - 18s - loss: 714.1685 - acc: 0.9669 - mDice: 0.8636 - val_loss: 2212.5784 - val_acc: 0.9563 - val_mDice: 0.6149

Epoch 00102: val_mDice did not improve from 0.63354
Epoch 103/300
 - 18s - loss: 708.7744 - acc: 0.9670 - mDice: 0.8645 - val_loss: 2339.4388 - val_acc: 0.9560 - val_mDice: 0.6041

Epoch 00103: val_mDice did not improve from 0.63354
Epoch 104/300
 - 18s - loss: 708.2593 - acc: 0.9670 - mDice: 0.8646 - val_loss: 2144.6873 - val_acc: 0.9557 - val_mDice: 0.6233

Epoch 00104: val_mDice did not improve from 0.63354
Epoch 105/300
 - 18s - loss: 710.3004 - acc: 0.9670 - mDice: 0.8643 - val_loss: 2167.4027 - val_acc: 0.9548 - val_mDice: 0.6185

Epoch 00105: val_mDice did not improve from 0.63354
Restoring model weights from the end of the best epoch
Epoch 00105: early stopping
{'val_loss': [3910.554647946491, 3065.3636999716305, 2610.3738761347763, 2650.3099603919345, 2407.0807027976607, 2298.905263890101, 2346.472229344885, 2276.537394433048, 2264.038461013879, 2313.9261331398393, 2383.727009863827, 2195.3975195858065, 2218.9232402780203, 2340.3292570487083, 2342.1005122861384, 2307.5514059226607, 2380.595063449284, 2278.3470793143333, 2217.804867536662, 2285.6423571709147, 2262.998175082926, 2261.6990973616444, 2225.2751642152584, 2246.4124926348636, 2269.020878797137, 2220.156956507507, 2191.384110946229, 2117.852408126746, 2120.940248286924, 2402.813364721543, 2322.5642471739698, 2186.0628696207227, 2196.377534152409, 2235.1885229355794, 2315.3863013922837, 2234.274348594623, 2180.493341371334, 2239.3510196621855, 2317.145275947102, 2227.6006677723462, 2152.335586974075, 2175.21780344361, 2212.1226567955655, 2114.7467061474335, 2076.6909016017808, 2257.1013374541726, 2149.5419949153284, 2095.20327775838, 2219.8125886544167, 2259.864015035789, 2175.0759754713686, 2201.933592386086, 2572.1696245417247, 2185.045155104312, 2150.292712334148, 2187.2728441973636, 2102.1244407952163, 2102.184300257507, 2193.0791192933834, 2286.2982825593576, 2214.576222339822, 2176.3630848463686, 2145.7351360640714, 2161.303701390101, 2190.4944434139315, 2206.108793972591, 2232.2204535287187, 2191.585363292161, 2191.5321679141935, 2328.072508401711, 2208.6624489896126, 2226.701582413146, 2251.598964243628, 2210.1918399746855, 2052.1881587705134, 2159.3479849532996, 2189.3779065009603, 2299.3885122970496, 2175.440107803771, 2273.3883295325595, 2089.831335653806, 2207.915270927898, 2125.2249271669866, 2237.598324567912, 2371.496251964036, 2183.734466382245, 2170.9594303749127, 2122.269861317214, 2235.622727719099, 2263.9084799995635, 2179.3607948345843, 2290.4479912273046, 2288.0288263246334, 2286.2059332991444, 2308.384146407996, 2286.043776187151, 2293.4187980097763, 2319.290707380412, 2268.402474685754, 2268.88893101868, 2278.8177251549405, 2212.5783664127966, 2339.4387548009777, 2144.687269498516, 2167.402690184183], 'val_acc': [0.9304692602024398, 0.94125813279072, 0.9460513605085831, 0.9475699256918284, 0.9500388479765567, 0.9517371488017077, 0.9530780058999301, 0.953100718599458, 0.954414735626242, 0.9542824932316828, 0.9539188915790793, 0.9528796279896571, 0.9533238580772997, 0.9554415341862087, 0.9536709662256294, 0.9555882458580273, 0.9537660046662698, 0.954832058379104, 0.954175046702337, 0.9546853840018118, 0.9549932253427346, 0.9534581493398997, 0.9521358679126761, 0.9555407306335492, 0.9559498053023269, 0.9551977621776432, 0.9542184565320361, 0.9544106062564104, 0.9553816621529989, 0.9532556770234134, 0.9548031591170327, 0.9559208750724792, 0.9546378511290311, 0.9557700623347106, 0.9561089010877982, 0.9560551620062503, 0.9543610301763652, 0.956009708303313, 0.9557390779090327, 0.9545862341726292, 0.9539643299646218, 0.9556398864564949, 0.9545738237530159, 0.9571481167271151, 0.9553836947046844, 0.9556068524968024, 0.956472506736244, 0.9540738150394162, 0.9553961197757188, 0.9549642841243211, 0.9551192505399608, 0.9540758832206939, 0.9554869885551197, 0.9528920597204283, 0.9558650984444432, 0.955551059885398, 0.9545738180922396, 0.9558898753294066, 0.9552328729762711, 0.9530655944813563, 0.9558650824610747, 0.9555944447410839, 0.9548052113149419, 0.9560427872162292, 0.9554746130991248, 0.9542845694046447, 0.9545159513057944, 0.9564394581251304, 0.9554353539504152, 0.9554188321422599, 0.9547390854558465, 0.955567576365764, 0.9542597525612602, 0.9551523247910612, 0.9553320521082957, 0.9571315779366307, 0.9553134834300206, 0.9559911296354325, 0.9548237983074934, 0.9541709359797685, 0.9552535491282713, 0.9561522866094578, 0.9559022807542172, 0.954873396697657, 0.9560551856483162, 0.9550221489128454, 0.9551233802427793, 0.9555221406441161, 0.9550386823755402, 0.9546151147874374, 0.9554394799903785, 0.9542329254763087, 0.9556006326355748, 0.9546812513021118, 0.9559684176018785, 0.9548176253974104, 0.9551915742831523, 0.9555572647622178, 0.9551708888075205, 0.9546977857637672, 0.9550076683140334, 0.9562927577748644, 0.9559518465116703, 0.9556729623725294, 0.9547742102399218], 'val_mDice': [0.4379775331007036, 0.5128879906744931, 0.5621620423300973, 0.5592429065171567, 0.589915593243178, 0.6036089981734419, 0.5992670688549233, 0.6063193718814317, 0.6092775733777265, 0.6032974270468984, 0.5993832336457748, 0.6168576162620629, 0.6182848504801702, 0.6087612050205635, 0.6029627296511687, 0.6057851134731783, 0.5981922522603467, 0.6089068884290131, 0.616900512959038, 0.609171289638434, 0.6125034410194312, 0.6120268276283861, 0.6125517843821862, 0.6132196740731181, 0.6124467203736971, 0.6159988508544154, 0.6176091026327464, 0.6257672486358514, 0.6257680075128651, 0.5993627596167879, 0.6081066371342323, 0.6229087334105422, 0.617239093314336, 0.6177759300397095, 0.6062066475106351, 0.6127827523806908, 0.6198054338966668, 0.6133414506912231, 0.6078746748370165, 0.6157876526177263, 0.6219843715928787, 0.619002773109095, 0.6201019583467665, 0.6283785637530535, 0.6295941132406949, 0.613657825485954, 0.6243564682965838, 0.628696713367654, 0.6138419072721257, 0.6099505987247276, 0.6189062775180326, 0.6162546033965809, 0.5796680230668138, 0.6171781434027176, 0.6243727400316207, 0.6174722703475526, 0.6299667654756728, 0.6285661052725169, 0.6167352192894706, 0.6064960670204802, 0.6177993037181193, 0.621262917638491, 0.6237026100052135, 0.6218271421986585, 0.6182151779782172, 0.6182946402933345, 0.6135970667087832, 0.6191235427749889, 0.6181632140495258, 0.6075739923802168, 0.6153708533201804, 0.6141567559881583, 0.612166502289266, 0.6156831999730797, 0.6335405837224183, 0.6222985473425029, 0.6175405556263205, 0.6063484932457268, 0.6218170197316388, 0.6068590519814517, 0.630600090799385, 0.6170752291572826, 0.62660644607171, 0.6161080582181835, 0.5992217260366045, 0.6181511242962416, 0.6200608634415952, 0.6245164521579636, 0.6109162898702994, 0.6114548791054241, 0.6211242962149934, 0.6067775581136096, 0.6100945173029128, 0.6079559049792795, 0.6079016221302181, 0.6080955739793831, 0.6093381576697919, 0.6055541611250552, 0.6081943119038417, 0.6097806555598808, 0.6081869359122974, 0.6148742563897671, 0.6040768916380472, 0.6233244298556664, 0.6185375285548205], 'loss': [10583.945028509179, 3646.7433021087922, 2807.861773218583, 2430.1096167405713, 2210.674146188603, 2044.5221473748281, 1928.058422475266, 1833.3771846138193, 1751.7822980688038, 1688.2369971116652, 1620.443431569408, 1568.1209177250216, 1521.4999470658554, 1475.8104035964582, 1436.5103302990894, 1393.0812466186503, 1362.0314154939956, 1328.224757533429, 1301.7105274432092, 1265.2610354195247, 1243.1724493075453, 1219.7638802142726, 1199.058026868659, 1183.5991579920799, 1155.679278028264, 1134.8007703600065, 1125.6139058489716, 1111.4358561095976, 1083.1164401426117, 1077.8426765611011, 1054.4436079567213, 1044.0967010685863, 1029.2577559225608, 1020.4825086758278, 1011.6296793497905, 992.9660486865683, 985.6099322877752, 972.9314775177612, 965.858549122301, 955.3287718642882, 944.5222067412491, 935.4749148732261, 924.7469902530968, 924.7366658078774, 910.3534093711067, 907.3493579245167, 896.0260540403498, 888.1492929163078, 884.4154761448242, 882.3677093254885, 867.2254470801095, 866.2505023458297, 1036.6645240449197, 945.4533961362409, 897.6544969503763, 870.2561088143582, 857.2455397764262, 848.1657261758853, 839.6670173980345, 834.69347409224, 829.358573422012, 828.1760381687493, 824.6701985659355, 816.8336406919888, 816.1360433044649, 808.7455106400423, 808.0559209729389, 797.7620520216988, 801.7417681222257, 797.0488315156573, 795.3636081725266, 790.8049926392154, 784.3400201389754, 779.9297441239776, 782.8669241024359, 781.8655662123177, 777.1953472575619, 771.1332784378154, 770.1846865189698, 764.8891128216763, 764.3410222693587, 764.3547203122554, 756.4214789778713, 758.728257469658, 755.6647007447053, 756.1608516488886, 748.6903264137286, 743.3765826956859, 743.210634298778, 741.8719579653961, 739.4917768348855, 736.2853853021999, 730.4966949484498, 731.8930175575151, 727.9944340465025, 727.2283088696963, 728.0296148687956, 725.4821769930842, 723.3169976986478, 715.0390412685016, 716.9335866545509, 714.1684925251164, 708.7743960039255, 708.2592691380269, 710.3003600937927], 'acc': [0.8875029846757243, 0.9211489113871357, 0.9324724418484213, 0.9382332416766545, 0.9419846594817342, 0.9446546096673466, 0.9467037472873723, 0.9481191286710371, 0.9494449388395889, 0.9504508161089025, 0.9514679530530277, 0.9522848826862033, 0.9529389877327387, 0.9536337759440114, 0.9542388942732374, 0.9549117895176673, 0.9554255218763223, 0.9558942435185223, 0.9563685006178851, 0.9568925493975414, 0.9572654732704214, 0.957682343481361, 0.9580450988849467, 0.9583851326609819, 0.9587435144678478, 0.9590562759911233, 0.9592604121022557, 0.9596028017112161, 0.9600445084806608, 0.9602019955088555, 0.9605432996257225, 0.9607751872647167, 0.9610122816150117, 0.961158041646035, 0.961304896914435, 0.9617044097535407, 0.9618055006983909, 0.961925284768117, 0.9621840447526658, 0.9623288851821548, 0.96255991026945, 0.9627262823079563, 0.9629600658427655, 0.9630091113012137, 0.9632356449361915, 0.9633326079842701, 0.9635001855649419, 0.963617874999353, 0.9637226915153034, 0.9638469863623538, 0.9640177090854519, 0.9641026670873948, 0.9614259708707457, 0.9625272199801257, 0.9633728077901058, 0.9638585089747731, 0.9641594256809883, 0.9644054166437409, 0.9645578097423225, 0.9646190383986031, 0.9647684722000994, 0.9648259754800556, 0.9648809857821907, 0.9650140187850829, 0.9649527694046559, 0.9651237117374821, 0.9651726368991426, 0.9653220459835883, 0.9653666199996875, 0.9653353981381959, 0.965353167282328, 0.965573596536227, 0.9656598436034496, 0.9656955547455083, 0.9656938837962786, 0.9657346294580815, 0.9657746347965002, 0.9659179816428602, 0.9659503506235123, 0.9659895237660422, 0.9660094233907313, 0.9660627802442435, 0.9661923297921087, 0.9661664287772977, 0.9662156779647529, 0.9662794448842307, 0.9663081460318257, 0.9664187052950971, 0.9664112938774235, 0.9664238217700106, 0.966485634328467, 0.9664968946655165, 0.9666136574377702, 0.9665909932625917, 0.9666517646404518, 0.9667057652702247, 0.9666948069979971, 0.9667367405065829, 0.966771687832048, 0.9668539486532085, 0.9668709271341476, 0.9669154366372517, 0.9669673659041728, 0.9670175181891585, 0.9670226542844887], 'mDice': [0.2588758522223741, 0.487426634360344, 0.570316521263507, 0.6134734057398457, 0.6408251844702395, 0.6616297803973783, 0.6771666173075066, 0.6898975074372385, 0.7012867266287387, 0.7100831427888915, 0.7195579980909224, 0.7270225191498093, 0.7338061439959184, 0.7403724439607311, 0.7462740440422151, 0.7527271818799148, 0.7574275669452444, 0.7624554249282158, 0.7666289425709104, 0.772171067458522, 0.7755880571224546, 0.7793538948106815, 0.7825809907149687, 0.7850757380221627, 0.7894993484374075, 0.7926960172012256, 0.7942405615774325, 0.7965799876303657, 0.8011110191946164, 0.8019936444043763, 0.8058226454440405, 0.8075112720491787, 0.8099537229922321, 0.8113260965780731, 0.8127998213389881, 0.8158988117405573, 0.8171829081823037, 0.8192383015794008, 0.82039630314369, 0.8222234268527646, 0.8239660249135052, 0.8254335223703263, 0.8273377467406795, 0.8273413807022229, 0.8297482371414664, 0.8302652384355614, 0.8321557472450892, 0.8334816611707162, 0.8341278018570175, 0.8344823678563956, 0.8369968539716294, 0.837221586005009, 0.8145551364910472, 0.8236685701330972, 0.8317674239615029, 0.8364193327292775, 0.8386991959850186, 0.8403058895117629, 0.8417013579253492, 0.8426201896569833, 0.8435240092052106, 0.8437327459664732, 0.8443868872348171, 0.8456865874298205, 0.8458014107965889, 0.8470929925507057, 0.8472032360531693, 0.8489887990545625, 0.848330836930791, 0.8490815924426892, 0.8493969534277221, 0.850198257041519, 0.8513081014614065, 0.8520651008560666, 0.8515276173011493, 0.8517521720333535, 0.8525320010457668, 0.8536518897815998, 0.8537646132313824, 0.8546852411401082, 0.8548152753648581, 0.8548153631697942, 0.85619251989447, 0.8557588275718595, 0.8563167958060651, 0.8562436687758685, 0.8575377124313254, 0.8584243340025046, 0.8584532557888934, 0.8586809782607643, 0.8591139339737159, 0.8596723007841585, 0.8606955882485062, 0.8604772196740057, 0.861141526824372, 0.8612782054266621, 0.8611442414797909, 0.8615742903455372, 0.8619670389907617, 0.863421016162494, 0.86308556590281, 0.8635843363756656, 0.8645119861666721, 0.8645964554209159, 0.8642782005152991]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.14s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<07:33,  1.60s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:55,  1.68s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:02,  1.71s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:19,  1.78s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:53,  1.69s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:07,  1.75s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:38,  1.87s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:54,  1.93s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:29,  1.85s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:53,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:10,  2.01s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:17,  2.04s/it]predicting train subjects:   5%|▍         | 13/285 [00:25<09:23,  2.07s/it]predicting train subjects:   5%|▍         | 14/285 [00:27<09:28,  2.10s/it]predicting train subjects:   5%|▌         | 15/285 [00:29<09:30,  2.11s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:27,  2.11s/it]predicting train subjects:   6%|▌         | 17/285 [00:33<09:18,  2.09s/it]predicting train subjects:   6%|▋         | 18/285 [00:35<09:17,  2.09s/it]predicting train subjects:   7%|▋         | 19/285 [00:37<09:11,  2.07s/it]predicting train subjects:   7%|▋         | 20/285 [00:39<09:21,  2.12s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:18,  2.12s/it]predicting train subjects:   8%|▊         | 22/285 [00:44<09:23,  2.14s/it]predicting train subjects:   8%|▊         | 23/285 [00:46<09:15,  2.12s/it]predicting train subjects:   8%|▊         | 24/285 [00:48<09:10,  2.11s/it]predicting train subjects:   9%|▉         | 25/285 [00:50<09:08,  2.11s/it]predicting train subjects:   9%|▉         | 26/285 [00:52<09:06,  2.11s/it]predicting train subjects:   9%|▉         | 27/285 [00:54<09:02,  2.10s/it]predicting train subjects:  10%|▉         | 28/285 [00:56<08:38,  2.02s/it]predicting train subjects:  10%|█         | 29/285 [00:58<08:23,  1.97s/it]predicting train subjects:  11%|█         | 30/285 [01:00<08:18,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [01:02<08:10,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [01:03<08:06,  1.92s/it]predicting train subjects:  12%|█▏        | 33/285 [01:05<08:05,  1.93s/it]predicting train subjects:  12%|█▏        | 34/285 [01:07<08:06,  1.94s/it]predicting train subjects:  12%|█▏        | 35/285 [01:09<08:10,  1.96s/it]predicting train subjects:  13%|█▎        | 36/285 [01:11<08:07,  1.96s/it]predicting train subjects:  13%|█▎        | 37/285 [01:13<07:53,  1.91s/it]predicting train subjects:  13%|█▎        | 38/285 [01:15<07:50,  1.91s/it]predicting train subjects:  14%|█▎        | 39/285 [01:17<07:53,  1.92s/it]predicting train subjects:  14%|█▍        | 40/285 [01:19<07:46,  1.90s/it]predicting train subjects:  14%|█▍        | 41/285 [01:21<07:44,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:23<07:40,  1.90s/it]predicting train subjects:  15%|█▌        | 43/285 [01:25<07:47,  1.93s/it]predicting train subjects:  15%|█▌        | 44/285 [01:27<07:45,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:28<07:38,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:30<07:19,  1.84s/it]predicting train subjects:  16%|█▋        | 47/285 [01:32<07:08,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<06:56,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:37<06:50,  1.75s/it]predicting train subjects:  18%|█▊        | 51/285 [01:39<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<06:38,  1.72s/it]predicting train subjects:  19%|█▉        | 54/285 [01:44<06:34,  1.71s/it]predicting train subjects:  19%|█▉        | 55/285 [01:46<06:36,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:47<06:28,  1.69s/it]predicting train subjects:  20%|██        | 57/285 [01:49<06:23,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:50<06:20,  1.68s/it]predicting train subjects:  21%|██        | 59/285 [01:52<06:17,  1.67s/it]predicting train subjects:  21%|██        | 60/285 [01:54<06:20,  1.69s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<06:15,  1.68s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<06:10,  1.66s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<06:07,  1.66s/it]predicting train subjects:  22%|██▏       | 64/285 [02:01<06:13,  1.69s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:31,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [02:06<06:31,  1.80s/it]predicting train subjects:  24%|██▍       | 68/285 [02:08<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:10<06:30,  1.81s/it]predicting train subjects:  25%|██▍       | 70/285 [02:12<06:31,  1.82s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:20,  1.78s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:08,  1.74s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:01,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:05,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:25<06:02,  1.75s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<06:05,  1.77s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:00,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<05:55,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<05:54,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<05:51,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:48,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<05:56,  1.78s/it]predicting train subjects:  30%|███       | 86/285 [02:40<05:59,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:44<06:14,  1.90s/it]predicting train subjects:  31%|███       | 89/285 [02:46<06:20,  1.94s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<06:16,  1.93s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<06:19,  1.96s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<06:16,  1.95s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<06:15,  1.96s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<06:17,  1.98s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<06:12,  1.96s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<06:09,  1.95s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<06:16,  2.00s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<06:05,  1.96s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<06:02,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<05:59,  1.94s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:54,  1.93s/it]predicting train subjects:  36%|███▌      | 102/285 [03:11<05:51,  1.92s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:44,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:38,  1.87s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:36,  1.87s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:33,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:20<05:36,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:27,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:22,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:23,  1.86s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:23,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:23,  1.89s/it]predicting train subjects:  40%|████      | 115/285 [03:35<05:22,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:37<05:19,  1.89s/it]predicting train subjects:  41%|████      | 117/285 [03:39<05:20,  1.91s/it]predicting train subjects:  41%|████▏     | 118/285 [03:41<05:16,  1.89s/it]predicting train subjects:  42%|████▏     | 119/285 [03:43<05:12,  1.88s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:11,  1.89s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:48<04:50,  1.78s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:39,  1.72s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:40,  1.74s/it]predicting train subjects:  44%|████▍     | 125/285 [03:53<04:39,  1.75s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:36,  1.74s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:34,  1.74s/it]predicting train subjects:  45%|████▍     | 128/285 [03:58<04:31,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:30,  1.73s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:22,  1.69s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:16,  1.67s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:12,  1.65s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<04:13,  1.68s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<04:13,  1.69s/it]predicting train subjects:  48%|████▊     | 136/285 [04:12<04:11,  1.69s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<04:11,  1.70s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<04:10,  1.70s/it]predicting train subjects:  49%|████▉     | 139/285 [04:17<04:12,  1.73s/it]predicting train subjects:  49%|████▉     | 140/285 [04:19<04:06,  1.70s/it]predicting train subjects:  49%|████▉     | 141/285 [04:20<04:00,  1.67s/it]predicting train subjects:  50%|████▉     | 142/285 [04:22<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:43,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:25<03:41,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:38,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:28<03:36,  1.56s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:29<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:31<03:31,  1.55s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:33<03:35,  1.59s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:34,  1.59s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:36<03:28,  1.55s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:37<03:25,  1.54s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:39<03:25,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:40<03:27,  1.59s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:42<03:29,  1.61s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:44<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:45<03:23,  1.59s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:47<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:48<03:19,  1.58s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:50<03:15,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:11,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:53<03:08,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:05,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:56<03:02,  1.51s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:01,  1.51s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:59<02:59,  1.51s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<02:57,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:02<02:53,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<02:50,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<02:50,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:45,  1.48s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:44,  1.48s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<02:43,  1.48s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:39,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:35,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:19<02:34,  1.47s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:35,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:33,  1.49s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:24<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:25<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:27<02:25,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:23,  1.45s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:30<02:24,  1.47s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:31<02:22,  1.47s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:20,  1.47s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:34<02:18,  1.46s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:36<02:16,  1.45s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:37<02:17,  1.48s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:39<02:18,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:14,  1.48s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:42<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:20,  1.58s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:26,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:49<02:27,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [05:51<02:26,  1.72s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:24,  1.72s/it]predicting train subjects:  71%|███████   | 202/285 [05:54<02:24,  1.74s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:23,  1.75s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:57<02:20,  1.73s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:20,  1.76s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<02:18,  1.75s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:03<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:05<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:12,  1.74s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:08<02:10,  1.74s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:10<02:10,  1.76s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:12<02:08,  1.76s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:13<02:05,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:15<01:58,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:18<01:46,  1.54s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:43,  1.52s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:41,  1.52s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:41,  1.54s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:38,  1.54s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:31,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:30,  1.53s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:34<01:27,  1.51s/it]predicting train subjects:  80%|████████  | 228/285 [06:36<01:24,  1.49s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:24,  1.51s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:21,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:27,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:45<01:34,  1.83s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:36,  1.89s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:49<01:38,  1.97s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:51<01:42,  2.09s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:54<01:43,  2.17s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:56<01:41,  2.15s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:58<01:40,  2.19s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:00<01:39,  2.21s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:02<01:36,  2.19s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:05<01:33,  2.18s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:07<01:31,  2.17s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:09<01:28,  2.16s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:11<01:28,  2.21s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:13<01:27,  2.24s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:16<01:23,  2.19s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:18<01:21,  2.21s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:20<01:21,  2.26s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:22<01:15,  2.17s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:24<01:10,  2.06s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:26<01:05,  1.97s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:27<01:00,  1.88s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:29<00:56,  1.83s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:31<00:54,  1.82s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:33<00:52,  1.80s/it]predicting train subjects:  90%|█████████ | 257/285 [07:34<00:47,  1.70s/it]predicting train subjects:  91%|█████████ | 258/285 [07:36<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:37<00:44,  1.72s/it]predicting train subjects:  91%|█████████ | 260/285 [07:39<00:43,  1.73s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:41<00:40,  1.70s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:42<00:38,  1.67s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:44<00:37,  1.72s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:46<00:35,  1.71s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:48<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:50<00:33,  1.77s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:51<00:31,  1.77s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:54<00:32,  1.92s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:56<00:30,  1.93s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:58<00:30,  2.04s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:00<00:28,  2.07s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:02<00:27,  2.09s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:05<00:26,  2.17s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:07<00:24,  2.25s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:09<00:22,  2.30s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:12<00:20,  2.30s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:14<00:18,  2.31s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:16<00:15,  2.27s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:19<00:14,  2.34s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:21<00:11,  2.30s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:23<00:09,  2.28s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:25<00:06,  2.29s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:28<00:04,  2.28s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:30<00:02,  2.26s/it]predicting train subjects: 100%|██████████| 285/285 [08:32<00:00,  2.31s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:36,  2.03s/it]Loading train:   1%|          | 2/285 [00:04<09:34,  2.03s/it]Loading train:   1%|          | 3/285 [00:05<08:51,  1.88s/it]Loading train:   1%|▏         | 4/285 [00:07<09:16,  1.98s/it]Loading train:   2%|▏         | 5/285 [00:09<08:47,  1.88s/it]Loading train:   2%|▏         | 6/285 [00:11<09:22,  2.02s/it]Loading train:   2%|▏         | 7/285 [00:13<09:36,  2.07s/it]Loading train:   3%|▎         | 8/285 [00:15<09:22,  2.03s/it]Loading train:   3%|▎         | 9/285 [00:17<08:59,  1.96s/it]Loading train:   4%|▎         | 10/285 [00:19<08:19,  1.81s/it]Loading train:   4%|▍         | 11/285 [00:20<07:39,  1.68s/it]Loading train:   4%|▍         | 12/285 [00:21<07:05,  1.56s/it]Loading train:   5%|▍         | 13/285 [00:23<06:44,  1.49s/it]Loading train:   5%|▍         | 14/285 [00:25<07:14,  1.60s/it]Loading train:   5%|▌         | 15/285 [00:26<07:28,  1.66s/it]Loading train:   6%|▌         | 16/285 [00:28<07:37,  1.70s/it]Loading train:   6%|▌         | 17/285 [00:30<07:37,  1.71s/it]Loading train:   6%|▋         | 18/285 [00:32<07:32,  1.70s/it]Loading train:   7%|▋         | 19/285 [00:33<06:53,  1.55s/it]Loading train:   7%|▋         | 20/285 [00:34<06:47,  1.54s/it]Loading train:   7%|▋         | 21/285 [00:36<06:59,  1.59s/it]Loading train:   8%|▊         | 22/285 [00:38<07:05,  1.62s/it]Loading train:   8%|▊         | 23/285 [00:39<06:59,  1.60s/it]Loading train:   8%|▊         | 24/285 [00:41<07:08,  1.64s/it]Loading train:   9%|▉         | 25/285 [00:42<06:43,  1.55s/it]Loading train:   9%|▉         | 26/285 [00:44<06:51,  1.59s/it]Loading train:   9%|▉         | 27/285 [00:45<06:35,  1.53s/it]Loading train:  10%|▉         | 28/285 [00:47<06:59,  1.63s/it]Loading train:  10%|█         | 29/285 [00:49<06:40,  1.57s/it]Loading train:  11%|█         | 30/285 [00:50<06:12,  1.46s/it]Loading train:  11%|█         | 31/285 [00:51<06:25,  1.52s/it]Loading train:  11%|█         | 32/285 [00:53<06:13,  1.48s/it]Loading train:  12%|█▏        | 33/285 [00:55<06:30,  1.55s/it]Loading train:  12%|█▏        | 34/285 [00:56<06:19,  1.51s/it]Loading train:  12%|█▏        | 35/285 [00:57<06:01,  1.45s/it]Loading train:  13%|█▎        | 36/285 [00:59<05:41,  1.37s/it]Loading train:  13%|█▎        | 37/285 [01:00<05:45,  1.39s/it]Loading train:  13%|█▎        | 38/285 [01:01<05:26,  1.32s/it]Loading train:  14%|█▎        | 39/285 [01:02<05:20,  1.30s/it]Loading train:  14%|█▍        | 40/285 [01:04<05:52,  1.44s/it]Loading train:  14%|█▍        | 41/285 [01:06<06:09,  1.52s/it]Loading train:  15%|█▍        | 42/285 [01:08<06:24,  1.58s/it]Loading train:  15%|█▌        | 43/285 [01:09<06:07,  1.52s/it]Loading train:  15%|█▌        | 44/285 [01:10<05:37,  1.40s/it]Loading train:  16%|█▌        | 45/285 [01:11<05:35,  1.40s/it]Loading train:  16%|█▌        | 46/285 [01:13<05:37,  1.41s/it]Loading train:  16%|█▋        | 47/285 [01:14<05:30,  1.39s/it]Loading train:  17%|█▋        | 48/285 [01:15<05:10,  1.31s/it]Loading train:  17%|█▋        | 49/285 [01:17<04:59,  1.27s/it]Loading train:  18%|█▊        | 50/285 [01:18<04:48,  1.23s/it]Loading train:  18%|█▊        | 51/285 [01:19<04:40,  1.20s/it]Loading train:  18%|█▊        | 52/285 [01:20<04:59,  1.28s/it]Loading train:  19%|█▊        | 53/285 [01:21<04:39,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:23<04:50,  1.26s/it]Loading train:  19%|█▉        | 55/285 [01:24<04:42,  1.23s/it]Loading train:  20%|█▉        | 56/285 [01:25<04:45,  1.25s/it]Loading train:  20%|██        | 57/285 [01:26<04:46,  1.25s/it]Loading train:  20%|██        | 58/285 [01:27<04:30,  1.19s/it]Loading train:  21%|██        | 59/285 [01:29<04:40,  1.24s/it]Loading train:  21%|██        | 60/285 [01:30<04:28,  1.19s/it]Loading train:  21%|██▏       | 61/285 [01:31<04:16,  1.15s/it]Loading train:  22%|██▏       | 62/285 [01:32<04:22,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:34<04:39,  1.26s/it]Loading train:  22%|██▏       | 64/285 [01:35<05:03,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:37<05:36,  1.53s/it]Loading train:  23%|██▎       | 66/285 [01:39<06:24,  1.76s/it]Loading train:  24%|██▎       | 67/285 [01:41<06:14,  1.72s/it]Loading train:  24%|██▍       | 68/285 [01:42<05:33,  1.54s/it]Loading train:  24%|██▍       | 69/285 [01:43<05:17,  1.47s/it]Loading train:  25%|██▍       | 70/285 [01:45<04:53,  1.37s/it]Loading train:  25%|██▍       | 71/285 [01:46<04:42,  1.32s/it]Loading train:  25%|██▌       | 72/285 [01:47<04:31,  1.27s/it]Loading train:  26%|██▌       | 73/285 [01:48<04:17,  1.21s/it]Loading train:  26%|██▌       | 74/285 [01:49<04:29,  1.28s/it]Loading train:  26%|██▋       | 75/285 [01:51<05:05,  1.45s/it]Loading train:  27%|██▋       | 76/285 [01:53<04:48,  1.38s/it]Loading train:  27%|██▋       | 77/285 [01:54<04:33,  1.32s/it]Loading train:  27%|██▋       | 78/285 [01:55<04:56,  1.43s/it]Loading train:  28%|██▊       | 79/285 [01:57<04:42,  1.37s/it]Loading train:  28%|██▊       | 80/285 [01:58<04:23,  1.28s/it]Loading train:  28%|██▊       | 81/285 [01:59<04:35,  1.35s/it]Loading train:  29%|██▉       | 82/285 [02:01<04:44,  1.40s/it]Loading train:  29%|██▉       | 83/285 [02:03<05:12,  1.55s/it]Loading train:  29%|██▉       | 84/285 [02:04<04:54,  1.46s/it]Loading train:  30%|██▉       | 85/285 [02:05<04:47,  1.44s/it]Loading train:  30%|███       | 86/285 [02:07<04:39,  1.41s/it]Loading train:  31%|███       | 87/285 [02:08<04:27,  1.35s/it]Loading train:  31%|███       | 88/285 [02:09<04:39,  1.42s/it]Loading train:  31%|███       | 89/285 [02:11<04:48,  1.47s/it]Loading train:  32%|███▏      | 90/285 [02:12<04:47,  1.47s/it]Loading train:  32%|███▏      | 91/285 [02:14<04:33,  1.41s/it]Loading train:  32%|███▏      | 92/285 [02:15<04:23,  1.37s/it]Loading train:  33%|███▎      | 93/285 [02:16<04:14,  1.33s/it]Loading train:  33%|███▎      | 94/285 [02:17<04:07,  1.29s/it]Loading train:  33%|███▎      | 95/285 [02:19<03:59,  1.26s/it]Loading train:  34%|███▎      | 96/285 [02:20<03:56,  1.25s/it]Loading train:  34%|███▍      | 97/285 [02:22<04:15,  1.36s/it]Loading train:  34%|███▍      | 98/285 [02:23<04:29,  1.44s/it]Loading train:  35%|███▍      | 99/285 [02:25<04:54,  1.58s/it]Loading train:  35%|███▌      | 100/285 [02:27<05:05,  1.65s/it]Loading train:  35%|███▌      | 101/285 [02:28<04:50,  1.58s/it]Loading train:  36%|███▌      | 102/285 [02:29<04:23,  1.44s/it]Loading train:  36%|███▌      | 103/285 [02:31<04:25,  1.46s/it]Loading train:  36%|███▋      | 104/285 [02:32<04:31,  1.50s/it]Loading train:  37%|███▋      | 105/285 [02:34<04:43,  1.57s/it]Loading train:  37%|███▋      | 106/285 [02:35<04:24,  1.48s/it]Loading train:  38%|███▊      | 107/285 [02:37<04:40,  1.57s/it]Loading train:  38%|███▊      | 108/285 [02:39<04:29,  1.52s/it]Loading train:  38%|███▊      | 109/285 [02:40<04:12,  1.44s/it]Loading train:  39%|███▊      | 110/285 [02:41<03:59,  1.37s/it]Loading train:  39%|███▉      | 111/285 [02:43<04:10,  1.44s/it]Loading train:  39%|███▉      | 112/285 [02:44<04:00,  1.39s/it]Loading train:  40%|███▉      | 113/285 [02:45<03:50,  1.34s/it]Loading train:  40%|████      | 114/285 [02:47<03:58,  1.40s/it]Loading train:  40%|████      | 115/285 [02:48<03:54,  1.38s/it]Loading train:  41%|████      | 116/285 [02:50<04:05,  1.45s/it]Loading train:  41%|████      | 117/285 [02:51<04:13,  1.51s/it]Loading train:  41%|████▏     | 118/285 [02:53<04:03,  1.46s/it]Loading train:  42%|████▏     | 119/285 [02:54<03:43,  1.35s/it]Loading train:  42%|████▏     | 120/285 [02:55<03:46,  1.37s/it]Loading train:  42%|████▏     | 121/285 [02:57<04:01,  1.48s/it]Loading train:  43%|████▎     | 122/285 [02:58<04:04,  1.50s/it]Loading train:  43%|████▎     | 123/285 [03:00<04:09,  1.54s/it]Loading train:  44%|████▎     | 124/285 [03:01<03:44,  1.39s/it]Loading train:  44%|████▍     | 125/285 [03:02<03:31,  1.32s/it]Loading train:  44%|████▍     | 126/285 [03:04<03:29,  1.32s/it]Loading train:  45%|████▍     | 127/285 [03:05<03:16,  1.24s/it]Loading train:  45%|████▍     | 128/285 [03:06<03:02,  1.16s/it]Loading train:  45%|████▌     | 129/285 [03:07<03:14,  1.25s/it]Loading train:  46%|████▌     | 130/285 [03:09<03:19,  1.29s/it]Loading train:  46%|████▌     | 131/285 [03:09<03:03,  1.19s/it]Loading train:  46%|████▋     | 132/285 [03:11<02:59,  1.18s/it]Loading train:  47%|████▋     | 133/285 [03:12<02:57,  1.17s/it]Loading train:  47%|████▋     | 134/285 [03:13<02:58,  1.18s/it]Loading train:  47%|████▋     | 135/285 [03:14<02:51,  1.14s/it]Loading train:  48%|████▊     | 136/285 [03:16<03:05,  1.24s/it]Loading train:  48%|████▊     | 137/285 [03:17<03:15,  1.32s/it]Loading train:  48%|████▊     | 138/285 [03:18<03:04,  1.26s/it]Loading train:  49%|████▉     | 139/285 [03:19<02:57,  1.22s/it]Loading train:  49%|████▉     | 140/285 [03:20<02:54,  1.21s/it]Loading train:  49%|████▉     | 141/285 [03:22<02:56,  1.23s/it]Loading train:  50%|████▉     | 142/285 [03:23<02:50,  1.19s/it]Loading train:  50%|█████     | 143/285 [03:24<02:44,  1.16s/it]Loading train:  51%|█████     | 144/285 [03:25<03:01,  1.29s/it]Loading train:  51%|█████     | 145/285 [03:27<02:50,  1.22s/it]Loading train:  51%|█████     | 146/285 [03:28<02:59,  1.29s/it]Loading train:  52%|█████▏    | 147/285 [03:29<03:00,  1.30s/it]Loading train:  52%|█████▏    | 148/285 [03:30<02:48,  1.23s/it]Loading train:  52%|█████▏    | 149/285 [03:32<02:48,  1.24s/it]Loading train:  53%|█████▎    | 150/285 [03:33<02:53,  1.28s/it]Loading train:  53%|█████▎    | 151/285 [03:34<02:40,  1.20s/it]Loading train:  53%|█████▎    | 152/285 [03:35<02:34,  1.16s/it]Loading train:  54%|█████▎    | 153/285 [03:36<02:28,  1.12s/it]Loading train:  54%|█████▍    | 154/285 [03:37<02:23,  1.10s/it]Loading train:  54%|█████▍    | 155/285 [03:38<02:24,  1.11s/it]Loading train:  55%|█████▍    | 156/285 [03:40<02:28,  1.15s/it]Loading train:  55%|█████▌    | 157/285 [03:41<02:36,  1.22s/it]Loading train:  55%|█████▌    | 158/285 [03:43<02:50,  1.34s/it]Loading train:  56%|█████▌    | 159/285 [03:44<02:57,  1.41s/it]Loading train:  56%|█████▌    | 160/285 [03:46<03:16,  1.57s/it]Loading train:  56%|█████▋    | 161/285 [03:48<03:15,  1.58s/it]Loading train:  57%|█████▋    | 162/285 [03:49<03:08,  1.53s/it]Loading train:  57%|█████▋    | 163/285 [03:50<02:47,  1.37s/it]Loading train:  58%|█████▊    | 164/285 [03:52<02:54,  1.44s/it]Loading train:  58%|█████▊    | 165/285 [03:53<02:57,  1.48s/it]Loading train:  58%|█████▊    | 166/285 [03:54<02:37,  1.32s/it]Loading train:  59%|█████▊    | 167/285 [03:55<02:32,  1.29s/it]Loading train:  59%|█████▉    | 168/285 [03:57<02:33,  1.32s/it]Loading train:  59%|█████▉    | 169/285 [03:59<02:50,  1.47s/it]Loading train:  60%|█████▉    | 170/285 [04:00<02:36,  1.36s/it]Loading train:  60%|██████    | 171/285 [04:01<02:27,  1.29s/it]Loading train:  60%|██████    | 172/285 [04:02<02:19,  1.23s/it]Loading train:  61%|██████    | 173/285 [04:03<02:16,  1.22s/it]Loading train:  61%|██████    | 174/285 [04:04<02:14,  1.21s/it]Loading train:  61%|██████▏   | 175/285 [04:06<02:20,  1.28s/it]Loading train:  62%|██████▏   | 176/285 [04:07<02:32,  1.40s/it]Loading train:  62%|██████▏   | 177/285 [04:09<02:25,  1.35s/it]Loading train:  62%|██████▏   | 178/285 [04:10<02:20,  1.31s/it]Loading train:  63%|██████▎   | 179/285 [04:11<02:20,  1.33s/it]Loading train:  63%|██████▎   | 180/285 [04:12<02:10,  1.24s/it]Loading train:  64%|██████▎   | 181/285 [04:13<02:04,  1.20s/it]Loading train:  64%|██████▍   | 182/285 [04:15<02:07,  1.23s/it]Loading train:  64%|██████▍   | 183/285 [04:16<02:15,  1.32s/it]Loading train:  65%|██████▍   | 184/285 [04:17<02:04,  1.23s/it]Loading train:  65%|██████▍   | 185/285 [04:18<01:57,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [04:20<01:57,  1.19s/it]Loading train:  66%|██████▌   | 187/285 [04:21<01:58,  1.21s/it]Loading train:  66%|██████▌   | 188/285 [04:22<01:51,  1.15s/it]Loading train:  66%|██████▋   | 189/285 [04:23<01:42,  1.07s/it]Loading train:  67%|██████▋   | 190/285 [04:24<01:37,  1.02s/it]Loading train:  67%|██████▋   | 191/285 [04:25<01:42,  1.09s/it]Loading train:  67%|██████▋   | 192/285 [04:26<01:41,  1.09s/it]Loading train:  68%|██████▊   | 193/285 [04:27<01:45,  1.14s/it]Loading train:  68%|██████▊   | 194/285 [04:28<01:46,  1.17s/it]Loading train:  68%|██████▊   | 195/285 [04:30<01:52,  1.25s/it]Loading train:  69%|██████▉   | 196/285 [04:32<02:02,  1.37s/it]Loading train:  69%|██████▉   | 197/285 [04:33<02:08,  1.46s/it]Loading train:  69%|██████▉   | 198/285 [04:34<01:58,  1.37s/it]Loading train:  70%|██████▉   | 199/285 [04:36<01:55,  1.34s/it]Loading train:  70%|███████   | 200/285 [04:37<02:00,  1.42s/it]Loading train:  71%|███████   | 201/285 [04:39<02:01,  1.45s/it]Loading train:  71%|███████   | 202/285 [04:40<02:03,  1.49s/it]Loading train:  71%|███████   | 203/285 [04:41<01:52,  1.37s/it]Loading train:  72%|███████▏  | 204/285 [04:43<01:56,  1.44s/it]Loading train:  72%|███████▏  | 205/285 [04:45<02:12,  1.66s/it]Loading train:  72%|███████▏  | 206/285 [04:46<02:00,  1.53s/it]Loading train:  73%|███████▎  | 207/285 [04:48<01:49,  1.40s/it]Loading train:  73%|███████▎  | 208/285 [04:49<01:49,  1.42s/it]Loading train:  73%|███████▎  | 209/285 [04:50<01:36,  1.27s/it]Loading train:  74%|███████▎  | 210/285 [04:51<01:35,  1.27s/it]Loading train:  74%|███████▍  | 211/285 [04:53<01:38,  1.33s/it]Loading train:  74%|███████▍  | 212/285 [04:54<01:38,  1.35s/it]Loading train:  75%|███████▍  | 213/285 [04:55<01:33,  1.29s/it]Loading train:  75%|███████▌  | 214/285 [04:57<01:33,  1.31s/it]Loading train:  75%|███████▌  | 215/285 [04:58<01:34,  1.34s/it]Loading train:  76%|███████▌  | 216/285 [05:00<01:39,  1.44s/it]Loading train:  76%|███████▌  | 217/285 [05:01<01:38,  1.46s/it]Loading train:  76%|███████▋  | 218/285 [05:03<01:45,  1.58s/it]Loading train:  77%|███████▋  | 219/285 [05:04<01:33,  1.41s/it]Loading train:  77%|███████▋  | 220/285 [05:05<01:27,  1.34s/it]Loading train:  78%|███████▊  | 221/285 [05:07<01:26,  1.35s/it]Loading train:  78%|███████▊  | 222/285 [05:08<01:30,  1.43s/it]Loading train:  78%|███████▊  | 223/285 [05:10<01:27,  1.41s/it]Loading train:  79%|███████▊  | 224/285 [05:11<01:21,  1.33s/it]Loading train:  79%|███████▉  | 225/285 [05:12<01:24,  1.42s/it]Loading train:  79%|███████▉  | 226/285 [05:14<01:23,  1.41s/it]Loading train:  80%|███████▉  | 227/285 [05:15<01:24,  1.46s/it]Loading train:  80%|████████  | 228/285 [05:16<01:18,  1.37s/it]Loading train:  80%|████████  | 229/285 [05:18<01:13,  1.31s/it]Loading train:  81%|████████  | 230/285 [05:19<01:09,  1.26s/it]Loading train:  81%|████████  | 231/285 [05:20<01:05,  1.21s/it]Loading train:  81%|████████▏ | 232/285 [05:21<01:09,  1.31s/it]Loading train:  82%|████████▏ | 233/285 [05:23<01:12,  1.40s/it]Loading train:  82%|████████▏ | 234/285 [05:24<01:10,  1.38s/it]Loading train:  82%|████████▏ | 235/285 [05:26<01:09,  1.39s/it]Loading train:  83%|████████▎ | 236/285 [05:27<01:07,  1.38s/it]Loading train:  83%|████████▎ | 237/285 [05:28<01:04,  1.34s/it]Loading train:  84%|████████▎ | 238/285 [05:30<01:08,  1.46s/it]Loading train:  84%|████████▍ | 239/285 [05:32<01:06,  1.44s/it]Loading train:  84%|████████▍ | 240/285 [05:33<01:02,  1.39s/it]Loading train:  85%|████████▍ | 241/285 [05:34<00:59,  1.35s/it]Loading train:  85%|████████▍ | 242/285 [05:35<00:58,  1.35s/it]Loading train:  85%|████████▌ | 243/285 [05:37<00:57,  1.37s/it]Loading train:  86%|████████▌ | 244/285 [05:39<01:02,  1.52s/it]Loading train:  86%|████████▌ | 245/285 [05:40<01:03,  1.59s/it]Loading train:  86%|████████▋ | 246/285 [05:42<01:06,  1.69s/it]Loading train:  87%|████████▋ | 247/285 [05:44<01:01,  1.63s/it]Loading train:  87%|████████▋ | 248/285 [05:45<00:55,  1.50s/it]Loading train:  87%|████████▋ | 249/285 [05:46<00:51,  1.43s/it]Loading train:  88%|████████▊ | 250/285 [05:47<00:45,  1.31s/it]Loading train:  88%|████████▊ | 251/285 [05:48<00:41,  1.23s/it]Loading train:  88%|████████▊ | 252/285 [05:50<00:43,  1.32s/it]Loading train:  89%|████████▉ | 253/285 [05:52<00:44,  1.40s/it]Loading train:  89%|████████▉ | 254/285 [05:53<00:42,  1.37s/it]Loading train:  89%|████████▉ | 255/285 [05:54<00:39,  1.33s/it]Loading train:  90%|████████▉ | 256/285 [05:55<00:35,  1.22s/it]Loading train:  90%|█████████ | 257/285 [05:56<00:32,  1.16s/it]Loading train:  91%|█████████ | 258/285 [05:57<00:31,  1.16s/it]Loading train:  91%|█████████ | 259/285 [05:58<00:30,  1.18s/it]Loading train:  91%|█████████ | 260/285 [05:59<00:27,  1.10s/it]Loading train:  92%|█████████▏| 261/285 [06:00<00:26,  1.09s/it]Loading train:  92%|█████████▏| 262/285 [06:01<00:24,  1.07s/it]Loading train:  92%|█████████▏| 263/285 [06:03<00:24,  1.12s/it]Loading train:  93%|█████████▎| 264/285 [06:04<00:24,  1.19s/it]Loading train:  93%|█████████▎| 265/285 [06:06<00:26,  1.34s/it]Loading train:  93%|█████████▎| 266/285 [06:07<00:25,  1.35s/it]Loading train:  94%|█████████▎| 267/285 [06:08<00:23,  1.33s/it]Loading train:  94%|█████████▍| 268/285 [06:10<00:24,  1.46s/it]Loading train:  94%|█████████▍| 269/285 [06:11<00:22,  1.43s/it]Loading train:  95%|█████████▍| 270/285 [06:13<00:20,  1.35s/it]Loading train:  95%|█████████▌| 271/285 [06:14<00:18,  1.34s/it]Loading train:  95%|█████████▌| 272/285 [06:15<00:17,  1.33s/it]Loading train:  96%|█████████▌| 273/285 [06:17<00:17,  1.44s/it]Loading train:  96%|█████████▌| 274/285 [06:19<00:16,  1.48s/it]Loading train:  96%|█████████▋| 275/285 [06:20<00:14,  1.46s/it]Loading train:  97%|█████████▋| 276/285 [06:22<00:13,  1.48s/it]Loading train:  97%|█████████▋| 277/285 [06:23<00:11,  1.45s/it]Loading train:  98%|█████████▊| 278/285 [06:24<00:09,  1.36s/it]Loading train:  98%|█████████▊| 279/285 [06:25<00:08,  1.36s/it]Loading train:  98%|█████████▊| 280/285 [06:27<00:06,  1.38s/it]Loading train:  99%|█████████▊| 281/285 [06:28<00:05,  1.43s/it]Loading train:  99%|█████████▉| 282/285 [06:30<00:04,  1.37s/it]Loading train:  99%|█████████▉| 283/285 [06:31<00:02,  1.33s/it]Loading train: 100%|█████████▉| 284/285 [06:32<00:01,  1.29s/it]Loading train: 100%|██████████| 285/285 [06:33<00:00,  1.22s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:12, 22.25it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:14, 19.29it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:13, 20.71it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:14, 19.32it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:15, 17.66it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:16, 16.02it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:16, 16.21it/s]concatenating: train:   6%|▋         | 18/285 [00:01<00:17, 15.58it/s]concatenating: train:   7%|▋         | 20/285 [00:01<00:16, 16.36it/s]concatenating: train:   9%|▉         | 26/285 [00:01<00:12, 20.66it/s]concatenating: train:  11%|█         | 32/285 [00:01<00:09, 25.46it/s]concatenating: train:  15%|█▌        | 44/285 [00:01<00:07, 33.30it/s]concatenating: train:  25%|██▍       | 71/285 [00:01<00:04, 45.16it/s]concatenating: train:  35%|███▌      | 101/285 [00:01<00:03, 60.55it/s]concatenating: train:  42%|████▏     | 119/285 [00:01<00:02, 61.12it/s]concatenating: train:  47%|████▋     | 134/285 [00:02<00:02, 51.62it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 54.79it/s]concatenating: train:  54%|█████▍    | 155/285 [00:02<00:02, 49.46it/s]concatenating: train:  57%|█████▋    | 163/285 [00:02<00:02, 50.37it/s]concatenating: train:  60%|██████    | 171/285 [00:03<00:02, 53.49it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:01, 55.91it/s]concatenating: train:  66%|██████▌   | 187/285 [00:03<00:01, 63.02it/s]concatenating: train:  71%|███████   | 201/285 [00:03<00:01, 74.98it/s]concatenating: train:  79%|███████▉  | 226/285 [00:03<00:00, 94.76it/s]concatenating: train:  88%|████████▊ | 252/285 [00:03<00:00, 116.92it/s]concatenating: train:  97%|█████████▋| 276/285 [00:03<00:00, 137.79it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 73.63it/s] 
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.82s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.82s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.68s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 148.67it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 31)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 31)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 60)   16800       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 91)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 91)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 91)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 120)  98400       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 211)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 211)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 60)   50700       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 151)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 60)   81600       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 60)   0           batch_normalization_7[0][0]      2019-07-07 07:06:04.187274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 07:06:04.187404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 07:06:04.187423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 07:06:04.187437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 07:06:04.187943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 211)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 26, 211)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 30)   25350       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 61)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 30)   16500       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 91)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 91)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   1196        dropout_5[0][0]                  
==================================================================================================
Total params: 504,146
Trainable params: 502,946
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 25s - loss: 24912.2552 - acc: 0.8472 - mDice: 0.1510 - val_loss: 9433.6625 - val_acc: 0.8726 - val_mDice: 0.2812

Epoch 00001: val_mDice improved from -inf to 0.28123, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 8356.3527 - acc: 0.8856 - mDice: 0.3510 - val_loss: 6708.2236 - val_acc: 0.8980 - val_mDice: 0.3997

Epoch 00002: val_mDice improved from 0.28123 to 0.39972, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 15s - loss: 6008.6581 - acc: 0.9063 - mDice: 0.4573 - val_loss: 5819.2084 - val_acc: 0.9152 - val_mDice: 0.4496

Epoch 00003: val_mDice improved from 0.39972 to 0.44957, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 15s - loss: 5067.3108 - acc: 0.9173 - mDice: 0.5151 - val_loss: 5221.5215 - val_acc: 0.9246 - val_mDice: 0.4852

Epoch 00004: val_mDice improved from 0.44957 to 0.48521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 15s - loss: 4533.6080 - acc: 0.9232 - mDice: 0.5516 - val_loss: 4811.9763 - val_acc: 0.9294 - val_mDice: 0.5103

Epoch 00005: val_mDice improved from 0.48521 to 0.51031, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 16s - loss: 4192.0748 - acc: 0.9267 - mDice: 0.5767 - val_loss: 4552.8647 - val_acc: 0.9348 - val_mDice: 0.5291

Epoch 00006: val_mDice improved from 0.51031 to 0.52915, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 15s - loss: 3943.2997 - acc: 0.9294 - mDice: 0.5956 - val_loss: 4532.7119 - val_acc: 0.9384 - val_mDice: 0.5330

Epoch 00007: val_mDice improved from 0.52915 to 0.53302, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 15s - loss: 3752.0413 - acc: 0.9314 - mDice: 0.6105 - val_loss: 4516.1695 - val_acc: 0.9396 - val_mDice: 0.5354

Epoch 00008: val_mDice improved from 0.53302 to 0.53543, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 3583.2982 - acc: 0.9333 - mDice: 0.6242 - val_loss: 4344.8217 - val_acc: 0.9406 - val_mDice: 0.5461

Epoch 00009: val_mDice improved from 0.53543 to 0.54611, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 15s - loss: 3449.4924 - acc: 0.9348 - mDice: 0.6352 - val_loss: 4343.5746 - val_acc: 0.9388 - val_mDice: 0.5447

Epoch 00010: val_mDice did not improve from 0.54611
Epoch 11/300
 - 14s - loss: 3334.3370 - acc: 0.9362 - mDice: 0.6448 - val_loss: 4152.2820 - val_acc: 0.9410 - val_mDice: 0.5588

Epoch 00011: val_mDice improved from 0.54611 to 0.55880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 14s - loss: 3205.8410 - acc: 0.9374 - mDice: 0.6554 - val_loss: 4257.0530 - val_acc: 0.9415 - val_mDice: 0.5521

Epoch 00012: val_mDice did not improve from 0.55880
Epoch 13/300
 - 14s - loss: 3117.5492 - acc: 0.9385 - mDice: 0.6630 - val_loss: 4165.9343 - val_acc: 0.9416 - val_mDice: 0.5585

Epoch 00013: val_mDice did not improve from 0.55880
Epoch 14/300
 - 14s - loss: 3026.3941 - acc: 0.9395 - mDice: 0.6708 - val_loss: 4296.0290 - val_acc: 0.9408 - val_mDice: 0.5503

Epoch 00014: val_mDice did not improve from 0.55880
Epoch 15/300
 - 14s - loss: 2948.1122 - acc: 0.9405 - mDice: 0.6780 - val_loss: 4281.6291 - val_acc: 0.9412 - val_mDice: 0.5534

Epoch 00015: val_mDice did not improve from 0.55880
Epoch 16/300
 - 14s - loss: 2882.1060 - acc: 0.9413 - mDice: 0.6837 - val_loss: 4338.9387 - val_acc: 0.9392 - val_mDice: 0.5496

Epoch 00016: val_mDice did not improve from 0.55880
Epoch 17/300
 - 14s - loss: 2805.2795 - acc: 0.9422 - mDice: 0.6905 - val_loss: 4341.2097 - val_acc: 0.9416 - val_mDice: 0.5520

Epoch 00017: val_mDice did not improve from 0.55880
Epoch 18/300
 - 14s - loss: 2742.3656 - acc: 0.9428 - mDice: 0.6961 - val_loss: 4306.2712 - val_acc: 0.9398 - val_mDice: 0.5530

Epoch 00018: val_mDice did not improve from 0.55880
Epoch 19/300
 - 14s - loss: 2691.2597 - acc: 0.9434 - mDice: 0.7007 - val_loss: 4402.5172 - val_acc: 0.9408 - val_mDice: 0.5521

Epoch 00019: val_mDice did not improve from 0.55880
Epoch 20/300
 - 14s - loss: 2636.7697 - acc: 0.9439 - mDice: 0.7056 - val_loss: 4455.8980 - val_acc: 0.9429 - val_mDice: 0.5511

Epoch 00020: val_mDice did not improve from 0.55880
Epoch 21/300
 - 14s - loss: 2572.3489 - acc: 0.9447 - mDice: 0.7116 - val_loss: 4205.6176 - val_acc: 0.9414 - val_mDice: 0.5588

Epoch 00021: val_mDice improved from 0.55880 to 0.55881, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 15s - loss: 2513.5858 - acc: 0.9453 - mDice: 0.7167 - val_loss: 4055.7878 - val_acc: 0.9420 - val_mDice: 0.5678

Epoch 00022: val_mDice improved from 0.55881 to 0.56780, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 14s - loss: 2466.7643 - acc: 0.9458 - mDice: 0.7212 - val_loss: 4149.1852 - val_acc: 0.9414 - val_mDice: 0.5617

Epoch 00023: val_mDice did not improve from 0.56780
Epoch 24/300
 - 14s - loss: 2421.1721 - acc: 0.9464 - mDice: 0.7256 - val_loss: 4255.5404 - val_acc: 0.9430 - val_mDice: 0.5552

Epoch 00024: val_mDice did not improve from 0.56780
Epoch 25/300
 - 14s - loss: 2381.3863 - acc: 0.9467 - mDice: 0.7293 - val_loss: 4185.1452 - val_acc: 0.9412 - val_mDice: 0.5594

Epoch 00025: val_mDice did not improve from 0.56780
Epoch 26/300
 - 14s - loss: 2339.7769 - acc: 0.9472 - mDice: 0.7332 - val_loss: 4134.2461 - val_acc: 0.9427 - val_mDice: 0.5627

Epoch 00026: val_mDice did not improve from 0.56780
Epoch 27/300
 - 14s - loss: 2300.0283 - acc: 0.9477 - mDice: 0.7369 - val_loss: 4225.9443 - val_acc: 0.9414 - val_mDice: 0.5572

Epoch 00027: val_mDice did not improve from 0.56780
Epoch 28/300
 - 15s - loss: 2271.7655 - acc: 0.9481 - mDice: 0.7397 - val_loss: 4101.8764 - val_acc: 0.9424 - val_mDice: 0.5667

Epoch 00028: val_mDice did not improve from 0.56780
Epoch 29/300
 - 14s - loss: 2227.6192 - acc: 0.9486 - mDice: 0.7440 - val_loss: 4085.9551 - val_acc: 0.9436 - val_mDice: 0.5671

Epoch 00029: val_mDice did not improve from 0.56780
Epoch 30/300
 - 15s - loss: 2203.0513 - acc: 0.9489 - mDice: 0.7464 - val_loss: 4398.9822 - val_acc: 0.9429 - val_mDice: 0.5501

Epoch 00030: val_mDice did not improve from 0.56780
Epoch 31/300
 - 14s - loss: 2162.7101 - acc: 0.9494 - mDice: 0.7503 - val_loss: 4198.1318 - val_acc: 0.9436 - val_mDice: 0.5587

Epoch 00031: val_mDice did not improve from 0.56780
Epoch 32/300
 - 14s - loss: 2136.6117 - acc: 0.9496 - mDice: 0.7528 - val_loss: 4411.3752 - val_acc: 0.9423 - val_mDice: 0.5534

Epoch 00032: val_mDice did not improve from 0.56780
Epoch 33/300
 - 15s - loss: 2114.0795 - acc: 0.9499 - mDice: 0.7551 - val_loss: 4459.2497 - val_acc: 0.9416 - val_mDice: 0.5486

Epoch 00033: val_mDice did not improve from 0.56780
Epoch 34/300
 - 14s - loss: 2075.4952 - acc: 0.9504 - mDice: 0.7588 - val_loss: 4431.3898 - val_acc: 0.9406 - val_mDice: 0.5472

Epoch 00034: val_mDice did not improve from 0.56780
Epoch 35/300
 - 14s - loss: 2051.8044 - acc: 0.9508 - mDice: 0.7612 - val_loss: 4198.6952 - val_acc: 0.9435 - val_mDice: 0.5572

Epoch 00035: val_mDice did not improve from 0.56780
Epoch 36/300
 - 14s - loss: 2023.8445 - acc: 0.9510 - mDice: 0.7640 - val_loss: 4390.9002 - val_acc: 0.9418 - val_mDice: 0.5529

Epoch 00036: val_mDice did not improve from 0.56780
Epoch 37/300
 - 14s - loss: 1982.4105 - acc: 0.9515 - mDice: 0.7682 - val_loss: 4021.9857 - val_acc: 0.9453 - val_mDice: 0.5724

Epoch 00037: val_mDice improved from 0.56780 to 0.57236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 38/300
 - 15s - loss: 1962.6215 - acc: 0.9517 - mDice: 0.7702 - val_loss: 4374.9760 - val_acc: 0.9426 - val_mDice: 0.5515

Epoch 00038: val_mDice did not improve from 0.57236
Epoch 39/300
 - 14s - loss: 1937.0330 - acc: 0.9520 - mDice: 0.7727 - val_loss: 4183.0643 - val_acc: 0.9424 - val_mDice: 0.5601

Epoch 00039: val_mDice did not improve from 0.57236
Epoch 40/300
 - 14s - loss: 1918.9836 - acc: 0.9522 - mDice: 0.7746 - val_loss: 4215.4868 - val_acc: 0.9432 - val_mDice: 0.5544

Epoch 00040: val_mDice did not improve from 0.57236
Epoch 41/300
 - 15s - loss: 1891.1128 - acc: 0.9525 - mDice: 0.7774 - val_loss: 4520.1382 - val_acc: 0.9409 - val_mDice: 0.5435

Epoch 00041: val_mDice did not improve from 0.57236
Epoch 42/300
 - 14s - loss: 1869.9674 - acc: 0.9528 - mDice: 0.7795 - val_loss: 4106.9513 - val_acc: 0.9437 - val_mDice: 0.5644

Epoch 00042: val_mDice did not improve from 0.57236
Epoch 43/300
 - 14s - loss: 1854.6610 - acc: 0.9530 - mDice: 0.7811 - val_loss: 4051.0168 - val_acc: 0.9452 - val_mDice: 0.5697

Epoch 00043: val_mDice did not improve from 0.57236
Epoch 44/300
 - 15s - loss: 1830.5131 - acc: 0.9534 - mDice: 0.7837 - val_loss: 4154.5817 - val_acc: 0.9431 - val_mDice: 0.5637

Epoch 00044: val_mDice did not improve from 0.57236
Epoch 45/300
 - 14s - loss: 1805.9405 - acc: 0.9536 - mDice: 0.7860 - val_loss: 4335.3353 - val_acc: 0.9423 - val_mDice: 0.5515

Epoch 00045: val_mDice did not improve from 0.57236
Epoch 46/300
 - 14s - loss: 1792.3421 - acc: 0.9538 - mDice: 0.7876 - val_loss: 4139.8643 - val_acc: 0.9428 - val_mDice: 0.5651

Epoch 00046: val_mDice did not improve from 0.57236
Epoch 47/300
 - 14s - loss: 1768.5771 - acc: 0.9540 - mDice: 0.7901 - val_loss: 4331.9964 - val_acc: 0.9444 - val_mDice: 0.5499

Epoch 00047: val_mDice did not improve from 0.57236
Epoch 48/300
 - 14s - loss: 1762.9491 - acc: 0.9542 - mDice: 0.7906 - val_loss: 4342.8315 - val_acc: 0.9466 - val_mDice: 0.5508

Epoch 00048: val_mDice did not improve from 0.57236
Epoch 49/300
 - 14s - loss: 1748.4508 - acc: 0.9544 - mDice: 0.7922 - val_loss: 4124.8793 - val_acc: 0.9462 - val_mDice: 0.5646

Epoch 00049: val_mDice did not improve from 0.57236
Epoch 50/300
 - 14s - loss: 1724.6004 - acc: 0.9547 - mDice: 0.7947 - val_loss: 4488.0581 - val_acc: 0.9426 - val_mDice: 0.5429

Epoch 00050: val_mDice did not improve from 0.57236
Epoch 51/300
 - 15s - loss: 1700.9810 - acc: 0.9550 - mDice: 0.7972 - val_loss: 4242.1903 - val_acc: 0.9436 - val_mDice: 0.5558

Epoch 00051: val_mDice did not improve from 0.57236
Epoch 52/300
 - 14s - loss: 1687.3360 - acc: 0.9552 - mDice: 0.7986 - val_loss: 4206.1830 - val_acc: 0.9442 - val_mDice: 0.5586

Epoch 00052: val_mDice did not improve from 0.57236
Epoch 53/300
 - 14s - loss: 1681.1561 - acc: 0.9553 - mDice: 0.7992 - val_loss: 4205.5639 - val_acc: 0.9434 - val_mDice: 0.5577

Epoch 00053: val_mDice did not improve from 0.57236
Epoch 54/300
 - 14s - loss: 1668.8530 - acc: 0.9555 - mDice: 0.8006 - val_loss: 3964.5361 - val_acc: 0.9457 - val_mDice: 0.5759

Epoch 00054: val_mDice improved from 0.57236 to 0.57591, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet_NL3_LS_MyJoint_US1_CSFn2_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 14s - loss: 1644.4517 - acc: 0.9558 - mDice: 0.8031 - val_loss: 4352.1386 - val_acc: 0.9421 - val_mDice: 0.5473

Epoch 00055: val_mDice did not improve from 0.57591
Epoch 56/300
 - 14s - loss: 1637.9674 - acc: 0.9559 - mDice: 0.8037 - val_loss: 4241.7086 - val_acc: 0.9448 - val_mDice: 0.5587

Epoch 00056: val_mDice did not improve from 0.57591
Epoch 57/300
 - 14s - loss: 1633.3160 - acc: 0.9561 - mDice: 0.8050 - val_loss: 5838.1927 - val_acc: 0.9347 - val_mDice: 0.4471

Epoch 00057: val_mDice did not improve from 0.57591
Epoch 58/300
 - 14s - loss: 2232.8216 - acc: 0.9479 - mDice: 0.7460 - val_loss: 4725.0531 - val_acc: 0.9387 - val_mDice: 0.5300

Epoch 00058: val_mDice did not improve from 0.57591
Epoch 59/300
 - 14s - loss: 1751.4610 - acc: 0.9543 - mDice: 0.7919 - val_loss: 4261.9251 - val_acc: 0.9460 - val_mDice: 0.5613

Epoch 00059: val_mDice did not improve from 0.57591
Epoch 60/300
 - 14s - loss: 1676.2973 - acc: 0.9553 - mDice: 0.7998 - val_loss: 4297.2376 - val_acc: 0.9422 - val_mDice: 0.5529

Epoch 00060: val_mDice did not improve from 0.57591
Epoch 61/300
 - 14s - loss: 1637.9798 - acc: 0.9559 - mDice: 0.8038 - val_loss: 4227.6842 - val_acc: 0.9455 - val_mDice: 0.5571

Epoch 00061: val_mDice did not improve from 0.57591
Epoch 62/300
 - 14s - loss: 1618.7706 - acc: 0.9562 - mDice: 0.8059 - val_loss: 4067.9766 - val_acc: 0.9470 - val_mDice: 0.5710

Epoch 00062: val_mDice did not improve from 0.57591
Epoch 63/300
 - 14s - loss: 1589.1378 - acc: 0.9564 - mDice: 0.8090 - val_loss: 4006.8512 - val_acc: 0.9468 - val_mDice: 0.5749

Epoch 00063: val_mDice did not improve from 0.57591
Epoch 64/300
 - 14s - loss: 1567.1755 - acc: 0.9567 - mDice: 0.8114 - val_loss: 4311.8946 - val_acc: 0.9454 - val_mDice: 0.5536

Epoch 00064: val_mDice did not improve from 0.57591
Epoch 65/300
 - 14s - loss: 1563.1923 - acc: 0.9569 - mDice: 0.8118 - val_loss: 4272.5245 - val_acc: 0.9432 - val_mDice: 0.5547

Epoch 00065: val_mDice did not improve from 0.57591
Epoch 66/300
 - 14s - loss: 1541.6568 - acc: 0.9572 - mDice: 0.8141 - val_loss: 4182.1605 - val_acc: 0.9449 - val_mDice: 0.5585

Epoch 00066: val_mDice did not improve from 0.57591
Epoch 67/300
 - 14s - loss: 1526.9954 - acc: 0.9573 - mDice: 0.8157 - val_loss: 4136.1265 - val_acc: 0.9460 - val_mDice: 0.5661

Epoch 00067: val_mDice did not improve from 0.57591
Epoch 68/300
 - 14s - loss: 1527.3253 - acc: 0.9574 - mDice: 0.8157 - val_loss: 4100.9786 - val_acc: 0.9479 - val_mDice: 0.5652

Epoch 00068: val_mDice did not improve from 0.57591
Epoch 69/300
 - 14s - loss: 1511.4054 - acc: 0.9576 - mDice: 0.8174 - val_loss: 4170.2656 - val_acc: 0.9457 - val_mDice: 0.5631

Epoch 00069: val_mDice did not improve from 0.57591
Epoch 70/300
 - 14s - loss: 1504.1223 - acc: 0.9577 - mDice: 0.8182 - val_loss: 4516.4776 - val_acc: 0.9448 - val_mDice: 0.5448

Epoch 00070: val_mDice did not improve from 0.57591
Epoch 71/300
 - 14s - loss: 1492.6912 - acc: 0.9579 - mDice: 0.8194 - val_loss: 4383.5203 - val_acc: 0.9424 - val_mDice: 0.5477

Epoch 00071: val_mDice did not improve from 0.57591
Epoch 72/300
 - 14s - loss: 1486.0226 - acc: 0.9579 - mDice: 0.8201 - val_loss: 4268.3167 - val_acc: 0.9423 - val_mDice: 0.5571

Epoch 00072: val_mDice did not improve from 0.57591
Epoch 73/300
 - 14s - loss: 1472.9203 - acc: 0.9581 - mDice: 0.8215 - val_loss: 4066.1387 - val_acc: 0.9480 - val_mDice: 0.5720

Epoch 00073: val_mDice did not improve from 0.57591
Epoch 74/300
 - 14s - loss: 1464.9353 - acc: 0.9582 - mDice: 0.8224 - val_loss: 4029.8404 - val_acc: 0.9457 - val_mDice: 0.5699

Epoch 00074: val_mDice did not improve from 0.57591
Epoch 75/300
 - 14s - loss: 1450.3147 - acc: 0.9584 - mDice: 0.8240 - val_loss: 4118.0718 - val_acc: 0.9451 - val_mDice: 0.5656

Epoch 00075: val_mDice did not improve from 0.57591
Epoch 76/300
 - 14s - loss: 1447.3123 - acc: 0.9585 - mDice: 0.8244 - val_loss: 4436.0117 - val_acc: 0.9441 - val_mDice: 0.5411

Epoch 00076: val_mDice did not improve from 0.57591
Epoch 77/300
 - 14s - loss: 1445.4714 - acc: 0.9585 - mDice: 0.8246 - val_loss: 4358.3514 - val_acc: 0.9408 - val_mDice: 0.5475

Epoch 00077: val_mDice did not improve from 0.57591
Epoch 78/300
 - 14s - loss: 1440.9585 - acc: 0.9585 - mDice: 0.8250 - val_loss: 4449.0491 - val_acc: 0.9444 - val_mDice: 0.5460

Epoch 00078: val_mDice did not improve from 0.57591
Epoch 79/300
 - 14s - loss: 1423.9818 - acc: 0.9588 - mDice: 0.8269 - val_loss: 4383.1829 - val_acc: 0.9461 - val_mDice: 0.5572

Epoch 00079: val_mDice did not improve from 0.57591
Epoch 80/300
 - 14s - loss: 1415.0745 - acc: 0.9589 - mDice: 0.8279 - val_loss: 4495.4202 - val_acc: 0.9431 - val_mDice: 0.5491

Epoch 00080: val_mDice did not improve from 0.57591
Epoch 81/300
 - 14s - loss: 1409.7600 - acc: 0.9589 - mDice: 0.8285 - val_loss: 4331.1232 - val_acc: 0.9427 - val_mDice: 0.5535

Epoch 00081: val_mDice did not improve from 0.57591
Epoch 82/300
 - 14s - loss: 1406.6550 - acc: 0.9590 - mDice: 0.8288 - val_loss: 4429.1624 - val_acc: 0.9449 - val_mDice: 0.5454

Epoch 00082: val_mDice did not improve from 0.57591
Epoch 83/300
 - 14s - loss: 1404.3973 - acc: 0.9591 - mDice: 0.8291 - val_loss: 4093.3617 - val_acc: 0.9450 - val_mDice: 0.5678

Epoch 00083: val_mDice did not improve from 0.57591
Epoch 84/300
 - 14s - loss: 1382.4808 - acc: 0.9593 - mDice: 0.8314 - val_loss: 4227.2295 - val_acc: 0.9456 - val_mDice: 0.5595

Epoch 00084: val_mDice did not improve from 0.57591
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [9433.662475585938, 6708.223614032452, 5819.2083740234375, 5221.5215407151445, 4811.976337139423, 4552.8646897536055, 4532.711918757512, 4516.169532189002, 4344.821702223558, 4343.5745849609375, 4152.281973031851, 4257.052976168119, 4165.934305044321, 4296.028987004207, 4281.6291269155645, 4338.938669057993, 4341.2096933218145, 4306.271221454327, 4402.5171790489785, 4455.897958608774, 4205.61762883113, 4055.787804236779, 4149.185175969051, 4255.540447528546, 4185.145183856671, 4134.246096097506, 4225.944331242488, 4101.876410851111, 4085.9551438551684, 4398.9821542593145, 4198.131845327524, 4411.375234750601, 4459.249685434194, 4431.38977755033, 4198.695152869592, 4390.900174654447, 4021.9856989933896, 4374.975956843449, 4183.064349834735, 4215.486774151142, 4520.138211763822, 4106.951279860276, 4051.016808143029, 4154.581740159255, 4335.33530836839, 4139.8643470177285, 4331.996417705829, 4342.831500713642, 4124.879267765926, 4488.058091383714, 4242.190255972056, 4206.182992788462, 4205.563931978666, 3964.536095252404, 4352.138559194712, 4241.708571213942, 5838.192655123197, 4725.05308180589, 4261.925053523137, 4297.237586388221, 4227.684157151442, 4067.9766235351562, 4006.8511962890625, 4311.894564115084, 4272.52450796274, 4182.1605224609375, 4136.126497708834, 4100.978553185096, 4170.265615609976, 4516.477618877704, 4383.520334097056, 4268.316669170673, 4066.138653094952, 4029.8403977614184, 4118.071843073918, 4436.011676494892, 4358.351360614483, 4449.049142690806, 4383.182870718149, 4495.420170710637, 4331.123244065505, 4429.162419245793, 4093.3617225060098, 4227.229529747596], 'val_acc': [0.8726192460610316, 0.8980283989356115, 0.9152389902334946, 0.9245954981217017, 0.9293893048396478, 0.9347540598649245, 0.9384130147787241, 0.939619568678049, 0.9405833803690397, 0.9388244541791769, 0.9409509003162384, 0.9414987105589646, 0.9415888236119196, 0.9408468993810507, 0.9411820402512183, 0.9392474316633664, 0.9415726982630216, 0.9397674615566547, 0.9407636569096491, 0.9429340523022872, 0.9414247205624213, 0.9420118446533496, 0.9414247343173394, 0.9429826392577245, 0.9411704998749953, 0.9427329645707057, 0.9413854227616236, 0.9424278942438272, 0.9435997536549201, 0.9428555185978229, 0.9435743070565737, 0.9422799280056586, 0.9415542070682232, 0.940571835407844, 0.9434541693100562, 0.9417598774799933, 0.9453471646859095, 0.9425896658347204, 0.94240475159425, 0.9431859942582937, 0.9408515279109662, 0.9436899148500882, 0.9452431408258585, 0.943070439191965, 0.9422753384480109, 0.9428092378836411, 0.9444249318196223, 0.946574520606261, 0.946227830189925, 0.9426104724407196, 0.943602062188662, 0.9442168749295748, 0.9434426128864288, 0.9456707926896902, 0.9420557274268224, 0.944831710595351, 0.9346962823317602, 0.9386602892325475, 0.9459804846690252, 0.9421666952279898, 0.9454789138757266, 0.9470460391961611, 0.9468195392535284, 0.9453587073546189, 0.9432438199336712, 0.9448571388538067, 0.9460059220974262, 0.947949801500027, 0.9457216216967657, 0.9447877957270696, 0.942444044810075, 0.9422799669779264, 0.9479936980284177, 0.9456776953660525, 0.9450998764771682, 0.9441174933543572, 0.9407729185544528, 0.9443833484099462, 0.9460590940255386, 0.943142083974985, 0.94272603896948, 0.9448687227872702, 0.9449727191374853, 0.9456453552612891], 'val_mDice': [0.28123406062905604, 0.39972095076854414, 0.44957268925813526, 0.4852108978308164, 0.5103076209242527, 0.5291470850889499, 0.533018956390711, 0.535429838185127, 0.5461108357860491, 0.5446650970440644, 0.5587993550759095, 0.552146169428642, 0.5584677589627413, 0.550266044644209, 0.5533908043916409, 0.5495726729814823, 0.5519820428811587, 0.5530325082632211, 0.5520517241496307, 0.551126397573031, 0.5588090717792511, 0.5678042425559118, 0.5616528804485614, 0.5552443197140327, 0.5593995383152595, 0.5626525156773053, 0.5571910578470963, 0.5667150943325117, 0.5671419306443288, 0.5500981847827251, 0.558715239740335, 0.5533904685423925, 0.5486275135324552, 0.5472488380395449, 0.5571592037494366, 0.5528909288919889, 0.5723612973323235, 0.5515421147529895, 0.5600567202155406, 0.554421759568728, 0.543491827753874, 0.5643996109183018, 0.5696971502441627, 0.5636974613253887, 0.551490087635242, 0.5650610276139699, 0.549863766019161, 0.5507908761501312, 0.5646294808158507, 0.542881717475561, 0.555751886505347, 0.5586490284364957, 0.5577061113256675, 0.5759083823515818, 0.5472881816900693, 0.5587342966061372, 0.44711422748290575, 0.5299994939794908, 0.561256739955682, 0.5529284173479447, 0.5571038849078692, 0.5710388003633573, 0.5749406516551971, 0.5536099589214876, 0.5546574326088796, 0.5584817812419854, 0.5661392750648352, 0.5651748762107812, 0.5630886084758319, 0.5448273726953909, 0.5477261107701522, 0.5571333932188841, 0.5720073878765106, 0.5698701785160944, 0.5656442464544222, 0.5410706165891427, 0.547542960024797, 0.546006383231053, 0.5572487448270504, 0.5491062732270131, 0.5534853981091425, 0.5453809574246407, 0.56776374234603, 0.5594654518824357], 'loss': [24912.255156201365, 8356.352737383133, 6008.658110877085, 5067.31079171362, 4533.60799366797, 4192.074818091255, 3943.299659527064, 3752.041330837273, 3583.298206616776, 3449.4924086067913, 3334.3369641380095, 3205.8409906345287, 3117.549210142146, 3026.3940662952914, 2948.1121749617587, 2882.106004821389, 2805.2795434811233, 2742.36560838772, 2691.2596871455985, 2636.7696567877715, 2572.348860099924, 2513.5858270591843, 2466.764279400809, 2421.1720645168903, 2381.3862759172284, 2339.7768564031626, 2300.0282993613932, 2271.7654701858432, 2227.619155339184, 2203.0513100374737, 2162.7100784989902, 2136.6117379606226, 2114.0795255156336, 2075.495203761391, 2051.804433407318, 2023.8445025342621, 1982.4105064239404, 1962.621491229986, 1937.0329627614283, 1918.9835684499342, 1891.112832078984, 1869.9673537229971, 1854.6609579816488, 1830.5131198116458, 1805.9404893435533, 1792.3420939281464, 1768.5771078975022, 1762.9490894633202, 1748.4508064633794, 1724.6004160714197, 1700.9810425018588, 1687.335988723824, 1681.156135607632, 1668.8530053175057, 1644.4517198179324, 1637.9674308908434, 1633.3159814187436, 2232.8216424393368, 1751.4609670409482, 1676.2973052970071, 1637.9798066454885, 1618.7706125173734, 1589.1377587343486, 1567.175484630286, 1563.1923291344358, 1541.6567872365902, 1526.995421879188, 1527.3252791112984, 1511.4053750407988, 1504.1223439659282, 1492.6911859819286, 1486.022624279579, 1472.9203071625902, 1464.935269084263, 1450.3147449150392, 1447.312261899283, 1445.4714064562463, 1440.9585098566345, 1423.981752683588, 1415.0745364896907, 1409.759956678605, 1406.6550303888994, 1404.3972932104364, 1382.4807744549064], 'acc': [0.8471963280990732, 0.8856414363611386, 0.9062581794415631, 0.9172780497107329, 0.9232360125797366, 0.926707034438428, 0.9293641683185253, 0.9313917105393382, 0.9333358234852582, 0.9347701962062555, 0.9362266457884512, 0.9373509732656435, 0.9384951920710751, 0.9395278930817981, 0.9404896097155523, 0.9412508269171208, 0.9421899258447267, 0.9427574492079145, 0.9434128683409128, 0.9439477079756572, 0.9447340609721017, 0.9452599251357148, 0.9458137201579044, 0.9463892639381446, 0.9467469264547796, 0.947227475130392, 0.9477338285108867, 0.9480502501488788, 0.9485621058576982, 0.9488552769952338, 0.949352601016897, 0.949616533352376, 0.949908327849646, 0.950385659688471, 0.9507530547646176, 0.9509715824167656, 0.9515207411782676, 0.9517358570238282, 0.952023790950849, 0.9522205913659447, 0.952504050843799, 0.9528218967266148, 0.9529891894838417, 0.9533555011659995, 0.9535658876856106, 0.9538271774953663, 0.9540152846914831, 0.9541921978296746, 0.95439988517084, 0.9547375493479272, 0.9549797071881106, 0.9552119754122201, 0.9552589094277117, 0.9554620959832859, 0.9558030393008629, 0.9558634959462933, 0.9560631308555163, 0.9478745585018712, 0.9542775972736264, 0.9553388088191225, 0.9559125770977653, 0.9561692624693261, 0.956416359980542, 0.9567090459308819, 0.9568735649035358, 0.957160659341215, 0.9572923909383189, 0.9573608287957545, 0.9575864926625098, 0.9576708232906816, 0.9579002386549792, 0.9578888863036523, 0.9580543838193317, 0.958151905131848, 0.9583669537098592, 0.9584816979502198, 0.9585055110639921, 0.9585068377249687, 0.9587877980459774, 0.9588974879575833, 0.9589201257499966, 0.9590179172760994, 0.9590775961971785, 0.9592704476547628], 'mDice': [0.1510345104019833, 0.35099541913657173, 0.45727282953550374, 0.5151408327073285, 0.551554773507562, 0.5767462328660425, 0.5955696751312126, 0.6105003042831463, 0.6241827028753968, 0.6351563698755335, 0.6448117435544682, 0.6554431804297518, 0.6629613571739567, 0.6708479347862705, 0.677964213258785, 0.6836587411335097, 0.6904682588788358, 0.6961015338806674, 0.7006585309066358, 0.7056392409160965, 0.7115760171346357, 0.7167227455833725, 0.7211835551534557, 0.7255922647999252, 0.7292556688649885, 0.7331989832462271, 0.7369298489509578, 0.7396983022807676, 0.7439624738794384, 0.7464371479152369, 0.7502538812871812, 0.7528238155619087, 0.7550929745360845, 0.7588321447130566, 0.7611982553391992, 0.7640135292306351, 0.7681824737816381, 0.7701566271991689, 0.772707680104393, 0.7745607216826754, 0.7773999036991056, 0.7795080129130348, 0.7810748034843734, 0.7836940689059648, 0.7860314694649727, 0.7875653617355444, 0.7900594437429082, 0.7906242361601281, 0.7922046868924031, 0.7947117630366546, 0.797160891845395, 0.7985696157691862, 0.7992076753833401, 0.8005557903600973, 0.8031075541783795, 0.8037379225670472, 0.8050498557213893, 0.7460307537393466, 0.7919154922911396, 0.7997671318628092, 0.8038353649527453, 0.8058725035543494, 0.808978300961821, 0.8113679388984811, 0.8117830066248619, 0.8140899684940835, 0.815658961980092, 0.8156641693030799, 0.8173993996926079, 0.8181907772951919, 0.8193692301709988, 0.8201128870790255, 0.8215487667646375, 0.8224050499114737, 0.8240178618760475, 0.8243759359302396, 0.8245571699681608, 0.825042078292294, 0.8269134181612017, 0.8278951955041707, 0.8284615607078276, 0.8288187545339505, 0.8290685900328707, 0.8314393365788831]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.77s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<06:20,  1.34s/it]predicting train subjects:   1%|          | 2/285 [00:02<06:45,  1.43s/it]predicting train subjects:   1%|          | 3/285 [00:04<06:42,  1.43s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<06:49,  1.46s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:15,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:43,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:51,  1.70s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:37,  1.66s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:54,  1.73s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:04,  1.77s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:17,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:24,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:23,  1.87s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:23,  1.87s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:12,  1.84s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:10,  1.84s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<08:08,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:19,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:10,  1.86s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<08:06,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<08:09,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<08:19,  1.91s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<08:13,  1.90s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:10,  1.89s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<08:03,  1.88s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:51,  1.83s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:51,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:39,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:55<07:31,  1.78s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:27,  1.77s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:23,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:21,  1.76s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:18,  1.75s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:09,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:07,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:09,  1.74s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:10,  1.75s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:14,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:14,  1.78s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<07:13,  1.78s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:03,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<07:00,  1.75s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<06:44,  1.69s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:19,  1.60s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<06:08,  1.56s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<06:10,  1.57s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<06:03,  1.55s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<05:58,  1.53s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<05:57,  1.53s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<05:56,  1.54s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<05:54,  1.53s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<05:56,  1.55s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<05:53,  1.54s/it]predicting train subjects:  20%|██        | 57/285 [01:38<05:57,  1.57s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:00,  1.59s/it]predicting train subjects:  21%|██        | 59/285 [01:41<05:53,  1.56s/it]predicting train subjects:  21%|██        | 60/285 [01:42<05:50,  1.56s/it]predicting train subjects:  21%|██▏       | 61/285 [01:44<05:48,  1.56s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<05:47,  1.56s/it]predicting train subjects:  22%|██▏       | 63/285 [01:47<05:51,  1.58s/it]predicting train subjects:  22%|██▏       | 64/285 [01:49<05:49,  1.58s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<05:55,  1.62s/it]predicting train subjects:  23%|██▎       | 66/285 [01:52<05:59,  1.64s/it]predicting train subjects:  24%|██▎       | 67/285 [01:54<05:47,  1.60s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<05:40,  1.57s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<05:38,  1.57s/it]predicting train subjects:  25%|██▍       | 70/285 [01:58<05:34,  1.56s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<05:27,  1.53s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:24,  1.52s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<05:21,  1.52s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<05:21,  1.52s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<05:22,  1.53s/it]predicting train subjects:  27%|██▋       | 76/285 [02:07<05:21,  1.54s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:19,  1.54s/it]predicting train subjects:  27%|██▋       | 78/285 [02:10<05:19,  1.54s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:18,  1.55s/it]predicting train subjects:  28%|██▊       | 81/285 [02:15<05:16,  1.55s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:16,  1.56s/it]predicting train subjects:  29%|██▉       | 83/285 [02:18<05:13,  1.55s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:09,  1.54s/it]predicting train subjects:  30%|██▉       | 85/285 [02:21<05:17,  1.59s/it]predicting train subjects:  30%|███       | 86/285 [02:23<05:24,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:35,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:35,  1.70s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:40,  1.74s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:41,  1.75s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:35,  1.73s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:35,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:36<05:36,  1.75s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:34,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:28,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:41<05:25,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:27,  1.75s/it]predicting train subjects:  35%|███▍      | 99/285 [02:46<05:24,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:48<05:25,  1.76s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:23,  1.76s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:18,  1.74s/it]predicting train subjects:  36%|███▌      | 103/285 [02:53<05:15,  1.73s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<05:10,  1.72s/it]predicting train subjects:  37%|███▋      | 105/285 [02:56<05:08,  1.71s/it]predicting train subjects:  37%|███▋      | 106/285 [02:58<05:08,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<05:07,  1.73s/it]predicting train subjects:  38%|███▊      | 108/285 [03:01<05:03,  1.71s/it]predicting train subjects:  38%|███▊      | 109/285 [03:03<05:01,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<05:03,  1.74s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<05:00,  1.74s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:58,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:57,  1.74s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:56,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:52,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:51,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:19<04:50,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:21<04:47,  1.73s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:46,  1.74s/it]predicting train subjects:  42%|████▏     | 121/285 [03:24<04:36,  1.68s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:23,  1.62s/it]predicting train subjects:  43%|████▎     | 123/285 [03:27<04:11,  1.55s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:10,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:30<04:09,  1.56s/it]predicting train subjects:  44%|████▍     | 126/285 [03:31<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:33<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:35<04:05,  1.56s/it]predicting train subjects:  45%|████▌     | 129/285 [03:36<04:02,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:38<04:03,  1.57s/it]predicting train subjects:  46%|████▌     | 131/285 [03:39<04:01,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [03:41<03:59,  1.56s/it]predicting train subjects:  47%|████▋     | 133/285 [03:42<03:54,  1.54s/it]predicting train subjects:  47%|████▋     | 134/285 [03:44<03:50,  1.53s/it]predicting train subjects:  47%|████▋     | 135/285 [03:45<03:51,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [03:47<03:50,  1.54s/it]predicting train subjects:  48%|████▊     | 137/285 [03:48<03:48,  1.54s/it]predicting train subjects:  48%|████▊     | 138/285 [03:50<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:45,  1.55s/it]predicting train subjects:  49%|████▉     | 140/285 [03:53<03:44,  1.55s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:44,  1.56s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:40,  1.54s/it]predicting train subjects:  50%|█████     | 143/285 [03:58<03:36,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:27,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:04<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:20,  1.47s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:06<03:20,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:17,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:09<03:13,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:09,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:06,  1.42s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:05,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:16<03:03,  1.42s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:01,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:19<03:00,  1.42s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<02:58,  1.42s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:22<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<02:59,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<02:56,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:26<02:54,  1.43s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:52,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:29<02:48,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:48,  1.41s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:32<02:45,  1.40s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:33<02:42,  1.39s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:35<02:41,  1.39s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:36<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 171/285 [04:38<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:39<02:38,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:40<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:42<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:43<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:45<02:32,  1.40s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:46<02:30,  1.39s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:47<02:26,  1.37s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:49<02:22,  1.35s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:50<02:20,  1.34s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:19,  1.34s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:18,  1.34s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:18,  1.35s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:17,  1.36s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:14,  1.34s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:12,  1.33s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:59<02:10,  1.33s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:01<02:12,  1.37s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:02<02:09,  1.34s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:03<02:06,  1.33s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:05<02:06,  1.35s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:06<02:05,  1.35s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:07<02:05,  1.37s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:09<02:01,  1.34s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:10<02:01,  1.35s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:12<02:06,  1.42s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:13<02:11,  1.49s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:15<02:14,  1.55s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:17<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:18<02:14,  1.58s/it]predicting train subjects:  71%|███████   | 201/285 [05:20<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:21<02:12,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:23<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:25<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:26<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:28<02:08,  1.63s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:30<02:07,  1.63s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:31<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:33<02:03,  1.63s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:35<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:36<02:00,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:38<01:57,  1.61s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:39<01:55,  1.61s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:41<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:42<01:45,  1.50s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:44<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:45<01:38,  1.45s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:46<01:35,  1.43s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:48<01:33,  1.41s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:49<01:32,  1.42s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:51<01:31,  1.42s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:52<01:29,  1.43s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:53<01:28,  1.42s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:55<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:56<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:58<01:23,  1.41s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:59<01:21,  1.41s/it]predicting train subjects:  80%|████████  | 228/285 [06:00<01:19,  1.39s/it]predicting train subjects:  80%|████████  | 229/285 [06:02<01:17,  1.39s/it]predicting train subjects:  81%|████████  | 230/285 [06:03<01:16,  1.39s/it]predicting train subjects:  81%|████████  | 231/285 [06:05<01:14,  1.38s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:06<01:20,  1.51s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:08<01:22,  1.58s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:10<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:12<01:23,  1.68s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:13<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:15<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:17<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:19,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:17,  1.76s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:24<01:15,  1.76s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:26<01:14,  1.77s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:28<01:13,  1.79s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:29<01:11,  1.79s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:31<01:09,  1.79s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:33<01:08,  1.80s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:35<01:05,  1.78s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:37<01:03,  1.77s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:38<00:57,  1.65s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:39<00:52,  1.54s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:41<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:42<00:47,  1.47s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:43<00:44,  1.45s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:45<00:42,  1.41s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:46<00:41,  1.43s/it]predicting train subjects:  90%|█████████ | 257/285 [06:47<00:38,  1.39s/it]predicting train subjects:  91%|█████████ | 258/285 [06:49<00:37,  1.40s/it]predicting train subjects:  91%|█████████ | 259/285 [06:50<00:35,  1.37s/it]predicting train subjects:  91%|█████████ | 260/285 [06:52<00:34,  1.38s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:53<00:32,  1.34s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:54<00:30,  1.33s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:56<00:29,  1.34s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:57<00:27,  1.33s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:58<00:26,  1.32s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:25,  1.33s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:01<00:23,  1.32s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:03<00:24,  1.44s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:04<00:24,  1.53s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:06<00:24,  1.60s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:08<00:23,  1.66s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:10<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:11<00:20,  1.70s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:13<00:18,  1.72s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:15<00:17,  1.72s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:17<00:15,  1.75s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:18<00:14,  1.76s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:20<00:12,  1.76s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:22<00:10,  1.76s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:24<00:08,  1.76s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:25<00:06,  1.75s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:27<00:05,  1.74s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:29<00:03,  1.75s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:31<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [07:32<00:00,  1.77s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:27:58, 17.03s/it]Loading train:   1%|          | 2/311 [00:25<1:14:39, 14.50s/it]Loading train:   1%|          | 3/311 [00:36<1:08:15, 13.30s/it]Loading train:   1%|▏         | 4/311 [00:46<1:03:25, 12.39s/it]Loading train:   2%|▏         | 5/311 [00:55<58:41, 11.51s/it]  Loading train:   2%|▏         | 6/311 [01:05<55:08, 10.85s/it]Loading train:   2%|▏         | 7/311 [01:16<55:00, 10.86s/it]Loading train:   3%|▎         | 8/311 [01:28<57:17, 11.34s/it]Loading train:   3%|▎         | 9/311 [01:39<57:04, 11.34s/it]Loading train:   3%|▎         | 10/311 [01:49<54:21, 10.84s/it]Loading train:   4%|▎         | 11/311 [02:02<56:58, 11.39s/it]Loading train:   4%|▍         | 12/311 [02:12<54:34, 10.95s/it]Loading train:   4%|▍         | 13/311 [02:22<52:56, 10.66s/it]Loading train:   5%|▍         | 14/311 [02:34<54:48, 11.07s/it]Loading train:   5%|▍         | 15/311 [02:43<51:51, 10.51s/it]Loading train:   5%|▌         | 16/311 [02:52<49:48, 10.13s/it]Loading train:   5%|▌         | 17/311 [03:01<48:16,  9.85s/it]Loading train:   6%|▌         | 18/311 [03:11<47:40,  9.76s/it]Loading train:   6%|▌         | 19/311 [03:20<46:50,  9.62s/it]Loading train:   6%|▋         | 20/311 [03:29<46:11,  9.53s/it]Loading train:   7%|▋         | 21/311 [03:38<45:21,  9.38s/it]Loading train:   7%|▋         | 22/311 [03:47<44:22,  9.21s/it]Loading train:   7%|▋         | 23/311 [03:56<44:07,  9.19s/it]Loading train:   8%|▊         | 24/311 [04:06<43:48,  9.16s/it]Loading train:   8%|▊         | 25/311 [04:15<43:54,  9.21s/it]Loading train:   8%|▊         | 26/311 [04:24<43:21,  9.13s/it]Loading train:   9%|▊         | 27/311 [04:33<42:57,  9.08s/it]Loading train:   9%|▉         | 28/311 [04:42<42:22,  8.99s/it]Loading train:   9%|▉         | 29/311 [04:50<42:12,  8.98s/it]Loading train:  10%|▉         | 30/311 [04:59<41:39,  8.89s/it]Loading train:  10%|▉         | 31/311 [05:08<41:19,  8.86s/it]Loading train:  10%|█         | 32/311 [05:17<41:13,  8.87s/it]Loading train:  11%|█         | 33/311 [05:21<35:03,  7.57s/it]Loading train:  11%|█         | 34/311 [05:26<30:57,  6.71s/it]Loading train:  11%|█▏        | 35/311 [05:31<27:45,  6.03s/it]Loading train:  12%|█▏        | 36/311 [05:35<25:43,  5.61s/it]Loading train:  12%|█▏        | 37/311 [05:40<24:06,  5.28s/it]Loading train:  12%|█▏        | 38/311 [05:44<22:58,  5.05s/it]Loading train:  13%|█▎        | 39/311 [05:49<22:17,  4.92s/it]Loading train:  13%|█▎        | 40/311 [05:53<21:40,  4.80s/it]Loading train:  13%|█▎        | 41/311 [05:58<21:50,  4.85s/it]Loading train:  14%|█▎        | 42/311 [06:03<21:05,  4.71s/it]Loading train:  14%|█▍        | 43/311 [06:07<20:38,  4.62s/it]Loading train:  14%|█▍        | 44/311 [06:12<20:22,  4.58s/it]Loading train:  14%|█▍        | 45/311 [06:16<20:04,  4.53s/it]Loading train:  15%|█▍        | 46/311 [06:20<19:53,  4.50s/it]Loading train:  15%|█▌        | 47/311 [06:25<20:01,  4.55s/it]Loading train:  15%|█▌        | 48/311 [06:29<19:35,  4.47s/it]Loading train:  16%|█▌        | 49/311 [06:34<19:36,  4.49s/it]Loading train:  16%|█▌        | 50/311 [06:38<19:37,  4.51s/it]Loading train:  16%|█▋        | 51/311 [06:44<20:34,  4.75s/it]Loading train:  17%|█▋        | 52/311 [06:49<21:40,  5.02s/it]Loading train:  17%|█▋        | 53/311 [06:55<22:10,  5.16s/it]Loading train:  17%|█▋        | 54/311 [07:01<22:44,  5.31s/it]Loading train:  18%|█▊        | 55/311 [07:06<23:12,  5.44s/it]Loading train:  18%|█▊        | 56/311 [07:12<23:07,  5.44s/it]Loading train:  18%|█▊        | 57/311 [07:17<22:51,  5.40s/it]Loading train:  19%|█▊        | 58/311 [07:23<23:19,  5.53s/it]Loading train:  19%|█▉        | 59/311 [07:28<23:13,  5.53s/it]Loading train:  19%|█▉        | 60/311 [07:34<23:03,  5.51s/it]Loading train:  20%|█▉        | 61/311 [07:39<22:43,  5.46s/it]Loading train:  20%|█▉        | 62/311 [07:45<22:51,  5.51s/it]Loading train:  20%|██        | 63/311 [07:50<22:38,  5.48s/it]Loading train:  21%|██        | 64/311 [07:55<22:08,  5.38s/it]Loading train:  21%|██        | 65/311 [08:01<21:44,  5.30s/it]Loading train:  21%|██        | 66/311 [08:06<21:56,  5.37s/it]Loading train:  22%|██▏       | 67/311 [08:11<21:43,  5.34s/it]Loading train:  22%|██▏       | 68/311 [08:17<21:42,  5.36s/it]Loading train:  22%|██▏       | 69/311 [08:22<21:33,  5.35s/it]Loading train:  23%|██▎       | 70/311 [08:27<21:33,  5.37s/it]Loading train:  23%|██▎       | 71/311 [08:33<21:20,  5.33s/it]Loading train:  23%|██▎       | 72/311 [08:38<21:07,  5.30s/it]Loading train:  23%|██▎       | 73/311 [08:43<21:11,  5.34s/it]Loading train:  24%|██▍       | 74/311 [08:49<21:03,  5.33s/it]Loading train:  24%|██▍       | 75/311 [08:54<20:52,  5.31s/it]Loading train:  24%|██▍       | 76/311 [08:59<20:50,  5.32s/it]Loading train:  25%|██▍       | 77/311 [09:05<20:51,  5.35s/it]Loading train:  25%|██▌       | 78/311 [09:10<20:44,  5.34s/it]Loading train:  25%|██▌       | 79/311 [09:15<20:18,  5.25s/it]Loading train:  26%|██▌       | 80/311 [09:20<20:17,  5.27s/it]Loading train:  26%|██▌       | 81/311 [09:26<20:25,  5.33s/it]Loading train:  26%|██▋       | 82/311 [09:31<20:16,  5.31s/it]Loading train:  27%|██▋       | 83/311 [09:37<20:20,  5.35s/it]Loading train:  27%|██▋       | 84/311 [09:42<20:13,  5.34s/it]Loading train:  27%|██▋       | 85/311 [09:47<19:53,  5.28s/it]Loading train:  28%|██▊       | 86/311 [09:52<19:04,  5.09s/it]Loading train:  28%|██▊       | 87/311 [09:56<18:37,  4.99s/it]Loading train:  28%|██▊       | 88/311 [10:01<18:28,  4.97s/it]Loading train:  29%|██▊       | 89/311 [10:06<18:15,  4.93s/it]Loading train:  29%|██▉       | 90/311 [10:11<18:13,  4.95s/it]Loading train:  29%|██▉       | 91/311 [10:16<18:14,  4.98s/it]Loading train:  30%|██▉       | 92/311 [10:21<18:07,  4.97s/it]Loading train:  30%|██▉       | 93/311 [10:26<18:15,  5.02s/it]Loading train:  30%|███       | 94/311 [10:31<17:51,  4.94s/it]Loading train:  31%|███       | 95/311 [10:36<17:40,  4.91s/it]Loading train:  31%|███       | 96/311 [10:40<17:13,  4.81s/it]Loading train:  31%|███       | 97/311 [10:45<16:56,  4.75s/it]Loading train:  32%|███▏      | 98/311 [10:50<16:58,  4.78s/it]Loading train:  32%|███▏      | 99/311 [10:55<16:55,  4.79s/it]Loading train:  32%|███▏      | 100/311 [11:00<17:00,  4.83s/it]Loading train:  32%|███▏      | 101/311 [11:05<16:59,  4.85s/it]Loading train:  33%|███▎      | 102/311 [11:10<17:01,  4.89s/it]Loading train:  33%|███▎      | 103/311 [11:14<16:59,  4.90s/it]Loading train:  33%|███▎      | 104/311 [11:19<16:38,  4.82s/it]Loading train:  34%|███▍      | 105/311 [11:24<16:54,  4.92s/it]Loading train:  34%|███▍      | 106/311 [11:29<16:50,  4.93s/it]Loading train:  34%|███▍      | 107/311 [11:34<16:43,  4.92s/it]Loading train:  35%|███▍      | 108/311 [11:39<16:44,  4.95s/it]Loading train:  35%|███▌      | 109/311 [11:44<16:55,  5.03s/it]Loading train:  35%|███▌      | 110/311 [11:49<16:50,  5.03s/it]Loading train:  36%|███▌      | 111/311 [11:54<16:28,  4.94s/it]Loading train:  36%|███▌      | 112/311 [11:59<16:22,  4.94s/it]Loading train:  36%|███▋      | 113/311 [12:04<16:06,  4.88s/it]Loading train:  37%|███▋      | 114/311 [12:13<19:53,  6.06s/it]Loading train:  37%|███▋      | 115/311 [12:21<22:15,  6.81s/it]Loading train:  37%|███▋      | 116/311 [12:30<24:01,  7.39s/it]Loading train:  38%|███▊      | 117/311 [12:39<25:17,  7.82s/it]Loading train:  38%|███▊      | 118/311 [12:48<26:14,  8.16s/it]Loading train:  38%|███▊      | 119/311 [12:57<27:02,  8.45s/it]Loading train:  39%|███▊      | 120/311 [13:05<27:07,  8.52s/it]Loading train:  39%|███▉      | 121/311 [13:14<27:22,  8.65s/it]Loading train:  39%|███▉      | 122/311 [13:24<27:46,  8.82s/it]Loading train:  40%|███▉      | 123/311 [13:33<28:01,  8.94s/it]Loading train:  40%|███▉      | 124/311 [13:42<28:04,  9.01s/it]Loading train:  40%|████      | 125/311 [13:51<27:52,  8.99s/it]Loading train:  41%|████      | 126/311 [14:00<27:58,  9.07s/it]Loading train:  41%|████      | 127/311 [14:09<27:50,  9.08s/it]Loading train:  41%|████      | 128/311 [14:18<27:39,  9.07s/it]Loading train:  41%|████▏     | 129/311 [14:28<27:36,  9.10s/it]Loading train:  42%|████▏     | 130/311 [14:36<27:11,  9.01s/it]Loading train:  42%|████▏     | 131/311 [14:46<27:09,  9.05s/it]Loading train:  42%|████▏     | 132/311 [14:50<22:45,  7.63s/it]Loading train:  43%|████▎     | 133/311 [14:54<19:40,  6.63s/it]Loading train:  43%|████▎     | 134/311 [14:59<17:48,  6.04s/it]Loading train:  43%|████▎     | 135/311 [15:04<16:31,  5.64s/it]Loading train:  44%|████▎     | 136/311 [15:08<15:32,  5.33s/it]Loading train:  44%|████▍     | 137/311 [15:13<14:48,  5.10s/it]Loading train:  44%|████▍     | 138/311 [15:17<14:09,  4.91s/it]Loading train:  45%|████▍     | 139/311 [15:22<13:44,  4.79s/it]Loading train:  45%|████▌     | 140/311 [15:26<13:23,  4.70s/it]Loading train:  45%|████▌     | 141/311 [15:30<12:58,  4.58s/it]Loading train:  46%|████▌     | 142/311 [15:35<12:54,  4.58s/it]Loading train:  46%|████▌     | 143/311 [15:40<12:56,  4.62s/it]Loading train:  46%|████▋     | 144/311 [15:44<12:42,  4.56s/it]Loading train:  47%|████▋     | 145/311 [15:48<12:21,  4.47s/it]Loading train:  47%|████▋     | 146/311 [15:53<12:07,  4.41s/it]Loading train:  47%|████▋     | 147/311 [15:57<11:50,  4.33s/it]Loading train:  48%|████▊     | 148/311 [16:01<11:50,  4.36s/it]Loading train:  48%|████▊     | 149/311 [16:06<11:54,  4.41s/it]Loading train:  48%|████▊     | 150/311 [16:11<12:34,  4.69s/it]Loading train:  49%|████▊     | 151/311 [16:17<13:09,  4.93s/it]Loading train:  49%|████▉     | 152/311 [16:22<13:18,  5.02s/it]Loading train:  49%|████▉     | 153/311 [16:27<13:25,  5.10s/it]Loading train:  50%|████▉     | 154/311 [16:33<13:43,  5.24s/it]Loading train:  50%|████▉     | 155/311 [16:38<13:49,  5.31s/it]Loading train:  50%|█████     | 156/311 [16:44<13:53,  5.38s/it]Loading train:  50%|█████     | 157/311 [16:49<13:52,  5.40s/it]Loading train:  51%|█████     | 158/311 [16:55<13:50,  5.43s/it]Loading train:  51%|█████     | 159/311 [17:00<13:39,  5.39s/it]Loading train:  51%|█████▏    | 160/311 [17:05<13:32,  5.38s/it]Loading train:  52%|█████▏    | 161/311 [17:11<13:29,  5.40s/it]Loading train:  52%|█████▏    | 162/311 [17:16<13:36,  5.48s/it]Loading train:  52%|█████▏    | 163/311 [17:22<13:37,  5.52s/it]Loading train:  53%|█████▎    | 164/311 [17:27<13:26,  5.49s/it]Loading train:  53%|█████▎    | 165/311 [17:33<13:30,  5.55s/it]Loading train:  53%|█████▎    | 166/311 [17:38<13:05,  5.41s/it]Loading train:  54%|█████▎    | 167/311 [17:43<12:49,  5.34s/it]Loading train:  54%|█████▍    | 168/311 [17:49<13:00,  5.46s/it]Loading train:  54%|█████▍    | 169/311 [17:55<12:51,  5.43s/it]Loading train:  55%|█████▍    | 170/311 [18:00<12:38,  5.38s/it]Loading train:  55%|█████▍    | 171/311 [18:05<12:25,  5.33s/it]Loading train:  55%|█████▌    | 172/311 [18:11<12:29,  5.39s/it]Loading train:  56%|█████▌    | 173/311 [18:16<12:24,  5.39s/it]Loading train:  56%|█████▌    | 174/311 [18:21<12:19,  5.40s/it]Loading train:  56%|█████▋    | 175/311 [18:27<12:19,  5.44s/it]Loading train:  57%|█████▋    | 176/311 [18:32<12:12,  5.42s/it]Loading train:  57%|█████▋    | 177/311 [18:37<11:58,  5.36s/it]Loading train:  57%|█████▋    | 178/311 [18:43<11:48,  5.33s/it]Loading train:  58%|█████▊    | 179/311 [18:48<11:52,  5.40s/it]Loading train:  58%|█████▊    | 180/311 [18:53<11:30,  5.27s/it]Loading train:  58%|█████▊    | 181/311 [18:59<11:25,  5.27s/it]Loading train:  59%|█████▊    | 182/311 [19:03<11:07,  5.17s/it]Loading train:  59%|█████▉    | 183/311 [19:09<11:07,  5.22s/it]Loading train:  59%|█████▉    | 184/311 [19:14<10:51,  5.13s/it]Loading train:  59%|█████▉    | 185/311 [19:19<10:40,  5.08s/it]Loading train:  60%|█████▉    | 186/311 [19:24<10:31,  5.06s/it]Loading train:  60%|██████    | 187/311 [19:29<10:21,  5.01s/it]Loading train:  60%|██████    | 188/311 [19:33<10:05,  4.92s/it]Loading train:  61%|██████    | 189/311 [19:38<09:51,  4.85s/it]Loading train:  61%|██████    | 190/311 [19:43<09:40,  4.80s/it]Loading train:  61%|██████▏   | 191/311 [19:48<09:41,  4.85s/it]Loading train:  62%|██████▏   | 192/311 [19:53<09:42,  4.90s/it]Loading train:  62%|██████▏   | 193/311 [19:58<09:36,  4.88s/it]Loading train:  62%|██████▏   | 194/311 [20:02<09:31,  4.89s/it]Loading train:  63%|██████▎   | 195/311 [20:07<09:32,  4.93s/it]Loading train:  63%|██████▎   | 196/311 [20:12<09:27,  4.93s/it]Loading train:  63%|██████▎   | 197/311 [20:17<09:18,  4.90s/it]Loading train:  64%|██████▎   | 198/311 [20:22<09:18,  4.94s/it]Loading train:  64%|██████▍   | 199/311 [20:27<09:07,  4.89s/it]Loading train:  64%|██████▍   | 200/311 [20:32<08:58,  4.85s/it]Loading train:  65%|██████▍   | 201/311 [20:37<09:03,  4.94s/it]Loading train:  65%|██████▍   | 202/311 [20:42<09:03,  4.99s/it]Loading train:  65%|██████▌   | 203/311 [20:47<09:01,  5.01s/it]Loading train:  66%|██████▌   | 204/311 [20:52<09:00,  5.06s/it]Loading train:  66%|██████▌   | 205/311 [20:57<08:59,  5.09s/it]Loading train:  66%|██████▌   | 206/311 [21:02<08:50,  5.05s/it]Loading train:  67%|██████▋   | 207/311 [21:07<08:45,  5.05s/it]Loading train:  67%|██████▋   | 208/311 [21:13<08:45,  5.10s/it]Loading train:  67%|██████▋   | 209/311 [21:18<08:33,  5.03s/it]Loading train:  68%|██████▊   | 210/311 [21:22<08:21,  4.97s/it]Loading train:  68%|██████▊   | 211/311 [21:28<08:23,  5.03s/it]Loading train:  68%|██████▊   | 212/311 [21:32<08:08,  4.93s/it]Loading train:  68%|██████▊   | 213/311 [21:41<09:42,  5.94s/it]Loading train:  69%|██████▉   | 214/311 [21:50<11:10,  6.92s/it]Loading train:  69%|██████▉   | 215/311 [21:59<12:07,  7.58s/it]Loading train:  69%|██████▉   | 216/311 [22:08<12:38,  7.99s/it]Loading train:  70%|██████▉   | 217/311 [22:17<13:07,  8.38s/it]Loading train:  70%|███████   | 218/311 [22:26<13:10,  8.50s/it]Loading train:  70%|███████   | 219/311 [22:35<13:24,  8.74s/it]Loading train:  71%|███████   | 220/311 [22:44<13:22,  8.82s/it]Loading train:  71%|███████   | 221/311 [22:53<13:24,  8.94s/it]Loading train:  71%|███████▏  | 222/311 [23:03<13:21,  9.00s/it]Loading train:  72%|███████▏  | 223/311 [23:12<13:12,  9.00s/it]Loading train:  72%|███████▏  | 224/311 [23:21<13:11,  9.10s/it]Loading train:  72%|███████▏  | 225/311 [23:30<13:01,  9.08s/it]Loading train:  73%|███████▎  | 226/311 [23:39<12:58,  9.16s/it]Loading train:  73%|███████▎  | 227/311 [23:48<12:49,  9.16s/it]Loading train:  73%|███████▎  | 228/311 [23:58<12:43,  9.20s/it]Loading train:  74%|███████▎  | 229/311 [24:07<12:31,  9.16s/it]Loading train:  74%|███████▍  | 230/311 [24:16<12:21,  9.16s/it]Loading train:  74%|███████▍  | 231/311 [24:21<10:28,  7.86s/it]Loading train:  75%|███████▍  | 232/311 [24:26<09:08,  6.95s/it]Loading train:  75%|███████▍  | 233/311 [24:30<08:08,  6.26s/it]Loading train:  75%|███████▌  | 234/311 [24:35<07:23,  5.76s/it]Loading train:  76%|███████▌  | 235/311 [24:39<06:52,  5.43s/it]Loading train:  76%|███████▌  | 236/311 [24:44<06:31,  5.23s/it]Loading train:  76%|███████▌  | 237/311 [24:49<06:15,  5.07s/it]Loading train:  77%|███████▋  | 238/311 [24:53<05:59,  4.92s/it]Loading train:  77%|███████▋  | 239/311 [24:58<05:48,  4.84s/it]Loading train:  77%|███████▋  | 240/311 [25:03<05:43,  4.84s/it]Loading train:  77%|███████▋  | 241/311 [25:07<05:29,  4.70s/it]Loading train:  78%|███████▊  | 242/311 [25:12<05:19,  4.64s/it]Loading train:  78%|███████▊  | 243/311 [25:17<05:19,  4.70s/it]Loading train:  78%|███████▊  | 244/311 [25:21<05:10,  4.64s/it]Loading train:  79%|███████▉  | 245/311 [25:26<05:00,  4.55s/it]Loading train:  79%|███████▉  | 246/311 [25:30<04:57,  4.57s/it]Loading train:  79%|███████▉  | 247/311 [25:35<04:51,  4.56s/it]Loading train:  80%|███████▉  | 248/311 [25:39<04:45,  4.53s/it]Loading train:  80%|████████  | 249/311 [25:45<04:59,  4.83s/it]Loading train:  80%|████████  | 250/311 [25:50<05:10,  5.10s/it]Loading train:  81%|████████  | 251/311 [25:56<05:15,  5.25s/it]Loading train:  81%|████████  | 252/311 [26:02<05:15,  5.34s/it]Loading train:  81%|████████▏ | 253/311 [26:07<05:15,  5.43s/it]Loading train:  82%|████████▏ | 254/311 [26:13<05:18,  5.59s/it]Loading train:  82%|████████▏ | 255/311 [26:19<05:11,  5.56s/it]Loading train:  82%|████████▏ | 256/311 [26:24<05:09,  5.63s/it]Loading train:  83%|████████▎ | 257/311 [26:30<05:00,  5.56s/it]Loading train:  83%|████████▎ | 258/311 [26:35<04:55,  5.58s/it]Loading train:  83%|████████▎ | 259/311 [26:41<04:52,  5.62s/it]Loading train:  84%|████████▎ | 260/311 [26:47<04:46,  5.61s/it]Loading train:  84%|████████▍ | 261/311 [26:52<04:38,  5.58s/it]Loading train:  84%|████████▍ | 262/311 [26:58<04:33,  5.59s/it]Loading train:  85%|████████▍ | 263/311 [27:03<04:27,  5.57s/it]Loading train:  85%|████████▍ | 264/311 [27:09<04:23,  5.60s/it]Loading train:  85%|████████▌ | 265/311 [27:14<04:14,  5.53s/it]Loading train:  86%|████████▌ | 266/311 [27:20<04:12,  5.62s/it]Loading train:  86%|████████▌ | 267/311 [27:26<04:05,  5.58s/it]Loading train:  86%|████████▌ | 268/311 [27:31<03:58,  5.55s/it]Loading train:  86%|████████▋ | 269/311 [27:37<03:52,  5.53s/it]Loading train:  87%|████████▋ | 270/311 [27:42<03:44,  5.47s/it]Loading train:  87%|████████▋ | 271/311 [27:47<03:36,  5.41s/it]Loading train:  87%|████████▋ | 272/311 [27:53<03:33,  5.47s/it]Loading train:  88%|████████▊ | 273/311 [27:59<03:29,  5.51s/it]Loading train:  88%|████████▊ | 274/311 [28:04<03:24,  5.54s/it]Loading train:  88%|████████▊ | 275/311 [28:10<03:18,  5.50s/it]Loading train:  89%|████████▊ | 276/311 [28:15<03:10,  5.45s/it]Loading train:  89%|████████▉ | 277/311 [28:20<03:06,  5.47s/it]Loading train:  89%|████████▉ | 278/311 [28:26<03:01,  5.50s/it]Loading train:  90%|████████▉ | 279/311 [28:31<02:54,  5.44s/it]Loading train:  90%|█████████ | 280/311 [28:37<02:51,  5.52s/it]Loading train:  90%|█████████ | 281/311 [28:43<02:47,  5.59s/it]Loading train:  91%|█████████ | 282/311 [28:48<02:40,  5.53s/it]Loading train:  91%|█████████ | 283/311 [28:54<02:34,  5.53s/it]Loading train:  91%|█████████▏| 284/311 [28:59<02:27,  5.45s/it]Loading train:  92%|█████████▏| 285/311 [29:04<02:18,  5.33s/it]Loading train:  92%|█████████▏| 286/311 [29:09<02:11,  5.25s/it]Loading train:  92%|█████████▏| 287/311 [29:14<02:05,  5.23s/it]Loading train:  93%|█████████▎| 288/311 [29:19<02:00,  5.22s/it]Loading train:  93%|█████████▎| 289/311 [29:24<01:53,  5.17s/it]Loading train:  93%|█████████▎| 290/311 [29:30<01:49,  5.24s/it]Loading train:  94%|█████████▎| 291/311 [29:35<01:42,  5.11s/it]Loading train:  94%|█████████▍| 292/311 [29:40<01:36,  5.10s/it]Loading train:  94%|█████████▍| 293/311 [29:45<01:31,  5.07s/it]Loading train:  95%|█████████▍| 294/311 [29:50<01:25,  5.04s/it]Loading train:  95%|█████████▍| 295/311 [29:55<01:20,  5.03s/it]Loading train:  95%|█████████▌| 296/311 [30:00<01:16,  5.09s/it]Loading train:  95%|█████████▌| 297/311 [30:05<01:10,  5.07s/it]Loading train:  96%|█████████▌| 298/311 [30:10<01:05,  5.03s/it]Loading train:  96%|█████████▌| 299/311 [30:15<01:00,  5.05s/it]Loading train:  96%|█████████▋| 300/311 [30:20<00:54,  4.99s/it]Loading train:  97%|█████████▋| 301/311 [30:25<00:50,  5.03s/it]Loading train:  97%|█████████▋| 302/311 [30:30<00:46,  5.14s/it]Loading train:  97%|█████████▋| 303/311 [30:36<00:41,  5.17s/it]Loading train:  98%|█████████▊| 304/311 [30:41<00:35,  5.10s/it]Loading train:  98%|█████████▊| 305/311 [30:46<00:30,  5.08s/it]Loading train:  98%|█████████▊| 306/311 [30:51<00:26,  5.20s/it]Loading train:  99%|█████████▊| 307/311 [30:56<00:20,  5.19s/it]Loading train:  99%|█████████▉| 308/311 [31:02<00:15,  5.25s/it]Loading train:  99%|█████████▉| 309/311 [31:07<00:10,  5.23s/it]Loading train: 100%|█████████▉| 310/311 [31:12<00:05,  5.16s/it]Loading train: 100%|██████████| 311/311 [31:17<00:00,  5.17s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/311 [00:00<00:07, 42.89it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:05, 50.50it/s]concatenating: train:   8%|▊         | 26/311 [00:00<00:04, 60.76it/s]concatenating: train:  15%|█▌        | 47/311 [00:00<00:03, 75.76it/s]concatenating: train:  21%|██        | 66/311 [00:00<00:02, 92.37it/s]concatenating: train:  28%|██▊       | 86/311 [00:00<00:02, 109.62it/s]concatenating: train:  37%|███▋      | 114/311 [00:00<00:01, 133.56it/s]concatenating: train:  43%|████▎     | 133/311 [00:00<00:01, 143.94it/s]concatenating: train:  50%|████▉     | 155/311 [00:00<00:00, 159.68it/s]concatenating: train:  57%|█████▋    | 176/311 [00:01<00:00, 169.23it/s]concatenating: train:  63%|██████▎   | 196/311 [00:01<00:00, 149.26it/s]concatenating: train:  69%|██████▉   | 214/311 [00:01<00:00, 155.61it/s]concatenating: train:  77%|███████▋  | 238/311 [00:01<00:00, 173.88it/s]concatenating: train:  84%|████████▎ | 260/311 [00:01<00:00, 185.43it/s]concatenating: train:  91%|█████████▏| 284/311 [00:01<00:00, 197.66it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 179.49it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.87s/it]Loading test:  50%|█████     | 2/4 [00:22<00:23, 11.59s/it]Loading test:  75%|███████▌  | 3/4 [00:34<00:11, 11.67s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.65s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 48.34it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   2019-07-07 08:06:49.149686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 08:06:49.149797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 08:06:49.149812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 08:06:49.149821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 08:06:49.150218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 19s - loss: 23093.3479 - acc: 0.8626 - mDice: 0.1263 - val_loss: 20425.9468 - val_acc: 0.8767 - val_mDice: 0.2203

Epoch 00001: val_mDice improved from -inf to 0.22035, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 15585.3964 - acc: 0.8728 - mDice: 0.2245 - val_loss: 19089.6508 - val_acc: 0.8752 - val_mDice: 0.2705

Epoch 00002: val_mDice improved from 0.22035 to 0.27054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 14224.6253 - acc: 0.8821 - mDice: 0.2798 - val_loss: 11445.9333 - val_acc: 0.8814 - val_mDice: 0.3518

Epoch 00003: val_mDice improved from 0.27054 to 0.35183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 13182.0553 - acc: 0.8913 - mDice: 0.3398 - val_loss: 10738.1415 - val_acc: 0.8950 - val_mDice: 0.4164

Epoch 00004: val_mDice improved from 0.35183 to 0.41639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 8737.8054 - acc: 0.8916 - mDice: 0.3524 - val_loss: 3880.2592 - val_acc: 0.9001 - val_mDice: 0.4387

Epoch 00005: val_mDice improved from 0.41639 to 0.43867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 4819.6618 - acc: 0.8969 - mDice: 0.3997 - val_loss: 3363.5437 - val_acc: 0.8995 - val_mDice: 0.4843

Epoch 00006: val_mDice improved from 0.43867 to 0.48430, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 4226.1958 - acc: 0.9035 - mDice: 0.4410 - val_loss: 3022.0482 - val_acc: 0.9106 - val_mDice: 0.5199

Epoch 00007: val_mDice improved from 0.48430 to 0.51989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 3872.4854 - acc: 0.9080 - mDice: 0.4708 - val_loss: 2908.9355 - val_acc: 0.9152 - val_mDice: 0.5373

Epoch 00008: val_mDice improved from 0.51989 to 0.53735, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 3646.7111 - acc: 0.9110 - mDice: 0.4913 - val_loss: 2758.5518 - val_acc: 0.9232 - val_mDice: 0.5563

Epoch 00009: val_mDice improved from 0.53735 to 0.55633, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 3446.3395 - acc: 0.9140 - mDice: 0.5106 - val_loss: 2785.3872 - val_acc: 0.9201 - val_mDice: 0.5545

Epoch 00010: val_mDice did not improve from 0.55633
Epoch 11/300
 - 10s - loss: 3298.4222 - acc: 0.9163 - mDice: 0.5254 - val_loss: 2686.5099 - val_acc: 0.9252 - val_mDice: 0.5651

Epoch 00011: val_mDice improved from 0.55633 to 0.56512, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 3175.1212 - acc: 0.9182 - mDice: 0.5376 - val_loss: 2630.5231 - val_acc: 0.9272 - val_mDice: 0.5730

Epoch 00012: val_mDice improved from 0.56512 to 0.57295, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 3057.7424 - acc: 0.9200 - mDice: 0.5497 - val_loss: 2442.1264 - val_acc: 0.9345 - val_mDice: 0.5940

Epoch 00013: val_mDice improved from 0.57295 to 0.59403, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 2964.0805 - acc: 0.9214 - mDice: 0.5596 - val_loss: 2432.6338 - val_acc: 0.9311 - val_mDice: 0.5923

Epoch 00014: val_mDice did not improve from 0.59403
Epoch 15/300
 - 9s - loss: 2862.6575 - acc: 0.9226 - mDice: 0.5702 - val_loss: 2422.2462 - val_acc: 0.9344 - val_mDice: 0.5946

Epoch 00015: val_mDice improved from 0.59403 to 0.59464, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 2792.9720 - acc: 0.9239 - mDice: 0.5776 - val_loss: 2483.3380 - val_acc: 0.9303 - val_mDice: 0.5903

Epoch 00016: val_mDice did not improve from 0.59464
Epoch 17/300
 - 10s - loss: 2724.7275 - acc: 0.9250 - mDice: 0.5849 - val_loss: 2439.2483 - val_acc: 0.9365 - val_mDice: 0.5959

Epoch 00017: val_mDice improved from 0.59464 to 0.59592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 9s - loss: 2655.8690 - acc: 0.9261 - mDice: 0.5920 - val_loss: 2426.1942 - val_acc: 0.9312 - val_mDice: 0.5917

Epoch 00018: val_mDice did not improve from 0.59592
Epoch 19/300
 - 9s - loss: 2584.4512 - acc: 0.9268 - mDice: 0.5992 - val_loss: 2166.9456 - val_acc: 0.9380 - val_mDice: 0.6200

Epoch 00019: val_mDice improved from 0.59592 to 0.61995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 10s - loss: 2522.2818 - acc: 0.9277 - mDice: 0.6055 - val_loss: 2062.0915 - val_acc: 0.9391 - val_mDice: 0.6318

Epoch 00020: val_mDice improved from 0.61995 to 0.63176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 9s - loss: 2455.1404 - acc: 0.9284 - mDice: 0.6130 - val_loss: 2012.8355 - val_acc: 0.9395 - val_mDice: 0.6371

Epoch 00021: val_mDice improved from 0.63176 to 0.63707, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 22/300
 - 9s - loss: 2404.7193 - acc: 0.9289 - mDice: 0.6183 - val_loss: 1988.6143 - val_acc: 0.9416 - val_mDice: 0.6405

Epoch 00022: val_mDice improved from 0.63707 to 0.64054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 2343.8106 - acc: 0.9299 - mDice: 0.6253 - val_loss: 2051.6726 - val_acc: 0.9381 - val_mDice: 0.6335

Epoch 00023: val_mDice did not improve from 0.64054
Epoch 24/300
 - 9s - loss: 2308.4650 - acc: 0.9303 - mDice: 0.6296 - val_loss: 2156.9457 - val_acc: 0.9373 - val_mDice: 0.6217

Epoch 00024: val_mDice did not improve from 0.64054
Epoch 25/300
 - 9s - loss: 2271.4472 - acc: 0.9309 - mDice: 0.6339 - val_loss: 2015.2778 - val_acc: 0.9389 - val_mDice: 0.6393

Epoch 00025: val_mDice did not improve from 0.64054
Epoch 26/300
 - 10s - loss: 2229.7715 - acc: 0.9315 - mDice: 0.6388 - val_loss: 2058.3946 - val_acc: 0.9409 - val_mDice: 0.6340

Epoch 00026: val_mDice did not improve from 0.64054
Epoch 27/300
 - 10s - loss: 2193.7288 - acc: 0.9319 - mDice: 0.6433 - val_loss: 1881.7612 - val_acc: 0.9444 - val_mDice: 0.6561

Epoch 00027: val_mDice improved from 0.64054 to 0.65606, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 9s - loss: 2168.4704 - acc: 0.9325 - mDice: 0.6463 - val_loss: 1928.3001 - val_acc: 0.9433 - val_mDice: 0.6493

Epoch 00028: val_mDice did not improve from 0.65606
Epoch 29/300
 - 10s - loss: 2131.4565 - acc: 0.9330 - mDice: 0.6512 - val_loss: 1982.9353 - val_acc: 0.9410 - val_mDice: 0.6429

Epoch 00029: val_mDice did not improve from 0.65606
Epoch 30/300
 - 10s - loss: 2106.0968 - acc: 0.9335 - mDice: 0.6542 - val_loss: 1852.3020 - val_acc: 0.9451 - val_mDice: 0.6580

Epoch 00030: val_mDice improved from 0.65606 to 0.65801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 31/300
 - 9s - loss: 2080.5482 - acc: 0.9338 - mDice: 0.6575 - val_loss: 1916.5396 - val_acc: 0.9441 - val_mDice: 0.6510

Epoch 00031: val_mDice did not improve from 0.65801
Epoch 32/300
 - 10s - loss: 2055.0753 - acc: 0.9343 - mDice: 0.6607 - val_loss: 2204.8889 - val_acc: 0.9323 - val_mDice: 0.6152

Epoch 00032: val_mDice did not improve from 0.65801
Epoch 33/300
 - 10s - loss: 2018.8757 - acc: 0.9349 - mDice: 0.6654 - val_loss: 2016.3323 - val_acc: 0.9424 - val_mDice: 0.6415

Epoch 00033: val_mDice did not improve from 0.65801
Epoch 34/300
 - 9s - loss: 2008.8685 - acc: 0.9352 - mDice: 0.6669 - val_loss: 2103.6015 - val_acc: 0.9382 - val_mDice: 0.6264

Epoch 00034: val_mDice did not improve from 0.65801
Epoch 35/300
 - 10s - loss: 1991.8051 - acc: 0.9354 - mDice: 0.6690 - val_loss: 1842.2521 - val_acc: 0.9477 - val_mDice: 0.6616

Epoch 00035: val_mDice improved from 0.65801 to 0.66156, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 36/300
 - 10s - loss: 1967.7028 - acc: 0.9358 - mDice: 0.6724 - val_loss: 1785.6296 - val_acc: 0.9475 - val_mDice: 0.6687

Epoch 00036: val_mDice improved from 0.66156 to 0.66872, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 37/300
 - 9s - loss: 1948.9388 - acc: 0.9361 - mDice: 0.6747 - val_loss: 1902.1949 - val_acc: 0.9470 - val_mDice: 0.6524

Epoch 00037: val_mDice did not improve from 0.66872
Epoch 38/300
 - 10s - loss: 1924.1527 - acc: 0.9365 - mDice: 0.6782 - val_loss: 1912.2770 - val_acc: 0.9470 - val_mDice: 0.6537

Epoch 00038: val_mDice did not improve from 0.66872
Epoch 39/300
 - 10s - loss: 1911.1895 - acc: 0.9370 - mDice: 0.6799 - val_loss: 2228.7729 - val_acc: 0.9361 - val_mDice: 0.6149

Epoch 00039: val_mDice did not improve from 0.66872
Epoch 40/300
 - 9s - loss: 1887.5515 - acc: 0.9373 - mDice: 0.6831 - val_loss: 2105.5180 - val_acc: 0.9396 - val_mDice: 0.6307

Epoch 00040: val_mDice did not improve from 0.66872
Epoch 41/300
 - 10s - loss: 1874.6880 - acc: 0.9375 - mDice: 0.6847 - val_loss: 2363.9980 - val_acc: 0.9300 - val_mDice: 0.5951

Epoch 00041: val_mDice did not improve from 0.66872
Epoch 42/300
 - 10s - loss: 1851.1379 - acc: 0.9379 - mDice: 0.6879 - val_loss: 1827.1950 - val_acc: 0.9484 - val_mDice: 0.6641

Epoch 00042: val_mDice did not improve from 0.66872
Epoch 43/300
 - 9s - loss: 1835.0552 - acc: 0.9381 - mDice: 0.6901 - val_loss: 1901.7155 - val_acc: 0.9471 - val_mDice: 0.6554

Epoch 00043: val_mDice did not improve from 0.66872
Epoch 44/300
 - 10s - loss: 1815.8268 - acc: 0.9385 - mDice: 0.6928 - val_loss: 1969.7160 - val_acc: 0.9408 - val_mDice: 0.6450

Epoch 00044: val_mDice did not improve from 0.66872
Epoch 45/300
 - 10s - loss: 1793.3765 - acc: 0.9388 - mDice: 0.6957 - val_loss: 1778.4848 - val_acc: 0.9490 - val_mDice: 0.6721

Epoch 00045: val_mDice improved from 0.66872 to 0.67213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 46/300
 - 9s - loss: 1789.2044 - acc: 0.9390 - mDice: 0.6965 - val_loss: 1889.3411 - val_acc: 0.9450 - val_mDice: 0.6575

Epoch 00046: val_mDice did not improve from 0.67213
Epoch 47/300
 - 10s - loss: 1769.4035 - acc: 0.9393 - mDice: 0.6991 - val_loss: 2553.5268 - val_acc: 0.9277 - val_mDice: 0.5755

Epoch 00047: val_mDice did not improve from 0.67213
Epoch 48/300
 - 10s - loss: 1766.7943 - acc: 0.9394 - mDice: 0.6996 - val_loss: 1886.9360 - val_acc: 0.9432 - val_mDice: 0.6562

Epoch 00048: val_mDice did not improve from 0.67213
Epoch 49/300
 - 9s - loss: 1745.5984 - acc: 0.9398 - mDice: 0.7023 - val_loss: 1804.8980 - val_acc: 0.9496 - val_mDice: 0.6688

Epoch 00049: val_mDice did not improve from 0.67213
Epoch 50/300
 - 10s - loss: 1730.4418 - acc: 0.9399 - mDice: 0.7044 - val_loss: 1894.6578 - val_acc: 0.9439 - val_mDice: 0.6570

Epoch 00050: val_mDice did not improve from 0.67213
Epoch 51/300
 - 10s - loss: 1719.0813 - acc: 0.9402 - mDice: 0.7061 - val_loss: 1723.6071 - val_acc: 0.9502 - val_mDice: 0.6802

Epoch 00051: val_mDice improved from 0.67213 to 0.68023, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 52/300
 - 9s - loss: 1699.8405 - acc: 0.9407 - mDice: 0.7088 - val_loss: 1781.3811 - val_acc: 0.9507 - val_mDice: 0.6728

Epoch 00052: val_mDice did not improve from 0.68023
Epoch 53/300
 - 9s - loss: 1680.7985 - acc: 0.9408 - mDice: 0.7113 - val_loss: 1830.0805 - val_acc: 0.9495 - val_mDice: 0.6655

Epoch 00053: val_mDice did not improve from 0.68023
Epoch 54/300
 - 10s - loss: 1671.2730 - acc: 0.9411 - mDice: 0.7128 - val_loss: 1736.6235 - val_acc: 0.9514 - val_mDice: 0.6788

Epoch 00054: val_mDice did not improve from 0.68023
Epoch 55/300
 - 10s - loss: 1660.1465 - acc: 0.9413 - mDice: 0.7143 - val_loss: 1818.5810 - val_acc: 0.9472 - val_mDice: 0.6672

Epoch 00055: val_mDice did not improve from 0.68023
Epoch 56/300
 - 9s - loss: 1646.2315 - acc: 0.9415 - mDice: 0.7162 - val_loss: 1790.1187 - val_acc: 0.9492 - val_mDice: 0.6713

Epoch 00056: val_mDice did not improve from 0.68023
Epoch 57/300
 - 10s - loss: 1643.6156 - acc: 0.9415 - mDice: 0.7167 - val_loss: 1889.7996 - val_acc: 0.9477 - val_mDice: 0.6585

Epoch 00057: val_mDice did not improve from 0.68023
Epoch 58/300
 - 10s - loss: 1619.9150 - acc: 0.9419 - mDice: 0.7200 - val_loss: 1780.7590 - val_acc: 0.9520 - val_mDice: 0.6738

Epoch 00058: val_mDice did not improve from 0.68023
Epoch 59/300
 - 10s - loss: 1618.2663 - acc: 0.9419 - mDice: 0.7203 - val_loss: 1790.0348 - val_acc: 0.9505 - val_mDice: 0.6713

Epoch 00059: val_mDice did not improve from 0.68023
Epoch 60/300
 - 11s - loss: 1613.4334 - acc: 0.9421 - mDice: 0.7210 - val_loss: 1845.7997 - val_acc: 0.9476 - val_mDice: 0.6631

Epoch 00060: val_mDice did not improve from 0.68023
Epoch 61/300
 - 10s - loss: 1589.5934 - acc: 0.9424 - mDice: 0.7244 - val_loss: 1722.2026 - val_acc: 0.9512 - val_mDice: 0.6801

Epoch 00061: val_mDice did not improve from 0.68023
Epoch 62/300
 - 10s - loss: 1598.3331 - acc: 0.9423 - mDice: 0.7232 - val_loss: 1796.9399 - val_acc: 0.9493 - val_mDice: 0.6714

Epoch 00062: val_mDice did not improve from 0.68023
Epoch 63/300
 - 11s - loss: 1589.0301 - acc: 0.9425 - mDice: 0.7245 - val_loss: 1852.4371 - val_acc: 0.9463 - val_mDice: 0.6632

Epoch 00063: val_mDice did not improve from 0.68023
Epoch 64/300
 - 10s - loss: 1571.8273 - acc: 0.9429 - mDice: 0.7270 - val_loss: 1899.6990 - val_acc: 0.9448 - val_mDice: 0.6564

Epoch 00064: val_mDice did not improve from 0.68023
Epoch 65/300
 - 10s - loss: 1562.1390 - acc: 0.9431 - mDice: 0.7284 - val_loss: 1718.5840 - val_acc: 0.9508 - val_mDice: 0.6810

Epoch 00065: val_mDice improved from 0.68023 to 0.68102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 66/300
 - 11s - loss: 1557.0351 - acc: 0.9432 - mDice: 0.7291 - val_loss: 1748.9479 - val_acc: 0.9476 - val_mDice: 0.6759

Epoch 00066: val_mDice did not improve from 0.68102
Epoch 67/300
 - 9s - loss: 1542.2920 - acc: 0.9434 - mDice: 0.7313 - val_loss: 1806.0415 - val_acc: 0.9457 - val_mDice: 0.6677

Epoch 00067: val_mDice did not improve from 0.68102
Epoch 68/300
 - 10s - loss: 1534.8174 - acc: 0.9435 - mDice: 0.7323 - val_loss: 1689.2782 - val_acc: 0.9539 - val_mDice: 0.6852

Epoch 00068: val_mDice improved from 0.68102 to 0.68522, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 69/300
 - 11s - loss: 1530.9160 - acc: 0.9435 - mDice: 0.7330 - val_loss: 1815.0244 - val_acc: 0.9454 - val_mDice: 0.6666

Epoch 00069: val_mDice did not improve from 0.68522
Epoch 70/300
 - 10s - loss: 1516.8483 - acc: 0.9436 - mDice: 0.7350 - val_loss: 1709.3440 - val_acc: 0.9530 - val_mDice: 0.6818

Epoch 00070: val_mDice did not improve from 0.68522
Epoch 71/300
 - 10s - loss: 1518.0221 - acc: 0.9437 - mDice: 0.7349 - val_loss: 1788.8147 - val_acc: 0.9487 - val_mDice: 0.6715

Epoch 00071: val_mDice did not improve from 0.68522
Epoch 72/300
 - 11s - loss: 1508.6094 - acc: 0.9439 - mDice: 0.7361 - val_loss: 1731.6648 - val_acc: 0.9509 - val_mDice: 0.6793

Epoch 00072: val_mDice did not improve from 0.68522
Epoch 73/300
 - 10s - loss: 1507.5613 - acc: 0.9437 - mDice: 0.7365 - val_loss: 1823.1221 - val_acc: 0.9456 - val_mDice: 0.6653

Epoch 00073: val_mDice did not improve from 0.68522
Epoch 74/300
 - 10s - loss: 1496.8809 - acc: 0.9439 - mDice: 0.7379 - val_loss: 1690.5246 - val_acc: 0.9522 - val_mDice: 0.6838

Epoch 00074: val_mDice did not improve from 0.68522
Epoch 75/300
 - 11s - loss: 1492.1110 - acc: 0.9441 - mDice: 0.7387 - val_loss: 1796.3431 - val_acc: 0.9501 - val_mDice: 0.6722

Epoch 00075: val_mDice did not improve from 0.68522
Epoch 76/300
 - 10s - loss: 1480.8107 - acc: 0.9443 - mDice: 0.7404 - val_loss: 1855.1378 - val_acc: 0.9498 - val_mDice: 0.6647

Epoch 00076: val_mDice did not improve from 0.68522
Epoch 77/300
 - 10s - loss: 1475.2914 - acc: 0.9443 - mDice: 0.7412 - val_loss: 2355.1347 - val_acc: 0.9304 - val_mDice: 0.5959

Epoch 00077: val_mDice did not improve from 0.68522
Epoch 78/300
 - 11s - loss: 1466.4996 - acc: 0.9445 - mDice: 0.7426 - val_loss: 1709.0683 - val_acc: 0.9524 - val_mDice: 0.6820

Epoch 00078: val_mDice did not improve from 0.68522
Epoch 79/300
 - 10s - loss: 1464.6563 - acc: 0.9446 - mDice: 0.7428 - val_loss: 1735.4851 - val_acc: 0.9551 - val_mDice: 0.6797

Epoch 00079: val_mDice did not improve from 0.68522
Epoch 80/300
 - 10s - loss: 1463.1858 - acc: 0.9446 - mDice: 0.7430 - val_loss: 1761.3732 - val_acc: 0.9518 - val_mDice: 0.6771

Epoch 00080: val_mDice did not improve from 0.68522
Epoch 81/300
 - 11s - loss: 1444.2714 - acc: 0.9447 - mDice: 0.7458 - val_loss: 1765.6636 - val_acc: 0.9517 - val_mDice: 0.6757

Epoch 00081: val_mDice did not improve from 0.68522
Epoch 82/300
 - 10s - loss: 1445.1200 - acc: 0.9448 - mDice: 0.7457 - val_loss: 1784.0172 - val_acc: 0.9449 - val_mDice: 0.6710

Epoch 00082: val_mDice did not improve from 0.68522
Epoch 83/300
 - 10s - loss: 1435.3973 - acc: 0.9449 - mDice: 0.7470 - val_loss: 1708.9019 - val_acc: 0.9512 - val_mDice: 0.6820

Epoch 00083: val_mDice did not improve from 0.68522
Epoch 84/300
 - 10s - loss: 1439.2585 - acc: 0.9449 - mDice: 0.7465 - val_loss: 1700.5426 - val_acc: 0.9543 - val_mDice: 0.6835

Epoch 00084: val_mDice did not improve from 0.68522
Epoch 85/300
 - 10s - loss: 1437.6439 - acc: 0.9450 - mDice: 0.7468 - val_loss: 1643.1651 - val_acc: 0.9538 - val_mDice: 0.6920

Epoch 00085: val_mDice improved from 0.68522 to 0.69199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 86/300
 - 10s - loss: 1426.8982 - acc: 0.9452 - mDice: 0.7484 - val_loss: 1711.8129 - val_acc: 0.9537 - val_mDice: 0.6832

Epoch 00086: val_mDice did not improve from 0.69199
Epoch 87/300
 - 11s - loss: 1421.3854 - acc: 0.9452 - mDice: 0.7491 - val_loss: 1641.9239 - val_acc: 0.9542 - val_mDice: 0.6920

Epoch 00087: val_mDice did not improve from 0.69199
Epoch 88/300
 - 10s - loss: 1417.7115 - acc: 0.9453 - mDice: 0.7497 - val_loss: 1694.0333 - val_acc: 0.9496 - val_mDice: 0.6843

Epoch 00088: val_mDice did not improve from 0.69199
Epoch 89/300
 - 10s - loss: 1415.5005 - acc: 0.9454 - mDice: 0.7501 - val_loss: 1720.4774 - val_acc: 0.9529 - val_mDice: 0.6819

Epoch 00089: val_mDice did not improve from 0.69199
Epoch 90/300
 - 10s - loss: 1413.9911 - acc: 0.9455 - mDice: 0.7509 - val_loss: 1792.4165 - val_acc: 0.9500 - val_mDice: 0.6709

Epoch 00090: val_mDice did not improve from 0.69199
Epoch 91/300
 - 10s - loss: 1399.9343 - acc: 0.9456 - mDice: 0.7525 - val_loss: 1719.3479 - val_acc: 0.9533 - val_mDice: 0.6812

Epoch 00091: val_mDice did not improve from 0.69199
Epoch 92/300
 - 10s - loss: 1393.1293 - acc: 0.9457 - mDice: 0.7535 - val_loss: 1679.2486 - val_acc: 0.9539 - val_mDice: 0.6854

Epoch 00092: val_mDice did not improve from 0.69199
Epoch 93/300
 - 10s - loss: 1400.9283 - acc: 0.9456 - mDice: 0.7522 - val_loss: 1699.5028 - val_acc: 0.9543 - val_mDice: 0.6828

Epoch 00093: val_mDice did not improve from 0.69199
Epoch 94/300
 - 10s - loss: 1392.0093 - acc: 0.9458 - mDice: 0.7536 - val_loss: 1787.6816 - val_acc: 0.9513 - val_mDice: 0.6708

Epoch 00094: val_mDice did not improve from 0.69199
Epoch 95/300
 - 10s - loss: 1382.4871 - acc: 0.9459 - mDice: 0.7550 - val_loss: 1726.5741 - val_acc: 0.9520 - val_mDice: 0.6818

Epoch 00095: val_mDice did not improve from 0.69199
Epoch 96/300
 - 11s - loss: 1377.1436 - acc: 0.9462 - mDice: 0.7559 - val_loss: 1801.4978 - val_acc: 0.9448 - val_mDice: 0.6677

Epoch 00096: val_mDice did not improve from 0.69199
Epoch 97/300
 - 10s - loss: 1368.9853 - acc: 0.9460 - mDice: 0.7570 - val_loss: 1695.7862 - val_acc: 0.9517 - val_mDice: 0.6838

Epoch 00097: val_mDice did not improve from 0.69199
Epoch 98/300
 - 10s - loss: 1370.9826 - acc: 0.9461 - mDice: 0.7568 - val_loss: 1683.0074 - val_acc: 0.9526 - val_mDice: 0.6852

Epoch 00098: val_mDice did not improve from 0.69199
Epoch 99/300
 - 10s - loss: 1364.4997 - acc: 0.9463 - mDice: 0.7578 - val_loss: 1647.3169 - val_acc: 0.9538 - val_mDice: 0.6910

Epoch 00099: val_mDice did not improve from 0.69199
Epoch 100/300
 - 10s - loss: 1360.8492 - acc: 0.9464 - mDice: 0.7582 - val_loss: 1687.5270 - val_acc: 0.9558 - val_mDice: 0.6858

Epoch 00100: val_mDice did not improve from 0.69199
Epoch 101/300
 - 10s - loss: 1358.6745 - acc: 0.9465 - mDice: 0.7586 - val_loss: 1921.9353 - val_acc: 0.9429 - val_mDice: 0.6522

Epoch 00101: val_mDice did not improve from 0.69199
Epoch 102/300
 - 10s - loss: 1361.0233 - acc: 0.9464 - mDice: 0.7582 - val_loss: 1665.6665 - val_acc: 0.9531 - val_mDice: 0.6889

Epoch 00102: val_mDice did not improve from 0.69199
Epoch 103/300
 - 10s - loss: 1361.2136 - acc: 0.9463 - mDice: 0.7582 - val_loss: 1788.4194 - val_acc: 0.9490 - val_mDice: 0.6709

Epoch 00103: val_mDice did not improve from 0.69199
Epoch 104/300
 - 11s - loss: 1348.9976 - acc: 0.9465 - mDice: 0.7600 - val_loss: 1676.2084 - val_acc: 0.9535 - val_mDice: 0.6864

Epoch 00104: val_mDice did not improve from 0.69199
Epoch 105/300
 - 10s - loss: 1347.7456 - acc: 0.9465 - mDice: 0.7603 - val_loss: 1688.6340 - val_acc: 0.9525 - val_mDice: 0.6858

Epoch 00105: val_mDice did not improve from 0.69199
Epoch 106/300
 - 11s - loss: 1345.0761 - acc: 0.9465 - mDice: 0.7606 - val_loss: 1681.3512 - val_acc: 0.9527 - val_mDice: 0.6873

Epoch 00106: val_mDice did not improve from 0.69199
Epoch 107/300
 - 10s - loss: 1334.2257 - acc: 0.9467 - mDice: 0.7623 - val_loss: 1651.8117 - val_acc: 0.9553 - val_mDice: 0.6911

Epoch 00107: val_mDice did not improve from 0.69199
Epoch 108/300
 - 10s - loss: 1337.8390 - acc: 0.9467 - mDice: 0.7618 - val_loss: 1616.3973 - val_acc: 0.9560 - val_mDice: 0.6948

Epoch 00108: val_mDice improved from 0.69199 to 0.69476, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 109/300
 - 11s - loss: 1329.9619 - acc: 0.9469 - mDice: 0.7630 - val_loss: 1817.3948 - val_acc: 0.9529 - val_mDice: 0.6650

Epoch 00109: val_mDice did not improve from 0.69476
Epoch 110/300
 - 10s - loss: 1330.4582 - acc: 0.9468 - mDice: 0.7628 - val_loss: 1679.1342 - val_acc: 0.9515 - val_mDice: 0.6874

Epoch 00110: val_mDice did not improve from 0.69476
Epoch 111/300
 - 11s - loss: 1326.9546 - acc: 0.9469 - mDice: 0.7634 - val_loss: 1719.4887 - val_acc: 0.9493 - val_mDice: 0.6801

Epoch 00111: val_mDice did not improve from 0.69476
Epoch 112/300
 - 10s - loss: 1326.9768 - acc: 0.9469 - mDice: 0.7634 - val_loss: 1793.9058 - val_acc: 0.9477 - val_mDice: 0.6712

Epoch 00112: val_mDice did not improve from 0.69476
Epoch 113/300
 - 10s - loss: 1323.8145 - acc: 0.9469 - mDice: 0.7639 - val_loss: 1903.5176 - val_acc: 0.9457 - val_mDice: 0.6534

Epoch 00113: val_mDice did not improve from 0.69476
Epoch 114/300
 - 11s - loss: 1320.5850 - acc: 0.9470 - mDice: 0.7644 - val_loss: 1667.1786 - val_acc: 0.9533 - val_mDice: 0.6886

Epoch 00114: val_mDice did not improve from 0.69476
Epoch 115/300
 - 9s - loss: 1313.3267 - acc: 0.9471 - mDice: 0.7655 - val_loss: 1801.0258 - val_acc: 0.9475 - val_mDice: 0.6703

Epoch 00115: val_mDice did not improve from 0.69476
Epoch 116/300
 - 10s - loss: 1309.1649 - acc: 0.9471 - mDice: 0.7661 - val_loss: 1864.1823 - val_acc: 0.9431 - val_mDice: 0.6617

Epoch 00116: val_mDice did not improve from 0.69476
Epoch 117/300
 - 10s - loss: 1311.2354 - acc: 0.9472 - mDice: 0.7659 - val_loss: 1729.5016 - val_acc: 0.9518 - val_mDice: 0.6794

Epoch 00117: val_mDice did not improve from 0.69476
Epoch 118/300
 - 10s - loss: 1304.5130 - acc: 0.9472 - mDice: 0.7668 - val_loss: 1863.0811 - val_acc: 0.9497 - val_mDice: 0.6583

Epoch 00118: val_mDice did not improve from 0.69476
Epoch 119/300
 - 11s - loss: 1308.6346 - acc: 0.9473 - mDice: 0.7662 - val_loss: 1868.3811 - val_acc: 0.9423 - val_mDice: 0.6600

Epoch 00119: val_mDice did not improve from 0.69476
Epoch 120/300
 - 10s - loss: 1304.1811 - acc: 0.9473 - mDice: 0.7669 - val_loss: 1709.6081 - val_acc: 0.9537 - val_mDice: 0.6845

Epoch 00120: val_mDice did not improve from 0.69476
Epoch 121/300
 - 10s - loss: 1306.6712 - acc: 0.9473 - mDice: 0.7666 - val_loss: 1900.8528 - val_acc: 0.9492 - val_mDice: 0.6556

Epoch 00121: val_mDice did not improve from 0.69476
Epoch 122/300
 - 10s - loss: 1298.3935 - acc: 0.9474 - mDice: 0.7678 - val_loss: 1737.2080 - val_acc: 0.9548 - val_mDice: 0.6794

Epoch 00122: val_mDice did not improve from 0.69476
Epoch 123/300
 - 10s - loss: 1293.1799 - acc: 0.9475 - mDice: 0.7686 - val_loss: 1774.2796 - val_acc: 0.9537 - val_mDice: 0.6745

Epoch 00123: val_mDice did not improve from 0.69476
Epoch 124/300
 - 11s - loss: 1284.8185 - acc: 0.9475 - mDice: 0.7699 - val_loss: 1640.3391 - val_acc: 0.9559 - val_mDice: 0.6937

Epoch 00124: val_mDice did not improve from 0.69476
Epoch 125/300
 - 10s - loss: 1290.5141 - acc: 0.9475 - mDice: 0.7690 - val_loss: 1632.1973 - val_acc: 0.9559 - val_mDice: 0.6934

Epoch 00125: val_mDice did not improve from 0.69476
Epoch 126/300
 - 11s - loss: 1282.0710 - acc: 0.9477 - mDice: 0.7703 - val_loss: 1649.0372 - val_acc: 0.9543 - val_mDice: 0.6910

Epoch 00126: val_mDice did not improve from 0.69476
Epoch 127/300
 - 10s - loss: 1278.6813 - acc: 0.9477 - mDice: 0.7708 - val_loss: 1732.7338 - val_acc: 0.9511 - val_mDice: 0.6794

Epoch 00127: val_mDice did not improve from 0.69476
Epoch 128/300
 - 11s - loss: 1281.1152 - acc: 0.9477 - mDice: 0.7704 - val_loss: 1682.0645 - val_acc: 0.9531 - val_mDice: 0.6870

Epoch 00128: val_mDice did not improve from 0.69476
Epoch 129/300
 - 10s - loss: 1284.2947 - acc: 0.9476 - mDice: 0.7699 - val_loss: 1848.2444 - val_acc: 0.9512 - val_mDice: 0.6586

Epoch 00129: val_mDice did not improve from 0.69476
Epoch 130/300
 - 10s - loss: 1277.1436 - acc: 0.9478 - mDice: 0.7711 - val_loss: 1730.7775 - val_acc: 0.9515 - val_mDice: 0.6770

Epoch 00130: val_mDice did not improve from 0.69476
Epoch 131/300
 - 10s - loss: 1275.2069 - acc: 0.9478 - mDice: 0.7713 - val_loss: 1760.4370 - val_acc: 0.9540 - val_mDice: 0.6736

Epoch 00131: val_mDice did not improve from 0.69476
Epoch 132/300
 - 10s - loss: 1274.2967 - acc: 0.9478 - mDice: 0.7715 - val_loss: 1704.0071 - val_acc: 0.9530 - val_mDice: 0.6838

Epoch 00132: val_mDice did not improve from 0.69476
Epoch 133/300
 - 10s - loss: 1275.7201 - acc: 0.9478 - mDice: 0.7713 - val_loss: 1722.6327 - val_acc: 0.9546 - val_mDice: 0.6805

Epoch 00133: val_mDice did not improve from 0.69476
Epoch 134/300
 - 9s - loss: 1266.9955 - acc: 0.9479 - mDice: 0.7726 - val_loss: 1765.3894 - val_acc: 0.9548 - val_mDice: 0.6722

Epoch 00134: val_mDice did not improve from 0.69476
Epoch 135/300
 - 10s - loss: 1267.8546 - acc: 0.9480 - mDice: 0.7726 - val_loss: 1678.2727 - val_acc: 0.9550 - val_mDice: 0.6863

Epoch 00135: val_mDice did not improve from 0.69476
Epoch 136/300
 - 10s - loss: 1260.3801 - acc: 0.9480 - mDice: 0.7737 - val_loss: 1637.8183 - val_acc: 0.9544 - val_mDice: 0.6928

Epoch 00136: val_mDice did not improve from 0.69476
Epoch 137/300
 - 10s - loss: 1264.4660 - acc: 0.9480 - mDice: 0.7731 - val_loss: 1730.2068 - val_acc: 0.9541 - val_mDice: 0.6795

Epoch 00137: val_mDice did not improve from 0.69476
Epoch 138/300
 - 11s - loss: 1265.6613 - acc: 0.9480 - mDice: 0.7729 - val_loss: 1683.6327 - val_acc: 0.9548 - val_mDice: 0.6876

Epoch 00138: val_mDice did not improve from 0.69476
Restoring model weights from the end of the best epoch
Epoch 00138: early stopping
{'val_loss': [20425.946800595237, 19089.650785900296, 11445.933268229166, 10738.141531808036, 3880.2592017764136, 3363.5436662946427, 3022.048182896205, 2908.935538155692, 2758.5518304734005, 2785.387233189174, 2686.50985281808, 2630.5231119791665, 2442.1263834635415, 2432.633783249628, 2422.2462390718006, 2483.3379516601562, 2439.248285202753, 2426.1942080543154, 2166.945606050037, 2062.091526576451, 2012.83549281529, 1988.6143246605284, 2051.672569638207, 2156.945722307478, 2015.2777855282739, 2058.394577752976, 1881.7611752464659, 1928.3000953311011, 1982.935334705171, 1852.302022298177, 1916.539562406994, 2204.888875325521, 2016.3323248000372, 2103.6014782133557, 1842.2520984468006, 1785.6295572916667, 1902.1949433826264, 1912.2770298549108, 2228.7729375930057, 2105.5179530552455, 2363.997977120536, 1827.1949724469866, 1901.7155151367188, 1969.7160063244048, 1778.4847644624256, 1889.341064453125, 2553.5267508370534, 1886.936032249814, 1804.8980131603423, 1894.6578252883185, 1723.6070847284227, 1781.381059919085, 1830.080534435454, 1736.6235060918898, 1818.5810488746279, 1790.1187104724702, 1889.799575079055, 1780.759024483817, 1790.0347551618304, 1845.7997174944196, 1722.2025902157739, 1796.9398803710938, 1852.4370960053943, 1899.698962983631, 1718.583987281436, 1748.9479399181548, 1806.041480654762, 1689.2782098679315, 1815.0243966238838, 1709.3440232049852, 1788.8147495814733, 1731.6648210797991, 1823.1220703125, 1690.5245739164807, 1796.3431134905134, 1855.1377534412202, 2355.1346842447915, 1709.0682983398438, 1735.485087076823, 1761.3732154482886, 1765.6636294410341, 1784.0172409784227, 1708.901878720238, 1700.5426374162946, 1643.1651466006324, 1711.8129388718378, 1641.9239414760045, 1694.0332670665923, 1720.4774198986236, 1792.4165416899182, 1719.3478742327009, 1679.2485874720983, 1699.5027523949034, 1787.6815941220239, 1726.5741024925596, 1801.4978201729912, 1695.786164783296, 1683.0074114118304, 1647.316874186198, 1687.5269746326264, 1921.935346330915, 1665.66651843843, 1788.4193841843378, 1676.2083769298736, 1688.634044828869, 1681.3511933826264, 1651.8117414202009, 1616.3973214285713, 1817.394784109933, 1679.1341785249256, 1719.4886648995537, 1793.9057675316221, 1903.517586844308, 1667.1786092122395, 1801.0257742745537, 1864.182341076079, 1729.5015898204986, 1863.081086658296, 1868.381083170573, 1709.6080990745909, 1900.8528209867932, 1737.2080455961682, 1774.2796398344494, 1640.339114234561, 1632.1973295665923, 1649.0372256324404, 1732.7338053385417, 1682.0645490373884, 1848.244416736421, 1730.7774890718006, 1760.4369564964659, 1704.0071178617932, 1722.6327282133557, 1765.3893519810267, 1678.272702171689, 1637.8183070591517, 1730.206772577195, 1683.6327049618676], 'val_acc': [0.8767256197475252, 0.8752418259779612, 0.8814145610446021, 0.8950434937363579, 0.9001416663328806, 0.899451983826501, 0.9105612011182875, 0.9151957531770071, 0.923234319403058, 0.92013076373509, 0.9252045920916966, 0.927193501165935, 0.9345009014720008, 0.9310825892857143, 0.934352118344534, 0.9302584060600826, 0.9364769572303409, 0.9311698504856655, 0.9380294041974204, 0.9391369152636755, 0.9395389783950079, 0.9415622012955802, 0.9381481806437174, 0.9372510356562478, 0.9389422848111108, 0.9408725414957319, 0.9443752950146085, 0.9432978388809022, 0.9410456617673238, 0.9451136120728084, 0.9441348910331726, 0.9322644826911745, 0.9424121507576534, 0.9381767809391022, 0.9476891599950337, 0.9474516141982305, 0.9469937625385466, 0.9469837290900094, 0.9360977382886977, 0.9395933647950491, 0.9300180432342348, 0.9483974434080578, 0.9471067928132557, 0.9407738191740853, 0.9490084321725936, 0.9449962959403083, 0.9277443829036894, 0.943204824413572, 0.9495607018470764, 0.9439102652527037, 0.9501516677084423, 0.9507025565419879, 0.9494562645753225, 0.9513736111777169, 0.9471640359787714, 0.9491700984182811, 0.9477435236885434, 0.951971731015614, 0.9504936252321515, 0.9475589295228323, 0.951247730425426, 0.9492702796345666, 0.9463369874727159, 0.9447974151089078, 0.9508270209743863, 0.9475603799025217, 0.9457174355075473, 0.9539377306188855, 0.9453811759040469, 0.9529532988866171, 0.9487022246633258, 0.9509257759366717, 0.9456000895727248, 0.9522307146163214, 0.9500801350389209, 0.9497624664079576, 0.930418671596618, 0.9524066944917043, 0.9551425249803633, 0.9518415232499441, 0.9516755498590923, 0.944939041421527, 0.9512162378856114, 0.954328369526636, 0.9538203804265886, 0.9537030600366139, 0.9542181548618135, 0.9495592826888675, 0.9529132317929041, 0.9499885411489577, 0.9533210396766663, 0.9539033813135964, 0.9542839910302844, 0.9512748845985958, 0.9520289571512313, 0.9448331566083998, 0.9517442215056646, 0.9525669444174993, 0.9538461736270359, 0.9557692380178542, 0.9428556859493256, 0.9530534545580546, 0.9489683437915075, 0.9535470888728187, 0.9525412136600131, 0.9526513871692476, 0.955288461276463, 0.9560425182183584, 0.9529375618412381, 0.9514766420636859, 0.9493031643685841, 0.9477163652578989, 0.9456702186947777, 0.9533439221836272, 0.9475475109758831, 0.9431161128339314, 0.9518128874756041, 0.9496566085588365, 0.9423248611745381, 0.9537145012900943, 0.9492001590274629, 0.9547862495694842, 0.9536572737353188, 0.9558651262805575, 0.9559008819716317, 0.9542868634064993, 0.9510974557626815, 0.9531164226077852, 0.951233392670041, 0.9514537467843011, 0.9539706522510165, 0.9529719026315779, 0.9545816069557553, 0.9547776650814783, 0.9550051405316308, 0.9544299415179661, 0.954149508760089, 0.9548148385116032], 'val_mDice': [0.2203499082298506, 0.27054206814084736, 0.35182708288942066, 0.41638504678294774, 0.4386688612756275, 0.48430346165384563, 0.5198879880564553, 0.5373471904368627, 0.5563322248912993, 0.5545397840795063, 0.56511719028155, 0.5729537975220453, 0.5940292420841399, 0.5922998899505252, 0.5946443478266398, 0.5902900709992364, 0.5959221522013346, 0.5916555637405032, 0.6199538977373213, 0.6317604609898159, 0.6370724113214583, 0.6405449381896428, 0.6335106577192035, 0.6217477151325771, 0.6392873852025895, 0.6340287412915911, 0.6560605693431127, 0.6492572724819183, 0.6429226597150167, 0.6580109241462889, 0.6510076735700879, 0.61517200867335, 0.6414573873792376, 0.6263743511268071, 0.6615637512434096, 0.6687230879352206, 0.6523748948460534, 0.6536617804141271, 0.6149233764126187, 0.6306937620753333, 0.5951146369888669, 0.6641153608049665, 0.6553933677219209, 0.6449881820451646, 0.6721289853254954, 0.6574712495009104, 0.5755089507216499, 0.6562322165284838, 0.6688179515656971, 0.6569564030283973, 0.6802318748973665, 0.6728162282989139, 0.665481394245511, 0.6788030437060765, 0.6672277862117404, 0.6712556197529748, 0.6584889420441219, 0.6738264929680597, 0.6713365969203767, 0.6630623269648779, 0.6801485064483824, 0.6714102228482565, 0.6631969483125777, 0.656446879818326, 0.6810167673088255, 0.6758845987774077, 0.6677011379173824, 0.6852198782421294, 0.6666159374373299, 0.6817723257201058, 0.6714591469083514, 0.6793107106572106, 0.6652926263355073, 0.6838227368536449, 0.6721932519049871, 0.6646769940853119, 0.5959010124206543, 0.6820200582345327, 0.6797160506248474, 0.6771072773706346, 0.6756866460754758, 0.6709665060043335, 0.6820107613291059, 0.683476345879691, 0.6919921012151808, 0.6831777237710499, 0.6919698190121424, 0.6843323068959373, 0.6818644177346003, 0.6708780456156958, 0.6812125430220649, 0.6854321459929148, 0.682776479494004, 0.6708056018466041, 0.6818251027947381, 0.66774425194377, 0.6838483796233222, 0.6852241825489771, 0.691024131718136, 0.685772024449848, 0.6521581595852262, 0.6888599977606819, 0.670931454215731, 0.6864329335235414, 0.685822205884116, 0.687253794499806, 0.691070515485037, 0.6947601508526575, 0.6649953112715766, 0.6874223096030099, 0.6801006822358995, 0.6712192396322886, 0.653402505885987, 0.6886175175507864, 0.6703404798394158, 0.6616599474634443, 0.6794328916640509, 0.6582834834144229, 0.6600295730999538, 0.6844853943302518, 0.6556248806771778, 0.6794287675902957, 0.6745181779066721, 0.6937309503555298, 0.6933898216202146, 0.6909969718683333, 0.6793956614675976, 0.6869828757785615, 0.6585768972124372, 0.6770198997997102, 0.6735616354715257, 0.6838343611785344, 0.6804965223584857, 0.6722075683729989, 0.6862974379743848, 0.692843442871457, 0.6794638406662714, 0.6876442829767863], 'loss': [23093.347932354172, 15585.396368088568, 14224.625301370597, 13182.055273802798, 8737.805374716285, 4819.661783499017, 4226.195794008022, 3872.48542134958, 3646.711124638964, 3446.3394904005854, 3298.422180708507, 3175.1212015128194, 3057.7424499055096, 2964.080473027027, 2862.6575256499864, 2792.9720270247235, 2724.7275465206612, 2655.868958508879, 2584.451207491525, 2522.281801066791, 2455.14043588234, 2404.7193268659407, 2343.8106467991397, 2308.464957905529, 2271.4472245290094, 2229.7715356308327, 2193.7287846134786, 2168.470376792394, 2131.4564992852343, 2106.0967951748435, 2080.5481894248146, 2055.07529668261, 2018.8757466532643, 2008.8685377696506, 1991.8051440840648, 1967.7028491241379, 1948.938755101991, 1924.1527148315733, 1911.1895381328175, 1887.5514729944548, 1874.688004757698, 1851.1379291791275, 1835.0551662302373, 1815.8268067700012, 1793.3765006124825, 1789.2044449042799, 1769.4034811576405, 1766.7942925736197, 1745.598440117967, 1730.4417594472072, 1719.0813069331675, 1699.8404851518665, 1680.7984926218999, 1671.2730306496942, 1660.146464017264, 1646.2314880447198, 1643.61561158292, 1619.9149731947598, 1618.266282535848, 1613.433420614114, 1589.5934495426472, 1598.3330961308277, 1589.030135994243, 1571.8272963830657, 1562.1389692882053, 1557.03509369277, 1542.2920268527291, 1534.8173714730508, 1530.915958166717, 1516.8482666776663, 1518.0221310660727, 1508.6093799847915, 1507.5612915115166, 1496.8809157678313, 1492.111026982714, 1480.8106627428622, 1475.2913705725919, 1466.4996345881511, 1464.6563230975905, 1463.1857828725306, 1444.2713894356516, 1445.1199521947085, 1435.3973102141497, 1439.2584766568687, 1437.643914467676, 1426.8981811066815, 1421.3853944697582, 1417.7114980417, 1415.5005489358878, 1413.9910692704884, 1399.9343473286997, 1393.1292616542141, 1400.9283114311997, 1392.0093264306274, 1382.487141521197, 1377.143574284199, 1368.9853119505315, 1370.9826399120607, 1364.4996780814079, 1360.8492399296558, 1358.6745357751252, 1361.023310673207, 1361.2135795916702, 1348.9975537992177, 1347.745576625453, 1345.0761223315003, 1334.2257464021222, 1337.8389798590072, 1329.9619275328525, 1330.45817463178, 1326.9546239001495, 1326.9768369679439, 1323.8144796851864, 1320.584975473304, 1313.3267334060479, 1309.164885104743, 1311.235360999357, 1304.5129536464624, 1308.634618935145, 1304.1811330895175, 1306.6712211932327, 1298.3935319705497, 1293.1799152783326, 1284.8185350984113, 1290.514119440778, 1282.0709509718745, 1278.681274033544, 1281.1152139411604, 1284.2947307786442, 1277.143646126079, 1275.20693813714, 1274.2966816966373, 1275.72009654057, 1266.995515780556, 1267.85461874793, 1260.3801134447208, 1264.4660303206217, 1265.6613095633109], 'acc': [0.8626328750775937, 0.872826274660906, 0.8820732306140914, 0.891296698435435, 0.8916436533566722, 0.8969153323747273, 0.9034921536198876, 0.9079686807389569, 0.9110476346012958, 0.913995810354737, 0.9163046583458967, 0.9182324773467092, 0.9200416924315795, 0.9214172536632664, 0.9226473118190159, 0.9238516753005268, 0.9250139927774891, 0.9260923335714233, 0.9268323708873735, 0.9276548498437887, 0.928381871720056, 0.9289389006477639, 0.929858810716585, 0.930338891162688, 0.9309103465139718, 0.9314811136434203, 0.9319342494642645, 0.9324614752706447, 0.9329671959887419, 0.9334655053486254, 0.9337545174761603, 0.9342524648232947, 0.9348971701396671, 0.9351998224594349, 0.9353690780606353, 0.9358158279721279, 0.936129029961001, 0.9365314344998606, 0.9369795527727229, 0.9372735370572963, 0.9374839452994137, 0.9379045436915912, 0.938087585728216, 0.9385031821238727, 0.9387803965636025, 0.9390275412961432, 0.939324876744105, 0.9394197444666056, 0.939789367807179, 0.9399174462232803, 0.9402180776148663, 0.9406854528144113, 0.9408396994718292, 0.9411467172372668, 0.9413143272263154, 0.9414922338805889, 0.9415209132091066, 0.9418774105589883, 0.94194857703703, 0.9420565342590993, 0.9424410938770694, 0.9423131832941215, 0.942468723509823, 0.9429237159187359, 0.9430573389417215, 0.9431512856721284, 0.943354544478313, 0.9435033235986928, 0.9435257666611909, 0.9436397927992064, 0.9436900158438302, 0.9439009120153667, 0.943734635791725, 0.9439087085741714, 0.9441249995234601, 0.9442802417530978, 0.9443099536837782, 0.9444779735662396, 0.9446041768514307, 0.9445791879757087, 0.9447201375392013, 0.9448434947583444, 0.9448945418074541, 0.944941471100894, 0.9450022743415654, 0.9452044252408413, 0.9451917482173057, 0.9452931856796926, 0.9453665063231068, 0.9454540656577619, 0.9455720868862775, 0.9456725905363697, 0.945600975295552, 0.9458404589918189, 0.9459025774922157, 0.9461569572030161, 0.946009149723814, 0.9461172991931587, 0.9462769231259675, 0.9463856123071953, 0.9464890768291647, 0.9463722200836624, 0.9462764741402314, 0.9465379349311391, 0.9464653393722829, 0.9464821843546525, 0.9467189357502205, 0.9467261652287997, 0.9469119024061206, 0.946832737348918, 0.9469462608978932, 0.9468997437646264, 0.9468799495043005, 0.9469987898321818, 0.9471386686859286, 0.9471357512912548, 0.947211242469023, 0.9472208341532514, 0.9472983304662003, 0.9473349565356747, 0.9472863447302, 0.9473812886678667, 0.9475028227986838, 0.9475414329336171, 0.9475225141258014, 0.9476902907217233, 0.9477249844524629, 0.9477067189732394, 0.9475755467639302, 0.9478240248716977, 0.9477652965712726, 0.9478262169031134, 0.9478287608769171, 0.9479092615946867, 0.9479508119962756, 0.9480252756256415, 0.9480101383869487, 0.9480181015154667], 'mDice': [0.12626724483148008, 0.22445696490605424, 0.27981157639433174, 0.3397561962765054, 0.3523763259059919, 0.39970567643159344, 0.44103549860250624, 0.4708239448876898, 0.49127277495000427, 0.5106199066853732, 0.525371502815488, 0.5375991997650437, 0.5497114939842735, 0.5596034803666974, 0.5702373064366957, 0.5775548563968214, 0.5849317880788646, 0.5920351907759533, 0.599200438828837, 0.6054968967327751, 0.6129515990429091, 0.6183399352015105, 0.6253305302556613, 0.6295638126030825, 0.6338754581320019, 0.6387935327621469, 0.6432748910160433, 0.6463300096163725, 0.6512149761516852, 0.654174092850483, 0.6574643903279542, 0.6606968506761917, 0.6654347954805653, 0.6669118270426617, 0.6690154915067026, 0.6723835192750814, 0.6747130809207806, 0.6781960093878451, 0.6799337590610297, 0.6831187622579851, 0.6846796116998368, 0.6878864335040202, 0.69010179409957, 0.6927601158098687, 0.6957268330112955, 0.6964767026224933, 0.6991093798059775, 0.699607527984348, 0.7023440208889897, 0.7044207221663503, 0.706109144796903, 0.7087873046349111, 0.7113467628261693, 0.7127836965340332, 0.714273052285437, 0.7162425397080079, 0.7166652980067784, 0.7199682594274642, 0.7203492015563044, 0.7209514128299722, 0.724424710501905, 0.7232287506807474, 0.7245384754236797, 0.7270246449848661, 0.7283789572535905, 0.7291470485881082, 0.7313077034163951, 0.7323422769730228, 0.7329563679094624, 0.734967515745811, 0.7348531790430707, 0.7361473638071978, 0.7364598535317138, 0.737885033028976, 0.7386933198184741, 0.7404132419988104, 0.7412058894064956, 0.742570125291175, 0.7427809069913225, 0.7430127552173976, 0.7457714895543612, 0.7456769304642653, 0.7470177924469522, 0.7465144101892623, 0.7467702904953029, 0.748381532264172, 0.7491486969396955, 0.7497034700694227, 0.7501169269407479, 0.7509325848070166, 0.7524880839144797, 0.7534559710216047, 0.7522214414955969, 0.753588205319539, 0.7549944893826273, 0.7558570381003128, 0.7570044732004627, 0.7567579756651138, 0.7577531773067472, 0.7582470280422534, 0.7586179355396296, 0.7582267104947656, 0.7582030025429262, 0.7600447693630644, 0.760331729050735, 0.7606496953421698, 0.7623001281311387, 0.7617758840619775, 0.7629918361319568, 0.7628114857987276, 0.7634342593928227, 0.7634276814034158, 0.7638706123442424, 0.7643646767683457, 0.7654883574109125, 0.7661104173471506, 0.7658714183288025, 0.7668424613235003, 0.7661929321370815, 0.7669336248440041, 0.7666010033534352, 0.7677756783893875, 0.7686366029919829, 0.7698924142932356, 0.7690226942152156, 0.7703164624900295, 0.770758779937787, 0.7704185286996668, 0.7699239807310247, 0.7710813206627481, 0.7713488223881199, 0.7715215274037566, 0.7713447194964511, 0.772576954225055, 0.7725713253392841, 0.7737102298590905, 0.7731131584827144, 0.7728906263437058]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:46, 15.47s/it]predicting test subjects:  50%|█████     | 2/4 [00:29<00:30, 15.01s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:44<00:15, 15.07s/it]predicting test subjects: 100%|██████████| 4/4 [00:59<00:00, 14.96s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:22<1:54:38, 22.19s/it]predicting train subjects:   1%|          | 2/311 [00:33<1:36:54, 18.82s/it]predicting train subjects:   1%|          | 3/311 [00:46<1:28:03, 17.15s/it]predicting train subjects:   1%|▏         | 4/311 [00:59<1:20:57, 15.82s/it]predicting train subjects:   2%|▏         | 5/311 [01:10<1:14:06, 14.53s/it]predicting train subjects:   2%|▏         | 6/311 [01:22<1:09:35, 13.69s/it]predicting train subjects:   2%|▏         | 7/311 [01:36<1:09:16, 13.67s/it]predicting train subjects:   3%|▎         | 8/311 [01:51<1:12:04, 14.27s/it]predicting train subjects:   3%|▎         | 9/311 [02:05<1:11:01, 14.11s/it]predicting train subjects:   3%|▎         | 10/311 [02:19<1:10:30, 14.06s/it]predicting train subjects:   4%|▎         | 11/311 [02:38<1:18:34, 15.71s/it]predicting train subjects:   4%|▍         | 12/311 [02:53<1:15:59, 15.25s/it]predicting train subjects:   4%|▍         | 13/311 [03:07<1:14:35, 15.02s/it]predicting train subjects:   5%|▍         | 14/311 [03:26<1:20:15, 16.21s/it]predicting train subjects:   5%|▍         | 15/311 [03:54<1:37:12, 19.70s/it]predicting train subjects:   5%|▌         | 16/311 [04:21<1:47:12, 21.81s/it]predicting train subjects:   5%|▌         | 17/311 [04:47<1:53:22, 23.14s/it]predicting train subjects:   6%|▌         | 18/311 [05:14<1:58:40, 24.30s/it]predicting train subjects:   6%|▌         | 19/311 [05:41<2:02:12, 25.11s/it]predicting train subjects:   6%|▋         | 20/311 [06:08<2:04:24, 25.65s/it]predicting train subjects:   7%|▋         | 21/311 [06:34<2:04:50, 25.83s/it]predicting train subjects:   7%|▋         | 22/311 [07:00<2:03:54, 25.73s/it]predicting train subjects:   7%|▋         | 23/311 [07:27<2:06:04, 26.27s/it]predicting train subjects:   8%|▊         | 24/311 [07:54<2:06:01, 26.35s/it]predicting train subjects:   8%|▊         | 25/311 [08:21<2:06:51, 26.61s/it]predicting train subjects:   8%|▊         | 26/311 [08:47<2:05:42, 26.46s/it]predicting train subjects:   9%|▊         | 27/311 [09:14<2:06:34, 26.74s/it]predicting train subjects:   9%|▉         | 28/311 [09:41<2:06:19, 26.78s/it]predicting train subjects:   9%|▉         | 29/311 [10:06<2:02:50, 26.14s/it]predicting train subjects:  10%|▉         | 30/311 [10:33<2:04:21, 26.55s/it]predicting train subjects:  10%|▉         | 31/311 [10:59<2:02:12, 26.19s/it]predicting train subjects:  10%|█         | 32/311 [11:20<1:55:26, 24.83s/it]predicting train subjects:  11%|█         | 33/311 [11:31<1:35:13, 20.55s/it]predicting train subjects:  11%|█         | 34/311 [11:41<1:21:01, 17.55s/it]predicting train subjects:  11%|█▏        | 35/311 [11:52<1:10:42, 15.37s/it]predicting train subjects:  12%|█▏        | 36/311 [12:02<1:03:11, 13.79s/it]predicting train subjects:  12%|█▏        | 37/311 [12:12<58:23, 12.78s/it]  predicting train subjects:  12%|█▏        | 38/311 [12:23<55:04, 12.11s/it]predicting train subjects:  13%|█▎        | 39/311 [12:33<52:26, 11.57s/it]predicting train subjects:  13%|█▎        | 40/311 [12:43<50:09, 11.10s/it]predicting train subjects:  13%|█▎        | 41/311 [12:54<49:05, 10.91s/it]predicting train subjects:  14%|█▎        | 42/311 [13:04<48:09, 10.74s/it]predicting train subjects:  14%|█▍        | 43/311 [13:14<47:14, 10.58s/it]predicting train subjects:  14%|█▍        | 44/311 [13:24<46:38, 10.48s/it]predicting train subjects:  14%|█▍        | 45/311 [13:35<46:46, 10.55s/it]predicting train subjects:  15%|█▍        | 46/311 [13:46<47:30, 10.75s/it]predicting train subjects:  15%|█▌        | 47/311 [13:57<47:08, 10.71s/it]predicting train subjects:  15%|█▌        | 48/311 [14:07<46:05, 10.52s/it]predicting train subjects:  16%|█▌        | 49/311 [14:17<45:36, 10.44s/it]predicting train subjects:  16%|█▌        | 50/311 [14:28<46:09, 10.61s/it]predicting train subjects:  16%|█▋        | 51/311 [14:41<49:17, 11.38s/it]predicting train subjects:  17%|█▋        | 52/311 [14:55<51:27, 11.92s/it]predicting train subjects:  17%|█▋        | 53/311 [15:08<53:06, 12.35s/it]predicting train subjects:  17%|█▋        | 54/311 [15:22<54:53, 12.81s/it]predicting train subjects:  18%|█▊        | 55/311 [15:35<55:04, 12.91s/it]predicting train subjects:  18%|█▊        | 56/311 [15:48<55:16, 13.01s/it]predicting train subjects:  18%|█▊        | 57/311 [16:02<56:14, 13.29s/it]predicting train subjects:  19%|█▊        | 58/311 [16:15<55:50, 13.24s/it]predicting train subjects:  19%|█▉        | 59/311 [16:29<55:57, 13.32s/it]predicting train subjects:  19%|█▉        | 60/311 [16:42<55:14, 13.20s/it]predicting train subjects:  20%|█▉        | 61/311 [16:54<54:23, 13.06s/it]predicting train subjects:  20%|█▉        | 62/311 [17:08<54:12, 13.06s/it]predicting train subjects:  20%|██        | 63/311 [17:21<54:03, 13.08s/it]predicting train subjects:  21%|██        | 64/311 [17:34<53:53, 13.09s/it]predicting train subjects:  21%|██        | 65/311 [17:47<53:41, 13.10s/it]predicting train subjects:  21%|██        | 66/311 [18:00<53:23, 13.08s/it]predicting train subjects:  22%|██▏       | 67/311 [18:14<53:46, 13.22s/it]predicting train subjects:  22%|██▏       | 68/311 [18:26<52:54, 13.06s/it]predicting train subjects:  22%|██▏       | 69/311 [18:39<52:09, 12.93s/it]predicting train subjects:  23%|██▎       | 70/311 [18:52<52:23, 13.04s/it]predicting train subjects:  23%|██▎       | 71/311 [19:05<51:39, 12.91s/it]predicting train subjects:  23%|██▎       | 72/311 [19:17<51:09, 12.84s/it]predicting train subjects:  23%|██▎       | 73/311 [19:30<50:50, 12.82s/it]predicting train subjects:  24%|██▍       | 74/311 [19:43<50:21, 12.75s/it]predicting train subjects:  24%|██▍       | 75/311 [19:56<50:23, 12.81s/it]predicting train subjects:  24%|██▍       | 76/311 [20:09<50:08, 12.80s/it]predicting train subjects:  25%|██▍       | 77/311 [20:21<49:51, 12.78s/it]predicting train subjects:  25%|██▌       | 78/311 [20:34<49:37, 12.78s/it]predicting train subjects:  25%|██▌       | 79/311 [20:47<49:31, 12.81s/it]predicting train subjects:  26%|██▌       | 80/311 [20:59<49:02, 12.74s/it]predicting train subjects:  26%|██▌       | 81/311 [21:13<49:37, 12.94s/it]predicting train subjects:  26%|██▋       | 82/311 [21:26<49:09, 12.88s/it]predicting train subjects:  27%|██▋       | 83/311 [21:38<48:35, 12.79s/it]predicting train subjects:  27%|██▋       | 84/311 [21:51<48:07, 12.72s/it]predicting train subjects:  27%|██▋       | 85/311 [22:03<47:31, 12.62s/it]predicting train subjects:  28%|██▊       | 86/311 [22:15<46:03, 12.28s/it]predicting train subjects:  28%|██▊       | 87/311 [22:26<44:25, 11.90s/it]predicting train subjects:  28%|██▊       | 88/311 [22:37<44:04, 11.86s/it]predicting train subjects:  29%|██▊       | 89/311 [22:49<43:34, 11.78s/it]predicting train subjects:  29%|██▉       | 90/311 [23:01<43:23, 11.78s/it]predicting train subjects:  29%|██▉       | 91/311 [23:12<42:39, 11.64s/it]predicting train subjects:  30%|██▉       | 92/311 [23:23<42:13, 11.57s/it]predicting train subjects:  30%|██▉       | 93/311 [23:35<42:27, 11.69s/it]predicting train subjects:  30%|███       | 94/311 [23:47<42:19, 11.70s/it]predicting train subjects:  31%|███       | 95/311 [23:59<42:01, 11.67s/it]predicting train subjects:  31%|███       | 96/311 [24:10<41:20, 11.54s/it]predicting train subjects:  31%|███       | 97/311 [24:22<41:25, 11.61s/it]predicting train subjects:  32%|███▏      | 98/311 [24:34<41:34, 11.71s/it]predicting train subjects:  32%|███▏      | 99/311 [24:45<41:05, 11.63s/it]predicting train subjects:  32%|███▏      | 100/311 [24:57<40:51, 11.62s/it]predicting train subjects:  32%|███▏      | 101/311 [25:09<41:01, 11.72s/it]predicting train subjects:  33%|███▎      | 102/311 [25:20<40:39, 11.67s/it]predicting train subjects:  33%|███▎      | 103/311 [25:32<40:51, 11.79s/it]predicting train subjects:  33%|███▎      | 104/311 [25:44<40:44, 11.81s/it]predicting train subjects:  34%|███▍      | 105/311 [25:56<40:44, 11.87s/it]predicting train subjects:  34%|███▍      | 106/311 [26:08<40:19, 11.80s/it]predicting train subjects:  34%|███▍      | 107/311 [26:20<40:17, 11.85s/it]predicting train subjects:  35%|███▍      | 108/311 [26:32<40:19, 11.92s/it]predicting train subjects:  35%|███▌      | 109/311 [26:44<40:01, 11.89s/it]predicting train subjects:  35%|███▌      | 110/311 [26:55<39:28, 11.78s/it]predicting train subjects:  36%|███▌      | 111/311 [27:07<39:21, 11.81s/it]predicting train subjects:  36%|███▌      | 112/311 [27:19<39:06, 11.79s/it]predicting train subjects:  36%|███▋      | 113/311 [27:31<39:00, 11.82s/it]predicting train subjects:  37%|███▋      | 114/311 [27:53<49:02, 14.94s/it]predicting train subjects:  37%|███▋      | 115/311 [28:16<56:17, 17.23s/it]predicting train subjects:  37%|███▋      | 116/311 [28:38<1:00:45, 18.69s/it]predicting train subjects:  38%|███▊      | 117/311 [29:00<1:03:43, 19.71s/it]predicting train subjects:  38%|███▊      | 118/311 [29:23<1:06:22, 20.64s/it]predicting train subjects:  38%|███▊      | 119/311 [29:45<1:07:20, 21.05s/it]predicting train subjects:  39%|███▊      | 120/311 [30:07<1:08:25, 21.49s/it]predicting train subjects:  39%|███▉      | 121/311 [30:30<1:09:28, 21.94s/it]predicting train subjects:  39%|███▉      | 122/311 [30:52<1:09:25, 22.04s/it]predicting train subjects:  40%|███▉      | 123/311 [31:15<1:09:59, 22.34s/it]predicting train subjects:  40%|███▉      | 124/311 [31:38<1:09:54, 22.43s/it]predicting train subjects:  40%|████      | 125/311 [32:00<1:09:04, 22.28s/it]predicting train subjects:  41%|████      | 126/311 [32:22<1:08:23, 22.18s/it]predicting train subjects:  41%|████      | 127/311 [32:44<1:08:08, 22.22s/it]predicting train subjects:  41%|████      | 128/311 [33:07<1:08:03, 22.31s/it]predicting train subjects:  41%|████▏     | 129/311 [33:29<1:07:30, 22.26s/it]predicting train subjects:  42%|████▏     | 130/311 [33:51<1:06:45, 22.13s/it]predicting train subjects:  42%|████▏     | 131/311 [34:13<1:06:12, 22.07s/it]predicting train subjects:  42%|████▏     | 132/311 [34:23<55:34, 18.63s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:33<47:45, 16.10s/it]predicting train subjects:  43%|████▎     | 134/311 [34:44<42:10, 14.30s/it]predicting train subjects:  43%|████▎     | 135/311 [34:54<38:38, 13.17s/it]predicting train subjects:  44%|████▎     | 136/311 [35:05<36:03, 12.36s/it]predicting train subjects:  44%|████▍     | 137/311 [35:15<33:49, 11.67s/it]predicting train subjects:  44%|████▍     | 138/311 [35:25<32:33, 11.29s/it]predicting train subjects:  45%|████▍     | 139/311 [35:36<31:52, 11.12s/it]predicting train subjects:  45%|████▌     | 140/311 [35:47<31:41, 11.12s/it]predicting train subjects:  45%|████▌     | 141/311 [35:57<30:41, 10.83s/it]predicting train subjects:  46%|████▌     | 142/311 [36:07<30:12, 10.72s/it]predicting train subjects:  46%|████▌     | 143/311 [36:18<30:01, 10.72s/it]predicting train subjects:  46%|████▋     | 144/311 [36:29<30:11, 10.85s/it]predicting train subjects:  47%|████▋     | 145/311 [36:39<29:23, 10.63s/it]predicting train subjects:  47%|████▋     | 146/311 [36:50<29:09, 10.60s/it]predicting train subjects:  47%|████▋     | 147/311 [37:01<29:06, 10.65s/it]predicting train subjects:  48%|████▊     | 148/311 [37:11<28:52, 10.63s/it]predicting train subjects:  48%|████▊     | 149/311 [37:21<28:14, 10.46s/it]predicting train subjects:  48%|████▊     | 150/311 [37:34<30:11, 11.25s/it]predicting train subjects:  49%|████▊     | 151/311 [37:48<31:33, 11.83s/it]predicting train subjects:  49%|████▉     | 152/311 [38:01<32:28, 12.25s/it]predicting train subjects:  49%|████▉     | 153/311 [38:14<33:08, 12.58s/it]predicting train subjects:  50%|████▉     | 154/311 [38:27<33:23, 12.76s/it]predicting train subjects:  50%|████▉     | 155/311 [38:40<33:23, 12.84s/it]predicting train subjects:  50%|█████     | 156/311 [38:53<33:17, 12.89s/it]predicting train subjects:  50%|█████     | 157/311 [39:06<33:05, 12.90s/it]predicting train subjects:  51%|█████     | 158/311 [39:20<33:04, 12.97s/it]predicting train subjects:  51%|█████     | 159/311 [39:34<33:42, 13.30s/it]predicting train subjects:  51%|█████▏    | 160/311 [39:47<33:21, 13.26s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:00<33:04, 13.23s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:14<33:24, 13.45s/it]predicting train subjects:  52%|█████▏    | 163/311 [40:27<32:58, 13.37s/it]predicting train subjects:  53%|█████▎    | 164/311 [40:40<32:39, 13.33s/it]predicting train subjects:  53%|█████▎    | 165/311 [40:54<32:39, 13.42s/it]predicting train subjects:  53%|█████▎    | 166/311 [41:07<31:53, 13.20s/it]predicting train subjects:  54%|█████▎    | 167/311 [41:19<31:11, 12.99s/it]predicting train subjects:  54%|█████▍    | 168/311 [41:32<30:43, 12.89s/it]predicting train subjects:  54%|█████▍    | 169/311 [41:45<31:03, 13.12s/it]predicting train subjects:  55%|█████▍    | 170/311 [41:58<30:39, 13.04s/it]predicting train subjects:  55%|█████▍    | 171/311 [42:11<30:14, 12.96s/it]predicting train subjects:  55%|█████▌    | 172/311 [42:24<30:00, 12.95s/it]predicting train subjects:  56%|█████▌    | 173/311 [42:37<29:42, 12.92s/it]predicting train subjects:  56%|█████▌    | 174/311 [42:50<29:25, 12.89s/it]predicting train subjects:  56%|█████▋    | 175/311 [43:03<29:14, 12.90s/it]predicting train subjects:  57%|█████▋    | 176/311 [43:15<28:49, 12.81s/it]predicting train subjects:  57%|█████▋    | 177/311 [43:27<28:08, 12.60s/it]predicting train subjects:  57%|█████▋    | 178/311 [43:40<28:04, 12.67s/it]predicting train subjects:  58%|█████▊    | 179/311 [43:54<28:31, 12.96s/it]predicting train subjects:  58%|█████▊    | 180/311 [44:07<28:14, 12.94s/it]predicting train subjects:  58%|█████▊    | 181/311 [44:19<27:58, 12.91s/it]predicting train subjects:  59%|█████▊    | 182/311 [44:32<27:41, 12.88s/it]predicting train subjects:  59%|█████▉    | 183/311 [44:45<27:21, 12.82s/it]predicting train subjects:  59%|█████▉    | 184/311 [44:56<26:12, 12.39s/it]predicting train subjects:  59%|█████▉    | 185/311 [45:08<25:26, 12.12s/it]predicting train subjects:  60%|█████▉    | 186/311 [45:20<25:02, 12.02s/it]predicting train subjects:  60%|██████    | 187/311 [45:32<24:47, 12.00s/it]predicting train subjects:  60%|██████    | 188/311 [45:43<24:22, 11.89s/it]predicting train subjects:  61%|██████    | 189/311 [45:54<23:46, 11.69s/it]predicting train subjects:  61%|██████    | 190/311 [46:07<23:54, 11.86s/it]predicting train subjects:  61%|██████▏   | 191/311 [46:19<23:41, 11.85s/it]predicting train subjects:  62%|██████▏   | 192/311 [46:30<23:27, 11.83s/it]predicting train subjects:  62%|██████▏   | 193/311 [46:42<23:10, 11.79s/it]predicting train subjects:  62%|██████▏   | 194/311 [46:54<23:05, 11.84s/it]predicting train subjects:  63%|██████▎   | 195/311 [47:05<22:35, 11.68s/it]predicting train subjects:  63%|██████▎   | 196/311 [47:17<22:27, 11.71s/it]predicting train subjects:  63%|██████▎   | 197/311 [47:29<22:13, 11.70s/it]predicting train subjects:  64%|██████▎   | 198/311 [47:40<21:50, 11.60s/it]predicting train subjects:  64%|██████▍   | 199/311 [47:51<21:28, 11.50s/it]predicting train subjects:  64%|██████▍   | 200/311 [48:03<21:23, 11.56s/it]predicting train subjects:  65%|██████▍   | 201/311 [48:15<21:19, 11.63s/it]predicting train subjects:  65%|██████▍   | 202/311 [48:27<21:12, 11.67s/it]predicting train subjects:  65%|██████▌   | 203/311 [48:38<20:52, 11.59s/it]predicting train subjects:  66%|██████▌   | 204/311 [48:49<20:32, 11.52s/it]predicting train subjects:  66%|██████▌   | 205/311 [49:01<20:29, 11.60s/it]predicting train subjects:  66%|██████▌   | 206/311 [49:13<20:30, 11.72s/it]predicting train subjects:  67%|██████▋   | 207/311 [49:25<20:25, 11.79s/it]predicting train subjects:  67%|██████▋   | 208/311 [49:36<19:57, 11.62s/it]predicting train subjects:  67%|██████▋   | 209/311 [49:48<19:44, 11.61s/it]predicting train subjects:  68%|██████▊   | 210/311 [50:00<19:37, 11.65s/it]predicting train subjects:  68%|██████▊   | 211/311 [50:11<19:21, 11.61s/it]predicting train subjects:  68%|██████▊   | 212/311 [50:22<18:50, 11.42s/it]predicting train subjects:  68%|██████▊   | 213/311 [50:44<23:46, 14.56s/it]predicting train subjects:  69%|██████▉   | 214/311 [51:06<26:52, 16.63s/it]predicting train subjects:  69%|██████▉   | 215/311 [51:28<29:24, 18.38s/it]predicting train subjects:  69%|██████▉   | 216/311 [51:50<30:38, 19.35s/it]predicting train subjects:  70%|██████▉   | 217/311 [52:12<31:46, 20.28s/it]predicting train subjects:  70%|███████   | 218/311 [52:34<32:02, 20.67s/it]predicting train subjects:  70%|███████   | 219/311 [52:56<32:29, 21.19s/it]predicting train subjects:  71%|███████   | 220/311 [53:18<32:19, 21.31s/it]predicting train subjects:  71%|███████   | 221/311 [53:39<32:11, 21.46s/it]predicting train subjects:  71%|███████▏  | 222/311 [54:02<32:19, 21.79s/it]predicting train subjects:  72%|███████▏  | 223/311 [54:24<31:52, 21.74s/it]predicting train subjects:  72%|███████▏  | 224/311 [54:46<31:49, 21.95s/it]predicting train subjects:  72%|███████▏  | 225/311 [55:09<31:49, 22.21s/it]predicting train subjects:  73%|███████▎  | 226/311 [55:31<31:35, 22.30s/it]predicting train subjects:  73%|███████▎  | 227/311 [55:53<31:02, 22.17s/it]predicting train subjects:  73%|███████▎  | 228/311 [56:16<30:56, 22.36s/it]predicting train subjects:  74%|███████▎  | 229/311 [56:39<30:39, 22.44s/it]predicting train subjects:  74%|███████▍  | 230/311 [57:00<29:59, 22.22s/it]predicting train subjects:  74%|███████▍  | 231/311 [57:11<24:58, 18.74s/it]predicting train subjects:  75%|███████▍  | 232/311 [57:21<21:16, 16.16s/it]predicting train subjects:  75%|███████▍  | 233/311 [57:31<18:43, 14.40s/it]predicting train subjects:  75%|███████▌  | 234/311 [57:42<16:58, 13.23s/it]predicting train subjects:  76%|███████▌  | 235/311 [57:52<15:39, 12.36s/it]predicting train subjects:  76%|███████▌  | 236/311 [58:02<14:34, 11.66s/it]predicting train subjects:  76%|███████▌  | 237/311 [58:13<14:02, 11.39s/it]predicting train subjects:  77%|███████▋  | 238/311 [58:24<13:32, 11.13s/it]predicting train subjects:  77%|███████▋  | 239/311 [58:34<12:57, 10.80s/it]predicting train subjects:  77%|███████▋  | 240/311 [58:44<12:35, 10.65s/it]predicting train subjects:  77%|███████▋  | 241/311 [58:55<12:27, 10.68s/it]predicting train subjects:  78%|███████▊  | 242/311 [59:05<12:09, 10.57s/it]predicting train subjects:  78%|███████▊  | 243/311 [59:15<11:49, 10.43s/it]predicting train subjects:  78%|███████▊  | 244/311 [59:26<11:44, 10.52s/it]predicting train subjects:  79%|███████▉  | 245/311 [59:36<11:36, 10.55s/it]predicting train subjects:  79%|███████▉  | 246/311 [59:46<11:16, 10.40s/it]predicting train subjects:  79%|███████▉  | 247/311 [59:58<11:20, 10.63s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:00:08<11:10, 10.64s/it]predicting train subjects:  80%|████████  | 249/311 [1:00:22<11:49, 11.44s/it]predicting train subjects:  80%|████████  | 250/311 [1:00:35<12:10, 11.98s/it]predicting train subjects:  81%|████████  | 251/311 [1:00:48<12:27, 12.46s/it]predicting train subjects:  81%|████████  | 252/311 [1:01:01<12:25, 12.64s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:01:15<12:20, 12.77s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:01:28<12:16, 12.93s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:01:41<12:07, 12.98s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:01:54<11:58, 13.07s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:02:07<11:47, 13.11s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:02:21<11:39, 13.20s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:02:34<11:27, 13.23s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:02:47<11:16, 13.26s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:03:01<11:10, 13.41s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:03:14<10:51, 13.30s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:03:27<10:34, 13.22s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:03:40<10:19, 13.18s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:03:53<09:59, 13.03s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:04:06<09:43, 12.96s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:04:19<09:31, 12.98s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:04:32<09:17, 12.97s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:04:45<09:01, 12.90s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:04:57<08:47, 12.85s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:05:11<08:41, 13.05s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:05:24<08:25, 12.95s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:05:36<08:11, 12.92s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:05:49<07:58, 12.92s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:06:02<07:44, 12.91s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:06:15<07:31, 12.89s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:06:28<07:18, 12.89s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:06:41<07:02, 12.79s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:06:53<06:48, 12.77s/it]predicting train subjects:  90%|█████████ | 280/311 [1:07:06<06:34, 12.73s/it]predicting train subjects:  90%|█████████ | 281/311 [1:07:20<06:30, 13.00s/it]predicting train subjects:  91%|█████████ | 282/311 [1:07:33<06:16, 13.00s/it]predicting train subjects:  91%|█████████ | 283/311 [1:07:44<05:53, 12.63s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:07:56<05:34, 12.40s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:08:08<05:14, 12.11s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:08:19<04:57, 11.91s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:08:31<04:44, 11.85s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:08:43<04:32, 11.84s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:08:54<04:19, 11.78s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:09:06<04:05, 11.71s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:09:17<03:52, 11.60s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:09:29<03:41, 11.66s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:09:41<03:30, 11.70s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:09:52<03:19, 11.72s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:10:04<03:05, 11.57s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:10:15<02:54, 11.64s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:10:28<02:46, 11.88s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:10:40<02:34, 11.87s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:10:51<02:21, 11.80s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:11:03<02:08, 11.66s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:11:14<01:56, 11.69s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:11:26<01:45, 11.73s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:11:38<01:34, 11.77s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:11:50<01:23, 11.90s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:12:02<01:10, 11.73s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:12:13<00:58, 11.71s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:12:25<00:46, 11.74s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:12:37<00:35, 11.75s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:12:48<00:23, 11.66s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:13:00<00:11, 11.56s/it]predicting train subjects: 100%|██████████| 311/311 [1:13:11<00:00, 11.58s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:16<1:24:55, 16.44s/it]Loading train:   1%|          | 2/311 [00:24<1:12:24, 14.06s/it]Loading train:   1%|          | 3/311 [00:35<1:06:34, 12.97s/it]Loading train:   1%|▏         | 4/311 [00:45<1:02:18, 12.18s/it]Loading train:   2%|▏         | 5/311 [00:54<57:37, 11.30s/it]  Loading train:   2%|▏         | 6/311 [01:04<54:43, 10.77s/it]Loading train:   2%|▏         | 7/311 [01:15<54:19, 10.72s/it]Loading train:   3%|▎         | 8/311 [01:27<56:21, 11.16s/it]Loading train:   3%|▎         | 9/311 [01:38<56:44, 11.27s/it]Loading train:   3%|▎         | 10/311 [01:48<54:10, 10.80s/it]Loading train:   4%|▎         | 11/311 [02:01<56:37, 11.33s/it]Loading train:   4%|▍         | 12/311 [02:10<54:03, 10.85s/it]Loading train:   4%|▍         | 13/311 [02:20<52:07, 10.50s/it]Loading train:   5%|▍         | 14/311 [02:32<54:17, 10.97s/it]Loading train:   5%|▍         | 15/311 [02:41<51:19, 10.40s/it]Loading train:   5%|▌         | 16/311 [02:51<49:49, 10.13s/it]Loading train:   5%|▌         | 17/311 [02:59<47:33,  9.70s/it]Loading train:   6%|▌         | 18/311 [03:08<46:19,  9.48s/it]Loading train:   6%|▌         | 19/311 [03:18<45:58,  9.45s/it]Loading train:   6%|▋         | 20/311 [03:27<45:44,  9.43s/it]Loading train:   7%|▋         | 21/311 [03:36<45:19,  9.38s/it]Loading train:   7%|▋         | 22/311 [03:46<45:05,  9.36s/it]Loading train:   7%|▋         | 23/311 [03:55<44:59,  9.37s/it]Loading train:   8%|▊         | 24/311 [04:05<45:08,  9.44s/it]Loading train:   8%|▊         | 25/311 [04:14<44:38,  9.36s/it]Loading train:   8%|▊         | 26/311 [04:23<44:18,  9.33s/it]Loading train:   9%|▊         | 27/311 [04:33<44:23,  9.38s/it]Loading train:   9%|▉         | 28/311 [04:42<44:18,  9.39s/it]Loading train:   9%|▉         | 29/311 [04:51<44:11,  9.40s/it]Loading train:  10%|▉         | 30/311 [05:01<44:07,  9.42s/it]Loading train:  10%|▉         | 31/311 [05:10<44:14,  9.48s/it]Loading train:  10%|█         | 32/311 [05:20<44:01,  9.47s/it]Loading train:  11%|█         | 33/311 [05:25<37:35,  8.11s/it]Loading train:  11%|█         | 34/311 [05:30<32:46,  7.10s/it]Loading train:  11%|█▏        | 35/311 [05:34<29:23,  6.39s/it]Loading train:  12%|█▏        | 36/311 [05:39<27:00,  5.89s/it]Loading train:  12%|█▏        | 37/311 [05:44<25:27,  5.58s/it]Loading train:  12%|█▏        | 38/311 [05:49<24:12,  5.32s/it]Loading train:  13%|█▎        | 39/311 [05:53<23:27,  5.18s/it]Loading train:  13%|█▎        | 40/311 [05:58<22:49,  5.05s/it]Loading train:  13%|█▎        | 41/311 [06:03<22:14,  4.94s/it]Loading train:  14%|█▎        | 42/311 [06:08<21:56,  4.90s/it]Loading train:  14%|█▍        | 43/311 [06:12<21:36,  4.84s/it]Loading train:  14%|█▍        | 44/311 [06:17<21:29,  4.83s/it]Loading train:  14%|█▍        | 45/311 [06:22<21:32,  4.86s/it]Loading train:  15%|█▍        | 46/311 [06:27<21:11,  4.80s/it]Loading train:  15%|█▌        | 47/311 [06:31<20:51,  4.74s/it]Loading train:  15%|█▌        | 48/311 [06:36<20:55,  4.77s/it]Loading train:  16%|█▌        | 49/311 [06:41<20:52,  4.78s/it]Loading train:  16%|█▌        | 50/311 [06:46<20:43,  4.77s/it]Loading train:  16%|█▋        | 51/311 [06:52<22:18,  5.15s/it]Loading train:  17%|█▋        | 52/311 [06:58<22:58,  5.32s/it]Loading train:  17%|█▋        | 53/311 [07:03<23:38,  5.50s/it]Loading train:  17%|█▋        | 54/311 [07:09<24:04,  5.62s/it]Loading train:  18%|█▊        | 55/311 [07:15<23:53,  5.60s/it]Loading train:  18%|█▊        | 56/311 [07:20<23:42,  5.58s/it]Loading train:  18%|█▊        | 57/311 [07:26<24:00,  5.67s/it]Loading train:  19%|█▊        | 58/311 [07:32<24:03,  5.71s/it]Loading train:  19%|█▉        | 59/311 [07:38<24:25,  5.81s/it]Loading train:  19%|█▉        | 60/311 [07:44<24:03,  5.75s/it]Loading train:  20%|█▉        | 61/311 [07:50<23:58,  5.76s/it]Loading train:  20%|█▉        | 62/311 [07:55<24:04,  5.80s/it]Loading train:  20%|██        | 63/311 [08:01<23:44,  5.75s/it]Loading train:  21%|██        | 64/311 [08:07<23:48,  5.78s/it]Loading train:  21%|██        | 65/311 [08:13<24:05,  5.88s/it]Loading train:  21%|██        | 66/311 [08:19<23:49,  5.83s/it]Loading train:  22%|██▏       | 67/311 [08:24<23:27,  5.77s/it]Loading train:  22%|██▏       | 68/311 [08:30<23:08,  5.71s/it]Loading train:  22%|██▏       | 69/311 [08:36<22:51,  5.67s/it]Loading train:  23%|██▎       | 70/311 [08:41<22:40,  5.64s/it]Loading train:  23%|██▎       | 71/311 [08:47<22:29,  5.62s/it]Loading train:  23%|██▎       | 72/311 [08:52<22:28,  5.64s/it]Loading train:  23%|██▎       | 73/311 [08:58<22:25,  5.65s/it]Loading train:  24%|██▍       | 74/311 [09:03<22:03,  5.58s/it]Loading train:  24%|██▍       | 75/311 [09:09<22:08,  5.63s/it]Loading train:  24%|██▍       | 76/311 [09:15<22:03,  5.63s/it]Loading train:  25%|██▍       | 77/311 [09:20<21:44,  5.57s/it]Loading train:  25%|██▌       | 78/311 [09:26<21:53,  5.64s/it]Loading train:  25%|██▌       | 79/311 [09:32<21:45,  5.63s/it]Loading train:  26%|██▌       | 80/311 [09:37<21:40,  5.63s/it]Loading train:  26%|██▌       | 81/311 [09:43<21:34,  5.63s/it]Loading train:  26%|██▋       | 82/311 [09:49<21:23,  5.60s/it]Loading train:  27%|██▋       | 83/311 [09:54<21:18,  5.61s/it]Loading train:  27%|██▋       | 84/311 [10:00<21:02,  5.56s/it]Loading train:  27%|██▋       | 85/311 [10:05<20:35,  5.47s/it]Loading train:  28%|██▊       | 86/311 [10:10<20:06,  5.36s/it]Loading train:  28%|██▊       | 87/311 [10:15<19:42,  5.28s/it]Loading train:  28%|██▊       | 88/311 [10:20<19:05,  5.14s/it]Loading train:  29%|██▊       | 89/311 [10:25<18:52,  5.10s/it]Loading train:  29%|██▉       | 90/311 [10:30<18:52,  5.12s/it]Loading train:  29%|██▉       | 91/311 [10:35<18:39,  5.09s/it]Loading train:  30%|██▉       | 92/311 [10:40<18:47,  5.15s/it]Loading train:  30%|██▉       | 93/311 [10:45<18:44,  5.16s/it]Loading train:  30%|███       | 94/311 [10:51<18:38,  5.15s/it]Loading train:  31%|███       | 95/311 [10:56<18:34,  5.16s/it]Loading train:  31%|███       | 96/311 [11:01<18:20,  5.12s/it]Loading train:  31%|███       | 97/311 [11:06<18:27,  5.18s/it]Loading train:  32%|███▏      | 98/311 [11:11<18:11,  5.12s/it]Loading train:  32%|███▏      | 99/311 [11:16<18:07,  5.13s/it]Loading train:  32%|███▏      | 100/311 [11:21<18:03,  5.14s/it]Loading train:  32%|███▏      | 101/311 [11:26<17:53,  5.11s/it]Loading train:  33%|███▎      | 102/311 [11:32<18:10,  5.22s/it]Loading train:  33%|███▎      | 103/311 [11:37<18:07,  5.23s/it]Loading train:  33%|███▎      | 104/311 [11:42<18:03,  5.24s/it]Loading train:  34%|███▍      | 105/311 [11:48<18:03,  5.26s/it]Loading train:  34%|███▍      | 106/311 [11:53<18:01,  5.27s/it]Loading train:  34%|███▍      | 107/311 [11:58<17:41,  5.21s/it]Loading train:  35%|███▍      | 108/311 [12:03<17:41,  5.23s/it]Loading train:  35%|███▌      | 109/311 [12:09<17:44,  5.27s/it]Loading train:  35%|███▌      | 110/311 [12:14<17:33,  5.24s/it]Loading train:  36%|███▌      | 111/311 [12:19<17:29,  5.25s/it]Loading train:  36%|███▌      | 112/311 [12:24<17:10,  5.18s/it]Loading train:  36%|███▋      | 113/311 [12:29<16:56,  5.13s/it]Loading train:  37%|███▋      | 114/311 [12:38<20:49,  6.34s/it]Loading train:  37%|███▋      | 115/311 [12:48<23:55,  7.32s/it]Loading train:  37%|███▋      | 116/311 [12:57<25:44,  7.92s/it]Loading train:  38%|███▊      | 117/311 [13:06<26:48,  8.29s/it]Loading train:  38%|███▊      | 118/311 [13:16<27:43,  8.62s/it]Loading train:  38%|███▊      | 119/311 [13:25<28:25,  8.88s/it]Loading train:  39%|███▊      | 120/311 [13:35<29:06,  9.14s/it]Loading train:  39%|███▉      | 121/311 [13:45<29:12,  9.22s/it]Loading train:  39%|███▉      | 122/311 [13:54<28:55,  9.18s/it]Loading train:  40%|███▉      | 123/311 [14:03<28:48,  9.19s/it]Loading train:  40%|███▉      | 124/311 [14:12<28:49,  9.25s/it]Loading train:  40%|████      | 125/311 [14:22<28:52,  9.31s/it]Loading train:  41%|████      | 126/311 [14:31<28:48,  9.34s/it]Loading train:  41%|████      | 127/311 [14:40<28:25,  9.27s/it]Loading train:  41%|████      | 128/311 [14:50<28:23,  9.31s/it]Loading train:  41%|████▏     | 129/311 [14:59<28:18,  9.33s/it]Loading train:  42%|████▏     | 130/311 [15:09<28:20,  9.40s/it]Loading train:  42%|████▏     | 131/311 [15:18<28:24,  9.47s/it]Loading train:  42%|████▏     | 132/311 [15:23<24:20,  8.16s/it]Loading train:  43%|████▎     | 133/311 [15:28<21:19,  7.19s/it]Loading train:  43%|████▎     | 134/311 [15:33<19:07,  6.48s/it]Loading train:  43%|████▎     | 135/311 [15:38<17:46,  6.06s/it]Loading train:  44%|████▎     | 136/311 [15:43<16:35,  5.69s/it]Loading train:  44%|████▍     | 137/311 [15:48<15:36,  5.38s/it]Loading train:  44%|████▍     | 138/311 [15:52<14:49,  5.14s/it]Loading train:  45%|████▍     | 139/311 [15:57<14:19,  5.00s/it]Loading train:  45%|████▌     | 140/311 [16:02<14:12,  4.98s/it]Loading train:  45%|████▌     | 141/311 [16:07<13:55,  4.92s/it]Loading train:  46%|████▌     | 142/311 [16:11<13:35,  4.82s/it]Loading train:  46%|████▌     | 143/311 [16:16<13:20,  4.77s/it]Loading train:  46%|████▋     | 144/311 [16:20<13:12,  4.74s/it]Loading train:  47%|████▋     | 145/311 [16:25<13:04,  4.73s/it]Loading train:  47%|████▋     | 146/311 [16:30<12:59,  4.72s/it]Loading train:  47%|████▋     | 147/311 [16:35<13:09,  4.81s/it]Loading train:  48%|████▊     | 148/311 [16:39<12:52,  4.74s/it]Loading train:  48%|████▊     | 149/311 [16:44<12:48,  4.74s/it]Loading train:  48%|████▊     | 150/311 [16:50<13:53,  5.18s/it]Loading train:  49%|████▊     | 151/311 [16:56<14:18,  5.37s/it]Loading train:  49%|████▉     | 152/311 [17:02<14:45,  5.57s/it]Loading train:  49%|████▉     | 153/311 [17:08<14:56,  5.68s/it]Loading train:  50%|████▉     | 154/311 [17:14<15:10,  5.80s/it]Loading train:  50%|████▉     | 155/311 [17:20<15:03,  5.79s/it]Loading train:  50%|█████     | 156/311 [17:26<14:49,  5.74s/it]Loading train:  50%|█████     | 157/311 [17:31<14:48,  5.77s/it]Loading train:  51%|█████     | 158/311 [17:37<14:44,  5.78s/it]Loading train:  51%|█████     | 159/311 [17:43<14:38,  5.78s/it]Loading train:  51%|█████▏    | 160/311 [17:49<14:30,  5.77s/it]Loading train:  52%|█████▏    | 161/311 [17:55<14:30,  5.80s/it]Loading train:  52%|█████▏    | 162/311 [18:01<14:28,  5.83s/it]Loading train:  52%|█████▏    | 163/311 [18:06<14:25,  5.85s/it]Loading train:  53%|█████▎    | 164/311 [18:12<14:16,  5.82s/it]Loading train:  53%|█████▎    | 165/311 [18:18<14:02,  5.77s/it]Loading train:  53%|█████▎    | 166/311 [18:24<13:54,  5.76s/it]Loading train:  54%|█████▎    | 167/311 [18:29<13:42,  5.71s/it]Loading train:  54%|█████▍    | 168/311 [18:35<13:31,  5.68s/it]Loading train:  54%|█████▍    | 169/311 [18:40<13:24,  5.67s/it]Loading train:  55%|█████▍    | 170/311 [18:46<13:14,  5.63s/it]Loading train:  55%|█████▍    | 171/311 [18:51<12:59,  5.57s/it]Loading train:  55%|█████▌    | 172/311 [18:57<12:52,  5.56s/it]Loading train:  56%|█████▌    | 173/311 [19:03<12:58,  5.64s/it]Loading train:  56%|█████▌    | 174/311 [19:08<12:51,  5.63s/it]Loading train:  56%|█████▋    | 175/311 [19:14<12:59,  5.73s/it]Loading train:  57%|█████▋    | 176/311 [19:20<12:50,  5.71s/it]Loading train:  57%|█████▋    | 177/311 [19:26<12:41,  5.69s/it]Loading train:  57%|█████▋    | 178/311 [19:31<12:37,  5.69s/it]Loading train:  58%|█████▊    | 179/311 [19:37<12:30,  5.68s/it]Loading train:  58%|█████▊    | 180/311 [19:43<12:23,  5.68s/it]Loading train:  58%|█████▊    | 181/311 [19:48<12:18,  5.68s/it]Loading train:  59%|█████▊    | 182/311 [19:54<12:16,  5.71s/it]Loading train:  59%|█████▉    | 183/311 [20:00<12:18,  5.77s/it]Loading train:  59%|█████▉    | 184/311 [20:05<11:58,  5.66s/it]Loading train:  59%|█████▉    | 185/311 [20:10<11:26,  5.45s/it]Loading train:  60%|█████▉    | 186/311 [20:16<11:24,  5.48s/it]Loading train:  60%|██████    | 187/311 [20:21<11:10,  5.40s/it]Loading train:  60%|██████    | 188/311 [20:27<11:04,  5.40s/it]Loading train:  61%|██████    | 189/311 [20:32<11:00,  5.42s/it]Loading train:  61%|██████    | 190/311 [20:37<10:45,  5.33s/it]Loading train:  61%|██████▏   | 191/311 [20:42<10:29,  5.24s/it]Loading train:  62%|██████▏   | 192/311 [20:48<10:26,  5.27s/it]Loading train:  62%|██████▏   | 193/311 [20:53<10:21,  5.27s/it]Loading train:  62%|██████▏   | 194/311 [20:58<10:10,  5.22s/it]Loading train:  63%|██████▎   | 195/311 [21:03<10:03,  5.20s/it]Loading train:  63%|██████▎   | 196/311 [21:08<09:56,  5.19s/it]Loading train:  63%|██████▎   | 197/311 [21:13<09:51,  5.19s/it]Loading train:  64%|██████▎   | 198/311 [21:19<09:49,  5.22s/it]Loading train:  64%|██████▍   | 199/311 [21:24<09:46,  5.24s/it]Loading train:  64%|██████▍   | 200/311 [21:29<09:37,  5.20s/it]Loading train:  65%|██████▍   | 201/311 [21:35<09:40,  5.28s/it]Loading train:  65%|██████▍   | 202/311 [21:40<09:38,  5.31s/it]Loading train:  65%|██████▌   | 203/311 [21:46<09:41,  5.38s/it]Loading train:  66%|██████▌   | 204/311 [21:51<09:48,  5.50s/it]Loading train:  66%|██████▌   | 205/311 [21:57<09:49,  5.56s/it]Loading train:  66%|██████▌   | 206/311 [22:03<09:41,  5.54s/it]Loading train:  67%|██████▋   | 207/311 [22:08<09:44,  5.62s/it]Loading train:  67%|██████▋   | 208/311 [22:14<09:50,  5.73s/it]Loading train:  67%|██████▋   | 209/311 [22:20<09:49,  5.78s/it]Loading train:  68%|██████▊   | 210/311 [22:26<09:36,  5.71s/it]Loading train:  68%|██████▊   | 211/311 [22:31<09:30,  5.70s/it]Loading train:  68%|██████▊   | 212/311 [22:37<09:22,  5.68s/it]Loading train:  68%|██████▊   | 213/311 [22:47<11:16,  6.90s/it]Loading train:  69%|██████▉   | 214/311 [22:57<12:44,  7.88s/it]Loading train:  69%|██████▉   | 215/311 [23:07<13:46,  8.61s/it]Loading train:  69%|██████▉   | 216/311 [23:17<14:18,  9.04s/it]Loading train:  70%|██████▉   | 217/311 [23:28<14:43,  9.40s/it]Loading train:  70%|███████   | 218/311 [23:38<14:50,  9.57s/it]Loading train:  70%|███████   | 219/311 [23:48<14:58,  9.76s/it]Loading train:  71%|███████   | 220/311 [23:58<14:47,  9.76s/it]Loading train:  71%|███████   | 221/311 [24:08<14:59,  9.99s/it]Loading train:  71%|███████▏  | 222/311 [24:18<14:49,  9.99s/it]Loading train:  72%|███████▏  | 223/311 [24:28<14:39, 10.00s/it]Loading train:  72%|███████▏  | 224/311 [24:38<14:22,  9.91s/it]Loading train:  72%|███████▏  | 225/311 [24:48<14:17,  9.97s/it]Loading train:  73%|███████▎  | 226/311 [24:58<14:06,  9.96s/it]Loading train:  73%|███████▎  | 227/311 [25:08<14:03, 10.05s/it]Loading train:  73%|███████▎  | 228/311 [25:18<13:49, 10.00s/it]Loading train:  74%|███████▎  | 229/311 [25:28<13:51, 10.14s/it]Loading train:  74%|███████▍  | 230/311 [25:38<13:37, 10.09s/it]Loading train:  74%|███████▍  | 231/311 [25:44<11:33,  8.67s/it]Loading train:  75%|███████▍  | 232/311 [25:49<09:58,  7.57s/it]Loading train:  75%|███████▍  | 233/311 [25:54<08:56,  6.88s/it]Loading train:  75%|███████▌  | 234/311 [25:59<08:11,  6.39s/it]Loading train:  76%|███████▌  | 235/311 [26:05<07:46,  6.13s/it]Loading train:  76%|███████▌  | 236/311 [26:13<08:22,  6.70s/it]Loading train:  76%|███████▌  | 237/311 [26:20<08:31,  6.92s/it]Loading train:  77%|███████▋  | 238/311 [26:28<08:34,  7.05s/it]Loading train:  77%|███████▋  | 239/311 [26:35<08:37,  7.19s/it]Loading train:  77%|███████▋  | 240/311 [26:43<08:37,  7.29s/it]Loading train:  77%|███████▋  | 241/311 [26:51<08:48,  7.55s/it]Loading train:  78%|███████▊  | 242/311 [26:58<08:42,  7.57s/it]Loading train:  78%|███████▊  | 243/311 [27:06<08:42,  7.68s/it]Loading train:  78%|███████▊  | 244/311 [27:14<08:29,  7.60s/it]Loading train:  79%|███████▉  | 245/311 [27:22<08:25,  7.65s/it]Loading train:  79%|███████▉  | 246/311 [27:28<07:58,  7.35s/it]Loading train:  79%|███████▉  | 247/311 [27:36<07:50,  7.35s/it]Loading train:  80%|███████▉  | 248/311 [27:43<07:44,  7.37s/it]Loading train:  80%|████████  | 249/311 [27:52<08:09,  7.90s/it]Loading train:  80%|████████  | 250/311 [28:01<08:13,  8.09s/it]Loading train:  81%|████████  | 251/311 [28:10<08:27,  8.46s/it]Loading train:  81%|████████  | 252/311 [28:19<08:27,  8.61s/it]Loading train:  81%|████████▏ | 253/311 [28:27<08:16,  8.56s/it]Loading train:  82%|████████▏ | 254/311 [28:37<08:18,  8.75s/it]Loading train:  82%|████████▏ | 255/311 [28:45<08:04,  8.65s/it]Loading train:  82%|████████▏ | 256/311 [28:53<07:49,  8.54s/it]Loading train:  83%|████████▎ | 257/311 [29:02<07:42,  8.56s/it]Loading train:  83%|████████▎ | 258/311 [29:10<07:34,  8.58s/it]Loading train:  83%|████████▎ | 259/311 [29:19<07:30,  8.65s/it]Loading train:  84%|████████▎ | 260/311 [29:27<07:10,  8.43s/it]Loading train:  84%|████████▍ | 261/311 [29:36<07:07,  8.56s/it]Loading train:  84%|████████▍ | 262/311 [29:44<06:49,  8.35s/it]Loading train:  85%|████████▍ | 263/311 [29:52<06:40,  8.34s/it]Loading train:  85%|████████▍ | 264/311 [30:00<06:29,  8.28s/it]Loading train:  85%|████████▌ | 265/311 [30:08<06:16,  8.18s/it]Loading train:  86%|████████▌ | 266/311 [30:17<06:12,  8.28s/it]Loading train:  86%|████████▌ | 267/311 [30:26<06:12,  8.46s/it]Loading train:  86%|████████▌ | 268/311 [30:34<05:57,  8.30s/it]Loading train:  86%|████████▋ | 269/311 [30:42<05:48,  8.30s/it]Loading train:  87%|████████▋ | 270/311 [30:50<05:34,  8.16s/it]Loading train:  87%|████████▋ | 271/311 [30:58<05:27,  8.20s/it]Loading train:  87%|████████▋ | 272/311 [31:07<05:23,  8.29s/it]Loading train:  88%|████████▊ | 273/311 [31:15<05:14,  8.28s/it]Loading train:  88%|████████▊ | 274/311 [31:23<05:05,  8.25s/it]Loading train:  88%|████████▊ | 275/311 [31:32<05:00,  8.36s/it]Loading train:  89%|████████▊ | 276/311 [31:40<04:56,  8.47s/it]Loading train:  89%|████████▉ | 277/311 [31:49<04:47,  8.46s/it]Loading train:  89%|████████▉ | 278/311 [31:57<04:39,  8.48s/it]Loading train:  90%|████████▉ | 279/311 [32:05<04:24,  8.26s/it]Loading train:  90%|█████████ | 280/311 [32:14<04:18,  8.35s/it]Loading train:  90%|█████████ | 281/311 [32:21<03:58,  7.93s/it]Loading train:  91%|█████████ | 282/311 [32:29<03:52,  8.00s/it]Loading train:  91%|█████████ | 283/311 [32:37<03:42,  7.93s/it]Loading train:  91%|█████████▏| 284/311 [32:43<03:20,  7.42s/it]Loading train:  92%|█████████▏| 285/311 [32:49<03:04,  7.10s/it]Loading train:  92%|█████████▏| 286/311 [32:55<02:52,  6.88s/it]Loading train:  92%|█████████▏| 287/311 [33:02<02:39,  6.66s/it]Loading train:  93%|█████████▎| 288/311 [33:08<02:28,  6.48s/it]Loading train:  93%|█████████▎| 289/311 [33:14<02:23,  6.52s/it]Loading train:  93%|█████████▎| 290/311 [33:21<02:15,  6.45s/it]Loading train:  94%|█████████▎| 291/311 [33:27<02:07,  6.37s/it]Loading train:  94%|█████████▍| 292/311 [33:33<01:58,  6.23s/it]Loading train:  94%|█████████▍| 293/311 [33:39<01:53,  6.30s/it]Loading train:  95%|█████████▍| 294/311 [33:45<01:45,  6.19s/it]Loading train:  95%|█████████▍| 295/311 [33:51<01:40,  6.26s/it]Loading train:  95%|█████████▌| 296/311 [33:58<01:33,  6.22s/it]Loading train:  95%|█████████▌| 297/311 [34:04<01:27,  6.24s/it]Loading train:  96%|█████████▌| 298/311 [34:10<01:20,  6.20s/it]Loading train:  96%|█████████▌| 299/311 [34:17<01:16,  6.39s/it]Loading train:  96%|█████████▋| 300/311 [34:23<01:10,  6.37s/it]Loading train:  97%|█████████▋| 301/311 [34:30<01:05,  6.52s/it]Loading train:  97%|█████████▋| 302/311 [34:36<00:58,  6.48s/it]Loading train:  97%|█████████▋| 303/311 [34:42<00:50,  6.26s/it]Loading train:  98%|█████████▊| 304/311 [34:49<00:44,  6.32s/it]Loading train:  98%|█████████▊| 305/311 [34:55<00:37,  6.31s/it]Loading train:  98%|█████████▊| 306/311 [35:02<00:32,  6.45s/it]Loading train:  99%|█████████▊| 307/311 [35:08<00:25,  6.29s/it]Loading train:  99%|█████████▉| 308/311 [35:14<00:18,  6.33s/it]Loading train:  99%|█████████▉| 309/311 [35:20<00:12,  6.37s/it]Loading train: 100%|█████████▉| 310/311 [35:27<00:06,  6.42s/it]Loading train: 100%|██████████| 311/311 [35:33<00:00,  6.36s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/311 [00:00<00:17, 17.39it/s]concatenating: train:   1%|▏         | 4/311 [00:00<00:23, 13.16it/s]concatenating: train:   2%|▏         | 6/311 [00:00<00:23, 12.84it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:17, 17.16it/s]concatenating: train:  11%|█▏        | 35/311 [00:00<00:11, 23.66it/s]concatenating: train:  20%|█▉        | 61/311 [00:00<00:07, 32.52it/s]concatenating: train:  26%|██▋       | 82/311 [00:00<00:05, 43.49it/s]concatenating: train:  35%|███▌      | 109/311 [00:00<00:03, 58.08it/s]concatenating: train:  42%|████▏     | 132/311 [00:01<00:02, 74.37it/s]concatenating: train:  49%|████▉     | 152/311 [00:01<00:02, 58.51it/s]concatenating: train:  54%|█████▎    | 167/311 [00:02<00:03, 40.89it/s]concatenating: train:  58%|█████▊    | 179/311 [00:02<00:03, 43.22it/s]concatenating: train:  66%|██████▌   | 206/311 [00:02<00:01, 57.77it/s]concatenating: train:  75%|███████▍  | 233/311 [00:02<00:01, 75.60it/s]concatenating: train:  84%|████████▍ | 261/311 [00:02<00:00, 96.60it/s]concatenating: train:  91%|█████████ | 283/311 [00:02<00:00, 99.11it/s]concatenating: train:  97%|█████████▋| 301/311 [00:03<00:00, 58.38it/s]concatenating: train: 100%|██████████| 311/311 [00:03<00:00, 80.91it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:13<00:41, 13.72s/it]Loading test:  50%|█████     | 2/4 [00:26<00:26, 13.33s/it]Loading test:  75%|███████▌  | 3/4 [00:39<00:13, 13.41s/it]Loading test: 100%|██████████| 4/4 [00:52<00:00, 13.26s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 41.80it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 10:21:25.778789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 10:21:25.778936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 10:21:25.778954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 10:21:25.778968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 10:21:25.779492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 26, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 22s - loss: 18985.6451 - acc: 0.8530 - mDice: 0.0951 - val_loss: 9460.8876 - val_acc: 0.8756 - val_mDice: 0.1813

Epoch 00001: val_mDice improved from -inf to 0.18128, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 15s - loss: 8148.6765 - acc: 0.8723 - mDice: 0.2201 - val_loss: 5692.9602 - val_acc: 0.8879 - val_mDice: 0.3245

Epoch 00002: val_mDice improved from 0.18128 to 0.32446, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 6189.4755 - acc: 0.8882 - mDice: 0.3133 - val_loss: 4533.0896 - val_acc: 0.8976 - val_mDice: 0.3948

Epoch 00003: val_mDice improved from 0.32446 to 0.39477, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 5158.8675 - acc: 0.8997 - mDice: 0.3798 - val_loss: 4039.5677 - val_acc: 0.9015 - val_mDice: 0.4295

Epoch 00004: val_mDice improved from 0.39477 to 0.42952, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 4606.6671 - acc: 0.9058 - mDice: 0.4179 - val_loss: 3517.2699 - val_acc: 0.9077 - val_mDice: 0.4767

Epoch 00005: val_mDice improved from 0.42952 to 0.47674, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 4114.4138 - acc: 0.9118 - mDice: 0.4551 - val_loss: 3197.3601 - val_acc: 0.9145 - val_mDice: 0.5067

Epoch 00006: val_mDice improved from 0.47674 to 0.50675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 3716.1717 - acc: 0.9163 - mDice: 0.4866 - val_loss: 2821.5638 - val_acc: 0.9220 - val_mDice: 0.5410

Epoch 00007: val_mDice improved from 0.50675 to 0.54097, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 12s - loss: 3369.6463 - acc: 0.9206 - mDice: 0.5172 - val_loss: 2606.6959 - val_acc: 0.9263 - val_mDice: 0.5657

Epoch 00008: val_mDice improved from 0.54097 to 0.56575, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 3075.3520 - acc: 0.9243 - mDice: 0.5439 - val_loss: 2510.0422 - val_acc: 0.9297 - val_mDice: 0.5796

Epoch 00009: val_mDice improved from 0.56575 to 0.57958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 12s - loss: 2871.9534 - acc: 0.9271 - mDice: 0.5652 - val_loss: 2316.6950 - val_acc: 0.9328 - val_mDice: 0.6013

Epoch 00010: val_mDice improved from 0.57958 to 0.60129, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 2707.0904 - acc: 0.9291 - mDice: 0.5826 - val_loss: 2237.1332 - val_acc: 0.9352 - val_mDice: 0.6110

Epoch 00011: val_mDice improved from 0.60129 to 0.61096, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 12/300
 - 12s - loss: 2592.7200 - acc: 0.9311 - mDice: 0.5958 - val_loss: 2171.8803 - val_acc: 0.9369 - val_mDice: 0.6213

Epoch 00012: val_mDice improved from 0.61096 to 0.62129, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 13s - loss: 2481.5195 - acc: 0.9327 - mDice: 0.6085 - val_loss: 2104.0245 - val_acc: 0.9387 - val_mDice: 0.6318

Epoch 00013: val_mDice improved from 0.62129 to 0.63183, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 12s - loss: 2388.1537 - acc: 0.9340 - mDice: 0.6193 - val_loss: 1996.8912 - val_acc: 0.9404 - val_mDice: 0.6447

Epoch 00014: val_mDice improved from 0.63183 to 0.64471, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 13s - loss: 2340.4569 - acc: 0.9350 - mDice: 0.6257 - val_loss: 1971.5254 - val_acc: 0.9418 - val_mDice: 0.6480

Epoch 00015: val_mDice improved from 0.64471 to 0.64797, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 11s - loss: 2259.8723 - acc: 0.9361 - mDice: 0.6353 - val_loss: 2000.4225 - val_acc: 0.9435 - val_mDice: 0.6445

Epoch 00016: val_mDice did not improve from 0.64797
Epoch 17/300
 - 12s - loss: 2200.4846 - acc: 0.9371 - mDice: 0.6426 - val_loss: 1927.4783 - val_acc: 0.9433 - val_mDice: 0.6551

Epoch 00017: val_mDice improved from 0.64797 to 0.65506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 12s - loss: 2140.5877 - acc: 0.9380 - mDice: 0.6502 - val_loss: 1886.2462 - val_acc: 0.9445 - val_mDice: 0.6605

Epoch 00018: val_mDice improved from 0.65506 to 0.66051, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 11s - loss: 2090.3080 - acc: 0.9387 - mDice: 0.6566 - val_loss: 1838.4161 - val_acc: 0.9472 - val_mDice: 0.6674

Epoch 00019: val_mDice improved from 0.66051 to 0.66739, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 13s - loss: 2048.5851 - acc: 0.9394 - mDice: 0.6621 - val_loss: 1876.4861 - val_acc: 0.9456 - val_mDice: 0.6630

Epoch 00020: val_mDice did not improve from 0.66739
Epoch 21/300
 - 11s - loss: 2009.0838 - acc: 0.9401 - mDice: 0.6673 - val_loss: 1819.3486 - val_acc: 0.9464 - val_mDice: 0.6709

Epoch 00021: val_mDice improved from 0.66739 to 0.67086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 12s - loss: 1968.4484 - acc: 0.9408 - mDice: 0.6726 - val_loss: 1777.1576 - val_acc: 0.9481 - val_mDice: 0.6767

Epoch 00022: val_mDice improved from 0.67086 to 0.67675, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 12s - loss: 1940.7637 - acc: 0.9414 - mDice: 0.6764 - val_loss: 1755.2143 - val_acc: 0.9496 - val_mDice: 0.6804

Epoch 00023: val_mDice improved from 0.67675 to 0.68036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 24/300
 - 12s - loss: 1897.1222 - acc: 0.9421 - mDice: 0.6822 - val_loss: 1783.1832 - val_acc: 0.9490 - val_mDice: 0.6762

Epoch 00024: val_mDice did not improve from 0.68036
Epoch 25/300
 - 12s - loss: 1866.0623 - acc: 0.9427 - mDice: 0.6864 - val_loss: 1832.1781 - val_acc: 0.9483 - val_mDice: 0.6706

Epoch 00025: val_mDice did not improve from 0.68036
Epoch 26/300
 - 11s - loss: 1850.8865 - acc: 0.9430 - mDice: 0.6885 - val_loss: 1744.4072 - val_acc: 0.9500 - val_mDice: 0.6814

Epoch 00026: val_mDice improved from 0.68036 to 0.68137, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 27/300
 - 13s - loss: 1810.0503 - acc: 0.9434 - mDice: 0.6938 - val_loss: 1775.5068 - val_acc: 0.9478 - val_mDice: 0.6773

Epoch 00027: val_mDice did not improve from 0.68137
Epoch 28/300
 - 11s - loss: 1791.0994 - acc: 0.9440 - mDice: 0.6967 - val_loss: 1722.8688 - val_acc: 0.9522 - val_mDice: 0.6858

Epoch 00028: val_mDice improved from 0.68137 to 0.68577, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 12s - loss: 1765.8161 - acc: 0.9444 - mDice: 0.7001 - val_loss: 1710.9820 - val_acc: 0.9508 - val_mDice: 0.6870

Epoch 00029: val_mDice improved from 0.68577 to 0.68697, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 30/300
 - 12s - loss: 1746.8169 - acc: 0.9448 - mDice: 0.7029 - val_loss: 1725.6873 - val_acc: 0.9526 - val_mDice: 0.6835

Epoch 00030: val_mDice did not improve from 0.68697
Epoch 31/300
 - 11s - loss: 1726.1805 - acc: 0.9452 - mDice: 0.7057 - val_loss: 1692.6021 - val_acc: 0.9534 - val_mDice: 0.6909

Epoch 00031: val_mDice improved from 0.68697 to 0.69086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 32/300
 - 13s - loss: 1706.5195 - acc: 0.9453 - mDice: 0.7084 - val_loss: 1725.1525 - val_acc: 0.9505 - val_mDice: 0.6854

Epoch 00032: val_mDice did not improve from 0.69086
Epoch 33/300
 - 11s - loss: 1681.7086 - acc: 0.9459 - mDice: 0.7119 - val_loss: 1662.5201 - val_acc: 0.9554 - val_mDice: 0.6939

Epoch 00033: val_mDice improved from 0.69086 to 0.69394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 12s - loss: 1685.5116 - acc: 0.9460 - mDice: 0.7115 - val_loss: 1748.9990 - val_acc: 0.9510 - val_mDice: 0.6826

Epoch 00034: val_mDice did not improve from 0.69394
Epoch 35/300
 - 12s - loss: 1662.9738 - acc: 0.9464 - mDice: 0.7150 - val_loss: 1877.7500 - val_acc: 0.9517 - val_mDice: 0.6655

Epoch 00035: val_mDice did not improve from 0.69394
Epoch 36/300
 - 11s - loss: 1949.7264 - acc: 0.9420 - mDice: 0.6784 - val_loss: 1969.0626 - val_acc: 0.9507 - val_mDice: 0.6525

Epoch 00036: val_mDice did not improve from 0.69394
Epoch 37/300
 - 13s - loss: 1679.4201 - acc: 0.9461 - mDice: 0.7123 - val_loss: 1685.4190 - val_acc: 0.9548 - val_mDice: 0.6907

Epoch 00037: val_mDice did not improve from 0.69394
Epoch 38/300
 - 11s - loss: 1647.2697 - acc: 0.9467 - mDice: 0.7169 - val_loss: 1723.1191 - val_acc: 0.9518 - val_mDice: 0.6867

Epoch 00038: val_mDice did not improve from 0.69394
Epoch 39/300
 - 12s - loss: 1624.9744 - acc: 0.9470 - mDice: 0.7200 - val_loss: 1706.6741 - val_acc: 0.9509 - val_mDice: 0.6879

Epoch 00039: val_mDice did not improve from 0.69394
Epoch 40/300
 - 12s - loss: 1610.1823 - acc: 0.9474 - mDice: 0.7222 - val_loss: 1638.3374 - val_acc: 0.9557 - val_mDice: 0.6980

Epoch 00040: val_mDice improved from 0.69394 to 0.69798, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 41/300
 - 12s - loss: 1588.9702 - acc: 0.9477 - mDice: 0.7252 - val_loss: 1642.8498 - val_acc: 0.9537 - val_mDice: 0.6972

Epoch 00041: val_mDice did not improve from 0.69798
Epoch 42/300
 - 13s - loss: 1579.7433 - acc: 0.9479 - mDice: 0.7265 - val_loss: 1760.0468 - val_acc: 0.9548 - val_mDice: 0.6811

Epoch 00042: val_mDice did not improve from 0.69798
Epoch 43/300
 - 11s - loss: 1572.1962 - acc: 0.9479 - mDice: 0.7277 - val_loss: 1930.2475 - val_acc: 0.9521 - val_mDice: 0.6579

Epoch 00043: val_mDice did not improve from 0.69798
Epoch 44/300
 - 13s - loss: 1566.6662 - acc: 0.9482 - mDice: 0.7286 - val_loss: 1770.4992 - val_acc: 0.9549 - val_mDice: 0.6808

Epoch 00044: val_mDice did not improve from 0.69798
Epoch 45/300
 - 12s - loss: 1552.2124 - acc: 0.9483 - mDice: 0.7305 - val_loss: 1853.4548 - val_acc: 0.9553 - val_mDice: 0.6690

Epoch 00045: val_mDice did not improve from 0.69798
Epoch 46/300
 - 12s - loss: 1549.3228 - acc: 0.9484 - mDice: 0.7313 - val_loss: 1640.7312 - val_acc: 0.9552 - val_mDice: 0.6987

Epoch 00046: val_mDice improved from 0.69798 to 0.69867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 12s - loss: 1541.2026 - acc: 0.9487 - mDice: 0.7323 - val_loss: 1652.9923 - val_acc: 0.9556 - val_mDice: 0.6958

Epoch 00047: val_mDice did not improve from 0.69867
Epoch 48/300
 - 11s - loss: 1518.3477 - acc: 0.9490 - mDice: 0.7354 - val_loss: 1683.8864 - val_acc: 0.9515 - val_mDice: 0.6904

Epoch 00048: val_mDice did not improve from 0.69867
Epoch 49/300
 - 13s - loss: 1516.4533 - acc: 0.9490 - mDice: 0.7358 - val_loss: 1762.0639 - val_acc: 0.9510 - val_mDice: 0.6790

Epoch 00049: val_mDice did not improve from 0.69867
Epoch 50/300
 - 11s - loss: 1503.1748 - acc: 0.9492 - mDice: 0.7377 - val_loss: 1629.1985 - val_acc: 0.9561 - val_mDice: 0.6997

Epoch 00050: val_mDice improved from 0.69867 to 0.69975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 51/300
 - 12s - loss: 1499.8070 - acc: 0.9493 - mDice: 0.7382 - val_loss: 1682.4088 - val_acc: 0.9533 - val_mDice: 0.6915

Epoch 00051: val_mDice did not improve from 0.69975
Epoch 52/300
 - 12s - loss: 1487.7881 - acc: 0.9494 - mDice: 0.7400 - val_loss: 1662.0295 - val_acc: 0.9551 - val_mDice: 0.6944

Epoch 00052: val_mDice did not improve from 0.69975
Epoch 53/300
 - 12s - loss: 1493.5508 - acc: 0.9494 - mDice: 0.7392 - val_loss: 1677.8971 - val_acc: 0.9512 - val_mDice: 0.6921

Epoch 00053: val_mDice did not improve from 0.69975
Epoch 54/300
 - 13s - loss: 1472.6803 - acc: 0.9497 - mDice: 0.7421 - val_loss: 1657.7623 - val_acc: 0.9557 - val_mDice: 0.6961

Epoch 00054: val_mDice did not improve from 0.69975
Epoch 55/300
 - 11s - loss: 1466.5546 - acc: 0.9498 - mDice: 0.7430 - val_loss: 1655.4488 - val_acc: 0.9560 - val_mDice: 0.6955

Epoch 00055: val_mDice did not improve from 0.69975
Epoch 56/300
 - 12s - loss: 1464.2771 - acc: 0.9500 - mDice: 0.7435 - val_loss: 1756.6678 - val_acc: 0.9568 - val_mDice: 0.6841

Epoch 00056: val_mDice did not improve from 0.69975
Epoch 57/300
 - 12s - loss: 1464.1077 - acc: 0.9500 - mDice: 0.7436 - val_loss: 1755.5713 - val_acc: 0.9550 - val_mDice: 0.6831

Epoch 00057: val_mDice did not improve from 0.69975
Epoch 58/300
 - 12s - loss: 1461.6332 - acc: 0.9499 - mDice: 0.7439 - val_loss: 1942.5707 - val_acc: 0.9547 - val_mDice: 0.6580

Epoch 00058: val_mDice did not improve from 0.69975
Epoch 59/300
 - 13s - loss: 1445.0074 - acc: 0.9502 - mDice: 0.7462 - val_loss: 1526.0752 - val_acc: 0.9588 - val_mDice: 0.7155

Epoch 00059: val_mDice improved from 0.69975 to 0.71554, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 60/300
 - 11s - loss: 1435.0250 - acc: 0.9503 - mDice: 0.7477 - val_loss: 1612.1581 - val_acc: 0.9571 - val_mDice: 0.7011

Epoch 00060: val_mDice did not improve from 0.71554
Epoch 61/300
 - 13s - loss: 1432.4319 - acc: 0.9504 - mDice: 0.7482 - val_loss: 1593.9774 - val_acc: 0.9575 - val_mDice: 0.7059

Epoch 00061: val_mDice did not improve from 0.71554
Epoch 62/300
 - 11s - loss: 1429.6060 - acc: 0.9506 - mDice: 0.7486 - val_loss: 1642.1961 - val_acc: 0.9569 - val_mDice: 0.6982

Epoch 00062: val_mDice did not improve from 0.71554
Epoch 63/300
 - 12s - loss: 1422.2185 - acc: 0.9506 - mDice: 0.7497 - val_loss: 1698.5302 - val_acc: 0.9541 - val_mDice: 0.6897

Epoch 00063: val_mDice did not improve from 0.71554
Epoch 64/300
 - 12s - loss: 1415.2885 - acc: 0.9508 - mDice: 0.7506 - val_loss: 1701.2630 - val_acc: 0.9560 - val_mDice: 0.6892

Epoch 00064: val_mDice did not improve from 0.71554
Epoch 65/300
 - 11s - loss: 1407.6562 - acc: 0.9509 - mDice: 0.7520 - val_loss: 1580.7308 - val_acc: 0.9574 - val_mDice: 0.7078

Epoch 00065: val_mDice did not improve from 0.71554
Epoch 66/300
 - 13s - loss: 1402.2251 - acc: 0.9510 - mDice: 0.7527 - val_loss: 1561.1728 - val_acc: 0.9576 - val_mDice: 0.7098

Epoch 00066: val_mDice did not improve from 0.71554
Epoch 67/300
 - 11s - loss: 1400.7131 - acc: 0.9511 - mDice: 0.7529 - val_loss: 1589.4364 - val_acc: 0.9575 - val_mDice: 0.7073

Epoch 00067: val_mDice did not improve from 0.71554
Epoch 68/300
 - 12s - loss: 1391.4147 - acc: 0.9511 - mDice: 0.7543 - val_loss: 1652.4858 - val_acc: 0.9586 - val_mDice: 0.6975

Epoch 00068: val_mDice did not improve from 0.71554
Epoch 69/300
 - 12s - loss: 1418.4388 - acc: 0.9508 - mDice: 0.7506 - val_loss: 1884.5328 - val_acc: 0.9573 - val_mDice: 0.6669

Epoch 00069: val_mDice did not improve from 0.71554
Epoch 70/300
 - 12s - loss: 1389.2506 - acc: 0.9513 - mDice: 0.7545 - val_loss: 1781.2874 - val_acc: 0.9572 - val_mDice: 0.6803

Epoch 00070: val_mDice did not improve from 0.71554
Epoch 71/300
 - 12s - loss: 1387.6604 - acc: 0.9513 - mDice: 0.7548 - val_loss: 1651.3239 - val_acc: 0.9587 - val_mDice: 0.6981

Epoch 00071: val_mDice did not improve from 0.71554
Epoch 72/300
 - 11s - loss: 1372.1030 - acc: 0.9515 - mDice: 0.7571 - val_loss: 1686.4169 - val_acc: 0.9565 - val_mDice: 0.6935

Epoch 00072: val_mDice did not improve from 0.71554
Epoch 73/300
 - 13s - loss: 1377.0746 - acc: 0.9515 - mDice: 0.7565 - val_loss: 1606.2522 - val_acc: 0.9583 - val_mDice: 0.7037

Epoch 00073: val_mDice did not improve from 0.71554
Epoch 74/300
 - 11s - loss: 1370.7189 - acc: 0.9515 - mDice: 0.7574 - val_loss: 1570.4276 - val_acc: 0.9578 - val_mDice: 0.7086

Epoch 00074: val_mDice did not improve from 0.71554
Epoch 75/300
 - 12s - loss: 1365.0344 - acc: 0.9516 - mDice: 0.7581 - val_loss: 1864.9839 - val_acc: 0.9553 - val_mDice: 0.6669

Epoch 00075: val_mDice did not improve from 0.71554
Epoch 76/300
 - 12s - loss: 1355.1327 - acc: 0.9517 - mDice: 0.7595 - val_loss: 1846.0101 - val_acc: 0.9568 - val_mDice: 0.6708

Epoch 00076: val_mDice did not improve from 0.71554
Epoch 77/300
 - 11s - loss: 1354.3578 - acc: 0.9517 - mDice: 0.7598 - val_loss: 1649.9570 - val_acc: 0.9582 - val_mDice: 0.6986

Epoch 00077: val_mDice did not improve from 0.71554
Epoch 78/300
 - 13s - loss: 1355.9273 - acc: 0.9518 - mDice: 0.7596 - val_loss: 1616.7599 - val_acc: 0.9569 - val_mDice: 0.7030

Epoch 00078: val_mDice did not improve from 0.71554
Epoch 79/300
 - 11s - loss: 1344.6357 - acc: 0.9518 - mDice: 0.7612 - val_loss: 1694.5234 - val_acc: 0.9583 - val_mDice: 0.6921

Epoch 00079: val_mDice did not improve from 0.71554
Epoch 80/300
 - 12s - loss: 1346.6984 - acc: 0.9518 - mDice: 0.7609 - val_loss: 1709.6155 - val_acc: 0.9571 - val_mDice: 0.6895

Epoch 00080: val_mDice did not improve from 0.71554
Epoch 81/300
 - 12s - loss: 1340.3624 - acc: 0.9520 - mDice: 0.7619 - val_loss: 1612.9892 - val_acc: 0.9597 - val_mDice: 0.7042

Epoch 00081: val_mDice did not improve from 0.71554
Epoch 82/300
 - 11s - loss: 1339.8194 - acc: 0.9520 - mDice: 0.7620 - val_loss: 1621.1794 - val_acc: 0.9604 - val_mDice: 0.7023

Epoch 00082: val_mDice did not improve from 0.71554
Epoch 83/300
 - 13s - loss: 1330.1516 - acc: 0.9522 - mDice: 0.7635 - val_loss: 1682.1122 - val_acc: 0.9557 - val_mDice: 0.6922

Epoch 00083: val_mDice did not improve from 0.71554
Epoch 84/300
 - 11s - loss: 1324.6038 - acc: 0.9523 - mDice: 0.7643 - val_loss: 1697.9445 - val_acc: 0.9546 - val_mDice: 0.6888

Epoch 00084: val_mDice did not improve from 0.71554
Epoch 85/300
 - 12s - loss: 1329.0183 - acc: 0.9522 - mDice: 0.7636 - val_loss: 1733.8912 - val_acc: 0.9584 - val_mDice: 0.6852

Epoch 00085: val_mDice did not improve from 0.71554
Epoch 86/300
 - 12s - loss: 1327.0867 - acc: 0.9521 - mDice: 0.7640 - val_loss: 1762.6565 - val_acc: 0.9573 - val_mDice: 0.6837

Epoch 00086: val_mDice did not improve from 0.71554
Epoch 87/300
 - 12s - loss: 1320.2232 - acc: 0.9524 - mDice: 0.7650 - val_loss: 1678.7534 - val_acc: 0.9562 - val_mDice: 0.6933

Epoch 00087: val_mDice did not improve from 0.71554
Epoch 88/300
 - 12s - loss: 1328.3219 - acc: 0.9523 - mDice: 0.7640 - val_loss: 1737.3462 - val_acc: 0.9524 - val_mDice: 0.6843

Epoch 00088: val_mDice did not improve from 0.71554
Epoch 89/300
 - 11s - loss: 1317.7799 - acc: 0.9523 - mDice: 0.7654 - val_loss: 1667.8266 - val_acc: 0.9569 - val_mDice: 0.6950

Epoch 00089: val_mDice did not improve from 0.71554
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
{'val_loss': [9460.88764312977, 5692.9601678047475, 4533.089601473044, 4039.5677425005965, 3517.2699412571565, 3197.3600887851862, 2821.5637598401718, 2606.6958976920323, 2510.042209304926, 2316.695003130964, 2237.1332225071565, 2171.880317047352, 2104.024484881918, 1996.8912400107347, 1971.5253542834566, 2000.4225021245825, 1927.4782565750238, 1886.246216752147, 1838.416078057908, 1876.4860746660306, 1819.3485946072876, 1777.157566682073, 1755.2143219227098, 1783.1831911975191, 1832.178124813633, 1744.4072088576456, 1775.5067912094466, 1722.8688275286258, 1710.9819801854724, 1725.6873005874284, 1692.602138373688, 1725.152490048008, 1662.5200707821446, 1748.99899827797, 1877.7500009318344, 1969.0626183429747, 1685.4190030862358, 1723.1191424886688, 1706.6741281756917, 1638.3373827752266, 1642.8498069239026, 1760.0468256127742, 1930.2475138656966, 1770.499151098819, 1853.4548349162094, 1640.7312160812262, 1652.9922722969347, 1683.886412176467, 1762.0639257067032, 1629.198486328125, 1682.4088321132515, 1662.0294674007037, 1677.8970984539003, 1657.7623169877147, 1655.4487565601146, 1756.6678066108063, 1755.5713337905534, 1942.5706721880963, 1526.075233051795, 1612.1580717363431, 1593.9773862416507, 1642.1961418326575, 1698.5302119364264, 1701.2629636808206, 1580.7307809145395, 1561.1727546517175, 1589.4364013671875, 1652.4858156160544, 1884.532794049678, 1781.2873572429628, 1651.3239177674739, 1686.4168794355319, 1606.2521842199428, 1570.427638396052, 1864.9839109464456, 1846.010063812023, 1649.9569883856154, 1616.7599333552005, 1694.5234375, 1709.6154831747972, 1612.9891581062143, 1621.1793529714337, 1682.1121760943463, 1697.9444999403627, 1733.891202737357, 1762.6565267548306, 1678.753363922352, 1737.3461550647066, 1667.8266042461833], 'val_acc': [0.8755617942518861, 0.8879155571224125, 0.8975520902917585, 0.9015340732254145, 0.9077123703847405, 0.9144834857860594, 0.9220493222010955, 0.9263192210488647, 0.9297309035563287, 0.9327953530631903, 0.9352189507193238, 0.9368761145431577, 0.938718150135215, 0.9404289413044471, 0.9418235384780942, 0.9435470236166743, 0.9433494223893144, 0.9444969719602861, 0.94721419438151, 0.9455782284263436, 0.9463954995606692, 0.9481119304212905, 0.9496039306844464, 0.9489588355290071, 0.9482883542548609, 0.9499949194092787, 0.947832424222058, 0.9522053822306277, 0.9508037394239702, 0.9526217911989634, 0.953395298419108, 0.950500245312698, 0.9553686507785594, 0.951043684063977, 0.9516746601985611, 0.9506724636063321, 0.9547659117756909, 0.9518355740845659, 0.9508517243479955, 0.9557328101332861, 0.9537157225244828, 0.9548152939963886, 0.9521460942639649, 0.9549338731146951, 0.9552853644349193, 0.9551724227330157, 0.9556283509458294, 0.9515433757359745, 0.9509519543356568, 0.956118166901683, 0.9533374223090311, 0.9551456079228233, 0.9512031979233254, 0.9557370461580408, 0.9560461644907944, 0.9567576128107901, 0.9550355044940045, 0.9546897015498794, 0.9587774890979738, 0.9570935414037631, 0.9574760526191187, 0.9568888636035774, 0.9541279200379175, 0.9559925471553365, 0.9574322855199566, 0.9575720493120091, 0.9574605235616669, 0.9585798742206952, 0.9572530343332364, 0.9572205761916764, 0.958736554811929, 0.9564851608895163, 0.9582806397940367, 0.9578233038196127, 0.9552867731065241, 0.9567646443388844, 0.9581648839339045, 0.9568803810891304, 0.9582820361807146, 0.9571358793564425, 0.9597119206690606, 0.9603852324813377, 0.9557356474963763, 0.9546021587066068, 0.9584302479074202, 0.9572996074006758, 0.9561957976290287, 0.9523860793987303, 0.9568733381861039], 'val_mDice': [0.18127621039179445, 0.3244619146558165, 0.3947730132641683, 0.42952374101595114, 0.4767387971168256, 0.5067488833238151, 0.540968173787794, 0.5657496516031163, 0.5795766492836348, 0.6012893196280676, 0.6109629560062904, 0.6212887431829031, 0.6318257874204912, 0.6447051144738234, 0.647972222502905, 0.6444833915652209, 0.6550575804164391, 0.6605129223743468, 0.6673935824678144, 0.6629864896526774, 0.6708555535505746, 0.6767496289187716, 0.6803576008964131, 0.676198962535567, 0.6706282637501491, 0.6813711146361955, 0.6773015465445191, 0.6857671965169543, 0.6869674884635983, 0.6835040923293311, 0.6908570241382104, 0.6853867414343449, 0.6939365308703357, 0.6825669981141127, 0.6654966123231495, 0.652467240359037, 0.6906530593187754, 0.6866904888444274, 0.6879031576273096, 0.6979760727809585, 0.6971664005563459, 0.6811152223412317, 0.6579207072731192, 0.6808068465640527, 0.6689880294654206, 0.6986701652293897, 0.6958086636230236, 0.690447577538381, 0.6789979033797752, 0.6997452460172522, 0.6914988515031246, 0.6944332964547718, 0.6921224007169708, 0.6961349849482529, 0.6954785344254879, 0.6840668498104765, 0.6831259627378624, 0.6580063013630059, 0.7155408595354502, 0.7010539933925367, 0.7058987885941076, 0.6981614364012507, 0.6896583105771597, 0.6891794996407196, 0.707828875716406, 0.7097976212283127, 0.7073227831425558, 0.697498842050101, 0.6668638273049857, 0.6802857559145862, 0.6980847265884167, 0.6935037884093423, 0.7036963896897003, 0.7086318763157794, 0.6669228213434001, 0.6707985319254053, 0.6985953987099742, 0.7029752280875927, 0.6921015377263077, 0.6895239071081612, 0.7042406114913126, 0.702320417375055, 0.6921972545958658, 0.6887976358865053, 0.6852123955733903, 0.6836918060106175, 0.6932918602273664, 0.6842993975595664, 0.6949789296579725], 'loss': [18985.645057991514, 8148.676501648582, 6189.475472489232, 5158.86753385645, 4606.667058589136, 4114.413806770158, 3716.1716812715777, 3369.6462615932605, 3075.3519593162227, 2871.953434020024, 2707.090417984115, 2592.7200314677275, 2481.519469569677, 2388.1536851052597, 2340.4569161665167, 2259.872287852631, 2200.4845644382117, 2140.5876727191753, 2090.308038876835, 2048.5850715167085, 2009.0837999791977, 1968.4484171971662, 1940.7637457124058, 1897.1222330937285, 1866.0623440212673, 1850.8865422002582, 1810.0502766938976, 1791.0994384087753, 1765.8161091224515, 1746.8168826001242, 1726.1805137386393, 1706.5194979837736, 1681.7086438339704, 1685.5116300648388, 1662.9737907861954, 1949.7263754551489, 1679.4201333574013, 1647.2696796413334, 1624.9743856418627, 1610.1822660591943, 1588.9701986402524, 1579.7433457245195, 1572.1962123753597, 1566.666165954807, 1552.2124118190798, 1549.3227962434619, 1541.2025791844412, 1518.3476748453716, 1516.4532555897845, 1503.1747591021558, 1499.807039177524, 1487.7881308464598, 1493.550842505167, 1472.6802508346616, 1466.5546297412207, 1464.277131614999, 1464.1076537396175, 1461.6332115059247, 1445.007400859807, 1435.0249612278549, 1432.4318578797115, 1429.6059753976915, 1422.2185190362377, 1415.2884575743794, 1407.6562491913116, 1402.2251346091439, 1400.71307311206, 1391.4147464332802, 1418.4387829215825, 1389.2505516339525, 1387.660396365022, 1372.1030166761998, 1377.0745963717675, 1370.7188888387027, 1365.0343929047162, 1355.1327077391852, 1354.3578345587578, 1355.927263983006, 1344.6357397658946, 1346.6984454432816, 1340.3624379382259, 1339.8193612283353, 1330.1516075136135, 1324.6038017163316, 1329.0183266017166, 1327.0866581289993, 1320.2231932963448, 1328.3218784506016, 1317.779918777129], 'acc': [0.8530010669135834, 0.8722503729027776, 0.888156754965092, 0.8996515523569171, 0.9057627131217837, 0.9117648096885711, 0.9163380236056365, 0.9205760395795745, 0.9242729313642192, 0.9270530246109986, 0.9291323423327551, 0.9310829700000497, 0.9327141594605727, 0.9339761935100791, 0.9350241581790545, 0.9361178449238611, 0.9371018046857529, 0.9380406545671742, 0.9387125121478105, 0.9394345924819322, 0.9401131116198207, 0.940754092269822, 0.941421499077068, 0.9420750309049523, 0.9426576809322406, 0.9430465090901372, 0.9433605228822702, 0.9439784980585597, 0.9443617914247817, 0.9448217068362372, 0.9452026087638842, 0.9453430315813985, 0.9458740486997189, 0.9460028558091208, 0.9463602486242768, 0.9419856438611695, 0.9460916292348591, 0.9467457604365294, 0.946976779611003, 0.9473717148133612, 0.9476681626994551, 0.9478953647493904, 0.9479496619560743, 0.9482071987257135, 0.948285308776268, 0.9483976643155975, 0.9486665729017926, 0.9490152610231523, 0.9489886378648481, 0.9491738088846706, 0.9492950996361251, 0.9494342090871111, 0.9494122530633704, 0.9496588717683895, 0.9497982876886958, 0.9499883945590191, 0.9500017074418141, 0.94993228012927, 0.9501903568451598, 0.9503421863436937, 0.9504164762036812, 0.9505790067552922, 0.9506218444964838, 0.9508117359434439, 0.950850739252713, 0.9510073592934689, 0.9510875937071027, 0.9510828369695902, 0.9508144208903992, 0.9512794143510542, 0.9513069032211672, 0.9515156221579074, 0.9514929432975572, 0.9515245225578307, 0.9515689278091409, 0.9516632178858836, 0.9517124121841462, 0.9518024893457144, 0.9518287863493999, 0.9517664568586469, 0.9519541160392194, 0.9520208963353006, 0.9522062116704267, 0.9523207145274031, 0.9521513590334661, 0.9521468911210911, 0.9523595531305351, 0.9523059956933015, 0.9523354500446499], 'mDice': [0.09509395292440075, 0.22005544561134044, 0.3132557963028857, 0.37984828732900877, 0.41786493605683345, 0.4550605262372235, 0.4866070166310772, 0.5172228241891251, 0.5439272674456673, 0.5652138379587689, 0.5825620937105846, 0.5957816204294679, 0.6085400038184992, 0.6192815729620464, 0.6257006407271835, 0.635317349014062, 0.642606379587574, 0.6502227616023261, 0.6566409765846563, 0.6621191883419312, 0.6672676581746215, 0.6725539162292641, 0.6764284898635619, 0.6821727552203267, 0.6864079650927173, 0.688463931747637, 0.6937813237160655, 0.6966887159577254, 0.7000722452752095, 0.702921959212104, 0.7056796034635887, 0.7084064730086256, 0.7118775419046344, 0.7115182613738822, 0.7149560875873825, 0.6783789772600396, 0.712314959566292, 0.7168778881384896, 0.7199966637713915, 0.7221944184686305, 0.7252135991562394, 0.726546870575674, 0.7277476455297883, 0.7285951155938898, 0.7305475011989826, 0.7313200824677297, 0.7322593711251622, 0.7354248067396488, 0.7357901133293125, 0.7376658480957936, 0.7382496351435969, 0.7399553958999994, 0.7391969219929488, 0.7421046693161637, 0.7430018073973952, 0.743510986359877, 0.7435683679915165, 0.7438562309418532, 0.7462450927984025, 0.7476796562042545, 0.7482329532217368, 0.7486268470311596, 0.7497423230785849, 0.7506028123603155, 0.7519545872721648, 0.7526612128265603, 0.7529280796785711, 0.7542781095583967, 0.7505937732661413, 0.7545112294271364, 0.7548241080946985, 0.757120415691022, 0.756547641322119, 0.7573631687057228, 0.75810833738634, 0.7595475171369436, 0.7597810131313449, 0.7596054363253055, 0.761236825260616, 0.7608915906229093, 0.761911157260038, 0.7620338647606788, 0.763499000427976, 0.7642966256208326, 0.7635982137397886, 0.7639798732901161, 0.7649797027995673, 0.7639697590331385, 0.7654235088806063]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:46, 15.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:28<00:29, 14.69s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.57s/it]predicting test subjects: 100%|██████████| 4/4 [00:56<00:00, 14.37s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:48:34, 21.01s/it]predicting train subjects:   1%|          | 2/311 [00:31<1:31:12, 17.71s/it]predicting train subjects:   1%|          | 3/311 [00:43<1:23:28, 16.26s/it]predicting train subjects:   1%|▏         | 4/311 [00:56<1:17:03, 15.06s/it]predicting train subjects:   2%|▏         | 5/311 [01:07<1:11:18, 13.98s/it]predicting train subjects:   2%|▏         | 6/311 [01:18<1:06:49, 13.15s/it]predicting train subjects:   2%|▏         | 7/311 [01:32<1:07:36, 13.34s/it]predicting train subjects:   3%|▎         | 8/311 [01:47<1:10:23, 13.94s/it]predicting train subjects:   3%|▎         | 9/311 [02:01<1:09:56, 13.89s/it]predicting train subjects:   3%|▎         | 10/311 [02:12<1:05:44, 13.10s/it]predicting train subjects:   4%|▎         | 11/311 [02:28<1:08:38, 13.73s/it]predicting train subjects:   4%|▍         | 12/311 [02:39<1:05:03, 13.05s/it]predicting train subjects:   4%|▍         | 13/311 [02:51<1:03:14, 12.73s/it]predicting train subjects:   5%|▍         | 14/311 [03:06<1:06:46, 13.49s/it]predicting train subjects:   5%|▍         | 15/311 [03:28<1:18:14, 15.86s/it]predicting train subjects:   5%|▌         | 16/311 [03:49<1:25:46, 17.45s/it]predicting train subjects:   5%|▌         | 17/311 [04:10<1:30:44, 18.52s/it]predicting train subjects:   6%|▌         | 18/311 [04:32<1:35:58, 19.65s/it]predicting train subjects:   6%|▌         | 19/311 [04:53<1:37:34, 20.05s/it]predicting train subjects:   6%|▋         | 20/311 [05:15<1:39:04, 20.43s/it]predicting train subjects:   7%|▋         | 21/311 [05:35<1:39:21, 20.56s/it]predicting train subjects:   7%|▋         | 22/311 [05:57<1:40:03, 20.77s/it]predicting train subjects:   7%|▋         | 23/311 [06:18<1:40:21, 20.91s/it]predicting train subjects:   8%|▊         | 24/311 [06:39<1:40:57, 21.11s/it]predicting train subjects:   8%|▊         | 25/311 [07:01<1:41:08, 21.22s/it]predicting train subjects:   8%|▊         | 26/311 [07:23<1:42:28, 21.57s/it]predicting train subjects:   9%|▊         | 27/311 [07:44<1:40:54, 21.32s/it]predicting train subjects:   9%|▉         | 28/311 [08:06<1:41:50, 21.59s/it]predicting train subjects:   9%|▉         | 29/311 [08:27<1:40:35, 21.40s/it]predicting train subjects:  10%|▉         | 30/311 [08:50<1:41:31, 21.68s/it]predicting train subjects:  10%|▉         | 31/311 [09:11<1:40:18, 21.49s/it]predicting train subjects:  10%|█         | 32/311 [09:33<1:40:51, 21.69s/it]predicting train subjects:  11%|█         | 33/311 [09:43<1:24:21, 18.21s/it]predicting train subjects:  11%|█         | 34/311 [09:53<1:12:19, 15.67s/it]predicting train subjects:  11%|█▏        | 35/311 [10:03<1:04:31, 14.03s/it]predicting train subjects:  12%|█▏        | 36/311 [10:14<1:00:15, 13.15s/it]predicting train subjects:  12%|█▏        | 37/311 [10:24<56:05, 12.28s/it]  predicting train subjects:  12%|█▏        | 38/311 [10:34<52:19, 11.50s/it]predicting train subjects:  13%|█▎        | 39/311 [10:44<50:01, 11.04s/it]predicting train subjects:  13%|█▎        | 40/311 [10:54<48:46, 10.80s/it]predicting train subjects:  13%|█▎        | 41/311 [11:04<47:54, 10.65s/it]predicting train subjects:  14%|█▎        | 42/311 [11:14<46:27, 10.36s/it]predicting train subjects:  14%|█▍        | 43/311 [11:24<45:46, 10.25s/it]predicting train subjects:  14%|█▍        | 44/311 [11:34<45:32, 10.23s/it]predicting train subjects:  14%|█▍        | 45/311 [11:44<44:54, 10.13s/it]predicting train subjects:  15%|█▍        | 46/311 [11:54<44:15, 10.02s/it]predicting train subjects:  15%|█▌        | 47/311 [12:04<44:11, 10.04s/it]predicting train subjects:  15%|█▌        | 48/311 [12:14<44:24, 10.13s/it]predicting train subjects:  16%|█▌        | 49/311 [12:25<44:20, 10.16s/it]predicting train subjects:  16%|█▌        | 50/311 [12:34<43:41, 10.05s/it]predicting train subjects:  16%|█▋        | 51/311 [12:47<47:08, 10.88s/it]predicting train subjects:  17%|█▋        | 52/311 [13:00<49:21, 11.44s/it]predicting train subjects:  17%|█▋        | 53/311 [13:13<51:03, 11.87s/it]predicting train subjects:  17%|█▋        | 54/311 [13:26<52:07, 12.17s/it]predicting train subjects:  18%|█▊        | 55/311 [13:38<52:45, 12.36s/it]predicting train subjects:  18%|█▊        | 56/311 [13:51<52:46, 12.42s/it]predicting train subjects:  18%|█▊        | 57/311 [14:04<52:45, 12.46s/it]predicting train subjects:  19%|█▊        | 58/311 [14:16<52:47, 12.52s/it]predicting train subjects:  19%|█▉        | 59/311 [14:29<52:49, 12.58s/it]predicting train subjects:  19%|█▉        | 60/311 [14:42<53:04, 12.69s/it]predicting train subjects:  20%|█▉        | 61/311 [14:55<52:57, 12.71s/it]predicting train subjects:  20%|█▉        | 62/311 [15:07<52:45, 12.71s/it]predicting train subjects:  20%|██        | 63/311 [15:20<52:49, 12.78s/it]predicting train subjects:  21%|██        | 64/311 [15:33<52:35, 12.77s/it]predicting train subjects:  21%|██        | 65/311 [15:46<52:43, 12.86s/it]predicting train subjects:  21%|██        | 66/311 [15:59<52:20, 12.82s/it]predicting train subjects:  22%|██▏       | 67/311 [16:11<51:24, 12.64s/it]predicting train subjects:  22%|██▏       | 68/311 [16:23<50:47, 12.54s/it]predicting train subjects:  22%|██▏       | 69/311 [16:36<50:10, 12.44s/it]predicting train subjects:  23%|██▎       | 70/311 [16:48<49:59, 12.45s/it]predicting train subjects:  23%|██▎       | 71/311 [17:01<49:59, 12.50s/it]predicting train subjects:  23%|██▎       | 72/311 [17:13<49:47, 12.50s/it]predicting train subjects:  23%|██▎       | 73/311 [17:26<49:24, 12.45s/it]predicting train subjects:  24%|██▍       | 74/311 [17:38<48:53, 12.38s/it]predicting train subjects:  24%|██▍       | 75/311 [17:50<48:27, 12.32s/it]predicting train subjects:  24%|██▍       | 76/311 [18:02<47:58, 12.25s/it]predicting train subjects:  25%|██▍       | 77/311 [18:14<47:56, 12.29s/it]predicting train subjects:  25%|██▌       | 78/311 [18:27<47:50, 12.32s/it]predicting train subjects:  25%|██▌       | 79/311 [18:39<47:40, 12.33s/it]predicting train subjects:  26%|██▌       | 80/311 [18:51<47:30, 12.34s/it]predicting train subjects:  26%|██▌       | 81/311 [19:04<47:07, 12.29s/it]predicting train subjects:  26%|██▋       | 82/311 [19:16<46:42, 12.24s/it]predicting train subjects:  27%|██▋       | 83/311 [19:28<46:21, 12.20s/it]predicting train subjects:  27%|██▋       | 84/311 [19:40<46:20, 12.25s/it]predicting train subjects:  27%|██▋       | 85/311 [19:52<45:08, 11.98s/it]predicting train subjects:  28%|██▊       | 86/311 [20:03<43:44, 11.66s/it]predicting train subjects:  28%|██▊       | 87/311 [20:14<43:05, 11.54s/it]predicting train subjects:  28%|██▊       | 88/311 [20:25<42:42, 11.49s/it]predicting train subjects:  29%|██▊       | 89/311 [20:36<42:20, 11.44s/it]predicting train subjects:  29%|██▉       | 90/311 [20:48<42:07, 11.44s/it]predicting train subjects:  29%|██▉       | 91/311 [20:59<41:28, 11.31s/it]predicting train subjects:  30%|██▉       | 92/311 [21:10<41:06, 11.26s/it]predicting train subjects:  30%|██▉       | 93/311 [21:21<40:56, 11.27s/it]predicting train subjects:  30%|███       | 94/311 [21:33<40:52, 11.30s/it]predicting train subjects:  31%|███       | 95/311 [21:44<40:38, 11.29s/it]predicting train subjects:  31%|███       | 96/311 [21:55<40:08, 11.20s/it]predicting train subjects:  31%|███       | 97/311 [22:06<39:46, 11.15s/it]predicting train subjects:  32%|███▏      | 98/311 [22:17<39:50, 11.22s/it]predicting train subjects:  32%|███▏      | 99/311 [22:29<39:44, 11.25s/it]predicting train subjects:  32%|███▏      | 100/311 [22:41<40:26, 11.50s/it]predicting train subjects:  32%|███▏      | 101/311 [22:52<39:49, 11.38s/it]predicting train subjects:  33%|███▎      | 102/311 [23:03<39:19, 11.29s/it]predicting train subjects:  33%|███▎      | 103/311 [23:14<39:11, 11.31s/it]predicting train subjects:  33%|███▎      | 104/311 [23:27<40:03, 11.61s/it]predicting train subjects:  34%|███▍      | 105/311 [23:38<39:34, 11.53s/it]predicting train subjects:  34%|███▍      | 106/311 [23:49<38:58, 11.41s/it]predicting train subjects:  34%|███▍      | 107/311 [24:00<38:38, 11.37s/it]predicting train subjects:  35%|███▍      | 108/311 [24:12<38:33, 11.40s/it]predicting train subjects:  35%|███▌      | 109/311 [24:23<38:30, 11.44s/it]predicting train subjects:  35%|███▌      | 110/311 [24:35<38:09, 11.39s/it]predicting train subjects:  36%|███▌      | 111/311 [24:46<37:36, 11.28s/it]predicting train subjects:  36%|███▌      | 112/311 [24:58<38:25, 11.59s/it]predicting train subjects:  36%|███▋      | 113/311 [25:10<38:16, 11.60s/it]predicting train subjects:  37%|███▋      | 114/311 [25:31<47:40, 14.52s/it]predicting train subjects:  37%|███▋      | 115/311 [25:52<53:52, 16.49s/it]predicting train subjects:  37%|███▋      | 116/311 [26:13<57:31, 17.70s/it]predicting train subjects:  38%|███▊      | 117/311 [26:34<1:01:11, 18.93s/it]predicting train subjects:  38%|███▊      | 118/311 [26:55<1:02:38, 19.47s/it]predicting train subjects:  38%|███▊      | 119/311 [27:18<1:05:18, 20.41s/it]predicting train subjects:  39%|███▊      | 120/311 [27:39<1:05:39, 20.63s/it]predicting train subjects:  39%|███▉      | 121/311 [28:00<1:05:43, 20.76s/it]predicting train subjects:  39%|███▉      | 122/311 [28:22<1:06:27, 21.10s/it]predicting train subjects:  40%|███▉      | 123/311 [28:43<1:06:03, 21.08s/it]predicting train subjects:  40%|███▉      | 124/311 [29:04<1:05:57, 21.16s/it]predicting train subjects:  40%|████      | 125/311 [29:27<1:06:47, 21.55s/it]predicting train subjects:  41%|████      | 126/311 [29:48<1:06:12, 21.47s/it]predicting train subjects:  41%|████      | 127/311 [30:09<1:05:16, 21.29s/it]predicting train subjects:  41%|████      | 128/311 [30:30<1:04:59, 21.31s/it]predicting train subjects:  41%|████▏     | 129/311 [30:52<1:04:42, 21.33s/it]predicting train subjects:  42%|████▏     | 130/311 [31:13<1:04:14, 21.29s/it]predicting train subjects:  42%|████▏     | 131/311 [31:35<1:04:25, 21.47s/it]predicting train subjects:  42%|████▏     | 132/311 [31:45<53:49, 18.04s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:55<46:40, 15.73s/it]predicting train subjects:  43%|████▎     | 134/311 [32:05<41:01, 13.91s/it]predicting train subjects:  43%|████▎     | 135/311 [32:15<37:21, 12.74s/it]predicting train subjects:  44%|████▎     | 136/311 [32:25<35:01, 12.01s/it]predicting train subjects:  44%|████▍     | 137/311 [32:35<32:55, 11.35s/it]predicting train subjects:  44%|████▍     | 138/311 [32:45<31:42, 11.00s/it]predicting train subjects:  45%|████▍     | 139/311 [32:55<31:04, 10.84s/it]predicting train subjects:  45%|████▌     | 140/311 [33:05<29:53, 10.49s/it]predicting train subjects:  45%|████▌     | 141/311 [33:15<29:33, 10.43s/it]predicting train subjects:  46%|████▌     | 142/311 [33:26<29:20, 10.42s/it]predicting train subjects:  46%|████▌     | 143/311 [33:35<28:25, 10.15s/it]predicting train subjects:  46%|████▋     | 144/311 [33:46<28:29, 10.24s/it]predicting train subjects:  47%|████▋     | 145/311 [33:56<28:40, 10.37s/it]predicting train subjects:  47%|████▋     | 146/311 [34:06<28:02, 10.20s/it]predicting train subjects:  47%|████▋     | 147/311 [34:16<27:48, 10.17s/it]predicting train subjects:  48%|████▊     | 148/311 [34:27<27:59, 10.31s/it]predicting train subjects:  48%|████▊     | 149/311 [34:37<27:25, 10.16s/it]predicting train subjects:  48%|████▊     | 150/311 [34:50<29:22, 10.95s/it]predicting train subjects:  49%|████▊     | 151/311 [35:02<30:41, 11.51s/it]predicting train subjects:  49%|████▉     | 152/311 [35:15<31:39, 11.95s/it]predicting train subjects:  49%|████▉     | 153/311 [35:28<32:08, 12.21s/it]predicting train subjects:  50%|████▉     | 154/311 [35:41<32:24, 12.39s/it]predicting train subjects:  50%|████▉     | 155/311 [35:54<32:26, 12.47s/it]predicting train subjects:  50%|█████     | 156/311 [36:06<32:29, 12.57s/it]predicting train subjects:  50%|█████     | 157/311 [36:19<32:25, 12.63s/it]predicting train subjects:  51%|█████     | 158/311 [36:32<32:29, 12.74s/it]predicting train subjects:  51%|█████     | 159/311 [36:45<32:16, 12.74s/it]predicting train subjects:  51%|█████▏    | 160/311 [36:58<32:03, 12.74s/it]predicting train subjects:  52%|█████▏    | 161/311 [37:10<31:51, 12.74s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:24<32:15, 12.99s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:37<31:56, 12.95s/it]predicting train subjects:  53%|█████▎    | 164/311 [37:50<31:37, 12.91s/it]predicting train subjects:  53%|█████▎    | 165/311 [38:03<31:46, 13.06s/it]predicting train subjects:  53%|█████▎    | 166/311 [38:16<31:16, 12.94s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:28<30:46, 12.82s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:41<30:17, 12.71s/it]predicting train subjects:  54%|█████▍    | 169/311 [38:54<30:16, 12.79s/it]predicting train subjects:  55%|█████▍    | 170/311 [39:06<29:38, 12.61s/it]predicting train subjects:  55%|█████▍    | 171/311 [39:18<29:05, 12.47s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:30<28:41, 12.39s/it]predicting train subjects:  56%|█████▌    | 173/311 [39:43<28:38, 12.45s/it]predicting train subjects:  56%|█████▌    | 174/311 [39:55<28:32, 12.50s/it]predicting train subjects:  56%|█████▋    | 175/311 [40:08<28:33, 12.60s/it]predicting train subjects:  57%|█████▋    | 176/311 [40:22<28:47, 12.79s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:34<28:11, 12.62s/it]predicting train subjects:  57%|█████▋    | 178/311 [40:46<27:30, 12.41s/it]predicting train subjects:  58%|█████▊    | 179/311 [40:58<27:12, 12.37s/it]predicting train subjects:  58%|█████▊    | 180/311 [41:10<27:03, 12.39s/it]predicting train subjects:  58%|█████▊    | 181/311 [41:23<26:50, 12.39s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:35<26:26, 12.30s/it]predicting train subjects:  59%|█████▉    | 183/311 [41:48<26:33, 12.45s/it]predicting train subjects:  59%|█████▉    | 184/311 [41:59<25:41, 12.14s/it]predicting train subjects:  59%|█████▉    | 185/311 [42:11<25:01, 11.92s/it]predicting train subjects:  60%|█████▉    | 186/311 [42:22<24:32, 11.78s/it]predicting train subjects:  60%|██████    | 187/311 [42:33<24:09, 11.69s/it]predicting train subjects:  60%|██████    | 188/311 [42:44<23:31, 11.48s/it]predicting train subjects:  61%|██████    | 189/311 [42:56<23:13, 11.42s/it]predicting train subjects:  61%|██████    | 190/311 [43:07<23:03, 11.43s/it]predicting train subjects:  61%|██████▏   | 191/311 [43:19<23:12, 11.61s/it]predicting train subjects:  62%|██████▏   | 192/311 [43:30<22:50, 11.52s/it]predicting train subjects:  62%|██████▏   | 193/311 [43:41<22:19, 11.35s/it]predicting train subjects:  62%|██████▏   | 194/311 [43:53<22:18, 11.44s/it]predicting train subjects:  63%|██████▎   | 195/311 [44:04<22:03, 11.41s/it]predicting train subjects:  63%|██████▎   | 196/311 [44:16<21:48, 11.38s/it]predicting train subjects:  63%|██████▎   | 197/311 [44:27<21:23, 11.25s/it]predicting train subjects:  64%|██████▎   | 198/311 [44:38<21:08, 11.22s/it]predicting train subjects:  64%|██████▍   | 199/311 [44:50<21:11, 11.35s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:01<20:59, 11.35s/it]predicting train subjects:  65%|██████▍   | 201/311 [45:12<20:51, 11.38s/it]predicting train subjects:  65%|██████▍   | 202/311 [45:23<20:26, 11.25s/it]predicting train subjects:  65%|██████▌   | 203/311 [45:34<20:11, 11.22s/it]predicting train subjects:  66%|██████▌   | 204/311 [45:46<20:11, 11.33s/it]predicting train subjects:  66%|██████▌   | 205/311 [45:58<20:08, 11.40s/it]predicting train subjects:  66%|██████▌   | 206/311 [46:10<20:27, 11.69s/it]predicting train subjects:  67%|██████▋   | 207/311 [46:21<20:08, 11.62s/it]predicting train subjects:  67%|██████▋   | 208/311 [46:33<19:43, 11.49s/it]predicting train subjects:  67%|██████▋   | 209/311 [46:44<19:25, 11.42s/it]predicting train subjects:  68%|██████▊   | 210/311 [46:55<19:15, 11.44s/it]predicting train subjects:  68%|██████▊   | 211/311 [47:07<19:07, 11.47s/it]predicting train subjects:  68%|██████▊   | 212/311 [47:18<18:51, 11.43s/it]predicting train subjects:  68%|██████▊   | 213/311 [47:40<23:48, 14.57s/it]predicting train subjects:  69%|██████▉   | 214/311 [48:01<26:48, 16.59s/it]predicting train subjects:  69%|██████▉   | 215/311 [48:23<28:55, 18.08s/it]predicting train subjects:  69%|██████▉   | 216/311 [48:44<29:58, 18.93s/it]predicting train subjects:  70%|██████▉   | 217/311 [49:06<31:13, 19.93s/it]predicting train subjects:  70%|███████   | 218/311 [49:27<31:28, 20.30s/it]predicting train subjects:  70%|███████   | 219/311 [49:49<31:50, 20.76s/it]predicting train subjects:  71%|███████   | 220/311 [50:10<31:32, 20.80s/it]predicting train subjects:  71%|███████   | 221/311 [50:33<31:57, 21.30s/it]predicting train subjects:  71%|███████▏  | 222/311 [50:53<31:24, 21.17s/it]predicting train subjects:  72%|███████▏  | 223/311 [51:15<31:18, 21.35s/it]predicting train subjects:  72%|███████▏  | 224/311 [51:36<30:47, 21.24s/it]predicting train subjects:  72%|███████▏  | 225/311 [51:58<30:37, 21.37s/it]predicting train subjects:  73%|███████▎  | 226/311 [52:19<30:04, 21.22s/it]predicting train subjects:  73%|███████▎  | 227/311 [52:40<29:52, 21.34s/it]predicting train subjects:  73%|███████▎  | 228/311 [53:02<29:32, 21.35s/it]predicting train subjects:  74%|███████▎  | 229/311 [53:23<29:07, 21.30s/it]predicting train subjects:  74%|███████▍  | 230/311 [53:44<28:46, 21.31s/it]predicting train subjects:  74%|███████▍  | 231/311 [53:54<23:59, 17.99s/it]predicting train subjects:  75%|███████▍  | 232/311 [54:04<20:26, 15.53s/it]predicting train subjects:  75%|███████▍  | 233/311 [54:14<18:01, 13.87s/it]predicting train subjects:  75%|███████▌  | 234/311 [54:25<16:31, 12.88s/it]predicting train subjects:  76%|███████▌  | 235/311 [54:35<15:07, 11.94s/it]predicting train subjects:  76%|███████▌  | 236/311 [54:45<14:15, 11.41s/it]predicting train subjects:  76%|███████▌  | 237/311 [54:55<13:44, 11.14s/it]predicting train subjects:  77%|███████▋  | 238/311 [55:05<13:11, 10.84s/it]predicting train subjects:  77%|███████▋  | 239/311 [55:15<12:36, 10.51s/it]predicting train subjects:  77%|███████▋  | 240/311 [55:25<12:22, 10.46s/it]predicting train subjects:  77%|███████▋  | 241/311 [55:36<12:08, 10.41s/it]predicting train subjects:  78%|███████▊  | 242/311 [55:45<11:42, 10.18s/it]predicting train subjects:  78%|███████▊  | 243/311 [55:56<11:40, 10.30s/it]predicting train subjects:  78%|███████▊  | 244/311 [56:06<11:27, 10.26s/it]predicting train subjects:  79%|███████▉  | 245/311 [56:16<11:08, 10.12s/it]predicting train subjects:  79%|███████▉  | 246/311 [56:26<11:02, 10.19s/it]predicting train subjects:  79%|███████▉  | 247/311 [56:37<11:00, 10.33s/it]predicting train subjects:  80%|███████▉  | 248/311 [56:47<10:44, 10.23s/it]predicting train subjects:  80%|████████  | 249/311 [57:00<11:18, 10.94s/it]predicting train subjects:  80%|████████  | 250/311 [57:12<11:42, 11.51s/it]predicting train subjects:  81%|████████  | 251/311 [57:25<11:56, 11.94s/it]predicting train subjects:  81%|████████  | 252/311 [57:38<12:04, 12.28s/it]predicting train subjects:  81%|████████▏ | 253/311 [57:51<12:05, 12.50s/it]predicting train subjects:  82%|████████▏ | 254/311 [58:05<12:13, 12.87s/it]predicting train subjects:  82%|████████▏ | 255/311 [58:18<12:01, 12.88s/it]predicting train subjects:  82%|████████▏ | 256/311 [58:31<11:48, 12.89s/it]predicting train subjects:  83%|████████▎ | 257/311 [58:44<11:38, 12.93s/it]predicting train subjects:  83%|████████▎ | 258/311 [58:57<11:22, 12.88s/it]predicting train subjects:  83%|████████▎ | 259/311 [59:09<11:06, 12.83s/it]predicting train subjects:  84%|████████▎ | 260/311 [59:23<10:58, 12.90s/it]predicting train subjects:  84%|████████▍ | 261/311 [59:35<10:43, 12.86s/it]predicting train subjects:  84%|████████▍ | 262/311 [59:48<10:34, 12.95s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:00:01<10:20, 12.93s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:00:14<10:08, 12.94s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:00:27<09:47, 12.78s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:00:39<09:28, 12.63s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:00:51<09:08, 12.46s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:01:03<08:55, 12.46s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:01:16<08:42, 12.43s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:01:28<08:29, 12.43s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:01:41<08:20, 12.52s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:01:53<08:04, 12.43s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:02:05<07:50, 12.37s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:02:18<07:39, 12.42s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:02:31<07:28, 12.47s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:02:43<07:16, 12.47s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:02:55<07:00, 12.38s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:03:07<06:45, 12.29s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:03:20<06:33, 12.29s/it]predicting train subjects:  90%|█████████ | 280/311 [1:03:32<06:22, 12.34s/it]predicting train subjects:  90%|█████████ | 281/311 [1:03:44<06:11, 12.37s/it]predicting train subjects:  91%|█████████ | 282/311 [1:03:57<05:57, 12.34s/it]predicting train subjects:  91%|█████████ | 283/311 [1:04:08<05:33, 11.92s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:04:19<05:16, 11.72s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:04:30<05:01, 11.61s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:04:41<04:45, 11.43s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:04:53<04:32, 11.36s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:05:04<04:20, 11.32s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:05:15<04:09, 11.33s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:05:26<03:55, 11.22s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:05:37<03:43, 11.15s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:05:48<03:32, 11.19s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:06:00<03:22, 11.28s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:06:11<03:10, 11.18s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:06:22<03:00, 11.25s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:06:34<02:49, 11.33s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:06:45<02:40, 11.46s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:06:57<02:28, 11.44s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:07:08<02:16, 11.36s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:07:20<02:06, 11.47s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:07:32<01:56, 11.60s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:07:43<01:44, 11.67s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:07:55<01:32, 11.60s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:08:06<01:20, 11.55s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:08:18<01:09, 11.59s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:08:30<00:58, 11.64s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:08:41<00:46, 11.51s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:08:52<00:34, 11.44s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:09:04<00:23, 11.53s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:09:16<00:11, 11.67s/it]predicting train subjects: 100%|██████████| 311/311 [1:09:27<00:00, 11.58s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:29:11, 17.26s/it]Loading train:   1%|          | 2/311 [00:25<1:15:28, 14.66s/it]Loading train:   1%|          | 3/311 [00:36<1:09:21, 13.51s/it]Loading train:   1%|▏         | 4/311 [00:47<1:04:14, 12.56s/it]Loading train:   2%|▏         | 5/311 [00:56<59:21, 11.64s/it]  Loading train:   2%|▏         | 6/311 [01:06<55:59, 11.02s/it]Loading train:   2%|▏         | 7/311 [01:17<55:42, 10.99s/it]Loading train:   3%|▎         | 8/311 [01:29<58:00, 11.49s/it]Loading train:   3%|▎         | 9/311 [01:41<58:00, 11.52s/it]Loading train:   3%|▎         | 10/311 [01:50<54:59, 10.96s/it]Loading train:   4%|▎         | 11/311 [02:03<57:32, 11.51s/it]Loading train:   4%|▍         | 12/311 [02:13<55:02, 11.04s/it]Loading train:   4%|▍         | 13/311 [02:23<52:57, 10.66s/it]Loading train:   5%|▍         | 14/311 [02:36<55:49, 11.28s/it]Loading train:   5%|▍         | 15/311 [02:45<53:12, 10.78s/it]Loading train:   5%|▌         | 16/311 [02:55<51:01, 10.38s/it]Loading train:   5%|▌         | 17/311 [03:04<49:17, 10.06s/it]Loading train:   6%|▌         | 18/311 [03:13<48:04,  9.85s/it]Loading train:   6%|▌         | 19/311 [03:23<47:02,  9.67s/it]Loading train:   6%|▋         | 20/311 [03:32<46:19,  9.55s/it]Loading train:   7%|▋         | 21/311 [03:41<45:47,  9.47s/it]Loading train:   7%|▋         | 22/311 [03:51<45:36,  9.47s/it]Loading train:   7%|▋         | 23/311 [04:00<45:17,  9.44s/it]Loading train:   8%|▊         | 24/311 [04:10<45:25,  9.50s/it]Loading train:   8%|▊         | 25/311 [04:19<44:43,  9.38s/it]Loading train:   8%|▊         | 26/311 [04:28<44:18,  9.33s/it]Loading train:   9%|▊         | 27/311 [04:37<43:58,  9.29s/it]Loading train:   9%|▉         | 28/311 [04:47<43:56,  9.32s/it]Loading train:   9%|▉         | 29/311 [04:56<44:19,  9.43s/it]Loading train:  10%|▉         | 30/311 [05:06<44:25,  9.48s/it]Loading train:  10%|▉         | 31/311 [05:15<44:13,  9.48s/it]Loading train:  10%|█         | 32/311 [05:25<43:56,  9.45s/it]Loading train:  11%|█         | 33/311 [05:30<37:25,  8.08s/it]Loading train:  11%|█         | 34/311 [05:35<33:18,  7.21s/it]Loading train:  11%|█▏        | 35/311 [05:40<30:18,  6.59s/it]Loading train:  12%|█▏        | 36/311 [05:45<28:03,  6.12s/it]Loading train:  12%|█▏        | 37/311 [05:50<26:47,  5.87s/it]Loading train:  12%|█▏        | 38/311 [05:55<25:45,  5.66s/it]Loading train:  13%|█▎        | 39/311 [06:01<25:00,  5.52s/it]Loading train:  13%|█▎        | 40/311 [06:06<24:30,  5.43s/it]Loading train:  13%|█▎        | 41/311 [06:11<24:14,  5.39s/it]Loading train:  14%|█▎        | 42/311 [06:16<23:41,  5.29s/it]Loading train:  14%|█▍        | 43/311 [06:21<23:33,  5.27s/it]Loading train:  14%|█▍        | 44/311 [06:26<23:11,  5.21s/it]Loading train:  14%|█▍        | 45/311 [06:32<23:02,  5.20s/it]Loading train:  15%|█▍        | 46/311 [06:37<22:52,  5.18s/it]Loading train:  15%|█▌        | 47/311 [06:42<22:30,  5.12s/it]Loading train:  15%|█▌        | 48/311 [06:47<22:05,  5.04s/it]Loading train:  16%|█▌        | 49/311 [06:51<21:52,  5.01s/it]Loading train:  16%|█▌        | 50/311 [06:56<21:46,  5.00s/it]Loading train:  16%|█▋        | 51/311 [07:03<23:35,  5.45s/it]Loading train:  17%|█▋        | 52/311 [07:09<24:16,  5.62s/it]Loading train:  17%|█▋        | 53/311 [07:15<24:52,  5.79s/it]Loading train:  17%|█▋        | 54/311 [07:21<25:12,  5.89s/it]Loading train:  18%|█▊        | 55/311 [07:28<25:44,  6.03s/it]Loading train:  18%|█▊        | 56/311 [07:34<26:07,  6.15s/it]Loading train:  18%|█▊        | 57/311 [07:40<25:50,  6.10s/it]Loading train:  19%|█▊        | 58/311 [07:46<25:56,  6.15s/it]Loading train:  19%|█▉        | 59/311 [07:53<25:57,  6.18s/it]Loading train:  19%|█▉        | 60/311 [07:59<26:11,  6.26s/it]Loading train:  20%|█▉        | 61/311 [08:05<25:55,  6.22s/it]Loading train:  20%|█▉        | 62/311 [08:11<25:49,  6.22s/it]Loading train:  20%|██        | 63/311 [08:18<25:47,  6.24s/it]Loading train:  21%|██        | 64/311 [08:24<25:36,  6.22s/it]Loading train:  21%|██        | 65/311 [08:30<25:42,  6.27s/it]Loading train:  21%|██        | 66/311 [08:37<25:39,  6.28s/it]Loading train:  22%|██▏       | 67/311 [08:43<25:21,  6.24s/it]Loading train:  22%|██▏       | 68/311 [08:49<25:08,  6.21s/it]Loading train:  22%|██▏       | 69/311 [08:55<25:15,  6.26s/it]Loading train:  23%|██▎       | 70/311 [09:01<25:07,  6.26s/it]Loading train:  23%|██▎       | 71/311 [09:07<24:44,  6.19s/it]Loading train:  23%|██▎       | 72/311 [09:14<24:29,  6.15s/it]Loading train:  23%|██▎       | 73/311 [09:20<24:30,  6.18s/it]Loading train:  24%|██▍       | 74/311 [09:26<24:08,  6.11s/it]Loading train:  24%|██▍       | 75/311 [09:32<23:47,  6.05s/it]Loading train:  24%|██▍       | 76/311 [09:38<23:59,  6.13s/it]Loading train:  25%|██▍       | 77/311 [09:44<23:48,  6.11s/it]Loading train:  25%|██▌       | 78/311 [09:50<23:31,  6.06s/it]Loading train:  25%|██▌       | 79/311 [09:56<23:07,  5.98s/it]Loading train:  26%|██▌       | 80/311 [10:02<23:00,  5.97s/it]Loading train:  26%|██▌       | 81/311 [10:08<22:48,  5.95s/it]Loading train:  26%|██▋       | 82/311 [10:13<22:38,  5.93s/it]Loading train:  27%|██▋       | 83/311 [10:19<22:31,  5.93s/it]Loading train:  27%|██▋       | 84/311 [10:25<22:22,  5.91s/it]Loading train:  27%|██▋       | 85/311 [10:31<21:43,  5.77s/it]Loading train:  28%|██▊       | 86/311 [10:36<21:27,  5.72s/it]Loading train:  28%|██▊       | 87/311 [10:42<21:01,  5.63s/it]Loading train:  28%|██▊       | 88/311 [10:48<21:06,  5.68s/it]Loading train:  29%|██▊       | 89/311 [10:53<20:57,  5.67s/it]Loading train:  29%|██▉       | 90/311 [10:59<20:37,  5.60s/it]Loading train:  29%|██▉       | 91/311 [11:04<20:41,  5.64s/it]Loading train:  30%|██▉       | 92/311 [11:10<20:30,  5.62s/it]Loading train:  30%|██▉       | 93/311 [11:15<20:12,  5.56s/it]Loading train:  30%|███       | 94/311 [11:21<20:00,  5.53s/it]Loading train:  31%|███       | 95/311 [11:26<19:53,  5.52s/it]Loading train:  31%|███       | 96/311 [11:32<19:43,  5.51s/it]Loading train:  31%|███       | 97/311 [11:37<19:28,  5.46s/it]Loading train:  32%|███▏      | 98/311 [11:42<19:15,  5.42s/it]Loading train:  32%|███▏      | 99/311 [11:48<19:09,  5.42s/it]Loading train:  32%|███▏      | 100/311 [11:53<19:10,  5.45s/it]Loading train:  32%|███▏      | 101/311 [11:59<19:26,  5.55s/it]Loading train:  33%|███▎      | 102/311 [12:05<19:42,  5.66s/it]Loading train:  33%|███▎      | 103/311 [12:11<19:19,  5.58s/it]Loading train:  33%|███▎      | 104/311 [12:16<19:02,  5.52s/it]Loading train:  34%|███▍      | 105/311 [12:21<19:01,  5.54s/it]Loading train:  34%|███▍      | 106/311 [12:27<18:45,  5.49s/it]Loading train:  34%|███▍      | 107/311 [12:33<18:52,  5.55s/it]Loading train:  35%|███▍      | 108/311 [12:38<18:57,  5.60s/it]Loading train:  35%|███▌      | 109/311 [12:44<18:59,  5.64s/it]Loading train:  35%|███▌      | 110/311 [12:49<18:43,  5.59s/it]Loading train:  36%|███▌      | 111/311 [12:55<18:16,  5.48s/it]Loading train:  36%|███▌      | 112/311 [13:00<17:55,  5.40s/it]Loading train:  36%|███▋      | 113/311 [13:06<18:22,  5.57s/it]Loading train:  37%|███▋      | 114/311 [13:16<22:25,  6.83s/it]Loading train:  37%|███▋      | 115/311 [13:26<25:30,  7.81s/it]Loading train:  37%|███▋      | 116/311 [13:36<27:40,  8.52s/it]Loading train:  38%|███▊      | 117/311 [13:46<29:08,  9.01s/it]Loading train:  38%|███▊      | 118/311 [13:56<29:36,  9.21s/it]Loading train:  38%|███▊      | 119/311 [14:06<30:17,  9.47s/it]Loading train:  39%|███▊      | 120/311 [14:16<30:35,  9.61s/it]Loading train:  39%|███▉      | 121/311 [14:25<30:16,  9.56s/it]Loading train:  39%|███▉      | 122/311 [14:34<29:18,  9.30s/it]Loading train:  40%|███▉      | 123/311 [14:43<28:52,  9.22s/it]Loading train:  40%|███▉      | 124/311 [14:52<28:45,  9.22s/it]Loading train:  40%|████      | 125/311 [15:02<28:42,  9.26s/it]Loading train:  41%|████      | 126/311 [15:11<28:31,  9.25s/it]Loading train:  41%|████      | 127/311 [15:20<28:26,  9.28s/it]Loading train:  41%|████      | 128/311 [15:29<27:55,  9.16s/it]Loading train:  41%|████▏     | 129/311 [15:38<27:23,  9.03s/it]Loading train:  42%|████▏     | 130/311 [15:47<27:08,  9.00s/it]Loading train:  42%|████▏     | 131/311 [15:57<28:15,  9.42s/it]Loading train:  42%|████▏     | 132/311 [16:03<24:58,  8.37s/it]Loading train:  43%|████▎     | 133/311 [16:09<22:26,  7.56s/it]Loading train:  43%|████▎     | 134/311 [16:14<20:43,  7.03s/it]Loading train:  43%|████▎     | 135/311 [16:20<19:29,  6.64s/it]Loading train:  44%|████▎     | 136/311 [16:26<18:29,  6.34s/it]Loading train:  44%|████▍     | 137/311 [16:32<18:29,  6.37s/it]Loading train:  44%|████▍     | 138/311 [16:38<17:38,  6.12s/it]Loading train:  45%|████▍     | 139/311 [16:44<17:19,  6.04s/it]Loading train:  45%|████▌     | 140/311 [16:49<17:04,  5.99s/it]Loading train:  45%|████▌     | 141/311 [16:55<16:36,  5.86s/it]Loading train:  46%|████▌     | 142/311 [17:01<16:32,  5.88s/it]Loading train:  46%|████▌     | 143/311 [17:06<16:03,  5.74s/it]Loading train:  46%|████▋     | 144/311 [17:12<15:51,  5.70s/it]Loading train:  47%|████▋     | 145/311 [17:18<16:00,  5.79s/it]Loading train:  47%|████▋     | 146/311 [17:24<15:57,  5.80s/it]Loading train:  47%|████▋     | 147/311 [17:29<15:37,  5.72s/it]Loading train:  48%|████▊     | 148/311 [17:35<15:31,  5.72s/it]Loading train:  48%|████▊     | 149/311 [17:41<15:19,  5.68s/it]Loading train:  48%|████▊     | 150/311 [17:48<16:33,  6.17s/it]Loading train:  49%|████▊     | 151/311 [17:55<17:09,  6.44s/it]Loading train:  49%|████▉     | 152/311 [18:02<17:27,  6.59s/it]Loading train:  49%|████▉     | 153/311 [18:09<17:59,  6.83s/it]Loading train:  50%|████▉     | 154/311 [18:16<17:44,  6.78s/it]Loading train:  50%|████▉     | 155/311 [18:23<17:40,  6.80s/it]Loading train:  50%|█████     | 156/311 [18:30<17:40,  6.84s/it]Loading train:  50%|█████     | 157/311 [18:37<17:48,  6.94s/it]Loading train:  51%|█████     | 158/311 [18:44<17:27,  6.85s/it]Loading train:  51%|█████     | 159/311 [18:51<17:34,  6.94s/it]Loading train:  51%|█████▏    | 160/311 [18:58<17:42,  7.04s/it]Loading train:  52%|█████▏    | 161/311 [19:05<17:26,  6.98s/it]Loading train:  52%|█████▏    | 162/311 [19:12<17:09,  6.91s/it]Loading train:  52%|█████▏    | 163/311 [19:19<17:12,  6.98s/it]Loading train:  53%|█████▎    | 164/311 [19:26<17:06,  6.98s/it]Loading train:  53%|█████▎    | 165/311 [19:33<17:20,  7.13s/it]Loading train:  53%|█████▎    | 166/311 [19:40<17:19,  7.17s/it]Loading train:  54%|█████▎    | 167/311 [19:47<17:00,  7.08s/it]Loading train:  54%|█████▍    | 168/311 [19:55<17:10,  7.21s/it]Loading train:  54%|█████▍    | 169/311 [20:01<16:30,  6.97s/it]Loading train:  55%|█████▍    | 170/311 [20:08<16:33,  7.04s/it]Loading train:  55%|█████▍    | 171/311 [20:15<16:10,  6.94s/it]Loading train:  55%|█████▌    | 172/311 [20:22<16:08,  6.97s/it]Loading train:  56%|█████▌    | 173/311 [20:29<15:37,  6.79s/it]Loading train:  56%|█████▌    | 174/311 [20:36<15:41,  6.87s/it]Loading train:  56%|█████▋    | 175/311 [20:42<15:21,  6.78s/it]Loading train:  57%|█████▋    | 176/311 [20:49<15:23,  6.84s/it]Loading train:  57%|█████▋    | 177/311 [20:56<15:15,  6.83s/it]Loading train:  57%|█████▋    | 178/311 [21:03<15:10,  6.85s/it]Loading train:  58%|█████▊    | 179/311 [21:10<15:03,  6.84s/it]Loading train:  58%|█████▊    | 180/311 [21:17<15:07,  6.92s/it]Loading train:  58%|█████▊    | 181/311 [21:23<14:47,  6.82s/it]Loading train:  59%|█████▊    | 182/311 [21:30<14:47,  6.88s/it]Loading train:  59%|█████▉    | 183/311 [21:37<14:21,  6.73s/it]Loading train:  59%|█████▉    | 184/311 [21:44<14:13,  6.72s/it]Loading train:  59%|█████▉    | 185/311 [21:50<13:52,  6.61s/it]Loading train:  60%|█████▉    | 186/311 [21:57<13:47,  6.62s/it]Loading train:  60%|██████    | 187/311 [22:03<13:42,  6.63s/it]Loading train:  60%|██████    | 188/311 [22:10<13:31,  6.59s/it]Loading train:  61%|██████    | 189/311 [22:16<13:01,  6.41s/it]Loading train:  61%|██████    | 190/311 [22:22<13:05,  6.49s/it]Loading train:  61%|██████▏   | 191/311 [22:29<12:53,  6.45s/it]Loading train:  62%|██████▏   | 192/311 [22:35<12:49,  6.46s/it]Loading train:  62%|██████▏   | 193/311 [22:41<12:35,  6.40s/it]Loading train:  62%|██████▏   | 194/311 [22:48<12:48,  6.57s/it]Loading train:  63%|██████▎   | 195/311 [22:55<12:32,  6.49s/it]Loading train:  63%|██████▎   | 196/311 [23:01<12:29,  6.52s/it]Loading train:  63%|██████▎   | 197/311 [23:07<12:10,  6.41s/it]Loading train:  64%|██████▎   | 198/311 [23:14<12:07,  6.43s/it]Loading train:  64%|██████▍   | 199/311 [23:20<11:55,  6.38s/it]Loading train:  64%|██████▍   | 200/311 [23:27<12:08,  6.57s/it]Loading train:  65%|██████▍   | 201/311 [23:34<11:59,  6.54s/it]Loading train:  65%|██████▍   | 202/311 [23:41<12:02,  6.63s/it]Loading train:  65%|██████▌   | 203/311 [23:47<11:41,  6.50s/it]Loading train:  66%|██████▌   | 204/311 [23:53<11:33,  6.48s/it]Loading train:  66%|██████▌   | 205/311 [23:59<11:18,  6.40s/it]Loading train:  66%|██████▌   | 206/311 [24:06<11:05,  6.33s/it]Loading train:  67%|██████▋   | 207/311 [24:12<10:47,  6.23s/it]Loading train:  67%|██████▋   | 208/311 [24:18<10:39,  6.21s/it]Loading train:  67%|██████▋   | 209/311 [24:24<10:39,  6.27s/it]Loading train:  68%|██████▊   | 210/311 [24:30<10:33,  6.27s/it]Loading train:  68%|██████▊   | 211/311 [24:37<10:38,  6.39s/it]Loading train:  68%|██████▊   | 212/311 [24:43<10:29,  6.36s/it]Loading train:  68%|██████▊   | 213/311 [24:54<12:44,  7.80s/it]Loading train:  69%|██████▉   | 214/311 [25:05<13:58,  8.64s/it]Loading train:  69%|██████▉   | 215/311 [25:16<14:58,  9.36s/it]Loading train:  69%|██████▉   | 216/311 [25:29<16:15, 10.27s/it]Loading train:  70%|██████▉   | 217/311 [25:42<17:46, 11.34s/it]Loading train:  70%|███████   | 218/311 [25:55<18:04, 11.67s/it]Loading train:  70%|███████   | 219/311 [26:08<18:49, 12.28s/it]Loading train:  71%|███████   | 220/311 [26:20<18:23, 12.12s/it]Loading train:  71%|███████   | 221/311 [26:33<18:32, 12.36s/it]Loading train:  71%|███████▏  | 222/311 [26:43<17:23, 11.72s/it]Loading train:  72%|███████▏  | 223/311 [26:53<16:12, 11.05s/it]Loading train:  72%|███████▏  | 224/311 [27:03<15:27, 10.66s/it]Loading train:  72%|███████▏  | 225/311 [27:12<14:48, 10.33s/it]Loading train:  73%|███████▎  | 226/311 [27:23<14:38, 10.33s/it]Loading train:  73%|███████▎  | 227/311 [27:32<14:15, 10.19s/it]Loading train:  73%|███████▎  | 228/311 [27:42<13:43,  9.92s/it]Loading train:  74%|███████▎  | 229/311 [27:52<13:32,  9.91s/it]Loading train:  74%|███████▍  | 230/311 [28:01<13:11,  9.77s/it]Loading train:  74%|███████▍  | 231/311 [28:06<11:09,  8.37s/it]Loading train:  75%|███████▍  | 232/311 [28:11<09:40,  7.35s/it]Loading train:  75%|███████▍  | 233/311 [28:16<08:34,  6.59s/it]Loading train:  75%|███████▌  | 234/311 [28:21<07:56,  6.18s/it]Loading train:  76%|███████▌  | 235/311 [28:27<07:32,  5.95s/it]Loading train:  76%|███████▌  | 236/311 [28:31<07:00,  5.61s/it]Loading train:  76%|███████▌  | 237/311 [28:36<06:38,  5.39s/it]Loading train:  77%|███████▋  | 238/311 [28:41<06:28,  5.32s/it]Loading train:  77%|███████▋  | 239/311 [28:46<06:12,  5.17s/it]Loading train:  77%|███████▋  | 240/311 [28:51<05:58,  5.05s/it]Loading train:  77%|███████▋  | 241/311 [28:56<05:51,  5.02s/it]Loading train:  78%|███████▊  | 242/311 [29:01<05:47,  5.03s/it]Loading train:  78%|███████▊  | 243/311 [29:06<05:41,  5.02s/it]Loading train:  78%|███████▊  | 244/311 [29:11<05:29,  4.92s/it]Loading train:  79%|███████▉  | 245/311 [29:16<05:28,  4.98s/it]Loading train:  79%|███████▉  | 246/311 [29:21<05:23,  4.97s/it]Loading train:  79%|███████▉  | 247/311 [29:25<05:10,  4.86s/it]Loading train:  80%|███████▉  | 248/311 [29:30<05:07,  4.88s/it]Loading train:  80%|████████  | 249/311 [29:36<05:27,  5.29s/it]Loading train:  80%|████████  | 250/311 [29:42<05:32,  5.44s/it]Loading train:  81%|████████  | 251/311 [29:49<05:40,  5.67s/it]Loading train:  81%|████████  | 252/311 [29:54<05:38,  5.73s/it]Loading train:  81%|████████▏ | 253/311 [30:00<05:31,  5.72s/it]Loading train:  82%|████████▏ | 254/311 [30:06<05:36,  5.91s/it]Loading train:  82%|████████▏ | 255/311 [30:12<05:29,  5.88s/it]Loading train:  82%|████████▏ | 256/311 [30:18<05:24,  5.90s/it]Loading train:  83%|████████▎ | 257/311 [30:25<05:29,  6.10s/it]Loading train:  83%|████████▎ | 258/311 [30:30<05:17,  5.99s/it]Loading train:  83%|████████▎ | 259/311 [30:36<05:08,  5.94s/it]Loading train:  84%|████████▎ | 260/311 [30:42<05:05,  5.99s/it]Loading train:  84%|████████▍ | 261/311 [30:48<04:56,  5.93s/it]Loading train:  84%|████████▍ | 262/311 [30:54<04:51,  5.96s/it]Loading train:  85%|████████▍ | 263/311 [31:00<04:48,  6.00s/it]Loading train:  85%|████████▍ | 264/311 [31:06<04:42,  6.01s/it]Loading train:  85%|████████▌ | 265/311 [31:12<04:33,  5.94s/it]Loading train:  86%|████████▌ | 266/311 [31:18<04:27,  5.94s/it]Loading train:  86%|████████▌ | 267/311 [31:24<04:17,  5.86s/it]Loading train:  86%|████████▌ | 268/311 [31:30<04:12,  5.88s/it]Loading train:  86%|████████▋ | 269/311 [31:35<04:05,  5.84s/it]Loading train:  87%|████████▋ | 270/311 [31:41<03:55,  5.75s/it]Loading train:  87%|████████▋ | 271/311 [31:47<03:50,  5.75s/it]Loading train:  87%|████████▋ | 272/311 [31:53<03:45,  5.77s/it]Loading train:  88%|████████▊ | 273/311 [31:58<03:38,  5.74s/it]Loading train:  88%|████████▊ | 274/311 [32:04<03:38,  5.90s/it]Loading train:  88%|████████▊ | 275/311 [32:10<03:32,  5.91s/it]Loading train:  89%|████████▊ | 276/311 [32:16<03:24,  5.84s/it]Loading train:  89%|████████▉ | 277/311 [32:22<03:18,  5.85s/it]Loading train:  89%|████████▉ | 278/311 [32:28<03:11,  5.82s/it]Loading train:  90%|████████▉ | 279/311 [32:33<03:05,  5.80s/it]Loading train:  90%|█████████ | 280/311 [32:39<03:00,  5.82s/it]Loading train:  90%|█████████ | 281/311 [32:45<02:52,  5.76s/it]Loading train:  91%|█████████ | 282/311 [32:51<02:46,  5.75s/it]Loading train:  91%|█████████ | 283/311 [32:56<02:38,  5.67s/it]Loading train:  91%|█████████▏| 284/311 [33:01<02:29,  5.54s/it]Loading train:  92%|█████████▏| 285/311 [33:07<02:21,  5.46s/it]Loading train:  92%|█████████▏| 286/311 [33:12<02:15,  5.40s/it]Loading train:  92%|█████████▏| 287/311 [33:17<02:07,  5.31s/it]Loading train:  93%|█████████▎| 288/311 [33:22<02:00,  5.23s/it]Loading train:  93%|█████████▎| 289/311 [33:28<01:57,  5.34s/it]Loading train:  93%|█████████▎| 290/311 [33:33<01:51,  5.31s/it]Loading train:  94%|█████████▎| 291/311 [33:38<01:45,  5.28s/it]Loading train:  94%|█████████▍| 292/311 [33:44<01:41,  5.32s/it]Loading train:  94%|█████████▍| 293/311 [33:49<01:36,  5.37s/it]Loading train:  95%|█████████▍| 294/311 [33:54<01:31,  5.38s/it]Loading train:  95%|█████████▍| 295/311 [34:00<01:26,  5.39s/it]Loading train:  95%|█████████▌| 296/311 [34:05<01:21,  5.40s/it]Loading train:  95%|█████████▌| 297/311 [34:10<01:14,  5.35s/it]Loading train:  96%|█████████▌| 298/311 [34:16<01:10,  5.42s/it]Loading train:  96%|█████████▌| 299/311 [34:21<01:04,  5.38s/it]Loading train:  96%|█████████▋| 300/311 [34:27<00:59,  5.37s/it]Loading train:  97%|█████████▋| 301/311 [34:32<00:54,  5.44s/it]Loading train:  97%|█████████▋| 302/311 [34:38<00:48,  5.43s/it]Loading train:  97%|█████████▋| 303/311 [34:43<00:43,  5.42s/it]Loading train:  98%|█████████▊| 304/311 [34:48<00:37,  5.35s/it]Loading train:  98%|█████████▊| 305/311 [34:54<00:32,  5.42s/it]Loading train:  98%|█████████▊| 306/311 [34:59<00:26,  5.30s/it]Loading train:  99%|█████████▊| 307/311 [35:04<00:21,  5.38s/it]Loading train:  99%|█████████▉| 308/311 [35:10<00:16,  5.37s/it]Loading train:  99%|█████████▉| 309/311 [35:15<00:10,  5.22s/it]Loading train: 100%|█████████▉| 310/311 [35:20<00:05,  5.15s/it]Loading train: 100%|██████████| 311/311 [35:25<00:00,  5.20s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 18/311 [00:00<00:01, 176.28it/s]concatenating: train:  13%|█▎        | 39/311 [00:00<00:01, 181.74it/s]concatenating: train:  20%|█▉        | 62/311 [00:00<00:01, 193.11it/s]concatenating: train:  27%|██▋       | 84/311 [00:00<00:01, 199.25it/s]concatenating: train:  36%|███▌      | 111/311 [00:00<00:00, 208.15it/s]concatenating: train:  42%|████▏     | 131/311 [00:00<00:00, 194.32it/s]concatenating: train:  48%|████▊     | 149/311 [00:00<00:00, 179.68it/s]concatenating: train:  57%|█████▋    | 176/311 [00:00<00:00, 199.46it/s]concatenating: train:  66%|██████▌   | 205/311 [00:00<00:00, 211.82it/s]concatenating: train:  75%|███████▌  | 234/311 [00:01<00:00, 215.81it/s]concatenating: train:  84%|████████▍ | 261/311 [00:01<00:00, 221.49it/s]concatenating: train:  92%|█████████▏| 285/311 [00:01<00:00, 216.88it/s]concatenating: train:  99%|█████████▊| 307/311 [00:01<00:00, 214.80it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 209.13it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 12.00s/it]Loading test:  50%|█████     | 2/4 [00:22<00:23, 11.65s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.82s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.82s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 51.29it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 10 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 12:27:04.063271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 12:27:04.063369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 12:27:04.063384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 12:27:04.063394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 12:27:04.063822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 57,266
Non-trainable params: 400
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 19s - loss: 38413.1631 - acc: 0.8465 - mDice: 0.0707 - val_loss: 40610.3573 - val_acc: 0.8740 - val_mDice: 0.1274

Epoch 00001: val_mDice improved from -inf to 0.12744, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 17146.1880 - acc: 0.8480 - mDice: 0.1483 - val_loss: 28042.5072 - val_acc: 0.8509 - val_mDice: 0.2088

Epoch 00002: val_mDice improved from 0.12744 to 0.20878, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 9s - loss: 14083.1405 - acc: 0.8620 - mDice: 0.1986 - val_loss: 23326.6886 - val_acc: 0.8844 - val_mDice: 0.2756

Epoch 00003: val_mDice improved from 0.20878 to 0.27562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 11808.6767 - acc: 0.8741 - mDice: 0.2481 - val_loss: 21287.2062 - val_acc: 0.8912 - val_mDice: 0.3132

Epoch 00004: val_mDice improved from 0.27562 to 0.31323, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 9s - loss: 10522.3137 - acc: 0.8814 - mDice: 0.2854 - val_loss: 16248.5180 - val_acc: 0.8956 - val_mDice: 0.3365

Epoch 00005: val_mDice improved from 0.31323 to 0.33646, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 9s - loss: 9112.4546 - acc: 0.8880 - mDice: 0.3258 - val_loss: 6049.1653 - val_acc: 0.9022 - val_mDice: 0.4128

Epoch 00006: val_mDice improved from 0.33646 to 0.41284, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 9s - loss: 7934.4207 - acc: 0.8926 - mDice: 0.3651 - val_loss: 5184.9243 - val_acc: 0.9062 - val_mDice: 0.4605

Epoch 00007: val_mDice improved from 0.41284 to 0.46052, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 7277.7691 - acc: 0.8971 - mDice: 0.3945 - val_loss: 4983.7121 - val_acc: 0.9098 - val_mDice: 0.4758

Epoch 00008: val_mDice improved from 0.46052 to 0.47584, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 9s - loss: 6755.7863 - acc: 0.9006 - mDice: 0.4199 - val_loss: 4669.1983 - val_acc: 0.9138 - val_mDice: 0.4994

Epoch 00009: val_mDice improved from 0.47584 to 0.49943, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 9s - loss: 6293.0732 - acc: 0.9038 - mDice: 0.4447 - val_loss: 4441.1229 - val_acc: 0.9158 - val_mDice: 0.5167

Epoch 00010: val_mDice improved from 0.49943 to 0.51669, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 5877.6649 - acc: 0.9074 - mDice: 0.4684 - val_loss: 4149.8066 - val_acc: 0.9193 - val_mDice: 0.5400

Epoch 00011: val_mDice improved from 0.51669 to 0.54005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 9s - loss: 5499.8272 - acc: 0.9102 - mDice: 0.4907 - val_loss: 4207.6313 - val_acc: 0.9216 - val_mDice: 0.5414

Epoch 00012: val_mDice improved from 0.54005 to 0.54140, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 9s - loss: 5192.6230 - acc: 0.9125 - mDice: 0.5098 - val_loss: 4058.0899 - val_acc: 0.9232 - val_mDice: 0.5537

Epoch 00013: val_mDice improved from 0.54140 to 0.55370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 4958.0231 - acc: 0.9147 - mDice: 0.5252 - val_loss: 4298.3755 - val_acc: 0.9231 - val_mDice: 0.5410

Epoch 00014: val_mDice did not improve from 0.55370
Epoch 15/300
 - 9s - loss: 4718.2369 - acc: 0.9165 - mDice: 0.5408 - val_loss: 3745.7831 - val_acc: 0.9270 - val_mDice: 0.5759

Epoch 00015: val_mDice improved from 0.55370 to 0.57585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 9s - loss: 4561.2427 - acc: 0.9180 - mDice: 0.5520 - val_loss: 3682.5331 - val_acc: 0.9268 - val_mDice: 0.5800

Epoch 00016: val_mDice improved from 0.57585 to 0.57998, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 4414.5859 - acc: 0.9196 - mDice: 0.5625 - val_loss: 3805.5677 - val_acc: 0.9270 - val_mDice: 0.5739

Epoch 00017: val_mDice did not improve from 0.57998
Epoch 18/300
 - 9s - loss: 4286.1239 - acc: 0.9207 - mDice: 0.5717 - val_loss: 3475.7924 - val_acc: 0.9304 - val_mDice: 0.5981

Epoch 00018: val_mDice improved from 0.57998 to 0.59807, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 9s - loss: 4169.2819 - acc: 0.9216 - mDice: 0.5802 - val_loss: 3404.8136 - val_acc: 0.9315 - val_mDice: 0.6033

Epoch 00019: val_mDice improved from 0.59807 to 0.60333, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 20/300
 - 10s - loss: 4057.3521 - acc: 0.9228 - mDice: 0.5885 - val_loss: 3517.5239 - val_acc: 0.9311 - val_mDice: 0.5960

Epoch 00020: val_mDice did not improve from 0.60333
Epoch 21/300
 - 9s - loss: 3978.4043 - acc: 0.9236 - mDice: 0.5946 - val_loss: 3321.6951 - val_acc: 0.9325 - val_mDice: 0.6108

Epoch 00021: val_mDice improved from 0.60333 to 0.61082, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 9s - loss: 3861.0889 - acc: 0.9248 - mDice: 0.6038 - val_loss: 3213.9240 - val_acc: 0.9341 - val_mDice: 0.6187

Epoch 00022: val_mDice improved from 0.61082 to 0.61874, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 3798.4539 - acc: 0.9254 - mDice: 0.6084 - val_loss: 3604.3823 - val_acc: 0.9334 - val_mDice: 0.5954

Epoch 00023: val_mDice did not improve from 0.61874
Epoch 24/300
 - 9s - loss: 3725.4724 - acc: 0.9263 - mDice: 0.6143 - val_loss: 3113.3136 - val_acc: 0.9363 - val_mDice: 0.6292

Epoch 00024: val_mDice improved from 0.61874 to 0.62918, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 9s - loss: 3679.2901 - acc: 0.9268 - mDice: 0.6180 - val_loss: 3258.4850 - val_acc: 0.9366 - val_mDice: 0.6189

Epoch 00025: val_mDice did not improve from 0.62918
Epoch 26/300
 - 10s - loss: 3603.3278 - acc: 0.9279 - mDice: 0.6243 - val_loss: 3166.3387 - val_acc: 0.9361 - val_mDice: 0.6259

Epoch 00026: val_mDice did not improve from 0.62918
Epoch 27/300
 - 9s - loss: 3525.4209 - acc: 0.9285 - mDice: 0.6303 - val_loss: 3206.0304 - val_acc: 0.9368 - val_mDice: 0.6256

Epoch 00027: val_mDice did not improve from 0.62918
Epoch 28/300
 - 9s - loss: 3488.9787 - acc: 0.9291 - mDice: 0.6336 - val_loss: 3316.1795 - val_acc: 0.9355 - val_mDice: 0.6172

Epoch 00028: val_mDice did not improve from 0.62918
Epoch 29/300
 - 10s - loss: 3418.6000 - acc: 0.9298 - mDice: 0.6391 - val_loss: 3056.0614 - val_acc: 0.9396 - val_mDice: 0.6374

Epoch 00029: val_mDice improved from 0.62918 to 0.63741, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 9s - loss: 3388.1474 - acc: 0.9303 - mDice: 0.6417 - val_loss: 3184.2776 - val_acc: 0.9363 - val_mDice: 0.6279

Epoch 00030: val_mDice did not improve from 0.63741
Epoch 31/300
 - 9s - loss: 3332.2462 - acc: 0.9311 - mDice: 0.6464 - val_loss: 3167.7748 - val_acc: 0.9374 - val_mDice: 0.6318

Epoch 00031: val_mDice did not improve from 0.63741
Epoch 32/300
 - 10s - loss: 3290.5124 - acc: 0.9315 - mDice: 0.6498 - val_loss: 3229.2507 - val_acc: 0.9360 - val_mDice: 0.6278

Epoch 00032: val_mDice did not improve from 0.63741
Epoch 33/300
 - 9s - loss: 3243.3754 - acc: 0.9318 - mDice: 0.6536 - val_loss: 3133.2858 - val_acc: 0.9373 - val_mDice: 0.6316

Epoch 00033: val_mDice did not improve from 0.63741
Epoch 34/300
 - 9s - loss: 3219.7481 - acc: 0.9324 - mDice: 0.6558 - val_loss: 3016.6911 - val_acc: 0.9416 - val_mDice: 0.6428

Epoch 00034: val_mDice improved from 0.63741 to 0.64280, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 9s - loss: 3157.3262 - acc: 0.9330 - mDice: 0.6609 - val_loss: 3017.5662 - val_acc: 0.9389 - val_mDice: 0.6415

Epoch 00035: val_mDice did not improve from 0.64280
Epoch 36/300
 - 10s - loss: 3141.1552 - acc: 0.9333 - mDice: 0.6624 - val_loss: 3885.2664 - val_acc: 0.9386 - val_mDice: 0.6059

Epoch 00036: val_mDice did not improve from 0.64280
Epoch 37/300
 - 9s - loss: 3115.2848 - acc: 0.9336 - mDice: 0.6646 - val_loss: 3198.9579 - val_acc: 0.9389 - val_mDice: 0.6300

Epoch 00037: val_mDice did not improve from 0.64280
Epoch 38/300
 - 9s - loss: 3061.0283 - acc: 0.9343 - mDice: 0.6692 - val_loss: 3013.6151 - val_acc: 0.9401 - val_mDice: 0.6439

Epoch 00038: val_mDice improved from 0.64280 to 0.64386, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 39/300
 - 10s - loss: 3045.4800 - acc: 0.9346 - mDice: 0.6708 - val_loss: 3007.2649 - val_acc: 0.9401 - val_mDice: 0.6433

Epoch 00039: val_mDice did not improve from 0.64386
Epoch 40/300
 - 9s - loss: 3013.1699 - acc: 0.9350 - mDice: 0.6733 - val_loss: 3106.7638 - val_acc: 0.9399 - val_mDice: 0.6360

Epoch 00040: val_mDice did not improve from 0.64386
Epoch 41/300
 - 9s - loss: 2989.7963 - acc: 0.9353 - mDice: 0.6756 - val_loss: 2888.6785 - val_acc: 0.9420 - val_mDice: 0.6520

Epoch 00041: val_mDice improved from 0.64386 to 0.65204, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 42/300
 - 10s - loss: 2950.0465 - acc: 0.9355 - mDice: 0.6788 - val_loss: 2986.1887 - val_acc: 0.9406 - val_mDice: 0.6436

Epoch 00042: val_mDice did not improve from 0.65204
Epoch 43/300
 - 9s - loss: 2940.1173 - acc: 0.9359 - mDice: 0.6799 - val_loss: 3008.0862 - val_acc: 0.9416 - val_mDice: 0.6445

Epoch 00043: val_mDice did not improve from 0.65204
Epoch 44/300
 - 9s - loss: 2895.3964 - acc: 0.9364 - mDice: 0.6839 - val_loss: 3036.1132 - val_acc: 0.9418 - val_mDice: 0.6482

Epoch 00044: val_mDice did not improve from 0.65204
Epoch 45/300
 - 10s - loss: 2895.7019 - acc: 0.9366 - mDice: 0.6839 - val_loss: 2708.8554 - val_acc: 0.9450 - val_mDice: 0.6660

Epoch 00045: val_mDice improved from 0.65204 to 0.66601, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 9s - loss: 2858.4931 - acc: 0.9369 - mDice: 0.6869 - val_loss: 2837.6286 - val_acc: 0.9432 - val_mDice: 0.6582

Epoch 00046: val_mDice did not improve from 0.66601
Epoch 47/300
 - 9s - loss: 2824.6959 - acc: 0.9372 - mDice: 0.6899 - val_loss: 2859.3293 - val_acc: 0.9428 - val_mDice: 0.6557

Epoch 00047: val_mDice did not improve from 0.66601
Epoch 48/300
 - 10s - loss: 2823.3592 - acc: 0.9374 - mDice: 0.6902 - val_loss: 2769.7058 - val_acc: 0.9452 - val_mDice: 0.6588

Epoch 00048: val_mDice did not improve from 0.66601
Epoch 49/300
 - 10s - loss: 2788.0196 - acc: 0.9378 - mDice: 0.6933 - val_loss: 2679.3886 - val_acc: 0.9426 - val_mDice: 0.6678

Epoch 00049: val_mDice improved from 0.66601 to 0.66778, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 50/300
 - 9s - loss: 2784.7295 - acc: 0.9378 - mDice: 0.6936 - val_loss: 2596.3442 - val_acc: 0.9442 - val_mDice: 0.6732

Epoch 00050: val_mDice improved from 0.66778 to 0.67317, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 51/300
 - 10s - loss: 2757.0484 - acc: 0.9382 - mDice: 0.6959 - val_loss: 3005.7682 - val_acc: 0.9412 - val_mDice: 0.6432

Epoch 00051: val_mDice did not improve from 0.67317
Epoch 52/300
 - 10s - loss: 2748.7513 - acc: 0.9384 - mDice: 0.6969 - val_loss: 2681.7939 - val_acc: 0.9440 - val_mDice: 0.6704

Epoch 00052: val_mDice did not improve from 0.67317
Epoch 53/300
 - 9s - loss: 2729.9861 - acc: 0.9386 - mDice: 0.6984 - val_loss: 2518.3778 - val_acc: 0.9464 - val_mDice: 0.6803

Epoch 00053: val_mDice improved from 0.67317 to 0.68034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 54/300
 - 9s - loss: 2719.8745 - acc: 0.9389 - mDice: 0.6995 - val_loss: 2950.3320 - val_acc: 0.9431 - val_mDice: 0.6503

Epoch 00054: val_mDice did not improve from 0.68034
Epoch 55/300
 - 10s - loss: 2683.1317 - acc: 0.9391 - mDice: 0.7027 - val_loss: 2790.1420 - val_acc: 0.9424 - val_mDice: 0.6613

Epoch 00055: val_mDice did not improve from 0.68034
Epoch 56/300
 - 9s - loss: 2683.3681 - acc: 0.9393 - mDice: 0.7029 - val_loss: 3176.1922 - val_acc: 0.9400 - val_mDice: 0.6340

Epoch 00056: val_mDice did not improve from 0.68034
Epoch 57/300
 - 9s - loss: 2663.4726 - acc: 0.9395 - mDice: 0.7046 - val_loss: 2750.8686 - val_acc: 0.9474 - val_mDice: 0.6662

Epoch 00057: val_mDice did not improve from 0.68034
Epoch 58/300
 - 10s - loss: 2629.3096 - acc: 0.9398 - mDice: 0.7076 - val_loss: 2860.9919 - val_acc: 0.9440 - val_mDice: 0.6572

Epoch 00058: val_mDice did not improve from 0.68034
Epoch 59/300
 - 9s - loss: 2616.8912 - acc: 0.9399 - mDice: 0.7087 - val_loss: 2955.4830 - val_acc: 0.9451 - val_mDice: 0.6520

Epoch 00059: val_mDice did not improve from 0.68034
Epoch 60/300
 - 9s - loss: 2613.8949 - acc: 0.9401 - mDice: 0.7090 - val_loss: 2921.6788 - val_acc: 0.9435 - val_mDice: 0.6522

Epoch 00060: val_mDice did not improve from 0.68034
Epoch 61/300
 - 10s - loss: 2604.4577 - acc: 0.9402 - mDice: 0.7098 - val_loss: 2649.1053 - val_acc: 0.9452 - val_mDice: 0.6719

Epoch 00061: val_mDice did not improve from 0.68034
Epoch 62/300
 - 9s - loss: 2583.5933 - acc: 0.9404 - mDice: 0.7117 - val_loss: 2979.6409 - val_acc: 0.9425 - val_mDice: 0.6462

Epoch 00062: val_mDice did not improve from 0.68034
Epoch 63/300
 - 9s - loss: 2553.9215 - acc: 0.9408 - mDice: 0.7144 - val_loss: 2577.3390 - val_acc: 0.9471 - val_mDice: 0.6767

Epoch 00063: val_mDice did not improve from 0.68034
Epoch 64/300
 - 10s - loss: 2557.5493 - acc: 0.9406 - mDice: 0.7141 - val_loss: 2604.1401 - val_acc: 0.9482 - val_mDice: 0.6762

Epoch 00064: val_mDice did not improve from 0.68034
Epoch 65/300
 - 10s - loss: 2537.6523 - acc: 0.9409 - mDice: 0.7160 - val_loss: 2993.6983 - val_acc: 0.9451 - val_mDice: 0.6467

Epoch 00065: val_mDice did not improve from 0.68034
Epoch 66/300
 - 9s - loss: 2533.9751 - acc: 0.9409 - mDice: 0.7163 - val_loss: 2675.5224 - val_acc: 0.9464 - val_mDice: 0.6685

Epoch 00066: val_mDice did not improve from 0.68034
Epoch 67/300
 - 9s - loss: 2509.1711 - acc: 0.9412 - mDice: 0.7186 - val_loss: 3013.9183 - val_acc: 0.9443 - val_mDice: 0.6431

Epoch 00067: val_mDice did not improve from 0.68034
Epoch 68/300
 - 10s - loss: 2498.5354 - acc: 0.9415 - mDice: 0.7195 - val_loss: 2617.0387 - val_acc: 0.9462 - val_mDice: 0.6731

Epoch 00068: val_mDice did not improve from 0.68034
Epoch 69/300
 - 9s - loss: 2493.7836 - acc: 0.9414 - mDice: 0.7200 - val_loss: 2953.3305 - val_acc: 0.9440 - val_mDice: 0.6500

Epoch 00069: val_mDice did not improve from 0.68034
Epoch 70/300
 - 9s - loss: 2483.4023 - acc: 0.9415 - mDice: 0.7210 - val_loss: 2868.9057 - val_acc: 0.9457 - val_mDice: 0.6555

Epoch 00070: val_mDice did not improve from 0.68034
Epoch 71/300
 - 10s - loss: 2460.3891 - acc: 0.9418 - mDice: 0.7231 - val_loss: 2631.3761 - val_acc: 0.9477 - val_mDice: 0.6734

Epoch 00071: val_mDice did not improve from 0.68034
Epoch 72/300
 - 9s - loss: 2448.6482 - acc: 0.9420 - mDice: 0.7242 - val_loss: 2646.2102 - val_acc: 0.9480 - val_mDice: 0.6728

Epoch 00072: val_mDice did not improve from 0.68034
Epoch 73/300
 - 9s - loss: 2432.3787 - acc: 0.9420 - mDice: 0.7257 - val_loss: 2807.9324 - val_acc: 0.9454 - val_mDice: 0.6585

Epoch 00073: val_mDice did not improve from 0.68034
Epoch 74/300
 - 10s - loss: 2410.8239 - acc: 0.9423 - mDice: 0.7276 - val_loss: 2869.2240 - val_acc: 0.9453 - val_mDice: 0.6527

Epoch 00074: val_mDice did not improve from 0.68034
Epoch 75/300
 - 9s - loss: 2418.4953 - acc: 0.9422 - mDice: 0.7269 - val_loss: 2771.5863 - val_acc: 0.9468 - val_mDice: 0.6677

Epoch 00075: val_mDice did not improve from 0.68034
Epoch 76/300
 - 9s - loss: 2397.3431 - acc: 0.9425 - mDice: 0.7289 - val_loss: 3378.1596 - val_acc: 0.9432 - val_mDice: 0.6239

Epoch 00076: val_mDice did not improve from 0.68034
Epoch 77/300
 - 9s - loss: 2400.2679 - acc: 0.9425 - mDice: 0.7287 - val_loss: 3160.1155 - val_acc: 0.9431 - val_mDice: 0.6337

Epoch 00077: val_mDice did not improve from 0.68034
Epoch 78/300
 - 10s - loss: 2377.2728 - acc: 0.9429 - mDice: 0.7309 - val_loss: 2792.0096 - val_acc: 0.9459 - val_mDice: 0.6622

Epoch 00078: val_mDice did not improve from 0.68034
Epoch 79/300
 - 9s - loss: 2376.3264 - acc: 0.9427 - mDice: 0.7309 - val_loss: 2773.8266 - val_acc: 0.9469 - val_mDice: 0.6651

Epoch 00079: val_mDice did not improve from 0.68034
Epoch 80/300
 - 9s - loss: 2372.1193 - acc: 0.9429 - mDice: 0.7315 - val_loss: 2637.5080 - val_acc: 0.9456 - val_mDice: 0.6728

Epoch 00080: val_mDice did not improve from 0.68034
Epoch 81/300
 - 10s - loss: 2353.3251 - acc: 0.9430 - mDice: 0.7331 - val_loss: 3015.1216 - val_acc: 0.9437 - val_mDice: 0.6473

Epoch 00081: val_mDice did not improve from 0.68034
Epoch 82/300
 - 9s - loss: 2342.7042 - acc: 0.9432 - mDice: 0.7342 - val_loss: 3818.6100 - val_acc: 0.9431 - val_mDice: 0.6095

Epoch 00082: val_mDice did not improve from 0.68034
Epoch 83/300
 - 9s - loss: 2341.7141 - acc: 0.9432 - mDice: 0.7343 - val_loss: 2560.1816 - val_acc: 0.9483 - val_mDice: 0.6806

Epoch 00083: val_mDice improved from 0.68034 to 0.68056, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 84/300
 - 10s - loss: 2338.8494 - acc: 0.9434 - mDice: 0.7346 - val_loss: 3077.5072 - val_acc: 0.9427 - val_mDice: 0.6341

Epoch 00084: val_mDice did not improve from 0.68056
Epoch 85/300
 - 9s - loss: 2336.9781 - acc: 0.9433 - mDice: 0.7348 - val_loss: 2787.6152 - val_acc: 0.9442 - val_mDice: 0.6608

Epoch 00085: val_mDice did not improve from 0.68056
Epoch 86/300
 - 9s - loss: 2314.5215 - acc: 0.9435 - mDice: 0.7368 - val_loss: 2677.3642 - val_acc: 0.9475 - val_mDice: 0.6700

Epoch 00086: val_mDice did not improve from 0.68056
Epoch 87/300
 - 10s - loss: 2308.4024 - acc: 0.9438 - mDice: 0.7376 - val_loss: 2622.3268 - val_acc: 0.9479 - val_mDice: 0.6760

Epoch 00087: val_mDice did not improve from 0.68056
Epoch 88/300
 - 9s - loss: 2318.5722 - acc: 0.9436 - mDice: 0.7364 - val_loss: 3020.8827 - val_acc: 0.9466 - val_mDice: 0.6483

Epoch 00088: val_mDice did not improve from 0.68056
Epoch 89/300
 - 9s - loss: 2288.1476 - acc: 0.9438 - mDice: 0.7393 - val_loss: 2843.0200 - val_acc: 0.9458 - val_mDice: 0.6559

Epoch 00089: val_mDice did not improve from 0.68056
Epoch 90/300
 - 9s - loss: 2280.6664 - acc: 0.9440 - mDice: 0.7401 - val_loss: 2875.9362 - val_acc: 0.9459 - val_mDice: 0.6566

Epoch 00090: val_mDice did not improve from 0.68056
Epoch 91/300
 - 10s - loss: 2281.5676 - acc: 0.9441 - mDice: 0.7400 - val_loss: 3003.8940 - val_acc: 0.9484 - val_mDice: 0.6508

Epoch 00091: val_mDice did not improve from 0.68056
Epoch 92/300
 - 9s - loss: 2268.0311 - acc: 0.9441 - mDice: 0.7412 - val_loss: 2660.3948 - val_acc: 0.9493 - val_mDice: 0.6732

Epoch 00092: val_mDice did not improve from 0.68056
Epoch 93/300
 - 9s - loss: 2277.1551 - acc: 0.9441 - mDice: 0.7406 - val_loss: 2756.3452 - val_acc: 0.9460 - val_mDice: 0.6648

Epoch 00093: val_mDice did not improve from 0.68056
Epoch 94/300
 - 10s - loss: 2249.7380 - acc: 0.9443 - mDice: 0.7431 - val_loss: 2629.3314 - val_acc: 0.9473 - val_mDice: 0.6744

Epoch 00094: val_mDice did not improve from 0.68056
Epoch 95/300
 - 9s - loss: 2242.8631 - acc: 0.9443 - mDice: 0.7436 - val_loss: 2519.5084 - val_acc: 0.9491 - val_mDice: 0.6846

Epoch 00095: val_mDice improved from 0.68056 to 0.68460, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 96/300
 - 9s - loss: 2247.6330 - acc: 0.9443 - mDice: 0.7432 - val_loss: 2474.9505 - val_acc: 0.9493 - val_mDice: 0.6896

Epoch 00096: val_mDice improved from 0.68460 to 0.68956, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 97/300
 - 10s - loss: 2228.9183 - acc: 0.9446 - mDice: 0.7450 - val_loss: 2950.2331 - val_acc: 0.9468 - val_mDice: 0.6496

Epoch 00097: val_mDice did not improve from 0.68956
Epoch 98/300
 - 9s - loss: 2227.6921 - acc: 0.9445 - mDice: 0.7451 - val_loss: 2534.0546 - val_acc: 0.9498 - val_mDice: 0.6824

Epoch 00098: val_mDice did not improve from 0.68956
Epoch 99/300
 - 9s - loss: 2217.4148 - acc: 0.9447 - mDice: 0.7462 - val_loss: 2594.7761 - val_acc: 0.9486 - val_mDice: 0.6787

Epoch 00099: val_mDice did not improve from 0.68956
Epoch 100/300
 - 10s - loss: 2222.4957 - acc: 0.9446 - mDice: 0.7456 - val_loss: 2585.2779 - val_acc: 0.9468 - val_mDice: 0.6781

Epoch 00100: val_mDice did not improve from 0.68956
Epoch 101/300
 - 9s - loss: 2210.8383 - acc: 0.9448 - mDice: 0.7468 - val_loss: 2564.5019 - val_acc: 0.9476 - val_mDice: 0.6797

Epoch 00101: val_mDice did not improve from 0.68956
Epoch 102/300
 - 9s - loss: 2200.4326 - acc: 0.9449 - mDice: 0.7478 - val_loss: 2634.1514 - val_acc: 0.9484 - val_mDice: 0.6748

Epoch 00102: val_mDice did not improve from 0.68956
Epoch 103/300
 - 10s - loss: 2193.3310 - acc: 0.9449 - mDice: 0.7484 - val_loss: 3036.7003 - val_acc: 0.9471 - val_mDice: 0.6490

Epoch 00103: val_mDice did not improve from 0.68956
Epoch 104/300
 - 9s - loss: 2188.0577 - acc: 0.9450 - mDice: 0.7490 - val_loss: 2455.2135 - val_acc: 0.9495 - val_mDice: 0.6893

Epoch 00104: val_mDice did not improve from 0.68956
Epoch 105/300
 - 9s - loss: 2194.8376 - acc: 0.9450 - mDice: 0.7484 - val_loss: 2398.3302 - val_acc: 0.9508 - val_mDice: 0.6944

Epoch 00105: val_mDice improved from 0.68956 to 0.69441, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 106/300
 - 9s - loss: 2191.5920 - acc: 0.9450 - mDice: 0.7487 - val_loss: 2739.8450 - val_acc: 0.9477 - val_mDice: 0.6664

Epoch 00106: val_mDice did not improve from 0.69441
Epoch 107/300
 - 9s - loss: 2178.6746 - acc: 0.9452 - mDice: 0.7500 - val_loss: 2467.9283 - val_acc: 0.9514 - val_mDice: 0.6888

Epoch 00107: val_mDice did not improve from 0.69441
Epoch 108/300
 - 9s - loss: 2164.4998 - acc: 0.9453 - mDice: 0.7513 - val_loss: 2503.5731 - val_acc: 0.9498 - val_mDice: 0.6865

Epoch 00108: val_mDice did not improve from 0.69441
Epoch 109/300
 - 9s - loss: 2154.2678 - acc: 0.9454 - mDice: 0.7523 - val_loss: 2503.5548 - val_acc: 0.9494 - val_mDice: 0.6870

Epoch 00109: val_mDice did not improve from 0.69441
Epoch 110/300
 - 10s - loss: 2148.0975 - acc: 0.9454 - mDice: 0.7529 - val_loss: 2513.6611 - val_acc: 0.9511 - val_mDice: 0.6825

Epoch 00110: val_mDice did not improve from 0.69441
Epoch 111/300
 - 9s - loss: 2143.3741 - acc: 0.9455 - mDice: 0.7534 - val_loss: 2474.9649 - val_acc: 0.9507 - val_mDice: 0.6889

Epoch 00111: val_mDice did not improve from 0.69441
Epoch 112/300
 - 9s - loss: 2143.5986 - acc: 0.9455 - mDice: 0.7534 - val_loss: 2730.7299 - val_acc: 0.9504 - val_mDice: 0.6678

Epoch 00112: val_mDice did not improve from 0.69441
Epoch 113/300
 - 10s - loss: 2133.5735 - acc: 0.9457 - mDice: 0.7544 - val_loss: 2824.8292 - val_acc: 0.9481 - val_mDice: 0.6611

Epoch 00113: val_mDice did not improve from 0.69441
Epoch 114/300
 - 9s - loss: 2138.8605 - acc: 0.9455 - mDice: 0.7538 - val_loss: 2451.9002 - val_acc: 0.9520 - val_mDice: 0.6901

Epoch 00114: val_mDice did not improve from 0.69441
Epoch 115/300
 - 9s - loss: 2137.8528 - acc: 0.9457 - mDice: 0.7540 - val_loss: 2528.0228 - val_acc: 0.9492 - val_mDice: 0.6821

Epoch 00115: val_mDice did not improve from 0.69441
Epoch 116/300
 - 10s - loss: 2132.9056 - acc: 0.9457 - mDice: 0.7545 - val_loss: 2618.9200 - val_acc: 0.9510 - val_mDice: 0.6772

Epoch 00116: val_mDice did not improve from 0.69441
Epoch 117/300
 - 9s - loss: 2135.1630 - acc: 0.9457 - mDice: 0.7542 - val_loss: 3068.0860 - val_acc: 0.9459 - val_mDice: 0.6405

Epoch 00117: val_mDice did not improve from 0.69441
Epoch 118/300
 - 9s - loss: 2111.9659 - acc: 0.9459 - mDice: 0.7565 - val_loss: 2589.9561 - val_acc: 0.9488 - val_mDice: 0.6784

Epoch 00118: val_mDice did not improve from 0.69441
Epoch 119/300
 - 9s - loss: 2124.9751 - acc: 0.9457 - mDice: 0.7552 - val_loss: 2617.0069 - val_acc: 0.9480 - val_mDice: 0.6770

Epoch 00119: val_mDice did not improve from 0.69441
Epoch 120/300
 - 10s - loss: 2114.8588 - acc: 0.9459 - mDice: 0.7562 - val_loss: 2599.7115 - val_acc: 0.9493 - val_mDice: 0.6805

Epoch 00120: val_mDice did not improve from 0.69441
Epoch 121/300
 - 9s - loss: 2101.2722 - acc: 0.9460 - mDice: 0.7575 - val_loss: 2478.8444 - val_acc: 0.9509 - val_mDice: 0.6888

Epoch 00121: val_mDice did not improve from 0.69441
Epoch 122/300
 - 9s - loss: 2097.6911 - acc: 0.9459 - mDice: 0.7579 - val_loss: 2446.1084 - val_acc: 0.9505 - val_mDice: 0.6918

Epoch 00122: val_mDice did not improve from 0.69441
Epoch 123/300
 - 10s - loss: 2097.0693 - acc: 0.9461 - mDice: 0.7580 - val_loss: 2839.7843 - val_acc: 0.9475 - val_mDice: 0.6578

Epoch 00123: val_mDice did not improve from 0.69441
Epoch 124/300
 - 9s - loss: 2091.6934 - acc: 0.9461 - mDice: 0.7585 - val_loss: 2619.9578 - val_acc: 0.9502 - val_mDice: 0.6764

Epoch 00124: val_mDice did not improve from 0.69441
Epoch 125/300
 - 9s - loss: 2096.7069 - acc: 0.9460 - mDice: 0.7580 - val_loss: 2561.8982 - val_acc: 0.9509 - val_mDice: 0.6786

Epoch 00125: val_mDice did not improve from 0.69441
Epoch 126/300
 - 10s - loss: 2079.1967 - acc: 0.9463 - mDice: 0.7597 - val_loss: 2460.5982 - val_acc: 0.9519 - val_mDice: 0.6912

Epoch 00126: val_mDice did not improve from 0.69441
Epoch 127/300
 - 9s - loss: 2083.3330 - acc: 0.9463 - mDice: 0.7593 - val_loss: 2906.8007 - val_acc: 0.9452 - val_mDice: 0.6524

Epoch 00127: val_mDice did not improve from 0.69441
Epoch 128/300
 - 9s - loss: 2083.9770 - acc: 0.9461 - mDice: 0.7591 - val_loss: 2568.7219 - val_acc: 0.9497 - val_mDice: 0.6804

Epoch 00128: val_mDice did not improve from 0.69441
Epoch 129/300
 - 10s - loss: 2067.7115 - acc: 0.9463 - mDice: 0.7608 - val_loss: 2575.0409 - val_acc: 0.9499 - val_mDice: 0.6801

Epoch 00129: val_mDice did not improve from 0.69441
Epoch 130/300
 - 9s - loss: 2069.3878 - acc: 0.9463 - mDice: 0.7606 - val_loss: 2365.8933 - val_acc: 0.9515 - val_mDice: 0.6990

Epoch 00130: val_mDice improved from 0.69441 to 0.69899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 131/300
 - 9s - loss: 2066.6062 - acc: 0.9464 - mDice: 0.7609 - val_loss: 2568.7023 - val_acc: 0.9495 - val_mDice: 0.6808

Epoch 00131: val_mDice did not improve from 0.69899
Epoch 132/300
 - 10s - loss: 2056.8921 - acc: 0.9464 - mDice: 0.7619 - val_loss: 2558.8777 - val_acc: 0.9497 - val_mDice: 0.6810

Epoch 00132: val_mDice did not improve from 0.69899
Epoch 133/300
 - 9s - loss: 2059.6126 - acc: 0.9463 - mDice: 0.7616 - val_loss: 2639.4122 - val_acc: 0.9479 - val_mDice: 0.6746

Epoch 00133: val_mDice did not improve from 0.69899
Epoch 134/300
 - 9s - loss: 2042.2673 - acc: 0.9466 - mDice: 0.7633 - val_loss: 2391.7363 - val_acc: 0.9518 - val_mDice: 0.6962

Epoch 00134: val_mDice did not improve from 0.69899
Epoch 135/300
 - 9s - loss: 2055.6033 - acc: 0.9465 - mDice: 0.7620 - val_loss: 2709.1156 - val_acc: 0.9482 - val_mDice: 0.6683

Epoch 00135: val_mDice did not improve from 0.69899
Epoch 136/300
 - 10s - loss: 2046.6432 - acc: 0.9466 - mDice: 0.7631 - val_loss: 2463.7835 - val_acc: 0.9512 - val_mDice: 0.6879

Epoch 00136: val_mDice did not improve from 0.69899
Epoch 137/300
 - 9s - loss: 2045.9472 - acc: 0.9467 - mDice: 0.7631 - val_loss: 2593.4367 - val_acc: 0.9495 - val_mDice: 0.6783

Epoch 00137: val_mDice did not improve from 0.69899
Epoch 138/300
 - 9s - loss: 2049.9520 - acc: 0.9466 - mDice: 0.7626 - val_loss: 2533.4586 - val_acc: 0.9508 - val_mDice: 0.6827

Epoch 00138: val_mDice did not improve from 0.69899
Epoch 139/300
 - 10s - loss: 2036.9402 - acc: 0.9466 - mDice: 0.7638 - val_loss: 2517.8370 - val_acc: 0.9515 - val_mDice: 0.6855

Epoch 00139: val_mDice did not improve from 0.69899
Epoch 140/300
 - 9s - loss: 2026.0487 - acc: 0.9469 - mDice: 0.7650 - val_loss: 2551.3931 - val_acc: 0.9494 - val_mDice: 0.6840

Epoch 00140: val_mDice did not improve from 0.69899
Epoch 141/300
 - 9s - loss: 2037.1239 - acc: 0.9467 - mDice: 0.7639 - val_loss: 2656.5259 - val_acc: 0.9492 - val_mDice: 0.6731

Epoch 00141: val_mDice did not improve from 0.69899
Epoch 142/300
 - 9s - loss: 2028.6270 - acc: 0.9468 - mDice: 0.7647 - val_loss: 2737.7213 - val_acc: 0.9506 - val_mDice: 0.6666

Epoch 00142: val_mDice did not improve from 0.69899
Epoch 143/300
 - 9s - loss: 2017.5071 - acc: 0.9469 - mDice: 0.7658 - val_loss: 2608.0414 - val_acc: 0.9498 - val_mDice: 0.6760

Epoch 00143: val_mDice did not improve from 0.69899
Epoch 144/300
 - 9s - loss: 2024.4416 - acc: 0.9469 - mDice: 0.7652 - val_loss: 2583.3997 - val_acc: 0.9504 - val_mDice: 0.6781

Epoch 00144: val_mDice did not improve from 0.69899
Epoch 145/300
 - 9s - loss: 2007.1258 - acc: 0.9470 - mDice: 0.7668 - val_loss: 2609.8660 - val_acc: 0.9497 - val_mDice: 0.6775

Epoch 00145: val_mDice did not improve from 0.69899
Epoch 146/300
 - 10s - loss: 2010.3991 - acc: 0.9470 - mDice: 0.7665 - val_loss: 2493.6238 - val_acc: 0.9502 - val_mDice: 0.6873

Epoch 00146: val_mDice did not improve from 0.69899
Epoch 147/300
 - 9s - loss: 2021.0455 - acc: 0.9469 - mDice: 0.7655 - val_loss: 2482.2768 - val_acc: 0.9519 - val_mDice: 0.6885

Epoch 00147: val_mDice did not improve from 0.69899
Epoch 148/300
 - 9s - loss: 2019.6516 - acc: 0.9469 - mDice: 0.7656 - val_loss: 2456.9125 - val_acc: 0.9513 - val_mDice: 0.6901

Epoch 00148: val_mDice did not improve from 0.69899
Epoch 149/300
 - 10s - loss: 2011.1593 - acc: 0.9470 - mDice: 0.7664 - val_loss: 2448.7856 - val_acc: 0.9526 - val_mDice: 0.6903

Epoch 00149: val_mDice did not improve from 0.69899
Epoch 150/300
 - 9s - loss: 2005.1506 - acc: 0.9471 - mDice: 0.7671 - val_loss: 2395.9258 - val_acc: 0.9525 - val_mDice: 0.6952

Epoch 00150: val_mDice did not improve from 0.69899
Epoch 151/300
 - 9s - loss: 1999.9418 - acc: 0.9472 - mDice: 0.7676 - val_loss: 2360.3748 - val_acc: 0.9518 - val_mDice: 0.6998

Epoch 00151: val_mDice improved from 0.69899 to 0.69981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM10_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 152/300
 - 10s - loss: 2007.6171 - acc: 0.9470 - mDice: 0.7668 - val_loss: 2410.1086 - val_acc: 0.9514 - val_mDice: 0.6971

Epoch 00152: val_mDice did not improve from 0.69981
Epoch 153/300
 - 9s - loss: 1992.1326 - acc: 0.9472 - mDice: 0.7684 - val_loss: 2481.6029 - val_acc: 0.9512 - val_mDice: 0.6888

Epoch 00153: val_mDice did not improve from 0.69981
Epoch 154/300
 - 9s - loss: 1997.6853 - acc: 0.9471 - mDice: 0.7678 - val_loss: 2785.2116 - val_acc: 0.9482 - val_mDice: 0.6632

Epoch 00154: val_mDice did not improve from 0.69981
Epoch 155/300
 - 9s - loss: 1984.7609 - acc: 0.9473 - mDice: 0.7691 - val_loss: 2597.9528 - val_acc: 0.9518 - val_mDice: 0.6789

Epoch 00155: val_mDice did not improve from 0.69981
Epoch 156/300
 - 10s - loss: 2002.1521 - acc: 0.9472 - mDice: 0.7674 - val_loss: 2602.5901 - val_acc: 0.9524 - val_mDice: 0.6785

Epoch 00156: val_mDice did not improve from 0.69981
Epoch 157/300
 - 9s - loss: 1988.4633 - acc: 0.9473 - mDice: 0.7688 - val_loss: 2989.9382 - val_acc: 0.9472 - val_mDice: 0.6466

Epoch 00157: val_mDice did not improve from 0.69981
Epoch 158/300
 - 9s - loss: 1992.4182 - acc: 0.9472 - mDice: 0.7683 - val_loss: 2582.6157 - val_acc: 0.9509 - val_mDice: 0.6796

Epoch 00158: val_mDice did not improve from 0.69981
Epoch 159/300
 - 10s - loss: 1980.1379 - acc: 0.9472 - mDice: 0.7694 - val_loss: 2639.3162 - val_acc: 0.9477 - val_mDice: 0.6732

Epoch 00159: val_mDice did not improve from 0.69981
Epoch 160/300
 - 9s - loss: 1982.5244 - acc: 0.9474 - mDice: 0.7694 - val_loss: 2574.7306 - val_acc: 0.9506 - val_mDice: 0.6816

Epoch 00160: val_mDice did not improve from 0.69981
Epoch 161/300
 - 9s - loss: 1972.7554 - acc: 0.9473 - mDice: 0.7703 - val_loss: 2521.0691 - val_acc: 0.9481 - val_mDice: 0.6849

Epoch 00161: val_mDice did not improve from 0.69981
Epoch 162/300
 - 10s - loss: 1958.1732 - acc: 0.9475 - mDice: 0.7718 - val_loss: 2482.3990 - val_acc: 0.9503 - val_mDice: 0.6887

Epoch 00162: val_mDice did not improve from 0.69981
Epoch 163/300
 - 9s - loss: 1968.8943 - acc: 0.9474 - mDice: 0.7706 - val_loss: 2469.1858 - val_acc: 0.9510 - val_mDice: 0.6896

Epoch 00163: val_mDice did not improve from 0.69981
Epoch 164/300
 - 9s - loss: 1975.4457 - acc: 0.9474 - mDice: 0.7701 - val_loss: 2853.7253 - val_acc: 0.9434 - val_mDice: 0.6544

Epoch 00164: val_mDice did not improve from 0.69981
Epoch 165/300
 - 10s - loss: 1965.5513 - acc: 0.9474 - mDice: 0.7710 - val_loss: 2596.6449 - val_acc: 0.9516 - val_mDice: 0.6792

Epoch 00165: val_mDice did not improve from 0.69981
Epoch 166/300
 - 9s - loss: 1960.3018 - acc: 0.9475 - mDice: 0.7715 - val_loss: 2408.6635 - val_acc: 0.9522 - val_mDice: 0.6961

Epoch 00166: val_mDice did not improve from 0.69981
Epoch 167/300
 - 9s - loss: 1971.8985 - acc: 0.9474 - mDice: 0.7704 - val_loss: 2514.7149 - val_acc: 0.9497 - val_mDice: 0.6847

Epoch 00167: val_mDice did not improve from 0.69981
Epoch 168/300
 - 10s - loss: 1962.3775 - acc: 0.9474 - mDice: 0.7713 - val_loss: 2361.4698 - val_acc: 0.9516 - val_mDice: 0.6974

Epoch 00168: val_mDice did not improve from 0.69981
Epoch 169/300
 - 10s - loss: 1956.3044 - acc: 0.9475 - mDice: 0.7720 - val_loss: 2698.8611 - val_acc: 0.9494 - val_mDice: 0.6719

Epoch 00169: val_mDice did not improve from 0.69981
Epoch 170/300
 - 9s - loss: 1948.8829 - acc: 0.9477 - mDice: 0.7726 - val_loss: 2434.5014 - val_acc: 0.9517 - val_mDice: 0.6923

Epoch 00170: val_mDice did not improve from 0.69981
Epoch 171/300
 - 9s - loss: 1950.5021 - acc: 0.9476 - mDice: 0.7726 - val_loss: 2430.5582 - val_acc: 0.9518 - val_mDice: 0.6925

Epoch 00171: val_mDice did not improve from 0.69981
Epoch 172/300
 - 10s - loss: 1959.1332 - acc: 0.9477 - mDice: 0.7716 - val_loss: 2419.3159 - val_acc: 0.9515 - val_mDice: 0.6948

Epoch 00172: val_mDice did not improve from 0.69981
Epoch 173/300
 - 9s - loss: 1944.4829 - acc: 0.9477 - mDice: 0.7731 - val_loss: 2800.2006 - val_acc: 0.9493 - val_mDice: 0.6632

Epoch 00173: val_mDice did not improve from 0.69981
Epoch 174/300
 - 9s - loss: 1948.4185 - acc: 0.9477 - mDice: 0.7728 - val_loss: 2606.9068 - val_acc: 0.9472 - val_mDice: 0.6777

Epoch 00174: val_mDice did not improve from 0.69981
Epoch 175/300
 - 10s - loss: 1942.3741 - acc: 0.9477 - mDice: 0.7733 - val_loss: 2666.9942 - val_acc: 0.9483 - val_mDice: 0.6713

Epoch 00175: val_mDice did not improve from 0.69981
Epoch 176/300
 - 9s - loss: 1944.1776 - acc: 0.9477 - mDice: 0.7732 - val_loss: 2662.2286 - val_acc: 0.9496 - val_mDice: 0.6718

Epoch 00176: val_mDice did not improve from 0.69981
Epoch 177/300
 - 9s - loss: 1939.9647 - acc: 0.9477 - mDice: 0.7736 - val_loss: 2589.5265 - val_acc: 0.9506 - val_mDice: 0.6784

Epoch 00177: val_mDice did not improve from 0.69981
Epoch 178/300
 - 9s - loss: 1948.9062 - acc: 0.9477 - mDice: 0.7727 - val_loss: 2549.2938 - val_acc: 0.9503 - val_mDice: 0.6833

Epoch 00178: val_mDice did not improve from 0.69981
Epoch 179/300
 - 10s - loss: 1934.9580 - acc: 0.9478 - mDice: 0.7741 - val_loss: 2856.8196 - val_acc: 0.9467 - val_mDice: 0.6539

Epoch 00179: val_mDice did not improve from 0.69981
Epoch 180/300
 - 9s - loss: 1934.1045 - acc: 0.9478 - mDice: 0.7742 - val_loss: 2403.4753 - val_acc: 0.9529 - val_mDice: 0.6960

Epoch 00180: val_mDice did not improve from 0.69981
Epoch 181/300
 - 9s - loss: 1929.8150 - acc: 0.9477 - mDice: 0.7746 - val_loss: 2463.2153 - val_acc: 0.9523 - val_mDice: 0.6892

Epoch 00181: val_mDice did not improve from 0.69981
Restoring model weights from the end of the best epoch
Epoch 00181: early stopping
{'val_loss': [40610.3573477057, 28042.507169699365, 23326.688587816454, 21287.206203026108, 16248.517998417721, 6049.165348101265, 5184.924310225475, 4983.712062401108, 4669.198279272152, 4441.122929440269, 4149.806581907635, 4207.631276577334, 4058.0898931962024, 4298.375482100475, 3745.7830671479433, 3682.533101142207, 3805.5676702185524, 3475.7924402937106, 3404.8135970876187, 3517.523918055281, 3321.6951178055774, 3213.9240042770966, 3604.382288679292, 3113.313595542425, 3258.484951357298, 3166.3386802190466, 3206.0303816010683, 3316.179506712322, 3056.0613689181173, 3184.2775940714005, 3167.774837445609, 3229.2507478738135, 3133.2858222285404, 3016.6910941208466, 3017.566199194027, 3885.26643622676, 3198.9579398239716, 3013.6150767652293, 3007.264850857892, 3106.763755315467, 2888.6784915199764, 2986.188739245451, 3008.0862156348894, 3036.1132240778284, 2708.8553605864317, 2837.6286327506923, 2859.3292869857596, 2769.7058259988135, 2679.388644061511, 2596.344191925435, 3005.7681838409812, 2681.7938587816457, 2518.377759716179, 2950.3320003461236, 2790.142043487935, 3176.192245290249, 2750.868596716772, 2860.9919449045688, 2955.4830430429192, 2921.678771200059, 2649.1052647844144, 2979.6409077704707, 2577.338958353936, 2604.140067185028, 2993.69833489913, 2675.522406855716, 3013.9183117830303, 2617.03866693038, 2953.3304675138447, 2868.9056999109966, 2631.3761449886274, 2646.210150996341, 2807.932437945016, 2869.223960393592, 2771.586272807061, 3378.1596432456486, 3160.115495512757, 2792.00956784019, 2773.8265921677216, 2637.5079762905457, 3015.1216021187697, 3818.6099621736553, 2560.181649896163, 3077.5071975128562, 2787.6151849287976, 2677.3641867335837, 2622.326840943928, 3020.8826672517803, 2843.0199978985365, 2875.9362020371836, 3003.8939626186707, 2660.3948001137264, 2756.3451653975476, 2629.331423988825, 2519.5084336679192, 2474.9505259839793, 2950.2331342093553, 2534.0545731556567, 2594.7760797814476, 2585.277886113034, 2564.50192067593, 2634.151441356804, 3036.7003220183938, 2455.21347161788, 2398.3301909241495, 2739.8450139685524, 2467.9283277294303, 2503.573098484474, 2503.554761669304, 2513.661078730716, 2474.9648561115505, 2730.7298862119264, 2824.8291726414163, 2451.9001897498024, 2528.022756069521, 2618.919977501978, 3068.0860333020173, 2589.9560763202135, 2617.006877657733, 2599.7115385803995, 2478.8444159785404, 2446.1083551720726, 2839.7842507664163, 2619.9577605814875, 2561.8982242632514, 2460.598153802413, 2906.800716351859, 2568.7219191925437, 2575.0408904643, 2365.8933136372625, 2568.702264327037, 2558.8776809112937, 2639.4121804539163, 2391.736346667326, 2709.1156237638447, 2463.7834627175635, 2593.4366872280457, 2533.4585718082476, 2517.8370005933543, 2551.3931096716774, 2656.5258835418313, 2737.7212624851663, 2608.0414096494264, 2583.3996736550635, 2609.8659652516812, 2493.62382565269, 2482.276773573477, 2456.9124616791933, 2448.785625988924, 2395.9258059731014, 2360.3748145767404, 2410.1086178550236, 2481.6028820955303, 2785.2116312920293, 2597.9528128708466, 2602.5900987069817, 2989.9382169699365, 2582.615685571598, 2639.316227007516, 2574.7306356309336, 2521.069110339201, 2482.399007676523, 2469.1857709281053, 2853.725341796875, 2596.6448897349683, 2408.6635077754154, 2514.7149333712423, 2361.469782189478, 2698.8611318853837, 2434.5013520446005, 2430.5581734572784, 2419.31588551968, 2800.2005939725077, 2606.90681090536, 2666.9941977971716, 2662.2286021558543, 2589.526455263548, 2549.2937676152096, 2856.8196387954904, 2403.475276898734, 2463.215276404272], 'val_acc': [0.8740430217754992, 0.8508535178401803, 0.8844419348089001, 0.8911559838282911, 0.8955696285525455, 0.9021726009211962, 0.9061571887776821, 0.9098086010051679, 0.9137719137759148, 0.9157786693754075, 0.919274900532976, 0.9216467624978174, 0.9232168899306769, 0.9230693095847021, 0.9270341418966462, 0.9268379015258595, 0.9269671945632258, 0.9304040911831434, 0.9315390783020213, 0.9310674441011646, 0.9324838662449317, 0.9341422160969505, 0.9333921520015861, 0.9363193859027911, 0.9365597812435295, 0.9360804995404014, 0.9367666991451119, 0.9355145436298998, 0.9395539383345013, 0.9362996009331715, 0.93741024294986, 0.9360409703435777, 0.9372596099406858, 0.941613927672181, 0.9389316665975354, 0.9385847788822802, 0.9388890726656853, 0.9400651213489001, 0.9400970860372616, 0.9398962319651737, 0.9419516641882402, 0.9405595818652382, 0.941583484033995, 0.9417782259892814, 0.9449868934063972, 0.9431611971010135, 0.9428447530239443, 0.9452136241936986, 0.9425876397120801, 0.9441927309277691, 0.941184890421131, 0.9440360182448279, 0.9464444306832326, 0.9431003513215463, 0.9423822330523141, 0.9400453356247914, 0.9474272637427608, 0.9439888649348971, 0.9451497234875643, 0.9435004856013045, 0.9452455511576012, 0.942494840561589, 0.9470955933196635, 0.948181918150262, 0.9450614640984354, 0.9463653141939188, 0.9442961812019348, 0.9462192443352712, 0.9440481760833836, 0.9456746012349672, 0.9477269951301285, 0.9480069521107252, 0.945370315750943, 0.945317073713375, 0.9468430522121961, 0.9431536122213436, 0.9430760175366945, 0.9458997898463961, 0.9468765002262743, 0.9455863410913492, 0.943667830545691, 0.9430851423287694, 0.94825646168069, 0.9427078026759473, 0.9442323008670083, 0.9475413696675361, 0.9479110935066319, 0.9465965628623962, 0.9458221762995177, 0.9458906401561785, 0.9483979434906682, 0.9492940427381781, 0.9460001716130897, 0.947305570674848, 0.9491267128835751, 0.9493381743189655, 0.9468384769898427, 0.9498022093048578, 0.9485957267918165, 0.9467897913123988, 0.9475900613808934, 0.9484420788439014, 0.9471047301835651, 0.9495390087743348, 0.950830694995349, 0.9476509109328065, 0.9514316712753682, 0.949823532677904, 0.9493686006039004, 0.9510999789720849, 0.950742474085168, 0.9503773179235337, 0.9480541031571883, 0.9519915505300595, 0.9492453698870502, 0.9510117610798606, 0.9458952289593371, 0.948760034162787, 0.9480206121372271, 0.9493199247348157, 0.9509280723861501, 0.95048687201512, 0.9475078982642934, 0.9502084330667423, 0.9508580693715736, 0.9519093783595894, 0.945187730125234, 0.949672870243652, 0.9499406678767144, 0.9514986125728752, 0.9495055328441572, 0.9496652891364279, 0.9478882400295402, 0.9518044160891183, 0.9482473285892342, 0.9512247579007209, 0.9494690472566629, 0.9507652694665933, 0.9515320522875725, 0.9494066676007041, 0.949193667007398, 0.9505918214592752, 0.9497900326040727, 0.9504366607605657, 0.9497428958929037, 0.9501673639575138, 0.9518652905391741, 0.9512856066981449, 0.9525651177273521, 0.9525012328654905, 0.9517542176608798, 0.9513571209545377, 0.951200389409367, 0.9481590842898888, 0.9517739724509323, 0.9523947088024284, 0.947240139864668, 0.9508778505687472, 0.9477391491962385, 0.9506283342083798, 0.9481210338918469, 0.9502738751942599, 0.9509721851047082, 0.9433529007283947, 0.9515503486500511, 0.9521619277664378, 0.9496881297872036, 0.9516279486161244, 0.9493853261199179, 0.9516918349869644, 0.9517633326445953, 0.9515275087537645, 0.9493168826344647, 0.9472279541100128, 0.9483035999008372, 0.9495557425897333, 0.9506253026708772, 0.9502768969234032, 0.9467030688177182, 0.9529272053815141, 0.9523125411588934], 'val_mDice': [0.12744452474237997, 0.20877737221838552, 0.2756170962430254, 0.3132320604746855, 0.33645634786992135, 0.41283718619165544, 0.460517401936688, 0.47584150184558915, 0.4994308812708794, 0.5166931763479982, 0.5400486158419259, 0.5414043046251128, 0.5536978810648375, 0.5409697369684147, 0.5758527705941019, 0.5799795449534549, 0.5738893437989151, 0.59806889295578, 0.6033251572258865, 0.5959771818752531, 0.6108240885070607, 0.6187370940099789, 0.5954103002065345, 0.6291769727875914, 0.6188908196702788, 0.6258582540705234, 0.625599867180933, 0.6172122102749499, 0.6374105343335792, 0.6279320731947694, 0.6318377603458453, 0.6278369223015218, 0.631627389901801, 0.64279827739619, 0.6415345631068265, 0.6059425737284407, 0.6300241260588924, 0.6438625334184381, 0.643256460564046, 0.6360183531724954, 0.6520368871809561, 0.6436497486090358, 0.644453569303585, 0.6481710491301138, 0.6660070630568492, 0.6581546302083172, 0.6556877214697343, 0.6587712598752372, 0.6677840193615684, 0.6731651674343061, 0.6432438372056696, 0.6703583062449588, 0.6803392760361298, 0.6503320298617399, 0.6612503392786919, 0.6339821928664099, 0.666154924827286, 0.6571733076361161, 0.6520452001426793, 0.6522306731984585, 0.6719208623789534, 0.6461570534525038, 0.6767213201221032, 0.6761653000795389, 0.6467497122438648, 0.6685281946689268, 0.6430947441089002, 0.6730638169035127, 0.6499883034561253, 0.655501975288874, 0.6733700127541264, 0.6728466749191284, 0.6584624104861971, 0.6527022349683544, 0.6677302657803402, 0.6238953124118757, 0.633665759352189, 0.6621548088291024, 0.6651042073587828, 0.6728471909897237, 0.6472520813157286, 0.6095044763782357, 0.6805587267573876, 0.6341209985032866, 0.6608229951013492, 0.6699589438076261, 0.6759583308726926, 0.6482840761353698, 0.6559228210509578, 0.6566042967989475, 0.6507633630233475, 0.6732075802887543, 0.6647923618932313, 0.6744218687467938, 0.6845985258681865, 0.6895600346070302, 0.6495794940598404, 0.6823590360110319, 0.6786835774590697, 0.6781017538867419, 0.679709108569954, 0.6748244558708577, 0.6489689003063154, 0.6893084615091735, 0.6944059646582301, 0.6664275791071639, 0.6887750384173815, 0.6865049842037733, 0.6870074475867839, 0.6825003427795217, 0.6888899765437162, 0.6678275405606137, 0.661068367807171, 0.6900753084617325, 0.6821123520030251, 0.6771513751790493, 0.6405381567870514, 0.6784063192862498, 0.677014752279354, 0.680452853818483, 0.6887629288661329, 0.6917851220203352, 0.6577704978894584, 0.676395988917049, 0.678649513027336, 0.6911725771578052, 0.6524305871770352, 0.680418273316154, 0.6801266051545928, 0.69898684568043, 0.6808394865144657, 0.6809763727308829, 0.6746053989929489, 0.6962366647358182, 0.6683029396624505, 0.6878934917570669, 0.6783001211625111, 0.6826852861839005, 0.6854787506634676, 0.6839746825302704, 0.6730555220495297, 0.66656648584559, 0.6759637096260167, 0.6781293508372729, 0.6775448216667658, 0.6873368673686739, 0.6884561550768116, 0.6900604933123046, 0.6902557068233248, 0.6952327912366842, 0.6998134534570235, 0.6971020442021044, 0.688840727262859, 0.6631800758687756, 0.6789110846157316, 0.6785120149201984, 0.6465937185891067, 0.6796019077301025, 0.6731843042977249, 0.681612945810149, 0.6848960224586197, 0.6887436003624638, 0.6896040665952465, 0.6543688925006722, 0.6792238000073011, 0.6960846532749224, 0.6847480626045903, 0.697390503521207, 0.67194810698304, 0.6922999929778183, 0.6924557617948025, 0.6948015916196606, 0.6631652818450445, 0.6776751370369634, 0.671310145643693, 0.6717883718164661, 0.6784331096878534, 0.6833074515378927, 0.653946024707601, 0.6959615289410458, 0.6892087701000745], 'loss': [38413.16305076386, 17146.188016143515, 14083.140468497066, 11808.676697938272, 10522.313708945645, 9112.45461454434, 7934.420713281882, 7277.769078537599, 6755.786252857364, 6293.073219067748, 5877.66490577812, 5499.827244176984, 5192.622999548671, 4958.023134176763, 4718.236924100819, 4561.242669556702, 4414.585852529973, 4286.123903293834, 4169.281909110526, 4057.35210443093, 3978.4042720756083, 3861.0888752892934, 3798.453948122439, 3725.4723889896236, 3679.2901266013887, 3603.3278074492237, 3525.4209497159236, 3488.9787102162427, 3418.5999868988074, 3388.147382933039, 3332.2461704700304, 3290.51241827069, 3243.375374065725, 3219.7481138629983, 3157.3261821998462, 3141.1552001261507, 3115.28478070224, 3061.028250558036, 3045.4800270540613, 3013.169867089093, 2989.7962778879532, 2950.046549545035, 2940.1173360987455, 2895.3964239079573, 2895.7019357160248, 2858.493091837977, 2824.6959081794125, 2823.359249422204, 2788.019566324837, 2784.729496139594, 2757.0483701760736, 2748.7513226671576, 2729.9860826999443, 2719.8744922052842, 2683.13167498846, 2683.3681342735895, 2663.472623694623, 2629.309576388845, 2616.8911722662574, 2613.894852802272, 2604.457701821599, 2583.5932530735436, 2553.9215045899623, 2557.5493470349807, 2537.6523057604936, 2533.9751394990485, 2509.1710982158666, 2498.535403157091, 2493.7836388433957, 2483.402262979073, 2460.389111199682, 2448.648241525524, 2432.3787357171313, 2410.8238931962323, 2418.4953022937166, 2397.3431280885616, 2400.267865936267, 2377.2728407337618, 2376.3263721967796, 2372.1193280036705, 2353.3250690924883, 2342.7041688963063, 2341.7141234314136, 2338.849373484372, 2336.9781201685646, 2314.521547213299, 2308.4024489745107, 2318.5722167672343, 2288.147627073664, 2280.666425358376, 2281.5676483932366, 2268.031091224612, 2277.155065853747, 2249.7379760989193, 2242.863138529995, 2247.6329708801786, 2228.9183239444747, 2227.692076525192, 2217.4148241179714, 2222.4956719627367, 2210.838328862856, 2200.4325725782355, 2193.3310282578695, 2188.057715298241, 2194.8375617613538, 2191.592032222215, 2178.6745518028665, 2164.4997864387046, 2154.267836838973, 2148.097474305459, 2143.37409971292, 2143.5986436313583, 2133.573474768249, 2138.860457626831, 2137.85275366122, 2132.9056381170008, 2135.163017319263, 2111.965853213685, 2124.975099039483, 2114.8587596589186, 2101.2722304316003, 2097.6911152276566, 2097.069300813262, 2091.6933763196043, 2096.706866151261, 2079.19674715963, 2083.333010578966, 2083.9770075552187, 2067.7114594728537, 2069.387791002583, 2066.606229083541, 2056.892072800343, 2059.6125727876965, 2042.267330674496, 2055.603298062209, 2046.643202457096, 2045.9472408256083, 2049.95195187021, 2036.9402042699217, 2026.0486772043992, 2037.1239470632777, 2028.6269526309882, 2017.5070710871105, 2024.4416429804483, 2007.1257828110772, 2010.3990511120403, 2021.0455354870403, 2019.6516091050719, 2011.1593442922274, 2005.1506384707134, 1999.9418347558237, 2007.617086326386, 1992.1325665315314, 1997.6852962134194, 1984.760901703906, 2002.152063645317, 1988.4633143883107, 1992.418228106188, 1980.1378505310033, 1982.5244296732724, 1972.7554262995673, 1958.1732166372103, 1968.8942778219534, 1975.4457377947472, 1965.5512568845484, 1960.3017710026147, 1971.898465411666, 1962.3774681816888, 1956.304388919276, 1948.8828739550663, 1950.5021316608597, 1959.13320983368, 1944.4829201352882, 1948.4184809414205, 1942.3741022817812, 1944.1775599394382, 1939.9647432680026, 1948.9061720449401, 1934.9579786658046, 1934.1044712908015, 1929.815003602334], 'acc': [0.846506066189175, 0.8479688827058459, 0.8620241559357452, 0.874140705091661, 0.8814308285134276, 0.8879558631689719, 0.8926314096226956, 0.8970754814746167, 0.9006152710466914, 0.9038329803475673, 0.9073645246506509, 0.910224508607209, 0.9125326647299208, 0.9146758542037695, 0.9165030911787952, 0.9180467270106644, 0.9196187115690092, 0.9206687973511456, 0.9216066969401052, 0.9228058163090208, 0.9235995241815096, 0.9248167195574855, 0.9253643982953651, 0.926270486926415, 0.9267802069371454, 0.9278891084889852, 0.9284870842602126, 0.9290996528453356, 0.9298380066247567, 0.9303467126087542, 0.9310718379923806, 0.93148546183172, 0.9318272736283846, 0.9323844488986056, 0.9330150511331377, 0.9333206558459107, 0.9336367631817288, 0.9342636105889784, 0.9346023896405302, 0.9349900390493007, 0.9352850940776518, 0.9355388868921249, 0.9359376677276151, 0.9364250682713483, 0.936553835024577, 0.9368526638157211, 0.937185331304659, 0.9373779279024965, 0.9378232665748936, 0.9378480398186977, 0.9382482963455491, 0.9383602086130495, 0.9386162556698814, 0.9388852605015003, 0.9391052384986321, 0.9392756943710416, 0.939544563445906, 0.9397893857492796, 0.9399400747338561, 0.9400802379385849, 0.940175204926394, 0.9404256294150914, 0.9407975779328448, 0.9406334840542196, 0.9409463803375457, 0.9409276260773888, 0.9411990041194392, 0.9414560617536053, 0.9413577528532484, 0.9414952267571916, 0.9418117675594065, 0.9419758429608331, 0.9420085689983885, 0.942271542544309, 0.9421933842351783, 0.9425287579341921, 0.9424992595448373, 0.9429323847165526, 0.9426618979219384, 0.9429188393620237, 0.9430203236630454, 0.9432245420328956, 0.9432454161053484, 0.9433772156519332, 0.943273549087614, 0.9434702351044084, 0.9437726271485375, 0.9436132006923085, 0.9437688736238252, 0.9439576959764364, 0.9440669083537384, 0.9441047864180255, 0.944094242836386, 0.9443095712370353, 0.9443321952159855, 0.9443132428686805, 0.9445706929141623, 0.9444943658015545, 0.9446618463384242, 0.9445938076967172, 0.9448175155552039, 0.944921767214733, 0.944866878404544, 0.945026267230969, 0.9450131887272272, 0.9449920401260564, 0.9452159837738602, 0.9452790024790962, 0.9453558004225666, 0.9453953343429627, 0.9454552623387147, 0.9454796219923776, 0.9456544953866894, 0.9455212012373547, 0.945677239467431, 0.9456709956698262, 0.9456652392746706, 0.9458738296488334, 0.9457157824455317, 0.9458870166759653, 0.9460202541393773, 0.9459184208219228, 0.9460806695858219, 0.9461085294866697, 0.9459724543742061, 0.9462810348325874, 0.946262683428429, 0.9461226396500847, 0.9462855874358378, 0.9462957982108063, 0.9463532954418239, 0.9463876552641609, 0.9463441319332485, 0.9465911470652109, 0.946521183948486, 0.946615839284328, 0.9466857678347008, 0.9466403357319773, 0.9466198284536275, 0.9468676040935786, 0.9466960977224723, 0.9467595619066965, 0.9469369285891096, 0.9468610095910243, 0.9470036449532719, 0.9469527463254924, 0.9469128432953131, 0.9469383930156512, 0.9469914268453514, 0.9471123516438993, 0.9472113061124909, 0.9470141331756805, 0.9471837340796443, 0.947107328595733, 0.947343373313118, 0.9471738307353506, 0.9472726710119599, 0.9472499840754529, 0.9472158967797354, 0.947410789736366, 0.9473064876384264, 0.9474885403410427, 0.9473578336749275, 0.947356625902947, 0.9474389822750331, 0.947470038490033, 0.9473834378861166, 0.9474382654272656, 0.9475157966453601, 0.9476587455893084, 0.9475860168990795, 0.9476681775720628, 0.9476944299083835, 0.9477100512943785, 0.9476895844439465, 0.9476567601829539, 0.9476522269252822, 0.9476780272456423, 0.9477782071191547, 0.9477770810231464, 0.9477414511225571], 'mDice': [0.07066890128780019, 0.14828366352353006, 0.19857959885290402, 0.24812170687063365, 0.28536825980169483, 0.32575545398776995, 0.36505619167847364, 0.3945214450479953, 0.4199320542238252, 0.44468069400974536, 0.4684321465930298, 0.4907355797237734, 0.5097888970317169, 0.5251564498567137, 0.5408287945183508, 0.5520115015671737, 0.5624579633840517, 0.571682697749244, 0.58019735725338, 0.5884569120619375, 0.5946322023410249, 0.6038073063716866, 0.6083851445304966, 0.6142855962487379, 0.6179748546107487, 0.6242507518133814, 0.6302532884380876, 0.6335508756336535, 0.6390642403880867, 0.6416811601732579, 0.646369283520611, 0.6498429662589842, 0.6535515619018983, 0.6558193279055631, 0.6608921186203225, 0.662424244049926, 0.6646235504405116, 0.6692072585834178, 0.6707518184681934, 0.6732941489140546, 0.675602884680479, 0.6787699674701266, 0.6798607100122421, 0.6838778618712601, 0.6838668147738961, 0.6869318010545559, 0.6898868623314383, 0.6902135004644112, 0.6932600011520663, 0.6936155077852444, 0.6959069276907723, 0.6969179436534293, 0.6984386856331125, 0.6995371473988556, 0.7027095752127109, 0.7029002849894562, 0.7045777796830595, 0.7075983941530901, 0.7087162842107948, 0.7090457909409211, 0.709823397285588, 0.7117427395259451, 0.7144034924848705, 0.7140785994581826, 0.7159883946071796, 0.7162889435628029, 0.7185875245888964, 0.7194628242006769, 0.7199774461446721, 0.7209926123852577, 0.7231464516725775, 0.7242139950786608, 0.7256548561002021, 0.7276114958686319, 0.7269166177798263, 0.7289191490722928, 0.7286818781539719, 0.7308953982622988, 0.7309055094388949, 0.7314854664920265, 0.7330591367208634, 0.7341633371282135, 0.7343093083484701, 0.7346086243732117, 0.7348395016259965, 0.7368419118518049, 0.7375621476765829, 0.7364058975553956, 0.7393495421426974, 0.7401190132614284, 0.740040610889248, 0.7412489117856259, 0.7405707672123772, 0.7430546071692451, 0.7436464456641592, 0.7431588953007382, 0.7450438287758914, 0.7450976290957545, 0.7461892571925924, 0.745625704611327, 0.7468391592229536, 0.7478110049717439, 0.7484383114384814, 0.7489933130085975, 0.7483775408728216, 0.7486818445592407, 0.7499531375064101, 0.7513389800879117, 0.7523007791373277, 0.7529404406748239, 0.7534208757488509, 0.7533983239178135, 0.7543502380760128, 0.7537938617637214, 0.7539647710270266, 0.7544997943793651, 0.7542312374147796, 0.7564593582247877, 0.7552170179383275, 0.7562045363557817, 0.7575265095331368, 0.7578923240310024, 0.7579972646536494, 0.758540316879484, 0.7579678563828509, 0.7596995619230066, 0.7593007149458992, 0.7591489145312894, 0.7608154582523807, 0.7606442606627628, 0.7609198503000251, 0.7618599329241756, 0.761602462230545, 0.7633206535572468, 0.7620192162906627, 0.7630771890385148, 0.7630668102319981, 0.7625829359144877, 0.7638064554373487, 0.7649775777013618, 0.7639374587276309, 0.7646606601427943, 0.7658278149470102, 0.7652099751017442, 0.7667965623638688, 0.7664741993143412, 0.7654769657981005, 0.7655995912466972, 0.7664191220656719, 0.7670957421735441, 0.7675740825941765, 0.766800319699805, 0.7683834705648033, 0.7677999319503395, 0.7690795440752948, 0.7673765279801931, 0.7687699174359953, 0.7683077149427839, 0.7694313082797283, 0.7693971528402952, 0.7703198654745234, 0.7717714492052202, 0.7706029799388807, 0.7700522673945348, 0.77104068998864, 0.7714985571183545, 0.7703856919661846, 0.7712949997787291, 0.7719569906007419, 0.7726242501983658, 0.772576401900396, 0.7716415282059951, 0.7731215358504107, 0.7727651320358656, 0.7733482856443661, 0.7731715046602046, 0.7735678253266456, 0.772743010028853, 0.7740588295754032, 0.7741725810719424, 0.7745861994597846]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.70s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:28, 14.15s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:41<00:14, 14.10s/it]predicting test subjects: 100%|██████████| 4/4 [00:55<00:00, 13.95s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:48:17, 20.96s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:30:16, 17.53s/it]predicting train subjects:   1%|          | 3/311 [00:42<1:21:35, 15.89s/it]predicting train subjects:   1%|▏         | 4/311 [00:54<1:15:18, 14.72s/it]predicting train subjects:   2%|▏         | 5/311 [01:05<1:09:14, 13.58s/it]predicting train subjects:   2%|▏         | 6/311 [01:15<1:04:16, 12.64s/it]predicting train subjects:   2%|▏         | 7/311 [01:28<1:04:35, 12.75s/it]predicting train subjects:   3%|▎         | 8/311 [01:43<1:07:06, 13.29s/it]predicting train subjects:   3%|▎         | 9/311 [01:56<1:07:14, 13.36s/it]predicting train subjects:   3%|▎         | 10/311 [02:08<1:04:02, 12.77s/it]predicting train subjects:   4%|▎         | 11/311 [02:22<1:05:57, 13.19s/it]predicting train subjects:   4%|▍         | 12/311 [02:33<1:03:02, 12.65s/it]predicting train subjects:   4%|▍         | 13/311 [02:45<1:01:42, 12.42s/it]predicting train subjects:   5%|▍         | 14/311 [03:00<1:05:06, 13.15s/it]predicting train subjects:   5%|▍         | 15/311 [03:21<1:16:03, 15.42s/it]predicting train subjects:   5%|▌         | 16/311 [03:42<1:23:43, 17.03s/it]predicting train subjects:   5%|▌         | 17/311 [04:02<1:28:46, 18.12s/it]predicting train subjects:   6%|▌         | 18/311 [04:23<1:31:45, 18.79s/it]predicting train subjects:   6%|▌         | 19/311 [04:44<1:34:39, 19.45s/it]predicting train subjects:   6%|▋         | 20/311 [05:04<1:35:57, 19.79s/it]predicting train subjects:   7%|▋         | 21/311 [05:25<1:37:23, 20.15s/it]predicting train subjects:   7%|▋         | 22/311 [05:46<1:37:39, 20.27s/it]predicting train subjects:   7%|▋         | 23/311 [06:06<1:37:46, 20.37s/it]predicting train subjects:   8%|▊         | 24/311 [06:28<1:39:06, 20.72s/it]predicting train subjects:   8%|▊         | 25/311 [06:49<1:39:53, 20.96s/it]predicting train subjects:   8%|▊         | 26/311 [07:10<1:39:22, 20.92s/it]predicting train subjects:   9%|▊         | 27/311 [07:31<1:38:31, 20.82s/it]predicting train subjects:   9%|▉         | 28/311 [07:52<1:38:31, 20.89s/it]predicting train subjects:   9%|▉         | 29/311 [08:12<1:37:29, 20.74s/it]predicting train subjects:  10%|▉         | 30/311 [08:33<1:37:08, 20.74s/it]predicting train subjects:  10%|▉         | 31/311 [08:54<1:36:52, 20.76s/it]predicting train subjects:  10%|█         | 32/311 [09:15<1:36:23, 20.73s/it]predicting train subjects:  11%|█         | 33/311 [09:24<1:20:48, 17.44s/it]predicting train subjects:  11%|█         | 34/311 [09:34<1:10:10, 15.20s/it]predicting train subjects:  11%|█▏        | 35/311 [09:45<1:03:06, 13.72s/it]predicting train subjects:  12%|█▏        | 36/311 [09:54<56:57, 12.43s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:04<53:05, 11.62s/it]predicting train subjects:  12%|█▏        | 38/311 [10:13<50:07, 11.02s/it]predicting train subjects:  13%|█▎        | 39/311 [10:23<47:33, 10.49s/it]predicting train subjects:  13%|█▎        | 40/311 [10:32<46:25, 10.28s/it]predicting train subjects:  13%|█▎        | 41/311 [10:42<45:12, 10.05s/it]predicting train subjects:  14%|█▎        | 42/311 [10:52<44:38,  9.96s/it]predicting train subjects:  14%|█▍        | 43/311 [11:02<44:28,  9.96s/it]predicting train subjects:  14%|█▍        | 44/311 [11:11<43:32,  9.78s/it]predicting train subjects:  14%|█▍        | 45/311 [11:21<43:19,  9.77s/it]predicting train subjects:  15%|█▍        | 46/311 [11:31<43:24,  9.83s/it]predicting train subjects:  15%|█▌        | 47/311 [11:41<43:29,  9.89s/it]predicting train subjects:  15%|█▌        | 48/311 [11:50<42:46,  9.76s/it]predicting train subjects:  16%|█▌        | 49/311 [12:00<42:40,  9.77s/it]predicting train subjects:  16%|█▌        | 50/311 [12:09<41:58,  9.65s/it]predicting train subjects:  16%|█▋        | 51/311 [12:22<46:11, 10.66s/it]predicting train subjects:  17%|█▋        | 52/311 [12:35<48:15, 11.18s/it]predicting train subjects:  17%|█▋        | 53/311 [12:47<49:37, 11.54s/it]predicting train subjects:  17%|█▋        | 54/311 [13:00<50:40, 11.83s/it]predicting train subjects:  18%|█▊        | 55/311 [13:12<51:16, 12.02s/it]predicting train subjects:  18%|█▊        | 56/311 [13:24<51:32, 12.13s/it]predicting train subjects:  18%|█▊        | 57/311 [13:37<51:35, 12.19s/it]predicting train subjects:  19%|█▊        | 58/311 [13:49<51:25, 12.19s/it]predicting train subjects:  19%|█▉        | 59/311 [14:01<51:27, 12.25s/it]predicting train subjects:  19%|█▉        | 60/311 [14:14<51:12, 12.24s/it]predicting train subjects:  20%|█▉        | 61/311 [14:26<51:17, 12.31s/it]predicting train subjects:  20%|█▉        | 62/311 [14:39<52:02, 12.54s/it]predicting train subjects:  20%|██        | 63/311 [14:52<51:52, 12.55s/it]predicting train subjects:  21%|██        | 64/311 [15:04<51:24, 12.49s/it]predicting train subjects:  21%|██        | 65/311 [15:16<51:08, 12.47s/it]predicting train subjects:  21%|██        | 66/311 [15:29<50:31, 12.37s/it]predicting train subjects:  22%|██▏       | 67/311 [15:40<49:31, 12.18s/it]predicting train subjects:  22%|██▏       | 68/311 [15:53<49:20, 12.18s/it]predicting train subjects:  22%|██▏       | 69/311 [16:05<49:35, 12.29s/it]predicting train subjects:  23%|██▎       | 70/311 [16:17<49:09, 12.24s/it]predicting train subjects:  23%|██▎       | 71/311 [16:29<48:21, 12.09s/it]predicting train subjects:  23%|██▎       | 72/311 [16:41<47:59, 12.05s/it]predicting train subjects:  23%|██▎       | 73/311 [16:53<47:58, 12.09s/it]predicting train subjects:  24%|██▍       | 74/311 [17:05<47:54, 12.13s/it]predicting train subjects:  24%|██▍       | 75/311 [17:17<47:44, 12.14s/it]predicting train subjects:  24%|██▍       | 76/311 [17:30<47:26, 12.11s/it]predicting train subjects:  25%|██▍       | 77/311 [17:42<47:38, 12.22s/it]predicting train subjects:  25%|██▌       | 78/311 [17:54<47:39, 12.27s/it]predicting train subjects:  25%|██▌       | 79/311 [18:07<47:26, 12.27s/it]predicting train subjects:  26%|██▌       | 80/311 [18:18<46:45, 12.14s/it]predicting train subjects:  26%|██▌       | 81/311 [18:31<46:51, 12.23s/it]predicting train subjects:  26%|██▋       | 82/311 [18:43<46:59, 12.31s/it]predicting train subjects:  27%|██▋       | 83/311 [18:55<46:12, 12.16s/it]predicting train subjects:  27%|██▋       | 84/311 [19:07<45:32, 12.04s/it]predicting train subjects:  27%|██▋       | 85/311 [19:18<44:24, 11.79s/it]predicting train subjects:  28%|██▊       | 86/311 [19:29<43:34, 11.62s/it]predicting train subjects:  28%|██▊       | 87/311 [19:40<42:21, 11.35s/it]predicting train subjects:  28%|██▊       | 88/311 [19:51<41:57, 11.29s/it]predicting train subjects:  29%|██▊       | 89/311 [20:02<41:38, 11.25s/it]predicting train subjects:  29%|██▉       | 90/311 [20:13<40:46, 11.07s/it]predicting train subjects:  29%|██▉       | 91/311 [20:24<40:19, 11.00s/it]predicting train subjects:  30%|██▉       | 92/311 [20:35<40:13, 11.02s/it]predicting train subjects:  30%|██▉       | 93/311 [20:46<39:46, 10.95s/it]predicting train subjects:  30%|███       | 94/311 [20:57<39:51, 11.02s/it]predicting train subjects:  31%|███       | 95/311 [21:08<39:52, 11.07s/it]predicting train subjects:  31%|███       | 96/311 [21:19<39:19, 10.97s/it]predicting train subjects:  31%|███       | 97/311 [21:30<39:16, 11.01s/it]predicting train subjects:  32%|███▏      | 98/311 [21:41<39:20, 11.08s/it]predicting train subjects:  32%|███▏      | 99/311 [21:52<38:53, 11.01s/it]predicting train subjects:  32%|███▏      | 100/311 [22:03<38:14, 10.87s/it]predicting train subjects:  32%|███▏      | 101/311 [22:14<38:14, 10.93s/it]predicting train subjects:  33%|███▎      | 102/311 [22:25<38:23, 11.02s/it]predicting train subjects:  33%|███▎      | 103/311 [22:36<38:07, 11.00s/it]predicting train subjects:  33%|███▎      | 104/311 [22:47<37:54, 10.99s/it]predicting train subjects:  34%|███▍      | 105/311 [22:58<37:52, 11.03s/it]predicting train subjects:  34%|███▍      | 106/311 [23:09<37:48, 11.06s/it]predicting train subjects:  34%|███▍      | 107/311 [23:20<37:49, 11.12s/it]predicting train subjects:  35%|███▍      | 108/311 [23:31<37:29, 11.08s/it]predicting train subjects:  35%|███▌      | 109/311 [23:42<36:52, 10.95s/it]predicting train subjects:  35%|███▌      | 110/311 [23:53<36:58, 11.04s/it]predicting train subjects:  36%|███▌      | 111/311 [24:04<36:59, 11.10s/it]predicting train subjects:  36%|███▌      | 112/311 [24:16<36:57, 11.15s/it]predicting train subjects:  36%|███▋      | 113/311 [24:27<36:45, 11.14s/it]predicting train subjects:  37%|███▋      | 114/311 [24:48<45:57, 14.00s/it]predicting train subjects:  37%|███▋      | 115/311 [25:08<52:17, 16.01s/it]predicting train subjects:  37%|███▋      | 116/311 [25:29<56:13, 17.30s/it]predicting train subjects:  38%|███▊      | 117/311 [25:49<58:54, 18.22s/it]predicting train subjects:  38%|███▊      | 118/311 [26:09<1:00:43, 18.88s/it]predicting train subjects:  38%|███▊      | 119/311 [26:30<1:01:43, 19.29s/it]predicting train subjects:  39%|███▊      | 120/311 [26:50<1:02:35, 19.66s/it]predicting train subjects:  39%|███▉      | 121/311 [27:11<1:03:20, 20.00s/it]predicting train subjects:  39%|███▉      | 122/311 [27:31<1:03:13, 20.07s/it]predicting train subjects:  40%|███▉      | 123/311 [27:51<1:03:07, 20.15s/it]predicting train subjects:  40%|███▉      | 124/311 [28:13<1:03:38, 20.42s/it]predicting train subjects:  40%|████      | 125/311 [28:34<1:04:04, 20.67s/it]predicting train subjects:  41%|████      | 126/311 [28:55<1:03:56, 20.74s/it]predicting train subjects:  41%|████      | 127/311 [29:16<1:04:02, 20.88s/it]predicting train subjects:  41%|████      | 128/311 [29:37<1:03:53, 20.95s/it]predicting train subjects:  41%|████▏     | 129/311 [29:58<1:03:59, 21.10s/it]predicting train subjects:  42%|████▏     | 130/311 [30:19<1:03:23, 21.01s/it]predicting train subjects:  42%|████▏     | 131/311 [30:40<1:03:10, 21.06s/it]predicting train subjects:  42%|████▏     | 132/311 [30:50<52:44, 17.68s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:00<45:41, 15.40s/it]predicting train subjects:  43%|████▎     | 134/311 [31:10<40:14, 13.64s/it]predicting train subjects:  43%|████▎     | 135/311 [31:19<36:29, 12.44s/it]predicting train subjects:  44%|████▎     | 136/311 [31:30<34:12, 11.73s/it]predicting train subjects:  44%|████▍     | 137/311 [31:39<32:03, 11.06s/it]predicting train subjects:  44%|████▍     | 138/311 [31:49<30:43, 10.65s/it]predicting train subjects:  45%|████▍     | 139/311 [31:59<30:00, 10.47s/it]predicting train subjects:  45%|████▌     | 140/311 [32:08<29:01, 10.18s/it]predicting train subjects:  45%|████▌     | 141/311 [32:18<28:32, 10.07s/it]predicting train subjects:  46%|████▌     | 142/311 [32:28<28:19, 10.06s/it]predicting train subjects:  46%|████▌     | 143/311 [32:38<28:16, 10.10s/it]predicting train subjects:  46%|████▋     | 144/311 [32:48<27:46,  9.98s/it]predicting train subjects:  47%|████▋     | 145/311 [32:58<27:31,  9.95s/it]predicting train subjects:  47%|████▋     | 146/311 [33:08<27:21,  9.95s/it]predicting train subjects:  47%|████▋     | 147/311 [33:17<26:34,  9.72s/it]predicting train subjects:  48%|████▊     | 148/311 [33:27<26:30,  9.76s/it]predicting train subjects:  48%|████▊     | 149/311 [33:37<26:58,  9.99s/it]predicting train subjects:  48%|████▊     | 150/311 [33:50<28:39, 10.68s/it]predicting train subjects:  49%|████▊     | 151/311 [34:02<29:44, 11.15s/it]predicting train subjects:  49%|████▉     | 152/311 [34:14<30:30, 11.51s/it]predicting train subjects:  49%|████▉     | 153/311 [34:27<31:04, 11.80s/it]predicting train subjects:  50%|████▉     | 154/311 [34:39<31:32, 12.06s/it]predicting train subjects:  50%|████▉     | 155/311 [34:52<31:42, 12.19s/it]predicting train subjects:  50%|█████     | 156/311 [35:05<31:58, 12.38s/it]predicting train subjects:  50%|█████     | 157/311 [35:17<31:50, 12.41s/it]predicting train subjects:  51%|█████     | 158/311 [35:29<31:21, 12.30s/it]predicting train subjects:  51%|█████     | 159/311 [35:41<31:04, 12.26s/it]predicting train subjects:  51%|█████▏    | 160/311 [35:55<31:43, 12.60s/it]predicting train subjects:  52%|█████▏    | 161/311 [36:07<31:28, 12.59s/it]predicting train subjects:  52%|█████▏    | 162/311 [36:20<31:12, 12.56s/it]predicting train subjects:  52%|█████▏    | 163/311 [36:33<31:32, 12.79s/it]predicting train subjects:  53%|█████▎    | 164/311 [36:45<30:50, 12.59s/it]predicting train subjects:  53%|█████▎    | 165/311 [36:58<30:19, 12.46s/it]predicting train subjects:  53%|█████▎    | 166/311 [37:09<29:37, 12.26s/it]predicting train subjects:  54%|█████▎    | 167/311 [37:21<29:15, 12.19s/it]predicting train subjects:  54%|█████▍    | 168/311 [37:34<29:02, 12.18s/it]predicting train subjects:  54%|█████▍    | 169/311 [37:46<28:47, 12.16s/it]predicting train subjects:  55%|█████▍    | 170/311 [37:58<28:32, 12.15s/it]predicting train subjects:  55%|█████▍    | 171/311 [38:09<28:03, 12.03s/it]predicting train subjects:  55%|█████▌    | 172/311 [38:21<27:39, 11.94s/it]predicting train subjects:  56%|█████▌    | 173/311 [38:33<27:29, 11.95s/it]predicting train subjects:  56%|█████▌    | 174/311 [38:45<27:20, 11.97s/it]predicting train subjects:  56%|█████▋    | 175/311 [38:57<27:19, 12.05s/it]predicting train subjects:  57%|█████▋    | 176/311 [39:09<26:55, 11.97s/it]predicting train subjects:  57%|█████▋    | 177/311 [39:21<26:28, 11.85s/it]predicting train subjects:  57%|█████▋    | 178/311 [39:32<26:06, 11.78s/it]predicting train subjects:  58%|█████▊    | 179/311 [39:44<26:05, 11.86s/it]predicting train subjects:  58%|█████▊    | 180/311 [39:56<25:54, 11.87s/it]predicting train subjects:  58%|█████▊    | 181/311 [40:08<25:37, 11.83s/it]predicting train subjects:  59%|█████▊    | 182/311 [40:20<25:28, 11.85s/it]predicting train subjects:  59%|█████▉    | 183/311 [40:32<25:32, 11.97s/it]predicting train subjects:  59%|█████▉    | 184/311 [40:43<24:51, 11.74s/it]predicting train subjects:  59%|█████▉    | 185/311 [40:54<24:07, 11.49s/it]predicting train subjects:  60%|█████▉    | 186/311 [41:05<23:26, 11.25s/it]predicting train subjects:  60%|██████    | 187/311 [41:16<23:10, 11.21s/it]predicting train subjects:  60%|██████    | 188/311 [41:27<22:56, 11.20s/it]predicting train subjects:  61%|██████    | 189/311 [41:38<22:33, 11.09s/it]predicting train subjects:  61%|██████    | 190/311 [41:49<22:15, 11.03s/it]predicting train subjects:  61%|██████▏   | 191/311 [42:00<22:08, 11.07s/it]predicting train subjects:  62%|██████▏   | 192/311 [42:11<21:53, 11.04s/it]predicting train subjects:  62%|██████▏   | 193/311 [42:22<21:36, 10.99s/it]predicting train subjects:  62%|██████▏   | 194/311 [42:33<21:14, 10.90s/it]predicting train subjects:  63%|██████▎   | 195/311 [42:44<21:14, 10.99s/it]predicting train subjects:  63%|██████▎   | 196/311 [42:55<21:08, 11.03s/it]predicting train subjects:  63%|██████▎   | 197/311 [43:06<20:52, 10.98s/it]predicting train subjects:  64%|██████▎   | 198/311 [43:17<20:31, 10.90s/it]predicting train subjects:  64%|██████▍   | 199/311 [43:28<20:38, 11.06s/it]predicting train subjects:  64%|██████▍   | 200/311 [43:39<20:32, 11.10s/it]predicting train subjects:  65%|██████▍   | 201/311 [43:50<20:22, 11.11s/it]predicting train subjects:  65%|██████▍   | 202/311 [44:01<20:00, 11.02s/it]predicting train subjects:  65%|██████▌   | 203/311 [44:12<19:52, 11.04s/it]predicting train subjects:  66%|██████▌   | 204/311 [44:24<19:46, 11.09s/it]predicting train subjects:  66%|██████▌   | 205/311 [44:35<19:46, 11.19s/it]predicting train subjects:  66%|██████▌   | 206/311 [44:46<19:27, 11.12s/it]predicting train subjects:  67%|██████▋   | 207/311 [44:57<19:08, 11.04s/it]predicting train subjects:  67%|██████▋   | 208/311 [45:08<19:01, 11.08s/it]predicting train subjects:  67%|██████▋   | 209/311 [45:19<18:51, 11.09s/it]predicting train subjects:  68%|██████▊   | 210/311 [45:30<18:44, 11.14s/it]predicting train subjects:  68%|██████▊   | 211/311 [45:41<18:25, 11.05s/it]predicting train subjects:  68%|██████▊   | 212/311 [45:52<18:09, 11.01s/it]predicting train subjects:  68%|██████▊   | 213/311 [46:13<22:55, 14.04s/it]predicting train subjects:  69%|██████▉   | 214/311 [46:34<26:01, 16.10s/it]predicting train subjects:  69%|██████▉   | 215/311 [46:55<27:55, 17.45s/it]predicting train subjects:  69%|██████▉   | 216/311 [47:16<29:16, 18.49s/it]predicting train subjects:  70%|██████▉   | 217/311 [47:36<29:49, 19.04s/it]predicting train subjects:  70%|███████   | 218/311 [47:57<30:33, 19.71s/it]predicting train subjects:  70%|███████   | 219/311 [48:18<30:45, 20.06s/it]predicting train subjects:  71%|███████   | 220/311 [48:39<30:59, 20.43s/it]predicting train subjects:  71%|███████   | 221/311 [49:00<30:39, 20.44s/it]predicting train subjects:  71%|███████▏  | 222/311 [49:21<30:37, 20.65s/it]predicting train subjects:  72%|███████▏  | 223/311 [49:42<30:14, 20.62s/it]predicting train subjects:  72%|███████▏  | 224/311 [50:03<30:08, 20.79s/it]predicting train subjects:  72%|███████▏  | 225/311 [50:23<29:44, 20.75s/it]predicting train subjects:  73%|███████▎  | 226/311 [50:44<29:18, 20.69s/it]predicting train subjects:  73%|███████▎  | 227/311 [51:05<29:09, 20.83s/it]predicting train subjects:  73%|███████▎  | 228/311 [51:25<28:39, 20.71s/it]predicting train subjects:  74%|███████▎  | 229/311 [51:47<28:29, 20.85s/it]predicting train subjects:  74%|███████▍  | 230/311 [52:08<28:09, 20.86s/it]predicting train subjects:  74%|███████▍  | 231/311 [52:17<23:20, 17.51s/it]predicting train subjects:  75%|███████▍  | 232/311 [52:27<20:08, 15.30s/it]predicting train subjects:  75%|███████▍  | 233/311 [52:38<17:54, 13.78s/it]predicting train subjects:  75%|███████▌  | 234/311 [52:47<16:05, 12.54s/it]predicting train subjects:  76%|███████▌  | 235/311 [52:58<15:01, 11.86s/it]predicting train subjects:  76%|███████▌  | 236/311 [53:08<14:16, 11.42s/it]predicting train subjects:  76%|███████▌  | 237/311 [53:18<13:24, 10.87s/it]predicting train subjects:  77%|███████▋  | 238/311 [53:28<13:06, 10.78s/it]predicting train subjects:  77%|███████▋  | 239/311 [53:38<12:47, 10.67s/it]predicting train subjects:  77%|███████▋  | 240/311 [53:48<12:21, 10.45s/it]predicting train subjects:  77%|███████▋  | 241/311 [53:59<12:11, 10.45s/it]predicting train subjects:  78%|███████▊  | 242/311 [54:09<11:52, 10.33s/it]predicting train subjects:  78%|███████▊  | 243/311 [54:19<11:31, 10.16s/it]predicting train subjects:  78%|███████▊  | 244/311 [54:29<11:20, 10.15s/it]predicting train subjects:  79%|███████▉  | 245/311 [54:39<11:01, 10.02s/it]predicting train subjects:  79%|███████▉  | 246/311 [54:49<10:54, 10.07s/it]predicting train subjects:  79%|███████▉  | 247/311 [54:59<10:47, 10.11s/it]predicting train subjects:  80%|███████▉  | 248/311 [55:09<10:31, 10.03s/it]predicting train subjects:  80%|████████  | 249/311 [55:22<11:18, 10.95s/it]predicting train subjects:  80%|████████  | 250/311 [55:35<11:51, 11.67s/it]predicting train subjects:  81%|████████  | 251/311 [55:48<12:03, 12.06s/it]predicting train subjects:  81%|████████  | 252/311 [56:01<12:01, 12.23s/it]predicting train subjects:  81%|████████▏ | 253/311 [56:13<11:56, 12.35s/it]predicting train subjects:  82%|████████▏ | 254/311 [56:26<11:55, 12.54s/it]predicting train subjects:  82%|████████▏ | 255/311 [56:39<11:49, 12.66s/it]predicting train subjects:  82%|████████▏ | 256/311 [56:52<11:37, 12.68s/it]predicting train subjects:  83%|████████▎ | 257/311 [57:05<11:25, 12.69s/it]predicting train subjects:  83%|████████▎ | 258/311 [57:17<11:07, 12.60s/it]predicting train subjects:  83%|████████▎ | 259/311 [57:30<11:02, 12.74s/it]predicting train subjects:  84%|████████▎ | 260/311 [57:43<10:53, 12.81s/it]predicting train subjects:  84%|████████▍ | 261/311 [57:56<10:42, 12.86s/it]predicting train subjects:  84%|████████▍ | 262/311 [58:09<10:27, 12.81s/it]predicting train subjects:  85%|████████▍ | 263/311 [58:22<10:12, 12.76s/it]predicting train subjects:  85%|████████▍ | 264/311 [58:34<09:54, 12.66s/it]predicting train subjects:  85%|████████▌ | 265/311 [58:46<09:39, 12.61s/it]predicting train subjects:  86%|████████▌ | 266/311 [58:59<09:26, 12.59s/it]predicting train subjects:  86%|████████▌ | 267/311 [59:11<09:07, 12.44s/it]predicting train subjects:  86%|████████▌ | 268/311 [59:23<08:44, 12.20s/it]predicting train subjects:  86%|████████▋ | 269/311 [59:35<08:29, 12.14s/it]predicting train subjects:  87%|████████▋ | 270/311 [59:47<08:22, 12.26s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:00:00<08:12, 12.30s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:00:12<08:02, 12.38s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:00:24<07:41, 12.14s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:00:36<07:29, 12.15s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:00:48<07:20, 12.23s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:01:01<07:07, 12.22s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:01:13<06:54, 12.20s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:01:25<06:40, 12.15s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:01:37<06:29, 12.17s/it]predicting train subjects:  90%|█████████ | 280/311 [1:01:49<06:17, 12.19s/it]predicting train subjects:  90%|█████████ | 281/311 [1:02:01<06:04, 12.16s/it]predicting train subjects:  91%|█████████ | 282/311 [1:02:14<05:53, 12.18s/it]predicting train subjects:  91%|█████████ | 283/311 [1:02:24<05:30, 11.79s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:02:35<05:11, 11.54s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:02:46<04:55, 11.38s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:02:57<04:41, 11.28s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:03:08<04:27, 11.16s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:03:20<04:16, 11.17s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:03:31<04:07, 11.25s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:03:42<03:53, 11.10s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:03:52<03:39, 10.95s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:04:03<03:28, 10.97s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:04:14<03:18, 11.00s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:04:25<03:06, 10.98s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:04:36<02:54, 10.91s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:04:47<02:44, 11.00s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:04:58<02:34, 11.02s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:05:09<02:22, 10.98s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:05:20<02:11, 10.98s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:05:31<02:01, 11.04s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:05:42<01:50, 11.01s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:05:53<01:38, 10.90s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:06:04<01:28, 11.01s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:06:16<01:17, 11.09s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:06:26<01:05, 10.97s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:06:37<00:54, 10.96s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:06:49<00:44, 11.10s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:07:00<00:33, 11.10s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:07:11<00:22, 11.02s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:07:22<00:11, 11.10s/it]predicting train subjects: 100%|██████████| 311/311 [1:07:34<00:00, 11.54s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:30:29, 17.51s/it]Loading train:   1%|          | 2/311 [00:26<1:16:31, 14.86s/it]Loading train:   1%|          | 3/311 [00:36<1:09:59, 13.63s/it]Loading train:   1%|▏         | 4/311 [00:48<1:07:07, 13.12s/it]Loading train:   2%|▏         | 5/311 [01:00<1:03:55, 12.53s/it]Loading train:   2%|▏         | 6/311 [01:11<1:02:01, 12.20s/it]Loading train:   2%|▏         | 7/311 [01:24<1:03:05, 12.45s/it]Loading train:   3%|▎         | 8/311 [01:39<1:06:19, 13.14s/it]Loading train:   3%|▎         | 9/311 [01:52<1:06:15, 13.16s/it]Loading train:   3%|▎         | 10/311 [02:04<1:03:52, 12.73s/it]Loading train:   4%|▎         | 11/311 [02:18<1:06:27, 13.29s/it]Loading train:   4%|▍         | 12/311 [02:31<1:05:04, 13.06s/it]Loading train:   4%|▍         | 13/311 [02:42<1:02:04, 12.50s/it]Loading train:   5%|▍         | 14/311 [02:57<1:05:34, 13.25s/it]Loading train:   5%|▍         | 15/311 [03:08<1:02:20, 12.64s/it]Loading train:   5%|▌         | 16/311 [03:20<1:00:21, 12.28s/it]Loading train:   5%|▌         | 17/311 [03:31<58:06, 11.86s/it]  Loading train:   6%|▌         | 18/311 [03:41<56:13, 11.51s/it]Loading train:   6%|▌         | 19/311 [03:53<55:53, 11.48s/it]Loading train:   6%|▋         | 20/311 [04:04<55:30, 11.45s/it]Loading train:   7%|▋         | 21/311 [04:16<55:48, 11.55s/it]Loading train:   7%|▋         | 22/311 [04:29<57:19, 11.90s/it]Loading train:   7%|▋         | 23/311 [04:40<56:48, 11.83s/it]Loading train:   8%|▊         | 24/311 [04:51<55:19, 11.57s/it]Loading train:   8%|▊         | 25/311 [05:02<54:29, 11.43s/it]Loading train:   8%|▊         | 26/311 [05:14<54:34, 11.49s/it]Loading train:   9%|▊         | 27/311 [05:26<54:59, 11.62s/it]Loading train:   9%|▉         | 28/311 [05:37<54:53, 11.64s/it]Loading train:   9%|▉         | 29/311 [05:49<54:57, 11.70s/it]Loading train:  10%|▉         | 30/311 [06:01<54:51, 11.71s/it]Loading train:  10%|▉         | 31/311 [06:13<54:38, 11.71s/it]Loading train:  10%|█         | 32/311 [06:25<54:45, 11.77s/it]Loading train:  11%|█         | 33/311 [06:31<47:03, 10.16s/it]Loading train:  11%|█         | 34/311 [06:37<41:14,  8.93s/it]Loading train:  11%|█▏        | 35/311 [06:43<37:10,  8.08s/it]Loading train:  12%|█▏        | 36/311 [06:49<34:24,  7.51s/it]Loading train:  12%|█▏        | 37/311 [06:56<33:12,  7.27s/it]Loading train:  12%|█▏        | 38/311 [07:04<33:15,  7.31s/it]Loading train:  13%|█▎        | 39/311 [07:10<32:38,  7.20s/it]Loading train:  13%|█▎        | 40/311 [07:18<32:48,  7.26s/it]Loading train:  13%|█▎        | 41/311 [07:24<31:17,  6.95s/it]Loading train:  14%|█▎        | 42/311 [07:31<31:14,  6.97s/it]Loading train:  14%|█▍        | 43/311 [07:38<31:05,  6.96s/it]Loading train:  14%|█▍        | 44/311 [07:46<31:37,  7.11s/it]Loading train:  14%|█▍        | 45/311 [07:52<31:03,  7.01s/it]Loading train:  15%|█▍        | 46/311 [07:59<30:59,  7.02s/it]Loading train:  15%|█▌        | 47/311 [08:06<30:34,  6.95s/it]Loading train:  15%|█▌        | 48/311 [08:14<31:18,  7.14s/it]Loading train:  16%|█▌        | 49/311 [08:20<30:28,  6.98s/it]Loading train:  16%|█▌        | 50/311 [08:27<30:18,  6.97s/it]Loading train:  16%|█▋        | 51/311 [08:35<31:33,  7.28s/it]Loading train:  17%|█▋        | 52/311 [08:44<32:58,  7.64s/it]Loading train:  17%|█▋        | 53/311 [08:52<33:33,  7.80s/it]Loading train:  17%|█▋        | 54/311 [09:00<34:14,  7.99s/it]Loading train:  18%|█▊        | 55/311 [09:10<36:04,  8.46s/it]Loading train:  18%|█▊        | 56/311 [09:16<33:30,  7.89s/it]Loading train:  18%|█▊        | 57/311 [09:24<32:37,  7.71s/it]Loading train:  19%|█▊        | 58/311 [09:30<30:40,  7.27s/it]Loading train:  19%|█▉        | 59/311 [09:36<29:13,  6.96s/it]Loading train:  19%|█▉        | 60/311 [09:42<28:10,  6.73s/it]Loading train:  20%|█▉        | 61/311 [09:49<27:33,  6.62s/it]Loading train:  20%|█▉        | 62/311 [09:55<27:01,  6.51s/it]Loading train:  20%|██        | 63/311 [10:01<26:17,  6.36s/it]Loading train:  21%|██        | 64/311 [10:07<25:56,  6.30s/it]Loading train:  21%|██        | 65/311 [10:13<25:26,  6.21s/it]Loading train:  21%|██        | 66/311 [10:19<25:20,  6.20s/it]Loading train:  22%|██▏       | 67/311 [10:25<24:54,  6.13s/it]Loading train:  22%|██▏       | 68/311 [10:31<24:30,  6.05s/it]Loading train:  22%|██▏       | 69/311 [10:37<24:27,  6.07s/it]Loading train:  23%|██▎       | 70/311 [10:44<24:33,  6.11s/it]Loading train:  23%|██▎       | 71/311 [10:49<23:54,  5.98s/it]Loading train:  23%|██▎       | 72/311 [10:55<23:39,  5.94s/it]Loading train:  23%|██▎       | 73/311 [11:01<23:28,  5.92s/it]Loading train:  24%|██▍       | 74/311 [11:07<23:18,  5.90s/it]Loading train:  24%|██▍       | 75/311 [11:12<22:59,  5.85s/it]Loading train:  24%|██▍       | 76/311 [11:18<22:53,  5.84s/it]Loading train:  25%|██▍       | 77/311 [11:24<22:30,  5.77s/it]Loading train:  25%|██▌       | 78/311 [11:30<22:10,  5.71s/it]Loading train:  25%|██▌       | 79/311 [11:35<22:11,  5.74s/it]Loading train:  26%|██▌       | 80/311 [11:41<22:03,  5.73s/it]Loading train:  26%|██▌       | 81/311 [11:47<21:53,  5.71s/it]Loading train:  26%|██▋       | 82/311 [11:53<21:57,  5.75s/it]Loading train:  27%|██▋       | 83/311 [11:58<21:38,  5.70s/it]Loading train:  27%|██▋       | 84/311 [12:04<21:43,  5.74s/it]Loading train:  27%|██▋       | 85/311 [12:09<21:18,  5.66s/it]Loading train:  28%|██▊       | 86/311 [12:15<20:53,  5.57s/it]Loading train:  28%|██▊       | 87/311 [12:20<20:39,  5.53s/it]Loading train:  28%|██▊       | 88/311 [12:26<20:25,  5.50s/it]Loading train:  29%|██▊       | 89/311 [12:31<20:01,  5.41s/it]Loading train:  29%|██▉       | 90/311 [12:36<19:43,  5.35s/it]Loading train:  29%|██▉       | 91/311 [12:41<19:37,  5.35s/it]Loading train:  30%|██▉       | 92/311 [12:47<19:25,  5.32s/it]Loading train:  30%|██▉       | 93/311 [12:52<19:23,  5.34s/it]Loading train:  30%|███       | 94/311 [12:57<19:20,  5.35s/it]Loading train:  31%|███       | 95/311 [13:03<19:09,  5.32s/it]Loading train:  31%|███       | 96/311 [13:08<19:17,  5.38s/it]Loading train:  31%|███       | 97/311 [13:14<19:12,  5.39s/it]Loading train:  32%|███▏      | 98/311 [13:19<19:20,  5.45s/it]Loading train:  32%|███▏      | 99/311 [13:25<19:23,  5.49s/it]Loading train:  32%|███▏      | 100/311 [13:31<19:35,  5.57s/it]Loading train:  32%|███▏      | 101/311 [13:36<19:37,  5.60s/it]Loading train:  33%|███▎      | 102/311 [13:43<20:32,  5.90s/it]Loading train:  33%|███▎      | 103/311 [13:49<20:40,  5.96s/it]Loading train:  33%|███▎      | 104/311 [13:54<19:57,  5.78s/it]Loading train:  34%|███▍      | 105/311 [14:01<20:21,  5.93s/it]Loading train:  34%|███▍      | 106/311 [14:07<20:18,  5.94s/it]Loading train:  34%|███▍      | 107/311 [14:12<19:54,  5.86s/it]Loading train:  35%|███▍      | 108/311 [14:18<19:59,  5.91s/it]Loading train:  35%|███▌      | 109/311 [14:24<19:46,  5.87s/it]Loading train:  35%|███▌      | 110/311 [14:30<19:51,  5.93s/it]Loading train:  36%|███▌      | 111/311 [14:36<19:53,  5.97s/it]Loading train:  36%|███▌      | 112/311 [14:42<19:51,  5.99s/it]Loading train:  36%|███▋      | 113/311 [14:48<19:23,  5.88s/it]Loading train:  37%|███▋      | 114/311 [14:58<23:38,  7.20s/it]Loading train:  37%|███▋      | 115/311 [15:08<26:36,  8.14s/it]Loading train:  37%|███▋      | 116/311 [15:18<28:17,  8.71s/it]Loading train:  38%|███▊      | 117/311 [15:30<30:34,  9.46s/it]Loading train:  38%|███▊      | 118/311 [15:41<31:48,  9.89s/it]Loading train:  38%|███▊      | 119/311 [15:51<31:51,  9.96s/it]Loading train:  39%|███▊      | 120/311 [16:01<31:40,  9.95s/it]Loading train:  39%|███▉      | 121/311 [16:11<32:23, 10.23s/it]Loading train:  39%|███▉      | 122/311 [16:22<32:12, 10.22s/it]Loading train:  40%|███▉      | 123/311 [16:32<32:27, 10.36s/it]Loading train:  40%|███▉      | 124/311 [16:42<31:58, 10.26s/it]Loading train:  40%|████      | 125/311 [16:53<31:44, 10.24s/it]Loading train:  41%|████      | 126/311 [17:03<31:26, 10.20s/it]Loading train:  41%|████      | 127/311 [17:13<31:38, 10.32s/it]Loading train:  41%|████      | 128/311 [17:24<31:35, 10.36s/it]Loading train:  41%|████▏     | 129/311 [17:34<31:44, 10.46s/it]Loading train:  42%|████▏     | 130/311 [17:45<31:22, 10.40s/it]Loading train:  42%|████▏     | 131/311 [17:55<31:17, 10.43s/it]Loading train:  42%|████▏     | 132/311 [18:01<26:55,  9.02s/it]Loading train:  43%|████▎     | 133/311 [18:07<23:51,  8.04s/it]Loading train:  43%|████▎     | 134/311 [18:12<21:40,  7.35s/it]Loading train:  43%|████▎     | 135/311 [18:18<20:05,  6.85s/it]Loading train:  44%|████▎     | 136/311 [18:23<18:28,  6.34s/it]Loading train:  44%|████▍     | 137/311 [18:28<17:13,  5.94s/it]Loading train:  44%|████▍     | 138/311 [18:34<16:39,  5.78s/it]Loading train:  45%|████▍     | 139/311 [18:39<16:02,  5.59s/it]Loading train:  45%|████▌     | 140/311 [18:44<15:25,  5.41s/it]Loading train:  45%|████▌     | 141/311 [18:49<15:09,  5.35s/it]Loading train:  46%|████▌     | 142/311 [18:54<14:48,  5.26s/it]Loading train:  46%|████▌     | 143/311 [18:59<14:22,  5.13s/it]Loading train:  46%|████▋     | 144/311 [19:04<14:01,  5.04s/it]Loading train:  47%|████▋     | 145/311 [19:09<13:58,  5.05s/it]Loading train:  47%|████▋     | 146/311 [19:14<13:41,  4.98s/it]Loading train:  47%|████▋     | 147/311 [19:19<13:35,  4.97s/it]Loading train:  48%|████▊     | 148/311 [19:23<13:24,  4.93s/it]Loading train:  48%|████▊     | 149/311 [19:28<13:27,  4.98s/it]Loading train:  48%|████▊     | 150/311 [19:34<13:55,  5.19s/it]Loading train:  49%|████▊     | 151/311 [19:40<14:21,  5.39s/it]Loading train:  49%|████▉     | 152/311 [19:46<14:56,  5.64s/it]Loading train:  49%|████▉     | 153/311 [19:52<15:05,  5.73s/it]Loading train:  50%|████▉     | 154/311 [19:58<15:00,  5.73s/it]Loading train:  50%|████▉     | 155/311 [20:04<15:04,  5.80s/it]Loading train:  50%|█████     | 156/311 [20:10<15:15,  5.90s/it]Loading train:  50%|█████     | 157/311 [20:16<15:03,  5.87s/it]Loading train:  51%|█████     | 158/311 [20:22<15:10,  5.95s/it]Loading train:  51%|█████     | 159/311 [20:28<15:08,  5.98s/it]Loading train:  51%|█████▏    | 160/311 [20:34<14:53,  5.92s/it]Loading train:  52%|█████▏    | 161/311 [20:40<14:48,  5.93s/it]Loading train:  52%|█████▏    | 162/311 [20:46<14:43,  5.93s/it]Loading train:  52%|█████▏    | 163/311 [20:51<14:28,  5.87s/it]Loading train:  53%|█████▎    | 164/311 [20:57<14:26,  5.90s/it]Loading train:  53%|█████▎    | 165/311 [21:03<14:22,  5.91s/it]Loading train:  53%|█████▎    | 166/311 [21:09<14:13,  5.89s/it]Loading train:  54%|█████▎    | 167/311 [21:15<14:02,  5.85s/it]Loading train:  54%|█████▍    | 168/311 [21:21<13:59,  5.87s/it]Loading train:  54%|█████▍    | 169/311 [21:27<13:50,  5.85s/it]Loading train:  55%|█████▍    | 170/311 [21:32<13:39,  5.81s/it]Loading train:  55%|█████▍    | 171/311 [21:38<13:39,  5.86s/it]Loading train:  55%|█████▌    | 172/311 [21:44<13:34,  5.86s/it]Loading train:  56%|█████▌    | 173/311 [21:50<13:23,  5.82s/it]Loading train:  56%|█████▌    | 174/311 [21:56<13:17,  5.82s/it]Loading train:  56%|█████▋    | 175/311 [22:02<13:15,  5.85s/it]Loading train:  57%|█████▋    | 176/311 [22:08<13:11,  5.87s/it]Loading train:  57%|█████▋    | 177/311 [22:14<13:14,  5.93s/it]Loading train:  57%|█████▋    | 178/311 [22:20<13:14,  5.97s/it]Loading train:  58%|█████▊    | 179/311 [22:25<12:56,  5.88s/it]Loading train:  58%|█████▊    | 180/311 [22:31<12:38,  5.79s/it]Loading train:  58%|█████▊    | 181/311 [22:37<12:42,  5.86s/it]Loading train:  59%|█████▊    | 182/311 [22:43<12:28,  5.80s/it]Loading train:  59%|█████▉    | 183/311 [22:49<12:28,  5.85s/it]Loading train:  59%|█████▉    | 184/311 [22:54<12:12,  5.77s/it]Loading train:  59%|█████▉    | 185/311 [23:00<11:54,  5.67s/it]Loading train:  60%|█████▉    | 186/311 [23:05<11:45,  5.65s/it]Loading train:  60%|██████    | 187/311 [23:11<11:37,  5.63s/it]Loading train:  60%|██████    | 188/311 [23:16<11:26,  5.58s/it]Loading train:  61%|██████    | 189/311 [23:21<10:56,  5.38s/it]Loading train:  61%|██████    | 190/311 [23:26<10:39,  5.28s/it]Loading train:  61%|██████▏   | 191/311 [23:32<10:38,  5.32s/it]Loading train:  62%|██████▏   | 192/311 [23:37<10:23,  5.24s/it]Loading train:  62%|██████▏   | 193/311 [23:42<10:08,  5.16s/it]Loading train:  62%|██████▏   | 194/311 [23:47<10:00,  5.13s/it]Loading train:  63%|██████▎   | 195/311 [23:52<09:53,  5.12s/it]Loading train:  63%|██████▎   | 196/311 [23:57<09:42,  5.07s/it]Loading train:  63%|██████▎   | 197/311 [24:02<09:31,  5.02s/it]Loading train:  64%|██████▎   | 198/311 [24:07<09:27,  5.02s/it]Loading train:  64%|██████▍   | 199/311 [24:12<09:21,  5.01s/it]Loading train:  64%|██████▍   | 200/311 [24:17<09:15,  5.01s/it]Loading train:  65%|██████▍   | 201/311 [24:22<09:13,  5.04s/it]Loading train:  65%|██████▍   | 202/311 [24:27<09:10,  5.05s/it]Loading train:  65%|██████▌   | 203/311 [24:32<09:03,  5.03s/it]Loading train:  66%|██████▌   | 204/311 [24:37<08:55,  5.01s/it]Loading train:  66%|██████▌   | 205/311 [24:42<08:59,  5.09s/it]Loading train:  66%|██████▌   | 206/311 [24:47<08:40,  4.96s/it]Loading train:  67%|██████▋   | 207/311 [24:52<08:41,  5.02s/it]Loading train:  67%|██████▋   | 208/311 [24:57<08:47,  5.12s/it]Loading train:  67%|██████▋   | 209/311 [25:02<08:39,  5.09s/it]Loading train:  68%|██████▊   | 210/311 [25:07<08:32,  5.08s/it]Loading train:  68%|██████▊   | 211/311 [25:13<08:33,  5.13s/it]Loading train:  68%|██████▊   | 212/311 [25:18<08:31,  5.16s/it]Loading train:  68%|██████▊   | 213/311 [25:27<10:19,  6.32s/it]Loading train:  69%|██████▉   | 214/311 [25:36<11:32,  7.13s/it]Loading train:  69%|██████▉   | 215/311 [25:45<12:20,  7.71s/it]Loading train:  69%|██████▉   | 216/311 [25:54<12:43,  8.04s/it]Loading train:  70%|██████▉   | 217/311 [26:03<13:08,  8.38s/it]Loading train:  70%|███████   | 218/311 [26:12<13:14,  8.54s/it]Loading train:  70%|███████   | 219/311 [26:21<13:24,  8.74s/it]Loading train:  71%|███████   | 220/311 [26:30<13:16,  8.75s/it]Loading train:  71%|███████   | 221/311 [26:39<13:08,  8.76s/it]Loading train:  71%|███████▏  | 222/311 [26:48<13:11,  8.89s/it]Loading train:  72%|███████▏  | 223/311 [26:57<13:03,  8.91s/it]Loading train:  72%|███████▏  | 224/311 [27:06<12:59,  8.96s/it]Loading train:  72%|███████▏  | 225/311 [27:14<12:39,  8.83s/it]Loading train:  73%|███████▎  | 226/311 [27:24<12:40,  8.94s/it]Loading train:  73%|███████▎  | 227/311 [27:33<12:35,  8.99s/it]Loading train:  73%|███████▎  | 228/311 [27:42<12:27,  9.01s/it]Loading train:  74%|███████▎  | 229/311 [27:51<12:25,  9.09s/it]Loading train:  74%|███████▍  | 230/311 [28:00<12:12,  9.05s/it]Loading train:  74%|███████▍  | 231/311 [28:05<10:19,  7.75s/it]Loading train:  75%|███████▍  | 232/311 [28:09<08:57,  6.80s/it]Loading train:  75%|███████▍  | 233/311 [28:14<07:56,  6.11s/it]Loading train:  75%|███████▌  | 234/311 [28:18<07:15,  5.66s/it]Loading train:  76%|███████▌  | 235/311 [28:23<06:46,  5.35s/it]Loading train:  76%|███████▌  | 236/311 [28:27<06:21,  5.09s/it]Loading train:  76%|███████▌  | 237/311 [28:32<05:57,  4.83s/it]Loading train:  77%|███████▋  | 238/311 [28:36<05:45,  4.73s/it]Loading train:  77%|███████▋  | 239/311 [28:41<05:36,  4.68s/it]Loading train:  77%|███████▋  | 240/311 [28:45<05:25,  4.59s/it]Loading train:  77%|███████▋  | 241/311 [28:49<05:14,  4.49s/it]Loading train:  78%|███████▊  | 242/311 [28:54<05:13,  4.54s/it]Loading train:  78%|███████▊  | 243/311 [28:59<05:08,  4.54s/it]Loading train:  78%|███████▊  | 244/311 [29:03<04:59,  4.47s/it]Loading train:  79%|███████▉  | 245/311 [29:07<04:51,  4.42s/it]Loading train:  79%|███████▉  | 246/311 [29:12<04:49,  4.45s/it]Loading train:  79%|███████▉  | 247/311 [29:16<04:44,  4.45s/it]Loading train:  80%|███████▉  | 248/311 [29:21<04:43,  4.50s/it]Loading train:  80%|████████  | 249/311 [29:26<04:58,  4.81s/it]Loading train:  80%|████████  | 250/311 [29:32<05:09,  5.08s/it]Loading train:  81%|████████  | 251/311 [29:38<05:17,  5.30s/it]Loading train:  81%|████████  | 252/311 [29:43<05:15,  5.35s/it]Loading train:  81%|████████▏ | 253/311 [29:49<05:18,  5.49s/it]Loading train:  82%|████████▏ | 254/311 [29:55<05:12,  5.48s/it]Loading train:  82%|████████▏ | 255/311 [30:00<05:08,  5.51s/it]Loading train:  82%|████████▏ | 256/311 [30:06<05:09,  5.63s/it]Loading train:  83%|████████▎ | 257/311 [30:12<05:03,  5.62s/it]Loading train:  83%|████████▎ | 258/311 [30:17<04:54,  5.56s/it]Loading train:  83%|████████▎ | 259/311 [30:23<04:53,  5.65s/it]Loading train:  84%|████████▎ | 260/311 [30:28<04:46,  5.61s/it]Loading train:  84%|████████▍ | 261/311 [30:34<04:41,  5.64s/it]Loading train:  84%|████████▍ | 262/311 [30:40<04:38,  5.68s/it]Loading train:  85%|████████▍ | 263/311 [30:46<04:31,  5.67s/it]Loading train:  85%|████████▍ | 264/311 [30:51<04:19,  5.51s/it]Loading train:  85%|████████▌ | 265/311 [30:56<04:16,  5.57s/it]Loading train:  86%|████████▌ | 266/311 [31:02<04:08,  5.52s/it]Loading train:  86%|████████▌ | 267/311 [31:07<03:56,  5.39s/it]Loading train:  86%|████████▌ | 268/311 [31:13<03:55,  5.47s/it]Loading train:  86%|████████▋ | 269/311 [31:18<03:49,  5.47s/it]Loading train:  87%|████████▋ | 270/311 [31:23<03:41,  5.41s/it]Loading train:  87%|████████▋ | 271/311 [31:29<03:38,  5.47s/it]Loading train:  87%|████████▋ | 272/311 [31:34<03:34,  5.50s/it]Loading train:  88%|████████▊ | 273/311 [31:40<03:26,  5.42s/it]Loading train:  88%|████████▊ | 274/311 [31:45<03:23,  5.49s/it]Loading train:  88%|████████▊ | 275/311 [31:51<03:18,  5.50s/it]Loading train:  89%|████████▊ | 276/311 [31:56<03:07,  5.36s/it]Loading train:  89%|████████▉ | 277/311 [32:01<03:01,  5.35s/it]Loading train:  89%|████████▉ | 278/311 [32:07<02:59,  5.42s/it]Loading train:  90%|████████▉ | 279/311 [32:12<02:52,  5.38s/it]Loading train:  90%|█████████ | 280/311 [32:17<02:44,  5.31s/it]Loading train:  90%|█████████ | 281/311 [32:23<02:45,  5.51s/it]Loading train:  91%|█████████ | 282/311 [32:28<02:36,  5.40s/it]Loading train:  91%|█████████ | 283/311 [32:33<02:25,  5.20s/it]Loading train:  91%|█████████▏| 284/311 [32:38<02:20,  5.21s/it]Loading train:  92%|█████████▏| 285/311 [32:43<02:14,  5.16s/it]Loading train:  92%|█████████▏| 286/311 [32:48<02:04,  4.98s/it]Loading train:  92%|█████████▏| 287/311 [32:53<02:00,  5.02s/it]Loading train:  93%|█████████▎| 288/311 [32:58<01:55,  5.02s/it]Loading train:  93%|█████████▎| 289/311 [33:03<01:49,  4.96s/it]Loading train:  93%|█████████▎| 290/311 [33:08<01:45,  5.02s/it]Loading train:  94%|█████████▎| 291/311 [33:13<01:41,  5.08s/it]Loading train:  94%|█████████▍| 292/311 [33:18<01:34,  4.98s/it]Loading train:  94%|█████████▍| 293/311 [33:23<01:29,  4.97s/it]Loading train:  95%|█████████▍| 294/311 [33:28<01:25,  5.05s/it]Loading train:  95%|█████████▍| 295/311 [33:33<01:19,  4.96s/it]Loading train:  95%|█████████▌| 296/311 [33:38<01:13,  4.92s/it]Loading train:  95%|█████████▌| 297/311 [33:43<01:09,  4.95s/it]Loading train:  96%|█████████▌| 298/311 [33:48<01:04,  4.95s/it]Loading train:  96%|█████████▌| 299/311 [33:53<00:59,  4.97s/it]Loading train:  96%|█████████▋| 300/311 [33:58<00:54,  4.99s/it]Loading train:  97%|█████████▋| 301/311 [34:03<00:49,  4.92s/it]Loading train:  97%|█████████▋| 302/311 [34:07<00:43,  4.84s/it]Loading train:  97%|█████████▋| 303/311 [34:12<00:39,  4.91s/it]Loading train:  98%|█████████▊| 304/311 [34:18<00:35,  5.01s/it]Loading train:  98%|█████████▊| 305/311 [34:22<00:29,  4.98s/it]Loading train:  98%|█████████▊| 306/311 [34:28<00:25,  5.03s/it]Loading train:  99%|█████████▊| 307/311 [34:33<00:20,  5.14s/it]Loading train:  99%|█████████▉| 308/311 [34:38<00:15,  5.11s/it]Loading train:  99%|█████████▉| 309/311 [34:43<00:10,  5.04s/it]Loading train: 100%|█████████▉| 310/311 [34:48<00:05,  5.03s/it]Loading train: 100%|██████████| 311/311 [34:53<00:00,  4.98s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 22/311 [00:00<00:01, 217.23it/s]concatenating: train:  14%|█▍        | 44/311 [00:00<00:01, 217.03it/s]concatenating: train:  18%|█▊        | 57/311 [00:00<00:01, 180.19it/s]concatenating: train:  26%|██▋       | 82/311 [00:00<00:01, 195.09it/s]concatenating: train:  34%|███▍      | 105/311 [00:00<00:01, 204.12it/s]concatenating: train:  42%|████▏     | 130/311 [00:00<00:00, 213.97it/s]concatenating: train:  48%|████▊     | 150/311 [00:00<00:00, 192.40it/s]concatenating: train:  57%|█████▋    | 178/311 [00:00<00:00, 212.32it/s]concatenating: train:  65%|██████▍   | 201/311 [00:00<00:00, 214.83it/s]concatenating: train:  73%|███████▎  | 228/311 [00:01<00:00, 226.76it/s]concatenating: train:  81%|████████  | 251/311 [00:01<00:00, 225.18it/s]concatenating: train:  88%|████████▊ | 274/311 [00:01<00:00, 226.48it/s]concatenating: train:  98%|█████████▊| 304/311 [00:01<00:00, 243.60it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 225.89it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:12<00:36, 12.14s/it]Loading test:  50%|█████     | 2/4 [00:23<00:23, 11.82s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.86s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.85s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 75.74it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 30)   120         conv2d_7[0][0]                   2019-07-07 14:40:41.705769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 14:40:41.705876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 14:40:41.705904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 14:40:41.705916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 14:40:41.733027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 21s - loss: 10742.7608 - acc: 0.8540 - mDice: 0.2010 - val_loss: 8955.4724 - val_acc: 0.8971 - val_mDice: 0.3065

Epoch 00001: val_mDice improved from -inf to 0.30655, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 11s - loss: 4801.3338 - acc: 0.8958 - mDice: 0.4005 - val_loss: 4308.3741 - val_acc: 0.9135 - val_mDice: 0.4253

Epoch 00002: val_mDice improved from 0.30655 to 0.42531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 12s - loss: 3646.7141 - acc: 0.9109 - mDice: 0.4915 - val_loss: 2848.8421 - val_acc: 0.9247 - val_mDice: 0.5324

Epoch 00003: val_mDice improved from 0.42531 to 0.53235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 11s - loss: 3111.8797 - acc: 0.9192 - mDice: 0.5414 - val_loss: 2536.6556 - val_acc: 0.9266 - val_mDice: 0.5700

Epoch 00004: val_mDice improved from 0.53235 to 0.56995, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 12s - loss: 2772.3188 - acc: 0.9246 - mDice: 0.5765 - val_loss: 2324.3065 - val_acc: 0.9283 - val_mDice: 0.5956

Epoch 00005: val_mDice improved from 0.56995 to 0.59556, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 2531.4382 - acc: 0.9286 - mDice: 0.6033 - val_loss: 2255.6791 - val_acc: 0.9277 - val_mDice: 0.6018

Epoch 00006: val_mDice improved from 0.59556 to 0.60177, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 11s - loss: 2370.5198 - acc: 0.9312 - mDice: 0.6219 - val_loss: 2052.4361 - val_acc: 0.9343 - val_mDice: 0.6297

Epoch 00007: val_mDice improved from 0.60177 to 0.62968, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 12s - loss: 2241.2373 - acc: 0.9333 - mDice: 0.6377 - val_loss: 2161.4573 - val_acc: 0.9325 - val_mDice: 0.6133

Epoch 00008: val_mDice did not improve from 0.62968
Epoch 9/300
 - 11s - loss: 2125.5608 - acc: 0.9352 - mDice: 0.6516 - val_loss: 2172.7367 - val_acc: 0.9260 - val_mDice: 0.6098

Epoch 00009: val_mDice did not improve from 0.62968
Epoch 10/300
 - 11s - loss: 2053.2458 - acc: 0.9364 - mDice: 0.6612 - val_loss: 1820.6524 - val_acc: 0.9405 - val_mDice: 0.6603

Epoch 00010: val_mDice improved from 0.62968 to 0.66033, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 12s - loss: 1972.5656 - acc: 0.9379 - mDice: 0.6715 - val_loss: 1792.9113 - val_acc: 0.9436 - val_mDice: 0.6640

Epoch 00011: val_mDice improved from 0.66033 to 0.66401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 1912.2243 - acc: 0.9391 - mDice: 0.6796 - val_loss: 1862.7540 - val_acc: 0.9426 - val_mDice: 0.6565

Epoch 00012: val_mDice did not improve from 0.66401
Epoch 13/300
 - 12s - loss: 1867.9190 - acc: 0.9400 - mDice: 0.6855 - val_loss: 1814.2103 - val_acc: 0.9402 - val_mDice: 0.6611

Epoch 00013: val_mDice did not improve from 0.66401
Epoch 14/300
 - 11s - loss: 1811.9841 - acc: 0.9411 - mDice: 0.6931 - val_loss: 1880.2757 - val_acc: 0.9417 - val_mDice: 0.6539

Epoch 00014: val_mDice did not improve from 0.66401
Epoch 15/300
 - 11s - loss: 1787.4211 - acc: 0.9417 - mDice: 0.6966 - val_loss: 1797.6026 - val_acc: 0.9447 - val_mDice: 0.6656

Epoch 00015: val_mDice improved from 0.66401 to 0.66561, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 16/300
 - 12s - loss: 1732.8615 - acc: 0.9428 - mDice: 0.7041 - val_loss: 1824.1526 - val_acc: 0.9408 - val_mDice: 0.6619

Epoch 00016: val_mDice did not improve from 0.66561
Epoch 17/300
 - 11s - loss: 1697.5068 - acc: 0.9433 - mDice: 0.7089 - val_loss: 1784.8077 - val_acc: 0.9435 - val_mDice: 0.6676

Epoch 00017: val_mDice improved from 0.66561 to 0.66759, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 11s - loss: 1672.1949 - acc: 0.9439 - mDice: 0.7125 - val_loss: 1711.6737 - val_acc: 0.9484 - val_mDice: 0.6783

Epoch 00018: val_mDice improved from 0.66759 to 0.67832, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 12s - loss: 1638.0553 - acc: 0.9447 - mDice: 0.7174 - val_loss: 1711.9333 - val_acc: 0.9460 - val_mDice: 0.6785

Epoch 00019: val_mDice improved from 0.67832 to 0.67845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 11s - loss: 1606.3068 - acc: 0.9452 - mDice: 0.7219 - val_loss: 1736.9276 - val_acc: 0.9512 - val_mDice: 0.6749

Epoch 00020: val_mDice did not improve from 0.67845
Epoch 21/300
 - 12s - loss: 1580.8427 - acc: 0.9457 - mDice: 0.7256 - val_loss: 1722.4696 - val_acc: 0.9484 - val_mDice: 0.6733

Epoch 00021: val_mDice did not improve from 0.67845
Epoch 22/300
 - 11s - loss: 1557.8014 - acc: 0.9462 - mDice: 0.7289 - val_loss: 1673.8846 - val_acc: 0.9517 - val_mDice: 0.6836

Epoch 00022: val_mDice improved from 0.67845 to 0.68360, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 23/300
 - 11s - loss: 1541.9867 - acc: 0.9465 - mDice: 0.7313 - val_loss: 1640.4545 - val_acc: 0.9520 - val_mDice: 0.6890

Epoch 00023: val_mDice improved from 0.68360 to 0.68899, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 24/300
 - 12s - loss: 1507.9910 - acc: 0.9471 - mDice: 0.7361 - val_loss: 1629.4789 - val_acc: 0.9530 - val_mDice: 0.6917

Epoch 00024: val_mDice improved from 0.68899 to 0.69165, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 25/300
 - 11s - loss: 1493.4664 - acc: 0.9475 - mDice: 0.7383 - val_loss: 1772.9328 - val_acc: 0.9450 - val_mDice: 0.6710

Epoch 00025: val_mDice did not improve from 0.69165
Epoch 26/300
 - 12s - loss: 1474.6624 - acc: 0.9478 - mDice: 0.7410 - val_loss: 1703.8299 - val_acc: 0.9515 - val_mDice: 0.6817

Epoch 00026: val_mDice did not improve from 0.69165
Epoch 27/300
 - 12s - loss: 1456.0965 - acc: 0.9482 - mDice: 0.7438 - val_loss: 1595.9014 - val_acc: 0.9538 - val_mDice: 0.6978

Epoch 00027: val_mDice improved from 0.69165 to 0.69781, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 28/300
 - 12s - loss: 1437.3597 - acc: 0.9485 - mDice: 0.7467 - val_loss: 1752.9238 - val_acc: 0.9531 - val_mDice: 0.6749

Epoch 00028: val_mDice did not improve from 0.69781
Epoch 29/300
 - 12s - loss: 1420.0591 - acc: 0.9488 - mDice: 0.7491 - val_loss: 1672.0159 - val_acc: 0.9504 - val_mDice: 0.6841

Epoch 00029: val_mDice did not improve from 0.69781
Epoch 30/300
 - 11s - loss: 1395.5356 - acc: 0.9492 - mDice: 0.7527 - val_loss: 1701.2602 - val_acc: 0.9497 - val_mDice: 0.6791

Epoch 00030: val_mDice did not improve from 0.69781
Epoch 31/300
 - 12s - loss: 1388.7163 - acc: 0.9495 - mDice: 0.7540 - val_loss: 1637.9665 - val_acc: 0.9544 - val_mDice: 0.6923

Epoch 00031: val_mDice did not improve from 0.69781
Epoch 32/300
 - 12s - loss: 1373.0523 - acc: 0.9497 - mDice: 0.7563 - val_loss: 1596.1825 - val_acc: 0.9546 - val_mDice: 0.6976

Epoch 00032: val_mDice did not improve from 0.69781
Epoch 33/300
 - 12s - loss: 1357.3497 - acc: 0.9500 - mDice: 0.7586 - val_loss: 1706.3968 - val_acc: 0.9534 - val_mDice: 0.6825

Epoch 00033: val_mDice did not improve from 0.69781
Epoch 34/300
 - 12s - loss: 1346.0881 - acc: 0.9502 - mDice: 0.7603 - val_loss: 1619.9271 - val_acc: 0.9512 - val_mDice: 0.6923

Epoch 00034: val_mDice did not improve from 0.69781
Epoch 35/300
 - 11s - loss: 1333.6314 - acc: 0.9505 - mDice: 0.7629 - val_loss: 1646.3132 - val_acc: 0.9507 - val_mDice: 0.6894

Epoch 00035: val_mDice did not improve from 0.69781
Epoch 36/300
 - 12s - loss: 1323.4617 - acc: 0.9507 - mDice: 0.7638 - val_loss: 1696.7786 - val_acc: 0.9530 - val_mDice: 0.6833

Epoch 00036: val_mDice did not improve from 0.69781
Epoch 37/300
 - 11s - loss: 1310.4510 - acc: 0.9509 - mDice: 0.7657 - val_loss: 1751.3047 - val_acc: 0.9540 - val_mDice: 0.6762

Epoch 00037: val_mDice did not improve from 0.69781
Epoch 38/300
 - 12s - loss: 1294.7279 - acc: 0.9511 - mDice: 0.7682 - val_loss: 1627.6162 - val_acc: 0.9496 - val_mDice: 0.6933

Epoch 00038: val_mDice did not improve from 0.69781
Epoch 39/300
 - 12s - loss: 1286.9875 - acc: 0.9513 - mDice: 0.7694 - val_loss: 1655.5127 - val_acc: 0.9536 - val_mDice: 0.6893

Epoch 00039: val_mDice did not improve from 0.69781
Epoch 40/300
 - 12s - loss: 1280.0091 - acc: 0.9515 - mDice: 0.7705 - val_loss: 1630.0425 - val_acc: 0.9520 - val_mDice: 0.6932

Epoch 00040: val_mDice did not improve from 0.69781
Epoch 41/300
 - 12s - loss: 1267.9461 - acc: 0.9516 - mDice: 0.7722 - val_loss: 1652.2985 - val_acc: 0.9532 - val_mDice: 0.6888

Epoch 00041: val_mDice did not improve from 0.69781
Epoch 42/300
 - 11s - loss: 1254.7695 - acc: 0.9519 - mDice: 0.7743 - val_loss: 1631.9387 - val_acc: 0.9530 - val_mDice: 0.6928

Epoch 00042: val_mDice did not improve from 0.69781
Epoch 43/300
 - 12s - loss: 1243.6065 - acc: 0.9521 - mDice: 0.7761 - val_loss: 1717.7797 - val_acc: 0.9534 - val_mDice: 0.6808

Epoch 00043: val_mDice did not improve from 0.69781
Epoch 44/300
 - 11s - loss: 1239.2516 - acc: 0.9522 - mDice: 0.7768 - val_loss: 1647.4586 - val_acc: 0.9545 - val_mDice: 0.6906

Epoch 00044: val_mDice did not improve from 0.69781
Epoch 45/300
 - 12s - loss: 1230.5747 - acc: 0.9523 - mDice: 0.7781 - val_loss: 1654.0555 - val_acc: 0.9513 - val_mDice: 0.6893

Epoch 00045: val_mDice did not improve from 0.69781
Epoch 46/300
 - 12s - loss: 1220.5808 - acc: 0.9525 - mDice: 0.7796 - val_loss: 1773.7372 - val_acc: 0.9453 - val_mDice: 0.6694

Epoch 00046: val_mDice did not improve from 0.69781
Epoch 47/300
 - 11s - loss: 1216.7535 - acc: 0.9527 - mDice: 0.7803 - val_loss: 1592.1089 - val_acc: 0.9542 - val_mDice: 0.6989

Epoch 00047: val_mDice improved from 0.69781 to 0.69889, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 48/300
 - 12s - loss: 1198.1332 - acc: 0.9529 - mDice: 0.7832 - val_loss: 1672.2922 - val_acc: 0.9560 - val_mDice: 0.6874

Epoch 00048: val_mDice did not improve from 0.69889
Epoch 49/300
 - 11s - loss: 1197.0935 - acc: 0.9529 - mDice: 0.7833 - val_loss: 1650.1322 - val_acc: 0.9532 - val_mDice: 0.6907

Epoch 00049: val_mDice did not improve from 0.69889
Epoch 50/300
 - 12s - loss: 1194.9374 - acc: 0.9530 - mDice: 0.7838 - val_loss: 1648.8271 - val_acc: 0.9553 - val_mDice: 0.6906

Epoch 00050: val_mDice did not improve from 0.69889
Epoch 51/300
 - 12s - loss: 1181.3626 - acc: 0.9532 - mDice: 0.7857 - val_loss: 1644.3679 - val_acc: 0.9549 - val_mDice: 0.6904

Epoch 00051: val_mDice did not improve from 0.69889
Epoch 52/300
 - 11s - loss: 1170.4472 - acc: 0.9534 - mDice: 0.7876 - val_loss: 1649.9967 - val_acc: 0.9549 - val_mDice: 0.6934

Epoch 00052: val_mDice did not improve from 0.69889
Epoch 53/300
 - 12s - loss: 1165.1618 - acc: 0.9535 - mDice: 0.7884 - val_loss: 1713.6153 - val_acc: 0.9552 - val_mDice: 0.6824

Epoch 00053: val_mDice did not improve from 0.69889
Epoch 54/300
 - 11s - loss: 1158.0646 - acc: 0.9535 - mDice: 0.7895 - val_loss: 1600.2527 - val_acc: 0.9563 - val_mDice: 0.6980

Epoch 00054: val_mDice did not improve from 0.69889
Epoch 55/300
 - 12s - loss: 1149.3208 - acc: 0.9537 - mDice: 0.7909 - val_loss: 1548.4486 - val_acc: 0.9554 - val_mDice: 0.7059

Epoch 00055: val_mDice improved from 0.69889 to 0.70587, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 56/300
 - 11s - loss: 1144.8830 - acc: 0.9538 - mDice: 0.7916 - val_loss: 1709.0290 - val_acc: 0.9564 - val_mDice: 0.6834

Epoch 00056: val_mDice did not improve from 0.70587
Epoch 57/300
 - 12s - loss: 1134.0599 - acc: 0.9540 - mDice: 0.7933 - val_loss: 1604.6453 - val_acc: 0.9553 - val_mDice: 0.6979

Epoch 00057: val_mDice did not improve from 0.70587
Epoch 58/300
 - 12s - loss: 1128.8661 - acc: 0.9540 - mDice: 0.7941 - val_loss: 1662.3492 - val_acc: 0.9528 - val_mDice: 0.6893

Epoch 00058: val_mDice did not improve from 0.70587
Epoch 59/300
 - 12s - loss: 1125.6379 - acc: 0.9541 - mDice: 0.7947 - val_loss: 1708.3369 - val_acc: 0.9522 - val_mDice: 0.6811

Epoch 00059: val_mDice did not improve from 0.70587
Epoch 60/300
 - 12s - loss: 1121.2387 - acc: 0.9542 - mDice: 0.7954 - val_loss: 1673.5994 - val_acc: 0.9538 - val_mDice: 0.6886

Epoch 00060: val_mDice did not improve from 0.70587
Epoch 61/300
 - 11s - loss: 1116.2191 - acc: 0.9542 - mDice: 0.7962 - val_loss: 1674.3357 - val_acc: 0.9546 - val_mDice: 0.6873

Epoch 00061: val_mDice did not improve from 0.70587
Epoch 62/300
 - 13s - loss: 1106.7267 - acc: 0.9546 - mDice: 0.7977 - val_loss: 1775.0423 - val_acc: 0.9484 - val_mDice: 0.6720

Epoch 00062: val_mDice did not improve from 0.70587
Epoch 63/300
 - 12s - loss: 1105.5569 - acc: 0.9545 - mDice: 0.7978 - val_loss: 1732.6457 - val_acc: 0.9476 - val_mDice: 0.6788

Epoch 00063: val_mDice did not improve from 0.70587
Epoch 64/300
 - 11s - loss: 1098.1208 - acc: 0.9547 - mDice: 0.7991 - val_loss: 1845.8646 - val_acc: 0.9447 - val_mDice: 0.6579

Epoch 00064: val_mDice did not improve from 0.70587
Epoch 65/300
 - 13s - loss: 1084.1007 - acc: 0.9549 - mDice: 0.8014 - val_loss: 1805.2466 - val_acc: 0.9525 - val_mDice: 0.6703

Epoch 00065: val_mDice did not improve from 0.70587
Epoch 66/300
 - 11s - loss: 1092.6540 - acc: 0.9547 - mDice: 0.8000 - val_loss: 1665.4839 - val_acc: 0.9547 - val_mDice: 0.6905

Epoch 00066: val_mDice did not improve from 0.70587
Epoch 67/300
 - 12s - loss: 1078.7063 - acc: 0.9549 - mDice: 0.8022 - val_loss: 1650.9091 - val_acc: 0.9555 - val_mDice: 0.6901

Epoch 00067: val_mDice did not improve from 0.70587
Epoch 68/300
 - 12s - loss: 1076.4947 - acc: 0.9550 - mDice: 0.8026 - val_loss: 1754.8898 - val_acc: 0.9509 - val_mDice: 0.6778

Epoch 00068: val_mDice did not improve from 0.70587
Epoch 69/300
 - 11s - loss: 1069.7570 - acc: 0.9550 - mDice: 0.8037 - val_loss: 1727.3093 - val_acc: 0.9566 - val_mDice: 0.6806

Epoch 00069: val_mDice did not improve from 0.70587
Epoch 70/300
 - 12s - loss: 1063.7263 - acc: 0.9551 - mDice: 0.8046 - val_loss: 1638.1139 - val_acc: 0.9546 - val_mDice: 0.6937

Epoch 00070: val_mDice did not improve from 0.70587
Epoch 71/300
 - 11s - loss: 1059.7630 - acc: 0.9552 - mDice: 0.8053 - val_loss: 1759.3722 - val_acc: 0.9517 - val_mDice: 0.6796

Epoch 00071: val_mDice did not improve from 0.70587
Epoch 72/300
 - 12s - loss: 1062.1613 - acc: 0.9551 - mDice: 0.8049 - val_loss: 1623.6496 - val_acc: 0.9565 - val_mDice: 0.6961

Epoch 00072: val_mDice did not improve from 0.70587
Epoch 73/300
 - 12s - loss: 1046.8097 - acc: 0.9555 - mDice: 0.8074 - val_loss: 1763.2764 - val_acc: 0.9519 - val_mDice: 0.6769

Epoch 00073: val_mDice did not improve from 0.70587
Epoch 74/300
 - 11s - loss: 1046.1508 - acc: 0.9555 - mDice: 0.8075 - val_loss: 1643.5563 - val_acc: 0.9524 - val_mDice: 0.6910

Epoch 00074: val_mDice did not improve from 0.70587
Epoch 75/300
 - 13s - loss: 1045.5289 - acc: 0.9556 - mDice: 0.8076 - val_loss: 1793.4021 - val_acc: 0.9534 - val_mDice: 0.6742

Epoch 00075: val_mDice did not improve from 0.70587
Epoch 76/300
 - 11s - loss: 1033.2498 - acc: 0.9557 - mDice: 0.8096 - val_loss: 1662.1125 - val_acc: 0.9566 - val_mDice: 0.6903

Epoch 00076: val_mDice did not improve from 0.70587
Epoch 77/300
 - 12s - loss: 1029.8178 - acc: 0.9558 - mDice: 0.8102 - val_loss: 1648.7044 - val_acc: 0.9527 - val_mDice: 0.6901

Epoch 00077: val_mDice did not improve from 0.70587
Epoch 78/300
 - 12s - loss: 1031.7474 - acc: 0.9557 - mDice: 0.8099 - val_loss: 1685.4276 - val_acc: 0.9552 - val_mDice: 0.6873

Epoch 00078: val_mDice did not improve from 0.70587
Epoch 79/300
 - 11s - loss: 1025.6755 - acc: 0.9558 - mDice: 0.8109 - val_loss: 1714.5741 - val_acc: 0.9542 - val_mDice: 0.6841

Epoch 00079: val_mDice did not improve from 0.70587
Epoch 80/300
 - 12s - loss: 1024.4081 - acc: 0.9558 - mDice: 0.8111 - val_loss: 1674.4805 - val_acc: 0.9550 - val_mDice: 0.6886

Epoch 00080: val_mDice did not improve from 0.70587
Epoch 81/300
 - 12s - loss: 1019.1856 - acc: 0.9560 - mDice: 0.8119 - val_loss: 1626.9453 - val_acc: 0.9550 - val_mDice: 0.6951

Epoch 00081: val_mDice did not improve from 0.70587
Epoch 82/300
 - 12s - loss: 1014.5527 - acc: 0.9560 - mDice: 0.8127 - val_loss: 1658.6763 - val_acc: 0.9575 - val_mDice: 0.6902

Epoch 00082: val_mDice did not improve from 0.70587
Epoch 83/300
 - 12s - loss: 1013.7386 - acc: 0.9560 - mDice: 0.8129 - val_loss: 1577.2133 - val_acc: 0.9563 - val_mDice: 0.7018

Epoch 00083: val_mDice did not improve from 0.70587
Epoch 84/300
 - 12s - loss: 1012.7580 - acc: 0.9560 - mDice: 0.8130 - val_loss: 1767.5778 - val_acc: 0.9561 - val_mDice: 0.6748

Epoch 00084: val_mDice did not improve from 0.70587
Epoch 85/300
 - 13s - loss: 1003.6411 - acc: 0.9562 - mDice: 0.8145 - val_loss: 1610.8454 - val_acc: 0.9571 - val_mDice: 0.6979

Epoch 00085: val_mDice did not improve from 0.70587
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
{'val_loss': [8955.472423735118, 4308.374104817708, 2848.842110770089, 2536.6555902390255, 2324.3065476190477, 2255.6790713355654, 2052.4360555013022, 2161.4573364257812, 2172.7366710844494, 1820.6524222237724, 1792.9112897600446, 1862.7540399460565, 1814.2103097098213, 1880.2756958007812, 1797.6026407877605, 1824.152611142113, 1784.80766078404, 1711.6737089611236, 1711.9332798549108, 1736.9275570824034, 1722.4695521763392, 1673.8845592680432, 1640.4545375279017, 1629.4789196196057, 1772.932829357329, 1703.8299182710193, 1595.901375906808, 1752.9237583705358, 1672.015869140625, 1701.260221935454, 1637.9665352957588, 1596.1824922107514, 1706.396760486421, 1619.9271065848213, 1646.3132033575148, 1696.778564453125, 1751.3046816871279, 1627.6162051246279, 1655.512663341704, 1630.0425356910341, 1652.2985229492188, 1631.9386596679688, 1717.7796514601935, 1647.4585774739583, 1654.0555216471355, 1773.7372349330358, 1592.1089274088542, 1672.2921578543526, 1650.1322428385417, 1648.8270670572917, 1644.3678937639509, 1649.9967273530506, 1713.615266345796, 1600.252673921131, 1548.4486316499256, 1709.0289539155506, 1604.6453421456474, 1662.34916469029, 1708.336890811012, 1673.599350702195, 1674.3356875465029, 1775.0423031761534, 1732.6457141694568, 1845.8645775204614, 1805.2465762183779, 1665.48390125093, 1650.9090954008557, 1754.8897617885045, 1727.3092767624628, 1638.1138945079986, 1759.3721545991443, 1623.6495739164807, 1763.2764282226562, 1643.5563412620909, 1793.402108328683, 1662.112534295945, 1648.7044067382812, 1685.4276384626116, 1714.5741141183037, 1674.4804745628721, 1626.9453125, 1658.6763160342261, 1577.2133033389136, 1767.5777529761904, 1610.8453543526787], 'val_acc': [0.89707531389736, 0.9134787008875892, 0.9247424290293739, 0.9266011218229929, 0.9283167265710377, 0.9276971831208184, 0.9342648230847859, 0.932474801937739, 0.925960103670756, 0.9404919374556768, 0.9435897299221584, 0.94256382612955, 0.940179990870612, 0.941683848698934, 0.9446986658232552, 0.940821050178437, 0.9435425287201291, 0.9484360842477708, 0.9460036087603796, 0.951217688265301, 0.9484460949897766, 0.9516626752558208, 0.9520447041307177, 0.9529647713615781, 0.944957645166488, 0.9515267014503479, 0.9537688805943444, 0.9530792335669199, 0.9503519918237414, 0.9496766201087407, 0.9544256471452259, 0.9545515662147885, 0.9533739941460746, 0.9511547145389375, 0.950701138802937, 0.9529890829608554, 0.9539691961946941, 0.9496494389715648, 0.9535671273867289, 0.9519774459657215, 0.9532208655561719, 0.953047731092998, 0.9534054512069339, 0.9545172424543471, 0.951329258226213, 0.9453496961366563, 0.9542253329640343, 0.9560310798031944, 0.9532237095492226, 0.9552770242804572, 0.9549150083746228, 0.9548978209495544, 0.9552226307846251, 0.9563329702331906, 0.9553599939459846, 0.9563587620144799, 0.9552841725803557, 0.9528345252786364, 0.9522493041697002, 0.9537731934161413, 0.9545858999093374, 0.9484274884064993, 0.9476261933644613, 0.9446514561062768, 0.9524739654291243, 0.9546631546247573, 0.9554858988239652, 0.9509400782131013, 0.956583382118316, 0.9545844665595463, 0.9516669682094029, 0.9565433207012358, 0.9518658547174363, 0.9524396246387845, 0.9533696784859612, 0.9565690826802027, 0.9526814222335815, 0.9552011830466134, 0.9542210343338194, 0.9550280528409141, 0.9550480700674511, 0.9575234836056119, 0.9563487072785696, 0.9561369660354796, 0.9571113969598498], 'val_mDice': [0.3065478170201892, 0.4253060207480476, 0.532354671330679, 0.5699538162776402, 0.5955641127768017, 0.6017705485934303, 0.6296788780462175, 0.613310843706131, 0.609760263136455, 0.6603341996669769, 0.6640140698069618, 0.6565113195351192, 0.6610963855470929, 0.6539206036499569, 0.665610154469808, 0.6618636931691851, 0.6675919393698374, 0.6783163845539093, 0.6784538882119315, 0.6748719158626738, 0.673277660494759, 0.6836002071698507, 0.6889905943757012, 0.6916533084142775, 0.6710215665045238, 0.6816561945847103, 0.6978080528123038, 0.6748634860629127, 0.6840757954688299, 0.679077760094688, 0.6922808729466938, 0.6976112169878823, 0.6825470796653202, 0.6922671227228074, 0.6893828724111829, 0.683341037659418, 0.6761503020922343, 0.6932875897203173, 0.6892591970307487, 0.6931995167618706, 0.6888295298530942, 0.6928065248898098, 0.6808358161222368, 0.6905915254638308, 0.6893292963504791, 0.669422237646012, 0.6988944141637712, 0.6874481581506275, 0.690712686095919, 0.6906397740046183, 0.6903993714423406, 0.6933507365839822, 0.6823542302563077, 0.6980370496000562, 0.7058691410791307, 0.6834417581558228, 0.6978895224276043, 0.6892685123852321, 0.6810781090032487, 0.6886442715213412, 0.6873223228113992, 0.6720470998968396, 0.6787571736744472, 0.6578973886512575, 0.6703445911407471, 0.6904576477550325, 0.6901141149657113, 0.6777714576039996, 0.6806231779711587, 0.6936664879322052, 0.6796331221149081, 0.6961444715658823, 0.6769191367285592, 0.6909634854112353, 0.6741725021884555, 0.690299989212127, 0.6900999333177295, 0.687344335374378, 0.6841470216001783, 0.6885823422954196, 0.6951295676685515, 0.6902305086453756, 0.7018203706968398, 0.6748079983961015, 0.697932759920756], 'loss': [10742.760845688514, 4801.333751802135, 3646.7141315717054, 3111.8797191134713, 2772.318829771884, 2531.438205785585, 2370.5197970040717, 2241.2373483710157, 2125.560814950234, 2053.2457624326025, 1972.5655755782664, 1912.2243266498062, 1867.9190289885028, 1811.9840526247856, 1787.4210849676347, 1732.8615342518337, 1697.5067630682206, 1672.1948660757773, 1638.0553023797318, 1606.3067792478641, 1580.8426622500147, 1557.8014095239805, 1541.9867219235236, 1507.9909985321121, 1493.4663792560225, 1474.6624479602995, 1456.0964575027883, 1437.359682877462, 1420.0590560418411, 1395.5355625295283, 1388.7162546362365, 1373.0522989858118, 1357.349657624737, 1346.0881150547702, 1333.631383767449, 1323.4617292827502, 1310.4509828334437, 1294.7279187818417, 1286.9875277474039, 1280.0090970921694, 1267.9461436664078, 1254.7694930078978, 1243.606536751079, 1239.2516397300205, 1230.5746740022503, 1220.580786764473, 1216.7535212034002, 1198.1331593425493, 1197.0935094743002, 1194.937419976974, 1181.362591027619, 1170.4471790951088, 1165.1617994046865, 1158.0645960096706, 1149.3207577446155, 1144.883048155064, 1134.0598976725057, 1128.866078098516, 1125.6378716447407, 1121.2386646032928, 1116.2191443502754, 1106.7266515413128, 1105.5568909490496, 1098.1207699097897, 1084.1006791074376, 1092.6539953902475, 1078.70626176563, 1076.494684690252, 1069.7569722582277, 1063.7263168373013, 1059.7630175355068, 1062.1612605144853, 1046.8096623028305, 1046.1507906259742, 1045.528865557359, 1033.24981573395, 1029.817750811874, 1031.7474113140916, 1025.6754781290183, 1024.4081407770552, 1019.1856197062276, 1014.5527009084041, 1013.7386173809556, 1012.7579683032714, 1003.6411107127506], 'acc': [0.854013854428717, 0.8958337909339966, 0.9109447864337158, 0.9192003080449497, 0.9245840482358029, 0.9285657726729897, 0.9311855984782043, 0.9333164237829813, 0.9352150912816982, 0.9364400006217553, 0.937942886107283, 0.9390762726453474, 0.9400083210105611, 0.9410626268817897, 0.9417451527016121, 0.9427998135066092, 0.9433360145127684, 0.9439245756724826, 0.9446823730172956, 0.9451865574851298, 0.9457340731547955, 0.9461808024053264, 0.9465175688712674, 0.9470665477903704, 0.9475412271229406, 0.9478210634795805, 0.9482466275443757, 0.9484982709783568, 0.9487778435918756, 0.949242127692313, 0.9494943713160822, 0.9497025889946041, 0.9499891706349843, 0.9501719861256511, 0.9505404515791118, 0.9507236448569488, 0.9508905030433971, 0.9511497131644044, 0.9512710111434025, 0.9514714579406819, 0.9515935220474614, 0.9519035576882208, 0.9520622822003174, 0.9522108368185392, 0.9523259730559037, 0.9525031162764961, 0.9526721239461566, 0.952906534503077, 0.9528716712855638, 0.9529511550083719, 0.9532164538887671, 0.9533531285469371, 0.9534811762874561, 0.9535317934696513, 0.9536718604273332, 0.9538338473275713, 0.954003868276193, 0.954012467918402, 0.9541304300253528, 0.9541772436211234, 0.9542379954880907, 0.9545764298436054, 0.9544734912471581, 0.9546574510801166, 0.9548697358838043, 0.9547386040674184, 0.9549457206764721, 0.954958438780391, 0.9550049694584789, 0.9550645804204548, 0.9552152703267678, 0.955132881918007, 0.9555065888642076, 0.9555043205433058, 0.9555856604268426, 0.9557159709885827, 0.9557628436315981, 0.9557337323366258, 0.9558291173635278, 0.9557936188586038, 0.9559524414359483, 0.9560226154817905, 0.9560204624869579, 0.9559627438238136, 0.9561714519214749], 'mDice': [0.20103963174882747, 0.4005141644517977, 0.4914515696354489, 0.5413657333097999, 0.5764833305802132, 0.6032955993775121, 0.621926761810619, 0.6377288645082281, 0.6516138618612229, 0.6612498709499984, 0.6714691032569604, 0.6795591197146145, 0.6854627430253195, 0.6930571464900661, 0.696550789579489, 0.7041050756810014, 0.7088529505857506, 0.7124838652716313, 0.7173689742783953, 0.7218939923214496, 0.7255743319294102, 0.7289027969847593, 0.7312685059490347, 0.7361060437604674, 0.7383151695763975, 0.741004766650182, 0.7438238005982968, 0.7466700188351094, 0.7491492795342222, 0.7527487116524406, 0.7539822335849676, 0.7562622883150405, 0.7586452680409995, 0.7602743135203149, 0.762866734250674, 0.7637666061223296, 0.7657425576388984, 0.7681608156224439, 0.769394314218489, 0.7705025838832011, 0.7722166835927309, 0.7743033732559318, 0.7760740805630969, 0.7767778619417823, 0.778082387814498, 0.7796244471707844, 0.7802888089024516, 0.7832305057164737, 0.7833159610703402, 0.7837676205428461, 0.7857430997000371, 0.7875791881744404, 0.7884012964040858, 0.7895445931990842, 0.7908513337522374, 0.7915727959346592, 0.7933465192963061, 0.794123749873436, 0.7946932533584034, 0.7953621696987354, 0.7962064662962186, 0.7977007255701353, 0.7978498546262631, 0.7990733567541675, 0.8013657319947074, 0.7999987623786688, 0.8021880727159115, 0.802597976199112, 0.8036796677476747, 0.8046384866063732, 0.805292597639739, 0.804927996603628, 0.8073531567047064, 0.8075426218850059, 0.8075816685942343, 0.8095946344837286, 0.8102478410797821, 0.809915729535934, 0.8108504591440024, 0.8111009477937311, 0.8118778391000339, 0.8126903228517482, 0.812860582107469, 0.8129902006013138, 0.8145028576812244]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:16<00:49, 16.42s/it]predicting test subjects:  50%|█████     | 2/4 [00:34<00:33, 16.96s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:53<00:17, 17.55s/it]predicting test subjects: 100%|██████████| 4/4 [01:12<00:00, 17.89s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:28<2:24:45, 28.02s/it]predicting train subjects:   1%|          | 2/311 [00:40<2:00:25, 23.38s/it]predicting train subjects:   1%|          | 3/311 [00:56<1:48:21, 21.11s/it]predicting train subjects:   1%|▏         | 4/311 [01:11<1:38:23, 19.23s/it]predicting train subjects:   2%|▏         | 5/311 [01:25<1:29:58, 17.64s/it]predicting train subjects:   2%|▏         | 6/311 [01:39<1:25:05, 16.74s/it]predicting train subjects:   2%|▏         | 7/311 [01:55<1:22:43, 16.33s/it]predicting train subjects:   3%|▎         | 8/311 [02:15<1:28:16, 17.48s/it]predicting train subjects:   3%|▎         | 9/311 [02:32<1:26:51, 17.26s/it]predicting train subjects:   3%|▎         | 10/311 [02:46<1:22:18, 16.41s/it]predicting train subjects:   4%|▎         | 11/311 [03:05<1:25:39, 17.13s/it]predicting train subjects:   4%|▍         | 12/311 [03:19<1:20:44, 16.20s/it]predicting train subjects:   4%|▍         | 13/311 [03:32<1:16:07, 15.33s/it]predicting train subjects:   5%|▍         | 14/311 [03:51<1:20:54, 16.34s/it]predicting train subjects:   5%|▍         | 15/311 [04:18<1:36:33, 19.57s/it]predicting train subjects:   5%|▌         | 16/311 [04:43<1:43:58, 21.15s/it]predicting train subjects:   5%|▌         | 17/311 [05:09<1:50:54, 22.64s/it]predicting train subjects:   6%|▌         | 18/311 [05:36<1:57:08, 23.99s/it]predicting train subjects:   6%|▌         | 19/311 [06:04<2:01:54, 25.05s/it]predicting train subjects:   6%|▋         | 20/311 [06:30<2:04:03, 25.58s/it]predicting train subjects:   7%|▋         | 21/311 [06:55<2:02:24, 25.33s/it]predicting train subjects:   7%|▋         | 22/311 [07:17<1:57:05, 24.31s/it]predicting train subjects:   7%|▋         | 23/311 [07:39<1:53:27, 23.64s/it]predicting train subjects:   8%|▊         | 24/311 [08:02<1:52:02, 23.42s/it]predicting train subjects:   8%|▊         | 25/311 [08:25<1:51:15, 23.34s/it]predicting train subjects:   8%|▊         | 26/311 [08:48<1:50:06, 23.18s/it]predicting train subjects:   9%|▊         | 27/311 [09:10<1:47:40, 22.75s/it]predicting train subjects:   9%|▉         | 28/311 [09:32<1:47:09, 22.72s/it]predicting train subjects:   9%|▉         | 29/311 [09:54<1:45:12, 22.38s/it]predicting train subjects:  10%|▉         | 30/311 [10:16<1:45:00, 22.42s/it]predicting train subjects:  10%|▉         | 31/311 [10:39<1:44:15, 22.34s/it]predicting train subjects:  10%|█         | 32/311 [11:00<1:42:50, 22.12s/it]predicting train subjects:  11%|█         | 33/311 [11:11<1:26:17, 18.63s/it]predicting train subjects:  11%|█         | 34/311 [11:21<1:14:49, 16.21s/it]predicting train subjects:  11%|█▏        | 35/311 [11:31<1:05:50, 14.31s/it]predicting train subjects:  12%|█▏        | 36/311 [11:41<1:00:01, 13.10s/it]predicting train subjects:  12%|█▏        | 37/311 [11:52<56:14, 12.32s/it]  predicting train subjects:  12%|█▏        | 38/311 [12:02<53:37, 11.78s/it]predicting train subjects:  13%|█▎        | 39/311 [12:12<50:55, 11.23s/it]predicting train subjects:  13%|█▎        | 40/311 [12:23<49:27, 10.95s/it]predicting train subjects:  13%|█▎        | 41/311 [12:33<48:42, 10.82s/it]predicting train subjects:  14%|█▎        | 42/311 [12:43<47:25, 10.58s/it]predicting train subjects:  14%|█▍        | 43/311 [12:54<46:48, 10.48s/it]predicting train subjects:  14%|█▍        | 44/311 [13:04<46:36, 10.47s/it]predicting train subjects:  14%|█▍        | 45/311 [13:14<45:48, 10.33s/it]predicting train subjects:  15%|█▍        | 46/311 [13:25<45:56, 10.40s/it]predicting train subjects:  15%|█▌        | 47/311 [13:35<45:58, 10.45s/it]predicting train subjects:  15%|█▌        | 48/311 [13:46<46:00, 10.49s/it]predicting train subjects:  16%|█▌        | 49/311 [13:56<45:17, 10.37s/it]predicting train subjects:  16%|█▌        | 50/311 [14:06<45:13, 10.40s/it]predicting train subjects:  16%|█▋        | 51/311 [14:19<48:43, 11.25s/it]predicting train subjects:  17%|█▋        | 52/311 [14:33<51:08, 11.85s/it]predicting train subjects:  17%|█▋        | 53/311 [14:46<52:44, 12.26s/it]predicting train subjects:  17%|█▋        | 54/311 [14:59<53:52, 12.58s/it]predicting train subjects:  18%|█▊        | 55/311 [15:12<53:56, 12.64s/it]predicting train subjects:  18%|█▊        | 56/311 [15:25<54:18, 12.78s/it]predicting train subjects:  18%|█▊        | 57/311 [15:38<54:37, 12.90s/it]predicting train subjects:  19%|█▊        | 58/311 [15:52<54:59, 13.04s/it]predicting train subjects:  19%|█▉        | 59/311 [16:05<55:07, 13.12s/it]predicting train subjects:  19%|█▉        | 60/311 [16:18<54:53, 13.12s/it]predicting train subjects:  20%|█▉        | 61/311 [16:31<54:50, 13.16s/it]predicting train subjects:  20%|█▉        | 62/311 [16:45<55:43, 13.43s/it]predicting train subjects:  20%|██        | 63/311 [16:59<55:14, 13.36s/it]predicting train subjects:  21%|██        | 64/311 [17:12<54:55, 13.34s/it]predicting train subjects:  21%|██        | 65/311 [17:25<54:31, 13.30s/it]predicting train subjects:  21%|██        | 66/311 [17:38<54:09, 13.26s/it]predicting train subjects:  22%|██▏       | 67/311 [17:51<53:13, 13.09s/it]predicting train subjects:  22%|██▏       | 68/311 [18:03<52:11, 12.89s/it]predicting train subjects:  22%|██▏       | 69/311 [18:16<51:30, 12.77s/it]predicting train subjects:  23%|██▎       | 70/311 [18:29<51:07, 12.73s/it]predicting train subjects:  23%|██▎       | 71/311 [18:42<51:17, 12.82s/it]predicting train subjects:  23%|██▎       | 72/311 [18:55<51:38, 12.97s/it]predicting train subjects:  23%|██▎       | 73/311 [19:08<51:13, 12.92s/it]predicting train subjects:  24%|██▍       | 74/311 [19:21<50:58, 12.91s/it]predicting train subjects:  24%|██▍       | 75/311 [19:33<50:23, 12.81s/it]predicting train subjects:  24%|██▍       | 76/311 [19:46<49:48, 12.72s/it]predicting train subjects:  25%|██▍       | 77/311 [19:58<49:40, 12.74s/it]predicting train subjects:  25%|██▌       | 78/311 [20:11<49:31, 12.75s/it]predicting train subjects:  25%|██▌       | 79/311 [20:24<49:19, 12.76s/it]predicting train subjects:  26%|██▌       | 80/311 [20:37<49:21, 12.82s/it]predicting train subjects:  26%|██▌       | 81/311 [20:50<49:12, 12.84s/it]predicting train subjects:  26%|██▋       | 82/311 [21:03<49:29, 12.97s/it]predicting train subjects:  27%|██▋       | 83/311 [21:17<49:46, 13.10s/it]predicting train subjects:  27%|██▋       | 84/311 [21:30<49:28, 13.08s/it]predicting train subjects:  27%|██▋       | 85/311 [21:41<47:21, 12.57s/it]predicting train subjects:  28%|██▊       | 86/311 [21:52<45:51, 12.23s/it]predicting train subjects:  28%|██▊       | 87/311 [22:04<44:59, 12.05s/it]predicting train subjects:  28%|██▊       | 88/311 [22:16<44:27, 11.96s/it]predicting train subjects:  29%|██▊       | 89/311 [22:28<44:13, 11.95s/it]predicting train subjects:  29%|██▉       | 90/311 [22:40<43:59, 11.95s/it]predicting train subjects:  29%|██▉       | 91/311 [22:51<43:21, 11.83s/it]predicting train subjects:  30%|██▉       | 92/311 [23:03<43:22, 11.88s/it]predicting train subjects:  30%|██▉       | 93/311 [23:15<43:07, 11.87s/it]predicting train subjects:  30%|███       | 94/311 [23:27<42:50, 11.84s/it]predicting train subjects:  31%|███       | 95/311 [23:39<42:31, 11.81s/it]predicting train subjects:  31%|███       | 96/311 [23:50<42:14, 11.79s/it]predicting train subjects:  31%|███       | 97/311 [24:02<41:57, 11.76s/it]predicting train subjects:  32%|███▏      | 98/311 [24:14<41:36, 11.72s/it]predicting train subjects:  32%|███▏      | 99/311 [24:26<41:38, 11.78s/it]predicting train subjects:  32%|███▏      | 100/311 [24:37<41:31, 11.81s/it]predicting train subjects:  32%|███▏      | 101/311 [24:49<41:05, 11.74s/it]predicting train subjects:  33%|███▎      | 102/311 [25:01<40:41, 11.68s/it]predicting train subjects:  33%|███▎      | 103/311 [25:12<40:42, 11.74s/it]predicting train subjects:  33%|███▎      | 104/311 [25:24<40:46, 11.82s/it]predicting train subjects:  34%|███▍      | 105/311 [25:36<40:40, 11.85s/it]predicting train subjects:  34%|███▍      | 106/311 [25:48<40:08, 11.75s/it]predicting train subjects:  34%|███▍      | 107/311 [25:59<39:43, 11.69s/it]predicting train subjects:  35%|███▍      | 108/311 [26:11<39:31, 11.68s/it]predicting train subjects:  35%|███▌      | 109/311 [26:23<39:37, 11.77s/it]predicting train subjects:  35%|███▌      | 110/311 [26:35<39:26, 11.78s/it]predicting train subjects:  36%|███▌      | 111/311 [26:46<39:01, 11.71s/it]predicting train subjects:  36%|███▌      | 112/311 [26:58<38:48, 11.70s/it]predicting train subjects:  36%|███▋      | 113/311 [27:10<39:01, 11.82s/it]predicting train subjects:  37%|███▋      | 114/311 [27:33<49:18, 15.02s/it]predicting train subjects:  37%|███▋      | 115/311 [27:55<56:12, 17.21s/it]predicting train subjects:  37%|███▋      | 116/311 [28:17<1:01:01, 18.78s/it]predicting train subjects:  38%|███▊      | 117/311 [28:40<1:04:52, 20.07s/it]predicting train subjects:  38%|███▊      | 118/311 [29:03<1:06:29, 20.67s/it]predicting train subjects:  38%|███▊      | 119/311 [29:26<1:08:36, 21.44s/it]predicting train subjects:  39%|███▊      | 120/311 [29:49<1:09:29, 21.83s/it]predicting train subjects:  39%|███▉      | 121/311 [30:11<1:09:38, 21.99s/it]predicting train subjects:  39%|███▉      | 122/311 [30:33<1:09:30, 22.06s/it]predicting train subjects:  40%|███▉      | 123/311 [30:56<1:10:02, 22.35s/it]predicting train subjects:  40%|███▉      | 124/311 [31:18<1:09:37, 22.34s/it]predicting train subjects:  40%|████      | 125/311 [31:41<1:09:49, 22.52s/it]predicting train subjects:  41%|████      | 126/311 [32:04<1:09:41, 22.60s/it]predicting train subjects:  41%|████      | 127/311 [32:27<1:09:29, 22.66s/it]predicting train subjects:  41%|████      | 128/311 [32:50<1:09:37, 22.83s/it]predicting train subjects:  41%|████▏     | 129/311 [33:12<1:08:23, 22.55s/it]predicting train subjects:  42%|████▏     | 130/311 [33:34<1:07:48, 22.48s/it]predicting train subjects:  42%|████▏     | 131/311 [33:56<1:06:47, 22.27s/it]predicting train subjects:  42%|████▏     | 132/311 [34:07<56:01, 18.78s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:17<48:12, 16.25s/it]predicting train subjects:  43%|████▎     | 134/311 [34:29<43:36, 14.78s/it]predicting train subjects:  43%|████▎     | 135/311 [34:40<40:05, 13.67s/it]predicting train subjects:  44%|████▎     | 136/311 [34:50<37:20, 12.80s/it]predicting train subjects:  44%|████▍     | 137/311 [35:02<35:42, 12.32s/it]predicting train subjects:  44%|████▍     | 138/311 [35:13<34:40, 12.03s/it]predicting train subjects:  45%|████▍     | 139/311 [35:23<33:07, 11.56s/it]predicting train subjects:  45%|████▌     | 140/311 [35:34<32:07, 11.27s/it]predicting train subjects:  45%|████▌     | 141/311 [35:45<31:47, 11.22s/it]predicting train subjects:  46%|████▌     | 142/311 [35:56<31:07, 11.05s/it]predicting train subjects:  46%|████▌     | 143/311 [36:07<30:56, 11.05s/it]predicting train subjects:  46%|████▋     | 144/311 [36:18<30:47, 11.06s/it]predicting train subjects:  47%|████▋     | 145/311 [36:29<30:24, 10.99s/it]predicting train subjects:  47%|████▋     | 146/311 [36:40<30:22, 11.04s/it]predicting train subjects:  47%|████▋     | 147/311 [36:51<30:17, 11.08s/it]predicting train subjects:  48%|████▊     | 148/311 [37:02<30:15, 11.14s/it]predicting train subjects:  48%|████▊     | 149/311 [37:13<29:52, 11.06s/it]predicting train subjects:  48%|████▊     | 150/311 [37:27<32:12, 12.00s/it]predicting train subjects:  49%|████▊     | 151/311 [37:42<33:46, 12.67s/it]predicting train subjects:  49%|████▉     | 152/311 [37:56<34:35, 13.06s/it]predicting train subjects:  49%|████▉     | 153/311 [38:09<35:01, 13.30s/it]predicting train subjects:  50%|████▉     | 154/311 [38:23<35:08, 13.43s/it]predicting train subjects:  50%|████▉     | 155/311 [38:37<35:32, 13.67s/it]predicting train subjects:  50%|█████     | 156/311 [38:51<35:31, 13.75s/it]predicting train subjects:  50%|█████     | 157/311 [39:05<35:20, 13.77s/it]predicting train subjects:  51%|█████     | 158/311 [39:19<35:05, 13.76s/it]predicting train subjects:  51%|█████     | 159/311 [39:33<35:01, 13.83s/it]predicting train subjects:  51%|█████▏    | 160/311 [39:47<35:07, 13.96s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:05<37:42, 15.09s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:23<39:40, 15.98s/it]predicting train subjects:  52%|█████▏    | 163/311 [40:41<41:10, 16.69s/it]predicting train subjects:  53%|█████▎    | 164/311 [40:59<41:42, 17.03s/it]predicting train subjects:  53%|█████▎    | 165/311 [41:17<42:21, 17.41s/it]predicting train subjects:  53%|█████▎    | 166/311 [41:35<41:54, 17.34s/it]predicting train subjects:  54%|█████▎    | 167/311 [41:50<39:55, 16.64s/it]predicting train subjects:  54%|█████▍    | 168/311 [42:06<39:09, 16.43s/it]predicting train subjects:  54%|█████▍    | 169/311 [42:22<38:39, 16.34s/it]predicting train subjects:  55%|█████▍    | 170/311 [42:36<37:10, 15.82s/it]predicting train subjects:  55%|█████▍    | 171/311 [42:51<36:18, 15.56s/it]predicting train subjects:  55%|█████▌    | 172/311 [43:07<36:10, 15.62s/it]predicting train subjects:  56%|█████▌    | 173/311 [43:23<36:02, 15.67s/it]predicting train subjects:  56%|█████▌    | 174/311 [43:39<36:27, 15.96s/it]predicting train subjects:  56%|█████▋    | 175/311 [43:56<36:47, 16.23s/it]predicting train subjects:  57%|█████▋    | 176/311 [44:14<37:14, 16.55s/it]predicting train subjects:  57%|█████▋    | 177/311 [44:32<38:12, 17.11s/it]predicting train subjects:  57%|█████▋    | 178/311 [44:50<38:16, 17.26s/it]predicting train subjects:  58%|█████▊    | 179/311 [45:07<38:05, 17.32s/it]predicting train subjects:  58%|█████▊    | 180/311 [45:25<37:59, 17.40s/it]predicting train subjects:  58%|█████▊    | 181/311 [45:42<37:48, 17.45s/it]predicting train subjects:  59%|█████▊    | 182/311 [45:59<37:02, 17.23s/it]predicting train subjects:  59%|█████▉    | 183/311 [46:16<36:30, 17.11s/it]predicting train subjects:  59%|█████▉    | 184/311 [46:32<35:29, 16.77s/it]predicting train subjects:  59%|█████▉    | 185/311 [46:48<34:37, 16.49s/it]predicting train subjects:  60%|█████▉    | 186/311 [47:03<33:52, 16.26s/it]predicting train subjects:  60%|██████    | 187/311 [47:20<34:11, 16.54s/it]predicting train subjects:  60%|██████    | 188/311 [47:35<32:56, 16.07s/it]predicting train subjects:  61%|██████    | 189/311 [47:51<32:19, 15.90s/it]predicting train subjects:  61%|██████    | 190/311 [48:04<30:12, 14.98s/it]predicting train subjects:  61%|██████▏   | 191/311 [48:16<28:18, 14.15s/it]predicting train subjects:  62%|██████▏   | 192/311 [48:27<26:24, 13.31s/it]predicting train subjects:  62%|██████▏   | 193/311 [48:39<25:17, 12.86s/it]predicting train subjects:  62%|██████▏   | 194/311 [48:51<24:38, 12.63s/it]predicting train subjects:  63%|██████▎   | 195/311 [49:03<23:48, 12.32s/it]predicting train subjects:  63%|██████▎   | 196/311 [49:14<23:06, 12.05s/it]predicting train subjects:  63%|██████▎   | 197/311 [49:26<22:54, 12.05s/it]predicting train subjects:  64%|██████▎   | 198/311 [49:38<22:39, 12.03s/it]predicting train subjects:  64%|██████▍   | 199/311 [49:50<22:19, 11.96s/it]predicting train subjects:  64%|██████▍   | 200/311 [50:01<21:44, 11.76s/it]predicting train subjects:  65%|██████▍   | 201/311 [50:13<21:43, 11.85s/it]predicting train subjects:  65%|██████▍   | 202/311 [50:25<21:32, 11.86s/it]predicting train subjects:  65%|██████▌   | 203/311 [50:37<21:23, 11.88s/it]predicting train subjects:  66%|██████▌   | 204/311 [50:49<21:01, 11.79s/it]predicting train subjects:  66%|██████▌   | 205/311 [51:01<20:46, 11.76s/it]predicting train subjects:  66%|██████▌   | 206/311 [51:13<20:42, 11.83s/it]predicting train subjects:  67%|██████▋   | 207/311 [51:24<20:34, 11.87s/it]predicting train subjects:  67%|██████▋   | 208/311 [51:36<20:04, 11.69s/it]predicting train subjects:  67%|██████▋   | 209/311 [51:48<20:01, 11.78s/it]predicting train subjects:  68%|██████▊   | 210/311 [52:00<20:00, 11.89s/it]predicting train subjects:  68%|██████▊   | 211/311 [52:12<19:47, 11.88s/it]predicting train subjects:  68%|██████▊   | 212/311 [52:23<19:18, 11.71s/it]predicting train subjects:  68%|██████▊   | 213/311 [52:46<24:37, 15.07s/it]predicting train subjects:  69%|██████▉   | 214/311 [53:08<27:48, 17.20s/it]predicting train subjects:  69%|██████▉   | 215/311 [53:30<29:56, 18.72s/it]predicting train subjects:  69%|██████▉   | 216/311 [53:52<31:14, 19.73s/it]predicting train subjects:  70%|██████▉   | 217/311 [54:16<32:33, 20.78s/it]predicting train subjects:  70%|███████   | 218/311 [54:37<32:37, 21.05s/it]predicting train subjects:  70%|███████   | 219/311 [55:00<33:10, 21.64s/it]predicting train subjects:  71%|███████   | 220/311 [55:22<32:58, 21.74s/it]predicting train subjects:  71%|███████   | 221/311 [55:45<32:51, 21.91s/it]predicting train subjects:  71%|███████▏  | 222/311 [56:07<32:31, 21.93s/it]predicting train subjects:  72%|███████▏  | 223/311 [56:29<32:32, 22.19s/it]predicting train subjects:  72%|███████▏  | 224/311 [56:51<31:58, 22.05s/it]predicting train subjects:  72%|███████▏  | 225/311 [57:13<31:42, 22.13s/it]predicting train subjects:  73%|███████▎  | 226/311 [57:36<31:25, 22.18s/it]predicting train subjects:  73%|███████▎  | 227/311 [57:58<31:14, 22.32s/it]predicting train subjects:  73%|███████▎  | 228/311 [58:21<31:00, 22.42s/it]predicting train subjects:  74%|███████▎  | 229/311 [58:44<30:39, 22.43s/it]predicting train subjects:  74%|███████▍  | 230/311 [59:06<30:14, 22.40s/it]predicting train subjects:  74%|███████▍  | 231/311 [59:16<25:08, 18.86s/it]predicting train subjects:  75%|███████▍  | 232/311 [59:27<21:28, 16.31s/it]predicting train subjects:  75%|███████▍  | 233/311 [59:37<18:48, 14.47s/it]predicting train subjects:  75%|███████▌  | 234/311 [59:48<17:09, 13.37s/it]predicting train subjects:  76%|███████▌  | 235/311 [59:59<16:01, 12.65s/it]predicting train subjects:  76%|███████▌  | 236/311 [1:00:09<14:53, 11.91s/it]predicting train subjects:  76%|███████▌  | 237/311 [1:00:19<14:10, 11.49s/it]predicting train subjects:  77%|███████▋  | 238/311 [1:00:30<13:37, 11.20s/it]predicting train subjects:  77%|███████▋  | 239/311 [1:00:40<13:09, 10.96s/it]predicting train subjects:  77%|███████▋  | 240/311 [1:00:51<12:49, 10.84s/it]predicting train subjects:  77%|███████▋  | 241/311 [1:01:02<12:33, 10.77s/it]predicting train subjects:  78%|███████▊  | 242/311 [1:01:12<12:13, 10.63s/it]predicting train subjects:  78%|███████▊  | 243/311 [1:01:22<11:56, 10.53s/it]predicting train subjects:  78%|███████▊  | 244/311 [1:01:33<11:50, 10.61s/it]predicting train subjects:  79%|███████▉  | 245/311 [1:01:43<11:34, 10.52s/it]predicting train subjects:  79%|███████▉  | 246/311 [1:01:53<11:16, 10.40s/it]predicting train subjects:  79%|███████▉  | 247/311 [1:02:04<11:10, 10.48s/it]predicting train subjects:  80%|███████▉  | 248/311 [1:02:15<11:10, 10.65s/it]predicting train subjects:  80%|████████  | 249/311 [1:02:28<11:45, 11.38s/it]predicting train subjects:  80%|████████  | 250/311 [1:02:41<12:01, 11.83s/it]predicting train subjects:  81%|████████  | 251/311 [1:02:54<12:15, 12.26s/it]predicting train subjects:  81%|████████  | 252/311 [1:03:08<12:24, 12.62s/it]predicting train subjects:  81%|████████▏ | 253/311 [1:03:21<12:23, 12.82s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:03:35<12:23, 13.04s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:03:48<12:23, 13.27s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:04:02<12:09, 13.27s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:04:15<11:52, 13.20s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:04:28<11:37, 13.16s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:04:41<11:24, 13.16s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:04:54<11:12, 13.19s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:05:08<11:00, 13.22s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:05:21<10:53, 13.34s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:05:34<10:38, 13.31s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:05:48<10:24, 13.29s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:06:00<10:03, 13.11s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:06:13<09:44, 13.00s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:06:26<09:30, 12.96s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:06:39<09:14, 12.90s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:06:52<09:05, 13.00s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:07:05<08:52, 13.00s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:07:18<08:39, 13.00s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:07:31<08:25, 12.97s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:07:43<08:06, 12.79s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:07:56<07:51, 12.73s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:08:09<07:39, 12.77s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:08:22<07:31, 12.91s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:08:35<07:19, 12.93s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:08:48<07:10, 13.03s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:09:01<06:59, 13.12s/it]predicting train subjects:  90%|█████████ | 280/311 [1:09:15<06:46, 13.11s/it]predicting train subjects:  90%|█████████ | 281/311 [1:09:28<06:32, 13.10s/it]predicting train subjects:  91%|█████████ | 282/311 [1:09:41<06:25, 13.28s/it]predicting train subjects:  91%|█████████ | 283/311 [1:09:53<06:01, 12.93s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:10:06<05:42, 12.70s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:10:17<05:22, 12.40s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:10:30<05:11, 12.48s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:10:42<04:57, 12.39s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:10:54<04:42, 12.28s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:11:06<04:27, 12.18s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:11:18<04:11, 11.98s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:11:29<03:57, 11.90s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:11:42<03:47, 11.97s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:11:54<03:35, 11.99s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:12:05<03:21, 11.85s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:12:17<03:09, 11.84s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:12:29<02:59, 11.94s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:12:41<02:47, 11.98s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:12:53<02:34, 11.88s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:13:04<02:21, 11.82s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:13:16<02:10, 11.87s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:13:29<01:59, 11.94s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:13:41<01:47, 11.95s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:13:52<01:35, 11.90s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:14:04<01:22, 11.79s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:14:16<01:11, 11.91s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:14:28<01:00, 12.02s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:14:41<00:48, 12.08s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:14:53<00:36, 12.22s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:15:05<00:24, 12.10s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:15:17<00:12, 12.13s/it]predicting train subjects: 100%|██████████| 311/311 [1:15:29<00:00, 12.12s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:17<1:28:50, 17.20s/it]Loading train:   1%|          | 2/311 [00:25<1:15:24, 14.64s/it]Loading train:   1%|          | 3/311 [00:36<1:09:19, 13.51s/it]Loading train:   1%|▏         | 4/311 [00:46<1:04:03, 12.52s/it]Loading train:   2%|▏         | 5/311 [00:56<59:04, 11.58s/it]  Loading train:   2%|▏         | 6/311 [01:06<55:57, 11.01s/it]Loading train:   2%|▏         | 7/311 [01:16<55:34, 10.97s/it]Loading train:   3%|▎         | 8/311 [01:28<56:55, 11.27s/it]Loading train:   3%|▎         | 9/311 [01:39<56:28, 11.22s/it]Loading train:   3%|▎         | 10/311 [01:49<53:40, 10.70s/it]Loading train:   4%|▎         | 11/311 [02:02<56:26, 11.29s/it]Loading train:   4%|▍         | 12/311 [02:12<54:11, 10.87s/it]Loading train:   4%|▍         | 13/311 [02:21<52:28, 10.56s/it]Loading train:   5%|▍         | 14/311 [02:34<54:51, 11.08s/it]Loading train:   5%|▍         | 15/311 [02:43<52:01, 10.54s/it]Loading train:   5%|▌         | 16/311 [02:52<50:03, 10.18s/it]Loading train:   5%|▌         | 17/311 [03:01<48:12,  9.84s/it]Loading train:   6%|▌         | 18/311 [03:11<47:20,  9.69s/it]Loading train:   6%|▌         | 19/311 [03:20<46:39,  9.59s/it]Loading train:   6%|▋         | 20/311 [03:29<45:33,  9.39s/it]Loading train:   7%|▋         | 21/311 [03:38<45:24,  9.39s/it]Loading train:   7%|▋         | 22/311 [03:48<45:11,  9.38s/it]Loading train:   7%|▋         | 23/311 [03:57<44:53,  9.35s/it]Loading train:   8%|▊         | 24/311 [04:06<44:36,  9.33s/it]Loading train:   8%|▊         | 25/311 [04:16<44:48,  9.40s/it]Loading train:   8%|▊         | 26/311 [04:25<44:22,  9.34s/it]Loading train:   9%|▊         | 27/311 [04:34<44:06,  9.32s/it]Loading train:   9%|▉         | 28/311 [04:44<44:13,  9.38s/it]Loading train:   9%|▉         | 29/311 [04:53<44:04,  9.38s/it]Loading train:  10%|▉         | 30/311 [05:02<43:35,  9.31s/it]Loading train:  10%|▉         | 31/311 [05:12<43:29,  9.32s/it]Loading train:  10%|█         | 32/311 [05:21<43:31,  9.36s/it]Loading train:  11%|█         | 33/311 [05:26<37:20,  8.06s/it]Loading train:  11%|█         | 34/311 [05:31<32:31,  7.05s/it]Loading train:  11%|█▏        | 35/311 [05:35<28:49,  6.27s/it]Loading train:  12%|█▏        | 36/311 [05:40<26:19,  5.74s/it]Loading train:  12%|█▏        | 37/311 [05:45<25:09,  5.51s/it]Loading train:  12%|█▏        | 38/311 [05:49<23:55,  5.26s/it]Loading train:  13%|█▎        | 39/311 [05:54<23:04,  5.09s/it]Loading train:  13%|█▎        | 40/311 [05:59<22:35,  5.00s/it]Loading train:  13%|█▎        | 41/311 [06:04<21:57,  4.88s/it]Loading train:  14%|█▎        | 42/311 [06:08<21:34,  4.81s/it]Loading train:  14%|█▍        | 43/311 [06:13<21:06,  4.73s/it]Loading train:  14%|█▍        | 44/311 [06:17<20:53,  4.69s/it]Loading train:  14%|█▍        | 45/311 [06:22<20:52,  4.71s/it]Loading train:  15%|█▍        | 46/311 [06:27<20:47,  4.71s/it]Loading train:  15%|█▌        | 47/311 [06:31<20:32,  4.67s/it]Loading train:  15%|█▌        | 48/311 [06:36<20:17,  4.63s/it]Loading train:  16%|█▌        | 49/311 [06:41<20:23,  4.67s/it]Loading train:  16%|█▌        | 50/311 [06:45<20:20,  4.68s/it]Loading train:  16%|█▋        | 51/311 [06:51<21:33,  4.98s/it]Loading train:  17%|█▋        | 52/311 [06:57<22:37,  5.24s/it]Loading train:  17%|█▋        | 53/311 [07:03<23:02,  5.36s/it]Loading train:  17%|█▋        | 54/311 [07:08<23:17,  5.44s/it]Loading train:  18%|█▊        | 55/311 [07:14<23:22,  5.48s/it]Loading train:  18%|█▊        | 56/311 [07:19<23:22,  5.50s/it]Loading train:  18%|█▊        | 57/311 [07:25<23:40,  5.59s/it]Loading train:  19%|█▊        | 58/311 [07:31<23:59,  5.69s/it]Loading train:  19%|█▉        | 59/311 [07:37<24:02,  5.72s/it]Loading train:  19%|█▉        | 60/311 [07:43<24:03,  5.75s/it]Loading train:  20%|█▉        | 61/311 [07:48<23:35,  5.66s/it]Loading train:  20%|█▉        | 62/311 [07:54<23:20,  5.63s/it]Loading train:  20%|██        | 63/311 [07:59<23:29,  5.68s/it]Loading train:  21%|██        | 64/311 [08:05<23:46,  5.78s/it]Loading train:  21%|██        | 65/311 [08:11<23:47,  5.80s/it]Loading train:  21%|██        | 66/311 [08:17<23:33,  5.77s/it]Loading train:  22%|██▏       | 67/311 [08:23<23:20,  5.74s/it]Loading train:  22%|██▏       | 68/311 [08:28<23:21,  5.77s/it]Loading train:  22%|██▏       | 69/311 [08:34<22:42,  5.63s/it]Loading train:  23%|██▎       | 70/311 [08:40<22:45,  5.67s/it]Loading train:  23%|██▎       | 71/311 [08:45<22:38,  5.66s/it]Loading train:  23%|██▎       | 72/311 [08:51<22:35,  5.67s/it]Loading train:  23%|██▎       | 73/311 [08:56<22:19,  5.63s/it]Loading train:  24%|██▍       | 74/311 [09:02<22:03,  5.58s/it]Loading train:  24%|██▍       | 75/311 [09:08<22:04,  5.61s/it]Loading train:  24%|██▍       | 76/311 [09:13<22:12,  5.67s/it]Loading train:  25%|██▍       | 77/311 [09:19<21:59,  5.64s/it]Loading train:  25%|██▌       | 78/311 [09:24<21:43,  5.60s/it]Loading train:  25%|██▌       | 79/311 [09:30<21:40,  5.60s/it]Loading train:  26%|██▌       | 80/311 [09:35<21:16,  5.53s/it]Loading train:  26%|██▌       | 81/311 [09:41<20:57,  5.47s/it]Loading train:  26%|██▋       | 82/311 [09:46<20:49,  5.46s/it]Loading train:  27%|██▋       | 83/311 [09:51<20:31,  5.40s/it]Loading train:  27%|██▋       | 84/311 [09:57<20:26,  5.40s/it]Loading train:  27%|██▋       | 85/311 [10:02<20:12,  5.37s/it]Loading train:  28%|██▊       | 86/311 [10:07<19:58,  5.33s/it]Loading train:  28%|██▊       | 87/311 [10:12<19:36,  5.25s/it]Loading train:  28%|██▊       | 88/311 [10:17<19:09,  5.15s/it]Loading train:  29%|██▊       | 89/311 [10:23<19:02,  5.15s/it]Loading train:  29%|██▉       | 90/311 [10:28<18:59,  5.16s/it]Loading train:  29%|██▉       | 91/311 [10:33<19:00,  5.19s/it]Loading train:  30%|██▉       | 92/311 [10:38<18:57,  5.19s/it]Loading train:  30%|██▉       | 93/311 [10:43<18:32,  5.10s/it]Loading train:  30%|███       | 94/311 [10:48<18:22,  5.08s/it]Loading train:  31%|███       | 95/311 [10:53<18:19,  5.09s/it]Loading train:  31%|███       | 96/311 [10:58<18:18,  5.11s/it]Loading train:  31%|███       | 97/311 [11:03<18:14,  5.12s/it]Loading train:  32%|███▏      | 98/311 [11:08<18:02,  5.08s/it]Loading train:  32%|███▏      | 99/311 [11:13<17:53,  5.06s/it]Loading train:  32%|███▏      | 100/311 [11:18<17:43,  5.04s/it]Loading train:  32%|███▏      | 101/311 [11:24<17:45,  5.08s/it]Loading train:  33%|███▎      | 102/311 [11:29<17:53,  5.14s/it]Loading train:  33%|███▎      | 103/311 [11:34<18:00,  5.19s/it]Loading train:  33%|███▎      | 104/311 [11:40<18:13,  5.28s/it]Loading train:  34%|███▍      | 105/311 [11:45<17:51,  5.20s/it]Loading train:  34%|███▍      | 106/311 [11:50<17:46,  5.20s/it]Loading train:  34%|███▍      | 107/311 [11:55<17:39,  5.19s/it]Loading train:  35%|███▍      | 108/311 [12:00<17:20,  5.13s/it]Loading train:  35%|███▌      | 109/311 [12:06<17:35,  5.22s/it]Loading train:  35%|███▌      | 110/311 [12:11<17:27,  5.21s/it]Loading train:  36%|███▌      | 111/311 [12:16<17:30,  5.25s/it]Loading train:  36%|███▌      | 112/311 [12:22<17:45,  5.35s/it]Loading train:  36%|███▋      | 113/311 [12:27<17:32,  5.31s/it]Loading train:  37%|███▋      | 114/311 [12:36<21:25,  6.52s/it]Loading train:  37%|███▋      | 115/311 [12:45<23:55,  7.32s/it]Loading train:  37%|███▋      | 116/311 [12:54<25:27,  7.84s/it]Loading train:  38%|███▊      | 117/311 [13:04<26:41,  8.25s/it]Loading train:  38%|███▊      | 118/311 [13:13<27:28,  8.54s/it]Loading train:  38%|███▊      | 119/311 [13:22<28:06,  8.79s/it]Loading train:  39%|███▊      | 120/311 [13:31<28:12,  8.86s/it]Loading train:  39%|███▉      | 121/311 [13:41<28:28,  8.99s/it]Loading train:  39%|███▉      | 122/311 [13:50<28:24,  9.02s/it]Loading train:  40%|███▉      | 123/311 [13:59<28:32,  9.11s/it]Loading train:  40%|███▉      | 124/311 [14:08<28:34,  9.17s/it]Loading train:  40%|████      | 125/311 [14:18<28:58,  9.34s/it]Loading train:  41%|████      | 126/311 [14:27<28:34,  9.27s/it]Loading train:  41%|████      | 127/311 [14:37<28:39,  9.35s/it]Loading train:  41%|████      | 128/311 [14:46<28:18,  9.28s/it]Loading train:  41%|████▏     | 129/311 [14:55<28:01,  9.24s/it]Loading train:  42%|████▏     | 130/311 [15:04<27:59,  9.28s/it]Loading train:  42%|████▏     | 131/311 [15:13<27:30,  9.17s/it]Loading train:  42%|████▏     | 132/311 [15:18<23:43,  7.95s/it]Loading train:  43%|████▎     | 133/311 [15:23<20:36,  6.95s/it]Loading train:  43%|████▎     | 134/311 [15:28<18:28,  6.26s/it]Loading train:  43%|████▎     | 135/311 [15:32<16:56,  5.78s/it]Loading train:  44%|████▎     | 136/311 [15:37<15:46,  5.41s/it]Loading train:  44%|████▍     | 137/311 [15:41<14:55,  5.15s/it]Loading train:  44%|████▍     | 138/311 [15:46<14:30,  5.03s/it]Loading train:  45%|████▍     | 139/311 [15:51<14:05,  4.91s/it]Loading train:  45%|████▌     | 140/311 [15:55<13:47,  4.84s/it]Loading train:  45%|████▌     | 141/311 [16:00<13:30,  4.77s/it]Loading train:  46%|████▌     | 142/311 [16:05<13:24,  4.76s/it]Loading train:  46%|████▌     | 143/311 [16:09<13:18,  4.76s/it]Loading train:  46%|████▋     | 144/311 [16:14<13:13,  4.75s/it]Loading train:  47%|████▋     | 145/311 [16:19<13:09,  4.76s/it]Loading train:  47%|████▋     | 146/311 [16:24<13:03,  4.75s/it]Loading train:  47%|████▋     | 147/311 [16:29<13:02,  4.77s/it]Loading train:  48%|████▊     | 148/311 [16:33<12:55,  4.76s/it]Loading train:  48%|████▊     | 149/311 [16:38<12:49,  4.75s/it]Loading train:  48%|████▊     | 150/311 [16:44<13:40,  5.09s/it]Loading train:  49%|████▊     | 151/311 [16:50<14:02,  5.27s/it]Loading train:  49%|████▉     | 152/311 [16:55<14:26,  5.45s/it]Loading train:  49%|████▉     | 153/311 [17:01<14:44,  5.60s/it]Loading train:  50%|████▉     | 154/311 [17:07<14:51,  5.68s/it]Loading train:  50%|████▉     | 155/311 [17:13<14:51,  5.72s/it]Loading train:  50%|█████     | 156/311 [17:19<14:44,  5.71s/it]Loading train:  50%|█████     | 157/311 [17:24<14:34,  5.68s/it]Loading train:  51%|█████     | 158/311 [17:30<14:34,  5.71s/it]Loading train:  51%|█████     | 159/311 [17:36<14:30,  5.73s/it]Loading train:  51%|█████▏    | 160/311 [17:42<14:28,  5.75s/it]Loading train:  52%|█████▏    | 161/311 [17:48<14:26,  5.78s/it]Loading train:  52%|█████▏    | 162/311 [17:53<14:14,  5.73s/it]Loading train:  52%|█████▏    | 163/311 [17:59<14:12,  5.76s/it]Loading train:  53%|█████▎    | 164/311 [18:05<14:17,  5.84s/it]Loading train:  53%|█████▎    | 165/311 [18:11<14:06,  5.80s/it]Loading train:  53%|█████▎    | 166/311 [18:16<13:57,  5.78s/it]Loading train:  54%|█████▎    | 167/311 [18:22<13:42,  5.71s/it]Loading train:  54%|█████▍    | 168/311 [18:28<13:46,  5.78s/it]Loading train:  54%|█████▍    | 169/311 [18:34<13:48,  5.83s/it]Loading train:  55%|█████▍    | 170/311 [18:39<13:30,  5.75s/it]Loading train:  55%|█████▍    | 171/311 [18:45<13:24,  5.74s/it]Loading train:  55%|█████▌    | 172/311 [18:51<13:26,  5.80s/it]Loading train:  56%|█████▌    | 173/311 [18:57<13:15,  5.76s/it]Loading train:  56%|█████▌    | 174/311 [19:03<13:15,  5.81s/it]Loading train:  56%|█████▋    | 175/311 [19:08<13:08,  5.80s/it]Loading train:  57%|█████▋    | 176/311 [19:14<12:58,  5.76s/it]Loading train:  57%|█████▋    | 177/311 [19:20<13:02,  5.84s/it]Loading train:  57%|█████▋    | 178/311 [19:26<12:51,  5.80s/it]Loading train:  58%|█████▊    | 179/311 [19:32<12:43,  5.78s/it]Loading train:  58%|█████▊    | 180/311 [19:37<12:40,  5.80s/it]Loading train:  58%|█████▊    | 181/311 [19:43<12:30,  5.77s/it]Loading train:  59%|█████▊    | 182/311 [19:49<12:14,  5.69s/it]Loading train:  59%|█████▉    | 183/311 [19:55<12:15,  5.75s/it]Loading train:  59%|█████▉    | 184/311 [20:00<11:54,  5.63s/it]Loading train:  59%|█████▉    | 185/311 [20:05<11:43,  5.58s/it]Loading train:  60%|█████▉    | 186/311 [20:11<11:25,  5.49s/it]Loading train:  60%|██████    | 187/311 [20:16<11:09,  5.40s/it]Loading train:  60%|██████    | 188/311 [20:21<11:03,  5.40s/it]Loading train:  61%|██████    | 189/311 [20:27<11:01,  5.42s/it]Loading train:  61%|██████    | 190/311 [20:32<10:52,  5.39s/it]Loading train:  61%|██████▏   | 191/311 [20:38<10:53,  5.45s/it]Loading train:  62%|██████▏   | 192/311 [20:43<10:50,  5.46s/it]Loading train:  62%|██████▏   | 193/311 [20:48<10:40,  5.42s/it]Loading train:  62%|██████▏   | 194/311 [20:54<10:33,  5.42s/it]Loading train:  63%|██████▎   | 195/311 [21:00<10:42,  5.54s/it]Loading train:  63%|██████▎   | 196/311 [21:05<10:29,  5.47s/it]Loading train:  63%|██████▎   | 197/311 [21:10<10:16,  5.41s/it]Loading train:  64%|██████▎   | 198/311 [21:16<10:13,  5.43s/it]Loading train:  64%|██████▍   | 199/311 [21:21<10:02,  5.38s/it]Loading train:  64%|██████▍   | 200/311 [21:27<10:02,  5.42s/it]Loading train:  65%|██████▍   | 201/311 [21:32<09:54,  5.40s/it]Loading train:  65%|██████▍   | 202/311 [21:37<09:53,  5.44s/it]Loading train:  65%|██████▌   | 203/311 [21:43<09:42,  5.40s/it]Loading train:  66%|██████▌   | 204/311 [21:48<09:38,  5.40s/it]Loading train:  66%|██████▌   | 205/311 [21:53<09:24,  5.32s/it]Loading train:  66%|██████▌   | 206/311 [21:59<09:22,  5.35s/it]Loading train:  67%|██████▋   | 207/311 [22:04<09:11,  5.30s/it]Loading train:  67%|██████▋   | 208/311 [22:09<09:06,  5.31s/it]Loading train:  67%|██████▋   | 209/311 [22:15<09:03,  5.33s/it]Loading train:  68%|██████▊   | 210/311 [22:20<08:54,  5.29s/it]Loading train:  68%|██████▊   | 211/311 [22:25<08:52,  5.33s/it]Loading train:  68%|██████▊   | 212/311 [22:31<08:51,  5.37s/it]Loading train:  68%|██████▊   | 213/311 [22:42<11:29,  7.03s/it]Loading train:  69%|██████▉   | 214/311 [22:54<13:52,  8.58s/it]Loading train:  69%|██████▉   | 215/311 [23:07<15:45,  9.85s/it]Loading train:  69%|██████▉   | 216/311 [23:18<16:33, 10.46s/it]Loading train:  70%|██████▉   | 217/311 [23:31<17:12, 10.99s/it]Loading train:  70%|███████   | 218/311 [23:42<17:16, 11.15s/it]Loading train:  70%|███████   | 219/311 [23:54<17:24, 11.35s/it]Loading train:  71%|███████   | 220/311 [24:06<17:16, 11.39s/it]Loading train:  71%|███████   | 221/311 [24:17<17:06, 11.40s/it]Loading train:  71%|███████▏  | 222/311 [24:29<17:13, 11.62s/it]Loading train:  72%|███████▏  | 223/311 [24:41<17:14, 11.76s/it]Loading train:  72%|███████▏  | 224/311 [24:53<17:08, 11.82s/it]Loading train:  72%|███████▏  | 225/311 [25:05<16:52, 11.77s/it]Loading train:  73%|███████▎  | 226/311 [25:16<16:27, 11.62s/it]Loading train:  73%|███████▎  | 227/311 [25:28<16:24, 11.72s/it]Loading train:  73%|███████▎  | 228/311 [25:39<16:05, 11.63s/it]Loading train:  74%|███████▎  | 229/311 [25:51<15:56, 11.66s/it]Loading train:  74%|███████▍  | 230/311 [26:03<15:55, 11.80s/it]Loading train:  74%|███████▍  | 231/311 [26:09<13:21, 10.02s/it]Loading train:  75%|███████▍  | 232/311 [26:16<11:54,  9.04s/it]Loading train:  75%|███████▍  | 233/311 [26:22<10:28,  8.06s/it]Loading train:  75%|███████▌  | 234/311 [26:28<09:37,  7.50s/it]Loading train:  76%|███████▌  | 235/311 [26:34<08:57,  7.07s/it]Loading train:  76%|███████▌  | 236/311 [26:40<08:27,  6.77s/it]Loading train:  76%|███████▌  | 237/311 [26:46<08:10,  6.63s/it]Loading train:  77%|███████▋  | 238/311 [26:52<07:54,  6.50s/it]Loading train:  77%|███████▋  | 239/311 [26:59<07:44,  6.45s/it]Loading train:  77%|███████▋  | 240/311 [27:05<07:23,  6.24s/it]Loading train:  77%|███████▋  | 241/311 [27:11<07:17,  6.25s/it]Loading train:  78%|███████▊  | 242/311 [27:17<07:08,  6.21s/it]Loading train:  78%|███████▊  | 243/311 [27:24<07:10,  6.34s/it]Loading train:  78%|███████▊  | 244/311 [27:30<07:03,  6.32s/it]Loading train:  79%|███████▉  | 245/311 [27:37<07:03,  6.42s/it]Loading train:  79%|███████▉  | 246/311 [27:43<06:48,  6.29s/it]Loading train:  79%|███████▉  | 247/311 [27:49<06:45,  6.33s/it]Loading train:  80%|███████▉  | 248/311 [27:55<06:33,  6.25s/it]Loading train:  80%|████████  | 249/311 [28:03<06:53,  6.67s/it]Loading train:  80%|████████  | 250/311 [28:10<06:53,  6.77s/it]Loading train:  81%|████████  | 251/311 [28:17<07:01,  7.02s/it]Loading train:  81%|████████  | 252/311 [28:24<06:51,  6.98s/it]Loading train:  81%|████████▏ | 253/311 [28:32<06:59,  7.24s/it]Loading train:  82%|████████▏ | 254/311 [28:39<06:55,  7.28s/it]Loading train:  82%|████████▏ | 255/311 [28:47<06:51,  7.35s/it]Loading train:  82%|████████▏ | 256/311 [28:54<06:46,  7.40s/it]Loading train:  83%|████████▎ | 257/311 [29:02<06:40,  7.42s/it]Loading train:  83%|████████▎ | 258/311 [29:09<06:34,  7.45s/it]Loading train:  83%|████████▎ | 259/311 [29:17<06:24,  7.39s/it]Loading train:  84%|████████▎ | 260/311 [29:24<06:18,  7.43s/it]Loading train:  84%|████████▍ | 261/311 [29:32<06:10,  7.40s/it]Loading train:  84%|████████▍ | 262/311 [29:40<06:13,  7.63s/it]Loading train:  85%|████████▍ | 263/311 [29:47<06:02,  7.55s/it]Loading train:  85%|████████▍ | 264/311 [29:55<05:57,  7.62s/it]Loading train:  85%|████████▌ | 265/311 [30:02<05:46,  7.54s/it]Loading train:  86%|████████▌ | 266/311 [30:10<05:39,  7.55s/it]Loading train:  86%|████████▌ | 267/311 [30:17<05:28,  7.48s/it]Loading train:  86%|████████▌ | 268/311 [30:24<05:14,  7.32s/it]Loading train:  86%|████████▋ | 269/311 [30:31<05:06,  7.30s/it]Loading train:  87%|████████▋ | 270/311 [30:39<05:04,  7.42s/it]Loading train:  87%|████████▋ | 271/311 [30:46<04:49,  7.24s/it]Loading train:  87%|████████▋ | 272/311 [30:53<04:40,  7.18s/it]Loading train:  88%|████████▊ | 273/311 [30:59<04:23,  6.92s/it]Loading train:  88%|████████▊ | 274/311 [31:05<04:01,  6.52s/it]Loading train:  88%|████████▊ | 275/311 [31:10<03:45,  6.27s/it]Loading train:  89%|████████▊ | 276/311 [31:16<03:32,  6.06s/it]Loading train:  89%|████████▉ | 277/311 [31:22<03:23,  5.98s/it]Loading train:  89%|████████▉ | 278/311 [31:27<03:14,  5.88s/it]Loading train:  90%|████████▉ | 279/311 [31:33<03:04,  5.75s/it]Loading train:  90%|█████████ | 280/311 [31:39<02:58,  5.77s/it]Loading train:  90%|█████████ | 281/311 [31:44<02:53,  5.78s/it]Loading train:  91%|█████████ | 282/311 [31:50<02:49,  5.83s/it]Loading train:  91%|█████████ | 283/311 [31:56<02:41,  5.75s/it]Loading train:  91%|█████████▏| 284/311 [32:01<02:32,  5.64s/it]Loading train:  92%|█████████▏| 285/311 [32:07<02:25,  5.60s/it]Loading train:  92%|█████████▏| 286/311 [32:13<02:22,  5.68s/it]Loading train:  92%|█████████▏| 287/311 [32:18<02:15,  5.64s/it]Loading train:  93%|█████████▎| 288/311 [32:24<02:10,  5.67s/it]Loading train:  93%|█████████▎| 289/311 [32:30<02:05,  5.71s/it]Loading train:  93%|█████████▎| 290/311 [32:35<01:59,  5.67s/it]Loading train:  94%|█████████▎| 291/311 [32:41<01:53,  5.69s/it]Loading train:  94%|█████████▍| 292/311 [32:47<01:46,  5.61s/it]Loading train:  94%|█████████▍| 293/311 [32:52<01:40,  5.57s/it]Loading train:  95%|█████████▍| 294/311 [32:57<01:33,  5.48s/it]Loading train:  95%|█████████▍| 295/311 [33:03<01:28,  5.50s/it]Loading train:  95%|█████████▌| 296/311 [33:09<01:23,  5.56s/it]Loading train:  95%|█████████▌| 297/311 [33:14<01:16,  5.50s/it]Loading train:  96%|█████████▌| 298/311 [33:20<01:11,  5.53s/it]Loading train:  96%|█████████▌| 299/311 [33:25<01:07,  5.58s/it]Loading train:  96%|█████████▋| 300/311 [33:31<01:01,  5.61s/it]Loading train:  97%|█████████▋| 301/311 [33:37<00:56,  5.69s/it]Loading train:  97%|█████████▋| 302/311 [33:42<00:51,  5.68s/it]Loading train:  97%|█████████▋| 303/311 [33:48<00:45,  5.68s/it]Loading train:  98%|█████████▊| 304/311 [33:54<00:39,  5.63s/it]Loading train:  98%|█████████▊| 305/311 [34:00<00:34,  5.74s/it]Loading train:  98%|█████████▊| 306/311 [34:05<00:28,  5.68s/it]Loading train:  99%|█████████▊| 307/311 [34:11<00:22,  5.67s/it]Loading train:  99%|█████████▉| 308/311 [34:17<00:17,  5.74s/it]Loading train:  99%|█████████▉| 309/311 [34:22<00:11,  5.72s/it]Loading train: 100%|█████████▉| 310/311 [34:28<00:05,  5.64s/it]Loading train: 100%|██████████| 311/311 [34:34<00:00,  5.71s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/311 [00:00<00:06, 44.90it/s]concatenating: train:   3%|▎         | 10/311 [00:00<00:06, 44.29it/s]concatenating: train:   5%|▍         | 15/311 [00:00<00:06, 44.45it/s]concatenating: train:   7%|▋         | 21/311 [00:00<00:06, 45.56it/s]concatenating: train:   8%|▊         | 25/311 [00:00<00:06, 43.74it/s]concatenating: train:   9%|▉         | 29/311 [00:00<00:06, 42.15it/s]concatenating: train:  11%|█         | 34/311 [00:00<00:06, 43.20it/s]concatenating: train:  13%|█▎        | 39/311 [00:00<00:06, 44.08it/s]concatenating: train:  14%|█▍        | 44/311 [00:01<00:07, 36.82it/s]concatenating: train:  16%|█▌        | 49/311 [00:01<00:06, 37.80it/s]concatenating: train:  17%|█▋        | 54/311 [00:01<00:06, 39.25it/s]concatenating: train:  19%|█▉        | 60/311 [00:01<00:05, 42.67it/s]concatenating: train:  21%|██        | 65/311 [00:01<00:05, 43.25it/s]concatenating: train:  23%|██▎       | 70/311 [00:01<00:05, 44.68it/s]concatenating: train:  24%|██▍       | 75/311 [00:01<00:05, 45.07it/s]concatenating: train:  27%|██▋       | 83/311 [00:01<00:04, 50.68it/s]concatenating: train:  29%|██▊       | 89/311 [00:01<00:04, 52.59it/s]concatenating: train:  31%|███       | 97/311 [00:02<00:03, 57.55it/s]concatenating: train:  33%|███▎      | 104/311 [00:02<00:03, 59.62it/s]concatenating: train:  36%|███▌      | 112/311 [00:02<00:03, 63.86it/s]concatenating: train:  39%|███▉      | 121/311 [00:02<00:02, 65.68it/s]concatenating: train:  42%|████▏     | 130/311 [00:02<00:02, 70.79it/s]concatenating: train:  45%|████▌     | 140/311 [00:02<00:02, 77.06it/s]concatenating: train:  48%|████▊     | 149/311 [00:02<00:02, 78.72it/s]concatenating: train:  51%|█████     | 158/311 [00:02<00:02, 72.24it/s]concatenating: train:  53%|█████▎    | 166/311 [00:03<00:02, 62.04it/s]concatenating: train:  56%|█████▌    | 173/311 [00:03<00:02, 59.40it/s]concatenating: train:  58%|█████▊    | 180/311 [00:03<00:02, 60.54it/s]concatenating: train:  60%|██████    | 187/311 [00:03<00:02, 61.11it/s]concatenating: train:  62%|██████▏   | 194/311 [00:03<00:01, 61.52it/s]concatenating: train:  65%|██████▍   | 201/311 [00:03<00:01, 60.53it/s]concatenating: train:  67%|██████▋   | 208/311 [00:03<00:01, 61.11it/s]concatenating: train:  70%|███████   | 218/311 [00:03<00:01, 68.61it/s]concatenating: train:  73%|███████▎  | 226/311 [00:03<00:01, 71.58it/s]concatenating: train:  77%|███████▋  | 239/311 [00:04<00:00, 82.11it/s]concatenating: train:  81%|████████  | 251/311 [00:04<00:00, 89.89it/s]concatenating: train:  85%|████████▍ | 263/311 [00:04<00:00, 93.62it/s]concatenating: train:  88%|████████▊ | 273/311 [00:04<00:00, 95.37it/s]concatenating: train:  91%|█████████ | 283/311 [00:04<00:00, 92.55it/s]concatenating: train:  94%|█████████▍| 293/311 [00:04<00:00, 88.52it/s]concatenating: train:  97%|█████████▋| 303/311 [00:04<00:00, 88.75it/s]concatenating: train: 100%|██████████| 311/311 [00:04<00:00, 63.58it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:12<00:37, 12.54s/it]Loading test:  50%|█████     | 2/4 [00:23<00:24, 12.08s/it]Loading test:  75%|███████▌  | 3/4 [00:36<00:12, 12.26s/it]Loading test: 100%|██████████| 4/4 [00:48<00:00, 12.21s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 39.59it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 16:50:31.801381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 16:50:31.801492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 16:50:31.801509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 16:50:31.801520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 16:50:31.801932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 26, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [5.88176395e-02 2.85713643e-02 1.22080201e-01 1.04952659e-02
 3.15779544e-02 5.46270752e-03 7.23535399e-02 1.13294426e-01
 7.88079565e-02 1.27907394e-02 2.93002722e-01 1.72516551e-01
 2.28932584e-04]
Train on 20529 samples, validate on 262 samples
Epoch 1/300
 - 24s - loss: 13081.2405 - acc: 0.8667 - mDice: 0.1979 - val_loss: 5763.8436 - val_acc: 0.8654 - val_mDice: 0.3344

Epoch 00001: val_mDice improved from -inf to 0.33442, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 14s - loss: 5354.9381 - acc: 0.8985 - mDice: 0.3733 - val_loss: 4086.5296 - val_acc: 0.8859 - val_mDice: 0.4335

Epoch 00002: val_mDice improved from 0.33442 to 0.43348, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 14s - loss: 4033.6326 - acc: 0.9126 - mDice: 0.4627 - val_loss: 2902.9668 - val_acc: 0.9162 - val_mDice: 0.5351

Epoch 00003: val_mDice improved from 0.43348 to 0.53507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 14s - loss: 3371.7175 - acc: 0.9213 - mDice: 0.5200 - val_loss: 2516.6574 - val_acc: 0.9273 - val_mDice: 0.5748

Epoch 00004: val_mDice improved from 0.53507 to 0.57484, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 14s - loss: 2930.9028 - acc: 0.9272 - mDice: 0.5624 - val_loss: 2389.5735 - val_acc: 0.9267 - val_mDice: 0.5920

Epoch 00005: val_mDice improved from 0.57484 to 0.59203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 14s - loss: 2655.9580 - acc: 0.9310 - mDice: 0.5911 - val_loss: 2187.7077 - val_acc: 0.9343 - val_mDice: 0.6190

Epoch 00006: val_mDice improved from 0.59203 to 0.61903, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 14s - loss: 2455.9281 - acc: 0.9340 - mDice: 0.6132 - val_loss: 2067.3275 - val_acc: 0.9402 - val_mDice: 0.6336

Epoch 00007: val_mDice improved from 0.61903 to 0.63362, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 8/300
 - 14s - loss: 2310.7606 - acc: 0.9362 - mDice: 0.6305 - val_loss: 2023.7573 - val_acc: 0.9409 - val_mDice: 0.6450

Epoch 00008: val_mDice improved from 0.63362 to 0.64503, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 9/300
 - 14s - loss: 2188.7119 - acc: 0.9381 - mDice: 0.6453 - val_loss: 1960.6365 - val_acc: 0.9423 - val_mDice: 0.6517

Epoch 00009: val_mDice improved from 0.64503 to 0.65168, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 2089.9855 - acc: 0.9397 - mDice: 0.6575 - val_loss: 1897.6588 - val_acc: 0.9453 - val_mDice: 0.6602

Epoch 00010: val_mDice improved from 0.65168 to 0.66025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 14s - loss: 2017.9713 - acc: 0.9410 - mDice: 0.6670 - val_loss: 1919.7385 - val_acc: 0.9447 - val_mDice: 0.6571

Epoch 00011: val_mDice did not improve from 0.66025
Epoch 12/300
 - 13s - loss: 1941.1152 - acc: 0.9423 - mDice: 0.6768 - val_loss: 1813.0220 - val_acc: 0.9479 - val_mDice: 0.6746

Epoch 00012: val_mDice improved from 0.66025 to 0.67455, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 13/300
 - 14s - loss: 1887.0173 - acc: 0.9433 - mDice: 0.6842 - val_loss: 1781.9196 - val_acc: 0.9493 - val_mDice: 0.6785

Epoch 00013: val_mDice improved from 0.67455 to 0.67847, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 14/300
 - 13s - loss: 1825.7170 - acc: 0.9443 - mDice: 0.6923 - val_loss: 1733.4212 - val_acc: 0.9494 - val_mDice: 0.6835

Epoch 00014: val_mDice improved from 0.67847 to 0.68351, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 15/300
 - 14s - loss: 1770.1294 - acc: 0.9451 - mDice: 0.7001 - val_loss: 1719.0596 - val_acc: 0.9492 - val_mDice: 0.6848

Epoch 00015: val_mDice improved from 0.68351 to 0.68480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 16/300
 - 13s - loss: 1731.2047 - acc: 0.9459 - mDice: 0.7053 - val_loss: 1747.5207 - val_acc: 0.9494 - val_mDice: 0.6805

Epoch 00016: val_mDice did not improve from 0.68480
Epoch 17/300
 - 14s - loss: 1679.4389 - acc: 0.9466 - mDice: 0.7123 - val_loss: 1730.7412 - val_acc: 0.9519 - val_mDice: 0.6853

Epoch 00017: val_mDice improved from 0.68480 to 0.68532, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 13s - loss: 1645.1039 - acc: 0.9473 - mDice: 0.7171 - val_loss: 1713.8059 - val_acc: 0.9519 - val_mDice: 0.6871

Epoch 00018: val_mDice improved from 0.68532 to 0.68712, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 19/300
 - 14s - loss: 1605.4703 - acc: 0.9480 - mDice: 0.7227 - val_loss: 1691.3816 - val_acc: 0.9527 - val_mDice: 0.6917

Epoch 00019: val_mDice improved from 0.68712 to 0.69171, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 20/300
 - 14s - loss: 1584.1165 - acc: 0.9484 - mDice: 0.7259 - val_loss: 1769.6671 - val_acc: 0.9509 - val_mDice: 0.6799

Epoch 00020: val_mDice did not improve from 0.69171
Epoch 21/300
 - 14s - loss: 1550.3823 - acc: 0.9490 - mDice: 0.7307 - val_loss: 1648.7801 - val_acc: 0.9546 - val_mDice: 0.6969

Epoch 00021: val_mDice improved from 0.69171 to 0.69690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 22/300
 - 14s - loss: 1525.8549 - acc: 0.9495 - mDice: 0.7343 - val_loss: 1637.5937 - val_acc: 0.9539 - val_mDice: 0.6991

Epoch 00022: val_mDice improved from 0.69690 to 0.69911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 13s - loss: 1490.9433 - acc: 0.9500 - mDice: 0.7391 - val_loss: 1702.9352 - val_acc: 0.9531 - val_mDice: 0.6896

Epoch 00023: val_mDice did not improve from 0.69911
Epoch 24/300
 - 14s - loss: 1475.5634 - acc: 0.9503 - mDice: 0.7417 - val_loss: 1629.1583 - val_acc: 0.9544 - val_mDice: 0.7015

Epoch 00024: val_mDice improved from 0.69911 to 0.70150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 25/300
 - 13s - loss: 1447.9756 - acc: 0.9508 - mDice: 0.7456 - val_loss: 1762.1554 - val_acc: 0.9520 - val_mDice: 0.6812

Epoch 00025: val_mDice did not improve from 0.70150
Epoch 26/300
 - 14s - loss: 1428.6082 - acc: 0.9512 - mDice: 0.7484 - val_loss: 1681.3020 - val_acc: 0.9530 - val_mDice: 0.6918

Epoch 00026: val_mDice did not improve from 0.70150
Epoch 27/300
 - 13s - loss: 1407.2761 - acc: 0.9516 - mDice: 0.7517 - val_loss: 1638.2119 - val_acc: 0.9547 - val_mDice: 0.6997

Epoch 00027: val_mDice did not improve from 0.70150
Epoch 28/300
 - 14s - loss: 1388.6545 - acc: 0.9519 - mDice: 0.7545 - val_loss: 1619.3489 - val_acc: 0.9564 - val_mDice: 0.7029

Epoch 00028: val_mDice improved from 0.70150 to 0.70286, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 29/300
 - 13s - loss: 1373.2213 - acc: 0.9522 - mDice: 0.7569 - val_loss: 1641.1675 - val_acc: 0.9547 - val_mDice: 0.6992

Epoch 00029: val_mDice did not improve from 0.70286
Epoch 30/300
 - 14s - loss: 1363.2066 - acc: 0.9525 - mDice: 0.7586 - val_loss: 1681.9515 - val_acc: 0.9553 - val_mDice: 0.6957

Epoch 00030: val_mDice did not improve from 0.70286
Epoch 31/300
 - 14s - loss: 1339.6332 - acc: 0.9529 - mDice: 0.7620 - val_loss: 1635.5942 - val_acc: 0.9550 - val_mDice: 0.7002

Epoch 00031: val_mDice did not improve from 0.70286
Epoch 32/300
 - 13s - loss: 1325.5811 - acc: 0.9531 - mDice: 0.7640 - val_loss: 1679.9814 - val_acc: 0.9557 - val_mDice: 0.6933

Epoch 00032: val_mDice did not improve from 0.70286
Epoch 33/300
 - 14s - loss: 1314.1458 - acc: 0.9534 - mDice: 0.7657 - val_loss: 1600.1640 - val_acc: 0.9584 - val_mDice: 0.7062

Epoch 00033: val_mDice improved from 0.70286 to 0.70623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 34/300
 - 13s - loss: 1295.4880 - acc: 0.9536 - mDice: 0.7686 - val_loss: 1710.4159 - val_acc: 0.9545 - val_mDice: 0.6901

Epoch 00034: val_mDice did not improve from 0.70623
Epoch 35/300
 - 14s - loss: 1283.3716 - acc: 0.9539 - mDice: 0.7706 - val_loss: 1606.4361 - val_acc: 0.9571 - val_mDice: 0.7055

Epoch 00035: val_mDice did not improve from 0.70623
Epoch 36/300
 - 13s - loss: 1265.8975 - acc: 0.9541 - mDice: 0.7731 - val_loss: 1633.3935 - val_acc: 0.9576 - val_mDice: 0.7020

Epoch 00036: val_mDice did not improve from 0.70623
Epoch 37/300
 - 14s - loss: 1255.4234 - acc: 0.9544 - mDice: 0.7748 - val_loss: 1644.6012 - val_acc: 0.9580 - val_mDice: 0.6986

Epoch 00037: val_mDice did not improve from 0.70623
Epoch 38/300
 - 13s - loss: 1289.6418 - acc: 0.9544 - mDice: 0.7745 - val_loss: 1631.6191 - val_acc: 0.9588 - val_mDice: 0.7026

Epoch 00038: val_mDice did not improve from 0.70623
Epoch 39/300
 - 14s - loss: 1229.5157 - acc: 0.9547 - mDice: 0.7788 - val_loss: 1597.2660 - val_acc: 0.9575 - val_mDice: 0.7066

Epoch 00039: val_mDice improved from 0.70623 to 0.70663, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 40/300
 - 13s - loss: 1222.9036 - acc: 0.9549 - mDice: 0.7799 - val_loss: 1739.0019 - val_acc: 0.9542 - val_mDice: 0.6858

Epoch 00040: val_mDice did not improve from 0.70663
Epoch 41/300
 - 14s - loss: 1216.0971 - acc: 0.9551 - mDice: 0.7811 - val_loss: 1714.2821 - val_acc: 0.9541 - val_mDice: 0.6881

Epoch 00041: val_mDice did not improve from 0.70663
Epoch 42/300
 - 14s - loss: 1212.5068 - acc: 0.9552 - mDice: 0.7815 - val_loss: 1635.1437 - val_acc: 0.9585 - val_mDice: 0.6997

Epoch 00042: val_mDice did not improve from 0.70663
Epoch 43/300
 - 14s - loss: 1193.6267 - acc: 0.9554 - mDice: 0.7844 - val_loss: 1684.1881 - val_acc: 0.9577 - val_mDice: 0.6926

Epoch 00043: val_mDice did not improve from 0.70663
Epoch 44/300
 - 14s - loss: 1232.5824 - acc: 0.9554 - mDice: 0.7833 - val_loss: 1637.4167 - val_acc: 0.9570 - val_mDice: 0.7011

Epoch 00044: val_mDice did not improve from 0.70663
Epoch 45/300
 - 14s - loss: 1181.1343 - acc: 0.9557 - mDice: 0.7864 - val_loss: 1756.9654 - val_acc: 0.9566 - val_mDice: 0.6861

Epoch 00045: val_mDice did not improve from 0.70663
Epoch 46/300
 - 14s - loss: 1169.3208 - acc: 0.9559 - mDice: 0.7883 - val_loss: 1584.2257 - val_acc: 0.9586 - val_mDice: 0.7073

Epoch 00046: val_mDice improved from 0.70663 to 0.70727, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 47/300
 - 13s - loss: 1163.3546 - acc: 0.9561 - mDice: 0.7892 - val_loss: 1711.0201 - val_acc: 0.9537 - val_mDice: 0.6864

Epoch 00047: val_mDice did not improve from 0.70727
Epoch 48/300
 - 14s - loss: 1156.7536 - acc: 0.9562 - mDice: 0.7902 - val_loss: 1650.5911 - val_acc: 0.9566 - val_mDice: 0.6997

Epoch 00048: val_mDice did not improve from 0.70727
Epoch 49/300
 - 13s - loss: 1144.5564 - acc: 0.9563 - mDice: 0.7921 - val_loss: 1606.4979 - val_acc: 0.9578 - val_mDice: 0.7041

Epoch 00049: val_mDice did not improve from 0.70727
Epoch 50/300
 - 14s - loss: 1132.0379 - acc: 0.9565 - mDice: 0.7941 - val_loss: 1589.7610 - val_acc: 0.9566 - val_mDice: 0.7054

Epoch 00050: val_mDice did not improve from 0.70727
Epoch 51/300
 - 13s - loss: 1136.4300 - acc: 0.9565 - mDice: 0.7935 - val_loss: 1923.1727 - val_acc: 0.9466 - val_mDice: 0.6572

Epoch 00051: val_mDice did not improve from 0.70727
Epoch 52/300
 - 14s - loss: 1115.6559 - acc: 0.9568 - mDice: 0.7968 - val_loss: 1622.5629 - val_acc: 0.9595 - val_mDice: 0.7028

Epoch 00052: val_mDice did not improve from 0.70727
Epoch 53/300
 - 14s - loss: 1116.8992 - acc: 0.9567 - mDice: 0.7965 - val_loss: 1686.6385 - val_acc: 0.9559 - val_mDice: 0.6924

Epoch 00053: val_mDice did not improve from 0.70727
Epoch 54/300
 - 14s - loss: 1108.3395 - acc: 0.9569 - mDice: 0.7979 - val_loss: 1595.3451 - val_acc: 0.9586 - val_mDice: 0.7058

Epoch 00054: val_mDice did not improve from 0.70727
Epoch 55/300
 - 14s - loss: 1112.3232 - acc: 0.9570 - mDice: 0.7973 - val_loss: 1690.7807 - val_acc: 0.9572 - val_mDice: 0.6920

Epoch 00055: val_mDice did not improve from 0.70727
Epoch 56/300
 - 13s - loss: 1097.9938 - acc: 0.9571 - mDice: 0.7996 - val_loss: 1607.6292 - val_acc: 0.9591 - val_mDice: 0.7048

Epoch 00056: val_mDice did not improve from 0.70727
Epoch 57/300
 - 14s - loss: 1097.2018 - acc: 0.9572 - mDice: 0.7997 - val_loss: 1680.3411 - val_acc: 0.9548 - val_mDice: 0.6924

Epoch 00057: val_mDice did not improve from 0.70727
Epoch 58/300
 - 13s - loss: 1087.0501 - acc: 0.9573 - mDice: 0.8013 - val_loss: 1659.3740 - val_acc: 0.9584 - val_mDice: 0.6971

Epoch 00058: val_mDice did not improve from 0.70727
Epoch 59/300
 - 14s - loss: 1101.4299 - acc: 0.9570 - mDice: 0.7996 - val_loss: 4387.8920 - val_acc: 0.9404 - val_mDice: 0.5265

Epoch 00059: val_mDice did not improve from 0.70727
Epoch 60/300
 - 13s - loss: 1103.1201 - acc: 0.9570 - mDice: 0.7988 - val_loss: 1606.9398 - val_acc: 0.9571 - val_mDice: 0.7053

Epoch 00060: val_mDice did not improve from 0.70727
Epoch 61/300
 - 14s - loss: 1073.7339 - acc: 0.9574 - mDice: 0.8035 - val_loss: 1589.3186 - val_acc: 0.9591 - val_mDice: 0.7067

Epoch 00061: val_mDice did not improve from 0.70727
Epoch 62/300
 - 13s - loss: 1063.9044 - acc: 0.9577 - mDice: 0.8050 - val_loss: 1634.8861 - val_acc: 0.9580 - val_mDice: 0.7009

Epoch 00062: val_mDice did not improve from 0.70727
Epoch 63/300
 - 14s - loss: 1063.4773 - acc: 0.9577 - mDice: 0.8051 - val_loss: 1591.0524 - val_acc: 0.9600 - val_mDice: 0.7080

Epoch 00063: val_mDice improved from 0.70727 to 0.70799, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 64/300
 - 14s - loss: 1062.0630 - acc: 0.9577 - mDice: 0.8054 - val_loss: 1612.1834 - val_acc: 0.9584 - val_mDice: 0.7035

Epoch 00064: val_mDice did not improve from 0.70799
Epoch 65/300
 - 14s - loss: 1049.3009 - acc: 0.9578 - mDice: 0.8074 - val_loss: 1593.7038 - val_acc: 0.9584 - val_mDice: 0.7066

Epoch 00065: val_mDice did not improve from 0.70799
Epoch 66/300
 - 14s - loss: 1049.8856 - acc: 0.9578 - mDice: 0.8073 - val_loss: 1641.5747 - val_acc: 0.9573 - val_mDice: 0.6994

Epoch 00066: val_mDice did not improve from 0.70799
Epoch 67/300
 - 13s - loss: 1040.2020 - acc: 0.9579 - mDice: 0.8088 - val_loss: 1607.2991 - val_acc: 0.9598 - val_mDice: 0.7049

Epoch 00067: val_mDice did not improve from 0.70799
Epoch 68/300
 - 14s - loss: 1039.2494 - acc: 0.9580 - mDice: 0.8091 - val_loss: 1771.4112 - val_acc: 0.9510 - val_mDice: 0.6792

Epoch 00068: val_mDice did not improve from 0.70799
Epoch 69/300
 - 13s - loss: 1032.7788 - acc: 0.9582 - mDice: 0.8101 - val_loss: 1625.0071 - val_acc: 0.9602 - val_mDice: 0.7024

Epoch 00069: val_mDice did not improve from 0.70799
Epoch 70/300
 - 14s - loss: 1035.7715 - acc: 0.9581 - mDice: 0.8097 - val_loss: 1678.2759 - val_acc: 0.9555 - val_mDice: 0.6946

Epoch 00070: val_mDice did not improve from 0.70799
Epoch 71/300
 - 13s - loss: 1027.6829 - acc: 0.9583 - mDice: 0.8110 - val_loss: 1593.4908 - val_acc: 0.9588 - val_mDice: 0.7072

Epoch 00071: val_mDice did not improve from 0.70799
Epoch 72/300
 - 14s - loss: 1021.9483 - acc: 0.9583 - mDice: 0.8121 - val_loss: 1670.0053 - val_acc: 0.9577 - val_mDice: 0.6942

Epoch 00072: val_mDice did not improve from 0.70799
Epoch 73/300
 - 13s - loss: 1339.8743 - acc: 0.9520 - mDice: 0.7634 - val_loss: 1598.6811 - val_acc: 0.9580 - val_mDice: 0.7060

Epoch 00073: val_mDice did not improve from 0.70799
Epoch 74/300
 - 14s - loss: 1106.8474 - acc: 0.9566 - mDice: 0.7981 - val_loss: 1616.1609 - val_acc: 0.9588 - val_mDice: 0.7038

Epoch 00074: val_mDice did not improve from 0.70799
Epoch 75/300
 - 14s - loss: 1062.6421 - acc: 0.9574 - mDice: 0.8052 - val_loss: 1615.1940 - val_acc: 0.9580 - val_mDice: 0.7039

Epoch 00075: val_mDice did not improve from 0.70799
Epoch 76/300
 - 13s - loss: 1046.1089 - acc: 0.9578 - mDice: 0.8080 - val_loss: 1600.7623 - val_acc: 0.9582 - val_mDice: 0.7059

Epoch 00076: val_mDice did not improve from 0.70799
Epoch 77/300
 - 14s - loss: 1030.8213 - acc: 0.9580 - mDice: 0.8104 - val_loss: 1625.3858 - val_acc: 0.9581 - val_mDice: 0.7006

Epoch 00077: val_mDice did not improve from 0.70799
Epoch 78/300
 - 13s - loss: 1024.5970 - acc: 0.9582 - mDice: 0.8114 - val_loss: 1598.5321 - val_acc: 0.9584 - val_mDice: 0.7068

Epoch 00078: val_mDice did not improve from 0.70799
Epoch 79/300
 - 14s - loss: 1020.4029 - acc: 0.9583 - mDice: 0.8128 - val_loss: 1691.7955 - val_acc: 0.9566 - val_mDice: 0.6932

Epoch 00079: val_mDice did not improve from 0.70799
Epoch 80/300
 - 13s - loss: 1115.6953 - acc: 0.9566 - mDice: 0.7972 - val_loss: 1659.1455 - val_acc: 0.9584 - val_mDice: 0.6986

Epoch 00080: val_mDice did not improve from 0.70799
Epoch 81/300
 - 14s - loss: 1028.5725 - acc: 0.9581 - mDice: 0.8108 - val_loss: 1596.8156 - val_acc: 0.9556 - val_mDice: 0.7065

Epoch 00081: val_mDice did not improve from 0.70799
Epoch 82/300
 - 13s - loss: 1011.5954 - acc: 0.9583 - mDice: 0.8136 - val_loss: 1637.1568 - val_acc: 0.9567 - val_mDice: 0.7002

Epoch 00082: val_mDice did not improve from 0.70799
Epoch 83/300
 - 14s - loss: 1007.1727 - acc: 0.9585 - mDice: 0.8143 - val_loss: 1614.7216 - val_acc: 0.9580 - val_mDice: 0.7032

Epoch 00083: val_mDice did not improve from 0.70799
Epoch 84/300
 - 13s - loss: 997.3493 - acc: 0.9586 - mDice: 0.8159 - val_loss: 1619.3315 - val_acc: 0.9587 - val_mDice: 0.7046

Epoch 00084: val_mDice did not improve from 0.70799
Epoch 85/300
 - 14s - loss: 991.2029 - acc: 0.9588 - mDice: 0.8169 - val_loss: 1592.2951 - val_acc: 0.9581 - val_mDice: 0.7063

Epoch 00085: val_mDice did not improve from 0.70799
Epoch 86/300
 - 13s - loss: 992.4024 - acc: 0.9587 - mDice: 0.8168 - val_loss: 1563.1098 - val_acc: 0.9589 - val_mDice: 0.7114

Epoch 00086: val_mDice improved from 0.70799 to 0.71141, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 87/300
 - 14s - loss: 991.3403 - acc: 0.9587 - mDice: 0.8169 - val_loss: 1709.5849 - val_acc: 0.9559 - val_mDice: 0.6891

Epoch 00087: val_mDice did not improve from 0.71141
Epoch 88/300
 - 14s - loss: 982.7172 - acc: 0.9587 - mDice: 0.8183 - val_loss: 1576.9286 - val_acc: 0.9593 - val_mDice: 0.7090

Epoch 00088: val_mDice did not improve from 0.71141
Epoch 89/300
 - 14s - loss: 984.7758 - acc: 0.9589 - mDice: 0.8180 - val_loss: 1688.7350 - val_acc: 0.9546 - val_mDice: 0.6921

Epoch 00089: val_mDice did not improve from 0.71141
Epoch 90/300
 - 14s - loss: 987.3607 - acc: 0.9587 - mDice: 0.8175 - val_loss: 1667.5846 - val_acc: 0.9566 - val_mDice: 0.6948

Epoch 00090: val_mDice did not improve from 0.71141
Epoch 91/300
 - 13s - loss: 982.1434 - acc: 0.9589 - mDice: 0.8184 - val_loss: 1588.1732 - val_acc: 0.9594 - val_mDice: 0.7086

Epoch 00091: val_mDice did not improve from 0.71141
Epoch 92/300
 - 14s - loss: 988.2452 - acc: 0.9587 - mDice: 0.8174 - val_loss: 1671.1887 - val_acc: 0.9585 - val_mDice: 0.6971

Epoch 00092: val_mDice did not improve from 0.71141
Epoch 93/300
 - 13s - loss: 981.7078 - acc: 0.9589 - mDice: 0.8185 - val_loss: 1620.2385 - val_acc: 0.9593 - val_mDice: 0.7039

Epoch 00093: val_mDice did not improve from 0.71141
Epoch 94/300
 - 14s - loss: 977.3088 - acc: 0.9589 - mDice: 0.8192 - val_loss: 1647.6723 - val_acc: 0.9576 - val_mDice: 0.6985

Epoch 00094: val_mDice did not improve from 0.71141
Epoch 95/300
 - 13s - loss: 974.7871 - acc: 0.9590 - mDice: 0.8197 - val_loss: 1608.8587 - val_acc: 0.9590 - val_mDice: 0.7048

Epoch 00095: val_mDice did not improve from 0.71141
Epoch 96/300
 - 14s - loss: 982.2713 - acc: 0.9590 - mDice: 0.8187 - val_loss: 1623.4717 - val_acc: 0.9584 - val_mDice: 0.7030

Epoch 00096: val_mDice did not improve from 0.71141
Epoch 97/300
 - 13s - loss: 979.8414 - acc: 0.9589 - mDice: 0.8188 - val_loss: 1691.1914 - val_acc: 0.9561 - val_mDice: 0.6935

Epoch 00097: val_mDice did not improve from 0.71141
Epoch 98/300
 - 14s - loss: 971.8526 - acc: 0.9591 - mDice: 0.8201 - val_loss: 1750.5351 - val_acc: 0.9526 - val_mDice: 0.6826

Epoch 00098: val_mDice did not improve from 0.71141
Epoch 99/300
 - 14s - loss: 973.0534 - acc: 0.9590 - mDice: 0.8199 - val_loss: 1732.9780 - val_acc: 0.9532 - val_mDice: 0.6853

Epoch 00099: val_mDice did not improve from 0.71141
Epoch 100/300
 - 14s - loss: 979.1048 - acc: 0.9590 - mDice: 0.8191 - val_loss: 1793.2994 - val_acc: 0.9513 - val_mDice: 0.6767

Epoch 00100: val_mDice did not improve from 0.71141
Epoch 101/300
 - 14s - loss: 970.0246 - acc: 0.9591 - mDice: 0.8205 - val_loss: 1635.7151 - val_acc: 0.9572 - val_mDice: 0.7007

Epoch 00101: val_mDice did not improve from 0.71141
Epoch 102/300
 - 14s - loss: 966.0267 - acc: 0.9592 - mDice: 0.8211 - val_loss: 1629.7496 - val_acc: 0.9578 - val_mDice: 0.7028

Epoch 00102: val_mDice did not improve from 0.71141
Epoch 103/300
 - 14s - loss: 960.9594 - acc: 0.9592 - mDice: 0.8218 - val_loss: 1640.4071 - val_acc: 0.9574 - val_mDice: 0.6994

Epoch 00103: val_mDice did not improve from 0.71141
Epoch 104/300
 - 13s - loss: 963.7301 - acc: 0.9592 - mDice: 0.8215 - val_loss: 1622.6012 - val_acc: 0.9593 - val_mDice: 0.7035

Epoch 00104: val_mDice did not improve from 0.71141
Epoch 105/300
 - 15s - loss: 953.0353 - acc: 0.9594 - mDice: 0.8232 - val_loss: 1637.4266 - val_acc: 0.9581 - val_mDice: 0.7003

Epoch 00105: val_mDice did not improve from 0.71141
Epoch 106/300
 - 13s - loss: 954.8675 - acc: 0.9593 - mDice: 0.8229 - val_loss: 1667.7357 - val_acc: 0.9569 - val_mDice: 0.6957

Epoch 00106: val_mDice did not improve from 0.71141
Epoch 107/300
 - 14s - loss: 956.4548 - acc: 0.9594 - mDice: 0.8227 - val_loss: 1687.6319 - val_acc: 0.9590 - val_mDice: 0.6951

Epoch 00107: val_mDice did not improve from 0.71141
Epoch 108/300
 - 13s - loss: 953.4559 - acc: 0.9594 - mDice: 0.8232 - val_loss: 1637.4474 - val_acc: 0.9592 - val_mDice: 0.7018

Epoch 00108: val_mDice did not improve from 0.71141
Epoch 109/300
 - 14s - loss: 952.5050 - acc: 0.9594 - mDice: 0.8234 - val_loss: 1683.5654 - val_acc: 0.9582 - val_mDice: 0.6954

Epoch 00109: val_mDice did not improve from 0.71141
Epoch 110/300
 - 14s - loss: 953.2454 - acc: 0.9595 - mDice: 0.8235 - val_loss: 1759.6622 - val_acc: 0.9545 - val_mDice: 0.6831

Epoch 00110: val_mDice did not improve from 0.71141
Epoch 111/300
 - 14s - loss: 949.2244 - acc: 0.9595 - mDice: 0.8239 - val_loss: 1653.5583 - val_acc: 0.9583 - val_mDice: 0.6994

Epoch 00111: val_mDice did not improve from 0.71141
Epoch 112/300
 - 14s - loss: 943.9194 - acc: 0.9596 - mDice: 0.8247 - val_loss: 1619.3247 - val_acc: 0.9590 - val_mDice: 0.7045

Epoch 00112: val_mDice did not improve from 0.71141
Epoch 113/300
 - 13s - loss: 942.5777 - acc: 0.9596 - mDice: 0.8250 - val_loss: 1609.5864 - val_acc: 0.9586 - val_mDice: 0.7048

Epoch 00113: val_mDice did not improve from 0.71141
Epoch 114/300
 - 14s - loss: 941.9532 - acc: 0.9596 - mDice: 0.8251 - val_loss: 2134.5495 - val_acc: 0.9540 - val_mDice: 0.6444

Epoch 00114: val_mDice did not improve from 0.71141
Epoch 115/300
 - 13s - loss: 939.8842 - acc: 0.9597 - mDice: 0.8255 - val_loss: 1623.3176 - val_acc: 0.9596 - val_mDice: 0.7018

Epoch 00115: val_mDice did not improve from 0.71141
Epoch 116/300
 - 14s - loss: 939.6439 - acc: 0.9596 - mDice: 0.8255 - val_loss: 1654.5485 - val_acc: 0.9574 - val_mDice: 0.6979

Epoch 00116: val_mDice did not improve from 0.71141
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [5763.843561769442, 4086.5296211533873, 2902.9667577379532, 2516.657401747376, 2389.5735254651718, 2187.7077142846492, 2067.3274540791986, 2023.7573354007634, 1960.6364867232228, 1897.6587529073236, 1919.7384508438693, 1813.021999679449, 1781.9196106422949, 1733.4212441480797, 1719.0596075858778, 1747.5206951112239, 1730.7412202558444, 1713.8058504293892, 1691.3815899332062, 1769.6671282353293, 1648.780143912512, 1637.5937267041388, 1702.9352412333014, 1629.1583130814647, 1762.1553740756203, 1681.3019991576216, 1638.2118767891222, 1619.3488657711116, 1641.167499105439, 1681.9515194492485, 1635.5942410767534, 1679.981384743261, 1600.1639609300453, 1710.4159187142175, 1606.4360910663167, 1633.3935313916388, 1644.6012419489505, 1631.61913223849, 1597.2660079839575, 1739.0018785782443, 1714.282128719883, 1635.1437158948593, 1684.1881066242247, 1637.4167089098282, 1756.9654326693703, 1584.225732235508, 1711.020125760377, 1650.5911278178673, 1606.4978698264551, 1589.7609574412572, 1923.172735083194, 1622.562900688812, 1686.6384957582895, 1595.3450694775763, 1690.7807319000476, 1607.6292389148973, 1680.3411380680463, 1659.3739563454199, 4387.892026479008, 1606.9397857898973, 1589.3186268114862, 1634.886097216424, 1591.052400778268, 1612.1834139059517, 1593.7038453080272, 1641.5746977129056, 1607.2991281756917, 1771.4112381097925, 1625.0070670324428, 1678.2758500193822, 1593.490774838979, 1670.005291887822, 1598.6810945700142, 1616.1609464456108, 1615.1939986134303, 1600.7623141922113, 1625.3857999612358, 1598.5320513776242, 1691.7954930895157, 1659.1455096761688, 1596.8155713263359, 1637.1567541224356, 1614.7216125954199, 1619.3314903201037, 1592.2950635138359, 1563.1098208827827, 1709.584871481393, 1576.9286019128697, 1688.734952737357, 1667.5846236134303, 1588.173176772722, 1671.1886787705748, 1620.238542163645, 1647.6722878026599, 1608.8586984881917, 1623.4717281428912, 1691.1913503399333, 1750.5350779759065, 1732.977991934041, 1793.2993667253102, 1635.7151037318106, 1629.7496086295325, 1640.407078400823, 1622.601201880069, 1637.4266180373331, 1667.735685159232, 1687.6318825292224, 1637.4474026046637, 1683.5653570044133, 1759.6621568985568, 1653.5583160633348, 1619.3246697578722, 1609.5864052808922, 2134.549539114683, 1623.3175896797472, 1654.5484703005725], 'val_acc': [0.8654001437070715, 0.8859224797205161, 0.9161942719503213, 0.9272889490345962, 0.9266862195866709, 0.9343282994423204, 0.9401847378898213, 0.9409031972630333, 0.9422949830084356, 0.9453015655051661, 0.9446833060897943, 0.9479256117616901, 0.9492976215049511, 0.9493681879443977, 0.94918470118792, 0.9493554766851527, 0.9519061423440016, 0.9519075482856226, 0.9526641478065316, 0.9509251267855404, 0.9545555910991348, 0.9539190066679744, 0.9530664204641153, 0.954446918636788, 0.9519851890229086, 0.9530268930296861, 0.954739100605477, 0.9563948207229148, 0.9547023905142573, 0.9553079286604437, 0.954971995972495, 0.9556523611527363, 0.9584020408055255, 0.9544666573291517, 0.9571048389864332, 0.9576228761490975, 0.958011017045902, 0.9587803210010966, 0.9575367451624106, 0.9541504883584175, 0.9540841420188205, 0.9585107200928317, 0.9577386165393218, 0.9569904740530116, 0.956567017176679, 0.9585855266520085, 0.9536536203995916, 0.9566023040363807, 0.957758373431577, 0.9565585574120966, 0.9466368665221994, 0.9594988126791161, 0.9558880897878691, 0.9586250522664486, 0.9571895230817431, 0.9590626286186335, 0.9548209646275936, 0.9584118987767751, 0.9403583530251306, 0.9570624873838351, 0.9590979095633704, 0.9580392678275363, 0.9599561168037298, 0.9584062727353045, 0.9584048636087025, 0.9573236130576097, 0.9597641716476615, 0.9510352402242995, 0.9602073835962601, 0.9554745090826777, 0.9588000724333843, 0.957725902550093, 0.9580223287334879, 0.9587633723521051, 0.9580110370657826, 0.958241103714659, 0.9581451247666628, 0.9583850798716071, 0.9565656303449441, 0.9583511989535266, 0.9555676483925972, 0.9567166562298782, 0.9580110352457935, 0.9586547071697148, 0.9580943029345447, 0.9588791236622642, 0.9559092558067264, 0.9593435275645656, 0.9546007473050183, 0.9565514922142029, 0.9594169372820672, 0.9585177943906711, 0.9593477590393474, 0.9576186128245056, 0.9589892343710397, 0.9583737950288612, 0.9561478199849602, 0.9526387293830173, 0.9531850054973864, 0.9513203547201083, 0.9571824510588901, 0.9578402433686584, 0.9573603117738971, 0.9592545865146258, 0.9581310275856775, 0.9569410768174033, 0.9589807623215304, 0.9591515523786763, 0.9582467552359778, 0.9544779599167919, 0.9583060404726567, 0.9589567694045206, 0.9585855312019814, 0.9539853370826663, 0.9595693741135924, 0.9574238253003768], 'val_mDice': [0.33441733995466744, 0.4334812949176963, 0.5350652742021866, 0.5748390678231042, 0.5920337929980446, 0.6190345446572049, 0.6336170871749179, 0.6450297295592213, 0.6516829383282261, 0.6602466957259724, 0.6571158821346196, 0.674550177031801, 0.6784696474330116, 0.6835096200913874, 0.6848025599508795, 0.6804568257950644, 0.6853210562058077, 0.6871225251496293, 0.6917141666849151, 0.6799318995184571, 0.6968980995753339, 0.6991050065928743, 0.6896280541674782, 0.7015017343841436, 0.6811749125254973, 0.6918304853766929, 0.6997326348574107, 0.7028616735043417, 0.6991919597596613, 0.6956528270517597, 0.7001852579699218, 0.6933168018137226, 0.7062306868211004, 0.6901215669762997, 0.705478791972153, 0.7020376342853517, 0.6986305932052262, 0.7025976481328484, 0.706633020903318, 0.6857874161414518, 0.6880688307849505, 0.6996549195005693, 0.692648844409535, 0.7011025752730042, 0.6860587742492443, 0.7072745256751548, 0.6863849640802573, 0.6997489132953965, 0.7040584606068735, 0.7053554690521182, 0.6571579648338202, 0.7027795847135646, 0.6924072340244555, 0.7058165592091684, 0.6919950237710968, 0.7048061135161015, 0.6923902817354858, 0.6970833994960057, 0.5264559683908943, 0.7053258127838601, 0.7067338569473675, 0.7009379172143135, 0.7079946630783663, 0.7035277927194843, 0.706617642904966, 0.6994093256142303, 0.7048853353689645, 0.6792433425670362, 0.702418168082492, 0.694582927773017, 0.7072482946264835, 0.6942051471644686, 0.7060482188035514, 0.7037718778348151, 0.7039245894847025, 0.7058567836994433, 0.7006040998087585, 0.7068415943902867, 0.6932147522919051, 0.6986247910798051, 0.7064956308321189, 0.7002357972487239, 0.7032105786199788, 0.7045740039294003, 0.706282907314883, 0.7114121445262706, 0.689142202602998, 0.7090047506885674, 0.6920576914576174, 0.6947868780325387, 0.708577227956466, 0.6971348000846747, 0.703903345661309, 0.6985101185682165, 0.7048100119328681, 0.7029818014334176, 0.6935448628345519, 0.6825991914472507, 0.6853170731595455, 0.6766941065096673, 0.7007164727640516, 0.7027528222280605, 0.6993925607841434, 0.703472079211519, 0.700347657422073, 0.6957114056776498, 0.6950533849592427, 0.7017882980463159, 0.6953761081659157, 0.6830932989375282, 0.6994421582185585, 0.7045484317168025, 0.7048173514941266, 0.6444231194394235, 0.7017545572674001, 0.69791150866574], 'loss': [13081.24053317344, 5354.93811833736, 4033.63259355953, 3371.717502399069, 2930.902780542778, 2655.958017692174, 2455.9280887588707, 2310.760562117586, 2188.7119117523866, 2089.98553349656, 2017.971251858675, 1941.1152243050465, 1887.0173426450701, 1825.7169557763084, 1770.1293759670962, 1731.2047197749887, 1679.4389477810212, 1645.1039457015029, 1605.4702867144379, 1584.1164583634213, 1550.382328847896, 1525.8548678797133, 1490.9432822641902, 1475.5634092050066, 1447.9755901741944, 1428.608225073455, 1407.2760563300887, 1388.654515565728, 1373.2213019245094, 1363.2065588006078, 1339.6332190710255, 1325.5810941021361, 1314.1458481275727, 1295.488020118001, 1283.371589889203, 1265.8975252178154, 1255.423412405688, 1289.6418482897384, 1229.5156937712113, 1222.9035561001476, 1216.0971163509475, 1212.5067774919303, 1193.6267225863935, 1232.5824282594754, 1181.1342996213293, 1169.3208035670623, 1163.3545627663677, 1156.753561907838, 1144.5564309457952, 1132.037850630011, 1136.4300060042729, 1115.6559028259423, 1116.8991834495657, 1108.3395011798168, 1112.3231719594603, 1097.9938153167448, 1097.201792697887, 1087.0500598821807, 1101.4299346494213, 1103.1200600828067, 1073.7338554623518, 1063.9044305285834, 1063.4773300819782, 1062.0629902568874, 1049.3009344414338, 1049.8856338440771, 1040.2020406009938, 1039.2494357005614, 1032.7787507472638, 1035.7715387280716, 1027.6828901718372, 1021.9483156711048, 1339.874312240316, 1106.8473699059534, 1062.642108161135, 1046.1089180346105, 1030.8213112895362, 1024.5969670320012, 1020.4029390635275, 1115.695329042433, 1028.5725495087909, 1011.5954077575377, 1007.172701293642, 997.3492857643955, 991.2028774239362, 992.4023546791848, 991.3403457180025, 982.7171715801379, 984.7757643683341, 987.3607150812784, 982.14340227651, 988.245234191618, 981.7077597354656, 977.3087627762645, 974.7871019213911, 982.2713108459469, 979.8413539665163, 971.8526475218746, 973.0533670056284, 979.1048240083721, 970.0245581175396, 966.0267012441575, 960.9594005819035, 963.7300632834881, 953.0352998962358, 954.8675484500037, 956.4547580955171, 953.4559209075591, 952.5049676400396, 953.2454384151498, 949.2243504758131, 943.9194485544839, 942.5777093014998, 941.9532107581258, 939.8841629648958, 939.6438616070154], 'acc': [0.8667243277952833, 0.8984847270052829, 0.9126285412086363, 0.9212878716950689, 0.9271595445945855, 0.931044903623883, 0.9339738865237571, 0.9361556049236175, 0.9380737476675456, 0.939703587808288, 0.9410325450348815, 0.9422573053869921, 0.9433385636647496, 0.9443432218501557, 0.9451184614907052, 0.9458793110793817, 0.9466272621375679, 0.9472888114652235, 0.9479599652151444, 0.9483881171665176, 0.9490211707297556, 0.9495339914782547, 0.9500400425019804, 0.9502979238949968, 0.9508433867327754, 0.9511777585785797, 0.9516219435958067, 0.9519431271597869, 0.952238548588222, 0.9524826857349052, 0.9528975783254291, 0.9531044218339157, 0.9533578169474187, 0.9536193355535403, 0.9538781163933924, 0.9541100736245984, 0.9543725083258597, 0.9544368382290908, 0.9547282622557213, 0.9549159373674491, 0.9550928599539802, 0.9552157911847156, 0.955437623706573, 0.9554103670155545, 0.9556874687797439, 0.9558932679918588, 0.9560870348556489, 0.9561686214808859, 0.9563011204228375, 0.9564706036273256, 0.9565372730644002, 0.9568345507235678, 0.9567380117611679, 0.9569116368598739, 0.9570217072118815, 0.9570709563328291, 0.9571942325527747, 0.9572852792269047, 0.9570054383492516, 0.9570320284606432, 0.9574467417320347, 0.9576629546557454, 0.9576866605660554, 0.957724130254115, 0.9578224203718859, 0.9578103510163612, 0.9579147633751797, 0.9579633842767014, 0.9581711839071013, 0.9581363081897226, 0.9582514923961066, 0.9583102913489094, 0.9520324635240883, 0.9565973193508783, 0.95742674810608, 0.9578119351428461, 0.9579972888323665, 0.9581783171304917, 0.9583184893233806, 0.9566020915375757, 0.958143475627207, 0.9583068707118317, 0.9584850884022764, 0.9586201631800454, 0.9587723479836989, 0.9587188113350696, 0.9587449486758869, 0.9587406467065128, 0.958860333352937, 0.9587493995886421, 0.9588578852305741, 0.958734286157217, 0.9588553254652769, 0.9589330581852439, 0.9590184839285496, 0.9589774976332274, 0.9589119827389061, 0.9591194188474615, 0.9590001992303877, 0.9590037848116842, 0.9590790521280352, 0.9591950471451502, 0.9592343333042849, 0.9592282485175664, 0.9593864889864717, 0.9593300836527248, 0.9593973679911626, 0.9594057810231641, 0.9594043024365904, 0.959457195004321, 0.9594929001550713, 0.9595945382194876, 0.9596266748843745, 0.9596484190037168, 0.9596985004556656, 0.9596063925726472], 'mDice': [0.19791117237357392, 0.373251794505743, 0.46265036570903323, 0.5200314332891982, 0.5623577810122374, 0.5910587289944342, 0.6131628667090557, 0.6304662055514909, 0.6452509351385001, 0.6574970851122673, 0.6670306427537207, 0.6767723810609465, 0.6841730713855914, 0.6922955128585516, 0.7001497976017728, 0.7053151046302409, 0.7122507551118352, 0.7171174334541346, 0.7227338298743673, 0.7258861829501816, 0.7306866363657044, 0.7342986369296749, 0.7391386078065889, 0.7417245803942456, 0.7456494076658813, 0.7484208469041528, 0.7517319590635763, 0.7545430189136221, 0.7568740117706101, 0.7586419672257333, 0.7620380267960346, 0.7640158609307058, 0.7657380286603984, 0.7686099148167109, 0.7706116659502249, 0.7730980486968296, 0.7747513628736487, 0.7744944155073948, 0.7787788476787881, 0.7798871534056169, 0.7810965717126277, 0.7815483591224279, 0.7844338611438286, 0.7833334710758377, 0.7864109861606269, 0.7882784393772216, 0.7892350242375875, 0.7901858192335887, 0.7921479349913544, 0.7940708516059729, 0.7935053098625072, 0.7967679277363647, 0.7965213039474287, 0.7979431989433483, 0.7972816072139083, 0.7996016935242083, 0.7997244203994798, 0.8013344021098776, 0.7995760037132627, 0.7987982693124522, 0.8034569564178768, 0.8050193045431863, 0.8051376331914586, 0.805415764357391, 0.8074027103986131, 0.8073258903506345, 0.8088348036305033, 0.8090573439230392, 0.8101293890252894, 0.8096731454678382, 0.810959857666543, 0.8121285093783566, 0.7634480916331298, 0.7981491636977901, 0.8052070884757084, 0.8079510256535556, 0.8104018116317854, 0.8114389334380455, 0.8128054327992423, 0.7971619366031631, 0.8107964563221095, 0.8135554654586971, 0.8142802886023571, 0.8158670075307071, 0.8168509245394987, 0.8167644966664274, 0.8168733807672532, 0.818292585709073, 0.817986244453632, 0.8175338360539622, 0.8184456260334737, 0.8174324865998293, 0.8185487021031339, 0.8192261888806776, 0.819652612561565, 0.8187296098099338, 0.8187516859952911, 0.8201489711598696, 0.819913028570313, 0.8191089185668917, 0.8204667077845422, 0.8210738588049569, 0.8218250633755211, 0.821528908335824, 0.8232377821973264, 0.8229395908006093, 0.8226537770172538, 0.8231500048709163, 0.8234374972818029, 0.8235474884251635, 0.8239439013546781, 0.824749332758436, 0.8250086761565011, 0.8251108496610348, 0.825484686479908, 0.8254777077048142]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:44, 14.94s/it]predicting test subjects:  50%|█████     | 2/4 [00:28<00:28, 14.40s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:42<00:14, 14.51s/it]predicting test subjects: 100%|██████████| 4/4 [00:56<00:00, 14.24s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:47:59, 20.90s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:30:24, 17.55s/it]predicting train subjects:   1%|          | 3/311 [00:43<1:22:37, 16.10s/it]predicting train subjects:   1%|▏         | 4/311 [00:55<1:16:32, 14.96s/it]predicting train subjects:   2%|▏         | 5/311 [01:06<1:10:40, 13.86s/it]predicting train subjects:   2%|▏         | 6/311 [01:17<1:06:08, 13.01s/it]predicting train subjects:   2%|▏         | 7/311 [01:30<1:05:28, 12.92s/it]predicting train subjects:   3%|▎         | 8/311 [01:45<1:08:46, 13.62s/it]predicting train subjects:   3%|▎         | 9/311 [01:59<1:08:40, 13.65s/it]predicting train subjects:   3%|▎         | 10/311 [02:11<1:05:52, 13.13s/it]predicting train subjects:   4%|▎         | 11/311 [02:26<1:08:44, 13.75s/it]predicting train subjects:   4%|▍         | 12/311 [02:38<1:05:56, 13.23s/it]predicting train subjects:   4%|▍         | 13/311 [02:50<1:03:32, 12.79s/it]predicting train subjects:   5%|▍         | 14/311 [03:05<1:06:59, 13.53s/it]predicting train subjects:   5%|▍         | 15/311 [03:27<1:18:21, 15.88s/it]predicting train subjects:   5%|▌         | 16/311 [03:48<1:26:44, 17.64s/it]predicting train subjects:   5%|▌         | 17/311 [04:10<1:32:19, 18.84s/it]predicting train subjects:   6%|▌         | 18/311 [04:33<1:37:17, 19.92s/it]predicting train subjects:   6%|▌         | 19/311 [04:54<1:39:05, 20.36s/it]predicting train subjects:   6%|▋         | 20/311 [05:16<1:40:45, 20.78s/it]predicting train subjects:   7%|▋         | 21/311 [05:37<1:41:09, 20.93s/it]predicting train subjects:   7%|▋         | 22/311 [05:58<1:40:45, 20.92s/it]predicting train subjects:   7%|▋         | 23/311 [06:20<1:41:50, 21.22s/it]predicting train subjects:   8%|▊         | 24/311 [06:42<1:43:02, 21.54s/it]predicting train subjects:   8%|▊         | 25/311 [07:04<1:43:06, 21.63s/it]predicting train subjects:   8%|▊         | 26/311 [07:26<1:43:06, 21.71s/it]predicting train subjects:   9%|▊         | 27/311 [07:48<1:43:41, 21.91s/it]predicting train subjects:   9%|▉         | 28/311 [08:10<1:43:04, 21.85s/it]predicting train subjects:   9%|▉         | 29/311 [08:31<1:42:19, 21.77s/it]predicting train subjects:  10%|▉         | 30/311 [08:54<1:42:33, 21.90s/it]predicting train subjects:  10%|▉         | 31/311 [09:16<1:42:19, 21.93s/it]predicting train subjects:  10%|█         | 32/311 [09:38<1:41:54, 21.92s/it]predicting train subjects:  11%|█         | 33/311 [09:48<1:26:04, 18.58s/it]predicting train subjects:  11%|█         | 34/311 [09:58<1:14:03, 16.04s/it]predicting train subjects:  11%|█▏        | 35/311 [10:09<1:06:00, 14.35s/it]predicting train subjects:  12%|█▏        | 36/311 [10:19<1:00:26, 13.19s/it]predicting train subjects:  12%|█▏        | 37/311 [10:29<55:34, 12.17s/it]  predicting train subjects:  12%|█▏        | 38/311 [10:40<52:58, 11.64s/it]predicting train subjects:  13%|█▎        | 39/311 [10:50<50:39, 11.17s/it]predicting train subjects:  13%|█▎        | 40/311 [11:00<49:21, 10.93s/it]predicting train subjects:  13%|█▎        | 41/311 [11:11<48:41, 10.82s/it]predicting train subjects:  14%|█▎        | 42/311 [11:20<47:22, 10.57s/it]predicting train subjects:  14%|█▍        | 43/311 [11:31<47:07, 10.55s/it]predicting train subjects:  14%|█▍        | 44/311 [11:41<46:10, 10.38s/it]predicting train subjects:  14%|█▍        | 45/311 [11:51<45:49, 10.34s/it]predicting train subjects:  15%|█▍        | 46/311 [12:02<46:01, 10.42s/it]predicting train subjects:  15%|█▌        | 47/311 [12:12<45:07, 10.26s/it]predicting train subjects:  15%|█▌        | 48/311 [12:22<45:21, 10.35s/it]predicting train subjects:  16%|█▌        | 49/311 [12:33<45:11, 10.35s/it]predicting train subjects:  16%|█▌        | 50/311 [12:43<44:50, 10.31s/it]predicting train subjects:  16%|█▋        | 51/311 [12:57<49:05, 11.33s/it]predicting train subjects:  17%|█▋        | 52/311 [13:10<51:41, 11.97s/it]predicting train subjects:  17%|█▋        | 53/311 [13:23<52:27, 12.20s/it]predicting train subjects:  17%|█▋        | 54/311 [13:35<52:26, 12.24s/it]predicting train subjects:  18%|█▊        | 55/311 [13:48<52:44, 12.36s/it]predicting train subjects:  18%|█▊        | 56/311 [14:01<53:27, 12.58s/it]predicting train subjects:  18%|█▊        | 57/311 [14:14<53:37, 12.67s/it]predicting train subjects:  19%|█▊        | 58/311 [14:28<56:03, 13.29s/it]predicting train subjects:  19%|█▉        | 59/311 [14:43<57:39, 13.73s/it]predicting train subjects:  19%|█▉        | 60/311 [14:58<59:22, 14.19s/it]predicting train subjects:  20%|█▉        | 61/311 [15:13<59:29, 14.28s/it]predicting train subjects:  20%|█▉        | 62/311 [15:27<59:20, 14.30s/it]predicting train subjects:  20%|██        | 63/311 [15:41<58:21, 14.12s/it]predicting train subjects:  21%|██        | 64/311 [15:56<59:24, 14.43s/it]predicting train subjects:  21%|██        | 65/311 [16:11<59:48, 14.59s/it]predicting train subjects:  21%|██        | 66/311 [16:26<59:52, 14.66s/it]predicting train subjects:  22%|██▏       | 67/311 [16:40<58:20, 14.35s/it]predicting train subjects:  22%|██▏       | 68/311 [16:54<58:39, 14.48s/it]predicting train subjects:  22%|██▏       | 69/311 [17:09<59:06, 14.65s/it]predicting train subjects:  23%|██▎       | 70/311 [17:24<58:55, 14.67s/it]predicting train subjects:  23%|██▎       | 71/311 [17:39<58:54, 14.73s/it]predicting train subjects:  23%|██▎       | 72/311 [17:53<57:47, 14.51s/it]predicting train subjects:  23%|██▎       | 73/311 [18:08<57:38, 14.53s/it]predicting train subjects:  24%|██▍       | 74/311 [18:23<58:35, 14.83s/it]predicting train subjects:  24%|██▍       | 75/311 [18:39<59:01, 15.01s/it]predicting train subjects:  24%|██▍       | 76/311 [18:53<58:01, 14.81s/it]predicting train subjects:  25%|██▍       | 77/311 [19:08<58:23, 14.97s/it]predicting train subjects:  25%|██▌       | 78/311 [19:23<57:52, 14.90s/it]predicting train subjects:  25%|██▌       | 79/311 [19:36<55:52, 14.45s/it]predicting train subjects:  26%|██▌       | 80/311 [19:50<54:57, 14.27s/it]predicting train subjects:  26%|██▌       | 81/311 [20:04<53:52, 14.05s/it]predicting train subjects:  26%|██▋       | 82/311 [20:17<52:33, 13.77s/it]predicting train subjects:  27%|██▋       | 83/311 [20:30<51:55, 13.67s/it]predicting train subjects:  27%|██▋       | 84/311 [20:45<52:47, 13.96s/it]predicting train subjects:  27%|██▋       | 85/311 [20:58<52:02, 13.82s/it]predicting train subjects:  28%|██▊       | 86/311 [21:12<51:05, 13.62s/it]predicting train subjects:  28%|██▊       | 87/311 [21:25<50:10, 13.44s/it]predicting train subjects:  28%|██▊       | 88/311 [21:38<49:22, 13.28s/it]predicting train subjects:  29%|██▊       | 89/311 [21:49<46:56, 12.69s/it]predicting train subjects:  29%|██▉       | 90/311 [21:59<44:15, 12.02s/it]predicting train subjects:  29%|██▉       | 91/311 [22:10<42:56, 11.71s/it]predicting train subjects:  30%|██▉       | 92/311 [22:21<42:09, 11.55s/it]predicting train subjects:  30%|██▉       | 93/311 [22:32<41:23, 11.39s/it]predicting train subjects:  30%|███       | 94/311 [22:43<40:32, 11.21s/it]predicting train subjects:  31%|███       | 95/311 [22:55<40:26, 11.23s/it]predicting train subjects:  31%|███       | 96/311 [23:06<40:12, 11.22s/it]predicting train subjects:  31%|███       | 97/311 [23:16<39:26, 11.06s/it]predicting train subjects:  32%|███▏      | 98/311 [23:28<39:31, 11.13s/it]predicting train subjects:  32%|███▏      | 99/311 [23:39<39:22, 11.15s/it]predicting train subjects:  32%|███▏      | 100/311 [23:51<39:51, 11.33s/it]predicting train subjects:  32%|███▏      | 101/311 [24:01<39:08, 11.18s/it]predicting train subjects:  33%|███▎      | 102/311 [24:13<38:56, 11.18s/it]predicting train subjects:  33%|███▎      | 103/311 [24:24<38:58, 11.24s/it]predicting train subjects:  33%|███▎      | 104/311 [24:35<38:54, 11.28s/it]predicting train subjects:  34%|███▍      | 105/311 [24:47<38:47, 11.30s/it]predicting train subjects:  34%|███▍      | 106/311 [24:58<38:27, 11.26s/it]predicting train subjects:  34%|███▍      | 107/311 [25:09<38:06, 11.21s/it]predicting train subjects:  35%|███▍      | 108/311 [25:21<38:16, 11.31s/it]predicting train subjects:  35%|███▌      | 109/311 [25:32<38:01, 11.29s/it]predicting train subjects:  35%|███▌      | 110/311 [25:43<37:33, 11.21s/it]predicting train subjects:  36%|███▌      | 111/311 [25:54<37:17, 11.19s/it]predicting train subjects:  36%|███▌      | 112/311 [26:06<37:32, 11.32s/it]predicting train subjects:  36%|███▋      | 113/311 [26:17<37:24, 11.34s/it]predicting train subjects:  37%|███▋      | 114/311 [26:38<46:24, 14.13s/it]predicting train subjects:  37%|███▋      | 115/311 [26:59<53:19, 16.32s/it]predicting train subjects:  37%|███▋      | 116/311 [27:20<57:40, 17.75s/it]predicting train subjects:  38%|███▊      | 117/311 [27:42<1:00:58, 18.86s/it]predicting train subjects:  38%|███▊      | 118/311 [28:03<1:02:55, 19.56s/it]predicting train subjects:  38%|███▊      | 119/311 [28:24<1:04:12, 20.06s/it]predicting train subjects:  39%|███▊      | 120/311 [28:45<1:04:51, 20.38s/it]predicting train subjects:  39%|███▉      | 121/311 [29:06<1:05:19, 20.63s/it]predicting train subjects:  39%|███▉      | 122/311 [29:27<1:05:21, 20.75s/it]predicting train subjects:  40%|███▉      | 123/311 [29:49<1:05:31, 20.91s/it]predicting train subjects:  40%|███▉      | 124/311 [30:09<1:05:03, 20.88s/it]predicting train subjects:  40%|████      | 125/311 [30:32<1:05:56, 21.27s/it]predicting train subjects:  41%|████      | 126/311 [30:52<1:05:05, 21.11s/it]predicting train subjects:  41%|████      | 127/311 [31:14<1:04:56, 21.18s/it]predicting train subjects:  41%|████      | 128/311 [31:34<1:04:04, 21.01s/it]predicting train subjects:  41%|████▏     | 129/311 [31:55<1:03:10, 20.83s/it]predicting train subjects:  42%|████▏     | 130/311 [32:15<1:02:35, 20.75s/it]predicting train subjects:  42%|████▏     | 131/311 [32:37<1:03:15, 21.09s/it]predicting train subjects:  42%|████▏     | 132/311 [32:47<52:29, 17.59s/it]  predicting train subjects:  43%|████▎     | 133/311 [32:57<45:31, 15.34s/it]predicting train subjects:  43%|████▎     | 134/311 [33:07<40:32, 13.74s/it]predicting train subjects:  43%|████▎     | 135/311 [33:16<36:46, 12.54s/it]predicting train subjects:  44%|████▎     | 136/311 [33:28<35:18, 12.11s/it]predicting train subjects:  44%|████▍     | 137/311 [33:37<33:12, 11.45s/it]predicting train subjects:  44%|████▍     | 138/311 [33:47<31:30, 10.93s/it]predicting train subjects:  45%|████▍     | 139/311 [33:57<30:37, 10.68s/it]predicting train subjects:  45%|████▌     | 140/311 [34:07<29:40, 10.41s/it]predicting train subjects:  45%|████▌     | 141/311 [34:18<29:31, 10.42s/it]predicting train subjects:  46%|████▌     | 142/311 [34:28<29:10, 10.36s/it]predicting train subjects:  46%|████▌     | 143/311 [34:38<28:48, 10.29s/it]predicting train subjects:  46%|████▋     | 144/311 [34:48<28:09, 10.12s/it]predicting train subjects:  47%|████▋     | 145/311 [34:58<27:55, 10.09s/it]predicting train subjects:  47%|████▋     | 146/311 [35:08<27:41, 10.07s/it]predicting train subjects:  47%|████▋     | 147/311 [35:17<27:09,  9.94s/it]predicting train subjects:  48%|████▊     | 148/311 [35:27<26:55,  9.91s/it]predicting train subjects:  48%|████▊     | 149/311 [35:37<26:47,  9.92s/it]predicting train subjects:  48%|████▊     | 150/311 [35:49<28:37, 10.67s/it]predicting train subjects:  49%|████▊     | 151/311 [36:02<29:53, 11.21s/it]predicting train subjects:  49%|████▉     | 152/311 [36:14<30:43, 11.59s/it]predicting train subjects:  49%|████▉     | 153/311 [36:27<31:17, 11.89s/it]predicting train subjects:  50%|████▉     | 154/311 [36:40<31:38, 12.09s/it]predicting train subjects:  50%|████▉     | 155/311 [36:52<32:02, 12.32s/it]predicting train subjects:  50%|█████     | 156/311 [37:05<32:24, 12.55s/it]predicting train subjects:  50%|█████     | 157/311 [37:19<32:37, 12.71s/it]predicting train subjects:  51%|█████     | 158/311 [37:31<32:33, 12.77s/it]predicting train subjects:  51%|█████     | 159/311 [37:44<32:25, 12.80s/it]predicting train subjects:  51%|█████▏    | 160/311 [37:57<32:06, 12.76s/it]predicting train subjects:  52%|█████▏    | 161/311 [38:10<32:04, 12.83s/it]predicting train subjects:  52%|█████▏    | 162/311 [38:23<31:50, 12.83s/it]predicting train subjects:  52%|█████▏    | 163/311 [38:36<31:40, 12.84s/it]predicting train subjects:  53%|█████▎    | 164/311 [38:48<31:24, 12.82s/it]predicting train subjects:  53%|█████▎    | 165/311 [39:01<30:51, 12.68s/it]predicting train subjects:  53%|█████▎    | 166/311 [39:13<30:23, 12.57s/it]predicting train subjects:  54%|█████▎    | 167/311 [39:26<30:16, 12.62s/it]predicting train subjects:  54%|█████▍    | 168/311 [39:38<29:57, 12.57s/it]predicting train subjects:  54%|█████▍    | 169/311 [39:50<29:22, 12.41s/it]predicting train subjects:  55%|█████▍    | 170/311 [40:02<28:49, 12.27s/it]predicting train subjects:  55%|█████▍    | 171/311 [40:15<28:55, 12.39s/it]predicting train subjects:  55%|█████▌    | 172/311 [40:28<29:06, 12.56s/it]predicting train subjects:  56%|█████▌    | 173/311 [40:41<29:05, 12.65s/it]predicting train subjects:  56%|█████▌    | 174/311 [40:53<28:53, 12.66s/it]predicting train subjects:  56%|█████▋    | 175/311 [41:06<28:15, 12.47s/it]predicting train subjects:  57%|█████▋    | 176/311 [41:18<27:53, 12.40s/it]predicting train subjects:  57%|█████▋    | 177/311 [41:30<27:55, 12.51s/it]predicting train subjects:  57%|█████▋    | 178/311 [41:43<27:43, 12.51s/it]predicting train subjects:  58%|█████▊    | 179/311 [41:55<27:22, 12.44s/it]predicting train subjects:  58%|█████▊    | 180/311 [42:07<26:50, 12.30s/it]predicting train subjects:  58%|█████▊    | 181/311 [42:20<26:37, 12.29s/it]predicting train subjects:  59%|█████▊    | 182/311 [42:32<26:42, 12.42s/it]predicting train subjects:  59%|█████▉    | 183/311 [42:45<26:49, 12.58s/it]predicting train subjects:  59%|█████▉    | 184/311 [42:57<25:53, 12.24s/it]predicting train subjects:  59%|█████▉    | 185/311 [43:07<24:47, 11.81s/it]predicting train subjects:  60%|█████▉    | 186/311 [43:19<24:16, 11.66s/it]predicting train subjects:  60%|██████    | 187/311 [43:30<24:04, 11.65s/it]predicting train subjects:  60%|██████    | 188/311 [43:42<23:37, 11.52s/it]predicting train subjects:  61%|██████    | 189/311 [43:53<23:08, 11.38s/it]predicting train subjects:  61%|██████    | 190/311 [44:04<22:54, 11.36s/it]predicting train subjects:  61%|██████▏   | 191/311 [44:16<22:51, 11.43s/it]predicting train subjects:  62%|██████▏   | 192/311 [44:27<22:43, 11.46s/it]predicting train subjects:  62%|██████▏   | 193/311 [44:38<22:26, 11.41s/it]predicting train subjects:  62%|██████▏   | 194/311 [44:50<22:16, 11.42s/it]predicting train subjects:  63%|██████▎   | 195/311 [45:01<22:02, 11.40s/it]predicting train subjects:  63%|██████▎   | 196/311 [45:13<21:57, 11.45s/it]predicting train subjects:  63%|██████▎   | 197/311 [45:24<21:39, 11.40s/it]predicting train subjects:  64%|██████▎   | 198/311 [45:35<21:16, 11.30s/it]predicting train subjects:  64%|██████▍   | 199/311 [45:47<21:18, 11.42s/it]predicting train subjects:  64%|██████▍   | 200/311 [45:58<21:15, 11.49s/it]predicting train subjects:  65%|██████▍   | 201/311 [46:10<20:58, 11.44s/it]predicting train subjects:  65%|██████▍   | 202/311 [46:21<20:30, 11.29s/it]predicting train subjects:  65%|██████▌   | 203/311 [46:32<20:28, 11.37s/it]predicting train subjects:  66%|██████▌   | 204/311 [46:44<20:15, 11.36s/it]predicting train subjects:  66%|██████▌   | 205/311 [46:55<19:58, 11.31s/it]predicting train subjects:  66%|██████▌   | 206/311 [47:06<19:44, 11.28s/it]predicting train subjects:  67%|██████▋   | 207/311 [47:18<19:46, 11.41s/it]predicting train subjects:  67%|██████▋   | 208/311 [47:29<19:43, 11.49s/it]predicting train subjects:  67%|██████▋   | 209/311 [47:40<19:19, 11.37s/it]predicting train subjects:  68%|██████▊   | 210/311 [47:52<19:11, 11.40s/it]predicting train subjects:  68%|██████▊   | 211/311 [48:04<19:11, 11.51s/it]predicting train subjects:  68%|██████▊   | 212/311 [48:15<19:01, 11.53s/it]predicting train subjects:  68%|██████▊   | 213/311 [48:36<23:33, 14.42s/it]predicting train subjects:  69%|██████▉   | 214/311 [48:59<27:08, 16.79s/it]predicting train subjects:  69%|██████▉   | 215/311 [49:22<30:02, 18.78s/it]predicting train subjects:  69%|██████▉   | 216/311 [49:50<33:53, 21.41s/it]predicting train subjects:  70%|██████▉   | 217/311 [50:16<35:38, 22.76s/it]predicting train subjects:  70%|███████   | 218/311 [50:43<37:24, 24.13s/it]predicting train subjects:  70%|███████   | 219/311 [51:09<37:49, 24.66s/it]predicting train subjects:  71%|███████   | 220/311 [51:35<38:15, 25.23s/it]predicting train subjects:  71%|███████   | 221/311 [52:01<37:56, 25.30s/it]predicting train subjects:  71%|███████▏  | 222/311 [52:29<38:41, 26.08s/it]predicting train subjects:  72%|███████▏  | 223/311 [52:53<37:36, 25.64s/it]predicting train subjects:  72%|███████▏  | 224/311 [53:20<37:21, 25.77s/it]predicting train subjects:  72%|███████▏  | 225/311 [53:46<37:13, 25.97s/it]predicting train subjects:  73%|███████▎  | 226/311 [54:10<35:59, 25.40s/it]predicting train subjects:  73%|███████▎  | 227/311 [54:37<36:07, 25.80s/it]predicting train subjects:  73%|███████▎  | 228/311 [55:03<35:58, 26.00s/it]predicting train subjects:  74%|███████▎  | 229/311 [55:30<35:54, 26.28s/it]predicting train subjects:  74%|███████▍  | 230/311 [55:52<33:33, 24.86s/it]predicting train subjects:  74%|███████▍  | 231/311 [56:02<27:15, 20.45s/it]predicting train subjects:  75%|███████▍  | 232/311 [56:12<22:41, 17.23s/it]predicting train subjects:  75%|███████▍  | 233/311 [56:21<19:27, 14.97s/it]predicting train subjects:  75%|███████▌  | 234/311 [56:31<17:18, 13.48s/it]predicting train subjects:  76%|███████▌  | 235/311 [56:41<15:34, 12.30s/it]predicting train subjects:  76%|███████▌  | 236/311 [56:51<14:28, 11.57s/it]predicting train subjects:  76%|███████▌  | 237/311 [57:01<13:45, 11.15s/it]predicting train subjects:  77%|███████▋  | 238/311 [57:10<12:59, 10.68s/it]predicting train subjects:  77%|███████▋  | 239/311 [57:20<12:30, 10.42s/it]predicting train subjects:  77%|███████▋  | 240/311 [57:30<12:13, 10.32s/it]predicting train subjects:  77%|███████▋  | 241/311 [57:40<11:49, 10.13s/it]predicting train subjects:  78%|███████▊  | 242/311 [57:50<11:33, 10.04s/it]predicting train subjects:  78%|███████▊  | 243/311 [58:00<11:24, 10.07s/it]predicting train subjects:  78%|███████▊  | 244/311 [58:10<11:06,  9.95s/it]predicting train subjects:  79%|███████▉  | 245/311 [58:20<11:01, 10.03s/it]predicting train subjects:  79%|███████▉  | 246/311 [58:30<10:51, 10.02s/it]predicting train subjects:  79%|███████▉  | 247/311 [58:40<10:41, 10.02s/it]predicting train subjects:  80%|███████▉  | 248/311 [58:50<10:26,  9.94s/it]predicting train subjects:  80%|████████  | 249/311 [59:03<11:12, 10.85s/it]predicting train subjects:  80%|████████  | 250/311 [59:16<11:41, 11.50s/it]predicting train subjects:  81%|████████  | 251/311 [59:28<11:53, 11.88s/it]predicting train subjects:  81%|████████  | 252/311 [59:41<11:51, 12.07s/it]predicting train subjects:  81%|████████▏ | 253/311 [59:53<11:41, 12.09s/it]predicting train subjects:  82%|████████▏ | 254/311 [1:00:06<11:42, 12.33s/it]predicting train subjects:  82%|████████▏ | 255/311 [1:00:19<11:40, 12.51s/it]predicting train subjects:  82%|████████▏ | 256/311 [1:00:32<11:31, 12.57s/it]predicting train subjects:  83%|████████▎ | 257/311 [1:00:44<11:23, 12.66s/it]predicting train subjects:  83%|████████▎ | 258/311 [1:00:57<11:11, 12.66s/it]predicting train subjects:  83%|████████▎ | 259/311 [1:01:10<10:55, 12.60s/it]predicting train subjects:  84%|████████▎ | 260/311 [1:01:22<10:38, 12.53s/it]predicting train subjects:  84%|████████▍ | 261/311 [1:01:34<10:25, 12.50s/it]predicting train subjects:  84%|████████▍ | 262/311 [1:01:48<10:21, 12.68s/it]predicting train subjects:  85%|████████▍ | 263/311 [1:02:00<10:08, 12.68s/it]predicting train subjects:  85%|████████▍ | 264/311 [1:02:13<09:54, 12.65s/it]predicting train subjects:  85%|████████▌ | 265/311 [1:02:25<09:35, 12.52s/it]predicting train subjects:  86%|████████▌ | 266/311 [1:02:37<09:20, 12.47s/it]predicting train subjects:  86%|████████▌ | 267/311 [1:02:50<09:07, 12.45s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:03:02<08:52, 12.38s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:03:14<08:36, 12.30s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:03:26<08:23, 12.28s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:03:38<08:06, 12.15s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:03:50<07:51, 12.10s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:04:02<07:42, 12.16s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:04:15<07:36, 12.34s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:04:28<07:24, 12.35s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:04:40<07:09, 12.28s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:04:52<06:53, 12.16s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:05:03<06:38, 12.09s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:05:16<06:30, 12.20s/it]predicting train subjects:  90%|█████████ | 280/311 [1:05:29<06:21, 12.32s/it]predicting train subjects:  90%|█████████ | 281/311 [1:05:41<06:09, 12.33s/it]predicting train subjects:  91%|█████████ | 282/311 [1:05:53<05:55, 12.25s/it]predicting train subjects:  91%|█████████ | 283/311 [1:06:04<05:30, 11.80s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:06:15<05:15, 11.67s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:06:27<05:08, 11.87s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:06:39<04:53, 11.75s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:06:50<04:35, 11.47s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:07:01<04:20, 11.33s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:07:12<04:09, 11.34s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:07:23<03:58, 11.37s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:07:34<03:44, 11.21s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:07:46<03:36, 11.38s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:07:57<03:22, 11.26s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:08:08<03:10, 11.22s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:08:19<02:59, 11.19s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:08:30<02:46, 11.10s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:08:41<02:35, 11.12s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:08:52<02:24, 11.08s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:09:03<02:10, 10.89s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:09:14<02:02, 11.12s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:09:26<01:51, 11.18s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:09:37<01:40, 11.18s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:09:48<01:29, 11.13s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:10:00<01:18, 11.27s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:10:11<01:07, 11.32s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:10:22<00:56, 11.35s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:10:34<00:45, 11.28s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:10:45<00:33, 11.19s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:10:56<00:22, 11.21s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:11:07<00:11, 11.32s/it]predicting train subjects: 100%|██████████| 311/311 [1:11:18<00:00, 11.23s/it]
Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:16<1:23:25, 16.15s/it]Loading train:   1%|          | 2/311 [00:24<1:11:18, 13.85s/it]Loading train:   1%|          | 3/311 [00:35<1:05:50, 12.83s/it]Loading train:   1%|▏         | 4/311 [00:45<1:01:29, 12.02s/it]Loading train:   2%|▏         | 5/311 [00:54<57:13, 11.22s/it]  Loading train:   2%|▏         | 6/311 [01:03<54:12, 10.66s/it]Loading train:   2%|▏         | 7/311 [01:14<54:24, 10.74s/it]Loading train:   3%|▎         | 8/311 [01:27<56:48, 11.25s/it]Loading train:   3%|▎         | 9/311 [01:38<57:10, 11.36s/it]Loading train:   3%|▎         | 10/311 [01:48<54:28, 10.86s/it]Loading train:   4%|▎         | 11/311 [02:00<56:29, 11.30s/it]Loading train:   4%|▍         | 12/311 [02:10<53:47, 10.80s/it]Loading train:   4%|▍         | 13/311 [02:20<51:38, 10.40s/it]Loading train:   5%|▍         | 14/311 [02:32<54:23, 10.99s/it]Loading train:   5%|▍         | 15/311 [02:41<52:08, 10.57s/it]Loading train:   5%|▌         | 16/311 [02:50<49:37, 10.09s/it]Loading train:   5%|▌         | 17/311 [03:00<48:23,  9.88s/it]Loading train:   6%|▌         | 18/311 [03:09<46:54,  9.61s/it]Loading train:   6%|▌         | 19/311 [03:18<46:39,  9.59s/it]Loading train:   6%|▋         | 20/311 [03:27<45:38,  9.41s/it]Loading train:   7%|▋         | 21/311 [03:37<45:15,  9.36s/it]Loading train:   7%|▋         | 22/311 [03:46<45:06,  9.37s/it]Loading train:   7%|▋         | 23/311 [03:55<44:29,  9.27s/it]Loading train:   8%|▊         | 24/311 [04:04<44:20,  9.27s/it]Loading train:   8%|▊         | 25/311 [04:13<43:55,  9.22s/it]Loading train:   8%|▊         | 26/311 [04:23<44:10,  9.30s/it]Loading train:   9%|▊         | 27/311 [04:32<44:01,  9.30s/it]Loading train:   9%|▉         | 28/311 [04:41<43:40,  9.26s/it]Loading train:   9%|▉         | 29/311 [04:51<43:45,  9.31s/it]Loading train:  10%|▉         | 30/311 [05:00<43:18,  9.25s/it]Loading train:  10%|▉         | 31/311 [05:09<43:17,  9.28s/it]Loading train:  10%|█         | 32/311 [05:19<43:27,  9.34s/it]Loading train:  11%|█         | 33/311 [05:23<36:43,  7.93s/it]Loading train:  11%|█         | 34/311 [05:28<31:43,  6.87s/it]Loading train:  11%|█▏        | 35/311 [05:32<28:17,  6.15s/it]Loading train:  12%|█▏        | 36/311 [05:37<26:06,  5.70s/it]Loading train:  12%|█▏        | 37/311 [05:42<24:47,  5.43s/it]Loading train:  12%|█▏        | 38/311 [05:46<23:25,  5.15s/it]Loading train:  13%|█▎        | 39/311 [05:51<22:37,  4.99s/it]Loading train:  13%|█▎        | 40/311 [05:55<21:41,  4.80s/it]Loading train:  13%|█▎        | 41/311 [06:00<21:26,  4.76s/it]Loading train:  14%|█▎        | 42/311 [06:04<21:09,  4.72s/it]Loading train:  14%|█▍        | 43/311 [06:09<20:45,  4.65s/it]Loading train:  14%|█▍        | 44/311 [06:13<20:28,  4.60s/it]Loading train:  14%|█▍        | 45/311 [06:18<20:05,  4.53s/it]Loading train:  15%|█▍        | 46/311 [06:22<20:15,  4.59s/it]Loading train:  15%|█▌        | 47/311 [06:27<19:58,  4.54s/it]Loading train:  15%|█▌        | 48/311 [06:31<19:57,  4.55s/it]Loading train:  16%|█▌        | 49/311 [06:36<19:29,  4.46s/it]Loading train:  16%|█▌        | 50/311 [06:40<19:37,  4.51s/it]Loading train:  16%|█▋        | 51/311 [06:46<21:10,  4.89s/it]Loading train:  17%|█▋        | 52/311 [06:52<21:48,  5.05s/it]Loading train:  17%|█▋        | 53/311 [06:57<22:08,  5.15s/it]Loading train:  17%|█▋        | 54/311 [07:03<22:51,  5.34s/it]Loading train:  18%|█▊        | 55/311 [07:08<23:02,  5.40s/it]Loading train:  18%|█▊        | 56/311 [07:14<23:06,  5.44s/it]Loading train:  18%|█▊        | 57/311 [07:19<23:15,  5.49s/it]Loading train:  19%|█▊        | 58/311 [07:25<23:20,  5.53s/it]Loading train:  19%|█▉        | 59/311 [07:31<23:12,  5.53s/it]Loading train:  19%|█▉        | 60/311 [07:36<23:23,  5.59s/it]Loading train:  20%|█▉        | 61/311 [07:42<23:23,  5.61s/it]Loading train:  20%|█▉        | 62/311 [07:48<23:21,  5.63s/it]Loading train:  20%|██        | 63/311 [07:53<23:22,  5.66s/it]Loading train:  21%|██        | 64/311 [07:59<23:18,  5.66s/it]Loading train:  21%|██        | 65/311 [08:05<23:18,  5.69s/it]Loading train:  21%|██        | 66/311 [08:10<23:09,  5.67s/it]Loading train:  22%|██▏       | 67/311 [08:16<23:01,  5.66s/it]Loading train:  22%|██▏       | 68/311 [08:22<22:47,  5.63s/it]Loading train:  22%|██▏       | 69/311 [08:27<22:20,  5.54s/it]Loading train:  23%|██▎       | 70/311 [08:33<22:24,  5.58s/it]Loading train:  23%|██▎       | 71/311 [08:38<22:27,  5.61s/it]Loading train:  23%|██▎       | 72/311 [08:44<22:17,  5.60s/it]Loading train:  23%|██▎       | 73/311 [08:49<22:10,  5.59s/it]Loading train:  24%|██▍       | 74/311 [08:55<22:19,  5.65s/it]Loading train:  24%|██▍       | 75/311 [09:01<22:18,  5.67s/it]Loading train:  24%|██▍       | 76/311 [09:07<22:20,  5.70s/it]Loading train:  25%|██▍       | 77/311 [09:12<22:18,  5.72s/it]Loading train:  25%|██▌       | 78/311 [09:18<21:51,  5.63s/it]Loading train:  25%|██▌       | 79/311 [09:23<21:21,  5.52s/it]Loading train:  26%|██▌       | 80/311 [09:29<21:15,  5.52s/it]Loading train:  26%|██▌       | 81/311 [09:34<21:20,  5.57s/it]Loading train:  26%|██▋       | 82/311 [09:40<21:09,  5.54s/it]Loading train:  27%|██▋       | 83/311 [09:45<20:51,  5.49s/it]Loading train:  27%|██▋       | 84/311 [09:51<20:49,  5.51s/it]Loading train:  27%|██▋       | 85/311 [09:56<20:15,  5.38s/it]Loading train:  28%|██▊       | 86/311 [10:01<19:49,  5.28s/it]Loading train:  28%|██▊       | 87/311 [10:06<19:22,  5.19s/it]Loading train:  28%|██▊       | 88/311 [10:11<19:14,  5.18s/it]Loading train:  29%|██▊       | 89/311 [10:16<18:54,  5.11s/it]Loading train:  29%|██▉       | 90/311 [10:21<18:35,  5.05s/it]Loading train:  29%|██▉       | 91/311 [10:26<18:34,  5.06s/it]Loading train:  30%|██▉       | 92/311 [10:31<18:21,  5.03s/it]Loading train:  30%|██▉       | 93/311 [10:36<18:05,  4.98s/it]Loading train:  30%|███       | 94/311 [10:41<17:53,  4.95s/it]Loading train:  31%|███       | 95/311 [10:46<18:03,  5.01s/it]Loading train:  31%|███       | 96/311 [10:51<17:49,  4.98s/it]Loading train:  31%|███       | 97/311 [10:56<17:50,  5.00s/it]Loading train:  32%|███▏      | 98/311 [11:01<17:55,  5.05s/it]Loading train:  32%|███▏      | 99/311 [11:06<18:03,  5.11s/it]Loading train:  32%|███▏      | 100/311 [11:11<17:54,  5.09s/it]Loading train:  32%|███▏      | 101/311 [11:16<17:36,  5.03s/it]Loading train:  33%|███▎      | 102/311 [11:21<17:32,  5.03s/it]Loading train:  33%|███▎      | 103/311 [11:26<17:34,  5.07s/it]Loading train:  33%|███▎      | 104/311 [11:31<17:19,  5.02s/it]Loading train:  34%|███▍      | 105/311 [11:36<17:27,  5.09s/it]Loading train:  34%|███▍      | 106/311 [11:41<17:07,  5.01s/it]Loading train:  34%|███▍      | 107/311 [11:47<17:14,  5.07s/it]Loading train:  35%|███▍      | 108/311 [11:51<16:59,  5.02s/it]Loading train:  35%|███▌      | 109/311 [11:56<16:53,  5.02s/it]Loading train:  35%|███▌      | 110/311 [12:01<16:37,  4.96s/it]Loading train:  36%|███▌      | 111/311 [12:06<16:39,  5.00s/it]Loading train:  36%|███▌      | 112/311 [12:11<16:27,  4.96s/it]Loading train:  36%|███▋      | 113/311 [12:16<16:19,  4.95s/it]Loading train:  37%|███▋      | 114/311 [12:26<20:41,  6.30s/it]Loading train:  37%|███▋      | 115/311 [12:35<23:14,  7.11s/it]Loading train:  37%|███▋      | 116/311 [12:44<25:00,  7.70s/it]Loading train:  38%|███▊      | 117/311 [12:53<26:29,  8.19s/it]Loading train:  38%|███▊      | 118/311 [13:02<27:13,  8.46s/it]Loading train:  38%|███▊      | 119/311 [13:11<27:32,  8.60s/it]Loading train:  39%|███▊      | 120/311 [13:20<27:44,  8.71s/it]Loading train:  39%|███▉      | 121/311 [13:29<27:47,  8.78s/it]Loading train:  39%|███▉      | 122/311 [13:38<27:50,  8.84s/it]Loading train:  40%|███▉      | 123/311 [13:47<27:52,  8.90s/it]Loading train:  40%|███▉      | 124/311 [13:57<28:27,  9.13s/it]Loading train:  40%|████      | 125/311 [14:05<27:54,  9.00s/it]Loading train:  41%|████      | 126/311 [14:15<27:55,  9.06s/it]Loading train:  41%|████      | 127/311 [14:24<27:46,  9.06s/it]Loading train:  41%|████      | 128/311 [14:33<27:47,  9.11s/it]Loading train:  41%|████▏     | 129/311 [14:42<27:51,  9.18s/it]Loading train:  42%|████▏     | 130/311 [14:51<27:27,  9.10s/it]Loading train:  42%|████▏     | 131/311 [15:01<27:35,  9.20s/it]Loading train:  42%|████▏     | 132/311 [15:05<23:21,  7.83s/it]Loading train:  43%|████▎     | 133/311 [15:10<20:15,  6.83s/it]Loading train:  43%|████▎     | 134/311 [15:14<18:09,  6.16s/it]Loading train:  43%|████▎     | 135/311 [15:19<16:42,  5.69s/it]Loading train:  44%|████▎     | 136/311 [15:23<15:21,  5.27s/it]Loading train:  44%|████▍     | 137/311 [15:28<14:34,  5.03s/it]Loading train:  44%|████▍     | 138/311 [15:32<14:04,  4.88s/it]Loading train:  45%|████▍     | 139/311 [15:37<13:39,  4.77s/it]Loading train:  45%|████▌     | 140/311 [15:41<13:04,  4.59s/it]Loading train:  45%|████▌     | 141/311 [15:45<12:51,  4.54s/it]Loading train:  46%|████▌     | 142/311 [15:50<12:46,  4.53s/it]Loading train:  46%|████▌     | 143/311 [15:54<12:44,  4.55s/it]Loading train:  46%|████▋     | 144/311 [15:59<12:47,  4.60s/it]Loading train:  47%|████▋     | 145/311 [16:03<12:36,  4.56s/it]Loading train:  47%|████▋     | 146/311 [16:08<12:28,  4.54s/it]Loading train:  47%|████▋     | 147/311 [16:13<12:32,  4.59s/it]Loading train:  48%|████▊     | 148/311 [16:17<12:21,  4.55s/it]Loading train:  48%|████▊     | 149/311 [16:22<12:17,  4.55s/it]Loading train:  48%|████▊     | 150/311 [16:27<13:00,  4.85s/it]Loading train:  49%|████▊     | 151/311 [16:33<13:35,  5.10s/it]Loading train:  49%|████▉     | 152/311 [16:38<13:49,  5.21s/it]Loading train:  49%|████▉     | 153/311 [16:44<13:49,  5.25s/it]Loading train:  50%|████▉     | 154/311 [16:49<13:57,  5.33s/it]Loading train:  50%|████▉     | 155/311 [16:55<14:17,  5.50s/it]Loading train:  50%|█████     | 156/311 [17:01<14:16,  5.53s/it]Loading train:  50%|█████     | 157/311 [17:06<14:15,  5.55s/it]Loading train:  51%|█████     | 158/311 [17:12<14:20,  5.62s/it]Loading train:  51%|█████     | 159/311 [17:17<13:59,  5.52s/it]Loading train:  51%|█████▏    | 160/311 [17:23<13:43,  5.46s/it]Loading train:  52%|█████▏    | 161/311 [17:29<14:03,  5.62s/it]Loading train:  52%|█████▏    | 162/311 [17:34<14:00,  5.64s/it]Loading train:  52%|█████▏    | 163/311 [17:40<13:53,  5.63s/it]Loading train:  53%|█████▎    | 164/311 [17:46<13:58,  5.71s/it]Loading train:  53%|█████▎    | 165/311 [17:51<13:45,  5.65s/it]Loading train:  53%|█████▎    | 166/311 [17:57<13:24,  5.55s/it]Loading train:  54%|█████▎    | 167/311 [18:02<13:22,  5.57s/it]Loading train:  54%|█████▍    | 168/311 [18:08<12:59,  5.45s/it]Loading train:  54%|█████▍    | 169/311 [18:13<12:52,  5.44s/it]Loading train:  55%|█████▍    | 170/311 [18:18<12:46,  5.43s/it]Loading train:  55%|█████▍    | 171/311 [18:24<12:39,  5.43s/it]Loading train:  55%|█████▌    | 172/311 [18:29<12:18,  5.32s/it]Loading train:  56%|█████▌    | 173/311 [18:34<12:21,  5.37s/it]Loading train:  56%|█████▌    | 174/311 [18:40<12:21,  5.41s/it]Loading train:  56%|█████▋    | 175/311 [18:45<12:19,  5.44s/it]Loading train:  57%|█████▋    | 176/311 [18:51<12:08,  5.40s/it]Loading train:  57%|█████▋    | 177/311 [18:56<11:59,  5.37s/it]Loading train:  57%|█████▋    | 178/311 [19:01<11:45,  5.31s/it]Loading train:  58%|█████▊    | 179/311 [19:06<11:36,  5.28s/it]Loading train:  58%|█████▊    | 180/311 [19:12<11:47,  5.40s/it]Loading train:  58%|█████▊    | 181/311 [19:17<11:39,  5.38s/it]Loading train:  59%|█████▊    | 182/311 [19:22<11:20,  5.28s/it]Loading train:  59%|█████▉    | 183/311 [19:28<11:25,  5.36s/it]Loading train:  59%|█████▉    | 184/311 [19:33<11:01,  5.21s/it]Loading train:  59%|█████▉    | 185/311 [19:38<10:42,  5.10s/it]Loading train:  60%|█████▉    | 186/311 [19:42<10:24,  5.00s/it]Loading train:  60%|██████    | 187/311 [19:47<10:22,  5.02s/it]Loading train:  60%|██████    | 188/311 [19:53<10:19,  5.03s/it]Loading train:  61%|██████    | 189/311 [19:57<10:04,  4.96s/it]Loading train:  61%|██████    | 190/311 [20:02<10:06,  5.01s/it]Loading train:  61%|██████▏   | 191/311 [20:07<10:02,  5.02s/it]Loading train:  62%|██████▏   | 192/311 [20:14<10:54,  5.50s/it]Loading train:  62%|██████▏   | 193/311 [20:21<11:30,  5.85s/it]Loading train:  62%|██████▏   | 194/311 [20:27<11:43,  6.01s/it]Loading train:  63%|██████▎   | 195/311 [20:34<12:19,  6.38s/it]Loading train:  63%|██████▎   | 196/311 [20:41<12:16,  6.41s/it]Loading train:  63%|██████▎   | 197/311 [20:48<12:23,  6.52s/it]Loading train:  64%|██████▎   | 198/311 [20:54<12:03,  6.41s/it]Loading train:  64%|██████▍   | 199/311 [21:00<11:58,  6.42s/it]Loading train:  64%|██████▍   | 200/311 [21:06<11:38,  6.30s/it]Loading train:  65%|██████▍   | 201/311 [21:12<11:27,  6.25s/it]Loading train:  65%|██████▍   | 202/311 [21:19<11:21,  6.25s/it]Loading train:  65%|██████▌   | 203/311 [21:25<11:05,  6.16s/it]Loading train:  66%|██████▌   | 204/311 [21:31<10:55,  6.13s/it]Loading train:  66%|██████▌   | 205/311 [21:37<10:41,  6.05s/it]Loading train:  66%|██████▌   | 206/311 [21:43<10:42,  6.12s/it]Loading train:  67%|██████▋   | 207/311 [21:50<10:54,  6.30s/it]Loading train:  67%|██████▋   | 208/311 [21:56<11:03,  6.44s/it]Loading train:  67%|██████▋   | 209/311 [22:02<10:44,  6.32s/it]Loading train:  68%|██████▊   | 210/311 [22:09<10:49,  6.43s/it]Loading train:  68%|██████▊   | 211/311 [22:16<10:47,  6.48s/it]Loading train:  68%|██████▊   | 212/311 [22:23<10:54,  6.61s/it]Loading train:  68%|██████▊   | 213/311 [22:34<13:02,  7.98s/it]Loading train:  69%|██████▉   | 214/311 [22:44<13:58,  8.65s/it]Loading train:  69%|██████▉   | 215/311 [22:55<14:49,  9.26s/it]Loading train:  69%|██████▉   | 216/311 [23:06<15:30,  9.80s/it]Loading train:  70%|██████▉   | 217/311 [23:17<15:58, 10.19s/it]Loading train:  70%|███████   | 218/311 [23:28<16:15, 10.48s/it]Loading train:  70%|███████   | 219/311 [23:39<16:16, 10.62s/it]Loading train:  71%|███████   | 220/311 [23:51<16:38, 10.97s/it]Loading train:  71%|███████   | 221/311 [24:02<16:30, 11.00s/it]Loading train:  71%|███████▏  | 222/311 [24:13<16:20, 11.02s/it]Loading train:  72%|███████▏  | 223/311 [24:24<16:04, 10.96s/it]Loading train:  72%|███████▏  | 224/311 [24:34<15:47, 10.89s/it]Loading train:  72%|███████▏  | 225/311 [24:46<15:46, 11.01s/it]Loading train:  73%|███████▎  | 226/311 [24:56<15:25, 10.89s/it]Loading train:  73%|███████▎  | 227/311 [25:07<15:09, 10.83s/it]Loading train:  73%|███████▎  | 228/311 [25:18<15:01, 10.87s/it]Loading train:  74%|███████▎  | 229/311 [25:29<14:52, 10.88s/it]Loading train:  74%|███████▍  | 230/311 [25:40<14:53, 11.03s/it]Loading train:  74%|███████▍  | 231/311 [25:46<12:48,  9.61s/it]Loading train:  75%|███████▍  | 232/311 [25:52<11:04,  8.41s/it]Loading train:  75%|███████▍  | 233/311 [25:58<10:01,  7.71s/it]Loading train:  75%|███████▌  | 234/311 [26:03<08:57,  6.98s/it]Loading train:  76%|███████▌  | 235/311 [26:10<08:35,  6.79s/it]Loading train:  76%|███████▌  | 236/311 [26:15<08:04,  6.46s/it]Loading train:  76%|███████▌  | 237/311 [26:21<07:40,  6.22s/it]Loading train:  77%|███████▋  | 238/311 [26:27<07:19,  6.03s/it]Loading train:  77%|███████▋  | 239/311 [26:32<07:02,  5.87s/it]Loading train:  77%|███████▋  | 240/311 [26:38<06:49,  5.77s/it]Loading train:  77%|███████▋  | 241/311 [26:43<06:37,  5.68s/it]Loading train:  78%|███████▊  | 242/311 [26:48<06:21,  5.53s/it]Loading train:  78%|███████▊  | 243/311 [26:54<06:17,  5.56s/it]Loading train:  78%|███████▊  | 244/311 [26:59<06:08,  5.50s/it]Loading train:  79%|███████▉  | 245/311 [27:05<06:04,  5.52s/it]Loading train:  79%|███████▉  | 246/311 [27:11<06:04,  5.61s/it]Loading train:  79%|███████▉  | 247/311 [27:16<05:53,  5.52s/it]Loading train:  80%|███████▉  | 248/311 [27:22<06:00,  5.72s/it]Loading train:  80%|████████  | 249/311 [27:29<06:11,  5.98s/it]Loading train:  80%|████████  | 250/311 [27:36<06:28,  6.37s/it]Loading train:  81%|████████  | 251/311 [27:43<06:26,  6.44s/it]Loading train:  81%|████████  | 252/311 [27:48<06:00,  6.11s/it]Loading train:  81%|████████▏ | 253/311 [27:54<05:53,  6.09s/it]Loading train:  82%|████████▏ | 254/311 [27:59<05:34,  5.87s/it]Loading train:  82%|████████▏ | 255/311 [28:05<05:16,  5.64s/it]Loading train:  82%|████████▏ | 256/311 [28:10<05:06,  5.57s/it]Loading train:  83%|████████▎ | 257/311 [28:15<04:58,  5.52s/it]Loading train:  83%|████████▎ | 258/311 [28:21<04:46,  5.41s/it]Loading train:  83%|████████▎ | 259/311 [28:26<04:38,  5.36s/it]Loading train:  84%|████████▎ | 260/311 [28:31<04:36,  5.42s/it]Loading train:  84%|████████▍ | 261/311 [28:37<04:32,  5.44s/it]Loading train:  84%|████████▍ | 262/311 [28:43<04:31,  5.53s/it]Loading train:  85%|████████▍ | 263/311 [28:48<04:24,  5.51s/it]Loading train:  85%|████████▍ | 264/311 [28:54<04:19,  5.53s/it]Loading train:  85%|████████▌ | 265/311 [28:59<04:14,  5.52s/it]Loading train:  86%|████████▌ | 266/311 [29:04<04:05,  5.45s/it]Loading train:  86%|████████▌ | 267/311 [29:09<03:54,  5.33s/it]Loading train:  86%|████████▌ | 268/311 [29:15<03:53,  5.43s/it]Loading train:  86%|████████▋ | 269/311 [29:21<03:50,  5.48s/it]Loading train:  87%|████████▋ | 270/311 [29:26<03:40,  5.38s/it]Loading train:  87%|████████▋ | 271/311 [29:31<03:35,  5.40s/it]Loading train:  87%|████████▋ | 272/311 [29:37<03:32,  5.44s/it]Loading train:  88%|████████▊ | 273/311 [29:42<03:22,  5.34s/it]Loading train:  88%|████████▊ | 274/311 [29:47<03:18,  5.36s/it]Loading train:  88%|████████▊ | 275/311 [29:53<03:14,  5.39s/it]Loading train:  89%|████████▊ | 276/311 [29:58<03:05,  5.31s/it]Loading train:  89%|████████▉ | 277/311 [30:03<02:57,  5.22s/it]Loading train:  89%|████████▉ | 278/311 [30:08<02:53,  5.25s/it]Loading train:  90%|████████▉ | 279/311 [30:13<02:46,  5.19s/it]Loading train:  90%|█████████ | 280/311 [30:18<02:40,  5.18s/it]Loading train:  90%|█████████ | 281/311 [30:24<02:34,  5.14s/it]Loading train:  91%|█████████ | 282/311 [30:29<02:27,  5.10s/it]Loading train:  91%|█████████ | 283/311 [30:33<02:18,  4.95s/it]Loading train:  91%|█████████▏| 284/311 [30:38<02:13,  4.95s/it]Loading train:  92%|█████████▏| 285/311 [30:43<02:06,  4.86s/it]Loading train:  92%|█████████▏| 286/311 [30:47<01:58,  4.75s/it]Loading train:  92%|█████████▏| 287/311 [30:52<01:52,  4.71s/it]Loading train:  93%|█████████▎| 288/311 [30:56<01:47,  4.67s/it]Loading train:  93%|█████████▎| 289/311 [31:01<01:42,  4.67s/it]Loading train:  93%|█████████▎| 290/311 [31:06<01:37,  4.66s/it]Loading train:  94%|█████████▎| 291/311 [31:10<01:33,  4.68s/it]Loading train:  94%|█████████▍| 292/311 [31:15<01:28,  4.67s/it]Loading train:  94%|█████████▍| 293/311 [31:20<01:22,  4.60s/it]Loading train:  95%|█████████▍| 294/311 [31:24<01:18,  4.63s/it]Loading train:  95%|█████████▍| 295/311 [31:29<01:15,  4.72s/it]Loading train:  95%|█████████▌| 296/311 [31:34<01:10,  4.69s/it]Loading train:  95%|█████████▌| 297/311 [31:39<01:05,  4.70s/it]Loading train:  96%|█████████▌| 298/311 [31:44<01:02,  4.85s/it]Loading train:  96%|█████████▌| 299/311 [31:48<00:57,  4.79s/it]Loading train:  96%|█████████▋| 300/311 [31:53<00:53,  4.86s/it]Loading train:  97%|█████████▋| 301/311 [31:58<00:48,  4.87s/it]Loading train:  97%|█████████▋| 302/311 [32:03<00:44,  4.96s/it]Loading train:  97%|█████████▋| 303/311 [32:08<00:39,  4.92s/it]Loading train:  98%|█████████▊| 304/311 [32:13<00:34,  4.91s/it]Loading train:  98%|█████████▊| 305/311 [32:18<00:29,  4.92s/it]Loading train:  98%|█████████▊| 306/311 [32:23<00:24,  4.81s/it]Loading train:  99%|█████████▊| 307/311 [32:28<00:19,  4.83s/it]Loading train:  99%|█████████▉| 308/311 [32:33<00:14,  4.92s/it]Loading train:  99%|█████████▉| 309/311 [32:38<00:09,  4.92s/it]Loading train: 100%|█████████▉| 310/311 [32:43<00:04,  4.95s/it]Loading train: 100%|██████████| 311/311 [32:48<00:00,  5.03s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 16/311 [00:00<00:01, 153.72it/s]concatenating: train:  12%|█▏        | 38/311 [00:00<00:01, 168.20it/s]concatenating: train:  19%|█▉        | 60/311 [00:00<00:01, 180.95it/s]concatenating: train:  27%|██▋       | 83/311 [00:00<00:01, 191.78it/s]concatenating: train:  33%|███▎      | 104/311 [00:00<00:01, 194.48it/s]concatenating: train:  41%|████      | 126/311 [00:00<00:00, 198.60it/s]concatenating: train:  49%|████▉     | 153/311 [00:00<00:00, 208.82it/s]concatenating: train:  57%|█████▋    | 177/311 [00:00<00:00, 216.39it/s]concatenating: train:  65%|██████▍   | 202/311 [00:00<00:00, 224.75it/s]concatenating: train:  74%|███████▎  | 229/311 [00:01<00:00, 227.88it/s]concatenating: train:  82%|████████▏ | 254/311 [00:01<00:00, 234.08it/s]concatenating: train:  89%|████████▉ | 278/311 [00:01<00:00, 234.74it/s]concatenating: train:  98%|█████████▊| 305/311 [00:01<00:00, 232.52it/s]concatenating: train: 100%|██████████| 311/311 [00:01<00:00, 224.03it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:34, 11.45s/it]Loading test:  50%|█████     | 2/4 [00:22<00:22, 11.20s/it]Loading test:  75%|███████▌  | 3/4 [00:33<00:11, 11.41s/it]Loading test: 100%|██████████| 4/4 [00:45<00:00, 11.30s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 154.14it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 15 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 26, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 26, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 26, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 26, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 26, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 26, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 26, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 13, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 13, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 13, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 13, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 13, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 13, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 13, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 13, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 26, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 26, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 26, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 26, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 26, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 26, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2019-07-07 19:03:58.991404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 19:03:58.991523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 19:03:58.991539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 19:03:58.991548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 19:03:58.991991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 40, 26, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 52, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 52, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 52, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 52, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 52, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 52, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 52, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 127,286
Non-trainable params: 600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [5.87995836e-02 2.85625934e-02 1.22042724e-01 1.04920441e-02
 3.15682606e-02 5.46103058e-03 7.22892131e-02 1.13259646e-01
 7.87837639e-02 1.27868129e-02 2.92912776e-01 1.72791632e-01
 2.49918858e-04]
Train on 12355 samples, validate on 158 samples
Epoch 1/300
 - 19s - loss: 38039.5624 - acc: 0.8367 - mDice: 0.0729 - val_loss: 14343.2429 - val_acc: 0.8552 - val_mDice: 0.1718

Epoch 00001: val_mDice improved from -inf to 0.17176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 10s - loss: 13356.3733 - acc: 0.8588 - mDice: 0.2042 - val_loss: 8313.3647 - val_acc: 0.8654 - val_mDice: 0.2999

Epoch 00002: val_mDice improved from 0.17176 to 0.29991, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 11s - loss: 9846.0734 - acc: 0.8778 - mDice: 0.2937 - val_loss: 7268.7685 - val_acc: 0.8768 - val_mDice: 0.3524

Epoch 00003: val_mDice improved from 0.29991 to 0.35244, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 10s - loss: 8239.7245 - acc: 0.8889 - mDice: 0.3578 - val_loss: 6601.4406 - val_acc: 0.8849 - val_mDice: 0.3960

Epoch 00004: val_mDice improved from 0.35244 to 0.39597, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 10s - loss: 7257.8286 - acc: 0.8978 - mDice: 0.4053 - val_loss: 6041.6465 - val_acc: 0.8980 - val_mDice: 0.4250

Epoch 00005: val_mDice improved from 0.39597 to 0.42498, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 11s - loss: 6704.3010 - acc: 0.9044 - mDice: 0.4392 - val_loss: 5395.5410 - val_acc: 0.9075 - val_mDice: 0.4614

Epoch 00006: val_mDice improved from 0.42498 to 0.46139, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 10s - loss: 6136.8916 - acc: 0.9084 - mDice: 0.4658 - val_loss: 4977.6152 - val_acc: 0.9124 - val_mDice: 0.4984

Epoch 00007: val_mDice improved from 0.46139 to 0.49844, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 10s - loss: 5703.0272 - acc: 0.9125 - mDice: 0.4907 - val_loss: 4825.8010 - val_acc: 0.9175 - val_mDice: 0.5088

Epoch 00008: val_mDice improved from 0.49844 to 0.50880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 11s - loss: 5442.2910 - acc: 0.9146 - mDice: 0.5059 - val_loss: 4562.5598 - val_acc: 0.9187 - val_mDice: 0.5231

Epoch 00009: val_mDice improved from 0.50880 to 0.52314, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 10/300
 - 10s - loss: 5190.2789 - acc: 0.9168 - mDice: 0.5220 - val_loss: 4320.6792 - val_acc: 0.9218 - val_mDice: 0.5456

Epoch 00010: val_mDice improved from 0.52314 to 0.54562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 10s - loss: 4877.8682 - acc: 0.9186 - mDice: 0.5394 - val_loss: 4127.7080 - val_acc: 0.9237 - val_mDice: 0.5564

Epoch 00011: val_mDice improved from 0.54562 to 0.55645, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 11s - loss: 4695.5867 - acc: 0.9202 - mDice: 0.5515 - val_loss: 3920.2271 - val_acc: 0.9249 - val_mDice: 0.5684

Epoch 00012: val_mDice improved from 0.55645 to 0.56835, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 13/300
 - 10s - loss: 4496.9463 - acc: 0.9217 - mDice: 0.5638 - val_loss: 3698.9734 - val_acc: 0.9275 - val_mDice: 0.5842

Epoch 00013: val_mDice improved from 0.56835 to 0.58416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 10s - loss: 4319.5283 - acc: 0.9227 - mDice: 0.5745 - val_loss: 3603.1142 - val_acc: 0.9275 - val_mDice: 0.5889

Epoch 00014: val_mDice improved from 0.58416 to 0.58895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 15/300
 - 10s - loss: 4112.0631 - acc: 0.9240 - mDice: 0.5873 - val_loss: 3394.4066 - val_acc: 0.9291 - val_mDice: 0.6049

Epoch 00015: val_mDice improved from 0.58895 to 0.60489, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 10s - loss: 3919.9133 - acc: 0.9253 - mDice: 0.6002 - val_loss: 3264.4298 - val_acc: 0.9326 - val_mDice: 0.6143

Epoch 00016: val_mDice improved from 0.60489 to 0.61427, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 10s - loss: 3778.4254 - acc: 0.9267 - mDice: 0.6106 - val_loss: 3308.4248 - val_acc: 0.9321 - val_mDice: 0.6134

Epoch 00017: val_mDice did not improve from 0.61427
Epoch 18/300
 - 11s - loss: 3682.2562 - acc: 0.9276 - mDice: 0.6178 - val_loss: 3201.0286 - val_acc: 0.9332 - val_mDice: 0.6215

Epoch 00018: val_mDice improved from 0.61427 to 0.62145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 19/300
 - 10s - loss: 3555.4154 - acc: 0.9289 - mDice: 0.6276 - val_loss: 3225.4167 - val_acc: 0.9332 - val_mDice: 0.6187

Epoch 00019: val_mDice did not improve from 0.62145
Epoch 20/300
 - 10s - loss: 3467.1463 - acc: 0.9297 - mDice: 0.6347 - val_loss: 3372.0650 - val_acc: 0.9317 - val_mDice: 0.6104

Epoch 00020: val_mDice did not improve from 0.62145
Epoch 21/300
 - 11s - loss: 3393.5484 - acc: 0.9304 - mDice: 0.6409 - val_loss: 3166.6144 - val_acc: 0.9343 - val_mDice: 0.6263

Epoch 00021: val_mDice improved from 0.62145 to 0.62628, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 10s - loss: 3336.5009 - acc: 0.9314 - mDice: 0.6457 - val_loss: 2997.6912 - val_acc: 0.9363 - val_mDice: 0.6398

Epoch 00022: val_mDice improved from 0.62628 to 0.63984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 23/300
 - 10s - loss: 3240.2986 - acc: 0.9325 - mDice: 0.6536 - val_loss: 3003.2606 - val_acc: 0.9350 - val_mDice: 0.6386

Epoch 00023: val_mDice did not improve from 0.63984
Epoch 24/300
 - 11s - loss: 3190.4966 - acc: 0.9331 - mDice: 0.6580 - val_loss: 2968.8476 - val_acc: 0.9375 - val_mDice: 0.6411

Epoch 00024: val_mDice improved from 0.63984 to 0.64112, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 25/300
 - 10s - loss: 3146.9784 - acc: 0.9338 - mDice: 0.6619 - val_loss: 2953.1281 - val_acc: 0.9365 - val_mDice: 0.6422

Epoch 00025: val_mDice improved from 0.64112 to 0.64224, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 26/300
 - 10s - loss: 3083.1900 - acc: 0.9343 - mDice: 0.6670 - val_loss: 2963.4441 - val_acc: 0.9366 - val_mDice: 0.6438

Epoch 00026: val_mDice improved from 0.64224 to 0.64383, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 27/300
 - 11s - loss: 3022.3289 - acc: 0.9351 - mDice: 0.6724 - val_loss: 2899.4625 - val_acc: 0.9378 - val_mDice: 0.6475

Epoch 00027: val_mDice improved from 0.64383 to 0.64749, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 28/300
 - 10s - loss: 2970.8625 - acc: 0.9357 - mDice: 0.6767 - val_loss: 3008.7126 - val_acc: 0.9394 - val_mDice: 0.6447

Epoch 00028: val_mDice did not improve from 0.64749
Epoch 29/300
 - 10s - loss: 2940.3409 - acc: 0.9363 - mDice: 0.6796 - val_loss: 2770.1243 - val_acc: 0.9420 - val_mDice: 0.6598

Epoch 00029: val_mDice improved from 0.64749 to 0.65984, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 30/300
 - 11s - loss: 2880.3315 - acc: 0.9369 - mDice: 0.6849 - val_loss: 2731.6702 - val_acc: 0.9412 - val_mDice: 0.6612

Epoch 00030: val_mDice improved from 0.65984 to 0.66118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 31/300
 - 10s - loss: 2840.2787 - acc: 0.9375 - mDice: 0.6884 - val_loss: 2750.8320 - val_acc: 0.9424 - val_mDice: 0.6624

Epoch 00031: val_mDice improved from 0.66118 to 0.66238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 10s - loss: 2816.2860 - acc: 0.9378 - mDice: 0.6905 - val_loss: 2871.5844 - val_acc: 0.9436 - val_mDice: 0.6541

Epoch 00032: val_mDice did not improve from 0.66238
Epoch 33/300
 - 11s - loss: 2771.5062 - acc: 0.9382 - mDice: 0.6944 - val_loss: 2822.7166 - val_acc: 0.9408 - val_mDice: 0.6575

Epoch 00033: val_mDice did not improve from 0.66238
Epoch 34/300
 - 10s - loss: 2737.1022 - acc: 0.9387 - mDice: 0.6975 - val_loss: 2655.1214 - val_acc: 0.9443 - val_mDice: 0.6688

Epoch 00034: val_mDice improved from 0.66238 to 0.66882, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 35/300
 - 10s - loss: 2693.2257 - acc: 0.9392 - mDice: 0.7016 - val_loss: 2654.5120 - val_acc: 0.9435 - val_mDice: 0.6704

Epoch 00035: val_mDice improved from 0.66882 to 0.67042, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 36/300
 - 11s - loss: 2669.1493 - acc: 0.9397 - mDice: 0.7038 - val_loss: 2839.7778 - val_acc: 0.9425 - val_mDice: 0.6577

Epoch 00036: val_mDice did not improve from 0.67042
Epoch 37/300
 - 10s - loss: 2620.8086 - acc: 0.9401 - mDice: 0.7081 - val_loss: 2625.4600 - val_acc: 0.9443 - val_mDice: 0.6692

Epoch 00037: val_mDice did not improve from 0.67042
Epoch 38/300
 - 10s - loss: 2591.1325 - acc: 0.9404 - mDice: 0.7110 - val_loss: 2799.7256 - val_acc: 0.9429 - val_mDice: 0.6585

Epoch 00038: val_mDice did not improve from 0.67042
Epoch 39/300
 - 11s - loss: 2564.1180 - acc: 0.9409 - mDice: 0.7133 - val_loss: 2743.5441 - val_acc: 0.9441 - val_mDice: 0.6625

Epoch 00039: val_mDice did not improve from 0.67042
Epoch 40/300
 - 10s - loss: 2535.5682 - acc: 0.9412 - mDice: 0.7160 - val_loss: 2526.8291 - val_acc: 0.9473 - val_mDice: 0.6811

Epoch 00040: val_mDice improved from 0.67042 to 0.68114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 41/300
 - 10s - loss: 2493.2198 - acc: 0.9416 - mDice: 0.7199 - val_loss: 2512.0900 - val_acc: 0.9457 - val_mDice: 0.6827

Epoch 00041: val_mDice improved from 0.68114 to 0.68268, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 42/300
 - 11s - loss: 2478.7310 - acc: 0.9418 - mDice: 0.7213 - val_loss: 2774.1915 - val_acc: 0.9434 - val_mDice: 0.6646

Epoch 00042: val_mDice did not improve from 0.68268
Epoch 43/300
 - 10s - loss: 2440.5290 - acc: 0.9424 - mDice: 0.7248 - val_loss: 2686.9662 - val_acc: 0.9470 - val_mDice: 0.6685

Epoch 00043: val_mDice did not improve from 0.68268
Epoch 44/300
 - 10s - loss: 2426.8705 - acc: 0.9425 - mDice: 0.7262 - val_loss: 2721.0609 - val_acc: 0.9430 - val_mDice: 0.6668

Epoch 00044: val_mDice did not improve from 0.68268
Epoch 45/300
 - 11s - loss: 2402.7742 - acc: 0.9428 - mDice: 0.7284 - val_loss: 2421.0888 - val_acc: 0.9474 - val_mDice: 0.6926

Epoch 00045: val_mDice improved from 0.68268 to 0.69255, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 46/300
 - 10s - loss: 2363.4819 - acc: 0.9432 - mDice: 0.7321 - val_loss: 2717.6931 - val_acc: 0.9430 - val_mDice: 0.6679

Epoch 00046: val_mDice did not improve from 0.69255
Epoch 47/300
 - 10s - loss: 2339.9024 - acc: 0.9437 - mDice: 0.7343 - val_loss: 2595.9878 - val_acc: 0.9456 - val_mDice: 0.6791

Epoch 00047: val_mDice did not improve from 0.69255
Epoch 48/300
 - 11s - loss: 2325.8853 - acc: 0.9439 - mDice: 0.7357 - val_loss: 2581.7359 - val_acc: 0.9443 - val_mDice: 0.6813

Epoch 00048: val_mDice did not improve from 0.69255
Epoch 49/300
 - 10s - loss: 2303.6183 - acc: 0.9441 - mDice: 0.7378 - val_loss: 2600.9391 - val_acc: 0.9476 - val_mDice: 0.6748

Epoch 00049: val_mDice did not improve from 0.69255
Epoch 50/300
 - 10s - loss: 2285.6042 - acc: 0.9445 - mDice: 0.7395 - val_loss: 2723.8335 - val_acc: 0.9429 - val_mDice: 0.6691

Epoch 00050: val_mDice did not improve from 0.69255
Epoch 51/300
 - 11s - loss: 2246.7832 - acc: 0.9449 - mDice: 0.7432 - val_loss: 2531.6406 - val_acc: 0.9504 - val_mDice: 0.6855

Epoch 00051: val_mDice did not improve from 0.69255
Epoch 52/300
 - 10s - loss: 2248.6750 - acc: 0.9450 - mDice: 0.7430 - val_loss: 2567.6909 - val_acc: 0.9494 - val_mDice: 0.6769

Epoch 00052: val_mDice did not improve from 0.69255
Epoch 53/300
 - 10s - loss: 2228.7866 - acc: 0.9454 - mDice: 0.7451 - val_loss: 2900.8701 - val_acc: 0.9440 - val_mDice: 0.6504

Epoch 00053: val_mDice did not improve from 0.69255
Epoch 54/300
 - 11s - loss: 2199.6198 - acc: 0.9456 - mDice: 0.7478 - val_loss: 2409.6065 - val_acc: 0.9497 - val_mDice: 0.6966

Epoch 00054: val_mDice improved from 0.69255 to 0.69662, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 55/300
 - 10s - loss: 2190.6358 - acc: 0.9459 - mDice: 0.7488 - val_loss: 2660.0926 - val_acc: 0.9484 - val_mDice: 0.6730

Epoch 00055: val_mDice did not improve from 0.69662
Epoch 56/300
 - 10s - loss: 2175.6730 - acc: 0.9462 - mDice: 0.7501 - val_loss: 2748.0354 - val_acc: 0.9451 - val_mDice: 0.6676

Epoch 00056: val_mDice did not improve from 0.69662
Epoch 57/300
 - 10s - loss: 2149.2889 - acc: 0.9464 - mDice: 0.7526 - val_loss: 2585.6011 - val_acc: 0.9483 - val_mDice: 0.6774

Epoch 00057: val_mDice did not improve from 0.69662
Epoch 58/300
 - 10s - loss: 2131.9455 - acc: 0.9466 - mDice: 0.7544 - val_loss: 2420.3353 - val_acc: 0.9509 - val_mDice: 0.6947

Epoch 00058: val_mDice did not improve from 0.69662
Epoch 59/300
 - 10s - loss: 2119.5396 - acc: 0.9470 - mDice: 0.7556 - val_loss: 2659.1991 - val_acc: 0.9459 - val_mDice: 0.6708

Epoch 00059: val_mDice did not improve from 0.69662
Epoch 60/300
 - 10s - loss: 2103.1696 - acc: 0.9471 - mDice: 0.7572 - val_loss: 2525.1086 - val_acc: 0.9486 - val_mDice: 0.6833

Epoch 00060: val_mDice did not improve from 0.69662
Epoch 61/300
 - 10s - loss: 2083.4872 - acc: 0.9474 - mDice: 0.7592 - val_loss: 2488.3701 - val_acc: 0.9508 - val_mDice: 0.6893

Epoch 00061: val_mDice did not improve from 0.69662
Epoch 62/300
 - 10s - loss: 2061.2573 - acc: 0.9477 - mDice: 0.7614 - val_loss: 2804.7723 - val_acc: 0.9479 - val_mDice: 0.6619

Epoch 00062: val_mDice did not improve from 0.69662
Epoch 63/300
 - 11s - loss: 2060.9922 - acc: 0.9477 - mDice: 0.7614 - val_loss: 2669.1360 - val_acc: 0.9497 - val_mDice: 0.6718

Epoch 00063: val_mDice did not improve from 0.69662
Epoch 64/300
 - 10s - loss: 2042.6950 - acc: 0.9480 - mDice: 0.7632 - val_loss: 2441.5993 - val_acc: 0.9515 - val_mDice: 0.6943

Epoch 00064: val_mDice did not improve from 0.69662
Epoch 65/300
 - 10s - loss: 2029.8249 - acc: 0.9482 - mDice: 0.7645 - val_loss: 2765.1715 - val_acc: 0.9467 - val_mDice: 0.6631

Epoch 00065: val_mDice did not improve from 0.69662
Epoch 66/300
 - 10s - loss: 2016.7996 - acc: 0.9483 - mDice: 0.7659 - val_loss: 2466.7648 - val_acc: 0.9510 - val_mDice: 0.6894

Epoch 00066: val_mDice did not improve from 0.69662
Epoch 67/300
 - 10s - loss: 2006.7235 - acc: 0.9485 - mDice: 0.7667 - val_loss: 2455.9222 - val_acc: 0.9506 - val_mDice: 0.6894

Epoch 00067: val_mDice did not improve from 0.69662
Epoch 68/300
 - 10s - loss: 1994.5731 - acc: 0.9487 - mDice: 0.7680 - val_loss: 2578.5255 - val_acc: 0.9480 - val_mDice: 0.6797

Epoch 00068: val_mDice did not improve from 0.69662
Epoch 69/300
 - 10s - loss: 1976.8844 - acc: 0.9489 - mDice: 0.7699 - val_loss: 2427.4095 - val_acc: 0.9513 - val_mDice: 0.6953

Epoch 00069: val_mDice did not improve from 0.69662
Epoch 70/300
 - 10s - loss: 1969.6438 - acc: 0.9490 - mDice: 0.7706 - val_loss: 2571.7905 - val_acc: 0.9508 - val_mDice: 0.6820

Epoch 00070: val_mDice did not improve from 0.69662
Epoch 71/300
 - 10s - loss: 1961.4423 - acc: 0.9493 - mDice: 0.7714 - val_loss: 2777.9799 - val_acc: 0.9508 - val_mDice: 0.6668

Epoch 00071: val_mDice did not improve from 0.69662
Epoch 72/300
 - 10s - loss: 1948.4007 - acc: 0.9495 - mDice: 0.7727 - val_loss: 2852.0750 - val_acc: 0.9474 - val_mDice: 0.6559

Epoch 00072: val_mDice did not improve from 0.69662
Epoch 73/300
 - 10s - loss: 1928.8590 - acc: 0.9497 - mDice: 0.7747 - val_loss: 2508.8339 - val_acc: 0.9520 - val_mDice: 0.6885

Epoch 00073: val_mDice did not improve from 0.69662
Epoch 74/300
 - 10s - loss: 1925.3380 - acc: 0.9496 - mDice: 0.7750 - val_loss: 2715.2170 - val_acc: 0.9493 - val_mDice: 0.6702

Epoch 00074: val_mDice did not improve from 0.69662
Epoch 75/300
 - 11s - loss: 1911.1151 - acc: 0.9499 - mDice: 0.7764 - val_loss: 2493.5163 - val_acc: 0.9508 - val_mDice: 0.6891

Epoch 00075: val_mDice did not improve from 0.69662
Epoch 76/300
 - 10s - loss: 1908.4115 - acc: 0.9500 - mDice: 0.7767 - val_loss: 2544.4856 - val_acc: 0.9491 - val_mDice: 0.6856

Epoch 00076: val_mDice did not improve from 0.69662
Epoch 77/300
 - 10s - loss: 1891.2750 - acc: 0.9501 - mDice: 0.7784 - val_loss: 2399.1906 - val_acc: 0.9525 - val_mDice: 0.6963

Epoch 00077: val_mDice did not improve from 0.69662
Epoch 78/300
 - 10s - loss: 1880.5658 - acc: 0.9505 - mDice: 0.7795 - val_loss: 2480.7919 - val_acc: 0.9523 - val_mDice: 0.6914

Epoch 00078: val_mDice did not improve from 0.69662
Epoch 79/300
 - 10s - loss: 1875.9915 - acc: 0.9504 - mDice: 0.7800 - val_loss: 2423.1827 - val_acc: 0.9513 - val_mDice: 0.6931

Epoch 00079: val_mDice did not improve from 0.69662
Epoch 80/300
 - 10s - loss: 1868.7990 - acc: 0.9506 - mDice: 0.7808 - val_loss: 2446.6915 - val_acc: 0.9512 - val_mDice: 0.6927

Epoch 00080: val_mDice did not improve from 0.69662
Epoch 81/300
 - 10s - loss: 1858.3168 - acc: 0.9506 - mDice: 0.7818 - val_loss: 2350.8728 - val_acc: 0.9539 - val_mDice: 0.7009

Epoch 00081: val_mDice improved from 0.69662 to 0.70092, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 82/300
 - 10s - loss: 1850.2522 - acc: 0.9507 - mDice: 0.7826 - val_loss: 2682.0574 - val_acc: 0.9496 - val_mDice: 0.6727

Epoch 00082: val_mDice did not improve from 0.70092
Epoch 83/300
 - 10s - loss: 1846.5453 - acc: 0.9509 - mDice: 0.7831 - val_loss: 2500.5028 - val_acc: 0.9498 - val_mDice: 0.6879

Epoch 00083: val_mDice did not improve from 0.70092
Epoch 84/300
 - 10s - loss: 1836.1163 - acc: 0.9509 - mDice: 0.7841 - val_loss: 2480.4042 - val_acc: 0.9527 - val_mDice: 0.6911

Epoch 00084: val_mDice did not improve from 0.70092
Epoch 85/300
 - 10s - loss: 1823.1975 - acc: 0.9511 - mDice: 0.7854 - val_loss: 2529.2921 - val_acc: 0.9522 - val_mDice: 0.6866

Epoch 00085: val_mDice did not improve from 0.70092
Epoch 86/300
 - 10s - loss: 1823.6547 - acc: 0.9511 - mDice: 0.7854 - val_loss: 2906.7942 - val_acc: 0.9450 - val_mDice: 0.6568

Epoch 00086: val_mDice did not improve from 0.70092
Epoch 87/300
 - 10s - loss: 1808.8200 - acc: 0.9513 - mDice: 0.7869 - val_loss: 2564.3740 - val_acc: 0.9515 - val_mDice: 0.6807

Epoch 00087: val_mDice did not improve from 0.70092
Epoch 88/300
 - 11s - loss: 1809.6424 - acc: 0.9515 - mDice: 0.7869 - val_loss: 2357.8996 - val_acc: 0.9544 - val_mDice: 0.7015

Epoch 00088: val_mDice improved from 0.70092 to 0.70150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 89/300
 - 10s - loss: 1811.5311 - acc: 0.9514 - mDice: 0.7867 - val_loss: 2721.1345 - val_acc: 0.9486 - val_mDice: 0.6688

Epoch 00089: val_mDice did not improve from 0.70150
Epoch 90/300
 - 10s - loss: 1785.2645 - acc: 0.9517 - mDice: 0.7893 - val_loss: 2380.8082 - val_acc: 0.9537 - val_mDice: 0.6974

Epoch 00090: val_mDice did not improve from 0.70150
Epoch 91/300
 - 11s - loss: 1782.5697 - acc: 0.9516 - mDice: 0.7896 - val_loss: 2700.2414 - val_acc: 0.9464 - val_mDice: 0.6708

Epoch 00091: val_mDice did not improve from 0.70150
Epoch 92/300
 - 10s - loss: 1776.4774 - acc: 0.9517 - mDice: 0.7902 - val_loss: 2363.4926 - val_acc: 0.9534 - val_mDice: 0.6997

Epoch 00092: val_mDice did not improve from 0.70150
Epoch 93/300
 - 10s - loss: 1762.7047 - acc: 0.9519 - mDice: 0.7917 - val_loss: 2468.2377 - val_acc: 0.9512 - val_mDice: 0.6910

Epoch 00093: val_mDice did not improve from 0.70150
Epoch 94/300
 - 11s - loss: 1757.1112 - acc: 0.9520 - mDice: 0.7923 - val_loss: 2483.6402 - val_acc: 0.9520 - val_mDice: 0.6880

Epoch 00094: val_mDice did not improve from 0.70150
Epoch 95/300
 - 10s - loss: 1751.5158 - acc: 0.9520 - mDice: 0.7929 - val_loss: 2460.5873 - val_acc: 0.9512 - val_mDice: 0.6860

Epoch 00095: val_mDice did not improve from 0.70150
Epoch 96/300
 - 10s - loss: 1747.5185 - acc: 0.9521 - mDice: 0.7933 - val_loss: 2510.4553 - val_acc: 0.9523 - val_mDice: 0.6893

Epoch 00096: val_mDice did not improve from 0.70150
Epoch 97/300
 - 11s - loss: 1742.1754 - acc: 0.9521 - mDice: 0.7938 - val_loss: 2409.5362 - val_acc: 0.9523 - val_mDice: 0.6961

Epoch 00097: val_mDice did not improve from 0.70150
Epoch 98/300
 - 10s - loss: 1731.6212 - acc: 0.9523 - mDice: 0.7949 - val_loss: 2651.5915 - val_acc: 0.9496 - val_mDice: 0.6743

Epoch 00098: val_mDice did not improve from 0.70150
Epoch 99/300
 - 10s - loss: 1721.8559 - acc: 0.9524 - mDice: 0.7959 - val_loss: 2523.1498 - val_acc: 0.9521 - val_mDice: 0.6850

Epoch 00099: val_mDice did not improve from 0.70150
Epoch 100/300
 - 11s - loss: 1725.8029 - acc: 0.9524 - mDice: 0.7956 - val_loss: 2538.3918 - val_acc: 0.9517 - val_mDice: 0.6841

Epoch 00100: val_mDice did not improve from 0.70150
Epoch 101/300
 - 10s - loss: 1719.8200 - acc: 0.9525 - mDice: 0.7961 - val_loss: 2505.2751 - val_acc: 0.9524 - val_mDice: 0.6875

Epoch 00101: val_mDice did not improve from 0.70150
Epoch 102/300
 - 10s - loss: 1707.2227 - acc: 0.9526 - mDice: 0.7974 - val_loss: 2410.2785 - val_acc: 0.9540 - val_mDice: 0.6964

Epoch 00102: val_mDice did not improve from 0.70150
Epoch 103/300
 - 11s - loss: 1711.8293 - acc: 0.9525 - mDice: 0.7970 - val_loss: 2605.6897 - val_acc: 0.9519 - val_mDice: 0.6788

Epoch 00103: val_mDice did not improve from 0.70150
Epoch 104/300
 - 10s - loss: 1702.1180 - acc: 0.9526 - mDice: 0.7979 - val_loss: 2498.5318 - val_acc: 0.9515 - val_mDice: 0.6897

Epoch 00104: val_mDice did not improve from 0.70150
Epoch 105/300
 - 10s - loss: 1706.1124 - acc: 0.9527 - mDice: 0.7975 - val_loss: 2493.8393 - val_acc: 0.9537 - val_mDice: 0.6882

Epoch 00105: val_mDice did not improve from 0.70150
Epoch 106/300
 - 11s - loss: 1686.6089 - acc: 0.9528 - mDice: 0.7996 - val_loss: 2578.4014 - val_acc: 0.9510 - val_mDice: 0.6828

Epoch 00106: val_mDice did not improve from 0.70150
Epoch 107/300
 - 10s - loss: 1680.8191 - acc: 0.9530 - mDice: 0.8002 - val_loss: 3103.9039 - val_acc: 0.9480 - val_mDice: 0.6413

Epoch 00107: val_mDice did not improve from 0.70150
Epoch 108/300
 - 10s - loss: 1677.8280 - acc: 0.9530 - mDice: 0.8005 - val_loss: 2787.6019 - val_acc: 0.9481 - val_mDice: 0.6639

Epoch 00108: val_mDice did not improve from 0.70150
Epoch 109/300
 - 11s - loss: 1680.4749 - acc: 0.9530 - mDice: 0.8002 - val_loss: 2342.9858 - val_acc: 0.9542 - val_mDice: 0.7014

Epoch 00109: val_mDice did not improve from 0.70150
Epoch 110/300
 - 10s - loss: 1677.5198 - acc: 0.9531 - mDice: 0.8005 - val_loss: 2486.7253 - val_acc: 0.9541 - val_mDice: 0.6897

Epoch 00110: val_mDice did not improve from 0.70150
Epoch 111/300
 - 10s - loss: 1667.0016 - acc: 0.9532 - mDice: 0.8017 - val_loss: 2550.8995 - val_acc: 0.9529 - val_mDice: 0.6832

Epoch 00111: val_mDice did not improve from 0.70150
Epoch 112/300
 - 11s - loss: 1663.9078 - acc: 0.9532 - mDice: 0.8020 - val_loss: 2389.4396 - val_acc: 0.9540 - val_mDice: 0.6969

Epoch 00112: val_mDice did not improve from 0.70150
Epoch 113/300
 - 10s - loss: 1661.0690 - acc: 0.9533 - mDice: 0.8023 - val_loss: 2725.6282 - val_acc: 0.9510 - val_mDice: 0.6719

Epoch 00113: val_mDice did not improve from 0.70150
Epoch 114/300
 - 10s - loss: 1658.1405 - acc: 0.9533 - mDice: 0.8026 - val_loss: 2435.6389 - val_acc: 0.9546 - val_mDice: 0.6904

Epoch 00114: val_mDice did not improve from 0.70150
Epoch 115/300
 - 11s - loss: 1645.3647 - acc: 0.9534 - mDice: 0.8039 - val_loss: 3146.9432 - val_acc: 0.9515 - val_mDice: 0.6546

Epoch 00115: val_mDice did not improve from 0.70150
Epoch 116/300
 - 10s - loss: 1649.7309 - acc: 0.9534 - mDice: 0.8034 - val_loss: 2699.6896 - val_acc: 0.9514 - val_mDice: 0.6674

Epoch 00116: val_mDice did not improve from 0.70150
Epoch 117/300
 - 10s - loss: 1636.7105 - acc: 0.9536 - mDice: 0.8048 - val_loss: 2528.7010 - val_acc: 0.9516 - val_mDice: 0.6829

Epoch 00117: val_mDice did not improve from 0.70150
Epoch 118/300
 - 11s - loss: 1641.9354 - acc: 0.9536 - mDice: 0.8043 - val_loss: 2389.2138 - val_acc: 0.9554 - val_mDice: 0.6988

Epoch 00118: val_mDice did not improve from 0.70150
Restoring model weights from the end of the best epoch
Epoch 00118: early stopping
{'val_loss': [14343.242879746835, 8313.364653382121, 7268.768505241297, 6601.440621291535, 6041.646453471123, 5395.540975449961, 4977.615197290348, 4825.800979034811, 4562.559761916535, 4320.6792084899125, 4127.7080078125, 3920.2271125890034, 3698.9733933074563, 3603.114216092267, 3394.4065837618673, 3264.4298420193827, 3308.424795416337, 3201.0285629079312, 3225.41670169106, 3372.0650171207476, 3166.614367521262, 2997.691152838212, 3003.26064947587, 2968.847558902789, 2953.1281429242486, 2963.4441443334654, 2899.4625058717365, 3008.712564589102, 2770.124321659909, 2731.6702092810524, 2750.831975623022, 2871.5843923061707, 2822.716640810423, 2655.1214275118673, 2654.5120494214793, 2839.777776404272, 2625.4599825702135, 2799.725558124011, 2743.544055021262, 2526.8291139240505, 2512.0899797270567, 2774.1914927808543, 2686.9662467859966, 2721.0609022695808, 2421.0887713854827, 2717.693147683445, 2595.9877867879745, 2581.7358707476264, 2600.9390791880933, 2723.833533178402, 2531.640583279767, 2567.690853070609, 2900.8700507441654, 2409.606454583663, 2660.0925911046284, 2748.0353509444226, 2585.601064947587, 2420.3352946993673, 2659.1990951344937, 2525.10856377324, 2488.37008473843, 2804.772323415249, 2669.136023412777, 2441.599337420886, 2765.171487156349, 2466.764776688588, 2455.9222273041933, 2578.525464794304, 2427.4095289013053, 2571.7905134370058, 2777.979906299446, 2852.0750284315664, 2508.8339411095726, 2715.216976117484, 2493.5162616198577, 2544.4855709800236, 2399.1906429242486, 2480.791922653778, 2423.1826697240904, 2446.6914742385284, 2350.8727532881726, 2682.0573946795885, 2500.502801436412, 2480.4041670787183, 2529.2921096222312, 2906.7942018146755, 2564.3739755364913, 2357.899635025218, 2721.1345431170885, 2380.8082290842563, 2700.2414149030856, 2363.492647967761, 2468.237677079213, 2483.6402047072784, 2460.5873158128957, 2510.455262003066, 2409.5362471568433, 2651.591515649723, 2523.1497849090188, 2538.3917560818827, 2505.275058408327, 2410.2785350944423, 2605.689669452136, 2498.5317815466774, 2493.8393261100673, 2578.4013718230813, 3103.9039260284812, 2787.601871538766, 2342.985795033129, 2486.7253217093553, 2550.899542313588, 2389.439627731903, 2725.6281985512264, 2435.638852662678, 3146.9432450306567, 2699.6895705597312, 2528.7009709998024, 2389.2138270124606], 'val_acc': [0.8552260889282709, 0.8654181112216998, 0.8768302677552912, 0.884874009633366, 0.8980358507059798, 0.9074762810634661, 0.9123661125762553, 0.9175130694727355, 0.91870436110074, 0.9218141413942168, 0.9236855122107493, 0.9248782833920249, 0.9274722956403901, 0.927502756631827, 0.9291382514977757, 0.9326390397699573, 0.9320518042467818, 0.9331928650035134, 0.9331700137898892, 0.9316972999633113, 0.934300452848024, 0.9362965701501581, 0.9349546477764468, 0.9374650150914735, 0.9365278188186356, 0.9366373510300359, 0.9378149222724045, 0.9394443548178371, 0.9420307663422597, 0.9411970414692843, 0.9424187752264964, 0.9436100381839124, 0.9407756207864496, 0.9443159827703163, 0.9434654908844188, 0.9425054796134369, 0.9443083729925035, 0.9428721228732339, 0.9441029602968241, 0.9472781796998615, 0.9456502621686911, 0.9434365705598758, 0.9469708332532569, 0.9430364272262477, 0.9473709750779068, 0.9430227702177023, 0.9455574562277975, 0.9443235797218129, 0.9476402877252313, 0.9429406161549725, 0.9503666645363916, 0.9493640457527547, 0.9439675709869289, 0.9497337379033053, 0.948429896861692, 0.9451116564907606, 0.9483203488060191, 0.9508945957014833, 0.9458632672889323, 0.9486002793794945, 0.9508200438716744, 0.9479126243651668, 0.9496866011921363, 0.9515077147302748, 0.9466696109952806, 0.9510087114346178, 0.9505766185024117, 0.9479552069796792, 0.951320577271377, 0.9507591701761077, 0.9508337446405918, 0.9474272810960118, 0.9519824031033094, 0.9492940570734725, 0.9508352581458756, 0.9491023504281346, 0.9524601396126083, 0.952309545082382, 0.9512779999382889, 0.9511502038074445, 0.9539237361920031, 0.9496333463282525, 0.949785482279862, 0.9526807439478138, 0.9521512728703173, 0.9450234476524063, 0.9515183862251572, 0.9544014975994448, 0.9485713922524754, 0.953663594360593, 0.9464261690272561, 0.953394288503671, 0.9512004037446613, 0.9520189090620114, 0.9511851811710792, 0.9522578052327603, 0.9523323464997208, 0.949570937247216, 0.9520523880101457, 0.9516872695729702, 0.9524342576159707, 0.9540211309360552, 0.9519108933738515, 0.9515077486822877, 0.9537457552137254, 0.9509509153003934, 0.9480008611196205, 0.9480571573293661, 0.9542326127426534, 0.9540865534468542, 0.9529363196107405, 0.9540348075613191, 0.9509813091422938, 0.9545703364323966, 0.9515457515475116, 0.951411892341662, 0.9516111997109425, 0.9554208215278915], 'val_mDice': [0.17176300287246704, 0.299908346767667, 0.3524371566651743, 0.3959710699847982, 0.42497636245775827, 0.4613914580284795, 0.4984365814848791, 0.5087959223155734, 0.5231402493730376, 0.5456170371816128, 0.5564477594592904, 0.5683546262451366, 0.584155551240414, 0.5889452122434785, 0.6048942615714255, 0.6142687065691887, 0.6133990710294699, 0.6214532399479347, 0.6186552440063863, 0.6104225591768192, 0.6262796807892715, 0.6398393632490423, 0.6386133726639084, 0.6411166251460209, 0.6422436448592174, 0.6438262507885317, 0.6474869990650611, 0.6446700888344005, 0.6598386870154852, 0.661181347279609, 0.6623816203467453, 0.6541494085818906, 0.6574999078919616, 0.6688227132905887, 0.6704172205321396, 0.6577195457265347, 0.6692097647280633, 0.6585310750369784, 0.6625001558774635, 0.6811364081841481, 0.6826764903491056, 0.6645526606825334, 0.6684625707095182, 0.6667798259590245, 0.6925502381747282, 0.6679056437709664, 0.6791120314899879, 0.6813406235055078, 0.674816863446296, 0.6690844938724856, 0.6854865664168249, 0.6768632478351835, 0.6503611870958835, 0.6966196947459933, 0.6729509566403642, 0.6676071565362471, 0.677398482455483, 0.6947383035587359, 0.670840405210664, 0.683267796341377, 0.6892614983305146, 0.6618904961815363, 0.671800222577928, 0.6942888785012161, 0.6631428410735312, 0.6894466695906241, 0.6894301281699652, 0.6797187260434597, 0.6953479866438275, 0.6820084882687919, 0.6668441484246073, 0.6559341300891924, 0.6885276406626158, 0.6701865860178501, 0.6890694959254204, 0.6856168274638019, 0.6962619838835318, 0.6914061232458187, 0.6930765637868568, 0.692700293999684, 0.7009168395513221, 0.6726905635640591, 0.6879026150401635, 0.6911255226859564, 0.6866074211989777, 0.656826536866683, 0.6806734166567838, 0.7014963475963737, 0.6687503192998185, 0.6973749716070634, 0.6707707560515102, 0.6996977148176748, 0.6910133422175541, 0.6879860645608057, 0.6860410171219066, 0.6892504812795904, 0.6961467764045619, 0.6743362870397447, 0.6850035522557512, 0.6841313401355019, 0.6874749909473371, 0.6963795966739896, 0.6787936076333251, 0.6896901462651506, 0.6881550769262677, 0.6827739612965644, 0.641328587562223, 0.663906749290756, 0.7014208217210407, 0.6896658094623421, 0.6831823164903665, 0.6968999414504329, 0.6719040659409535, 0.6904331724854964, 0.6545914652981336, 0.6673978559578522, 0.6829063273683379, 0.6987962405892867], 'loss': [38039.56238578448, 13356.373314036575, 9846.073351858116, 8239.724503854082, 7257.828592038743, 6704.3010224265545, 6136.891616876866, 5703.02718951952, 5442.290950316642, 5190.278924192508, 4877.868236385825, 4695.58668602666, 4496.946336784039, 4319.528262019109, 4112.0630865895955, 3919.913315158969, 3778.4253646992615, 3682.2561799886494, 3555.4154426207288, 3467.146280348132, 3393.548432520361, 3336.5009156508468, 3240.2986247403473, 3190.496624417461, 3146.978356553205, 3083.1899583014533, 3022.3288921015023, 2970.862547988305, 2940.3408841388227, 2880.3314980630785, 2840.2787355294067, 2816.286001800574, 2771.5062281053974, 2737.1022160775938, 2693.225651147056, 2669.149281370934, 2620.8085868832363, 2591.1324938623975, 2564.1180118080674, 2535.5681820741697, 2493.219789894811, 2478.730978619565, 2440.528964009858, 2426.870491747237, 2402.774201686833, 2363.481878017424, 2339.9024097499746, 2325.885337344841, 2303.618309795977, 2285.604230311852, 2246.783196208835, 2248.6749736889324, 2228.786638186558, 2199.619813913664, 2190.6358041859794, 2175.673037162728, 2149.2889227934666, 2131.9455269505165, 2119.5396258216406, 2103.1696112403883, 2083.4871936336503, 2061.2573121154614, 2060.992209434123, 2042.6949647651034, 2029.8249086868614, 2016.7996096516465, 2006.7235420131335, 1994.5731021351585, 1976.8843794559864, 1969.6438255047615, 1961.442322296056, 1948.4007320365458, 1928.8590156064251, 1925.3379793989182, 1911.1150780202695, 1908.411518783909, 1891.2750074694582, 1880.5658398654866, 1875.9914784448824, 1868.7989617551882, 1858.3167692004597, 1850.2522074422677, 1846.5452907042, 1836.1163484456808, 1823.1974585366027, 1823.6546685447677, 1808.8199685442935, 1809.642385287499, 1811.531109379545, 1785.2644878095675, 1782.5696967390084, 1776.477443792327, 1762.7046688609353, 1757.1112262597696, 1751.5158392776125, 1747.5185340378073, 1742.1753934013464, 1731.621221205041, 1721.855903258067, 1725.8028758105745, 1719.8200017418856, 1707.2226557559882, 1711.8292944741027, 1702.1180281598574, 1706.1124356500247, 1686.6088847674034, 1680.8190888575048, 1677.8280310142575, 1680.4749249991305, 1677.51977099392, 1667.0016176415957, 1663.9077639485215, 1661.0689827437732, 1658.1404941609783, 1645.364680834793, 1649.7309046165994, 1636.7105268774028, 1641.9354067238562], 'acc': [0.836686077001171, 0.8587564778009535, 0.8777952104481257, 0.8889079675265334, 0.8978181692425995, 0.9043682661195459, 0.9084171567161958, 0.9125059907950644, 0.914587621310615, 0.9167786730730018, 0.9185953003730141, 0.9202143931282719, 0.9216690144525371, 0.922738383531281, 0.9239635366941936, 0.9253251374081435, 0.9267014291353044, 0.9275909961355403, 0.9289126745943403, 0.9297408196714811, 0.9304488650076498, 0.9314328135869031, 0.932460679114468, 0.9330989871851011, 0.9338099836868972, 0.9343402152696345, 0.9350775548052277, 0.9356726500631971, 0.9362571601055258, 0.9369002138492503, 0.9374808753274897, 0.9378357014160126, 0.9382270914926456, 0.9387182295684243, 0.939195300152021, 0.9397144581276798, 0.9400581156421123, 0.940427750409349, 0.9408505584054127, 0.9412071945116328, 0.9415836981654119, 0.9418041400946089, 0.9423714129850479, 0.9424845518635526, 0.9428481335391018, 0.9432387627217993, 0.9437168844553778, 0.9438684293009019, 0.9441311512095684, 0.9445341941510459, 0.9449392560762415, 0.9449660285722384, 0.9453670670271209, 0.9456149431579464, 0.945899372036184, 0.9462066321226326, 0.9463961384451761, 0.9466264832362333, 0.9469980018334754, 0.9471180506294818, 0.9473660424478331, 0.947659815795409, 0.9477284969418988, 0.9479551274541996, 0.9481723369591055, 0.9483482228363637, 0.9485387804294974, 0.9486658700513049, 0.9488812322222911, 0.9490110859220591, 0.9492524426893298, 0.949462649794254, 0.9496660121584267, 0.9496342959745555, 0.9498812581112104, 0.950034203123149, 0.9501414111344644, 0.9504586291525442, 0.9503898892697898, 0.9505564766536112, 0.9506106214067899, 0.95073893862859, 0.9509256806319564, 0.9508822151689287, 0.9510977334794801, 0.9510865456080543, 0.951300974463413, 0.9514648371840816, 0.9513686069926961, 0.9516618933720128, 0.9516390687248959, 0.9517029835019021, 0.9518643575417084, 0.95196338960971, 0.9520292113976457, 0.9520566839286067, 0.952088885633437, 0.9522896955390538, 0.9524200518861661, 0.9524168636527731, 0.9524851533769355, 0.9526153200071189, 0.9524961265172615, 0.9526091879169645, 0.9526560247209765, 0.9528370213286687, 0.953038477333197, 0.9530351877164281, 0.9529846192660577, 0.953111321035545, 0.9532487438497925, 0.9532460180770429, 0.9533117426546515, 0.9533045851523362, 0.9534325097939689, 0.953418132024755, 0.9536257302746605, 0.9535755919377749], 'mDice': [0.07291555966094938, 0.20420923150053685, 0.29368486092284546, 0.35777103145901173, 0.4052541154760525, 0.4391749733158183, 0.46580145287639163, 0.49074111369301654, 0.5059416757475167, 0.5220243479500218, 0.5393735955765931, 0.551532479444046, 0.5638450081171849, 0.5745279178210281, 0.587261638724336, 0.6002289215498537, 0.6105960434817534, 0.6178218302626399, 0.6276261002271584, 0.6347366659229268, 0.6408688474019884, 0.6456660392891295, 0.6536023571200816, 0.6580189584913837, 0.6618764361163857, 0.6669720212538104, 0.6723651610516865, 0.6766965140074865, 0.6796321762278706, 0.6848583537429415, 0.6884170639182045, 0.6904609206715657, 0.6944206664312325, 0.6975406323401661, 0.7016116404330764, 0.7038133225668688, 0.7080842369917866, 0.7110214568207207, 0.7133385578373191, 0.7160427540432147, 0.7199327012683061, 0.7212922445968403, 0.724815768975567, 0.7261645629887444, 0.7284294926218058, 0.7320702806362398, 0.7343325889192579, 0.7357130972106946, 0.7377884477943797, 0.7394692573601396, 0.7432460562269102, 0.7430176247184164, 0.7451447440949783, 0.7477749334033903, 0.748750216707147, 0.7501431742162176, 0.7526465442826129, 0.754439757353668, 0.7556254814048375, 0.7572222449720654, 0.7592036683566172, 0.7613889294228348, 0.7613772066051494, 0.7632259826146847, 0.7644563316816456, 0.7658674444857033, 0.7667469916098613, 0.7680228480150323, 0.7698525725372019, 0.7705726682633246, 0.7713864210500065, 0.7726740848916785, 0.7747060390485534, 0.7749720554224444, 0.7764309315438311, 0.7767179582052413, 0.7784211128552111, 0.7795494406727922, 0.7800257370231702, 0.7807615460870914, 0.7817950699311044, 0.7826019326524183, 0.783056483028486, 0.7841184964454014, 0.7853556568204801, 0.7854048889786162, 0.7868615434942627, 0.7869218951147705, 0.7867215594652933, 0.7893369248018531, 0.7896269110955965, 0.7901799940522601, 0.7916787177722303, 0.7922912588586503, 0.7928504854115046, 0.7932858288601699, 0.7938212373873234, 0.7948573459888074, 0.7958954181665353, 0.795556313134745, 0.7960792452350217, 0.797428677362838, 0.796950299215915, 0.7979369361310872, 0.7975302450042271, 0.7996105371048363, 0.800200518617163, 0.8005010513871462, 0.8001975684646458, 0.8004931805829488, 0.8016570783105277, 0.8020029514967696, 0.8023369367766217, 0.8026157741071916, 0.8039493999805396, 0.8034407711376405, 0.8048112991607802, 0.8042964288359564]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:14<00:43, 14.37s/it]predicting test subjects:  50%|█████     | 2/4 [00:27<00:27, 13.93s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:40<00:13, 13.84s/it]predicting test subjects: 100%|██████████| 4/4 [00:54<00:00, 13.65s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:20<1:46:18, 20.58s/it]predicting train subjects:   1%|          | 2/311 [00:30<1:29:30, 17.38s/it]predicting train subjects:   1%|          | 3/311 [00:42<1:21:31, 15.88s/it]predicting train subjects:   1%|▏         | 4/311 [00:54<1:15:23, 14.73s/it]predicting train subjects:   2%|▏         | 5/311 [01:05<1:09:03, 13.54s/it]predicting train subjects:   2%|▏         | 6/311 [01:16<1:05:05, 12.81s/it]predicting train subjects:   2%|▏         | 7/311 [01:29<1:04:33, 12.74s/it]predicting train subjects:   3%|▎         | 8/311 [01:44<1:07:41, 13.40s/it]predicting train subjects:   3%|▎         | 9/311 [01:57<1:07:51, 13.48s/it]predicting train subjects:   3%|▎         | 10/311 [02:08<1:03:50, 12.72s/it]predicting train subjects:   4%|▎         | 11/311 [02:23<1:06:34, 13.32s/it]predicting train subjects:   4%|▍         | 12/311 [02:34<1:02:50, 12.61s/it]predicting train subjects:   4%|▍         | 13/311 [02:45<1:00:19, 12.15s/it]predicting train subjects:   5%|▍         | 14/311 [03:00<1:03:34, 12.84s/it]predicting train subjects:   5%|▍         | 15/311 [03:21<1:15:51, 15.38s/it]predicting train subjects:   5%|▌         | 16/311 [03:41<1:23:08, 16.91s/it]predicting train subjects:   5%|▌         | 17/311 [04:02<1:28:41, 18.10s/it]predicting train subjects:   6%|▌         | 18/311 [04:24<1:33:05, 19.06s/it]predicting train subjects:   6%|▌         | 19/311 [04:44<1:34:39, 19.45s/it]predicting train subjects:   6%|▋         | 20/311 [05:05<1:36:52, 19.97s/it]predicting train subjects:   7%|▋         | 21/311 [05:27<1:38:47, 20.44s/it]predicting train subjects:   7%|▋         | 22/311 [05:48<1:39:05, 20.57s/it]predicting train subjects:   7%|▋         | 23/311 [06:09<1:39:54, 20.81s/it]predicting train subjects:   8%|▊         | 24/311 [06:29<1:38:06, 20.51s/it]predicting train subjects:   8%|▊         | 25/311 [06:49<1:37:36, 20.48s/it]predicting train subjects:   8%|▊         | 26/311 [07:10<1:37:39, 20.56s/it]predicting train subjects:   9%|▊         | 27/311 [07:31<1:38:42, 20.85s/it]predicting train subjects:   9%|▉         | 28/311 [07:52<1:38:35, 20.90s/it]predicting train subjects:   9%|▉         | 29/311 [08:14<1:38:30, 20.96s/it]predicting train subjects:  10%|▉         | 30/311 [08:35<1:38:31, 21.04s/it]predicting train subjects:  10%|▉         | 31/311 [08:56<1:38:28, 21.10s/it]predicting train subjects:  10%|█         | 32/311 [09:17<1:37:24, 20.95s/it]predicting train subjects:  11%|█         | 33/311 [09:27<1:22:05, 17.72s/it]predicting train subjects:  11%|█         | 34/311 [09:36<1:10:29, 15.27s/it]predicting train subjects:  11%|█▏        | 35/311 [09:46<1:02:58, 13.69s/it]predicting train subjects:  12%|█▏        | 36/311 [09:56<57:38, 12.58s/it]  predicting train subjects:  12%|█▏        | 37/311 [10:06<53:44, 11.77s/it]predicting train subjects:  12%|█▏        | 38/311 [10:16<50:48, 11.17s/it]predicting train subjects:  13%|█▎        | 39/311 [10:26<49:03, 10.82s/it]predicting train subjects:  13%|█▎        | 40/311 [10:36<47:27, 10.51s/it]predicting train subjects:  13%|█▎        | 41/311 [10:46<46:22, 10.31s/it]predicting train subjects:  14%|█▎        | 42/311 [10:56<45:44, 10.20s/it]predicting train subjects:  14%|█▍        | 43/311 [11:06<45:19, 10.15s/it]predicting train subjects:  14%|█▍        | 44/311 [11:15<44:05,  9.91s/it]predicting train subjects:  14%|█▍        | 45/311 [11:25<43:43,  9.86s/it]predicting train subjects:  15%|█▍        | 46/311 [11:34<43:27,  9.84s/it]predicting train subjects:  15%|█▌        | 47/311 [11:44<43:09,  9.81s/it]predicting train subjects:  15%|█▌        | 48/311 [11:54<43:30,  9.93s/it]predicting train subjects:  16%|█▌        | 49/311 [12:04<43:06,  9.87s/it]predicting train subjects:  16%|█▌        | 50/311 [12:14<42:52,  9.86s/it]predicting train subjects:  16%|█▋        | 51/311 [12:26<46:03, 10.63s/it]predicting train subjects:  17%|█▋        | 52/311 [12:39<47:50, 11.08s/it]predicting train subjects:  17%|█▋        | 53/311 [12:52<50:27, 11.73s/it]predicting train subjects:  17%|█▋        | 54/311 [13:05<52:45, 12.32s/it]predicting train subjects:  18%|█▊        | 55/311 [13:20<55:56, 13.11s/it]predicting train subjects:  18%|█▊        | 56/311 [13:34<56:09, 13.21s/it]predicting train subjects:  18%|█▊        | 57/311 [13:48<57:05, 13.49s/it]predicting train subjects:  19%|█▊        | 58/311 [14:02<57:36, 13.66s/it]predicting train subjects:  19%|█▉        | 59/311 [14:17<58:53, 14.02s/it]predicting train subjects:  19%|█▉        | 60/311 [14:31<58:46, 14.05s/it]predicting train subjects:  20%|█▉        | 61/311 [14:44<57:14, 13.74s/it]predicting train subjects:  20%|█▉        | 62/311 [14:58<56:58, 13.73s/it]predicting train subjects:  20%|██        | 63/311 [15:11<55:43, 13.48s/it]predicting train subjects:  21%|██        | 64/311 [15:24<55:43, 13.54s/it]predicting train subjects:  21%|██        | 65/311 [15:39<56:26, 13.77s/it]predicting train subjects:  21%|██        | 66/311 [15:52<55:41, 13.64s/it]predicting train subjects:  22%|██▏       | 67/311 [16:06<55:30, 13.65s/it]predicting train subjects:  22%|██▏       | 68/311 [16:20<55:47, 13.77s/it]predicting train subjects:  22%|██▏       | 69/311 [16:33<54:59, 13.63s/it]predicting train subjects:  23%|██▎       | 70/311 [16:47<54:36, 13.59s/it]predicting train subjects:  23%|██▎       | 71/311 [17:00<53:43, 13.43s/it]predicting train subjects:  23%|██▎       | 72/311 [17:14<54:34, 13.70s/it]predicting train subjects:  23%|██▎       | 73/311 [17:28<54:34, 13.76s/it]predicting train subjects:  24%|██▍       | 74/311 [17:40<52:45, 13.36s/it]predicting train subjects:  24%|██▍       | 75/311 [17:53<51:28, 13.09s/it]predicting train subjects:  24%|██▍       | 76/311 [18:05<50:34, 12.91s/it]predicting train subjects:  25%|██▍       | 77/311 [18:18<49:42, 12.75s/it]predicting train subjects:  25%|██▌       | 78/311 [18:30<48:43, 12.55s/it]predicting train subjects:  25%|██▌       | 79/311 [18:43<49:56, 12.92s/it]predicting train subjects:  26%|██▌       | 80/311 [18:58<51:24, 13.35s/it]predicting train subjects:  26%|██▌       | 81/311 [19:12<52:44, 13.76s/it]predicting train subjects:  26%|██▋       | 82/311 [19:26<51:48, 13.58s/it]predicting train subjects:  27%|██▋       | 83/311 [19:39<51:48, 13.63s/it]predicting train subjects:  27%|██▋       | 84/311 [19:52<50:22, 13.31s/it]predicting train subjects:  27%|██▋       | 85/311 [20:03<48:04, 12.77s/it]predicting train subjects:  28%|██▊       | 86/311 [20:14<45:45, 12.20s/it]predicting train subjects:  28%|██▊       | 87/311 [20:25<44:02, 11.80s/it]predicting train subjects:  28%|██▊       | 88/311 [20:36<42:21, 11.40s/it]predicting train subjects:  29%|██▊       | 89/311 [20:47<41:39, 11.26s/it]predicting train subjects:  29%|██▉       | 90/311 [20:58<41:22, 11.23s/it]predicting train subjects:  29%|██▉       | 91/311 [21:09<40:57, 11.17s/it]predicting train subjects:  30%|██▉       | 92/311 [21:20<40:24, 11.07s/it]predicting train subjects:  30%|██▉       | 93/311 [21:30<39:47, 10.95s/it]predicting train subjects:  30%|███       | 94/311 [21:41<39:50, 11.02s/it]predicting train subjects:  31%|███       | 95/311 [21:53<39:45, 11.05s/it]predicting train subjects:  31%|███       | 96/311 [22:03<39:22, 10.99s/it]predicting train subjects:  31%|███       | 97/311 [22:14<38:49, 10.89s/it]predicting train subjects:  32%|███▏      | 98/311 [22:25<38:50, 10.94s/it]predicting train subjects:  32%|███▏      | 99/311 [22:36<38:47, 10.98s/it]predicting train subjects:  32%|███▏      | 100/311 [22:47<37:53, 10.77s/it]predicting train subjects:  32%|███▏      | 101/311 [22:57<37:40, 10.76s/it]predicting train subjects:  33%|███▎      | 102/311 [23:09<38:00, 10.91s/it]predicting train subjects:  33%|███▎      | 103/311 [23:19<37:40, 10.87s/it]predicting train subjects:  33%|███▎      | 104/311 [23:30<37:43, 10.93s/it]predicting train subjects:  34%|███▍      | 105/311 [23:41<37:39, 10.97s/it]predicting train subjects:  34%|███▍      | 106/311 [23:53<37:43, 11.04s/it]predicting train subjects:  34%|███▍      | 107/311 [24:04<37:24, 11.00s/it]predicting train subjects:  35%|███▍      | 108/311 [24:14<37:02, 10.95s/it]predicting train subjects:  35%|███▌      | 109/311 [24:26<37:11, 11.05s/it]predicting train subjects:  35%|███▌      | 110/311 [24:37<37:08, 11.09s/it]predicting train subjects:  36%|███▌      | 111/311 [24:48<36:58, 11.09s/it]predicting train subjects:  36%|███▌      | 112/311 [24:59<36:15, 10.93s/it]predicting train subjects:  36%|███▋      | 113/311 [25:10<36:20, 11.01s/it]predicting train subjects:  37%|███▋      | 114/311 [25:31<46:09, 14.06s/it]predicting train subjects:  37%|███▋      | 115/311 [25:51<52:13, 15.99s/it]predicting train subjects:  37%|███▋      | 116/311 [26:13<57:10, 17.59s/it]predicting train subjects:  38%|███▊      | 117/311 [26:34<1:00:03, 18.57s/it]predicting train subjects:  38%|███▊      | 118/311 [26:55<1:02:08, 19.32s/it]predicting train subjects:  38%|███▊      | 119/311 [27:16<1:03:39, 19.89s/it]predicting train subjects:  39%|███▊      | 120/311 [27:37<1:04:59, 20.42s/it]predicting train subjects:  39%|███▉      | 121/311 [27:58<1:05:11, 20.59s/it]predicting train subjects:  39%|███▉      | 122/311 [28:19<1:04:42, 20.54s/it]predicting train subjects:  40%|███▉      | 123/311 [28:40<1:04:24, 20.56s/it]predicting train subjects:  40%|███▉      | 124/311 [29:00<1:04:05, 20.56s/it]predicting train subjects:  40%|████      | 125/311 [29:22<1:04:40, 20.86s/it]predicting train subjects:  41%|████      | 126/311 [29:43<1:04:29, 20.92s/it]predicting train subjects:  41%|████      | 127/311 [30:03<1:03:55, 20.84s/it]predicting train subjects:  41%|████      | 128/311 [30:25<1:04:01, 20.99s/it]predicting train subjects:  41%|████▏     | 129/311 [30:46<1:03:50, 21.05s/it]predicting train subjects:  42%|████▏     | 130/311 [31:07<1:03:09, 20.94s/it]predicting train subjects:  42%|████▏     | 131/311 [31:28<1:03:18, 21.10s/it]predicting train subjects:  42%|████▏     | 132/311 [31:38<52:50, 17.71s/it]  predicting train subjects:  43%|████▎     | 133/311 [31:47<45:10, 15.22s/it]predicting train subjects:  43%|████▎     | 134/311 [31:57<40:14, 13.64s/it]predicting train subjects:  43%|████▎     | 135/311 [32:07<36:49, 12.55s/it]predicting train subjects:  44%|████▎     | 136/311 [32:16<33:39, 11.54s/it]predicting train subjects:  44%|████▍     | 137/311 [32:26<32:02, 11.05s/it]predicting train subjects:  44%|████▍     | 138/311 [32:36<30:56, 10.73s/it]predicting train subjects:  45%|████▍     | 139/311 [32:46<29:39, 10.35s/it]predicting train subjects:  45%|████▌     | 140/311 [32:55<28:55, 10.15s/it]predicting train subjects:  45%|████▌     | 141/311 [33:05<28:35, 10.09s/it]predicting train subjects:  46%|████▌     | 142/311 [33:15<27:55,  9.92s/it]predicting train subjects:  46%|████▌     | 143/311 [33:24<27:29,  9.82s/it]predicting train subjects:  46%|████▋     | 144/311 [33:34<27:16,  9.80s/it]predicting train subjects:  47%|████▋     | 145/311 [33:43<26:38,  9.63s/it]predicting train subjects:  47%|████▋     | 146/311 [33:54<26:53,  9.78s/it]predicting train subjects:  47%|████▋     | 147/311 [34:03<26:41,  9.77s/it]predicting train subjects:  48%|████▊     | 148/311 [34:13<26:14,  9.66s/it]predicting train subjects:  48%|████▊     | 149/311 [34:23<26:33,  9.84s/it]predicting train subjects:  48%|████▊     | 150/311 [34:35<28:31, 10.63s/it]predicting train subjects:  49%|████▊     | 151/311 [34:48<30:03, 11.27s/it]predicting train subjects:  49%|████▉     | 152/311 [35:00<30:38, 11.56s/it]predicting train subjects:  49%|████▉     | 153/311 [35:13<31:00, 11.77s/it]predicting train subjects:  50%|████▉     | 154/311 [35:25<31:22, 11.99s/it]predicting train subjects:  50%|████▉     | 155/311 [35:38<31:30, 12.12s/it]predicting train subjects:  50%|█████     | 156/311 [35:50<31:43, 12.28s/it]predicting train subjects:  50%|█████     | 157/311 [36:03<31:40, 12.34s/it]predicting train subjects:  51%|█████     | 158/311 [36:15<31:34, 12.38s/it]predicting train subjects:  51%|█████     | 159/311 [36:27<31:12, 12.32s/it]predicting train subjects:  51%|█████▏    | 160/311 [36:40<30:52, 12.27s/it]predicting train subjects:  52%|█████▏    | 161/311 [36:52<30:47, 12.32s/it]predicting train subjects:  52%|█████▏    | 162/311 [37:05<30:45, 12.39s/it]predicting train subjects:  52%|█████▏    | 163/311 [37:18<31:10, 12.64s/it]predicting train subjects:  53%|█████▎    | 164/311 [37:30<30:52, 12.60s/it]predicting train subjects:  53%|█████▎    | 165/311 [37:43<30:43, 12.63s/it]predicting train subjects:  53%|█████▎    | 166/311 [37:55<30:05, 12.45s/it]predicting train subjects:  54%|█████▎    | 167/311 [38:07<29:16, 12.20s/it]predicting train subjects:  54%|█████▍    | 168/311 [38:18<28:48, 12.09s/it]predicting train subjects:  54%|█████▍    | 169/311 [38:31<28:37, 12.09s/it]predicting train subjects:  55%|█████▍    | 170/311 [38:43<28:59, 12.34s/it]predicting train subjects:  55%|█████▍    | 171/311 [38:55<28:24, 12.18s/it]predicting train subjects:  55%|█████▌    | 172/311 [39:07<28:03, 12.11s/it]predicting train subjects:  56%|█████▌    | 173/311 [39:19<27:48, 12.09s/it]predicting train subjects:  56%|█████▌    | 174/311 [39:31<27:39, 12.11s/it]predicting train subjects:  56%|█████▋    | 175/311 [39:43<27:21, 12.07s/it]predicting train subjects:  57%|█████▋    | 176/311 [39:56<27:12, 12.09s/it]predicting train subjects:  57%|█████▋    | 177/311 [40:07<26:29, 11.86s/it]predicting train subjects:  57%|█████▋    | 178/311 [40:18<26:00, 11.74s/it]predicting train subjects:  58%|█████▊    | 179/311 [40:30<25:52, 11.76s/it]predicting train subjects:  58%|█████▊    | 180/311 [40:42<25:48, 11.82s/it]predicting train subjects:  58%|█████▊    | 181/311 [40:54<25:20, 11.70s/it]predicting train subjects:  59%|█████▊    | 182/311 [41:05<25:13, 11.74s/it]predicting train subjects:  59%|█████▉    | 183/311 [41:17<25:02, 11.74s/it]predicting train subjects:  59%|█████▉    | 184/311 [41:28<24:00, 11.34s/it]predicting train subjects:  59%|█████▉    | 185/311 [41:38<23:22, 11.13s/it]predicting train subjects:  60%|█████▉    | 186/311 [41:49<23:10, 11.12s/it]predicting train subjects:  60%|██████    | 187/311 [42:00<22:48, 11.04s/it]predicting train subjects:  60%|██████    | 188/311 [42:11<22:26, 10.95s/it]predicting train subjects:  61%|██████    | 189/311 [42:22<22:08, 10.89s/it]predicting train subjects:  61%|██████    | 190/311 [42:32<21:56, 10.88s/it]predicting train subjects:  61%|██████▏   | 191/311 [42:43<21:33, 10.78s/it]predicting train subjects:  62%|██████▏   | 192/311 [42:53<21:11, 10.69s/it]predicting train subjects:  62%|██████▏   | 193/311 [43:04<21:11, 10.77s/it]predicting train subjects:  62%|██████▏   | 194/311 [43:15<21:09, 10.85s/it]predicting train subjects:  63%|██████▎   | 195/311 [43:26<20:50, 10.78s/it]predicting train subjects:  63%|██████▎   | 196/311 [43:37<20:48, 10.86s/it]predicting train subjects:  63%|██████▎   | 197/311 [43:48<20:42, 10.90s/it]predicting train subjects:  64%|██████▎   | 198/311 [43:59<20:20, 10.80s/it]predicting train subjects:  64%|██████▍   | 199/311 [44:09<20:04, 10.75s/it]predicting train subjects:  64%|██████▍   | 200/311 [44:21<20:11, 10.92s/it]predicting train subjects:  65%|██████▍   | 201/311 [44:32<20:11, 11.02s/it]predicting train subjects:  65%|██████▍   | 202/311 [44:42<19:43, 10.86s/it]predicting train subjects:  65%|██████▌   | 203/311 [44:53<19:40, 10.93s/it]predicting train subjects:  66%|██████▌   | 204/311 [45:04<19:30, 10.94s/it]predicting train subjects:  66%|██████▌   | 205/311 [45:16<19:37, 11.11s/it]predicting train subjects:  66%|██████▌   | 206/311 [45:27<19:20, 11.05s/it]predicting train subjects:  67%|██████▋   | 207/311 [45:38<19:10, 11.06s/it]predicting train subjects:  67%|██████▋   | 208/311 [45:49<19:03, 11.10s/it]predicting train subjects:  67%|██████▋   | 209/311 [46:00<18:49, 11.08s/it]predicting train subjects:  68%|██████▊   | 210/311 [46:11<18:27, 10.97s/it]predicting train subjects:  68%|██████▊   | 211/311 [46:22<18:15, 10.95s/it]predicting train subjects:  68%|██████▊   | 212/311 [46:33<18:11, 11.03s/it]predicting train subjects:  68%|██████▊   | 213/311 [46:54<22:49, 13.98s/it]predicting train subjects:  69%|██████▉   | 214/311 [47:15<25:57, 16.06s/it]predicting train subjects:  69%|██████▉   | 215/311 [47:35<27:48, 17.38s/it]predicting train subjects:  69%|██████▉   | 216/311 [47:56<28:57, 18.29s/it]predicting train subjects:  70%|██████▉   | 217/311 [48:16<29:38, 18.92s/it]predicting train subjects:  70%|███████   | 218/311 [48:36<29:47, 19.22s/it]predicting train subjects:  70%|███████   | 219/311 [48:57<30:06, 19.63s/it]predicting train subjects:  71%|███████   | 220/311 [49:17<30:13, 19.92s/it]predicting train subjects:  71%|███████   | 221/311 [49:37<29:57, 19.98s/it]predicting train subjects:  71%|███████▏  | 222/311 [49:58<29:45, 20.06s/it]predicting train subjects:  72%|███████▏  | 223/311 [50:18<29:42, 20.25s/it]predicting train subjects:  72%|███████▏  | 224/311 [50:38<29:20, 20.23s/it]predicting train subjects:  72%|███████▏  | 225/311 [50:59<29:11, 20.37s/it]predicting train subjects:  73%|███████▎  | 226/311 [51:20<28:58, 20.45s/it]predicting train subjects:  73%|███████▎  | 227/311 [51:41<28:53, 20.64s/it]predicting train subjects:  73%|███████▎  | 228/311 [52:02<28:43, 20.76s/it]predicting train subjects:  74%|███████▎  | 229/311 [52:24<28:47, 21.07s/it]predicting train subjects:  74%|███████▍  | 230/311 [52:45<28:23, 21.03s/it]predicting train subjects:  74%|███████▍  | 231/311 [52:55<23:46, 17.83s/it]predicting train subjects:  75%|███████▍  | 232/311 [53:05<20:12, 15.35s/it]predicting train subjects:  75%|███████▍  | 233/311 [53:15<17:59, 13.84s/it]predicting train subjects:  75%|███████▌  | 234/311 [53:25<16:27, 12.83s/it]predicting train subjects:  76%|███████▌  | 235/311 [53:35<15:05, 11.91s/it]predicting train subjects:  76%|███████▌  | 236/311 [53:45<14:18, 11.44s/it]predicting train subjects:  76%|███████▌  | 237/311 [53:55<13:32, 10.98s/it]predicting train subjects:  77%|███████▋  | 238/311 [54:05<12:53, 10.59s/it]predicting train subjects:  77%|███████▋  | 239/311 [54:15<12:33, 10.47s/it]predicting train subjects:  77%|███████▋  | 240/311 [54:25<12:05, 10.21s/it]predicting train subjects:  77%|███████▋  | 241/311 [54:35<11:55, 10.22s/it]predicting train subjects:  78%|███████▊  | 242/311 [54:45<11:39, 10.13s/it]predicting train subjects:  78%|███████▊  | 243/311 [54:55<11:24, 10.07s/it]predicting train subjects:  78%|███████▊  | 244/311 [55:05<11:21, 10.17s/it]predicting train subjects:  79%|███████▉  | 245/311 [55:15<11:11, 10.18s/it]predicting train subjects:  79%|███████▉  | 246/311 [55:25<10:50, 10.00s/it]predicting train subjects:  79%|███████▉  | 247/311 [55:35<10:45, 10.09s/it]predicting train subjects:  80%|███████▉  | 248/311 [55:45<10:29, 10.00s/it]predicting train subjects:  80%|████████  | 249/311 [55:58<11:06, 10.74s/it]predicting train subjects:  80%|████████  | 250/311 [56:10<11:26, 11.26s/it]predicting train subjects:  81%|████████  | 251/311 [56:23<11:42, 11.71s/it]predicting train subjects:  81%|████████  | 252/311 [56:35<11:44, 11.94s/it]predicting train subjects:  81%|████████▏ | 253/311 [56:48<11:45, 12.16s/it]predicting train subjects:  82%|████████▏ | 254/311 [57:01<11:40, 12.30s/it]predicting train subjects:  82%|████████▏ | 255/311 [57:13<11:36, 12.43s/it]predicting train subjects:  82%|████████▏ | 256/311 [57:28<11:57, 13.04s/it]predicting train subjects:  83%|████████▎ | 257/311 [57:44<12:31, 13.91s/it]predicting train subjects:  83%|████████▎ | 258/311 [57:58<12:19, 13.95s/it]predicting train subjects:  83%|████████▎ | 259/311 [58:11<11:49, 13.64s/it]predicting train subjects:  84%|████████▎ | 260/311 [58:23<11:19, 13.33s/it]predicting train subjects:  84%|████████▍ | 261/311 [58:36<10:58, 13.18s/it]predicting train subjects:  84%|████████▍ | 262/311 [58:49<10:42, 13.11s/it]predicting train subjects:  85%|████████▍ | 263/311 [59:02<10:26, 13.04s/it]predicting train subjects:  85%|████████▍ | 264/311 [59:15<10:13, 13.05s/it]predicting train subjects:  85%|████████▌ | 265/311 [59:27<09:45, 12.74s/it]predicting train subjects:  86%|████████▌ | 266/311 [59:39<09:26, 12.60s/it]predicting train subjects:  86%|████████▌ | 267/311 [59:51<09:08, 12.45s/it]predicting train subjects:  86%|████████▌ | 268/311 [1:00:04<08:56, 12.49s/it]predicting train subjects:  86%|████████▋ | 269/311 [1:00:16<08:38, 12.36s/it]predicting train subjects:  87%|████████▋ | 270/311 [1:00:28<08:20, 12.20s/it]predicting train subjects:  87%|████████▋ | 271/311 [1:00:40<08:05, 12.15s/it]predicting train subjects:  87%|████████▋ | 272/311 [1:00:52<07:53, 12.14s/it]predicting train subjects:  88%|████████▊ | 273/311 [1:01:05<07:45, 12.24s/it]predicting train subjects:  88%|████████▊ | 274/311 [1:01:16<07:28, 12.11s/it]predicting train subjects:  88%|████████▊ | 275/311 [1:01:28<07:15, 12.08s/it]predicting train subjects:  89%|████████▊ | 276/311 [1:01:40<07:01, 12.04s/it]predicting train subjects:  89%|████████▉ | 277/311 [1:01:52<06:49, 12.03s/it]predicting train subjects:  89%|████████▉ | 278/311 [1:02:04<06:35, 11.99s/it]predicting train subjects:  90%|████████▉ | 279/311 [1:02:16<06:22, 11.95s/it]predicting train subjects:  90%|█████████ | 280/311 [1:02:29<06:17, 12.16s/it]predicting train subjects:  90%|█████████ | 281/311 [1:02:41<06:04, 12.16s/it]predicting train subjects:  91%|█████████ | 282/311 [1:02:53<05:48, 12.01s/it]predicting train subjects:  91%|█████████ | 283/311 [1:03:03<05:25, 11.62s/it]predicting train subjects:  91%|█████████▏| 284/311 [1:03:14<05:08, 11.44s/it]predicting train subjects:  92%|█████████▏| 285/311 [1:03:25<04:49, 11.13s/it]predicting train subjects:  92%|█████████▏| 286/311 [1:03:37<04:44, 11.39s/it]predicting train subjects:  92%|█████████▏| 287/311 [1:03:50<04:45, 11.88s/it]predicting train subjects:  93%|█████████▎| 288/311 [1:04:04<04:47, 12.49s/it]predicting train subjects:  93%|█████████▎| 289/311 [1:04:17<04:42, 12.84s/it]predicting train subjects:  93%|█████████▎| 290/311 [1:04:31<04:34, 13.08s/it]predicting train subjects:  94%|█████████▎| 291/311 [1:04:45<04:24, 13.25s/it]predicting train subjects:  94%|█████████▍| 292/311 [1:04:58<04:12, 13.31s/it]predicting train subjects:  94%|█████████▍| 293/311 [1:05:11<03:58, 13.27s/it]predicting train subjects:  95%|█████████▍| 294/311 [1:05:25<03:47, 13.35s/it]predicting train subjects:  95%|█████████▍| 295/311 [1:05:38<03:34, 13.42s/it]predicting train subjects:  95%|█████████▌| 296/311 [1:05:53<03:24, 13.66s/it]predicting train subjects:  95%|█████████▌| 297/311 [1:06:06<03:08, 13.47s/it]predicting train subjects:  96%|█████████▌| 298/311 [1:06:19<02:55, 13.54s/it]predicting train subjects:  96%|█████████▌| 299/311 [1:06:33<02:42, 13.56s/it]predicting train subjects:  96%|█████████▋| 300/311 [1:06:46<02:29, 13.57s/it]predicting train subjects:  97%|█████████▋| 301/311 [1:07:00<02:15, 13.59s/it]predicting train subjects:  97%|█████████▋| 302/311 [1:07:15<02:05, 13.90s/it]predicting train subjects:  97%|█████████▋| 303/311 [1:07:28<01:49, 13.70s/it]predicting train subjects:  98%|█████████▊| 304/311 [1:07:42<01:36, 13.78s/it]predicting train subjects:  98%|█████████▊| 305/311 [1:07:55<01:21, 13.55s/it]predicting train subjects:  98%|█████████▊| 306/311 [1:08:08<01:07, 13.48s/it]predicting train subjects:  99%|█████████▊| 307/311 [1:08:22<00:54, 13.61s/it]predicting train subjects:  99%|█████████▉| 308/311 [1:08:36<00:41, 13.74s/it]predicting train subjects:  99%|█████████▉| 309/311 [1:08:49<00:26, 13.43s/it]predicting train subjects: 100%|█████████▉| 310/311 [1:09:02<00:13, 13.38s/it]predicting train subjects: 100%|██████████| 311/311 [1:09:16<00:00, 13.54s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a’: File exists

Loading train:   0%|          | 0/311 [00:00<?, ?it/s]Loading train:   0%|          | 1/311 [00:18<1:34:55, 18.37s/it]Loading train:   1%|          | 2/311 [00:28<1:21:21, 15.80s/it]Loading train:   1%|          | 3/311 [00:38<1:12:54, 14.20s/it]Loading train:   1%|▏         | 4/311 [00:48<1:06:10, 12.93s/it]Loading train:   2%|▏         | 5/311 [00:57<1:00:08, 11.79s/it]Loading train:   2%|▏         | 6/311 [01:07<56:12, 11.06s/it]  Loading train:   2%|▏         | 7/311 [01:17<55:19, 10.92s/it]Loading train:   3%|▎         | 8/311 [01:30<58:07, 11.51s/it]Loading train:   3%|▎         | 9/311 [01:41<57:39, 11.46s/it]Loading train:   3%|▎         | 10/311 [01:51<54:51, 10.94s/it]Loading train:   4%|▎         | 11/311 [02:04<57:31, 11.51s/it]Loading train:   4%|▍         | 12/311 [02:14<54:41, 10.98s/it]Loading train:   4%|▍         | 13/311 [02:23<52:33, 10.58s/it]Loading train:   5%|▍         | 14/311 [02:36<54:53, 11.09s/it]Loading train:   5%|▍         | 15/311 [02:45<52:13, 10.59s/it]Loading train:   5%|▌         | 16/311 [02:54<50:17, 10.23s/it]Loading train:   5%|▌         | 17/311 [03:03<48:06,  9.82s/it]Loading train:   6%|▌         | 18/311 [03:12<46:39,  9.56s/it]Loading train:   6%|▌         | 19/311 [03:21<45:15,  9.30s/it]Loading train:   6%|▋         | 20/311 [03:30<44:55,  9.26s/it]Loading train:   7%|▋         | 21/311 [03:39<44:01,  9.11s/it]Loading train:   7%|▋         | 22/311 [03:48<44:08,  9.17s/it]Loading train:   7%|▋         | 23/311 [03:57<43:46,  9.12s/it]Loading train:   8%|▊         | 24/311 [04:07<44:08,  9.23s/it]Loading train:   8%|▊         | 25/311 [04:16<43:44,  9.18s/it]Loading train:   8%|▊         | 26/311 [04:25<43:43,  9.21s/it]Loading train:   9%|▊         | 27/311 [04:34<43:14,  9.14s/it]Loading train:   9%|▉         | 28/311 [04:43<42:52,  9.09s/it]Loading train:   9%|▉         | 29/311 [04:52<42:44,  9.09s/it]Loading train:  10%|▉         | 30/311 [05:01<42:37,  9.10s/it]Loading train:  10%|▉         | 31/311 [05:10<42:30,  9.11s/it]Loading train:  10%|█         | 32/311 [05:19<42:22,  9.11s/it]Loading train:  11%|█         | 33/311 [05:24<35:52,  7.74s/it]Loading train:  11%|█         | 34/311 [05:29<31:33,  6.83s/it]Loading train:  11%|█▏        | 35/311 [05:33<28:25,  6.18s/it]Loading train:  12%|█▏        | 36/311 [05:38<26:00,  5.67s/it]Loading train:  12%|█▏        | 37/311 [05:42<24:30,  5.37s/it]Loading train:  12%|█▏        | 38/311 [05:47<23:02,  5.07s/it]Loading train:  13%|█▎        | 39/311 [05:51<22:06,  4.88s/it]Loading train:  13%|█▎        | 40/311 [05:56<21:22,  4.73s/it]Loading train:  13%|█▎        | 41/311 [06:00<20:47,  4.62s/it]Loading train:  14%|█▎        | 42/311 [06:05<20:50,  4.65s/it]Loading train:  14%|█▍        | 43/311 [06:09<20:21,  4.56s/it]Loading train:  14%|█▍        | 44/311 [06:14<20:21,  4.58s/it]Loading train:  14%|█▍        | 45/311 [06:18<20:23,  4.60s/it]Loading train:  15%|█▍        | 46/311 [06:23<20:42,  4.69s/it]Loading train:  15%|█▌        | 47/311 [06:28<20:23,  4.63s/it]Loading train:  15%|█▌        | 48/311 [06:32<20:16,  4.63s/it]Loading train:  16%|█▌        | 49/311 [06:37<20:15,  4.64s/it]Loading train:  16%|█▌        | 50/311 [06:42<20:12,  4.64s/it]Loading train:  16%|█▋        | 51/311 [06:48<21:39,  5.00s/it]Loading train:  17%|█▋        | 52/311 [06:53<22:48,  5.29s/it]Loading train:  17%|█▋        | 53/311 [07:00<23:45,  5.53s/it]Loading train:  17%|█▋        | 54/311 [07:05<23:59,  5.60s/it]Loading train:  18%|█▊        | 55/311 [07:11<23:56,  5.61s/it]Loading train:  18%|█▊        | 56/311 [07:16<23:42,  5.58s/it]Loading train:  18%|█▊        | 57/311 [07:22<23:49,  5.63s/it]Loading train:  19%|█▊        | 58/311 [07:28<23:31,  5.58s/it]Loading train:  19%|█▉        | 59/311 [07:33<23:20,  5.56s/it]Loading train:  19%|█▉        | 60/311 [07:39<23:33,  5.63s/it]Loading train:  20%|█▉        | 61/311 [07:45<23:30,  5.64s/it]Loading train:  20%|█▉        | 62/311 [07:50<23:08,  5.58s/it]Loading train:  20%|██        | 63/311 [07:56<23:13,  5.62s/it]Loading train:  21%|██        | 64/311 [08:01<22:58,  5.58s/it]Loading train:  21%|██        | 65/311 [08:07<22:40,  5.53s/it]Loading train:  21%|██        | 66/311 [08:12<22:35,  5.53s/it]Loading train:  22%|██▏       | 67/311 [08:18<22:48,  5.61s/it]Loading train:  22%|██▏       | 68/311 [08:23<22:12,  5.48s/it]Loading train:  22%|██▏       | 69/311 [08:28<21:43,  5.39s/it]Loading train:  23%|██▎       | 70/311 [08:34<21:46,  5.42s/it]Loading train:  23%|██▎       | 71/311 [08:39<21:35,  5.40s/it]Loading train:  23%|██▎       | 72/311 [08:45<21:36,  5.42s/it]Loading train:  23%|██▎       | 73/311 [08:50<21:27,  5.41s/it]Loading train:  24%|██▍       | 74/311 [08:56<21:31,  5.45s/it]Loading train:  24%|██▍       | 75/311 [09:01<21:32,  5.48s/it]Loading train:  24%|██▍       | 76/311 [09:07<21:27,  5.48s/it]Loading train:  25%|██▍       | 77/311 [09:12<21:22,  5.48s/it]Loading train:  25%|██▌       | 78/311 [09:18<21:14,  5.47s/it]Loading train:  25%|██▌       | 79/311 [09:23<21:14,  5.49s/it]Loading train:  26%|██▌       | 80/311 [09:29<21:01,  5.46s/it]Loading train:  26%|██▌       | 81/311 [09:34<20:45,  5.42s/it]Loading train:  26%|██▋       | 82/311 [09:39<20:30,  5.37s/it]Loading train:  27%|██▋       | 83/311 [09:44<20:17,  5.34s/it]Loading train:  27%|██▋       | 84/311 [09:50<20:03,  5.30s/it]Loading train:  27%|██▋       | 85/311 [09:55<19:56,  5.30s/it]Loading train:  28%|██▊       | 86/311 [10:00<19:31,  5.20s/it]Loading train:  28%|██▊       | 87/311 [10:05<19:04,  5.11s/it]Loading train:  28%|██▊       | 88/311 [10:10<18:37,  5.01s/it]Loading train:  29%|██▊       | 89/311 [10:14<18:25,  4.98s/it]Loading train:  29%|██▉       | 90/311 [10:19<18:21,  4.98s/it]Loading train:  29%|██▉       | 91/311 [10:24<18:13,  4.97s/it]Loading train:  30%|██▉       | 92/311 [10:29<17:53,  4.90s/it]Loading train:  30%|██▉       | 93/311 [10:34<17:45,  4.89s/it]Loading train:  30%|███       | 94/311 [10:39<17:31,  4.84s/it]Loading train:  31%|███       | 95/311 [10:43<17:22,  4.83s/it]Loading train:  31%|███       | 96/311 [10:48<17:04,  4.77s/it]Loading train:  31%|███       | 97/311 [10:53<17:19,  4.86s/it]Loading train:  32%|███▏      | 98/311 [10:58<17:25,  4.91s/it]Loading train:  32%|███▏      | 99/311 [11:03<17:00,  4.81s/it]Loading train:  32%|███▏      | 100/311 [11:07<16:44,  4.76s/it]Loading train:  32%|███▏      | 101/311 [11:12<16:49,  4.81s/it]Loading train:  33%|███▎      | 102/311 [11:17<16:49,  4.83s/it]Loading train:  33%|███▎      | 103/311 [11:22<16:55,  4.88s/it]Loading train:  33%|███▎      | 104/311 [11:27<17:00,  4.93s/it]Loading train:  34%|███▍      | 105/311 [11:32<17:01,  4.96s/it]Loading train:  34%|███▍      | 106/311 [11:37<17:00,  4.98s/it]Loading train:  34%|███▍      | 107/311 [11:42<17:02,  5.01s/it]Loading train:  35%|███▍      | 108/311 [11:47<16:55,  5.00s/it]Loading train:  35%|███▌      | 109/311 [11:53<17:07,  5.09s/it]Loading train:  35%|███▌      | 110/311 [11:58<17:07,  5.11s/it]Loading train:  36%|███▌      | 111/311 [12:03<16:50,  5.05s/it]Loading train:  36%|███▌      | 112/311 [12:08<16:41,  5.03s/it]Loading train:  36%|███▋      | 113/311 [12:13<16:46,  5.08s/it]Loading train:  37%|███▋      | 114/311 [12:23<21:12,  6.46s/it]Loading train:  37%|███▋      | 115/311 [12:32<24:01,  7.36s/it]Loading train:  37%|███▋      | 116/311 [12:41<25:34,  7.87s/it]Loading train:  38%|███▊      | 117/311 [12:50<26:46,  8.28s/it]Loading train:  38%|███▊      | 118/311 [12:59<27:14,  8.47s/it]Loading train:  38%|███▊      | 119/311 [13:08<27:41,  8.65s/it]Loading train:  39%|███▊      | 120/311 [13:17<27:47,  8.73s/it]Loading train:  39%|███▉      | 121/311 [13:26<28:02,  8.85s/it]Loading train:  39%|███▉      | 122/311 [13:35<27:49,  8.83s/it]Loading train:  40%|███▉      | 123/311 [13:44<27:58,  8.93s/it]Loading train:  40%|███▉      | 124/311 [13:54<28:18,  9.08s/it]Loading train:  40%|████      | 125/311 [14:03<28:00,  9.03s/it]Loading train:  41%|████      | 126/311 [14:11<27:22,  8.88s/it]Loading train:  41%|████      | 127/311 [14:20<27:27,  8.95s/it]Loading train:  41%|████      | 128/311 [14:29<27:11,  8.91s/it]Loading train:  41%|████▏     | 129/311 [14:38<26:50,  8.85s/it]Loading train:  42%|████▏     | 130/311 [14:47<26:36,  8.82s/it]Loading train:  42%|████▏     | 131/311 [14:56<26:53,  8.96s/it]Loading train:  42%|████▏     | 132/311 [15:00<22:38,  7.59s/it]Loading train:  43%|████▎     | 133/311 [15:05<19:41,  6.63s/it]Loading train:  43%|████▎     | 134/311 [15:10<18:10,  6.16s/it]Loading train:  43%|████▎     | 135/311 [15:15<16:59,  5.79s/it]Loading train:  44%|████▎     | 136/311 [15:20<16:18,  5.59s/it]Loading train:  44%|████▍     | 137/311 [15:24<15:23,  5.30s/it]Loading train:  44%|████▍     | 138/311 [15:29<14:43,  5.11s/it]Loading train:  45%|████▍     | 139/311 [15:34<14:15,  4.98s/it]Loading train:  45%|████▌     | 140/311 [15:38<13:35,  4.77s/it]Loading train:  45%|████▌     | 141/311 [15:43<13:19,  4.71s/it]Loading train:  46%|████▌     | 142/311 [15:47<13:11,  4.68s/it]Loading train:  46%|████▌     | 143/311 [15:52<12:51,  4.59s/it]Loading train:  46%|████▋     | 144/311 [15:56<12:40,  4.56s/it]Loading train:  47%|████▋     | 145/311 [16:01<12:36,  4.56s/it]Loading train:  47%|████▋     | 146/311 [16:05<12:33,  4.57s/it]Loading train:  47%|████▋     | 147/311 [16:10<12:28,  4.56s/it]Loading train:  48%|████▊     | 148/311 [16:14<12:14,  4.50s/it]Loading train:  48%|████▊     | 149/311 [16:19<12:01,  4.45s/it]Loading train:  48%|████▊     | 150/311 [16:24<13:02,  4.86s/it]Loading train:  49%|████▊     | 151/311 [16:30<13:48,  5.18s/it]Loading train:  49%|████▉     | 152/311 [16:36<14:10,  5.35s/it]Loading train:  49%|████▉     | 153/311 [16:42<14:25,  5.48s/it]Loading train:  50%|████▉     | 154/311 [16:47<14:12,  5.43s/it]Loading train:  50%|████▉     | 155/311 [16:52<13:46,  5.30s/it]Loading train:  50%|█████     | 156/311 [16:58<13:55,  5.39s/it]Loading train:  50%|█████     | 157/311 [17:03<14:01,  5.46s/it]Loading train:  51%|█████     | 158/311 [17:09<13:51,  5.44s/it]Loading train:  51%|█████     | 159/311 [17:14<13:53,  5.48s/it]Loading train:  51%|█████▏    | 160/311 [17:20<13:56,  5.54s/it]Loading train:  52%|█████▏    | 161/311 [17:26<13:51,  5.54s/it]Loading train:  52%|█████▏    | 162/311 [17:31<13:48,  5.56s/it]Loading train:  52%|█████▏    | 163/311 [17:37<13:47,  5.59s/it]Loading train:  53%|█████▎    | 164/311 [17:42<13:30,  5.52s/it]Loading train:  53%|█████▎    | 165/311 [17:48<13:24,  5.51s/it]Loading train:  53%|█████▎    | 166/311 [17:53<13:14,  5.48s/it]Loading train:  54%|█████▎    | 167/311 [17:58<12:51,  5.36s/it]Loading train:  54%|█████▍    | 168/311 [18:03<12:31,  5.26s/it]Loading train:  54%|█████▍    | 169/311 [18:08<12:27,  5.26s/it]Loading train:  55%|█████▍    | 170/311 [18:14<12:26,  5.29s/it]Loading train:  55%|█████▍    | 171/311 [18:19<12:18,  5.28s/it]Loading train:  55%|█████▌    | 172/311 [18:24<12:19,  5.32s/it]Loading train:  56%|█████▌    | 173/311 [18:30<12:23,  5.39s/it]Loading train:  56%|█████▌    | 174/311 [18:36<12:24,  5.43s/it]Loading train:  56%|█████▋    | 175/311 [18:41<12:17,  5.43s/it]Loading train:  57%|█████▋    | 176/311 [18:46<12:18,  5.47s/it]Loading train:  57%|█████▋    | 177/311 [18:52<12:12,  5.47s/it]Loading train:  57%|█████▋    | 178/311 [18:58<12:28,  5.63s/it]Loading train:  58%|█████▊    | 179/311 [19:04<12:28,  5.67s/it]Loading train:  58%|█████▊    | 180/311 [19:09<12:13,  5.60s/it]Loading train:  58%|█████▊    | 181/311 [19:14<11:57,  5.52s/it]Loading train:  59%|█████▊    | 182/311 [19:20<11:47,  5.49s/it]Loading train:  59%|█████▉    | 183/311 [19:25<11:43,  5.49s/it]Loading train:  59%|█████▉    | 184/311 [19:30<11:14,  5.31s/it]Loading train:  59%|█████▉    | 185/311 [19:35<10:50,  5.17s/it]Loading train:  60%|█████▉    | 186/311 [19:40<10:47,  5.18s/it]Loading train:  60%|██████    | 187/311 [19:45<10:39,  5.16s/it]Loading train:  60%|██████    | 188/311 [19:50<10:25,  5.09s/it]Loading train:  61%|██████    | 189/311 [19:56<10:24,  5.12s/it]Loading train:  61%|██████    | 190/311 [20:01<10:17,  5.10s/it]Loading train:  61%|██████▏   | 191/311 [20:05<10:01,  5.01s/it]Loading train:  62%|██████▏   | 192/311 [20:10<09:53,  4.99s/it]Loading train:  62%|██████▏   | 193/311 [20:16<09:59,  5.08s/it]Loading train:  62%|██████▏   | 194/311 [20:21<09:52,  5.06s/it]Loading train:  63%|██████▎   | 195/311 [20:26<09:44,  5.04s/it]Loading train:  63%|██████▎   | 196/311 [20:31<09:41,  5.06s/it]Loading train:  63%|██████▎   | 197/311 [20:36<09:33,  5.03s/it]Loading train:  64%|██████▎   | 198/311 [20:41<09:23,  4.99s/it]Loading train:  64%|██████▍   | 199/311 [20:46<09:16,  4.97s/it]Loading train:  64%|██████▍   | 200/311 [20:51<09:11,  4.97s/it]Loading train:  65%|██████▍   | 201/311 [20:56<09:07,  4.98s/it]Loading train:  65%|██████▍   | 202/311 [21:01<09:13,  5.08s/it]Loading train:  65%|██████▌   | 203/311 [21:06<09:13,  5.12s/it]Loading train:  66%|██████▌   | 204/311 [21:11<09:14,  5.18s/it]Loading train:  66%|██████▌   | 205/311 [21:16<09:02,  5.12s/it]Loading train:  66%|██████▌   | 206/311 [21:22<09:05,  5.19s/it]Loading train:  67%|██████▋   | 207/311 [21:27<08:59,  5.19s/it]Loading train:  67%|██████▋   | 208/311 [21:32<08:53,  5.18s/it]Loading train:  67%|██████▋   | 209/311 [21:37<08:54,  5.24s/it]Loading train:  68%|██████▊   | 210/311 [21:42<08:36,  5.11s/it]Loading train:  68%|██████▊   | 211/311 [21:47<08:16,  4.96s/it]Loading train:  68%|██████▊   | 212/311 [21:52<08:09,  4.95s/it]Loading train:  68%|██████▊   | 213/311 [22:01<10:11,  6.24s/it]Loading train:  69%|██████▉   | 214/311 [22:10<11:29,  7.11s/it]Loading train:  69%|██████▉   | 215/311 [22:19<12:14,  7.65s/it]Loading train:  69%|██████▉   | 216/311 [22:28<12:51,  8.12s/it]Loading train:  70%|██████▉   | 217/311 [22:37<13:00,  8.30s/it]Loading train:  70%|███████   | 218/311 [22:46<13:13,  8.53s/it]Loading train:  70%|███████   | 219/311 [22:55<13:13,  8.63s/it]Loading train:  71%|███████   | 220/311 [23:04<13:22,  8.82s/it]Loading train:  71%|███████   | 221/311 [23:13<13:15,  8.84s/it]Loading train:  71%|███████▏  | 222/311 [23:22<13:05,  8.83s/it]Loading train:  72%|███████▏  | 223/311 [23:30<12:49,  8.74s/it]Loading train:  72%|███████▏  | 224/311 [23:39<12:45,  8.80s/it]Loading train:  72%|███████▏  | 225/311 [23:48<12:38,  8.82s/it]Loading train:  73%|███████▎  | 226/311 [23:57<12:27,  8.80s/it]Loading train:  73%|███████▎  | 227/311 [24:06<12:26,  8.89s/it]Loading train:  73%|███████▎  | 228/311 [24:15<12:17,  8.88s/it]Loading train:  74%|███████▎  | 229/311 [24:24<12:21,  9.05s/it]Loading train:  74%|███████▍  | 230/311 [24:33<12:13,  9.05s/it]Loading train:  74%|███████▍  | 231/311 [24:38<10:20,  7.76s/it]Loading train:  75%|███████▍  | 232/311 [24:43<08:59,  6.83s/it]Loading train:  75%|███████▍  | 233/311 [24:47<07:59,  6.15s/it]Loading train:  75%|███████▌  | 234/311 [24:52<07:21,  5.73s/it]Loading train:  76%|███████▌  | 235/311 [24:57<06:48,  5.38s/it]Loading train:  76%|███████▌  | 236/311 [25:01<06:22,  5.10s/it]Loading train:  76%|███████▌  | 237/311 [25:06<06:13,  5.05s/it]Loading train:  77%|███████▋  | 238/311 [25:11<06:01,  4.95s/it]Loading train:  77%|███████▋  | 239/311 [25:15<05:46,  4.81s/it]Loading train:  77%|███████▋  | 240/311 [25:20<05:33,  4.70s/it]Loading train:  77%|███████▋  | 241/311 [25:24<05:29,  4.71s/it]Loading train:  78%|███████▊  | 242/311 [25:29<05:24,  4.71s/it]Loading train:  78%|███████▊  | 243/311 [25:34<05:19,  4.69s/it]Loading train:  78%|███████▊  | 244/311 [25:39<05:16,  4.72s/it]Loading train:  79%|███████▉  | 245/311 [25:43<05:11,  4.72s/it]Loading train:  79%|███████▉  | 246/311 [25:48<05:04,  4.69s/it]Loading train:  79%|███████▉  | 247/311 [25:53<04:59,  4.68s/it]Loading train:  80%|███████▉  | 248/311 [25:57<04:54,  4.68s/it]Loading train:  80%|████████  | 249/311 [26:03<05:03,  4.89s/it]Loading train:  80%|████████  | 250/311 [26:08<05:10,  5.09s/it]Loading train:  81%|████████  | 251/311 [26:14<05:15,  5.26s/it]Loading train:  81%|████████  | 252/311 [26:20<05:22,  5.46s/it]Loading train:  81%|████████▏ | 253/311 [26:25<05:18,  5.49s/it]Loading train:  82%|████████▏ | 254/311 [26:31<05:18,  5.58s/it]Loading train:  82%|████████▏ | 255/311 [26:37<05:17,  5.66s/it]Loading train:  82%|████████▏ | 256/311 [26:43<05:09,  5.62s/it]Loading train:  83%|████████▎ | 257/311 [26:49<05:10,  5.76s/it]Loading train:  83%|████████▎ | 258/311 [26:54<04:57,  5.61s/it]Loading train:  83%|████████▎ | 259/311 [27:00<04:52,  5.63s/it]Loading train:  84%|████████▎ | 260/311 [27:05<04:51,  5.72s/it]Loading train:  84%|████████▍ | 261/311 [27:11<04:41,  5.62s/it]Loading train:  84%|████████▍ | 262/311 [27:17<04:37,  5.65s/it]Loading train:  85%|████████▍ | 263/311 [27:22<04:33,  5.70s/it]Loading train:  85%|████████▍ | 264/311 [27:28<04:22,  5.59s/it]Loading train:  85%|████████▌ | 265/311 [27:33<04:17,  5.60s/it]Loading train:  86%|████████▌ | 266/311 [27:39<04:19,  5.76s/it]Loading train:  86%|████████▌ | 267/311 [27:45<04:14,  5.79s/it]Loading train:  86%|████████▌ | 268/311 [27:51<04:10,  5.82s/it]Loading train:  86%|████████▋ | 269/311 [27:57<04:01,  5.75s/it]Loading train:  87%|████████▋ | 270/311 [28:02<03:49,  5.60s/it]Loading train:  87%|████████▋ | 271/311 [28:08<03:44,  5.62s/it]Loading train:  87%|████████▋ | 272/311 [28:13<03:35,  5.54s/it]Loading train:  88%|████████▊ | 273/311 [28:19<03:29,  5.51s/it]Loading train:  88%|████████▊ | 274/311 [28:24<03:25,  5.57s/it]Loading train:  88%|████████▊ | 275/311 [28:30<03:19,  5.53s/it]Loading train:  89%|████████▊ | 276/311 [28:35<03:12,  5.51s/it]Loading train:  89%|████████▉ | 277/311 [28:41<03:07,  5.51s/it]Loading train:  89%|████████▉ | 278/311 [28:46<02:58,  5.42s/it]Loading train:  90%|████████▉ | 279/311 [28:51<02:50,  5.34s/it]Loading train:  90%|█████████ | 280/311 [28:57<02:48,  5.45s/it]Loading train:  90%|█████████ | 281/311 [29:02<02:43,  5.44s/it]Loading train:  91%|█████████ | 282/311 [29:07<02:35,  5.37s/it]Loading train:  91%|█████████ | 283/311 [29:12<02:28,  5.29s/it]Loading train:  91%|█████████▏| 284/311 [29:18<02:21,  5.25s/it]Loading train:  92%|█████████▏| 285/311 [29:22<02:13,  5.14s/it]Loading train:  92%|█████████▏| 286/311 [29:27<02:07,  5.10s/it]Loading train:  92%|█████████▏| 287/311 [29:33<02:03,  5.13s/it]Loading train:  93%|█████████▎| 288/311 [29:38<01:56,  5.06s/it]Loading train:  93%|█████████▎| 289/311 [29:43<01:51,  5.05s/it]Loading train:  93%|█████████▎| 290/311 [29:48<01:47,  5.10s/it]Loading train:  94%|█████████▎| 291/311 [29:53<01:41,  5.09s/it]Loading train:  94%|█████████▍| 292/311 [29:58<01:34,  5.00s/it]Loading train:  94%|█████████▍| 293/311 [30:03<01:30,  5.05s/it]Loading train:  95%|█████████▍| 294/311 [30:08<01:26,  5.10s/it]Loading train:  95%|█████████▍| 295/311 [30:13<01:20,  5.05s/it]Loading train:  95%|█████████▌| 296/311 [30:18<01:16,  5.10s/it]Loading train:  95%|█████████▌| 297/311 [30:23<01:12,  5.16s/it]Loading train:  96%|█████████▌| 298/311 [30:29<01:06,  5.13s/it]Loading train:  96%|█████████▌| 299/311 [30:34<01:01,  5.16s/it]Loading train:  96%|█████████▋| 300/311 [30:39<00:56,  5.10s/it]Loading train:  97%|█████████▋| 301/311 [30:43<00:49,  4.97s/it]Loading train:  97%|█████████▋| 302/311 [30:48<00:44,  4.98s/it]Loading train:  97%|█████████▋| 303/311 [30:54<00:40,  5.06s/it]Loading train:  98%|█████████▊| 304/311 [30:59<00:35,  5.01s/it]Loading train:  98%|█████████▊| 305/311 [31:04<00:30,  5.05s/it]Loading train:  98%|█████████▊| 306/311 [31:09<00:25,  5.12s/it]Loading train:  99%|█████████▊| 307/311 [31:14<00:20,  5.16s/it]Loading train:  99%|█████████▉| 308/311 [31:19<00:15,  5.10s/it]Loading train:  99%|█████████▉| 309/311 [31:24<00:10,  5.14s/it]Loading train: 100%|█████████▉| 310/311 [31:30<00:05,  5.15s/it]Loading train: 100%|██████████| 311/311 [31:35<00:00,  5.20s/it]
concatenating: train:   0%|          | 0/311 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/311 [00:00<00:04, 63.37it/s]concatenating: train:   5%|▍         | 14/311 [00:00<00:04, 63.10it/s]concatenating: train:   6%|▌         | 19/311 [00:00<00:04, 58.50it/s]concatenating: train:   7%|▋         | 23/311 [00:00<00:05, 49.10it/s]concatenating: train:   9%|▊         | 27/311 [00:00<00:06, 45.34it/s]concatenating: train:  11%|█         | 34/311 [00:00<00:05, 48.99it/s]concatenating: train:  13%|█▎        | 40/311 [00:00<00:05, 49.78it/s]concatenating: train:  16%|█▌        | 49/311 [00:00<00:04, 56.98it/s]concatenating: train:  18%|█▊        | 56/311 [00:00<00:04, 58.63it/s]concatenating: train:  22%|██▏       | 68/311 [00:01<00:03, 69.18it/s]concatenating: train:  30%|███       | 94/311 [00:01<00:02, 88.67it/s]concatenating: train:  41%|████      | 127/311 [00:01<00:01, 113.39it/s]concatenating: train:  47%|████▋     | 146/311 [00:01<00:01, 106.95it/s]concatenating: train:  52%|█████▏    | 163/311 [00:01<00:01, 103.53it/s]concatenating: train:  57%|█████▋    | 178/311 [00:01<00:01, 107.28it/s]concatenating: train:  62%|██████▏   | 192/311 [00:01<00:01, 113.10it/s]concatenating: train:  66%|██████▌   | 206/311 [00:02<00:00, 116.47it/s]concatenating: train:  71%|███████   | 220/311 [00:02<00:00, 118.91it/s]concatenating: train:  75%|███████▍  | 233/311 [00:02<00:00, 120.66it/s]concatenating: train:  79%|███████▉  | 246/311 [00:02<00:00, 120.70it/s]concatenating: train:  83%|████████▎ | 259/311 [00:02<00:00, 119.14it/s]concatenating: train:  87%|████████▋ | 272/311 [00:02<00:00, 119.52it/s]concatenating: train:  92%|█████████▏| 285/311 [00:02<00:00, 113.48it/s]concatenating: train:  95%|█████████▌| 297/311 [00:02<00:00, 102.51it/s]concatenating: train:  99%|█████████▉| 308/311 [00:03<00:00, 81.41it/s] concatenating: train: 100%|██████████| 311/311 [00:03<00:00, 100.11it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:35, 11.93s/it]Loading test:  50%|█████     | 2/4 [00:23<00:23, 11.71s/it]Loading test:  75%|███████▌  | 3/4 [00:35<00:11, 11.77s/it]Loading test: 100%|██████████| 4/4 [00:46<00:00, 11.66s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 46.69it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 2  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a
---------------------------------------------------------------
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 40)   160         conv2d_7[0][0]                   2019-07-07 21:07:55.538908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 21:07:55.539009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 21:07:55.539026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 21:07:55.539037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 21:07:55.598583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14197 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 224,906
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [5.86066190e-02 2.84688586e-02 1.21642213e-01 1.04576120e-02
 3.14646619e-02 5.44310893e-03 7.20519791e-02 1.12887958e-01
 7.85252165e-02 1.27448500e-02 2.91951514e-01 1.75516909e-01
 2.38500254e-04]
Train on 12832 samples, validate on 168 samples
Epoch 1/300
 - 23s - loss: 15254.6004 - acc: 0.8693 - mDice: 0.1572 - val_loss: 8293.6316 - val_acc: 0.9073 - val_mDice: 0.2914

Epoch 00001: val_mDice improved from -inf to 0.29145, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 13s - loss: 5894.7875 - acc: 0.8988 - mDice: 0.3506 - val_loss: 4201.0891 - val_acc: 0.9109 - val_mDice: 0.4212

Epoch 00002: val_mDice improved from 0.29145 to 0.42120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 13s - loss: 4354.5981 - acc: 0.9070 - mDice: 0.4427 - val_loss: 3203.3208 - val_acc: 0.9086 - val_mDice: 0.4995

Epoch 00003: val_mDice improved from 0.42120 to 0.49954, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 13s - loss: 3508.4881 - acc: 0.9136 - mDice: 0.5086 - val_loss: 2870.3019 - val_acc: 0.9160 - val_mDice: 0.5391

Epoch 00004: val_mDice improved from 0.49954 to 0.53913, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 13s - loss: 3041.7127 - acc: 0.9195 - mDice: 0.5534 - val_loss: 2561.6460 - val_acc: 0.9267 - val_mDice: 0.5757

Epoch 00005: val_mDice improved from 0.53913 to 0.57571, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 13s - loss: 2763.0068 - acc: 0.9244 - mDice: 0.5830 - val_loss: 2506.0021 - val_acc: 0.9279 - val_mDice: 0.5864

Epoch 00006: val_mDice improved from 0.57571 to 0.58639, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 13s - loss: 2532.3444 - acc: 0.9280 - mDice: 0.6073 - val_loss: 2147.8598 - val_acc: 0.9348 - val_mDice: 0.6200

Epoch 00007: val_mDice improved from 0.58639 to 0.61999, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 13s - loss: 2294.4345 - acc: 0.9311 - mDice: 0.6323 - val_loss: 2048.0113 - val_acc: 0.9369 - val_mDice: 0.6311

Epoch 00008: val_mDice improved from 0.61999 to 0.63111, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 13s - loss: 2145.7014 - acc: 0.9336 - mDice: 0.6494 - val_loss: 1986.2879 - val_acc: 0.9375 - val_mDice: 0.6389

Epoch 00009: val_mDice improved from 0.63111 to 0.63887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 14s - loss: 2033.5865 - acc: 0.9356 - mDice: 0.6634 - val_loss: 1865.7609 - val_acc: 0.9415 - val_mDice: 0.6560

Epoch 00010: val_mDice improved from 0.63887 to 0.65601, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 13s - loss: 1936.1940 - acc: 0.9377 - mDice: 0.6760 - val_loss: 1828.5160 - val_acc: 0.9439 - val_mDice: 0.6614

Epoch 00011: val_mDice improved from 0.65601 to 0.66136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 12/300
 - 14s - loss: 1865.5488 - acc: 0.9391 - mDice: 0.6854 - val_loss: 1822.2324 - val_acc: 0.9435 - val_mDice: 0.6625

Epoch 00012: val_mDice improved from 0.66136 to 0.66253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 12s - loss: 1806.7650 - acc: 0.9405 - mDice: 0.6935 - val_loss: 1826.7922 - val_acc: 0.9439 - val_mDice: 0.6633

Epoch 00013: val_mDice improved from 0.66253 to 0.66334, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 13s - loss: 1758.2901 - acc: 0.9415 - mDice: 0.7001 - val_loss: 1760.2409 - val_acc: 0.9460 - val_mDice: 0.6719

Epoch 00014: val_mDice improved from 0.66334 to 0.67192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 15/300
 - 12s - loss: 1711.7762 - acc: 0.9423 - mDice: 0.7067 - val_loss: 1771.1969 - val_acc: 0.9437 - val_mDice: 0.6682

Epoch 00015: val_mDice did not improve from 0.67192
Epoch 16/300
 - 13s - loss: 1667.8579 - acc: 0.9433 - mDice: 0.7128 - val_loss: 1724.0721 - val_acc: 0.9468 - val_mDice: 0.6778

Epoch 00016: val_mDice improved from 0.67192 to 0.67783, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 17/300
 - 13s - loss: 1632.3953 - acc: 0.9440 - mDice: 0.7179 - val_loss: 1709.2819 - val_acc: 0.9489 - val_mDice: 0.6794

Epoch 00017: val_mDice improved from 0.67783 to 0.67938, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 18/300
 - 14s - loss: 1597.4274 - acc: 0.9448 - mDice: 0.7230 - val_loss: 1707.8355 - val_acc: 0.9467 - val_mDice: 0.6797

Epoch 00018: val_mDice improved from 0.67938 to 0.67973, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 14s - loss: 1562.4147 - acc: 0.9454 - mDice: 0.7280 - val_loss: 1698.6762 - val_acc: 0.9482 - val_mDice: 0.6816

Epoch 00019: val_mDice improved from 0.67973 to 0.68157, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 20/300
 - 16s - loss: 1535.1524 - acc: 0.9459 - mDice: 0.7319 - val_loss: 1665.6740 - val_acc: 0.9483 - val_mDice: 0.6874

Epoch 00020: val_mDice improved from 0.68157 to 0.68742, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 13s - loss: 1505.0960 - acc: 0.9466 - mDice: 0.7364 - val_loss: 1707.8760 - val_acc: 0.9467 - val_mDice: 0.6771

Epoch 00021: val_mDice did not improve from 0.68742
Epoch 22/300
 - 14s - loss: 1471.9184 - acc: 0.9471 - mDice: 0.7412 - val_loss: 1670.0643 - val_acc: 0.9514 - val_mDice: 0.6865

Epoch 00022: val_mDice did not improve from 0.68742
Epoch 23/300
 - 13s - loss: 1447.2166 - acc: 0.9477 - mDice: 0.7449 - val_loss: 1709.3213 - val_acc: 0.9468 - val_mDice: 0.6792

Epoch 00023: val_mDice did not improve from 0.68742
Epoch 24/300
 - 14s - loss: 1423.9117 - acc: 0.9482 - mDice: 0.7484 - val_loss: 1668.3928 - val_acc: 0.9502 - val_mDice: 0.6855

Epoch 00024: val_mDice did not improve from 0.68742
Epoch 25/300
 - 14s - loss: 1404.4624 - acc: 0.9486 - mDice: 0.7514 - val_loss: 1640.4876 - val_acc: 0.9510 - val_mDice: 0.6907

Epoch 00025: val_mDice improved from 0.68742 to 0.69067, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 26/300
 - 13s - loss: 1377.0511 - acc: 0.9490 - mDice: 0.7554 - val_loss: 1641.8688 - val_acc: 0.9510 - val_mDice: 0.6908

Epoch 00026: val_mDice improved from 0.69067 to 0.69082, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 27/300
 - 13s - loss: 1356.0373 - acc: 0.9493 - mDice: 0.7587 - val_loss: 1635.7527 - val_acc: 0.9512 - val_mDice: 0.6907

Epoch 00027: val_mDice did not improve from 0.69082
Epoch 28/300
 - 13s - loss: 1339.4087 - acc: 0.9498 - mDice: 0.7612 - val_loss: 1651.4547 - val_acc: 0.9505 - val_mDice: 0.6893

Epoch 00028: val_mDice did not improve from 0.69082
Epoch 29/300
 - 13s - loss: 1318.9929 - acc: 0.9502 - mDice: 0.7644 - val_loss: 1704.1135 - val_acc: 0.9530 - val_mDice: 0.6820

Epoch 00029: val_mDice did not improve from 0.69082
Epoch 30/300
 - 14s - loss: 1297.5301 - acc: 0.9505 - mDice: 0.7676 - val_loss: 1658.7960 - val_acc: 0.9531 - val_mDice: 0.6894

Epoch 00030: val_mDice did not improve from 0.69082
Epoch 31/300
 - 14s - loss: 1282.8305 - acc: 0.9509 - mDice: 0.7700 - val_loss: 1696.9367 - val_acc: 0.9538 - val_mDice: 0.6822

Epoch 00031: val_mDice did not improve from 0.69082
Epoch 32/300
 - 16s - loss: 1271.4440 - acc: 0.9510 - mDice: 0.7717 - val_loss: 1612.5410 - val_acc: 0.9530 - val_mDice: 0.6951

Epoch 00032: val_mDice improved from 0.69082 to 0.69505, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 15s - loss: 1253.3933 - acc: 0.9514 - mDice: 0.7745 - val_loss: 1624.6213 - val_acc: 0.9528 - val_mDice: 0.6940

Epoch 00033: val_mDice did not improve from 0.69505
Epoch 34/300
 - 13s - loss: 1241.9297 - acc: 0.9515 - mDice: 0.7763 - val_loss: 1693.8908 - val_acc: 0.9536 - val_mDice: 0.6856

Epoch 00034: val_mDice did not improve from 0.69505
Epoch 35/300
 - 14s - loss: 1230.1301 - acc: 0.9517 - mDice: 0.7781 - val_loss: 1732.4482 - val_acc: 0.9534 - val_mDice: 0.6766

Epoch 00035: val_mDice did not improve from 0.69505
Epoch 36/300
 - 13s - loss: 1216.0177 - acc: 0.9522 - mDice: 0.7804 - val_loss: 1769.4255 - val_acc: 0.9545 - val_mDice: 0.6728

Epoch 00036: val_mDice did not improve from 0.69505
Epoch 37/300
 - 14s - loss: 1200.2470 - acc: 0.9523 - mDice: 0.7828 - val_loss: 1701.3906 - val_acc: 0.9530 - val_mDice: 0.6827

Epoch 00037: val_mDice did not improve from 0.69505
Epoch 38/300
 - 13s - loss: 1185.3157 - acc: 0.9527 - mDice: 0.7852 - val_loss: 1640.8424 - val_acc: 0.9556 - val_mDice: 0.6919

Epoch 00038: val_mDice did not improve from 0.69505
Epoch 39/300
 - 15s - loss: 1176.3641 - acc: 0.9529 - mDice: 0.7866 - val_loss: 1748.6506 - val_acc: 0.9532 - val_mDice: 0.6760

Epoch 00039: val_mDice did not improve from 0.69505
Epoch 40/300
 - 13s - loss: 1157.3148 - acc: 0.9531 - mDice: 0.7896 - val_loss: 1663.8314 - val_acc: 0.9520 - val_mDice: 0.6880

Epoch 00040: val_mDice did not improve from 0.69505
Epoch 41/300
 - 14s - loss: 1148.0663 - acc: 0.9532 - mDice: 0.7910 - val_loss: 1658.7651 - val_acc: 0.9562 - val_mDice: 0.6900

Epoch 00041: val_mDice did not improve from 0.69505
Epoch 42/300
 - 14s - loss: 1134.1680 - acc: 0.9534 - mDice: 0.7933 - val_loss: 1685.2632 - val_acc: 0.9548 - val_mDice: 0.6862

Epoch 00042: val_mDice did not improve from 0.69505
Epoch 43/300
 - 14s - loss: 1129.5999 - acc: 0.9537 - mDice: 0.7940 - val_loss: 1726.8742 - val_acc: 0.9552 - val_mDice: 0.6781

Epoch 00043: val_mDice did not improve from 0.69505
Epoch 44/300
 - 14s - loss: 1120.8645 - acc: 0.9539 - mDice: 0.7955 - val_loss: 1597.0725 - val_acc: 0.9577 - val_mDice: 0.6983

Epoch 00044: val_mDice improved from 0.69505 to 0.69826, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 45/300
 - 13s - loss: 1107.8069 - acc: 0.9540 - mDice: 0.7975 - val_loss: 1659.9713 - val_acc: 0.9532 - val_mDice: 0.6877

Epoch 00045: val_mDice did not improve from 0.69826
Epoch 46/300
 - 14s - loss: 1101.7954 - acc: 0.9542 - mDice: 0.7985 - val_loss: 1573.0013 - val_acc: 0.9574 - val_mDice: 0.7006

Epoch 00046: val_mDice improved from 0.69826 to 0.70058, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet_NL3_LS_MyJoint_US1_CSFn1_Init_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 47/300
 - 13s - loss: 1090.9792 - acc: 0.9543 - mDice: 0.8003 - val_loss: 1613.9354 - val_acc: 0.9559 - val_mDice: 0.6965

Epoch 00047: val_mDice did not improve from 0.70058
Epoch 48/300
 - 14s - loss: 1078.9369 - acc: 0.9546 - mDice: 0.8022 - val_loss: 1630.1535 - val_acc: 0.9554 - val_mDice: 0.6934

Epoch 00048: val_mDice did not improve from 0.70058
Epoch 49/300
 - 12s - loss: 1074.0283 - acc: 0.9546 - mDice: 0.8030 - val_loss: 1686.0579 - val_acc: 0.9553 - val_mDice: 0.6857

Epoch 00049: val_mDice did not improve from 0.70058
Epoch 50/300
 - 13s - loss: 1060.4538 - acc: 0.9549 - mDice: 0.8052 - val_loss: 1618.2453 - val_acc: 0.9577 - val_mDice: 0.6961

Epoch 00050: val_mDice did not improve from 0.70058
Epoch 51/300
 - 12s - loss: 1055.0097 - acc: 0.9549 - mDice: 0.8060 - val_loss: 1731.3869 - val_acc: 0.9577 - val_mDice: 0.6789

Epoch 00051: val_mDice did not improve from 0.70058
Epoch 52/300
 - 13s - loss: 1051.4401 - acc: 0.9551 - mDice: 0.8067 - val_loss: 1624.2002 - val_acc: 0.9571 - val_mDice: 0.6941

Epoch 00052: val_mDice did not improve from 0.70058
Epoch 53/300
 - 13s - loss: 1038.0656 - acc: 0.9552 - mDice: 0.8089 - val_loss: 1717.8687 - val_acc: 0.9559 - val_mDice: 0.6807

Epoch 00053: val_mDice did not improve from 0.70058
Epoch 54/300
 - 12s - loss: 1030.7913 - acc: 0.9554 - mDice: 0.8101 - val_loss: 1636.5952 - val_acc: 0.9563 - val_mDice: 0.6909

Epoch 00054: val_mDice did not improve from 0.70058
Epoch 55/300
 - 13s - loss: 1023.1741 - acc: 0.9556 - mDice: 0.8113 - val_loss: 1699.1556 - val_acc: 0.9568 - val_mDice: 0.6866

Epoch 00055: val_mDice did not improve from 0.70058
Epoch 56/300
 - 12s - loss: 1015.3242 - acc: 0.9558 - mDice: 0.8126 - val_loss: 1637.0285 - val_acc: 0.9547 - val_mDice: 0.6904

Epoch 00056: val_mDice did not improve from 0.70058
Epoch 57/300
 - 13s - loss: 1006.9638 - acc: 0.9559 - mDice: 0.8140 - val_loss: 1688.9988 - val_acc: 0.9566 - val_mDice: 0.6825

Epoch 00057: val_mDice did not improve from 0.70058
Epoch 58/300
 - 13s - loss: 998.6281 - acc: 0.9560 - mDice: 0.8153 - val_loss: 1583.5584 - val_acc: 0.9582 - val_mDice: 0.6998

Epoch 00058: val_mDice did not improve from 0.70058
Epoch 59/300
 - 12s - loss: 991.8081 - acc: 0.9561 - mDice: 0.8164 - val_loss: 1615.1017 - val_acc: 0.9562 - val_mDice: 0.6933

Epoch 00059: val_mDice did not improve from 0.70058
Epoch 60/300
 - 13s - loss: 989.0858 - acc: 0.9562 - mDice: 0.8169 - val_loss: 1654.9687 - val_acc: 0.9565 - val_mDice: 0.6881

Epoch 00060: val_mDice did not improve from 0.70058
Epoch 61/300
 - 12s - loss: 986.8486 - acc: 0.9562 - mDice: 0.8173 - val_loss: 1617.5129 - val_acc: 0.9581 - val_mDice: 0.6944

Epoch 00061: val_mDice did not improve from 0.70058
Epoch 62/300
 - 13s - loss: 979.3356 - acc: 0.9563 - mDice: 0.8186 - val_loss: 1585.4193 - val_acc: 0.9568 - val_mDice: 0.6985

Epoch 00062: val_mDice did not improve from 0.70058
Epoch 63/300
 - 12s - loss: 970.6655 - acc: 0.9565 - mDice: 0.8200 - val_loss: 1620.2981 - val_acc: 0.9584 - val_mDice: 0.6949

Epoch 00063: val_mDice did not improve from 0.70058
Epoch 64/300
 - 13s - loss: 960.8599 - acc: 0.9566 - mDice: 0.8216 - val_loss: 1661.6387 - val_acc: 0.9578 - val_mDice: 0.6884

Epoch 00064: val_mDice did not improve from 0.70058
Epoch 65/300
 - 13s - loss: 956.6545 - acc: 0.9567 - mDice: 0.8223 - val_loss: 1640.8630 - val_acc: 0.9564 - val_mDice: 0.6901

Epoch 00065: val_mDice did not improve from 0.70058
Epoch 66/300
 - 12s - loss: 953.3803 - acc: 0.9568 - mDice: 0.8229 - val_loss: 1609.4537 - val_acc: 0.9584 - val_mDice: 0.6969

Epoch 00066: val_mDice did not improve from 0.70058
Epoch 67/300
 - 13s - loss: 945.5318 - acc: 0.9570 - mDice: 0.8242 - val_loss: 1643.8299 - val_acc: 0.9568 - val_mDice: 0.6894

Epoch 00067: val_mDice did not improve from 0.70058
Epoch 68/300
 - 12s - loss: 941.3698 - acc: 0.9570 - mDice: 0.8249 - val_loss: 1673.2814 - val_acc: 0.9575 - val_mDice: 0.6873

Epoch 00068: val_mDice did not improve from 0.70058
Epoch 69/300
 - 13s - loss: 930.4285 - acc: 0.9572 - mDice: 0.8266 - val_loss: 1636.0244 - val_acc: 0.9576 - val_mDice: 0.6924

Epoch 00069: val_mDice did not improve from 0.70058
Epoch 70/300
 - 13s - loss: 929.0901 - acc: 0.9572 - mDice: 0.8269 - val_loss: 1698.2453 - val_acc: 0.9565 - val_mDice: 0.6822

Epoch 00070: val_mDice did not improve from 0.70058
Epoch 71/300
 - 12s - loss: 928.6618 - acc: 0.9571 - mDice: 0.8270 - val_loss: 1646.9756 - val_acc: 0.9563 - val_mDice: 0.6911

Epoch 00071: val_mDice did not improve from 0.70058
Epoch 72/300
 - 13s - loss: 915.7517 - acc: 0.9574 - mDice: 0.8292 - val_loss: 1706.1825 - val_acc: 0.9578 - val_mDice: 0.6840

Epoch 00072: val_mDice did not improve from 0.70058
Epoch 73/300
 - 12s - loss: 920.5360 - acc: 0.9574 - mDice: 0.8284 - val_loss: 1628.6004 - val_acc: 0.9580 - val_mDice: 0.6926

Epoch 00073: val_mDice did not improve from 0.70058
Epoch 74/300
 - 13s - loss: 908.3934 - acc: 0.9575 - mDice: 0.8304 - val_loss: 1633.8502 - val_acc: 0.9567 - val_mDice: 0.6919

Epoch 00074: val_mDice did not improve from 0.70058
Epoch 75/300
 - 13s - loss: 906.8401 - acc: 0.9576 - mDice: 0.8306 - val_loss: 1775.7812 - val_acc: 0.9556 - val_mDice: 0.6727

Epoch 00075: val_mDice did not improve from 0.70058
Epoch 76/300
 - 12s - loss: 904.5096 - acc: 0.9576 - mDice: 0.8311 - val_loss: 1632.0312 - val_acc: 0.9586 - val_mDice: 0.6922

Epoch 00076: val_mDice did not improve from 0.70058
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [8293.631568545386, 4201.0890880766365, 3203.320824032738, 2870.3019205729165, 2561.645999000186, 2506.0021449497767, 2147.859837123326, 2048.01131766183, 1986.287865048363, 1865.7609194800966, 1828.5159534272693, 1822.232430594308, 1826.7921549479167, 1760.2409173874628, 1771.1969342912946, 1724.0721144903273, 1709.2818748837426, 1707.8354753766741, 1698.6762172154017, 1665.6740025111608, 1707.8760143461682, 1670.0643397739955, 1709.321254185268, 1668.392799014137, 1640.4876156761534, 1641.8687511625744, 1635.7526913597471, 1651.4546508789062, 1704.1135428292412, 1658.7960146949404, 1696.936723981585, 1612.5409691220239, 1624.6212681361608, 1693.8907819475446, 1732.448218936012, 1769.4254906063989, 1701.3905552455358, 1640.8424391973585, 1748.650649297805, 1663.8313569568452, 1658.765133812314, 1685.2632242838542, 1726.8742123558409, 1597.0724603562128, 1659.9712524414062, 1573.0013078962054, 1613.9353666759673, 1630.1535179501489, 1686.057884579613, 1618.245329357329, 1731.3868669782366, 1624.200160435268, 1717.868675595238, 1636.595206124442, 1699.1555931454614, 1637.0285121372767, 1688.9988490513392, 1583.5584455217634, 1615.1016816638764, 1654.968715122768, 1617.5128638857886, 1585.4193434942335, 1620.298075358073, 1661.638695126488, 1640.8629644484747, 1609.4537237258185, 1643.8299095517114, 1673.2813749767486, 1636.0244198753721, 1698.2452857607886, 1646.9755917503721, 1706.1824573335193, 1628.6004173642114, 1633.8502400716145, 1775.7811628069196, 1632.031238374256], 'val_acc': [0.9072587433315459, 0.9109489449432918, 0.9085808864661625, 0.9159669805140722, 0.9267428162552062, 0.927946130434672, 0.9347842151210422, 0.9368547002474467, 0.937527175460543, 0.9415192902088165, 0.9438830883730025, 0.9435138972032637, 0.9439002261275337, 0.9460422354085105, 0.9437385513668969, 0.9467662714776539, 0.9488782087961832, 0.9466746747493744, 0.9481957001345498, 0.9483172978673663, 0.9466603526047298, 0.9513965036187854, 0.946813471260525, 0.9501974469139463, 0.9510359338351658, 0.9509586720239549, 0.9511733097689492, 0.9505322603952318, 0.9530119526953924, 0.9531164254461016, 0.9537674671127683, 0.9530105392138163, 0.9528073455606189, 0.9536286620866685, 0.9533596379416329, 0.954544430687314, 0.9529962113925389, 0.9555917878945669, 0.9532308862322852, 0.9519889014107841, 0.9562399926639739, 0.9548091349147615, 0.955198313508715, 0.9577123409225827, 0.9531650614170801, 0.9574347564152309, 0.9558837115764618, 0.9553542733192444, 0.9552741618383498, 0.9577123238926842, 0.9577066160383678, 0.9571085373560587, 0.9558607950097039, 0.9562843214897883, 0.9567894282795134, 0.9547490136963981, 0.956557632911773, 0.9582260165895734, 0.9561755969410851, 0.9565361582097553, 0.9580671787261963, 0.9567708358878181, 0.958434922354562, 0.9578139384587606, 0.9564045454774585, 0.9584234598137084, 0.9567922822066716, 0.9574548006057739, 0.9575892857142857, 0.9564674837248666, 0.9562700163750422, 0.9578182427656083, 0.9580085220791045, 0.9567422199816931, 0.955603247597104, 0.9585808841955095], 'val_mDice': [0.2914453964857828, 0.4212020706562769, 0.4995401586805071, 0.5391264586221605, 0.575706300281343, 0.5863921798410869, 0.6199935064429328, 0.6311060942354656, 0.6388727838084811, 0.6560069947015672, 0.6613649285974956, 0.6625283445630755, 0.6633448359512147, 0.6719237849825904, 0.6682034305163792, 0.6778277854124705, 0.6793776069368634, 0.6797297511781965, 0.68157401964778, 0.6874166343893323, 0.6771087561334882, 0.6865119962465196, 0.6791809598604838, 0.6854956192629678, 0.6906726984750657, 0.6908244036492848, 0.6906713985261463, 0.6893387380100432, 0.6820251090185983, 0.6894353954564958, 0.6821508123761132, 0.6950524747371674, 0.6939872588430133, 0.6855728881699699, 0.6766116193362645, 0.672819265297481, 0.6827111627374377, 0.6918546968982333, 0.6759940612883795, 0.6880179331416175, 0.6900485824970972, 0.6862293850807917, 0.6780711582728794, 0.6982589562733968, 0.6876960496107737, 0.7005839958077386, 0.69651679339863, 0.6933518307549613, 0.685670758996691, 0.6961410130773272, 0.6789271292232332, 0.6940830945968628, 0.6806832310699281, 0.6908946789446331, 0.6866476166815985, 0.6904258245513553, 0.6825287711052668, 0.6997787115119752, 0.6932922871339888, 0.6881314189661116, 0.6944331626097361, 0.6984918259439015, 0.6948728022121248, 0.688350111246109, 0.6900941147690728, 0.6968691419987452, 0.6893691193489802, 0.6873446972597212, 0.6923577657767704, 0.6822043302513304, 0.6910529094082969, 0.6840466658274332, 0.6925982378778004, 0.6918815062159583, 0.6726850555056617, 0.6921896622294471], 'loss': [15254.600375891327, 5894.787524596712, 4354.598142780866, 3508.488062528006, 3041.7126699243104, 2763.0067519190306, 2532.3444384339446, 2294.434527656384, 2145.701393717245, 2033.5865071360904, 1936.19402996263, 1865.548782538892, 1806.7650216499767, 1758.2900757444768, 1711.77619024643, 1667.8579054378215, 1632.3953370738802, 1597.427446817222, 1562.4146542442113, 1535.1523863300124, 1505.0960226082743, 1471.9184398698687, 1447.2165832519531, 1423.9116876464234, 1404.4624005172616, 1377.0511321640965, 1356.0372893602175, 1339.4086619541235, 1318.9929247164073, 1297.5300914735865, 1282.8304579204455, 1271.4440201452546, 1253.3932774798234, 1241.9297304985826, 1230.1301052635745, 1216.017730142113, 1200.2469712635525, 1185.3156528235077, 1176.3640828881776, 1157.3147923191289, 1148.0663226501008, 1134.1679511319967, 1129.5999440980374, 1120.8644571280538, 1107.8069265846004, 1101.7954337293668, 1090.979209272047, 1078.9369285754728, 1074.028290517907, 1060.4537500776257, 1055.0096971507085, 1051.4400942034258, 1038.0655664648498, 1030.7913101272393, 1023.1741331675998, 1015.3241754279767, 1006.9638290976051, 998.6280709739932, 991.8080649245112, 989.085773344349, 986.8486371694361, 979.3356379178397, 970.6655314723749, 960.8598718999924, 956.6544762513881, 953.3803370183246, 945.5317762950413, 941.369788438602, 930.4284796964498, 929.090102179092, 928.6617559685077, 915.7517328619065, 920.535999250531, 908.3933692989207, 906.8400648882858, 904.509609726599], 'acc': [0.8693120732271761, 0.8988081929726791, 0.9070028706158783, 0.9136135208227688, 0.9194852417320979, 0.9244067595152189, 0.9280153350379698, 0.931142582578998, 0.9335811076839071, 0.9356357654245417, 0.9376849347256365, 0.939118942213326, 0.940473860970459, 0.9414697526547677, 0.942306961780623, 0.9433185739670311, 0.9439830790062498, 0.9447704924646756, 0.9453985035939704, 0.9459460760812807, 0.9465650392143506, 0.9471375291186972, 0.9476854934582389, 0.9481952405555587, 0.9485729988153438, 0.9489569702090468, 0.9492932504363488, 0.9497529822134615, 0.9501765620455778, 0.950544237012875, 0.9508643491830017, 0.9509850691381535, 0.951398192089692, 0.9515283670545813, 0.9517157001053901, 0.9521854741503473, 0.9523102725273058, 0.9526557345825835, 0.9528774589374476, 0.9530525751913574, 0.9532287287667505, 0.9534153078410988, 0.9537192931459134, 0.9538816519992013, 0.9540010781545294, 0.9542094462010035, 0.9542893785751074, 0.9545739573470672, 0.9545510087784687, 0.9548575610962889, 0.9549125430924339, 0.955123457974032, 0.9552308221224538, 0.9553858933603377, 0.9555870490775739, 0.95576336656574, 0.9558643940789742, 0.9560166227995903, 0.9560588274401917, 0.9561612800767, 0.9561968702925113, 0.9562757390358502, 0.9565096784410928, 0.956628131097243, 0.9566878118085445, 0.9567890277229937, 0.9569683267997388, 0.9569936507472077, 0.9571897510132588, 0.9572226129044916, 0.9571237717371927, 0.957421762316007, 0.9573900490033062, 0.9574750953927599, 0.9575940528118105, 0.9576302249718486], 'mDice': [0.157160208663297, 0.350556094041489, 0.44273109915213393, 0.5086437174748453, 0.553385054344251, 0.58295788582498, 0.6072901222028042, 0.6322520981517219, 0.6493980915394805, 0.6633823986659918, 0.6759836932927593, 0.6853924232193657, 0.6935151840311631, 0.7000500317152004, 0.7067252990796679, 0.7128295790859291, 0.7179208028123266, 0.7229950149680611, 0.7280307192903505, 0.7319011077507773, 0.7364020092305994, 0.7412116710941987, 0.7449392193087616, 0.7484099644600899, 0.7513880241950254, 0.7553996477935677, 0.7586539170316925, 0.7611926724191318, 0.7643624938968708, 0.7676451326234085, 0.7699612477919705, 0.7716848299539, 0.7745426425761416, 0.7762670707041188, 0.778057261502505, 0.7803617272888336, 0.7828283797104163, 0.7851624311763152, 0.7866127363910105, 0.7895968211559287, 0.7909917827147498, 0.7932809767245949, 0.7940408033585905, 0.795511768680261, 0.79750631968874, 0.7985223471523818, 0.8002631912504943, 0.802209834821355, 0.8029737817007407, 0.8051746901579926, 0.8060278450870454, 0.80666421565629, 0.8088889997684747, 0.8100648166569986, 0.8112968073930229, 0.8126125169959746, 0.8139885426905387, 0.8152894039180808, 0.8163957388843979, 0.8169416363659939, 0.8172563697000097, 0.8185602768215158, 0.8199536891054928, 0.8215736202393982, 0.8222869393459876, 0.8228604946090396, 0.8242155082356603, 0.8248725598701218, 0.826628539404667, 0.8269174207847314, 0.8269989235219812, 0.8291629265594364, 0.8283578005812114, 0.8304226693332641, 0.8306400656997415, 0.8310785947966755]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:15<00:47, 15.87s/it]predicting test subjects:  50%|█████     | 2/4 [00:29<00:30, 15.23s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:44<00:15, 15.19s/it]predicting test subjects: 100%|██████████| 4/4 [00:59<00:00, 15.06s/it]
predicting train subjects:   0%|          | 0/311 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/311 [00:21<1:53:21, 21.94s/it]predicting train subjects:   1%|          | 2/311 [00:32<1:36:09, 18.67s/it]predicting train subjects:   1%|          | 3/311 [00:46<1:28:40, 17.27s/it]predicting train subjects:   1%|▏         | 4/311 [01:00<1:22:20, 16.09s/it]predicting train subjects:   2%|▏         | 5/311 [01:12<1:15:48, 14.87s/it]predicting train subjects:   2%|▏         | 6/311 [01:23<1:10:36, 13.89s/it]predicting train subjects:   2%|▏         | 7/311 [01:37<1:10:08, 13.84s/it]predicting train subjects:   3%|▎         | 8/311 [01:53<1:12:31, 14.36s/it]predicting train subjects:   3%|▎         | 9/311 [02:07<1:11:46, 14.26s/it]predicting train subjects:   3%|▎         | 10/311 [02:19<1:07:46, 13.51s/it]predicting train subjects:   4%|▎         | 11/311 [02:34<1:10:22, 14.07s/it]predicting train subjects:   4%|▍         | 12/311 [02:46<1:07:13, 13.49s/it]predicting train subjects:   4%|▍         | 13/311 [02:59<1:05:31, 13.19s/it]predicting train subjects:   5%|▍         | 14/311 [03:14<1:08:58, 13.93s/it]predicting train subjects:   5%|▍         | 15/311 [03:36<1:20:21, 16.29s/it]predicting train subjects:   5%|▌         | 16/311 [03:58<1:29:10, 18.14s/it]predicting train subjects:   5%|▌         | 17/311 [04:20<1:33:50, 19.15s/it]predicting train subjects:   6%|▌         | 18/311 [04:44<1:41:00, 20.68s/it]predicting train subjects:   6%|▌         | 19/311 [05:14<1:53:12, 23.26s/it]predicting train subjects:   6%|▋         | 20/311 [05:41<1:59:04, 24.55s/it]predicting train subjects:   7%|▋         | 21/311 [06:08<2:01:52, 25.21s/it]predicting train subjects:   7%|▋         | 22/311 [06:35<2:04:41, 25.89s/it]predicting train subjects:   7%|▋         | 23/311 [07:04<2:08:08, 26.69s/it]predicting train subjects:   8%|▊         | 24/311 [07:32<2:09:04, 26.98s/it]predicting train subjects:   8%|▊         | 25/311 [08:00<2:10:10, 27.31s/it]predicting train subjects:   8%|▊         | 26/311 [08:27<2:09:26, 27.25s/it]predicting train subjects:   9%|▊         | 27/311 [08:53<2:07:52, 27.01s/it]predicting train subjects:   9%|▉         | 28/311 [09:15<2:00:42, 25.59s/it]predicting train subjects:   9%|▉         | 29/311 [09:37<1:54:57, 24.46s/it]predicting train subjects:  10%|▉         | 30/311 [09:59<1:50:11, 23.53s/it]predicting train subjects:  10%|▉         | 31/311 [10:20<1:47:17, 22.99s/it]predicting train subjects:  10%|█         | 32/311 [10:42<1:45:24, 22.67s/it]predicting train subjects:  11%|█         | 33/311 [10:53<1:28:01, 19.00s/it]predicting train subjects:  11%|█         | 34/311 [11:03<1:15:15, 16.30s/it]predicting train subjects:  11%|█▏        | 35/311 [11:13<1:07:05, 14.58s/it]predicting train subjects:  12%|█▏        | 36/311 [11:24<1:01:14, 13.36s/it]predicting train subjects:  12%|█▏        | 37/311 [11:34<56:37, 12.40s/it]  predicting train subjects:  12%|█▏        | 38/311 [11:44<53:43, 11.81s/it]predicting train subjects:  13%|█▎        | 39/311 [11:55<51:58, 11.47s/it]predicting train subjects:  13%|█▎        | 40/311 [12:05<50:13, 11.12s/it]predicting train subjects:  13%|█▎        | 41/311 [12:16<48:58, 10.88s/it]predicting train subjects:  14%|█▎        | 42/311 [12:26<48:23, 10.79s/it]predicting train subjects:  14%|█▍        | 43/311 [12:37<48:16, 10.81s/it]predicting train subjects:  14%|█▍        | 44/311 [12:47<46:44, 10.51s/it]predicting train subjects:  14%|█▍        | 45/311 [12:57<46:37, 10.52s/it]predicting train subjects:  15%|█▍        | 46/311 [13:08<46:18, 10.48s/it]predicting train subjects:  15%|█▌        | 47/311 [13:18<45:35, 10.36s/it]predicting train subjects:  15%|█▌        | 48/311 [13:29<45:52, 10.47s/it]predicting train subjects:  16%|█▌        | 49/311 [13:39<45:54, 10.51s/it]predicting train subjects:  16%|█▌        | 50/311 [13:49<45:18, 10.42s/it]predicting train subjects:  16%|█▋        | 51/311 [14:02<48:14, 11.13s/it]predicting train subjects:  17%|█▋        | 52/311 [14:15<50:44, 11.75s/it]predicting train subjects:  17%|█▋        | 53/311 [14:29<52:26, 12.20s/it]predicting train subjects:  17%|█▋        | 54/311 [14:42<53:35, 12.51s/it]predicting train subjects:  18%|█▊        | 55/311 [14:55<54:11, 12.70s/it]predicting train subjects:  18%|█▊        | 56/311 [15:08<54:45, 12.88s/it]predicting train subjects:  18%|█▊        | 57/311 [15:21<54:42, 12.92s/it]predicting train subjects:  19%|█▊        | 58/311 [15:35<54:42, 12.97s/it]predicting train subjects:  19%|█▉        | 59/311 [15:48<55:45, 13.27s/it]predicting train subjects:  19%|█▉        | 60/311 [16:02<55:52, 13.36s/it]predicting train subjects:  20%|█▉        | 61/311 [16:15<55:21, 13.29s/it]predicting train subjects:  20%|█▉        | 62/311 [16:28<54:56, 13.24s/it]predicting train subjects:  20%|██        | 63/311 [16:42<54:45, 13.25s/it]predicting train subjects:  21%|██        | 64/311 [16:55<54:40, 13.28s/it]predicting train subjects:  21%|██        | 65/311 [17:10<56:13, 13.71s/it]predicting train subjects:  21%|██        | 66/311 [17:23<55:52, 13.68s/it]predicting train subjects:  22%|██▏       | 67/311 [17:36<54:47, 13.48s/it]predicting train subjects:  22%|██▏       | 68/311 [17:49<53:35, 13.23s/it]predicting train subjects:  22%|██▏       | 69/311 [18:02<52:55, 13.12s/it]predicting train subjects:  23%|██▎       | 70/311 [18:15<52:22, 13.04s/it]predicting train subjects:  23%|██▎       | 71/311 [18:28<52:03, 13.01s/it]predicting train subjects:  23%|██▎       | 72/311 [18:41<52:09, 13.09s/it]predicting train subjects:  23%|██▎       | 73/311 [18:54<52:18, 13.19s/it]predicting train subjects:  24%|██▍       | 74/311 [19:07<51:27, 13.03s/it]predicting train subjects:  24%|██▍       | 75/311 [19:19<50:31, 12.84s/it]predicting train subjects:  24%|██▍       | 76/311 [19:33<50:42, 12.95s/it]predicting train subjects:  25%|██▍       | 77/311 [19:46<50:50, 13.04s/it]predicting train subjects:  25%|██▌       | 78/311 [19:58<50:00, 12.88s/it]predicting train subjects:  25%|██▌       | 79/311 [20:11<49:55, 12.91s/it]predicting train subjects:  26%|██▌       | 80/311 [20:24<49:35, 12.88s/it]predicting train subjects:  26%|██▌       | 81/311 [20:37<49:26, 12.90s/it]predicting train subjects:  26%|██▋       | 82/311 [20:50<49:18, 12.92s/it]predicting train subjects:  27%|██▋       | 83/311 [21:03<49:16, 12.97s/it]predicting train subjects:  27%|██▋       | 84/311 [21:16<49:32, 13.09s/it]predicting train subjects:  27%|██▋       | 85/311 [21:28<47:54, 12.72s/it]predicting train subjects:  28%|██▊       | 86/311 [21:40<46:37, 12.43s/it]predicting train subjects:  28%|██▊       | 87/311 [21:52<45:53, 12.29s/it]predicting train subjects:  28%|██▊       | 88/311 [22:04<45:47, 12.32s/it]predicting train subjects:  29%|██▊       | 89/311 [22:18<46:30, 12.57s/it]predicting train subjects:  29%|██▉       | 90/311 [22:29<45:36, 12.38s/it]predicting train subjects:  29%|██▉       | 91/311 [22:41<44:57, 12.26s/it]predicting train subjects:  30%|██▉       | 92/311 [22:53<44:21, 12.15s/it]predicting train subjects:  30%|██▉       | 93/311 [23:05<43:44, 12.04s/it]predicting train subjects:  30%|███       | 94/311 [23:17<43:26, 12.01s/it]predicting train subjects:  31%|███       | 95/311 [23:29<43:11, 12.00s/it]predicting train subjects:  31%|███       | 96/311 [23:41<42:51, 11.96s/it]predicting train subjects:  31%|███       | 97/311 [23:53<42:15, 11.85s/it]predicting train subjects:  32%|███▏      | 98/311 [24:04<41:43, 11.75s/it]predicting train subjects:  32%|███▏      | 99/311 [24:15<41:06, 11.63s/it]predicting train subjects:  32%|███▏      | 100/311 [24:27<40:20, 11.47s/it]predicting train subjects:  32%|███▏      | 101/311 [24:38<40:31, 11.58s/it]predicting train subjects:  33%|███▎      | 102/311 [24:50<40:55, 11.75s/it]predicting train subjects:  33%|███▎      | 103/311 [25:02<40:10, 11.59s/it]predicting train subjects:  33%|███▎      | 104/311 [25:14<40:25, 11.72s/it]predicting train subjects:  34%|███▍      | 105/311 [25:26<40:50, 11.90s/it]predicting train subjects:  34%|███▍      | 106/311 [25:38<41:00, 12.00s/it]predicting train subjects:  34%|███▍      | 107/311 [25:50<40:51, 12.02s/it]predicting train subjects:  35%|███▍      | 108/311 [26:02<40:38, 12.01s/it]predicting train subjects:  35%|███▌      | 109/311 [26:14<40:18, 11.97s/it]predicting train subjects:  35%|███▌      | 110/311 [26:25<39:25, 11.77s/it]predicting train subjects:  36%|███▌      | 111/311 [26:40<42:01, 12.61s/it]predicting train subjects:  36%|███▌      | 112/311 [26:55<43:49, 13.21s/it]predicting train subjects:  36%|███▋      | 113/311 [27:09<45:00, 13.64s/it]predicting train subjects:  37%|███▋      | 114/311 [27:36<57:18, 17.46s/it]predicting train subjects:  37%|███▋      | 115/311 [28:02<1:05:57, 20.19s/it]predicting train subjects:  37%|███▋      | 116/311 [28:30<1:13:04, 22.48s/it]predicting train subjects:  38%|███▊      | 117/311 [28:53<1:12:38, 22.46s/it]predicting train subjects:  38%|███▊      | 118/311 [29:15<1:11:54, 22.35s/it]predicting train subjects:  38%|███▊      | 119/311 [29:38<1:12:19, 22.60s/it]predicting train subjects:  39%|███▊      | 120/311 [30:01<1:12:06, 22.65s/it]predicting train subjects:  39%|███▉      | 121/311 [30:23<1:11:19, 22.53s/it]predicting train subjects:  39%|███▉      | 122/311 [30:46<1:11:35, 22.72s/it]predicting train subjects:  40%|███▉      | 123/311 [31:08<1:10:47, 22.59s/it]predicting train subjects:  40%|███▉      | 124/311 [31:31<1:10:39, 22.67s/it]predicting train subjects:  40%|████      | 125/311 [31:53<1:09:50, 22.53s/it]predicting train subjects:  41%|████      | 126/311 [32:16<1:09:34, 22.56s/it]predicting train subjects:  41%|████      | 127/311 [32:38<1:08:41, 22.40s/it]predicting train subjects:  41%|████      | 128/311 [33:01<1:09:02, 22.63s/it]predicting train subjects:  41%|████▏     | 129/311 [33:25<1:09:24, 22.88s/it]predicting train subjects:  42%|████▏     | 130/311 [33:48<1:09:47, 23.14s/it]predicting train subjects:  42%|████▏     | 131/311 [34:11<1:09:01, 23.01s/it]predicting train subjects:  42%|████▏     | 132/311 [34:22<58:05, 19.47s/it]  predicting train subjects:  43%|████▎     | 133/311 [34:34<50:47, 17.12s/it]predicting train subjects:  43%|████▎     | 134/311 [34:45<45:13, 15.33s/it]predicting train subjects:  43%|████▎     | 135/311 [34:56<40:46, 13.90s/it]predicting train subjects:  44%|████▎     | 136/311 [35:07<38:10, 13.09s/it]predicting train subjects:  44%|████▍     | 137/311 [35:18<35:51, 12.36s/it]predicting train subjects:  44%|████▍     | 138/311 [35:28<33:56, 11.77s/it]predicting train subjects:  45%|████▍     | 139/311 [35:38<32:39, 11.39s/it]predicting train subjects:  45%|████▌     | 140/311 [35:49<32:06, 11.27s/it]predicting train subjects:  45%|████▌     | 141/311 [36:00<31:28, 11.11s/it]predicting train subjects:  46%|████▌     | 142/311 [36:11<30:58, 11.00s/it]predicting train subjects:  46%|████▌     | 143/311 [36:24<32:23, 11.57s/it]predicting train subjects:  46%|████▋     | 144/311 [36:37<33:58, 12.20s/it]predicting train subjects:  47%|████▋     | 145/311 [36:51<34:31, 12.48s/it]predicting train subjects:  47%|████▋     | 146/311 [37:04<35:18, 12.84s/it]predicting train subjects:  47%|████▋     | 147/311 [37:18<35:49, 13.11s/it]predicting train subjects:  48%|████▊     | 148/311 [37:31<35:33, 13.09s/it]predicting train subjects:  48%|████▊     | 149/311 [37:44<35:26, 13.13s/it]predicting train subjects:  48%|████▊     | 150/311 [38:02<38:34, 14.37s/it]predicting train subjects:  49%|████▊     | 151/311 [38:15<37:35, 14.09s/it]predicting train subjects:  49%|████▉     | 152/311 [38:28<36:54, 13.93s/it]predicting train subjects:  49%|████▉     | 153/311 [38:41<35:50, 13.61s/it]predicting train subjects:  50%|████▉     | 154/311 [38:55<35:31, 13.58s/it]predicting train subjects:  50%|████▉     | 155/311 [39:08<35:08, 13.52s/it]predicting train subjects:  50%|█████     | 156/311 [39:22<34:50, 13.49s/it]predicting train subjects:  50%|█████     | 157/311 [39:37<36:06, 14.07s/it]predicting train subjects:  51%|█████     | 158/311 [39:53<37:15, 14.61s/it]predicting train subjects:  51%|█████     | 159/311 [40:09<37:52, 14.95s/it]predicting train subjects:  51%|█████▏    | 160/311 [40:25<38:43, 15.39s/it]predicting train subjects:  52%|█████▏    | 161/311 [40:41<38:59, 15.60s/it]predicting train subjects:  52%|█████▏    | 162/311 [40:58<39:47, 16.02s/it]predicting train subjects:  52%|█████▏    | 163/311 [41:14<39:24, 15.97s/it]predicting train subjects:  53%|█████▎    | 164/311 [41:30<39:11, 16.00s/it]predicting train subjects:  53%|█████▎    | 165/311 [41:47<39:20, 16.17s/it]predicting train subjects:  53%|█████▎    | 166/311 [42:03<39:11, 16.22s/it]predicting train subjects:  54%|█████▎    | 167/311 [42:18<38:00, 15.84s/it]predicting train subjects:  54%|█████▍    | 168/311 [42:33<37:16, 15.64s/it]predicting train subjects:  54%|█████▍    | 169/311 [42:50<37:39, 15.91s/it]predicting train subjects:  55%|█████▍    | 170/311 [43:06<37:38, 16.02s/it]predicting train subjects:  55%|█████▍    | 171/311 [43:21<36:54, 15.82s/it]predicting train subjects:  55%|█████▌    | 172/311 [43:36<35:34, 15.35s/it]predicting train subjects:  56%|█████▌    | 173/311 [43:52<35:43, 15.53s/it]predicting train subjects:  56%|█████▌    | 174/311 [44:07<35:35, 15.59s/it]predicting train subjects:  56%|█████▋    | 175/311 [44:23<35:41, 15.75s/it]predicting train subjects:  57%|█████▋    | 176/311 [44:39<35:06, 15.60s/it]predicting train subjects:  57%|█████▋    | 177/311 [44:55<35:21, 15.83s/it]predicting train subjects:  57%|█████▋    | 178/311 [45:11<35:22, 15.96s/it]predicting train subjects:  58%|█████▊    | 179/311 [45:27<34:51, 15.84s/it]predicting train subjects:  58%|█████▊    | 180/311 [45:43<34:39, 15.87s/it]predicting train subjects:  58%|█████▊    | 181/311 [45:58<34:15, 15.81s/it]predicting train subjects:  59%|█████▊    | 182/311 [46:14<34:03, 15.84s/it]predicting train subjects:  59%|█████▉    | 183/311 [46:31<34:01, 15.95s/it]predicting train subjects:  59%|█████▉    | 184/311 [46:45<32:34, 15.39s/it]predicting train subjects:  59%|█████▉    | 185/311 [46:59<31:33, 15.03s/it]predicting train subjects:  60%|█████▉    | 186/311 [47:13<30:40, 14.72s/it]predicting train subjects:  60%|██████    | 187/311 [47:26<29:24, 14.23s/it]predicting train subjects:  60%|██████    | 188/311 [47:39<28:35, 13.95s/it]predicting train subjects:  61%|██████    | 189/311 [47:54<28:53, 14.21s/it]predicting train subjects:  61%|██████    | 190/311 [48:09<28:58, 14.37s/it]predicting train subjects:  61%|██████▏   | 191/311 [48:24<28:57, 14.48s/it]predicting train subjects:  62%|██████▏   | 192/311 [48:38<28:55, 14.58s/it]predicting train subjects:  62%|██████▏   | 193/311 [48:53<29:00, 14.75s/it]predicting train subjects:  62%|██████▏   | 194/311 [49:08<28:37, 14.68s/it]predicting train subjects:  63%|██████▎   | 195/311 [49:23<28:39, 14.82s/it]predicting train subjects:  63%|██████▎   | 196/311 [49:38<28:23, 14.82s/it]predicting train subjects:  63%|██████▎   | 197/311 [49:52<27:54, 14.69s/it]predicting train subjects:  64%|██████▎   | 198/311 [50:07<27:21, 14.53s/it]predicting train subjects:  64%|██████▍   | 199/311 [50:21<27:10, 14.56s/it]predicting train subjects:  64%|██████▍   | 200/311 [50:36<26:52, 14.53s/it]predicting train subjects:  65%|██████▍   | 201/311 [50:50<26:36, 14.52s/it]predicting train subjects:  65%|██████▍   | 202/311 [51:04<26:00, 14.32s/it]predicting train subjects:  65%|██████▌   | 203/311 [51:19<25:55, 14.40s/it]predicting train subjects:  66%|██████▌   | 204/311 [51:33<25:42, 14.42s/it]predicting train subjects:  66%|██████▌   | 205/311 [51:48<25:42, 14.55s/it]predicting train subjects:  66%|██████▌   | 206/311 [52:00<24:23, 13.94s/it]predicting train subjects:  67%|██████▋   | 207/311 [52:12<22:59, 13.27s/it]predicting train subjects:  67%|██████▋   | 208/311 [52:24<22:01, 12.83s/it]predicting train subjects:  67%|██████▋   | 209/311 [52:36<21:24, 12.59s/it]predicting train subjects:  68%|██████▊   | 210/311 [52:48<20:45, 12.34s/it]predicting train subjects:  68%|██████▊   | 211/311 [52:59<20:07, 12.07s/it]predicting train subjects:  68%|██████▊   | 212/311 [53:10<19:33, 11.86s/it]predicting train subjects:  68%|██████▊   | 213/311 [53:34<25:10, 15.42s/it]predicting train subjects:  69%|██████▉   | 214/311 [53:57<28:17, 17.50s/it]predicting train subjects:  69%|██████▉   | 215/311 [54:20<30:44, 19.21s/it]predicting train subjects:  69%|██████▉   | 216/311 [54:43<32:10, 20.33s/it]predicting train subjects:  70%|██████▉   | 217/311 [55:07<33:39, 21.49s/it]predicting train subjects:  70%|███████   | 218/311 [55:33<35:20, 22.80s/it]predicting train subjects:  70%|███████   | 219/311 [56:00<37:07, 24.22s/it]predicting train subjects:  71%|███████   | 220/311 [56:29<38:35, 25.44s/it]predicting train subjects:  71%|███████   | 221/311 [56:57<39:29, 26.33s/it]predicting train subjects:  71%|███████▏  | 222/311 [57:26<40:15, 27.14s/it]predicting train subjects:  72%|███████▏  | 223/311 [57:54<40:24, 27.55s/it]predicting train subjects:  72%|███████▏  | 224/311 [58:24<40:38, 28.03s/it]predicting train subjects:  72%|███████▏  | 225/311 [58:53<40:35, 28.32s/it]predicting train subjects:  73%|███████▎  | 226/311 [59:23<40:48, 28.81s/it]predicting train subjects:  73%|███████▎  | 227/311 [59:53<41:03, 29.32s/it]predicting train subjects:  73%|███████▎  | 228/311 [1:00:24<41:02, 29.67s/it]predicting train subjects:  74%|███████▎  | 229/311 [1:00:56<41:33, 30.41s/it]predicting train subjects:  74%|███████▍  | 230/311 [1:01:29<42:22, 31.38s/it]predicting train subjects:  74%|███████▍  | 231/311 [1:01:43<34:53, 26.17s/it]predicting train subjects:  75%|███████▍  | 232/311 [1:01:58<29:49, 22.66s/it]predicting train subjects:  75%|███████▍  | 233/311 [1:02:12<26:09, 20.13s/it]predicting train subjects:  75%|███████▌  | 234/311 [1:02:26<23:32, 18.34s/it]predicting train subjects:  76%|███████▌  | 235/311 [1:02:41<21:46, 17.19s/it]predicting train subjects:  76%|███████▌  | 236/311 [1:02:55<20:22, 16.29s/it]predicting train subjects:  76%|███████▌  | 237/311 [1:03:10<19:28, 15.79s/it]predicting train subjects:  77%|███████▋  | 238/311 [1:03:25<18:56, 15.57s/it]predicting train subjects:  77%|███████▋  | 239/311 [1:03:40<18:32, 15.45s/it]predicting train subjects:  77%|███████▋  | 240/311 [1:03:54<17:42, 14.96s/it]predicting train subjects:  77%|███████▋  | 241/311 [1:04:09<17:38, 15.13s/it]predicting train subjects:  78%|███████▊  | 242/311 [1:04:23<16:57, 14.75s/it]predicting train subjects:  78%|███████▊  | 243/311 [1:04:37<16:23, 14.46s/it]predicting train subjects:  78%|███████▊  | 244/311 [1:04:51<15:58, 14.31s/it]predicting train subjects:  79%|███████▉  | 245/311 [1:05:06<16:05, 14.62s/it]predicting train subjects:  79%|███████▉  | 246/311 [1:05:21<15:53, 14.67s/it]