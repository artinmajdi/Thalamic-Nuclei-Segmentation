/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
2019-09-01 14:17:22.528397: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-09-01 14:17:30.465845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-09-01 14:17:30.465918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-09-01 14:17:30.823374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-01 14:17:30.823443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-09-01 14:17:30.823457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-09-01 14:17:30.823913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
(0/5) test vimp2_J_CSFn2
(1/5) test vimp2_D_CSFn2
(2/5) test vimp2_F_CSFn2
(3/5) test vimp2_G_CSFn2
(4/5) test vimp2_ANON911_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_BC_CSFn
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:30,  1.17it/s]Loading train:   1%|          | 2/247 [00:01<03:00,  1.36it/s]Loading train:   1%|          | 3/247 [00:01<02:51,  1.42it/s]Loading train:   2%|▏         | 4/247 [00:02<02:48,  1.44it/s]Loading train:   2%|▏         | 5/247 [00:03<02:45,  1.47it/s]Loading train:   2%|▏         | 6/247 [00:03<02:34,  1.56it/s]Loading train:   3%|▎         | 7/247 [00:04<02:35,  1.55it/s]Loading train:   3%|▎         | 8/247 [00:04<02:14,  1.78it/s]Loading train:   4%|▎         | 9/247 [00:05<02:00,  1.98it/s]Loading train:   4%|▍         | 10/247 [00:05<01:58,  2.00it/s]Loading train:   4%|▍         | 11/247 [00:06<02:03,  1.92it/s]Loading train:   5%|▍         | 12/247 [00:07<02:18,  1.70it/s]Loading train:   5%|▌         | 13/247 [00:07<02:18,  1.70it/s]Loading train:   6%|▌         | 14/247 [00:08<02:09,  1.79it/s]Loading train:   6%|▌         | 15/247 [00:08<01:55,  2.01it/s]Loading train:   6%|▋         | 16/247 [00:08<01:58,  1.95it/s]Loading train:   7%|▋         | 17/247 [00:09<01:56,  1.97it/s]Loading train:   7%|▋         | 18/247 [00:10<02:01,  1.89it/s]Loading train:   8%|▊         | 19/247 [00:10<02:09,  1.76it/s]Loading train:   8%|▊         | 20/247 [00:11<02:18,  1.63it/s]Loading train:   9%|▊         | 21/247 [00:12<02:21,  1.59it/s]Loading train:   9%|▉         | 22/247 [00:12<02:14,  1.67it/s]Loading train:   9%|▉         | 23/247 [00:12<01:57,  1.90it/s]Loading train:  10%|▉         | 24/247 [00:13<02:11,  1.70it/s]Loading train:  10%|█         | 25/247 [00:14<02:08,  1.73it/s]Loading train:  11%|█         | 26/247 [00:14<02:05,  1.76it/s]Loading train:  11%|█         | 27/247 [00:15<01:48,  2.03it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:44,  2.09it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:53,  1.92it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:57,  1.84it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:42,  2.10it/s]Loading train:  13%|█▎        | 32/247 [00:17<01:32,  2.32it/s]Loading train:  13%|█▎        | 33/247 [00:17<01:24,  2.53it/s]Loading train:  14%|█▍        | 34/247 [00:18<01:23,  2.54it/s]Loading train:  14%|█▍        | 35/247 [00:18<01:20,  2.62it/s]Loading train:  15%|█▍        | 36/247 [00:18<01:15,  2.80it/s]Loading train:  15%|█▍        | 37/247 [00:19<01:13,  2.87it/s]Loading train:  15%|█▌        | 38/247 [00:19<01:26,  2.42it/s]Loading train:  16%|█▌        | 39/247 [00:20<01:29,  2.32it/s]Loading train:  16%|█▌        | 40/247 [00:20<01:25,  2.43it/s]Loading train:  17%|█▋        | 41/247 [00:21<01:31,  2.25it/s]Loading train:  17%|█▋        | 42/247 [00:21<01:32,  2.22it/s]Loading train:  17%|█▋        | 43/247 [00:22<01:38,  2.08it/s]Loading train:  18%|█▊        | 44/247 [00:22<01:28,  2.28it/s]Loading train:  18%|█▊        | 45/247 [00:22<01:28,  2.29it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:42,  1.95it/s]Loading train:  19%|█▉        | 47/247 [00:23<01:36,  2.07it/s]Loading train:  19%|█▉        | 48/247 [00:24<02:01,  1.63it/s]Loading train:  20%|█▉        | 49/247 [00:25<02:24,  1.37it/s]Loading train:  20%|██        | 50/247 [00:26<02:32,  1.29it/s]Loading train:  21%|██        | 51/247 [00:27<02:45,  1.19it/s]Loading train:  21%|██        | 52/247 [00:28<02:49,  1.15it/s]Loading train:  21%|██▏       | 53/247 [00:29<02:56,  1.10it/s]Loading train:  22%|██▏       | 54/247 [00:30<02:32,  1.27it/s]Loading train:  22%|██▏       | 55/247 [00:31<02:38,  1.21it/s]Loading train:  23%|██▎       | 56/247 [00:31<02:38,  1.21it/s]Loading train:  23%|██▎       | 57/247 [00:32<02:36,  1.21it/s]Loading train:  23%|██▎       | 58/247 [00:33<02:44,  1.15it/s]Loading train:  24%|██▍       | 59/247 [00:34<02:39,  1.18it/s]Loading train:  24%|██▍       | 60/247 [00:35<02:28,  1.26it/s]Loading train:  25%|██▍       | 61/247 [00:35<02:25,  1.28it/s]Loading train:  25%|██▌       | 62/247 [00:36<02:27,  1.25it/s]Loading train:  26%|██▌       | 63/247 [00:37<02:25,  1.27it/s]Loading train:  26%|██▌       | 64/247 [00:38<02:22,  1.28it/s]Loading train:  26%|██▋       | 65/247 [00:39<02:30,  1.21it/s]Loading train:  27%|██▋       | 66/247 [00:39<02:16,  1.33it/s]Loading train:  27%|██▋       | 67/247 [00:40<02:23,  1.25it/s]Loading train:  28%|██▊       | 68/247 [00:41<02:16,  1.31it/s]Loading train:  28%|██▊       | 69/247 [00:42<02:20,  1.26it/s]Loading train:  28%|██▊       | 70/247 [00:43<02:21,  1.25it/s]Loading train:  29%|██▊       | 71/247 [00:43<02:22,  1.23it/s]Loading train:  29%|██▉       | 72/247 [00:44<02:12,  1.32it/s]Loading train:  30%|██▉       | 73/247 [00:45<02:02,  1.42it/s]Loading train:  30%|██▉       | 74/247 [00:45<01:50,  1.57it/s]Loading train:  30%|███       | 75/247 [00:46<01:57,  1.46it/s]Loading train:  31%|███       | 76/247 [00:47<02:00,  1.42it/s]Loading train:  31%|███       | 77/247 [00:48<02:17,  1.24it/s]Loading train:  32%|███▏      | 78/247 [00:49<02:44,  1.03it/s]Loading train:  32%|███▏      | 79/247 [00:50<02:47,  1.01it/s]Loading train:  32%|███▏      | 80/247 [00:51<02:57,  1.07s/it]Loading train:  33%|███▎      | 81/247 [00:53<03:09,  1.14s/it]Loading train:  33%|███▎      | 82/247 [00:54<03:12,  1.17s/it]Loading train:  34%|███▎      | 83/247 [00:55<02:59,  1.09s/it]Loading train:  34%|███▍      | 84/247 [00:56<02:56,  1.08s/it]Loading train:  34%|███▍      | 85/247 [00:57<02:48,  1.04s/it]Loading train:  35%|███▍      | 86/247 [00:58<02:53,  1.08s/it]Loading train:  35%|███▌      | 87/247 [00:59<03:05,  1.16s/it]Loading train:  36%|███▌      | 88/247 [01:00<02:52,  1.08s/it]Loading train:  36%|███▌      | 89/247 [01:02<03:01,  1.15s/it]Loading train:  36%|███▋      | 90/247 [01:03<02:52,  1.10s/it]Loading train:  37%|███▋      | 91/247 [01:04<02:49,  1.09s/it]Loading train:  37%|███▋      | 92/247 [01:05<03:01,  1.17s/it]Loading train:  38%|███▊      | 93/247 [01:06<02:55,  1.14s/it]Loading train:  38%|███▊      | 94/247 [01:07<02:53,  1.13s/it]Loading train:  38%|███▊      | 95/247 [01:08<02:48,  1.11s/it]Loading train:  39%|███▉      | 96/247 [01:09<02:42,  1.07s/it]Loading train:  39%|███▉      | 97/247 [01:10<02:43,  1.09s/it]Loading train:  40%|███▉      | 98/247 [01:11<02:32,  1.02s/it]Loading train:  40%|████      | 99/247 [01:12<02:43,  1.11s/it]Loading train:  40%|████      | 100/247 [01:14<02:47,  1.14s/it]Loading train:  41%|████      | 101/247 [01:15<02:48,  1.15s/it]Loading train:  41%|████▏     | 102/247 [01:16<02:41,  1.12s/it]Loading train:  42%|████▏     | 103/247 [01:17<02:45,  1.15s/it]Loading train:  42%|████▏     | 104/247 [01:18<02:44,  1.15s/it]Loading train:  43%|████▎     | 105/247 [01:19<02:44,  1.16s/it]Loading train:  43%|████▎     | 106/247 [01:21<02:46,  1.18s/it]Loading train:  43%|████▎     | 107/247 [01:22<02:53,  1.24s/it]Loading train:  44%|████▎     | 108/247 [01:23<02:36,  1.13s/it]Loading train:  44%|████▍     | 109/247 [01:24<02:42,  1.18s/it]Loading train:  45%|████▍     | 110/247 [01:25<02:42,  1.19s/it]Loading train:  45%|████▍     | 111/247 [01:27<02:46,  1.22s/it]Loading train:  45%|████▌     | 112/247 [01:28<02:40,  1.19s/it]Loading train:  46%|████▌     | 113/247 [01:29<02:20,  1.05s/it]Loading train:  46%|████▌     | 114/247 [01:29<02:11,  1.01it/s]Loading train:  47%|████▋     | 115/247 [01:31<02:15,  1.03s/it]Loading train:  47%|████▋     | 116/247 [01:32<02:12,  1.01s/it]Loading train:  47%|████▋     | 117/247 [01:33<02:15,  1.04s/it]Loading train:  48%|████▊     | 118/247 [01:34<02:11,  1.02s/it]Loading train:  48%|████▊     | 119/247 [01:34<02:01,  1.05it/s]Loading train:  49%|████▊     | 120/247 [01:35<01:50,  1.15it/s]Loading train:  49%|████▉     | 121/247 [01:36<01:54,  1.10it/s]Loading train:  49%|████▉     | 122/247 [01:38<02:19,  1.12s/it]Loading train:  50%|████▉     | 123/247 [01:39<02:09,  1.04s/it]Loading train:  50%|█████     | 124/247 [01:40<02:07,  1.04s/it]Loading train:  51%|█████     | 125/247 [01:41<02:04,  1.02s/it]Loading train:  51%|█████     | 126/247 [01:42<02:10,  1.08s/it]Loading train:  51%|█████▏    | 127/247 [01:43<02:14,  1.12s/it]Loading train:  52%|█████▏    | 128/247 [01:44<02:20,  1.18s/it]Loading train:  52%|█████▏    | 129/247 [01:45<02:16,  1.16s/it]Loading train:  53%|█████▎    | 130/247 [01:47<02:20,  1.20s/it]Loading train:  53%|█████▎    | 131/247 [01:48<02:10,  1.13s/it]Loading train:  53%|█████▎    | 132/247 [01:49<02:09,  1.13s/it]Loading train:  54%|█████▍    | 133/247 [01:50<02:08,  1.13s/it]Loading train:  54%|█████▍    | 134/247 [01:51<01:59,  1.06s/it]Loading train:  55%|█████▍    | 135/247 [01:52<02:04,  1.11s/it]Loading train:  55%|█████▌    | 136/247 [01:53<02:12,  1.19s/it]Loading train:  55%|█████▌    | 137/247 [01:54<02:06,  1.15s/it]Loading train:  56%|█████▌    | 138/247 [01:56<02:08,  1.18s/it]Loading train:  56%|█████▋    | 139/247 [01:57<02:12,  1.22s/it]Loading train:  57%|█████▋    | 140/247 [01:58<02:04,  1.16s/it]Loading train:  57%|█████▋    | 141/247 [01:59<01:49,  1.03s/it]Loading train:  57%|█████▋    | 142/247 [02:00<01:44,  1.00it/s]Loading train:  58%|█████▊    | 143/247 [02:01<01:52,  1.08s/it]Loading train:  58%|█████▊    | 144/247 [02:02<01:45,  1.02s/it]Loading train:  59%|█████▊    | 145/247 [02:03<01:47,  1.06s/it]Loading train:  59%|█████▉    | 146/247 [02:04<01:50,  1.10s/it]Loading train:  60%|█████▉    | 147/247 [02:05<01:50,  1.11s/it]Loading train:  60%|█████▉    | 148/247 [02:06<01:47,  1.09s/it]Loading train:  60%|██████    | 149/247 [02:07<01:42,  1.05s/it]Loading train:  61%|██████    | 150/247 [02:08<01:40,  1.04s/it]Loading train:  61%|██████    | 151/247 [02:09<01:31,  1.05it/s]Loading train:  62%|██████▏   | 152/247 [02:10<01:36,  1.02s/it]Loading train:  62%|██████▏   | 153/247 [02:11<01:34,  1.01s/it]Loading train:  62%|██████▏   | 154/247 [02:12<01:39,  1.07s/it]Loading train:  63%|██████▎   | 155/247 [02:14<01:39,  1.08s/it]Loading train:  63%|██████▎   | 156/247 [02:14<01:33,  1.03s/it]Loading train:  64%|██████▎   | 157/247 [02:15<01:30,  1.00s/it]Loading train:  64%|██████▍   | 158/247 [02:16<01:27,  1.02it/s]Loading train:  64%|██████▍   | 159/247 [02:18<01:32,  1.05s/it]Loading train:  65%|██████▍   | 160/247 [02:19<01:40,  1.16s/it]Loading train:  65%|██████▌   | 161/247 [02:20<01:38,  1.14s/it]Loading train:  66%|██████▌   | 162/247 [02:21<01:37,  1.14s/it]Loading train:  66%|██████▌   | 163/247 [02:22<01:32,  1.10s/it]Loading train:  66%|██████▋   | 164/247 [02:23<01:26,  1.04s/it]Loading train:  67%|██████▋   | 165/247 [02:24<01:20,  1.02it/s]Loading train:  67%|██████▋   | 166/247 [02:25<01:14,  1.09it/s]Loading train:  68%|██████▊   | 167/247 [02:26<01:21,  1.02s/it]Loading train:  68%|██████▊   | 168/247 [02:27<01:26,  1.10s/it]Loading train:  68%|██████▊   | 169/247 [02:28<01:27,  1.13s/it]Loading train:  69%|██████▉   | 170/247 [02:29<01:24,  1.10s/it]Loading train:  69%|██████▉   | 171/247 [02:30<01:17,  1.02s/it]Loading train:  70%|██████▉   | 172/247 [02:32<01:20,  1.07s/it]Loading train:  70%|███████   | 173/247 [02:32<01:14,  1.00s/it]Loading train:  70%|███████   | 174/247 [02:33<01:11,  1.02it/s]Loading train:  71%|███████   | 175/247 [02:34<01:09,  1.04it/s]Loading train:  71%|███████▏  | 176/247 [02:35<01:08,  1.04it/s]Loading train:  72%|███████▏  | 177/247 [02:36<01:03,  1.10it/s]Loading train:  72%|███████▏  | 178/247 [02:37<01:06,  1.03it/s]Loading train:  72%|███████▏  | 179/247 [02:38<01:11,  1.06s/it]Loading train:  73%|███████▎  | 180/247 [02:39<01:10,  1.05s/it]Loading train:  73%|███████▎  | 181/247 [02:40<01:09,  1.06s/it]Loading train:  74%|███████▎  | 182/247 [02:42<01:09,  1.07s/it]Loading train:  74%|███████▍  | 183/247 [02:42<01:04,  1.01s/it]Loading train:  74%|███████▍  | 184/247 [02:43<01:00,  1.03it/s]Loading train:  75%|███████▍  | 185/247 [02:44<01:01,  1.01it/s]Loading train:  75%|███████▌  | 186/247 [02:45<01:03,  1.04s/it]Loading train:  76%|███████▌  | 187/247 [02:46<01:01,  1.03s/it]Loading train:  76%|███████▌  | 188/247 [02:47<01:00,  1.02s/it]Loading train:  77%|███████▋  | 189/247 [02:49<01:02,  1.08s/it]Loading train:  77%|███████▋  | 190/247 [02:50<01:00,  1.06s/it]Loading train:  77%|███████▋  | 191/247 [02:51<00:59,  1.06s/it]Loading train:  78%|███████▊  | 192/247 [02:52<00:55,  1.00s/it]Loading train:  78%|███████▊  | 193/247 [02:53<00:55,  1.03s/it]Loading train:  79%|███████▊  | 194/247 [02:54<00:51,  1.03it/s]Loading train:  79%|███████▉  | 195/247 [02:55<00:53,  1.03s/it]Loading train:  79%|███████▉  | 196/247 [02:56<00:51,  1.01s/it]Loading train:  80%|███████▉  | 197/247 [02:57<00:49,  1.01it/s]Loading train:  80%|████████  | 198/247 [02:58<00:52,  1.06s/it]Loading train:  81%|████████  | 199/247 [03:00<01:01,  1.29s/it]Loading train:  81%|████████  | 200/247 [03:01<01:07,  1.44s/it]Loading train:  81%|████████▏ | 201/247 [03:03<01:04,  1.40s/it]Loading train:  82%|████████▏ | 202/247 [03:04<01:04,  1.43s/it]Loading train:  82%|████████▏ | 203/247 [03:06<01:06,  1.51s/it]Loading train:  83%|████████▎ | 204/247 [03:08<01:06,  1.55s/it]Loading train:  83%|████████▎ | 205/247 [03:09<01:02,  1.49s/it]Loading train:  83%|████████▎ | 206/247 [03:10<00:55,  1.35s/it]Loading train:  84%|████████▍ | 207/247 [03:11<00:50,  1.26s/it]Loading train:  84%|████████▍ | 208/247 [03:12<00:45,  1.16s/it]Loading train:  85%|████████▍ | 209/247 [03:13<00:43,  1.15s/it]Loading train:  85%|████████▌ | 210/247 [03:14<00:42,  1.15s/it]Loading train:  85%|████████▌ | 211/247 [03:15<00:42,  1.18s/it]Loading train:  86%|████████▌ | 212/247 [03:16<00:38,  1.11s/it]Loading train:  86%|████████▌ | 213/247 [03:17<00:35,  1.04s/it]Loading train:  87%|████████▋ | 214/247 [03:18<00:33,  1.02s/it]Loading train:  87%|████████▋ | 215/247 [03:19<00:33,  1.05s/it]Loading train:  87%|████████▋ | 216/247 [03:21<00:33,  1.08s/it]Loading train:  88%|████████▊ | 217/247 [03:22<00:32,  1.08s/it]Loading train:  88%|████████▊ | 218/247 [03:23<00:31,  1.08s/it]Loading train:  89%|████████▊ | 219/247 [03:24<00:32,  1.15s/it]Loading train:  89%|████████▉ | 220/247 [03:25<00:31,  1.18s/it]Loading train:  89%|████████▉ | 221/247 [03:27<00:33,  1.30s/it]Loading train:  90%|████████▉ | 222/247 [03:28<00:35,  1.40s/it]Loading train:  90%|█████████ | 223/247 [03:30<00:31,  1.31s/it]Loading train:  91%|█████████ | 224/247 [03:30<00:25,  1.12s/it]Loading train:  91%|█████████ | 225/247 [03:31<00:22,  1.03s/it]Loading train:  91%|█████████▏| 226/247 [03:32<00:20,  1.02it/s]Loading train:  92%|█████████▏| 227/247 [03:33<00:19,  1.03it/s]Loading train:  92%|█████████▏| 228/247 [03:34<00:20,  1.07s/it]Loading train:  93%|█████████▎| 229/247 [03:35<00:19,  1.08s/it]Loading train:  93%|█████████▎| 230/247 [03:36<00:16,  1.00it/s]Loading train:  94%|█████████▎| 231/247 [03:37<00:15,  1.03it/s]Loading train:  94%|█████████▍| 232/247 [03:38<00:14,  1.00it/s]Loading train:  94%|█████████▍| 233/247 [03:39<00:14,  1.02s/it]Loading train:  95%|█████████▍| 234/247 [03:40<00:14,  1.09s/it]Loading train:  95%|█████████▌| 235/247 [03:41<00:12,  1.04s/it]Loading train:  96%|█████████▌| 236/247 [03:42<00:10,  1.01it/s]Loading train:  96%|█████████▌| 237/247 [03:43<00:09,  1.09it/s]Loading train:  96%|█████████▋| 238/247 [03:44<00:09,  1.02s/it]Loading train:  97%|█████████▋| 239/247 [03:45<00:08,  1.10s/it]Loading train:  97%|█████████▋| 240/247 [03:47<00:07,  1.08s/it]Loading train:  98%|█████████▊| 241/247 [03:48<00:06,  1.05s/it]Loading train:  98%|█████████▊| 242/247 [03:49<00:05,  1.08s/it]Loading train:  98%|█████████▊| 243/247 [03:50<00:04,  1.04s/it]Loading train:  99%|█████████▉| 244/247 [03:51<00:03,  1.08s/it]Loading train:  99%|█████████▉| 245/247 [03:52<00:02,  1.02s/it]Loading train: 100%|█████████▉| 246/247 [03:53<00:01,  1.00s/it]Loading train: 100%|██████████| 247/247 [03:53<00:00,  1.04it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/247 [00:00<00:18, 13.30it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:16, 14.66it/s]concatenating: train:   3%|▎         | 7/247 [00:00<00:16, 14.93it/s]concatenating: train:   4%|▎         | 9/247 [00:00<00:15, 15.14it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:18, 12.52it/s]concatenating: train:   5%|▌         | 13/247 [00:00<00:17, 13.76it/s]concatenating: train:   6%|▌         | 15/247 [00:01<00:18, 12.54it/s]concatenating: train:   7%|▋         | 17/247 [00:01<00:18, 12.26it/s]concatenating: train:   8%|▊         | 19/247 [00:01<00:19, 11.48it/s]concatenating: train:   9%|▊         | 21/247 [00:01<00:20, 10.96it/s]concatenating: train:   9%|▉         | 23/247 [00:01<00:19, 11.34it/s]concatenating: train:  10%|█         | 25/247 [00:01<00:17, 12.36it/s]concatenating: train:  11%|█         | 27/247 [00:02<00:16, 13.50it/s]concatenating: train:  12%|█▏        | 29/247 [00:02<00:20, 10.62it/s]concatenating: train:  13%|█▎        | 32/247 [00:02<00:16, 12.87it/s]concatenating: train:  14%|█▍        | 34/247 [00:02<00:15, 13.71it/s]concatenating: train:  15%|█▍        | 36/247 [00:02<00:15, 13.97it/s]concatenating: train:  15%|█▌        | 38/247 [00:03<00:20, 10.02it/s]concatenating: train:  16%|█▌        | 40/247 [00:03<00:18, 11.30it/s]concatenating: train:  17%|█▋        | 42/247 [00:03<00:16, 12.80it/s]concatenating: train:  18%|█▊        | 44/247 [00:03<00:18, 10.95it/s]concatenating: train:  19%|█▊        | 46/247 [00:03<00:18, 10.93it/s]concatenating: train:  19%|█▉        | 48/247 [00:03<00:17, 11.67it/s]concatenating: train:  21%|██        | 51/247 [00:04<00:16, 11.84it/s]concatenating: train:  21%|██▏       | 53/247 [00:04<00:16, 11.80it/s]concatenating: train:  23%|██▎       | 56/247 [00:04<00:13, 13.94it/s]concatenating: train:  23%|██▎       | 58/247 [00:04<00:12, 14.93it/s]concatenating: train:  24%|██▍       | 60/247 [00:04<00:12, 14.40it/s]concatenating: train:  25%|██▌       | 62/247 [00:04<00:14, 12.97it/s]concatenating: train:  26%|██▌       | 64/247 [00:04<00:12, 14.26it/s]concatenating: train:  27%|██▋       | 66/247 [00:05<00:13, 13.35it/s]concatenating: train:  28%|██▊       | 68/247 [00:05<00:16, 10.66it/s]concatenating: train:  29%|██▊       | 71/247 [00:05<00:13, 13.00it/s]concatenating: train:  30%|██▉       | 74/247 [00:05<00:11, 14.66it/s]concatenating: train:  31%|███       | 77/247 [00:05<00:10, 16.51it/s]concatenating: train:  32%|███▏      | 79/247 [00:06<00:12, 13.49it/s]concatenating: train:  33%|███▎      | 81/247 [00:06<00:12, 13.49it/s]concatenating: train:  34%|███▎      | 83/247 [00:06<00:12, 13.28it/s]concatenating: train:  34%|███▍      | 85/247 [00:06<00:11, 13.89it/s]concatenating: train:  35%|███▌      | 87/247 [00:06<00:12, 12.55it/s]concatenating: train:  36%|███▌      | 89/247 [00:06<00:13, 11.50it/s]concatenating: train:  37%|███▋      | 92/247 [00:06<00:11, 13.49it/s]concatenating: train:  38%|███▊      | 95/247 [00:07<00:09, 15.85it/s]concatenating: train:  39%|███▉      | 97/247 [00:07<00:11, 13.26it/s]concatenating: train:  40%|████      | 100/247 [00:07<00:09, 15.64it/s]concatenating: train:  42%|████▏     | 103/247 [00:07<00:08, 17.38it/s]concatenating: train:  43%|████▎     | 106/247 [00:07<00:08, 16.37it/s]concatenating: train:  44%|████▎     | 108/247 [00:07<00:10, 13.30it/s]concatenating: train:  45%|████▍     | 110/247 [00:08<00:13, 10.37it/s]concatenating: train:  45%|████▌     | 112/247 [00:08<00:12, 10.72it/s]concatenating: train:  46%|████▌     | 114/247 [00:08<00:13,  9.70it/s]concatenating: train:  47%|████▋     | 116/247 [00:08<00:12, 10.87it/s]concatenating: train:  48%|████▊     | 118/247 [00:08<00:10, 11.97it/s]concatenating: train:  49%|████▊     | 120/247 [00:09<00:10, 12.21it/s]concatenating: train:  49%|████▉     | 122/247 [00:09<00:09, 12.67it/s]concatenating: train:  50%|█████     | 124/247 [00:09<00:09, 13.43it/s]concatenating: train:  51%|█████▏    | 127/247 [00:09<00:07, 15.27it/s]concatenating: train:  52%|█████▏    | 129/247 [00:09<00:07, 16.01it/s]concatenating: train:  53%|█████▎    | 131/247 [00:09<00:08, 14.37it/s]concatenating: train:  54%|█████▍    | 133/247 [00:09<00:07, 14.29it/s]concatenating: train:  55%|█████▍    | 135/247 [00:10<00:07, 14.37it/s]concatenating: train:  55%|█████▌    | 137/247 [00:10<00:07, 14.98it/s]concatenating: train:  56%|█████▋    | 139/247 [00:10<00:07, 14.13it/s]concatenating: train:  57%|█████▋    | 141/247 [00:10<00:08, 11.95it/s]concatenating: train:  58%|█████▊    | 143/247 [00:10<00:07, 13.59it/s]concatenating: train:  59%|█████▊    | 145/247 [00:10<00:07, 13.80it/s]concatenating: train:  60%|█████▉    | 147/247 [00:10<00:07, 13.49it/s]concatenating: train:  60%|██████    | 149/247 [00:11<00:07, 12.45it/s]concatenating: train:  62%|██████▏   | 152/247 [00:11<00:07, 13.36it/s]concatenating: train:  62%|██████▏   | 154/247 [00:11<00:07, 12.69it/s]concatenating: train:  63%|██████▎   | 156/247 [00:11<00:08, 10.49it/s]concatenating: train:  64%|██████▍   | 158/247 [00:11<00:07, 11.67it/s]concatenating: train:  65%|██████▍   | 160/247 [00:12<00:07, 11.78it/s]concatenating: train:  66%|██████▌   | 163/247 [00:12<00:07, 11.90it/s]concatenating: train:  67%|██████▋   | 165/247 [00:12<00:06, 11.87it/s]concatenating: train:  68%|██████▊   | 167/247 [00:12<00:06, 12.60it/s]concatenating: train:  68%|██████▊   | 169/247 [00:12<00:07, 10.44it/s]concatenating: train:  69%|██████▉   | 171/247 [00:13<00:07, 10.24it/s]concatenating: train:  70%|███████   | 174/247 [00:13<00:05, 12.51it/s]concatenating: train:  72%|███████▏  | 178/247 [00:13<00:04, 15.73it/s]concatenating: train:  82%|████████▏ | 203/247 [00:13<00:02, 21.82it/s]concatenating: train:  86%|████████▌ | 212/247 [00:14<00:01, 18.82it/s]concatenating: train:  89%|████████▊ | 219/247 [00:14<00:01, 16.25it/s]concatenating: train:  91%|█████████ | 224/247 [00:15<00:01, 13.91it/s]concatenating: train:  92%|█████████▏| 228/247 [00:15<00:01, 12.03it/s]concatenating: train:  94%|█████████▎| 231/247 [00:15<00:01, 12.43it/s]concatenating: train:  95%|█████████▍| 234/247 [00:15<00:00, 13.31it/s]concatenating: train:  96%|█████████▌| 237/247 [00:16<00:00, 11.82it/s]concatenating: train:  97%|█████████▋| 239/247 [00:16<00:00, 12.95it/s]concatenating: train:  98%|█████████▊| 241/247 [00:16<00:00, 13.88it/s]concatenating: train:  99%|█████████▉| 245/247 [00:16<00:00, 14.36it/s]concatenating: train: 100%|██████████| 247/247 [00:16<00:00, 13.86it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Error in label values min 0.0 max 2.0      1-THALAMUS
Loading test:  20%|██        | 1/5 [00:01<00:05,  1.32s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.24s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.21s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.14s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  9.59it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  9.60it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  8.84it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  8.92it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<02:42,  1.51it/s]Loading trainS:   1%|          | 2/247 [00:01<03:26,  1.18it/s]Loading trainS:   1%|          | 3/247 [00:03<03:52,  1.05it/s]Loading trainS:   2%|▏         | 4/247 [00:04<04:03,  1.00s/it]Loading trainS:   2%|▏         | 5/247 [00:05<04:01,  1.00it/s]Loading trainS:   2%|▏         | 6/247 [00:06<04:15,  1.06s/it]Loading trainS:   3%|▎         | 7/247 [00:07<04:18,  1.08s/it]Loading trainS:   3%|▎         | 8/247 [00:08<04:18,  1.08s/it]Loading trainS:   4%|▎         | 9/247 [00:09<04:04,  1.03s/it]Loading trainS:   4%|▍         | 10/247 [00:10<04:25,  1.12s/it]Loading trainS:   4%|▍         | 11/247 [00:11<04:15,  1.08s/it]Loading trainS:   5%|▍         | 12/247 [00:12<04:02,  1.03s/it]Loading trainS:   5%|▌         | 13/247 [00:13<04:10,  1.07s/it]Loading trainS:   6%|▌         | 14/247 [00:15<04:26,  1.14s/it]Loading trainS:   6%|▌         | 15/247 [00:16<04:32,  1.18s/it]Loading trainS:   6%|▋         | 16/247 [00:17<04:43,  1.23s/it]Loading trainS:   7%|▋         | 17/247 [00:19<04:49,  1.26s/it]Loading trainS:   7%|▋         | 18/247 [00:20<05:24,  1.42s/it]Loading trainS:   8%|▊         | 19/247 [00:22<05:47,  1.52s/it]Loading trainS:   8%|▊         | 20/247 [00:23<05:21,  1.42s/it]Loading trainS:   9%|▊         | 21/247 [00:25<05:17,  1.40s/it]Loading trainS:   9%|▉         | 22/247 [00:26<05:00,  1.34s/it]Loading trainS:   9%|▉         | 23/247 [00:27<04:28,  1.20s/it]Loading trainS:  10%|▉         | 24/247 [00:28<04:23,  1.18s/it]Loading trainS:  10%|█         | 25/247 [00:29<04:17,  1.16s/it]Loading trainS:  11%|█         | 26/247 [00:30<04:09,  1.13s/it]Loading trainS:  11%|█         | 27/247 [00:31<03:51,  1.05s/it]Loading trainS:  11%|█▏        | 28/247 [00:32<03:26,  1.06it/s]Loading trainS:  12%|█▏        | 29/247 [00:33<03:27,  1.05it/s]Loading trainS:  12%|█▏        | 30/247 [00:34<03:35,  1.01it/s]Loading trainS:  13%|█▎        | 31/247 [00:35<03:52,  1.07s/it]Loading trainS:  13%|█▎        | 32/247 [00:36<03:55,  1.10s/it]Loading trainS:  13%|█▎        | 33/247 [00:37<04:06,  1.15s/it]Loading trainS:  14%|█▍        | 34/247 [00:39<04:17,  1.21s/it]Loading trainS:  14%|█▍        | 35/247 [00:40<03:59,  1.13s/it]Loading trainS:  15%|█▍        | 36/247 [00:41<04:04,  1.16s/it]Loading trainS:  15%|█▍        | 37/247 [00:42<03:48,  1.09s/it]Loading trainS:  15%|█▌        | 38/247 [00:42<03:01,  1.15it/s]Loading trainS:  16%|█▌        | 39/247 [00:43<03:21,  1.03it/s]Loading trainS:  16%|█▌        | 40/247 [00:45<03:58,  1.15s/it]Loading trainS:  17%|█▋        | 41/247 [00:47<04:20,  1.26s/it]Loading trainS:  17%|█▋        | 42/247 [00:48<04:21,  1.27s/it]Loading trainS:  17%|█▋        | 43/247 [00:49<04:20,  1.28s/it]Loading trainS:  18%|█▊        | 44/247 [00:50<04:12,  1.24s/it]Loading trainS:  18%|█▊        | 45/247 [00:51<04:05,  1.22s/it]Loading trainS:  19%|█▊        | 46/247 [00:52<03:47,  1.13s/it]Loading trainS:  19%|█▉        | 47/247 [00:53<03:38,  1.09s/it]Loading trainS:  19%|█▉        | 48/247 [00:54<03:31,  1.06s/it]Loading trainS:  20%|█▉        | 49/247 [00:55<03:19,  1.01s/it]Loading trainS:  20%|██        | 50/247 [00:56<03:08,  1.05it/s]Loading trainS:  21%|██        | 51/247 [00:57<03:16,  1.00s/it]Loading trainS:  21%|██        | 52/247 [00:58<03:26,  1.06s/it]Loading trainS:  21%|██▏       | 53/247 [00:59<03:25,  1.06s/it]Loading trainS:  22%|██▏       | 54/247 [01:01<03:29,  1.08s/it]Loading trainS:  22%|██▏       | 55/247 [01:02<03:28,  1.09s/it]Loading trainS:  23%|██▎       | 56/247 [01:03<03:28,  1.09s/it]Loading trainS:  23%|██▎       | 57/247 [01:04<03:33,  1.12s/it]Loading trainS:  23%|██▎       | 58/247 [01:05<03:28,  1.11s/it]Loading trainS:  24%|██▍       | 59/247 [01:06<03:35,  1.15s/it]Loading trainS:  24%|██▍       | 60/247 [01:07<03:28,  1.12s/it]Loading trainS:  25%|██▍       | 61/247 [01:08<03:22,  1.09s/it]Loading trainS:  25%|██▌       | 62/247 [01:10<03:38,  1.18s/it]Loading trainS:  26%|██▌       | 63/247 [01:11<03:34,  1.16s/it]Loading trainS:  26%|██▌       | 64/247 [01:12<03:52,  1.27s/it]Loading trainS:  26%|██▋       | 65/247 [01:14<03:46,  1.24s/it]Loading trainS:  27%|██▋       | 66/247 [01:15<03:52,  1.28s/it]Loading trainS:  27%|██▋       | 67/247 [01:16<03:53,  1.30s/it]Loading trainS:  28%|██▊       | 68/247 [01:18<03:51,  1.29s/it]Loading trainS:  28%|██▊       | 69/247 [01:19<03:47,  1.28s/it]Loading trainS:  28%|██▊       | 70/247 [01:20<03:43,  1.26s/it]Loading trainS:  29%|██▊       | 71/247 [01:21<03:42,  1.26s/it]Loading trainS:  29%|██▉       | 72/247 [01:23<03:40,  1.26s/it]Loading trainS:  30%|██▉       | 73/247 [01:24<03:38,  1.26s/it]Loading trainS:  30%|██▉       | 74/247 [01:25<03:23,  1.18s/it]Loading trainS:  30%|███       | 75/247 [01:26<03:10,  1.11s/it]Loading trainS:  31%|███       | 76/247 [01:27<03:12,  1.12s/it]Loading trainS:  31%|███       | 77/247 [01:28<03:00,  1.06s/it]Loading trainS:  32%|███▏      | 78/247 [01:29<03:02,  1.08s/it]Loading trainS:  32%|███▏      | 79/247 [01:30<03:11,  1.14s/it]Loading trainS:  32%|███▏      | 80/247 [01:32<03:21,  1.21s/it]Loading trainS:  33%|███▎      | 81/247 [01:32<03:00,  1.09s/it]Loading trainS:  33%|███▎      | 82/247 [01:33<02:43,  1.01it/s]Loading trainS:  34%|███▎      | 83/247 [01:34<02:27,  1.11it/s]Loading trainS:  34%|███▍      | 84/247 [01:35<02:21,  1.16it/s]Loading trainS:  34%|███▍      | 85/247 [01:36<02:28,  1.09it/s]Loading trainS:  35%|███▍      | 86/247 [01:37<02:38,  1.01it/s]Loading trainS:  35%|███▌      | 87/247 [01:38<02:36,  1.02it/s]Loading trainS:  36%|███▌      | 88/247 [01:39<02:45,  1.04s/it]Loading trainS:  36%|███▌      | 89/247 [01:40<02:51,  1.09s/it]Loading trainS:  36%|███▋      | 90/247 [01:41<02:40,  1.02s/it]Loading trainS:  37%|███▋      | 91/247 [01:42<02:35,  1.00it/s]Loading trainS:  37%|███▋      | 92/247 [01:43<02:30,  1.03it/s]Loading trainS:  38%|███▊      | 93/247 [01:44<02:38,  1.03s/it]Loading trainS:  38%|███▊      | 94/247 [01:45<02:53,  1.13s/it]Loading trainS:  38%|███▊      | 95/247 [01:47<02:53,  1.14s/it]Loading trainS:  39%|███▉      | 96/247 [01:48<02:43,  1.08s/it]Loading trainS:  39%|███▉      | 97/247 [01:49<02:37,  1.05s/it]Loading trainS:  40%|███▉      | 98/247 [01:49<02:27,  1.01it/s]Loading trainS:  40%|████      | 99/247 [01:50<02:26,  1.01it/s]Loading trainS:  40%|████      | 100/247 [01:51<02:28,  1.01s/it]Loading trainS:  41%|████      | 101/247 [01:53<02:39,  1.09s/it]Loading trainS:  41%|████▏     | 102/247 [01:54<02:37,  1.09s/it]Loading trainS:  42%|████▏     | 103/247 [01:55<02:39,  1.11s/it]Loading trainS:  42%|████▏     | 104/247 [01:56<02:27,  1.03s/it]Loading trainS:  43%|████▎     | 105/247 [01:57<02:27,  1.04s/it]Loading trainS:  43%|████▎     | 106/247 [01:58<02:19,  1.01it/s]Loading trainS:  43%|████▎     | 107/247 [01:59<02:27,  1.05s/it]Loading trainS:  44%|████▎     | 108/247 [02:00<02:33,  1.11s/it]Loading trainS:  44%|████▍     | 109/247 [02:01<02:30,  1.09s/it]Loading trainS:  45%|████▍     | 110/247 [02:02<02:32,  1.11s/it]Loading trainS:  45%|████▍     | 111/247 [02:04<02:39,  1.17s/it]Loading trainS:  45%|████▌     | 112/247 [02:05<02:34,  1.15s/it]Loading trainS:  46%|████▌     | 113/247 [02:06<02:22,  1.06s/it]Loading trainS:  46%|████▌     | 114/247 [02:06<02:11,  1.01it/s]Loading trainS:  47%|████▋     | 115/247 [02:07<02:03,  1.07it/s]Loading trainS:  47%|████▋     | 116/247 [02:08<01:59,  1.10it/s]Loading trainS:  47%|████▋     | 117/247 [02:09<02:01,  1.07it/s]Loading trainS:  48%|████▊     | 118/247 [02:10<02:00,  1.07it/s]Loading trainS:  48%|████▊     | 119/247 [02:11<02:14,  1.05s/it]Loading trainS:  49%|████▊     | 120/247 [02:13<02:16,  1.07s/it]Loading trainS:  49%|████▉     | 121/247 [02:13<02:03,  1.02it/s]Loading trainS:  49%|████▉     | 122/247 [02:15<02:13,  1.07s/it]Loading trainS:  50%|████▉     | 123/247 [02:16<02:15,  1.09s/it]Loading trainS:  50%|█████     | 124/247 [02:16<02:00,  1.02it/s]Loading trainS:  51%|█████     | 125/247 [02:18<02:13,  1.10s/it]Loading trainS:  51%|█████     | 126/247 [02:19<02:16,  1.13s/it]Loading trainS:  51%|█████▏    | 127/247 [02:20<02:09,  1.08s/it]Loading trainS:  52%|█████▏    | 128/247 [02:21<01:58,  1.00it/s]Loading trainS:  52%|█████▏    | 129/247 [02:22<02:07,  1.08s/it]Loading trainS:  53%|█████▎    | 130/247 [02:23<01:56,  1.01it/s]Loading trainS:  53%|█████▎    | 131/247 [02:24<01:57,  1.02s/it]Loading trainS:  53%|█████▎    | 132/247 [02:25<01:54,  1.01it/s]Loading trainS:  54%|█████▍    | 133/247 [02:26<01:56,  1.02s/it]Loading trainS:  54%|█████▍    | 134/247 [02:27<01:53,  1.00s/it]Loading trainS:  55%|█████▍    | 135/247 [02:28<01:59,  1.07s/it]Loading trainS:  55%|█████▌    | 136/247 [02:29<02:01,  1.10s/it]Loading trainS:  55%|█████▌    | 137/247 [02:30<02:00,  1.09s/it]Loading trainS:  56%|█████▌    | 138/247 [02:31<01:53,  1.04s/it]Loading trainS:  56%|█████▋    | 139/247 [02:32<01:55,  1.07s/it]Loading trainS:  57%|█████▋    | 140/247 [02:34<01:58,  1.11s/it]Loading trainS:  57%|█████▋    | 141/247 [02:35<02:05,  1.18s/it]Loading trainS:  57%|█████▋    | 142/247 [02:36<02:02,  1.17s/it]Loading trainS:  58%|█████▊    | 143/247 [02:37<01:53,  1.09s/it]Loading trainS:  58%|█████▊    | 144/247 [02:38<01:52,  1.10s/it]Loading trainS:  59%|█████▊    | 145/247 [02:39<01:53,  1.11s/it]Loading trainS:  59%|█████▉    | 146/247 [02:40<01:51,  1.11s/it]Loading trainS:  60%|█████▉    | 147/247 [02:41<01:38,  1.02it/s]Loading trainS:  60%|█████▉    | 148/247 [02:42<01:32,  1.07it/s]Loading trainS:  60%|██████    | 149/247 [02:43<01:38,  1.00s/it]Loading trainS:  61%|██████    | 150/247 [02:44<01:41,  1.05s/it]Loading trainS:  61%|██████    | 151/247 [02:45<01:28,  1.08it/s]Loading trainS:  62%|██████▏   | 152/247 [02:46<01:24,  1.12it/s]Loading trainS:  62%|██████▏   | 153/247 [02:47<01:29,  1.06it/s]Loading trainS:  62%|██████▏   | 154/247 [02:48<01:27,  1.06it/s]Loading trainS:  63%|██████▎   | 155/247 [02:49<01:27,  1.05it/s]Loading trainS:  63%|██████▎   | 156/247 [02:49<01:22,  1.11it/s]Loading trainS:  64%|██████▎   | 157/247 [02:50<01:19,  1.13it/s]Loading trainS:  64%|██████▍   | 158/247 [02:51<01:28,  1.00it/s]Loading trainS:  64%|██████▍   | 159/247 [02:52<01:27,  1.00it/s]Loading trainS:  65%|██████▍   | 160/247 [02:54<01:28,  1.01s/it]Loading trainS:  65%|██████▌   | 161/247 [02:55<01:39,  1.16s/it]Loading trainS:  66%|██████▌   | 162/247 [02:56<01:37,  1.15s/it]Loading trainS:  66%|██████▌   | 163/247 [02:57<01:35,  1.14s/it]Loading trainS:  66%|██████▋   | 164/247 [02:58<01:31,  1.10s/it]Loading trainS:  67%|██████▋   | 165/247 [02:59<01:25,  1.04s/it]Loading trainS:  67%|██████▋   | 166/247 [03:00<01:22,  1.02s/it]Loading trainS:  68%|██████▊   | 167/247 [03:01<01:24,  1.05s/it]Loading trainS:  68%|██████▊   | 168/247 [03:02<01:24,  1.07s/it]Loading trainS:  68%|██████▊   | 169/247 [03:03<01:19,  1.02s/it]Loading trainS:  69%|██████▉   | 170/247 [03:04<01:17,  1.00s/it]Loading trainS:  69%|██████▉   | 171/247 [03:05<01:16,  1.01s/it]Loading trainS:  70%|██████▉   | 172/247 [03:06<01:17,  1.04s/it]Loading trainS:  70%|███████   | 173/247 [03:07<01:05,  1.14it/s]Loading trainS:  70%|███████   | 174/247 [03:08<01:03,  1.15it/s]Loading trainS:  71%|███████   | 175/247 [03:09<01:07,  1.07it/s]Loading trainS:  71%|███████▏  | 176/247 [03:10<01:04,  1.11it/s]Loading trainS:  72%|███████▏  | 177/247 [03:11<01:05,  1.07it/s]Loading trainS:  72%|███████▏  | 178/247 [03:12<01:03,  1.09it/s]Loading trainS:  72%|███████▏  | 179/247 [03:13<01:05,  1.04it/s]Loading trainS:  73%|███████▎  | 180/247 [03:13<01:01,  1.09it/s]Loading trainS:  73%|███████▎  | 181/247 [03:15<01:07,  1.02s/it]Loading trainS:  74%|███████▎  | 182/247 [03:16<01:05,  1.01s/it]Loading trainS:  74%|███████▍  | 183/247 [03:17<01:06,  1.04s/it]Loading trainS:  74%|███████▍  | 184/247 [03:18<01:03,  1.01s/it]Loading trainS:  75%|███████▍  | 185/247 [03:19<01:06,  1.07s/it]Loading trainS:  75%|███████▌  | 186/247 [03:20<01:03,  1.05s/it]Loading trainS:  76%|███████▌  | 187/247 [03:21<01:05,  1.08s/it]Loading trainS:  76%|███████▌  | 188/247 [03:22<01:02,  1.06s/it]Loading trainS:  77%|███████▋  | 189/247 [03:23<00:57,  1.00it/s]Loading trainS:  77%|███████▋  | 190/247 [03:24<00:57,  1.01s/it]Loading trainS:  77%|███████▋  | 191/247 [03:25<00:51,  1.09it/s]Loading trainS:  78%|███████▊  | 192/247 [03:26<00:49,  1.11it/s]Loading trainS:  78%|███████▊  | 193/247 [03:27<00:50,  1.06it/s]Loading trainS:  79%|███████▊  | 194/247 [03:28<00:51,  1.04it/s]Loading trainS:  79%|███████▉  | 195/247 [03:29<00:52,  1.00s/it]Loading trainS:  79%|███████▉  | 196/247 [03:30<00:52,  1.03s/it]Loading trainS:  80%|███████▉  | 197/247 [03:31<00:51,  1.03s/it]Loading trainS:  80%|████████  | 198/247 [03:32<00:48,  1.01it/s]Loading trainS:  81%|████████  | 199/247 [03:33<00:46,  1.03it/s]Loading trainS:  81%|████████  | 200/247 [03:34<00:45,  1.03it/s]Loading trainS:  81%|████████▏ | 201/247 [03:35<00:44,  1.02it/s]Loading trainS:  82%|████████▏ | 202/247 [03:36<00:42,  1.06it/s]Loading trainS:  82%|████████▏ | 203/247 [03:36<00:40,  1.08it/s]Loading trainS:  83%|████████▎ | 204/247 [03:37<00:35,  1.22it/s]Loading trainS:  83%|████████▎ | 205/247 [03:38<00:39,  1.07it/s]Loading trainS:  83%|████████▎ | 206/247 [03:39<00:40,  1.00it/s]Loading trainS:  84%|████████▍ | 207/247 [03:41<00:42,  1.07s/it]Loading trainS:  84%|████████▍ | 208/247 [03:42<00:43,  1.11s/it]Loading trainS:  85%|████████▍ | 209/247 [03:43<00:40,  1.07s/it]Loading trainS:  85%|████████▌ | 210/247 [03:44<00:39,  1.06s/it]Loading trainS:  85%|████████▌ | 211/247 [03:45<00:40,  1.12s/it]Loading trainS:  86%|████████▌ | 212/247 [03:46<00:38,  1.09s/it]Loading trainS:  86%|████████▌ | 213/247 [03:47<00:37,  1.09s/it]Loading trainS:  87%|████████▋ | 214/247 [03:48<00:33,  1.03s/it]Loading trainS:  87%|████████▋ | 215/247 [03:49<00:32,  1.02s/it]Loading trainS:  87%|████████▋ | 216/247 [03:50<00:31,  1.01s/it]Loading trainS:  88%|████████▊ | 217/247 [03:51<00:31,  1.05s/it]Loading trainS:  88%|████████▊ | 218/247 [03:52<00:31,  1.08s/it]Loading trainS:  89%|████████▊ | 219/247 [03:53<00:29,  1.04s/it]Loading trainS:  89%|████████▉ | 220/247 [03:54<00:29,  1.07s/it]Loading trainS:  89%|████████▉ | 221/247 [03:55<00:26,  1.02s/it]Loading trainS:  90%|████████▉ | 222/247 [03:56<00:23,  1.05it/s]Loading trainS:  90%|█████████ | 223/247 [03:57<00:24,  1.02s/it]Loading trainS:  91%|█████████ | 224/247 [03:58<00:23,  1.04s/it]Loading trainS:  91%|█████████ | 225/247 [03:59<00:22,  1.02s/it]Loading trainS:  91%|█████████▏| 226/247 [04:00<00:22,  1.07s/it]Loading trainS:  92%|█████████▏| 227/247 [04:02<00:21,  1.09s/it]Loading trainS:  92%|█████████▏| 228/247 [04:03<00:21,  1.11s/it]Loading trainS:  93%|█████████▎| 229/247 [04:04<00:19,  1.10s/it]Loading trainS:  93%|█████████▎| 230/247 [04:05<00:16,  1.01it/s]Loading trainS:  94%|█████████▎| 231/247 [04:05<00:15,  1.05it/s]Loading trainS:  94%|█████████▍| 232/247 [04:06<00:14,  1.04it/s]Loading trainS:  94%|█████████▍| 233/247 [04:07<00:13,  1.03it/s]Loading trainS:  95%|█████████▍| 234/247 [04:08<00:12,  1.01it/s]Loading trainS:  95%|█████████▌| 235/247 [04:09<00:11,  1.03it/s]Loading trainS:  96%|█████████▌| 236/247 [04:10<00:10,  1.03it/s]Loading trainS:  96%|█████████▌| 237/247 [04:11<00:10,  1.01s/it]Loading trainS:  96%|█████████▋| 238/247 [04:13<00:09,  1.06s/it]Loading trainS:  97%|█████████▋| 239/247 [04:14<00:08,  1.03s/it]Loading trainS:  97%|█████████▋| 240/247 [04:15<00:07,  1.00s/it]Loading trainS:  98%|█████████▊| 241/247 [04:16<00:06,  1.00s/it]Loading trainS:  98%|█████████▊| 242/247 [04:17<00:05,  1.02s/it]Loading trainS:  98%|█████████▊| 243/247 [04:17<00:03,  1.02it/s]Loading trainS:  99%|█████████▉| 244/247 [04:19<00:03,  1.00s/it]Loading trainS:  99%|█████████▉| 245/247 [04:19<00:01,  1.03it/s]Loading trainS: 100%|█████████▉| 246/247 [04:20<00:00,  1.01it/s]Loading trainS: 100%|██████████| 247/247 [04:22<00:00,  1.05s/it]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Error in label values min 0.0 max 2.0      1-THALAMUS
Loading testS:  20%|██        | 1/5 [00:01<00:04,  1.24s/it]Loading testS:  40%|████      | 2/5 [00:02<00:03,  1.17s/it]Loading testS:  60%|██████    | 3/5 [00:03<00:02,  1.16s/it]Loading testS:  80%|████████  | 4/5 [00:04<00:01,  1.16s/it]Loading testS: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  6.14it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.09it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.79it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.07it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.82it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.68it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:18,  1.75it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:04<00:13,  1.99it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:05<00:17,  1.52it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:06<00:13,  1.84it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:06<00:10,  2.28it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:06<00:06,  3.07it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:06<00:04,  3.81it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:07<00:04,  3.59it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:07<00:03,  4.28it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:07<00:03,  3.88it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:09<00:03,  2.94it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:10<00:02,  2.58it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:12<00:03,  1.64it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:12<00:01,  2.11it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:12<00:01,  2.42it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:12<00:00,  3.48it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 48,482
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 39s - loss: 0.4038 - acc: 0.9323 - mDice: 0.5858 - val_loss: 1.0666 - val_acc: 0.9778 - val_mDice: 0.3492

Epoch 00001: val_mDice improved from -inf to 0.34922, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 30s - loss: 0.1175 - acc: 0.9844 - mDice: 0.8042 - val_loss: 5.4187 - val_acc: 0.9742 - val_mDice: 3.4752e-04

Epoch 00002: val_mDice did not improve from 0.34922
Epoch 3/300
 - 30s - loss: 0.1098 - acc: 0.9856 - mDice: 0.8152 - val_loss: 0.2159 - val_acc: 0.9889 - val_mDice: 0.7149

Epoch 00003: val_mDice improved from 0.34922 to 0.71493, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 30s - loss: 0.1015 - acc: 0.9877 - mDice: 0.8243 - val_loss: 0.1982 - val_acc: 0.9893 - val_mDice: 0.7251

Epoch 00004: val_mDice improved from 0.71493 to 0.72515, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 29s - loss: 0.0912 - acc: 0.9894 - mDice: 0.8414 - val_loss: 0.1754 - val_acc: 0.9812 - val_mDice: 0.7329

Epoch 00005: val_mDice improved from 0.72515 to 0.73292, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 29s - loss: 0.0872 - acc: 0.9901 - mDice: 0.8467 - val_loss: 0.1332 - val_acc: 0.9883 - val_mDice: 0.7827

Epoch 00006: val_mDice improved from 0.73292 to 0.78272, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 29s - loss: 0.0828 - acc: 0.9908 - mDice: 0.8537 - val_loss: 0.2782 - val_acc: 0.9886 - val_mDice: 0.6786

Epoch 00007: val_mDice did not improve from 0.78272
Epoch 8/300
 - 29s - loss: 0.0845 - acc: 0.9909 - mDice: 0.8516 - val_loss: 7.4884 - val_acc: 0.9742 - val_mDice: 6.2826e-07

Epoch 00008: val_mDice did not improve from 0.78272
Epoch 9/300
 - 30s - loss: 0.1467 - acc: 0.9873 - mDice: 0.7768 - val_loss: 3.2088 - val_acc: 0.9745 - val_mDice: 0.0221

Epoch 00009: val_mDice did not improve from 0.78272
Epoch 10/300
 - 30s - loss: 0.1056 - acc: 0.9893 - mDice: 0.8161 - val_loss: 0.2256 - val_acc: 0.9883 - val_mDice: 0.7086

Epoch 00010: val_mDice did not improve from 0.78272
Epoch 11/300
 - 29s - loss: 0.0895 - acc: 0.9907 - mDice: 0.8417 - val_loss: 0.1918 - val_acc: 0.9888 - val_mDice: 0.7329

Epoch 00011: val_mDice did not improve from 0.78272
Epoch 12/300
 - 31s - loss: 0.0934 - acc: 0.9904 - mDice: 0.8355 - val_loss: 0.1826 - val_acc: 0.9812 - val_mDice: 0.7145

Epoch 00012: val_mDice did not improve from 0.78272
Epoch 13/300
 - 31s - loss: 0.0882 - acc: 0.9909 - mDice: 0.8432 - val_loss: 0.3235 - val_acc: 0.9890 - val_mDice: 0.6767

Epoch 00013: val_mDice did not improve from 0.78272
Epoch 14/300
 - 31s - loss: 0.0800 - acc: 0.9916 - mDice: 0.8565 - val_loss: 0.3800 - val_acc: 0.9885 - val_mDice: 0.6538

Epoch 00014: val_mDice did not improve from 0.78272
Epoch 15/300
 - 31s - loss: 0.0787 - acc: 0.9917 - mDice: 0.8596 - val_loss: 0.3483 - val_acc: 0.9879 - val_mDice: 0.6405

Epoch 00015: val_mDice did not improve from 0.78272
Epoch 16/300
 - 31s - loss: 0.0810 - acc: 0.9915 - mDice: 0.8549 - val_loss: 0.5182 - val_acc: 0.9840 - val_mDice: 0.5179

Epoch 00016: val_mDice did not improve from 0.78272
Epoch 17/300
 - 31s - loss: 0.0768 - acc: 0.9918 - mDice: 0.8618 - val_loss: 0.3858 - val_acc: 0.9883 - val_mDice: 0.6491

Epoch 00017: val_mDice did not improve from 0.78272
Epoch 18/300
 - 31s - loss: 0.0742 - acc: 0.9920 - mDice: 0.8659 - val_loss: 0.1341 - val_acc: 0.9881 - val_mDice: 0.7824

Epoch 00018: val_mDice did not improve from 0.78272
Epoch 19/300
 - 31s - loss: 0.0727 - acc: 0.9922 - mDice: 0.8686 - val_loss: 0.3842 - val_acc: 0.9876 - val_mDice: 0.6286

Epoch 00019: val_mDice did not improve from 0.78272
Epoch 20/300
 - 31s - loss: 0.0722 - acc: 0.9923 - mDice: 0.8693 - val_loss: 0.2363 - val_acc: 0.9897 - val_mDice: 0.7139

Epoch 00020: val_mDice did not improve from 0.78272
Epoch 21/300
 - 32s - loss: 0.0718 - acc: 0.9923 - mDice: 0.8701 - val_loss: 0.4376 - val_acc: 0.9874 - val_mDice: 0.6219

Epoch 00021: val_mDice did not improve from 0.78272
Epoch 22/300
 - 31s - loss: 0.0705 - acc: 0.9925 - mDice: 0.8731 - val_loss: 0.2651 - val_acc: 0.9868 - val_mDice: 0.6320

Epoch 00022: val_mDice did not improve from 0.78272
Epoch 23/300
 - 32s - loss: 0.0789 - acc: 0.9918 - mDice: 0.8593 - val_loss: 2.9763 - val_acc: 0.9743 - val_mDice: 0.0073

Epoch 00023: val_mDice did not improve from 0.78272
Epoch 24/300
 - 31s - loss: 0.1048 - acc: 0.9895 - mDice: 0.8210 - val_loss: 0.2654 - val_acc: 0.9886 - val_mDice: 0.6956

Epoch 00024: val_mDice did not improve from 0.78272
Epoch 25/300
 - 31s - loss: 0.0760 - acc: 0.9919 - mDice: 0.8629 - val_loss: 0.1246 - val_acc: 0.9896 - val_mDice: 0.7952

Epoch 00025: val_mDice improved from 0.78272 to 0.79516, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 32s - loss: 0.0732 - acc: 0.9922 - mDice: 0.8684 - val_loss: 0.5636 - val_acc: 0.9849 - val_mDice: 0.5372

Epoch 00026: val_mDice did not improve from 0.79516
Epoch 27/300
 - 32s - loss: 0.0742 - acc: 0.9921 - mDice: 0.8668 - val_loss: 0.1721 - val_acc: 0.9819 - val_mDice: 0.7269

Epoch 00027: val_mDice did not improve from 0.79516
Epoch 28/300
 - 32s - loss: 0.1391 - acc: 0.9862 - mDice: 0.7675 - val_loss: 0.2182 - val_acc: 0.9815 - val_mDice: 0.6781

Epoch 00028: val_mDice did not improve from 0.79516
Epoch 29/300
 - 31s - loss: 0.0982 - acc: 0.9901 - mDice: 0.8271 - val_loss: 0.4044 - val_acc: 0.9867 - val_mDice: 0.6051

Epoch 00029: val_mDice did not improve from 0.79516
Epoch 30/300
 - 31s - loss: 0.0930 - acc: 0.9905 - mDice: 0.8350 - val_loss: 0.1518 - val_acc: 0.9886 - val_mDice: 0.7613

Epoch 00030: val_mDice did not improve from 0.79516
Epoch 31/300
 - 32s - loss: 0.0849 - acc: 0.9912 - mDice: 0.8481 - val_loss: 0.2614 - val_acc: 0.9882 - val_mDice: 0.6750

Epoch 00031: val_mDice did not improve from 0.79516
Epoch 32/300
 - 32s - loss: 0.0815 - acc: 0.9915 - mDice: 0.8546 - val_loss: 0.3884 - val_acc: 0.9858 - val_mDice: 0.5867

Epoch 00032: val_mDice did not improve from 0.79516
Epoch 33/300
 - 31s - loss: 0.0826 - acc: 0.9914 - mDice: 0.8519 - val_loss: 0.1443 - val_acc: 0.9901 - val_mDice: 0.7743

Epoch 00033: val_mDice did not improve from 0.79516
Epoch 34/300
 - 31s - loss: 0.0777 - acc: 0.9919 - mDice: 0.8610 - val_loss: 0.1493 - val_acc: 0.9903 - val_mDice: 0.7707

Epoch 00034: val_mDice did not improve from 0.79516
Epoch 35/300
 - 32s - loss: 0.0763 - acc: 0.9920 - mDice: 0.8632 - val_loss: 0.2287 - val_acc: 0.9722 - val_mDice: 0.6666

Epoch 00035: val_mDice did not improve from 0.79516
Epoch 36/300
 - 31s - loss: 0.0795 - acc: 0.9916 - mDice: 0.8571 - val_loss: 0.2492 - val_acc: 0.9886 - val_mDice: 0.6823

Epoch 00036: val_mDice did not improve from 0.79516
Epoch 37/300
 - 31s - loss: 0.0746 - acc: 0.9921 - mDice: 0.8657 - val_loss: 0.1366 - val_acc: 0.9871 - val_mDice: 0.7791

Epoch 00037: val_mDice did not improve from 0.79516
Epoch 38/300
 - 32s - loss: 0.0745 - acc: 0.9921 - mDice: 0.8663 - val_loss: 3.2380 - val_acc: 0.9771 - val_mDice: 0.2023

Epoch 00038: val_mDice did not improve from 0.79516
Epoch 39/300
 - 31s - loss: 0.0773 - acc: 0.9918 - mDice: 0.8608 - val_loss: 0.1880 - val_acc: 0.9765 - val_mDice: 0.7174

Epoch 00039: val_mDice did not improve from 0.79516
Epoch 40/300
 - 31s - loss: 0.0749 - acc: 0.9921 - mDice: 0.8658 - val_loss: 0.1596 - val_acc: 0.9899 - val_mDice: 0.7622

Epoch 00040: val_mDice did not improve from 0.79516
Epoch 41/300
 - 31s - loss: 0.0722 - acc: 0.9923 - mDice: 0.8701 - val_loss: 0.2268 - val_acc: 0.9770 - val_mDice: 0.6669

Epoch 00041: val_mDice did not improve from 0.79516
Epoch 42/300
 - 31s - loss: 0.0826 - acc: 0.9914 - mDice: 0.8530 - val_loss: 2.1952 - val_acc: 0.9752 - val_mDice: 0.0717

Epoch 00042: val_mDice did not improve from 0.79516
Epoch 43/300
 - 31s - loss: 0.0888 - acc: 0.9911 - mDice: 0.8455 - val_loss: 4.3498 - val_acc: 0.9746 - val_mDice: 0.0294

Epoch 00043: val_mDice did not improve from 0.79516
Epoch 44/300
 - 31s - loss: 0.1773 - acc: 0.9852 - mDice: 0.7295 - val_loss: 0.1894 - val_acc: 0.9836 - val_mDice: 0.7066

Epoch 00044: val_mDice did not improve from 0.79516
Epoch 45/300
 - 31s - loss: 0.0968 - acc: 0.9901 - mDice: 0.8293 - val_loss: 0.3023 - val_acc: 0.9878 - val_mDice: 0.6650

Epoch 00045: val_mDice did not improve from 0.79516
Epoch 46/300
 - 31s - loss: 0.0914 - acc: 0.9906 - mDice: 0.8375 - val_loss: 0.1767 - val_acc: 0.9805 - val_mDice: 0.7312

Epoch 00046: val_mDice did not improve from 0.79516
Epoch 47/300
 - 32s - loss: 0.0806 - acc: 0.9915 - mDice: 0.8551 - val_loss: 0.1590 - val_acc: 0.9846 - val_mDice: 0.7526

Epoch 00047: val_mDice did not improve from 0.79516
Epoch 48/300
 - 32s - loss: 0.0752 - acc: 0.9920 - mDice: 0.8642 - val_loss: 0.1688 - val_acc: 0.9876 - val_mDice: 0.7485

Epoch 00048: val_mDice did not improve from 0.79516
Epoch 49/300
 - 31s - loss: 0.0736 - acc: 0.9922 - mDice: 0.8675 - val_loss: 0.1616 - val_acc: 0.9895 - val_mDice: 0.7606

Epoch 00049: val_mDice did not improve from 0.79516
Epoch 50/300
 - 32s - loss: 0.0724 - acc: 0.9923 - mDice: 0.8700 - val_loss: 0.2372 - val_acc: 0.9894 - val_mDice: 0.7028

Epoch 00050: val_mDice did not improve from 0.79516
Epoch 51/300
 - 33s - loss: 0.0728 - acc: 0.9922 - mDice: 0.8683 - val_loss: 0.1318 - val_acc: 0.9896 - val_mDice: 0.7879

Epoch 00051: val_mDice did not improve from 0.79516
Epoch 52/300
 - 33s - loss: 0.0694 - acc: 0.9926 - mDice: 0.8748 - val_loss: 0.4028 - val_acc: 0.9854 - val_mDice: 0.5522

Epoch 00052: val_mDice did not improve from 0.79516
Epoch 53/300
 - 33s - loss: 0.0805 - acc: 0.9916 - mDice: 0.8565 - val_loss: 1.6250 - val_acc: 0.9763 - val_mDice: 0.1322

Epoch 00053: val_mDice did not improve from 0.79516
Epoch 54/300
 - 33s - loss: 0.1062 - acc: 0.9898 - mDice: 0.8189 - val_loss: 0.5334 - val_acc: 0.9865 - val_mDice: 0.5904

Epoch 00054: val_mDice did not improve from 0.79516
Epoch 55/300
 - 33s - loss: 0.0810 - acc: 0.9915 - mDice: 0.8555 - val_loss: 0.1380 - val_acc: 0.9862 - val_mDice: 0.7779

Epoch 00055: val_mDice did not improve from 0.79516
Epoch 56/300
 - 32s - loss: 0.0737 - acc: 0.9922 - mDice: 0.8673 - val_loss: 0.7022 - val_acc: 0.9830 - val_mDice: 0.4759

Epoch 00056: val_mDice did not improve from 0.79516
Epoch 57/300
 - 33s - loss: 0.0803 - acc: 0.9915 - mDice: 0.8569 - val_loss: 0.1394 - val_acc: 0.9864 - val_mDice: 0.7760

Epoch 00057: val_mDice did not improve from 0.79516
Epoch 58/300
 - 56s - loss: 0.0838 - acc: 0.9913 - mDice: 0.8510 - val_loss: 0.9444 - val_acc: 0.9779 - val_mDice: 0.2485

Epoch 00058: val_mDice did not improve from 0.79516
Epoch 59/300
 - 64s - loss: 0.0794 - acc: 0.9917 - mDice: 0.8576 - val_loss: 0.1307 - val_acc: 0.9901 - val_mDice: 0.7909

Epoch 00059: val_mDice did not improve from 0.79516
Epoch 60/300
 - 64s - loss: 0.0713 - acc: 0.9924 - mDice: 0.8716 - val_loss: 0.2480 - val_acc: 0.9896 - val_mDice: 0.7057

Epoch 00060: val_mDice did not improve from 0.79516
Epoch 61/300
 - 65s - loss: 0.0771 - acc: 0.9920 - mDice: 0.8615 - val_loss: 0.1056 - val_acc: 0.9903 - val_mDice: 0.8199

Epoch 00061: val_mDice improved from 0.79516 to 0.81987, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 67s - loss: 0.0698 - acc: 0.9926 - mDice: 0.8737 - val_loss: 0.1227 - val_acc: 0.9913 - val_mDice: 0.7987

Epoch 00062: val_mDice did not improve from 0.81987
Epoch 63/300
 - 63s - loss: 0.0709 - acc: 0.9924 - mDice: 0.8720 - val_loss: 0.1131 - val_acc: 0.9893 - val_mDice: 0.8109

Epoch 00063: val_mDice did not improve from 0.81987
Epoch 64/300
 - 35s - loss: 0.0750 - acc: 0.9921 - mDice: 0.8645 - val_loss: 0.1267 - val_acc: 0.9865 - val_mDice: 0.7910

Epoch 00064: val_mDice did not improve from 0.81987
Epoch 65/300
 - 31s - loss: 0.0698 - acc: 0.9926 - mDice: 0.8743 - val_loss: 0.1745 - val_acc: 0.9786 - val_mDice: 0.7342

Epoch 00065: val_mDice did not improve from 0.81987
Epoch 66/300
 - 31s - loss: 0.0722 - acc: 0.9924 - mDice: 0.8703 - val_loss: 0.2679 - val_acc: 0.9859 - val_mDice: 0.6217

Epoch 00066: val_mDice did not improve from 0.81987
Epoch 67/300
 - 32s - loss: 0.0841 - acc: 0.9913 - mDice: 0.8515 - val_loss: 0.1254 - val_acc: 0.9897 - val_mDice: 0.7961

Epoch 00067: val_mDice did not improve from 0.81987
Epoch 68/300
 - 31s - loss: 0.0893 - acc: 0.9910 - mDice: 0.8437 - val_loss: 0.1324 - val_acc: 0.9886 - val_mDice: 0.7884

Epoch 00068: val_mDice did not improve from 0.81987
Epoch 69/300
 - 31s - loss: 0.0717 - acc: 0.9924 - mDice: 0.8708 - val_loss: 0.2094 - val_acc: 0.9889 - val_mDice: 0.7082

Epoch 00069: val_mDice did not improve from 0.81987
Epoch 70/300
 - 32s - loss: 0.0708 - acc: 0.9924 - mDice: 0.8717 - val_loss: 0.1152 - val_acc: 0.9908 - val_mDice: 0.8102

Epoch 00070: val_mDice did not improve from 0.81987
Epoch 71/300
 - 32s - loss: 0.0679 - acc: 0.9927 - mDice: 0.8765 - val_loss: 0.1420 - val_acc: 0.9908 - val_mDice: 0.7817

Epoch 00071: val_mDice did not improve from 0.81987
Epoch 72/300
 - 32s - loss: 0.0667 - acc: 0.9928 - mDice: 0.8786 - val_loss: 0.1221 - val_acc: 0.9877 - val_mDice: 0.7997

Epoch 00072: val_mDice did not improve from 0.81987
Epoch 73/300
 - 32s - loss: 0.0654 - acc: 0.9929 - mDice: 0.8808 - val_loss: 0.1084 - val_acc: 0.9898 - val_mDice: 0.8176

Epoch 00073: val_mDice did not improve from 0.81987
Epoch 74/300
 - 31s - loss: 0.0656 - acc: 0.9929 - mDice: 0.8811 - val_loss: 0.1053 - val_acc: 0.9913 - val_mDice: 0.8174

Epoch 00074: val_mDice did not improve from 0.81987
Epoch 75/300
 - 32s - loss: 0.0869 - acc: 0.9911 - mDice: 0.8457 - val_loss: 0.1342 - val_acc: 0.9901 - val_mDice: 0.7872

Epoch 00075: val_mDice did not improve from 0.81987
Epoch 76/300
 - 32s - loss: 0.0701 - acc: 0.9925 - mDice: 0.8729 - val_loss: 0.2053 - val_acc: 0.9897 - val_mDice: 0.7250

Epoch 00076: val_mDice did not improve from 0.81987
Epoch 77/300
 - 31s - loss: 0.0682 - acc: 0.9927 - mDice: 0.8768 - val_loss: 0.2690 - val_acc: 0.9879 - val_mDice: 0.6605

Epoch 00077: val_mDice did not improve from 0.81987
Epoch 78/300
 - 32s - loss: 0.0730 - acc: 0.9923 - mDice: 0.8691 - val_loss: 0.2857 - val_acc: 0.9887 - val_mDice: 0.6747

Epoch 00078: val_mDice did not improve from 0.81987
Epoch 79/300
 - 31s - loss: 0.0683 - acc: 0.9927 - mDice: 0.8768 - val_loss: 0.1166 - val_acc: 0.9900 - val_mDice: 0.8076

Epoch 00079: val_mDice did not improve from 0.81987
Epoch 80/300
 - 31s - loss: 0.0662 - acc: 0.9928 - mDice: 0.8795 - val_loss: 0.1293 - val_acc: 0.9901 - val_mDice: 0.7939

Epoch 00080: val_mDice did not improve from 0.81987
Epoch 81/300
 - 30s - loss: 0.0648 - acc: 0.9930 - mDice: 0.8818 - val_loss: 0.1541 - val_acc: 0.9907 - val_mDice: 0.7712

Epoch 00081: val_mDice did not improve from 0.81987
Epoch 82/300
 - 30s - loss: 0.0638 - acc: 0.9931 - mDice: 0.8835 - val_loss: 0.1158 - val_acc: 0.9904 - val_mDice: 0.8095

Epoch 00082: val_mDice did not improve from 0.81987
Epoch 83/300
 - 30s - loss: 0.0637 - acc: 0.9931 - mDice: 0.8838 - val_loss: 0.1040 - val_acc: 0.9909 - val_mDice: 0.8242

Epoch 00083: val_mDice improved from 0.81987 to 0.82423, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 84/300
 - 30s - loss: 0.0641 - acc: 0.9931 - mDice: 0.8836 - val_loss: 0.1560 - val_acc: 0.9902 - val_mDice: 0.7617

Epoch 00084: val_mDice did not improve from 0.82423
Epoch 85/300
 - 30s - loss: 0.0666 - acc: 0.9928 - mDice: 0.8788 - val_loss: 0.1506 - val_acc: 0.9905 - val_mDice: 0.7734

Epoch 00085: val_mDice did not improve from 0.82423
Epoch 86/300
 - 30s - loss: 0.0626 - acc: 0.9932 - mDice: 0.8857 - val_loss: 0.1301 - val_acc: 0.9882 - val_mDice: 0.7917

Epoch 00086: val_mDice did not improve from 0.82423
Epoch 87/300
 - 31s - loss: 0.0625 - acc: 0.9932 - mDice: 0.8858 - val_loss: 0.1462 - val_acc: 0.9896 - val_mDice: 0.7774

Epoch 00087: val_mDice did not improve from 0.82423
Epoch 88/300
 - 32s - loss: 0.0621 - acc: 0.9933 - mDice: 0.8872 - val_loss: 0.2082 - val_acc: 0.9899 - val_mDice: 0.7279

Epoch 00088: val_mDice did not improve from 0.82423
Epoch 89/300
 - 32s - loss: 0.0615 - acc: 0.9933 - mDice: 0.8875 - val_loss: 0.1363 - val_acc: 0.9854 - val_mDice: 0.7858

Epoch 00089: val_mDice did not improve from 0.82423
Epoch 90/300
 - 32s - loss: 0.0604 - acc: 0.9934 - mDice: 0.8894 - val_loss: 0.1463 - val_acc: 0.9898 - val_mDice: 0.7783

Epoch 00090: val_mDice did not improve from 0.82423
Epoch 91/300
 - 32s - loss: 0.0603 - acc: 0.9934 - mDice: 0.8901 - val_loss: 0.3537 - val_acc: 0.9845 - val_mDice: 0.5566

Epoch 00091: val_mDice did not improve from 0.82423
Epoch 92/300
 - 31s - loss: 0.0636 - acc: 0.9931 - mDice: 0.8844 - val_loss: 0.1396 - val_acc: 0.9895 - val_mDice: 0.7836

Epoch 00092: val_mDice did not improve from 0.82423
Epoch 93/300
 - 31s - loss: 0.0642 - acc: 0.9930 - mDice: 0.8833 - val_loss: 0.1089 - val_acc: 0.9911 - val_mDice: 0.8135

Epoch 00093: val_mDice did not improve from 0.82423
Epoch 94/300
 - 31s - loss: 0.0802 - acc: 0.9915 - mDice: 0.8565 - val_loss: 0.2418 - val_acc: 0.9897 - val_mDice: 0.7128

Epoch 00094: val_mDice did not improve from 0.82423
Epoch 95/300
 - 31s - loss: 0.0646 - acc: 0.9930 - mDice: 0.8821 - val_loss: 0.1454 - val_acc: 0.9855 - val_mDice: 0.7700

Epoch 00095: val_mDice did not improve from 0.82423
Epoch 96/300
 - 31s - loss: 0.0630 - acc: 0.9931 - mDice: 0.8849 - val_loss: 0.1325 - val_acc: 0.9903 - val_mDice: 0.7920

Epoch 00096: val_mDice did not improve from 0.82423
Epoch 97/300
 - 31s - loss: 0.0620 - acc: 0.9932 - mDice: 0.8870 - val_loss: 0.1921 - val_acc: 0.9814 - val_mDice: 0.7132

Epoch 00097: val_mDice did not improve from 0.82423
Epoch 98/300
 - 31s - loss: 0.0700 - acc: 0.9925 - mDice: 0.8730 - val_loss: 0.1657 - val_acc: 0.9900 - val_mDice: 0.7615

Epoch 00098: val_mDice did not improve from 0.82423
Epoch 99/300
 - 31s - loss: 0.0626 - acc: 0.9932 - mDice: 0.8859 - val_loss: 0.1529 - val_acc: 0.9833 - val_mDice: 0.7605

Epoch 00099: val_mDice did not improve from 0.82423
Epoch 100/300
 - 31s - loss: 0.0669 - acc: 0.9928 - mDice: 0.8793 - val_loss: 2.7815 - val_acc: 0.9767 - val_mDice: 0.1761

Epoch 00100: val_mDice did not improve from 0.82423
Epoch 101/300
 - 31s - loss: 0.0666 - acc: 0.9928 - mDice: 0.8790 - val_loss: 0.1328 - val_acc: 0.9894 - val_mDice: 0.7888

Epoch 00101: val_mDice did not improve from 0.82423
Epoch 102/300
 - 32s - loss: 0.0616 - acc: 0.9932 - mDice: 0.8872 - val_loss: 0.1480 - val_acc: 0.9903 - val_mDice: 0.7772

Epoch 00102: val_mDice did not improve from 0.82423
Epoch 103/300
 - 33s - loss: 0.0604 - acc: 0.9934 - mDice: 0.8901 - val_loss: 0.1446 - val_acc: 0.9881 - val_mDice: 0.7745

Epoch 00103: val_mDice did not improve from 0.82423
Epoch 104/300
 - 34s - loss: 0.0610 - acc: 0.9933 - mDice: 0.8884 - val_loss: 0.1424 - val_acc: 0.9908 - val_mDice: 0.7825

Epoch 00104: val_mDice did not improve from 0.82423
Epoch 105/300
 - 33s - loss: 0.0597 - acc: 0.9934 - mDice: 0.8908 - val_loss: 0.1404 - val_acc: 0.9868 - val_mDice: 0.7788

Epoch 00105: val_mDice did not improve from 0.82423
Epoch 106/300
 - 33s - loss: 0.0640 - acc: 0.9931 - mDice: 0.8833 - val_loss: 0.1830 - val_acc: 0.9901 - val_mDice: 0.7495

Epoch 00106: val_mDice did not improve from 0.82423
Epoch 107/300
 - 33s - loss: 0.0606 - acc: 0.9934 - mDice: 0.8898 - val_loss: 0.1261 - val_acc: 0.9906 - val_mDice: 0.7955

Epoch 00107: val_mDice did not improve from 0.82423
Epoch 108/300
 - 33s - loss: 0.0842 - acc: 0.9914 - mDice: 0.8517 - val_loss: 0.3500 - val_acc: 0.9875 - val_mDice: 0.6281

Epoch 00108: val_mDice did not improve from 0.82423
Epoch 109/300
 - 33s - loss: 0.0673 - acc: 0.9927 - mDice: 0.8776 - val_loss: 0.1329 - val_acc: 0.9907 - val_mDice: 0.7917

Epoch 00109: val_mDice did not improve from 0.82423
Epoch 110/300
 - 33s - loss: 0.0632 - acc: 0.9931 - mDice: 0.8846 - val_loss: 0.1486 - val_acc: 0.9906 - val_mDice: 0.7770

Epoch 00110: val_mDice did not improve from 0.82423
Epoch 111/300
 - 33s - loss: 0.0615 - acc: 0.9933 - mDice: 0.8875 - val_loss: 0.1652 - val_acc: 0.9904 - val_mDice: 0.7617

Epoch 00111: val_mDice did not improve from 0.82423
Epoch 112/300
 - 33s - loss: 0.0614 - acc: 0.9933 - mDice: 0.8885 - val_loss: 0.1671 - val_acc: 0.9902 - val_mDice: 0.7511

Epoch 00112: val_mDice did not improve from 0.82423
Epoch 113/300
 - 33s - loss: 0.0749 - acc: 0.9922 - mDice: 0.8658 - val_loss: 0.1753 - val_acc: 0.9808 - val_mDice: 0.7357

Epoch 00113: val_mDice did not improve from 0.82423
Epoch 114/300
 - 33s - loss: 0.0840 - acc: 0.9914 - mDice: 0.8512 - val_loss: 0.2338 - val_acc: 0.9894 - val_mDice: 0.7091

Epoch 00114: val_mDice did not improve from 0.82423
Epoch 115/300
 - 31s - loss: 0.0676 - acc: 0.9928 - mDice: 0.8778 - val_loss: 0.1534 - val_acc: 0.9907 - val_mDice: 0.7708

Epoch 00115: val_mDice did not improve from 0.82423
Epoch 116/300
 - 31s - loss: 0.0636 - acc: 0.9931 - mDice: 0.8842 - val_loss: 0.1158 - val_acc: 0.9886 - val_mDice: 0.8085

Epoch 00116: val_mDice did not improve from 0.82423
Epoch 117/300
 - 31s - loss: 0.0671 - acc: 0.9927 - mDice: 0.8781 - val_loss: 0.1327 - val_acc: 0.9911 - val_mDice: 0.7880

Epoch 00117: val_mDice did not improve from 0.82423
Epoch 118/300
 - 31s - loss: 0.0617 - acc: 0.9932 - mDice: 0.8872 - val_loss: 0.0987 - val_acc: 0.9908 - val_mDice: 0.8304

Epoch 00118: val_mDice improved from 0.82423 to 0.83038, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 119/300
 - 31s - loss: 0.0610 - acc: 0.9933 - mDice: 0.8886 - val_loss: 0.1303 - val_acc: 0.9856 - val_mDice: 0.7915

Epoch 00119: val_mDice did not improve from 0.83038
Epoch 120/300
 - 31s - loss: 0.0650 - acc: 0.9930 - mDice: 0.8814 - val_loss: 0.1006 - val_acc: 0.9910 - val_mDice: 0.8283

Epoch 00120: val_mDice did not improve from 0.83038
Epoch 121/300
 - 31s - loss: 0.0620 - acc: 0.9933 - mDice: 0.8874 - val_loss: 4.8774 - val_acc: 0.9746 - val_mDice: 0.0262

Epoch 00121: val_mDice did not improve from 0.83038
Epoch 122/300
 - 31s - loss: 0.1193 - acc: 0.9890 - mDice: 0.8028 - val_loss: 0.3647 - val_acc: 0.9832 - val_mDice: 0.5254

Epoch 00122: val_mDice did not improve from 0.83038
Epoch 123/300
 - 31s - loss: 0.0771 - acc: 0.9919 - mDice: 0.8610 - val_loss: 0.1013 - val_acc: 0.9911 - val_mDice: 0.8268

Epoch 00123: val_mDice did not improve from 0.83038
Epoch 124/300
 - 30s - loss: 0.0699 - acc: 0.9925 - mDice: 0.8730 - val_loss: 0.1017 - val_acc: 0.9905 - val_mDice: 0.8266

Epoch 00124: val_mDice did not improve from 0.83038
Epoch 125/300
 - 31s - loss: 0.0668 - acc: 0.9928 - mDice: 0.8788 - val_loss: 0.1048 - val_acc: 0.9916 - val_mDice: 0.8227

Epoch 00125: val_mDice did not improve from 0.83038
Epoch 126/300
 - 31s - loss: 0.0712 - acc: 0.9925 - mDice: 0.8720 - val_loss: 0.1365 - val_acc: 0.9871 - val_mDice: 0.7822

Epoch 00126: val_mDice did not improve from 0.83038
Epoch 127/300
 - 31s - loss: 0.0657 - acc: 0.9929 - mDice: 0.8802 - val_loss: 0.1256 - val_acc: 0.9902 - val_mDice: 0.7987

Epoch 00127: val_mDice did not improve from 0.83038
Epoch 128/300
 - 31s - loss: 0.0630 - acc: 0.9931 - mDice: 0.8849 - val_loss: 0.7968 - val_acc: 0.9794 - val_mDice: 0.3247

Epoch 00128: val_mDice did not improve from 0.83038
Epoch 129/300
 - 31s - loss: 0.0693 - acc: 0.9926 - mDice: 0.8748 - val_loss: 0.1550 - val_acc: 0.9888 - val_mDice: 0.7665

Epoch 00129: val_mDice did not improve from 0.83038
Epoch 130/300
 - 31s - loss: 0.0648 - acc: 0.9929 - mDice: 0.8819 - val_loss: 0.1307 - val_acc: 0.9890 - val_mDice: 0.7906

Epoch 00130: val_mDice did not improve from 0.83038
Epoch 131/300
 - 31s - loss: 0.0611 - acc: 0.9933 - mDice: 0.8884 - val_loss: 0.4715 - val_acc: 0.9849 - val_mDice: 0.5352

Epoch 00131: val_mDice did not improve from 0.83038
Epoch 132/300
 - 31s - loss: 0.0642 - acc: 0.9930 - mDice: 0.8829 - val_loss: 0.1419 - val_acc: 0.9892 - val_mDice: 0.7799

Epoch 00132: val_mDice did not improve from 0.83038
Epoch 133/300
 - 30s - loss: 0.0608 - acc: 0.9933 - mDice: 0.8890 - val_loss: 0.1476 - val_acc: 0.9883 - val_mDice: 0.7727

Epoch 00133: val_mDice did not improve from 0.83038
Epoch 134/300
 - 30s - loss: 0.0614 - acc: 0.9933 - mDice: 0.8878 - val_loss: 0.1638 - val_acc: 0.9905 - val_mDice: 0.7672

Epoch 00134: val_mDice did not improve from 0.83038
Epoch 135/300
 - 30s - loss: 0.0597 - acc: 0.9934 - mDice: 0.8910 - val_loss: 0.2383 - val_acc: 0.9677 - val_mDice: 0.6603

Epoch 00135: val_mDice did not improve from 0.83038
Epoch 136/300
 - 30s - loss: 0.0659 - acc: 0.9929 - mDice: 0.8801 - val_loss: 0.1896 - val_acc: 0.9902 - val_mDice: 0.7469

Epoch 00136: val_mDice did not improve from 0.83038
Epoch 137/300
 - 30s - loss: 0.0609 - acc: 0.9934 - mDice: 0.8896 - val_loss: 0.1724 - val_acc: 0.9841 - val_mDice: 0.7425

Epoch 00137: val_mDice did not improve from 0.83038
Epoch 138/300
 - 29s - loss: 0.0596 - acc: 0.9934 - mDice: 0.8908 - val_loss: 0.1983 - val_acc: 0.9903 - val_mDice: 0.7429

Epoch 00138: val_mDice did not improve from 0.83038
Epoch 139/300
 - 30s - loss: 0.0590 - acc: 0.9935 - mDice: 0.8919 - val_loss: 0.1267 - val_acc: 0.9908 - val_mDice: 0.7962

Epoch 00139: val_mDice did not improve from 0.83038
Epoch 140/300
 - 29s - loss: 0.0647 - acc: 0.9930 - mDice: 0.8832 - val_loss: 0.4657 - val_acc: 0.9868 - val_mDice: 0.6087

Epoch 00140: val_mDice did not improve from 0.83038
Epoch 141/300
 - 30s - loss: 0.0640 - acc: 0.9931 - mDice: 0.8843 - val_loss: 0.1833 - val_acc: 0.9904 - val_mDice: 0.7494

Epoch 00141: val_mDice did not improve from 0.83038
Epoch 142/300
 - 30s - loss: 0.0592 - acc: 0.9935 - mDice: 0.8926 - val_loss: 0.4364 - val_acc: 0.9856 - val_mDice: 0.5694

Epoch 00142: val_mDice did not improve from 0.83038
Epoch 143/300
 - 29s - loss: 0.0586 - acc: 0.9935 - mDice: 0.8931 - val_loss: 0.1131 - val_acc: 0.9915 - val_mDice: 0.8140

Epoch 00143: val_mDice did not improve from 0.83038
Epoch 144/300
 - 29s - loss: 0.0771 - acc: 0.9919 - mDice: 0.8614 - val_loss: 0.1858 - val_acc: 0.9902 - val_mDice: 0.7459

Epoch 00144: val_mDice did not improve from 0.83038
Epoch 145/300
 - 29s - loss: 0.0641 - acc: 0.9930 - mDice: 0.8832 - val_loss: 0.1970 - val_acc: 0.9898 - val_mDice: 0.7317

Epoch 00145: val_mDice did not improve from 0.83038
Epoch 146/300
 - 30s - loss: 0.0657 - acc: 0.9929 - mDice: 0.8803 - val_loss: 0.1641 - val_acc: 0.9902 - val_mDice: 0.7657

Epoch 00146: val_mDice did not improve from 0.83038
Epoch 147/300
 - 29s - loss: 0.0615 - acc: 0.9933 - mDice: 0.8882 - val_loss: 0.1421 - val_acc: 0.9899 - val_mDice: 0.7809

Epoch 00147: val_mDice did not improve from 0.83038
Epoch 148/300
 - 30s - loss: 0.0595 - acc: 0.9934 - mDice: 0.8912 - val_loss: 0.5717 - val_acc: 0.9854 - val_mDice: 0.5567

Epoch 00148: val_mDice did not improve from 0.83038
Epoch 149/300
 - 29s - loss: 0.0655 - acc: 0.9929 - mDice: 0.8808 - val_loss: 0.1604 - val_acc: 0.9904 - val_mDice: 0.7692

Epoch 00149: val_mDice did not improve from 0.83038
Epoch 150/300
 - 29s - loss: 0.0640 - acc: 0.9930 - mDice: 0.8842 - val_loss: 0.1611 - val_acc: 0.9896 - val_mDice: 0.7662

Epoch 00150: val_mDice did not improve from 0.83038
Epoch 151/300
 - 29s - loss: 0.0687 - acc: 0.9927 - mDice: 0.8757 - val_loss: 0.2030 - val_acc: 0.9902 - val_mDice: 0.7371

Epoch 00151: val_mDice did not improve from 0.83038
Epoch 152/300
 - 29s - loss: 0.0645 - acc: 0.9930 - mDice: 0.8827 - val_loss: 0.1234 - val_acc: 0.9891 - val_mDice: 0.7980

Epoch 00152: val_mDice did not improve from 0.83038
Epoch 153/300
 - 29s - loss: 0.0682 - acc: 0.9927 - mDice: 0.8761 - val_loss: 0.1645 - val_acc: 0.9908 - val_mDice: 0.7668

Epoch 00153: val_mDice did not improve from 0.83038
Epoch 154/300
 - 29s - loss: 0.0624 - acc: 0.9932 - mDice: 0.8860 - val_loss: 0.1320 - val_acc: 0.9910 - val_mDice: 0.7960

Epoch 00154: val_mDice did not improve from 0.83038
Epoch 155/300
 - 30s - loss: 0.0611 - acc: 0.9933 - mDice: 0.8882 - val_loss: 0.1310 - val_acc: 0.9893 - val_mDice: 0.7911

Epoch 00155: val_mDice did not improve from 0.83038
Epoch 156/300
 - 29s - loss: 0.0604 - acc: 0.9934 - mDice: 0.8895 - val_loss: 0.1352 - val_acc: 0.9902 - val_mDice: 0.7905

Epoch 00156: val_mDice did not improve from 0.83038
Epoch 157/300
 - 29s - loss: 0.0601 - acc: 0.9934 - mDice: 0.8904 - val_loss: 0.3804 - val_acc: 0.9370 - val_mDice: 0.5146

Epoch 00157: val_mDice did not improve from 0.83038
Epoch 158/300
 - 29s - loss: 0.0815 - acc: 0.9914 - mDice: 0.8541 - val_loss: 0.2520 - val_acc: 0.9893 - val_mDice: 0.7116

Epoch 00158: val_mDice did not improve from 0.83038
Restoring model weights from the end of the best epoch
Epoch 00158: early stopping
{'val_loss': [1.0665962880438153, 5.418738021506919, 0.21592074323881855, 0.19815725750393337, 0.1753863716895158, 0.13320941598834218, 0.27823286241776235, 7.488400742814347, 3.208786661560471, 0.22558141166383439, 0.19184673799050822, 0.18261139663132103, 0.3235408090077363, 0.379964411929921, 0.34825495042063453, 0.5181596014234755, 0.3858466765007099, 0.1341496781857164, 0.3842432421069961, 0.23630453561161374, 0.4376394167408213, 0.2650798442395958, 2.9763250236396677, 0.26535845885763654, 0.12459414772264234, 0.5635746520560783, 0.17210189752034596, 0.21815537775422003, 0.4044008926675842, 0.15179735167069477, 0.2613593254450921, 0.3883952037976669, 0.14427855243911972, 0.1492643730194719, 0.22872145764820567, 0.24915241268840996, 0.13658931605271749, 3.238036088399343, 0.18803673951296476, 0.15959707508842508, 0.22681128280656832, 2.1952322961331845, 4.349796264379232, 0.18936548536425238, 0.3023460877908243, 0.17670750394239798, 0.15900477556673973, 0.168780853306209, 0.16157921804143144, 0.2371501340432926, 0.13184718056036546, 0.4028210522265764, 1.6250119538636536, 0.5333712784735648, 0.1380060815864855, 0.7022220067254774, 0.13941104032166368, 0.9443978602821762, 0.13072517037660153, 0.2479971203807596, 0.10558147160140602, 0.12274458277243394, 0.11308103670050074, 0.12673745449777837, 0.17449869591373582, 0.26792474462463334, 0.12544147419678914, 0.13243672824478722, 0.20942609754947572, 0.11516904282766778, 0.1420086395588365, 0.12207623179610427, 0.10836767991473367, 0.10531828988779772, 0.134154188002015, 0.20534369801436816, 0.26901543507346876, 0.2856783682519609, 0.11658938141824964, 0.12928820741516692, 0.15410149920810093, 0.11576768581394677, 0.1040147209355423, 0.15595182566134422, 0.15055482698095454, 0.13014360969220554, 0.14620510316467858, 0.2082324913135162, 0.1363475710019335, 0.14633634127117134, 0.3537326107422511, 0.13958558807143936, 0.10888027435576951, 0.2418219212207708, 0.1454111852266409, 0.1324786468892842, 0.19212581253087557, 0.16572358000564863, 0.15289040551976757, 2.781486279971607, 0.13278770012719496, 0.14804273192678485, 0.14458598988550203, 0.14235568059994294, 0.14044348929110947, 0.1830064456563096, 0.12610311607072303, 0.3500447694335256, 0.13287586678524274, 0.1486037620553025, 0.1652318179920629, 0.16708076716185333, 0.1752522750659748, 0.23377167896644488, 0.1533956709387782, 0.11578899628675736, 0.1326674943168958, 0.09874375325602454, 0.13029530566107403, 0.10060800379282003, 4.877398168718493, 0.36473113857769035, 0.101297769617211, 0.10167149009110334, 0.10481849350818284, 0.13648424572772808, 0.12564424022629456, 0.7967893040931977, 0.15496647830034518, 0.13065014587150323, 0.4715464259232129, 0.14189290033804403, 0.1475798114686757, 0.16384016268246165, 0.23834048131027738, 0.1895823666417563, 0.17236404129871735, 0.1983257433897382, 0.12673856738630357, 0.4656549774043195, 0.1832574467445995, 0.43639074055640187, 0.11308701202139124, 0.18584681414179616, 0.19704239050278793, 0.16408626278778454, 0.14213031617639302, 0.5717187389597163, 0.16043315165572697, 0.16105167997312975, 0.2030062692256661, 0.12335176705508619, 0.16452969149784283, 0.13203608244657516, 0.13103936153936674, 0.13517654521597755, 0.38036226044904003, 0.2520329200469696], 'val_acc': [0.97780252559049, 0.9742031208387725, 0.9889376936732112, 0.989295815025364, 0.98122093215719, 0.9882591019521605, 0.988599705266523, 0.9742028791983206, 0.974473274863876, 0.9882658066692295, 0.9888322256706856, 0.9812412995833892, 0.989011280350499, 0.9884712314820504, 0.9878597461783493, 0.9840132338148696, 0.9883166302789796, 0.9880527093245819, 0.9875553289691249, 0.9897023469836146, 0.9873947239852883, 0.9867741338483564, 0.9743133978442745, 0.9886188789888903, 0.9896021422681149, 0.9848963015072338, 0.9818834653487792, 0.9814685488248373, 0.9867285858761441, 0.9885592048948592, 0.9882224164567552, 0.9858376100972608, 0.9901390875781979, 0.9903171894786594, 0.9721932208931839, 0.9885620743304759, 0.9871221825525209, 0.9770637589531976, 0.9764863000259744, 0.9899070508129246, 0.9769779295176715, 0.9751748829274565, 0.9746115826987647, 0.983594221932752, 0.9878264382794812, 0.9805049187428242, 0.9846225549150873, 0.9875766631361242, 0.9895125015361889, 0.9893816122421631, 0.9896270749089238, 0.9853893579305472, 0.9762540380875986, 0.9865289203397505, 0.9862254505400901, 0.9829983201112833, 0.9863956450700044, 0.9779333960902583, 0.9900997692758257, 0.9896009582299012, 0.9902999186301017, 0.9912839075466534, 0.9892811925561579, 0.9864641941703476, 0.9786218241886334, 0.9859277366159914, 0.9897430961554473, 0.9886217695456725, 0.9888530727979299, 0.9907723792322405, 0.9907544047624858, 0.9876919608932357, 0.9898262684409683, 0.991302130816577, 0.9900786724534478, 0.9897265632947286, 0.9878863597417379, 0.9886663488081625, 0.9900309835468326, 0.9901299804180592, 0.99069999270253, 0.9903648735524656, 0.990917156408499, 0.9902196252668226, 0.990501034367192, 0.9881651233266424, 0.9895848826961117, 0.9898886023698984, 0.9853797809139744, 0.9897814448531326, 0.9845206834174491, 0.9894554441397613, 0.9911048566256916, 0.9897325489972089, 0.9855039402529284, 0.9902531867986685, 0.9814026250137581, 0.9900434520151522, 0.9833096988924273, 0.9766862088137561, 0.9894190153202137, 0.9902821938554804, 0.98806613343614, 0.9907603951187821, 0.9868340436760727, 0.990115842840693, 0.9906189654682491, 0.9875246309661292, 0.9906892067677265, 0.9905504126090545, 0.9904195464051163, 0.9901721690510128, 0.9808287749419341, 0.9894278894315611, 0.9906580226199405, 0.9886268092705323, 0.9911139496453889, 0.990760882695516, 0.9856113250907119, 0.9910343769076351, 0.9745593346632995, 0.9832107025581796, 0.9911434469638286, 0.990520703541982, 0.9916355565145567, 0.9871293664336562, 0.9901704750619493, 0.9793977354381893, 0.9887914768568389, 0.9889875566279208, 0.9849109066141261, 0.9892095109005948, 0.9883206980722444, 0.9904904906098191, 0.9676513240502045, 0.9902193771826254, 0.9840846571836386, 0.9902848187867586, 0.9908382965995742, 0.9868486761688828, 0.9903967693761304, 0.9856319397061437, 0.9914917315806713, 0.9901539595635446, 0.9897562832803698, 0.9902349594119075, 0.9899303175665595, 0.9854140584175293, 0.9903814330831304, 0.9896182163699612, 0.9902145939546304, 0.989117236824723, 0.9907783774642257, 0.9910463579782136, 0.9893219494246863, 0.9901954121775813, 0.936996618548671, 0.9893274420016521], 'val_mDice': [0.3492160260155741, 0.00034752173176159587, 0.7149347432919809, 0.725145097072418, 0.7329238255818685, 0.7827216818167999, 0.6786317020744175, 6.28261047473109e-07, 0.022069022486969694, 0.7086119916703966, 0.7329456483995592, 0.7144530856752539, 0.6767219609326428, 0.6537999150765551, 0.6405426624479953, 0.5179322139994876, 0.6490535071796483, 0.7824378691994034, 0.6286049263926597, 0.7138501837983862, 0.6219254337900035, 0.6320182775949931, 0.0072933475853419584, 0.6956353508405857, 0.7951644059416052, 0.5372484069172148, 0.7269093643974613, 0.6781343199290313, 0.6050952698912349, 0.7613173295427729, 0.6750428944199651, 0.586697414785892, 0.7743240462409126, 0.7706633815178284, 0.6665972586687621, 0.6822585750807513, 0.7791020625883395, 0.2022687919087322, 0.7173873172686981, 0.7622202314414062, 0.6668867093843741, 0.07166500645802193, 0.02940885901657713, 0.7066468073799087, 0.6649824365212753, 0.7312184487198208, 0.7526188968001185, 0.7485439587641765, 0.7605908599880723, 0.702847306703304, 0.7879397310652174, 0.5521551397022184, 0.13215173421752383, 0.5904316181714112, 0.7779089924809452, 0.4759331460127624, 0.7759627682847662, 0.2485347210650553, 0.7908659752782758, 0.7056537534560527, 0.81987436361857, 0.7987202536594402, 0.8109332931650294, 0.7909982020074541, 0.7342472653668206, 0.6217002224277806, 0.7961474601570908, 0.788405767969183, 0.7081913880041769, 0.810195618921572, 0.7816769779623449, 0.7996707651708219, 0.8175946210955715, 0.8174337069909494, 0.7871969079112148, 0.7249620440485958, 0.6605487335193623, 0.6746562305871431, 0.8076016584316174, 0.7938780634252874, 0.7712304311113672, 0.8094604393025419, 0.8242278140228432, 0.7616840080097989, 0.773383115504955, 0.7916813491879999, 0.7773957932675565, 0.7278611591986349, 0.7857589399492418, 0.7782947712832385, 0.5565848326360857, 0.7836152827059543, 0.8135033602471108, 0.7128172717294894, 0.7700268794466425, 0.7920390569769943, 0.7131708644710861, 0.7615468416128073, 0.7604834210944247, 0.1760795414091197, 0.7887800939090259, 0.7772307741391408, 0.774456317628826, 0.7825424749929983, 0.7788092774134856, 0.7494519166760258, 0.7954947889388144, 0.6281472223925519, 0.7916980342822032, 0.7770004923995193, 0.7616687272941028, 0.7510529982972074, 0.7357207108009327, 0.7090915990126384, 0.7708108663200974, 0.808464037405478, 0.7880133766311783, 0.8303772959265265, 0.7915396992866699, 0.8282859230542684, 0.02624199006361006, 0.5253664920100937, 0.8268104868608194, 0.8265861648697037, 0.8226909381491286, 0.7822407941381495, 0.7987135550281307, 0.3246683540052032, 0.7664897307619318, 0.7906459985194622, 0.5351666171361018, 0.7798528832358282, 0.7727093856792908, 0.7672139606676303, 0.6602878372321974, 0.7468763262301952, 0.7425031473149767, 0.7428836108327986, 0.7962216572002606, 0.6087482347077614, 0.7494090858164493, 0.5694392643667556, 0.8140291897384254, 0.7458552700263243, 0.7316973694451936, 0.7656903214998789, 0.7809284903981664, 0.5566700753383897, 0.7692078750233751, 0.7662442789242432, 0.7371015787661612, 0.7979893985095324, 0.7667649144882912, 0.7960195929796489, 0.7911192803411512, 0.7904986305995746, 0.5145897740447843, 0.7116460500357745], 'loss': [0.4037837192683922, 0.11753217068034712, 0.10984217799581744, 0.10147819257518177, 0.0912356539221122, 0.08720731673594634, 0.08280475297011494, 0.08446619545947588, 0.14671088986533473, 0.10563714881827586, 0.08953006435442286, 0.09342439368515724, 0.0881546085399905, 0.08002924616157377, 0.0787246952904882, 0.08098146115232745, 0.07677583418146526, 0.07424564727758061, 0.07265801562403022, 0.07222815320197533, 0.07175499407981216, 0.0705012894628101, 0.07888724270487397, 0.10481016153629209, 0.07601500782387408, 0.07320091113496391, 0.0742094085480431, 0.13910704393642953, 0.09822792681618181, 0.0929547643522998, 0.08489833038949972, 0.08148118035334359, 0.08258511605851991, 0.07770177360919005, 0.07626389173984634, 0.07945943493652659, 0.0746285635813608, 0.07453399948748805, 0.07729385686116735, 0.07491264079229906, 0.07219130095395049, 0.08264433393036931, 0.08876055441586285, 0.17727234380338755, 0.09682855305009612, 0.09137348646788694, 0.0806295097562012, 0.07522753578758597, 0.07360302606512044, 0.07237266298163755, 0.07278389935805361, 0.06938537897338838, 0.08050190819671332, 0.10618565690677496, 0.08101573119637823, 0.07370922029771454, 0.08031709480144494, 0.08375418714222987, 0.07936910697618565, 0.07134679355813801, 0.07706549970012007, 0.06984620996098179, 0.07091594010243363, 0.07501689194365234, 0.06979419079814803, 0.0722385263717914, 0.08408542858457635, 0.08926492308994738, 0.07169969468924758, 0.07079443995920139, 0.06789887984055094, 0.06671786339082353, 0.06539332248569935, 0.06556341640684811, 0.08689545045346807, 0.0700503100173548, 0.06824932782199752, 0.07301284307671323, 0.06832759650086503, 0.06617069353700313, 0.06478335468699142, 0.0638315760748181, 0.06366253439503755, 0.06413600595933916, 0.06664375177974301, 0.0625512603147432, 0.062491734711824995, 0.06214947930455745, 0.06149582010637381, 0.06038463020945691, 0.06025508667607435, 0.06362251554619403, 0.06422484991312194, 0.08017480079540865, 0.06461083039979118, 0.06303077619247274, 0.061982795937645135, 0.07003507546692166, 0.0625843835223456, 0.06688945553286266, 0.06661706072161307, 0.06164744135996825, 0.060427121492153, 0.06096769227435737, 0.059743139071885644, 0.06396969179326895, 0.06059707856736072, 0.08422167589220424, 0.0673270397388241, 0.06320360839332856, 0.06149466565709804, 0.061423551072927365, 0.07485085131762391, 0.08401481465236489, 0.06760072208286792, 0.06355184843677028, 0.0670580674400614, 0.06166738051710398, 0.06100254361127779, 0.06504306819143996, 0.062030542740976385, 0.11928621748984182, 0.07711076490620296, 0.06994541554140761, 0.06684701409209577, 0.07118740070188592, 0.06574707938819739, 0.06302501175286059, 0.0693009164945662, 0.06479357712812313, 0.06105634302532822, 0.06422583016043473, 0.06077870233979545, 0.06136832443065291, 0.05974107325544403, 0.06588027470746151, 0.06085438882036517, 0.059574749162519376, 0.058955135478227, 0.06465683583437197, 0.06397787754007479, 0.059183029118178195, 0.05857980090248025, 0.07713873921248748, 0.06405214843445525, 0.06570723550903268, 0.06153282091001671, 0.05950216553775585, 0.06546927866205535, 0.0639632736017504, 0.06874464522605168, 0.06446783816399676, 0.06815245421322465, 0.062366858642692834, 0.06107560681294702, 0.060355445376109124, 0.06009749393184316, 0.08153989726269437], 'acc': [0.9323485822732407, 0.9843668727736709, 0.9856285513881562, 0.9877136491282116, 0.9894198958559359, 0.990133039440914, 0.9908184134258587, 0.9909059037163813, 0.9873050539752853, 0.9893053190934151, 0.9907049244831089, 0.9904075279689033, 0.9908800265250316, 0.9915575158875312, 0.9917306427947756, 0.9914914394861463, 0.991832873649608, 0.9920446360446515, 0.9922191425547752, 0.9922527873276166, 0.9923091960796424, 0.992452848980097, 0.9917830178173191, 0.9895203553088604, 0.9918807485347158, 0.9922019992167742, 0.9921153530220207, 0.9862204050005114, 0.990066937076259, 0.9905450861799582, 0.9911760199857843, 0.9914961715674265, 0.9913507536565468, 0.9918579005466992, 0.9919552268675264, 0.9916113511425118, 0.9920810535138588, 0.9920997796615081, 0.9918492278154522, 0.9920941956398502, 0.9923489070924061, 0.9913851413512773, 0.9911129059590852, 0.9851930279420237, 0.9901472667680227, 0.9905782597843453, 0.991547918366626, 0.9920040259027654, 0.9922033187192808, 0.9923339777012173, 0.9922485298583957, 0.9925969549833226, 0.9916021667104412, 0.9898136628937263, 0.9915249266364704, 0.9921643244305169, 0.9915366880129757, 0.9912733623704625, 0.9917193318380567, 0.9924448996822037, 0.9919571484408979, 0.99255591608609, 0.9924212030119899, 0.9921203379131228, 0.9925741094133981, 0.9923936891583032, 0.9913261350423795, 0.9909612700361107, 0.9923951597404771, 0.9924175381569641, 0.9926865207044732, 0.992806263101963, 0.9928935558052262, 0.9929176645917398, 0.9910788057145751, 0.9924659237173821, 0.9926911991941733, 0.9922956650760104, 0.9926951667231821, 0.9928389163019089, 0.9929715591183572, 0.9930608751516359, 0.9930833054795264, 0.9930666858117154, 0.992808840803234, 0.9931750813670919, 0.993176723512708, 0.9932783708921441, 0.9932617251551058, 0.9933632721137141, 0.9933889839930895, 0.9930844561394173, 0.9930456291114812, 0.9915408996027785, 0.9929646910444062, 0.9931331633514892, 0.9932246135231896, 0.9924809102043032, 0.9931777297833648, 0.9928128384089184, 0.9928231359239563, 0.9932443068357628, 0.9934075348915036, 0.9933321189330908, 0.9934416431509103, 0.9930516901065278, 0.993404280306097, 0.9914331378940401, 0.9927374670811437, 0.9930954175247902, 0.9932518516311297, 0.9933196339529436, 0.9921575099746354, 0.9914473328891008, 0.9927789516300938, 0.9930922924227263, 0.9927240215243328, 0.9932241536088916, 0.9933357174741179, 0.9929745071282895, 0.9932894901838479, 0.9889964529782445, 0.9919234939805516, 0.9925393851005754, 0.9928228365535638, 0.9924733191170425, 0.992888098788272, 0.993116337392801, 0.9926117480985627, 0.9928840581564424, 0.9932949241854094, 0.9930049281568044, 0.9933214995469164, 0.9932764616249312, 0.9934397599529247, 0.9928524631234201, 0.9933620896666975, 0.9934405179169358, 0.9934779312881422, 0.9929894173109722, 0.9930857842509372, 0.9935259934713194, 0.9935463577419998, 0.9918697264283644, 0.9930216835669946, 0.9928774812298573, 0.9933138105098985, 0.9934217226512091, 0.992880926958062, 0.9930432919214418, 0.9926727560995253, 0.9929990458356774, 0.9926637375886823, 0.9931680740276887, 0.9933039738854774, 0.9933740047945022, 0.9934375981332143, 0.9914322277605174], 'mDice': [0.5858179034316254, 0.8042399413729008, 0.8152140192694607, 0.8243041139626517, 0.8413797215456947, 0.8466676991974753, 0.8536889709555439, 0.8516304065792017, 0.7768133532559333, 0.8160719255494069, 0.8417251773349539, 0.8354523082673744, 0.8432287726998065, 0.8564800867564519, 0.8596102806600144, 0.8549082171848089, 0.8617634411600157, 0.8658871033533619, 0.8685539927598249, 0.869309425751343, 0.870087081500821, 0.8731433145054317, 0.8592966240357992, 0.8209516460135221, 0.8628918215869896, 0.8684051554510763, 0.8668112765080025, 0.7675160449365988, 0.8270794043850652, 0.8350162861551695, 0.8480838604763828, 0.8545849084642212, 0.851924791494087, 0.861004592842412, 0.8631729945690849, 0.8571168309688174, 0.8657081048758505, 0.8663332709796987, 0.8607730929847445, 0.8658237532504921, 0.8700608170287555, 0.8530425869103924, 0.8455373940449065, 0.72954714804761, 0.8292967095236863, 0.8375499586394216, 0.855135775647022, 0.8641634998105986, 0.8675346150639534, 0.8699941889428842, 0.8682955822621623, 0.8748458291710646, 0.8564977089675008, 0.8189118809680637, 0.8554525147950016, 0.8673358681421266, 0.8569078900368885, 0.8510496476575856, 0.8575806911502836, 0.8715857489435539, 0.861501101175722, 0.8737047250956083, 0.8719907734978503, 0.864457612601199, 0.8742969726034289, 0.8703021231276649, 0.8515224709343391, 0.8436662824515214, 0.87083746203089, 0.8716945037435906, 0.876498580209778, 0.8785502434639649, 0.8807968614775146, 0.8811263735427091, 0.8456947426857717, 0.8728905592515093, 0.8768152879553064, 0.8690942273004632, 0.8767759725787315, 0.8794783263855545, 0.8818318165186421, 0.8834703934661139, 0.883781589104572, 0.8835832466512141, 0.8787542769177953, 0.8856544102095746, 0.8858081102106323, 0.8871593506977555, 0.887492447760391, 0.8894186910542449, 0.8901409927333894, 0.8843807998244538, 0.8832920847162505, 0.8565256766013271, 0.8821357506115122, 0.8848742775429348, 0.886979450703303, 0.8730071241700773, 0.8859443828027428, 0.8792887045598304, 0.8790418527162792, 0.8872264861477783, 0.8901294116239443, 0.8884193355806608, 0.8907832856647825, 0.8832980454607575, 0.889779559680904, 0.851665591710742, 0.8775535796825549, 0.8845620680049097, 0.8874879210996262, 0.8885246788870379, 0.8658324031328506, 0.851235967326956, 0.8778093939818667, 0.8841781406264541, 0.8780545680063216, 0.8871759588048916, 0.8886315002796211, 0.8814013320736246, 0.8873718612557797, 0.8028221709776603, 0.8609601696720806, 0.8730433739849018, 0.8787609357227182, 0.8719902319814598, 0.8802105618063575, 0.8849378281525601, 0.8748340089808085, 0.8819037284194746, 0.8884486372709562, 0.8828682817471882, 0.8889979021517892, 0.8877570881146369, 0.8910334628314475, 0.8800591423045142, 0.8896466476804802, 0.8908284644037343, 0.8919216643083013, 0.8831808477513382, 0.8842984948201555, 0.8925693815499667, 0.8931428939529801, 0.8614021568977677, 0.8831716404590264, 0.8803084315735078, 0.8882139137560023, 0.891205885472218, 0.8808475436880342, 0.8841928404691854, 0.8756968053391863, 0.8827480783342037, 0.8761060742505141, 0.8859899937936249, 0.8882182916681559, 0.8894874642299596, 0.8903776948077059, 0.8541464334472415]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.28s/it]predicting test subjects:  40%|████      | 2/5 [00:01<00:03,  1.06s/it]predicting test subjects:  60%|██████    | 3/5 [00:02<00:01,  1.17it/s]predicting test subjects:  80%|████████  | 4/5 [00:02<00:00,  1.39it/s]predicting test subjects: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<02:09,  1.90it/s]predicting train subjects:   1%|          | 2/247 [00:01<02:07,  1.93it/s]predicting train subjects:   1%|          | 3/247 [00:01<02:06,  1.93it/s]predicting train subjects:   2%|▏         | 4/247 [00:01<01:57,  2.06it/s]predicting train subjects:   2%|▏         | 5/247 [00:02<01:55,  2.09it/s]predicting train subjects:   2%|▏         | 6/247 [00:02<01:59,  2.02it/s]predicting train subjects:   3%|▎         | 7/247 [00:03<01:51,  2.15it/s]predicting train subjects:   3%|▎         | 8/247 [00:03<01:53,  2.10it/s]predicting train subjects:   4%|▎         | 9/247 [00:04<01:56,  2.03it/s]predicting train subjects:   4%|▍         | 10/247 [00:04<01:46,  2.22it/s]predicting train subjects:   4%|▍         | 11/247 [00:05<01:46,  2.22it/s]predicting train subjects:   5%|▍         | 12/247 [00:05<01:48,  2.17it/s]predicting train subjects:   5%|▌         | 13/247 [00:06<01:39,  2.34it/s]predicting train subjects:   6%|▌         | 14/247 [00:06<01:41,  2.30it/s]predicting train subjects:   6%|▌         | 15/247 [00:06<01:37,  2.39it/s]predicting train subjects:   6%|▋         | 16/247 [00:07<01:41,  2.29it/s]predicting train subjects:   7%|▋         | 17/247 [00:07<01:46,  2.17it/s]predicting train subjects:   7%|▋         | 18/247 [00:08<01:55,  1.98it/s]predicting train subjects:   8%|▊         | 19/247 [00:08<01:45,  2.15it/s]predicting train subjects:   8%|▊         | 20/247 [00:09<01:43,  2.20it/s]predicting train subjects:   9%|▊         | 21/247 [00:09<01:35,  2.36it/s]predicting train subjects:   9%|▉         | 22/247 [00:10<01:36,  2.33it/s]predicting train subjects:   9%|▉         | 23/247 [00:10<01:36,  2.32it/s]predicting train subjects:  10%|▉         | 24/247 [00:10<01:33,  2.38it/s]predicting train subjects:  10%|█         | 25/247 [00:11<01:41,  2.18it/s]predicting train subjects:  11%|█         | 26/247 [00:11<01:42,  2.16it/s]predicting train subjects:  11%|█         | 27/247 [00:12<01:40,  2.18it/s]predicting train subjects:  11%|█▏        | 28/247 [00:12<01:37,  2.24it/s]predicting train subjects:  12%|█▏        | 29/247 [00:13<01:40,  2.17it/s]predicting train subjects:  12%|█▏        | 30/247 [00:13<01:38,  2.21it/s]predicting train subjects:  13%|█▎        | 31/247 [00:14<01:35,  2.26it/s]predicting train subjects:  13%|█▎        | 32/247 [00:14<01:35,  2.26it/s]predicting train subjects:  13%|█▎        | 33/247 [00:14<01:25,  2.51it/s]predicting train subjects:  14%|█▍        | 34/247 [00:15<01:27,  2.43it/s]predicting train subjects:  14%|█▍        | 35/247 [00:15<01:36,  2.20it/s]predicting train subjects:  15%|█▍        | 36/247 [00:16<01:33,  2.26it/s]predicting train subjects:  15%|█▍        | 37/247 [00:16<01:37,  2.16it/s]predicting train subjects:  15%|█▌        | 38/247 [00:17<01:43,  2.02it/s]predicting train subjects:  16%|█▌        | 39/247 [00:17<01:46,  1.96it/s]predicting train subjects:  16%|█▌        | 40/247 [00:18<01:37,  2.11it/s]predicting train subjects:  17%|█▋        | 41/247 [00:18<01:38,  2.10it/s]predicting train subjects:  17%|█▋        | 42/247 [00:19<01:41,  2.02it/s]predicting train subjects:  17%|█▋        | 43/247 [00:19<01:37,  2.08it/s]predicting train subjects:  18%|█▊        | 44/247 [00:20<01:36,  2.10it/s]predicting train subjects:  18%|█▊        | 45/247 [00:20<01:33,  2.16it/s]predicting train subjects:  19%|█▊        | 46/247 [00:20<01:23,  2.42it/s]predicting train subjects:  19%|█▉        | 47/247 [00:21<01:26,  2.32it/s]predicting train subjects:  19%|█▉        | 48/247 [00:22<01:35,  2.08it/s]predicting train subjects:  20%|█▉        | 49/247 [00:22<01:28,  2.24it/s]predicting train subjects:  20%|██        | 50/247 [00:22<01:30,  2.19it/s]predicting train subjects:  21%|██        | 51/247 [00:23<01:32,  2.12it/s]predicting train subjects:  21%|██        | 52/247 [00:23<01:24,  2.32it/s]predicting train subjects:  21%|██▏       | 53/247 [00:24<01:23,  2.34it/s]predicting train subjects:  22%|██▏       | 54/247 [00:24<01:29,  2.16it/s]predicting train subjects:  22%|██▏       | 55/247 [00:25<01:26,  2.21it/s]predicting train subjects:  23%|██▎       | 56/247 [00:25<01:28,  2.15it/s]predicting train subjects:  23%|██▎       | 57/247 [00:26<01:29,  2.11it/s]predicting train subjects:  23%|██▎       | 58/247 [00:26<01:26,  2.19it/s]predicting train subjects:  24%|██▍       | 59/247 [00:26<01:23,  2.25it/s]predicting train subjects:  24%|██▍       | 60/247 [00:27<01:19,  2.34it/s]predicting train subjects:  25%|██▍       | 61/247 [00:27<01:22,  2.24it/s]predicting train subjects:  25%|██▌       | 62/247 [00:28<01:22,  2.24it/s]predicting train subjects:  26%|██▌       | 63/247 [00:28<01:20,  2.28it/s]predicting train subjects:  26%|██▌       | 64/247 [00:29<01:24,  2.18it/s]predicting train subjects:  26%|██▋       | 65/247 [00:29<01:24,  2.15it/s]predicting train subjects:  27%|██▋       | 66/247 [00:30<01:29,  2.03it/s]predicting train subjects:  27%|██▋       | 67/247 [00:30<01:20,  2.24it/s]predicting train subjects:  28%|██▊       | 68/247 [00:30<01:19,  2.26it/s]predicting train subjects:  28%|██▊       | 69/247 [00:31<01:13,  2.41it/s]predicting train subjects:  28%|██▊       | 70/247 [00:31<01:21,  2.17it/s]predicting train subjects:  29%|██▊       | 71/247 [00:32<01:24,  2.08it/s]predicting train subjects:  29%|██▉       | 72/247 [00:32<01:17,  2.25it/s]predicting train subjects:  30%|██▉       | 73/247 [00:33<01:14,  2.33it/s]predicting train subjects:  30%|██▉       | 74/247 [00:33<01:16,  2.27it/s]predicting train subjects:  30%|███       | 75/247 [00:34<01:17,  2.21it/s]predicting train subjects:  31%|███       | 76/247 [00:34<01:17,  2.20it/s]predicting train subjects:  31%|███       | 77/247 [00:35<01:19,  2.14it/s]predicting train subjects:  32%|███▏      | 78/247 [00:35<01:23,  2.02it/s]predicting train subjects:  32%|███▏      | 79/247 [00:36<01:20,  2.08it/s]predicting train subjects:  32%|███▏      | 80/247 [00:36<01:20,  2.07it/s]predicting train subjects:  33%|███▎      | 81/247 [00:37<01:22,  2.02it/s]predicting train subjects:  33%|███▎      | 82/247 [00:37<01:25,  1.93it/s]predicting train subjects:  34%|███▎      | 83/247 [00:37<01:14,  2.19it/s]predicting train subjects:  34%|███▍      | 84/247 [00:38<01:13,  2.21it/s]predicting train subjects:  34%|███▍      | 85/247 [00:38<01:15,  2.14it/s]predicting train subjects:  35%|███▍      | 86/247 [00:39<01:09,  2.33it/s]predicting train subjects:  35%|███▌      | 87/247 [00:39<01:11,  2.22it/s]predicting train subjects:  36%|███▌      | 88/247 [00:40<01:18,  2.03it/s]predicting train subjects:  36%|███▌      | 89/247 [00:40<01:20,  1.97it/s]predicting train subjects:  36%|███▋      | 90/247 [00:41<01:12,  2.17it/s]predicting train subjects:  37%|███▋      | 91/247 [00:41<01:14,  2.10it/s]predicting train subjects:  37%|███▋      | 92/247 [00:42<01:17,  2.00it/s]predicting train subjects:  38%|███▊      | 93/247 [00:42<01:21,  1.88it/s]predicting train subjects:  38%|███▊      | 94/247 [00:43<01:22,  1.85it/s]predicting train subjects:  38%|███▊      | 95/247 [00:43<01:12,  2.11it/s]predicting train subjects:  39%|███▉      | 96/247 [00:44<01:10,  2.13it/s]predicting train subjects:  39%|███▉      | 97/247 [00:44<01:11,  2.10it/s]predicting train subjects:  40%|███▉      | 98/247 [00:45<01:14,  1.99it/s]predicting train subjects:  40%|████      | 99/247 [00:45<01:13,  2.01it/s]predicting train subjects:  40%|████      | 100/247 [00:46<01:12,  2.03it/s]predicting train subjects:  41%|████      | 101/247 [00:46<01:09,  2.09it/s]predicting train subjects:  41%|████▏     | 102/247 [00:47<01:01,  2.35it/s]predicting train subjects:  42%|████▏     | 103/247 [00:47<01:00,  2.39it/s]predicting train subjects:  42%|████▏     | 104/247 [00:47<00:57,  2.47it/s]predicting train subjects:  43%|████▎     | 105/247 [00:48<00:59,  2.39it/s]predicting train subjects:  43%|████▎     | 106/247 [00:48<00:53,  2.65it/s]predicting train subjects:  43%|████▎     | 107/247 [00:49<00:56,  2.48it/s]predicting train subjects:  44%|████▎     | 108/247 [00:49<00:57,  2.43it/s]predicting train subjects:  44%|████▍     | 109/247 [00:49<00:59,  2.33it/s]predicting train subjects:  45%|████▍     | 110/247 [00:50<00:57,  2.40it/s]predicting train subjects:  45%|████▍     | 111/247 [00:50<00:59,  2.30it/s]predicting train subjects:  45%|████▌     | 112/247 [00:51<00:59,  2.28it/s]predicting train subjects:  46%|████▌     | 113/247 [00:51<01:02,  2.13it/s]predicting train subjects:  46%|████▌     | 114/247 [00:52<01:03,  2.09it/s]predicting train subjects:  47%|████▋     | 115/247 [00:52<00:56,  2.34it/s]predicting train subjects:  47%|████▋     | 116/247 [00:53<01:01,  2.13it/s]predicting train subjects:  47%|████▋     | 117/247 [00:53<01:00,  2.13it/s]predicting train subjects:  48%|████▊     | 118/247 [00:54<01:00,  2.13it/s]predicting train subjects:  48%|████▊     | 119/247 [00:54<01:01,  2.07it/s]predicting train subjects:  49%|████▊     | 120/247 [00:54<00:55,  2.30it/s]predicting train subjects:  49%|████▉     | 121/247 [00:55<00:56,  2.21it/s]predicting train subjects:  49%|████▉     | 122/247 [00:55<00:58,  2.13it/s]predicting train subjects:  50%|████▉     | 123/247 [00:56<00:59,  2.08it/s]predicting train subjects:  50%|█████     | 124/247 [00:56<00:54,  2.26it/s]predicting train subjects:  51%|█████     | 125/247 [00:57<00:51,  2.38it/s]predicting train subjects:  51%|█████     | 126/247 [00:57<00:51,  2.33it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:58<00:56,  2.14it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:58<00:54,  2.18it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:59<01:00,  1.94it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:59<01:02,  1.87it/s]predicting train subjects:  53%|█████▎    | 131/247 [01:00<01:04,  1.81it/s]predicting train subjects:  53%|█████▎    | 132/247 [01:00<00:57,  2.00it/s]predicting train subjects:  54%|█████▍    | 133/247 [01:01<00:56,  2.02it/s]predicting train subjects:  54%|█████▍    | 134/247 [01:01<00:56,  2.01it/s]predicting train subjects:  55%|█████▍    | 135/247 [01:02<00:58,  1.93it/s]predicting train subjects:  55%|█████▌    | 136/247 [01:02<00:52,  2.10it/s]predicting train subjects:  55%|█████▌    | 137/247 [01:03<00:48,  2.26it/s]predicting train subjects:  56%|█████▌    | 138/247 [01:03<00:45,  2.37it/s]predicting train subjects:  56%|█████▋    | 139/247 [01:04<00:50,  2.15it/s]predicting train subjects:  57%|█████▋    | 140/247 [01:04<00:52,  2.05it/s]predicting train subjects:  57%|█████▋    | 141/247 [01:04<00:49,  2.14it/s]predicting train subjects:  57%|█████▋    | 142/247 [01:05<00:45,  2.29it/s]predicting train subjects:  58%|█████▊    | 143/247 [01:05<00:46,  2.22it/s]predicting train subjects:  58%|█████▊    | 144/247 [01:06<00:47,  2.18it/s]predicting train subjects:  59%|█████▊    | 145/247 [01:06<00:46,  2.20it/s]predicting train subjects:  59%|█████▉    | 146/247 [01:07<00:49,  2.02it/s]predicting train subjects:  60%|█████▉    | 147/247 [01:07<00:49,  2.00it/s]predicting train subjects:  60%|█████▉    | 148/247 [01:08<00:47,  2.09it/s]predicting train subjects:  60%|██████    | 149/247 [01:08<00:43,  2.23it/s]predicting train subjects:  61%|██████    | 150/247 [01:09<00:43,  2.24it/s]predicting train subjects:  61%|██████    | 151/247 [01:09<00:41,  2.32it/s]predicting train subjects:  62%|██████▏   | 152/247 [01:09<00:37,  2.53it/s]predicting train subjects:  62%|██████▏   | 153/247 [01:10<00:41,  2.28it/s]predicting train subjects:  62%|██████▏   | 154/247 [01:11<00:47,  1.97it/s]predicting train subjects:  63%|██████▎   | 155/247 [01:11<00:49,  1.86it/s]predicting train subjects:  63%|██████▎   | 156/247 [01:12<00:46,  1.95it/s]predicting train subjects:  64%|██████▎   | 157/247 [01:12<00:44,  2.01it/s]predicting train subjects:  64%|██████▍   | 158/247 [01:12<00:43,  2.06it/s]predicting train subjects:  64%|██████▍   | 159/247 [01:13<00:38,  2.27it/s]predicting train subjects:  65%|██████▍   | 160/247 [01:13<00:38,  2.23it/s]predicting train subjects:  65%|██████▌   | 161/247 [01:14<00:39,  2.15it/s]predicting train subjects:  66%|██████▌   | 162/247 [01:14<00:39,  2.15it/s]predicting train subjects:  66%|██████▌   | 163/247 [01:15<00:43,  1.94it/s]predicting train subjects:  66%|██████▋   | 164/247 [01:15<00:43,  1.89it/s]predicting train subjects:  67%|██████▋   | 165/247 [01:16<00:37,  2.20it/s]predicting train subjects:  67%|██████▋   | 166/247 [01:16<00:38,  2.10it/s]predicting train subjects:  68%|██████▊   | 167/247 [01:17<00:39,  2.00it/s]predicting train subjects:  68%|██████▊   | 168/247 [01:17<00:40,  1.95it/s]predicting train subjects:  68%|██████▊   | 169/247 [01:18<00:38,  2.04it/s]predicting train subjects:  69%|██████▉   | 170/247 [01:18<00:37,  2.06it/s]predicting train subjects:  69%|██████▉   | 171/247 [01:19<00:34,  2.19it/s]predicting train subjects:  70%|██████▉   | 172/247 [01:19<00:33,  2.27it/s]predicting train subjects:  70%|███████   | 173/247 [01:20<00:34,  2.15it/s]predicting train subjects:  70%|███████   | 174/247 [01:20<00:34,  2.09it/s]predicting train subjects:  71%|███████   | 175/247 [01:21<00:37,  1.92it/s]predicting train subjects:  71%|███████▏  | 176/247 [01:21<00:37,  1.88it/s]predicting train subjects:  72%|███████▏  | 177/247 [01:22<00:33,  2.10it/s]predicting train subjects:  72%|███████▏  | 178/247 [01:22<00:32,  2.10it/s]predicting train subjects:  72%|███████▏  | 179/247 [01:23<00:33,  2.04it/s]predicting train subjects:  73%|███████▎  | 180/247 [01:23<00:29,  2.25it/s]predicting train subjects:  73%|███████▎  | 181/247 [01:23<00:30,  2.20it/s]predicting train subjects:  74%|███████▎  | 182/247 [01:24<00:28,  2.25it/s]predicting train subjects:  74%|███████▍  | 183/247 [01:24<00:27,  2.36it/s]predicting train subjects:  74%|███████▍  | 184/247 [01:25<00:26,  2.36it/s]predicting train subjects:  75%|███████▍  | 185/247 [01:25<00:27,  2.26it/s]predicting train subjects:  75%|███████▌  | 186/247 [01:26<00:27,  2.24it/s]predicting train subjects:  76%|███████▌  | 187/247 [01:26<00:28,  2.11it/s]predicting train subjects:  76%|███████▌  | 188/247 [01:26<00:25,  2.32it/s]predicting train subjects:  77%|███████▋  | 189/247 [01:27<00:23,  2.44it/s]predicting train subjects:  77%|███████▋  | 190/247 [01:27<00:23,  2.42it/s]predicting train subjects:  77%|███████▋  | 191/247 [01:28<00:24,  2.32it/s]predicting train subjects:  78%|███████▊  | 192/247 [01:28<00:23,  2.33it/s]predicting train subjects:  78%|███████▊  | 193/247 [01:29<00:25,  2.14it/s]predicting train subjects:  79%|███████▊  | 194/247 [01:29<00:25,  2.05it/s]predicting train subjects:  79%|███████▉  | 195/247 [01:30<00:25,  2.07it/s]predicting train subjects:  79%|███████▉  | 196/247 [01:30<00:21,  2.33it/s]predicting train subjects:  80%|███████▉  | 197/247 [01:30<00:22,  2.25it/s]predicting train subjects:  80%|████████  | 198/247 [01:31<00:23,  2.10it/s]predicting train subjects:  81%|████████  | 199/247 [01:31<00:22,  2.16it/s]predicting train subjects:  81%|████████  | 200/247 [01:32<00:21,  2.15it/s]predicting train subjects:  81%|████████▏ | 201/247 [01:32<00:20,  2.19it/s]predicting train subjects:  82%|████████▏ | 202/247 [01:33<00:22,  1.97it/s]predicting train subjects:  82%|████████▏ | 203/247 [01:34<00:23,  1.85it/s]predicting train subjects:  83%|████████▎ | 204/247 [01:34<00:21,  2.05it/s]predicting train subjects:  83%|████████▎ | 205/247 [01:34<00:20,  2.06it/s]predicting train subjects:  83%|████████▎ | 206/247 [01:35<00:20,  2.04it/s]predicting train subjects:  84%|████████▍ | 207/247 [01:36<00:20,  1.96it/s]predicting train subjects:  84%|████████▍ | 208/247 [01:36<00:20,  1.90it/s]predicting train subjects:  85%|████████▍ | 209/247 [01:37<00:18,  2.01it/s]predicting train subjects:  85%|████████▌ | 210/247 [01:37<00:17,  2.07it/s]predicting train subjects:  85%|████████▌ | 211/247 [01:37<00:15,  2.31it/s]predicting train subjects:  86%|████████▌ | 212/247 [01:38<00:14,  2.34it/s]predicting train subjects:  86%|████████▌ | 213/247 [01:38<00:14,  2.30it/s]predicting train subjects:  87%|████████▋ | 214/247 [01:39<00:15,  2.13it/s]predicting train subjects:  87%|████████▋ | 215/247 [01:39<00:13,  2.29it/s]predicting train subjects:  87%|████████▋ | 216/247 [01:40<00:14,  2.19it/s]predicting train subjects:  88%|████████▊ | 217/247 [01:40<00:14,  2.14it/s]predicting train subjects:  88%|████████▊ | 218/247 [01:40<00:12,  2.31it/s]predicting train subjects:  89%|████████▊ | 219/247 [01:41<00:12,  2.28it/s]predicting train subjects:  89%|████████▉ | 220/247 [01:41<00:11,  2.37it/s]predicting train subjects:  89%|████████▉ | 221/247 [01:42<00:10,  2.40it/s]predicting train subjects:  90%|████████▉ | 222/247 [01:42<00:10,  2.37it/s]predicting train subjects:  90%|█████████ | 223/247 [01:43<00:10,  2.20it/s]predicting train subjects:  91%|█████████ | 224/247 [01:43<00:10,  2.25it/s]predicting train subjects:  91%|█████████ | 225/247 [01:44<00:10,  2.16it/s]predicting train subjects:  91%|█████████▏| 226/247 [01:44<00:10,  2.09it/s]predicting train subjects:  92%|█████████▏| 227/247 [01:45<00:09,  2.06it/s]predicting train subjects:  92%|█████████▏| 228/247 [01:45<00:09,  2.02it/s]predicting train subjects:  93%|█████████▎| 229/247 [01:46<00:08,  2.10it/s]predicting train subjects:  93%|█████████▎| 230/247 [01:46<00:07,  2.13it/s]predicting train subjects:  94%|█████████▎| 231/247 [01:46<00:07,  2.20it/s]predicting train subjects:  94%|█████████▍| 232/247 [01:47<00:06,  2.16it/s]predicting train subjects:  94%|█████████▍| 233/247 [01:47<00:06,  2.17it/s]predicting train subjects:  95%|█████████▍| 234/247 [01:48<00:06,  2.12it/s]predicting train subjects:  95%|█████████▌| 235/247 [01:48<00:05,  2.38it/s]predicting train subjects:  96%|█████████▌| 236/247 [01:49<00:04,  2.29it/s]predicting train subjects:  96%|█████████▌| 237/247 [01:49<00:04,  2.16it/s]predicting train subjects:  96%|█████████▋| 238/247 [01:49<00:03,  2.34it/s]predicting train subjects:  97%|█████████▋| 239/247 [01:50<00:03,  2.39it/s]predicting train subjects:  97%|█████████▋| 240/247 [01:50<00:02,  2.49it/s]predicting train subjects:  98%|█████████▊| 241/247 [01:51<00:02,  2.41it/s]predicting train subjects:  98%|█████████▊| 242/247 [01:51<00:02,  2.28it/s]predicting train subjects:  98%|█████████▊| 243/247 [01:52<00:01,  2.10it/s]predicting train subjects:  99%|█████████▉| 244/247 [01:52<00:01,  1.95it/s]predicting train subjects:  99%|█████████▉| 245/247 [01:53<00:00,  2.09it/s]predicting train subjects: 100%|█████████▉| 246/247 [01:53<00:00,  2.04it/s]predicting train subjects: 100%|██████████| 247/247 [01:54<00:00,  2.03it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:01,  2.46it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:01,  2.36it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:01<00:00,  2.12it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:01<00:00,  2.10it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:02<00:00,  2.00it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<02:10,  1.88it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<01:54,  2.13it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:01<01:43,  2.36it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:01<01:46,  2.28it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:02<01:49,  2.21it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:02<01:56,  2.06it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:03<01:51,  2.15it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:03<01:55,  2.07it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:04<01:56,  2.04it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:04<01:49,  2.17it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:04<01:39,  2.36it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:05<01:38,  2.38it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:05<01:32,  2.54it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:06<01:34,  2.47it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:06<01:37,  2.38it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:06<01:41,  2.28it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:07<01:38,  2.34it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:07<01:42,  2.23it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:08<01:42,  2.22it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:08<01:52,  2.02it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:09<01:44,  2.15it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:09<01:40,  2.25it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:10<01:41,  2.21it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:10<01:43,  2.16it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:11<01:43,  2.15it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:11<01:44,  2.12it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:12<01:46,  2.06it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:12<01:46,  2.05it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:13<01:42,  2.13it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:13<01:42,  2.12it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:13<01:34,  2.28it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:14<01:39,  2.17it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:14<01:42,  2.10it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:15<01:37,  2.18it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:15<01:35,  2.23it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:16<01:31,  2.31it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:16<01:36,  2.17it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:17<01:45,  1.97it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:17<01:39,  2.09it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:18<01:37,  2.13it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:18<01:36,  2.13it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:19<01:35,  2.15it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:19<01:34,  2.16it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:19<01:30,  2.23it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:20<01:33,  2.16it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:20<01:30,  2.23it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:21<01:31,  2.20it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:21<01:35,  2.08it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:22<01:31,  2.16it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:22<01:25,  2.30it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:23<01:24,  2.32it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:23<01:29,  2.17it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:24<01:39,  1.95it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:24<01:28,  2.19it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:25<01:27,  2.18it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:25<01:29,  2.13it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:26<01:31,  2.07it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:26<01:26,  2.20it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:26<01:23,  2.25it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:27<01:27,  2.14it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:27<01:19,  2.33it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:28<01:17,  2.37it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:28<01:11,  2.57it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:28<01:16,  2.39it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:29<01:21,  2.24it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:29<01:25,  2.12it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:30<01:21,  2.20it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:30<01:24,  2.13it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:31<01:21,  2.18it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:31<01:12,  2.43it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:32<01:17,  2.26it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:32<01:16,  2.29it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:33<01:20,  2.15it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:33<01:11,  2.43it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:33<01:11,  2.42it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:34<01:07,  2.55it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:34<01:08,  2.48it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:35<01:12,  2.34it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:35<01:10,  2.40it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:36<01:16,  2.19it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:36<01:19,  2.10it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:37<01:23,  1.99it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:37<01:24,  1.94it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:38<01:21,  2.00it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:38<01:19,  2.04it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:39<01:16,  2.11it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:39<01:16,  2.09it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:39<01:14,  2.14it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:40<01:10,  2.23it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:40<01:12,  2.18it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:41<01:17,  2.02it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:41<01:13,  2.12it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:42<01:12,  2.12it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:42<01:12,  2.11it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:43<01:11,  2.13it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:43<01:05,  2.29it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:44<01:06,  2.26it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:44<01:11,  2.08it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:45<01:06,  2.22it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:45<01:09,  2.10it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:46<01:10,  2.06it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:46<01:12,  2.01it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:47<01:12,  1.99it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:47<01:07,  2.13it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:47<01:03,  2.24it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:48<00:56,  2.48it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:48<00:59,  2.36it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:49<01:00,  2.31it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:49<00:59,  2.31it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:49<00:57,  2.40it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:50<00:56,  2.42it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:50<00:51,  2.62it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:51<00:55,  2.43it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:51<00:58,  2.28it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:52<00:58,  2.26it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:52<00:56,  2.33it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:52<00:53,  2.42it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:53<00:51,  2.52it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:53<00:54,  2.36it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:54<00:55,  2.29it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:54<00:54,  2.31it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:55<01:05,  1.92it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:55<00:59,  2.09it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:56<01:00,  2.03it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:56<01:01,  2.00it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:57<01:01,  1.98it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:57<00:57,  2.09it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:58<00:57,  2.06it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:58<00:57,  2.04it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:59<01:00,  1.93it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:59<00:53,  2.16it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [01:00<00:55,  2.08it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [01:00<00:56,  2.02it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [01:01<00:58,  1.93it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [01:01<00:53,  2.09it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [01:02<00:58,  1.90it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [01:02<00:57,  1.93it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [01:03<00:53,  2.04it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [01:03<00:56,  1.91it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [01:04<00:53,  1.98it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [01:04<00:50,  2.09it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [01:05<00:52,  1.98it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [01:05<00:56,  1.86it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [01:06<00:57,  1.81it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [01:06<00:55,  1.83it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [01:07<00:50,  2.02it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [01:07<00:47,  2.13it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [01:08<00:43,  2.29it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [01:08<00:44,  2.22it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [01:09<00:45,  2.14it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [01:09<00:39,  2.42it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [01:09<00:40,  2.37it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [01:10<00:40,  2.34it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [01:10<00:43,  2.11it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [01:11<00:41,  2.24it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [01:11<00:39,  2.29it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [01:12<00:39,  2.26it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [01:12<00:38,  2.29it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [01:13<00:40,  2.17it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [01:13<00:37,  2.30it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [01:13<00:41,  2.09it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [01:14<00:37,  2.28it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [01:14<00:38,  2.20it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [01:15<00:39,  2.11it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [01:15<00:34,  2.37it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [01:16<00:35,  2.29it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [01:16<00:35,  2.28it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [01:17<00:36,  2.19it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [01:17<00:33,  2.30it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [01:17<00:33,  2.31it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [01:18<00:32,  2.31it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [01:18<00:33,  2.26it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [01:19<00:33,  2.23it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [01:19<00:32,  2.26it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [01:20<00:31,  2.29it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [01:20<00:31,  2.24it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [01:20<00:30,  2.28it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [01:21<00:29,  2.36it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [01:21<00:28,  2.36it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [01:22<00:29,  2.24it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [01:22<00:28,  2.33it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [01:23<00:28,  2.26it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [01:23<00:29,  2.18it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [01:23<00:27,  2.32it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [01:24<00:28,  2.18it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [01:25<00:29,  2.06it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [01:25<00:29,  2.05it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [01:25<00:27,  2.16it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [01:26<00:25,  2.27it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [01:26<00:22,  2.57it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [01:26<00:21,  2.58it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [01:27<00:21,  2.56it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [01:27<00:20,  2.58it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [01:28<00:20,  2.62it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [01:28<00:19,  2.63it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [01:29<00:22,  2.27it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [01:29<00:23,  2.15it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [01:29<00:20,  2.38it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [01:30<00:19,  2.43it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [01:30<00:20,  2.33it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [01:31<00:19,  2.33it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [01:31<00:20,  2.25it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [01:32<00:21,  2.09it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [01:32<00:21,  2.01it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [01:33<00:19,  2.14it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [01:33<00:19,  2.08it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [01:34<00:18,  2.13it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [01:34<00:17,  2.19it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [01:35<00:18,  2.06it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [01:35<00:16,  2.20it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [01:35<00:16,  2.19it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [01:36<00:15,  2.27it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [01:36<00:15,  2.14it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [01:37<00:15,  2.08it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [01:37<00:15,  2.12it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [01:38<00:15,  2.05it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [01:38<00:13,  2.26it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [01:39<00:12,  2.26it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [01:39<00:14,  1.99it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [01:40<00:13,  1.96it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [01:40<00:14,  1.85it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [01:41<00:12,  1.98it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [01:41<00:11,  2.07it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [01:42<00:10,  2.09it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [01:42<00:09,  2.34it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [01:43<00:09,  2.22it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [01:43<00:08,  2.25it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [01:43<00:07,  2.41it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [01:44<00:07,  2.32it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [01:44<00:07,  2.26it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [01:45<00:07,  2.17it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [01:45<00:06,  2.19it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [01:46<00:06,  2.20it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [01:46<00:06,  2.13it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [01:47<00:05,  2.24it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [01:47<00:04,  2.26it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [01:48<00:04,  2.18it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [01:48<00:04,  2.03it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [01:48<00:03,  2.22it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [01:49<00:03,  2.23it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [01:49<00:02,  2.32it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [01:50<00:02,  2.43it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [01:50<00:01,  2.38it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [01:51<00:01,  2.37it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [01:51<00:00,  2.32it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [01:51<00:00,  2.46it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [01:52<00:00,  2.29it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 62.14it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/247 [00:00<00:03, 79.48it/s]saving BB  train1-THALAMUS:   6%|▋         | 16/247 [00:00<00:02, 79.44it/s]saving BB  train1-THALAMUS:   9%|▉         | 23/247 [00:00<00:03, 74.66it/s]saving BB  train1-THALAMUS:  12%|█▏        | 29/247 [00:00<00:03, 66.47it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:03, 67.24it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 70.86it/s]saving BB  train1-THALAMUS:  21%|██▏       | 53/247 [00:00<00:02, 73.17it/s]saving BB  train1-THALAMUS:  25%|██▍       | 61/247 [00:00<00:02, 74.97it/s]saving BB  train1-THALAMUS:  28%|██▊       | 69/247 [00:00<00:02, 68.46it/s]saving BB  train1-THALAMUS:  31%|███       | 76/247 [00:01<00:02, 60.17it/s]saving BB  train1-THALAMUS:  34%|███▍      | 84/247 [00:01<00:02, 64.35it/s]saving BB  train1-THALAMUS:  37%|███▋      | 92/247 [00:01<00:02, 66.79it/s]saving BB  train1-THALAMUS:  40%|████      | 100/247 [00:01<00:02, 68.60it/s]saving BB  train1-THALAMUS:  44%|████▎     | 108/247 [00:01<00:01, 69.86it/s]saving BB  train1-THALAMUS:  47%|████▋     | 116/247 [00:01<00:02, 59.75it/s]saving BB  train1-THALAMUS:  50%|█████     | 124/247 [00:01<00:01, 64.57it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 132/247 [00:01<00:01, 67.92it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 140/247 [00:02<00:01, 69.98it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 148/247 [00:02<00:01, 72.21it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 156/247 [00:02<00:01, 60.10it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 163/247 [00:02<00:01, 59.84it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 171/247 [00:02<00:01, 64.28it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 179/247 [00:02<00:01, 67.02it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 186/247 [00:02<00:00, 67.13it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 193/247 [00:02<00:00, 65.11it/s]saving BB  train1-THALAMUS:  81%|████████  | 200/247 [00:03<00:00, 59.28it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 208/247 [00:03<00:00, 62.96it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 216/247 [00:03<00:00, 65.87it/s]saving BB  train1-THALAMUS:  91%|█████████ | 224/247 [00:03<00:00, 68.37it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 232/247 [00:03<00:00, 68.73it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 239/247 [00:03<00:00, 55.66it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 60.50it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 67.64it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/247 [00:00<00:03, 78.80it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 16/247 [00:00<00:02, 78.99it/s]saving BB  train1-THALAMUS Sagittal:   9%|▉         | 23/247 [00:00<00:03, 74.22it/s]saving BB  train1-THALAMUS Sagittal:  12%|█▏        | 29/247 [00:00<00:03, 66.68it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 36/247 [00:00<00:03, 67.41it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 44/247 [00:00<00:02, 70.57it/s]saving BB  train1-THALAMUS Sagittal:  21%|██        | 52/247 [00:00<00:02, 73.09it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▍       | 61/247 [00:00<00:02, 75.53it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 69/247 [00:00<00:02, 71.10it/s]saving BB  train1-THALAMUS Sagittal:  31%|███       | 76/247 [00:01<00:02, 66.33it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▍      | 84/247 [00:01<00:02, 69.19it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 92/247 [00:01<00:02, 70.83it/s]saving BB  train1-THALAMUS Sagittal:  40%|████      | 100/247 [00:01<00:02, 72.24it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▎     | 108/247 [00:01<00:01, 74.18it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 116/247 [00:01<00:02, 64.43it/s]saving BB  train1-THALAMUS Sagittal:  50%|████▉     | 123/247 [00:01<00:02, 59.54it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 131/247 [00:01<00:01, 64.14it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▋    | 139/247 [00:02<00:01, 66.95it/s]saving BB  train1-THALAMUS Sagittal:  60%|█████▉    | 147/247 [00:02<00:01, 70.37it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 155/247 [00:02<00:01, 66.06it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 162/247 [00:02<00:01, 61.18it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 169/247 [00:02<00:01, 59.72it/s]saving BB  train1-THALAMUS Sagittal:  72%|███████▏  | 177/247 [00:02<00:01, 64.31it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▍  | 185/247 [00:02<00:00, 67.80it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 193/247 [00:02<00:00, 68.28it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 200/247 [00:02<00:00, 62.82it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 207/247 [00:03<00:00, 64.61it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 215/247 [00:03<00:00, 68.17it/s]saving BB  train1-THALAMUS Sagittal:  90%|█████████ | 223/247 [00:03<00:00, 70.12it/s]saving BB  train1-THALAMUS Sagittal:  94%|█████████▎| 231/247 [00:03<00:00, 72.46it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 239/247 [00:03<00:00, 69.40it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 64.36it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_BC_CSFn
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:02<08:33,  2.09s/it]Loading train:   1%|          | 2/247 [00:03<08:06,  1.99s/it]Loading train:   1%|          | 3/247 [00:05<07:50,  1.93s/it]Loading train:   2%|▏         | 4/247 [00:07<07:42,  1.90s/it]Loading train:   2%|▏         | 5/247 [00:08<06:40,  1.65s/it]Loading train:   2%|▏         | 6/247 [00:09<06:22,  1.59s/it]Loading train:   3%|▎         | 7/247 [00:11<06:04,  1.52s/it]Loading train:   3%|▎         | 8/247 [00:12<05:41,  1.43s/it]Loading train:   4%|▎         | 9/247 [00:13<05:33,  1.40s/it]Loading train:   4%|▍         | 10/247 [00:15<05:11,  1.32s/it]Loading train:   4%|▍         | 11/247 [00:16<05:16,  1.34s/it]Loading train:   5%|▍         | 12/247 [00:17<04:58,  1.27s/it]Loading train:   5%|▌         | 13/247 [00:18<04:50,  1.24s/it]Loading train:   6%|▌         | 14/247 [00:20<04:58,  1.28s/it]Loading train:   6%|▌         | 15/247 [00:21<05:17,  1.37s/it]Loading train:   6%|▋         | 16/247 [00:22<05:02,  1.31s/it]Loading train:   7%|▋         | 17/247 [00:24<05:10,  1.35s/it]Loading train:   7%|▋         | 18/247 [00:25<04:57,  1.30s/it]Loading train:   8%|▊         | 19/247 [00:26<04:24,  1.16s/it]Loading train:   8%|▊         | 20/247 [00:27<04:30,  1.19s/it]Loading train:   9%|▊         | 21/247 [00:29<05:13,  1.39s/it]Loading train:   9%|▉         | 22/247 [00:30<05:08,  1.37s/it]Loading train:   9%|▉         | 23/247 [00:31<04:53,  1.31s/it]Loading train:  10%|▉         | 24/247 [00:33<05:09,  1.39s/it]Loading train:  10%|█         | 25/247 [00:35<05:21,  1.45s/it]Loading train:  11%|█         | 26/247 [00:36<05:08,  1.40s/it]Loading train:  11%|█         | 27/247 [00:37<04:56,  1.35s/it]Loading train:  11%|█▏        | 28/247 [00:39<05:10,  1.42s/it]Loading train:  12%|█▏        | 29/247 [00:40<05:22,  1.48s/it]Loading train:  12%|█▏        | 30/247 [00:42<05:28,  1.51s/it]Loading train:  13%|█▎        | 31/247 [00:43<05:09,  1.43s/it]Loading train:  13%|█▎        | 32/247 [00:45<05:24,  1.51s/it]Loading train:  13%|█▎        | 33/247 [00:46<05:13,  1.47s/it]Loading train:  14%|█▍        | 34/247 [00:48<05:11,  1.46s/it]Loading train:  14%|█▍        | 35/247 [00:49<05:03,  1.43s/it]Loading train:  15%|█▍        | 36/247 [00:50<04:53,  1.39s/it]Loading train:  15%|█▍        | 37/247 [00:51<04:28,  1.28s/it]Loading train:  15%|█▌        | 38/247 [00:53<04:53,  1.40s/it]Loading train:  16%|█▌        | 39/247 [00:54<04:31,  1.31s/it]Loading train:  16%|█▌        | 40/247 [00:55<04:27,  1.29s/it]Loading train:  17%|█▋        | 41/247 [00:57<04:25,  1.29s/it]Loading train:  17%|█▋        | 42/247 [00:58<04:56,  1.45s/it]Loading train:  17%|█▋        | 43/247 [01:00<04:50,  1.42s/it]Loading train:  18%|█▊        | 44/247 [01:01<04:49,  1.43s/it]Loading train:  18%|█▊        | 45/247 [01:02<04:23,  1.31s/it]Loading train:  19%|█▊        | 46/247 [01:04<04:23,  1.31s/it]Loading train:  19%|█▉        | 47/247 [01:05<04:33,  1.37s/it]Loading train:  19%|█▉        | 48/247 [01:06<04:31,  1.37s/it]Loading train:  20%|█▉        | 49/247 [01:07<04:13,  1.28s/it]Loading train:  20%|██        | 50/247 [01:09<04:21,  1.33s/it]Loading train:  21%|██        | 51/247 [01:10<04:19,  1.33s/it]Loading train:  21%|██        | 52/247 [01:12<04:22,  1.34s/it]Loading train:  21%|██▏       | 53/247 [01:13<04:22,  1.35s/it]Loading train:  22%|██▏       | 54/247 [01:14<04:14,  1.32s/it]Loading train:  22%|██▏       | 55/247 [01:16<04:12,  1.32s/it]Loading train:  23%|██▎       | 56/247 [01:17<04:25,  1.39s/it]Loading train:  23%|██▎       | 57/247 [01:18<04:18,  1.36s/it]Loading train:  23%|██▎       | 58/247 [01:20<04:24,  1.40s/it]Loading train:  24%|██▍       | 59/247 [01:21<04:20,  1.39s/it]Loading train:  24%|██▍       | 60/247 [01:23<04:19,  1.39s/it]Loading train:  25%|██▍       | 61/247 [01:24<04:30,  1.45s/it]Loading train:  25%|██▌       | 62/247 [01:26<04:17,  1.39s/it]Loading train:  26%|██▌       | 63/247 [01:27<04:14,  1.38s/it]Loading train:  26%|██▌       | 64/247 [01:28<04:07,  1.36s/it]Loading train:  26%|██▋       | 65/247 [01:29<04:04,  1.35s/it]Loading train:  27%|██▋       | 66/247 [01:31<04:01,  1.34s/it]Loading train:  27%|██▋       | 67/247 [01:33<04:23,  1.46s/it]Loading train:  28%|██▊       | 68/247 [01:34<04:15,  1.43s/it]Loading train:  28%|██▊       | 69/247 [01:36<04:33,  1.54s/it]Loading train:  28%|██▊       | 70/247 [01:37<04:06,  1.39s/it]Loading train:  29%|██▊       | 71/247 [01:38<04:00,  1.37s/it]Loading train:  29%|██▉       | 72/247 [01:39<03:58,  1.36s/it]Loading train:  30%|██▉       | 73/247 [01:40<03:39,  1.26s/it]Loading train:  30%|██▉       | 74/247 [01:42<03:53,  1.35s/it]Loading train:  30%|███       | 75/247 [01:43<03:49,  1.33s/it]Loading train:  31%|███       | 76/247 [01:44<03:26,  1.21s/it]Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Loading train:  31%|███       | 77/247 [01:46<03:54,  1.38s/it]Loading train:  32%|███▏      | 78/247 [01:48<04:15,  1.51s/it]Loading train:  32%|███▏      | 79/247 [01:49<04:17,  1.53s/it]Loading train:  32%|███▏      | 80/247 [01:52<04:49,  1.74s/it]Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Loading train:  33%|███▎      | 81/247 [01:54<04:58,  1.80s/it]Loading train:  33%|███▎      | 82/247 [01:55<04:57,  1.80s/it]Loading train:  34%|███▎      | 83/247 [01:56<04:17,  1.57s/it]Loading train:  34%|███▍      | 84/247 [01:58<04:16,  1.57s/it]Loading train:  34%|███▍      | 85/247 [02:00<04:25,  1.64s/it]Loading train:  35%|███▍      | 86/247 [02:01<04:16,  1.59s/it]Loading train:  35%|███▌      | 87/247 [02:03<04:22,  1.64s/it]Loading train:  36%|███▌      | 88/247 [02:04<04:11,  1.58s/it]Loading train:  36%|███▌      | 89/247 [02:06<03:51,  1.46s/it]Loading train:  36%|███▋      | 90/247 [02:07<03:34,  1.37s/it]Loading train:  37%|███▋      | 91/247 [02:08<03:33,  1.37s/it]Loading train:  37%|███▋      | 92/247 [02:10<03:36,  1.40s/it]Loading train:  38%|███▊      | 93/247 [02:11<03:39,  1.42s/it]Loading train:  38%|███▊      | 94/247 [02:13<03:43,  1.46s/it]Loading train:  38%|███▊      | 95/247 [02:14<03:39,  1.44s/it]Loading train:  39%|███▉      | 96/247 [02:15<03:34,  1.42s/it]Loading train:  39%|███▉      | 97/247 [02:17<03:56,  1.58s/it]Loading train:  40%|███▉      | 98/247 [02:19<04:02,  1.62s/it]Loading train:  40%|████      | 99/247 [02:21<04:00,  1.63s/it]Loading train:  40%|████      | 100/247 [02:22<03:51,  1.58s/it]Loading train:  41%|████      | 101/247 [02:24<03:46,  1.55s/it]Loading train:  41%|████▏     | 102/247 [02:25<03:55,  1.63s/it]Loading train:  42%|████▏     | 103/247 [02:27<03:55,  1.63s/it]Loading train:  42%|████▏     | 104/247 [02:29<03:48,  1.60s/it]Loading train:  43%|████▎     | 105/247 [02:30<03:47,  1.60s/it]Loading train:  43%|████▎     | 106/247 [02:32<03:39,  1.56s/it]Loading train:  43%|████▎     | 107/247 [02:33<03:35,  1.54s/it]Loading train:  44%|████▎     | 108/247 [02:35<03:32,  1.53s/it]Loading train:  44%|████▍     | 109/247 [02:36<03:31,  1.53s/it]Loading train:  45%|████▍     | 110/247 [02:37<03:14,  1.42s/it]Loading train:  45%|████▍     | 111/247 [02:39<03:11,  1.41s/it]Loading train:  45%|████▌     | 112/247 [02:40<03:01,  1.34s/it]Loading train:  46%|████▌     | 113/247 [02:41<03:01,  1.36s/it]Loading train:  46%|████▌     | 114/247 [02:43<02:52,  1.30s/it]Loading train:  47%|████▋     | 115/247 [02:44<02:43,  1.24s/it]Loading train:  47%|████▋     | 116/247 [02:45<02:42,  1.24s/it]Loading train:  47%|████▋     | 117/247 [02:46<02:50,  1.31s/it]Loading train:  48%|████▊     | 118/247 [02:48<02:55,  1.36s/it]Loading train:  48%|████▊     | 119/247 [02:50<03:07,  1.47s/it]Loading train:  49%|████▊     | 120/247 [02:51<02:54,  1.37s/it]Loading train:  49%|████▉     | 121/247 [02:52<03:06,  1.48s/it]Loading train:  49%|████▉     | 122/247 [02:54<03:16,  1.57s/it]Loading train:  50%|████▉     | 123/247 [02:56<03:05,  1.50s/it]Loading train:  50%|█████     | 124/247 [02:57<03:03,  1.49s/it]Loading train:  51%|█████     | 125/247 [02:59<03:05,  1.52s/it]Loading train:  51%|█████     | 126/247 [03:00<02:59,  1.48s/it]Loading train:  51%|█████▏    | 127/247 [03:01<02:48,  1.41s/it]Loading train:  52%|█████▏    | 128/247 [03:03<02:46,  1.40s/it]Loading train:  52%|█████▏    | 129/247 [03:04<02:45,  1.40s/it]Loading train:  53%|█████▎    | 130/247 [03:05<02:42,  1.39s/it]Loading train:  53%|█████▎    | 131/247 [03:07<02:39,  1.37s/it]Loading train:  53%|█████▎    | 132/247 [03:08<02:50,  1.48s/it]Loading train:  54%|█████▍    | 133/247 [03:10<02:44,  1.45s/it]Loading train:  54%|█████▍    | 134/247 [03:11<02:34,  1.37s/it]Loading train:  55%|█████▍    | 135/247 [03:12<02:37,  1.41s/it]Loading train:  55%|█████▌    | 136/247 [03:14<02:44,  1.49s/it]Loading train:  55%|█████▌    | 137/247 [03:16<02:40,  1.46s/it]Loading train:  56%|█████▌    | 138/247 [03:17<02:35,  1.42s/it]Loading train:  56%|█████▋    | 139/247 [03:19<02:40,  1.49s/it]Loading train:  57%|█████▋    | 140/247 [03:20<02:37,  1.47s/it]Loading train:  57%|█████▋    | 141/247 [03:21<02:27,  1.39s/it]Loading train:  57%|█████▋    | 142/247 [03:23<02:32,  1.45s/it]Loading train:  58%|█████▊    | 143/247 [03:24<02:29,  1.43s/it]Loading train:  58%|█████▊    | 144/247 [03:25<02:24,  1.40s/it]Loading train:  59%|█████▊    | 145/247 [03:27<02:26,  1.44s/it]Loading train:  59%|█████▉    | 146/247 [03:29<02:27,  1.46s/it]Loading train:  60%|█████▉    | 147/247 [03:29<02:11,  1.31s/it]Loading train:  60%|█████▉    | 148/247 [03:31<02:04,  1.26s/it]Loading train:  60%|██████    | 149/247 [03:32<02:02,  1.25s/it]Loading train:  61%|██████    | 150/247 [03:33<02:02,  1.26s/it]Loading train:  61%|██████    | 151/247 [03:34<01:59,  1.25s/it]Loading train:  62%|██████▏   | 152/247 [03:36<02:05,  1.32s/it]Loading train:  62%|██████▏   | 153/247 [03:37<02:05,  1.34s/it]Loading train:  62%|██████▏   | 154/247 [03:39<02:18,  1.49s/it]Loading train:  63%|██████▎   | 155/247 [03:40<02:06,  1.38s/it]Loading train:  63%|██████▎   | 156/247 [03:42<02:03,  1.36s/it]Loading train:  64%|██████▎   | 157/247 [03:43<02:02,  1.36s/it]Loading train:  64%|██████▍   | 158/247 [03:45<02:16,  1.54s/it]Loading train:  64%|██████▍   | 159/247 [03:46<02:04,  1.41s/it]Loading train:  65%|██████▍   | 160/247 [03:48<02:10,  1.50s/it]Loading train:  65%|██████▌   | 161/247 [03:49<02:11,  1.52s/it]Loading train:  66%|██████▌   | 162/247 [03:51<02:05,  1.48s/it]Loading train:  66%|██████▌   | 163/247 [03:52<02:04,  1.48s/it]Loading train:  66%|██████▋   | 164/247 [03:53<01:58,  1.43s/it]Loading train:  67%|██████▋   | 165/247 [03:55<01:55,  1.41s/it]Loading train:  67%|██████▋   | 166/247 [03:56<01:56,  1.44s/it]Loading train:  68%|██████▊   | 167/247 [03:58<02:01,  1.52s/it]Loading train:  68%|██████▊   | 168/247 [04:00<02:01,  1.54s/it]Loading train:  68%|██████▊   | 169/247 [04:01<01:52,  1.44s/it]Loading train:  69%|██████▉   | 170/247 [04:02<01:51,  1.45s/it]Loading train:  69%|██████▉   | 171/247 [04:04<01:48,  1.43s/it]Loading train:  70%|██████▉   | 172/247 [04:05<01:55,  1.54s/it]Loading train:  70%|███████   | 173/247 [04:07<01:55,  1.57s/it]Loading train:  70%|███████   | 174/247 [04:09<01:57,  1.61s/it]Loading train:  71%|███████   | 175/247 [04:11<02:08,  1.79s/it]Loading train:  71%|███████▏  | 176/247 [04:12<02:00,  1.70s/it]Loading train:  72%|███████▏  | 177/247 [04:14<01:54,  1.63s/it]Loading train:  72%|███████▏  | 178/247 [04:16<01:51,  1.62s/it]Loading train:  72%|███████▏  | 179/247 [04:17<01:39,  1.47s/it]Loading train:  73%|███████▎  | 180/247 [04:18<01:35,  1.43s/it]Loading train:  73%|███████▎  | 181/247 [04:20<01:36,  1.47s/it]Loading train:  74%|███████▎  | 182/247 [04:21<01:32,  1.43s/it]Loading train:  74%|███████▍  | 183/247 [04:22<01:29,  1.39s/it]Loading train:  74%|███████▍  | 184/247 [04:23<01:23,  1.32s/it]Loading train:  75%|███████▍  | 185/247 [04:25<01:24,  1.36s/it]Loading train:  75%|███████▌  | 186/247 [04:26<01:19,  1.30s/it]Loading train:  76%|███████▌  | 187/247 [04:28<01:28,  1.47s/it]Loading train:  76%|███████▌  | 188/247 [04:29<01:26,  1.47s/it]Loading train:  77%|███████▋  | 189/247 [04:30<01:20,  1.38s/it]Loading train:  77%|███████▋  | 190/247 [04:32<01:16,  1.35s/it]Loading train:  77%|███████▋  | 191/247 [04:33<01:14,  1.34s/it]Loading train:  78%|███████▊  | 192/247 [04:34<01:15,  1.37s/it]Loading train:  78%|███████▊  | 193/247 [04:36<01:16,  1.42s/it]Loading train:  79%|███████▊  | 194/247 [04:37<01:15,  1.43s/it]Loading train:  79%|███████▉  | 195/247 [04:39<01:20,  1.54s/it]Loading train:  79%|███████▉  | 196/247 [04:41<01:15,  1.47s/it]Loading train:  80%|███████▉  | 197/247 [04:42<01:17,  1.55s/it]Loading train:  80%|████████  | 198/247 [04:44<01:13,  1.49s/it]Loading train:  81%|████████  | 199/247 [04:45<01:12,  1.51s/it]Loading train:  81%|████████  | 200/247 [04:47<01:10,  1.49s/it]Loading train:  81%|████████▏ | 201/247 [04:48<01:07,  1.46s/it]Loading train:  82%|████████▏ | 202/247 [04:50<01:09,  1.54s/it]Loading train:  82%|████████▏ | 203/247 [04:51<01:09,  1.57s/it]Loading train:  83%|████████▎ | 204/247 [04:53<01:07,  1.57s/it]Loading train:  83%|████████▎ | 205/247 [04:54<01:01,  1.47s/it]Loading train:  83%|████████▎ | 206/247 [04:56<00:58,  1.42s/it]Loading train:  84%|████████▍ | 207/247 [04:57<00:52,  1.31s/it]Loading train:  84%|████████▍ | 208/247 [04:58<00:55,  1.43s/it]Loading train:  85%|████████▍ | 209/247 [05:00<00:55,  1.45s/it]Loading train:  85%|████████▌ | 210/247 [05:01<00:54,  1.47s/it]Loading train:  85%|████████▌ | 211/247 [05:03<00:55,  1.55s/it]Loading train:  86%|████████▌ | 212/247 [05:04<00:49,  1.43s/it]Loading train:  86%|████████▌ | 213/247 [05:06<00:49,  1.45s/it]Loading train:  87%|████████▋ | 214/247 [05:07<00:48,  1.48s/it]Loading train:  87%|████████▋ | 215/247 [05:08<00:43,  1.35s/it]Loading train:  87%|████████▋ | 216/247 [05:10<00:43,  1.41s/it]Loading train:  88%|████████▊ | 217/247 [05:11<00:42,  1.43s/it]Loading train:  88%|████████▊ | 218/247 [05:13<00:41,  1.44s/it]Loading train:  89%|████████▊ | 219/247 [05:14<00:39,  1.40s/it]Loading train:  89%|████████▉ | 220/247 [05:16<00:38,  1.44s/it]Loading train:  89%|████████▉ | 221/247 [05:17<00:36,  1.40s/it]Loading train:  90%|████████▉ | 222/247 [05:18<00:34,  1.38s/it]Loading train:  90%|█████████ | 223/247 [05:19<00:31,  1.33s/it]Loading train:  91%|█████████ | 224/247 [05:21<00:29,  1.30s/it]Loading train:  91%|█████████ | 225/247 [05:22<00:27,  1.24s/it]Loading train:  91%|█████████▏| 226/247 [05:23<00:26,  1.27s/it]Loading train:  92%|█████████▏| 227/247 [05:24<00:25,  1.26s/it]Loading train:  92%|█████████▏| 228/247 [05:26<00:25,  1.33s/it]Loading train:  93%|█████████▎| 229/247 [05:27<00:24,  1.37s/it]Loading train:  93%|█████████▎| 230/247 [05:29<00:22,  1.35s/it]Loading train:  94%|█████████▎| 231/247 [05:30<00:21,  1.36s/it]Loading train:  94%|█████████▍| 232/247 [05:31<00:20,  1.39s/it]Loading train:  94%|█████████▍| 233/247 [05:33<00:19,  1.37s/it]Loading train:  95%|█████████▍| 234/247 [05:34<00:18,  1.39s/it]Loading train:  95%|█████████▌| 235/247 [05:36<00:18,  1.53s/it]Loading train:  96%|█████████▌| 236/247 [05:37<00:16,  1.49s/it]Loading train:  96%|█████████▌| 237/247 [05:39<00:14,  1.40s/it]Loading train:  96%|█████████▋| 238/247 [05:40<00:12,  1.43s/it]Loading train:  97%|█████████▋| 239/247 [05:42<00:11,  1.50s/it]Loading train:  97%|█████████▋| 240/247 [05:43<00:09,  1.37s/it]Loading train:  98%|█████████▊| 241/247 [05:44<00:07,  1.31s/it]Loading train:  98%|█████████▊| 242/247 [05:45<00:06,  1.33s/it]Loading train:  98%|█████████▊| 243/247 [05:47<00:05,  1.43s/it]Loading train:  99%|█████████▉| 244/247 [05:49<00:04,  1.58s/it]Loading train:  99%|█████████▉| 245/247 [05:51<00:03,  1.61s/it]Loading train: 100%|█████████▉| 246/247 [05:52<00:01,  1.61s/it]Loading train: 100%|██████████| 247/247 [05:54<00:00,  1.54s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/247 [00:00<00:14, 16.75it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:12, 19.46it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:10, 22.91it/s]concatenating: train:   6%|▌         | 14/247 [00:00<00:11, 21.18it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:12, 18.01it/s]concatenating: train:   9%|▉         | 22/247 [00:00<00:09, 22.59it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:07, 28.08it/s]concatenating: train:  15%|█▍        | 37/247 [00:01<00:06, 34.33it/s]concatenating: train:  17%|█▋        | 42/247 [00:01<00:05, 34.81it/s]concatenating: train:  19%|█▉        | 47/247 [00:01<00:06, 32.04it/s]concatenating: train:  22%|██▏       | 54/247 [00:01<00:05, 38.26it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:03, 48.89it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 53.14it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:03, 40.97it/s]concatenating: train:  37%|███▋      | 92/247 [00:02<00:03, 45.66it/s]concatenating: train:  40%|████      | 99/247 [00:02<00:02, 50.10it/s]concatenating: train:  43%|████▎     | 106/247 [00:02<00:02, 54.77it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:03, 41.02it/s]concatenating: train:  49%|████▉     | 122/247 [00:02<00:02, 48.28it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 52.28it/s]concatenating: train:  55%|█████▌    | 136/247 [00:02<00:02, 54.46it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:01, 53.85it/s]concatenating: train:  61%|██████    | 151/247 [00:03<00:02, 35.95it/s]concatenating: train:  64%|██████▍   | 158/247 [00:03<00:02, 41.49it/s]concatenating: train:  66%|██████▋   | 164/247 [00:03<00:01, 45.68it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:02, 38.34it/s]concatenating: train:  71%|███████▏  | 176/247 [00:03<00:01, 41.88it/s]concatenating: train:  74%|███████▍  | 183/247 [00:04<00:01, 47.23it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 50.97it/s]concatenating: train:  80%|███████▉  | 197/247 [00:04<00:00, 55.49it/s]concatenating: train:  83%|████████▎ | 204/247 [00:04<00:00, 44.48it/s]concatenating: train:  85%|████████▌ | 210/247 [00:04<00:00, 41.62it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 46.25it/s]concatenating: train:  90%|█████████ | 223/247 [00:04<00:00, 43.12it/s]concatenating: train:  92%|█████████▏| 228/247 [00:05<00:00, 35.24it/s]concatenating: train:  95%|█████████▌| 235/247 [00:05<00:00, 41.39it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 47.28it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:07,  1.91s/it]Loading test:  40%|████      | 2/5 [00:03<00:05,  1.93s/it]Loading test:  60%|██████    | 3/5 [00:05<00:03,  1.88s/it]Loading test:  80%|████████  | 4/5 [00:07<00:01,  1.76s/it]Loading test: 100%|██████████| 5/5 [00:09<00:00,  1.94s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00, 29.16it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 32.53it/s]
2019-09-01 16:02:24.895182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-09-01 16:02:24.895284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-01 16:02:24.895308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-09-01 16:02:24.895322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-09-01 16:02:24.895797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.19it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.38it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.08it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.37it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.94it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.79it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.87it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.78it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.33it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.19it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.30it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.42it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.30it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.12it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.13it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.57it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.22it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.90it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.32it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 49,153
Non-trainable params: 174,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.13811226e-02 3.09606972e-02 7.74847635e-02 9.43756021e-03
 2.81210625e-02 7.11727631e-03 9.30702995e-02 1.14616485e-01
 8.86750504e-02 1.28613563e-02 2.89506074e-01 1.86505532e-01
 2.62719778e-04]
Train on 8459 samples, validate on 169 samples
Epoch 1/300
 - 16s - loss: 2.4864 - acc: 0.7530 - mDice: 0.1339 - val_loss: 2.0896 - val_acc: 0.8841 - val_mDice: 0.2615

Epoch 00001: val_mDice improved from -inf to 0.26154, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 0.9817 - acc: 0.8919 - mDice: 0.3680 - val_loss: 1.6337 - val_acc: 0.8754 - val_mDice: 0.3747

Epoch 00002: val_mDice improved from 0.26154 to 0.37469, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.7068 - acc: 0.9088 - mDice: 0.4807 - val_loss: 1.6008 - val_acc: 0.9181 - val_mDice: 0.4943

Epoch 00003: val_mDice improved from 0.37469 to 0.49425, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.5791 - acc: 0.9191 - mDice: 0.5457 - val_loss: 1.4027 - val_acc: 0.9271 - val_mDice: 0.5358

Epoch 00004: val_mDice improved from 0.49425 to 0.53579, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5207 - acc: 0.9244 - mDice: 0.5796 - val_loss: 1.4177 - val_acc: 0.9307 - val_mDice: 0.5370

Epoch 00005: val_mDice improved from 0.53579 to 0.53702, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.4877 - acc: 0.9276 - mDice: 0.6001 - val_loss: 1.4493 - val_acc: 0.9193 - val_mDice: 0.5202

Epoch 00006: val_mDice did not improve from 0.53702
Epoch 7/300
 - 8s - loss: 0.4730 - acc: 0.9286 - mDice: 0.6102 - val_loss: 1.6969 - val_acc: 0.9183 - val_mDice: 0.3815

Epoch 00007: val_mDice did not improve from 0.53702
Epoch 8/300
 - 8s - loss: 0.4489 - acc: 0.9307 - mDice: 0.6249 - val_loss: 1.2894 - val_acc: 0.9363 - val_mDice: 0.5514

Epoch 00008: val_mDice improved from 0.53702 to 0.55141, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4337 - acc: 0.9323 - mDice: 0.6359 - val_loss: 1.0219 - val_acc: 0.9277 - val_mDice: 0.5267

Epoch 00009: val_mDice did not improve from 0.55141
Epoch 10/300
 - 9s - loss: 0.4261 - acc: 0.9322 - mDice: 0.6386 - val_loss: 1.0710 - val_acc: 0.9340 - val_mDice: 0.5610

Epoch 00010: val_mDice improved from 0.55141 to 0.56104, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 8s - loss: 0.4104 - acc: 0.9340 - mDice: 0.6501 - val_loss: 1.2291 - val_acc: 0.9372 - val_mDice: 0.5738

Epoch 00011: val_mDice improved from 0.56104 to 0.57375, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 8s - loss: 0.4033 - acc: 0.9343 - mDice: 0.6536 - val_loss: 1.2136 - val_acc: 0.9345 - val_mDice: 0.5724

Epoch 00012: val_mDice did not improve from 0.57375
Epoch 13/300
 - 8s - loss: 0.3953 - acc: 0.9351 - mDice: 0.6590 - val_loss: 1.0494 - val_acc: 0.9362 - val_mDice: 0.5830

Epoch 00013: val_mDice improved from 0.57375 to 0.58296, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.3887 - acc: 0.9357 - mDice: 0.6634 - val_loss: 1.0589 - val_acc: 0.9340 - val_mDice: 0.5718

Epoch 00014: val_mDice did not improve from 0.58296
Epoch 15/300
 - 8s - loss: 0.3848 - acc: 0.9360 - mDice: 0.6669 - val_loss: 1.3436 - val_acc: 0.9367 - val_mDice: 0.5717

Epoch 00015: val_mDice did not improve from 0.58296
Epoch 16/300
 - 8s - loss: 0.3841 - acc: 0.9359 - mDice: 0.6669 - val_loss: 1.3631 - val_acc: 0.9067 - val_mDice: 0.4965

Epoch 00016: val_mDice did not improve from 0.58296
Epoch 17/300
 - 8s - loss: 0.4413 - acc: 0.9325 - mDice: 0.6322 - val_loss: 0.9825 - val_acc: 0.9323 - val_mDice: 0.5545

Epoch 00017: val_mDice did not improve from 0.58296
Epoch 18/300
 - 9s - loss: 0.3919 - acc: 0.9357 - mDice: 0.6613 - val_loss: 1.1326 - val_acc: 0.9359 - val_mDice: 0.5852

Epoch 00018: val_mDice improved from 0.58296 to 0.58521, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 8s - loss: 0.3827 - acc: 0.9365 - mDice: 0.6682 - val_loss: 0.9154 - val_acc: 0.9306 - val_mDice: 0.5567

Epoch 00019: val_mDice did not improve from 0.58521
Epoch 20/300
 - 8s - loss: 0.3722 - acc: 0.9373 - mDice: 0.6746 - val_loss: 1.2205 - val_acc: 0.9384 - val_mDice: 0.5835

Epoch 00020: val_mDice did not improve from 0.58521
Epoch 21/300
 - 8s - loss: 0.3696 - acc: 0.9377 - mDice: 0.6785 - val_loss: 1.4085 - val_acc: 0.9320 - val_mDice: 0.5175

Epoch 00021: val_mDice did not improve from 0.58521
Epoch 22/300
 - 8s - loss: 0.3683 - acc: 0.9375 - mDice: 0.6775 - val_loss: 1.3213 - val_acc: 0.9403 - val_mDice: 0.5690

Epoch 00022: val_mDice did not improve from 0.58521
Epoch 23/300
 - 8s - loss: 0.3580 - acc: 0.9383 - mDice: 0.6844 - val_loss: 1.1005 - val_acc: 0.9361 - val_mDice: 0.5790

Epoch 00023: val_mDice did not improve from 0.58521
Epoch 24/300
 - 8s - loss: 0.3537 - acc: 0.9387 - mDice: 0.6875 - val_loss: 1.1932 - val_acc: 0.9281 - val_mDice: 0.5522

Epoch 00024: val_mDice did not improve from 0.58521
Epoch 25/300
 - 8s - loss: 0.3928 - acc: 0.9361 - mDice: 0.6641 - val_loss: 1.3206 - val_acc: 0.9357 - val_mDice: 0.5834

Epoch 00025: val_mDice did not improve from 0.58521
Epoch 26/300
 - 8s - loss: 0.3843 - acc: 0.9354 - mDice: 0.6682 - val_loss: 7.4806 - val_acc: 0.8911 - val_mDice: 0.1520

Epoch 00026: val_mDice did not improve from 0.58521
Epoch 27/300
 - 8s - loss: 0.4112 - acc: 0.9333 - mDice: 0.6490 - val_loss: 1.1524 - val_acc: 0.9351 - val_mDice: 0.5911

Epoch 00027: val_mDice improved from 0.58521 to 0.59114, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 8s - loss: 0.3651 - acc: 0.9376 - mDice: 0.6806 - val_loss: 1.0899 - val_acc: 0.9231 - val_mDice: 0.5700

Epoch 00028: val_mDice did not improve from 0.59114
Epoch 29/300
 - 8s - loss: 0.3577 - acc: 0.9386 - mDice: 0.6886 - val_loss: 1.2676 - val_acc: 0.9173 - val_mDice: 0.5341

Epoch 00029: val_mDice did not improve from 0.59114
Epoch 30/300
 - 8s - loss: 0.4089 - acc: 0.9341 - mDice: 0.6528 - val_loss: 1.2296 - val_acc: 0.9343 - val_mDice: 0.5815

Epoch 00030: val_mDice did not improve from 0.59114
Epoch 31/300
 - 8s - loss: 0.3580 - acc: 0.9382 - mDice: 0.6854 - val_loss: 1.2161 - val_acc: 0.9211 - val_mDice: 0.5550

Epoch 00031: val_mDice did not improve from 0.59114
Epoch 32/300
 - 9s - loss: 0.3852 - acc: 0.9353 - mDice: 0.6664 - val_loss: 1.1875 - val_acc: 0.9305 - val_mDice: 0.5712

Epoch 00032: val_mDice did not improve from 0.59114
Epoch 33/300
 - 8s - loss: 0.3518 - acc: 0.9387 - mDice: 0.6900 - val_loss: 1.1673 - val_acc: 0.9295 - val_mDice: 0.5822

Epoch 00033: val_mDice did not improve from 0.59114
Epoch 34/300
 - 9s - loss: 0.3465 - acc: 0.9392 - mDice: 0.6930 - val_loss: 1.1430 - val_acc: 0.9353 - val_mDice: 0.5830

Epoch 00034: val_mDice did not improve from 0.59114
Epoch 35/300
 - 9s - loss: 0.3445 - acc: 0.9395 - mDice: 0.6963 - val_loss: 1.1947 - val_acc: 0.9348 - val_mDice: 0.5827

Epoch 00035: val_mDice did not improve from 0.59114
Epoch 36/300
 - 9s - loss: 0.3419 - acc: 0.9398 - mDice: 0.6974 - val_loss: 1.2322 - val_acc: 0.9362 - val_mDice: 0.5920

Epoch 00036: val_mDice improved from 0.59114 to 0.59199, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 8s - loss: 0.3408 - acc: 0.9400 - mDice: 0.6989 - val_loss: 1.3459 - val_acc: 0.9352 - val_mDice: 0.5372

Epoch 00037: val_mDice did not improve from 0.59199
Epoch 38/300
 - 8s - loss: 0.3652 - acc: 0.9380 - mDice: 0.6830 - val_loss: 1.2777 - val_acc: 0.9354 - val_mDice: 0.5663

Epoch 00038: val_mDice did not improve from 0.59199
Epoch 39/300
 - 8s - loss: 0.4110 - acc: 0.9336 - mDice: 0.6507 - val_loss: 1.0856 - val_acc: 0.9340 - val_mDice: 0.5804

Epoch 00039: val_mDice did not improve from 0.59199
Epoch 40/300
 - 8s - loss: 0.3591 - acc: 0.9387 - mDice: 0.6864 - val_loss: 1.2311 - val_acc: 0.9362 - val_mDice: 0.5859

Epoch 00040: val_mDice did not improve from 0.59199
Epoch 41/300
 - 8s - loss: 0.3539 - acc: 0.9389 - mDice: 0.6880 - val_loss: 1.1375 - val_acc: 0.9324 - val_mDice: 0.5845

Epoch 00041: val_mDice did not improve from 0.59199
Epoch 42/300
 - 8s - loss: 0.3445 - acc: 0.9397 - mDice: 0.6945 - val_loss: 1.5869 - val_acc: 0.9167 - val_mDice: 0.4836

Epoch 00042: val_mDice did not improve from 0.59199
Epoch 43/300
 - 8s - loss: 0.4663 - acc: 0.9285 - mDice: 0.6207 - val_loss: 1.2420 - val_acc: 0.9253 - val_mDice: 0.5622

Epoch 00043: val_mDice did not improve from 0.59199
Epoch 44/300
 - 8s - loss: 0.3661 - acc: 0.9379 - mDice: 0.6812 - val_loss: 1.2008 - val_acc: 0.9306 - val_mDice: 0.5688

Epoch 00044: val_mDice did not improve from 0.59199
Epoch 45/300
 - 8s - loss: 0.3539 - acc: 0.9390 - mDice: 0.6896 - val_loss: 1.1915 - val_acc: 0.9343 - val_mDice: 0.5812

Epoch 00045: val_mDice did not improve from 0.59199
Epoch 46/300
 - 8s - loss: 0.3449 - acc: 0.9396 - mDice: 0.6948 - val_loss: 1.2732 - val_acc: 0.9372 - val_mDice: 0.5798

Epoch 00046: val_mDice did not improve from 0.59199
Epoch 47/300
 - 8s - loss: 0.3406 - acc: 0.9402 - mDice: 0.6990 - val_loss: 1.1999 - val_acc: 0.9369 - val_mDice: 0.5893

Epoch 00047: val_mDice did not improve from 0.59199
Epoch 48/300
 - 8s - loss: 0.3373 - acc: 0.9405 - mDice: 0.7014 - val_loss: 1.1101 - val_acc: 0.9175 - val_mDice: 0.5531

Epoch 00048: val_mDice did not improve from 0.59199
Epoch 49/300
 - 9s - loss: 0.3547 - acc: 0.9384 - mDice: 0.6877 - val_loss: 1.2757 - val_acc: 0.9367 - val_mDice: 0.5904

Epoch 00049: val_mDice did not improve from 0.59199
Epoch 50/300
 - 8s - loss: 0.3309 - acc: 0.9406 - mDice: 0.7042 - val_loss: 1.2341 - val_acc: 0.9375 - val_mDice: 0.5838

Epoch 00050: val_mDice did not improve from 0.59199
Epoch 51/300
 - 9s - loss: 0.4036 - acc: 0.9353 - mDice: 0.6626 - val_loss: 1.3751 - val_acc: 0.9366 - val_mDice: 0.5663

Epoch 00051: val_mDice did not improve from 0.59199
Epoch 52/300
 - 9s - loss: 0.3530 - acc: 0.9387 - mDice: 0.6887 - val_loss: 1.2872 - val_acc: 0.9310 - val_mDice: 0.5803

Epoch 00052: val_mDice did not improve from 0.59199
Epoch 53/300
 - 8s - loss: 0.3370 - acc: 0.9402 - mDice: 0.6999 - val_loss: 1.2190 - val_acc: 0.9362 - val_mDice: 0.5867

Epoch 00053: val_mDice did not improve from 0.59199
Epoch 54/300
 - 8s - loss: 0.3303 - acc: 0.9407 - mDice: 0.7047 - val_loss: 1.1841 - val_acc: 0.9365 - val_mDice: 0.5879

Epoch 00054: val_mDice did not improve from 0.59199
Epoch 55/300
 - 7s - loss: 0.3320 - acc: 0.9408 - mDice: 0.7062 - val_loss: 1.1860 - val_acc: 0.9359 - val_mDice: 0.5807

Epoch 00055: val_mDice did not improve from 0.59199
Epoch 56/300
 - 7s - loss: 0.3383 - acc: 0.9400 - mDice: 0.6991 - val_loss: 1.2461 - val_acc: 0.9389 - val_mDice: 0.5922

Epoch 00056: val_mDice improved from 0.59199 to 0.59218, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 57/300
 - 8s - loss: 0.3277 - acc: 0.9410 - mDice: 0.7077 - val_loss: 1.1951 - val_acc: 0.9337 - val_mDice: 0.5839

Epoch 00057: val_mDice did not improve from 0.59218
Epoch 58/300
 - 8s - loss: 0.3284 - acc: 0.9410 - mDice: 0.7079 - val_loss: 1.2729 - val_acc: 0.9345 - val_mDice: 0.5864

Epoch 00058: val_mDice did not improve from 0.59218
Epoch 59/300
 - 7s - loss: 0.3494 - acc: 0.9381 - mDice: 0.6913 - val_loss: 1.2841 - val_acc: 0.9376 - val_mDice: 0.5890

Epoch 00059: val_mDice did not improve from 0.59218
Epoch 60/300
 - 7s - loss: 0.3238 - acc: 0.9410 - mDice: 0.7094 - val_loss: 1.2714 - val_acc: 0.9377 - val_mDice: 0.5915

Epoch 00060: val_mDice did not improve from 0.59218
Epoch 61/300
 - 8s - loss: 0.3198 - acc: 0.9414 - mDice: 0.7124 - val_loss: 1.1949 - val_acc: 0.9358 - val_mDice: 0.5894

Epoch 00061: val_mDice did not improve from 0.59218
Epoch 62/300
 - 7s - loss: 0.3188 - acc: 0.9415 - mDice: 0.7131 - val_loss: 1.3291 - val_acc: 0.9360 - val_mDice: 0.5767

Epoch 00062: val_mDice did not improve from 0.59218
Epoch 63/300
 - 8s - loss: 0.3159 - acc: 0.9417 - mDice: 0.7152 - val_loss: 1.1981 - val_acc: 0.9363 - val_mDice: 0.5868

Epoch 00063: val_mDice did not improve from 0.59218
Epoch 64/300
 - 8s - loss: 0.3136 - acc: 0.9418 - mDice: 0.7171 - val_loss: 1.2790 - val_acc: 0.9389 - val_mDice: 0.5914

Epoch 00064: val_mDice did not improve from 0.59218
Epoch 65/300
 - 8s - loss: 0.3127 - acc: 0.9419 - mDice: 0.7184 - val_loss: 1.1997 - val_acc: 0.9350 - val_mDice: 0.5856

Epoch 00065: val_mDice did not improve from 0.59218
Epoch 66/300
 - 7s - loss: 0.3154 - acc: 0.9416 - mDice: 0.7159 - val_loss: 1.4922 - val_acc: 0.9379 - val_mDice: 0.5378

Epoch 00066: val_mDice did not improve from 0.59218
Epoch 67/300
 - 7s - loss: 0.3754 - acc: 0.9368 - mDice: 0.6742 - val_loss: 1.1588 - val_acc: 0.9314 - val_mDice: 0.5682

Epoch 00067: val_mDice did not improve from 0.59218
Epoch 68/300
 - 7s - loss: 0.3275 - acc: 0.9409 - mDice: 0.7084 - val_loss: 1.2946 - val_acc: 0.9344 - val_mDice: 0.5782

Epoch 00068: val_mDice did not improve from 0.59218
Epoch 69/300
 - 7s - loss: 0.3201 - acc: 0.9415 - mDice: 0.7122 - val_loss: 1.1238 - val_acc: 0.9373 - val_mDice: 0.5650

Epoch 00069: val_mDice did not improve from 0.59218
Epoch 70/300
 - 8s - loss: 0.3201 - acc: 0.9414 - mDice: 0.7131 - val_loss: 1.1262 - val_acc: 0.9395 - val_mDice: 0.5765

Epoch 00070: val_mDice did not improve from 0.59218
Epoch 71/300
 - 8s - loss: 0.3147 - acc: 0.9418 - mDice: 0.7162 - val_loss: 1.1845 - val_acc: 0.9389 - val_mDice: 0.5823

Epoch 00071: val_mDice did not improve from 0.59218
Epoch 72/300
 - 7s - loss: 0.3146 - acc: 0.9421 - mDice: 0.7178 - val_loss: 1.2472 - val_acc: 0.9374 - val_mDice: 0.5834

Epoch 00072: val_mDice did not improve from 0.59218
Epoch 73/300
 - 7s - loss: 0.3128 - acc: 0.9422 - mDice: 0.7195 - val_loss: 1.3118 - val_acc: 0.9307 - val_mDice: 0.5745

Epoch 00073: val_mDice did not improve from 0.59218
Epoch 74/300
 - 7s - loss: 0.3099 - acc: 0.9423 - mDice: 0.7196 - val_loss: 1.2877 - val_acc: 0.9360 - val_mDice: 0.5788

Epoch 00074: val_mDice did not improve from 0.59218
Epoch 75/300
 - 7s - loss: 0.3090 - acc: 0.9424 - mDice: 0.7215 - val_loss: 1.2866 - val_acc: 0.9332 - val_mDice: 0.5771

Epoch 00075: val_mDice did not improve from 0.59218
Epoch 76/300
 - 7s - loss: 0.3066 - acc: 0.9425 - mDice: 0.7223 - val_loss: 1.3015 - val_acc: 0.9274 - val_mDice: 0.5693

Epoch 00076: val_mDice did not improve from 0.59218
Epoch 77/300
 - 8s - loss: 0.3065 - acc: 0.9427 - mDice: 0.7223 - val_loss: 1.3312 - val_acc: 0.9311 - val_mDice: 0.5719

Epoch 00077: val_mDice did not improve from 0.59218
Epoch 78/300
 - 8s - loss: 0.3061 - acc: 0.9429 - mDice: 0.7227 - val_loss: 1.3234 - val_acc: 0.9339 - val_mDice: 0.5734

Epoch 00078: val_mDice did not improve from 0.59218
Epoch 79/300
 - 9s - loss: 0.3022 - acc: 0.9431 - mDice: 0.7255 - val_loss: 1.1508 - val_acc: 0.9318 - val_mDice: 0.5738

Epoch 00079: val_mDice did not improve from 0.59218
Epoch 80/300
 - 8s - loss: 0.3015 - acc: 0.9431 - mDice: 0.7259 - val_loss: 1.3064 - val_acc: 0.9357 - val_mDice: 0.5795

Epoch 00080: val_mDice did not improve from 0.59218
Epoch 81/300
 - 9s - loss: 0.3032 - acc: 0.9432 - mDice: 0.7249 - val_loss: 1.1781 - val_acc: 0.9374 - val_mDice: 0.5691

Epoch 00081: val_mDice did not improve from 0.59218
Epoch 82/300
 - 9s - loss: 0.3052 - acc: 0.9433 - mDice: 0.7257 - val_loss: 1.9001 - val_acc: 0.9165 - val_mDice: 0.3492

Epoch 00082: val_mDice did not improve from 0.59218
Epoch 83/300
 - 8s - loss: 0.3789 - acc: 0.9354 - mDice: 0.6729 - val_loss: 1.1756 - val_acc: 0.9225 - val_mDice: 0.5507

Epoch 00083: val_mDice did not improve from 0.59218
Epoch 84/300
 - 8s - loss: 0.3213 - acc: 0.9417 - mDice: 0.7132 - val_loss: 1.1698 - val_acc: 0.9243 - val_mDice: 0.5587

Epoch 00084: val_mDice did not improve from 0.59218
Epoch 85/300
 - 8s - loss: 0.3100 - acc: 0.9426 - mDice: 0.7208 - val_loss: 1.1750 - val_acc: 0.9275 - val_mDice: 0.5623

Epoch 00085: val_mDice did not improve from 0.59218
Epoch 86/300
 - 9s - loss: 0.3054 - acc: 0.9429 - mDice: 0.7231 - val_loss: 1.2221 - val_acc: 0.9289 - val_mDice: 0.5672

Epoch 00086: val_mDice did not improve from 0.59218
Epoch 87/300
 - 8s - loss: 0.3067 - acc: 0.9431 - mDice: 0.7241 - val_loss: 1.1438 - val_acc: 0.9328 - val_mDice: 0.5603

Epoch 00087: val_mDice did not improve from 0.59218
Epoch 88/300
 - 8s - loss: 0.3215 - acc: 0.9418 - mDice: 0.7120 - val_loss: 1.2068 - val_acc: 0.9207 - val_mDice: 0.5452

Epoch 00088: val_mDice did not improve from 0.59218
Epoch 89/300
 - 9s - loss: 0.3208 - acc: 0.9417 - mDice: 0.7120 - val_loss: 1.1371 - val_acc: 0.9382 - val_mDice: 0.5769

Epoch 00089: val_mDice did not improve from 0.59218
Epoch 90/300
 - 8s - loss: 0.3041 - acc: 0.9432 - mDice: 0.7242 - val_loss: 1.1426 - val_acc: 0.9364 - val_mDice: 0.5768

Epoch 00090: val_mDice did not improve from 0.59218
Epoch 91/300
 - 9s - loss: 0.3104 - acc: 0.9435 - mDice: 0.7255 - val_loss: 1.1513 - val_acc: 0.9337 - val_mDice: 0.5719

Epoch 00091: val_mDice did not improve from 0.59218
Epoch 92/300
 - 8s - loss: 0.3024 - acc: 0.9436 - mDice: 0.7287 - val_loss: 1.1897 - val_acc: 0.9240 - val_mDice: 0.5546

Epoch 00092: val_mDice did not improve from 0.59218
Epoch 93/300
 - 8s - loss: 0.3099 - acc: 0.9430 - mDice: 0.7217 - val_loss: 1.2780 - val_acc: 0.9214 - val_mDice: 0.5461

Epoch 00093: val_mDice did not improve from 0.59218
Epoch 94/300
 - 8s - loss: 0.3766 - acc: 0.9366 - mDice: 0.6728 - val_loss: 1.1458 - val_acc: 0.9347 - val_mDice: 0.5771

Epoch 00094: val_mDice did not improve from 0.59218
Epoch 95/300
 - 8s - loss: 0.3198 - acc: 0.9420 - mDice: 0.7129 - val_loss: 1.1587 - val_acc: 0.9340 - val_mDice: 0.5729

Epoch 00095: val_mDice did not improve from 0.59218
Epoch 96/300
 - 9s - loss: 0.3102 - acc: 0.9427 - mDice: 0.7192 - val_loss: 1.1614 - val_acc: 0.9325 - val_mDice: 0.5725

Epoch 00096: val_mDice did not improve from 0.59218
Restoring model weights from the end of the best epoch
Epoch 00096: early stopping
{'val_loss': [2.089646361988677, 1.633717014944765, 1.6008489886684532, 1.4026916919375312, 1.417733261571128, 1.4493168754690497, 1.696906216751189, 1.2894161248348168, 1.0218856994216965, 1.0710060458916884, 1.2291070670771176, 1.2135614001539332, 1.0493837665524004, 1.058918703237229, 1.3435730419215366, 1.3630689904534605, 0.9824876940462011, 1.132565640838894, 0.9153880558070346, 1.220456569505161, 1.408451124055851, 1.321330602705126, 1.1005369364862612, 1.1931628521377518, 1.3206475546374123, 7.480647363606289, 1.1524007570814099, 1.0898970640622652, 1.2675679326057434, 1.229623421056736, 1.2161127882596303, 1.1874774966014208, 1.1673046572673955, 1.1430251623046468, 1.1946943402290344, 1.2321695868785565, 1.3458639661941303, 1.2776933375900315, 1.0855635200026472, 1.2310717765396164, 1.1375277077657937, 1.5869297889562755, 1.2419514232838647, 1.2007883035925013, 1.191486661603465, 1.27321043063903, 1.1999268824532188, 1.110147085415541, 1.275726781088925, 1.234091315749129, 1.3751066337675737, 1.287247651074765, 1.2190075573131178, 1.1841348021693483, 1.1860334605154907, 1.2460820082376693, 1.195115350054566, 1.2729399701547341, 1.2840523825594659, 1.271427441630843, 1.1948918950628247, 1.3290873374459307, 1.1981321023060725, 1.279042150494615, 1.1996550940902981, 1.4921951600785792, 1.1588215369444628, 1.294554565432509, 1.1237958595597533, 1.126201727333859, 1.1845348064716046, 1.247240276731683, 1.3118117758508265, 1.2877290996574087, 1.2865704636602007, 1.3015089401831994, 1.3312104869876387, 1.3234474895268502, 1.1507782502287238, 1.3064172447785822, 1.1781332968960148, 1.9001222009489522, 1.175560376700565, 1.1698194206113646, 1.1750232972336945, 1.2220588580391112, 1.1438092123827286, 1.20678765780827, 1.1371405107029797, 1.1425517970288293, 1.151270086595998, 1.189700352369681, 1.2779966688015052, 1.1458202187831585, 1.158664897701444, 1.1614338462874734], 'val_acc': [0.8840775824862824, 0.8754334865942509, 0.9181202209207433, 0.9271043225152958, 0.9306630435779956, 0.9192879432757225, 0.9183031038419734, 0.9363052026759944, 0.9277098605618674, 0.9340320800888468, 0.9371613239395548, 0.9344804607904874, 0.9362157823066034, 0.9339657044975009, 0.936684480432928, 0.9066773843483107, 0.9323292455729648, 0.9359421285651844, 0.9305763332801458, 0.9384211693289717, 0.931990585736269, 0.9403447910878785, 0.9360721866054648, 0.9281230329056464, 0.9357226963579302, 0.8911014943433231, 0.9350846427432179, 0.9230891240419016, 0.9173155617431776, 0.9343084111016178, 0.9210706536586468, 0.9305424651450659, 0.9294763475480164, 0.9353460789432188, 0.9348258954533458, 0.9361669890273957, 0.935202491706645, 0.935407034038792, 0.9340279980524052, 0.9362144413784411, 0.9323861507269052, 0.9167465888536893, 0.9252890884523561, 0.9306047555257583, 0.9342840313911438, 0.9371979134322623, 0.9369418730397197, 0.9174916497349034, 0.9367075121614354, 0.9375460659258464, 0.9366303110969137, 0.9310342151032397, 0.9362360824494672, 0.9364772280292398, 0.9358906735329938, 0.9388628044777368, 0.933686624264576, 0.9345468374399039, 0.937638180143029, 0.9376639025451163, 0.9358026254811936, 0.9360424057971797, 0.9362970643494961, 0.9389007239652103, 0.9350155563749505, 0.9378874192576436, 0.9314175794815877, 0.9344154254219236, 0.9373266012710932, 0.939465625046273, 0.9388912429470988, 0.9374105852736524, 0.9307402474640389, 0.9360220612153499, 0.9332165640486768, 0.9274362325668335, 0.9311182022800107, 0.9339318229601934, 0.9317941782037182, 0.93565087981478, 0.9374336314624583, 0.916453981187922, 0.9224903527096179, 0.924315091773603, 0.9275364473726623, 0.9289466647001413, 0.9328318248839068, 0.9206927101287616, 0.9382152497415712, 0.9364271185101842, 0.9336568159464549, 0.9239750709054033, 0.9213781832943301, 0.9347364814323786, 0.9340429016824304, 0.9325405754281219], 'val_mDice': [0.2615431317034558, 0.3746914721628618, 0.49425386906375546, 0.5357872117200547, 0.5370150296645757, 0.5201883245501998, 0.3815248106005629, 0.5514067175120292, 0.5267161984415449, 0.5610431235217483, 0.5737536725913279, 0.5723728858507596, 0.5829586587714021, 0.5717717403843559, 0.5716801086473747, 0.49647006921514253, 0.5545280157814364, 0.5852143757442045, 0.5567108468543849, 0.5834956020998532, 0.5175363615419738, 0.5690356060950714, 0.5790189799119735, 0.5522412775888951, 0.5834257279980112, 0.15195012401194263, 0.5911364641767987, 0.5699934137643442, 0.534127169283184, 0.581468132473308, 0.554958992455838, 0.5712469636335881, 0.5821511062997333, 0.5829645927841142, 0.5827436850973841, 0.5919914071023817, 0.537219425101252, 0.5663437756913654, 0.5803526326044072, 0.5859322286921845, 0.5845266910347008, 0.4836436275547073, 0.5621657801803047, 0.5687839663945712, 0.5812245565053273, 0.5797701150002564, 0.5893386091000935, 0.5530694952377906, 0.5904315583099274, 0.5837535895186768, 0.5662772713680945, 0.5802971117595244, 0.5866689710222053, 0.5878976191994707, 0.580664153282459, 0.5921762310541593, 0.583873495195039, 0.586358891083644, 0.5890345051443788, 0.5915256657543972, 0.5893567751145222, 0.576720336132501, 0.5868034519740111, 0.5913507707372925, 0.585632358606045, 0.5378141161605451, 0.5681811412410623, 0.5782127486178156, 0.5650231787086238, 0.576470848018601, 0.5822791132701219, 0.5833927033215585, 0.574540937087945, 0.5788106562117853, 0.5770526318507787, 0.5693123206584412, 0.5718877294359828, 0.5733878721852275, 0.5738480283311133, 0.5794522215628765, 0.5691071535355946, 0.3491929281040056, 0.550708035216529, 0.5586852967386415, 0.5622721205096273, 0.5671871718923016, 0.5603054721327223, 0.5451794113280505, 0.5768898785466978, 0.5768399965128249, 0.571900051726392, 0.554564733829724, 0.5461338893372631, 0.5770736502472466, 0.572930649363783, 0.5725297585746946], 'loss': [2.486441072356209, 0.9816752352998082, 0.7068475395078171, 0.5791024908217319, 0.5206706630153455, 0.4877016174411334, 0.4730009614244563, 0.4488844507791032, 0.4337489850936256, 0.42614095744292974, 0.41043137185665746, 0.4032990677564727, 0.39532791156480745, 0.3886540229508803, 0.38480527227772426, 0.38405047580273893, 0.44131140276139647, 0.39188986255677544, 0.3827052439819175, 0.372198961501652, 0.36959625156456477, 0.3682609830874756, 0.3580386196098537, 0.3536533694456677, 0.3928319489875574, 0.3842502278925919, 0.41121785223434715, 0.36507547122956674, 0.3576990922569228, 0.4089421808036144, 0.35804872640214475, 0.38519800677833893, 0.3517568433999254, 0.3464775225987656, 0.3444565335674649, 0.34185826950341563, 0.34076437768762535, 0.3652390971337668, 0.4110285600092214, 0.3590548912576079, 0.353855704222606, 0.34445548111108026, 0.4662946296761343, 0.3660837880882167, 0.35387939803072405, 0.3448536340149459, 0.340578473675461, 0.3372610535008897, 0.3547135037632611, 0.33088226559483735, 0.4036409724884696, 0.35298315914532075, 0.33704849040061535, 0.3303352981816371, 0.3319736656137555, 0.3383417122575997, 0.32773594282552526, 0.32842623463109927, 0.34941753663694286, 0.3238211381567865, 0.31975462358039325, 0.3187714503235337, 0.31589376202414876, 0.3135878738781735, 0.3126775906826957, 0.3153710701122029, 0.37537003520716306, 0.3274926845240162, 0.32013068333460176, 0.32011391069748424, 0.31474995488026336, 0.3146050169417475, 0.3128164545034514, 0.30989880292448596, 0.3089991643406536, 0.3065796542046467, 0.3064897222106853, 0.3061342294341016, 0.302184872863873, 0.30150428586274486, 0.30317657657134106, 0.30517664574635395, 0.37891622275054165, 0.32129316459467033, 0.309981212800298, 0.30537286007611486, 0.3067070656471577, 0.32154225281387205, 0.32083319007244104, 0.30405004944188585, 0.31044608608939883, 0.3024497294781098, 0.30989135851997024, 0.37659077728058177, 0.31979015708772945, 0.31018847651636083], 'acc': [0.7529870695376709, 0.8918835000656982, 0.9087941742194208, 0.9190609735480887, 0.9244337425698117, 0.9276072050200693, 0.9286089980837611, 0.930675766867996, 0.9323257459000587, 0.9322434716408438, 0.9340064722971088, 0.9342969000966629, 0.9351122434193649, 0.9357095304244601, 0.9360126739473317, 0.9359015753427314, 0.9324597956539821, 0.9356941027567451, 0.936527951486089, 0.9373454087196843, 0.937650613059585, 0.9375296627986176, 0.9383429466642265, 0.9386583559055647, 0.9361166835028534, 0.935406350972509, 0.9332635038033461, 0.9376372426787031, 0.938649558446018, 0.9341286435548909, 0.9382457590748591, 0.9353359829507154, 0.9386512939847379, 0.9391932862562299, 0.939518625248069, 0.9397702695334377, 0.9399553357899534, 0.9380375261227281, 0.9336129565345492, 0.9387052856744188, 0.938853436785255, 0.9397181448311879, 0.9285141317074089, 0.9378926777602905, 0.9390456760263651, 0.9395996005361223, 0.9401564250771409, 0.9405429314490342, 0.9383830857172631, 0.9405739743499021, 0.9352922486926326, 0.938722013955083, 0.9402068205189235, 0.9406763293568667, 0.940828756133861, 0.9400148502491456, 0.9409957998525252, 0.9410481437721888, 0.9381252943884609, 0.9409730364307047, 0.9414074494492318, 0.9415096160945268, 0.9416893788694081, 0.941814658200435, 0.9419181030091699, 0.9415846914458126, 0.9368388970166829, 0.940938287211699, 0.94147340446545, 0.9414235800346142, 0.9418104395388374, 0.9420646267772101, 0.9421617077772098, 0.9423273145722673, 0.94243286515342, 0.9425198250465717, 0.9427286497257691, 0.9429248157214408, 0.943092016692364, 0.9431302848543198, 0.9432373537015571, 0.9433349475241649, 0.9354231325654727, 0.9416621785480117, 0.9425512997376072, 0.9429338543335305, 0.9430686613602733, 0.9418448109564199, 0.9417213679261912, 0.9432091534609828, 0.9434630431411875, 0.943619911278065, 0.943039108906701, 0.9365851694224983, 0.9419898220249519, 0.9427122780723991], 'mDice': [0.13387495512985031, 0.36804483538683547, 0.4806763268218901, 0.5456705822605291, 0.5796228825714814, 0.6001393036267932, 0.6102161119277066, 0.6249362180413105, 0.6358946963100093, 0.6385709226363967, 0.6501072588112354, 0.6536342386433328, 0.658959996250733, 0.6633635573331339, 0.6668642363743884, 0.6669375748763426, 0.6321511271293316, 0.6612656482258986, 0.6682124019993833, 0.674624566674472, 0.6785430730002219, 0.6774949149144628, 0.6844366782099689, 0.6875324692902575, 0.6640861173275867, 0.668233085417102, 0.6490267555769178, 0.6806086578511757, 0.6886249680738384, 0.6527844403973566, 0.6854339307582552, 0.6663862874722394, 0.6899573266936019, 0.6930072332530569, 0.6963481991859541, 0.6973920682528183, 0.698905369007696, 0.6829830113525777, 0.6507181238727883, 0.6863717306433932, 0.6880455729470691, 0.6945352617033351, 0.6207288054727129, 0.6812245069503897, 0.6895749890179989, 0.6948002210913686, 0.6989945680456164, 0.7013959030913945, 0.6876772787571235, 0.7042236114551672, 0.662581145192647, 0.688698805411497, 0.6998748872308024, 0.7046731540406761, 0.706161772215503, 0.6991210833186587, 0.7077020125716611, 0.7079323551970208, 0.6913109654046525, 0.7094353326162642, 0.7124400525626342, 0.713080364080281, 0.7152250924140289, 0.7170617108170847, 0.7183900004315988, 0.7158593889922591, 0.6742309779052067, 0.7083553013007879, 0.7122453899019392, 0.7131343324608042, 0.7162396878493792, 0.7178318175613944, 0.719482358613326, 0.719639292943138, 0.7214905289079382, 0.7223187650767804, 0.7223013472241394, 0.7226824685182537, 0.7254754168539975, 0.7259242944309285, 0.724881912281164, 0.7256930084540808, 0.6729280216246579, 0.7131825228971375, 0.7207714268284383, 0.7231130816437896, 0.7241196855471086, 0.7120061320592811, 0.7119938236895655, 0.7241910287978478, 0.7254868412091103, 0.7287399310397121, 0.7217006389378008, 0.672761046663781, 0.7128550414146155, 0.7192325966833669]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:15,  3.96s/it]predicting test subjects:  40%|████      | 2/5 [00:07<00:11,  3.72s/it]predicting test subjects:  60%|██████    | 3/5 [00:09<00:06,  3.40s/it]predicting test subjects:  80%|████████  | 4/5 [00:12<00:03,  3.15s/it]predicting test subjects: 100%|██████████| 5/5 [00:15<00:00,  3.27s/it]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:02<10:58,  2.68s/it]predicting train subjects:   1%|          | 2/247 [00:05<10:53,  2.67s/it]predicting train subjects:   1%|          | 3/247 [00:07<10:42,  2.63s/it]predicting train subjects:   2%|▏         | 4/247 [00:10<11:01,  2.72s/it]predicting train subjects:   2%|▏         | 5/247 [00:13<10:28,  2.60s/it]predicting train subjects:   2%|▏         | 6/247 [00:15<10:43,  2.67s/it]predicting train subjects:   3%|▎         | 7/247 [00:18<10:11,  2.55s/it]predicting train subjects:   3%|▎         | 8/247 [00:21<10:51,  2.73s/it]predicting train subjects:   4%|▎         | 9/247 [00:24<11:05,  2.80s/it]predicting train subjects:   4%|▍         | 10/247 [00:26<10:31,  2.66s/it]predicting train subjects:   4%|▍         | 11/247 [00:29<10:39,  2.71s/it]predicting train subjects:   5%|▍         | 12/247 [00:32<10:22,  2.65s/it]predicting train subjects:   5%|▌         | 13/247 [00:34<10:06,  2.59s/it]predicting train subjects:   6%|▌         | 14/247 [00:37<10:26,  2.69s/it]predicting train subjects:   6%|▌         | 15/247 [00:39<10:06,  2.62s/it]predicting train subjects:   6%|▋         | 16/247 [00:42<10:19,  2.68s/it]predicting train subjects:   7%|▋         | 17/247 [00:45<10:10,  2.65s/it]predicting train subjects:   7%|▋         | 18/247 [00:47<09:48,  2.57s/it]predicting train subjects:   8%|▊         | 19/247 [00:49<09:25,  2.48s/it]predicting train subjects:   8%|▊         | 20/247 [00:51<08:45,  2.31s/it]predicting train subjects:   9%|▊         | 21/247 [00:54<08:42,  2.31s/it]predicting train subjects:   9%|▉         | 22/247 [00:56<08:21,  2.23s/it]predicting train subjects:   9%|▉         | 23/247 [00:58<08:06,  2.17s/it]predicting train subjects:  10%|▉         | 24/247 [01:00<08:14,  2.22s/it]predicting train subjects:  10%|█         | 25/247 [01:02<08:14,  2.23s/it]predicting train subjects:  11%|█         | 26/247 [01:04<07:46,  2.11s/it]predicting train subjects:  11%|█         | 27/247 [01:06<07:47,  2.12s/it]predicting train subjects:  11%|█▏        | 28/247 [01:08<07:44,  2.12s/it]predicting train subjects:  12%|█▏        | 29/247 [01:11<08:20,  2.30s/it]predicting train subjects:  12%|█▏        | 30/247 [01:14<08:44,  2.41s/it]predicting train subjects:  13%|█▎        | 31/247 [01:16<08:31,  2.37s/it]predicting train subjects:  13%|█▎        | 32/247 [01:18<08:28,  2.36s/it]predicting train subjects:  13%|█▎        | 33/247 [01:21<08:28,  2.38s/it]predicting train subjects:  14%|█▍        | 34/247 [01:23<08:16,  2.33s/it]predicting train subjects:  14%|█▍        | 35/247 [01:26<08:45,  2.48s/it]predicting train subjects:  15%|█▍        | 36/247 [01:29<09:14,  2.63s/it]predicting train subjects:  15%|█▍        | 37/247 [01:31<09:00,  2.57s/it]predicting train subjects:  15%|█▌        | 38/247 [01:34<09:15,  2.66s/it]predicting train subjects:  16%|█▌        | 39/247 [01:37<08:58,  2.59s/it]predicting train subjects:  16%|█▌        | 40/247 [01:39<08:46,  2.54s/it]predicting train subjects:  17%|█▋        | 41/247 [01:42<09:14,  2.69s/it]predicting train subjects:  17%|█▋        | 42/247 [01:45<09:14,  2.71s/it]predicting train subjects:  17%|█▋        | 43/247 [01:48<09:20,  2.75s/it]predicting train subjects:  18%|█▊        | 44/247 [01:50<08:49,  2.61s/it]predicting train subjects:  18%|█▊        | 45/247 [01:52<08:43,  2.59s/it]predicting train subjects:  19%|█▊        | 46/247 [01:55<08:48,  2.63s/it]predicting train subjects:  19%|█▉        | 47/247 [01:58<08:31,  2.56s/it]predicting train subjects:  19%|█▉        | 48/247 [02:00<08:45,  2.64s/it]predicting train subjects:  20%|█▉        | 49/247 [02:03<08:29,  2.57s/it]predicting train subjects:  20%|██        | 50/247 [02:06<08:35,  2.62s/it]predicting train subjects:  21%|██        | 51/247 [02:08<08:26,  2.58s/it]predicting train subjects:  21%|██        | 52/247 [02:11<08:38,  2.66s/it]predicting train subjects:  21%|██▏       | 53/247 [02:13<08:31,  2.64s/it]predicting train subjects:  22%|██▏       | 54/247 [02:16<08:13,  2.56s/it]predicting train subjects:  22%|██▏       | 55/247 [02:19<08:33,  2.67s/it]predicting train subjects:  23%|██▎       | 56/247 [02:21<08:19,  2.61s/it]predicting train subjects:  23%|██▎       | 57/247 [02:24<08:32,  2.70s/it]predicting train subjects:  23%|██▎       | 58/247 [02:27<08:38,  2.74s/it]predicting train subjects:  24%|██▍       | 59/247 [02:29<08:14,  2.63s/it]predicting train subjects:  24%|██▍       | 60/247 [02:32<08:03,  2.59s/it]predicting train subjects:  25%|██▍       | 61/247 [02:35<08:31,  2.75s/it]predicting train subjects:  25%|██▌       | 62/247 [02:37<08:08,  2.64s/it]predicting train subjects:  26%|██▌       | 63/247 [02:40<08:20,  2.72s/it]predicting train subjects:  26%|██▌       | 64/247 [02:43<08:01,  2.63s/it]predicting train subjects:  26%|██▋       | 65/247 [02:45<07:42,  2.54s/it]predicting train subjects:  27%|██▋       | 66/247 [02:48<07:53,  2.62s/it]predicting train subjects:  27%|██▋       | 67/247 [02:51<08:12,  2.74s/it]predicting train subjects:  28%|██▊       | 68/247 [02:54<08:16,  2.77s/it]predicting train subjects:  28%|██▊       | 69/247 [02:57<08:25,  2.84s/it]predicting train subjects:  28%|██▊       | 70/247 [02:59<07:47,  2.64s/it]predicting train subjects:  29%|██▊       | 71/247 [03:01<07:44,  2.64s/it]predicting train subjects:  29%|██▉       | 72/247 [03:04<07:23,  2.54s/it]predicting train subjects:  30%|██▉       | 73/247 [03:06<07:09,  2.47s/it]predicting train subjects:  30%|██▉       | 74/247 [03:08<06:56,  2.41s/it]predicting train subjects:  30%|███       | 75/247 [03:11<07:15,  2.53s/it]predicting train subjects:  31%|███       | 76/247 [03:13<06:37,  2.32s/it]predicting train subjects:  31%|███       | 77/247 [03:15<06:03,  2.14s/it]predicting train subjects:  32%|███▏      | 78/247 [03:17<06:09,  2.19s/it]predicting train subjects:  32%|███▏      | 79/247 [03:19<05:58,  2.14s/it]predicting train subjects:  32%|███▏      | 80/247 [03:21<06:13,  2.24s/it]predicting train subjects:  33%|███▎      | 81/247 [03:24<06:21,  2.30s/it]predicting train subjects:  33%|███▎      | 82/247 [03:27<07:03,  2.56s/it]predicting train subjects:  34%|███▎      | 83/247 [03:29<06:39,  2.44s/it]predicting train subjects:  34%|███▍      | 84/247 [03:31<06:23,  2.35s/it]predicting train subjects:  34%|███▍      | 85/247 [03:34<06:49,  2.53s/it]predicting train subjects:  35%|███▍      | 86/247 [03:37<06:39,  2.48s/it]predicting train subjects:  35%|███▌      | 87/247 [03:40<07:01,  2.63s/it]predicting train subjects:  36%|███▌      | 88/247 [03:43<07:13,  2.73s/it]predicting train subjects:  36%|███▌      | 89/247 [03:45<06:36,  2.51s/it]predicting train subjects:  36%|███▋      | 90/247 [03:47<06:32,  2.50s/it]predicting train subjects:  37%|███▋      | 91/247 [03:50<06:47,  2.62s/it]predicting train subjects:  37%|███▋      | 92/247 [03:53<06:56,  2.68s/it]predicting train subjects:  38%|███▊      | 93/247 [03:56<07:15,  2.83s/it]predicting train subjects:  38%|███▊      | 94/247 [03:59<07:33,  2.96s/it]predicting train subjects:  38%|███▊      | 95/247 [04:02<07:20,  2.90s/it]predicting train subjects:  39%|███▉      | 96/247 [04:04<06:56,  2.76s/it]predicting train subjects:  39%|███▉      | 97/247 [04:07<07:03,  2.83s/it]predicting train subjects:  40%|███▉      | 98/247 [04:10<06:52,  2.77s/it]predicting train subjects:  40%|████      | 99/247 [04:13<07:05,  2.88s/it]predicting train subjects:  40%|████      | 100/247 [04:16<07:11,  2.94s/it]predicting train subjects:  41%|████      | 101/247 [04:19<07:07,  2.93s/it]predicting train subjects:  41%|████▏     | 102/247 [04:22<07:01,  2.90s/it]predicting train subjects:  42%|████▏     | 103/247 [04:24<06:37,  2.76s/it]predicting train subjects:  42%|████▏     | 104/247 [04:28<06:53,  2.89s/it]predicting train subjects:  43%|████▎     | 105/247 [04:30<06:42,  2.83s/it]predicting train subjects:  43%|████▎     | 106/247 [04:33<06:22,  2.71s/it]predicting train subjects:  43%|████▎     | 107/247 [04:36<06:28,  2.77s/it]predicting train subjects:  44%|████▎     | 108/247 [04:38<06:23,  2.76s/it]predicting train subjects:  44%|████▍     | 109/247 [04:41<06:21,  2.76s/it]predicting train subjects:  45%|████▍     | 110/247 [04:44<06:19,  2.77s/it]predicting train subjects:  45%|████▍     | 111/247 [04:47<06:32,  2.89s/it]predicting train subjects:  45%|████▌     | 112/247 [04:50<06:17,  2.79s/it]predicting train subjects:  46%|████▌     | 113/247 [04:53<06:25,  2.88s/it]predicting train subjects:  46%|████▌     | 114/247 [04:55<06:12,  2.80s/it]predicting train subjects:  47%|████▋     | 115/247 [04:58<05:48,  2.64s/it]predicting train subjects:  47%|████▋     | 116/247 [05:01<05:57,  2.73s/it]predicting train subjects:  47%|████▋     | 117/247 [05:04<06:05,  2.81s/it]predicting train subjects:  48%|████▊     | 118/247 [05:06<06:00,  2.79s/it]predicting train subjects:  48%|████▊     | 119/247 [05:10<06:17,  2.95s/it]predicting train subjects:  49%|████▊     | 120/247 [05:12<05:47,  2.74s/it]predicting train subjects:  49%|████▉     | 121/247 [05:15<05:53,  2.81s/it]predicting train subjects:  49%|████▉     | 122/247 [05:18<06:10,  2.97s/it]predicting train subjects:  50%|████▉     | 123/247 [05:21<05:44,  2.78s/it]predicting train subjects:  50%|█████     | 124/247 [05:23<05:38,  2.75s/it]predicting train subjects:  51%|█████     | 125/247 [05:27<05:52,  2.89s/it]predicting train subjects:  51%|█████     | 126/247 [05:30<05:57,  2.95s/it]predicting train subjects:  51%|█████▏    | 127/247 [05:32<05:51,  2.93s/it]predicting train subjects:  52%|█████▏    | 128/247 [05:35<05:27,  2.75s/it]predicting train subjects:  52%|█████▏    | 129/247 [05:38<05:40,  2.88s/it]predicting train subjects:  53%|█████▎    | 130/247 [05:41<05:37,  2.88s/it]predicting train subjects:  53%|█████▎    | 131/247 [05:43<05:11,  2.68s/it]predicting train subjects:  53%|█████▎    | 132/247 [05:46<05:26,  2.84s/it]predicting train subjects:  54%|█████▍    | 133/247 [05:49<05:18,  2.79s/it]predicting train subjects:  54%|█████▍    | 134/247 [05:52<05:10,  2.75s/it]predicting train subjects:  55%|█████▍    | 135/247 [05:54<04:51,  2.60s/it]predicting train subjects:  55%|█████▌    | 136/247 [05:56<04:47,  2.59s/it]predicting train subjects:  55%|█████▌    | 137/247 [05:58<04:19,  2.36s/it]predicting train subjects:  56%|█████▌    | 138/247 [06:01<04:29,  2.47s/it]predicting train subjects:  56%|█████▋    | 139/247 [06:03<04:26,  2.46s/it]predicting train subjects:  57%|█████▋    | 140/247 [06:05<04:07,  2.31s/it]predicting train subjects:  57%|█████▋    | 141/247 [06:07<03:56,  2.23s/it]predicting train subjects:  57%|█████▋    | 142/247 [06:10<03:51,  2.20s/it]predicting train subjects:  58%|█████▊    | 143/247 [06:12<03:56,  2.27s/it]predicting train subjects:  58%|█████▊    | 144/247 [06:14<03:45,  2.19s/it]predicting train subjects:  59%|█████▊    | 145/247 [06:17<03:55,  2.30s/it]predicting train subjects:  59%|█████▉    | 146/247 [06:19<03:44,  2.22s/it]predicting train subjects:  60%|█████▉    | 147/247 [06:20<03:28,  2.08s/it]predicting train subjects:  60%|█████▉    | 148/247 [06:23<03:45,  2.28s/it]predicting train subjects:  60%|██████    | 149/247 [06:26<03:58,  2.43s/it]predicting train subjects:  61%|██████    | 150/247 [06:28<03:44,  2.31s/it]predicting train subjects:  61%|██████    | 151/247 [06:30<03:38,  2.27s/it]predicting train subjects:  62%|██████▏   | 152/247 [06:32<03:31,  2.23s/it]predicting train subjects:  62%|██████▏   | 153/247 [06:35<03:34,  2.28s/it]predicting train subjects:  62%|██████▏   | 154/247 [06:37<03:42,  2.39s/it]predicting train subjects:  63%|██████▎   | 155/247 [06:40<03:37,  2.37s/it]predicting train subjects:  63%|██████▎   | 156/247 [06:41<03:20,  2.21s/it]predicting train subjects:  64%|██████▎   | 157/247 [06:44<03:21,  2.24s/it]predicting train subjects:  64%|██████▍   | 158/247 [06:46<03:32,  2.39s/it]predicting train subjects:  64%|██████▍   | 159/247 [06:49<03:22,  2.30s/it]predicting train subjects:  65%|██████▍   | 160/247 [06:51<03:34,  2.47s/it]predicting train subjects:  65%|██████▌   | 161/247 [06:54<03:41,  2.58s/it]predicting train subjects:  66%|██████▌   | 162/247 [06:57<03:31,  2.49s/it]predicting train subjects:  66%|██████▌   | 163/247 [06:59<03:38,  2.60s/it]predicting train subjects:  66%|██████▋   | 164/247 [07:01<03:22,  2.44s/it]predicting train subjects:  67%|██████▋   | 165/247 [07:03<03:02,  2.22s/it]predicting train subjects:  67%|██████▋   | 166/247 [07:05<02:59,  2.22s/it]predicting train subjects:  68%|██████▊   | 167/247 [07:08<02:54,  2.19s/it]predicting train subjects:  68%|██████▊   | 168/247 [07:10<03:07,  2.37s/it]predicting train subjects:  68%|██████▊   | 169/247 [07:12<02:53,  2.22s/it]predicting train subjects:  69%|██████▉   | 170/247 [07:14<02:48,  2.19s/it]predicting train subjects:  69%|██████▉   | 171/247 [07:16<02:41,  2.12s/it]predicting train subjects:  70%|██████▉   | 172/247 [07:18<02:40,  2.14s/it]predicting train subjects:  70%|███████   | 173/247 [07:20<02:29,  2.03s/it]predicting train subjects:  70%|███████   | 174/247 [07:22<02:25,  1.99s/it]predicting train subjects:  71%|███████   | 175/247 [07:25<02:33,  2.13s/it]predicting train subjects:  71%|███████▏  | 176/247 [07:27<02:38,  2.23s/it]predicting train subjects:  72%|███████▏  | 177/247 [07:30<02:43,  2.34s/it]predicting train subjects:  72%|███████▏  | 178/247 [07:32<02:48,  2.44s/it]predicting train subjects:  72%|███████▏  | 179/247 [07:35<02:52,  2.54s/it]predicting train subjects:  73%|███████▎  | 180/247 [07:38<03:04,  2.75s/it]predicting train subjects:  73%|███████▎  | 181/247 [07:42<03:10,  2.89s/it]predicting train subjects:  74%|███████▎  | 182/247 [07:44<03:08,  2.90s/it]predicting train subjects:  74%|███████▍  | 183/247 [07:47<03:02,  2.84s/it]predicting train subjects:  74%|███████▍  | 184/247 [07:50<02:53,  2.75s/it]predicting train subjects:  75%|███████▍  | 185/247 [07:52<02:46,  2.69s/it]predicting train subjects:  75%|███████▌  | 186/247 [07:55<02:52,  2.83s/it]predicting train subjects:  76%|███████▌  | 187/247 [07:59<02:55,  2.93s/it]predicting train subjects:  76%|███████▌  | 188/247 [08:02<02:53,  2.94s/it]predicting train subjects:  77%|███████▋  | 189/247 [08:04<02:43,  2.81s/it]predicting train subjects:  77%|███████▋  | 190/247 [08:07<02:34,  2.71s/it]predicting train subjects:  77%|███████▋  | 191/247 [08:09<02:28,  2.65s/it]predicting train subjects:  78%|███████▊  | 192/247 [08:12<02:23,  2.60s/it]predicting train subjects:  78%|███████▊  | 193/247 [08:15<02:31,  2.81s/it]predicting train subjects:  79%|███████▊  | 194/247 [08:18<02:35,  2.93s/it]predicting train subjects:  79%|███████▉  | 195/247 [08:21<02:33,  2.95s/it]predicting train subjects:  79%|███████▉  | 196/247 [08:24<02:29,  2.93s/it]predicting train subjects:  80%|███████▉  | 197/247 [08:27<02:25,  2.92s/it]predicting train subjects:  80%|████████  | 198/247 [08:30<02:23,  2.93s/it]predicting train subjects:  81%|████████  | 199/247 [08:32<02:16,  2.85s/it]predicting train subjects:  81%|████████  | 200/247 [08:35<02:10,  2.79s/it]predicting train subjects:  81%|████████▏ | 201/247 [08:38<02:03,  2.68s/it]predicting train subjects:  82%|████████▏ | 202/247 [08:41<02:09,  2.88s/it]predicting train subjects:  82%|████████▏ | 203/247 [08:44<02:10,  2.97s/it]predicting train subjects:  83%|████████▎ | 204/247 [08:47<02:06,  2.94s/it]predicting train subjects:  83%|████████▎ | 205/247 [08:49<01:58,  2.83s/it]predicting train subjects:  83%|████████▎ | 206/247 [08:52<01:55,  2.82s/it]predicting train subjects:  84%|████████▍ | 207/247 [08:55<01:51,  2.79s/it]predicting train subjects:  84%|████████▍ | 208/247 [08:58<01:54,  2.93s/it]predicting train subjects:  85%|████████▍ | 209/247 [09:02<01:55,  3.04s/it]predicting train subjects:  85%|████████▌ | 210/247 [09:05<01:51,  3.02s/it]predicting train subjects:  85%|████████▌ | 211/247 [09:07<01:43,  2.88s/it]predicting train subjects:  86%|████████▌ | 212/247 [09:10<01:36,  2.76s/it]predicting train subjects:  86%|████████▌ | 213/247 [09:12<01:34,  2.77s/it]predicting train subjects:  87%|████████▋ | 214/247 [09:15<01:28,  2.70s/it]predicting train subjects:  87%|████████▋ | 215/247 [09:17<01:25,  2.67s/it]predicting train subjects:  87%|████████▋ | 216/247 [09:21<01:28,  2.84s/it]predicting train subjects:  88%|████████▊ | 217/247 [09:24<01:28,  2.96s/it]predicting train subjects:  88%|████████▊ | 218/247 [09:27<01:26,  2.97s/it]predicting train subjects:  89%|████████▊ | 219/247 [09:29<01:19,  2.83s/it]predicting train subjects:  89%|████████▉ | 220/247 [09:32<01:17,  2.87s/it]predicting train subjects:  89%|████████▉ | 221/247 [09:35<01:09,  2.68s/it]predicting train subjects:  90%|████████▉ | 222/247 [09:38<01:10,  2.80s/it]predicting train subjects:  90%|█████████ | 223/247 [09:40<01:05,  2.72s/it]predicting train subjects:  91%|█████████ | 224/247 [09:43<01:01,  2.66s/it]predicting train subjects:  91%|█████████ | 225/247 [09:45<00:56,  2.58s/it]predicting train subjects:  91%|█████████▏| 226/247 [09:48<00:58,  2.78s/it]predicting train subjects:  92%|█████████▏| 227/247 [09:51<00:56,  2.81s/it]predicting train subjects:  92%|█████████▏| 228/247 [09:54<00:52,  2.75s/it]predicting train subjects:  93%|█████████▎| 229/247 [09:57<00:49,  2.76s/it]predicting train subjects:  93%|█████████▎| 230/247 [09:59<00:44,  2.63s/it]predicting train subjects:  94%|█████████▎| 231/247 [10:02<00:41,  2.60s/it]predicting train subjects:  94%|█████████▍| 232/247 [10:05<00:41,  2.79s/it]predicting train subjects:  94%|█████████▍| 233/247 [10:08<00:39,  2.84s/it]predicting train subjects:  95%|█████████▍| 234/247 [10:11<00:37,  2.86s/it]predicting train subjects:  95%|█████████▌| 235/247 [10:13<00:33,  2.82s/it]predicting train subjects:  96%|█████████▌| 236/247 [10:16<00:30,  2.77s/it]predicting train subjects:  96%|█████████▌| 237/247 [10:19<00:27,  2.72s/it]predicting train subjects:  96%|█████████▋| 238/247 [10:22<00:25,  2.83s/it]predicting train subjects:  97%|█████████▋| 239/247 [10:24<00:22,  2.77s/it]predicting train subjects:  97%|█████████▋| 240/247 [10:27<00:18,  2.69s/it]predicting train subjects:  98%|█████████▊| 241/247 [10:30<00:16,  2.68s/it]predicting train subjects:  98%|█████████▊| 242/247 [10:32<00:12,  2.60s/it]predicting train subjects:  98%|█████████▊| 243/247 [10:35<00:10,  2.75s/it]predicting train subjects:  99%|█████████▉| 244/247 [10:38<00:08,  2.86s/it]predicting train subjects:  99%|█████████▉| 245/247 [10:41<00:05,  2.87s/it]predicting train subjects: 100%|█████████▉| 246/247 [10:44<00:02,  2.87s/it]predicting train subjects: 100%|██████████| 247/247 [10:47<00:00,  2.81s/it]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_BC_CSFn
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<02:41,  1.52it/s]Loading train:   1%|          | 2/247 [00:01<02:42,  1.51it/s]Loading train:   1%|          | 3/247 [00:01<02:24,  1.69it/s]Loading train:   2%|▏         | 4/247 [00:02<02:26,  1.66it/s]Loading train:   2%|▏         | 5/247 [00:03<02:26,  1.65it/s]Loading train:   2%|▏         | 6/247 [00:03<02:18,  1.74it/s]Loading train:   3%|▎         | 7/247 [00:04<02:17,  1.74it/s]Loading train:   3%|▎         | 8/247 [00:04<02:30,  1.59it/s]Loading train:   4%|▎         | 9/247 [00:05<02:38,  1.50it/s]Loading train:   4%|▍         | 10/247 [00:06<02:37,  1.51it/s]Loading train:   4%|▍         | 11/247 [00:06<02:39,  1.48it/s]Loading train:   5%|▍         | 12/247 [00:07<02:31,  1.55it/s]Loading train:   5%|▌         | 13/247 [00:08<02:26,  1.60it/s]Loading train:   6%|▌         | 14/247 [00:08<02:30,  1.55it/s]Loading train:   6%|▌         | 15/247 [00:09<02:29,  1.55it/s]Loading train:   6%|▋         | 16/247 [00:10<02:28,  1.55it/s]Loading train:   7%|▋         | 17/247 [00:10<02:25,  1.59it/s]Loading train:   7%|▋         | 18/247 [00:11<02:18,  1.65it/s]Loading train:   8%|▊         | 19/247 [00:11<02:14,  1.69it/s]Loading train:   8%|▊         | 20/247 [00:12<02:16,  1.67it/s]Loading train:   9%|▊         | 21/247 [00:13<02:23,  1.58it/s]Loading train:   9%|▉         | 22/247 [00:13<02:13,  1.69it/s]Loading train:   9%|▉         | 23/247 [00:14<02:21,  1.58it/s]Loading train:  10%|▉         | 24/247 [00:14<02:21,  1.57it/s]Loading train:  10%|█         | 25/247 [00:15<02:26,  1.51it/s]Loading train:  11%|█         | 26/247 [00:16<02:29,  1.48it/s]Loading train:  11%|█         | 27/247 [00:17<02:26,  1.51it/s]Loading train:  11%|█▏        | 28/247 [00:17<02:30,  1.46it/s]Loading train:  12%|█▏        | 29/247 [00:18<02:24,  1.51it/s]Loading train:  12%|█▏        | 30/247 [00:19<02:26,  1.48it/s]Loading train:  13%|█▎        | 31/247 [00:19<02:30,  1.44it/s]Loading train:  13%|█▎        | 32/247 [00:20<02:32,  1.41it/s]Loading train:  13%|█▎        | 33/247 [00:21<02:30,  1.42it/s]Loading train:  14%|█▍        | 34/247 [00:21<02:19,  1.52it/s]Loading train:  14%|█▍        | 35/247 [00:22<02:21,  1.50it/s]Loading train:  15%|█▍        | 36/247 [00:23<02:28,  1.42it/s]Loading train:  15%|█▍        | 37/247 [00:23<02:25,  1.44it/s]Loading train:  15%|█▌        | 38/247 [00:24<02:29,  1.40it/s]Loading train:  16%|█▌        | 39/247 [00:25<02:16,  1.53it/s]Loading train:  16%|█▌        | 40/247 [00:25<02:05,  1.65it/s]Loading train:  17%|█▋        | 41/247 [00:26<02:06,  1.62it/s]Loading train:  17%|█▋        | 42/247 [00:26<01:53,  1.80it/s]Loading train:  17%|█▋        | 43/247 [00:27<02:05,  1.63it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:10,  1.55it/s]Loading train:  18%|█▊        | 45/247 [00:29<02:17,  1.47it/s]Loading train:  19%|█▊        | 46/247 [00:29<02:13,  1.50it/s]Loading train:  19%|█▉        | 47/247 [00:30<02:14,  1.49it/s]Loading train:  19%|█▉        | 48/247 [00:31<02:17,  1.45it/s]Loading train:  20%|█▉        | 49/247 [00:31<02:02,  1.61it/s]Loading train:  20%|██        | 50/247 [00:32<02:07,  1.55it/s]Loading train:  21%|██        | 51/247 [00:32<02:12,  1.48it/s]Loading train:  21%|██        | 52/247 [00:33<02:19,  1.39it/s]Loading train:  21%|██▏       | 53/247 [00:34<02:19,  1.40it/s]Loading train:  22%|██▏       | 54/247 [00:35<02:16,  1.42it/s]Loading train:  22%|██▏       | 55/247 [00:35<02:19,  1.37it/s]Loading train:  23%|██▎       | 56/247 [00:36<02:19,  1.37it/s]Loading train:  23%|██▎       | 57/247 [00:37<02:20,  1.35it/s]Loading train:  23%|██▎       | 58/247 [00:38<02:19,  1.35it/s]Loading train:  24%|██▍       | 59/247 [00:38<02:16,  1.38it/s]Loading train:  24%|██▍       | 60/247 [00:39<02:12,  1.41it/s]Loading train:  25%|██▍       | 61/247 [00:40<02:10,  1.42it/s]Loading train:  25%|██▌       | 62/247 [00:40<01:55,  1.61it/s]Loading train:  26%|██▌       | 63/247 [00:41<01:53,  1.62it/s]Loading train:  26%|██▌       | 64/247 [00:42<01:57,  1.55it/s]Loading train:  26%|██▋       | 65/247 [00:42<01:59,  1.52it/s]Loading train:  27%|██▋       | 66/247 [00:43<02:06,  1.44it/s]Loading train:  27%|██▋       | 67/247 [00:44<02:11,  1.37it/s]Loading train:  28%|██▊       | 68/247 [00:44<01:53,  1.57it/s]Loading train:  28%|██▊       | 69/247 [00:45<02:01,  1.47it/s]Loading train:  28%|██▊       | 70/247 [00:46<02:05,  1.41it/s]Loading train:  29%|██▊       | 71/247 [00:46<01:55,  1.52it/s]Loading train:  29%|██▉       | 72/247 [00:47<01:59,  1.47it/s]Loading train:  30%|██▉       | 73/247 [00:48<01:54,  1.52it/s]Loading train:  30%|██▉       | 74/247 [00:48<01:58,  1.46it/s]Loading train:  30%|███       | 75/247 [00:49<02:00,  1.43it/s]Loading train:  31%|███       | 76/247 [00:50<02:03,  1.39it/s]Loading train:  31%|███       | 77/247 [00:51<02:04,  1.37it/s]Loading train:  32%|███▏      | 78/247 [00:51<02:02,  1.38it/s]Loading train:  32%|███▏      | 79/247 [00:52<01:56,  1.44it/s]Loading train:  32%|███▏      | 80/247 [00:53<02:03,  1.35it/s]Loading train:  33%|███▎      | 81/247 [00:53<01:58,  1.40it/s]Loading train:  33%|███▎      | 82/247 [00:54<01:45,  1.56it/s]Loading train:  34%|███▎      | 83/247 [00:55<01:49,  1.50it/s]Loading train:  34%|███▍      | 84/247 [00:55<01:48,  1.51it/s]Loading train:  34%|███▍      | 85/247 [00:56<01:54,  1.42it/s]Loading train:  35%|███▍      | 86/247 [00:57<01:56,  1.39it/s]Loading train:  35%|███▌      | 87/247 [00:58<02:01,  1.32it/s]Loading train:  36%|███▌      | 88/247 [00:58<01:51,  1.42it/s]Loading train:  36%|███▌      | 89/247 [00:59<01:52,  1.41it/s]Loading train:  36%|███▋      | 90/247 [00:59<01:37,  1.61it/s]Loading train:  37%|███▋      | 91/247 [01:00<01:35,  1.64it/s]Loading train:  37%|███▋      | 92/247 [01:00<01:25,  1.80it/s]Loading train:  38%|███▊      | 93/247 [01:01<01:19,  1.93it/s]Loading train:  38%|███▊      | 94/247 [01:01<01:15,  2.02it/s]Loading train:  38%|███▊      | 95/247 [01:02<01:10,  2.16it/s]Loading train:  39%|███▉      | 96/247 [01:02<01:05,  2.30it/s]Loading train:  39%|███▉      | 97/247 [01:03<01:15,  1.99it/s]Loading train:  40%|███▉      | 98/247 [01:03<01:22,  1.80it/s]Loading train:  40%|████      | 99/247 [01:04<01:23,  1.76it/s]Loading train:  40%|████      | 100/247 [01:05<01:28,  1.67it/s]Loading train:  41%|████      | 101/247 [01:05<01:28,  1.65it/s]Loading train:  41%|████▏     | 102/247 [01:06<01:35,  1.51it/s]Loading train:  42%|████▏     | 103/247 [01:07<01:31,  1.57it/s]Loading train:  42%|████▏     | 104/247 [01:07<01:33,  1.53it/s]Loading train:  43%|████▎     | 105/247 [01:08<01:34,  1.51it/s]Loading train:  43%|████▎     | 106/247 [01:08<01:20,  1.74it/s]Loading train:  43%|████▎     | 107/247 [01:09<01:24,  1.65it/s]Loading train:  44%|████▎     | 108/247 [01:10<01:29,  1.56it/s]Loading train:  44%|████▍     | 109/247 [01:11<01:31,  1.51it/s]Loading train:  45%|████▍     | 110/247 [01:11<01:27,  1.56it/s]Loading train:  45%|████▍     | 111/247 [01:12<01:32,  1.47it/s]Loading train:  45%|████▌     | 112/247 [01:12<01:25,  1.59it/s]Loading train:  46%|████▌     | 113/247 [01:13<01:29,  1.50it/s]Loading train:  46%|████▌     | 114/247 [01:14<01:29,  1.48it/s]Loading train:  47%|████▋     | 115/247 [01:14<01:24,  1.56it/s]Loading train:  47%|████▋     | 116/247 [01:15<01:25,  1.54it/s]Loading train:  47%|████▋     | 117/247 [01:16<01:27,  1.49it/s]Loading train:  48%|████▊     | 118/247 [01:17<01:29,  1.45it/s]Loading train:  48%|████▊     | 119/247 [01:17<01:24,  1.52it/s]Loading train:  49%|████▊     | 120/247 [01:18<01:26,  1.46it/s]Loading train:  49%|████▉     | 121/247 [01:19<01:23,  1.50it/s]Loading train:  49%|████▉     | 122/247 [01:19<01:26,  1.44it/s]Loading train:  50%|████▉     | 123/247 [01:20<01:26,  1.44it/s]Loading train:  50%|█████     | 124/247 [01:21<01:24,  1.46it/s]Loading train:  51%|█████     | 125/247 [01:21<01:22,  1.48it/s]Loading train:  51%|█████     | 126/247 [01:22<01:25,  1.41it/s]Loading train:  51%|█████▏    | 127/247 [01:23<01:26,  1.39it/s]Loading train:  52%|█████▏    | 128/247 [01:24<01:24,  1.40it/s]Loading train:  52%|█████▏    | 129/247 [01:24<01:25,  1.38it/s]Loading train:  53%|█████▎    | 130/247 [01:25<01:20,  1.45it/s]Loading train:  53%|█████▎    | 131/247 [01:26<01:21,  1.42it/s]Loading train:  53%|█████▎    | 132/247 [01:26<01:10,  1.62it/s]Loading train:  54%|█████▍    | 133/247 [01:27<01:19,  1.44it/s]Loading train:  54%|█████▍    | 134/247 [01:27<01:08,  1.66it/s]Loading train:  55%|█████▍    | 135/247 [01:28<01:13,  1.52it/s]Loading train:  55%|█████▌    | 136/247 [01:29<01:18,  1.41it/s]Loading train:  55%|█████▌    | 137/247 [01:30<01:21,  1.35it/s]Loading train:  56%|█████▌    | 138/247 [01:30<01:18,  1.38it/s]Loading train:  56%|█████▋    | 139/247 [01:31<01:20,  1.35it/s]Loading train:  57%|█████▋    | 140/247 [01:32<01:20,  1.34it/s]Loading train:  57%|█████▋    | 141/247 [01:33<01:17,  1.37it/s]Loading train:  57%|█████▋    | 142/247 [01:33<01:15,  1.39it/s]Loading train:  58%|█████▊    | 143/247 [01:34<01:15,  1.38it/s]Loading train:  58%|█████▊    | 144/247 [01:35<01:14,  1.38it/s]Loading train:  59%|█████▊    | 145/247 [01:35<01:12,  1.40it/s]Loading train:  59%|█████▉    | 146/247 [01:36<01:12,  1.40it/s]Loading train:  60%|█████▉    | 147/247 [01:37<01:08,  1.45it/s]Loading train:  60%|█████▉    | 148/247 [01:37<01:05,  1.51it/s]Loading train:  60%|██████    | 149/247 [01:38<01:00,  1.61it/s]Loading train:  61%|██████    | 150/247 [01:39<01:05,  1.49it/s]Loading train:  61%|██████    | 151/247 [01:39<01:02,  1.53it/s]Loading train:  62%|██████▏   | 152/247 [01:40<01:01,  1.55it/s]Loading train:  62%|██████▏   | 153/247 [01:41<01:03,  1.48it/s]Loading train:  62%|██████▏   | 154/247 [01:41<01:01,  1.51it/s]Loading train:  63%|██████▎   | 155/247 [01:42<01:02,  1.48it/s]Loading train:  63%|██████▎   | 156/247 [01:43<01:00,  1.51it/s]Loading train:  64%|██████▎   | 157/247 [01:43<01:01,  1.47it/s]Loading train:  64%|██████▍   | 158/247 [01:44<01:07,  1.33it/s]Loading train:  64%|██████▍   | 159/247 [01:45<01:04,  1.36it/s]Loading train:  65%|██████▍   | 160/247 [01:46<01:01,  1.41it/s]Loading train:  65%|██████▌   | 161/247 [01:46<00:57,  1.49it/s]Loading train:  66%|██████▌   | 162/247 [01:47<00:57,  1.49it/s]Loading train:  66%|██████▌   | 163/247 [01:48<00:53,  1.56it/s]Loading train:  66%|██████▋   | 164/247 [01:48<00:53,  1.56it/s]Loading train:  67%|██████▋   | 165/247 [01:49<00:51,  1.58it/s]Loading train:  67%|██████▋   | 166/247 [01:49<00:52,  1.53it/s]Loading train:  68%|██████▊   | 167/247 [01:50<00:46,  1.72it/s]Loading train:  68%|██████▊   | 168/247 [01:51<00:48,  1.64it/s]Loading train:  68%|██████▊   | 169/247 [01:51<00:47,  1.65it/s]Loading train:  69%|██████▉   | 170/247 [01:52<00:47,  1.63it/s]Loading train:  69%|██████▉   | 171/247 [01:52<00:42,  1.81it/s]Loading train:  70%|██████▉   | 172/247 [01:53<00:42,  1.75it/s]Loading train:  70%|███████   | 173/247 [01:53<00:42,  1.76it/s]Loading train:  70%|███████   | 174/247 [01:54<00:46,  1.57it/s]Loading train:  71%|███████   | 175/247 [01:55<00:48,  1.50it/s]Loading train:  71%|███████▏  | 176/247 [01:56<00:48,  1.46it/s]Loading train:  72%|███████▏  | 177/247 [01:56<00:47,  1.47it/s]Loading train:  72%|███████▏  | 178/247 [01:57<00:44,  1.54it/s]Loading train:  72%|███████▏  | 179/247 [01:57<00:42,  1.62it/s]Loading train:  73%|███████▎  | 180/247 [01:58<00:44,  1.52it/s]Loading train:  73%|███████▎  | 181/247 [01:59<00:48,  1.37it/s]Loading train:  74%|███████▎  | 182/247 [02:00<00:44,  1.46it/s]Loading train:  74%|███████▍  | 183/247 [02:00<00:43,  1.46it/s]Loading train:  74%|███████▍  | 184/247 [02:01<00:41,  1.51it/s]Loading train:  75%|███████▍  | 185/247 [02:02<00:39,  1.56it/s]Loading train:  75%|███████▌  | 186/247 [02:02<00:41,  1.47it/s]Loading train:  76%|███████▌  | 187/247 [02:03<00:41,  1.45it/s]Loading train:  76%|███████▌  | 188/247 [02:04<00:41,  1.44it/s]Loading train:  77%|███████▋  | 189/247 [02:04<00:38,  1.51it/s]Loading train:  77%|███████▋  | 190/247 [02:05<00:37,  1.53it/s]Loading train:  77%|███████▋  | 191/247 [02:06<00:36,  1.55it/s]Loading train:  78%|███████▊  | 192/247 [02:06<00:35,  1.56it/s]Loading train:  78%|███████▊  | 193/247 [02:07<00:36,  1.47it/s]Loading train:  79%|███████▊  | 194/247 [02:08<00:37,  1.40it/s]Loading train:  79%|███████▉  | 195/247 [02:09<00:37,  1.40it/s]Loading train:  79%|███████▉  | 196/247 [02:09<00:31,  1.61it/s]Loading train:  80%|███████▉  | 197/247 [02:10<00:31,  1.59it/s]Loading train:  80%|████████  | 198/247 [02:10<00:29,  1.67it/s]Loading train:  81%|████████  | 199/247 [02:11<00:28,  1.67it/s]Loading train:  81%|████████  | 200/247 [02:11<00:24,  1.89it/s]Loading train:  81%|████████▏ | 201/247 [02:12<00:27,  1.69it/s]Loading train:  82%|████████▏ | 202/247 [02:13<00:28,  1.57it/s]Loading train:  82%|████████▏ | 203/247 [02:13<00:28,  1.52it/s]Loading train:  83%|████████▎ | 204/247 [02:14<00:28,  1.50it/s]Loading train:  83%|████████▎ | 205/247 [02:14<00:26,  1.59it/s]Loading train:  83%|████████▎ | 206/247 [02:15<00:25,  1.58it/s]Loading train:  84%|████████▍ | 207/247 [02:16<00:25,  1.55it/s]Loading train:  84%|████████▍ | 208/247 [02:17<00:26,  1.49it/s]Loading train:  85%|████████▍ | 209/247 [02:17<00:26,  1.43it/s]Loading train:  85%|████████▌ | 210/247 [02:18<00:24,  1.50it/s]Loading train:  85%|████████▌ | 211/247 [02:18<00:23,  1.54it/s]Loading train:  86%|████████▌ | 212/247 [02:19<00:22,  1.53it/s]Loading train:  86%|████████▌ | 213/247 [02:20<00:23,  1.47it/s]Loading train:  87%|████████▋ | 214/247 [02:20<00:19,  1.69it/s]Loading train:  87%|████████▋ | 215/247 [02:21<00:20,  1.57it/s]Loading train:  87%|████████▋ | 216/247 [02:22<00:19,  1.61it/s]Loading train:  88%|████████▊ | 217/247 [02:22<00:20,  1.44it/s]Loading train:  88%|████████▊ | 218/247 [02:23<00:19,  1.46it/s]Loading train:  89%|████████▊ | 219/247 [02:24<00:19,  1.47it/s]Loading train:  89%|████████▉ | 220/247 [02:24<00:18,  1.45it/s]Loading train:  89%|████████▉ | 221/247 [02:25<00:17,  1.50it/s]Loading train:  90%|████████▉ | 222/247 [02:26<00:17,  1.40it/s]Loading train:  90%|█████████ | 223/247 [02:27<00:17,  1.40it/s]Loading train:  91%|█████████ | 224/247 [02:27<00:16,  1.39it/s]Loading train:  91%|█████████ | 225/247 [02:28<00:14,  1.52it/s]Loading train:  91%|█████████▏| 226/247 [02:29<00:13,  1.50it/s]Loading train:  92%|█████████▏| 227/247 [02:29<00:13,  1.48it/s]Loading train:  92%|█████████▏| 228/247 [02:30<00:12,  1.47it/s]Loading train:  93%|█████████▎| 229/247 [02:31<00:11,  1.56it/s]Loading train:  93%|█████████▎| 230/247 [02:31<00:11,  1.53it/s]Loading train:  94%|█████████▎| 231/247 [02:32<00:10,  1.56it/s]Loading train:  94%|█████████▍| 232/247 [02:33<00:10,  1.48it/s]Loading train:  94%|█████████▍| 233/247 [02:33<00:09,  1.46it/s]Loading train:  95%|█████████▍| 234/247 [02:34<00:08,  1.45it/s]Loading train:  95%|█████████▌| 235/247 [02:34<00:07,  1.60it/s]Loading train:  96%|█████████▌| 236/247 [02:35<00:06,  1.58it/s]Loading train:  96%|█████████▌| 237/247 [02:36<00:06,  1.62it/s]Loading train:  96%|█████████▋| 238/247 [02:37<00:06,  1.48it/s]Loading train:  97%|█████████▋| 239/247 [02:37<00:05,  1.51it/s]Loading train:  97%|█████████▋| 240/247 [02:38<00:04,  1.48it/s]Loading train:  98%|█████████▊| 241/247 [02:38<00:03,  1.67it/s]Loading train:  98%|█████████▊| 242/247 [02:39<00:03,  1.59it/s]Loading train:  98%|█████████▊| 243/247 [02:40<00:02,  1.56it/s]Loading train:  99%|█████████▉| 244/247 [02:40<00:01,  1.54it/s]Loading train:  99%|█████████▉| 245/247 [02:41<00:01,  1.57it/s]Loading train: 100%|█████████▉| 246/247 [02:41<00:00,  1.78it/s]Loading train: 100%|██████████| 247/247 [02:42<00:00,  1.96it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/247 [00:00<00:15, 15.58it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:13, 18.43it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:08, 25.52it/s]concatenating: train:  33%|███▎      | 82/247 [00:00<00:04, 35.68it/s]concatenating: train:  55%|█████▌    | 136/247 [00:00<00:02, 49.55it/s]concatenating: train:  77%|███████▋  | 189/247 [00:00<00:00, 67.97it/s]concatenating: train: 100%|██████████| 247/247 [00:00<00:00, 327.87it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Error in label values min 0.0 max 2.0      1-THALAMUS
Loading test:  20%|██        | 1/5 [00:00<00:03,  1.12it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.22it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.28it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.39it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 12.26it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00, 13.10it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 13.46it/s]
2019-09-01 16:29:49.594115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-09-01 16:29:49.594213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-01 16:29:49.594228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-09-01 16:29:49.594236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-09-01 16:29:49.594630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.41it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.49it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.23it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.01it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.96it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.89it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.06it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.35it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.95it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.02it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.71it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.07it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.84it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.97it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 11.41it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.63it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  9.19it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.91it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 108,122
Non-trainable params: 392,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97426102 0.02573898]
Train on 25213 samples, validate on 542 samples
Epoch 1/300
 - 47s - loss: 0.1109 - acc: 0.9890 - mDice: 0.8387 - val_loss: 0.8037 - val_acc: 0.9910 - val_mDice: 0.7380

Epoch 00001: val_mDice improved from -inf to 0.73799, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 43s - loss: 0.0525 - acc: 0.9942 - mDice: 0.9032 - val_loss: 0.7115 - val_acc: 0.9918 - val_mDice: 0.7550

Epoch 00002: val_mDice improved from 0.73799 to 0.75505, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 43s - loss: 0.0477 - acc: 0.9947 - mDice: 0.9116 - val_loss: 0.3217 - val_acc: 0.9913 - val_mDice: 0.7442

Epoch 00003: val_mDice did not improve from 0.75505
Epoch 4/300
 - 44s - loss: 0.0449 - acc: 0.9950 - mDice: 0.9166 - val_loss: 0.9321 - val_acc: 0.9917 - val_mDice: 0.7599

Epoch 00004: val_mDice improved from 0.75505 to 0.75990, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 44s - loss: 0.0423 - acc: 0.9952 - mDice: 0.9211 - val_loss: 0.1287 - val_acc: 0.9929 - val_mDice: 0.8032

Epoch 00005: val_mDice improved from 0.75990 to 0.80316, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 44s - loss: 0.0407 - acc: 0.9953 - mDice: 0.9240 - val_loss: 0.9939 - val_acc: 0.9909 - val_mDice: 0.7100

Epoch 00006: val_mDice did not improve from 0.80316
Epoch 7/300
 - 45s - loss: 0.0393 - acc: 0.9955 - mDice: 0.9266 - val_loss: 0.3704 - val_acc: 0.9911 - val_mDice: 0.7347

Epoch 00007: val_mDice did not improve from 0.80316
Epoch 8/300
 - 44s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9287 - val_loss: 0.1343 - val_acc: 0.9925 - val_mDice: 0.7919

Epoch 00008: val_mDice did not improve from 0.80316
Epoch 9/300
 - 45s - loss: 0.0372 - acc: 0.9956 - mDice: 0.9303 - val_loss: 0.1642 - val_acc: 0.9923 - val_mDice: 0.7680

Epoch 00009: val_mDice did not improve from 0.80316
Epoch 10/300
 - 45s - loss: 0.0364 - acc: 0.9957 - mDice: 0.9318 - val_loss: 1.0601 - val_acc: 0.9911 - val_mDice: 0.7443

Epoch 00010: val_mDice did not improve from 0.80316
Epoch 11/300
 - 45s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9334 - val_loss: 1.0703 - val_acc: 0.9913 - val_mDice: 0.7369

Epoch 00011: val_mDice did not improve from 0.80316
Epoch 12/300
 - 45s - loss: 0.0348 - acc: 0.9958 - mDice: 0.9347 - val_loss: 0.9607 - val_acc: 0.9911 - val_mDice: 0.7263

Epoch 00012: val_mDice did not improve from 0.80316
Epoch 13/300
 - 45s - loss: 0.0345 - acc: 0.9959 - mDice: 0.9353 - val_loss: 1.2657 - val_acc: 0.9903 - val_mDice: 0.6649

Epoch 00013: val_mDice did not improve from 0.80316
Epoch 14/300
 - 45s - loss: 0.0336 - acc: 0.9960 - mDice: 0.9369 - val_loss: 0.3364 - val_acc: 0.9912 - val_mDice: 0.7198

Epoch 00014: val_mDice did not improve from 0.80316
Epoch 15/300
 - 45s - loss: 0.0331 - acc: 0.9960 - mDice: 0.9378 - val_loss: 1.0893 - val_acc: 0.9908 - val_mDice: 0.6897

Epoch 00015: val_mDice did not improve from 0.80316
Epoch 16/300
 - 45s - loss: 0.0326 - acc: 0.9960 - mDice: 0.9387 - val_loss: 0.3755 - val_acc: 0.9913 - val_mDice: 0.7412

Epoch 00016: val_mDice did not improve from 0.80316
Epoch 17/300
 - 45s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9389 - val_loss: 1.0273 - val_acc: 0.9919 - val_mDice: 0.7541

Epoch 00017: val_mDice did not improve from 0.80316
Epoch 18/300
 - 45s - loss: 0.0319 - acc: 0.9961 - mDice: 0.9399 - val_loss: 0.1490 - val_acc: 0.9922 - val_mDice: 0.7863

Epoch 00018: val_mDice did not improve from 0.80316
Epoch 19/300
 - 45s - loss: 0.0315 - acc: 0.9961 - mDice: 0.9407 - val_loss: 0.4349 - val_acc: 0.9914 - val_mDice: 0.7466

Epoch 00019: val_mDice did not improve from 0.80316
Epoch 20/300
 - 45s - loss: 0.0313 - acc: 0.9962 - mDice: 0.9410 - val_loss: 0.2067 - val_acc: 0.9919 - val_mDice: 0.7618

Epoch 00020: val_mDice did not improve from 0.80316
Epoch 21/300
 - 44s - loss: 0.0310 - acc: 0.9962 - mDice: 0.9416 - val_loss: 1.0830 - val_acc: 0.9919 - val_mDice: 0.7493

Epoch 00021: val_mDice did not improve from 0.80316
Epoch 22/300
 - 45s - loss: 0.0307 - acc: 0.9962 - mDice: 0.9422 - val_loss: 0.1571 - val_acc: 0.9921 - val_mDice: 0.7740

Epoch 00022: val_mDice did not improve from 0.80316
Epoch 23/300
 - 44s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9430 - val_loss: 1.0360 - val_acc: 0.9911 - val_mDice: 0.6828

Epoch 00023: val_mDice did not improve from 0.80316
Epoch 24/300
 - 45s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9432 - val_loss: 0.1368 - val_acc: 0.9927 - val_mDice: 0.7917

Epoch 00024: val_mDice did not improve from 0.80316
Epoch 25/300
 - 44s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9438 - val_loss: 1.0437 - val_acc: 0.9917 - val_mDice: 0.7422

Epoch 00025: val_mDice did not improve from 0.80316
Epoch 26/300
 - 45s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9442 - val_loss: 0.4525 - val_acc: 0.9927 - val_mDice: 0.7719

Epoch 00026: val_mDice did not improve from 0.80316
Epoch 27/300
 - 44s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9442 - val_loss: 1.1400 - val_acc: 0.9913 - val_mDice: 0.7318

Epoch 00027: val_mDice did not improve from 0.80316
Epoch 28/300
 - 45s - loss: 0.0294 - acc: 0.9963 - mDice: 0.9446 - val_loss: 0.3256 - val_acc: 0.9920 - val_mDice: 0.7522

Epoch 00028: val_mDice did not improve from 0.80316
Epoch 29/300
 - 44s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9453 - val_loss: 1.2213 - val_acc: 0.9919 - val_mDice: 0.7277

Epoch 00029: val_mDice did not improve from 0.80316
Epoch 30/300
 - 45s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9455 - val_loss: 0.2415 - val_acc: 0.9921 - val_mDice: 0.7336

Epoch 00030: val_mDice did not improve from 0.80316
Epoch 31/300
 - 44s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9461 - val_loss: 0.3676 - val_acc: 0.9912 - val_mDice: 0.7276

Epoch 00031: val_mDice did not improve from 0.80316
Epoch 32/300
 - 45s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9461 - val_loss: 1.0000 - val_acc: 0.9916 - val_mDice: 0.6964

Epoch 00032: val_mDice did not improve from 0.80316
Epoch 33/300
 - 45s - loss: 0.0283 - acc: 0.9964 - mDice: 0.9465 - val_loss: 0.1757 - val_acc: 0.9922 - val_mDice: 0.7653

Epoch 00033: val_mDice did not improve from 0.80316
Epoch 34/300
 - 44s - loss: 0.0283 - acc: 0.9964 - mDice: 0.9466 - val_loss: 0.2005 - val_acc: 0.9924 - val_mDice: 0.7586

Epoch 00034: val_mDice did not improve from 0.80316
Epoch 35/300
 - 45s - loss: 0.0282 - acc: 0.9964 - mDice: 0.9468 - val_loss: 0.1887 - val_acc: 0.9922 - val_mDice: 0.7510

Epoch 00035: val_mDice did not improve from 0.80316
Epoch 36/300
 - 44s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9474 - val_loss: 0.4319 - val_acc: 0.9914 - val_mDice: 0.7255

Epoch 00036: val_mDice did not improve from 0.80316
Epoch 37/300
 - 45s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9475 - val_loss: 0.2583 - val_acc: 0.9917 - val_mDice: 0.7266

Epoch 00037: val_mDice did not improve from 0.80316
Epoch 38/300
 - 45s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9475 - val_loss: 0.2476 - val_acc: 0.9921 - val_mDice: 0.7445

Epoch 00038: val_mDice did not improve from 0.80316
Epoch 39/300
 - 45s - loss: 0.0276 - acc: 0.9965 - mDice: 0.9480 - val_loss: 0.2020 - val_acc: 0.9917 - val_mDice: 0.7475

Epoch 00039: val_mDice did not improve from 0.80316
Epoch 40/300
 - 44s - loss: 0.0276 - acc: 0.9965 - mDice: 0.9480 - val_loss: 1.2092 - val_acc: 0.9912 - val_mDice: 0.7140

Epoch 00040: val_mDice did not improve from 0.80316
Epoch 41/300
 - 45s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9484 - val_loss: 0.3464 - val_acc: 0.9915 - val_mDice: 0.6985

Epoch 00041: val_mDice did not improve from 0.80316
Epoch 42/300
 - 44s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9484 - val_loss: 0.4108 - val_acc: 0.9912 - val_mDice: 0.6967

Epoch 00042: val_mDice did not improve from 0.80316
Epoch 43/300
 - 44s - loss: 0.0271 - acc: 0.9965 - mDice: 0.9487 - val_loss: 0.1492 - val_acc: 0.9930 - val_mDice: 0.7897

Epoch 00043: val_mDice did not improve from 0.80316
Epoch 44/300
 - 45s - loss: 0.0270 - acc: 0.9965 - mDice: 0.9490 - val_loss: 0.2263 - val_acc: 0.9921 - val_mDice: 0.7362

Epoch 00044: val_mDice did not improve from 0.80316
Epoch 45/300
 - 45s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9491 - val_loss: 0.2241 - val_acc: 0.9919 - val_mDice: 0.7354

Epoch 00045: val_mDice did not improve from 0.80316
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [0.8037383499593093, 0.7115403866168538, 0.32168593264538864, 0.9321076831886909, 0.1286731470527464, 0.9938562836676726, 0.37035493646160705, 0.13428378046053802, 0.1641971055981858, 1.060142148313597, 1.0703363731173572, 0.9607086204184817, 1.2656649426725517, 0.33643349752215, 1.08930719396395, 0.3755244538737839, 1.0272922913691653, 0.14901634774469802, 0.43488984043637763, 0.20668876514773526, 1.0829547955156253, 0.15707692646892307, 1.036040980355106, 0.13683949695467068, 1.0437087117938317, 0.4525421239105758, 1.1400082661079525, 0.3255588887774856, 1.221330675389274, 0.24147747819933943, 0.36764469377119163, 0.9999973676906301, 0.17565300415967663, 0.200549718377445, 0.18868941130508357, 0.43188939381019653, 0.25828754005616883, 0.2475897291764562, 0.20200329469138845, 1.2092487106161585, 0.3464081227861867, 0.41080843257233224, 0.1492423816305685, 0.22634134157062458, 0.2240824373335856], 'val_acc': [0.9910284608492552, 0.9918329680537825, 0.9912901039053154, 0.9917315858316598, 0.992899556001614, 0.9909160700231461, 0.9911484958060993, 0.9925372050697073, 0.9922670224935806, 0.991116573229927, 0.9912604397073443, 0.9911195026552545, 0.990266449337076, 0.9912017663026648, 0.9907731077327939, 0.9913283263185367, 0.9918965703886813, 0.9921879027162531, 0.9914193624060093, 0.991896569508908, 0.9919215247199984, 0.992127869621854, 0.9910920777004143, 0.9927181632316421, 0.9917448374178137, 0.9927273773179283, 0.9913478766420231, 0.9920197454765713, 0.9918646638683727, 0.9920548178612966, 0.9912390860684244, 0.9915645744967725, 0.9921611340723354, 0.9923648009440995, 0.9921730545614038, 0.9913795770754233, 0.9916569634557211, 0.9920817945716126, 0.9917147280545252, 0.9911615265691412, 0.9915358028288697, 0.9912370632495388, 0.9929977925941074, 0.9921469864370198, 0.9919350153845614], 'val_mDice': [0.7379900090065832, 0.7550488056289177, 0.744233961550457, 0.7598959407331669, 0.8031567772816028, 0.710005217674309, 0.7347228387370706, 0.7918604107580501, 0.7679821175842707, 0.7442915381135637, 0.7369454348875171, 0.7262786680100315, 0.6649309416405658, 0.7197548720119624, 0.689701840733309, 0.7412176982695546, 0.7541200058150594, 0.7863438138222782, 0.7465792137455467, 0.7617619023881715, 0.7492615863637884, 0.773975971000221, 0.6828033272521175, 0.7916648064592228, 0.742151581514344, 0.7718954173491699, 0.7318001751491908, 0.7521967941455241, 0.7277229260034782, 0.7335860437792605, 0.7276292488192005, 0.6963698939992219, 0.7652844860874859, 0.7585565959175574, 0.7510431098212176, 0.7255014327854756, 0.7266200573297005, 0.7444605113065551, 0.7474747256159342, 0.7140110664086157, 0.6984706477939093, 0.6967155062576337, 0.7896759400068614, 0.7361570182101753, 0.7354383543958524], 'loss': [0.11089406678689419, 0.05252075015142786, 0.04771937838781146, 0.04486289052482197, 0.042344248329434016, 0.040712373238917555, 0.03925619261759737, 0.03812754830676551, 0.03720968655365129, 0.03642627972154558, 0.03552106741356442, 0.03481326627868674, 0.03445373912981034, 0.03361517565213128, 0.03309856751204608, 0.032607045406869796, 0.03247434403428913, 0.03192917552062952, 0.03153083374737755, 0.03133372619880502, 0.031030458724659978, 0.03069766848668889, 0.030257195868084164, 0.030141532472677774, 0.02984081854067788, 0.029622944412754537, 0.029578491291124696, 0.029377467149074216, 0.02902743921815056, 0.02889993919914901, 0.028568147125105796, 0.028598503693060603, 0.02834964760304755, 0.0283205132228611, 0.028184684417583043, 0.02786810556557775, 0.027812034312182207, 0.027824053733199936, 0.027559753194287624, 0.027550462700598858, 0.027311049545966793, 0.027337150549463556, 0.027147049104030756, 0.027032086087210302, 0.026930466115507798], 'acc': [0.9889983626490558, 0.9942342713176767, 0.9946904271038456, 0.9949650705884319, 0.995188838228591, 0.9953204745393013, 0.9954548942779401, 0.9955595724714018, 0.9956372534652376, 0.9957063670071011, 0.9957952589199686, 0.9958418744991835, 0.995879332598835, 0.9959542652755256, 0.995997953071185, 0.9960345361955493, 0.9960670045852585, 0.9961094048964776, 0.9961417550390632, 0.9961599266189134, 0.9961957202920152, 0.9962211531516282, 0.9962574323426584, 0.9962654288779719, 0.9962917707480154, 0.9963095845156015, 0.9963120455257348, 0.9963287683011368, 0.9963582776191664, 0.9963797424259707, 0.9964009516512355, 0.9963966410318834, 0.9964144466647936, 0.9964137512386585, 0.9964333997125292, 0.9964624638952324, 0.9964579272874452, 0.9964623207854566, 0.9964825714735662, 0.9964760278490455, 0.9965079880260028, 0.9964969421408922, 0.9965068722751845, 0.9965276744333258, 0.9965347185969111], 'mDice': [0.8386786900886544, 0.903170212654717, 0.9115604939513898, 0.916610405684151, 0.9211015855311421, 0.9240290610777865, 0.9266425321312353, 0.9286763432743349, 0.9303346474933892, 0.9317512866104438, 0.9333909444101071, 0.9346846563361323, 0.9353352804944804, 0.9368615031256555, 0.937806895018163, 0.9387044610992492, 0.9389394164435266, 0.9399324143953686, 0.9406653948987258, 0.9410225840480676, 0.941576713357399, 0.9421912503040131, 0.9430020300412374, 0.94321290695298, 0.9437672312439436, 0.9441684696442009, 0.9442469328931486, 0.9446216129691174, 0.9452678057669232, 0.9454999828439804, 0.9461121236711086, 0.9460597370488165, 0.9465182967392686, 0.9465725952444303, 0.9468238540583297, 0.947407691695654, 0.9475152530016934, 0.9474926377044421, 0.9479839329594154, 0.9479965818130204, 0.9484407348057499, 0.9483946798666937, 0.9487496651713513, 0.9489590144685064, 0.9491482651848797]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.00it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.18it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.40it/s]predicting test subjects:  80%|████████  | 4/5 [00:02<00:00,  1.69it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<01:29,  2.73it/s]predicting train subjects:   1%|          | 2/247 [00:00<01:26,  2.84it/s]predicting train subjects:   1%|          | 3/247 [00:01<01:24,  2.88it/s]predicting train subjects:   2%|▏         | 4/247 [00:01<01:23,  2.91it/s]predicting train subjects:   2%|▏         | 5/247 [00:01<01:19,  3.06it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<01:18,  3.05it/s]predicting train subjects:   3%|▎         | 7/247 [00:02<01:15,  3.18it/s]predicting train subjects:   3%|▎         | 8/247 [00:02<01:17,  3.09it/s]predicting train subjects:   4%|▎         | 9/247 [00:02<01:17,  3.08it/s]predicting train subjects:   4%|▍         | 10/247 [00:03<01:15,  3.15it/s]predicting train subjects:   4%|▍         | 11/247 [00:03<01:18,  2.99it/s]predicting train subjects:   5%|▍         | 12/247 [00:03<01:12,  3.25it/s]predicting train subjects:   5%|▌         | 13/247 [00:04<01:09,  3.39it/s]predicting train subjects:   6%|▌         | 14/247 [00:04<01:08,  3.42it/s]predicting train subjects:   6%|▌         | 15/247 [00:04<01:06,  3.51it/s]predicting train subjects:   6%|▋         | 16/247 [00:04<01:08,  3.40it/s]predicting train subjects:   7%|▋         | 17/247 [00:05<01:10,  3.28it/s]predicting train subjects:   7%|▋         | 18/247 [00:05<01:08,  3.36it/s]predicting train subjects:   8%|▊         | 19/247 [00:05<01:07,  3.37it/s]predicting train subjects:   8%|▊         | 20/247 [00:06<01:04,  3.53it/s]predicting train subjects:   9%|▊         | 21/247 [00:06<01:04,  3.53it/s]predicting train subjects:   9%|▉         | 22/247 [00:06<01:01,  3.68it/s]predicting train subjects:   9%|▉         | 23/247 [00:06<01:03,  3.54it/s]predicting train subjects:  10%|▉         | 24/247 [00:07<01:04,  3.46it/s]predicting train subjects:  10%|█         | 25/247 [00:07<01:04,  3.43it/s]predicting train subjects:  11%|█         | 26/247 [00:07<01:02,  3.55it/s]predicting train subjects:  11%|█         | 27/247 [00:08<01:02,  3.50it/s]predicting train subjects:  11%|█▏        | 28/247 [00:08<00:59,  3.66it/s]predicting train subjects:  12%|█▏        | 29/247 [00:08<01:01,  3.52it/s]predicting train subjects:  12%|█▏        | 30/247 [00:08<01:02,  3.49it/s]predicting train subjects:  13%|█▎        | 31/247 [00:09<01:00,  3.60it/s]predicting train subjects:  13%|█▎        | 32/247 [00:09<01:04,  3.35it/s]predicting train subjects:  13%|█▎        | 33/247 [00:09<01:00,  3.54it/s]predicting train subjects:  14%|█▍        | 34/247 [00:10<00:58,  3.66it/s]predicting train subjects:  14%|█▍        | 35/247 [00:10<01:07,  3.15it/s]predicting train subjects:  15%|█▍        | 36/247 [00:10<01:04,  3.26it/s]predicting train subjects:  15%|█▍        | 37/247 [00:11<01:02,  3.38it/s]predicting train subjects:  15%|█▌        | 38/247 [00:11<01:01,  3.41it/s]predicting train subjects:  16%|█▌        | 39/247 [00:11<00:57,  3.59it/s]predicting train subjects:  16%|█▌        | 40/247 [00:11<00:55,  3.73it/s]predicting train subjects:  17%|█▋        | 41/247 [00:12<00:56,  3.63it/s]predicting train subjects:  17%|█▋        | 42/247 [00:12<00:57,  3.58it/s]predicting train subjects:  17%|█▋        | 43/247 [00:12<00:57,  3.55it/s]predicting train subjects:  18%|█▊        | 44/247 [00:12<00:55,  3.63it/s]predicting train subjects:  18%|█▊        | 45/247 [00:13<00:54,  3.72it/s]predicting train subjects:  19%|█▊        | 46/247 [00:13<00:54,  3.67it/s]predicting train subjects:  19%|█▉        | 47/247 [00:13<00:53,  3.75it/s]predicting train subjects:  19%|█▉        | 48/247 [00:14<00:54,  3.65it/s]predicting train subjects:  20%|█▉        | 49/247 [00:14<00:52,  3.75it/s]predicting train subjects:  20%|██        | 50/247 [00:14<00:53,  3.68it/s]predicting train subjects:  21%|██        | 51/247 [00:14<00:51,  3.78it/s]predicting train subjects:  21%|██        | 52/247 [00:15<00:52,  3.70it/s]predicting train subjects:  21%|██▏       | 53/247 [00:15<00:53,  3.65it/s]predicting train subjects:  22%|██▏       | 54/247 [00:15<00:52,  3.70it/s]predicting train subjects:  22%|██▏       | 55/247 [00:15<00:53,  3.59it/s]predicting train subjects:  23%|██▎       | 56/247 [00:16<00:53,  3.57it/s]predicting train subjects:  23%|██▎       | 57/247 [00:16<00:53,  3.58it/s]predicting train subjects:  23%|██▎       | 58/247 [00:16<00:53,  3.51it/s]predicting train subjects:  24%|██▍       | 59/247 [00:17<00:51,  3.65it/s]predicting train subjects:  24%|██▍       | 60/247 [00:17<00:49,  3.77it/s]predicting train subjects:  25%|██▍       | 61/247 [00:17<00:51,  3.63it/s]predicting train subjects:  25%|██▌       | 62/247 [00:17<00:50,  3.66it/s]predicting train subjects:  26%|██▌       | 63/247 [00:18<00:50,  3.63it/s]predicting train subjects:  26%|██▌       | 64/247 [00:18<00:49,  3.72it/s]predicting train subjects:  26%|██▋       | 65/247 [00:18<00:49,  3.70it/s]predicting train subjects:  27%|██▋       | 66/247 [00:18<00:49,  3.64it/s]predicting train subjects:  27%|██▋       | 67/247 [00:19<00:51,  3.52it/s]predicting train subjects:  28%|██▊       | 68/247 [00:19<00:50,  3.53it/s]predicting train subjects:  28%|██▊       | 69/247 [00:19<00:53,  3.34it/s]predicting train subjects:  28%|██▊       | 70/247 [00:20<00:55,  3.21it/s]predicting train subjects:  29%|██▊       | 71/247 [00:20<00:53,  3.26it/s]predicting train subjects:  29%|██▉       | 72/247 [00:20<00:50,  3.47it/s]predicting train subjects:  30%|██▉       | 73/247 [00:21<00:48,  3.55it/s]predicting train subjects:  30%|██▉       | 74/247 [00:21<00:47,  3.68it/s]predicting train subjects:  30%|███       | 75/247 [00:21<00:50,  3.44it/s]predicting train subjects:  31%|███       | 76/247 [00:21<00:48,  3.53it/s]predicting train subjects:  31%|███       | 77/247 [00:22<00:46,  3.62it/s]predicting train subjects:  32%|███▏      | 78/247 [00:22<00:48,  3.46it/s]predicting train subjects:  32%|███▏      | 79/247 [00:22<00:49,  3.37it/s]predicting train subjects:  32%|███▏      | 80/247 [00:23<00:55,  2.99it/s]predicting train subjects:  33%|███▎      | 81/247 [00:23<01:04,  2.57it/s]predicting train subjects:  33%|███▎      | 82/247 [00:24<01:06,  2.50it/s]predicting train subjects:  34%|███▎      | 83/247 [00:24<00:57,  2.83it/s]predicting train subjects:  34%|███▍      | 84/247 [00:24<00:54,  2.97it/s]predicting train subjects:  34%|███▍      | 85/247 [00:25<00:54,  2.95it/s]predicting train subjects:  35%|███▍      | 86/247 [00:25<00:52,  3.05it/s]predicting train subjects:  35%|███▌      | 87/247 [00:25<00:55,  2.87it/s]predicting train subjects:  36%|███▌      | 88/247 [00:26<00:56,  2.83it/s]predicting train subjects:  36%|███▌      | 89/247 [00:26<00:51,  3.08it/s]predicting train subjects:  36%|███▋      | 90/247 [00:26<00:49,  3.17it/s]predicting train subjects:  37%|███▋      | 91/247 [00:26<00:49,  3.18it/s]predicting train subjects:  37%|███▋      | 92/247 [00:27<00:48,  3.18it/s]predicting train subjects:  38%|███▊      | 93/247 [00:27<00:49,  3.12it/s]predicting train subjects:  38%|███▊      | 94/247 [00:27<00:50,  3.05it/s]predicting train subjects:  38%|███▊      | 95/247 [00:28<00:48,  3.15it/s]predicting train subjects:  39%|███▉      | 96/247 [00:28<00:45,  3.33it/s]predicting train subjects:  39%|███▉      | 97/247 [00:28<00:44,  3.35it/s]predicting train subjects:  40%|███▉      | 98/247 [00:29<00:45,  3.30it/s]predicting train subjects:  40%|████      | 99/247 [00:29<00:45,  3.25it/s]predicting train subjects:  40%|████      | 100/247 [00:29<00:45,  3.21it/s]predicting train subjects:  41%|████      | 101/247 [00:30<00:45,  3.21it/s]predicting train subjects:  41%|████▏     | 102/247 [00:30<00:45,  3.18it/s]predicting train subjects:  42%|████▏     | 103/247 [00:30<00:42,  3.38it/s]predicting train subjects:  42%|████▏     | 104/247 [00:30<00:44,  3.21it/s]predicting train subjects:  43%|████▎     | 105/247 [00:31<00:43,  3.29it/s]predicting train subjects:  43%|████▎     | 106/247 [00:31<00:41,  3.42it/s]predicting train subjects:  43%|████▎     | 107/247 [00:31<00:42,  3.29it/s]predicting train subjects:  44%|████▎     | 108/247 [00:32<00:41,  3.36it/s]predicting train subjects:  44%|████▍     | 109/247 [00:32<00:41,  3.30it/s]predicting train subjects:  45%|████▍     | 110/247 [00:32<00:43,  3.14it/s]predicting train subjects:  45%|████▍     | 111/247 [00:33<00:44,  3.09it/s]predicting train subjects:  45%|████▌     | 112/247 [00:33<00:41,  3.27it/s]predicting train subjects:  46%|████▌     | 113/247 [00:33<00:41,  3.20it/s]predicting train subjects:  46%|████▌     | 114/247 [00:34<00:40,  3.32it/s]predicting train subjects:  47%|████▋     | 115/247 [00:34<00:39,  3.36it/s]predicting train subjects:  47%|████▋     | 116/247 [00:34<00:40,  3.22it/s]predicting train subjects:  47%|████▋     | 117/247 [00:34<00:41,  3.13it/s]predicting train subjects:  48%|████▊     | 118/247 [00:35<00:39,  3.28it/s]predicting train subjects:  48%|████▊     | 119/247 [00:35<00:40,  3.15it/s]predicting train subjects:  49%|████▊     | 120/247 [00:35<00:40,  3.16it/s]predicting train subjects:  49%|████▉     | 121/247 [00:36<00:39,  3.18it/s]predicting train subjects:  49%|████▉     | 122/247 [00:36<00:39,  3.13it/s]predicting train subjects:  50%|████▉     | 123/247 [00:36<00:36,  3.39it/s]predicting train subjects:  50%|█████     | 124/247 [00:37<00:35,  3.42it/s]predicting train subjects:  51%|█████     | 125/247 [00:37<00:35,  3.39it/s]predicting train subjects:  51%|█████     | 126/247 [00:37<00:36,  3.30it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:37<00:35,  3.42it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:38<00:32,  3.62it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:38<00:33,  3.52it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:38<00:35,  3.29it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:39<00:34,  3.32it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:39<00:35,  3.22it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:39<00:35,  3.22it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:40<00:35,  3.20it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:40<00:34,  3.25it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:40<00:35,  3.12it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:41<00:36,  3.01it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:41<00:34,  3.11it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:41<00:34,  3.09it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:42<00:33,  3.24it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:42<00:31,  3.41it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:42<00:30,  3.39it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:42<00:31,  3.30it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:43<00:34,  2.97it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:43<00:36,  2.83it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:44<00:37,  2.72it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:44<00:34,  2.88it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:44<00:33,  2.96it/s]predicting train subjects:  60%|██████    | 149/247 [00:45<00:32,  3.03it/s]predicting train subjects:  61%|██████    | 150/247 [00:45<00:30,  3.19it/s]predicting train subjects:  61%|██████    | 151/247 [00:45<00:30,  3.17it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:45<00:30,  3.09it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:46<00:31,  3.01it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:46<00:30,  3.02it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:46<00:29,  3.10it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:47<00:27,  3.29it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:47<00:27,  3.27it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:47<00:28,  3.17it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:48<00:25,  3.41it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:48<00:26,  3.25it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:48<00:26,  3.23it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:49<00:26,  3.23it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:49<00:26,  3.15it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:49<00:25,  3.29it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:49<00:23,  3.50it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:50<00:23,  3.45it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:50<00:23,  3.43it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:50<00:24,  3.26it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:51<00:23,  3.38it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:51<00:22,  3.41it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:51<00:21,  3.48it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:52<00:22,  3.35it/s]predicting train subjects:  70%|███████   | 173/247 [00:52<00:23,  3.20it/s]predicting train subjects:  70%|███████   | 174/247 [00:52<00:22,  3.25it/s]predicting train subjects:  71%|███████   | 175/247 [00:53<00:23,  3.06it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:53<00:24,  2.89it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:53<00:22,  3.13it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:53<00:20,  3.37it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:54<00:19,  3.47it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:54<00:20,  3.34it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:54<00:20,  3.16it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:55<00:19,  3.27it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:55<00:18,  3.46it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:55<00:17,  3.62it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:55<00:16,  3.67it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:56<00:17,  3.46it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:56<00:18,  3.26it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:56<00:17,  3.30it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:57<00:16,  3.49it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:57<00:16,  3.49it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:57<00:16,  3.44it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:58<00:16,  3.40it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:58<00:16,  3.30it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:58<00:16,  3.24it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:58<00:15,  3.34it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:59<00:14,  3.44it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:59<00:14,  3.38it/s]predicting train subjects:  80%|████████  | 198/247 [00:59<00:14,  3.42it/s]predicting train subjects:  81%|████████  | 199/247 [01:00<00:13,  3.55it/s]predicting train subjects:  81%|████████  | 200/247 [01:00<00:13,  3.59it/s]predicting train subjects:  81%|████████▏ | 201/247 [01:00<00:13,  3.48it/s]predicting train subjects:  82%|████████▏ | 202/247 [01:00<00:13,  3.33it/s]predicting train subjects:  82%|████████▏ | 203/247 [01:01<00:13,  3.22it/s]predicting train subjects:  83%|████████▎ | 204/247 [01:01<00:12,  3.32it/s]predicting train subjects:  83%|████████▎ | 205/247 [01:01<00:12,  3.42it/s]predicting train subjects:  83%|████████▎ | 206/247 [01:02<00:12,  3.33it/s]predicting train subjects:  84%|████████▍ | 207/247 [01:02<00:11,  3.47it/s]predicting train subjects:  84%|████████▍ | 208/247 [01:02<00:11,  3.31it/s]predicting train subjects:  85%|████████▍ | 209/247 [01:03<00:12,  3.06it/s]predicting train subjects:  85%|████████▌ | 210/247 [01:03<00:12,  3.05it/s]predicting train subjects:  85%|████████▌ | 211/247 [01:03<00:11,  3.25it/s]predicting train subjects:  86%|████████▌ | 212/247 [01:04<00:10,  3.42it/s]predicting train subjects:  86%|████████▌ | 213/247 [01:04<00:09,  3.41it/s]predicting train subjects:  87%|████████▋ | 214/247 [01:04<00:09,  3.53it/s]predicting train subjects:  87%|████████▋ | 215/247 [01:04<00:08,  3.63it/s]predicting train subjects:  87%|████████▋ | 216/247 [01:05<00:09,  3.43it/s]predicting train subjects:  88%|████████▊ | 217/247 [01:05<00:09,  3.32it/s]predicting train subjects:  88%|████████▊ | 218/247 [01:05<00:08,  3.40it/s]predicting train subjects:  89%|████████▊ | 219/247 [01:05<00:07,  3.58it/s]predicting train subjects:  89%|████████▉ | 220/247 [01:06<00:08,  3.19it/s]predicting train subjects:  89%|████████▉ | 221/247 [01:06<00:07,  3.36it/s]predicting train subjects:  90%|████████▉ | 222/247 [01:06<00:07,  3.31it/s]predicting train subjects:  90%|█████████ | 223/247 [01:07<00:06,  3.51it/s]predicting train subjects:  91%|█████████ | 224/247 [01:07<00:06,  3.45it/s]predicting train subjects:  91%|█████████ | 225/247 [01:07<00:06,  3.64it/s]predicting train subjects:  91%|█████████▏| 226/247 [01:08<00:06,  3.45it/s]predicting train subjects:  92%|█████████▏| 227/247 [01:08<00:05,  3.43it/s]predicting train subjects:  92%|█████████▏| 228/247 [01:08<00:05,  3.56it/s]predicting train subjects:  93%|█████████▎| 229/247 [01:08<00:05,  3.54it/s]predicting train subjects:  93%|█████████▎| 230/247 [01:09<00:04,  3.67it/s]predicting train subjects:  94%|█████████▎| 231/247 [01:09<00:04,  3.63it/s]predicting train subjects:  94%|█████████▍| 232/247 [01:09<00:04,  3.26it/s]predicting train subjects:  94%|█████████▍| 233/247 [01:10<00:04,  3.38it/s]predicting train subjects:  95%|█████████▍| 234/247 [01:10<00:03,  3.44it/s]predicting train subjects:  95%|█████████▌| 235/247 [01:10<00:03,  3.47it/s]predicting train subjects:  96%|█████████▌| 236/247 [01:10<00:03,  3.38it/s]predicting train subjects:  96%|█████████▌| 237/247 [01:11<00:02,  3.52it/s]predicting train subjects:  96%|█████████▋| 238/247 [01:11<00:02,  3.39it/s]predicting train subjects:  97%|█████████▋| 239/247 [01:11<00:02,  3.52it/s]predicting train subjects:  97%|█████████▋| 240/247 [01:12<00:01,  3.68it/s]predicting train subjects:  98%|█████████▊| 241/247 [01:12<00:01,  3.72it/s]predicting train subjects:  98%|█████████▊| 242/247 [01:12<00:01,  3.77it/s]predicting train subjects:  98%|█████████▊| 243/247 [01:12<00:01,  3.45it/s]predicting train subjects:  99%|█████████▉| 244/247 [01:13<00:00,  3.33it/s]predicting train subjects:  99%|█████████▉| 245/247 [01:13<00:00,  3.41it/s]predicting train subjects: 100%|█████████▉| 246/247 [01:13<00:00,  3.47it/s]predicting train subjects: 100%|██████████| 247/247 [01:14<00:00,  3.59it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 58.50it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/247 [00:00<00:03, 66.02it/s]saving BB  train1-THALAMUS:   6%|▌         | 15/247 [00:00<00:03, 68.02it/s]saving BB  train1-THALAMUS:   9%|▉         | 23/247 [00:00<00:03, 69.45it/s]saving BB  train1-THALAMUS:  13%|█▎        | 31/247 [00:00<00:03, 70.95it/s]saving BB  train1-THALAMUS:  16%|█▌        | 39/247 [00:00<00:02, 72.05it/s]saving BB  train1-THALAMUS:  19%|█▉        | 47/247 [00:00<00:02, 73.00it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 74.28it/s]saving BB  train1-THALAMUS:  26%|██▌       | 63/247 [00:00<00:02, 73.98it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 74.32it/s]saving BB  train1-THALAMUS:  32%|███▏      | 79/247 [00:01<00:02, 73.66it/s]saving BB  train1-THALAMUS:  35%|███▌      | 87/247 [00:01<00:02, 71.00it/s]saving BB  train1-THALAMUS:  38%|███▊      | 95/247 [00:01<00:02, 70.96it/s]saving BB  train1-THALAMUS:  42%|████▏     | 103/247 [00:01<00:01, 72.09it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 71.76it/s]saving BB  train1-THALAMUS:  48%|████▊     | 119/247 [00:01<00:01, 71.53it/s]saving BB  train1-THALAMUS:  51%|█████▏    | 127/247 [00:01<00:01, 71.57it/s]saving BB  train1-THALAMUS:  55%|█████▍    | 135/247 [00:01<00:01, 70.65it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 143/247 [00:01<00:01, 70.23it/s]saving BB  train1-THALAMUS:  61%|██████    | 151/247 [00:02<00:01, 70.59it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 159/247 [00:02<00:01, 70.42it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 167/247 [00:02<00:01, 70.54it/s]saving BB  train1-THALAMUS:  71%|███████   | 175/247 [00:02<00:01, 70.42it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 183/247 [00:02<00:00, 70.83it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 191/247 [00:02<00:00, 70.41it/s]saving BB  train1-THALAMUS:  81%|████████  | 199/247 [00:02<00:00, 69.71it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 207/247 [00:02<00:00, 70.15it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 215/247 [00:03<00:00, 69.90it/s]saving BB  train1-THALAMUS:  90%|████████▉ | 222/247 [00:03<00:00, 68.96it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 229/247 [00:03<00:00, 68.78it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 237/247 [00:03<00:00, 70.10it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 245/247 [00:03<00:00, 70.95it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 71.32it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_BC_CSFn
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<06:06,  1.49s/it]Loading train:   1%|          | 2/247 [00:02<05:43,  1.40s/it]Loading train:   1%|          | 3/247 [00:03<05:15,  1.29s/it]Loading train:   2%|▏         | 4/247 [00:05<05:24,  1.33s/it]Loading train:   2%|▏         | 5/247 [00:05<04:43,  1.17s/it]Loading train:   2%|▏         | 6/247 [00:06<04:24,  1.10s/it]Loading train:   3%|▎         | 7/247 [00:07<04:02,  1.01s/it]Loading train:   3%|▎         | 8/247 [00:08<03:52,  1.03it/s]Loading train:   4%|▎         | 9/247 [00:09<03:42,  1.07it/s]Loading train:   4%|▍         | 10/247 [00:10<03:35,  1.10it/s]Loading train:   4%|▍         | 11/247 [00:11<03:33,  1.10it/s]Loading train:   5%|▍         | 12/247 [00:11<03:22,  1.16it/s]Loading train:   5%|▌         | 13/247 [00:12<03:18,  1.18it/s]Loading train:   6%|▌         | 14/247 [00:13<03:27,  1.12it/s]Loading train:   6%|▌         | 15/247 [00:14<03:14,  1.20it/s]Loading train:   6%|▋         | 16/247 [00:15<03:14,  1.19it/s]Loading train:   7%|▋         | 17/247 [00:16<03:13,  1.19it/s]Loading train:   7%|▋         | 18/247 [00:16<03:09,  1.21it/s]Loading train:   8%|▊         | 19/247 [00:17<03:16,  1.16it/s]Loading train:   8%|▊         | 20/247 [00:18<03:09,  1.20it/s]Loading train:   9%|▊         | 21/247 [00:19<03:11,  1.18it/s]Loading train:   9%|▉         | 22/247 [00:20<03:04,  1.22it/s]Loading train:   9%|▉         | 23/247 [00:21<03:07,  1.20it/s]Loading train:  10%|▉         | 24/247 [00:22<03:16,  1.14it/s]Loading train:  10%|█         | 25/247 [00:23<03:22,  1.09it/s]Loading train:  11%|█         | 26/247 [00:23<03:12,  1.15it/s]Loading train:  11%|█         | 27/247 [00:24<03:06,  1.18it/s]Loading train:  11%|█▏        | 28/247 [00:25<02:58,  1.22it/s]Loading train:  12%|█▏        | 29/247 [00:26<03:07,  1.16it/s]Loading train:  12%|█▏        | 30/247 [00:27<03:06,  1.16it/s]Loading train:  13%|█▎        | 31/247 [00:28<03:03,  1.18it/s]Loading train:  13%|█▎        | 32/247 [00:29<03:22,  1.06it/s]Loading train:  13%|█▎        | 33/247 [00:29<03:09,  1.13it/s]Loading train:  14%|█▍        | 34/247 [00:30<03:03,  1.16it/s]Loading train:  14%|█▍        | 35/247 [00:31<03:09,  1.12it/s]Loading train:  15%|█▍        | 36/247 [00:32<03:10,  1.11it/s]Loading train:  15%|█▍        | 37/247 [00:33<03:14,  1.08it/s]Loading train:  15%|█▌        | 38/247 [00:34<03:13,  1.08it/s]Loading train:  16%|█▌        | 39/247 [00:35<03:05,  1.12it/s]Loading train:  16%|█▌        | 40/247 [00:36<02:57,  1.17it/s]Loading train:  17%|█▋        | 41/247 [00:37<02:59,  1.15it/s]Loading train:  17%|█▋        | 42/247 [00:37<02:58,  1.15it/s]Loading train:  17%|█▋        | 43/247 [00:38<02:57,  1.15it/s]Loading train:  18%|█▊        | 44/247 [00:39<02:50,  1.19it/s]Loading train:  18%|█▊        | 45/247 [00:40<02:45,  1.22it/s]Loading train:  19%|█▊        | 46/247 [00:41<02:58,  1.12it/s]Loading train:  19%|█▉        | 47/247 [00:42<02:49,  1.18it/s]Loading train:  19%|█▉        | 48/247 [00:43<02:52,  1.16it/s]Loading train:  20%|█▉        | 49/247 [00:43<02:47,  1.18it/s]Loading train:  20%|██        | 50/247 [00:44<02:51,  1.15it/s]Loading train:  21%|██        | 51/247 [00:45<02:43,  1.20it/s]Loading train:  21%|██        | 52/247 [00:46<02:45,  1.18it/s]Loading train:  21%|██▏       | 53/247 [00:47<02:42,  1.20it/s]Loading train:  22%|██▏       | 54/247 [00:47<02:35,  1.24it/s]Loading train:  22%|██▏       | 55/247 [00:48<02:47,  1.15it/s]Loading train:  23%|██▎       | 56/247 [00:49<02:44,  1.16it/s]Loading train:  23%|██▎       | 57/247 [00:50<02:49,  1.12it/s]Loading train:  23%|██▎       | 58/247 [00:51<02:50,  1.11it/s]Loading train:  24%|██▍       | 59/247 [00:52<02:51,  1.10it/s]Loading train:  24%|██▍       | 60/247 [00:53<02:51,  1.09it/s]Loading train:  25%|██▍       | 61/247 [00:54<02:55,  1.06it/s]Loading train:  25%|██▌       | 62/247 [00:55<02:57,  1.04it/s]Loading train:  26%|██▌       | 63/247 [00:56<03:00,  1.02it/s]Loading train:  26%|██▌       | 64/247 [00:57<02:49,  1.08it/s]Loading train:  26%|██▋       | 65/247 [00:58<02:44,  1.11it/s]Loading train:  27%|██▋       | 66/247 [00:59<02:43,  1.11it/s]Loading train:  27%|██▋       | 67/247 [01:00<02:52,  1.04it/s]Loading train:  28%|██▊       | 68/247 [01:01<02:48,  1.06it/s]Loading train:  28%|██▊       | 69/247 [01:02<02:51,  1.04it/s]Loading train:  28%|██▊       | 70/247 [01:03<02:43,  1.08it/s]Loading train:  29%|██▊       | 71/247 [01:04<02:46,  1.06it/s]Loading train:  29%|██▉       | 72/247 [01:04<02:33,  1.14it/s]Loading train:  30%|██▉       | 73/247 [01:05<02:30,  1.16it/s]Loading train:  30%|██▉       | 74/247 [01:06<02:29,  1.16it/s]Loading train:  30%|███       | 75/247 [01:07<02:33,  1.12it/s]Loading train:  31%|███       | 76/247 [01:08<02:23,  1.19it/s]Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Loading train:  31%|███       | 77/247 [01:09<02:38,  1.07it/s]Loading train:  32%|███▏      | 78/247 [01:10<03:01,  1.08s/it]Loading train:  32%|███▏      | 79/247 [01:11<03:04,  1.10s/it]Loading train:  32%|███▏      | 80/247 [01:13<03:17,  1.18s/it]Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Loading train:  33%|███▎      | 81/247 [01:14<03:21,  1.22s/it]Loading train:  33%|███▎      | 82/247 [01:15<03:08,  1.14s/it]Loading train:  34%|███▎      | 83/247 [01:16<02:56,  1.08s/it]Loading train:  34%|███▍      | 84/247 [01:17<02:54,  1.07s/it]Loading train:  34%|███▍      | 85/247 [01:18<02:59,  1.11s/it]Loading train:  35%|███▍      | 86/247 [01:19<02:53,  1.08s/it]Loading train:  35%|███▌      | 87/247 [01:20<02:53,  1.09s/it]Loading train:  36%|███▌      | 88/247 [01:21<02:45,  1.04s/it]Loading train:  36%|███▌      | 89/247 [01:22<02:37,  1.00it/s]Loading train:  36%|███▋      | 90/247 [01:23<02:35,  1.01it/s]Loading train:  37%|███▋      | 91/247 [01:24<02:37,  1.01s/it]Loading train:  37%|███▋      | 92/247 [01:25<02:37,  1.02s/it]Loading train:  38%|███▊      | 93/247 [01:26<02:34,  1.00s/it]Loading train:  38%|███▊      | 94/247 [01:27<02:32,  1.00it/s]Loading train:  38%|███▊      | 95/247 [01:28<02:29,  1.02it/s]Loading train:  39%|███▉      | 96/247 [01:29<02:22,  1.06it/s]Loading train:  39%|███▉      | 97/247 [01:30<02:26,  1.02it/s]Loading train:  40%|███▉      | 98/247 [01:31<02:26,  1.02it/s]Loading train:  40%|████      | 99/247 [01:32<02:24,  1.02it/s]Loading train:  40%|████      | 100/247 [01:33<02:28,  1.01s/it]Loading train:  41%|████      | 101/247 [01:34<02:26,  1.00s/it]Loading train:  41%|████▏     | 102/247 [01:35<02:18,  1.04it/s]Loading train:  42%|████▏     | 103/247 [01:36<02:14,  1.07it/s]Loading train:  42%|████▏     | 104/247 [01:37<02:13,  1.08it/s]Loading train:  43%|████▎     | 105/247 [01:37<02:04,  1.14it/s]Loading train:  43%|████▎     | 106/247 [01:38<01:58,  1.19it/s]Loading train:  43%|████▎     | 107/247 [01:39<02:06,  1.11it/s]Loading train:  44%|████▎     | 108/247 [01:41<02:25,  1.05s/it]Loading train:  44%|████▍     | 109/247 [01:42<02:22,  1.04s/it]Loading train:  45%|████▍     | 110/247 [01:42<02:14,  1.02it/s]Loading train:  45%|████▍     | 111/247 [01:44<02:18,  1.02s/it]Loading train:  45%|████▌     | 112/247 [01:44<02:13,  1.01it/s]Loading train:  46%|████▌     | 113/247 [01:45<02:11,  1.02it/s]Loading train:  46%|████▌     | 114/247 [01:46<02:08,  1.03it/s]Loading train:  47%|████▋     | 115/247 [01:47<02:01,  1.08it/s]Loading train:  47%|████▋     | 116/247 [01:48<02:07,  1.03it/s]Loading train:  47%|████▋     | 117/247 [01:49<02:14,  1.04s/it]Loading train:  48%|████▊     | 118/247 [01:50<02:02,  1.05it/s]Loading train:  48%|████▊     | 119/247 [01:51<02:10,  1.02s/it]Loading train:  49%|████▊     | 120/247 [01:52<02:09,  1.02s/it]Loading train:  49%|████▉     | 121/247 [01:54<02:11,  1.05s/it]Loading train:  49%|████▉     | 122/247 [01:55<02:10,  1.04s/it]Loading train:  50%|████▉     | 123/247 [01:56<02:07,  1.03s/it]Loading train:  50%|█████     | 124/247 [01:57<02:06,  1.03s/it]Loading train:  51%|█████     | 125/247 [01:58<02:05,  1.03s/it]Loading train:  51%|█████     | 126/247 [01:59<02:01,  1.00s/it]Loading train:  51%|█████▏    | 127/247 [01:59<01:51,  1.07it/s]Loading train:  52%|█████▏    | 128/247 [02:00<01:50,  1.08it/s]Loading train:  52%|█████▏    | 129/247 [02:01<01:50,  1.06it/s]Loading train:  53%|█████▎    | 130/247 [02:02<01:48,  1.07it/s]Loading train:  53%|█████▎    | 131/247 [02:03<01:48,  1.07it/s]Loading train:  53%|█████▎    | 132/247 [02:04<01:51,  1.04it/s]Loading train:  54%|█████▍    | 133/247 [02:05<01:56,  1.02s/it]Loading train:  54%|█████▍    | 134/247 [02:06<01:55,  1.02s/it]Loading train:  55%|█████▍    | 135/247 [02:07<01:46,  1.05it/s]Loading train:  55%|█████▌    | 136/247 [02:08<01:46,  1.04it/s]Loading train:  55%|█████▌    | 137/247 [02:09<01:39,  1.10it/s]Loading train:  56%|█████▌    | 138/247 [02:10<01:41,  1.08it/s]Loading train:  56%|█████▋    | 139/247 [02:11<01:41,  1.06it/s]Loading train:  57%|█████▋    | 140/247 [02:12<01:39,  1.08it/s]Loading train:  57%|█████▋    | 141/247 [02:13<01:38,  1.08it/s]Loading train:  57%|█████▋    | 142/247 [02:13<01:36,  1.08it/s]Loading train:  58%|█████▊    | 143/247 [02:15<01:40,  1.03it/s]Loading train:  58%|█████▊    | 144/247 [02:16<01:40,  1.02it/s]Loading train:  59%|█████▊    | 145/247 [02:17<01:40,  1.01it/s]Loading train:  59%|█████▉    | 146/247 [02:17<01:34,  1.07it/s]Loading train:  60%|█████▉    | 147/247 [02:18<01:29,  1.11it/s]Loading train:  60%|█████▉    | 148/247 [02:19<01:32,  1.07it/s]Loading train:  60%|██████    | 149/247 [02:20<01:32,  1.06it/s]Loading train:  61%|██████    | 150/247 [02:21<01:30,  1.08it/s]Loading train:  61%|██████    | 151/247 [02:22<01:26,  1.11it/s]Loading train:  62%|██████▏   | 152/247 [02:23<01:32,  1.03it/s]Loading train:  62%|██████▏   | 153/247 [02:24<01:34,  1.00s/it]Loading train:  62%|██████▏   | 154/247 [02:25<01:39,  1.07s/it]Loading train:  63%|██████▎   | 155/247 [02:26<01:32,  1.00s/it]Loading train:  63%|██████▎   | 156/247 [02:27<01:28,  1.03it/s]Loading train:  64%|██████▎   | 157/247 [02:28<01:24,  1.06it/s]Loading train:  64%|██████▍   | 158/247 [02:29<01:27,  1.02it/s]Loading train:  64%|██████▍   | 159/247 [02:30<01:20,  1.09it/s]Loading train:  65%|██████▍   | 160/247 [02:31<01:26,  1.00it/s]Loading train:  65%|██████▌   | 161/247 [02:32<01:23,  1.02it/s]Loading train:  66%|██████▌   | 162/247 [02:33<01:23,  1.02it/s]Loading train:  66%|██████▌   | 163/247 [02:34<01:21,  1.03it/s]Loading train:  66%|██████▋   | 164/247 [02:35<01:15,  1.10it/s]Loading train:  67%|██████▋   | 165/247 [02:35<01:10,  1.16it/s]Loading train:  67%|██████▋   | 166/247 [02:36<01:10,  1.15it/s]Loading train:  68%|██████▊   | 167/247 [02:37<01:09,  1.15it/s]Loading train:  68%|██████▊   | 168/247 [02:38<01:10,  1.12it/s]Loading train:  68%|██████▊   | 169/247 [02:39<01:07,  1.15it/s]Loading train:  69%|██████▉   | 170/247 [02:40<01:08,  1.13it/s]Loading train:  69%|██████▉   | 171/247 [02:41<01:04,  1.18it/s]Loading train:  70%|██████▉   | 172/247 [02:42<01:14,  1.00it/s]Loading train:  70%|███████   | 173/247 [02:43<01:17,  1.05s/it]Loading train:  70%|███████   | 174/247 [02:44<01:21,  1.11s/it]Loading train:  71%|███████   | 175/247 [02:46<01:30,  1.25s/it]Loading train:  71%|███████▏  | 176/247 [02:47<01:27,  1.23s/it]Loading train:  72%|███████▏  | 177/247 [02:48<01:18,  1.12s/it]Loading train:  72%|███████▏  | 178/247 [02:49<01:12,  1.05s/it]Loading train:  72%|███████▏  | 179/247 [02:50<01:08,  1.00s/it]Loading train:  73%|███████▎  | 180/247 [02:51<01:12,  1.09s/it]Loading train:  73%|███████▎  | 181/247 [02:52<01:09,  1.05s/it]Loading train:  74%|███████▎  | 182/247 [02:53<01:03,  1.02it/s]Loading train:  74%|███████▍  | 183/247 [02:54<00:59,  1.07it/s]Loading train:  74%|███████▍  | 184/247 [02:54<00:56,  1.11it/s]Loading train:  75%|███████▍  | 185/247 [02:55<00:55,  1.12it/s]Loading train:  75%|███████▌  | 186/247 [02:56<00:56,  1.09it/s]Loading train:  76%|███████▌  | 187/247 [02:57<00:57,  1.05it/s]Loading train:  76%|███████▌  | 188/247 [02:58<00:53,  1.09it/s]Loading train:  77%|███████▋  | 189/247 [02:59<00:50,  1.15it/s]Loading train:  77%|███████▋  | 190/247 [03:00<00:48,  1.18it/s]Loading train:  77%|███████▋  | 191/247 [03:01<00:46,  1.20it/s]Loading train:  78%|███████▊  | 192/247 [03:01<00:45,  1.20it/s]Loading train:  78%|███████▊  | 193/247 [03:02<00:47,  1.13it/s]Loading train:  79%|███████▊  | 194/247 [03:03<00:49,  1.07it/s]Loading train:  79%|███████▉  | 195/247 [03:04<00:49,  1.06it/s]Loading train:  79%|███████▉  | 196/247 [03:05<00:46,  1.09it/s]Loading train:  80%|███████▉  | 197/247 [03:06<00:45,  1.10it/s]Loading train:  80%|████████  | 198/247 [03:07<00:43,  1.13it/s]Loading train:  81%|████████  | 199/247 [03:08<00:40,  1.18it/s]Loading train:  81%|████████  | 200/247 [03:09<00:39,  1.19it/s]Loading train:  81%|████████▏ | 201/247 [03:09<00:38,  1.18it/s]Loading train:  82%|████████▏ | 202/247 [03:10<00:39,  1.13it/s]Loading train:  82%|████████▏ | 203/247 [03:12<00:42,  1.03it/s]Loading train:  83%|████████▎ | 204/247 [03:12<00:40,  1.06it/s]Loading train:  83%|████████▎ | 205/247 [03:13<00:38,  1.09it/s]Loading train:  83%|████████▎ | 206/247 [03:14<00:37,  1.09it/s]Loading train:  84%|████████▍ | 207/247 [03:15<00:36,  1.10it/s]Loading train:  84%|████████▍ | 208/247 [03:16<00:36,  1.06it/s]Loading train:  85%|████████▍ | 209/247 [03:17<00:38,  1.01s/it]Loading train:  85%|████████▌ | 210/247 [03:18<00:36,  1.02it/s]Loading train:  85%|████████▌ | 211/247 [03:19<00:34,  1.03it/s]Loading train:  86%|████████▌ | 212/247 [03:20<00:33,  1.05it/s]Loading train:  86%|████████▌ | 213/247 [03:21<00:31,  1.06it/s]Loading train:  87%|████████▋ | 214/247 [03:22<00:29,  1.11it/s]Loading train:  87%|████████▋ | 215/247 [03:23<00:28,  1.13it/s]Loading train:  87%|████████▋ | 216/247 [03:24<00:31,  1.02s/it]Loading train:  88%|████████▊ | 217/247 [03:25<00:31,  1.05s/it]Loading train:  88%|████████▊ | 218/247 [03:26<00:33,  1.14s/it]Loading train:  89%|████████▊ | 219/247 [03:28<00:31,  1.13s/it]Loading train:  89%|████████▉ | 220/247 [03:29<00:32,  1.20s/it]Loading train:  89%|████████▉ | 221/247 [03:30<00:31,  1.22s/it]Loading train:  90%|████████▉ | 222/247 [03:32<00:31,  1.26s/it]Loading train:  90%|█████████ | 223/247 [03:33<00:30,  1.29s/it]Loading train:  91%|█████████ | 224/247 [03:34<00:28,  1.26s/it]Loading train:  91%|█████████ | 225/247 [03:35<00:27,  1.23s/it]Loading train:  91%|█████████▏| 226/247 [03:37<00:27,  1.33s/it]Loading train:  92%|█████████▏| 227/247 [03:38<00:25,  1.25s/it]Loading train:  92%|█████████▏| 228/247 [03:39<00:21,  1.13s/it]Loading train:  93%|█████████▎| 229/247 [03:40<00:19,  1.07s/it]Loading train:  93%|█████████▎| 230/247 [03:41<00:18,  1.09s/it]Loading train:  94%|█████████▎| 231/247 [03:42<00:16,  1.03s/it]Loading train:  94%|█████████▍| 232/247 [03:43<00:16,  1.13s/it]Loading train:  94%|█████████▍| 233/247 [03:45<00:17,  1.26s/it]Loading train:  95%|█████████▍| 234/247 [03:46<00:16,  1.27s/it]Loading train:  95%|█████████▌| 235/247 [03:47<00:15,  1.33s/it]Loading train:  96%|█████████▌| 236/247 [03:49<00:14,  1.28s/it]Loading train:  96%|█████████▌| 237/247 [03:50<00:13,  1.33s/it]Loading train:  96%|█████████▋| 238/247 [03:52<00:12,  1.42s/it]Loading train:  97%|█████████▋| 239/247 [03:53<00:10,  1.30s/it]Loading train:  97%|█████████▋| 240/247 [03:54<00:09,  1.30s/it]Loading train:  98%|█████████▊| 241/247 [03:55<00:07,  1.27s/it]Loading train:  98%|█████████▊| 242/247 [03:56<00:06,  1.28s/it]Loading train:  98%|█████████▊| 243/247 [03:58<00:05,  1.29s/it]Loading train:  99%|█████████▉| 244/247 [03:59<00:04,  1.40s/it]Loading train:  99%|█████████▉| 245/247 [04:00<00:02,  1.25s/it]Loading train: 100%|█████████▉| 246/247 [04:01<00:01,  1.17s/it]Loading train: 100%|██████████| 247/247 [04:02<00:00,  1.14s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/247 [00:00<00:13, 18.58it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:11, 20.46it/s]concatenating: train:   3%|▎         | 8/247 [00:00<00:10, 22.62it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:09, 24.66it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:07, 29.41it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:06, 34.96it/s]concatenating: train:  13%|█▎        | 32/247 [00:00<00:05, 40.28it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 46.35it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:03, 56.98it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:02, 73.18it/s]concatenating: train:  40%|████      | 99/247 [00:01<00:01, 91.75it/s]concatenating: train:  46%|████▌     | 114/247 [00:01<00:01, 81.24it/s]concatenating: train:  51%|█████▏    | 127/247 [00:01<00:01, 74.53it/s]concatenating: train:  56%|█████▌    | 138/247 [00:01<00:01, 70.45it/s]concatenating: train:  60%|█████▉    | 148/247 [00:01<00:01, 67.86it/s]concatenating: train:  64%|██████▎   | 157/247 [00:02<00:01, 61.80it/s]concatenating: train:  67%|██████▋   | 165/247 [00:02<00:01, 59.79it/s]concatenating: train:  70%|██████▉   | 172/247 [00:02<00:01, 60.56it/s]concatenating: train:  72%|███████▏  | 179/247 [00:02<00:01, 61.80it/s]concatenating: train:  75%|███████▌  | 186/247 [00:02<00:01, 60.08it/s]concatenating: train:  79%|███████▊  | 194/247 [00:02<00:00, 62.48it/s]concatenating: train:  82%|████████▏ | 202/247 [00:02<00:00, 64.32it/s]concatenating: train:  85%|████████▍ | 209/247 [00:02<00:00, 65.92it/s]concatenating: train:  87%|████████▋ | 216/247 [00:03<00:00, 64.85it/s]concatenating: train: 100%|██████████| 247/247 [00:03<00:00, 77.44it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:07,  1.87s/it]Loading test:  40%|████      | 2/5 [00:03<00:05,  1.81s/it]Loading test:  60%|██████    | 3/5 [00:05<00:03,  1.71s/it]Loading test:  80%|████████  | 4/5 [00:06<00:01,  1.57s/it]Loading test: 100%|██████████| 5/5 [00:08<00:00,  1.66s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 62.05it/s]
2019-09-01 17:09:16.010372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-09-01 17:09:16.010479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-01 17:09:16.010493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-09-01 17:09:16.010502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-09-01 17:09:16.010888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.98it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.16it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:05,  6.87it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.83it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.65it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:03,  8.21it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.58it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 11.08it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  9.05it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:01<00:01, 11.21it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 11.54it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.81it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.90it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:02<00:00, 11.22it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 11.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.79it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.77it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 109,123
Non-trainable params: 392,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.23741737e-02 3.14615932e-02 7.87383466e-02 9.59024527e-03
 2.85760176e-02 7.23242278e-03 8.58323938e-02 1.15198255e-01
 9.01096749e-02 1.30694331e-02 2.94189833e-01 1.83398313e-01
 2.29299012e-04]
Train on 15630 samples, validate on 313 samples
Epoch 1/300
 - 17s - loss: 1.4665 - acc: 0.8329 - mDice: 0.3122 - val_loss: 2.2445 - val_acc: 0.9197 - val_mDice: 0.4018

Epoch 00001: val_mDice improved from -inf to 0.40183, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.6956 - acc: 0.9114 - mDice: 0.4991 - val_loss: 1.7408 - val_acc: 0.9402 - val_mDice: 0.4857

Epoch 00002: val_mDice improved from 0.40183 to 0.48567, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.5623 - acc: 0.9319 - mDice: 0.5652 - val_loss: 2.2315 - val_acc: 0.9390 - val_mDice: 0.4826

Epoch 00003: val_mDice did not improve from 0.48567
Epoch 4/300
 - 13s - loss: 0.4826 - acc: 0.9369 - mDice: 0.6040 - val_loss: 1.4660 - val_acc: 0.9442 - val_mDice: 0.5299

Epoch 00004: val_mDice improved from 0.48567 to 0.52992, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5112 - acc: 0.9363 - mDice: 0.5932 - val_loss: 1.3839 - val_acc: 0.9442 - val_mDice: 0.5265

Epoch 00005: val_mDice did not improve from 0.52992
Epoch 6/300
 - 13s - loss: 0.4537 - acc: 0.9400 - mDice: 0.6256 - val_loss: 1.6580 - val_acc: 0.9408 - val_mDice: 0.5264

Epoch 00006: val_mDice did not improve from 0.52992
Epoch 7/300
 - 13s - loss: 0.4785 - acc: 0.9390 - mDice: 0.6182 - val_loss: 1.9716 - val_acc: 0.9409 - val_mDice: 0.5032

Epoch 00007: val_mDice did not improve from 0.52992
Epoch 8/300
 - 13s - loss: 0.4231 - acc: 0.9422 - mDice: 0.6465 - val_loss: 1.5478 - val_acc: 0.9426 - val_mDice: 0.5536

Epoch 00008: val_mDice improved from 0.52992 to 0.55358, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.4029 - acc: 0.9437 - mDice: 0.6575 - val_loss: 1.7166 - val_acc: 0.9448 - val_mDice: 0.5242

Epoch 00009: val_mDice did not improve from 0.55358
Epoch 10/300
 - 13s - loss: 0.4360 - acc: 0.9425 - mDice: 0.6458 - val_loss: 1.5971 - val_acc: 0.9404 - val_mDice: 0.5405

Epoch 00010: val_mDice did not improve from 0.55358
Epoch 11/300
 - 13s - loss: 0.3823 - acc: 0.9454 - mDice: 0.6735 - val_loss: 1.4853 - val_acc: 0.9452 - val_mDice: 0.5478

Epoch 00011: val_mDice did not improve from 0.55358
Epoch 12/300
 - 13s - loss: 0.4140 - acc: 0.9438 - mDice: 0.6578 - val_loss: 1.4371 - val_acc: 0.9439 - val_mDice: 0.5368

Epoch 00012: val_mDice did not improve from 0.55358
Epoch 13/300
 - 13s - loss: 0.3909 - acc: 0.9457 - mDice: 0.6743 - val_loss: 1.4307 - val_acc: 0.9439 - val_mDice: 0.5443

Epoch 00013: val_mDice did not improve from 0.55358
Epoch 14/300
 - 13s - loss: 0.3624 - acc: 0.9468 - mDice: 0.6862 - val_loss: 1.4593 - val_acc: 0.9449 - val_mDice: 0.5473

Epoch 00014: val_mDice did not improve from 0.55358
Epoch 15/300
 - 13s - loss: 0.3521 - acc: 0.9478 - mDice: 0.6956 - val_loss: 1.4500 - val_acc: 0.9458 - val_mDice: 0.5499

Epoch 00015: val_mDice did not improve from 0.55358
Epoch 16/300
 - 13s - loss: 0.3482 - acc: 0.9480 - mDice: 0.6960 - val_loss: 1.4194 - val_acc: 0.9448 - val_mDice: 0.5478

Epoch 00016: val_mDice did not improve from 0.55358
Epoch 17/300
 - 13s - loss: 0.3521 - acc: 0.9479 - mDice: 0.6952 - val_loss: 1.4520 - val_acc: 0.9428 - val_mDice: 0.5480

Epoch 00017: val_mDice did not improve from 0.55358
Epoch 18/300
 - 13s - loss: 0.3391 - acc: 0.9486 - mDice: 0.7047 - val_loss: 1.6905 - val_acc: 0.9463 - val_mDice: 0.5395

Epoch 00018: val_mDice did not improve from 0.55358
Epoch 19/300
 - 13s - loss: 0.3444 - acc: 0.9491 - mDice: 0.7072 - val_loss: 1.3776 - val_acc: 0.9460 - val_mDice: 0.5475

Epoch 00019: val_mDice did not improve from 0.55358
Epoch 20/300
 - 13s - loss: 0.3336 - acc: 0.9490 - mDice: 0.7063 - val_loss: 1.3138 - val_acc: 0.9469 - val_mDice: 0.5342

Epoch 00020: val_mDice did not improve from 0.55358
Epoch 21/300
 - 12s - loss: 0.3310 - acc: 0.9494 - mDice: 0.7100 - val_loss: 2.3163 - val_acc: 0.9213 - val_mDice: 0.3523

Epoch 00021: val_mDice did not improve from 0.55358
Epoch 22/300
 - 13s - loss: 0.3278 - acc: 0.9494 - mDice: 0.7081 - val_loss: 1.4615 - val_acc: 0.9419 - val_mDice: 0.5428

Epoch 00022: val_mDice did not improve from 0.55358
Epoch 23/300
 - 13s - loss: 0.3984 - acc: 0.9454 - mDice: 0.6727 - val_loss: 1.5151 - val_acc: 0.9430 - val_mDice: 0.5269

Epoch 00023: val_mDice did not improve from 0.55358
Epoch 24/300
 - 13s - loss: 0.3489 - acc: 0.9486 - mDice: 0.7008 - val_loss: 1.2815 - val_acc: 0.9430 - val_mDice: 0.5528

Epoch 00024: val_mDice did not improve from 0.55358
Epoch 25/300
 - 12s - loss: 0.3154 - acc: 0.9502 - mDice: 0.7171 - val_loss: 1.7372 - val_acc: 0.9451 - val_mDice: 0.5182

Epoch 00025: val_mDice did not improve from 0.55358
Epoch 26/300
 - 12s - loss: 0.3229 - acc: 0.9505 - mDice: 0.7205 - val_loss: 1.2941 - val_acc: 0.9445 - val_mDice: 0.5489

Epoch 00026: val_mDice did not improve from 0.55358
Epoch 27/300
 - 12s - loss: 0.3033 - acc: 0.9515 - mDice: 0.7289 - val_loss: 1.5117 - val_acc: 0.9445 - val_mDice: 0.5363

Epoch 00027: val_mDice did not improve from 0.55358
Epoch 28/300
 - 12s - loss: 0.3023 - acc: 0.9515 - mDice: 0.7293 - val_loss: 1.7926 - val_acc: 0.9467 - val_mDice: 0.5303

Epoch 00028: val_mDice did not improve from 0.55358
Epoch 29/300
 - 13s - loss: 0.3050 - acc: 0.9510 - mDice: 0.7253 - val_loss: 1.7897 - val_acc: 0.9475 - val_mDice: 0.5295

Epoch 00029: val_mDice did not improve from 0.55358
Epoch 30/300
 - 13s - loss: 0.2839 - acc: 0.9525 - mDice: 0.7402 - val_loss: 1.8469 - val_acc: 0.9454 - val_mDice: 0.5347

Epoch 00030: val_mDice did not improve from 0.55358
Epoch 31/300
 - 13s - loss: 0.3086 - acc: 0.9512 - mDice: 0.7287 - val_loss: 1.4771 - val_acc: 0.9447 - val_mDice: 0.5366

Epoch 00031: val_mDice did not improve from 0.55358
Epoch 32/300
 - 13s - loss: 0.2885 - acc: 0.9523 - mDice: 0.7387 - val_loss: 1.7359 - val_acc: 0.9434 - val_mDice: 0.5246

Epoch 00032: val_mDice did not improve from 0.55358
Epoch 33/300
 - 12s - loss: 0.2884 - acc: 0.9526 - mDice: 0.7394 - val_loss: 1.4905 - val_acc: 0.9497 - val_mDice: 0.5217

Epoch 00033: val_mDice did not improve from 0.55358
Epoch 34/300
 - 12s - loss: 0.3303 - acc: 0.9504 - mDice: 0.7190 - val_loss: 1.6335 - val_acc: 0.9446 - val_mDice: 0.5316

Epoch 00034: val_mDice did not improve from 0.55358
Epoch 35/300
 - 12s - loss: 0.3889 - acc: 0.9458 - mDice: 0.6749 - val_loss: 1.6425 - val_acc: 0.9407 - val_mDice: 0.4655

Epoch 00035: val_mDice did not improve from 0.55358
Epoch 36/300
 - 12s - loss: 0.3316 - acc: 0.9491 - mDice: 0.7085 - val_loss: 1.6135 - val_acc: 0.9386 - val_mDice: 0.5224

Epoch 00036: val_mDice did not improve from 0.55358
Epoch 37/300
 - 12s - loss: 0.3561 - acc: 0.9468 - mDice: 0.6926 - val_loss: 1.6410 - val_acc: 0.9385 - val_mDice: 0.4529

Epoch 00037: val_mDice did not improve from 0.55358
Epoch 38/300
 - 12s - loss: 0.3331 - acc: 0.9494 - mDice: 0.7091 - val_loss: 1.8510 - val_acc: 0.9428 - val_mDice: 0.5094

Epoch 00038: val_mDice did not improve from 0.55358
Epoch 39/300
 - 13s - loss: 0.2968 - acc: 0.9516 - mDice: 0.7323 - val_loss: 1.4166 - val_acc: 0.9434 - val_mDice: 0.5261

Epoch 00039: val_mDice did not improve from 0.55358
Epoch 40/300
 - 12s - loss: 0.3078 - acc: 0.9516 - mDice: 0.7293 - val_loss: 1.3290 - val_acc: 0.9455 - val_mDice: 0.5434

Epoch 00040: val_mDice did not improve from 0.55358
Epoch 41/300
 - 12s - loss: 0.2947 - acc: 0.9519 - mDice: 0.7327 - val_loss: 1.3799 - val_acc: 0.9457 - val_mDice: 0.5347

Epoch 00041: val_mDice did not improve from 0.55358
Epoch 42/300
 - 12s - loss: 0.2830 - acc: 0.9532 - mDice: 0.7459 - val_loss: 1.4113 - val_acc: 0.9429 - val_mDice: 0.5480

Epoch 00042: val_mDice did not improve from 0.55358
Epoch 43/300
 - 12s - loss: 0.2756 - acc: 0.9535 - mDice: 0.7485 - val_loss: 1.8251 - val_acc: 0.9441 - val_mDice: 0.5352

Epoch 00043: val_mDice did not improve from 0.55358
Epoch 44/300
 - 12s - loss: 0.2858 - acc: 0.9528 - mDice: 0.7412 - val_loss: 1.4124 - val_acc: 0.9458 - val_mDice: 0.5387

Epoch 00044: val_mDice did not improve from 0.55358
Epoch 45/300
 - 13s - loss: 0.2899 - acc: 0.9518 - mDice: 0.7363 - val_loss: 1.4450 - val_acc: 0.9467 - val_mDice: 0.5524

Epoch 00045: val_mDice did not improve from 0.55358
Epoch 46/300
 - 13s - loss: 0.2795 - acc: 0.9533 - mDice: 0.7473 - val_loss: 1.6300 - val_acc: 0.9460 - val_mDice: 0.5542

Epoch 00046: val_mDice improved from 0.55358 to 0.55421, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 12s - loss: 0.3222 - acc: 0.9514 - mDice: 0.7268 - val_loss: 1.3416 - val_acc: 0.9477 - val_mDice: 0.5568

Epoch 00047: val_mDice improved from 0.55421 to 0.55684, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 13s - loss: 0.2830 - acc: 0.9531 - mDice: 0.7444 - val_loss: 1.5581 - val_acc: 0.9446 - val_mDice: 0.5323

Epoch 00048: val_mDice did not improve from 0.55684
Epoch 49/300
 - 13s - loss: 0.2802 - acc: 0.9533 - mDice: 0.7443 - val_loss: 1.0863 - val_acc: 0.9439 - val_mDice: 0.5282

Epoch 00049: val_mDice did not improve from 0.55684
Epoch 50/300
 - 12s - loss: 0.2814 - acc: 0.9536 - mDice: 0.7484 - val_loss: 1.4167 - val_acc: 0.9477 - val_mDice: 0.5458

Epoch 00050: val_mDice did not improve from 0.55684
Epoch 51/300
 - 12s - loss: 0.3026 - acc: 0.9521 - mDice: 0.7346 - val_loss: 1.5630 - val_acc: 0.9478 - val_mDice: 0.5380

Epoch 00051: val_mDice did not improve from 0.55684
Epoch 52/300
 - 13s - loss: 0.2975 - acc: 0.9520 - mDice: 0.7371 - val_loss: 7.0510 - val_acc: 0.9221 - val_mDice: 0.2048

Epoch 00052: val_mDice did not improve from 0.55684
Epoch 53/300
 - 12s - loss: 0.3015 - acc: 0.9521 - mDice: 0.7334 - val_loss: 2.2582 - val_acc: 0.9277 - val_mDice: 0.4287

Epoch 00053: val_mDice did not improve from 0.55684
Epoch 54/300
 - 12s - loss: 0.3210 - acc: 0.9507 - mDice: 0.7205 - val_loss: 1.3835 - val_acc: 0.9450 - val_mDice: 0.5531

Epoch 00054: val_mDice did not improve from 0.55684
Epoch 55/300
 - 13s - loss: 0.2834 - acc: 0.9535 - mDice: 0.7496 - val_loss: 1.6261 - val_acc: 0.9471 - val_mDice: 0.5459

Epoch 00055: val_mDice did not improve from 0.55684
Epoch 56/300
 - 13s - loss: 0.2739 - acc: 0.9537 - mDice: 0.7512 - val_loss: 1.5638 - val_acc: 0.9458 - val_mDice: 0.5455

Epoch 00056: val_mDice did not improve from 0.55684
Epoch 57/300
 - 13s - loss: 0.2608 - acc: 0.9544 - mDice: 0.7595 - val_loss: 1.2454 - val_acc: 0.9481 - val_mDice: 0.5570

Epoch 00057: val_mDice improved from 0.55684 to 0.55704, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 58/300
 - 13s - loss: 0.2867 - acc: 0.9536 - mDice: 0.7478 - val_loss: 1.5444 - val_acc: 0.9462 - val_mDice: 0.5311

Epoch 00058: val_mDice did not improve from 0.55704
Epoch 59/300
 - 13s - loss: 0.2857 - acc: 0.9535 - mDice: 0.7470 - val_loss: 1.7256 - val_acc: 0.9450 - val_mDice: 0.5054

Epoch 00059: val_mDice did not improve from 0.55704
Epoch 60/300
 - 13s - loss: 0.2700 - acc: 0.9542 - mDice: 0.7560 - val_loss: 1.6083 - val_acc: 0.9478 - val_mDice: 0.5473

Epoch 00060: val_mDice did not improve from 0.55704
Epoch 61/300
 - 13s - loss: 0.2581 - acc: 0.9548 - mDice: 0.7628 - val_loss: 1.3617 - val_acc: 0.9461 - val_mDice: 0.5496

Epoch 00061: val_mDice did not improve from 0.55704
Epoch 62/300
 - 13s - loss: 0.2777 - acc: 0.9534 - mDice: 0.7498 - val_loss: 1.5753 - val_acc: 0.9350 - val_mDice: 0.4752

Epoch 00062: val_mDice did not improve from 0.55704
Epoch 63/300
 - 12s - loss: 0.2785 - acc: 0.9532 - mDice: 0.7475 - val_loss: 1.5399 - val_acc: 0.9488 - val_mDice: 0.5314

Epoch 00063: val_mDice did not improve from 0.55704
Epoch 64/300
 - 13s - loss: 0.2928 - acc: 0.9525 - mDice: 0.7426 - val_loss: 1.3057 - val_acc: 0.9460 - val_mDice: 0.5369

Epoch 00064: val_mDice did not improve from 0.55704
Epoch 65/300
 - 13s - loss: 0.2655 - acc: 0.9543 - mDice: 0.7578 - val_loss: 1.3143 - val_acc: 0.9459 - val_mDice: 0.5457

Epoch 00065: val_mDice did not improve from 0.55704
Epoch 66/300
 - 12s - loss: 0.2720 - acc: 0.9544 - mDice: 0.7582 - val_loss: 1.6874 - val_acc: 0.9455 - val_mDice: 0.5313

Epoch 00066: val_mDice did not improve from 0.55704
Epoch 67/300
 - 13s - loss: 0.2573 - acc: 0.9550 - mDice: 0.7652 - val_loss: 1.5612 - val_acc: 0.9453 - val_mDice: 0.5305

Epoch 00067: val_mDice did not improve from 0.55704
Epoch 68/300
 - 12s - loss: 0.2497 - acc: 0.9553 - mDice: 0.7677 - val_loss: 1.4639 - val_acc: 0.9461 - val_mDice: 0.5499

Epoch 00068: val_mDice did not improve from 0.55704
Epoch 69/300
 - 12s - loss: 0.2500 - acc: 0.9553 - mDice: 0.7676 - val_loss: 1.8675 - val_acc: 0.9474 - val_mDice: 0.5245

Epoch 00069: val_mDice did not improve from 0.55704
Epoch 70/300
 - 13s - loss: 0.2619 - acc: 0.9549 - mDice: 0.7624 - val_loss: 1.1240 - val_acc: 0.9445 - val_mDice: 0.5416

Epoch 00070: val_mDice did not improve from 0.55704
Epoch 71/300
 - 13s - loss: 0.2951 - acc: 0.9533 - mDice: 0.7455 - val_loss: 1.1590 - val_acc: 0.9467 - val_mDice: 0.5507

Epoch 00071: val_mDice did not improve from 0.55704
Epoch 72/300
 - 13s - loss: 0.2591 - acc: 0.9546 - mDice: 0.7598 - val_loss: 0.9593 - val_acc: 0.9497 - val_mDice: 0.5380

Epoch 00072: val_mDice did not improve from 0.55704
Epoch 73/300
 - 13s - loss: 0.2593 - acc: 0.9550 - mDice: 0.7619 - val_loss: 1.7307 - val_acc: 0.9475 - val_mDice: 0.5440

Epoch 00073: val_mDice did not improve from 0.55704
Epoch 74/300
 - 12s - loss: 0.3056 - acc: 0.9510 - mDice: 0.7282 - val_loss: 1.2505 - val_acc: 0.9444 - val_mDice: 0.5425

Epoch 00074: val_mDice did not improve from 0.55704
Epoch 75/300
 - 13s - loss: 0.3123 - acc: 0.9521 - mDice: 0.7325 - val_loss: 1.1534 - val_acc: 0.9468 - val_mDice: 0.5430

Epoch 00075: val_mDice did not improve from 0.55704
Epoch 76/300
 - 13s - loss: 0.2789 - acc: 0.9534 - mDice: 0.7468 - val_loss: 1.3633 - val_acc: 0.9463 - val_mDice: 0.5404

Epoch 00076: val_mDice did not improve from 0.55704
Epoch 77/300
 - 12s - loss: 0.2882 - acc: 0.9533 - mDice: 0.7422 - val_loss: 1.5477 - val_acc: 0.9469 - val_mDice: 0.5429

Epoch 00077: val_mDice did not improve from 0.55704
Epoch 78/300
 - 13s - loss: 0.2931 - acc: 0.9528 - mDice: 0.7417 - val_loss: 1.1962 - val_acc: 0.9468 - val_mDice: 0.5405

Epoch 00078: val_mDice did not improve from 0.55704
Epoch 79/300
 - 13s - loss: 0.2789 - acc: 0.9540 - mDice: 0.7510 - val_loss: 1.0873 - val_acc: 0.9491 - val_mDice: 0.5383

Epoch 00079: val_mDice did not improve from 0.55704
Epoch 80/300
 - 13s - loss: 0.2631 - acc: 0.9544 - mDice: 0.7584 - val_loss: 1.8144 - val_acc: 0.9460 - val_mDice: 0.5219

Epoch 00080: val_mDice did not improve from 0.55704
Epoch 81/300
 - 13s - loss: 0.2645 - acc: 0.9546 - mDice: 0.7585 - val_loss: 1.4215 - val_acc: 0.9482 - val_mDice: 0.5585

Epoch 00081: val_mDice improved from 0.55704 to 0.55854, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 82/300
 - 13s - loss: 0.2478 - acc: 0.9555 - mDice: 0.7684 - val_loss: 1.1928 - val_acc: 0.9485 - val_mDice: 0.5558

Epoch 00082: val_mDice did not improve from 0.55854
Epoch 83/300
 - 13s - loss: 0.3075 - acc: 0.9515 - mDice: 0.7326 - val_loss: 2.6222 - val_acc: 0.9161 - val_mDice: 0.3811

Epoch 00083: val_mDice did not improve from 0.55854
Epoch 84/300
 - 12s - loss: 0.2991 - acc: 0.9524 - mDice: 0.7375 - val_loss: 1.7870 - val_acc: 0.9460 - val_mDice: 0.5202

Epoch 00084: val_mDice did not improve from 0.55854
Epoch 85/300
 - 13s - loss: 0.2662 - acc: 0.9546 - mDice: 0.7574 - val_loss: 1.3014 - val_acc: 0.9461 - val_mDice: 0.5446

Epoch 00085: val_mDice did not improve from 0.55854
Epoch 86/300
 - 13s - loss: 0.2562 - acc: 0.9552 - mDice: 0.7651 - val_loss: 1.3129 - val_acc: 0.9477 - val_mDice: 0.5479

Epoch 00086: val_mDice did not improve from 0.55854
Epoch 87/300
 - 12s - loss: 0.2513 - acc: 0.9558 - mDice: 0.7717 - val_loss: 1.4164 - val_acc: 0.9480 - val_mDice: 0.5375

Epoch 00087: val_mDice did not improve from 0.55854
Epoch 88/300
 - 12s - loss: 0.2492 - acc: 0.9559 - mDice: 0.7729 - val_loss: 1.5365 - val_acc: 0.9477 - val_mDice: 0.5498

Epoch 00088: val_mDice did not improve from 0.55854
Epoch 89/300
 - 13s - loss: 0.2476 - acc: 0.9558 - mDice: 0.7732 - val_loss: 1.2741 - val_acc: 0.9469 - val_mDice: 0.5438

Epoch 00089: val_mDice did not improve from 0.55854
Epoch 90/300
 - 13s - loss: 0.2451 - acc: 0.9559 - mDice: 0.7722 - val_loss: 1.4026 - val_acc: 0.9473 - val_mDice: 0.5528

Epoch 00090: val_mDice did not improve from 0.55854
Epoch 91/300
 - 13s - loss: 0.2448 - acc: 0.9563 - mDice: 0.7757 - val_loss: 5.6514 - val_acc: 0.9183 - val_mDice: 0.2294

Epoch 00091: val_mDice did not improve from 0.55854
Epoch 92/300
 - 13s - loss: 0.2894 - acc: 0.9531 - mDice: 0.7434 - val_loss: 1.3227 - val_acc: 0.9462 - val_mDice: 0.5344

Epoch 00092: val_mDice did not improve from 0.55854
Epoch 93/300
 - 12s - loss: 0.2965 - acc: 0.9526 - mDice: 0.7411 - val_loss: 1.4125 - val_acc: 0.9469 - val_mDice: 0.5376

Epoch 00093: val_mDice did not improve from 0.55854
Epoch 94/300
 - 13s - loss: 0.2620 - acc: 0.9549 - mDice: 0.7627 - val_loss: 1.6492 - val_acc: 0.9442 - val_mDice: 0.5549

Epoch 00094: val_mDice did not improve from 0.55854
Epoch 95/300
 - 13s - loss: 0.2505 - acc: 0.9556 - mDice: 0.7693 - val_loss: 1.6289 - val_acc: 0.9478 - val_mDice: 0.5483

Epoch 00095: val_mDice did not improve from 0.55854
Epoch 96/300
 - 13s - loss: 0.2526 - acc: 0.9561 - mDice: 0.7745 - val_loss: 1.3441 - val_acc: 0.9494 - val_mDice: 0.5516

Epoch 00096: val_mDice did not improve from 0.55854
Epoch 97/300
 - 12s - loss: 0.2724 - acc: 0.9538 - mDice: 0.7516 - val_loss: 1.4648 - val_acc: 0.9496 - val_mDice: 0.5506

Epoch 00097: val_mDice did not improve from 0.55854
Epoch 98/300
 - 13s - loss: 0.2691 - acc: 0.9542 - mDice: 0.7548 - val_loss: 1.3561 - val_acc: 0.9479 - val_mDice: 0.5493

Epoch 00098: val_mDice did not improve from 0.55854
Epoch 99/300
 - 12s - loss: 0.2679 - acc: 0.9533 - mDice: 0.7539 - val_loss: 1.4057 - val_acc: 0.9468 - val_mDice: 0.5328

Epoch 00099: val_mDice did not improve from 0.55854
Epoch 100/300
 - 12s - loss: 0.2566 - acc: 0.9550 - mDice: 0.7660 - val_loss: 1.7290 - val_acc: 0.9438 - val_mDice: 0.5325

Epoch 00100: val_mDice did not improve from 0.55854
Epoch 101/300
 - 13s - loss: 0.2648 - acc: 0.9548 - mDice: 0.7605 - val_loss: 1.3821 - val_acc: 0.9482 - val_mDice: 0.5465

Epoch 00101: val_mDice did not improve from 0.55854
Epoch 102/300
 - 12s - loss: 0.2430 - acc: 0.9559 - mDice: 0.7724 - val_loss: 1.6338 - val_acc: 0.9467 - val_mDice: 0.5382

Epoch 00102: val_mDice did not improve from 0.55854
Epoch 103/300
 - 12s - loss: 0.2738 - acc: 0.9546 - mDice: 0.7602 - val_loss: 1.6078 - val_acc: 0.9469 - val_mDice: 0.5517

Epoch 00103: val_mDice did not improve from 0.55854
Epoch 104/300
 - 12s - loss: 0.2513 - acc: 0.9556 - mDice: 0.7695 - val_loss: 1.4254 - val_acc: 0.9477 - val_mDice: 0.5384

Epoch 00104: val_mDice did not improve from 0.55854
Epoch 105/300
 - 12s - loss: 0.2475 - acc: 0.9561 - mDice: 0.7735 - val_loss: 1.5119 - val_acc: 0.9481 - val_mDice: 0.5461

Epoch 00105: val_mDice did not improve from 0.55854
Epoch 106/300
 - 13s - loss: 0.2359 - acc: 0.9564 - mDice: 0.7781 - val_loss: 1.7701 - val_acc: 0.9469 - val_mDice: 0.5380

Epoch 00106: val_mDice did not improve from 0.55854
Epoch 107/300
 - 12s - loss: 0.2647 - acc: 0.9554 - mDice: 0.7646 - val_loss: 1.2739 - val_acc: 0.9477 - val_mDice: 0.5242

Epoch 00107: val_mDice did not improve from 0.55854
Epoch 108/300
 - 12s - loss: 0.2638 - acc: 0.9551 - mDice: 0.7621 - val_loss: 1.7176 - val_acc: 0.9461 - val_mDice: 0.5295

Epoch 00108: val_mDice did not improve from 0.55854
Epoch 109/300
 - 12s - loss: 0.2455 - acc: 0.9561 - mDice: 0.7735 - val_loss: 1.3345 - val_acc: 0.9468 - val_mDice: 0.5439

Epoch 00109: val_mDice did not improve from 0.55854
Epoch 110/300
 - 12s - loss: 0.2394 - acc: 0.9565 - mDice: 0.7785 - val_loss: 1.3934 - val_acc: 0.9461 - val_mDice: 0.5305

Epoch 00110: val_mDice did not improve from 0.55854
Epoch 111/300
 - 12s - loss: 0.2612 - acc: 0.9553 - mDice: 0.7625 - val_loss: 1.6183 - val_acc: 0.9473 - val_mDice: 0.5370

Epoch 00111: val_mDice did not improve from 0.55854
Epoch 112/300
 - 13s - loss: 0.2407 - acc: 0.9567 - mDice: 0.7777 - val_loss: 1.2117 - val_acc: 0.9475 - val_mDice: 0.5474

Epoch 00112: val_mDice did not improve from 0.55854
Epoch 113/300
 - 13s - loss: 0.2328 - acc: 0.9568 - mDice: 0.7809 - val_loss: 1.4745 - val_acc: 0.9478 - val_mDice: 0.5404

Epoch 00113: val_mDice did not improve from 0.55854
Epoch 114/300
 - 12s - loss: 0.2287 - acc: 0.9570 - mDice: 0.7839 - val_loss: 1.1466 - val_acc: 0.9489 - val_mDice: 0.5429

Epoch 00114: val_mDice did not improve from 0.55854
Epoch 115/300
 - 12s - loss: 0.2746 - acc: 0.9543 - mDice: 0.7564 - val_loss: 1.6563 - val_acc: 0.9427 - val_mDice: 0.5259

Epoch 00115: val_mDice did not improve from 0.55854
Epoch 116/300
 - 12s - loss: 0.2437 - acc: 0.9559 - mDice: 0.7728 - val_loss: 1.1473 - val_acc: 0.9473 - val_mDice: 0.5415

Epoch 00116: val_mDice did not improve from 0.55854
Epoch 117/300
 - 12s - loss: 0.2396 - acc: 0.9568 - mDice: 0.7812 - val_loss: 1.3436 - val_acc: 0.9475 - val_mDice: 0.5336

Epoch 00117: val_mDice did not improve from 0.55854
Epoch 118/300
 - 13s - loss: 0.2417 - acc: 0.9566 - mDice: 0.7801 - val_loss: 1.6125 - val_acc: 0.9466 - val_mDice: 0.5304

Epoch 00118: val_mDice did not improve from 0.55854
Epoch 119/300
 - 13s - loss: 0.2378 - acc: 0.9567 - mDice: 0.7799 - val_loss: 1.4638 - val_acc: 0.9478 - val_mDice: 0.5370

Epoch 00119: val_mDice did not improve from 0.55854
Epoch 120/300
 - 12s - loss: 0.2340 - acc: 0.9571 - mDice: 0.7847 - val_loss: 1.1690 - val_acc: 0.9470 - val_mDice: 0.5464

Epoch 00120: val_mDice did not improve from 0.55854
Epoch 121/300
 - 12s - loss: 0.2392 - acc: 0.9572 - mDice: 0.7850 - val_loss: 1.4204 - val_acc: 0.9466 - val_mDice: 0.5488

Epoch 00121: val_mDice did not improve from 0.55854
Restoring model weights from the end of the best epoch
Epoch 00121: early stopping
{'val_loss': [2.2445057398214128, 1.74077010040466, 2.231453262769376, 1.4660003486151894, 1.3839446900370784, 1.6579863638542711, 1.9715822247651438, 1.5478417578215797, 1.7165784321653956, 1.5970823361089055, 1.4853081583215024, 1.4371255143001056, 1.4306967490778182, 1.459341301704748, 1.4499745926917933, 1.4193512005166125, 1.452041943233234, 1.6904561830023987, 1.3775928570820501, 1.3137556080239268, 2.3162571382217894, 1.4615479414455426, 1.5150546092575732, 1.2815030253352448, 1.7372286441607978, 1.2941461135023318, 1.5116653887989422, 1.7926356502996086, 1.7896671003807847, 1.8468766189611758, 1.4770794465138128, 1.735890233478607, 1.4905198513509366, 1.6335189603388118, 1.6424508045275752, 1.6134628969640397, 1.6410074249243203, 1.850954109297012, 1.4165737705108838, 1.328960509155505, 1.3798682914374354, 1.4112794033635538, 1.825102212520453, 1.4124133887763222, 1.4450172522959237, 1.6300377011679994, 1.3415564778513802, 1.5580897504529252, 1.086254890353535, 1.4167016346614583, 1.5629856167509915, 7.051031374702819, 2.25817632789429, 1.3834923347726036, 1.6261342143098387, 1.5637711880686946, 1.2454168988873784, 1.5443693679361679, 1.7256357584136743, 1.6083232312918472, 1.3616876824976156, 1.5752603082230296, 1.5399031749548622, 1.3057039800924235, 1.314306404453497, 1.6873616046798876, 1.561202955512574, 1.4638850060514748, 1.8675316507443072, 1.1239883149393832, 1.1589839862177547, 0.9592676556910189, 1.7306590933388415, 1.2505400841609358, 1.1534486700551578, 1.3632711808140667, 1.5477370585496433, 1.1961515433491228, 1.0873443560478406, 1.8143621138490427, 1.4214940471009325, 1.1928067523450516, 2.622241511512488, 1.787030697440187, 1.3013867474973393, 1.3128987223195572, 1.416399863581307, 1.5364532154589035, 1.2740863142683865, 1.4026079029320908, 5.65143511089654, 1.3227404079879055, 1.4124683219784746, 1.6491578227034012, 1.6288713616684984, 1.3441275923777694, 1.4648285009228765, 1.3561438204000553, 1.4056668748109105, 1.7290270052397976, 1.382102600873088, 1.6337955934932817, 1.6078115686441001, 1.4253512836112001, 1.5118707212777183, 1.7700947650705283, 1.2739233485045143, 1.7175677119733426, 1.3344540590295395, 1.393385441920247, 1.6183397013920184, 1.2117355073602816, 1.474468129130598, 1.1466179457716286, 1.6562959806987654, 1.1472985574993462, 1.3435617679605087, 1.6125006858533182, 1.4637574039328212, 1.1689927897895107, 1.4203686411388385], 'val_acc': [0.9197426124121815, 0.9402352708597153, 0.9390324506515892, 0.9442454226100787, 0.9442465933747947, 0.940765774859407, 0.9409028562113119, 0.9425806127036341, 0.944754667556324, 0.940417224797197, 0.9451989280149198, 0.9438555099712774, 0.9439299495075457, 0.9448739973881755, 0.9458133325028343, 0.9448137300463911, 0.9428488461735149, 0.9463379383087158, 0.9459657493871622, 0.9468932585975233, 0.9212916158258725, 0.9419107016283103, 0.9430107076328021, 0.9430012594396695, 0.945133937623935, 0.9445230888482481, 0.9444758206510696, 0.9466853059899693, 0.947537188522351, 0.9453761564276089, 0.9446861321172013, 0.9434171600844532, 0.9497017759484605, 0.9445738950476479, 0.9406700684620549, 0.9385811103799473, 0.9385444820879366, 0.9428240171255776, 0.9434041782689933, 0.9455474672226098, 0.9456845289602066, 0.9428712818950129, 0.9440670146728857, 0.945773161447848, 0.9467136509502276, 0.9460212790166227, 0.9476671601636723, 0.9445502474285162, 0.9439027775971653, 0.9477404156051124, 0.9478266776179354, 0.922113969684028, 0.9276565789414671, 0.9450027925518755, 0.9471437477836975, 0.9458346005064991, 0.9480842370956469, 0.9462174116232144, 0.9450346985564064, 0.947844390480663, 0.9461264436999068, 0.9350163972796723, 0.948828612463162, 0.9459716529130174, 0.9458865719481399, 0.9454954883541924, 0.9452792514627353, 0.9461228921771431, 0.9474344011693717, 0.9444557241738414, 0.9466522187470628, 0.9497254186164076, 0.9475478360447259, 0.9443942950175593, 0.9467679930571169, 0.9462587679156099, 0.9468731750695469, 0.9467821873415011, 0.9490673008818216, 0.9459751916769594, 0.9481574993925734, 0.9485438820272208, 0.9161389251105702, 0.9459657337718879, 0.9460756312163112, 0.9476600635927707, 0.9480228172704435, 0.9477226932208759, 0.9469369684164517, 0.9473481618177396, 0.9183495838802082, 0.9462185909572881, 0.9468885336440211, 0.944205245651757, 0.947777054751643, 0.9494442164707488, 0.9495812690676972, 0.9479271131582534, 0.9467715518162273, 0.9438259689190898, 0.9482390377849055, 0.9466864805632886, 0.946899171454457, 0.9476884285481973, 0.9480700723279398, 0.9468838136417036, 0.9477392339858765, 0.9460968921740596, 0.9467715516257972, 0.946087444171357, 0.9472512646605031, 0.9474863945104824, 0.9477924032333179, 0.9489148839974937, 0.9426692390975099, 0.9472760801878981, 0.9474686723166761, 0.9466368575065661, 0.9478444036203452, 0.9469641332809156, 0.9465848696879304], 'val_mDice': [0.4018287718914949, 0.4856738247953284, 0.48264161568765823, 0.5299158642372004, 0.5265332139290559, 0.5264198114506353, 0.5032452824302375, 0.5535754521909994, 0.5242398913485554, 0.540534617040104, 0.5477632477451057, 0.5368483784004522, 0.5442852413835236, 0.5472691113385149, 0.5498981950001214, 0.5477659527819377, 0.5479688610131748, 0.539529784038044, 0.5474662290404018, 0.5342263469395165, 0.3522668456950317, 0.5427644757417064, 0.5269063336018938, 0.5528439125790002, 0.5181748682079604, 0.5488725322694443, 0.5363488449646642, 0.5303059304579378, 0.5294563929779461, 0.5347087958131355, 0.5366138249350051, 0.5246241587324264, 0.5217241299228547, 0.5315733152075698, 0.46550082141598953, 0.5224388659286042, 0.45294566788136387, 0.5094022717053136, 0.5260643771947763, 0.5434001906992147, 0.5346801687543765, 0.5480287574445859, 0.5352228273170444, 0.5387471653878118, 0.5524339176500186, 0.5542070353373932, 0.5568374490347533, 0.5323160377125771, 0.5282222368656256, 0.5457709880587392, 0.5380476743411332, 0.20478267353563645, 0.428718137331664, 0.5530995349295604, 0.5459454210040668, 0.5454694646806382, 0.5570380244963467, 0.531098789467027, 0.5054254762994976, 0.5472533120134007, 0.5496080784371105, 0.4752296443326405, 0.5314076536903366, 0.5369127057373714, 0.545739470769803, 0.5312928716405131, 0.5304591979224461, 0.5498879457624576, 0.524526959076857, 0.5416225676719373, 0.5507250118512697, 0.5379622026849479, 0.544029539671188, 0.5424654967487811, 0.5429670065641403, 0.5404476926873286, 0.5429352953934822, 0.540456628361449, 0.5382875403561912, 0.5219155926816761, 0.5585411904861752, 0.555784881924288, 0.3811054305908398, 0.520179239562906, 0.5446467713806957, 0.5478954235918987, 0.5375199712122591, 0.5498183209199113, 0.5437695739653926, 0.5528400827901432, 0.22942617842659782, 0.5343895889223574, 0.537550762819406, 0.5549079236416771, 0.5482670505778097, 0.5515739160795181, 0.550622846943121, 0.549262231697861, 0.532766902384857, 0.5325176438774926, 0.5464995841439159, 0.5382365423936052, 0.5516708674855506, 0.5384497013145362, 0.5460753110936656, 0.5380371738070497, 0.524157738414245, 0.5294501020218998, 0.5438690242199852, 0.5304607351938375, 0.5370356220597277, 0.5473975086459717, 0.5403758726847439, 0.5428550024144947, 0.5259045575516292, 0.5415044926797239, 0.533551681632051, 0.5304254145382311, 0.5369982141941881, 0.5463544376932394, 0.5488018498015099], 'loss': [1.4665282481157542, 0.6955831418873328, 0.5623169400641648, 0.48259862210608717, 0.5112053106323847, 0.45370943137871783, 0.47851558854316034, 0.4230580647176302, 0.40294471697706635, 0.43600583343420435, 0.38231375910727855, 0.41399470841129543, 0.3909183347255697, 0.36241193076623074, 0.35205692478043865, 0.3482372678210929, 0.3520607066246003, 0.33908624133847115, 0.34440152389989476, 0.3335963639592179, 0.33098144103759236, 0.32784746805598014, 0.39836937522781407, 0.3488789642955429, 0.31537734966436715, 0.3228927064002971, 0.3033280715832555, 0.3023261971490473, 0.3050380271459648, 0.283903888695452, 0.3085726600805308, 0.2884944536635606, 0.28835880120480895, 0.3303247643676387, 0.3888861971525374, 0.33161529772798753, 0.35612202682177835, 0.3330678912171628, 0.29681386304298274, 0.30776122369715897, 0.29471160322713763, 0.2829997615503792, 0.2756071048273311, 0.28584822151459566, 0.289876817894226, 0.2795018581095523, 0.3222490123884844, 0.2829901738019609, 0.28018553176524164, 0.2813754846328203, 0.3026132384745341, 0.29752014799523796, 0.30145123357850623, 0.3210256932468957, 0.2833924778020313, 0.27393840824421295, 0.2607577306123704, 0.28666661681651456, 0.2856818064713585, 0.27001925220835765, 0.25814889244597, 0.277664806348196, 0.2784542471971256, 0.29280896459110867, 0.26546323920051335, 0.2719709155789111, 0.25729877791073713, 0.24973926975875044, 0.24996088928544818, 0.2619031250514972, 0.29514887034702364, 0.2591444103861191, 0.2593137937635469, 0.30560755369301723, 0.31231476546706716, 0.2788972695306258, 0.2882496377766628, 0.29310523721932297, 0.27885346113682097, 0.2631158350334668, 0.2645191486093072, 0.24783545150942934, 0.3074959440827751, 0.299089173361497, 0.26616170057599087, 0.2561993413984356, 0.2513415898677255, 0.24917850703935324, 0.24755091944224394, 0.24511061383796212, 0.24483523297142082, 0.28941494604943274, 0.29648296970704846, 0.2620158708122245, 0.25049127923397396, 0.25264176640538016, 0.2723745313006491, 0.2691396325445297, 0.2679255234741356, 0.25657571716828753, 0.26477261250856515, 0.2430108210461611, 0.2737504272833133, 0.2512534238059629, 0.24750899585942313, 0.23593093626444261, 0.26465542399951913, 0.2638070871928374, 0.2455066745565705, 0.23944232865967816, 0.2611696823087169, 0.24065647575997118, 0.23276322423191462, 0.22867960857986566, 0.2746234165024315, 0.24370824112315553, 0.23959672851434366, 0.24172103032231407, 0.23779139578609382, 0.2339635481074767, 0.23915796305076176], 'acc': [0.8329057527928877, 0.9113888282540968, 0.9319440264848281, 0.9369124709530207, 0.9362588843243747, 0.9400141784493464, 0.9389896774169961, 0.9422434053585763, 0.9437013298215884, 0.9424639483407302, 0.9453750656952251, 0.9438355350372354, 0.9457076686891469, 0.9468300315484128, 0.9478120136855889, 0.9479679161359771, 0.9478692742623508, 0.9486436067448163, 0.9490986543821358, 0.948988227987625, 0.9494379075459769, 0.9494342159477474, 0.945354977900297, 0.948563041438373, 0.9501841071318604, 0.950525275309423, 0.9514679560200648, 0.9514710324281923, 0.9510231046667483, 0.9524911796520401, 0.9511606698988038, 0.9522669192925525, 0.9525651921466307, 0.9503727096513686, 0.9457932764417608, 0.9491351868430544, 0.9467783335760779, 0.9493843160297958, 0.9516256106487087, 0.9515886508114278, 0.9519205681421935, 0.9531996613958289, 0.9534614028948969, 0.952816469579344, 0.95180533874973, 0.9532847722142611, 0.9514353748170215, 0.9531271401614008, 0.9532976215723151, 0.9536172318214494, 0.9521432194432157, 0.9520113083008994, 0.9521302531639583, 0.9507213069777876, 0.9535254050124858, 0.9536582857694522, 0.9544300621927204, 0.9535501287750762, 0.9535437174432184, 0.9541699569040739, 0.9547513067455378, 0.9534140089270554, 0.9531640284197191, 0.9525330595228814, 0.9542708700083039, 0.9544489913008111, 0.9550022326519454, 0.9553089764967837, 0.9553438539087048, 0.9549186384151627, 0.9533241675285978, 0.9546006803549183, 0.9549806765158514, 0.9509592914688076, 0.9521261811714026, 0.9534165152966481, 0.953312857137303, 0.952812284288388, 0.9539722670596605, 0.954426347065338, 0.9545755318091301, 0.9554501625870713, 0.9515491378131923, 0.9524162438384097, 0.9545511355860753, 0.9552007737025494, 0.9557731577164839, 0.9559449368917401, 0.955789154870954, 0.9558572498789523, 0.9562968737180616, 0.9531066741839633, 0.9526262371416513, 0.9549128892173083, 0.9555658636303643, 0.956102144237672, 0.953844238608904, 0.9541510239062367, 0.9532641151816282, 0.9550117212308956, 0.9547911293981018, 0.9558520220215322, 0.9546315125067572, 0.9555691765884673, 0.9560743168387288, 0.9564071786533315, 0.9553519451534298, 0.9551154281646108, 0.9561416580748726, 0.95650968045206, 0.9553164048066752, 0.9566827140324251, 0.9567543360871226, 0.9570274079219698, 0.9543217889254321, 0.95585131088435, 0.9567892366468487, 0.9566463228608276, 0.956716145984042, 0.9571075709447293, 0.9571615174956147], 'mDice': [0.3122416041643667, 0.4990974841252093, 0.5652128149894133, 0.604009914459209, 0.5932230988680668, 0.6255855509202143, 0.6181840346703069, 0.6465130843417582, 0.6575105875558908, 0.6458394045030468, 0.6735448577963841, 0.6577962667455447, 0.6742719963278743, 0.6861575476953942, 0.6955623476457993, 0.6960046217751213, 0.6952463423145634, 0.7046554932514979, 0.7072153766797432, 0.7063394939373184, 0.7100493345059269, 0.7080607940886773, 0.6726854399695125, 0.7007623124564983, 0.7171468029629322, 0.7204832935745108, 0.728924333019586, 0.7293183713560294, 0.7252664263249969, 0.7401748348029851, 0.7286950508829728, 0.7387182534465558, 0.739370857342191, 0.718995465007411, 0.6749379626848876, 0.7084919785888852, 0.6925699191450386, 0.7090555285690537, 0.7322636700103623, 0.7292789917532175, 0.7327349075352771, 0.745926244931578, 0.7484568024169765, 0.74115279135762, 0.7363079258515449, 0.747286133253643, 0.7268290719921896, 0.7444131420120854, 0.7443291172337547, 0.7483597271578173, 0.7346053685199276, 0.7371349264548821, 0.7334395751538219, 0.7205426464535377, 0.7495900583968892, 0.7512102648758843, 0.7595033789779312, 0.74778636902933, 0.7469612439320931, 0.7560136060415745, 0.7627722229701315, 0.7498467873855805, 0.7474929488246744, 0.7426227662933994, 0.7578290088468077, 0.7581787902959554, 0.7652310916268513, 0.7676608830175564, 0.767647232867477, 0.7623633381577539, 0.7454682587814575, 0.7597561082013204, 0.7619101210656413, 0.7282395590899926, 0.7325059115238397, 0.7467539395114511, 0.7422047301659733, 0.7417476798430972, 0.7509910702247766, 0.758427311843279, 0.7585309746169312, 0.7683669311910276, 0.7325512427057277, 0.7375281426819639, 0.7574009070088294, 0.7651088988636063, 0.7717166179963891, 0.7729333357710299, 0.7731816015484542, 0.7721864219971826, 0.7756512720693172, 0.7433740455449885, 0.7411466410201251, 0.7627133004038439, 0.7693491067477548, 0.7745149198511969, 0.7515813361278956, 0.7548257776810737, 0.753943065687852, 0.7659566427604251, 0.7604877136109047, 0.7723737836875598, 0.7601619426516181, 0.7695036028259775, 0.7734600760886399, 0.7781258622042582, 0.764599388978913, 0.7620748779518972, 0.7734819678107059, 0.778480767936792, 0.7625212848224627, 0.7777391242355547, 0.7809457978756856, 0.7839035775443337, 0.7563895064901253, 0.7727509895274064, 0.7811967884205276, 0.7800639629821631, 0.7799050110849294, 0.7846503719563523, 0.7850413258763665]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:13,  3.26s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:09,  3.08s/it]predicting test subjects:  60%|██████    | 3/5 [00:08<00:05,  2.83s/it]predicting test subjects:  80%|████████  | 4/5 [00:10<00:02,  2.59s/it]predicting test subjects: 100%|██████████| 5/5 [00:12<00:00,  2.64s/it]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:02<09:04,  2.21s/it]predicting train subjects:   1%|          | 2/247 [00:04<08:39,  2.12s/it]predicting train subjects:   1%|          | 3/247 [00:06<08:28,  2.08s/it]predicting train subjects:   2%|▏         | 4/247 [00:08<08:48,  2.18s/it]predicting train subjects:   2%|▏         | 5/247 [00:10<08:32,  2.12s/it]predicting train subjects:   2%|▏         | 6/247 [00:12<08:40,  2.16s/it]predicting train subjects:   3%|▎         | 7/247 [00:14<08:28,  2.12s/it]predicting train subjects:   3%|▎         | 8/247 [00:17<08:46,  2.20s/it]predicting train subjects:   4%|▎         | 9/247 [00:19<08:56,  2.25s/it]predicting train subjects:   4%|▍         | 10/247 [00:21<08:43,  2.21s/it]predicting train subjects:   4%|▍         | 11/247 [00:23<08:44,  2.22s/it]predicting train subjects:   5%|▍         | 12/247 [00:25<08:23,  2.14s/it]predicting train subjects:   5%|▌         | 13/247 [00:27<08:06,  2.08s/it]predicting train subjects:   6%|▌         | 14/247 [00:30<08:15,  2.13s/it]predicting train subjects:   6%|▌         | 15/247 [00:32<08:17,  2.14s/it]predicting train subjects:   6%|▋         | 16/247 [00:34<08:34,  2.23s/it]predicting train subjects:   7%|▋         | 17/247 [00:36<08:38,  2.26s/it]predicting train subjects:   7%|▋         | 18/247 [00:39<08:34,  2.25s/it]predicting train subjects:   8%|▊         | 19/247 [00:41<08:33,  2.25s/it]predicting train subjects:   8%|▊         | 20/247 [00:43<08:12,  2.17s/it]predicting train subjects:   9%|▊         | 21/247 [00:45<08:17,  2.20s/it]predicting train subjects:   9%|▉         | 22/247 [00:47<07:57,  2.12s/it]predicting train subjects:   9%|▉         | 23/247 [00:49<07:43,  2.07s/it]predicting train subjects:  10%|▉         | 24/247 [00:51<07:58,  2.15s/it]predicting train subjects:  10%|█         | 25/247 [00:54<08:08,  2.20s/it]predicting train subjects:  11%|█         | 26/247 [00:56<07:51,  2.13s/it]predicting train subjects:  11%|█         | 27/247 [00:58<07:37,  2.08s/it]predicting train subjects:  11%|█▏        | 28/247 [01:00<07:26,  2.04s/it]predicting train subjects:  12%|█▏        | 29/247 [01:02<07:45,  2.14s/it]predicting train subjects:  12%|█▏        | 30/247 [01:04<07:53,  2.18s/it]predicting train subjects:  13%|█▎        | 31/247 [01:06<07:37,  2.12s/it]predicting train subjects:  13%|█▎        | 32/247 [01:08<07:39,  2.14s/it]predicting train subjects:  13%|█▎        | 33/247 [01:10<07:23,  2.07s/it]predicting train subjects:  14%|█▍        | 34/247 [01:12<07:19,  2.06s/it]predicting train subjects:  14%|█▍        | 35/247 [01:15<07:31,  2.13s/it]predicting train subjects:  15%|█▍        | 36/247 [01:17<07:35,  2.16s/it]predicting train subjects:  15%|█▍        | 37/247 [01:19<07:19,  2.09s/it]predicting train subjects:  15%|█▌        | 38/247 [01:21<07:25,  2.13s/it]predicting train subjects:  16%|█▌        | 39/247 [01:23<07:09,  2.06s/it]predicting train subjects:  16%|█▌        | 40/247 [01:25<06:58,  2.02s/it]predicting train subjects:  17%|█▋        | 41/247 [01:27<07:11,  2.09s/it]predicting train subjects:  17%|█▋        | 42/247 [01:29<07:13,  2.11s/it]predicting train subjects:  17%|█▋        | 43/247 [01:32<07:26,  2.19s/it]predicting train subjects:  18%|█▊        | 44/247 [01:34<07:07,  2.11s/it]predicting train subjects:  18%|█▊        | 45/247 [01:35<06:53,  2.05s/it]predicting train subjects:  19%|█▊        | 46/247 [01:38<07:03,  2.11s/it]predicting train subjects:  19%|█▉        | 47/247 [01:40<06:51,  2.06s/it]predicting train subjects:  19%|█▉        | 48/247 [01:42<07:06,  2.14s/it]predicting train subjects:  20%|█▉        | 49/247 [01:44<06:52,  2.08s/it]predicting train subjects:  20%|██        | 50/247 [01:46<06:59,  2.13s/it]predicting train subjects:  21%|██        | 51/247 [01:48<06:44,  2.06s/it]predicting train subjects:  21%|██        | 52/247 [01:50<06:50,  2.10s/it]predicting train subjects:  21%|██▏       | 53/247 [01:52<06:44,  2.08s/it]predicting train subjects:  22%|██▏       | 54/247 [01:54<06:33,  2.04s/it]predicting train subjects:  22%|██▏       | 55/247 [01:57<06:49,  2.13s/it]predicting train subjects:  23%|██▎       | 56/247 [01:59<06:36,  2.08s/it]predicting train subjects:  23%|██▎       | 57/247 [02:01<06:41,  2.11s/it]predicting train subjects:  23%|██▎       | 58/247 [02:03<06:50,  2.17s/it]predicting train subjects:  24%|██▍       | 59/247 [02:05<06:32,  2.09s/it]predicting train subjects:  24%|██▍       | 60/247 [02:07<06:21,  2.04s/it]predicting train subjects:  25%|██▍       | 61/247 [02:09<06:36,  2.13s/it]predicting train subjects:  25%|██▌       | 62/247 [02:11<06:26,  2.09s/it]predicting train subjects:  26%|██▌       | 63/247 [02:13<06:32,  2.14s/it]predicting train subjects:  26%|██▌       | 64/247 [02:15<06:20,  2.08s/it]predicting train subjects:  26%|██▋       | 65/247 [02:17<06:07,  2.02s/it]predicting train subjects:  27%|██▋       | 66/247 [02:19<06:14,  2.07s/it]predicting train subjects:  27%|██▋       | 67/247 [02:22<06:25,  2.14s/it]predicting train subjects:  28%|██▊       | 68/247 [02:24<06:30,  2.18s/it]predicting train subjects:  28%|██▊       | 69/247 [02:26<06:33,  2.21s/it]predicting train subjects:  28%|██▊       | 70/247 [02:28<06:16,  2.13s/it]predicting train subjects:  29%|██▊       | 71/247 [02:31<06:22,  2.17s/it]predicting train subjects:  29%|██▉       | 72/247 [02:33<06:11,  2.12s/it]predicting train subjects:  30%|██▉       | 73/247 [02:35<06:01,  2.08s/it]predicting train subjects:  30%|██▉       | 74/247 [02:37<05:53,  2.04s/it]predicting train subjects:  30%|███       | 75/247 [02:39<06:04,  2.12s/it]predicting train subjects:  31%|███       | 76/247 [02:41<05:51,  2.05s/it]predicting train subjects:  31%|███       | 77/247 [02:43<05:38,  1.99s/it]predicting train subjects:  32%|███▏      | 78/247 [02:45<05:49,  2.07s/it]predicting train subjects:  32%|███▏      | 79/247 [02:47<05:46,  2.06s/it]predicting train subjects:  32%|███▏      | 80/247 [02:49<06:05,  2.19s/it]predicting train subjects:  33%|███▎      | 81/247 [02:52<06:19,  2.29s/it]predicting train subjects:  33%|███▎      | 82/247 [02:54<06:26,  2.35s/it]predicting train subjects:  34%|███▎      | 83/247 [02:56<06:02,  2.21s/it]predicting train subjects:  34%|███▍      | 84/247 [02:59<06:04,  2.24s/it]predicting train subjects:  34%|███▍      | 85/247 [03:01<06:14,  2.31s/it]predicting train subjects:  35%|███▍      | 86/247 [03:03<06:03,  2.26s/it]predicting train subjects:  35%|███▌      | 87/247 [03:06<06:17,  2.36s/it]predicting train subjects:  36%|███▌      | 88/247 [03:08<06:25,  2.43s/it]predicting train subjects:  36%|███▌      | 89/247 [03:10<05:58,  2.27s/it]predicting train subjects:  36%|███▋      | 90/247 [03:13<05:59,  2.29s/it]predicting train subjects:  37%|███▋      | 91/247 [03:15<06:05,  2.35s/it]predicting train subjects:  37%|███▋      | 92/247 [03:18<06:10,  2.39s/it]predicting train subjects:  38%|███▊      | 93/247 [03:20<06:16,  2.45s/it]predicting train subjects:  38%|███▊      | 94/247 [03:23<06:21,  2.49s/it]predicting train subjects:  38%|███▊      | 95/247 [03:25<06:00,  2.37s/it]predicting train subjects:  39%|███▉      | 96/247 [03:27<05:36,  2.23s/it]predicting train subjects:  39%|███▉      | 97/247 [03:29<05:36,  2.24s/it]predicting train subjects:  40%|███▉      | 98/247 [03:31<05:36,  2.26s/it]predicting train subjects:  40%|████      | 99/247 [03:34<05:46,  2.34s/it]predicting train subjects:  40%|████      | 100/247 [03:36<05:49,  2.37s/it]predicting train subjects:  41%|████      | 101/247 [03:38<05:39,  2.33s/it]predicting train subjects:  41%|████▏     | 102/247 [03:40<05:24,  2.24s/it]predicting train subjects:  42%|████▏     | 103/247 [03:42<05:08,  2.14s/it]predicting train subjects:  42%|████▏     | 104/247 [03:45<05:20,  2.24s/it]predicting train subjects:  43%|████▎     | 105/247 [03:47<05:08,  2.17s/it]predicting train subjects:  43%|████▎     | 106/247 [03:49<04:53,  2.08s/it]predicting train subjects:  43%|████▎     | 107/247 [03:51<04:57,  2.13s/it]predicting train subjects:  44%|████▎     | 108/247 [03:53<04:59,  2.16s/it]predicting train subjects:  44%|████▍     | 109/247 [03:56<05:10,  2.25s/it]predicting train subjects:  45%|████▍     | 110/247 [03:58<05:01,  2.20s/it]predicting train subjects:  45%|████▍     | 111/247 [04:00<05:12,  2.29s/it]predicting train subjects:  45%|████▌     | 112/247 [04:02<04:51,  2.16s/it]predicting train subjects:  46%|████▌     | 113/247 [04:05<05:05,  2.28s/it]predicting train subjects:  46%|████▌     | 114/247 [04:07<04:53,  2.21s/it]predicting train subjects:  47%|████▋     | 115/247 [04:09<04:38,  2.11s/it]predicting train subjects:  47%|████▋     | 116/247 [04:11<04:41,  2.15s/it]predicting train subjects:  47%|████▋     | 117/247 [04:13<04:53,  2.26s/it]predicting train subjects:  48%|████▊     | 118/247 [04:15<04:44,  2.20s/it]predicting train subjects:  48%|████▊     | 119/247 [04:18<04:53,  2.29s/it]predicting train subjects:  49%|████▊     | 120/247 [04:20<04:32,  2.14s/it]predicting train subjects:  49%|████▉     | 121/247 [04:22<04:36,  2.20s/it]predicting train subjects:  49%|████▉     | 122/247 [04:25<04:49,  2.32s/it]predicting train subjects:  50%|████▉     | 123/247 [04:27<04:32,  2.19s/it]predicting train subjects:  50%|█████     | 124/247 [04:29<04:33,  2.22s/it]predicting train subjects:  51%|█████     | 125/247 [04:31<04:40,  2.30s/it]predicting train subjects:  51%|█████     | 126/247 [04:34<04:50,  2.40s/it]predicting train subjects:  51%|█████▏    | 127/247 [04:36<04:38,  2.32s/it]predicting train subjects:  52%|█████▏    | 128/247 [04:38<04:18,  2.17s/it]predicting train subjects:  52%|█████▏    | 129/247 [04:40<04:25,  2.25s/it]predicting train subjects:  53%|█████▎    | 130/247 [04:42<04:15,  2.19s/it]predicting train subjects:  53%|█████▎    | 131/247 [04:44<03:59,  2.07s/it]predicting train subjects:  53%|█████▎    | 132/247 [04:47<04:15,  2.22s/it]predicting train subjects:  54%|█████▍    | 133/247 [04:49<04:21,  2.29s/it]predicting train subjects:  54%|█████▍    | 134/247 [04:52<04:23,  2.33s/it]predicting train subjects:  55%|█████▍    | 135/247 [04:54<04:11,  2.24s/it]predicting train subjects:  55%|█████▌    | 136/247 [04:56<04:19,  2.34s/it]predicting train subjects:  55%|█████▌    | 137/247 [04:58<04:00,  2.18s/it]predicting train subjects:  56%|█████▌    | 138/247 [05:00<03:58,  2.19s/it]predicting train subjects:  56%|█████▋    | 139/247 [05:03<04:09,  2.31s/it]predicting train subjects:  57%|█████▋    | 140/247 [05:05<04:00,  2.24s/it]predicting train subjects:  57%|█████▋    | 141/247 [05:07<03:43,  2.11s/it]predicting train subjects:  57%|█████▋    | 142/247 [05:09<03:47,  2.17s/it]predicting train subjects:  58%|█████▊    | 143/247 [05:12<03:54,  2.26s/it]predicting train subjects:  58%|█████▊    | 144/247 [05:14<03:48,  2.22s/it]predicting train subjects:  59%|█████▊    | 145/247 [05:16<03:56,  2.32s/it]predicting train subjects:  59%|█████▉    | 146/247 [05:18<03:45,  2.23s/it]predicting train subjects:  60%|█████▉    | 147/247 [05:20<03:31,  2.11s/it]predicting train subjects:  60%|█████▉    | 148/247 [05:22<03:32,  2.15s/it]predicting train subjects:  60%|██████    | 149/247 [05:25<03:39,  2.24s/it]predicting train subjects:  61%|██████    | 150/247 [05:27<03:31,  2.19s/it]predicting train subjects:  61%|██████    | 151/247 [05:29<03:21,  2.10s/it]predicting train subjects:  62%|██████▏   | 152/247 [05:31<03:23,  2.14s/it]predicting train subjects:  62%|██████▏   | 153/247 [05:33<03:29,  2.23s/it]predicting train subjects:  62%|██████▏   | 154/247 [05:36<03:33,  2.30s/it]predicting train subjects:  63%|██████▎   | 155/247 [05:38<03:24,  2.23s/it]predicting train subjects:  63%|██████▎   | 156/247 [05:40<03:14,  2.13s/it]predicting train subjects:  64%|██████▎   | 157/247 [05:42<03:15,  2.17s/it]predicting train subjects:  64%|██████▍   | 158/247 [05:45<03:21,  2.26s/it]predicting train subjects:  64%|██████▍   | 159/247 [05:46<03:10,  2.16s/it]predicting train subjects:  65%|██████▍   | 160/247 [05:49<03:19,  2.29s/it]predicting train subjects:  65%|██████▌   | 161/247 [05:52<03:24,  2.37s/it]predicting train subjects:  66%|██████▌   | 162/247 [05:54<03:25,  2.41s/it]predicting train subjects:  66%|██████▌   | 163/247 [05:57<03:27,  2.48s/it]predicting train subjects:  66%|██████▋   | 164/247 [05:59<03:14,  2.35s/it]predicting train subjects:  67%|██████▋   | 165/247 [06:01<02:59,  2.19s/it]predicting train subjects:  67%|██████▋   | 166/247 [06:03<03:00,  2.23s/it]predicting train subjects:  68%|██████▊   | 167/247 [06:05<02:59,  2.24s/it]predicting train subjects:  68%|██████▊   | 168/247 [06:08<03:05,  2.35s/it]predicting train subjects:  68%|██████▊   | 169/247 [06:10<02:56,  2.26s/it]predicting train subjects:  69%|██████▉   | 170/247 [06:12<02:54,  2.27s/it]predicting train subjects:  69%|██████▉   | 171/247 [06:14<02:48,  2.22s/it]predicting train subjects:  70%|██████▉   | 172/247 [06:17<02:47,  2.23s/it]predicting train subjects:  70%|███████   | 173/247 [06:18<02:38,  2.15s/it]predicting train subjects:  70%|███████   | 174/247 [06:20<02:32,  2.10s/it]predicting train subjects:  71%|███████   | 175/247 [06:23<02:40,  2.23s/it]predicting train subjects:  71%|███████▏  | 176/247 [06:25<02:38,  2.23s/it]predicting train subjects:  72%|███████▏  | 177/247 [06:27<02:30,  2.15s/it]predicting train subjects:  72%|███████▏  | 178/247 [06:29<02:23,  2.08s/it]predicting train subjects:  72%|███████▏  | 179/247 [06:31<02:19,  2.05s/it]predicting train subjects:  73%|███████▎  | 180/247 [06:34<02:27,  2.20s/it]predicting train subjects:  73%|███████▎  | 181/247 [06:36<02:31,  2.30s/it]predicting train subjects:  74%|███████▎  | 182/247 [06:38<02:29,  2.30s/it]predicting train subjects:  74%|███████▍  | 183/247 [06:40<02:19,  2.18s/it]predicting train subjects:  74%|███████▍  | 184/247 [06:42<02:13,  2.11s/it]predicting train subjects:  75%|███████▍  | 185/247 [06:44<02:10,  2.11s/it]predicting train subjects:  75%|███████▌  | 186/247 [06:47<02:16,  2.24s/it]predicting train subjects:  76%|███████▌  | 187/247 [06:49<02:18,  2.31s/it]predicting train subjects:  76%|███████▌  | 188/247 [06:52<02:15,  2.29s/it]predicting train subjects:  77%|███████▋  | 189/247 [06:54<02:06,  2.18s/it]predicting train subjects:  77%|███████▋  | 190/247 [06:56<01:59,  2.10s/it]predicting train subjects:  77%|███████▋  | 191/247 [06:57<01:55,  2.06s/it]predicting train subjects:  78%|███████▊  | 192/247 [06:59<01:52,  2.04s/it]predicting train subjects:  78%|███████▊  | 193/247 [07:02<01:57,  2.18s/it]predicting train subjects:  79%|███████▊  | 194/247 [07:05<02:01,  2.28s/it]predicting train subjects:  79%|███████▉  | 195/247 [07:07<01:56,  2.25s/it]predicting train subjects:  79%|███████▉  | 196/247 [07:09<01:50,  2.16s/it]predicting train subjects:  80%|███████▉  | 197/247 [07:11<01:50,  2.21s/it]predicting train subjects:  80%|████████  | 198/247 [07:13<01:47,  2.19s/it]predicting train subjects:  81%|████████  | 199/247 [07:15<01:41,  2.12s/it]predicting train subjects:  81%|████████  | 200/247 [07:17<01:43,  2.21s/it]predicting train subjects:  81%|████████▏ | 201/247 [07:19<01:37,  2.13s/it]predicting train subjects:  82%|████████▏ | 202/247 [07:22<01:41,  2.26s/it]predicting train subjects:  82%|████████▏ | 203/247 [07:25<01:42,  2.34s/it]predicting train subjects:  83%|████████▎ | 204/247 [07:27<01:38,  2.30s/it]predicting train subjects:  83%|████████▎ | 205/247 [07:29<01:33,  2.23s/it]predicting train subjects:  83%|████████▎ | 206/247 [07:31<01:30,  2.22s/it]predicting train subjects:  84%|████████▍ | 207/247 [07:33<01:25,  2.15s/it]predicting train subjects:  84%|████████▍ | 208/247 [07:36<01:30,  2.32s/it]predicting train subjects:  85%|████████▍ | 209/247 [07:38<01:31,  2.41s/it]predicting train subjects:  85%|████████▌ | 210/247 [07:41<01:27,  2.36s/it]predicting train subjects:  85%|████████▌ | 211/247 [07:43<01:21,  2.25s/it]predicting train subjects:  86%|████████▌ | 212/247 [07:45<01:15,  2.17s/it]predicting train subjects:  86%|████████▌ | 213/247 [07:47<01:14,  2.19s/it]predicting train subjects:  87%|████████▋ | 214/247 [07:49<01:10,  2.13s/it]predicting train subjects:  87%|████████▋ | 215/247 [07:51<01:07,  2.10s/it]predicting train subjects:  87%|████████▋ | 216/247 [07:53<01:09,  2.23s/it]predicting train subjects:  88%|████████▊ | 217/247 [07:56<01:09,  2.32s/it]predicting train subjects:  88%|████████▊ | 218/247 [07:58<01:05,  2.28s/it]predicting train subjects:  89%|████████▊ | 219/247 [08:00<01:00,  2.17s/it]predicting train subjects:  89%|████████▉ | 220/247 [08:02<00:58,  2.18s/it]predicting train subjects:  89%|████████▉ | 221/247 [08:04<00:55,  2.12s/it]predicting train subjects:  90%|████████▉ | 222/247 [08:07<00:56,  2.25s/it]predicting train subjects:  90%|█████████ | 223/247 [08:09<00:51,  2.16s/it]predicting train subjects:  91%|█████████ | 224/247 [08:11<00:48,  2.10s/it]predicting train subjects:  91%|█████████ | 225/247 [08:13<00:45,  2.08s/it]predicting train subjects:  91%|█████████▏| 226/247 [08:15<00:47,  2.24s/it]predicting train subjects:  92%|█████████▏| 227/247 [08:17<00:44,  2.23s/it]predicting train subjects:  92%|█████████▏| 228/247 [08:19<00:40,  2.16s/it]predicting train subjects:  93%|█████████▎| 229/247 [08:22<00:39,  2.17s/it]predicting train subjects:  93%|█████████▎| 230/247 [08:24<00:35,  2.11s/it]predicting train subjects:  94%|█████████▎| 231/247 [08:26<00:32,  2.06s/it]predicting train subjects:  94%|█████████▍| 232/247 [08:28<00:33,  2.22s/it]predicting train subjects:  94%|█████████▍| 233/247 [08:30<00:30,  2.20s/it]predicting train subjects:  95%|█████████▍| 234/247 [08:32<00:28,  2.20s/it]predicting train subjects:  95%|█████████▌| 235/247 [08:35<00:25,  2.15s/it]predicting train subjects:  96%|█████████▌| 236/247 [08:36<00:22,  2.09s/it]predicting train subjects:  96%|█████████▌| 237/247 [08:38<00:20,  2.05s/it]predicting train subjects:  96%|█████████▋| 238/247 [08:41<00:19,  2.20s/it]predicting train subjects:  97%|█████████▋| 239/247 [08:43<00:16,  2.12s/it]predicting train subjects:  97%|█████████▋| 240/247 [08:45<00:14,  2.06s/it]predicting train subjects:  98%|█████████▊| 241/247 [08:47<00:12,  2.05s/it]predicting train subjects:  98%|█████████▊| 242/247 [08:49<00:10,  2.02s/it]predicting train subjects:  98%|█████████▊| 243/247 [08:51<00:08,  2.16s/it]predicting train subjects:  99%|█████████▉| 244/247 [08:54<00:06,  2.28s/it]predicting train subjects:  99%|█████████▉| 245/247 [08:56<00:04,  2.27s/it]predicting train subjects: 100%|█████████▉| 246/247 [08:58<00:02,  2.25s/it]predicting train subjects: 100%|██████████| 247/247 [09:00<00:00,  2.16s/it]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6_BC_CSFn
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<06:31,  1.59s/it]Loading train:   1%|          | 2/247 [00:02<06:15,  1.53s/it]Loading train:   1%|          | 3/247 [00:04<06:00,  1.48s/it]Loading train:   2%|▏         | 4/247 [00:05<05:52,  1.45s/it]Loading train:   2%|▏         | 5/247 [00:06<05:11,  1.29s/it]Loading train:   2%|▏         | 6/247 [00:07<04:55,  1.23s/it]Loading train:   3%|▎         | 7/247 [00:08<04:39,  1.17s/it]Loading train:   3%|▎         | 8/247 [00:09<04:33,  1.14s/it]Loading train:   4%|▎         | 9/247 [00:10<04:26,  1.12s/it]Loading train:   4%|▍         | 10/247 [00:11<04:04,  1.03s/it]Loading train:   4%|▍         | 11/247 [00:12<03:56,  1.00s/it]Loading train:   5%|▍         | 12/247 [00:13<03:45,  1.04it/s]Loading train:   5%|▌         | 13/247 [00:14<03:47,  1.03it/s]Loading train:   6%|▌         | 14/247 [00:15<03:57,  1.02s/it]Loading train:   6%|▌         | 15/247 [00:16<03:53,  1.01s/it]Loading train:   6%|▋         | 16/247 [00:17<04:14,  1.10s/it]Loading train:   7%|▋         | 17/247 [00:19<04:38,  1.21s/it]Loading train:   7%|▋         | 18/247 [00:20<04:32,  1.19s/it]Loading train:   8%|▊         | 19/247 [00:21<04:40,  1.23s/it]Loading train:   8%|▊         | 20/247 [00:22<04:22,  1.16s/it]Loading train:   9%|▊         | 21/247 [00:23<04:11,  1.11s/it]Loading train:   9%|▉         | 22/247 [00:24<03:40,  1.02it/s]Loading train:   9%|▉         | 23/247 [00:25<03:44,  1.00s/it]Loading train:  10%|▉         | 24/247 [00:26<03:58,  1.07s/it]Loading train:  10%|█         | 25/247 [00:28<04:11,  1.13s/it]Loading train:  11%|█         | 26/247 [00:29<03:59,  1.08s/it]Loading train:  11%|█         | 27/247 [00:29<03:46,  1.03s/it]Loading train:  11%|█▏        | 28/247 [00:31<03:51,  1.06s/it]Loading train:  12%|█▏        | 29/247 [00:32<03:52,  1.07s/it]Loading train:  12%|█▏        | 30/247 [00:33<03:48,  1.05s/it]Loading train:  13%|█▎        | 31/247 [00:34<03:59,  1.11s/it]Loading train:  13%|█▎        | 32/247 [00:35<04:08,  1.16s/it]Loading train:  13%|█▎        | 33/247 [00:36<04:14,  1.19s/it]Loading train:  14%|█▍        | 34/247 [00:38<04:23,  1.24s/it]Loading train:  14%|█▍        | 35/247 [00:39<04:08,  1.17s/it]Loading train:  15%|█▍        | 36/247 [00:40<03:57,  1.13s/it]Loading train:  15%|█▍        | 37/247 [00:41<03:41,  1.05s/it]Loading train:  15%|█▌        | 38/247 [00:42<03:53,  1.12s/it]Loading train:  16%|█▌        | 39/247 [00:43<03:46,  1.09s/it]Loading train:  16%|█▌        | 40/247 [00:44<03:38,  1.06s/it]Loading train:  17%|█▋        | 41/247 [00:45<03:47,  1.10s/it]Loading train:  17%|█▋        | 42/247 [00:46<03:39,  1.07s/it]Loading train:  17%|█▋        | 43/247 [00:47<03:35,  1.06s/it]Loading train:  18%|█▊        | 44/247 [00:48<03:27,  1.02s/it]Loading train:  18%|█▊        | 45/247 [00:49<03:26,  1.02s/it]Loading train:  19%|█▊        | 46/247 [00:51<03:52,  1.16s/it]Loading train:  19%|█▉        | 47/247 [00:52<03:45,  1.13s/it]Loading train:  19%|█▉        | 48/247 [00:53<04:11,  1.26s/it]Loading train:  20%|█▉        | 49/247 [00:54<03:51,  1.17s/it]Loading train:  20%|██        | 50/247 [00:55<03:47,  1.15s/it]Loading train:  21%|██        | 51/247 [00:56<03:20,  1.02s/it]Loading train:  21%|██        | 52/247 [00:57<03:13,  1.01it/s]Loading train:  21%|██▏       | 53/247 [00:58<02:57,  1.09it/s]Loading train:  22%|██▏       | 54/247 [00:58<02:42,  1.18it/s]Loading train:  22%|██▏       | 55/247 [00:59<02:41,  1.19it/s]Loading train:  23%|██▎       | 56/247 [01:00<02:26,  1.31it/s]Loading train:  23%|██▎       | 57/247 [01:01<02:25,  1.30it/s]Loading train:  23%|██▎       | 58/247 [01:01<02:24,  1.31it/s]Loading train:  24%|██▍       | 59/247 [01:02<02:15,  1.39it/s]Loading train:  24%|██▍       | 60/247 [01:03<02:14,  1.39it/s]Loading train:  25%|██▍       | 61/247 [01:04<02:23,  1.29it/s]Loading train:  25%|██▌       | 62/247 [01:04<02:23,  1.29it/s]Loading train:  26%|██▌       | 63/247 [01:05<02:21,  1.30it/s]Loading train:  26%|██▌       | 64/247 [01:06<02:21,  1.30it/s]Loading train:  26%|██▋       | 65/247 [01:07<02:13,  1.36it/s]Loading train:  27%|██▋       | 66/247 [01:07<02:12,  1.37it/s]Loading train:  27%|██▋       | 67/247 [01:08<02:15,  1.33it/s]Loading train:  28%|██▊       | 68/247 [01:09<02:10,  1.37it/s]Loading train:  28%|██▊       | 69/247 [01:10<02:17,  1.29it/s]Loading train:  28%|██▊       | 70/247 [01:10<02:12,  1.33it/s]Loading train:  29%|██▊       | 71/247 [01:11<02:14,  1.31it/s]Loading train:  29%|██▉       | 72/247 [01:12<02:06,  1.38it/s]Loading train:  30%|██▉       | 73/247 [01:13<02:06,  1.38it/s]Loading train:  30%|██▉       | 74/247 [01:13<02:01,  1.43it/s]Loading train:  30%|███       | 75/247 [01:14<02:09,  1.33it/s]Loading train:  31%|███       | 76/247 [01:15<02:07,  1.34it/s]Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Loading train:  31%|███       | 77/247 [01:16<02:22,  1.19it/s]Loading train:  32%|███▏      | 78/247 [01:17<02:41,  1.04it/s]Loading train:  32%|███▏      | 79/247 [01:18<02:49,  1.01s/it]Loading train:  32%|███▏      | 80/247 [01:20<03:06,  1.12s/it]Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Loading train:  33%|███▎      | 81/247 [01:21<03:09,  1.14s/it]Loading train:  33%|███▎      | 82/247 [01:22<02:59,  1.09s/it]Loading train:  34%|███▎      | 83/247 [01:22<02:38,  1.03it/s]Loading train:  34%|███▍      | 84/247 [01:23<02:30,  1.09it/s]Loading train:  34%|███▍      | 85/247 [01:24<02:23,  1.13it/s]Loading train:  35%|███▍      | 86/247 [01:25<02:12,  1.22it/s]Loading train:  35%|███▌      | 87/247 [01:26<02:12,  1.21it/s]Loading train:  36%|███▌      | 88/247 [01:26<02:14,  1.18it/s]Loading train:  36%|███▌      | 89/247 [01:27<02:06,  1.25it/s]Loading train:  36%|███▋      | 90/247 [01:28<02:10,  1.21it/s]Loading train:  37%|███▋      | 91/247 [01:29<02:08,  1.21it/s]Loading train:  37%|███▋      | 92/247 [01:30<02:04,  1.24it/s]Loading train:  38%|███▊      | 93/247 [01:30<02:02,  1.25it/s]Loading train:  38%|███▊      | 94/247 [01:31<02:03,  1.24it/s]Loading train:  38%|███▊      | 95/247 [01:32<01:56,  1.31it/s]Loading train:  39%|███▉      | 96/247 [01:32<01:46,  1.41it/s]Loading train:  39%|███▉      | 97/247 [01:33<01:45,  1.42it/s]Loading train:  40%|███▉      | 98/247 [01:34<01:41,  1.47it/s]Loading train:  40%|████      | 99/247 [01:35<01:47,  1.38it/s]Loading train:  40%|████      | 100/247 [01:35<01:50,  1.33it/s]Loading train:  41%|████      | 101/247 [01:36<01:45,  1.38it/s]Loading train:  41%|████▏     | 102/247 [01:37<01:42,  1.41it/s]Loading train:  42%|████▏     | 103/247 [01:37<01:39,  1.45it/s]Loading train:  42%|████▏     | 104/247 [01:38<01:42,  1.39it/s]Loading train:  43%|████▎     | 105/247 [01:39<01:39,  1.43it/s]Loading train:  43%|████▎     | 106/247 [01:40<01:38,  1.43it/s]Loading train:  43%|████▎     | 107/247 [01:40<01:37,  1.43it/s]Loading train:  44%|████▎     | 108/247 [01:41<01:35,  1.46it/s]Loading train:  44%|████▍     | 109/247 [01:42<01:40,  1.37it/s]Loading train:  45%|████▍     | 110/247 [01:42<01:41,  1.35it/s]Loading train:  45%|████▍     | 111/247 [01:43<01:45,  1.29it/s]Loading train:  45%|████▌     | 112/247 [01:44<01:36,  1.39it/s]Loading train:  46%|████▌     | 113/247 [01:45<01:43,  1.29it/s]Loading train:  46%|████▌     | 114/247 [01:46<01:40,  1.32it/s]Loading train:  47%|████▋     | 115/247 [01:46<01:36,  1.36it/s]Loading train:  47%|████▋     | 116/247 [01:47<01:35,  1.37it/s]Loading train:  47%|████▋     | 117/247 [01:48<01:39,  1.31it/s]Loading train:  48%|████▊     | 118/247 [01:48<01:36,  1.33it/s]Loading train:  48%|████▊     | 119/247 [01:49<01:40,  1.28it/s]Loading train:  49%|████▊     | 120/247 [01:50<01:34,  1.34it/s]Loading train:  49%|████▉     | 121/247 [01:51<01:33,  1.35it/s]Loading train:  49%|████▉     | 122/247 [01:52<01:37,  1.28it/s]Loading train:  50%|████▉     | 123/247 [01:52<01:31,  1.36it/s]Loading train:  50%|█████     | 124/247 [01:53<01:28,  1.39it/s]Loading train:  51%|█████     | 125/247 [01:54<01:31,  1.33it/s]Loading train:  51%|█████     | 126/247 [01:55<01:31,  1.32it/s]Loading train:  51%|█████▏    | 127/247 [01:55<01:27,  1.38it/s]Loading train:  52%|█████▏    | 128/247 [01:56<01:21,  1.46it/s]Loading train:  52%|█████▏    | 129/247 [01:57<01:28,  1.33it/s]Loading train:  53%|█████▎    | 130/247 [01:57<01:26,  1.35it/s]Loading train:  53%|█████▎    | 131/247 [01:58<01:23,  1.39it/s]Loading train:  53%|█████▎    | 132/247 [01:59<01:22,  1.39it/s]Loading train:  54%|█████▍    | 133/247 [02:00<01:22,  1.38it/s]Loading train:  54%|█████▍    | 134/247 [02:00<01:24,  1.34it/s]Loading train:  55%|█████▍    | 135/247 [02:01<01:19,  1.40it/s]Loading train:  55%|█████▌    | 136/247 [02:02<01:19,  1.40it/s]Loading train:  55%|█████▌    | 137/247 [02:02<01:13,  1.49it/s]Loading train:  56%|█████▌    | 138/247 [02:03<01:12,  1.50it/s]Loading train:  56%|█████▋    | 139/247 [02:04<01:18,  1.37it/s]Loading train:  57%|█████▋    | 140/247 [02:05<01:19,  1.34it/s]Loading train:  57%|█████▋    | 141/247 [02:05<01:18,  1.36it/s]Loading train:  57%|█████▋    | 142/247 [02:06<01:20,  1.31it/s]Loading train:  58%|█████▊    | 143/247 [02:07<01:23,  1.25it/s]Loading train:  58%|█████▊    | 144/247 [02:08<01:19,  1.29it/s]Loading train:  59%|█████▊    | 145/247 [02:09<01:21,  1.25it/s]Loading train:  59%|█████▉    | 146/247 [02:09<01:17,  1.31it/s]Loading train:  60%|█████▉    | 147/247 [02:10<01:14,  1.34it/s]Loading train:  60%|█████▉    | 148/247 [02:11<01:12,  1.36it/s]Loading train:  60%|██████    | 149/247 [02:11<01:15,  1.30it/s]Loading train:  61%|██████    | 150/247 [02:12<01:13,  1.31it/s]Loading train:  61%|██████    | 151/247 [02:13<01:11,  1.34it/s]Loading train:  62%|██████▏   | 152/247 [02:14<01:09,  1.37it/s]Loading train:  62%|██████▏   | 153/247 [02:14<01:09,  1.36it/s]Loading train:  62%|██████▏   | 154/247 [02:15<01:13,  1.26it/s]Loading train:  63%|██████▎   | 155/247 [02:16<01:14,  1.24it/s]Loading train:  63%|██████▎   | 156/247 [02:17<01:10,  1.30it/s]Loading train:  64%|██████▎   | 157/247 [02:18<01:10,  1.28it/s]Loading train:  64%|██████▍   | 158/247 [02:18<01:11,  1.25it/s]Loading train:  64%|██████▍   | 159/247 [02:19<01:06,  1.32it/s]Loading train:  65%|██████▍   | 160/247 [02:20<01:07,  1.30it/s]Loading train:  65%|██████▌   | 161/247 [02:21<01:06,  1.29it/s]Loading train:  66%|██████▌   | 162/247 [02:22<01:08,  1.24it/s]Loading train:  66%|██████▌   | 163/247 [02:22<01:08,  1.23it/s]Loading train:  66%|██████▋   | 164/247 [02:23<01:05,  1.27it/s]Loading train:  67%|██████▋   | 165/247 [02:24<01:01,  1.32it/s]Loading train:  67%|██████▋   | 166/247 [02:25<00:58,  1.38it/s]Loading train:  68%|██████▊   | 167/247 [02:25<00:57,  1.39it/s]Loading train:  68%|██████▊   | 168/247 [02:26<00:59,  1.32it/s]Loading train:  68%|██████▊   | 169/247 [02:27<00:58,  1.34it/s]Loading train:  69%|██████▉   | 170/247 [02:28<00:58,  1.32it/s]Loading train:  69%|██████▉   | 171/247 [02:28<00:55,  1.36it/s]Loading train:  70%|██████▉   | 172/247 [02:30<01:10,  1.06it/s]Loading train:  70%|███████   | 173/247 [02:31<01:13,  1.00it/s]Loading train:  70%|███████   | 174/247 [02:32<01:16,  1.04s/it]Loading train:  71%|███████   | 175/247 [02:33<01:23,  1.16s/it]Loading train:  71%|███████▏  | 176/247 [02:34<01:15,  1.06s/it]Loading train:  72%|███████▏  | 177/247 [02:35<01:08,  1.01it/s]Loading train:  72%|███████▏  | 178/247 [02:36<01:03,  1.08it/s]Loading train:  72%|███████▏  | 179/247 [02:37<00:59,  1.14it/s]Loading train:  73%|███████▎  | 180/247 [02:37<00:59,  1.13it/s]Loading train:  73%|███████▎  | 181/247 [02:38<00:58,  1.13it/s]Loading train:  74%|███████▎  | 182/247 [02:39<00:53,  1.22it/s]Loading train:  74%|███████▍  | 183/247 [02:40<00:49,  1.31it/s]Loading train:  74%|███████▍  | 184/247 [02:40<00:46,  1.37it/s]Loading train:  75%|███████▍  | 185/247 [02:41<00:43,  1.42it/s]Loading train:  75%|███████▌  | 186/247 [02:42<00:43,  1.39it/s]Loading train:  76%|███████▌  | 187/247 [02:42<00:43,  1.39it/s]Loading train:  76%|███████▌  | 188/247 [02:43<00:41,  1.42it/s]Loading train:  77%|███████▋  | 189/247 [02:44<00:40,  1.44it/s]Loading train:  77%|███████▋  | 190/247 [02:44<00:37,  1.50it/s]Loading train:  77%|███████▋  | 191/247 [02:45<00:36,  1.54it/s]Loading train:  78%|███████▊  | 192/247 [02:46<00:35,  1.57it/s]Loading train:  78%|███████▊  | 193/247 [02:46<00:36,  1.49it/s]Loading train:  79%|███████▊  | 194/247 [02:47<00:36,  1.44it/s]Loading train:  79%|███████▉  | 195/247 [02:48<00:36,  1.43it/s]Loading train:  79%|███████▉  | 196/247 [02:48<00:33,  1.51it/s]Loading train:  80%|███████▉  | 197/247 [02:49<00:33,  1.48it/s]Loading train:  80%|████████  | 198/247 [02:50<00:34,  1.43it/s]Loading train:  81%|████████  | 199/247 [02:50<00:32,  1.50it/s]Loading train:  81%|████████  | 200/247 [02:51<00:31,  1.49it/s]Loading train:  81%|████████▏ | 201/247 [02:52<00:30,  1.51it/s]Loading train:  82%|████████▏ | 202/247 [02:53<00:31,  1.42it/s]Loading train:  82%|████████▏ | 203/247 [02:53<00:32,  1.37it/s]Loading train:  83%|████████▎ | 204/247 [02:54<00:31,  1.39it/s]Loading train:  83%|████████▎ | 205/247 [02:55<00:30,  1.38it/s]Loading train:  83%|████████▎ | 206/247 [02:56<00:29,  1.38it/s]Loading train:  84%|████████▍ | 207/247 [02:56<00:29,  1.35it/s]Loading train:  84%|████████▍ | 208/247 [02:57<00:30,  1.29it/s]Loading train:  85%|████████▍ | 209/247 [02:58<00:30,  1.23it/s]Loading train:  85%|████████▌ | 210/247 [02:59<00:30,  1.23it/s]Loading train:  85%|████████▌ | 211/247 [03:00<00:29,  1.21it/s]Loading train:  86%|████████▌ | 212/247 [03:00<00:27,  1.25it/s]Loading train:  86%|████████▌ | 213/247 [03:01<00:27,  1.24it/s]Loading train:  87%|████████▋ | 214/247 [03:02<00:25,  1.29it/s]Loading train:  87%|████████▋ | 215/247 [03:03<00:24,  1.33it/s]Loading train:  87%|████████▋ | 216/247 [03:04<00:24,  1.28it/s]Loading train:  88%|████████▊ | 217/247 [03:05<00:26,  1.12it/s]Loading train:  88%|████████▊ | 218/247 [03:06<00:26,  1.11it/s]Loading train:  89%|████████▊ | 219/247 [03:06<00:24,  1.15it/s]Loading train:  89%|████████▉ | 220/247 [03:07<00:23,  1.17it/s]Loading train:  89%|████████▉ | 221/247 [03:08<00:21,  1.21it/s]Loading train:  90%|████████▉ | 222/247 [03:09<00:20,  1.21it/s]Loading train:  90%|█████████ | 223/247 [03:10<00:19,  1.24it/s]Loading train:  91%|█████████ | 224/247 [03:10<00:18,  1.23it/s]Loading train:  91%|█████████ | 225/247 [03:12<00:20,  1.07it/s]Loading train:  91%|█████████▏| 226/247 [03:13<00:21,  1.03s/it]Loading train:  92%|█████████▏| 227/247 [03:14<00:19,  1.05it/s]Loading train:  92%|█████████▏| 228/247 [03:14<00:17,  1.10it/s]Loading train:  93%|█████████▎| 229/247 [03:15<00:15,  1.14it/s]Loading train:  93%|█████████▎| 230/247 [03:16<00:14,  1.21it/s]Loading train:  94%|█████████▎| 231/247 [03:17<00:12,  1.26it/s]Loading train:  94%|█████████▍| 232/247 [03:17<00:12,  1.24it/s]Loading train:  94%|█████████▍| 233/247 [03:18<00:11,  1.26it/s]Loading train:  95%|█████████▍| 234/247 [03:19<00:10,  1.25it/s]Loading train:  95%|█████████▌| 235/247 [03:20<00:09,  1.27it/s]Loading train:  96%|█████████▌| 236/247 [03:21<00:08,  1.28it/s]Loading train:  96%|█████████▌| 237/247 [03:21<00:07,  1.28it/s]Loading train:  96%|█████████▋| 238/247 [03:22<00:07,  1.22it/s]Loading train:  97%|█████████▋| 239/247 [03:23<00:06,  1.22it/s]Loading train:  97%|█████████▋| 240/247 [03:24<00:05,  1.25it/s]Loading train:  98%|█████████▊| 241/247 [03:25<00:04,  1.24it/s]Loading train:  98%|█████████▊| 242/247 [03:25<00:03,  1.31it/s]Loading train:  98%|█████████▊| 243/247 [03:26<00:03,  1.31it/s]Loading train:  99%|█████████▉| 244/247 [03:27<00:02,  1.31it/s]Loading train:  99%|█████████▉| 245/247 [03:28<00:01,  1.30it/s]Loading train: 100%|█████████▉| 246/247 [03:28<00:00,  1.28it/s]Loading train: 100%|██████████| 247/247 [03:29<00:00,  1.29it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:00, 284.56it/s]concatenating: train:  24%|██▍       | 60/247 [00:00<00:00, 290.36it/s]concatenating: train:  36%|███▋      | 90/247 [00:00<00:00, 293.06it/s]concatenating: train:  48%|████▊     | 118/247 [00:00<00:00, 287.70it/s]concatenating: train:  59%|█████▉    | 146/247 [00:00<00:00, 285.12it/s]concatenating: train:  70%|███████   | 173/247 [00:00<00:00, 279.91it/s]concatenating: train:  80%|████████  | 198/247 [00:00<00:00, 267.99it/s]concatenating: train:  90%|█████████ | 223/247 [00:00<00:00, 260.21it/s]concatenating: train: 100%|██████████| 247/247 [00:00<00:00, 283.48it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.37s/it]Loading test:  40%|████      | 2/5 [00:02<00:04,  1.40s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.31s/it]Loading test:  80%|████████  | 4/5 [00:05<00:01,  1.26s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.36s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 836.69it/s]
2019-09-01 17:48:11.348905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-09-01 17:48:11.349000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-09-01 17:48:11.349013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-09-01 17:48:11.349021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-09-01 17:48:11.349370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu_V2/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:06,  6.45it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.67it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:05,  7.29it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:03,  9.35it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03, 10.16it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:03,  8.67it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 11.13it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 11.51it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  9.27it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:01<00:01, 11.45it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 11.74it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.98it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  9.47it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 11.72it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:02<00:00, 11.56it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.86it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.37it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.98it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 192,693
Non-trainable params: 696,560
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.21980040e-02 3.13727330e-02 7.85159578e-02 9.56315856e-03
 2.84953074e-02 7.21199551e-03 8.69748044e-02 1.15060844e-01
 8.98551690e-02 1.30325197e-02 2.93358922e-01 1.84100806e-01
 2.59778565e-04]
Train on 9366 samples, validate on 192 samples
Epoch 1/300
 - 18s - loss: 1.7524 - acc: 0.7771 - mDice: 0.2573 - val_loss: 1.6265 - val_acc: 0.9132 - val_mDice: 0.3494

Epoch 00001: val_mDice improved from -inf to 0.34944, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.7042 - acc: 0.9107 - mDice: 0.4840 - val_loss: 1.1719 - val_acc: 0.9178 - val_mDice: 0.4407

Epoch 00002: val_mDice improved from 0.34944 to 0.44074, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5553 - acc: 0.9235 - mDice: 0.5617 - val_loss: 0.8411 - val_acc: 0.9313 - val_mDice: 0.5028

Epoch 00003: val_mDice improved from 0.44074 to 0.50285, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.4976 - acc: 0.9292 - mDice: 0.5951 - val_loss: 0.6770 - val_acc: 0.9365 - val_mDice: 0.5438

Epoch 00004: val_mDice improved from 0.50285 to 0.54382, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.4481 - acc: 0.9333 - mDice: 0.6247 - val_loss: 0.6715 - val_acc: 0.9391 - val_mDice: 0.5360

Epoch 00005: val_mDice did not improve from 0.54382
Epoch 6/300
 - 13s - loss: 0.4222 - acc: 0.9357 - mDice: 0.6413 - val_loss: 0.8096 - val_acc: 0.9355 - val_mDice: 0.5333

Epoch 00006: val_mDice did not improve from 0.54382
Epoch 7/300
 - 13s - loss: 0.4450 - acc: 0.9344 - mDice: 0.6307 - val_loss: 0.7921 - val_acc: 0.9335 - val_mDice: 0.5185

Epoch 00007: val_mDice did not improve from 0.54382
Epoch 8/300
 - 13s - loss: 0.4062 - acc: 0.9372 - mDice: 0.6525 - val_loss: 0.7208 - val_acc: 0.9377 - val_mDice: 0.5591

Epoch 00008: val_mDice improved from 0.54382 to 0.55912, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.3916 - acc: 0.9390 - mDice: 0.6659 - val_loss: 0.7261 - val_acc: 0.9390 - val_mDice: 0.5640

Epoch 00009: val_mDice improved from 0.55912 to 0.56396, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.3707 - acc: 0.9403 - mDice: 0.6762 - val_loss: 0.6055 - val_acc: 0.9418 - val_mDice: 0.5736

Epoch 00010: val_mDice improved from 0.56396 to 0.57359, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3599 - acc: 0.9413 - mDice: 0.6839 - val_loss: 0.6863 - val_acc: 0.9420 - val_mDice: 0.5611

Epoch 00011: val_mDice did not improve from 0.57359
Epoch 12/300
 - 13s - loss: 0.3531 - acc: 0.9420 - mDice: 0.6891 - val_loss: 0.6752 - val_acc: 0.9380 - val_mDice: 0.5704

Epoch 00012: val_mDice did not improve from 0.57359
Epoch 13/300
 - 13s - loss: 0.3513 - acc: 0.9421 - mDice: 0.6901 - val_loss: 0.8414 - val_acc: 0.9390 - val_mDice: 0.5542

Epoch 00013: val_mDice did not improve from 0.57359
Epoch 14/300
 - 13s - loss: 0.3351 - acc: 0.9434 - mDice: 0.7015 - val_loss: 0.7179 - val_acc: 0.9359 - val_mDice: 0.5467

Epoch 00014: val_mDice did not improve from 0.57359
Epoch 15/300
 - 13s - loss: 0.3306 - acc: 0.9439 - mDice: 0.7049 - val_loss: 0.8750 - val_acc: 0.9357 - val_mDice: 0.5765

Epoch 00015: val_mDice improved from 0.57359 to 0.57651, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 13s - loss: 0.3252 - acc: 0.9443 - mDice: 0.7089 - val_loss: 0.6186 - val_acc: 0.9419 - val_mDice: 0.5810

Epoch 00016: val_mDice improved from 0.57651 to 0.58098, saving model to /array/ssd/msmajdi/experiments/keras/exp6_BC_CSFn/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_CSFn2_TL_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.3157 - acc: 0.9451 - mDice: 0.7168 - val_loss: 1.0841 - val_acc: 0.9393 - val_mDice: 0.5108

Epoch 00017: val_mDice did not improve from 0.58098
Epoch 18/300
 - 13s - loss: 0.3668 - acc: 0.9409 - mDice: 0.6805 - val_loss: 1.4015 - val_acc: 0.9364 - val_mDice: 0.5205

Epoch 00018: val_mDice did not improve from 0.58098
Epoch 19/300
 - 13s - loss: 0.3188 - acc: 0.9447 - mDice: 0.7136 - val_loss: 1.0293 - val_acc: 0.9402 - val_mDice: 0.5586

Epoch 00019: val_mDice did not improve from 0.58098
Epoch 20/300
 - 13s - loss: 0.3075 - acc: 0.9457 - mDice: 0.7229 - val_loss: 0.8005 - val_acc: 0.9410 - val_mDice: 0.5538

Epoch 00020: val_mDice did not improve from 0.58098
Epoch 21/300
 - 14s - loss: 0.3016 - acc: 0.9462 - mDice: 0.7264 - val_loss: 0.6834 - val_acc: 0.9432 - val_mDice: 0.5369

Epoch 00021: val_mDice did not improve from 0.58098
Epoch 22/300
 - 14s - loss: 0.3083 - acc: 0.9465 - mDice: 0.7262 - val_loss: 1.0440 - val_acc: 0.9391 - val_mDice: 0.5610

Epoch 00022: val_mDice did not improve from 0.58098
Epoch 23/300
 - 13s - loss: 0.2940 - acc: 0.9470 - mDice: 0.7331 - val_loss: 0.9095 - val_acc: 0.9391 - val_mDice: 0.5494

Epoch 00023: val_mDice did not improve from 0.58098
Epoch 24/300
 - 13s - loss: 0.3040 - acc: 0.9460 - mDice: 0.7247 - val_loss: 0.9870 - val_acc: 0.9389 - val_mDice: 0.5327

Epoch 00024: val_mDice did not improve from 0.58098
Epoch 25/300
 - 14s - loss: 0.2860 - acc: 0.9475 - mDice: 0.7380 - val_loss: 0.9733 - val_acc: 0.9372 - val_mDice: 0.5595

Epoch 00025: val_mDice did not improve from 0.58098
Epoch 26/300
 - 13s - loss: 0.2827 - acc: 0.9479 - mDice: 0.7409 - val_loss: 0.9784 - val_acc: 0.9430 - val_mDice: 0.5546

Epoch 00026: val_mDice did not improve from 0.58098
Epoch 27/300
 - 13s - loss: 0.2795 - acc: 0.9481 - mDice: 0.7431 - val_loss: 0.6729 - val_acc: 0.9437 - val_mDice: 0.5754

Epoch 00027: val_mDice did not improve from 0.58098
Epoch 28/300
 - 13s - loss: 0.2755 - acc: 0.9483 - mDice: 0.7462 - val_loss: 0.8204 - val_acc: 0.9427 - val_mDice: 0.5614

Epoch 00028: val_mDice did not improve from 0.58098
Epoch 29/300
 - 13s - loss: 0.3389 - acc: 0.9434 - mDice: 0.7022 - val_loss: 1.2413 - val_acc: 0.9310 - val_mDice: 0.4864

Epoch 00029: val_mDice did not improve from 0.58098
Epoch 30/300
 - 14s - loss: 0.3027 - acc: 0.9461 - mDice: 0.7255 - val_loss: 1.8315 - val_acc: 0.9363 - val_mDice: 0.5109

Epoch 00030: val_mDice did not improve from 0.58098
Epoch 31/300
 - 13s - loss: 0.2867 - acc: 0.9476 - mDice: 0.7387 - val_loss: 1.0833 - val_acc: 0.9399 - val_mDice: 0.5275

Epoch 00031: val_mDice did not improve from 0.58098
Epoch 32/300
 - 13s - loss: 0.2798 - acc: 0.9480 - mDice: 0.7429 - val_loss: 1.0248 - val_acc: 0.9415 - val_mDice: 0.5596

Epoch 00032: val_mDice did not improve from 0.58098
Epoch 33/300
 - 13s - loss: 0.2745 - acc: 0.9485 - mDice: 0.7471 - val_loss: 0.9389 - val_acc: 0.9414 - val_mDice: 0.5589

Epoch 00033: val_mDice did not improve from 0.58098
Epoch 34/300
 - 13s - loss: 0.2684 - acc: 0.9489 - mDice: 0.7516 - val_loss: 1.0794 - val_acc: 0.9418 - val_mDice: 0.5519

Epoch 00034: val_mDice did not improve from 0.58098
Epoch 35/300
 - 13s - loss: 0.2650 - acc: 0.9492 - mDice: 0.7543 - val_loss: 1.0494 - val_acc: 0.9409 - val_mDice: 0.5452

Epoch 00035: val_mDice did not improve from 0.58098
Epoch 36/300
 - 14s - loss: 0.2696 - acc: 0.9491 - mDice: 0.7517 - val_loss: 1.4294 - val_acc: 0.9402 - val_mDice: 0.5355

Epoch 00036: val_mDice did not improve from 0.58098
Epoch 37/300
 - 13s - loss: 0.2627 - acc: 0.9495 - mDice: 0.7561 - val_loss: 1.0462 - val_acc: 0.9396 - val_mDice: 0.5374

Epoch 00037: val_mDice did not improve from 0.58098
Epoch 38/300
 - 13s - loss: 0.2569 - acc: 0.9500 - mDice: 0.7607 - val_loss: 1.1429 - val_acc: 0.9397 - val_mDice: 0.5460

Epoch 00038: val_mDice did not improve from 0.58098
Epoch 39/300
 - 13s - loss: 0.2725 - acc: 0.9490 - mDice: 0.7520 - val_loss: 1.0168 - val_acc: 0.9381 - val_mDice: 0.5401

Epoch 00039: val_mDice did not improve from 0.58098
Epoch 40/300
 - 13s - loss: 0.2557 - acc: 0.9501 - mDice: 0.7618 - val_loss: 0.7651 - val_acc: 0.9434 - val_mDice: 0.5521

Epoch 00040: val_mDice did not improve from 0.58098
Epoch 41/300
 - 13s - loss: 0.2535 - acc: 0.9502 - mDice: 0.7635 - val_loss: 0.8520 - val_acc: 0.9402 - val_mDice: 0.5536

Epoch 00041: val_mDice did not improve from 0.58098
Epoch 42/300
 - 13s - loss: 0.2515 - acc: 0.9506 - mDice: 0.7666 - val_loss: 0.6573 - val_acc: 0.9435 - val_mDice: 0.5624

Epoch 00042: val_mDice did not improve from 0.58098
Epoch 43/300
 - 14s - loss: 0.2785 - acc: 0.9482 - mDice: 0.7442 - val_loss: 1.2260 - val_acc: 0.9387 - val_mDice: 0.5222

Epoch 00043: val_mDice did not improve from 0.58098
Epoch 44/300
 - 13s - loss: 0.2533 - acc: 0.9502 - mDice: 0.7637 - val_loss: 0.6772 - val_acc: 0.9429 - val_mDice: 0.5736

Epoch 00044: val_mDice did not improve from 0.58098
Epoch 45/300
 - 13s - loss: 0.2490 - acc: 0.9506 - mDice: 0.7670 - val_loss: 1.1340 - val_acc: 0.9384 - val_mDice: 0.5397

Epoch 00045: val_mDice did not improve from 0.58098
Epoch 46/300
 - 13s - loss: 0.2456 - acc: 0.9509 - mDice: 0.7698 - val_loss: 0.8681 - val_acc: 0.9413 - val_mDice: 0.5610

Epoch 00046: val_mDice did not improve from 0.58098
Epoch 47/300
 - 13s - loss: 0.2544 - acc: 0.9508 - mDice: 0.7677 - val_loss: 0.9486 - val_acc: 0.9412 - val_mDice: 0.5650

Epoch 00047: val_mDice did not improve from 0.58098
Epoch 48/300
 - 13s - loss: 0.2470 - acc: 0.9510 - mDice: 0.7701 - val_loss: 1.0786 - val_acc: 0.9265 - val_mDice: 0.5005

Epoch 00048: val_mDice did not improve from 0.58098
Epoch 49/300
 - 13s - loss: 0.2556 - acc: 0.9504 - mDice: 0.7639 - val_loss: 0.9066 - val_acc: 0.9381 - val_mDice: 0.5277

Epoch 00049: val_mDice did not improve from 0.58098
Epoch 50/300
 - 14s - loss: 0.2445 - acc: 0.9508 - mDice: 0.7707 - val_loss: 1.5969 - val_acc: 0.9336 - val_mDice: 0.5083

Epoch 00050: val_mDice did not improve from 0.58098
Epoch 51/300
 - 13s - loss: 0.2392 - acc: 0.9514 - mDice: 0.7750 - val_loss: 0.8791 - val_acc: 0.9399 - val_mDice: 0.5559

Epoch 00051: val_mDice did not improve from 0.58098
Epoch 52/300
 - 13s - loss: 0.2373 - acc: 0.9516 - mDice: 0.7766 - val_loss: 1.2318 - val_acc: 0.9404 - val_mDice: 0.5404

Epoch 00052: val_mDice did not improve from 0.58098
Epoch 53/300
 - 13s - loss: 0.2374 - acc: 0.9517 - mDice: 0.7783 - val_loss: 1.6823 - val_acc: 0.9366 - val_mDice: 0.5035

Epoch 00053: val_mDice did not improve from 0.58098
Epoch 54/300
 - 13s - loss: 0.2463 - acc: 0.9511 - mDice: 0.7729 - val_loss: 1.4254 - val_acc: 0.9326 - val_mDice: 0.5246

Epoch 00054: val_mDice did not improve from 0.58098
Epoch 55/300
 - 13s - loss: 0.2352 - acc: 0.9519 - mDice: 0.7783 - val_loss: 1.1483 - val_acc: 0.9318 - val_mDice: 0.4953

Epoch 00055: val_mDice did not improve from 0.58098
Epoch 56/300
 - 13s - loss: 0.2370 - acc: 0.9516 - mDice: 0.7769 - val_loss: 0.7809 - val_acc: 0.9417 - val_mDice: 0.5447

Epoch 00056: val_mDice did not improve from 0.58098
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [1.6264582468817632, 1.171879302089413, 0.8410693525026242, 0.6769742605586847, 0.6715368100752434, 0.8096464167659482, 0.7920913873240352, 0.7208374344433347, 0.7260617380961776, 0.6054693947856625, 0.6862777266651392, 0.675196268906196, 0.8414077926427126, 0.7178803610925873, 0.8750196869174639, 0.6186116170138121, 1.0840609936664503, 1.4015167771528165, 1.0293100991596777, 0.8005477264523506, 0.6834357843423883, 1.043955398723483, 0.9095135976870855, 0.9869781862944365, 0.9733067375297347, 0.9784350314488014, 0.6729443228493134, 0.8204127935071787, 1.2413381648560364, 1.831468574392299, 1.0833086914693315, 1.024774747590224, 0.9389210923885306, 1.0794092938303947, 1.0494410938893755, 1.4294373970478773, 1.0461793849244714, 1.1429465391362708, 1.0167544359962146, 0.765137594503661, 0.8520461472993096, 0.6572985872626305, 1.2260209095353882, 0.677182054768006, 1.1340009082729618, 0.8680828362703323, 0.9485937270025412, 1.0786300009737413, 0.9066013355428973, 1.59690296339492, 0.8790883958960573, 1.2318016542121768, 1.6822600072870653, 1.425399807592233, 1.1482825689017773, 0.7808557962998748], 'val_acc': [0.9132280113796393, 0.9177594830592474, 0.9312789452572664, 0.936514395599564, 0.9391056491682926, 0.935470669840773, 0.9334710283825794, 0.9377092501769463, 0.9389570914208889, 0.9418376907706261, 0.9420056243737539, 0.9380037871499857, 0.9390216867129008, 0.9358723989377419, 0.9357354765137037, 0.9418971252938112, 0.9392890532811483, 0.936372290054957, 0.9401635794589916, 0.94102258545657, 0.9432224420209726, 0.9390591289848089, 0.9390604191770157, 0.9389157555997372, 0.9371861157317957, 0.9429796033849319, 0.9437107238918543, 0.9426954258233309, 0.9309689098348221, 0.9363438859581947, 0.9399000704288483, 0.9415005501359701, 0.9413907391329607, 0.9418015281359354, 0.9409050401300192, 0.9401971815774838, 0.9395822969575723, 0.9396778965989748, 0.9380877409130335, 0.9434433281421661, 0.9401932942370573, 0.943453668927153, 0.9386767850567898, 0.9429356840749582, 0.9383719426890215, 0.9413365013897419, 0.9412409079571565, 0.926471047103405, 0.9381342542668184, 0.9335511084645987, 0.9399478708704313, 0.940380617355307, 0.9366086963564157, 0.9326404388993979, 0.9318472960342964, 0.9416568651795387], 'val_mDice': [0.3494350469360749, 0.4407423590309918, 0.5028461371548474, 0.5438239413003126, 0.5359951943779985, 0.533274122669051, 0.5184716451913118, 0.5591239230707288, 0.5639625818779072, 0.5735919795309504, 0.5611260626465082, 0.5704061184078455, 0.554169079909722, 0.5466612738867601, 0.5765103579809269, 0.5809780607620875, 0.5107915134479603, 0.5205255284284552, 0.5586163718253374, 0.5538424172749122, 0.5368544366210699, 0.5610252013429999, 0.549413496007522, 0.53268136177212, 0.559512327114741, 0.5545517634600401, 0.5753734257693092, 0.5614096404363712, 0.48640237127741176, 0.5109400050714612, 0.5274611612161001, 0.5596403939028581, 0.5589116178452969, 0.5519041926600039, 0.5452497905741135, 0.5355046050002178, 0.5373528876031438, 0.5459644344324867, 0.5400962298735976, 0.5521114493409792, 0.5536200900872549, 0.5623631874720255, 0.5222333020841082, 0.5735574817905823, 0.5397468473141392, 0.5609974392379323, 0.5650215651839972, 0.5005049405929943, 0.5276718218810856, 0.5083201918751001, 0.5558659161130587, 0.5404305624154707, 0.5035052032520374, 0.5245507773943245, 0.4953162589420875, 0.5446861966823539], 'loss': [1.7524453036911896, 0.7041898079211707, 0.5552825169343865, 0.4975984278217534, 0.4480680595560764, 0.42222600519822595, 0.4449719217580632, 0.40624437008483427, 0.3916386171472192, 0.3707463361375382, 0.3599366402552216, 0.35309308414120155, 0.3513378532694467, 0.3350838664986755, 0.3305911432085398, 0.3251720254247626, 0.3157326668316346, 0.3668439653269531, 0.3187624214106891, 0.3074623761002946, 0.30158102640274775, 0.3083217587133465, 0.2939868550791385, 0.30400402156965056, 0.2859761275569012, 0.28266910950571916, 0.2795141807624272, 0.2755266438016977, 0.3388960673250043, 0.30272558839331826, 0.2866518256560162, 0.2797930599493576, 0.27445565930625554, 0.2683608323087454, 0.2649629625046123, 0.2695657927085517, 0.2627379511242974, 0.2569013344262773, 0.27249825786072907, 0.2557240407671298, 0.2534922069873714, 0.2515047182295787, 0.27845946129012916, 0.25329378179485107, 0.24902617148601575, 0.24557742288408946, 0.25438902561300053, 0.2469572128933667, 0.25558010516272583, 0.24445590761235808, 0.2392295761550565, 0.23730167665085475, 0.23741384553153266, 0.2462568520042292, 0.23519198341601785, 0.2369552152058316], 'acc': [0.7771120059681599, 0.9106675739372844, 0.9234587145798638, 0.9292176324741316, 0.9333203261845034, 0.9356936359670257, 0.9344436274032014, 0.937209667735392, 0.9389834366826301, 0.9402700126132928, 0.9412667100154104, 0.9420104680243604, 0.9421444323209013, 0.9433533445449306, 0.943853956968795, 0.9443336243484867, 0.9451290694103774, 0.9409100734955883, 0.944739834533755, 0.9457219941428195, 0.946211112874353, 0.9464718391440654, 0.9470124919776501, 0.9460158986259214, 0.9474758482911051, 0.9478572973475964, 0.9481097348296894, 0.9483453584689756, 0.9433903903526397, 0.9460704215006164, 0.9475749897544465, 0.947962399313599, 0.9485095373310901, 0.948924936190289, 0.9492089129807779, 0.9490706051309827, 0.94945314169541, 0.9499595265039236, 0.9490208735889587, 0.9500558104826654, 0.9502208092745721, 0.9506030030645622, 0.9482298766143704, 0.9502025649075627, 0.9505744553543986, 0.9508625065035579, 0.9508180484643431, 0.9509849317838004, 0.9504412064536015, 0.9508226315944133, 0.9514155524066694, 0.9516118818716236, 0.9517437527761636, 0.951133646492568, 0.9518637348769085, 0.9516097612801511], 'mDice': [0.25725730593405155, 0.48401304682986795, 0.5617298259837948, 0.5950968289589134, 0.6246506503802854, 0.6412804490884043, 0.6307139012285616, 0.6524630425425898, 0.6658883409420701, 0.6762012976778385, 0.6838556473234284, 0.6890513005990797, 0.6900739563903874, 0.7014682672356225, 0.7049293205597043, 0.7089319354750115, 0.7168290457765236, 0.6805273887949725, 0.7135953313643011, 0.7228505399755094, 0.7263514271995183, 0.7262153711274167, 0.7331085409233261, 0.7246873164034389, 0.7380497119835546, 0.7408844210794535, 0.7430893614102245, 0.7461769256662055, 0.7022196667942256, 0.7255271734932714, 0.7386808296235585, 0.742886888084823, 0.7470956754409526, 0.751639826173536, 0.7543495389199935, 0.7517361637111812, 0.756089079705869, 0.7607401312861258, 0.7520115743863539, 0.7618188900288776, 0.7635449897828022, 0.7666446105068931, 0.7442143886180457, 0.7636963877442706, 0.7670143026331157, 0.7697837056702282, 0.7676574590240257, 0.7701266056168112, 0.7638565622001231, 0.770655619049337, 0.7749636119027538, 0.7765546494407988, 0.7783316845902005, 0.7729478110850634, 0.7782958040450236, 0.7769151557441352]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:12,  3.13s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.96s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.71s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.48s/it]predicting test subjects: 100%|██████████| 5/5 [00:12<00:00,  2.57s/it]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:02<08:52,  2.17s/it]predicting train subjects:   1%|          | 2/247 [00:04<08:28,  2.08s/it]predicting train subjects:   1%|          | 3/247 [00:05<08:10,  2.01s/it]predicting train subjects:   2%|▏         | 4/247 [00:08<08:26,  2.08s/it]predicting train subjects:   2%|▏         | 5/247 [00:10<08:08,  2.02s/it]predicting train subjects:   2%|▏         | 6/247 [00:12<08:20,  2.08s/it]predicting train subjects:   3%|▎         | 7/247 [00:14<08:00,  2.00s/it]predicting train subjects:   3%|▎         | 8/247 [00:16<08:19,  2.09s/it]predicting train subjects:   4%|▎         | 9/247 [00:18<08:28,  2.14s/it]predicting train subjects:   4%|▍         | 10/247 [00:20<08:02,  2.03s/it]predicting train subjects:   4%|▍         | 11/247 [00:22<08:06,  2.06s/it]predicting train subjects:   5%|▍         | 12/247 [00:24<07:49,  2.00s/it]predicting train subjects:   5%|▌         | 13/247 [00:26<07:41,  1.97s/it]predicting train subjects:   6%|▌         | 14/247 [00:28<07:51,  2.02s/it]predicting train subjects:   6%|▌         | 15/247 [00:30<07:39,  1.98s/it]predicting train subjects:   6%|▋         | 16/247 [00:32<07:56,  2.06s/it]predicting train subjects:   7%|▋         | 17/247 [00:34<08:04,  2.11s/it]predicting train subjects:   7%|▋         | 18/247 [00:36<08:09,  2.14s/it]predicting train subjects:   8%|▊         | 19/247 [00:39<08:05,  2.13s/it]predicting train subjects:   8%|▊         | 20/247 [00:40<07:44,  2.05s/it]predicting train subjects:   9%|▊         | 21/247 [00:43<07:51,  2.08s/it]predicting train subjects:   9%|▉         | 22/247 [00:44<07:32,  2.01s/it]predicting train subjects:   9%|▉         | 23/247 [00:46<07:19,  1.96s/it]predicting train subjects:  10%|▉         | 24/247 [00:49<07:34,  2.04s/it]predicting train subjects:  10%|█         | 25/247 [00:51<07:49,  2.11s/it]predicting train subjects:  11%|█         | 26/247 [00:53<07:30,  2.04s/it]predicting train subjects:  11%|█         | 27/247 [00:54<07:13,  1.97s/it]predicting train subjects:  11%|█▏        | 28/247 [00:56<07:03,  1.93s/it]predicting train subjects:  12%|█▏        | 29/247 [00:59<07:21,  2.03s/it]predicting train subjects:  12%|█▏        | 30/247 [01:01<07:34,  2.09s/it]predicting train subjects:  13%|█▎        | 31/247 [01:03<07:13,  2.01s/it]predicting train subjects:  13%|█▎        | 32/247 [01:05<07:16,  2.03s/it]predicting train subjects:  13%|█▎        | 33/247 [01:07<07:02,  1.97s/it]predicting train subjects:  14%|█▍        | 34/247 [01:08<06:51,  1.93s/it]predicting train subjects:  14%|█▍        | 35/247 [01:11<07:09,  2.03s/it]predicting train subjects:  15%|█▍        | 36/247 [01:13<07:14,  2.06s/it]predicting train subjects:  15%|█▍        | 37/247 [01:15<06:58,  1.99s/it]predicting train subjects:  15%|█▌        | 38/247 [01:17<07:06,  2.04s/it]predicting train subjects:  16%|█▌        | 39/247 [01:19<06:54,  1.99s/it]predicting train subjects:  16%|█▌        | 40/247 [01:20<06:44,  1.95s/it]predicting train subjects:  17%|█▋        | 41/247 [01:23<07:00,  2.04s/it]predicting train subjects:  17%|█▋        | 42/247 [01:25<07:03,  2.07s/it]predicting train subjects:  17%|█▋        | 43/247 [01:27<07:10,  2.11s/it]predicting train subjects:  18%|█▊        | 44/247 [01:29<06:53,  2.04s/it]predicting train subjects:  18%|█▊        | 45/247 [01:31<06:37,  1.97s/it]predicting train subjects:  19%|█▊        | 46/247 [01:33<06:44,  2.01s/it]predicting train subjects:  19%|█▉        | 47/247 [01:35<06:31,  1.96s/it]predicting train subjects:  19%|█▉        | 48/247 [01:37<06:45,  2.04s/it]predicting train subjects:  20%|█▉        | 49/247 [01:39<06:32,  1.98s/it]predicting train subjects:  20%|██        | 50/247 [01:41<06:49,  2.08s/it]predicting train subjects:  21%|██        | 51/247 [01:43<06:34,  2.01s/it]predicting train subjects:  21%|██        | 52/247 [01:45<06:39,  2.05s/it]predicting train subjects:  21%|██▏       | 53/247 [01:47<06:24,  1.98s/it]predicting train subjects:  22%|██▏       | 54/247 [01:49<06:14,  1.94s/it]predicting train subjects:  22%|██▏       | 55/247 [01:51<06:39,  2.08s/it]predicting train subjects:  23%|██▎       | 56/247 [01:53<06:21,  2.00s/it]predicting train subjects:  23%|██▎       | 57/247 [01:55<06:28,  2.04s/it]predicting train subjects:  23%|██▎       | 58/247 [01:57<06:37,  2.11s/it]predicting train subjects:  24%|██▍       | 59/247 [01:59<06:18,  2.01s/it]predicting train subjects:  24%|██▍       | 60/247 [02:01<06:06,  1.96s/it]predicting train subjects:  25%|██▍       | 61/247 [02:03<06:19,  2.04s/it]predicting train subjects:  25%|██▌       | 62/247 [02:05<06:03,  1.96s/it]predicting train subjects:  26%|██▌       | 63/247 [02:07<06:06,  1.99s/it]predicting train subjects:  26%|██▌       | 64/247 [02:09<05:55,  1.94s/it]predicting train subjects:  26%|██▋       | 65/247 [02:11<05:42,  1.88s/it]predicting train subjects:  27%|██▋       | 66/247 [02:13<05:57,  1.97s/it]predicting train subjects:  27%|██▋       | 67/247 [02:15<06:11,  2.06s/it]predicting train subjects:  28%|██▊       | 68/247 [02:17<06:14,  2.09s/it]predicting train subjects:  28%|██▊       | 69/247 [02:20<06:21,  2.15s/it]predicting train subjects:  28%|██▊       | 70/247 [02:21<06:01,  2.04s/it]predicting train subjects:  29%|██▊       | 71/247 [02:23<06:00,  2.05s/it]predicting train subjects:  29%|██▉       | 72/247 [02:25<05:53,  2.02s/it]predicting train subjects:  30%|██▉       | 73/247 [02:27<05:40,  1.95s/it]predicting train subjects:  30%|██▉       | 74/247 [02:29<05:32,  1.92s/it]predicting train subjects:  30%|███       | 75/247 [02:31<05:46,  2.02s/it]predicting train subjects:  31%|███       | 76/247 [02:33<05:35,  1.96s/it]predicting train subjects:  31%|███       | 77/247 [02:35<05:26,  1.92s/it]predicting train subjects:  32%|███▏      | 78/247 [02:37<05:33,  1.98s/it]predicting train subjects:  32%|███▏      | 79/247 [02:39<05:33,  1.99s/it]predicting train subjects:  32%|███▏      | 80/247 [02:41<05:56,  2.14s/it]predicting train subjects:  33%|███▎      | 81/247 [02:44<06:07,  2.22s/it]predicting train subjects:  33%|███▎      | 82/247 [02:46<06:18,  2.29s/it]predicting train subjects:  34%|███▎      | 83/247 [02:48<05:53,  2.15s/it]predicting train subjects:  34%|███▍      | 84/247 [02:50<05:51,  2.16s/it]predicting train subjects:  34%|███▍      | 85/247 [02:53<06:09,  2.28s/it]predicting train subjects:  35%|███▍      | 86/247 [02:55<05:53,  2.19s/it]predicting train subjects:  35%|███▌      | 87/247 [02:57<06:04,  2.28s/it]predicting train subjects:  36%|███▌      | 88/247 [03:00<06:10,  2.33s/it]predicting train subjects:  36%|███▌      | 89/247 [03:02<05:42,  2.17s/it]predicting train subjects:  36%|███▋      | 90/247 [03:04<05:38,  2.16s/it]predicting train subjects:  37%|███▋      | 91/247 [03:06<05:46,  2.22s/it]predicting train subjects:  37%|███▋      | 92/247 [03:08<05:49,  2.26s/it]predicting train subjects:  38%|███▊      | 93/247 [03:11<05:57,  2.32s/it]predicting train subjects:  38%|███▊      | 94/247 [03:13<06:01,  2.36s/it]predicting train subjects:  38%|███▊      | 95/247 [03:15<05:44,  2.26s/it]predicting train subjects:  39%|███▉      | 96/247 [03:17<05:19,  2.12s/it]predicting train subjects:  39%|███▉      | 97/247 [03:19<05:19,  2.13s/it]predicting train subjects:  40%|███▉      | 98/247 [03:21<05:17,  2.13s/it]predicting train subjects:  40%|████      | 99/247 [03:24<05:27,  2.21s/it]predicting train subjects:  40%|████      | 100/247 [03:26<05:32,  2.26s/it]predicting train subjects:  41%|████      | 101/247 [03:28<05:24,  2.22s/it]predicting train subjects:  41%|████▏     | 102/247 [03:30<05:12,  2.15s/it]predicting train subjects:  42%|████▏     | 103/247 [03:32<04:53,  2.04s/it]predicting train subjects:  42%|████▏     | 104/247 [03:35<05:07,  2.15s/it]predicting train subjects:  43%|████▎     | 105/247 [03:37<04:59,  2.11s/it]predicting train subjects:  43%|████▎     | 106/247 [03:38<04:42,  2.00s/it]predicting train subjects:  43%|████▎     | 107/247 [03:40<04:46,  2.05s/it]predicting train subjects:  44%|████▎     | 108/247 [03:43<04:49,  2.08s/it]predicting train subjects:  44%|████▍     | 109/247 [03:45<05:12,  2.26s/it]predicting train subjects:  45%|████▍     | 110/247 [03:47<04:59,  2.19s/it]predicting train subjects:  45%|████▍     | 111/247 [03:50<05:14,  2.31s/it]predicting train subjects:  45%|████▌     | 112/247 [03:52<04:50,  2.16s/it]predicting train subjects:  46%|████▌     | 113/247 [03:54<05:02,  2.26s/it]predicting train subjects:  46%|████▌     | 114/247 [03:56<04:50,  2.18s/it]predicting train subjects:  47%|████▋     | 115/247 [03:58<04:29,  2.04s/it]predicting train subjects:  47%|████▋     | 116/247 [04:00<04:30,  2.06s/it]predicting train subjects:  47%|████▋     | 117/247 [04:02<04:41,  2.17s/it]predicting train subjects:  48%|████▊     | 118/247 [04:05<04:34,  2.13s/it]predicting train subjects:  48%|████▊     | 119/247 [04:07<04:43,  2.21s/it]predicting train subjects:  49%|████▊     | 120/247 [04:09<04:22,  2.07s/it]predicting train subjects:  49%|████▉     | 121/247 [04:11<04:20,  2.07s/it]predicting train subjects:  49%|████▉     | 122/247 [04:13<04:31,  2.17s/it]predicting train subjects:  50%|████▉     | 123/247 [04:15<04:11,  2.03s/it]predicting train subjects:  50%|█████     | 124/247 [04:17<04:12,  2.05s/it]predicting train subjects:  51%|█████     | 125/247 [04:19<04:25,  2.18s/it]predicting train subjects:  51%|█████     | 126/247 [04:22<04:32,  2.25s/it]predicting train subjects:  51%|█████▏    | 127/247 [04:24<04:19,  2.16s/it]predicting train subjects:  52%|█████▏    | 128/247 [04:25<04:01,  2.03s/it]predicting train subjects:  52%|█████▏    | 129/247 [04:28<04:11,  2.13s/it]predicting train subjects:  53%|█████▎    | 130/247 [04:30<04:03,  2.08s/it]predicting train subjects:  53%|█████▎    | 131/247 [04:32<03:49,  1.97s/it]predicting train subjects:  53%|█████▎    | 132/247 [04:34<04:02,  2.11s/it]predicting train subjects:  54%|█████▍    | 133/247 [04:36<04:13,  2.22s/it]predicting train subjects:  54%|█████▍    | 134/247 [04:39<04:14,  2.26s/it]predicting train subjects:  55%|█████▍    | 135/247 [04:41<04:02,  2.16s/it]predicting train subjects:  55%|█████▌    | 136/247 [04:43<04:07,  2.23s/it]predicting train subjects:  55%|█████▌    | 137/247 [04:45<03:46,  2.06s/it]predicting train subjects:  56%|█████▌    | 138/247 [04:47<03:47,  2.08s/it]predicting train subjects:  56%|█████▋    | 139/247 [04:49<03:56,  2.19s/it]predicting train subjects:  57%|█████▋    | 140/247 [04:51<03:46,  2.11s/it]predicting train subjects:  57%|█████▋    | 141/247 [04:53<03:37,  2.05s/it]predicting train subjects:  57%|█████▋    | 142/247 [04:56<03:54,  2.23s/it]predicting train subjects:  58%|█████▊    | 143/247 [04:58<03:54,  2.26s/it]predicting train subjects:  58%|█████▊    | 144/247 [05:00<03:44,  2.18s/it]predicting train subjects:  59%|█████▊    | 145/247 [05:03<03:50,  2.26s/it]predicting train subjects:  59%|█████▉    | 146/247 [05:05<03:39,  2.18s/it]predicting train subjects:  60%|█████▉    | 147/247 [05:06<03:23,  2.04s/it]predicting train subjects:  60%|█████▉    | 148/247 [05:08<03:25,  2.07s/it]predicting train subjects:  60%|██████    | 149/247 [05:11<03:31,  2.16s/it]predicting train subjects:  61%|██████    | 150/247 [05:13<03:24,  2.11s/it]predicting train subjects:  61%|██████    | 151/247 [05:15<03:11,  2.00s/it]predicting train subjects:  62%|██████▏   | 152/247 [05:17<03:12,  2.03s/it]predicting train subjects:  62%|██████▏   | 153/247 [05:19<03:18,  2.11s/it]predicting train subjects:  62%|██████▏   | 154/247 [05:21<03:24,  2.20s/it]predicting train subjects:  63%|██████▎   | 155/247 [05:23<03:17,  2.15s/it]predicting train subjects:  63%|██████▎   | 156/247 [05:25<03:04,  2.03s/it]predicting train subjects:  64%|██████▎   | 157/247 [05:27<03:06,  2.07s/it]predicting train subjects:  64%|██████▍   | 158/247 [05:30<03:11,  2.15s/it]predicting train subjects:  64%|██████▍   | 159/247 [05:32<03:01,  2.06s/it]predicting train subjects:  65%|██████▍   | 160/247 [05:34<03:08,  2.17s/it]predicting train subjects:  65%|██████▌   | 161/247 [05:36<03:11,  2.23s/it]predicting train subjects:  66%|██████▌   | 162/247 [05:39<03:12,  2.27s/it]predicting train subjects:  66%|██████▌   | 163/247 [05:41<03:14,  2.31s/it]predicting train subjects:  66%|██████▋   | 164/247 [05:43<03:06,  2.25s/it]predicting train subjects:  67%|██████▋   | 165/247 [05:45<02:52,  2.11s/it]predicting train subjects:  67%|██████▋   | 166/247 [05:47<02:52,  2.13s/it]predicting train subjects:  68%|██████▊   | 167/247 [05:49<02:49,  2.12s/it]predicting train subjects:  68%|██████▊   | 168/247 [05:52<02:55,  2.22s/it]predicting train subjects:  68%|██████▊   | 169/247 [05:54<02:47,  2.14s/it]predicting train subjects:  69%|██████▉   | 170/247 [05:56<02:44,  2.14s/it]predicting train subjects:  69%|██████▉   | 171/247 [05:58<02:39,  2.10s/it]predicting train subjects:  70%|██████▉   | 172/247 [06:00<02:37,  2.10s/it]predicting train subjects:  70%|███████   | 173/247 [06:02<02:30,  2.04s/it]predicting train subjects:  70%|███████   | 174/247 [06:04<02:24,  1.99s/it]predicting train subjects:  71%|███████   | 175/247 [06:06<02:33,  2.13s/it]predicting train subjects:  71%|███████▏  | 176/247 [06:08<02:32,  2.15s/it]predicting train subjects:  72%|███████▏  | 177/247 [06:10<02:24,  2.07s/it]predicting train subjects:  72%|███████▏  | 178/247 [06:12<02:19,  2.02s/it]predicting train subjects:  72%|███████▏  | 179/247 [06:14<02:14,  1.98s/it]predicting train subjects:  73%|███████▎  | 180/247 [06:16<02:22,  2.13s/it]predicting train subjects:  73%|███████▎  | 181/247 [06:19<02:24,  2.19s/it]predicting train subjects:  74%|███████▎  | 182/247 [06:21<02:20,  2.17s/it]predicting train subjects:  74%|███████▍  | 183/247 [06:23<02:12,  2.07s/it]predicting train subjects:  74%|███████▍  | 184/247 [06:25<02:08,  2.03s/it]predicting train subjects:  75%|███████▍  | 185/247 [06:27<02:03,  1.99s/it]predicting train subjects:  75%|███████▌  | 186/247 [06:29<02:09,  2.13s/it]predicting train subjects:  76%|███████▌  | 187/247 [06:31<02:12,  2.20s/it]predicting train subjects:  76%|███████▌  | 188/247 [06:34<02:08,  2.18s/it]predicting train subjects:  77%|███████▋  | 189/247 [06:35<02:00,  2.07s/it]predicting train subjects:  77%|███████▋  | 190/247 [06:37<01:54,  2.00s/it]predicting train subjects:  77%|███████▋  | 191/247 [06:39<01:50,  1.97s/it]predicting train subjects:  78%|███████▊  | 192/247 [06:41<01:46,  1.93s/it]predicting train subjects:  78%|███████▊  | 193/247 [06:43<01:52,  2.08s/it]predicting train subjects:  79%|███████▊  | 194/247 [06:46<01:54,  2.17s/it]predicting train subjects:  79%|███████▉  | 195/247 [06:48<01:51,  2.14s/it]predicting train subjects:  79%|███████▉  | 196/247 [06:50<01:44,  2.05s/it]predicting train subjects:  80%|███████▉  | 197/247 [06:52<01:41,  2.04s/it]predicting train subjects:  80%|████████  | 198/247 [06:54<01:40,  2.05s/it]predicting train subjects:  81%|████████  | 199/247 [06:56<01:35,  1.99s/it]predicting train subjects:  81%|████████  | 200/247 [06:57<01:31,  1.95s/it]predicting train subjects:  81%|████████▏ | 201/247 [06:59<01:27,  1.91s/it]predicting train subjects:  82%|████████▏ | 202/247 [07:02<01:32,  2.06s/it]predicting train subjects:  82%|████████▏ | 203/247 [07:04<01:34,  2.14s/it]predicting train subjects:  83%|████████▎ | 204/247 [07:06<01:30,  2.11s/it]predicting train subjects:  83%|████████▎ | 205/247 [07:08<01:25,  2.03s/it]predicting train subjects:  83%|████████▎ | 206/247 [07:10<01:23,  2.05s/it]predicting train subjects:  84%|████████▍ | 207/247 [07:12<01:19,  1.99s/it]predicting train subjects:  84%|████████▍ | 208/247 [07:14<01:23,  2.13s/it]predicting train subjects:  85%|████████▍ | 209/247 [07:17<01:23,  2.19s/it]predicting train subjects:  85%|████████▌ | 210/247 [07:19<01:19,  2.16s/it]predicting train subjects:  85%|████████▌ | 211/247 [07:21<01:14,  2.07s/it]predicting train subjects:  86%|████████▌ | 212/247 [07:22<01:09,  2.00s/it]predicting train subjects:  86%|████████▌ | 213/247 [07:24<01:08,  2.01s/it]predicting train subjects:  87%|████████▋ | 214/247 [07:26<01:04,  1.95s/it]predicting train subjects:  87%|████████▋ | 215/247 [07:28<01:01,  1.93s/it]predicting train subjects:  87%|████████▋ | 216/247 [07:30<01:03,  2.06s/it]predicting train subjects:  88%|████████▊ | 217/247 [07:33<01:04,  2.16s/it]predicting train subjects:  88%|████████▊ | 218/247 [07:35<01:01,  2.12s/it]predicting train subjects:  89%|████████▊ | 219/247 [07:37<00:56,  2.02s/it]predicting train subjects:  89%|████████▉ | 220/247 [07:39<00:55,  2.06s/it]predicting train subjects:  89%|████████▉ | 221/247 [07:41<00:51,  1.99s/it]predicting train subjects:  90%|████████▉ | 222/247 [07:43<00:52,  2.11s/it]predicting train subjects:  90%|█████████ | 223/247 [07:45<00:48,  2.03s/it]predicting train subjects:  91%|█████████ | 224/247 [07:47<00:45,  1.97s/it]predicting train subjects:  91%|█████████ | 225/247 [07:49<00:42,  1.92s/it]predicting train subjects:  91%|█████████▏| 226/247 [07:51<00:43,  2.07s/it]predicting train subjects:  92%|█████████▏| 227/247 [07:53<00:41,  2.07s/it]predicting train subjects:  92%|█████████▏| 228/247 [07:55<00:38,  2.01s/it]predicting train subjects:  93%|█████████▎| 229/247 [07:57<00:36,  2.02s/it]predicting train subjects:  93%|█████████▎| 230/247 [07:59<00:33,  1.96s/it]predicting train subjects:  94%|█████████▎| 231/247 [08:01<00:30,  1.92s/it]predicting train subjects:  94%|█████████▍| 232/247 [08:03<00:30,  2.06s/it]predicting train subjects:  94%|█████████▍| 233/247 [08:05<00:28,  2.06s/it]predicting train subjects:  95%|█████████▍| 234/247 [08:07<00:26,  2.05s/it]predicting train subjects:  95%|█████████▌| 235/247 [08:09<00:23,  1.99s/it]predicting train subjects:  96%|█████████▌| 236/247 [08:11<00:21,  1.93s/it]predicting train subjects:  96%|█████████▌| 237/247 [08:13<00:19,  1.90s/it]predicting train subjects:  96%|█████████▋| 238/247 [08:15<00:18,  2.03s/it]predicting train subjects:  97%|█████████▋| 239/247 [08:17<00:15,  1.97s/it]predicting train subjects:  97%|█████████▋| 240/247 [08:19<00:13,  1.93s/it]predicting train subjects:  98%|█████████▊| 241/247 [08:20<00:11,  1.91s/it]predicting train subjects:  98%|█████████▊| 242/247 [08:22<00:09,  1.89s/it]predicting train subjects:  98%|█████████▊| 243/247 [08:25<00:08,  2.03s/it]predicting train subjects:  99%|█████████▉| 244/247 [08:27<00:06,  2.15s/it]predicting train subjects:  99%|█████████▉| 245/247 [08:29<00:04,  2.12s/it]predicting train subjects: 100%|█████████▉| 246/247 [08:31<00:02,  2.10s/it]predicting train subjects: 100%|██████████| 247/247 [08:33<00:00,  2.05s/it]
  0%|          | 0/5 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 1837, in <module>
    # UserInfoB['CrossVal'].index      = ['a']
  File "main.py", line 1673, in EXP37_CSFn2_Cascade_TL_Res_Unet_finetune_All_folds
    smallFuncs.apply_MajorityVoting(paramFunc.Run(UserInfoB, terminal=False))
  File "/array/ssd/msmajdi/code/thalamus/keras/otherFuncs/smallFuncs.py", line 783, in apply_MajorityVoting
    VSI[cnt,:]  = [nucleiIx , metrics.VSI_AllClasses(predMV, manual.Label).VSI()]
IndexError: index 12 is out of bounds for axis 0 with size 12
