run_script_csfn_te8_lr1e3: line 2: syntax error near unexpected token `;'
run_script_csfn_te8_lr1e3: line 2: `for x in b c d; do ; python main.py -wc csfn -cv $x -lr 1e-3 -te 8 -g 3; done'
2020-01-21 17:24:55.157396: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 17:24:56.731465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:09:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 17:24:56.731533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 17:24:57.134269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 17:24:57.134341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 17:24:57.134353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 17:24:57.134797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:30,  2.71it/s]Loading train:   1%|          | 2/247 [00:00<01:20,  3.04it/s]Loading train:   1%|          | 3/247 [00:00<01:13,  3.33it/s]Loading train:   2%|▏         | 4/247 [00:01<01:09,  3.51it/s]Loading train:   2%|▏         | 5/247 [00:01<01:05,  3.72it/s]Loading train:   2%|▏         | 6/247 [00:01<01:01,  3.94it/s]Loading train:   3%|▎         | 7/247 [00:01<00:58,  4.07it/s]Loading train:   3%|▎         | 8/247 [00:01<00:57,  4.19it/s]Loading train:   4%|▎         | 9/247 [00:02<00:55,  4.31it/s]Loading train:   4%|▍         | 10/247 [00:02<00:53,  4.40it/s]Loading train:   4%|▍         | 11/247 [00:02<00:53,  4.41it/s]Loading train:   5%|▍         | 12/247 [00:02<00:52,  4.46it/s]Loading train:   5%|▌         | 13/247 [00:03<00:52,  4.47it/s]Loading train:   6%|▌         | 14/247 [00:03<00:51,  4.49it/s]Loading train:   6%|▌         | 15/247 [00:03<00:52,  4.46it/s]Loading train:   6%|▋         | 16/247 [00:03<00:51,  4.50it/s]Loading train:   7%|▋         | 17/247 [00:03<00:50,  4.52it/s]Loading train:   7%|▋         | 18/247 [00:04<00:50,  4.56it/s]Loading train:   8%|▊         | 19/247 [00:04<00:49,  4.59it/s]Loading train:   8%|▊         | 20/247 [00:04<00:49,  4.57it/s]Loading train:   9%|▊         | 21/247 [00:04<00:50,  4.51it/s]Loading train:   9%|▉         | 22/247 [00:05<00:49,  4.52it/s]Loading train:   9%|▉         | 23/247 [00:05<00:49,  4.57it/s]Loading train:  10%|▉         | 24/247 [00:05<00:48,  4.60it/s]Loading train:  10%|█         | 25/247 [00:05<00:47,  4.63it/s]Loading train:  11%|█         | 26/247 [00:05<00:47,  4.65it/s]Loading train:  11%|█         | 27/247 [00:06<00:47,  4.63it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:47,  4.65it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:46,  4.67it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:46,  4.68it/s]Loading train:  13%|█▎        | 31/247 [00:06<00:46,  4.69it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:46,  4.66it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:45,  4.68it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:45,  4.71it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:44,  4.72it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:44,  4.73it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:44,  4.73it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:44,  4.70it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:44,  4.66it/s]Loading train:  16%|█▌        | 40/247 [00:08<00:44,  4.65it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:44,  4.60it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:44,  4.62it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:43,  4.65it/s]Loading train:  18%|█▊        | 44/247 [00:09<00:43,  4.68it/s]Loading train:  18%|█▊        | 45/247 [00:09<00:43,  4.68it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:42,  4.70it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:42,  4.69it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:42,  4.66it/s]Loading train:  20%|█▉        | 49/247 [00:10<00:42,  4.69it/s]Loading train:  20%|██        | 50/247 [00:11<00:42,  4.68it/s]Loading train:  21%|██        | 51/247 [00:11<00:41,  4.68it/s]Loading train:  21%|██        | 52/247 [00:11<00:41,  4.69it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:41,  4.67it/s]Loading train:  22%|██▏       | 54/247 [00:11<00:41,  4.68it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:40,  4.68it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:40,  4.67it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:40,  4.65it/s]Loading train:  23%|██▎       | 58/247 [00:12<00:40,  4.66it/s]Loading train:  24%|██▍       | 59/247 [00:12<00:40,  4.61it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:40,  4.59it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:40,  4.59it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:40,  4.57it/s]Loading train:  26%|██▌       | 63/247 [00:13<00:40,  4.56it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:40,  4.56it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:40,  4.54it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:39,  4.54it/s]Loading train:  27%|██▋       | 67/247 [00:14<00:39,  4.50it/s]Loading train:  28%|██▊       | 68/247 [00:14<00:39,  4.51it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:39,  4.51it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:39,  4.51it/s]Loading train:  29%|██▊       | 71/247 [00:15<00:39,  4.50it/s]Loading train:  29%|██▉       | 72/247 [00:15<00:38,  4.51it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:38,  4.49it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:38,  4.44it/s]Loading train:  30%|███       | 75/247 [00:16<00:38,  4.44it/s]Loading train:  31%|███       | 76/247 [00:16<00:38,  4.46it/s]Loading train:  31%|███       | 77/247 [00:17<00:38,  4.41it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:41,  4.08it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:41,  4.09it/s]Loading train:  32%|███▏      | 80/247 [00:17<00:38,  4.34it/s]Loading train:  33%|███▎      | 81/247 [00:17<00:39,  4.20it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:38,  4.26it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:37,  4.34it/s]Loading train:  34%|███▍      | 84/247 [00:18<00:37,  4.40it/s]Loading train:  34%|███▍      | 85/247 [00:18<00:36,  4.46it/s]Loading train:  35%|███▍      | 86/247 [00:19<00:36,  4.47it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:35,  4.48it/s]Loading train:  36%|███▌      | 88/247 [00:19<00:35,  4.50it/s]Loading train:  36%|███▌      | 89/247 [00:19<00:35,  4.49it/s]Loading train:  36%|███▋      | 90/247 [00:19<00:35,  4.47it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:34,  4.50it/s]Loading train:  37%|███▋      | 92/247 [00:20<00:34,  4.52it/s]Loading train:  38%|███▊      | 93/247 [00:20<00:33,  4.53it/s]Loading train:  38%|███▊      | 94/247 [00:20<00:33,  4.54it/s]Loading train:  38%|███▊      | 95/247 [00:21<00:33,  4.57it/s]Loading train:  39%|███▉      | 96/247 [00:21<00:33,  4.57it/s]Loading train:  39%|███▉      | 97/247 [00:21<00:32,  4.57it/s]Loading train:  40%|███▉      | 98/247 [00:21<00:32,  4.52it/s]Loading train:  40%|████      | 99/247 [00:21<00:32,  4.52it/s]Loading train:  40%|████      | 100/247 [00:22<00:34,  4.22it/s]Loading train:  41%|████      | 101/247 [00:22<00:35,  4.13it/s]Loading train:  41%|████▏     | 102/247 [00:22<00:35,  4.06it/s]Loading train:  42%|████▏     | 103/247 [00:23<00:35,  4.00it/s]Loading train:  42%|████▏     | 104/247 [00:23<00:36,  3.96it/s]Loading train:  43%|████▎     | 105/247 [00:23<00:36,  3.91it/s]Loading train:  43%|████▎     | 106/247 [00:23<00:36,  3.87it/s]Loading train:  43%|████▎     | 107/247 [00:24<00:36,  3.84it/s]Loading train:  44%|████▎     | 108/247 [00:24<00:36,  3.86it/s]Loading train:  44%|████▍     | 109/247 [00:24<00:35,  3.86it/s]Loading train:  45%|████▍     | 110/247 [00:24<00:35,  3.87it/s]Loading train:  45%|████▍     | 111/247 [00:25<00:35,  3.88it/s]Loading train:  45%|████▌     | 112/247 [00:25<00:35,  3.85it/s]Loading train:  46%|████▌     | 113/247 [00:25<00:35,  3.81it/s]Loading train:  46%|████▌     | 114/247 [00:25<00:35,  3.76it/s]Loading train:  47%|████▋     | 115/247 [00:26<00:35,  3.75it/s]Loading train:  47%|████▋     | 116/247 [00:26<00:34,  3.77it/s]Loading train:  47%|████▋     | 117/247 [00:26<00:34,  3.79it/s]Loading train:  48%|████▊     | 118/247 [00:26<00:33,  3.83it/s]Loading train:  48%|████▊     | 119/247 [00:27<00:32,  3.95it/s]Loading train:  49%|████▊     | 120/247 [00:27<00:37,  3.40it/s]Loading train:  49%|████▉     | 121/247 [00:27<00:35,  3.59it/s]Loading train:  49%|████▉     | 122/247 [00:28<00:33,  3.76it/s]Loading train:  50%|████▉     | 123/247 [00:28<00:31,  3.88it/s]Loading train:  50%|█████     | 124/247 [00:28<00:30,  3.97it/s]Loading train:  51%|█████     | 125/247 [00:28<00:30,  4.03it/s]Loading train:  51%|█████     | 126/247 [00:28<00:29,  4.06it/s]Loading train:  51%|█████▏    | 127/247 [00:29<00:29,  4.06it/s]Loading train:  52%|█████▏    | 128/247 [00:29<00:29,  4.10it/s]Loading train:  52%|█████▏    | 129/247 [00:29<00:28,  4.12it/s]Loading train:  53%|█████▎    | 130/247 [00:29<00:28,  4.15it/s]Loading train:  53%|█████▎    | 131/247 [00:30<00:27,  4.17it/s]Loading train:  53%|█████▎    | 132/247 [00:30<00:27,  4.19it/s]Loading train:  54%|█████▍    | 133/247 [00:30<00:27,  4.20it/s]Loading train:  54%|█████▍    | 134/247 [00:30<00:26,  4.20it/s]Loading train:  55%|█████▍    | 135/247 [00:31<00:26,  4.22it/s]Loading train:  55%|█████▌    | 136/247 [00:31<00:25,  4.43it/s]Loading train:  55%|█████▌    | 137/247 [00:31<00:24,  4.56it/s]Loading train:  56%|█████▌    | 138/247 [00:31<00:23,  4.73it/s]Loading train:  56%|█████▋    | 139/247 [00:31<00:22,  4.86it/s]Loading train:  57%|█████▋    | 140/247 [00:32<00:21,  4.95it/s]Loading train:  57%|█████▋    | 141/247 [00:32<00:21,  5.04it/s]Loading train:  57%|█████▋    | 142/247 [00:32<00:20,  5.07it/s]Loading train:  58%|█████▊    | 143/247 [00:32<00:20,  5.10it/s]Loading train:  58%|█████▊    | 144/247 [00:32<00:20,  5.08it/s]Loading train:  59%|█████▊    | 145/247 [00:33<00:20,  5.09it/s]Loading train:  59%|█████▉    | 146/247 [00:33<00:19,  5.10it/s]Loading train:  60%|█████▉    | 147/247 [00:33<00:19,  5.14it/s]Loading train:  60%|█████▉    | 148/247 [00:33<00:19,  5.06it/s]Loading train:  60%|██████    | 149/247 [00:33<00:19,  5.09it/s]Loading train:  61%|██████    | 150/247 [00:34<00:19,  5.09it/s]Loading train:  61%|██████    | 151/247 [00:34<00:19,  5.01it/s]Loading train:  62%|██████▏   | 152/247 [00:34<00:18,  5.02it/s]Loading train:  62%|██████▏   | 153/247 [00:34<00:18,  5.01it/s]Loading train:  62%|██████▏   | 154/247 [00:34<00:19,  4.87it/s]Loading train:  63%|██████▎   | 155/247 [00:35<00:19,  4.79it/s]Loading train:  63%|██████▎   | 156/247 [00:35<00:19,  4.65it/s]Loading train:  64%|██████▎   | 157/247 [00:35<00:19,  4.62it/s]Loading train:  64%|██████▍   | 158/247 [00:35<00:19,  4.63it/s]Loading train:  64%|██████▍   | 159/247 [00:36<00:19,  4.60it/s]Loading train:  65%|██████▍   | 160/247 [00:36<00:18,  4.62it/s]Loading train:  65%|██████▌   | 161/247 [00:36<00:18,  4.62it/s]Loading train:  66%|██████▌   | 162/247 [00:36<00:18,  4.65it/s]Loading train:  66%|██████▌   | 163/247 [00:36<00:17,  4.68it/s]Loading train:  66%|██████▋   | 164/247 [00:37<00:17,  4.71it/s]Loading train:  67%|██████▋   | 165/247 [00:37<00:17,  4.73it/s]Loading train:  67%|██████▋   | 166/247 [00:37<00:17,  4.70it/s]Loading train:  68%|██████▊   | 167/247 [00:37<00:17,  4.70it/s]Loading train:  68%|██████▊   | 168/247 [00:37<00:16,  4.67it/s]Loading train:  68%|██████▊   | 169/247 [00:38<00:16,  4.68it/s]Loading train:  69%|██████▉   | 170/247 [00:38<00:16,  4.69it/s]Loading train:  69%|██████▉   | 171/247 [00:38<00:16,  4.71it/s]Loading train:  70%|██████▉   | 172/247 [00:38<00:16,  4.62it/s]Loading train:  70%|███████   | 173/247 [00:38<00:15,  4.66it/s]Loading train:  70%|███████   | 174/247 [00:39<00:15,  4.60it/s]Loading train:  71%|███████   | 175/247 [00:39<00:16,  4.32it/s]Loading train:  71%|███████▏  | 176/247 [00:39<00:16,  4.36it/s]Loading train:  72%|███████▏  | 177/247 [00:39<00:15,  4.46it/s]Loading train:  72%|███████▏  | 178/247 [00:40<00:15,  4.51it/s]Loading train:  72%|███████▏  | 179/247 [00:40<00:14,  4.58it/s]Loading train:  73%|███████▎  | 180/247 [00:40<00:14,  4.55it/s]Loading train:  73%|███████▎  | 181/247 [00:40<00:14,  4.59it/s]Loading train:  74%|███████▎  | 182/247 [00:40<00:14,  4.61it/s]Loading train:  74%|███████▍  | 183/247 [00:41<00:13,  4.64it/s]Loading train:  74%|███████▍  | 184/247 [00:41<00:13,  4.65it/s]Loading train:  75%|███████▍  | 185/247 [00:41<00:13,  4.60it/s]Loading train:  75%|███████▌  | 186/247 [00:41<00:13,  4.58it/s]Loading train:  76%|███████▌  | 187/247 [00:42<00:13,  4.60it/s]Loading train:  76%|███████▌  | 188/247 [00:42<00:12,  4.63it/s]Loading train:  77%|███████▋  | 189/247 [00:42<00:12,  4.66it/s]Loading train:  77%|███████▋  | 190/247 [00:42<00:12,  4.66it/s]Loading train:  77%|███████▋  | 191/247 [00:42<00:12,  4.66it/s]Loading train:  78%|███████▊  | 192/247 [00:43<00:11,  4.64it/s]Loading train:  78%|███████▊  | 193/247 [00:43<00:11,  4.62it/s]Loading train:  79%|███████▊  | 194/247 [00:43<00:11,  4.68it/s]Loading train:  79%|███████▉  | 195/247 [00:43<00:11,  4.71it/s]Loading train:  79%|███████▉  | 196/247 [00:43<00:10,  4.72it/s]Loading train:  80%|███████▉  | 197/247 [00:44<00:10,  4.72it/s]Loading train:  80%|████████  | 198/247 [00:44<00:10,  4.76it/s]Loading train:  81%|████████  | 199/247 [00:44<00:10,  4.79it/s]Loading train:  81%|████████  | 200/247 [00:44<00:09,  4.81it/s]Loading train:  81%|████████▏ | 201/247 [00:45<00:09,  4.82it/s]Loading train:  82%|████████▏ | 202/247 [00:45<00:09,  4.78it/s]Loading train:  82%|████████▏ | 203/247 [00:45<00:09,  4.81it/s]Loading train:  83%|████████▎ | 204/247 [00:45<00:08,  4.79it/s]Loading train:  83%|████████▎ | 205/247 [00:45<00:08,  4.82it/s]Loading train:  83%|████████▎ | 206/247 [00:46<00:08,  4.84it/s]Loading train:  84%|████████▍ | 207/247 [00:46<00:08,  4.77it/s]Loading train:  84%|████████▍ | 208/247 [00:46<00:08,  4.81it/s]Loading train:  85%|████████▍ | 209/247 [00:46<00:07,  4.85it/s]Loading train:  85%|████████▌ | 210/247 [00:46<00:07,  4.84it/s]Loading train:  85%|████████▌ | 211/247 [00:47<00:07,  4.82it/s]Loading train:  86%|████████▌ | 212/247 [00:47<00:07,  4.75it/s]Loading train:  86%|████████▌ | 213/247 [00:47<00:07,  4.73it/s]Loading train:  87%|████████▋ | 214/247 [00:47<00:06,  4.73it/s]Loading train:  87%|████████▋ | 215/247 [00:47<00:06,  4.71it/s]Loading train:  87%|████████▋ | 216/247 [00:48<00:06,  4.72it/s]Loading train:  88%|████████▊ | 217/247 [00:48<00:06,  4.72it/s]Loading train:  88%|████████▊ | 218/247 [00:48<00:06,  4.70it/s]Loading train:  89%|████████▊ | 219/247 [00:48<00:06,  4.65it/s]Loading train:  89%|████████▉ | 220/247 [00:49<00:05,  4.63it/s]Loading train:  89%|████████▉ | 221/247 [00:49<00:05,  4.62it/s]Loading train:  90%|████████▉ | 222/247 [00:49<00:05,  4.63it/s]Loading train:  90%|█████████ | 223/247 [00:49<00:05,  4.66it/s]Loading train:  91%|█████████ | 224/247 [00:49<00:04,  4.68it/s]Loading train:  91%|█████████ | 225/247 [00:50<00:04,  4.67it/s]Loading train:  91%|█████████▏| 226/247 [00:50<00:04,  4.68it/s]Loading train:  92%|█████████▏| 227/247 [00:50<00:04,  4.65it/s]Loading train:  92%|█████████▏| 228/247 [00:50<00:04,  4.65it/s]Loading train:  93%|█████████▎| 229/247 [00:50<00:03,  4.65it/s]Loading train:  93%|█████████▎| 230/247 [00:51<00:03,  4.53it/s]Loading train:  94%|█████████▎| 231/247 [00:51<00:03,  4.45it/s]Loading train:  94%|█████████▍| 232/247 [00:51<00:03,  4.39it/s]Loading train:  94%|█████████▍| 233/247 [00:51<00:03,  4.36it/s]Loading train:  95%|█████████▍| 234/247 [00:52<00:02,  4.34it/s]Loading train:  95%|█████████▌| 235/247 [00:52<00:02,  4.30it/s]Loading train:  96%|█████████▌| 236/247 [00:52<00:02,  4.25it/s]Loading train:  96%|█████████▌| 237/247 [00:52<00:02,  4.21it/s]Loading train:  96%|█████████▋| 238/247 [00:53<00:02,  4.21it/s]Loading train:  97%|█████████▋| 239/247 [00:53<00:01,  4.21it/s]Loading train:  97%|█████████▋| 240/247 [00:53<00:01,  4.09it/s]Loading train:  98%|█████████▊| 241/247 [00:53<00:01,  4.07it/s]Loading train:  98%|█████████▊| 242/247 [00:54<00:01,  4.11it/s]Loading train:  98%|█████████▊| 243/247 [00:54<00:01,  3.89it/s]Loading train:  99%|█████████▉| 244/247 [00:54<00:00,  3.96it/s]Loading train:  99%|█████████▉| 245/247 [00:54<00:00,  4.01it/s]Loading train: 100%|█████████▉| 246/247 [00:55<00:00,  4.00it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.06it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.46it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 53.79it/s]concatenating: train:   5%|▌         | 13/247 [00:00<00:04, 55.93it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:03, 57.22it/s]concatenating: train:  11%|█         | 27/247 [00:00<00:03, 58.25it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:03, 59.08it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:03, 59.82it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 60.27it/s]concatenating: train:  22%|██▏       | 55/247 [00:00<00:03, 60.33it/s]concatenating: train:  25%|██▌       | 62/247 [00:01<00:03, 60.45it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:02, 60.38it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:02, 60.38it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:02, 59.26it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:02, 60.18it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:02, 60.78it/s]concatenating: train:  42%|████▏     | 103/247 [00:01<00:02, 59.14it/s]concatenating: train:  44%|████▍     | 109/247 [00:01<00:02, 57.13it/s]concatenating: train:  47%|████▋     | 115/247 [00:01<00:02, 56.09it/s]concatenating: train:  49%|████▉     | 121/247 [00:02<00:02, 56.31it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:02, 57.00it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:01, 57.48it/s]concatenating: train:  57%|█████▋    | 140/247 [00:02<00:01, 59.70it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:01, 62.10it/s]concatenating: train:  62%|██████▏   | 154/247 [00:02<00:01, 63.26it/s]concatenating: train:  65%|██████▌   | 161/247 [00:02<00:01, 63.08it/s]concatenating: train:  68%|██████▊   | 168/247 [00:02<00:01, 63.16it/s]concatenating: train:  71%|███████   | 175/247 [00:02<00:01, 62.08it/s]concatenating: train:  74%|███████▎  | 182/247 [00:03<00:01, 61.73it/s]concatenating: train:  77%|███████▋  | 189/247 [00:03<00:00, 59.16it/s]concatenating: train:  79%|███████▉  | 196/247 [00:03<00:00, 59.98it/s]concatenating: train:  82%|████████▏ | 203/247 [00:03<00:00, 60.54it/s]concatenating: train:  85%|████████▌ | 210/247 [00:03<00:00, 61.16it/s]concatenating: train:  88%|████████▊ | 217/247 [00:03<00:00, 60.78it/s]concatenating: train:  91%|█████████ | 224/247 [00:03<00:00, 59.39it/s]concatenating: train:  93%|█████████▎| 230/247 [00:03<00:00, 59.36it/s]concatenating: train:  96%|█████████▌| 236/247 [00:03<00:00, 58.24it/s]concatenating: train:  98%|█████████▊| 242/247 [00:04<00:00, 57.75it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 59.76it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.47it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.49it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.68it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.87it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.83it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.83it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 65.96it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<00:57,  4.28it/s]Loading trainS:   1%|          | 2/247 [00:00<00:57,  4.28it/s]Loading trainS:   1%|          | 3/247 [00:00<00:56,  4.31it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:56,  4.27it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:56,  4.30it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:55,  4.35it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:54,  4.37it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:56,  4.25it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:56,  4.21it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:56,  4.21it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:54,  4.31it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:57,  4.11it/s]Loading trainS:   5%|▌         | 13/247 [00:03<00:55,  4.22it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:53,  4.33it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:52,  4.39it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:52,  4.41it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:51,  4.46it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:51,  4.43it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:51,  4.44it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:50,  4.46it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:51,  4.41it/s]Loading trainS:   9%|▉         | 22/247 [00:05<00:50,  4.45it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:49,  4.49it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:49,  4.50it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:48,  4.54it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:48,  4.53it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:48,  4.56it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:47,  4.59it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:47,  4.59it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:47,  4.60it/s]Loading trainS:  13%|█▎        | 31/247 [00:07<00:47,  4.58it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:47,  4.57it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:46,  4.56it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:46,  4.53it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:46,  4.53it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:46,  4.51it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:46,  4.55it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:45,  4.55it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:45,  4.56it/s]Loading trainS:  16%|█▌        | 40/247 [00:09<00:46,  4.46it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:45,  4.49it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:45,  4.54it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:44,  4.58it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:44,  4.60it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:43,  4.60it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:43,  4.61it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:43,  4.61it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:43,  4.62it/s]Loading trainS:  20%|█▉        | 49/247 [00:10<00:43,  4.60it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:42,  4.59it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:42,  4.61it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:42,  4.63it/s]Loading trainS:  21%|██▏       | 53/247 [00:11<00:42,  4.61it/s]Loading trainS:  22%|██▏       | 54/247 [00:12<00:41,  4.62it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:41,  4.63it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:41,  4.64it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:40,  4.64it/s]Loading trainS:  23%|██▎       | 58/247 [00:12<00:41,  4.55it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:41,  4.53it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:41,  4.55it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:40,  4.55it/s]Loading trainS:  25%|██▌       | 62/247 [00:13<00:40,  4.54it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:40,  4.54it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:40,  4.52it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:42,  4.27it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:41,  4.32it/s]Loading trainS:  27%|██▋       | 67/247 [00:14<00:41,  4.39it/s]Loading trainS:  28%|██▊       | 68/247 [00:15<00:40,  4.42it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:39,  4.48it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:39,  4.51it/s]Loading trainS:  29%|██▊       | 71/247 [00:15<00:38,  4.52it/s]Loading trainS:  29%|██▉       | 72/247 [00:16<00:39,  4.47it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:38,  4.47it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:39,  4.38it/s]Loading trainS:  30%|███       | 75/247 [00:16<00:38,  4.44it/s]Loading trainS:  31%|███       | 76/247 [00:16<00:38,  4.46it/s]Loading trainS:  31%|███       | 77/247 [00:17<00:38,  4.42it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:40,  4.13it/s]Loading trainS:  32%|███▏      | 79/247 [00:17<00:42,  4.00it/s]Loading trainS:  32%|███▏      | 80/247 [00:17<00:39,  4.22it/s]Loading trainS:  33%|███▎      | 81/247 [00:18<00:39,  4.25it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:37,  4.34it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:36,  4.44it/s]Loading trainS:  34%|███▍      | 84/247 [00:18<00:36,  4.50it/s]Loading trainS:  34%|███▍      | 85/247 [00:19<00:35,  4.53it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:35,  4.52it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:35,  4.52it/s]Loading trainS:  36%|███▌      | 88/247 [00:19<00:35,  4.48it/s]Loading trainS:  36%|███▌      | 89/247 [00:19<00:34,  4.53it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:34,  4.58it/s]Loading trainS:  37%|███▋      | 91/247 [00:20<00:34,  4.56it/s]Loading trainS:  37%|███▋      | 92/247 [00:20<00:33,  4.61it/s]Loading trainS:  38%|███▊      | 93/247 [00:20<00:33,  4.63it/s]Loading trainS:  38%|███▊      | 94/247 [00:21<00:32,  4.65it/s]Loading trainS:  38%|███▊      | 95/247 [00:21<00:32,  4.65it/s]Loading trainS:  39%|███▉      | 96/247 [00:21<00:32,  4.66it/s]Loading trainS:  39%|███▉      | 97/247 [00:21<00:32,  4.66it/s]Loading trainS:  40%|███▉      | 98/247 [00:21<00:32,  4.64it/s]Loading trainS:  40%|████      | 99/247 [00:22<00:32,  4.62it/s]Loading trainS:  40%|████      | 100/247 [00:22<00:33,  4.38it/s]Loading trainS:  41%|████      | 101/247 [00:22<00:34,  4.25it/s]Loading trainS:  41%|████▏     | 102/247 [00:22<00:34,  4.16it/s]Loading trainS:  42%|████▏     | 103/247 [00:23<00:35,  4.03it/s]Loading trainS:  42%|████▏     | 104/247 [00:23<00:35,  4.00it/s]Loading trainS:  43%|████▎     | 105/247 [00:23<00:35,  4.00it/s]Loading trainS:  43%|████▎     | 106/247 [00:23<00:35,  3.97it/s]Loading trainS:  43%|████▎     | 107/247 [00:24<00:35,  3.99it/s]Loading trainS:  44%|████▎     | 108/247 [00:24<00:34,  4.00it/s]Loading trainS:  44%|████▍     | 109/247 [00:24<00:34,  4.00it/s]Loading trainS:  45%|████▍     | 110/247 [00:24<00:34,  3.99it/s]Loading trainS:  45%|████▍     | 111/247 [00:25<00:34,  3.98it/s]Loading trainS:  45%|████▌     | 112/247 [00:25<00:33,  4.00it/s]Loading trainS:  46%|████▌     | 113/247 [00:25<00:33,  4.00it/s]Loading trainS:  46%|████▌     | 114/247 [00:25<00:33,  3.97it/s]Loading trainS:  47%|████▋     | 115/247 [00:26<00:33,  3.93it/s]Loading trainS:  47%|████▋     | 116/247 [00:26<00:33,  3.95it/s]Loading trainS:  47%|████▋     | 117/247 [00:26<00:32,  3.96it/s]Loading trainS:  48%|████▊     | 118/247 [00:26<00:31,  4.10it/s]Loading trainS:  48%|████▊     | 119/247 [00:27<00:30,  4.19it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:29,  4.25it/s]Loading trainS:  49%|████▉     | 121/247 [00:27<00:29,  4.27it/s]Loading trainS:  49%|████▉     | 122/247 [00:27<00:29,  4.27it/s]Loading trainS:  50%|████▉     | 123/247 [00:28<00:29,  4.26it/s]Loading trainS:  50%|█████     | 124/247 [00:28<00:28,  4.27it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:28,  4.32it/s]Loading trainS:  51%|█████     | 126/247 [00:28<00:27,  4.35it/s]Loading trainS:  51%|█████▏    | 127/247 [00:28<00:27,  4.38it/s]Loading trainS:  52%|█████▏    | 128/247 [00:29<00:27,  4.38it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:27,  4.34it/s]Loading trainS:  53%|█████▎    | 130/247 [00:29<00:26,  4.36it/s]Loading trainS:  53%|█████▎    | 131/247 [00:29<00:26,  4.32it/s]Loading trainS:  53%|█████▎    | 132/247 [00:30<00:26,  4.35it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:26,  4.31it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:25,  4.35it/s]Loading trainS:  55%|█████▍    | 135/247 [00:30<00:25,  4.38it/s]Loading trainS:  55%|█████▌    | 136/247 [00:30<00:24,  4.60it/s]Loading trainS:  55%|█████▌    | 137/247 [00:31<00:23,  4.77it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:22,  4.87it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:21,  4.95it/s]Loading trainS:  57%|█████▋    | 140/247 [00:31<00:21,  4.96it/s]Loading trainS:  57%|█████▋    | 141/247 [00:31<00:21,  5.04it/s]Loading trainS:  57%|█████▋    | 142/247 [00:32<00:20,  5.05it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:20,  5.09it/s]Loading trainS:  58%|█████▊    | 144/247 [00:32<00:20,  5.11it/s]Loading trainS:  59%|█████▊    | 145/247 [00:32<00:20,  5.05it/s]Loading trainS:  59%|█████▉    | 146/247 [00:32<00:19,  5.10it/s]Loading trainS:  60%|█████▉    | 147/247 [00:33<00:19,  5.13it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:19,  5.15it/s]Loading trainS:  60%|██████    | 149/247 [00:33<00:18,  5.18it/s]Loading trainS:  61%|██████    | 150/247 [00:33<00:18,  5.17it/s]Loading trainS:  61%|██████    | 151/247 [00:33<00:18,  5.17it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:18,  5.18it/s]Loading trainS:  62%|██████▏   | 153/247 [00:34<00:18,  5.17it/s]Loading trainS:  62%|██████▏   | 154/247 [00:34<00:18,  4.95it/s]Loading trainS:  63%|██████▎   | 155/247 [00:34<00:18,  4.88it/s]Loading trainS:  63%|██████▎   | 156/247 [00:34<00:18,  4.80it/s]Loading trainS:  64%|██████▎   | 157/247 [00:35<00:18,  4.75it/s]Loading trainS:  64%|██████▍   | 158/247 [00:35<00:18,  4.75it/s]Loading trainS:  64%|██████▍   | 159/247 [00:35<00:18,  4.75it/s]Loading trainS:  65%|██████▍   | 160/247 [00:35<00:18,  4.75it/s]Loading trainS:  65%|██████▌   | 161/247 [00:35<00:18,  4.74it/s]Loading trainS:  66%|██████▌   | 162/247 [00:36<00:17,  4.73it/s]Loading trainS:  66%|██████▌   | 163/247 [00:36<00:17,  4.72it/s]Loading trainS:  66%|██████▋   | 164/247 [00:36<00:17,  4.73it/s]Loading trainS:  67%|██████▋   | 165/247 [00:36<00:17,  4.70it/s]Loading trainS:  67%|██████▋   | 166/247 [00:37<00:17,  4.68it/s]Loading trainS:  68%|██████▊   | 167/247 [00:37<00:17,  4.69it/s]Loading trainS:  68%|██████▊   | 168/247 [00:37<00:16,  4.71it/s]Loading trainS:  68%|██████▊   | 169/247 [00:37<00:16,  4.72it/s]Loading trainS:  69%|██████▉   | 170/247 [00:37<00:16,  4.72it/s]Loading trainS:  69%|██████▉   | 171/247 [00:38<00:16,  4.72it/s]Loading trainS:  70%|██████▉   | 172/247 [00:38<00:16,  4.60it/s]Loading trainS:  70%|███████   | 173/247 [00:38<00:16,  4.60it/s]Loading trainS:  70%|███████   | 174/247 [00:38<00:16,  4.48it/s]Loading trainS:  71%|███████   | 175/247 [00:39<00:16,  4.30it/s]Loading trainS:  71%|███████▏  | 176/247 [00:39<00:16,  4.34it/s]Loading trainS:  72%|███████▏  | 177/247 [00:39<00:15,  4.44it/s]Loading trainS:  72%|███████▏  | 178/247 [00:39<00:15,  4.49it/s]Loading trainS:  72%|███████▏  | 179/247 [00:39<00:15,  4.53it/s]Loading trainS:  73%|███████▎  | 180/247 [00:40<00:14,  4.56it/s]Loading trainS:  73%|███████▎  | 181/247 [00:40<00:14,  4.59it/s]Loading trainS:  74%|███████▎  | 182/247 [00:40<00:14,  4.59it/s]Loading trainS:  74%|███████▍  | 183/247 [00:40<00:13,  4.59it/s]Loading trainS:  74%|███████▍  | 184/247 [00:40<00:13,  4.60it/s]Loading trainS:  75%|███████▍  | 185/247 [00:41<00:13,  4.61it/s]Loading trainS:  75%|███████▌  | 186/247 [00:41<00:13,  4.59it/s]Loading trainS:  76%|███████▌  | 187/247 [00:41<00:12,  4.62it/s]Loading trainS:  76%|███████▌  | 188/247 [00:41<00:12,  4.61it/s]Loading trainS:  77%|███████▋  | 189/247 [00:42<00:12,  4.62it/s]Loading trainS:  77%|███████▋  | 190/247 [00:42<00:12,  4.62it/s]Loading trainS:  77%|███████▋  | 191/247 [00:42<00:12,  4.57it/s]Loading trainS:  78%|███████▊  | 192/247 [00:42<00:11,  4.60it/s]Loading trainS:  78%|███████▊  | 193/247 [00:42<00:11,  4.60it/s]Loading trainS:  79%|███████▊  | 194/247 [00:43<00:11,  4.67it/s]Loading trainS:  79%|███████▉  | 195/247 [00:43<00:11,  4.73it/s]Loading trainS:  79%|███████▉  | 196/247 [00:43<00:10,  4.76it/s]Loading trainS:  80%|███████▉  | 197/247 [00:43<00:10,  4.80it/s]Loading trainS:  80%|████████  | 198/247 [00:43<00:10,  4.82it/s]Loading trainS:  81%|████████  | 199/247 [00:44<00:09,  4.82it/s]Loading trainS:  81%|████████  | 200/247 [00:44<00:09,  4.80it/s]Loading trainS:  81%|████████▏ | 201/247 [00:44<00:09,  4.69it/s]Loading trainS:  82%|████████▏ | 202/247 [00:45<00:16,  2.76it/s]Loading trainS:  82%|████████▏ | 203/247 [00:46<00:22,  1.96it/s]Loading trainS:  83%|████████▎ | 204/247 [00:46<00:24,  1.74it/s]Loading trainS:  83%|████████▎ | 205/247 [00:47<00:24,  1.74it/s]Loading trainS:  83%|████████▎ | 206/247 [00:47<00:22,  1.79it/s]Loading trainS:  84%|████████▍ | 207/247 [00:48<00:23,  1.71it/s]Loading trainS:  84%|████████▍ | 208/247 [00:49<00:24,  1.58it/s]Loading trainS:  85%|████████▍ | 209/247 [00:50<00:25,  1.49it/s]Loading trainS:  85%|████████▌ | 210/247 [00:51<00:28,  1.31it/s]Loading trainS:  85%|████████▌ | 211/247 [00:51<00:26,  1.34it/s]Loading trainS:  86%|████████▌ | 212/247 [00:52<00:25,  1.38it/s]Loading trainS:  86%|████████▌ | 213/247 [00:53<00:24,  1.36it/s]Loading trainS:  87%|████████▋ | 214/247 [00:53<00:23,  1.38it/s]Loading trainS:  87%|████████▋ | 215/247 [00:54<00:22,  1.40it/s]Loading trainS:  87%|████████▋ | 216/247 [00:55<00:24,  1.26it/s]Loading trainS:  88%|████████▊ | 217/247 [00:56<00:22,  1.34it/s]Loading trainS:  88%|████████▊ | 218/247 [00:56<00:21,  1.36it/s]Loading trainS:  89%|████████▊ | 219/247 [00:57<00:22,  1.22it/s]Loading trainS:  89%|████████▉ | 220/247 [00:58<00:21,  1.23it/s]Loading trainS:  89%|████████▉ | 221/247 [00:59<00:23,  1.09it/s]Loading trainS:  90%|████████▉ | 222/247 [01:00<00:21,  1.16it/s]Loading trainS:  90%|█████████ | 223/247 [01:01<00:19,  1.25it/s]Loading trainS:  91%|█████████ | 224/247 [01:02<00:19,  1.17it/s]Loading trainS:  91%|█████████ | 225/247 [01:02<00:16,  1.37it/s]Loading trainS:  91%|█████████▏| 226/247 [01:03<00:13,  1.58it/s]Loading trainS:  92%|█████████▏| 227/247 [01:03<00:11,  1.74it/s]Loading trainS:  92%|█████████▏| 228/247 [01:04<00:10,  1.78it/s]Loading trainS:  93%|█████████▎| 229/247 [01:04<00:09,  1.88it/s]Loading trainS:  93%|█████████▎| 230/247 [01:05<00:08,  1.95it/s]Loading trainS:  94%|█████████▎| 231/247 [01:05<00:08,  1.92it/s]Loading trainS:  94%|█████████▍| 232/247 [01:06<00:07,  2.03it/s]Loading trainS:  94%|█████████▍| 233/247 [01:06<00:06,  2.01it/s]Loading trainS:  95%|█████████▍| 234/247 [01:07<00:06,  2.05it/s]Loading trainS:  95%|█████████▌| 235/247 [01:07<00:05,  2.02it/s]Loading trainS:  96%|█████████▌| 236/247 [01:08<00:05,  1.92it/s]Loading trainS:  96%|█████████▌| 237/247 [01:08<00:05,  1.95it/s]Loading trainS:  96%|█████████▋| 238/247 [01:09<00:04,  1.98it/s]Loading trainS:  97%|█████████▋| 239/247 [01:09<00:04,  2.00it/s]Loading trainS:  97%|█████████▋| 240/247 [01:10<00:03,  1.93it/s]Loading trainS:  98%|█████████▊| 241/247 [01:10<00:03,  1.67it/s]Loading trainS:  98%|█████████▊| 242/247 [01:11<00:03,  1.50it/s]Loading trainS:  98%|█████████▊| 243/247 [01:12<00:02,  1.54it/s]Loading trainS:  99%|█████████▉| 244/247 [01:12<00:01,  1.54it/s]Loading trainS:  99%|█████████▉| 245/247 [01:13<00:01,  1.56it/s]Loading trainS: 100%|█████████▉| 246/247 [01:14<00:00,  1.49it/s]Loading trainS: 100%|██████████| 247/247 [01:15<00:00,  1.46it/s]Loading trainS: 100%|██████████| 247/247 [01:15<00:00,  3.29it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.29it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.34it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.42it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.46it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]----------+++ 
CrossVal ['b']
CrossVal ['b']
(0/5) test vimp2_ANON911_CSFn2
(1/5) test vimp2_D_CSFn2
(2/5) test vimp2_F_CSFn2
(3/5) test vimp2_G_CSFn2
(4/5) test vimp2_J_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 76s - loss: 0.0931 - acc: 0.9898 - mDice: 0.8191 - val_loss: 0.2388 - val_acc: 0.9904 - val_mDice: 0.4323

Epoch 00001: val_mDice improved from -inf to 0.43225, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 71s - loss: 0.0629 - acc: 0.9933 - mDice: 0.8777 - val_loss: 0.1055 - val_acc: 0.9903 - val_mDice: 0.4153

Epoch 00002: val_mDice did not improve from 0.43225
Epoch 3/300
 - 72s - loss: 0.0561 - acc: 0.9939 - mDice: 0.8910 - val_loss: 0.1566 - val_acc: 0.9922 - val_mDice: 0.4608

Epoch 00003: val_mDice improved from 0.43225 to 0.46081, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 75s - loss: 0.0518 - acc: 0.9944 - mDice: 0.8994 - val_loss: 0.0828 - val_acc: 0.9923 - val_mDice: 0.4602

Epoch 00004: val_mDice did not improve from 0.46081
Epoch 5/300
 - 75s - loss: 0.0476 - acc: 0.9947 - mDice: 0.9074 - val_loss: 0.0315 - val_acc: 0.9922 - val_mDice: 0.4431

Epoch 00005: val_mDice did not improve from 0.46081
Epoch 6/300
 - 75s - loss: 0.0483 - acc: 0.9947 - mDice: 0.9060 - val_loss: 0.1337 - val_acc: 0.9920 - val_mDice: 0.4573

Epoch 00006: val_mDice did not improve from 0.46081
Epoch 7/300
 - 75s - loss: 0.0430 - acc: 0.9951 - mDice: 0.9165 - val_loss: -1.7744e-02 - val_acc: 0.9906 - val_mDice: 0.4311

Epoch 00007: val_mDice did not improve from 0.46081
Epoch 8/300
 - 75s - loss: 0.0426 - acc: 0.9952 - mDice: 0.9172 - val_loss: 0.1168 - val_acc: 0.9916 - val_mDice: 0.4528

Epoch 00008: val_mDice did not improve from 0.46081
Epoch 9/300
 - 74s - loss: 0.0412 - acc: 0.9953 - mDice: 0.9199 - val_loss: 0.0858 - val_acc: 0.9900 - val_mDice: 0.4558

Epoch 00009: val_mDice did not improve from 0.46081
Epoch 10/300
 - 73s - loss: 0.0406 - acc: 0.9954 - mDice: 0.9212 - val_loss: 0.0560 - val_acc: 0.9916 - val_mDice: 0.4544

Epoch 00010: val_mDice did not improve from 0.46081
Epoch 11/300
 - 73s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9230 - val_loss: 0.0499 - val_acc: 0.9927 - val_mDice: 0.4709

Epoch 00011: val_mDice improved from 0.46081 to 0.47090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 12/300
 - 72s - loss: 0.0369 - acc: 0.9956 - mDice: 0.9284 - val_loss: 0.0256 - val_acc: 0.9913 - val_mDice: 0.4569

Epoch 00012: val_mDice did not improve from 0.47090
Epoch 13/300
 - 72s - loss: 0.0381 - acc: 0.9956 - mDice: 0.9259 - val_loss: 0.0641 - val_acc: 0.9908 - val_mDice: 0.4385

Epoch 00013: val_mDice did not improve from 0.47090
Epoch 14/300
 - 73s - loss: 0.0347 - acc: 0.9957 - mDice: 0.9326 - val_loss: -8.3837e-03 - val_acc: 0.9923 - val_mDice: 0.4627

Epoch 00014: val_mDice did not improve from 0.47090
Epoch 15/300
 - 73s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9297 - val_loss: 0.0563 - val_acc: 0.9911 - val_mDice: 0.4543

Epoch 00015: val_mDice did not improve from 0.47090
Epoch 16/300
 - 74s - loss: 0.0360 - acc: 0.9957 - mDice: 0.9300 - val_loss: 0.0669 - val_acc: 0.9906 - val_mDice: 0.4330

Epoch 00016: val_mDice did not improve from 0.47090
Epoch 17/300
 - 74s - loss: 0.0347 - acc: 0.9959 - mDice: 0.9327 - val_loss: 0.1799 - val_acc: 0.9914 - val_mDice: 0.4433

Epoch 00017: val_mDice did not improve from 0.47090
Epoch 18/300
 - 73s - loss: 0.0349 - acc: 0.9958 - mDice: 0.9323 - val_loss: 0.0870 - val_acc: 0.9921 - val_mDice: 0.4521

Epoch 00018: val_mDice did not improve from 0.47090
Epoch 19/300
 - 74s - loss: 0.0334 - acc: 0.9959 - mDice: 0.9352 - val_loss: -2.7313e-03 - val_acc: 0.9922 - val_mDice: 0.4511

Epoch 00019: val_mDice did not improve from 0.47090
Epoch 20/300
 - 73s - loss: 0.0347 - acc: 0.9959 - mDice: 0.9326 - val_loss: 0.0618 - val_acc: 0.9916 - val_mDice: 0.4439

Epoch 00020: val_mDice did not improve from 0.47090
Epoch 21/300
 - 74s - loss: 0.0342 - acc: 0.9959 - mDice: 0.9337 - val_loss: 0.0775 - val_acc: 0.9917 - val_mDice: 0.4715

Epoch 00021: val_mDice improved from 0.47090 to 0.47150, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 22/300
 - 74s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9353 - val_loss: 0.0494 - val_acc: 0.9921 - val_mDice: 0.4673

Epoch 00022: val_mDice did not improve from 0.47150
Epoch 23/300
 - 73s - loss: 0.0351 - acc: 0.9959 - mDice: 0.9319 - val_loss: 0.1615 - val_acc: 0.9906 - val_mDice: 0.4734

Epoch 00023: val_mDice improved from 0.47150 to 0.47344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 24/300
 - 73s - loss: 0.0327 - acc: 0.9960 - mDice: 0.9366 - val_loss: 0.0803 - val_acc: 0.9922 - val_mDice: 0.4654

Epoch 00024: val_mDice did not improve from 0.47344
Epoch 25/300
 - 74s - loss: 0.0317 - acc: 0.9961 - mDice: 0.9386 - val_loss: 0.0525 - val_acc: 0.9922 - val_mDice: 0.4622

Epoch 00025: val_mDice did not improve from 0.47344
Epoch 26/300
 - 74s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9379 - val_loss: 0.0071 - val_acc: 0.9906 - val_mDice: 0.4323

Epoch 00026: val_mDice did not improve from 0.47344
Epoch 27/300
 - 74s - loss: 0.0319 - acc: 0.9961 - mDice: 0.9382 - val_loss: 0.0610 - val_acc: 0.9918 - val_mDice: 0.4453

Epoch 00027: val_mDice did not improve from 0.47344
Epoch 28/300
 - 74s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9379 - val_loss: 0.1166 - val_acc: 0.9904 - val_mDice: 0.4547

Epoch 00028: val_mDice did not improve from 0.47344
Epoch 29/300
 - 74s - loss: 0.0303 - acc: 0.9962 - mDice: 0.9413 - val_loss: 0.0659 - val_acc: 0.9922 - val_mDice: 0.4669

Epoch 00029: val_mDice did not improve from 0.47344
Epoch 30/300
 - 74s - loss: 0.0308 - acc: 0.9962 - mDice: 0.9403 - val_loss: -6.7443e-03 - val_acc: 0.9906 - val_mDice: 0.4334

Epoch 00030: val_mDice did not improve from 0.47344
Epoch 31/300
 - 74s - loss: 0.0303 - acc: 0.9962 - mDice: 0.9412 - val_loss: 0.1162 - val_acc: 0.9797 - val_mDice: 0.1622

Epoch 00031: val_mDice did not improve from 0.47344
Epoch 32/300
 - 74s - loss: 0.0298 - acc: 0.9962 - mDice: 0.9422 - val_loss: 0.1051 - val_acc: 0.9922 - val_mDice: 0.4768

Epoch 00032: val_mDice improved from 0.47344 to 0.47680, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 33/300
 - 74s - loss: 0.0295 - acc: 0.9962 - mDice: 0.9429 - val_loss: 0.0863 - val_acc: 0.9909 - val_mDice: 0.4653

Epoch 00033: val_mDice did not improve from 0.47680
Epoch 34/300
 - 74s - loss: 0.0306 - acc: 0.9962 - mDice: 0.9406 - val_loss: 0.0548 - val_acc: 0.9925 - val_mDice: 0.4670

Epoch 00034: val_mDice did not improve from 0.47680
Epoch 35/300
 - 75s - loss: 0.0297 - acc: 0.9962 - mDice: 0.9425 - val_loss: 0.0339 - val_acc: 0.9909 - val_mDice: 0.4388

Epoch 00035: val_mDice did not improve from 0.47680
Epoch 36/300
 - 74s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9422 - val_loss: 0.0308 - val_acc: 0.9912 - val_mDice: 0.4448

Epoch 00036: val_mDice did not improve from 0.47680
Epoch 37/300
 - 74s - loss: 0.0338 - acc: 0.9960 - mDice: 0.9345 - val_loss: 0.0810 - val_acc: 0.9922 - val_mDice: 0.4640

Epoch 00037: val_mDice did not improve from 0.47680
Epoch 38/300
 - 74s - loss: 0.0305 - acc: 0.9962 - mDice: 0.9409 - val_loss: 0.0806 - val_acc: 0.9917 - val_mDice: 0.4651

Epoch 00038: val_mDice did not improve from 0.47680
Epoch 39/300
 - 73s - loss: 0.0292 - acc: 0.9963 - mDice: 0.9433 - val_loss: 0.1088 - val_acc: 0.9912 - val_mDice: 0.4694

Epoch 00039: val_mDice did not improve from 0.47680
Epoch 40/300
 - 75s - loss: 0.0295 - acc: 0.9963 - mDice: 0.9428 - val_loss: 0.0527 - val_acc: 0.9929 - val_mDice: 0.4745

Epoch 00040: val_mDice did not improve from 0.47680
Epoch 41/300
 - 74s - loss: 0.0292 - acc: 0.9963 - mDice: 0.9434 - val_loss: 0.0502 - val_acc: 0.9912 - val_mDice: 0.4664

Epoch 00041: val_mDice did not improve from 0.47680
Epoch 42/300
 - 74s - loss: 0.0289 - acc: 0.9963 - mDice: 0.9440 - val_loss: 0.0642 - val_acc: 0.9916 - val_mDice: 0.4381

Epoch 00042: val_mDice did not improve from 0.47680
Epoch 43/300
 - 74s - loss: 0.0294 - acc: 0.9963 - mDice: 0.9431 - val_loss: 0.0574 - val_acc: 0.9919 - val_mDice: 0.4510

Epoch 00043: val_mDice did not improve from 0.47680
Epoch 44/300
 - 74s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9438 - val_loss: 0.0754 - val_acc: 0.9917 - val_mDice: 0.4757

Epoch 00044: val_mDice did not improve from 0.47680
Epoch 45/300
 - 74s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9437 - val_loss: 0.0089 - val_acc: 0.9885 - val_mDice: 0.3951

Epoch 00045: val_mDice did not improve from 0.47680
Epoch 46/300
 - 74s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9446 - val_loss: 0.0264 - val_acc: 0.9914 - val_mDice: 0.4532

Epoch 00046: val_mDice did not improve from 0.47680
Epoch 47/300
 - 75s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9448 - val_loss: 0.0485 - val_acc: 0.9921 - val_mDice: 0.4691

Epoch 00047: val_mDice did not improve from 0.47680

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 48/300
 - 75s - loss: 0.0272 - acc: 0.9965 - mDice: 0.9473 - val_loss: 0.0489 - val_acc: 0.9920 - val_mDice: 0.4685

Epoch 00048: val_mDice did not improve from 0.47680
Epoch 49/300
 - 74s - loss: 0.0265 - acc: 0.9965 - mDice: 0.9487 - val_loss: 0.0629 - val_acc: 0.9917 - val_mDice: 0.4624

Epoch 00049: val_mDice did not improve from 0.47680
Epoch 50/300
 - 75s - loss: 0.0260 - acc: 0.9965 - mDice: 0.9496 - val_loss: 0.0518 - val_acc: 0.9915 - val_mDice: 0.4628

Epoch 00050: val_mDice did not improve from 0.47680
Epoch 51/300
 - 75s - loss: 0.0265 - acc: 0.9965 - mDice: 0.9486 - val_loss: 0.0518 - val_acc: 0.9921 - val_mDice: 0.4624

Epoch 00051: val_mDice did not improve from 0.47680
Epoch 52/300
 - 75s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9491 - val_loss: 0.0066 - val_acc: 0.9874 - val_mDice: 0.3751

Epoch 00052: val_mDice did not improve from 0.47680
Epoch 53/300
 - 75s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9497 - val_loss: 0.0709 - val_acc: 0.9922 - val_mDice: 0.4689

Epoch 00053: val_mDice did not improve from 0.47680
Epoch 54/300
 - 75s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9492 - val_loss: 0.0466 - val_acc: 0.9928 - val_mDice: 0.4727

Epoch 00054: val_mDice did not improve from 0.47680
Epoch 55/300
 - 74s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9505 - val_loss: 0.0211 - val_acc: 0.9924 - val_mDice: 0.4635

Epoch 00055: val_mDice did not improve from 0.47680
Epoch 56/300
 - 75s - loss: 0.0258 - acc: 0.9966 - mDice: 0.9500 - val_loss: 0.0476 - val_acc: 0.9921 - val_mDice: 0.4711

Epoch 00056: val_mDice did not improve from 0.47680
Epoch 57/300
 - 74s - loss: 0.0254 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0564 - val_acc: 0.9916 - val_mDice: 0.4540

Epoch 00057: val_mDice did not improve from 0.47680
Epoch 58/300
 - 75s - loss: 0.0259 - acc: 0.9966 - mDice: 0.9498 - val_loss: 0.0582 - val_acc: 0.9914 - val_mDice: 0.4499

Epoch 00058: val_mDice did not improve from 0.47680
Epoch 59/300
 - 75s - loss: 0.0247 - acc: 0.9966 - mDice: 0.9523 - val_loss: 0.0221 - val_acc: 0.9924 - val_mDice: 0.4616

Epoch 00059: val_mDice did not improve from 0.47680
Epoch 60/300
 - 75s - loss: 0.0253 - acc: 0.9966 - mDice: 0.9509 - val_loss: 0.0491 - val_acc: 0.9925 - val_mDice: 0.4677

Epoch 00060: val_mDice did not improve from 0.47680
Epoch 61/300
 - 75s - loss: 0.0250 - acc: 0.9966 - mDice: 0.9515 - val_loss: 0.0555 - val_acc: 0.9917 - val_mDice: 0.4553

Epoch 00061: val_mDice did not improve from 0.47680
Epoch 62/300
 - 75s - loss: 0.0252 - acc: 0.9966 - mDice: 0.9512 - val_loss: 0.0485 - val_acc: 0.9915 - val_mDice: 0.4697

Epoch 00062: val_mDice did not improve from 0.47680

Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 63/300
 - 75s - loss: 0.0246 - acc: 0.9967 - mDice: 0.9524 - val_loss: 0.0482 - val_acc: 0.9924 - val_mDice: 0.4697

Epoch 00063: val_mDice did not improve from 0.47680
Epoch 64/300
 - 74s - loss: 0.0243 - acc: 0.9967 - mDice: 0.9530 - val_loss: 0.0507 - val_acc: 0.9925 - val_mDice: 0.4644

Epoch 00064: val_mDice did not improve from 0.47680
Epoch 65/300
 - 74s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9533 - val_loss: 0.0489 - val_acc: 0.9920 - val_mDice: 0.4686

Epoch 00065: val_mDice did not improve from 0.47680
Epoch 66/300
 - 74s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9538 - val_loss: 0.0488 - val_acc: 0.9924 - val_mDice: 0.4684

Epoch 00066: val_mDice did not improve from 0.47680
Epoch 67/300
 - 74s - loss: 0.0238 - acc: 0.9967 - mDice: 0.9539 - val_loss: 0.0487 - val_acc: 0.9925 - val_mDice: 0.4685

Epoch 00067: val_mDice did not improve from 0.47680
Epoch 68/300
 - 74s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9536 - val_loss: 0.0483 - val_acc: 0.9919 - val_mDice: 0.4698

Epoch 00068: val_mDice did not improve from 0.47680
Epoch 69/300
 - 74s - loss: 0.0236 - acc: 0.9967 - mDice: 0.9544 - val_loss: 0.0460 - val_acc: 0.9927 - val_mDice: 0.4738

Epoch 00069: val_mDice did not improve from 0.47680
Epoch 70/300
 - 74s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9537 - val_loss: 0.0470 - val_acc: 0.9925 - val_mDice: 0.4719

Epoch 00070: val_mDice did not improve from 0.47680
Epoch 71/300
 - 74s - loss: 0.0231 - acc: 0.9967 - mDice: 0.9553 - val_loss: 0.0786 - val_acc: 0.9923 - val_mDice: 0.4689

Epoch 00071: val_mDice did not improve from 0.47680
Epoch 72/300
 - 74s - loss: 0.0232 - acc: 0.9967 - mDice: 0.9551 - val_loss: 0.0193 - val_acc: 0.9926 - val_mDice: 0.4672

Epoch 00072: val_mDice did not improve from 0.47680
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
{'val_loss': [0.23875980092598512, 0.10554934178923701, 0.15659660660289787, 0.08282804422013394, 0.03146320934947189, 0.1337408222056724, -0.017744443348578148, 0.11683236626354424, 0.08583853561598975, 0.05598458764073369, 0.04989533837851103, 0.02563215353646436, 0.0640544328872148, -0.008383720755219102, 0.056334250771605573, 0.06688217912708316, 0.17990754119626753, 0.0870132660633093, -0.002731282208058927, 0.06178032421134971, 0.07753864669048034, 0.049395413728089664, 0.16147968173027039, 0.08034030538242501, 0.05247308524163278, 0.00714517140889669, 0.060952314251178016, 0.11664835558281289, 0.0659351509075623, -0.006744317732773743, 0.1162402548410513, 0.10506481777977299, 0.08630795315937237, 0.05477005583387953, 0.033927873940439196, 0.030825102472448494, 0.08100092352868558, 0.08063045434944623, 0.10878005664090852, 0.05271904098915982, 0.05023862971915855, 0.06417294473082454, 0.057427659138544904, 0.07542513821039114, 0.008944885106058093, 0.02644002142253223, 0.04854627284738752, 0.04888391727441782, 0.06294968133574133, 0.05182260391232488, 0.051774283876648175, 0.006623498983569331, 0.07091785980774476, 0.04655526045922403, 0.021144908111732644, 0.047552104513566416, 0.056392276564517896, 0.058227969629986505, 0.022099437566848845, 0.04912158139833101, 0.05546214921517415, 0.048462690981300745, 0.04819527331057254, 0.050748388151506764, 0.0489208336706992, 0.04878935195483245, 0.048745301571694225, 0.04828532621846185, 0.0460045305458275, 0.0470495454004935, 0.07857934530969854, 0.01926239072023569], 'val_acc': [0.9903790317140184, 0.9903282102521833, 0.9922292995023297, 0.9923206234837437, 0.9921753653534898, 0.9919699387507396, 0.9906031523380909, 0.9916314774447376, 0.9899751323837418, 0.9916381860996509, 0.9927101461021034, 0.9913316105937099, 0.990833272805085, 0.9923024109533957, 0.9911388871190068, 0.9905777407122088, 0.991422220393344, 0.992109689268622, 0.9922022142925778, 0.9915689176267332, 0.9916583299636841, 0.9920917058492208, 0.9905758290677458, 0.9921926220616063, 0.992175123713038, 0.9906299959073912, 0.9918491274744898, 0.990444706008957, 0.9922158750327857, 0.9906089033808436, 0.979668125375971, 0.9922024559330296, 0.990871378609368, 0.9925322862000795, 0.9908668250292987, 0.9911700479977124, 0.992221629655397, 0.9917206445613781, 0.9911602177061476, 0.9929297041964602, 0.9911695682966674, 0.991559570616072, 0.9918884396911025, 0.9917096275467057, 0.9884997563319163, 0.9913793122088229, 0.992118076877193, 0.9920118857432414, 0.9916820572661208, 0.9914596173856352, 0.9920900304754217, 0.9874038309664339, 0.9921624259547787, 0.9927719827886816, 0.992392292251816, 0.9921010564397406, 0.991554290324718, 0.9913591737145776, 0.9923853437463801, 0.9925193414315805, 0.9917218438139906, 0.9915379948086209, 0.9924227407386711, 0.9925286866523124, 0.992022673646967, 0.9923908585184688, 0.9925284485917192, 0.9919404550357623, 0.9926674759781754, 0.9925473842534933, 0.9923362066079905, 0.9926463798717694], 'val_mDice': [0.4322546384893167, 0.4153170835872813, 0.46080512008643726, 0.4601774064896701, 0.4430780978174181, 0.4572513997946326, 0.43114571376247807, 0.45278312699930806, 0.45575967914349325, 0.4543563723564148, 0.47089562491261505, 0.4569366440042719, 0.4384639680206597, 0.46271825718271353, 0.45426391473448313, 0.43295523643985884, 0.4433497401690254, 0.45210934164738087, 0.4511007100522697, 0.44394831108796345, 0.4715007261649982, 0.4673421669292753, 0.4734393967708484, 0.4653923343251775, 0.46223784542104407, 0.43232714360182706, 0.44526313698154135, 0.4547461156534764, 0.4669303405616019, 0.433365432126028, 0.16217514288027185, 0.47679905944668854, 0.4652843908504681, 0.46696457184025136, 0.4388333420093842, 0.4447620569003953, 0.46402986343200503, 0.4651242449834898, 0.4694487668529108, 0.4744728295693026, 0.4663514222066725, 0.43813173896870816, 0.4510415918911013, 0.475714210428691, 0.39507657121699136, 0.4531641075717615, 0.4691441372797654, 0.46854544777770546, 0.4624065046286195, 0.46282975176522684, 0.46242476326298787, 0.3751298798634125, 0.46892635815136424, 0.47270560639913195, 0.46347554314422895, 0.47109199402568575, 0.45397429736806555, 0.4499061798330772, 0.46156157401051967, 0.4677351163077943, 0.4552854292721183, 0.46966562153877794, 0.46971330340873374, 0.4643561250275678, 0.46855995314078286, 0.46835847836625466, 0.46847214381042296, 0.4697522261911862, 0.4738245615943687, 0.47185717050462067, 0.46891761574525015, 0.46717707146037446], 'loss': [0.0931062306436567, 0.06289957914058916, 0.05605192273868454, 0.05175737298811726, 0.04760478669390225, 0.0483429065275386, 0.04296214932105283, 0.04262402357298127, 0.0412155866876465, 0.04057213221116411, 0.03964320228944604, 0.036882352004217106, 0.0381459898399509, 0.034735169795027054, 0.03619683608029594, 0.03603750629547202, 0.0346848932289107, 0.034860199277956944, 0.03340256857736536, 0.03469070592487996, 0.03415877401211944, 0.03333377470785334, 0.03505583812842921, 0.03266818696457608, 0.03166942895650788, 0.03198727288554036, 0.03185022728918893, 0.032001252014798504, 0.030292301495925454, 0.030766025233833337, 0.03033925829789092, 0.029792224930041283, 0.029469032212595177, 0.030605352187518444, 0.029682111860449282, 0.029805618771280032, 0.033757649130779145, 0.030469513059222474, 0.02924430288497883, 0.0295021035683949, 0.02919455692261925, 0.02889041463164449, 0.02935102437611315, 0.028957017776920835, 0.02904549442289837, 0.02856788491511767, 0.028458454984913523, 0.027172559466061383, 0.026476262096495607, 0.02603539331879936, 0.02653580305160216, 0.026244553162797158, 0.025951833733414312, 0.026207929455691326, 0.02557229189413039, 0.025795093651393368, 0.02542874896483197, 0.025919027241000932, 0.024671749071419165, 0.0253367826827904, 0.025022118608199726, 0.0251820426788809, 0.024574340538300148, 0.024295396734348107, 0.0241251562806994, 0.023879882540220564, 0.02383761449254783, 0.02395668839637866, 0.023558859173952302, 0.023914677913351955, 0.023089579558131824, 0.02323004108982596], 'acc': [0.9897881466035623, 0.9932782854604597, 0.9939190338592016, 0.9943639319644308, 0.9947499518590945, 0.994734369897137, 0.9950783850314027, 0.9951736982357207, 0.9952949326679098, 0.99535315491708, 0.9954117993257681, 0.9956130876699165, 0.9955673774388712, 0.9957487495594438, 0.9957440826720445, 0.9957311336944674, 0.9958511166221096, 0.995848167000116, 0.9959207067420903, 0.9958738757348364, 0.9959331122203657, 0.9959993164135641, 0.9958754873458912, 0.9960100448712055, 0.9960792493944312, 0.9960749662154803, 0.996095101198812, 0.9960860200370579, 0.9961887168608788, 0.9961653038529198, 0.9961996164770552, 0.9962197452581131, 0.996206778218637, 0.9962097678469988, 0.996232460335424, 0.9962826717104974, 0.9959746927096725, 0.9962168618630821, 0.996348632993293, 0.9963185154712811, 0.9963060081001313, 0.9963418978803477, 0.9963214994498597, 0.9963948959721799, 0.9963722066057046, 0.9963907548097813, 0.9963699623248924, 0.9965106918163795, 0.9965295137870759, 0.9965199506605975, 0.9965393804162731, 0.9965814925111988, 0.9965986625541695, 0.9965787299072453, 0.9966077023169766, 0.9966044545317444, 0.9966261594547225, 0.9966072926339055, 0.9966224805263253, 0.9966312215431298, 0.9966465470586668, 0.9966425278036793, 0.996698328187962, 0.9967146522998356, 0.9967003052185153, 0.9967164199705404, 0.996725481121542, 0.9967149303123071, 0.9967380749952996, 0.996735287135718, 0.9967401621114805, 0.9967388853588738], 'mDice': [0.8191307357000911, 0.8776557426745897, 0.8910057002870206, 0.8993511358962484, 0.9074400391936507, 0.905971165019651, 0.9165451043789731, 0.917167679373177, 0.9199152862175738, 0.9211677752980839, 0.9229965117172804, 0.9284051491846229, 0.9259032459684678, 0.9326214348768085, 0.929710330580781, 0.9300255912596417, 0.9326640143257331, 0.9323199728399049, 0.9351902591236871, 0.932646211075651, 0.9336743482286443, 0.9352891980318877, 0.931907604112119, 0.9366113256064, 0.9385707966979061, 0.9379322648721985, 0.9381992552410753, 0.9379053834839235, 0.9412665575559189, 0.9403292995491873, 0.9411626809340085, 0.9422465831345963, 0.9428983235667981, 0.9406262052663886, 0.9424549849038957, 0.9421818851644134, 0.9344691727893965, 0.940893996738947, 0.9432691627627713, 0.9427687468305329, 0.9433955433603151, 0.9439881340366463, 0.9430673622977551, 0.943826713332539, 0.9436684838552852, 0.944602272713512, 0.9448226176341957, 0.9473251581955551, 0.9486935970995299, 0.9495799123624054, 0.9485721324831408, 0.9491301290527706, 0.9497120849488766, 0.9492115923037083, 0.9504577562654747, 0.9500205597796673, 0.950739725522636, 0.949759909470311, 0.9522520093212172, 0.9509171445319315, 0.9515401821092275, 0.9512221426080124, 0.9524045076856734, 0.9529522823444299, 0.9532980601467123, 0.9537774671804987, 0.9538588219505227, 0.9536229159517516, 0.9544100730761703, 0.9536924740449413, 0.9553436425880935, 0.9550557040568799], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.18it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:01,  1.51it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.78it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.04it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.42it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.54it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:37,  6.48it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:37,  6.60it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:37,  6.56it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:37,  6.41it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:37,  6.38it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:37,  6.42it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:36,  6.51it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:36,  6.58it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:35,  6.64it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:35,  6.67it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:35,  6.65it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:35,  6.63it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:35,  6.62it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.62it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:35,  6.55it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:35,  6.58it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:34,  6.59it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:34,  6.58it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:34,  6.61it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:34,  6.59it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.58it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:34,  6.60it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.70it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:33,  6.73it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:32,  6.76it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:32,  6.82it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:32,  6.87it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:31,  6.89it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:31,  6.93it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:31,  6.90it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:31,  6.87it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:31,  6.91it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:31,  6.88it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:30,  6.91it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:30,  6.92it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:30,  6.90it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:30,  6.92it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:30,  6.95it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:30,  6.92it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:31,  6.55it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:30,  6.65it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:30,  6.74it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:29,  6.83it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:29,  6.89it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.89it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:29,  6.92it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:28,  6.93it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:28,  6.94it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:28,  6.97it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:28,  7.00it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:27,  7.00it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:27,  7.01it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:27,  7.02it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:27,  6.95it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:27,  6.89it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:27,  6.89it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:27,  6.90it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:27,  6.82it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:27,  6.72it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:28,  6.63it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:28,  6.62it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:27,  6.63it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:27,  6.64it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:27,  6.61it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:27,  6.59it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:27,  6.57it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:27,  6.54it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:27,  6.57it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:27,  6.50it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.45it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.48it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:26,  6.50it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:26,  6.46it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:26,  6.48it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:27,  6.36it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:26,  6.37it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:34,  4.89it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:36,  4.57it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:33,  4.96it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:37,  4.47it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:33,  4.97it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:32,  5.15it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:29,  5.55it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:27,  5.83it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:27,  5.93it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:26,  6.03it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:25,  6.16it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:25,  6.34it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:25,  6.29it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:24,  6.41it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:23,  6.52it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:23,  6.59it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:23,  6.59it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:23,  6.63it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:23,  6.60it/s]predicting train subjects:  39%|███▉      | 96/247 [00:14<00:22,  6.64it/s]predicting train subjects:  39%|███▉      | 97/247 [00:14<00:22,  6.68it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:22,  6.62it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:22,  6.66it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:23,  6.27it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:24,  6.04it/s]predicting train subjects:  41%|████▏     | 102/247 [00:15<00:24,  5.94it/s]predicting train subjects:  42%|████▏     | 103/247 [00:15<00:24,  5.88it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:24,  5.83it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:24,  5.78it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:24,  5.77it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:24,  5.77it/s]predicting train subjects:  44%|████▎     | 108/247 [00:16<00:24,  5.77it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:23,  5.78it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:23,  5.78it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:23,  5.77it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:23,  5.76it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:23,  5.76it/s]predicting train subjects:  46%|████▌     | 114/247 [00:17<00:23,  5.76it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:22,  5.78it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:22,  5.78it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:22,  5.78it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:21,  5.92it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:21,  6.03it/s]predicting train subjects:  49%|████▊     | 120/247 [00:18<00:20,  6.11it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:20,  6.09it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:20,  6.14it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:20,  6.12it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:20,  6.10it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:20,  6.05it/s]predicting train subjects:  51%|█████     | 126/247 [00:19<00:19,  6.10it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:19,  6.11it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:19,  6.16it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:19,  6.18it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:20<00:18,  6.22it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:18,  6.21it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:18,  6.18it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:20<00:18,  6.20it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:18,  6.21it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:17,  6.24it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:16,  6.62it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:21<00:15,  6.91it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:15,  7.10it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:21<00:14,  7.27it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:21<00:14,  7.36it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:14,  7.32it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:14,  7.40it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:13,  7.47it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:22<00:14,  7.34it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:13,  7.40it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:22<00:13,  7.47it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:22<00:13,  7.49it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:13,  7.53it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:13,  7.51it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:12,  7.57it/s]predicting train subjects:  61%|██████    | 151/247 [00:23<00:12,  7.61it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:12,  7.61it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:23<00:12,  7.59it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:23<00:12,  7.36it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:23<00:12,  7.18it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:12,  7.06it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:24<00:12,  6.96it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:24<00:12,  6.93it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:24<00:12,  6.94it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:24<00:12,  6.95it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:24<00:12,  6.95it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:24<00:12,  6.96it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:25<00:12,  6.97it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:25<00:11,  6.95it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:25<00:11,  6.96it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:25<00:11,  6.94it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:25<00:11,  6.94it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:25<00:11,  6.95it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:11,  6.91it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:26<00:11,  6.88it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:26<00:11,  6.90it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:26<00:10,  6.88it/s]predicting train subjects:  70%|███████   | 173/247 [00:26<00:14,  5.18it/s]predicting train subjects:  70%|███████   | 174/247 [00:26<00:13,  5.59it/s]predicting train subjects:  71%|███████   | 175/247 [00:27<00:13,  5.20it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:27<00:12,  5.58it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:27<00:11,  5.88it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:27<00:11,  6.15it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:27<00:10,  6.35it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:27<00:10,  6.51it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:27<00:10,  6.58it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:28<00:09,  6.68it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:28<00:09,  6.74it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:28<00:09,  6.72it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:28<00:09,  6.42it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:28<00:09,  6.50it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:28<00:09,  6.58it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:29<00:08,  6.64it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:29<00:08,  6.67it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:29<00:08,  6.69it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:29<00:08,  6.73it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:29<00:08,  6.77it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:29<00:07,  6.77it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:29<00:07,  6.89it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:30<00:07,  6.92it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:30<00:07,  6.96it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:30<00:07,  7.02it/s]predicting train subjects:  80%|████████  | 198/247 [00:30<00:07,  6.96it/s]predicting train subjects:  81%|████████  | 199/247 [00:30<00:06,  6.98it/s]predicting train subjects:  81%|████████  | 200/247 [00:30<00:06,  7.06it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:30<00:06,  7.10it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:31<00:06,  7.12it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:31<00:06,  7.09it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:31<00:06,  7.06it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:31<00:05,  7.06it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:31<00:05,  7.05it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:31<00:05,  7.02it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:31<00:05,  6.95it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:32<00:05,  6.93it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:32<00:05,  6.97it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:32<00:05,  6.92it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:32<00:05,  6.87it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:32<00:04,  6.85it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:32<00:04,  6.84it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:32<00:04,  6.83it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  6.83it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:33<00:04,  6.87it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:33<00:04,  6.89it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:33<00:04,  6.93it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:33<00:03,  6.88it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:33<00:03,  6.90it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:33<00:03,  6.89it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  6.90it/s]predicting train subjects:  91%|█████████ | 224/247 [00:34<00:03,  6.92it/s]predicting train subjects:  91%|█████████ | 225/247 [00:34<00:03,  6.94it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:34<00:03,  6.93it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:34<00:02,  6.96it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:34<00:02,  6.97it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:34<00:02,  6.96it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:02,  6.66it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:35<00:02,  6.47it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:35<00:02,  6.32it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:35<00:02,  6.23it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:35<00:02,  6.13it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:35<00:01,  6.06it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:01,  6.02it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:36<00:01,  6.00it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:36<00:01,  6.02it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:36<00:01,  6.04it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:36<00:01,  6.05it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:36<00:01,  5.96it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:37<00:00,  5.87it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:37<00:00,  5.75it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:37<00:00,  5.80it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:37<00:00,  5.85it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:37<00:00,  5.88it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  5.94it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  6.50it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  5.62it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  5.65it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  5.97it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  6.18it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.05it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.10it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:38,  6.46it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:37,  6.60it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:36,  6.73it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:36,  6.59it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:36,  6.62it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:36,  6.66it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:36,  6.66it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:36,  6.63it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:36,  6.58it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:37,  6.31it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:36,  6.40it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:36,  6.51it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:36,  6.38it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:36,  6.47it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:35,  6.53it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:36,  6.38it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:36,  6.34it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:35,  6.39it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:35,  6.49it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:35,  6.40it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:34,  6.48it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:34,  6.54it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:03<00:33,  6.68it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:32,  6.77it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:32,  6.83it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:32,  6.86it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:31,  6.90it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:31,  6.88it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:04<00:32,  6.71it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:04<00:32,  6.77it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:04<00:31,  6.80it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:04<00:31,  6.85it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:04<00:31,  6.85it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:05<00:30,  6.88it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:05<00:30,  6.90it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:05<00:30,  6.93it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:05<00:30,  6.88it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:05<00:30,  6.91it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:05<00:31,  6.65it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:06<00:30,  6.68it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:06<00:31,  6.57it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:06<00:31,  6.51it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:06<00:30,  6.64it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:06<00:30,  6.76it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:06<00:29,  6.77it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:06<00:29,  6.76it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:07<00:29,  6.80it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:07<00:29,  6.80it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:07<00:28,  6.86it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:07<00:28,  6.90it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:07<00:30,  6.47it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:07<00:30,  6.49it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:07<00:29,  6.59it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:08<00:28,  6.70it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:08<00:28,  6.77it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:08<00:28,  6.70it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:08<00:28,  6.78it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:08<00:27,  6.82it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:08<00:27,  6.72it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:08<00:28,  6.63it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:09<00:28,  6.60it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:09<00:28,  6.56it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:09<00:28,  6.56it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:09<00:27,  6.55it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:09<00:27,  6.52it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:09<00:27,  6.52it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:10<00:27,  6.52it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:10<00:27,  6.45it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:10<00:27,  6.47it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:10<00:27,  6.50it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:10<00:27,  6.51it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:10<00:26,  6.52it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:10<00:26,  6.54it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:11<00:26,  6.51it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:11<00:26,  6.51it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:11<00:26,  6.51it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:11<00:25,  6.57it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:11<00:27,  6.22it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:11<00:27,  6.20it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:12<00:25,  6.53it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:12<00:25,  6.57it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:12<00:24,  6.64it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:12<00:24,  6.70it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:12<00:24,  6.74it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:12<00:24,  6.73it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:12<00:23,  6.73it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:13<00:23,  6.76it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:13<00:23,  6.79it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:13<00:23,  6.80it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:13<00:23,  6.77it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:13<00:23,  6.76it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:13<00:22,  6.78it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:14<00:22,  6.79it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:14<00:22,  6.71it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:14<00:22,  6.67it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:14<00:22,  6.69it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:14<00:22,  6.73it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:14<00:22,  6.74it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:14<00:21,  6.75it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:15<00:23,  6.33it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:15<00:23,  6.09it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:15<00:25,  5.73it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:15<00:25,  5.72it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:15<00:24,  5.74it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:15<00:24,  5.75it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:16<00:24,  5.73it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:16<00:24,  5.74it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:16<00:24,  5.75it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:16<00:23,  5.76it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:16<00:23,  5.75it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:17<00:23,  5.74it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:17<00:23,  5.75it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:17<00:23,  5.74it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:17<00:24,  5.35it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:17<00:24,  5.43it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:17<00:23,  5.52it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:18<00:23,  5.48it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:18<00:22,  5.68it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:18<00:21,  5.84it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:18<00:21,  5.97it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:18<00:20,  6.09it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:18<00:20,  6.02it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:19<00:20,  6.08it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:19<00:20,  6.09it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:19<00:19,  6.12it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:19<00:19,  6.13it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:19<00:19,  6.17it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:19<00:19,  6.19it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:20<00:19,  6.20it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:20<00:18,  6.22it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:20<00:18,  6.23it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:20<00:18,  6.24it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:20<00:18,  6.23it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:20<00:18,  6.25it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:21<00:17,  6.28it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:21<00:16,  6.66it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:21<00:16,  6.87it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:21<00:15,  7.09it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:21<00:14,  7.28it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:21<00:14,  7.40it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:21<00:14,  7.43it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:21<00:14,  7.49it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:22<00:13,  7.57it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:22<00:13,  7.61it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:22<00:13,  7.65it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:22<00:13,  7.67it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:22<00:12,  7.70it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:22<00:12,  7.71it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:22<00:12,  7.64it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:22<00:12,  7.66it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:23<00:12,  7.70it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:23<00:12,  7.69it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:23<00:12,  7.64it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:23<00:12,  7.38it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:23<00:12,  7.21it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:23<00:12,  7.09it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:23<00:12,  6.96it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:24<00:12,  6.93it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:24<00:12,  6.90it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:24<00:12,  6.92it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:24<00:12,  6.89it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:24<00:12,  6.81it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:24<00:12,  6.83it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:24<00:12,  6.87it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:25<00:11,  6.90it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:25<00:11,  6.89it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:25<00:11,  6.87it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:25<00:11,  6.89it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:25<00:11,  6.89it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:25<00:12,  6.41it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:26<00:11,  6.57it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:26<00:11,  6.65it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:26<00:10,  6.76it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:26<00:10,  6.73it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:26<00:11,  6.51it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:26<00:10,  6.59it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:26<00:10,  6.66it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:27<00:10,  6.72it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:27<00:10,  6.74it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:27<00:09,  6.75it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:27<00:09,  6.78it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:27<00:09,  6.77it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:27<00:09,  6.69it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:27<00:09,  6.72it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:28<00:09,  6.74it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:28<00:09,  6.76it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:28<00:08,  6.79it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:28<00:08,  6.82it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:28<00:08,  6.83it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:28<00:08,  6.83it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:28<00:08,  6.84it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:29<00:08,  6.82it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:29<00:07,  6.81it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:29<00:07,  6.91it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:29<00:07,  7.02it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:29<00:07,  6.89it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:29<00:07,  6.96it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:29<00:06,  7.00it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:30<00:06,  7.04it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:30<00:06,  6.90it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:30<00:06,  6.95it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:30<00:06,  7.02it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:30<00:06,  7.04it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:30<00:06,  7.00it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:30<00:06,  6.95it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:31<00:05,  6.95it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:31<00:05,  6.98it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:31<00:05,  7.01it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:31<00:05,  7.03it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:31<00:05,  7.02it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:31<00:05,  7.04it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:31<00:05,  6.94it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:32<00:04,  6.89it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:32<00:04,  6.89it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:32<00:04,  6.85it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:32<00:04,  6.79it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:32<00:04,  6.79it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:32<00:04,  6.79it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:33<00:04,  6.79it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:33<00:04,  6.65it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:33<00:03,  6.68it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:33<00:03,  6.71it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:33<00:03,  6.73it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:33<00:03,  6.76it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:33<00:03,  6.78it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:34<00:03,  6.82it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:34<00:02,  6.84it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:34<00:02,  6.86it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:34<00:02,  6.89it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:34<00:02,  6.56it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:34<00:02,  6.35it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:35<00:02,  6.21it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:35<00:02,  6.08it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:35<00:02,  6.05it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:35<00:02,  5.99it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:35<00:01,  6.00it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:35<00:01,  5.98it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:36<00:01,  5.95it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:36<00:01,  5.98it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:36<00:01,  5.98it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:36<00:01,  5.85it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:36<00:00,  5.87it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:36<00:00,  5.77it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:37<00:00,  5.82it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:37<00:00,  5.87it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:37<00:00,  5.88it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:37<00:00,  5.88it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:37<00:00,  6.58it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 70.79it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 85.09it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 84.16it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 84.61it/s]saving BB  train1-THALAMUS:  15%|█▍        | 37/247 [00:00<00:02, 87.29it/s]saving BB  train1-THALAMUS:  19%|█▉        | 47/247 [00:00<00:02, 88.80it/s]saving BB  train1-THALAMUS:  23%|██▎       | 57/247 [00:00<00:02, 90.57it/s]saving BB  train1-THALAMUS:  27%|██▋       | 66/247 [00:00<00:02, 87.54it/s]saving BB  train1-THALAMUS:  30%|███       | 75/247 [00:00<00:01, 86.82it/s]saving BB  train1-THALAMUS:  34%|███▍      | 84/247 [00:00<00:01, 86.58it/s]saving BB  train1-THALAMUS:  38%|███▊      | 93/247 [00:01<00:01, 84.85it/s]saving BB  train1-THALAMUS:  41%|████▏     | 102/247 [00:01<00:01, 83.22it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 82.70it/s]saving BB  train1-THALAMUS:  49%|████▊     | 120/247 [00:01<00:01, 81.52it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 129/247 [00:01<00:01, 80.20it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 79.35it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 146/247 [00:01<00:01, 81.89it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 156/247 [00:01<00:01, 84.74it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 166/247 [00:01<00:00, 87.10it/s]saving BB  train1-THALAMUS:  71%|███████   | 175/247 [00:02<00:00, 87.01it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 184/247 [00:02<00:00, 85.13it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 193/247 [00:02<00:00, 84.13it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 202/247 [00:02<00:00, 84.40it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 211/247 [00:02<00:00, 85.23it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 220/247 [00:02<00:00, 86.52it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 230/247 [00:02<00:00, 87.57it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 239/247 [00:02<00:00, 85.24it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:02<00:00, 85.12it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 74.06it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 87.67it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 87.22it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 87.79it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 37/247 [00:00<00:02, 89.25it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▉        | 47/247 [00:00<00:02, 90.60it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 57/247 [00:00<00:02, 90.45it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 66/247 [00:00<00:02, 88.43it/s]saving BB  train1-THALAMUS Sagittal:  30%|███       | 75/247 [00:00<00:01, 87.57it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▍      | 84/247 [00:00<00:01, 86.27it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 93/247 [00:01<00:01, 84.35it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 102/247 [00:01<00:01, 82.55it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 111/247 [00:01<00:01, 80.42it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 119/247 [00:01<00:01, 79.55it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████▏    | 127/247 [00:01<00:01, 79.03it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 135/247 [00:01<00:01, 78.21it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▊    | 145/247 [00:01<00:01, 82.33it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 155/247 [00:01<00:01, 85.60it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 165/247 [00:01<00:00, 87.58it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 174/247 [00:02<00:00, 87.99it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 183/247 [00:02<00:00, 85.25it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 192/247 [00:02<00:00, 83.67it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████▏ | 201/247 [00:02<00:00, 83.79it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 210/247 [00:02<00:00, 84.58it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▊ | 219/247 [00:02<00:00, 84.51it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 229/247 [00:02<00:00, 86.68it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▋| 238/247 [00:02<00:00, 81.49it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 79.65it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 84.36it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:25,  1.20it/s]Loading train:   1%|          | 2/247 [00:01<03:14,  1.26it/s]Loading train:   1%|          | 3/247 [00:02<03:07,  1.30it/s]Loading train:   2%|▏         | 4/247 [00:03<03:11,  1.27it/s]Loading train:   2%|▏         | 5/247 [00:03<02:49,  1.43it/s]Loading train:   2%|▏         | 6/247 [00:04<02:34,  1.56it/s]Loading train:   3%|▎         | 7/247 [00:04<02:22,  1.68it/s]Loading train:   3%|▎         | 8/247 [00:05<02:15,  1.76it/s]Loading train:   4%|▎         | 9/247 [00:05<02:10,  1.83it/s]Loading train:   4%|▍         | 10/247 [00:06<02:06,  1.87it/s]Loading train:   4%|▍         | 11/247 [00:06<02:04,  1.89it/s]Loading train:   5%|▍         | 12/247 [00:07<02:04,  1.89it/s]Loading train:   5%|▌         | 13/247 [00:07<02:01,  1.92it/s]Loading train:   6%|▌         | 14/247 [00:08<01:58,  1.96it/s]Loading train:   6%|▌         | 15/247 [00:08<01:58,  1.96it/s]Loading train:   6%|▋         | 16/247 [00:09<01:55,  2.00it/s]Loading train:   7%|▋         | 17/247 [00:09<01:54,  2.01it/s]Loading train:   7%|▋         | 18/247 [00:10<01:54,  2.01it/s]Loading train:   8%|▊         | 19/247 [00:10<01:51,  2.04it/s]Loading train:   8%|▊         | 20/247 [00:11<01:50,  2.05it/s]Loading train:   9%|▊         | 21/247 [00:11<01:49,  2.05it/s]Loading train:   9%|▉         | 22/247 [00:12<01:49,  2.05it/s]Loading train:   9%|▉         | 23/247 [00:12<01:47,  2.09it/s]Loading train:  10%|▉         | 24/247 [00:12<01:47,  2.08it/s]Loading train:  10%|█         | 25/247 [00:13<01:45,  2.10it/s]Loading train:  11%|█         | 26/247 [00:13<01:44,  2.11it/s]Loading train:  11%|█         | 27/247 [00:14<01:42,  2.14it/s]Loading train:  11%|█▏        | 28/247 [00:14<01:43,  2.12it/s]Loading train:  12%|█▏        | 29/247 [00:15<01:42,  2.13it/s]Loading train:  12%|█▏        | 30/247 [00:15<01:41,  2.14it/s]Loading train:  13%|█▎        | 31/247 [00:16<01:41,  2.14it/s]Loading train:  13%|█▎        | 32/247 [00:16<01:42,  2.10it/s]Loading train:  13%|█▎        | 33/247 [00:17<01:41,  2.11it/s]Loading train:  14%|█▍        | 34/247 [00:17<01:45,  2.02it/s]Loading train:  14%|█▍        | 35/247 [00:18<01:43,  2.06it/s]Loading train:  15%|█▍        | 36/247 [00:18<01:40,  2.10it/s]Loading train:  15%|█▍        | 37/247 [00:19<01:37,  2.15it/s]Loading train:  15%|█▌        | 38/247 [00:19<01:38,  2.13it/s]Loading train:  16%|█▌        | 39/247 [00:20<01:38,  2.10it/s]Loading train:  16%|█▌        | 40/247 [00:20<01:38,  2.09it/s]Loading train:  17%|█▋        | 41/247 [00:20<01:37,  2.12it/s]Loading train:  17%|█▋        | 42/247 [00:21<01:36,  2.13it/s]Loading train:  17%|█▋        | 43/247 [00:21<01:35,  2.14it/s]Loading train:  18%|█▊        | 44/247 [00:22<01:33,  2.16it/s]Loading train:  18%|█▊        | 45/247 [00:22<01:32,  2.18it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:31,  2.20it/s]Loading train:  19%|█▉        | 47/247 [00:23<01:30,  2.20it/s]Loading train:  19%|█▉        | 48/247 [00:24<01:30,  2.21it/s]Loading train:  20%|█▉        | 49/247 [00:24<01:31,  2.17it/s]Loading train:  20%|██        | 50/247 [00:25<01:30,  2.17it/s]Loading train:  21%|██        | 51/247 [00:25<01:30,  2.17it/s]Loading train:  21%|██        | 52/247 [00:26<01:29,  2.18it/s]Loading train:  21%|██▏       | 53/247 [00:26<01:28,  2.18it/s]Loading train:  22%|██▏       | 54/247 [00:26<01:29,  2.16it/s]Loading train:  22%|██▏       | 55/247 [00:27<01:28,  2.18it/s]Loading train:  23%|██▎       | 56/247 [00:27<01:27,  2.19it/s]Loading train:  23%|██▎       | 57/247 [00:28<01:27,  2.18it/s]Loading train:  23%|██▎       | 58/247 [00:28<01:27,  2.16it/s]Loading train:  24%|██▍       | 59/247 [00:29<01:33,  2.01it/s]Loading train:  24%|██▍       | 60/247 [00:29<01:35,  1.95it/s]Loading train:  25%|██▍       | 61/247 [00:30<01:36,  1.93it/s]Loading train:  25%|██▌       | 62/247 [00:30<01:37,  1.90it/s]Loading train:  26%|██▌       | 63/247 [00:31<01:37,  1.89it/s]Loading train:  26%|██▌       | 64/247 [00:32<01:37,  1.88it/s]Loading train:  26%|██▋       | 65/247 [00:32<01:37,  1.87it/s]Loading train:  27%|██▋       | 66/247 [00:33<01:36,  1.87it/s]Loading train:  27%|██▋       | 67/247 [00:33<01:37,  1.84it/s]Loading train:  28%|██▊       | 68/247 [00:34<01:37,  1.84it/s]Loading train:  28%|██▊       | 69/247 [00:34<01:36,  1.85it/s]Loading train:  28%|██▊       | 70/247 [00:35<01:35,  1.86it/s]Loading train:  29%|██▊       | 71/247 [00:35<01:34,  1.86it/s]Loading train:  29%|██▉       | 72/247 [00:36<01:35,  1.84it/s]Loading train:  30%|██▉       | 73/247 [00:36<01:34,  1.84it/s]Loading train:  30%|██▉       | 74/247 [00:37<01:33,  1.85it/s]Loading train:  30%|███       | 75/247 [00:38<01:32,  1.85it/s]Loading train:  31%|███       | 76/247 [00:38<01:31,  1.87it/s]Loading train:  31%|███       | 77/247 [00:39<01:43,  1.65it/s]Loading train:  32%|███▏      | 78/247 [00:40<01:55,  1.46it/s]Loading train:  32%|███▏      | 79/247 [00:40<02:01,  1.39it/s]Loading train:  32%|███▏      | 80/247 [00:41<01:56,  1.43it/s]Loading train:  33%|███▎      | 81/247 [00:42<01:57,  1.42it/s]Loading train:  33%|███▎      | 82/247 [00:42<01:46,  1.55it/s]Loading train:  34%|███▎      | 83/247 [00:43<01:38,  1.66it/s]Loading train:  34%|███▍      | 84/247 [00:43<01:34,  1.72it/s]Loading train:  34%|███▍      | 85/247 [00:44<01:31,  1.77it/s]Loading train:  35%|███▍      | 86/247 [00:44<01:29,  1.80it/s]Loading train:  35%|███▌      | 87/247 [00:45<01:27,  1.82it/s]Loading train:  36%|███▌      | 88/247 [00:45<01:25,  1.86it/s]Loading train:  36%|███▌      | 89/247 [00:46<01:23,  1.89it/s]Loading train:  36%|███▋      | 90/247 [00:47<01:22,  1.90it/s]Loading train:  37%|███▋      | 91/247 [00:47<01:20,  1.93it/s]Loading train:  37%|███▋      | 92/247 [00:48<01:19,  1.95it/s]Loading train:  38%|███▊      | 93/247 [00:48<01:19,  1.94it/s]Loading train:  38%|███▊      | 94/247 [00:49<01:18,  1.94it/s]Loading train:  38%|███▊      | 95/247 [00:49<01:18,  1.94it/s]Loading train:  39%|███▉      | 96/247 [00:50<01:16,  1.98it/s]Loading train:  39%|███▉      | 97/247 [00:50<01:16,  1.97it/s]Loading train:  40%|███▉      | 98/247 [00:51<01:16,  1.96it/s]Loading train:  40%|████      | 99/247 [00:51<01:14,  2.00it/s]Loading train:  40%|████      | 100/247 [00:52<01:15,  1.96it/s]Loading train:  41%|████      | 101/247 [00:52<01:15,  1.93it/s]Loading train:  41%|████▏     | 102/247 [00:53<01:16,  1.90it/s]Loading train:  42%|████▏     | 103/247 [00:53<01:16,  1.88it/s]Loading train:  42%|████▏     | 104/247 [00:54<01:16,  1.87it/s]Loading train:  43%|████▎     | 105/247 [00:54<01:16,  1.86it/s]Loading train:  43%|████▎     | 106/247 [00:55<01:15,  1.87it/s]Loading train:  43%|████▎     | 107/247 [00:55<01:14,  1.88it/s]Loading train:  44%|████▎     | 108/247 [00:56<01:14,  1.87it/s]Loading train:  44%|████▍     | 109/247 [00:56<01:14,  1.85it/s]Loading train:  45%|████▍     | 110/247 [00:57<01:15,  1.82it/s]Loading train:  45%|████▍     | 111/247 [00:58<01:13,  1.85it/s]Loading train:  45%|████▌     | 112/247 [00:58<01:12,  1.87it/s]Loading train:  46%|████▌     | 113/247 [00:59<01:12,  1.86it/s]Loading train:  46%|████▌     | 114/247 [00:59<01:11,  1.87it/s]Loading train:  47%|████▋     | 115/247 [01:00<01:10,  1.88it/s]Loading train:  47%|████▋     | 116/247 [01:00<01:09,  1.88it/s]Loading train:  47%|████▋     | 117/247 [01:01<01:09,  1.87it/s]Loading train:  48%|████▊     | 118/247 [01:01<01:10,  1.84it/s]Loading train:  48%|████▊     | 119/247 [01:02<01:10,  1.82it/s]Loading train:  49%|████▊     | 120/247 [01:02<01:10,  1.81it/s]Loading train:  49%|████▉     | 121/247 [01:03<01:10,  1.79it/s]Loading train:  49%|████▉     | 122/247 [01:04<01:11,  1.75it/s]Loading train:  50%|████▉     | 123/247 [01:04<01:10,  1.77it/s]Loading train:  50%|█████     | 124/247 [01:05<01:09,  1.77it/s]Loading train:  51%|█████     | 125/247 [01:05<01:08,  1.78it/s]Loading train:  51%|█████     | 126/247 [01:06<01:09,  1.75it/s]Loading train:  51%|█████▏    | 127/247 [01:06<01:08,  1.75it/s]Loading train:  52%|█████▏    | 128/247 [01:07<01:07,  1.76it/s]Loading train:  52%|█████▏    | 129/247 [01:08<01:06,  1.78it/s]Loading train:  53%|█████▎    | 130/247 [01:08<01:06,  1.76it/s]Loading train:  53%|█████▎    | 131/247 [01:09<01:05,  1.78it/s]Loading train:  53%|█████▎    | 132/247 [01:09<01:04,  1.78it/s]Loading train:  54%|█████▍    | 133/247 [01:10<01:04,  1.75it/s]Loading train:  54%|█████▍    | 134/247 [01:10<01:04,  1.76it/s]Loading train:  55%|█████▍    | 135/247 [01:11<01:03,  1.76it/s]Loading train:  55%|█████▌    | 136/247 [01:11<01:00,  1.83it/s]Loading train:  55%|█████▌    | 137/247 [01:12<00:57,  1.91it/s]Loading train:  56%|█████▌    | 138/247 [01:12<00:55,  1.97it/s]Loading train:  56%|█████▋    | 139/247 [01:13<00:54,  1.99it/s]Loading train:  57%|█████▋    | 140/247 [01:13<00:52,  2.02it/s]Loading train:  57%|█████▋    | 141/247 [01:14<00:51,  2.07it/s]Loading train:  57%|█████▋    | 142/247 [01:14<00:50,  2.09it/s]Loading train:  58%|█████▊    | 143/247 [01:15<00:49,  2.10it/s]Loading train:  58%|█████▊    | 144/247 [01:15<00:49,  2.09it/s]Loading train:  59%|█████▊    | 145/247 [01:16<00:48,  2.12it/s]Loading train:  59%|█████▉    | 146/247 [01:16<00:47,  2.12it/s]Loading train:  60%|█████▉    | 147/247 [01:17<00:46,  2.15it/s]Loading train:  60%|█████▉    | 148/247 [01:17<00:45,  2.16it/s]Loading train:  60%|██████    | 149/247 [01:18<00:45,  2.17it/s]Loading train:  61%|██████    | 150/247 [01:18<00:44,  2.19it/s]Loading train:  61%|██████    | 151/247 [01:18<00:44,  2.16it/s]Loading train:  62%|██████▏   | 152/247 [01:19<00:43,  2.18it/s]Loading train:  62%|██████▏   | 153/247 [01:19<00:42,  2.21it/s]Loading train:  62%|██████▏   | 154/247 [01:20<00:42,  2.17it/s]Loading train:  63%|██████▎   | 155/247 [01:20<00:41,  2.20it/s]Loading train:  63%|██████▎   | 156/247 [01:21<00:40,  2.23it/s]Loading train:  64%|██████▎   | 157/247 [01:21<00:40,  2.22it/s]Loading train:  64%|██████▍   | 158/247 [01:22<00:42,  2.11it/s]Loading train:  64%|██████▍   | 159/247 [01:22<00:41,  2.14it/s]Loading train:  65%|██████▍   | 160/247 [01:23<00:40,  2.15it/s]Loading train:  65%|██████▌   | 161/247 [01:23<00:40,  2.13it/s]Loading train:  66%|██████▌   | 162/247 [01:24<00:40,  2.10it/s]Loading train:  66%|██████▌   | 163/247 [01:24<00:40,  2.08it/s]Loading train:  66%|██████▋   | 164/247 [01:25<00:40,  2.07it/s]Loading train:  67%|██████▋   | 165/247 [01:25<00:40,  2.02it/s]Loading train:  67%|██████▋   | 166/247 [01:26<00:39,  2.04it/s]Loading train:  68%|██████▊   | 167/247 [01:26<00:38,  2.06it/s]Loading train:  68%|██████▊   | 168/247 [01:27<00:38,  2.07it/s]Loading train:  68%|██████▊   | 169/247 [01:27<00:38,  2.05it/s]Loading train:  69%|██████▉   | 170/247 [01:27<00:36,  2.10it/s]Loading train:  69%|██████▉   | 171/247 [01:28<00:35,  2.11it/s]Loading train:  70%|██████▉   | 172/247 [01:29<00:42,  1.76it/s]Loading train:  70%|███████   | 173/247 [01:29<00:46,  1.60it/s]Loading train:  70%|███████   | 174/247 [01:30<00:47,  1.54it/s]Loading train:  71%|███████   | 175/247 [01:31<00:51,  1.41it/s]Loading train:  71%|███████▏  | 176/247 [01:32<00:46,  1.54it/s]Loading train:  72%|███████▏  | 177/247 [01:32<00:43,  1.63it/s]Loading train:  72%|███████▏  | 178/247 [01:33<00:40,  1.70it/s]Loading train:  72%|███████▏  | 179/247 [01:33<00:38,  1.75it/s]Loading train:  73%|███████▎  | 180/247 [01:34<00:37,  1.79it/s]Loading train:  73%|███████▎  | 181/247 [01:34<00:36,  1.82it/s]Loading train:  74%|███████▎  | 182/247 [01:35<00:36,  1.79it/s]Loading train:  74%|███████▍  | 183/247 [01:35<00:35,  1.82it/s]Loading train:  74%|███████▍  | 184/247 [01:36<00:33,  1.86it/s]Loading train:  75%|███████▍  | 185/247 [01:36<00:32,  1.89it/s]Loading train:  75%|███████▌  | 186/247 [01:37<00:31,  1.91it/s]Loading train:  76%|███████▌  | 187/247 [01:37<00:31,  1.90it/s]Loading train:  76%|███████▌  | 188/247 [01:38<00:31,  1.90it/s]Loading train:  77%|███████▋  | 189/247 [01:38<00:30,  1.91it/s]Loading train:  77%|███████▋  | 190/247 [01:39<00:30,  1.90it/s]Loading train:  77%|███████▋  | 191/247 [01:39<00:29,  1.91it/s]Loading train:  78%|███████▊  | 192/247 [01:40<00:28,  1.92it/s]Loading train:  78%|███████▊  | 193/247 [01:40<00:27,  1.94it/s]Loading train:  79%|███████▊  | 194/247 [01:41<00:27,  1.96it/s]Loading train:  79%|███████▉  | 195/247 [01:41<00:26,  1.98it/s]Loading train:  79%|███████▉  | 196/247 [01:42<00:25,  1.97it/s]Loading train:  80%|███████▉  | 197/247 [01:42<00:25,  1.98it/s]Loading train:  80%|████████  | 198/247 [01:43<00:24,  2.00it/s]Loading train:  81%|████████  | 199/247 [01:43<00:23,  2.02it/s]Loading train:  81%|████████  | 200/247 [01:44<00:23,  2.02it/s]Loading train:  81%|████████▏ | 201/247 [01:44<00:22,  2.03it/s]Loading train:  82%|████████▏ | 202/247 [01:45<00:22,  2.00it/s]Loading train:  82%|████████▏ | 203/247 [01:45<00:22,  1.98it/s]Loading train:  83%|████████▎ | 204/247 [01:46<00:21,  1.97it/s]Loading train:  83%|████████▎ | 205/247 [01:47<00:21,  1.95it/s]Loading train:  83%|████████▎ | 206/247 [01:47<00:21,  1.94it/s]Loading train:  84%|████████▍ | 207/247 [01:48<00:20,  1.95it/s]Loading train:  84%|████████▍ | 208/247 [01:48<00:19,  1.97it/s]Loading train:  85%|████████▍ | 209/247 [01:49<00:19,  1.95it/s]Loading train:  85%|████████▌ | 210/247 [01:49<00:18,  1.96it/s]Loading train:  85%|████████▌ | 211/247 [01:50<00:18,  1.96it/s]Loading train:  86%|████████▌ | 212/247 [01:50<00:18,  1.89it/s]Loading train:  86%|████████▌ | 213/247 [01:51<00:17,  1.89it/s]Loading train:  87%|████████▋ | 214/247 [01:51<00:16,  1.94it/s]Loading train:  87%|████████▋ | 215/247 [01:52<00:16,  1.96it/s]Loading train:  87%|████████▋ | 216/247 [01:52<00:15,  1.99it/s]Loading train:  88%|████████▊ | 217/247 [01:53<00:15,  2.00it/s]Loading train:  88%|████████▊ | 218/247 [01:53<00:14,  1.99it/s]Loading train:  89%|████████▊ | 219/247 [01:54<00:14,  1.97it/s]Loading train:  89%|████████▉ | 220/247 [01:54<00:13,  1.96it/s]Loading train:  89%|████████▉ | 221/247 [01:55<00:13,  1.93it/s]Loading train:  90%|████████▉ | 222/247 [01:55<00:13,  1.90it/s]Loading train:  90%|█████████ | 223/247 [01:56<00:12,  1.89it/s]Loading train:  91%|█████████ | 224/247 [01:56<00:12,  1.87it/s]Loading train:  91%|█████████ | 225/247 [01:57<00:11,  1.88it/s]Loading train:  91%|█████████▏| 226/247 [01:57<00:11,  1.89it/s]Loading train:  92%|█████████▏| 227/247 [01:58<00:10,  1.87it/s]Loading train:  92%|█████████▏| 228/247 [01:58<00:10,  1.86it/s]Loading train:  93%|█████████▎| 229/247 [01:59<00:09,  1.88it/s]Loading train:  93%|█████████▎| 230/247 [02:00<00:09,  1.82it/s]Loading train:  94%|█████████▎| 231/247 [02:00<00:08,  1.79it/s]Loading train:  94%|█████████▍| 232/247 [02:01<00:08,  1.78it/s]Loading train:  94%|█████████▍| 233/247 [02:01<00:07,  1.75it/s]Loading train:  95%|█████████▍| 234/247 [02:02<00:07,  1.72it/s]Loading train:  95%|█████████▌| 235/247 [02:03<00:07,  1.70it/s]Loading train:  96%|█████████▌| 236/247 [02:03<00:06,  1.69it/s]Loading train:  96%|█████████▌| 237/247 [02:04<00:06,  1.65it/s]Loading train:  96%|█████████▋| 238/247 [02:04<00:05,  1.61it/s]Loading train:  97%|█████████▋| 239/247 [02:05<00:04,  1.64it/s]Loading train:  97%|█████████▋| 240/247 [02:06<00:04,  1.63it/s]Loading train:  98%|█████████▊| 241/247 [02:06<00:03,  1.63it/s]Loading train:  98%|█████████▊| 242/247 [02:07<00:03,  1.65it/s]Loading train:  98%|█████████▊| 243/247 [02:07<00:02,  1.66it/s]Loading train:  99%|█████████▉| 244/247 [02:08<00:01,  1.66it/s]Loading train:  99%|█████████▉| 245/247 [02:09<00:01,  1.65it/s]Loading train: 100%|█████████▉| 246/247 [02:09<00:00,  1.63it/s]Loading train: 100%|██████████| 247/247 [02:10<00:00,  1.63it/s]Loading train: 100%|██████████| 247/247 [02:10<00:00,  1.89it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/247 [00:00<00:04, 59.95it/s]concatenating: train:   5%|▌         | 13/247 [00:00<00:03, 59.40it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:03, 60.55it/s]concatenating: train:  11%|█         | 27/247 [00:00<00:03, 61.48it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:03, 61.17it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:03, 58.45it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 59.36it/s]concatenating: train:  22%|██▏       | 54/247 [00:00<00:03, 60.12it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 58.68it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 57.26it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 56.14it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:03, 56.04it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:02, 58.44it/s]concatenating: train:  37%|███▋      | 91/247 [00:01<00:02, 58.85it/s]concatenating: train:  40%|███▉      | 98/247 [00:01<00:02, 60.46it/s]concatenating: train:  43%|████▎     | 105/247 [00:01<00:02, 61.29it/s]concatenating: train:  45%|████▌     | 112/247 [00:01<00:02, 61.10it/s]concatenating: train:  48%|████▊     | 119/247 [00:01<00:02, 59.99it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 59.29it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:01, 57.52it/s]concatenating: train:  56%|█████▌    | 138/247 [00:02<00:01, 58.06it/s]concatenating: train:  58%|█████▊    | 144/247 [00:02<00:01, 56.80it/s]concatenating: train:  61%|██████    | 151/247 [00:02<00:01, 59.61it/s]concatenating: train:  64%|██████▍   | 158/247 [00:02<00:01, 62.39it/s]concatenating: train:  67%|██████▋   | 165/247 [00:02<00:01, 64.24it/s]concatenating: train:  70%|██████▉   | 172/247 [00:02<00:01, 65.69it/s]concatenating: train:  72%|███████▏  | 179/247 [00:02<00:01, 64.35it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:00, 63.56it/s]concatenating: train:  78%|███████▊  | 193/247 [00:03<00:00, 62.16it/s]concatenating: train:  81%|████████  | 200/247 [00:03<00:00, 61.17it/s]concatenating: train:  84%|████████▍ | 207/247 [00:03<00:00, 57.56it/s]concatenating: train:  86%|████████▌ | 213/247 [00:03<00:00, 53.83it/s]concatenating: train:  89%|████████▊ | 219/247 [00:03<00:00, 53.05it/s]concatenating: train:  91%|█████████ | 225/247 [00:03<00:00, 51.52it/s]concatenating: train:  94%|█████████▎| 231/247 [00:03<00:00, 50.44it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 49.97it/s]concatenating: train:  98%|█████████▊| 243/247 [00:04<00:00, 49.32it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 57.97it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:17<01:09, 17.50s/it]Loading test:  40%|████      | 2/5 [00:30<00:48, 16.13s/it]Loading test:  60%|██████    | 3/5 [00:40<00:28, 14.21s/it]Loading test:  80%|████████  | 4/5 [00:48<00:12, 12.44s/it]Loading test: 100%|██████████| 5/5 [01:01<00:00, 12.71s/it]Loading test: 100%|██████████| 5/5 [01:01<00:00, 12.36s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 50.75it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 26, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 13, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 13, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 13, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 26, 80)   320         conv2d_7[0][0]                   2020-01-21 19:03:36.744734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 19:03:36.744816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 19:03:36.744831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 19:03:36.744839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 19:03:36.745126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 26, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 52, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 52, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.22924582e-02 3.14203758e-02 7.86351926e-02 9.57768122e-03
 2.85385806e-02 7.22294769e-03 8.57849884e-02 1.15047335e-01
 8.99916235e-02 1.30523110e-02 2.93804419e-01 1.84396211e-01
 2.35876511e-04]
Train on 9425 samples, validate on 197 samples
Epoch 1/300
 - 27s - loss: 0.5634 - acc: 0.9296 - mDice: 0.3920 - val_loss: 0.2198 - val_acc: 0.9475 - val_mDice: 0.2482

Epoch 00001: val_mDice improved from -inf to 0.24823, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 24s - loss: 0.4580 - acc: 0.9420 - mDice: 0.5058 - val_loss: 0.3049 - val_acc: 0.9418 - val_mDice: 0.2305

Epoch 00002: val_mDice did not improve from 0.24823
Epoch 3/300
 - 23s - loss: 0.4120 - acc: 0.9454 - mDice: 0.5555 - val_loss: 0.4777 - val_acc: 0.9460 - val_mDice: 0.2634

Epoch 00003: val_mDice improved from 0.24823 to 0.26341, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 23s - loss: 0.3796 - acc: 0.9480 - mDice: 0.5906 - val_loss: 0.2366 - val_acc: 0.9495 - val_mDice: 0.2700

Epoch 00004: val_mDice improved from 0.26341 to 0.26997, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 23s - loss: 0.3632 - acc: 0.9496 - mDice: 0.6083 - val_loss: 0.2035 - val_acc: 0.9484 - val_mDice: 0.2735

Epoch 00005: val_mDice improved from 0.26997 to 0.27350, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 6/300
 - 23s - loss: 0.3398 - acc: 0.9506 - mDice: 0.6336 - val_loss: 0.2259 - val_acc: 0.9483 - val_mDice: 0.2768

Epoch 00006: val_mDice improved from 0.27350 to 0.27679, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 7/300
 - 23s - loss: 0.3106 - acc: 0.9517 - mDice: 0.6652 - val_loss: 0.2113 - val_acc: 0.9487 - val_mDice: 0.2897

Epoch 00007: val_mDice improved from 0.27679 to 0.28969, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 8/300
 - 23s - loss: 0.3042 - acc: 0.9523 - mDice: 0.6721 - val_loss: 0.2468 - val_acc: 0.9493 - val_mDice: 0.2923

Epoch 00008: val_mDice improved from 0.28969 to 0.29235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 23s - loss: 0.2957 - acc: 0.9529 - mDice: 0.6812 - val_loss: 0.2962 - val_acc: 0.9460 - val_mDice: 0.2736

Epoch 00009: val_mDice did not improve from 0.29235
Epoch 10/300
 - 23s - loss: 0.2933 - acc: 0.9538 - mDice: 0.6838 - val_loss: 0.1784 - val_acc: 0.9475 - val_mDice: 0.2782

Epoch 00010: val_mDice did not improve from 0.29235
Epoch 11/300
 - 23s - loss: 0.2888 - acc: 0.9540 - mDice: 0.6887 - val_loss: 0.1372 - val_acc: 0.9485 - val_mDice: 0.2751

Epoch 00011: val_mDice did not improve from 0.29235
Epoch 12/300
 - 23s - loss: 0.2794 - acc: 0.9548 - mDice: 0.6988 - val_loss: 0.1578 - val_acc: 0.9500 - val_mDice: 0.2890

Epoch 00012: val_mDice did not improve from 0.29235
Epoch 13/300
 - 23s - loss: 0.2759 - acc: 0.9552 - mDice: 0.7026 - val_loss: 0.1732 - val_acc: 0.9505 - val_mDice: 0.2860

Epoch 00013: val_mDice did not improve from 0.29235
Epoch 14/300
 - 23s - loss: 0.2761 - acc: 0.9553 - mDice: 0.7023 - val_loss: 0.0604 - val_acc: 0.9497 - val_mDice: 0.2897

Epoch 00014: val_mDice did not improve from 0.29235
Epoch 15/300
 - 23s - loss: 0.2748 - acc: 0.9555 - mDice: 0.7037 - val_loss: 0.0410 - val_acc: 0.9499 - val_mDice: 0.2800

Epoch 00015: val_mDice did not improve from 0.29235
Epoch 16/300
 - 23s - loss: 0.2693 - acc: 0.9559 - mDice: 0.7096 - val_loss: 0.0586 - val_acc: 0.9486 - val_mDice: 0.2881

Epoch 00016: val_mDice did not improve from 0.29235
Epoch 17/300
 - 23s - loss: 0.2725 - acc: 0.9555 - mDice: 0.7059 - val_loss: 0.0821 - val_acc: 0.9489 - val_mDice: 0.2846

Epoch 00017: val_mDice did not improve from 0.29235
Epoch 18/300
 - 23s - loss: 0.2724 - acc: 0.9554 - mDice: 0.7053 - val_loss: 0.0903 - val_acc: 0.9468 - val_mDice: 0.2814

Epoch 00018: val_mDice did not improve from 0.29235
Epoch 19/300
 - 23s - loss: 0.2681 - acc: 0.9557 - mDice: 0.7079 - val_loss: -4.5364e-02 - val_acc: 0.9502 - val_mDice: 0.2737

Epoch 00019: val_mDice did not improve from 0.29235
Epoch 20/300
 - 23s - loss: 0.2714 - acc: 0.9541 - mDice: 0.6927 - val_loss: 0.1129 - val_acc: 0.9365 - val_mDice: 0.2156

Epoch 00020: val_mDice did not improve from 0.29235
Epoch 21/300
 - 23s - loss: 0.2716 - acc: 0.9527 - mDice: 0.6764 - val_loss: -7.1832e-02 - val_acc: 0.9486 - val_mDice: 0.2927

Epoch 00021: val_mDice improved from 0.29235 to 0.29267, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 22/300
 - 23s - loss: 0.2664 - acc: 0.9534 - mDice: 0.6842 - val_loss: -1.1381e-01 - val_acc: 0.9485 - val_mDice: 0.2717

Epoch 00022: val_mDice did not improve from 0.29267
Epoch 23/300
 - 23s - loss: 0.2565 - acc: 0.9539 - mDice: 0.6938 - val_loss: -5.9631e-02 - val_acc: 0.9462 - val_mDice: 0.2730

Epoch 00023: val_mDice did not improve from 0.29267

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 24/300
 - 23s - loss: 0.2456 - acc: 0.9546 - mDice: 0.6958 - val_loss: -9.0100e-02 - val_acc: 0.9463 - val_mDice: 0.2778

Epoch 00024: val_mDice did not improve from 0.29267
Epoch 25/300
 - 23s - loss: 0.2514 - acc: 0.9539 - mDice: 0.6880 - val_loss: -9.7405e-02 - val_acc: 0.9485 - val_mDice: 0.2717

Epoch 00025: val_mDice did not improve from 0.29267
Epoch 26/300
 - 23s - loss: 0.2421 - acc: 0.9542 - mDice: 0.6921 - val_loss: -1.2096e-01 - val_acc: 0.9492 - val_mDice: 0.2755

Epoch 00026: val_mDice did not improve from 0.29267
Epoch 27/300
 - 23s - loss: 0.2419 - acc: 0.9545 - mDice: 0.6940 - val_loss: -1.1961e-01 - val_acc: 0.9475 - val_mDice: 0.2764

Epoch 00027: val_mDice did not improve from 0.29267
Epoch 28/300
 - 23s - loss: 0.2302 - acc: 0.9556 - mDice: 0.7076 - val_loss: -1.0473e-01 - val_acc: 0.9476 - val_mDice: 0.2690

Epoch 00028: val_mDice did not improve from 0.29267
Epoch 29/300
 - 22s - loss: 0.2255 - acc: 0.9554 - mDice: 0.7088 - val_loss: -1.1813e-01 - val_acc: 0.9492 - val_mDice: 0.2741

Epoch 00029: val_mDice did not improve from 0.29267
Epoch 30/300
 - 23s - loss: 0.2348 - acc: 0.9549 - mDice: 0.6992 - val_loss: -9.9342e-02 - val_acc: 0.9506 - val_mDice: 0.2872

Epoch 00030: val_mDice did not improve from 0.29267
Epoch 31/300
 - 23s - loss: 0.2291 - acc: 0.9553 - mDice: 0.6991 - val_loss: -1.2526e-01 - val_acc: 0.9487 - val_mDice: 0.2757

Epoch 00031: val_mDice did not improve from 0.29267
Epoch 32/300
 - 23s - loss: 0.2271 - acc: 0.9556 - mDice: 0.7073 - val_loss: -5.8347e-02 - val_acc: 0.9457 - val_mDice: 0.2701

Epoch 00032: val_mDice did not improve from 0.29267
Epoch 33/300
 - 23s - loss: 0.2252 - acc: 0.9558 - mDice: 0.7072 - val_loss: -1.0999e-01 - val_acc: 0.9498 - val_mDice: 0.2798

Epoch 00033: val_mDice did not improve from 0.29267
Epoch 34/300
 - 23s - loss: 0.2237 - acc: 0.9558 - mDice: 0.7079 - val_loss: -1.3017e-01 - val_acc: 0.9491 - val_mDice: 0.2811

Epoch 00034: val_mDice did not improve from 0.29267
Epoch 35/300
 - 23s - loss: 0.2250 - acc: 0.9552 - mDice: 0.7023 - val_loss: -1.2489e-01 - val_acc: 0.9488 - val_mDice: 0.2751

Epoch 00035: val_mDice did not improve from 0.29267
Epoch 36/300
 - 23s - loss: 0.2338 - acc: 0.9550 - mDice: 0.6970 - val_loss: -1.1122e-01 - val_acc: 0.9439 - val_mDice: 0.2691

Epoch 00036: val_mDice did not improve from 0.29267
Epoch 37/300
 - 23s - loss: 0.2292 - acc: 0.9547 - mDice: 0.7031 - val_loss: -1.1437e-01 - val_acc: 0.9479 - val_mDice: 0.2725

Epoch 00037: val_mDice did not improve from 0.29267
Epoch 38/300
 - 23s - loss: 0.2321 - acc: 0.9549 - mDice: 0.6981 - val_loss: -1.3416e-01 - val_acc: 0.9478 - val_mDice: 0.2685

Epoch 00038: val_mDice did not improve from 0.29267

Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 39/300
 - 23s - loss: 0.2264 - acc: 0.9555 - mDice: 0.7084 - val_loss: -1.3375e-01 - val_acc: 0.9481 - val_mDice: 0.2765

Epoch 00039: val_mDice did not improve from 0.29267
Epoch 40/300
 - 23s - loss: 0.2112 - acc: 0.9563 - mDice: 0.7142 - val_loss: -1.2556e-01 - val_acc: 0.9490 - val_mDice: 0.2760

Epoch 00040: val_mDice did not improve from 0.29267
Epoch 41/300
 - 23s - loss: 0.2149 - acc: 0.9565 - mDice: 0.7151 - val_loss: -1.0759e-01 - val_acc: 0.9478 - val_mDice: 0.2733

Epoch 00041: val_mDice did not improve from 0.29267
Epoch 42/300
 - 23s - loss: 0.2181 - acc: 0.9564 - mDice: 0.7156 - val_loss: -1.0689e-01 - val_acc: 0.9482 - val_mDice: 0.2702

Epoch 00042: val_mDice did not improve from 0.29267
Epoch 43/300
 - 23s - loss: 0.2094 - acc: 0.9565 - mDice: 0.7159 - val_loss: -1.2437e-01 - val_acc: 0.9491 - val_mDice: 0.2748

Epoch 00043: val_mDice did not improve from 0.29267
Epoch 44/300
 - 24s - loss: 0.2160 - acc: 0.9560 - mDice: 0.7162 - val_loss: -1.1381e-01 - val_acc: 0.9486 - val_mDice: 0.2718

Epoch 00044: val_mDice did not improve from 0.29267
Epoch 45/300
 - 24s - loss: 0.2053 - acc: 0.9569 - mDice: 0.7208 - val_loss: -1.1497e-01 - val_acc: 0.9490 - val_mDice: 0.2730

Epoch 00045: val_mDice did not improve from 0.29267
Epoch 46/300
 - 23s - loss: 0.2104 - acc: 0.9562 - mDice: 0.7127 - val_loss: -1.2423e-01 - val_acc: 0.9492 - val_mDice: 0.2746

Epoch 00046: val_mDice did not improve from 0.29267
Epoch 47/300
 - 23s - loss: 0.2062 - acc: 0.9569 - mDice: 0.7195 - val_loss: -1.2613e-01 - val_acc: 0.9505 - val_mDice: 0.2766

Epoch 00047: val_mDice did not improve from 0.29267
Epoch 48/300
 - 23s - loss: 0.2135 - acc: 0.9564 - mDice: 0.7149 - val_loss: -1.1682e-01 - val_acc: 0.9501 - val_mDice: 0.2796

Epoch 00048: val_mDice did not improve from 0.29267
Epoch 49/300
 - 23s - loss: 0.2098 - acc: 0.9566 - mDice: 0.7187 - val_loss: -1.0552e-01 - val_acc: 0.9489 - val_mDice: 0.2752

Epoch 00049: val_mDice did not improve from 0.29267
Epoch 50/300
 - 23s - loss: 0.2030 - acc: 0.9570 - mDice: 0.7187 - val_loss: -1.1892e-01 - val_acc: 0.9501 - val_mDice: 0.2791

Epoch 00050: val_mDice did not improve from 0.29267
Epoch 51/300
 - 23s - loss: 0.2058 - acc: 0.9571 - mDice: 0.7255 - val_loss: -1.2127e-01 - val_acc: 0.9488 - val_mDice: 0.2779

Epoch 00051: val_mDice did not improve from 0.29267
Epoch 52/300
 - 23s - loss: 0.2038 - acc: 0.9569 - mDice: 0.7239 - val_loss: -1.2488e-01 - val_acc: 0.9490 - val_mDice: 0.2753

Epoch 00052: val_mDice did not improve from 0.29267
Epoch 53/300
 - 22s - loss: 0.2036 - acc: 0.9568 - mDice: 0.7240 - val_loss: -1.1901e-01 - val_acc: 0.9488 - val_mDice: 0.2774

Epoch 00053: val_mDice did not improve from 0.29267

Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 54/300
 - 23s - loss: 0.2001 - acc: 0.9575 - mDice: 0.7290 - val_loss: -1.1057e-01 - val_acc: 0.9493 - val_mDice: 0.2767

Epoch 00054: val_mDice did not improve from 0.29267
Epoch 55/300
 - 23s - loss: 0.1961 - acc: 0.9577 - mDice: 0.7293 - val_loss: -1.0360e-01 - val_acc: 0.9483 - val_mDice: 0.2691

Epoch 00055: val_mDice did not improve from 0.29267
Epoch 56/300
 - 24s - loss: 0.1976 - acc: 0.9577 - mDice: 0.7277 - val_loss: -1.1786e-01 - val_acc: 0.9498 - val_mDice: 0.2761

Epoch 00056: val_mDice did not improve from 0.29267
Epoch 57/300
 - 24s - loss: 0.1989 - acc: 0.9578 - mDice: 0.7279 - val_loss: -1.2581e-01 - val_acc: 0.9505 - val_mDice: 0.2847

Epoch 00057: val_mDice did not improve from 0.29267
Epoch 58/300
 - 24s - loss: 0.2001 - acc: 0.9577 - mDice: 0.7306 - val_loss: -1.3096e-01 - val_acc: 0.9504 - val_mDice: 0.2818

Epoch 00058: val_mDice did not improve from 0.29267
Epoch 59/300
 - 24s - loss: 0.1986 - acc: 0.9579 - mDice: 0.7321 - val_loss: -1.3914e-01 - val_acc: 0.9503 - val_mDice: 0.2822

Epoch 00059: val_mDice did not improve from 0.29267
Epoch 60/300
 - 24s - loss: 0.1888 - acc: 0.9581 - mDice: 0.7304 - val_loss: -1.1572e-01 - val_acc: 0.9503 - val_mDice: 0.2822

Epoch 00060: val_mDice did not improve from 0.29267
Epoch 61/300
 - 24s - loss: 0.1943 - acc: 0.9579 - mDice: 0.7300 - val_loss: -1.2584e-01 - val_acc: 0.9505 - val_mDice: 0.2767

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.68s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.50s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.32s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.19s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]
Epoch 00061: val_mDice did not improve from 0.29267
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
{'val_loss': [0.2198110755703171, 0.3048544031033661, 0.47765409976697815, 0.23660237005283005, 0.203518446525417, 0.22591012217066614, 0.21133623935925175, 0.24676865286330887, 0.2962041020317731, 0.17843198269454355, 0.13721794443119903, 0.15779177623276178, 0.1731714365654034, 0.060432054100057045, 0.04102901432682112, 0.058567238924315736, 0.08207534164719775, 0.09030081277836095, -0.04536375267251494, 0.11289184525382095, -0.07183155083679003, -0.11380706649500555, -0.05963147320042407, -0.09009980028353366, -0.09740498658212914, -0.12095868402647639, -0.11960596776553217, -0.10473366058549755, -0.11813434026189867, -0.0993423023577874, -0.1252560726140016, -0.05834717936057427, -0.10998949520100797, -0.13017266302317532, -0.12489009432986303, -0.11121794488753764, -0.11437436851772106, -0.13416009732914455, -0.13375307127909006, -0.12555848095131103, -0.10758594979489515, -0.10688524209152019, -0.12437355379351807, -0.11381429414912529, -0.11496525104654017, -0.12423265530600161, -0.12612562229488103, -0.11682337711607745, -0.10551948656285474, -0.11891954977462436, -0.12127014858468535, -0.1248818238639287, -0.11900839064185162, -0.11057048525453218, -0.10359735809606949, -0.11785761023951968, -0.12581160256100185, -0.13096407188225517, -0.1391408266074161, -0.11571994128868665, -0.12583606178650095], 'val_acc': [0.9475023685978149, 0.9418300571780519, 0.9459904541218946, 0.9495163187762807, 0.9484169567902077, 0.9483019110515033, 0.94865519383232, 0.9493338789431577, 0.9460125314402701, 0.9474942354381387, 0.9484913349151611, 0.9499893109810534, 0.9504843677966123, 0.9496848289736637, 0.9499137749526706, 0.9485843009149968, 0.9489027316195106, 0.9468399664472202, 0.9501950087281048, 0.9365319585437097, 0.9486412505813057, 0.9484518103793188, 0.9462321700178428, 0.9462972483054031, 0.9485227220554642, 0.9492467121424408, 0.9475442089405156, 0.9476232338072684, 0.9491839635795748, 0.9505599056403649, 0.9487353844691049, 0.9457092179259673, 0.9498242926476571, 0.9490991192420727, 0.9487539735542336, 0.9439067707449047, 0.9478661073040842, 0.9477870906064958, 0.9481066746760141, 0.949041021656869, 0.9478347410405348, 0.9481891850529588, 0.9491444460026504, 0.9485924422438374, 0.949004992615753, 0.9492304449154035, 0.9505029608150424, 0.9501066861418903, 0.948864372248577, 0.9500683258632718, 0.9487876719629704, 0.9490189385898222, 0.9487969690773088, 0.9492943571303701, 0.9483135276034399, 0.9498405592695711, 0.9505192377240524, 0.9503565321718981, 0.9503100596103572, 0.9502972694217856, 0.9504983237552159], 'val_mDice': [0.24822883092358633, 0.23049994705594737, 0.2634127596156851, 0.2699652195430649, 0.2734990051857711, 0.2767853972119123, 0.2896912258288582, 0.2923485173035394, 0.27362260388843906, 0.27819001530935317, 0.2751280521680861, 0.28901376843755017, 0.2860209240677393, 0.28972023052309975, 0.27999881696580026, 0.2881039767549728, 0.2846079903659482, 0.2814260041955764, 0.27374572991417145, 0.215559287686941, 0.2926741803660611, 0.27171376268119374, 0.2730118759770684, 0.27781773570376606, 0.27166174344604993, 0.27546735062514466, 0.2764218003314159, 0.26901831965761136, 0.27407544578997617, 0.2872297657927886, 0.2756624782297212, 0.27007827968313003, 0.27977593939013895, 0.281126718230659, 0.2751252090340944, 0.2691494609574376, 0.27245064843729666, 0.2685007442753327, 0.27648399028983817, 0.2760298069434118, 0.27326524106379085, 0.27024591226263095, 0.2747632556306529, 0.2718027544203143, 0.2729906826303695, 0.27458259588116923, 0.27659470811108045, 0.27957702499960885, 0.2751669962394056, 0.27908260174814215, 0.2779322261662048, 0.27533978064955794, 0.27737726437561405, 0.27667265241672545, 0.2691364969850192, 0.2761283068336206, 0.2846911663785199, 0.2818144737236996, 0.28220659751577426, 0.28219200712321374, 0.2766901432787101], 'loss': [0.563430864014107, 0.4580293145989233, 0.4120021289792554, 0.37957357701003075, 0.36316222730302683, 0.3398078042885353, 0.3105615886595268, 0.3041574283999537, 0.2957264505109357, 0.29333807241062904, 0.28881148288041275, 0.2794099441099546, 0.27589505730636554, 0.27614579262404604, 0.27481842915322485, 0.2692565662316998, 0.2725323649869357, 0.272359960069707, 0.26811805531896393, 0.2714163322426596, 0.2716157071786471, 0.2663994110616749, 0.2564632316404059, 0.2456433025334495, 0.2514463683871913, 0.24208647308559886, 0.2419153382235876, 0.23017429411460694, 0.2254534218934629, 0.2348371196854415, 0.22905057579629737, 0.22714073461151882, 0.22518240810638734, 0.2237437860390532, 0.22501166264578423, 0.2337535372712904, 0.22915314824891028, 0.23210947499548726, 0.22641272918081568, 0.21115299174537394, 0.21489769762594363, 0.21806115027911102, 0.2094039902903772, 0.21596692682834298, 0.20532206855022622, 0.21041802394108733, 0.20624369957709107, 0.213527155453858, 0.20981832173867868, 0.20301682327081022, 0.2057953129503975, 0.2037554496234105, 0.203619381544657, 0.200067018978273, 0.19614710421499051, 0.19761496196996262, 0.19893184755743537, 0.2000846104809894, 0.19856782737617265, 0.18882187274642862, 0.19428048516359347], 'acc': [0.9296424928015043, 0.9420243199371217, 0.9453837176849103, 0.9479942622172105, 0.949635593960709, 0.950621472018467, 0.9516565624851763, 0.952320881294635, 0.9529454877269047, 0.9538454988907124, 0.9539761566989302, 0.9547997490164456, 0.9551908017153449, 0.9552835186849539, 0.9554520935531636, 0.955883225616789, 0.9555004314655334, 0.9554424269129806, 0.9557271354710708, 0.954072615701893, 0.9526917236237058, 0.9534181314374787, 0.9539403269082228, 0.9546398219126289, 0.9538504300130141, 0.954181969734971, 0.9545303684330746, 0.955561377135765, 0.9553750690161708, 0.9549336871038381, 0.9553042373227187, 0.9556018686421037, 0.9557993257709776, 0.9557623080296604, 0.9552442395718723, 0.9550353424934873, 0.9546896649292357, 0.9549408289734818, 0.9554598671055599, 0.956337845894639, 0.9564835649902688, 0.9564002485110842, 0.9564840024282825, 0.9560321268099372, 0.9568797656964876, 0.9561723550687734, 0.9569273033572129, 0.9564324587346388, 0.9566117209844311, 0.957008627902924, 0.9570705686070875, 0.9569367537764086, 0.9568085729601529, 0.9574556944857225, 0.9576928180471972, 0.9576562610482031, 0.9577922877013209, 0.9577362255012958, 0.9579436645583702, 0.9580628337847459, 0.9579471639043773], 'mDice': [0.39201185077982176, 0.5057919390479829, 0.5555498734709439, 0.5905890759801992, 0.6082998498997575, 0.633567503466214, 0.665211755875251, 0.6721269818768894, 0.68123650848075, 0.6837699557330944, 0.6886804550649, 0.6988232490238524, 0.7026101854182681, 0.7023288892972375, 0.7036863505998404, 0.7095885313474215, 0.7059298065043887, 0.7052892327941065, 0.7078650071861257, 0.6926707460330083, 0.6764342358004826, 0.6842411725527412, 0.6938009675681117, 0.695822340360687, 0.6880447862319036, 0.6920597162739984, 0.6940463178670059, 0.707612515839721, 0.7087665801022982, 0.6991525405597939, 0.6991316423175822, 0.7073231397320168, 0.7072393496725856, 0.7078590878124895, 0.7023160466148619, 0.6969904640625263, 0.7030602540514513, 0.6981182305186749, 0.7084150510378162, 0.714214212160844, 0.7151304930527583, 0.715610132577881, 0.7158926847126503, 0.7162138832342719, 0.720835882346257, 0.7126866118661288, 0.7194772374408631, 0.714868124378771, 0.7186807847465697, 0.7186747353020018, 0.7254921016705763, 0.7239303223017989, 0.7239618752616154, 0.7290084603926864, 0.729259913922621, 0.7277435837753256, 0.7278527426782907, 0.7305672434027695, 0.7320583405798247, 0.7304103040568708, 0.729977679347486], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
---------------------- check Layers Step ------------------------------
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:24,  2.90it/s]Loading train:   1%|          | 2/247 [00:00<01:20,  3.06it/s]Loading train:   1%|          | 3/247 [00:00<01:15,  3.21it/s]Loading train:   2%|▏         | 4/247 [00:01<01:15,  3.23it/s]Loading train:   2%|▏         | 5/247 [00:01<01:13,  3.28it/s]Loading train:   2%|▏         | 6/247 [00:01<01:11,  3.38it/s]Loading train:   3%|▎         | 7/247 [00:02<01:09,  3.46it/s]Loading train:   3%|▎         | 8/247 [00:02<01:08,  3.49it/s]Loading train:   4%|▎         | 9/247 [00:02<01:07,  3.53it/s]Loading train:   4%|▍         | 10/247 [00:02<01:06,  3.55it/s]Loading train:   4%|▍         | 11/247 [00:03<01:06,  3.56it/s]Loading train:   5%|▍         | 12/247 [00:03<01:05,  3.59it/s]Loading train:   5%|▌         | 13/247 [00:03<01:05,  3.55it/s]Loading train:   6%|▌         | 14/247 [00:04<01:08,  3.40it/s]Loading train:   6%|▌         | 15/247 [00:04<01:08,  3.38it/s]Loading train:   6%|▋         | 16/247 [00:04<01:08,  3.35it/s]Loading train:   7%|▋         | 17/247 [00:04<01:10,  3.25it/s]Loading train:   7%|▋         | 18/247 [00:05<01:09,  3.31it/s]Loading train:   8%|▊         | 19/247 [00:05<01:08,  3.34it/s]Loading train:   8%|▊         | 20/247 [00:05<01:06,  3.40it/s]Loading train:   9%|▊         | 21/247 [00:06<01:05,  3.44it/s]Loading train:   9%|▉         | 22/247 [00:06<01:04,  3.46it/s]Loading train:   9%|▉         | 23/247 [00:06<01:02,  3.57it/s]Loading train:  10%|▉         | 24/247 [00:06<01:00,  3.69it/s]Loading train:  10%|█         | 25/247 [00:07<00:58,  3.76it/s]Loading train:  11%|█         | 26/247 [00:07<00:58,  3.78it/s]Loading train:  11%|█         | 27/247 [00:07<00:57,  3.82it/s]Loading train:  11%|█▏        | 28/247 [00:07<00:57,  3.83it/s]Loading train:  12%|█▏        | 29/247 [00:08<00:56,  3.86it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:55,  3.89it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:55,  3.91it/s]Loading train:  13%|█▎        | 32/247 [00:08<00:54,  3.93it/s]Loading train:  13%|█▎        | 33/247 [00:09<00:54,  3.95it/s]Loading train:  14%|█▍        | 34/247 [00:09<00:53,  3.95it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:53,  3.96it/s]Loading train:  15%|█▍        | 36/247 [00:09<00:53,  3.94it/s]Loading train:  15%|█▍        | 37/247 [00:10<00:53,  3.95it/s]Loading train:  15%|█▌        | 38/247 [00:10<00:52,  3.94it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:52,  3.96it/s]Loading train:  16%|█▌        | 40/247 [00:10<00:52,  3.95it/s]Loading train:  17%|█▋        | 41/247 [00:11<00:52,  3.91it/s]Loading train:  17%|█▋        | 42/247 [00:11<00:53,  3.84it/s]Loading train:  17%|█▋        | 43/247 [00:11<00:53,  3.82it/s]Loading train:  18%|█▊        | 44/247 [00:12<00:53,  3.80it/s]Loading train:  18%|█▊        | 45/247 [00:12<00:53,  3.80it/s]Loading train:  19%|█▊        | 46/247 [00:12<00:53,  3.79it/s]Loading train:  19%|█▉        | 47/247 [00:12<00:53,  3.77it/s]Loading train:  19%|█▉        | 48/247 [00:13<00:52,  3.76it/s]Loading train:  20%|█▉        | 49/247 [00:13<00:52,  3.74it/s]Loading train:  20%|██        | 50/247 [00:13<00:52,  3.78it/s]Loading train:  21%|██        | 51/247 [00:13<00:51,  3.77it/s]Loading train:  21%|██        | 52/247 [00:14<00:51,  3.77it/s]Loading train:  21%|██▏       | 53/247 [00:14<00:51,  3.75it/s]Loading train:  22%|██▏       | 54/247 [00:14<00:51,  3.74it/s]Loading train:  22%|██▏       | 55/247 [00:14<00:51,  3.75it/s]Loading train:  23%|██▎       | 56/247 [00:15<00:50,  3.77it/s]Loading train:  23%|██▎       | 57/247 [00:15<00:50,  3.78it/s]Loading train:  23%|██▎       | 58/247 [00:15<00:49,  3.79it/s]Loading train:  24%|██▍       | 59/247 [00:16<00:50,  3.70it/s]Loading train:  24%|██▍       | 60/247 [00:16<00:51,  3.63it/s]Loading train:  25%|██▍       | 61/247 [00:16<00:51,  3.62it/s]Loading train:  25%|██▌       | 62/247 [00:16<00:50,  3.63it/s]Loading train:  26%|██▌       | 63/247 [00:17<00:50,  3.62it/s]Loading train:  26%|██▌       | 64/247 [00:17<00:50,  3.62it/s]Loading train:  26%|██▋       | 65/247 [00:17<00:50,  3.62it/s]Loading train:  27%|██▋       | 66/247 [00:18<00:50,  3.60it/s]Loading train:  27%|██▋       | 67/247 [00:18<00:49,  3.60it/s]Loading train:  28%|██▊       | 68/247 [00:18<00:49,  3.60it/s]Loading train:  28%|██▊       | 69/247 [00:18<00:49,  3.60it/s]Loading train:  28%|██▊       | 70/247 [00:19<00:48,  3.62it/s]Loading train:  29%|██▊       | 71/247 [00:19<00:48,  3.61it/s]Loading train:  29%|██▉       | 72/247 [00:19<00:48,  3.61it/s]Loading train:  30%|██▉       | 73/247 [00:19<00:48,  3.61it/s]Loading train:  30%|██▉       | 74/247 [00:20<00:48,  3.56it/s]Loading train:  30%|███       | 75/247 [00:20<00:48,  3.55it/s]Loading train:  31%|███       | 76/247 [00:20<00:48,  3.55it/s]Loading train:  31%|███       | 77/247 [00:21<00:49,  3.45it/s]Loading train:  32%|███▏      | 78/247 [00:21<00:51,  3.29it/s]Loading train:  32%|███▏      | 79/247 [00:21<00:51,  3.26it/s]Loading train:  32%|███▏      | 80/247 [00:22<00:49,  3.39it/s]Loading train:  33%|███▎      | 81/247 [00:22<00:48,  3.41it/s]Loading train:  33%|███▎      | 82/247 [00:22<00:48,  3.43it/s]Loading train:  34%|███▎      | 83/247 [00:22<00:47,  3.43it/s]Loading train:  34%|███▍      | 84/247 [00:23<00:50,  3.23it/s]Loading train:  34%|███▍      | 85/247 [00:23<00:49,  3.27it/s]Loading train:  35%|███▍      | 86/247 [00:23<00:48,  3.31it/s]Loading train:  35%|███▌      | 87/247 [00:24<00:48,  3.33it/s]Loading train:  36%|███▌      | 88/247 [00:24<00:47,  3.32it/s]Loading train:  36%|███▌      | 89/247 [00:24<00:47,  3.34it/s]Loading train:  36%|███▋      | 90/247 [00:25<00:47,  3.33it/s]Loading train:  37%|███▋      | 91/247 [00:25<00:46,  3.34it/s]Loading train:  37%|███▋      | 92/247 [00:25<00:46,  3.35it/s]Loading train:  38%|███▊      | 93/247 [00:25<00:49,  3.13it/s]Loading train:  38%|███▊      | 94/247 [00:26<00:48,  3.13it/s]Loading train:  38%|███▊      | 95/247 [00:26<00:47,  3.17it/s]Loading train:  39%|███▉      | 96/247 [00:26<00:47,  3.15it/s]Loading train:  39%|███▉      | 97/247 [00:27<00:46,  3.22it/s]Loading train:  40%|███▉      | 98/247 [00:27<00:46,  3.18it/s]Loading train:  40%|████      | 99/247 [00:27<00:46,  3.17it/s]Loading train:  40%|████      | 100/247 [00:28<00:46,  3.15it/s]Loading train:  41%|████      | 101/247 [00:28<00:46,  3.16it/s]Loading train:  41%|████▏     | 102/247 [00:28<00:45,  3.16it/s]Loading train:  42%|████▏     | 103/247 [00:29<00:45,  3.18it/s]Loading train:  42%|████▏     | 104/247 [00:29<00:44,  3.18it/s]Loading train:  43%|████▎     | 105/247 [00:29<00:44,  3.17it/s]Loading train:  43%|████▎     | 106/247 [00:30<00:47,  3.00it/s]Loading train:  43%|████▎     | 107/247 [00:30<00:45,  3.06it/s]Loading train:  44%|████▎     | 108/247 [00:30<00:45,  3.08it/s]Loading train:  44%|████▍     | 109/247 [00:31<00:44,  3.09it/s]Loading train:  45%|████▍     | 110/247 [00:31<00:44,  3.11it/s]Loading train:  45%|████▍     | 111/247 [00:31<00:43,  3.14it/s]Loading train:  45%|████▌     | 112/247 [00:32<00:43,  3.11it/s]Loading train:  46%|████▌     | 113/247 [00:32<00:43,  3.11it/s]Loading train:  46%|████▌     | 114/247 [00:32<00:43,  3.05it/s]Loading train:  47%|████▋     | 115/247 [00:33<00:43,  3.05it/s]Loading train:  47%|████▋     | 116/247 [00:33<00:44,  2.96it/s]Loading train:  47%|████▋     | 117/247 [00:33<00:43,  3.00it/s]Loading train:  48%|████▊     | 118/247 [00:34<00:41,  3.12it/s]Loading train:  48%|████▊     | 119/247 [00:34<00:40,  3.20it/s]Loading train:  49%|████▊     | 120/247 [00:34<00:38,  3.26it/s]Loading train:  49%|████▉     | 121/247 [00:34<00:38,  3.30it/s]Loading train:  49%|████▉     | 122/247 [00:35<00:37,  3.31it/s]Loading train:  50%|████▉     | 123/247 [00:35<00:37,  3.33it/s]Loading train:  50%|█████     | 124/247 [00:35<00:36,  3.33it/s]Loading train:  51%|█████     | 125/247 [00:36<00:37,  3.28it/s]Loading train:  51%|█████     | 126/247 [00:36<00:37,  3.26it/s]Loading train:  51%|█████▏    | 127/247 [00:36<00:36,  3.28it/s]Loading train:  52%|█████▏    | 128/247 [00:37<00:36,  3.30it/s]Loading train:  52%|█████▏    | 129/247 [00:37<00:35,  3.33it/s]Loading train:  53%|█████▎    | 130/247 [00:37<00:34,  3.35it/s]Loading train:  53%|█████▎    | 131/247 [00:37<00:34,  3.38it/s]Loading train:  53%|█████▎    | 132/247 [00:38<00:33,  3.41it/s]Loading train:  54%|█████▍    | 133/247 [00:38<00:33,  3.43it/s]Loading train:  54%|█████▍    | 134/247 [00:38<00:33,  3.41it/s]Loading train:  55%|█████▍    | 135/247 [00:39<00:32,  3.42it/s]Loading train:  55%|█████▌    | 136/247 [00:39<00:31,  3.53it/s]Loading train:  55%|█████▌    | 137/247 [00:39<00:30,  3.62it/s]Loading train:  56%|█████▌    | 138/247 [00:39<00:29,  3.68it/s]Loading train:  56%|█████▋    | 139/247 [00:40<00:28,  3.74it/s]Loading train:  57%|█████▋    | 140/247 [00:40<00:28,  3.77it/s]Loading train:  57%|█████▋    | 141/247 [00:40<00:27,  3.83it/s]Loading train:  57%|█████▋    | 142/247 [00:40<00:27,  3.87it/s]Loading train:  58%|█████▊    | 143/247 [00:41<00:26,  3.87it/s]Loading train:  58%|█████▊    | 144/247 [00:41<00:26,  3.84it/s]Loading train:  59%|█████▊    | 145/247 [00:41<00:26,  3.83it/s]Loading train:  59%|█████▉    | 146/247 [00:41<00:26,  3.84it/s]Loading train:  60%|█████▉    | 147/247 [00:42<00:26,  3.85it/s]Loading train:  60%|█████▉    | 148/247 [00:42<00:25,  3.86it/s]Loading train:  60%|██████    | 149/247 [00:42<00:25,  3.86it/s]Loading train:  61%|██████    | 150/247 [00:42<00:25,  3.86it/s]Loading train:  61%|██████    | 151/247 [00:43<00:25,  3.83it/s]Loading train:  62%|██████▏   | 152/247 [00:43<00:24,  3.84it/s]Loading train:  62%|██████▏   | 153/247 [00:43<00:24,  3.85it/s]Loading train:  62%|██████▏   | 154/247 [00:44<00:24,  3.77it/s]Loading train:  63%|██████▎   | 155/247 [00:44<00:24,  3.75it/s]Loading train:  63%|██████▎   | 156/247 [00:44<00:26,  3.48it/s]Loading train:  64%|██████▎   | 157/247 [00:44<00:25,  3.50it/s]Loading train:  64%|██████▍   | 158/247 [00:45<00:25,  3.54it/s]Loading train:  64%|██████▍   | 159/247 [00:45<00:24,  3.54it/s]Loading train:  65%|██████▍   | 160/247 [00:45<00:25,  3.46it/s]Loading train:  65%|██████▌   | 161/247 [00:46<00:24,  3.50it/s]Loading train:  66%|██████▌   | 162/247 [00:46<00:24,  3.51it/s]Loading train:  66%|██████▌   | 163/247 [00:46<00:23,  3.51it/s]Loading train:  66%|██████▋   | 164/247 [00:46<00:23,  3.56it/s]Loading train:  67%|██████▋   | 165/247 [00:47<00:22,  3.58it/s]Loading train:  67%|██████▋   | 166/247 [00:47<00:22,  3.55it/s]Loading train:  68%|██████▊   | 167/247 [00:47<00:22,  3.55it/s]Loading train:  68%|██████▊   | 168/247 [00:47<00:22,  3.58it/s]Loading train:  68%|██████▊   | 169/247 [00:48<00:21,  3.62it/s]Loading train:  69%|██████▉   | 170/247 [00:48<00:21,  3.63it/s]Loading train:  69%|██████▉   | 171/247 [00:48<00:20,  3.64it/s]Loading train:  70%|██████▉   | 172/247 [00:49<00:21,  3.52it/s]Loading train:  70%|███████   | 173/247 [00:49<00:20,  3.58it/s]Loading train:  70%|███████   | 174/247 [00:49<00:20,  3.57it/s]Loading train:  71%|███████   | 175/247 [00:49<00:20,  3.44it/s]Loading train:  71%|███████▏  | 176/247 [00:50<00:20,  3.53it/s]Loading train:  72%|███████▏  | 177/247 [00:50<00:19,  3.58it/s]Loading train:  72%|███████▏  | 178/247 [00:50<00:18,  3.63it/s]Loading train:  72%|███████▏  | 179/247 [00:51<00:18,  3.67it/s]Loading train:  73%|███████▎  | 180/247 [00:51<00:18,  3.69it/s]Loading train:  73%|███████▎  | 181/247 [00:51<00:17,  3.70it/s]Loading train:  74%|███████▎  | 182/247 [00:51<00:17,  3.65it/s]Loading train:  74%|███████▍  | 183/247 [00:52<00:17,  3.63it/s]Loading train:  74%|███████▍  | 184/247 [00:52<00:17,  3.59it/s]Loading train:  75%|███████▍  | 185/247 [00:52<00:17,  3.57it/s]Loading train:  75%|███████▌  | 186/247 [00:52<00:16,  3.60it/s]Loading train:  76%|███████▌  | 187/247 [00:53<00:16,  3.65it/s]Loading train:  76%|███████▌  | 188/247 [00:53<00:16,  3.65it/s]Loading train:  77%|███████▋  | 189/247 [00:53<00:15,  3.65it/s]Loading train:  77%|███████▋  | 190/247 [00:54<00:15,  3.66it/s]Loading train:  77%|███████▋  | 191/247 [00:54<00:15,  3.66it/s]Loading train:  78%|███████▊  | 192/247 [00:54<00:15,  3.61it/s]Loading train:  78%|███████▊  | 193/247 [00:54<00:14,  3.63it/s]Loading train:  79%|███████▊  | 194/247 [00:55<00:14,  3.62it/s]Loading train:  79%|███████▉  | 195/247 [00:55<00:13,  3.73it/s]Loading train:  79%|███████▉  | 196/247 [00:55<00:13,  3.76it/s]Loading train:  80%|███████▉  | 197/247 [00:55<00:13,  3.82it/s]Loading train:  80%|████████  | 198/247 [00:56<00:12,  3.83it/s]Loading train:  81%|████████  | 199/247 [00:56<00:12,  3.89it/s]Loading train:  81%|████████  | 200/247 [00:56<00:11,  3.94it/s]Loading train:  81%|████████▏ | 201/247 [00:56<00:11,  3.95it/s]Loading train:  82%|████████▏ | 202/247 [00:57<00:11,  3.97it/s]Loading train:  82%|████████▏ | 203/247 [00:57<00:11,  3.88it/s]Loading train:  83%|████████▎ | 204/247 [00:57<00:11,  3.90it/s]Loading train:  83%|████████▎ | 205/247 [00:57<00:10,  3.89it/s]Loading train:  83%|████████▎ | 206/247 [00:58<00:10,  3.89it/s]Loading train:  84%|████████▍ | 207/247 [00:58<00:10,  3.92it/s]Loading train:  84%|████████▍ | 208/247 [00:58<00:09,  3.92it/s]Loading train:  85%|████████▍ | 209/247 [00:58<00:09,  3.95it/s]Loading train:  85%|████████▌ | 210/247 [00:59<00:09,  3.97it/s]Loading train:  85%|████████▌ | 211/247 [00:59<00:09,  3.99it/s]Loading train:  86%|████████▌ | 212/247 [00:59<00:08,  3.92it/s]Loading train:  86%|████████▌ | 213/247 [01:00<00:08,  3.88it/s]Loading train:  87%|████████▋ | 214/247 [01:00<00:08,  3.86it/s]Loading train:  87%|████████▋ | 215/247 [01:00<00:08,  3.83it/s]Loading train:  87%|████████▋ | 216/247 [01:00<00:08,  3.79it/s]Loading train:  88%|████████▊ | 217/247 [01:01<00:07,  3.79it/s]Loading train:  88%|████████▊ | 218/247 [01:01<00:07,  3.76it/s]Loading train:  89%|████████▊ | 219/247 [01:01<00:07,  3.74it/s]Loading train:  89%|████████▉ | 220/247 [01:01<00:07,  3.76it/s]Loading train:  89%|████████▉ | 221/247 [01:02<00:06,  3.75it/s]Loading train:  90%|████████▉ | 222/247 [01:02<00:06,  3.69it/s]Loading train:  90%|█████████ | 223/247 [01:02<00:06,  3.69it/s]Loading train:  91%|█████████ | 224/247 [01:02<00:06,  3.72it/s]Loading train:  91%|█████████ | 225/247 [01:03<00:05,  3.73it/s]Loading train:  91%|█████████▏| 226/247 [01:03<00:05,  3.69it/s]Loading train:  92%|█████████▏| 227/247 [01:03<00:05,  3.54it/s]Loading train:  92%|█████████▏| 228/247 [01:04<00:05,  3.63it/s]Loading train:  93%|█████████▎| 229/247 [01:04<00:04,  3.68it/s]Loading train:  93%|█████████▎| 230/247 [01:04<00:04,  3.56it/s]Loading train:  94%|█████████▎| 231/247 [01:04<00:04,  3.47it/s]Loading train:  94%|█████████▍| 232/247 [01:05<00:04,  3.42it/s]Loading train:  94%|█████████▍| 233/247 [01:05<00:04,  3.36it/s]Loading train:  95%|█████████▍| 234/247 [01:05<00:03,  3.34it/s]Loading train:  95%|█████████▌| 235/247 [01:06<00:03,  3.33it/s]Loading train:  96%|█████████▌| 236/247 [01:06<00:03,  3.35it/s]Loading train:  96%|█████████▌| 237/247 [01:06<00:03,  3.33it/s]Loading train:  96%|█████████▋| 238/247 [01:07<00:02,  3.32it/s]Loading train:  97%|█████████▋| 239/247 [01:07<00:02,  3.32it/s]Loading train:  97%|█████████▋| 240/247 [01:07<00:02,  3.30it/s]Loading train:  98%|█████████▊| 241/247 [01:07<00:01,  3.28it/s]Loading train:  98%|█████████▊| 242/247 [01:08<00:01,  3.26it/s]Loading train:  98%|█████████▊| 243/247 [01:08<00:01,  3.27it/s]Loading train:  99%|█████████▉| 244/247 [01:08<00:00,  3.29it/s]Loading train:  99%|█████████▉| 245/247 [01:09<00:00,  3.30it/s]Loading train: 100%|█████████▉| 246/247 [01:09<00:00,  3.31it/s]Loading train: 100%|██████████| 247/247 [01:09<00:00,  3.31it/s]Loading train: 100%|██████████| 247/247 [01:09<00:00,  3.54it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 51.48it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 51.81it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 51.97it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 53.02it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:03, 56.11it/s]concatenating: train:  15%|█▌        | 38/247 [00:00<00:03, 58.51it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:03, 59.05it/s]concatenating: train:  21%|██        | 51/247 [00:00<00:03, 58.31it/s]concatenating: train:  23%|██▎       | 58/247 [00:01<00:03, 59.49it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:03, 58.86it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 57.79it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:02, 57.88it/s]concatenating: train:  33%|███▎      | 82/247 [00:01<00:02, 57.39it/s]concatenating: train:  36%|███▌      | 88/247 [00:01<00:02, 56.77it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:02, 56.09it/s]concatenating: train:  40%|████      | 100/247 [00:01<00:02, 54.99it/s]concatenating: train:  43%|████▎     | 106/247 [00:01<00:02, 52.82it/s]concatenating: train:  45%|████▌     | 112/247 [00:01<00:02, 52.27it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 51.09it/s]concatenating: train:  50%|█████     | 124/247 [00:02<00:02, 49.25it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 49.39it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 50.52it/s]concatenating: train:  57%|█████▋    | 141/247 [00:02<00:02, 52.52it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:01, 54.54it/s]concatenating: train:  62%|██████▏   | 154/247 [00:02<00:01, 56.52it/s]concatenating: train:  65%|██████▍   | 160/247 [00:02<00:01, 54.77it/s]concatenating: train:  67%|██████▋   | 166/247 [00:03<00:01, 53.91it/s]concatenating: train:  70%|██████▉   | 172/247 [00:03<00:01, 54.66it/s]concatenating: train:  72%|███████▏  | 178/247 [00:03<00:01, 55.58it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 57.11it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:00, 56.91it/s]concatenating: train:  80%|███████▉  | 197/247 [00:03<00:00, 56.50it/s]concatenating: train:  82%|████████▏ | 203/247 [00:03<00:00, 57.14it/s]concatenating: train:  85%|████████▍ | 209/247 [00:03<00:00, 57.00it/s]concatenating: train:  87%|████████▋ | 216/247 [00:03<00:00, 58.94it/s]concatenating: train:  90%|████████▉ | 222/247 [00:03<00:00, 58.81it/s]concatenating: train:  93%|█████████▎| 229/247 [00:04<00:00, 59.34it/s]concatenating: train:  95%|█████████▌| 235/247 [00:04<00:00, 56.44it/s]concatenating: train:  98%|█████████▊| 241/247 [00:04<00:00, 57.20it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 56.17it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 55.83it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.94it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.03it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.15it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.30it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.21it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.26it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 354.31it/s]
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              2020-01-21 19:29:36.271132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 19:29:36.271230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 19:29:36.271244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 19:29:36.271252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 19:29:36.271536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97426102 0.02573898]
Train on 25213 samples, validate on 542 samples
Epoch 1/300
 - 66s - loss: 0.0717 - acc: 0.9922 - mDice: 0.8607 - val_loss: 0.0062 - val_acc: 0.9932 - val_mDice: 0.4853

Epoch 00001: val_mDice improved from -inf to 0.48531, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 63s - loss: 0.0498 - acc: 0.9944 - mDice: 0.9033 - val_loss: -6.5690e-02 - val_acc: 0.9935 - val_mDice: 0.5003

Epoch 00002: val_mDice improved from 0.48531 to 0.50029, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 63s - loss: 0.0451 - acc: 0.9949 - mDice: 0.9124 - val_loss: -1.0281e-01 - val_acc: 0.9944 - val_mDice: 0.5003

Epoch 00003: val_mDice did not improve from 0.50029
Epoch 4/300
 - 63s - loss: 0.0422 - acc: 0.9952 - mDice: 0.9180 - val_loss: -7.4133e-02 - val_acc: 0.9933 - val_mDice: 0.4803

Epoch 00004: val_mDice did not improve from 0.50029
Epoch 5/300
 - 63s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9231 - val_loss: -4.3540e-02 - val_acc: 0.9939 - val_mDice: 0.4932

Epoch 00005: val_mDice did not improve from 0.50029
Epoch 6/300
 - 63s - loss: 0.0383 - acc: 0.9955 - mDice: 0.9257 - val_loss: -8.4197e-02 - val_acc: 0.9939 - val_mDice: 0.5002

Epoch 00006: val_mDice did not improve from 0.50029
Epoch 7/300
 - 63s - loss: 0.0369 - acc: 0.9957 - mDice: 0.9283 - val_loss: -9.6761e-02 - val_acc: 0.9938 - val_mDice: 0.4886

Epoch 00007: val_mDice did not improve from 0.50029
Epoch 8/300
 - 63s - loss: 0.0357 - acc: 0.9958 - mDice: 0.9307 - val_loss: -7.8078e-02 - val_acc: 0.9934 - val_mDice: 0.4883

Epoch 00008: val_mDice did not improve from 0.50029
Epoch 9/300
 - 64s - loss: 0.0351 - acc: 0.9958 - mDice: 0.9319 - val_loss: -9.1339e-02 - val_acc: 0.9932 - val_mDice: 0.4811

Epoch 00009: val_mDice did not improve from 0.50029
Epoch 10/300
 - 64s - loss: 0.0341 - acc: 0.9959 - mDice: 0.9338 - val_loss: -9.5819e-02 - val_acc: 0.9931 - val_mDice: 0.4880

Epoch 00010: val_mDice did not improve from 0.50029
Epoch 11/300
 - 63s - loss: 0.0337 - acc: 0.9960 - mDice: 0.9345 - val_loss: -6.1700e-02 - val_acc: 0.9919 - val_mDice: 0.4562

Epoch 00011: val_mDice did not improve from 0.50029
Epoch 12/300
 - 63s - loss: 0.0330 - acc: 0.9960 - mDice: 0.9360 - val_loss: -3.2750e-02 - val_acc: 0.9937 - val_mDice: 0.5091

Epoch 00012: val_mDice improved from 0.50029 to 0.50915, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 13/300
 - 63s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9368 - val_loss: -9.4692e-02 - val_acc: 0.9934 - val_mDice: 0.4846

Epoch 00013: val_mDice did not improve from 0.50915
Epoch 14/300
 - 63s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9372 - val_loss: -7.6021e-02 - val_acc: 0.9936 - val_mDice: 0.4878

Epoch 00014: val_mDice did not improve from 0.50915
Epoch 15/300
 - 65s - loss: 0.0318 - acc: 0.9961 - mDice: 0.9384 - val_loss: -7.2110e-02 - val_acc: 0.9930 - val_mDice: 0.4771

Epoch 00015: val_mDice did not improve from 0.50915
Epoch 16/300
 - 65s - loss: 0.0316 - acc: 0.9962 - mDice: 0.9387 - val_loss: -7.7789e-02 - val_acc: 0.9915 - val_mDice: 0.4530

Epoch 00016: val_mDice did not improve from 0.50915
Epoch 17/300
 - 66s - loss: 0.0312 - acc: 0.9962 - mDice: 0.9395 - val_loss: -8.7571e-02 - val_acc: 0.9925 - val_mDice: 0.4708

Epoch 00017: val_mDice did not improve from 0.50915
Epoch 18/300
 - 63s - loss: 0.0309 - acc: 0.9963 - mDice: 0.9400 - val_loss: -7.5018e-02 - val_acc: 0.9935 - val_mDice: 0.4948

Epoch 00018: val_mDice did not improve from 0.50915
Epoch 19/300
 - 63s - loss: 0.0305 - acc: 0.9963 - mDice: 0.9408 - val_loss: -6.2416e-02 - val_acc: 0.9933 - val_mDice: 0.4895

Epoch 00019: val_mDice did not improve from 0.50915
Epoch 20/300
 - 64s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9406 - val_loss: -7.1323e-02 - val_acc: 0.9927 - val_mDice: 0.4751

Epoch 00020: val_mDice did not improve from 0.50915
Epoch 21/300
 - 64s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9423 - val_loss: -6.4569e-02 - val_acc: 0.9922 - val_mDice: 0.4618

Epoch 00021: val_mDice did not improve from 0.50915
Epoch 22/300
 - 63s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9423 - val_loss: 0.0052 - val_acc: 0.9934 - val_mDice: 0.5177

Epoch 00022: val_mDice improved from 0.50915 to 0.51766, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 23/300
 - 63s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9425 - val_loss: -3.8785e-02 - val_acc: 0.9930 - val_mDice: 0.4796

Epoch 00023: val_mDice did not improve from 0.51766
Epoch 24/300
 - 63s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9430 - val_loss: -5.0431e-02 - val_acc: 0.9925 - val_mDice: 0.4698

Epoch 00024: val_mDice did not improve from 0.51766
Epoch 25/300
 - 63s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9430 - val_loss: -6.2343e-02 - val_acc: 0.9936 - val_mDice: 0.4906

Epoch 00025: val_mDice did not improve from 0.51766
Epoch 26/300
 - 64s - loss: 0.0291 - acc: 0.9964 - mDice: 0.9435 - val_loss: -7.0596e-02 - val_acc: 0.9930 - val_mDice: 0.4738

Epoch 00026: val_mDice did not improve from 0.51766
Epoch 27/300
 - 64s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9434 - val_loss: -9.4325e-02 - val_acc: 0.9926 - val_mDice: 0.4845

Epoch 00027: val_mDice did not improve from 0.51766
Epoch 28/300
 - 64s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9448 - val_loss: -8.5446e-02 - val_acc: 0.9925 - val_mDice: 0.4665

Epoch 00028: val_mDice did not improve from 0.51766
Epoch 29/300
 - 64s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9451 - val_loss: -7.8602e-02 - val_acc: 0.9929 - val_mDice: 0.4895

Epoch 00029: val_mDice did not improve from 0.51766
Epoch 30/300
 - 63s - loss: 0.0287 - acc: 0.9965 - mDice: 0.9443 - val_loss: -5.0358e-02 - val_acc: 0.9926 - val_mDice: 0.4680

Epoch 00030: val_mDice did not improve from 0.51766
Epoch 31/300
 - 63s - loss: 0.0282 - acc: 0.9965 - mDice: 0.9453 - val_loss: -8.5377e-02 - val_acc: 0.9934 - val_mDice: 0.4913

Epoch 00031: val_mDice did not improve from 0.51766
Epoch 32/300
 - 64s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9458 - val_loss: -5.8633e-02 - val_acc: 0.9935 - val_mDice: 0.5027

Epoch 00032: val_mDice did not improve from 0.51766
Epoch 33/300
 - 64s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9462 - val_loss: -9.9603e-02 - val_acc: 0.9931 - val_mDice: 0.4946

Epoch 00033: val_mDice did not improve from 0.51766
Epoch 34/300
 - 63s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9460 - val_loss: -1.1062e-01 - val_acc: 0.9937 - val_mDice: 0.5164

Epoch 00034: val_mDice did not improve from 0.51766
Epoch 35/300
 - 63s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9459 - val_loss: -7.2131e-02 - val_acc: 0.9926 - val_mDice: 0.4768

Epoch 00035: val_mDice did not improve from 0.51766
Epoch 36/300
 - 63s - loss: 0.0276 - acc: 0.9965 - mDice: 0.9465 - val_loss: -6.6154e-02 - val_acc: 0.9921 - val_mDice: 0.4659

Epoch 00036: val_mDice did not improve from 0.51766
Epoch 37/300
 - 63s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9471 - val_loss: -7.0014e-02 - val_acc: 0.9921 - val_mDice: 0.4807

Epoch 00037: val_mDice did not improve from 0.51766

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 38/300
 - 63s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9486 - val_loss: -9.4576e-02 - val_acc: 0.9929 - val_mDice: 0.4847

Epoch 00038: val_mDice did not improve from 0.51766
Epoch 39/300
 - 64s - loss: 0.0262 - acc: 0.9967 - mDice: 0.9492 - val_loss: -9.0212e-02 - val_acc: 0.9927 - val_mDice: 0.4761

Epoch 00039: val_mDice did not improve from 0.51766
Epoch 40/300
 - 63s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9501 - val_loss: -8.2697e-02 - val_acc: 0.9926 - val_mDice: 0.4626

Epoch 00040: val_mDice did not improve from 0.51766
Epoch 41/300
 - 63s - loss: 0.0259 - acc: 0.9967 - mDice: 0.9497 - val_loss: -6.1029e-02 - val_acc: 0.9922 - val_mDice: 0.4559

Epoch 00041: val_mDice did not improve from 0.51766
Epoch 42/300
 - 64s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9496 - val_loss: -4.1254e-02 - val_acc: 0.9929 - val_mDice: 0.4680

Epoch 00042: val_mDice did not improve from 0.51766
Epoch 43/300
 - 64s - loss: 0.0262 - acc: 0.9967 - mDice: 0.9491 - val_loss: -5.7082e-02 - val_acc: 0.9922 - val_mDice: 0.4642

Epoch 00043: val_mDice did not improve from 0.51766
Epoch 44/300
 - 63s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9509 - val_loss: -8.8832e-02 - val_acc: 0.9930 - val_mDice: 0.4738

Epoch 00044: val_mDice did not improve from 0.51766
Epoch 45/300
 - 63s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9507 - val_loss: -9.3580e-02 - val_acc: 0.9930 - val_mDice: 0.4826

Epoch 00045: val_mDice did not improve from 0.51766
Epoch 46/300
 - 63s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9501 - val_loss: -8.3813e-02 - val_acc: 0.9928 - val_mDice: 0.4793

Epoch 00046: val_mDice did not improve from 0.51766
Epoch 47/300
 - 63s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: -9.0129e-02 - val_acc: 0.9932 - val_mDice: 0.4757

Epoch 00047: val_mDice did not improve from 0.51766
Epoch 48/300
 - 63s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9513 - val_loss: -6.3398e-02 - val_acc: 0.9920 - val_mDice: 0.4545

Epoch 00048: val_mDice did not improve from 0.51766
Epoch 49/300
 - 63s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -7.3069e-02 - val_acc: 0.9927 - val_mDice: 0.4789

Epoch 00049: val_mDice did not improve from 0.51766
Epoch 50/300
 - 63s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9511 - val_loss: -8.6771e-02 - val_acc: 0.9926 - val_mDice: 0.4691

Epoch 00050: val_mDice did not improve from 0.51766
Epoch 51/300
 - 63s - loss: 0.0251 - acc: 0.9967 - mDice: 0.9514 - val_loss: -6.7956e-02 - val_acc: 0.9936 - val_mDice: 0.4870

Epoch 00051: val_mDice did not improve from 0.51766
Epoch 52/300
 - 63s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9518 - val_loss: -4.0970e-02 - val_acc: 0.9933 - val_mDice: 0.4896

Epoch 00052: val_mDice did not improve from 0.51766

Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 53/300
 - 63s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9527 - val_loss: -5.6610e-02 - val_acc: 0.9933 - val_mDice: 0.4936

Epoch 00053: val_mDice did not improve from 0.51766
Epoch 54/300
 - 63s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9528 - val_loss: -2.5308e-02 - val_acc: 0.9936 - val_mDice: 0.4994

Epoch 00054: val_mDice did not improve from 0.51766
Epoch 55/300
 - 63s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9528 - val_loss: -4.9729e-02 - val_acc: 0.9933 - val_mDice: 0.4860

Epoch 00055: val_mDice did not improve from 0.51766
Epoch 56/300
 - 63s - loss: 0.0240 - acc: 0.9968 - mDice: 0.9535 - val_loss: -6.8177e-02 - val_acc: 0.9932 - val_mDice: 0.4875

Epoch 00056: val_mDice did not improve from 0.51766
Epoch 57/300
 - 62s - loss: 0.0242 - acc: 0.9968 - mDice: 0.9530 - val_loss: -8.7659e-02 - val_acc: 0.9927 - val_mDice: 0.4730

Epoch 00057: val_mDice did not improve from 0.51766
Epoch 58/300
 - 63s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9530 - val_loss: -9.1762e-02 - val_acc: 0.9932 - val_mDice: 0.4822

Epoch 00058: val_mDice did not improve from 0.51766
Epoch 59/300
 - 63s - loss: 0.0242 - acc: 0.9968 - mDice: 0.9532 - val_loss: -4.6910e-02 - val_acc: 0.9924 - val_mDice: 0.4647

Epoch 00059: val_mDice did not improve from 0.51766
Epoch 60/300
 - 62s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: -7.2343e-02 - val_acc: 0.9930 - val_mDice: 0.4774

Epoch 00060: val_mDice did not improve from 0.51766
Epoch 61/300
 - 62s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9538 - val_loss: -7.0613e-02 - val_acc: 0.9929 - val_mDice: 0.4744

Epoch 00061: val_mDice did not improve from 0.51766
Epoch 62/300
 - 63s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9540 - val_loss: -2.0112e-02 - val_acc: 0.9928 - val_mDice: 0.4773

Epoch 00062: val_mDice did not improve from 0.51766
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
{'val_loss': [0.0061644442187024215, -0.06569043181259254, -0.10281313089756948, -0.07413251109668689, -0.04353994823909774, -0.08419733464277979, -0.09676059299729407, -0.07807779119683368, -0.09133857840541544, -0.09581853540071263, -0.061700369901542734, -0.032750076253475736, -0.09469216817309496, -0.0760207663108062, -0.07210985057028457, -0.0777893148885002, -0.08757136085816415, -0.07501800366543315, -0.06241612944655753, -0.0713233672824733, -0.06456859022158978, 0.005242446141929204, -0.03878471909633862, -0.050431392729502325, -0.062342515648291116, -0.0705963945586743, -0.09432452875859623, -0.08544646132036329, -0.07860235468487899, -0.05035794540085036, -0.08537735924729561, -0.05863273300477939, -0.09960303843241336, -0.11062173341912977, -0.07213056689588786, -0.06615378207276228, -0.07001441093058604, -0.09457601747059734, -0.09021202175159736, -0.08269734306748942, -0.06102854211391998, -0.041254097327754945, -0.05708249523630881, -0.08883158257746608, -0.09358032669088498, -0.08381302517278608, -0.09012851778871458, -0.06339824848509362, -0.0730688213972148, -0.0867710677405125, -0.06795614968806615, -0.04097033151841251, -0.05661024279699994, -0.025308033444564722, -0.04972939820087264, -0.06817657401530945, -0.08765937888314364, -0.09176247575186275, -0.046909828522548463, -0.07234307298801042, -0.07061320763232523, -0.020112033452275056], 'val_acc': [0.9931998655364962, 0.9935264758958148, 0.9943574988094203, 0.9932776386007611, 0.9939412010551819, 0.993877812285265, 0.9938240922245153, 0.9934199298439871, 0.9931827847368163, 0.9930683691123315, 0.9919354607698222, 0.9937344015304452, 0.9933972283922878, 0.9935671643137491, 0.9929658678185016, 0.9914915172376316, 0.9924574116059335, 0.9934626373417703, 0.9932621314956693, 0.9927143351178328, 0.9922162173418981, 0.993355641505815, 0.9930018362523885, 0.9925279903235911, 0.9935880677286549, 0.9929923918854267, 0.9925774434835708, 0.9924834847890143, 0.9928880914550866, 0.9926417329214596, 0.9934057676924111, 0.9934745483732751, 0.9930987157944824, 0.9936712382024505, 0.9926219468187142, 0.9920656122404711, 0.9920667339514982, 0.9928644893354156, 0.9927433313478843, 0.9925866569100271, 0.9921503542094213, 0.9928853938500379, 0.992202281731961, 0.9930362265928205, 0.9929550773983072, 0.9927682850193713, 0.9931578321650459, 0.9920026699555317, 0.9926520691586597, 0.9925724969578845, 0.9936103226953766, 0.9932828116680863, 0.9933061894455519, 0.9936094209276882, 0.9932560621592391, 0.9932338071925174, 0.99268983562934, 0.9932369567811269, 0.9923803082691347, 0.9929966598859132, 0.9929013551381242, 0.9927988560437276], 'val_mDice': [0.48530922329733733, 0.5002944539833772, 0.500272137982379, 0.4803095191607176, 0.493196199456491, 0.5001958298782146, 0.4886222619742045, 0.4883093978258597, 0.48110045355185005, 0.48799536484834144, 0.4562046264068008, 0.5091468538965246, 0.4845852088964994, 0.48775503831156064, 0.4771044557438842, 0.45301581825717346, 0.4708125485799522, 0.49479708336502, 0.48945437608169895, 0.47507138269853766, 0.4618273406011152, 0.5176593895273015, 0.47956568481077566, 0.4698440812819333, 0.4906456307181573, 0.47376818102664175, 0.4845089990494436, 0.4664701030923854, 0.4895397927268405, 0.46800624000166646, 0.49131246840381976, 0.5026675931202338, 0.4945941170423233, 0.5163521061323212, 0.4768049185994215, 0.4658697757223875, 0.4806753801958588, 0.4847457675036469, 0.4760526379099084, 0.46260018680911386, 0.45591214168292804, 0.4679615978642271, 0.4641764899681415, 0.47376569036619903, 0.4826129324101874, 0.4793120640230355, 0.47569141396737186, 0.4544601952347808, 0.47886988938514596, 0.4691058232335595, 0.48697321770224733, 0.48964362852687765, 0.4936067419078517, 0.49937526733233084, 0.4860106883123792, 0.48745145546994084, 0.47295286921566937, 0.48222609695968155, 0.4646738338184533, 0.47736411165047393, 0.47435270354316683, 0.47734868757399246], 'loss': [0.07165853343958686, 0.04977957356589811, 0.04507145093291394, 0.04220340500903736, 0.03959168096292791, 0.03826201773702103, 0.03693987386766507, 0.03568810942079577, 0.03508393214229116, 0.034133507163768693, 0.03374633696557453, 0.03298822398632629, 0.032544483716696014, 0.03234227073002054, 0.031755848578987264, 0.031599657284633334, 0.031200234202543736, 0.030905710233840335, 0.030509321760550677, 0.03058871011729659, 0.029753257372707148, 0.02973021193762563, 0.029644840553373943, 0.02937604036178176, 0.02937561786927013, 0.0291265515124543, 0.029199158511082183, 0.028462690540266514, 0.028309811222100776, 0.028715650092433476, 0.028197116147179645, 0.027977294565944517, 0.0277343063096244, 0.027864761874850975, 0.027881034319939695, 0.027588619642429226, 0.027310190762313426, 0.026508721924024814, 0.026214547848628665, 0.025775045665930394, 0.025937540051588454, 0.025993673577452577, 0.02624568859115169, 0.025334328061949088, 0.02545568282438829, 0.025764462144117733, 0.025200226972819234, 0.025154782184689074, 0.025412248084878276, 0.025211935360022312, 0.025100791677244546, 0.02490671072343622, 0.02440787455537557, 0.024355373047630587, 0.02438756431285711, 0.024035009105500663, 0.024243490823280787, 0.024281203101411606, 0.024160358523337176, 0.02390811204371276, 0.023852619257141775, 0.023761509935295966], 'acc': [0.992225111211698, 0.9944407854143368, 0.9949013158996382, 0.9952149112217108, 0.9954190442696664, 0.9955471291123333, 0.9956742389664619, 0.9957798208016101, 0.9958404690985857, 0.9959157629350269, 0.9959764640258362, 0.9960304772759763, 0.9960800509599769, 0.9961106999482232, 0.9961484008493916, 0.9961789832708832, 0.996204221683138, 0.9962517887830252, 0.9962653039878843, 0.996288435944617, 0.9963228448079455, 0.9963205206854239, 0.9963570900888761, 0.9963524418934776, 0.996375350516597, 0.9963763799821683, 0.9963985591156406, 0.9964492915926111, 0.9964648569390968, 0.9964534717829202, 0.9964554673718644, 0.9964927858297928, 0.9965056595347276, 0.9965170963003517, 0.9965248427694406, 0.9965286841662208, 0.9965386714961969, 0.996615792769487, 0.9966502886556442, 0.9966521541039587, 0.9966815531866102, 0.9966745897858645, 0.996682794948073, 0.9966982194211687, 0.996700948842509, 0.9967065448612146, 0.9967164215799298, 0.9967187119060765, 0.9967351029895382, 0.9967443611064605, 0.996735319545437, 0.9967438094709458, 0.9967845836223975, 0.996791028997244, 0.9967921080155445, 0.9968089999903134, 0.9968068935513397, 0.9968061109818097, 0.9968143435551099, 0.9968163203428111, 0.996825342171158, 0.9968305661365977], 'mDice': [0.8607189881724345, 0.9032682781888413, 0.9124328702651574, 0.9179986984226792, 0.9231102025972706, 0.9257006035137407, 0.9282753547582708, 0.9307197238387808, 0.9318941268402511, 0.9337526770087797, 0.9344945688308768, 0.9359809223896253, 0.9368459447814685, 0.9372281598868435, 0.9383777432684168, 0.9386797572919351, 0.9394660797396396, 0.9400328229099946, 0.9408115116747918, 0.9406381188459098, 0.9422943079877731, 0.9423389298149062, 0.9424920323177506, 0.9430308862731622, 0.9430205679037218, 0.9435176040885781, 0.9433549668851037, 0.9448038863463408, 0.9451063760037188, 0.9442999516442943, 0.9453253611967772, 0.9457512202230917, 0.9462345300750352, 0.9459619359661254, 0.9459269826256079, 0.9465117004438446, 0.94705987805221, 0.9486165302717874, 0.9491883990680742, 0.9500546054417776, 0.9497255494460013, 0.9496103311428513, 0.9491058255454226, 0.9509191410698412, 0.9506789107936966, 0.9500619077684387, 0.9511756819148324, 0.95126783545684, 0.9507486946011736, 0.951143838824253, 0.9513665061058852, 0.9517555157006277, 0.9527273065217479, 0.952823793687621, 0.9527583080386196, 0.953453154557379, 0.9530392233062914, 0.9529647584762992, 0.9532044982369263, 0.9537008933473862, 0.9538115770049056, 0.9539934839127353], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.41it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.79it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.23it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.82it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.13it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.37it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:46,  5.26it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:44,  5.45it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:46,  5.25it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:43,  5.57it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:41,  5.85it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<00:39,  6.10it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:38,  6.22it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:37,  6.34it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:36,  6.45it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.56it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:36,  6.55it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.44it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.37it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.49it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:37,  6.18it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:36,  6.31it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:35,  6.44it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:35,  6.53it/s]predicting train subjects:   8%|▊         | 19/247 [00:03<00:34,  6.58it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:34,  6.59it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:33,  6.70it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:33,  6.74it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:32,  6.96it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:31,  7.16it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:30,  7.28it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:29,  7.40it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:29,  7.46it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:29,  7.43it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:28,  7.54it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:28,  7.59it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:28,  7.61it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:28,  7.48it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:28,  7.58it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:28,  7.57it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:27,  7.61it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:27,  7.62it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:27,  7.64it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:27,  7.66it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:27,  7.65it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:27,  7.66it/s]predicting train subjects:  17%|█▋        | 41/247 [00:05<00:27,  7.54it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:27,  7.48it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:27,  7.44it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:27,  7.41it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:27,  7.35it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:27,  7.35it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:27,  7.35it/s]predicting train subjects:  19%|█▉        | 48/247 [00:06<00:27,  7.32it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:27,  7.33it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:26,  7.30it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:26,  7.29it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:26,  7.30it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:26,  7.33it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:26,  7.36it/s]predicting train subjects:  22%|██▏       | 55/247 [00:07<00:26,  7.35it/s]predicting train subjects:  23%|██▎       | 56/247 [00:07<00:25,  7.41it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:25,  7.40it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:26,  7.16it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:26,  6.97it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:27,  6.85it/s]predicting train subjects:  25%|██▍       | 61/247 [00:08<00:27,  6.77it/s]predicting train subjects:  25%|██▌       | 62/247 [00:08<00:27,  6.72it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:27,  6.69it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:27,  6.68it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:27,  6.70it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:27,  6.67it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:26,  6.72it/s]predicting train subjects:  28%|██▊       | 68/247 [00:09<00:26,  6.73it/s]predicting train subjects:  28%|██▊       | 69/247 [00:09<00:26,  6.68it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.44it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.50it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:26,  6.57it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:26,  6.64it/s]predicting train subjects:  30%|██▉       | 74/247 [00:10<00:25,  6.67it/s]predicting train subjects:  30%|███       | 75/247 [00:10<00:25,  6.68it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:25,  6.70it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:28,  6.00it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:31,  5.39it/s]predicting train subjects:  32%|███▏      | 79/247 [00:11<00:31,  5.25it/s]predicting train subjects:  32%|███▏      | 80/247 [00:11<00:28,  5.77it/s]predicting train subjects:  33%|███▎      | 81/247 [00:11<00:29,  5.70it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:28,  5.78it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:27,  6.01it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:26,  6.11it/s]predicting train subjects:  34%|███▍      | 85/247 [00:12<00:26,  6.20it/s]predicting train subjects:  35%|███▍      | 86/247 [00:12<00:25,  6.29it/s]predicting train subjects:  35%|███▌      | 87/247 [00:12<00:25,  6.29it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:25,  6.33it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:24,  6.40it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:24,  6.43it/s]predicting train subjects:  37%|███▋      | 91/247 [00:13<00:24,  6.49it/s]predicting train subjects:  37%|███▋      | 92/247 [00:13<00:23,  6.49it/s]predicting train subjects:  38%|███▊      | 93/247 [00:13<00:23,  6.47it/s]predicting train subjects:  38%|███▊      | 94/247 [00:13<00:23,  6.45it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:23,  6.49it/s]predicting train subjects:  39%|███▉      | 96/247 [00:14<00:23,  6.35it/s]predicting train subjects:  39%|███▉      | 97/247 [00:14<00:23,  6.27it/s]predicting train subjects:  40%|███▉      | 98/247 [00:14<00:23,  6.36it/s]predicting train subjects:  40%|████      | 99/247 [00:14<00:23,  6.41it/s]predicting train subjects:  40%|████      | 100/247 [00:14<00:23,  6.24it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:23,  6.16it/s]predicting train subjects:  41%|████▏     | 102/247 [00:15<00:23,  6.10it/s]predicting train subjects:  42%|████▏     | 103/247 [00:15<00:23,  6.04it/s]predicting train subjects:  42%|████▏     | 104/247 [00:15<00:23,  6.02it/s]predicting train subjects:  43%|████▎     | 105/247 [00:15<00:23,  5.98it/s]predicting train subjects:  43%|████▎     | 106/247 [00:15<00:23,  5.97it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:24,  5.67it/s]predicting train subjects:  44%|████▎     | 108/247 [00:16<00:24,  5.77it/s]predicting train subjects:  44%|████▍     | 109/247 [00:16<00:23,  5.81it/s]predicting train subjects:  45%|████▍     | 110/247 [00:16<00:23,  5.83it/s]predicting train subjects:  45%|████▍     | 111/247 [00:16<00:23,  5.80it/s]predicting train subjects:  45%|████▌     | 112/247 [00:16<00:23,  5.81it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:23,  5.75it/s]predicting train subjects:  46%|████▌     | 114/247 [00:17<00:23,  5.75it/s]predicting train subjects:  47%|████▋     | 115/247 [00:17<00:22,  5.80it/s]predicting train subjects:  47%|████▋     | 116/247 [00:17<00:22,  5.76it/s]predicting train subjects:  47%|████▋     | 117/247 [00:17<00:22,  5.75it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:21,  5.87it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:21,  5.98it/s]predicting train subjects:  49%|████▊     | 120/247 [00:18<00:21,  6.04it/s]predicting train subjects:  49%|████▉     | 121/247 [00:18<00:20,  6.07it/s]predicting train subjects:  49%|████▉     | 122/247 [00:18<00:20,  6.08it/s]predicting train subjects:  50%|████▉     | 123/247 [00:18<00:20,  6.05it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:20,  6.05it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:20,  6.05it/s]predicting train subjects:  51%|█████     | 126/247 [00:19<00:19,  6.06it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:19<00:20,  5.97it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:19<00:19,  6.04it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:19<00:19,  6.09it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:19<00:19,  6.12it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:19,  6.09it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:18,  6.10it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:20<00:18,  6.14it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:20<00:18,  6.15it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:20<00:18,  6.16it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:20<00:17,  6.47it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:21<00:16,  6.73it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:15,  6.82it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:21<00:15,  7.01it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:21<00:15,  7.11it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:21<00:15,  7.03it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:21<00:14,  7.14it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:21<00:14,  7.26it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:22<00:13,  7.37it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:13,  7.39it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:22<00:13,  7.35it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:22<00:13,  7.38it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:22<00:13,  7.36it/s]predicting train subjects:  60%|██████    | 149/247 [00:22<00:13,  7.36it/s]predicting train subjects:  61%|██████    | 150/247 [00:22<00:13,  7.38it/s]predicting train subjects:  61%|██████    | 151/247 [00:22<00:13,  7.29it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:12,  7.34it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:23<00:12,  7.35it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:23<00:12,  7.28it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:23<00:12,  7.23it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:23<00:12,  7.20it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:23<00:12,  7.14it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:23<00:12,  6.99it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:24<00:12,  6.87it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:24<00:12,  6.75it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:24<00:12,  6.79it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:24<00:12,  6.84it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:24<00:12,  6.88it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:24<00:12,  6.80it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:25<00:12,  6.82it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:25<00:11,  6.88it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:25<00:11,  6.86it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:25<00:11,  6.84it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:25<00:11,  6.87it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:25<00:11,  6.74it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:25<00:11,  6.86it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:26<00:10,  6.93it/s]predicting train subjects:  70%|███████   | 173/247 [00:26<00:12,  6.06it/s]predicting train subjects:  70%|███████   | 174/247 [00:26<00:11,  6.37it/s]predicting train subjects:  71%|███████   | 175/247 [00:26<00:12,  5.74it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:26<00:11,  6.01it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:26<00:11,  6.24it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:27<00:10,  6.44it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:27<00:10,  6.59it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:27<00:10,  6.63it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:27<00:09,  6.71it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:27<00:09,  6.73it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:27<00:09,  6.68it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:27<00:09,  6.67it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:28<00:09,  6.76it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:28<00:08,  6.84it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:28<00:08,  6.88it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:28<00:08,  6.90it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:28<00:08,  6.92it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:28<00:08,  6.93it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:28<00:08,  6.93it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:29<00:07,  6.89it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:29<00:07,  6.90it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:29<00:07,  7.09it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:29<00:07,  7.22it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:29<00:06,  7.34it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:29<00:06,  7.42it/s]predicting train subjects:  80%|████████  | 198/247 [00:29<00:06,  7.42it/s]predicting train subjects:  81%|████████  | 199/247 [00:30<00:06,  7.46it/s]predicting train subjects:  81%|████████  | 200/247 [00:30<00:06,  7.50it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:30<00:06,  7.53it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:30<00:05,  7.50it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:30<00:06,  7.32it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:30<00:05,  7.22it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:30<00:05,  7.30it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:30<00:05,  7.34it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:31<00:05,  7.33it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:31<00:05,  7.41it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:31<00:05,  7.43it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:31<00:04,  7.49it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:31<00:04,  7.54it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:31<00:04,  7.43it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:31<00:04,  7.34it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:32<00:04,  7.33it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:32<00:04,  7.18it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:32<00:04,  7.18it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:32<00:04,  7.14it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:32<00:04,  7.18it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:32<00:03,  7.24it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:32<00:03,  7.15it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:33<00:03,  7.14it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:33<00:03,  7.19it/s]predicting train subjects:  90%|█████████ | 223/247 [00:33<00:03,  7.23it/s]predicting train subjects:  91%|█████████ | 224/247 [00:33<00:03,  7.20it/s]predicting train subjects:  91%|█████████ | 225/247 [00:33<00:03,  7.24it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:33<00:02,  7.27it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:33<00:02,  7.24it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:33<00:02,  7.25it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:34<00:02,  7.25it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:34<00:02,  6.93it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:34<00:02,  6.71it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:34<00:02,  6.55it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:34<00:02,  6.41it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:34<00:02,  6.34it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:35<00:01,  6.28it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:35<00:01,  6.15it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:35<00:01,  6.18it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:35<00:01,  6.19it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:35<00:01,  6.12it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:35<00:01,  6.08it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:36<00:00,  6.07it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:36<00:00,  6.11it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:36<00:00,  6.13it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:36<00:00,  6.11it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:36<00:00,  6.06it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:36<00:00,  6.14it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  6.10it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  6.66it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 73.91it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/247 [00:00<00:02, 79.83it/s]saving BB  train1-THALAMUS:   6%|▋         | 16/247 [00:00<00:02, 79.42it/s]saving BB  train1-THALAMUS:  10%|█         | 25/247 [00:00<00:02, 81.01it/s]saving BB  train1-THALAMUS:  14%|█▍        | 34/247 [00:00<00:02, 83.25it/s]saving BB  train1-THALAMUS:  17%|█▋        | 43/247 [00:00<00:02, 84.73it/s]saving BB  train1-THALAMUS:  21%|██▏       | 53/247 [00:00<00:02, 86.88it/s]saving BB  train1-THALAMUS:  25%|██▌       | 62/247 [00:00<00:02, 86.49it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 84.97it/s]saving BB  train1-THALAMUS:  32%|███▏      | 80/247 [00:00<00:01, 83.52it/s]saving BB  train1-THALAMUS:  36%|███▌      | 89/247 [00:01<00:01, 81.75it/s]saving BB  train1-THALAMUS:  39%|███▉      | 97/247 [00:01<00:01, 80.82it/s]saving BB  train1-THALAMUS:  43%|████▎     | 105/247 [00:01<00:01, 78.42it/s]saving BB  train1-THALAMUS:  46%|████▌     | 113/247 [00:01<00:01, 75.66it/s]saving BB  train1-THALAMUS:  49%|████▉     | 121/247 [00:01<00:01, 76.13it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 129/247 [00:01<00:01, 74.61it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 76.07it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 146/247 [00:01<00:01, 79.49it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 155/247 [00:01<00:01, 82.09it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 165/247 [00:02<00:00, 84.65it/s]saving BB  train1-THALAMUS:  71%|███████   | 175/247 [00:02<00:00, 86.16it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 184/247 [00:02<00:00, 85.08it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 193/247 [00:02<00:00, 84.42it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 202/247 [00:02<00:00, 85.48it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 211/247 [00:02<00:00, 85.50it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 221/247 [00:02<00:00, 87.05it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 230/247 [00:02<00:00, 87.32it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 239/247 [00:02<00:00, 84.06it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:02<00:00, 82.69it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:58,  1.03it/s]Loading train:   1%|          | 2/247 [00:01<03:47,  1.08it/s]Loading train:   1%|          | 3/247 [00:02<03:36,  1.13it/s]Loading train:   2%|▏         | 4/247 [00:03<03:41,  1.10it/s]Loading train:   2%|▏         | 5/247 [00:04<03:19,  1.21it/s]Loading train:   2%|▏         | 6/247 [00:04<03:05,  1.30it/s]Loading train:   3%|▎         | 7/247 [00:05<02:54,  1.37it/s]Loading train:   3%|▎         | 8/247 [00:06<02:47,  1.43it/s]Loading train:   4%|▎         | 9/247 [00:06<02:41,  1.48it/s]Loading train:   4%|▍         | 10/247 [00:07<02:37,  1.50it/s]Loading train:   4%|▍         | 11/247 [00:07<02:34,  1.53it/s]Loading train:   5%|▍         | 12/247 [00:08<02:31,  1.55it/s]Loading train:   5%|▌         | 13/247 [00:09<02:29,  1.56it/s]Loading train:   6%|▌         | 14/247 [00:09<02:28,  1.57it/s]Loading train:   6%|▌         | 15/247 [00:10<02:29,  1.55it/s]Loading train:   6%|▋         | 16/247 [00:11<02:27,  1.57it/s]Loading train:   7%|▋         | 17/247 [00:11<02:25,  1.58it/s]Loading train:   7%|▋         | 18/247 [00:12<02:23,  1.60it/s]Loading train:   8%|▊         | 19/247 [00:12<02:22,  1.61it/s]Loading train:   8%|▊         | 20/247 [00:13<02:20,  1.62it/s]Loading train:   9%|▊         | 21/247 [00:14<02:18,  1.63it/s]Loading train:   9%|▉         | 22/247 [00:14<02:17,  1.63it/s]Loading train:   9%|▉         | 23/247 [00:15<02:13,  1.68it/s]Loading train:  10%|▉         | 24/247 [00:15<02:09,  1.73it/s]Loading train:  10%|█         | 25/247 [00:16<02:05,  1.76it/s]Loading train:  11%|█         | 26/247 [00:16<02:03,  1.79it/s]Loading train:  11%|█         | 27/247 [00:17<02:01,  1.81it/s]Loading train:  11%|█▏        | 28/247 [00:18<01:59,  1.84it/s]Loading train:  12%|█▏        | 29/247 [00:18<01:57,  1.85it/s]Loading train:  12%|█▏        | 30/247 [00:19<01:57,  1.84it/s]Loading train:  13%|█▎        | 31/247 [00:19<01:58,  1.82it/s]Loading train:  13%|█▎        | 32/247 [00:20<01:59,  1.80it/s]Loading train:  13%|█▎        | 33/247 [00:20<01:58,  1.81it/s]Loading train:  14%|█▍        | 34/247 [00:21<01:57,  1.82it/s]Loading train:  14%|█▍        | 35/247 [00:21<01:57,  1.80it/s]Loading train:  15%|█▍        | 36/247 [00:22<01:56,  1.81it/s]Loading train:  15%|█▍        | 37/247 [00:23<01:56,  1.80it/s]Loading train:  15%|█▌        | 38/247 [00:23<01:55,  1.81it/s]Loading train:  16%|█▌        | 39/247 [00:24<01:54,  1.82it/s]Loading train:  16%|█▌        | 40/247 [00:24<01:53,  1.83it/s]Loading train:  17%|█▋        | 41/247 [00:25<01:55,  1.78it/s]Loading train:  17%|█▋        | 42/247 [00:25<01:54,  1.79it/s]Loading train:  17%|█▋        | 43/247 [00:26<01:53,  1.79it/s]Loading train:  18%|█▊        | 44/247 [00:26<01:53,  1.79it/s]Loading train:  18%|█▊        | 45/247 [00:27<01:53,  1.78it/s]Loading train:  19%|█▊        | 46/247 [00:28<01:53,  1.77it/s]Loading train:  19%|█▉        | 47/247 [00:28<01:53,  1.76it/s]Loading train:  19%|█▉        | 48/247 [00:29<01:52,  1.77it/s]Loading train:  20%|█▉        | 49/247 [00:29<01:52,  1.76it/s]Loading train:  20%|██        | 50/247 [00:30<01:51,  1.77it/s]Loading train:  21%|██        | 51/247 [00:30<01:50,  1.78it/s]Loading train:  21%|██        | 52/247 [00:31<01:49,  1.78it/s]Loading train:  21%|██▏       | 53/247 [00:32<01:49,  1.77it/s]Loading train:  22%|██▏       | 54/247 [00:32<01:49,  1.77it/s]Loading train:  22%|██▏       | 55/247 [00:33<01:50,  1.74it/s]Loading train:  23%|██▎       | 56/247 [00:33<01:49,  1.74it/s]Loading train:  23%|██▎       | 57/247 [00:34<01:49,  1.74it/s]Loading train:  23%|██▎       | 58/247 [00:34<01:48,  1.74it/s]Loading train:  24%|██▍       | 59/247 [00:35<01:50,  1.71it/s]Loading train:  24%|██▍       | 60/247 [00:36<01:52,  1.67it/s]Loading train:  25%|██▍       | 61/247 [00:36<01:51,  1.66it/s]Loading train:  25%|██▌       | 62/247 [00:37<01:51,  1.65it/s]Loading train:  26%|██▌       | 63/247 [00:37<01:51,  1.66it/s]Loading train:  26%|██▌       | 64/247 [00:38<01:52,  1.63it/s]Loading train:  26%|██▋       | 65/247 [00:39<01:51,  1.64it/s]Loading train:  27%|██▋       | 66/247 [00:39<01:50,  1.64it/s]Loading train:  27%|██▋       | 67/247 [00:40<01:52,  1.61it/s]Loading train:  28%|██▊       | 68/247 [00:41<01:50,  1.62it/s]Loading train:  28%|██▊       | 69/247 [00:41<01:48,  1.64it/s]Loading train:  28%|██▊       | 70/247 [00:42<01:48,  1.64it/s]Loading train:  29%|██▊       | 71/247 [00:42<01:47,  1.64it/s]Loading train:  29%|██▉       | 72/247 [00:43<01:47,  1.62it/s]Loading train:  30%|██▉       | 73/247 [00:44<01:47,  1.62it/s]Loading train:  30%|██▉       | 74/247 [00:44<01:45,  1.63it/s]Loading train:  30%|███       | 75/247 [00:45<01:45,  1.63it/s]Loading train:  31%|███       | 76/247 [00:45<01:46,  1.61it/s]Loading train:  31%|███       | 77/247 [00:46<02:01,  1.40it/s]Loading train:  32%|███▏      | 78/247 [00:47<02:15,  1.25it/s]Loading train:  32%|███▏      | 79/247 [00:48<02:18,  1.21it/s]Loading train:  32%|███▏      | 80/247 [00:49<02:14,  1.24it/s]Loading train:  33%|███▎      | 81/247 [00:50<02:13,  1.24it/s]Loading train:  33%|███▎      | 82/247 [00:51<02:06,  1.31it/s]Loading train:  34%|███▎      | 83/247 [00:51<01:59,  1.37it/s]Loading train:  34%|███▍      | 84/247 [00:52<01:55,  1.41it/s]Loading train:  34%|███▍      | 85/247 [00:53<01:54,  1.41it/s]Loading train:  35%|███▍      | 86/247 [00:53<01:51,  1.44it/s]Loading train:  35%|███▌      | 87/247 [00:54<01:51,  1.44it/s]Loading train:  36%|███▌      | 88/247 [00:55<01:50,  1.44it/s]Loading train:  36%|███▌      | 89/247 [00:55<01:47,  1.47it/s]Loading train:  36%|███▋      | 90/247 [00:56<01:44,  1.51it/s]Loading train:  37%|███▋      | 91/247 [00:57<01:42,  1.52it/s]Loading train:  37%|███▋      | 92/247 [00:57<01:42,  1.51it/s]Loading train:  38%|███▊      | 93/247 [00:58<01:40,  1.53it/s]Loading train:  38%|███▊      | 94/247 [00:58<01:40,  1.53it/s]Loading train:  38%|███▊      | 95/247 [00:59<01:39,  1.53it/s]Loading train:  39%|███▉      | 96/247 [01:00<01:40,  1.51it/s]Loading train:  39%|███▉      | 97/247 [01:00<01:39,  1.50it/s]Loading train:  40%|███▉      | 98/247 [01:01<01:38,  1.51it/s]Loading train:  40%|████      | 99/247 [01:02<01:38,  1.50it/s]Loading train:  40%|████      | 100/247 [01:03<01:39,  1.48it/s]Loading train:  41%|████      | 101/247 [01:03<01:37,  1.50it/s]Loading train:  41%|████▏     | 102/247 [01:04<01:36,  1.50it/s]Loading train:  42%|████▏     | 103/247 [01:05<01:37,  1.48it/s]Loading train:  42%|████▏     | 104/247 [01:05<01:35,  1.49it/s]Loading train:  43%|████▎     | 105/247 [01:06<01:33,  1.51it/s]Loading train:  43%|████▎     | 106/247 [01:06<01:33,  1.51it/s]Loading train:  43%|████▎     | 107/247 [01:07<01:33,  1.50it/s]Loading train:  44%|████▎     | 108/247 [01:08<01:32,  1.50it/s]Loading train:  44%|████▍     | 109/247 [01:09<01:32,  1.49it/s]Loading train:  45%|████▍     | 110/247 [01:09<01:31,  1.49it/s]Loading train:  45%|████▍     | 111/247 [01:10<01:30,  1.51it/s]Loading train:  45%|████▌     | 112/247 [01:10<01:29,  1.52it/s]Loading train:  46%|████▌     | 113/247 [01:11<01:28,  1.51it/s]Loading train:  46%|████▌     | 114/247 [01:12<01:28,  1.50it/s]Loading train:  47%|████▋     | 115/247 [01:13<01:30,  1.46it/s]Loading train:  47%|████▋     | 116/247 [01:13<01:28,  1.48it/s]Loading train:  47%|████▋     | 117/247 [01:14<01:29,  1.46it/s]Loading train:  48%|████▊     | 118/247 [01:15<01:28,  1.45it/s]Loading train:  48%|████▊     | 119/247 [01:15<01:27,  1.46it/s]Loading train:  49%|████▊     | 120/247 [01:16<01:25,  1.48it/s]Loading train:  49%|████▉     | 121/247 [01:17<01:25,  1.48it/s]Loading train:  49%|████▉     | 122/247 [01:17<01:23,  1.49it/s]Loading train:  50%|████▉     | 123/247 [01:18<01:24,  1.47it/s]Loading train:  50%|█████     | 124/247 [01:19<01:24,  1.45it/s]Loading train:  51%|█████     | 125/247 [01:19<01:23,  1.45it/s]Loading train:  51%|█████     | 126/247 [01:20<01:22,  1.46it/s]Loading train:  51%|█████▏    | 127/247 [01:21<01:21,  1.47it/s]Loading train:  52%|█████▏    | 128/247 [01:21<01:19,  1.50it/s]Loading train:  52%|█████▏    | 129/247 [01:22<01:19,  1.48it/s]Loading train:  53%|█████▎    | 130/247 [01:23<01:18,  1.49it/s]Loading train:  53%|█████▎    | 131/247 [01:23<01:18,  1.48it/s]Loading train:  53%|█████▎    | 132/247 [01:24<01:17,  1.48it/s]Loading train:  54%|█████▍    | 133/247 [01:25<01:17,  1.47it/s]Loading train:  54%|█████▍    | 134/247 [01:25<01:17,  1.46it/s]Loading train:  55%|█████▍    | 135/247 [01:26<01:16,  1.47it/s]Loading train:  55%|█████▌    | 136/247 [01:27<01:12,  1.53it/s]Loading train:  55%|█████▌    | 137/247 [01:27<01:10,  1.55it/s]Loading train:  56%|█████▌    | 138/247 [01:28<01:08,  1.59it/s]Loading train:  56%|█████▋    | 139/247 [01:29<01:07,  1.60it/s]Loading train:  57%|█████▋    | 140/247 [01:29<01:05,  1.64it/s]Loading train:  57%|█████▋    | 141/247 [01:30<01:03,  1.66it/s]Loading train:  57%|█████▋    | 142/247 [01:30<01:02,  1.68it/s]Loading train:  58%|█████▊    | 143/247 [01:31<01:01,  1.70it/s]Loading train:  58%|█████▊    | 144/247 [01:31<01:00,  1.70it/s]Loading train:  59%|█████▊    | 145/247 [01:32<01:00,  1.69it/s]Loading train:  59%|█████▉    | 146/247 [01:33<01:00,  1.68it/s]Loading train:  60%|█████▉    | 147/247 [01:33<00:59,  1.69it/s]Loading train:  60%|█████▉    | 148/247 [01:34<00:58,  1.68it/s]Loading train:  60%|██████    | 149/247 [01:34<00:58,  1.68it/s]Loading train:  61%|██████    | 150/247 [01:35<00:57,  1.67it/s]Loading train:  61%|██████    | 151/247 [01:36<00:58,  1.65it/s]Loading train:  62%|██████▏   | 152/247 [01:36<00:57,  1.66it/s]Loading train:  62%|██████▏   | 153/247 [01:37<00:57,  1.65it/s]Loading train:  62%|██████▏   | 154/247 [01:37<00:55,  1.68it/s]Loading train:  63%|██████▎   | 155/247 [01:38<00:54,  1.70it/s]Loading train:  63%|██████▎   | 156/247 [01:39<00:52,  1.72it/s]Loading train:  64%|██████▎   | 157/247 [01:39<00:51,  1.75it/s]Loading train:  64%|██████▍   | 158/247 [01:40<00:50,  1.75it/s]Loading train:  64%|██████▍   | 159/247 [01:40<00:50,  1.75it/s]Loading train:  65%|██████▍   | 160/247 [01:41<00:49,  1.77it/s]Loading train:  65%|██████▌   | 161/247 [01:41<00:48,  1.78it/s]Loading train:  66%|██████▌   | 162/247 [01:42<00:47,  1.78it/s]Loading train:  66%|██████▌   | 163/247 [01:43<00:47,  1.78it/s]Loading train:  66%|██████▋   | 164/247 [01:43<00:45,  1.81it/s]Loading train:  67%|██████▋   | 165/247 [01:44<00:45,  1.80it/s]Loading train:  67%|██████▋   | 166/247 [01:44<00:45,  1.78it/s]Loading train:  68%|██████▊   | 167/247 [01:45<00:45,  1.77it/s]Loading train:  68%|██████▊   | 168/247 [01:45<00:44,  1.78it/s]Loading train:  68%|██████▊   | 169/247 [01:46<00:43,  1.79it/s]Loading train:  69%|██████▉   | 170/247 [01:46<00:43,  1.79it/s]Loading train:  69%|██████▉   | 171/247 [01:47<00:42,  1.77it/s]Loading train:  70%|██████▉   | 172/247 [01:48<00:49,  1.51it/s]Loading train:  70%|███████   | 173/247 [01:49<00:52,  1.41it/s]Loading train:  70%|███████   | 174/247 [01:50<00:53,  1.36it/s]Loading train:  71%|███████   | 175/247 [01:50<00:58,  1.23it/s]Loading train:  71%|███████▏  | 176/247 [01:51<00:53,  1.33it/s]Loading train:  72%|███████▏  | 177/247 [01:52<00:49,  1.42it/s]Loading train:  72%|███████▏  | 178/247 [01:52<00:46,  1.49it/s]Loading train:  72%|███████▏  | 179/247 [01:53<00:44,  1.54it/s]Loading train:  73%|███████▎  | 180/247 [01:53<00:42,  1.59it/s]Loading train:  73%|███████▎  | 181/247 [01:54<00:41,  1.60it/s]Loading train:  74%|███████▎  | 182/247 [01:55<00:40,  1.62it/s]Loading train:  74%|███████▍  | 183/247 [01:55<00:39,  1.62it/s]Loading train:  74%|███████▍  | 184/247 [01:56<00:38,  1.62it/s]Loading train:  75%|███████▍  | 185/247 [01:57<00:37,  1.63it/s]Loading train:  75%|███████▌  | 186/247 [01:57<00:37,  1.64it/s]Loading train:  76%|███████▌  | 187/247 [01:58<00:36,  1.63it/s]Loading train:  76%|███████▌  | 188/247 [01:58<00:36,  1.62it/s]Loading train:  77%|███████▋  | 189/247 [01:59<00:35,  1.61it/s]Loading train:  77%|███████▋  | 190/247 [02:00<00:35,  1.59it/s]Loading train:  77%|███████▋  | 191/247 [02:00<00:35,  1.59it/s]Loading train:  78%|███████▊  | 192/247 [02:01<00:34,  1.60it/s]Loading train:  78%|███████▊  | 193/247 [02:02<00:34,  1.57it/s]Loading train:  79%|███████▊  | 194/247 [02:02<00:33,  1.60it/s]Loading train:  79%|███████▉  | 195/247 [02:03<00:32,  1.59it/s]Loading train:  79%|███████▉  | 196/247 [02:03<00:31,  1.62it/s]Loading train:  80%|███████▉  | 197/247 [02:04<00:30,  1.64it/s]Loading train:  80%|████████  | 198/247 [02:05<00:29,  1.66it/s]Loading train:  81%|████████  | 199/247 [02:05<00:28,  1.68it/s]Loading train:  81%|████████  | 200/247 [02:06<00:27,  1.69it/s]Loading train:  81%|████████▏ | 201/247 [02:06<00:27,  1.69it/s]Loading train:  82%|████████▏ | 202/247 [02:07<00:27,  1.65it/s]Loading train:  82%|████████▏ | 203/247 [02:08<00:26,  1.66it/s]Loading train:  83%|████████▎ | 204/247 [02:08<00:25,  1.67it/s]Loading train:  83%|████████▎ | 205/247 [02:09<00:25,  1.68it/s]Loading train:  83%|████████▎ | 206/247 [02:09<00:24,  1.68it/s]Loading train:  84%|████████▍ | 207/247 [02:10<00:24,  1.66it/s]Loading train:  84%|████████▍ | 208/247 [02:11<00:23,  1.63it/s]Loading train:  85%|████████▍ | 209/247 [02:11<00:23,  1.64it/s]Loading train:  85%|████████▌ | 210/247 [02:12<00:22,  1.65it/s]Loading train:  85%|████████▌ | 211/247 [02:12<00:21,  1.66it/s]Loading train:  86%|████████▌ | 212/247 [02:13<00:20,  1.67it/s]Loading train:  86%|████████▌ | 213/247 [02:14<00:20,  1.66it/s]Loading train:  87%|████████▋ | 214/247 [02:14<00:20,  1.64it/s]Loading train:  87%|████████▋ | 215/247 [02:15<00:19,  1.64it/s]Loading train:  87%|████████▋ | 216/247 [02:15<00:18,  1.65it/s]Loading train:  88%|████████▊ | 217/247 [02:16<00:18,  1.64it/s]Loading train:  88%|████████▊ | 218/247 [02:17<00:17,  1.65it/s]Loading train:  89%|████████▊ | 219/247 [02:17<00:16,  1.66it/s]Loading train:  89%|████████▉ | 220/247 [02:18<00:16,  1.65it/s]Loading train:  89%|████████▉ | 221/247 [02:18<00:15,  1.65it/s]Loading train:  90%|████████▉ | 222/247 [02:19<00:15,  1.65it/s]Loading train:  90%|█████████ | 223/247 [02:20<00:14,  1.66it/s]Loading train:  91%|█████████ | 224/247 [02:20<00:13,  1.65it/s]Loading train:  91%|█████████ | 225/247 [02:21<00:13,  1.64it/s]Loading train:  91%|█████████▏| 226/247 [02:21<00:12,  1.63it/s]Loading train:  92%|█████████▏| 227/247 [02:22<00:12,  1.62it/s]Loading train:  92%|█████████▏| 228/247 [02:23<00:11,  1.62it/s]Loading train:  93%|█████████▎| 229/247 [02:23<00:11,  1.63it/s]Loading train:  93%|█████████▎| 230/247 [02:24<00:11,  1.54it/s]Loading train:  94%|█████████▎| 231/247 [02:25<00:10,  1.48it/s]Loading train:  94%|█████████▍| 232/247 [02:26<00:10,  1.45it/s]Loading train:  94%|█████████▍| 233/247 [02:26<00:09,  1.43it/s]Loading train:  95%|█████████▍| 234/247 [02:27<00:09,  1.40it/s]Loading train:  95%|█████████▌| 235/247 [02:28<00:08,  1.40it/s]Loading train:  96%|█████████▌| 236/247 [02:28<00:07,  1.40it/s]Loading train:  96%|█████████▌| 237/247 [02:29<00:07,  1.40it/s]Loading train:  96%|█████████▋| 238/247 [02:30<00:06,  1.40it/s]Loading train:  97%|█████████▋| 239/247 [02:31<00:05,  1.38it/s]Loading train:  97%|█████████▋| 240/247 [02:31<00:05,  1.37it/s]Loading train:  98%|█████████▊| 241/247 [02:32<00:04,  1.36it/s]Loading train:  98%|█████████▊| 242/247 [02:33<00:03,  1.36it/s]Loading train:  98%|█████████▊| 243/247 [02:34<00:02,  1.34it/s]Loading train:  99%|█████████▉| 244/247 [02:34<00:02,  1.33it/s]Loading train:  99%|█████████▉| 245/247 [02:35<00:01,  1.32it/s]Loading train: 100%|█████████▉| 246/247 [02:36<00:00,  1.31it/s]Loading train: 100%|██████████| 247/247 [02:37<00:00,  1.31it/s]Loading train: 100%|██████████| 247/247 [02:37<00:00,  1.57it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 57.22it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 56.12it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 55.81it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:03, 57.43it/s]concatenating: train:  13%|█▎        | 32/247 [00:00<00:03, 59.07it/s]concatenating: train:  15%|█▌        | 38/247 [00:00<00:03, 59.22it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:03, 60.32it/s]concatenating: train:  21%|██        | 52/247 [00:00<00:03, 62.07it/s]concatenating: train:  24%|██▍       | 59/247 [00:00<00:02, 63.48it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:02, 63.69it/s]concatenating: train:  30%|██▉       | 73/247 [00:01<00:02, 64.07it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:02, 63.39it/s]concatenating: train:  35%|███▌      | 87/247 [00:01<00:02, 62.86it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:02, 62.22it/s]concatenating: train:  41%|████      | 101/247 [00:01<00:02, 61.86it/s]concatenating: train:  44%|████▎     | 108/247 [00:01<00:02, 62.69it/s]concatenating: train:  47%|████▋     | 115/247 [00:01<00:02, 63.13it/s]concatenating: train:  49%|████▉     | 122/247 [00:01<00:02, 60.49it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 58.23it/s]concatenating: train:  55%|█████▌    | 136/247 [00:02<00:01, 59.27it/s]concatenating: train:  57%|█████▋    | 142/247 [00:02<00:01, 58.61it/s]concatenating: train:  60%|██████    | 149/247 [00:02<00:01, 59.81it/s]concatenating: train:  64%|██████▎   | 157/247 [00:02<00:01, 63.68it/s]concatenating: train:  67%|██████▋   | 165/247 [00:02<00:01, 65.99it/s]concatenating: train:  70%|███████   | 173/247 [00:02<00:01, 69.41it/s]concatenating: train:  73%|███████▎  | 181/247 [00:02<00:00, 69.07it/s]concatenating: train:  76%|███████▌  | 188/247 [00:02<00:00, 68.11it/s]concatenating: train:  79%|███████▉  | 195/247 [00:03<00:00, 68.48it/s]concatenating: train:  82%|████████▏ | 202/247 [00:03<00:00, 68.01it/s]concatenating: train:  85%|████████▍ | 209/247 [00:03<00:00, 63.58it/s]concatenating: train:  87%|████████▋ | 216/247 [00:03<00:00, 60.57it/s]concatenating: train:  90%|█████████ | 223/247 [00:03<00:00, 58.85it/s]concatenating: train:  93%|█████████▎| 229/247 [00:03<00:00, 56.93it/s]concatenating: train:  96%|█████████▌| 236/247 [00:03<00:00, 59.74it/s]concatenating: train:  98%|█████████▊| 243/247 [00:03<00:00, 62.07it/s]concatenating: train: 100%|██████████| 247/247 [00:03<00:00, 62.45it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:15<01:00, 15.01s/it]Loading test:  40%|████      | 2/5 [00:27<00:42, 14.30s/it]Loading test:  60%|██████    | 3/5 [00:37<00:25, 12.87s/it]Loading test:  80%|████████  | 4/5 [00:44<00:11, 11.14s/it]Loading test: 100%|██████████| 5/5 [00:55<00:00, 11.16s/it]Loading test: 100%|██████████| 5/5 [00:55<00:00, 11.10s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00, 38.81it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 43.37it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      2020-01-21 20:42:15.982803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 20:42:15.982893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 20:42:15.982908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 20:42:15.982915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 20:42:15.983224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.23734066e-02 3.14612062e-02 7.87373782e-02 9.59012732e-03
 2.85756661e-02 7.23233383e-03 8.58313381e-02 1.15196838e-01
 9.01085667e-02 1.30692723e-02 2.94186214e-01 1.83388239e-01
 2.49413668e-04]
Train on 15720 samples, validate on 324 samples
Epoch 1/300
 - 35s - loss: 0.4684 - acc: 0.9324 - mDice: 0.4949 - val_loss: -3.9953e-02 - val_acc: 0.9444 - val_mDice: 0.2216

Epoch 00001: val_mDice improved from -inf to 0.22164, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 31s - loss: 0.3860 - acc: 0.9427 - mDice: 0.5839 - val_loss: -5.8501e-02 - val_acc: 0.9463 - val_mDice: 0.2246

Epoch 00002: val_mDice improved from 0.22164 to 0.22458, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 30s - loss: 0.3720 - acc: 0.9447 - mDice: 0.5991 - val_loss: -4.6671e-02 - val_acc: 0.9451 - val_mDice: 0.2189

Epoch 00003: val_mDice did not improve from 0.22458
Epoch 4/300
 - 30s - loss: 0.3564 - acc: 0.9467 - mDice: 0.6159 - val_loss: -1.3522e-01 - val_acc: 0.9481 - val_mDice: 0.2195

Epoch 00004: val_mDice did not improve from 0.22458
Epoch 5/300
 - 30s - loss: 0.3468 - acc: 0.9478 - mDice: 0.6263 - val_loss: -1.3164e-01 - val_acc: 0.9467 - val_mDice: 0.2220

Epoch 00005: val_mDice did not improve from 0.22458
Epoch 6/300
 - 31s - loss: 0.3410 - acc: 0.9487 - mDice: 0.6325 - val_loss: -5.9432e-02 - val_acc: 0.9462 - val_mDice: 0.2199

Epoch 00006: val_mDice did not improve from 0.22458
Epoch 7/300
 - 31s - loss: 0.3323 - acc: 0.9497 - mDice: 0.6419 - val_loss: -1.5560e-01 - val_acc: 0.9503 - val_mDice: 0.2225

Epoch 00007: val_mDice did not improve from 0.22458
Epoch 8/300
 - 32s - loss: 0.3255 - acc: 0.9501 - mDice: 0.6493 - val_loss: -1.4024e-01 - val_acc: 0.9484 - val_mDice: 0.2208

Epoch 00008: val_mDice did not improve from 0.22458
Epoch 9/300
 - 32s - loss: 0.3205 - acc: 0.9506 - mDice: 0.6546 - val_loss: -2.3541e-01 - val_acc: 0.9511 - val_mDice: 0.2244

Epoch 00009: val_mDice did not improve from 0.22458
Epoch 10/300
 - 32s - loss: 0.3198 - acc: 0.9511 - mDice: 0.6553 - val_loss: -8.9491e-02 - val_acc: 0.9492 - val_mDice: 0.2225

Epoch 00010: val_mDice did not improve from 0.22458
Epoch 11/300
 - 31s - loss: 0.3186 - acc: 0.9513 - mDice: 0.6567 - val_loss: -2.7366e-02 - val_acc: 0.9438 - val_mDice: 0.1880

Epoch 00011: val_mDice did not improve from 0.22458
Epoch 12/300
 - 31s - loss: 0.3104 - acc: 0.9519 - mDice: 0.6655 - val_loss: -1.9831e-01 - val_acc: 0.9473 - val_mDice: 0.2174

Epoch 00012: val_mDice did not improve from 0.22458
Epoch 13/300
 - 32s - loss: 0.3109 - acc: 0.9524 - mDice: 0.6650 - val_loss: -1.8556e-01 - val_acc: 0.9496 - val_mDice: 0.2213

Epoch 00013: val_mDice did not improve from 0.22458
Epoch 14/300
 - 31s - loss: 0.3063 - acc: 0.9527 - mDice: 0.6699 - val_loss: -1.7016e-01 - val_acc: 0.9508 - val_mDice: 0.2240

Epoch 00014: val_mDice did not improve from 0.22458
Epoch 15/300
 - 31s - loss: 0.3068 - acc: 0.9526 - mDice: 0.6694 - val_loss: -1.9000e-01 - val_acc: 0.9489 - val_mDice: 0.2240

Epoch 00015: val_mDice did not improve from 0.22458
Epoch 16/300
 - 31s - loss: 0.3047 - acc: 0.9529 - mDice: 0.6716 - val_loss: -1.4907e-01 - val_acc: 0.9486 - val_mDice: 0.2191

Epoch 00016: val_mDice did not improve from 0.22458
Epoch 17/300
 - 32s - loss: 0.3070 - acc: 0.9527 - mDice: 0.6691 - val_loss: -2.0410e-01 - val_acc: 0.9494 - val_mDice: 0.2256

Epoch 00017: val_mDice improved from 0.22458 to 0.22564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 32s - loss: 0.3038 - acc: 0.9533 - mDice: 0.6726 - val_loss: -1.2472e-01 - val_acc: 0.9492 - val_mDice: 0.2184

Epoch 00018: val_mDice did not improve from 0.22564
Epoch 19/300
 - 32s - loss: 0.3040 - acc: 0.9527 - mDice: 0.6700 - val_loss: -1.3963e-01 - val_acc: 0.9446 - val_mDice: 0.2134

Epoch 00019: val_mDice did not improve from 0.22564
Epoch 20/300
 - 31s - loss: 0.3070 - acc: 0.9496 - mDice: 0.6420 - val_loss: -2.1655e-01 - val_acc: 0.9474 - val_mDice: 0.2165

Epoch 00020: val_mDice did not improve from 0.22564
Epoch 21/300
 - 32s - loss: 0.2884 - acc: 0.9492 - mDice: 0.6317 - val_loss: -2.2337e-01 - val_acc: 0.9475 - val_mDice: 0.2081

Epoch 00021: val_mDice did not improve from 0.22564
Epoch 22/300
 - 30s - loss: 0.2892 - acc: 0.9487 - mDice: 0.5986 - val_loss: -2.5637e-01 - val_acc: 0.9506 - val_mDice: 0.2224

Epoch 00022: val_mDice did not improve from 0.22564
Epoch 23/300
 - 31s - loss: 0.3017 - acc: 0.9482 - mDice: 0.5778 - val_loss: -2.4955e-01 - val_acc: 0.9501 - val_mDice: 0.2188

Epoch 00023: val_mDice did not improve from 0.22564
Epoch 24/300
 - 31s - loss: 0.2688 - acc: 0.9490 - mDice: 0.6167 - val_loss: -2.3948e-01 - val_acc: 0.9488 - val_mDice: 0.2177

Epoch 00024: val_mDice did not improve from 0.22564
Epoch 25/300
 - 31s - loss: 0.3049 - acc: 0.9453 - mDice: 0.5771 - val_loss: -2.6356e-01 - val_acc: 0.9492 - val_mDice: 0.2112

Epoch 00025: val_mDice did not improve from 0.22564
Epoch 26/300
 - 31s - loss: 0.2820 - acc: 0.9476 - mDice: 0.6005 - val_loss: -1.9908e-01 - val_acc: 0.9442 - val_mDice: 0.2141

Epoch 00026: val_mDice did not improve from 0.22564
Epoch 27/300
 - 31s - loss: 0.2806 - acc: 0.9475 - mDice: 0.5990 - val_loss: -2.2355e-01 - val_acc: 0.9471 - val_mDice: 0.2065

Epoch 00027: val_mDice did not improve from 0.22564
Epoch 28/300
 - 31s - loss: 0.2730 - acc: 0.9474 - mDice: 0.6044 - val_loss: -2.4277e-01 - val_acc: 0.9519 - val_mDice: 0.2063

Epoch 00028: val_mDice did not improve from 0.22564
Epoch 29/300
 - 31s - loss: 0.2958 - acc: 0.9461 - mDice: 0.5799 - val_loss: -2.3373e-01 - val_acc: 0.9484 - val_mDice: 0.2069

Epoch 00029: val_mDice did not improve from 0.22564
Epoch 30/300
 - 31s - loss: 0.2987 - acc: 0.9455 - mDice: 0.5710 - val_loss: -2.4374e-01 - val_acc: 0.9505 - val_mDice: 0.2074

Epoch 00030: val_mDice did not improve from 0.22564
Epoch 31/300
 - 31s - loss: 0.2737 - acc: 0.9472 - mDice: 0.6006 - val_loss: -5.7608e-02 - val_acc: 0.9137 - val_mDice: 0.0644

Epoch 00031: val_mDice did not improve from 0.22564
Epoch 32/300
 - 31s - loss: 0.3214 - acc: 0.9434 - mDice: 0.5484 - val_loss: -1.5457e-01 - val_acc: 0.9311 - val_mDice: 0.1014

Epoch 00032: val_mDice did not improve from 0.22564

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 33/300
 - 32s - loss: 0.2991 - acc: 0.9463 - mDice: 0.5699 - val_loss: -2.3455e-01 - val_acc: 0.9487 - val_mDice: 0.2014

Epoch 00033: val_mDice did not improve from 0.22564
Epoch 34/300
 - 31s - loss: 0.2765 - acc: 0.9481 - mDice: 0.5896 - val_loss: -2.4920e-01 - val_acc: 0.9502 - val_mDice: 0.2083

Epoch 00034: val_mDice did not improve from 0.22564
Epoch 35/300
 - 31s - loss: 0.2666 - acc: 0.9489 - mDice: 0.5928 - val_loss: -2.6217e-01 - val_acc: 0.9512 - val_mDice: 0.2068

Epoch 00035: val_mDice did not improve from 0.22564
Epoch 36/300
 - 32s - loss: 0.2663 - acc: 0.9489 - mDice: 0.5994 - val_loss: -2.5967e-01 - val_acc: 0.9501 - val_mDice: 0.2028

Epoch 00036: val_mDice did not improve from 0.22564
Epoch 37/300
 - 32s - loss: 0.2650 - acc: 0.9491 - mDice: 0.6018 - val_loss: -2.5316e-01 - val_acc: 0.9512 - val_mDice: 0.2146

Epoch 00037: val_mDice did not improve from 0.22564
Epoch 38/300
 - 32s - loss: 0.2400 - acc: 0.9499 - mDice: 0.6333 - val_loss: -2.6220e-01 - val_acc: 0.9504 - val_mDice: 0.2113

Epoch 00038: val_mDice did not improve from 0.22564
Epoch 39/300
 - 31s - loss: 0.2435 - acc: 0.9503 - mDice: 0.6353 - val_loss: -2.6211e-01 - val_acc: 0.9499 - val_mDice: 0.2117

Epoch 00039: val_mDice did not improve from 0.22564
Epoch 40/300
 - 31s - loss: 0.2431 - acc: 0.9497 - mDice: 0.6266 - val_loss: -2.5121e-01 - val_acc: 0.9475 - val_mDice: 0.2164

Epoch 00040: val_mDice did not improve from 0.22564
Epoch 41/300
 - 31s - loss: 0.2398 - acc: 0.9496 - mDice: 0.6293 - val_loss: -2.6766e-01 - val_acc: 0.9483 - val_mDice: 0.2212

Epoch 00041: val_mDice did not improve from 0.22564
Epoch 42/300
 - 31s - loss: 0.2357 - acc: 0.9502 - mDice: 0.6360 - val_loss: -2.5795e-01 - val_acc: 0.9499 - val_mDice: 0.2165

Epoch 00042: val_mDice did not improve from 0.22564
Epoch 43/300
 - 31s - loss: 0.2310 - acc: 0.9505 - mDice: 0.6359 - val_loss: -2.6243e-01 - val_acc: 0.9504 - val_mDice: 0.2173

Epoch 00043: val_mDice did not improve from 0.22564
Epoch 44/300
 - 31s - loss: 0.2331 - acc: 0.9507 - mDice: 0.6430 - val_loss: -2.3836e-01 - val_acc: 0.9493 - val_mDice: 0.2119

Epoch 00044: val_mDice did not improve from 0.22564
Epoch 45/300
 - 32s - loss: 0.2294 - acc: 0.9507 - mDice: 0.6372 - val_loss: -2.5172e-01 - val_acc: 0.9502 - val_mDice: 0.2162

Epoch 00045: val_mDice did not improve from 0.22564
Epoch 46/300
 - 31s - loss: 0.2309 - acc: 0.9502 - mDice: 0.6316 - val_loss: -2.5537e-01 - val_acc: 0.9511 - val_mDice: 0.2149

Epoch 00046: val_mDice did not improve from 0.22564
Epoch 47/300
 - 31s - loss: 0.2343 - acc: 0.9502 - mDice: 0.6320 - val_loss: -2.7206e-01 - val_acc: 0.9507 - val_mDice: 0.2132

Epoch 00047: val_mDice did not improve from 0.22564

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 48/300
 - 31s - loss: 0.2210 - acc: 0.9514 - mDice: 0.6446 - val_loss: -2.5863e-01 - val_acc: 0.9508 - val_mDice: 0.2108

Epoch 00048: val_mDice did not improve from 0.22564
Epoch 49/300
 - 31s - loss: 0.2179 - acc: 0.9515 - mDice: 0.6528 - val_loss: -2.6151e-01 - val_acc: 0.9516 - val_mDice: 0.2176

Epoch 00049: val_mDice did not improve from 0.22564
Epoch 50/300
 - 31s - loss: 0.2148 - acc: 0.9519 - mDice: 0.6516 - val_loss: -2.5658e-01 - val_acc: 0.9514 - val_mDice: 0.2194

Epoch 00050: val_mDice did not improve from 0.22564
Epoch 51/300
 - 32s - loss: 0.2186 - acc: 0.9518 - mDice: 0.6507 - val_loss: -2.6656e-01 - val_acc: 0.9515 - val_mDice: 0.2167

Epoch 00051: val_mDice did not improve from 0.22564
Epoch 52/300
 - 31s - loss: 0.2142 - acc: 0.9517 - mDice: 0.6509 - val_loss: -2.6416e-01 - val_acc: 0.9519 - val_mDice: 0.2139

Epoch 00052: val_mDice did not improve from 0.22564
Epoch 53/300
 - 31s - loss: 0.2154 - acc: 0.9517 - mDice: 0.6531 - val_loss: -2.6166e-01 - val_acc: 0.9517 - val_mDice: 0.2169

Epoch 00053: val_mDice did not improve from 0.22564
Epoch 54/300
 - 31s - loss: 0.2127 - acc: 0.9519 - mDice: 0.6550 - val_loss: -2.8347e-01 - val_acc: 0.9515 - val_mDice: 0.2197

Epoch 00054: val_mDice did not improve from 0.22564
Epoch 55/300
 - 31s - loss: 0.2134 - acc: 0.9519 - mDice: 0.6522 - val_loss: -2.6685e-01 - val_acc: 0.9508 - val_mDice: 0.2158

Epoch 00055: val_mDice did not improve from 0.22564
Epoch 56/300
 - 31s - loss: 0.2091 - acc: 0.9519 - mDice: 0.6518 - val_loss: -2.7040e-01 - val_acc: 0.9507 - val_mDice: 0.1974

Epoch 00056: val_mDice did not improve from 0.22564
Epoch 57/300
 - 31s - loss: 0.2091 - acc: 0.9522 - mDice: 0.6538 - val_loss: -2.7267e-01 - val_acc: 0.9509 - val_mDice: 0.2182

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.65s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.49s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.34s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.22s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<00:59,  4.12it/s]Loading train:   1%|          | 2/247 [00:00<00:58,  4.18it/s]Loading train:   1%|          | 3/247 [00:00<00:57,  4.24it/s]Loading train:   2%|▏         | 4/247 [00:00<00:57,  4.21it/s]Loading train:   2%|▏         | 5/247 [00:01<00:56,  4.31it/s]Loading train:   2%|▏         | 6/247 [00:01<00:55,  4.36it/s]Loading train:   3%|▎         | 7/247 [00:01<00:54,  4.42it/s]Loading train:   3%|▎         | 8/247 [00:01<00:53,  4.46it/s]Loading train:   4%|▎         | 9/247 [00:02<00:52,  4.50it/s]Loading train:   4%|▍         | 10/247 [00:02<00:52,  4.52it/s]Loading train:   4%|▍         | 11/247 [00:02<00:52,  4.51it/s]Loading train:   5%|▍         | 12/247 [00:02<00:52,  4.50it/s]Loading train:   5%|▌         | 13/247 [00:02<00:52,  4.48it/s]Loading train:   6%|▌         | 14/247 [00:03<00:52,  4.48it/s]Loading train:   6%|▌         | 15/247 [00:03<00:52,  4.46it/s]Loading train:   6%|▋         | 16/247 [00:03<00:51,  4.48it/s]Loading train:   7%|▋         | 17/247 [00:03<00:51,  4.50it/s]Loading train:   7%|▋         | 18/247 [00:04<00:50,  4.52it/s]Loading train:   8%|▊         | 19/247 [00:04<00:50,  4.53it/s]Loading train:   8%|▊         | 20/247 [00:04<00:49,  4.55it/s]Loading train:   9%|▊         | 21/247 [00:04<00:49,  4.57it/s]Loading train:   9%|▉         | 22/247 [00:04<00:49,  4.57it/s]Loading train:   9%|▉         | 23/247 [00:05<00:48,  4.60it/s]Loading train:  10%|▉         | 24/247 [00:05<00:48,  4.63it/s]Loading train:  10%|█         | 25/247 [00:05<00:47,  4.65it/s]Loading train:  11%|█         | 26/247 [00:05<00:47,  4.64it/s]Loading train:  11%|█         | 27/247 [00:06<00:49,  4.49it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:48,  4.47it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:48,  4.48it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:48,  4.44it/s]Loading train:  13%|█▎        | 31/247 [00:06<00:48,  4.48it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:47,  4.54it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:46,  4.56it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:46,  4.61it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:45,  4.63it/s]Loading train:  15%|█▍        | 36/247 [00:07<00:45,  4.63it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:45,  4.65it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:44,  4.67it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:45,  4.60it/s]Loading train:  16%|█▌        | 40/247 [00:08<00:44,  4.64it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:44,  4.66it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:44,  4.65it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:43,  4.65it/s]Loading train:  18%|█▊        | 44/247 [00:09<00:43,  4.67it/s]Loading train:  18%|█▊        | 45/247 [00:09<00:43,  4.68it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:42,  4.67it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:42,  4.67it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:42,  4.65it/s]Loading train:  20%|█▉        | 49/247 [00:10<00:42,  4.63it/s]Loading train:  20%|██        | 50/247 [00:10<00:42,  4.59it/s]Loading train:  21%|██        | 51/247 [00:11<00:42,  4.59it/s]Loading train:  21%|██        | 52/247 [00:11<00:42,  4.60it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:41,  4.62it/s]Loading train:  22%|██▏       | 54/247 [00:11<00:41,  4.64it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:41,  4.62it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:41,  4.60it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:40,  4.64it/s]Loading train:  23%|██▎       | 58/247 [00:12<00:40,  4.64it/s]Loading train:  24%|██▍       | 59/247 [00:12<00:40,  4.62it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:40,  4.59it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:40,  4.59it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:40,  4.58it/s]Loading train:  26%|██▌       | 63/247 [00:13<00:40,  4.51it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:41,  4.42it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:41,  4.39it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:41,  4.40it/s]Loading train:  27%|██▋       | 67/247 [00:14<00:40,  4.42it/s]Loading train:  28%|██▊       | 68/247 [00:14<00:40,  4.42it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:40,  4.42it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:39,  4.46it/s]Loading train:  29%|██▊       | 71/247 [00:15<00:39,  4.46it/s]Loading train:  29%|██▉       | 72/247 [00:15<00:39,  4.45it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:39,  4.46it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:38,  4.47it/s]Loading train:  30%|███       | 75/247 [00:16<00:38,  4.47it/s]Loading train:  31%|███       | 76/247 [00:16<00:37,  4.50it/s]Loading train:  31%|███       | 77/247 [00:16<00:38,  4.44it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:40,  4.21it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:39,  4.21it/s]Loading train:  32%|███▏      | 80/247 [00:17<00:37,  4.40it/s]Loading train:  33%|███▎      | 81/247 [00:17<00:37,  4.39it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:36,  4.48it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:36,  4.52it/s]Loading train:  34%|███▍      | 84/247 [00:18<00:35,  4.56it/s]Loading train:  34%|███▍      | 85/247 [00:18<00:35,  4.60it/s]Loading train:  35%|███▍      | 86/247 [00:18<00:34,  4.64it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:34,  4.68it/s]Loading train:  36%|███▌      | 88/247 [00:19<00:33,  4.68it/s]Loading train:  36%|███▌      | 89/247 [00:19<00:33,  4.67it/s]Loading train:  36%|███▋      | 90/247 [00:19<00:33,  4.65it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:33,  4.65it/s]Loading train:  37%|███▋      | 92/247 [00:20<00:33,  4.68it/s]Loading train:  38%|███▊      | 93/247 [00:20<00:32,  4.69it/s]Loading train:  38%|███▊      | 94/247 [00:20<00:32,  4.72it/s]Loading train:  38%|███▊      | 95/247 [00:20<00:32,  4.70it/s]Loading train:  39%|███▉      | 96/247 [00:21<00:32,  4.71it/s]Loading train:  39%|███▉      | 97/247 [00:21<00:31,  4.74it/s]Loading train:  40%|███▉      | 98/247 [00:21<00:31,  4.71it/s]Loading train:  40%|████      | 99/247 [00:21<00:31,  4.72it/s]Loading train:  40%|████      | 100/247 [00:22<00:32,  4.47it/s]Loading train:  41%|████      | 101/247 [00:22<00:33,  4.35it/s]Loading train:  41%|████▏     | 102/247 [00:22<00:34,  4.26it/s]Loading train:  42%|████▏     | 103/247 [00:22<00:34,  4.19it/s]Loading train:  42%|████▏     | 104/247 [00:22<00:34,  4.16it/s]Loading train:  43%|████▎     | 105/247 [00:23<00:34,  4.12it/s]Loading train:  43%|████▎     | 106/247 [00:23<00:34,  4.08it/s]Loading train:  43%|████▎     | 107/247 [00:23<00:34,  4.03it/s]Loading train:  44%|████▎     | 108/247 [00:23<00:34,  4.01it/s]Loading train:  44%|████▍     | 109/247 [00:24<00:34,  4.03it/s]Loading train:  45%|████▍     | 110/247 [00:24<00:34,  4.03it/s]Loading train:  45%|████▍     | 111/247 [00:24<00:33,  4.04it/s]Loading train:  45%|████▌     | 112/247 [00:24<00:33,  4.02it/s]Loading train:  46%|████▌     | 113/247 [00:25<00:33,  3.99it/s]Loading train:  46%|████▌     | 114/247 [00:25<00:33,  4.02it/s]Loading train:  47%|████▋     | 115/247 [00:25<00:33,  3.98it/s]Loading train:  47%|████▋     | 116/247 [00:25<00:32,  3.98it/s]Loading train:  47%|████▋     | 117/247 [00:26<00:32,  3.96it/s]Loading train:  48%|████▊     | 118/247 [00:26<00:31,  4.09it/s]Loading train:  48%|████▊     | 119/247 [00:26<00:30,  4.15it/s]Loading train:  49%|████▊     | 120/247 [00:26<00:29,  4.24it/s]Loading train:  49%|████▉     | 121/247 [00:27<00:29,  4.25it/s]Loading train:  49%|████▉     | 122/247 [00:27<00:29,  4.29it/s]Loading train:  50%|████▉     | 123/247 [00:27<00:28,  4.30it/s]Loading train:  50%|█████     | 124/247 [00:27<00:28,  4.36it/s]Loading train:  51%|█████     | 125/247 [00:28<00:28,  4.34it/s]Loading train:  51%|█████     | 126/247 [00:28<00:27,  4.37it/s]Loading train:  51%|█████▏    | 127/247 [00:28<00:27,  4.34it/s]Loading train:  52%|█████▏    | 128/247 [00:28<00:27,  4.35it/s]Loading train:  52%|█████▏    | 129/247 [00:28<00:26,  4.37it/s]Loading train:  53%|█████▎    | 130/247 [00:29<00:26,  4.42it/s]Loading train:  53%|█████▎    | 131/247 [00:29<00:26,  4.43it/s]Loading train:  53%|█████▎    | 132/247 [00:29<00:25,  4.45it/s]Loading train:  54%|█████▍    | 133/247 [00:29<00:25,  4.46it/s]Loading train:  54%|█████▍    | 134/247 [00:30<00:25,  4.48it/s]Loading train:  55%|█████▍    | 135/247 [00:30<00:24,  4.49it/s]Loading train:  55%|█████▌    | 136/247 [00:30<00:23,  4.69it/s]Loading train:  55%|█████▌    | 137/247 [00:30<00:22,  4.87it/s]Loading train:  56%|█████▌    | 138/247 [00:30<00:21,  4.98it/s]Loading train:  56%|█████▋    | 139/247 [00:31<00:21,  5.05it/s]Loading train:  57%|█████▋    | 140/247 [00:31<00:20,  5.13it/s]Loading train:  57%|█████▋    | 141/247 [00:31<00:20,  5.21it/s]Loading train:  57%|█████▋    | 142/247 [00:31<00:19,  5.28it/s]Loading train:  58%|█████▊    | 143/247 [00:31<00:19,  5.31it/s]Loading train:  58%|█████▊    | 144/247 [00:32<00:19,  5.31it/s]Loading train:  59%|█████▊    | 145/247 [00:32<00:19,  5.32it/s]Loading train:  59%|█████▉    | 146/247 [00:32<00:19,  5.28it/s]Loading train:  60%|█████▉    | 147/247 [00:32<00:18,  5.28it/s]Loading train:  60%|█████▉    | 148/247 [00:32<00:18,  5.29it/s]Loading train:  60%|██████    | 149/247 [00:32<00:18,  5.30it/s]Loading train:  61%|██████    | 150/247 [00:33<00:18,  5.29it/s]Loading train:  61%|██████    | 151/247 [00:33<00:18,  5.31it/s]Loading train:  62%|██████▏   | 152/247 [00:33<00:17,  5.32it/s]Loading train:  62%|██████▏   | 153/247 [00:33<00:17,  5.33it/s]Loading train:  62%|██████▏   | 154/247 [00:33<00:18,  5.15it/s]Loading train:  63%|██████▎   | 155/247 [00:34<00:18,  5.02it/s]Loading train:  63%|██████▎   | 156/247 [00:34<00:18,  4.92it/s]Loading train:  64%|██████▎   | 157/247 [00:34<00:18,  4.90it/s]Loading train:  64%|██████▍   | 158/247 [00:34<00:18,  4.84it/s]Loading train:  64%|██████▍   | 159/247 [00:34<00:18,  4.82it/s]Loading train:  65%|██████▍   | 160/247 [00:35<00:18,  4.82it/s]Loading train:  65%|██████▌   | 161/247 [00:35<00:18,  4.74it/s]Loading train:  66%|██████▌   | 162/247 [00:35<00:19,  4.46it/s]Loading train:  66%|██████▌   | 163/247 [00:35<00:19,  4.40it/s]Loading train:  66%|██████▋   | 164/247 [00:36<00:18,  4.43it/s]Loading train:  67%|██████▋   | 165/247 [00:36<00:18,  4.49it/s]Loading train:  67%|██████▋   | 166/247 [00:36<00:17,  4.53it/s]Loading train:  68%|██████▊   | 167/247 [00:36<00:17,  4.55it/s]Loading train:  68%|██████▊   | 168/247 [00:36<00:17,  4.57it/s]Loading train:  68%|██████▊   | 169/247 [00:37<00:17,  4.56it/s]Loading train:  69%|██████▉   | 170/247 [00:37<00:16,  4.56it/s]Loading train:  69%|██████▉   | 171/247 [00:37<00:16,  4.53it/s]Loading train:  70%|██████▉   | 172/247 [00:37<00:17,  4.37it/s]Loading train:  70%|███████   | 173/247 [00:38<00:16,  4.45it/s]Loading train:  70%|███████   | 174/247 [00:38<00:16,  4.43it/s]Loading train:  71%|███████   | 175/247 [00:38<00:16,  4.29it/s]Loading train:  71%|███████▏  | 176/247 [00:38<00:16,  4.41it/s]Loading train:  72%|███████▏  | 177/247 [00:39<00:15,  4.49it/s]Loading train:  72%|███████▏  | 178/247 [00:39<00:15,  4.55it/s]Loading train:  72%|███████▏  | 179/247 [00:39<00:16,  4.17it/s]Loading train:  73%|███████▎  | 180/247 [00:39<00:15,  4.32it/s]Loading train:  73%|███████▎  | 181/247 [00:39<00:14,  4.43it/s]Loading train:  74%|███████▎  | 182/247 [00:40<00:14,  4.49it/s]Loading train:  74%|███████▍  | 183/247 [00:40<00:14,  4.52it/s]Loading train:  74%|███████▍  | 184/247 [00:40<00:13,  4.57it/s]Loading train:  75%|███████▍  | 185/247 [00:40<00:13,  4.61it/s]Loading train:  75%|███████▌  | 186/247 [00:41<00:13,  4.63it/s]Loading train:  76%|███████▌  | 187/247 [00:41<00:13,  4.56it/s]Loading train:  76%|███████▌  | 188/247 [00:41<00:13,  4.47it/s]Loading train:  77%|███████▋  | 189/247 [00:41<00:13,  4.44it/s]Loading train:  77%|███████▋  | 190/247 [00:41<00:13,  4.34it/s]Loading train:  77%|███████▋  | 191/247 [00:42<00:12,  4.39it/s]Loading train:  78%|███████▊  | 192/247 [00:42<00:12,  4.47it/s]Loading train:  78%|███████▊  | 193/247 [00:42<00:12,  4.47it/s]Loading train:  79%|███████▊  | 194/247 [00:42<00:11,  4.56it/s]Loading train:  79%|███████▉  | 195/247 [00:43<00:11,  4.60it/s]Loading train:  79%|███████▉  | 196/247 [00:43<00:11,  4.62it/s]Loading train:  80%|███████▉  | 197/247 [00:43<00:10,  4.57it/s]Loading train:  80%|████████  | 198/247 [00:43<00:10,  4.63it/s]Loading train:  81%|████████  | 199/247 [00:43<00:10,  4.59it/s]Loading train:  81%|████████  | 200/247 [00:44<00:10,  4.47it/s]Loading train:  81%|████████▏ | 201/247 [00:44<00:10,  4.53it/s]Loading train:  82%|████████▏ | 202/247 [00:44<00:09,  4.59it/s]Loading train:  82%|████████▏ | 203/247 [00:44<00:09,  4.57it/s]Loading train:  83%|████████▎ | 204/247 [00:44<00:09,  4.60it/s]Loading train:  83%|████████▎ | 205/247 [00:45<00:09,  4.61it/s]Loading train:  83%|████████▎ | 206/247 [00:45<00:08,  4.65it/s]Loading train:  84%|████████▍ | 207/247 [00:45<00:08,  4.71it/s]Loading train:  84%|████████▍ | 208/247 [00:45<00:08,  4.75it/s]Loading train:  85%|████████▍ | 209/247 [00:46<00:07,  4.78it/s]Loading train:  85%|████████▌ | 210/247 [00:46<00:08,  4.49it/s]Loading train:  85%|████████▌ | 211/247 [00:46<00:08,  4.40it/s]Loading train:  86%|████████▌ | 212/247 [00:46<00:07,  4.43it/s]Loading train:  86%|████████▌ | 213/247 [00:46<00:07,  4.49it/s]Loading train:  87%|████████▋ | 214/247 [00:47<00:07,  4.54it/s]Loading train:  87%|████████▋ | 215/247 [00:47<00:07,  4.56it/s]Loading train:  87%|████████▋ | 216/247 [00:47<00:06,  4.59it/s]Loading train:  88%|████████▊ | 217/247 [00:47<00:06,  4.60it/s]Loading train:  88%|████████▊ | 218/247 [00:48<00:06,  4.64it/s]Loading train:  89%|████████▊ | 219/247 [00:48<00:06,  4.64it/s]Loading train:  89%|████████▉ | 220/247 [00:48<00:05,  4.63it/s]Loading train:  89%|████████▉ | 221/247 [00:48<00:05,  4.65it/s]Loading train:  90%|████████▉ | 222/247 [00:48<00:05,  4.66it/s]Loading train:  90%|█████████ | 223/247 [00:49<00:05,  4.68it/s]Loading train:  91%|█████████ | 224/247 [00:49<00:04,  4.68it/s]Loading train:  91%|█████████ | 225/247 [00:49<00:04,  4.64it/s]Loading train:  91%|█████████▏| 226/247 [00:49<00:04,  4.64it/s]Loading train:  92%|█████████▏| 227/247 [00:49<00:04,  4.63it/s]Loading train:  92%|█████████▏| 228/247 [00:50<00:04,  4.63it/s]Loading train:  93%|█████████▎| 229/247 [00:50<00:03,  4.63it/s]Loading train:  93%|█████████▎| 230/247 [00:50<00:03,  4.47it/s]Loading train:  94%|█████████▎| 231/247 [00:50<00:03,  4.41it/s]Loading train:  94%|█████████▍| 232/247 [00:51<00:03,  4.38it/s]Loading train:  94%|█████████▍| 233/247 [00:51<00:03,  4.35it/s]Loading train:  95%|█████████▍| 234/247 [00:51<00:03,  4.31it/s]Loading train:  95%|█████████▌| 235/247 [00:51<00:02,  4.28it/s]Loading train:  96%|█████████▌| 236/247 [00:52<00:02,  4.25it/s]Loading train:  96%|█████████▌| 237/247 [00:52<00:02,  4.24it/s]Loading train:  96%|█████████▋| 238/247 [00:52<00:02,  4.25it/s]Loading train:  97%|█████████▋| 239/247 [00:52<00:01,  4.20it/s]Loading train:  97%|█████████▋| 240/247 [00:53<00:01,  4.22it/s]Loading train:  98%|█████████▊| 241/247 [00:53<00:01,  4.24it/s]Loading train:  98%|█████████▊| 242/247 [00:53<00:01,  4.24it/s]Loading train:  98%|█████████▊| 243/247 [00:53<00:00,  4.23it/s]Loading train:  99%|█████████▉| 244/247 [00:53<00:00,  4.20it/s]Loading train:  99%|█████████▉| 245/247 [00:54<00:00,  4.12it/s]Loading train: 100%|█████████▉| 246/247 [00:54<00:00,  4.15it/s]Loading train: 100%|██████████| 247/247 [00:54<00:00,  3.81it/s]Loading train: 100%|██████████| 247/247 [00:54<00:00,  4.51it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 57.51it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 56.71it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 55.98it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:03, 55.92it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:03, 55.88it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:03, 56.81it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:03, 57.38it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 57.99it/s]concatenating: train:  22%|██▏       | 54/247 [00:00<00:03, 58.32it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 58.16it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 58.54it/s]concatenating: train:  30%|██▉       | 73/247 [00:01<00:02, 59.34it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:02, 60.09it/s]concatenating: train:  35%|███▌      | 87/247 [00:01<00:02, 61.03it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:02, 59.21it/s]concatenating: train:  40%|████      | 100/247 [00:01<00:02, 57.75it/s]concatenating: train:  43%|████▎     | 106/247 [00:01<00:02, 56.00it/s]concatenating: train:  45%|████▌     | 112/247 [00:01<00:02, 53.36it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 52.84it/s]concatenating: train:  50%|█████     | 124/247 [00:02<00:02, 52.19it/s]concatenating: train:  53%|█████▎    | 130/247 [00:02<00:02, 51.91it/s]concatenating: train:  55%|█████▌    | 136/247 [00:02<00:02, 53.57it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:01, 57.01it/s]concatenating: train:  61%|██████    | 150/247 [00:02<00:01, 59.14it/s]concatenating: train:  64%|██████▎   | 157/247 [00:02<00:01, 61.27it/s]concatenating: train:  66%|██████▋   | 164/247 [00:02<00:01, 59.34it/s]concatenating: train:  69%|██████▉   | 170/247 [00:02<00:01, 56.51it/s]concatenating: train:  71%|███████▏  | 176/247 [00:03<00:01, 56.18it/s]concatenating: train:  74%|███████▎  | 182/247 [00:03<00:01, 56.51it/s]concatenating: train:  77%|███████▋  | 189/247 [00:03<00:00, 58.08it/s]concatenating: train:  79%|███████▉  | 196/247 [00:03<00:00, 59.63it/s]concatenating: train:  82%|████████▏ | 203/247 [00:03<00:00, 61.12it/s]concatenating: train:  85%|████████▌ | 210/247 [00:03<00:00, 60.16it/s]concatenating: train:  88%|████████▊ | 217/247 [00:03<00:00, 60.12it/s]concatenating: train:  91%|█████████ | 224/247 [00:03<00:00, 60.61it/s]concatenating: train:  94%|█████████▎| 231/247 [00:04<00:00, 58.28it/s]concatenating: train:  96%|█████████▋| 238/247 [00:04<00:00, 59.17it/s]concatenating: train:  99%|█████████▉| 244/247 [00:04<00:00, 59.08it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 57.85it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.51it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.61it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.89it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.02it/s]
Epoch 00057: val_mDice did not improve from 0.22564
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [-0.03995260156376322, -0.05850091433715949, -0.04667145396111372, -0.13521821968498882, -0.13164381135577036, -0.05943192460539716, -0.1556002913290106, -0.140235758708491, -0.23541174537105555, -0.08949082875969233, -0.027366398008724237, -0.19831358791118053, -0.18556416254019203, -0.17016097310611425, -0.19000483243611216, -0.14906804091124623, -0.20410341460740677, -0.12471810125251427, -0.1396339317254814, -0.21655037600179144, -0.22337486705905182, -0.25636865108354406, -0.24954675841087728, -0.23947925830581857, -0.26356432981283207, -0.19907799935727208, -0.22355050820121428, -0.24276813126261126, -0.2337305955890635, -0.243737105153685, -0.05760845671519982, -0.1545677101009606, -0.234551871940278, -0.24920321561764053, -0.26216919181644227, -0.2596713944282929, -0.25315512529930767, -0.2622000348774348, -0.2621077638562125, -0.2512129930043478, -0.2676577924486296, -0.2579522891144195, -0.26243282549613567, -0.23835504204422855, -0.251716669707812, -0.2553718804186325, -0.2720553232960541, -0.25863465333693764, -0.26150704595083546, -0.25657883107469615, -0.2665607331889785, -0.26415670228285576, -0.2616580608645799, -0.28347462058221107, -0.266852412223356, -0.2704003985373326, -0.27267080738013727], 'val_acc': [0.9443937451751144, 0.9462596906556023, 0.9450973412136973, 0.9480922612143151, 0.9466529194219613, 0.9461706593448733, 0.9503427688722257, 0.9483927293324176, 0.9511428195753215, 0.9492001993420683, 0.9437742431958517, 0.9473045692767625, 0.9495971331625809, 0.9507619550934544, 0.9488502575291528, 0.9485559669541724, 0.9493708437607612, 0.9491655808172108, 0.9446311607772921, 0.94742946860231, 0.9474925336278515, 0.9505764724295817, 0.95006083154384, 0.9488465487957001, 0.9492051461596548, 0.9441773472008882, 0.94714629502944, 0.9519255481384419, 0.9483717223744333, 0.9505430883095588, 0.913710085698116, 0.9311342596271892, 0.9486610716507758, 0.9502005621238991, 0.9512318438953824, 0.9500818605776187, 0.95117496745086, 0.9504466410036441, 0.9498555744871681, 0.9475259177478743, 0.9483272010161553, 0.9499495456248154, 0.9504058320581177, 0.949276868575885, 0.9502475578107952, 0.9510562603856311, 0.950661799054087, 0.9508002952293113, 0.9515805549827623, 0.9514358812644158, 0.9514803952640958, 0.9518699060987543, 0.9516955533145387, 0.9515409859610192, 0.9508448073893417, 0.950691474440657, 0.9509004531083284], 'val_mDice': [0.22163573319069396, 0.22458174553366356, 0.21888345847895116, 0.2195041976225229, 0.22198369301119705, 0.21993619044897733, 0.2225013439440065, 0.22082974053459403, 0.2244300380303168, 0.22252580150961876, 0.18803495212377588, 0.21739365372024935, 0.2212700048852482, 0.22401901237942554, 0.22404199477607084, 0.2191098389664182, 0.22564179643436713, 0.21835505766909064, 0.2133587306296384, 0.2165487320104867, 0.20809117831105803, 0.22242029530950536, 0.2188422558484254, 0.21767769710241278, 0.2111930186273875, 0.21412751119997767, 0.2064734827267167, 0.20628216963859253, 0.20689206404818428, 0.2073606214037648, 0.0644348593562393, 0.1014383144699681, 0.20141828506265158, 0.208274714625728, 0.20683076267165165, 0.20277387163613314, 0.21457890508535468, 0.2112512807879183, 0.21171758169837204, 0.21639499192436537, 0.22124141477692275, 0.21647049907456944, 0.2173212909910046, 0.21192308549803715, 0.21624107028783104, 0.21487458850498553, 0.21317573126267503, 0.21082265291041064, 0.21757074539768106, 0.21940970689886147, 0.2166683590154589, 0.21390231337720228, 0.2168711495620233, 0.2197285868043517, 0.21578815098805929, 0.1973778872900171, 0.21824366229091896], 'loss': [0.46844728268284835, 0.3859972550460249, 0.37198093092737305, 0.3563687044169763, 0.3467846698395472, 0.3409773894317884, 0.3323112349890874, 0.32549357731795797, 0.32050878973559266, 0.31983898293805185, 0.3185642381167897, 0.31039064999375937, 0.3108652850124824, 0.30631888284331366, 0.30675045855855215, 0.3047369776658581, 0.3070276825293026, 0.3037871605700057, 0.3039542582104073, 0.3069829946246387, 0.28844370132634467, 0.28921475801610985, 0.30172321932224744, 0.2687967579062962, 0.3049439965298076, 0.28195107523627394, 0.28056535480956313, 0.27303858933411657, 0.2957839066689685, 0.29865860673692257, 0.2737259713701226, 0.32135105669318786, 0.2990650440734792, 0.27651894303973595, 0.2665697388072811, 0.26626257483680665, 0.26498380913259934, 0.2399520131175936, 0.2434782872423272, 0.2431362827021548, 0.23984778302612225, 0.23572943687405493, 0.2310443345115401, 0.23309068654247816, 0.22942758671806981, 0.23085415491982356, 0.23434792799711032, 0.221043530154962, 0.21785128771014328, 0.21481032067072714, 0.21864031008936455, 0.2141832272489007, 0.21536443587561416, 0.21266029163399408, 0.21339225698379163, 0.2090749242247477, 0.20905397901361578], 'acc': [0.9323540561981783, 0.942668778864482, 0.9446839370193676, 0.946679241670907, 0.9478300140255886, 0.9486936594693716, 0.9496529816671182, 0.950142875237926, 0.9505822549339469, 0.9510587423129846, 0.951335801423051, 0.9518603812571397, 0.9523782331600747, 0.9527399564972361, 0.9525741948426225, 0.9529286047050365, 0.9526504489756723, 0.953275902846084, 0.9527033320971724, 0.9496256349271793, 0.9492216296399216, 0.9486888182982234, 0.9481837608432042, 0.9490117008297801, 0.9453207834152169, 0.9476479420831792, 0.9475189564185591, 0.9474301632048217, 0.9461180386879972, 0.9454504303425626, 0.9472335631989948, 0.9434038729006401, 0.9462531143017398, 0.948081714278869, 0.9488801924326947, 0.9489267810458749, 0.9490847964095706, 0.9499330737511924, 0.9502837611670409, 0.9496844061306718, 0.9496344532296251, 0.9502261125935246, 0.9505434645192921, 0.9506697484858466, 0.9506578711607984, 0.9502287378899621, 0.9502316936281802, 0.9513710737986723, 0.9515313814766231, 0.9519223629973317, 0.9517550219712974, 0.9517339967741008, 0.951720870140248, 0.9518807452674434, 0.9519316401266263, 0.9519170373678207, 0.9521573191608181], 'mDice': [0.4949124750536665, 0.5839133748912629, 0.5990731113474181, 0.6159177774008904, 0.6262697815402167, 0.6325376408397393, 0.6418961226921197, 0.649258166039718, 0.6546493228572319, 0.6553340318207522, 0.6567089435177602, 0.6655322274254782, 0.6649915079465349, 0.6699027974566127, 0.6694452016029042, 0.6716135417990405, 0.6691359060297486, 0.6726274815489924, 0.6699963111913841, 0.6420206322735199, 0.6317215685663939, 0.598634114759114, 0.5777817238074829, 0.6166544865826311, 0.5770579864372886, 0.6005287546541248, 0.5990323657430614, 0.6043899362437598, 0.5799044914373005, 0.5709529900236135, 0.6005642870417381, 0.5483680767109073, 0.5698737313274209, 0.589636915398918, 0.592803652315346, 0.5993739382266695, 0.6018040774925671, 0.6333345897287206, 0.635262131520355, 0.626576402525562, 0.6293301385360517, 0.6360309578990209, 0.6358562686667795, 0.6429853989403818, 0.6371992431182898, 0.6315911885057091, 0.6320447412535131, 0.6445617871998831, 0.6527507895219872, 0.6516304320961465, 0.6506765790511179, 0.6508515685152159, 0.653073186201752, 0.6550055216741926, 0.6521744635572264, 0.6517959347435536, 0.6538090968822098], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label valuesLoading test: 100%|██████████| 5/5 [00:01<00:00,  3.89it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.97it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 290.04it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<00:57,  4.26it/s]Loading trainS:   1%|          | 2/247 [00:00<00:56,  4.30it/s]Loading trainS:   1%|          | 3/247 [00:00<00:56,  4.35it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:56,  4.32it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:55,  4.36it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:54,  4.38it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:54,  4.43it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:53,  4.46it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:53,  4.48it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:52,  4.48it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:52,  4.53it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:51,  4.55it/s]Loading trainS:   5%|▌         | 13/247 [00:02<00:51,  4.57it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:51,  4.57it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:50,  4.57it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:50,  4.54it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:50,  4.53it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:50,  4.57it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:49,  4.57it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:49,  4.56it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:49,  4.55it/s]Loading trainS:   9%|▉         | 22/247 [00:04<00:49,  4.56it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:48,  4.59it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:48,  4.60it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:48,  4.61it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:47,  4.63it/s]Loading trainS:  11%|█         | 27/247 [00:05<00:47,  4.65it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:46,  4.68it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:46,  4.70it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:46,  4.69it/s]Loading trainS:  13%|█▎        | 31/247 [00:06<00:45,  4.70it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:45,  4.69it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:45,  4.66it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:45,  4.68it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:45,  4.62it/s]Loading trainS:  15%|█▍        | 36/247 [00:07<00:45,  4.62it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:45,  4.62it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:45,  4.62it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:44,  4.63it/s]Loading trainS:  16%|█▌        | 40/247 [00:08<00:44,  4.62it/s]Loading trainS:  17%|█▋        | 41/247 [00:08<00:44,  4.64it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:44,  4.64it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:44,  4.62it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:43,  4.63it/s]Loading trainS:  18%|█▊        | 45/247 [00:09<00:43,  4.61it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:43,  4.60it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:43,  4.60it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:43,  4.62it/s]Loading trainS:  20%|█▉        | 49/247 [00:10<00:42,  4.62it/s]Loading trainS:  20%|██        | 50/247 [00:10<00:43,  4.54it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:43,  4.50it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:42,  4.56it/s]Loading trainS:  21%|██▏       | 53/247 [00:11<00:42,  4.61it/s]Loading trainS:  22%|██▏       | 54/247 [00:11<00:41,  4.63it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:41,  4.65it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:40,  4.67it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:40,  4.64it/s]Loading trainS:  23%|██▎       | 58/247 [00:12<00:41,  4.61it/s]Loading trainS:  24%|██▍       | 59/247 [00:12<00:41,  4.56it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:41,  4.54it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:40,  4.54it/s]Loading trainS:  25%|██▌       | 62/247 [00:13<00:40,  4.55it/s]Loading trainS:  26%|██▌       | 63/247 [00:13<00:40,  4.54it/s]Loading trainS:  26%|██▌       | 64/247 [00:13<00:40,  4.53it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:40,  4.52it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:40,  4.51it/s]Loading trainS:  27%|██▋       | 67/247 [00:14<00:39,  4.52it/s]Loading trainS:  28%|██▊       | 68/247 [00:14<00:39,  4.52it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:39,  4.53it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:38,  4.54it/s]Loading trainS:  29%|██▊       | 71/247 [00:15<00:38,  4.55it/s]Loading trainS:  29%|██▉       | 72/247 [00:15<00:38,  4.56it/s]Loading trainS:  30%|██▉       | 73/247 [00:15<00:38,  4.56it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:38,  4.55it/s]Loading trainS:  30%|███       | 75/247 [00:16<00:37,  4.56it/s]Loading trainS:  31%|███       | 76/247 [00:16<00:37,  4.55it/s]Loading trainS:  31%|███       | 77/247 [00:16<00:37,  4.48it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:39,  4.23it/s]Loading trainS:  32%|███▏      | 79/247 [00:17<00:39,  4.22it/s]Loading trainS:  32%|███▏      | 80/247 [00:17<00:37,  4.44it/s]Loading trainS:  33%|███▎      | 81/247 [00:17<00:37,  4.43it/s]Loading trainS:  33%|███▎      | 82/247 [00:17<00:36,  4.52it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:36,  4.55it/s]Loading trainS:  34%|███▍      | 84/247 [00:18<00:35,  4.57it/s]Loading trainS:  34%|███▍      | 85/247 [00:18<00:35,  4.59it/s]Loading trainS:  35%|███▍      | 86/247 [00:18<00:34,  4.62it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:34,  4.64it/s]Loading trainS:  36%|███▌      | 88/247 [00:19<00:34,  4.65it/s]Loading trainS:  36%|███▌      | 89/247 [00:19<00:33,  4.69it/s]Loading trainS:  36%|███▋      | 90/247 [00:19<00:33,  4.70it/s]Loading trainS:  37%|███▋      | 91/247 [00:19<00:33,  4.70it/s]Loading trainS:  37%|███▋      | 92/247 [00:20<00:32,  4.71it/s]Loading trainS:  38%|███▊      | 93/247 [00:20<00:32,  4.73it/s]Loading trainS:  38%|███▊      | 94/247 [00:20<00:32,  4.74it/s]Loading trainS:  38%|███▊      | 95/247 [00:20<00:32,  4.75it/s]Loading trainS:  39%|███▉      | 96/247 [00:20<00:31,  4.73it/s]Loading trainS:  39%|███▉      | 97/247 [00:21<00:31,  4.69it/s]Loading trainS:  40%|███▉      | 98/247 [00:21<00:31,  4.70it/s]Loading trainS:  40%|████      | 99/247 [00:21<00:31,  4.69it/s]Loading trainS:  40%|████      | 100/247 [00:21<00:33,  4.34it/s]Loading trainS:  41%|████      | 101/247 [00:22<00:34,  4.18it/s]Loading trainS:  41%|████▏     | 102/247 [00:22<00:35,  4.14it/s]Loading trainS:  42%|████▏     | 103/247 [00:22<00:34,  4.12it/s]Loading trainS:  42%|████▏     | 104/247 [00:22<00:34,  4.12it/s]Loading trainS:  43%|████▎     | 105/247 [00:23<00:34,  4.09it/s]Loading trainS:  43%|████▎     | 106/247 [00:23<00:34,  4.08it/s]Loading trainS:  43%|████▎     | 107/247 [00:23<00:34,  4.06it/s]Loading trainS:  44%|████▎     | 108/247 [00:23<00:34,  4.05it/s]Loading trainS:  44%|████▍     | 109/247 [00:24<00:34,  4.03it/s]Loading trainS:  45%|████▍     | 110/247 [00:24<00:34,  4.01it/s]Loading trainS:  45%|████▍     | 111/247 [00:24<00:34,  3.93it/s]Loading trainS:  45%|████▌     | 112/247 [00:24<00:35,  3.83it/s]Loading trainS:  46%|████▌     | 113/247 [00:25<00:35,  3.73it/s]Loading trainS:  46%|████▌     | 114/247 [00:25<00:36,  3.69it/s]Loading trainS:  47%|████▋     | 115/247 [00:25<00:35,  3.73it/s]Loading trainS:  47%|████▋     | 116/247 [00:26<00:34,  3.75it/s]Loading trainS:  47%|████▋     | 117/247 [00:26<00:35,  3.66it/s]Loading trainS:  48%|████▊     | 118/247 [00:26<00:34,  3.79it/s]Loading trainS:  48%|████▊     | 119/247 [00:26<00:33,  3.87it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:31,  4.01it/s]Loading trainS:  49%|████▉     | 121/247 [00:27<00:30,  4.14it/s]Loading trainS:  49%|████▉     | 122/247 [00:27<00:30,  4.12it/s]Loading trainS:  50%|████▉     | 123/247 [00:27<00:30,  4.04it/s]Loading trainS:  50%|█████     | 124/247 [00:27<00:29,  4.13it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:28,  4.22it/s]Loading trainS:  51%|█████     | 126/247 [00:28<00:28,  4.20it/s]Loading trainS:  51%|█████▏    | 127/247 [00:28<00:28,  4.27it/s]Loading trainS:  52%|█████▏    | 128/247 [00:28<00:27,  4.32it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:27,  4.28it/s]Loading trainS:  53%|█████▎    | 130/247 [00:29<00:28,  4.10it/s]Loading trainS:  53%|█████▎    | 131/247 [00:29<00:28,  4.12it/s]Loading trainS:  53%|█████▎    | 132/247 [00:29<00:27,  4.19it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:26,  4.24it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:26,  4.28it/s]Loading trainS:  55%|█████▍    | 135/247 [00:30<00:26,  4.20it/s]Loading trainS:  55%|█████▌    | 136/247 [00:30<00:25,  4.39it/s]Loading trainS:  55%|█████▌    | 137/247 [00:30<00:24,  4.55it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:23,  4.59it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:23,  4.58it/s]Loading trainS:  57%|█████▋    | 140/247 [00:31<00:23,  4.65it/s]Loading trainS:  57%|█████▋    | 141/247 [00:31<00:22,  4.61it/s]Loading trainS:  57%|█████▋    | 142/247 [00:32<00:22,  4.74it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:21,  4.75it/s]Loading trainS:  58%|█████▊    | 144/247 [00:32<00:21,  4.87it/s]Loading trainS:  59%|█████▊    | 145/247 [00:32<00:20,  4.90it/s]Loading trainS:  59%|█████▉    | 146/247 [00:32<00:20,  4.98it/s]Loading trainS:  60%|█████▉    | 147/247 [00:33<00:20,  4.86it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:19,  4.97it/s]Loading trainS:  60%|██████    | 149/247 [00:33<00:19,  5.00it/s]Loading trainS:  61%|██████    | 150/247 [00:33<00:19,  5.01it/s]Loading trainS:  61%|██████    | 151/247 [00:33<00:19,  4.83it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:19,  4.81it/s]Loading trainS:  62%|██████▏   | 153/247 [00:34<00:19,  4.78it/s]Loading trainS:  62%|██████▏   | 154/247 [00:34<00:19,  4.72it/s]Loading trainS:  63%|██████▎   | 155/247 [00:34<00:19,  4.65it/s]Loading trainS:  63%|██████▎   | 156/247 [00:34<00:19,  4.64it/s]Loading trainS:  64%|██████▎   | 157/247 [00:35<00:20,  4.49it/s]Loading trainS:  64%|██████▍   | 158/247 [00:35<00:19,  4.54it/s]Loading trainS:  64%|██████▍   | 159/247 [00:35<00:19,  4.59it/s]Loading trainS:  65%|██████▍   | 160/247 [00:35<00:19,  4.47it/s]Loading trainS:  65%|██████▌   | 161/247 [00:36<00:18,  4.55it/s]Loading trainS:  66%|██████▌   | 162/247 [00:36<00:18,  4.59it/s]Loading trainS:  66%|██████▌   | 163/247 [00:36<00:18,  4.61it/s]Loading trainS:  66%|██████▋   | 164/247 [00:36<00:17,  4.65it/s]Loading trainS:  67%|██████▋   | 165/247 [00:36<00:17,  4.66it/s]Loading trainS:  67%|██████▋   | 166/247 [00:37<00:17,  4.67it/s]Loading trainS:  68%|██████▊   | 167/247 [00:37<00:17,  4.65it/s]Loading trainS:  68%|██████▊   | 168/247 [00:37<00:16,  4.66it/s]Loading trainS:  68%|██████▊   | 169/247 [00:37<00:16,  4.61it/s]Loading trainS:  69%|██████▉   | 170/247 [00:37<00:16,  4.61it/s]Loading trainS:  69%|██████▉   | 171/247 [00:38<00:16,  4.65it/s]Loading trainS:  70%|██████▉   | 172/247 [00:38<00:16,  4.54it/s]Loading trainS:  70%|███████   | 173/247 [00:38<00:16,  4.56it/s]Loading trainS:  70%|███████   | 174/247 [00:38<00:16,  4.48it/s]Loading trainS:  71%|███████   | 175/247 [00:39<00:16,  4.29it/s]Loading trainS:  71%|███████▏  | 176/247 [00:39<00:16,  4.39it/s]Loading trainS:  72%|███████▏  | 177/247 [00:39<00:15,  4.44it/s]Loading trainS:  72%|███████▏  | 178/247 [00:39<00:15,  4.49it/s]Loading trainS:  72%|███████▏  | 179/247 [00:39<00:14,  4.54it/s]Loading trainS:  73%|███████▎  | 180/247 [00:40<00:14,  4.58it/s]Loading trainS:  73%|███████▎  | 181/247 [00:40<00:14,  4.60it/s]Loading trainS:  74%|███████▎  | 182/247 [00:40<00:14,  4.61it/s]Loading trainS:  74%|███████▍  | 183/247 [00:40<00:13,  4.62it/s]Loading trainS:  74%|███████▍  | 184/247 [00:41<00:13,  4.63it/s]Loading trainS:  75%|███████▍  | 185/247 [00:41<00:13,  4.64it/s]Loading trainS:  75%|███████▌  | 186/247 [00:41<00:13,  4.64it/s]Loading trainS:  76%|███████▌  | 187/247 [00:41<00:12,  4.64it/s]Loading trainS:  76%|███████▌  | 188/247 [00:41<00:12,  4.62it/s]Loading trainS:  77%|███████▋  | 189/247 [00:42<00:12,  4.61it/s]Loading trainS:  77%|███████▋  | 190/247 [00:42<00:12,  4.62it/s]Loading trainS:  77%|███████▋  | 191/247 [00:42<00:12,  4.63it/s]Loading trainS:  78%|███████▊  | 192/247 [00:42<00:11,  4.63it/s]Loading trainS:  78%|███████▊  | 193/247 [00:43<00:11,  4.64it/s]Loading trainS:  79%|███████▊  | 194/247 [00:43<00:11,  4.69it/s]Loading trainS:  79%|███████▉  | 195/247 [00:43<00:11,  4.73it/s]Loading trainS:  79%|███████▉  | 196/247 [00:43<00:10,  4.76it/s]Loading trainS:  80%|███████▉  | 197/247 [00:43<00:10,  4.80it/s]Loading trainS:  80%|████████  | 198/247 [00:44<00:10,  4.82it/s]Loading trainS:  81%|████████  | 199/247 [00:44<00:09,  4.84it/s]Loading trainS:  81%|████████  | 200/247 [00:44<00:09,  4.83it/s]Loading trainS:  81%|████████▏ | 201/247 [00:44<00:09,  4.82it/s]Loading trainS:  82%|████████▏ | 202/247 [00:44<00:09,  4.80it/s]Loading trainS:  82%|████████▏ | 203/247 [00:45<00:09,  4.77it/s]Loading trainS:  83%|████████▎ | 204/247 [00:45<00:08,  4.79it/s]Loading trainS:  83%|████████▎ | 205/247 [00:45<00:08,  4.80it/s]Loading trainS:  83%|████████▎ | 206/247 [00:45<00:08,  4.74it/s]Loading trainS:  84%|████████▍ | 207/247 [00:45<00:08,  4.71it/s]Loading trainS:  84%|████████▍ | 208/247 [00:46<00:08,  4.71it/s]Loading trainS:  85%|████████▍ | 209/247 [00:46<00:08,  4.71it/s]Loading trainS:  85%|████████▌ | 210/247 [00:46<00:07,  4.72it/s]Loading trainS:  85%|████████▌ | 211/247 [00:46<00:07,  4.68it/s]Loading trainS:  86%|████████▌ | 212/247 [00:47<00:07,  4.62it/s]Loading trainS:  86%|████████▌ | 213/247 [00:47<00:07,  4.60it/s]Loading trainS:  87%|████████▋ | 214/247 [00:47<00:07,  4.56it/s]Loading trainS:  87%|████████▋ | 215/247 [00:47<00:07,  4.54it/s]Loading trainS:  87%|████████▋ | 216/247 [00:47<00:06,  4.51it/s]Loading trainS:  88%|████████▊ | 217/247 [00:48<00:06,  4.52it/s]Loading trainS:  88%|████████▊ | 218/247 [00:48<00:06,  4.51it/s]Loading trainS:  89%|████████▊ | 219/247 [00:48<00:06,  4.41it/s]Loading trainS:  89%|████████▉ | 220/247 [00:48<00:06,  4.38it/s]Loading trainS:  89%|████████▉ | 221/247 [00:49<00:05,  4.44it/s]Loading trainS:  90%|████████▉ | 222/247 [00:49<00:05,  4.49it/s]Loading trainS:  90%|█████████ | 223/247 [00:49<00:05,  4.51it/s]Loading trainS:  91%|█████████ | 224/247 [00:49<00:05,  4.53it/s]Loading trainS:  91%|█████████ | 225/247 [00:49<00:04,  4.54it/s]Loading trainS:  91%|█████████▏| 226/247 [00:50<00:04,  4.54it/s]Loading trainS:  92%|█████████▏| 227/247 [00:50<00:04,  4.56it/s]Loading trainS:  92%|█████████▏| 228/247 [00:50<00:04,  4.57it/s]Loading trainS:  93%|█████████▎| 229/247 [00:50<00:03,  4.57it/s]Loading trainS:  93%|█████████▎| 230/247 [00:51<00:03,  4.45it/s]Loading trainS:  94%|█████████▎| 231/247 [00:51<00:03,  4.36it/s]Loading trainS:  94%|█████████▍| 232/247 [00:51<00:03,  4.30it/s]Loading trainS:  94%|█████████▍| 233/247 [00:51<00:03,  4.25it/s]Loading trainS:  95%|█████████▍| 234/247 [00:51<00:03,  4.23it/s]Loading trainS:  95%|█████████▌| 235/247 [00:52<00:02,  4.21it/s]Loading trainS:  96%|█████████▌| 236/247 [00:52<00:02,  4.21it/s]Loading trainS:  96%|█████████▌| 237/247 [00:52<00:02,  4.18it/s]Loading trainS:  96%|█████████▋| 238/247 [00:52<00:02,  4.17it/s]Loading trainS:  97%|█████████▋| 239/247 [00:53<00:01,  4.16it/s]Loading trainS:  97%|█████████▋| 240/247 [00:53<00:01,  4.17it/s]Loading trainS:  98%|█████████▊| 241/247 [00:53<00:01,  4.16it/s]Loading trainS:  98%|█████████▊| 242/247 [00:54<00:01,  2.60it/s]Loading trainS:  98%|█████████▊| 243/247 [00:55<00:01,  2.04it/s]Loading trainS:  99%|█████████▉| 244/247 [00:55<00:01,  1.78it/s]Loading trainS:  99%|█████████▉| 245/247 [00:56<00:01,  1.67it/s]Loading trainS: 100%|█████████▉| 246/247 [00:57<00:00,  1.58it/s]Loading trainS: 100%|██████████| 247/247 [00:58<00:00,  1.47it/s]Loading trainS: 100%|██████████| 247/247 [00:58<00:00,  4.25it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.15it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.21it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.43it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.45it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.37it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.43it/s] min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         2020-01-21 21:15:36.918028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 21:15:36.918132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 21:15:36.918146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 21:15:36.918153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 21:15:36.918443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 45s - loss: 0.1436 - acc: 0.9866 - mDice: 0.7198 - val_loss: 0.2861 - val_acc: 0.9897 - val_mDice: 0.4210

Epoch 00001: val_mDice improved from -inf to 0.42104, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 40s - loss: 0.0811 - acc: 0.9914 - mDice: 0.8423 - val_loss: 0.2092 - val_acc: 0.9885 - val_mDice: 0.4298

Epoch 00002: val_mDice improved from 0.42104 to 0.42985, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 40s - loss: 0.0735 - acc: 0.9922 - mDice: 0.8569 - val_loss: 0.2158 - val_acc: 0.9920 - val_mDice: 0.4392

Epoch 00003: val_mDice improved from 0.42985 to 0.43922, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 40s - loss: 0.0699 - acc: 0.9926 - mDice: 0.8640 - val_loss: 0.1090 - val_acc: 0.9925 - val_mDice: 0.4480

Epoch 00004: val_mDice improved from 0.43922 to 0.44802, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 40s - loss: 0.0663 - acc: 0.9930 - mDice: 0.8711 - val_loss: 0.1162 - val_acc: 0.9923 - val_mDice: 0.4424

Epoch 00005: val_mDice did not improve from 0.44802
Epoch 6/300
 - 40s - loss: 0.0634 - acc: 0.9933 - mDice: 0.8767 - val_loss: 0.1833 - val_acc: 0.9897 - val_mDice: 0.4326

Epoch 00006: val_mDice did not improve from 0.44802
Epoch 7/300
 - 40s - loss: 0.0607 - acc: 0.9935 - mDice: 0.8819 - val_loss: 0.1827 - val_acc: 0.9925 - val_mDice: 0.4512

Epoch 00007: val_mDice improved from 0.44802 to 0.45119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 40s - loss: 0.0587 - acc: 0.9937 - mDice: 0.8859 - val_loss: 0.0659 - val_acc: 0.9920 - val_mDice: 0.4416

Epoch 00008: val_mDice did not improve from 0.45119
Epoch 9/300
 - 40s - loss: 0.0573 - acc: 0.9938 - mDice: 0.8887 - val_loss: 0.0572 - val_acc: 0.9920 - val_mDice: 0.4325

Epoch 00009: val_mDice did not improve from 0.45119
Epoch 10/300
 - 40s - loss: 0.0564 - acc: 0.9939 - mDice: 0.8904 - val_loss: 0.1068 - val_acc: 0.9918 - val_mDice: 0.4423

Epoch 00010: val_mDice did not improve from 0.45119
Epoch 11/300
 - 39s - loss: 0.0565 - acc: 0.9940 - mDice: 0.8902 - val_loss: 0.1378 - val_acc: 0.9919 - val_mDice: 0.4646

Epoch 00011: val_mDice improved from 0.45119 to 0.46463, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 12/300
 - 41s - loss: 0.0551 - acc: 0.9941 - mDice: 0.8929 - val_loss: 0.1151 - val_acc: 0.9922 - val_mDice: 0.4579

Epoch 00012: val_mDice did not improve from 0.46463
Epoch 13/300
 - 40s - loss: 0.0527 - acc: 0.9943 - mDice: 0.8974 - val_loss: 0.0872 - val_acc: 0.9890 - val_mDice: 0.3744

Epoch 00013: val_mDice did not improve from 0.46463
Epoch 14/300
 - 40s - loss: 0.0521 - acc: 0.9943 - mDice: 0.8987 - val_loss: 0.1686 - val_acc: 0.9926 - val_mDice: 0.4695

Epoch 00014: val_mDice improved from 0.46463 to 0.46946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 15/300
 - 40s - loss: 0.0511 - acc: 0.9944 - mDice: 0.9007 - val_loss: 0.1380 - val_acc: 0.9797 - val_mDice: 0.1814

Epoch 00015: val_mDice did not improve from 0.46946
Epoch 16/300
 - 40s - loss: 0.0510 - acc: 0.9944 - mDice: 0.9009 - val_loss: 0.2200 - val_acc: 0.9927 - val_mDice: 0.4650

Epoch 00016: val_mDice did not improve from 0.46946
Epoch 17/300
 - 40s - loss: 0.0490 - acc: 0.9945 - mDice: 0.9048 - val_loss: 0.2142 - val_acc: 0.9930 - val_mDice: 0.4633

Epoch 00017: val_mDice did not improve from 0.46946
Epoch 18/300
 - 40s - loss: 0.0508 - acc: 0.9945 - mDice: 0.9012 - val_loss: 0.1641 - val_acc: 0.9934 - val_mDice: 0.4859

Epoch 00018: val_mDice improved from 0.46946 to 0.48594, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 19/300
 - 40s - loss: 0.0492 - acc: 0.9946 - mDice: 0.9043 - val_loss: 0.2425 - val_acc: 0.9927 - val_mDice: 0.4608

Epoch 00019: val_mDice did not improve from 0.48594
Epoch 20/300
 - 41s - loss: 0.0474 - acc: 0.9947 - mDice: 0.9079 - val_loss: 0.2107 - val_acc: 0.9924 - val_mDice: 0.4606

Epoch 00020: val_mDice did not improve from 0.48594
Epoch 21/300
 - 41s - loss: 0.0471 - acc: 0.9947 - mDice: 0.9084 - val_loss: 0.1847 - val_acc: 0.9908 - val_mDice: 0.4532

Epoch 00021: val_mDice did not improve from 0.48594
Epoch 22/300
 - 40s - loss: 0.0472 - acc: 0.9948 - mDice: 0.9082 - val_loss: 0.1618 - val_acc: 0.9927 - val_mDice: 0.4738

Epoch 00022: val_mDice did not improve from 0.48594
Epoch 23/300
 - 40s - loss: 0.0464 - acc: 0.9948 - mDice: 0.9099 - val_loss: 0.1953 - val_acc: 0.9907 - val_mDice: 0.4586

Epoch 00023: val_mDice did not improve from 0.48594
Epoch 24/300
 - 40s - loss: 0.0453 - acc: 0.9949 - mDice: 0.9120 - val_loss: 0.1312 - val_acc: 0.9926 - val_mDice: 0.4755

Epoch 00024: val_mDice did not improve from 0.48594
Epoch 25/300
 - 40s - loss: 0.0446 - acc: 0.9949 - mDice: 0.9133 - val_loss: 0.1968 - val_acc: 0.9926 - val_mDice: 0.4794

Epoch 00025: val_mDice did not improve from 0.48594
Epoch 26/300
 - 40s - loss: 0.0459 - acc: 0.9949 - mDice: 0.9107 - val_loss: 0.0753 - val_acc: 0.9925 - val_mDice: 0.4649

Epoch 00026: val_mDice did not improve from 0.48594
Epoch 27/300
 - 40s - loss: 0.0454 - acc: 0.9949 - mDice: 0.9118 - val_loss: 0.1480 - val_acc: 0.9928 - val_mDice: 0.4598

Epoch 00027: val_mDice did not improve from 0.48594
Epoch 28/300
 - 40s - loss: 0.0436 - acc: 0.9950 - mDice: 0.9152 - val_loss: 0.1103 - val_acc: 0.9925 - val_mDice: 0.4708

Epoch 00028: val_mDice did not improve from 0.48594
Epoch 29/300
 - 40s - loss: 0.0439 - acc: 0.9950 - mDice: 0.9148 - val_loss: 0.1409 - val_acc: 0.9913 - val_mDice: 0.4530

Epoch 00029: val_mDice did not improve from 0.48594
Epoch 30/300
 - 41s - loss: 0.0438 - acc: 0.9950 - mDice: 0.9149 - val_loss: 0.1678 - val_acc: 0.9901 - val_mDice: 0.4566

Epoch 00030: val_mDice did not improve from 0.48594
Epoch 31/300
 - 40s - loss: 0.0436 - acc: 0.9951 - mDice: 0.9152 - val_loss: 0.2396 - val_acc: 0.9810 - val_mDice: 0.4246

Epoch 00031: val_mDice did not improve from 0.48594
Epoch 32/300
 - 41s - loss: 0.0434 - acc: 0.9951 - mDice: 0.9157 - val_loss: 0.2464 - val_acc: 0.9905 - val_mDice: 0.4627

Epoch 00032: val_mDice did not improve from 0.48594
Epoch 33/300
 - 40s - loss: 0.0436 - acc: 0.9951 - mDice: 0.9152 - val_loss: 0.1625 - val_acc: 0.9918 - val_mDice: 0.4643

Epoch 00033: val_mDice did not improve from 0.48594

Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 34/300
 - 40s - loss: 0.0408 - acc: 0.9953 - mDice: 0.9208 - val_loss: 0.1073 - val_acc: 0.9927 - val_mDice: 0.4758

Epoch 00034: val_mDice did not improve from 0.48594
Epoch 35/300
 - 41s - loss: 0.0408 - acc: 0.9954 - mDice: 0.9207 - val_loss: 0.1322 - val_acc: 0.9925 - val_mDice: 0.4678

Epoch 00035: val_mDice did not improve from 0.48594
Epoch 36/300
 - 40s - loss: 0.0410 - acc: 0.9953 - mDice: 0.9204 - val_loss: 0.1985 - val_acc: 0.9931 - val_mDice: 0.4863

Epoch 00036: val_mDice improved from 0.48594 to 0.48627, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 37/300
 - 40s - loss: 0.0407 - acc: 0.9954 - mDice: 0.9210 - val_loss: 0.2222 - val_acc: 0.9927 - val_mDice: 0.4804

Epoch 00037: val_mDice did not improve from 0.48627
Epoch 38/300
 - 40s - loss: 0.0400 - acc: 0.9954 - mDice: 0.9224 - val_loss: 0.2190 - val_acc: 0.9927 - val_mDice: 0.4730

Epoch 00038: val_mDice did not improve from 0.48627
Epoch 39/300
 - 40s - loss: 0.0399 - acc: 0.9954 - mDice: 0.9224 - val_loss: 0.2113 - val_acc: 0.9919 - val_mDice: 0.4689

Epoch 00039: val_mDice did not improve from 0.48627
Epoch 40/300
 - 41s - loss: 0.0397 - acc: 0.9954 - mDice: 0.9230 - val_loss: 0.2032 - val_acc: 0.9927 - val_mDice: 0.4774

Epoch 00040: val_mDice did not improve from 0.48627
Epoch 41/300
 - 40s - loss: 0.0403 - acc: 0.9954 - mDice: 0.9217 - val_loss: 0.2586 - val_acc: 0.9925 - val_mDice: 0.4719

Epoch 00041: val_mDice did not improve from 0.48627
Epoch 42/300
 - 40s - loss: 0.0394 - acc: 0.9955 - mDice: 0.9235 - val_loss: 0.2474 - val_acc: 0.9928 - val_mDice: 0.4767

Epoch 00042: val_mDice did not improve from 0.48627
Epoch 43/300
 - 40s - loss: 0.0397 - acc: 0.9955 - mDice: 0.9228 - val_loss: 0.2226 - val_acc: 0.9923 - val_mDice: 0.4766

Epoch 00043: val_mDice did not improve from 0.48627
Epoch 44/300
 - 40s - loss: 0.0392 - acc: 0.9955 - mDice: 0.9238 - val_loss: 0.2411 - val_acc: 0.9923 - val_mDice: 0.4690

Epoch 00044: val_mDice did not improve from 0.48627
Epoch 45/300
 - 39s - loss: 0.0387 - acc: 0.9955 - mDice: 0.9249 - val_loss: 0.2391 - val_acc: 0.9916 - val_mDice: 0.4566

Epoch 00045: val_mDice did not improve from 0.48627
Epoch 46/300
 - 40s - loss: 0.0388 - acc: 0.9955 - mDice: 0.9247 - val_loss: 0.2241 - val_acc: 0.9923 - val_mDice: 0.4627

Epoch 00046: val_mDice did not improve from 0.48627
Epoch 47/300
 - 39s - loss: 0.0387 - acc: 0.9955 - mDice: 0.9248 - val_loss: 0.2232 - val_acc: 0.9915 - val_mDice: 0.4710

Epoch 00047: val_mDice did not improve from 0.48627
Epoch 48/300
 - 40s - loss: 0.0390 - acc: 0.9955 - mDice: 0.9243 - val_loss: 0.2004 - val_acc: 0.9930 - val_mDice: 0.4690

Epoch 00048: val_mDice did not improve from 0.48627

Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 49/300
 - 41s - loss: 0.0382 - acc: 0.9956 - mDice: 0.9259 - val_loss: 0.1966 - val_acc: 0.9926 - val_mDice: 0.4834

Epoch 00049: val_mDice did not improve from 0.48627
Epoch 50/300
 - 41s - loss: 0.0377 - acc: 0.9956 - mDice: 0.9267 - val_loss: 0.2174 - val_acc: 0.9930 - val_mDice: 0.4836

Epoch 00050: val_mDice did not improve from 0.48627
Epoch 51/300
 - 40s - loss: 0.0373 - acc: 0.9956 - mDice: 0.9275 - val_loss: 0.1883 - val_acc: 0.9930 - val_mDice: 0.4826

Epoch 00051: val_mDice did not improve from 0.48627
Epoch 52/300
 - 40s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9272 - val_loss: 0.1769 - val_acc: 0.9927 - val_mDice: 0.4747

Epoch 00052: val_mDice did not improve from 0.48627
Epoch 53/300
 - 40s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9293 - val_loss: 0.1861 - val_acc: 0.9924 - val_mDice: 0.4785

Epoch 00053: val_mDice did not improve from 0.48627
Epoch 54/300
 - 39s - loss: 0.0368 - acc: 0.9957 - mDice: 0.9285 - val_loss: 0.2306 - val_acc: 0.9926 - val_mDice: 0.4775

Epoch 00054: val_mDice did not improve from 0.48627
Epoch 55/300
 - 41s - loss: 0.0370 - acc: 0.9957 - mDice: 0.9281 - val_loss: 0.2360 - val_acc: 0.9930 - val_mDice: 0.4815

Epoch 00055: val_mDice did not improve from 0.48627
Epoch 56/300
 - 41s - loss: 0.0368 - acc: 0.9957 - mDice: 0.9285 - val_loss: 0.2476 - val_acc: 0.9927 - val_mDice: 0.4736

Epoch 00056: val_mDice did not improve from 0.48627
Epoch 57/300
 - 42s - loss: 0.0367 - acc: 0.9957 - mDice: 0.9287 - val_loss: 0.2578 - val_acc: 0.9929 - val_mDice: 0.4762

Epoch 00057: val_mDice did not improve from 0.48627
Epoch 58/300
 - 41s - loss: 0.0369 - acc: 0.9957 - mDice: 0.9284 - val_loss: 0.2439 - val_acc: 0.9927 - val_mDice: 0.4759

Epoch 00058: val_mDice did not improve from 0.48627
Epoch 59/300
 - 41s - loss: 0.0372 - acc: 0.9957 - mDice: 0.9277 - val_loss: 0.2121 - val_acc: 0.9919 - val_mDice: 0.4697

Epoch 00059: val_mDice did not improve from 0.48627
Epoch 60/300
 - 42s - loss: 0.0370 - acc: 0.9957 - mDice: 0.9282 - val_loss: 0.2097 - val_acc: 0.9927 - val_mDice: 0.4768

Epoch 00060: val_mDice did not improve from 0.48627
Epoch 61/300
 - 42s - loss: 0.0377 - acc: 0.9957 - mDice: 0.9268 - val_loss: 0.2213 - val_acc: 0.9928 - val_mDice: 0.4720

Epoch 00061: val_mDice did not improve from 0.48627
Epoch 62/300
 - 42s - loss: 0.0359 - acc: 0.9957 - mDice: 0.9303 - val_loss: 0.1902 - val_acc: 0.9924 - val_mDice: 0.4766

Epoch 00062: val_mDice did not improve from 0.48627
Epoch 63/300
 - 41s - loss: 0.0366 - acc: 0.9957 - mDice: 0.9290 - val_loss: 0.2321 - val_acc: 0.9896 - val_mDice: 0.4585

Epoch 00063: val_mDice did not improve from 0.48627

Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 64/300
 - 41s - loss: 0.0363 - acc: 0.9957 - mDice: 0.9294 - val_loss: 0.2316 - val_acc: 0.9929 - val_mDice: 0.4782

Epoch 00064: val_mDice did not improve from 0.48627
Epoch 65/300
 - 41s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9300 - val_loss: 0.2469 - val_acc: 0.9927 - val_mDice: 0.4819

Epoch 00065: val_mDice did not improve from 0.48627
Epoch 66/300
 - 42s - loss: 0.0357 - acc: 0.9958 - mDice: 0.9306 - val_loss: 0.2484 - val_acc: 0.9930 - val_mDice: 0.4788

Epoch 00066: val_mDice did not improve from 0.48627
Epoch 67/300
 - 42s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9310 - val_loss: 0.2404 - val_acc: 0.9928 - val_mDice: 0.4805

Epoch 00067: val_mDice did not improve from 0.48627
Epoch 68/300
 - 42s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9298 - val_loss: 0.2449 - val_acc: 0.9927 - val_mDice: 0.4743

Epoch 00068: val_mDice did not improve from 0.48627
Epoch 69/300
 - 41s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9316 - val_loss: 0.2557 - val_acc: 0.9930 - val_mDice: 0.4750

Epoch 00069: val_mDice did not improve from 0.48627
Epoch 70/300
 - 41s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9299 - val_loss: 0.2450 - val_acc: 0.9926 - val_mDice: 0.4791

Epoch 00070: val_mDice did not improve from 0.48627
Epoch 71/300
 - 40s - loss: 0.0347 - acc: 0.9958 - mDice: 0.9326 - val_loss: 0.2504 - val_acc: 0.9929 - val_mDice: 0.4777

Epoch 00071: val_mDice did not improve from 0.48627
Epoch 72/300
 - 40s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9304 - val_loss: 0.2572 - val_acc: 0.9928 - val_mDice: 0.4738

Epoch 00072: val_mDice did not improve from 0.48627
Epoch 73/300
 - 41s - loss: 0.0354 - acc: 0.9958 - mDice: 0.9313 - val_loss: 0.2547 - val_acc: 0.9928 - val_mDice: 0.4790

Epoch 00073: val_mDice did not improve from 0.48627
Epoch 74/300
 - 40s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9303 - val_loss: 0.2582 - val_acc: 0.9927 - val_mDice: 0.4757

Epoch 00074: val_mDice did not improve from 0.48627
Epoch 75/300
 - 41s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9310 - val_loss: 0.2582 - val_acc: 0.9925 - val_mDice: 0.4745

Epoch 00075: val_mDice did not improve from 0.48627
Epoch 76/300
 - 40s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9316 - val_loss: 0.2497 - val_acc: 0.9927 - val_mDice: 0.4758

Epoch 00076: val_mDice did not improve from 0.48627
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [0.2860725868392635, 0.2091578447872454, 0.2157881314958538, 0.10898940408373023, 0.1161690227709733, 0.18327582951959548, 0.1826582664215529, 0.06587335154100939, 0.057218223675951224, 0.10680016454633649, 0.13778083648409573, 0.11511633654793461, 0.08721524154817736, 0.16864966809212625, 0.13797706182117578, 0.220009801713554, 0.21420733187649701, 0.164113474142802, 0.24250346605663184, 0.21068399343583677, 0.18465037657333924, 0.16184701862277928, 0.1953281726207103, 0.13120839867863926, 0.19675132958917646, 0.07525541299993212, 0.14797920709078735, 0.11027120304358257, 0.14088177958408277, 0.16780593507998698, 0.23959666633749152, 0.2463924186276244, 0.16246631558055993, 0.10729256760071705, 0.13217888016242524, 0.19853791062001352, 0.22221614693378186, 0.21896333451027628, 0.21126465378580866, 0.20317653716505468, 0.25862523421152933, 0.24743490292503312, 0.22263274540951303, 0.24113126519743028, 0.23912373028538964, 0.2241238337737304, 0.22315535897965189, 0.20036874322203901, 0.19655546501234128, 0.217411776025732, 0.1883018861661802, 0.17693801103411494, 0.18609516000425494, 0.23060302306581903, 0.2359527004910661, 0.24757425563113467, 0.2578266868004212, 0.24392472001704368, 0.21208282750290078, 0.20965277862262438, 0.22130226502726386, 0.19020934044956803, 0.23214170019010882, 0.23163107212062353, 0.24690562285281517, 0.24837224001999017, 0.24037290800799122, 0.2448815391496853, 0.25568619853741414, 0.24502851051074248, 0.25040433370136284, 0.25715458500492683, 0.2546834411384823, 0.25816905400058526, 0.2581853841965621, 0.24965996301925933], 'val_acc': [0.9896572803233837, 0.9885321075135881, 0.9919792893412593, 0.9925092730794225, 0.9922916194698116, 0.9896927585114946, 0.9924534201264024, 0.992027225437107, 0.9919533980143321, 0.9918265994246658, 0.9919160081817581, 0.9922165927944241, 0.9889568720493946, 0.9926262485372411, 0.9797155853506323, 0.9927235705716474, 0.993005940864036, 0.9933618953278115, 0.9927408290696932, 0.9924083586569663, 0.9908270384814288, 0.9926955259598054, 0.9907074246678624, 0.9926399056975906, 0.9926233721209002, 0.9925030426936107, 0.992838142154453, 0.9925066311438162, 0.9912819937542752, 0.9900937832153596, 0.9809869721129134, 0.9904504588416388, 0.9917741043789609, 0.9926811349284541, 0.9924948909977177, 0.9930862353012726, 0.9926832971630154, 0.9926648376224277, 0.9918623174632992, 0.992665075683021, 0.9925317993393173, 0.9927561687635588, 0.9923323707895594, 0.9923136749783078, 0.9916377099784645, 0.9922988114056287, 0.9915200167590076, 0.9929798078966571, 0.992573035729898, 0.9929647080533139, 0.9929563204447428, 0.9927178159490362, 0.9924054822406253, 0.9926212134661975, 0.9929800495371088, 0.9927096628211998, 0.992901664954406, 0.9927108638637416, 0.9919291892209211, 0.9927298013154451, 0.9927532941371471, 0.992428013870308, 0.989594475285069, 0.9928995080896326, 0.992696003870921, 0.9929544034304919, 0.9928393449869242, 0.9926842565651055, 0.9929551158223424, 0.9926451859889446, 0.992902380926115, 0.9928077097769614, 0.9928307175278306, 0.9926847362661505, 0.9925054372609915, 0.9927357957885788], 'val_mDice': [0.42104214385107114, 0.4298456890268011, 0.4392190998022979, 0.44802317837695393, 0.4423894860722997, 0.43264102087293815, 0.45119132220684655, 0.44163480982766135, 0.43252487642736404, 0.44225052708607215, 0.4646251675065931, 0.45787100811620374, 0.37437252269627097, 0.4694584378967056, 0.1813530518013324, 0.46501061579844616, 0.4632851360617457, 0.48594419483665946, 0.46079644636885897, 0.46063094615220307, 0.4532485394864469, 0.47376178048394463, 0.4585959733248475, 0.4755325292659414, 0.47941305319423433, 0.4649430692374885, 0.45976537718876703, 0.47077113354170286, 0.45297120941114855, 0.45655554993911546, 0.4245563936726171, 0.46269471668399964, 0.46426883263809904, 0.4758271024570809, 0.4678257276771126, 0.48626657116699507, 0.48035134139048447, 0.47298127298720805, 0.4688743029474026, 0.4774465870634465, 0.47189383399770696, 0.47673270587359107, 0.4766057328776912, 0.46901874624573076, 0.4565558498641392, 0.4626978374459931, 0.47101124007108536, 0.4689829626509377, 0.4833724774565693, 0.4835901165509725, 0.4826286632019478, 0.4746595893178258, 0.47852579739179696, 0.4775153746543167, 0.4814518403049346, 0.473554178669646, 0.47622944603117556, 0.47594309569121124, 0.46965585713898456, 0.4767710310560817, 0.4720455739233229, 0.4765873797294661, 0.4584781004412396, 0.4782158187268912, 0.4819344795748099, 0.4787849879742519, 0.48046284240555837, 0.47434763065553287, 0.47496216266933045, 0.479148657091924, 0.47771721848988674, 0.47378450723751336, 0.47896675541773215, 0.4756544345245884, 0.4745330647831117, 0.47582125822613547], 'loss': [0.1435866742554214, 0.08108121166436773, 0.07353849323898881, 0.06991770318043239, 0.06626310413731112, 0.0633579711843374, 0.06072245132286627, 0.05867284214611652, 0.0572596357179955, 0.05637070330753984, 0.05645133309625881, 0.0550711642643072, 0.05272943955585318, 0.05210592480933702, 0.0510975129509281, 0.05096714025936038, 0.048987917852291236, 0.05077361334835444, 0.049245063403047656, 0.04742661616411083, 0.047137647204970975, 0.04722071886270752, 0.04635473911073214, 0.04531294997665861, 0.044643976389850924, 0.045916948482866295, 0.04536834184907443, 0.04364939967731954, 0.043861819804755404, 0.043838652789414886, 0.04362248237148465, 0.043376769348066065, 0.04363467524970617, 0.0407688840187797, 0.04082938476154807, 0.04098615944328766, 0.040675385476187986, 0.03998324115608134, 0.039947039059787075, 0.03966931610188858, 0.040313239684446105, 0.03938575103357704, 0.03974867067154033, 0.03922629250427192, 0.0386862013916857, 0.03878740949196616, 0.038697394785234096, 0.03895476016477739, 0.03817497302040918, 0.03774733410022515, 0.037336311240581004, 0.03746994835737357, 0.0364538420675959, 0.036842452255394884, 0.03704155567835024, 0.036840632188911246, 0.03671224548032447, 0.03686841092963543, 0.037207331087171336, 0.036957638221016824, 0.03769606092162953, 0.03592201332960134, 0.03658112748661735, 0.036346546414882205, 0.03602742156212871, 0.035749350820910054, 0.035539106667915925, 0.036122396379249466, 0.03526578792980168, 0.03608892421239248, 0.034718282796543265, 0.03583270127822782, 0.035384945445125514, 0.03590646942894267, 0.03552346249685069, 0.03526500539604531], 'acc': [0.986593388661938, 0.9914299424099821, 0.9922151292636578, 0.9926169160570192, 0.9930202940533437, 0.9933455947217287, 0.9935226395246559, 0.9937334154781542, 0.9937905993932966, 0.9938663099048387, 0.9939689655681162, 0.9940900591909072, 0.9943061352048584, 0.9942969780529531, 0.9943941613392833, 0.9944206086592208, 0.9945460953611652, 0.9945401314909242, 0.9945604160213295, 0.9946516343589268, 0.994744616617105, 0.9947529321556644, 0.9948137151756768, 0.9948806894914618, 0.9949472335949905, 0.9949025572137177, 0.9949468980932318, 0.9950099005773934, 0.9950178313100916, 0.9949899684564703, 0.9950700693301235, 0.9950824386505436, 0.9951381535425949, 0.9953212591437913, 0.9953678466578785, 0.9953410283027169, 0.9954060013540494, 0.9953722613598459, 0.9954338180974176, 0.9954112256211286, 0.9954052212033815, 0.9954535210823591, 0.9954741719820924, 0.995486901969079, 0.9955003157955269, 0.9954966630612349, 0.9955208045960563, 0.9955226952867215, 0.9956034493101232, 0.9956170254212002, 0.995633053909021, 0.995661797686067, 0.9956814300316901, 0.9956682236048844, 0.9956934817646672, 0.9956695669061093, 0.9956751512759118, 0.9957055727774495, 0.9956949453347524, 0.9956714120011702, 0.9956897568584632, 0.995714649114372, 0.9957051631662779, 0.9957284277813389, 0.9957864231082736, 0.9957739922646288, 0.9957573391900624, 0.9957882171282352, 0.9957593358075397, 0.9957634915730952, 0.9958005419050532, 0.9957871623330173, 0.9957977393666311, 0.9957788163242276, 0.9957812283502429, 0.9957963970455092], 'mDice': [0.7198004936907202, 0.8422662224584484, 0.8569340297793754, 0.8639654933878387, 0.871056602489315, 0.8766997837394702, 0.8818722901220546, 0.8858622834687156, 0.8886593032069422, 0.8903960839247872, 0.890176007720891, 0.8928766735023441, 0.8974432681683214, 0.8986898005655792, 0.9006644939136584, 0.900904457441671, 0.9047946488317645, 0.9012296576457102, 0.9042762716863505, 0.9078581561270869, 0.9083918718813063, 0.9082172177540416, 0.9099184333648921, 0.9119652814164585, 0.9132700061337939, 0.9107494027105545, 0.9118179065993033, 0.9152236535741249, 0.9147916752969217, 0.9148514749292237, 0.9152415190153399, 0.9157311355876178, 0.915181704736363, 0.9208124389187373, 0.9206717277010632, 0.920369724614347, 0.9209622331041702, 0.9223568723297264, 0.9223995368357015, 0.9229653388891861, 0.9216801898644906, 0.9235077829869859, 0.9227788578604192, 0.92381201914837, 0.9248793304901215, 0.9246798339975985, 0.9248460054049439, 0.9243361840898382, 0.9258543313681061, 0.9266940105847651, 0.9275111784877894, 0.9272302773920486, 0.929255688491681, 0.9284803295701611, 0.9280702125404791, 0.9284841009574681, 0.9287314914300793, 0.9284082270052295, 0.927731210894376, 0.9282440443045298, 0.9267526003009282, 0.930295104303403, 0.9289772029294188, 0.9294366142055919, 0.930048800284473, 0.9306122889390681, 0.9310338128355524, 0.9298499792191757, 0.9315739010116136, 0.9299257986697385, 0.932649017462586, 0.9304291841514708, 0.931318452517787, 0.9302827304665622, 0.9310469575120823, 0.9315603751847422], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.48it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.91it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.33it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.79it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.32it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.53it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:30,  8.06it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:30,  8.09it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:29,  8.21it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:29,  8.28it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:29,  8.27it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:28,  8.33it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:29,  8.26it/s]predicting train subjects:   3%|▎         | 8/247 [00:00<00:28,  8.35it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:29,  8.02it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:29,  8.12it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:28,  8.17it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:28,  8.26it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:28,  8.34it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:27,  8.39it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:27,  8.30it/s]predicting train subjects:   6%|▋         | 16/247 [00:01<00:27,  8.31it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:27,  8.35it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:27,  8.28it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:27,  8.41it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:27,  8.36it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:27,  8.15it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:27,  8.26it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:26,  8.39it/s]predicting train subjects:  10%|▉         | 24/247 [00:02<00:26,  8.54it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:26,  8.53it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:25,  8.60it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:25,  8.63it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:25,  8.67it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:25,  8.48it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:25,  8.52it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:25,  8.57it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:24,  8.64it/s]predicting train subjects:  13%|█▎        | 33/247 [00:03<00:24,  8.68it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:24,  8.57it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:24,  8.63it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:24,  8.64it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:24,  8.61it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:24,  8.67it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:24,  8.64it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:23,  8.69it/s]predicting train subjects:  17%|█▋        | 41/247 [00:04<00:23,  8.69it/s]predicting train subjects:  17%|█▋        | 42/247 [00:04<00:23,  8.77it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:23,  8.76it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:23,  8.82it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:23,  8.76it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:22,  8.80it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:23,  8.46it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:23,  8.61it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:22,  8.66it/s]predicting train subjects:  20%|██        | 50/247 [00:05<00:22,  8.73it/s]predicting train subjects:  21%|██        | 51/247 [00:06<00:22,  8.75it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:22,  8.70it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:22,  8.71it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:21,  8.77it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:21,  8.87it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:21,  8.91it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:21,  8.89it/s]predicting train subjects:  23%|██▎       | 58/247 [00:06<00:21,  8.94it/s]predicting train subjects:  24%|██▍       | 59/247 [00:06<00:21,  8.74it/s]predicting train subjects:  24%|██▍       | 60/247 [00:07<00:21,  8.59it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:21,  8.50it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:21,  8.44it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:21,  8.39it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:22,  8.23it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:22,  8.14it/s]predicting train subjects:  27%|██▋       | 66/247 [00:07<00:22,  8.19it/s]predicting train subjects:  27%|██▋       | 67/247 [00:07<00:21,  8.21it/s]predicting train subjects:  28%|██▊       | 68/247 [00:08<00:21,  8.23it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:21,  8.26it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:21,  8.26it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:21,  8.29it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:21,  8.30it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:20,  8.31it/s]predicting train subjects:  30%|██▉       | 74/247 [00:08<00:20,  8.32it/s]predicting train subjects:  30%|███       | 75/247 [00:08<00:20,  8.33it/s]predicting train subjects:  31%|███       | 76/247 [00:08<00:20,  8.35it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:24,  6.99it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:25,  6.50it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:24,  6.86it/s]predicting train subjects:  32%|███▏      | 80/247 [00:09<00:25,  6.65it/s]predicting train subjects:  33%|███▎      | 81/247 [00:09<00:23,  7.17it/s]predicting train subjects:  33%|███▎      | 82/247 [00:09<00:22,  7.49it/s]predicting train subjects:  34%|███▎      | 83/247 [00:09<00:21,  7.76it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:20,  8.02it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:19,  8.21it/s]predicting train subjects:  35%|███▍      | 86/247 [00:10<00:19,  8.36it/s]predicting train subjects:  35%|███▌      | 87/247 [00:10<00:18,  8.47it/s]predicting train subjects:  36%|███▌      | 88/247 [00:10<00:18,  8.54it/s]predicting train subjects:  36%|███▌      | 89/247 [00:10<00:18,  8.46it/s]predicting train subjects:  36%|███▋      | 90/247 [00:10<00:18,  8.47it/s]predicting train subjects:  37%|███▋      | 91/247 [00:10<00:18,  8.43it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:18,  8.22it/s]predicting train subjects:  38%|███▊      | 93/247 [00:11<00:18,  8.21it/s]predicting train subjects:  38%|███▊      | 94/247 [00:11<00:18,  8.30it/s]predicting train subjects:  38%|███▊      | 95/247 [00:11<00:18,  8.39it/s]predicting train subjects:  39%|███▉      | 96/247 [00:11<00:17,  8.44it/s]predicting train subjects:  39%|███▉      | 97/247 [00:11<00:17,  8.39it/s]predicting train subjects:  40%|███▉      | 98/247 [00:11<00:17,  8.40it/s]predicting train subjects:  40%|████      | 99/247 [00:11<00:17,  8.43it/s]predicting train subjects:  40%|████      | 100/247 [00:12<00:18,  7.88it/s]predicting train subjects:  41%|████      | 101/247 [00:12<00:19,  7.67it/s]predicting train subjects:  41%|████▏     | 102/247 [00:12<00:20,  7.17it/s]predicting train subjects:  42%|████▏     | 103/247 [00:12<00:20,  7.17it/s]predicting train subjects:  42%|████▏     | 104/247 [00:12<00:20,  7.10it/s]predicting train subjects:  43%|████▎     | 105/247 [00:12<00:20,  6.96it/s]predicting train subjects:  43%|████▎     | 106/247 [00:12<00:19,  7.06it/s]predicting train subjects:  43%|████▎     | 107/247 [00:13<00:20,  6.85it/s]predicting train subjects:  44%|████▎     | 108/247 [00:13<00:21,  6.50it/s]predicting train subjects:  44%|████▍     | 109/247 [00:13<00:21,  6.40it/s]predicting train subjects:  45%|████▍     | 110/247 [00:13<00:20,  6.58it/s]predicting train subjects:  45%|████▍     | 111/247 [00:13<00:20,  6.69it/s]predicting train subjects:  45%|████▌     | 112/247 [00:13<00:19,  6.86it/s]predicting train subjects:  46%|████▌     | 113/247 [00:13<00:19,  6.80it/s]predicting train subjects:  46%|████▌     | 114/247 [00:14<00:19,  6.92it/s]predicting train subjects:  47%|████▋     | 115/247 [00:14<00:18,  7.04it/s]predicting train subjects:  47%|████▋     | 116/247 [00:14<00:18,  7.01it/s]predicting train subjects:  47%|████▋     | 117/247 [00:14<00:18,  6.93it/s]predicting train subjects:  48%|████▊     | 118/247 [00:14<00:18,  7.08it/s]predicting train subjects:  48%|████▊     | 119/247 [00:14<00:17,  7.18it/s]predicting train subjects:  49%|████▊     | 120/247 [00:14<00:17,  7.32it/s]predicting train subjects:  49%|████▉     | 121/247 [00:15<00:17,  7.33it/s]predicting train subjects:  49%|████▉     | 122/247 [00:15<00:17,  7.32it/s]predicting train subjects:  50%|████▉     | 123/247 [00:15<00:16,  7.36it/s]predicting train subjects:  50%|█████     | 124/247 [00:15<00:16,  7.43it/s]predicting train subjects:  51%|█████     | 125/247 [00:15<00:16,  7.26it/s]predicting train subjects:  51%|█████     | 126/247 [00:15<00:16,  7.35it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:15<00:16,  7.45it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:15<00:15,  7.57it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:16<00:15,  7.55it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:16<00:15,  7.61it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:16<00:15,  7.66it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:16<00:15,  7.65it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:16<00:14,  7.66it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:16<00:14,  7.73it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:16<00:14,  7.75it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:17<00:13,  8.16it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:17<00:12,  8.55it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:17<00:12,  8.66it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:17<00:12,  8.85it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:17<00:11,  9.07it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:17<00:12,  8.81it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:17<00:11,  8.93it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:17<00:11,  9.15it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:17<00:11,  9.30it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:17<00:10,  9.33it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:18<00:10,  9.48it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:18<00:10,  9.52it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:18<00:10,  9.51it/s]predicting train subjects:  60%|██████    | 149/247 [00:18<00:10,  9.57it/s]predicting train subjects:  61%|██████    | 150/247 [00:18<00:10,  9.61it/s]predicting train subjects:  61%|██████    | 151/247 [00:18<00:09,  9.66it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:18<00:09,  9.67it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:18<00:09,  9.59it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:18<00:10,  9.22it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:19<00:10,  8.95it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:19<00:10,  8.90it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:19<00:10,  8.88it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:19<00:10,  8.76it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:19<00:10,  8.74it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:19<00:10,  8.55it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:19<00:10,  8.52it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:19<00:09,  8.55it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:19<00:09,  8.52it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:20<00:09,  8.48it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:20<00:09,  8.40it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:20<00:09,  8.33it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:20<00:09,  8.35it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:20<00:09,  8.43it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:20<00:09,  8.31it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:20<00:09,  8.31it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:20<00:09,  8.39it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:21<00:08,  8.45it/s]predicting train subjects:  70%|███████   | 173/247 [00:21<00:10,  7.09it/s]predicting train subjects:  70%|███████   | 174/247 [00:21<00:09,  7.48it/s]predicting train subjects:  71%|███████   | 175/247 [00:21<00:10,  7.02it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:21<00:09,  7.40it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:21<00:09,  7.57it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:21<00:08,  7.80it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:22<00:08,  7.95it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:22<00:08,  8.09it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:22<00:08,  8.13it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:22<00:08,  8.05it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:22<00:07,  8.25it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:22<00:07,  8.27it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:22<00:07,  8.41it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:22<00:07,  8.21it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:22<00:07,  8.26it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:23<00:07,  8.27it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:23<00:07,  8.08it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:23<00:06,  8.20it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:23<00:06,  8.21it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:23<00:06,  8.34it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:23<00:06,  8.43it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:23<00:06,  8.62it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:23<00:05,  8.76it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:24<00:05,  8.88it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:24<00:05,  8.97it/s]predicting train subjects:  80%|████████  | 198/247 [00:24<00:05,  9.03it/s]predicting train subjects:  81%|████████  | 199/247 [00:24<00:05,  9.09it/s]predicting train subjects:  81%|████████  | 200/247 [00:24<00:05,  9.13it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:24<00:05,  9.17it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:24<00:04,  9.18it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:24<00:04,  9.13it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:24<00:04,  9.09it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:25<00:04,  9.08it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:25<00:04,  9.13it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:25<00:04,  9.13it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:25<00:04,  9.17it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:25<00:04,  9.22it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:25<00:04,  9.12it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:25<00:03,  9.11it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:25<00:04,  8.61it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:25<00:03,  8.61it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:26<00:03,  8.73it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:26<00:03,  8.78it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:26<00:03,  8.66it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:26<00:03,  8.74it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:26<00:03,  8.82it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:26<00:03,  8.88it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:26<00:03,  8.83it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:26<00:02,  8.83it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:26<00:02,  8.83it/s]predicting train subjects:  90%|█████████ | 223/247 [00:27<00:02,  8.90it/s]predicting train subjects:  91%|█████████ | 224/247 [00:27<00:02,  8.93it/s]predicting train subjects:  91%|█████████ | 225/247 [00:27<00:02,  8.79it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:27<00:02,  8.84it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:27<00:02,  8.84it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:27<00:02,  8.78it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:27<00:02,  8.83it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:27<00:02,  8.37it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:27<00:01,  8.00it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:28<00:01,  7.77it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:28<00:01,  7.71it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:28<00:01,  7.67it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:28<00:01,  7.62it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:28<00:01,  7.56it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:28<00:01,  7.53it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:28<00:01,  7.53it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:29<00:01,  7.48it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:29<00:00,  7.47it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:29<00:00,  7.36it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:29<00:00,  7.41it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:29<00:00,  7.42it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:29<00:00,  7.44it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:29<00:00,  7.25it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:30<00:00,  7.27it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  7.34it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  8.19it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  6.96it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  6.90it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.35it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  7.61it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.47it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.49it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:31,  7.73it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:30,  8.00it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:29,  8.26it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:29,  8.27it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:29,  8.29it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:28,  8.37it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:28,  8.40it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:28,  8.39it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:28,  8.35it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:28,  8.40it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:28,  8.39it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:27,  8.46it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:27,  8.41it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:27,  8.42it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:27,  8.48it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:01<00:28,  8.14it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:28,  8.19it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:28,  8.17it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:27,  8.23it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:27,  8.32it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:27,  8.34it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:26,  8.35it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:27,  8.21it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:02<00:26,  8.37it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:02<00:26,  8.34it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:27,  8.17it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:26,  8.41it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:25,  8.47it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:25,  8.62it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:25,  8.65it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:24,  8.68it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:24,  8.79it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:03<00:24,  8.81it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:24,  8.79it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:24,  8.76it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:24,  8.79it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:24,  8.47it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:24,  8.55it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:24,  8.63it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:23,  8.70it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:04<00:23,  8.73it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:04<00:23,  8.77it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:23,  8.78it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:23,  8.73it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:23,  8.76it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:22,  8.76it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:23,  8.49it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:23,  8.64it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:05<00:22,  8.73it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:05<00:22,  8.74it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:05<00:22,  8.80it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:21,  8.89it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:21,  8.93it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:21,  8.99it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:21,  8.94it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:21,  8.90it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:06<00:21,  8.85it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:06<00:21,  8.80it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:06<00:22,  8.39it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:22,  8.35it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:22,  8.36it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:22,  8.36it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:22,  8.31it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:22,  8.32it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:07<00:22,  8.15it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:07<00:22,  8.18it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:07<00:21,  8.26it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:07<00:21,  8.25it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:22,  7.95it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:21,  8.07it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:21,  8.15it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:21,  8.16it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:08<00:21,  8.20it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:08<00:21,  8.24it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:08<00:20,  8.27it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:08<00:20,  8.21it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:20,  8.29it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:21,  7.94it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:21,  7.95it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:19,  8.43it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:09<00:20,  8.29it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:09<00:20,  8.05it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:09<00:20,  8.06it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:09<00:20,  8.01it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:20,  8.08it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:19,  8.16it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:19,  8.24it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:10<00:19,  8.19it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:10<00:20,  7.83it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:10<00:19,  7.91it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:10<00:20,  7.67it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:10<00:19,  7.87it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:19,  8.05it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:18,  8.12it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:11<00:19,  7.94it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:11<00:18,  8.02it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:11<00:18,  8.07it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:11<00:18,  8.18it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:11<00:17,  8.24it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:11<00:19,  7.62it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:19,  7.41it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:12<00:19,  7.30it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:12<00:19,  7.28it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:12<00:19,  7.30it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:12<00:19,  7.23it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:12<00:19,  7.23it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:12<00:19,  7.19it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:19,  7.19it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:13<00:19,  7.17it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:13<00:19,  7.18it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:13<00:18,  7.16it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:13<00:18,  7.15it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:13<00:18,  7.15it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:13<00:18,  7.12it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:18,  7.12it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:18,  7.16it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:14<00:18,  7.12it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:14<00:17,  7.32it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:14<00:17,  7.47it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:14<00:16,  7.56it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:14<00:16,  7.64it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:14<00:16,  7.72it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:16,  7.75it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:15,  7.76it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:15<00:15,  7.71it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:15<00:15,  7.77it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:15<00:15,  7.80it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:15<00:15,  7.75it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:15<00:15,  7.66it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:15,  7.69it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:15,  7.73it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:14,  7.68it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:14,  7.66it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:16<00:14,  7.63it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:16<00:14,  7.52it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:16<00:13,  7.99it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:16<00:13,  8.36it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.61it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.84it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:11,  9.02it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:11,  9.15it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:17<00:11,  9.25it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:17<00:11,  9.31it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:17<00:11,  9.22it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:17<00:10,  9.33it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:17<00:10,  9.29it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:17<00:10,  9.37it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:10,  9.38it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:10,  9.46it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:10,  9.59it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:18<00:09,  9.61it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:18<00:09,  9.63it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:18<00:09,  9.56it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:18<00:10,  9.19it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:18<00:10,  8.90it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:18<00:10,  8.73it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:10,  8.68it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:10,  8.70it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:19<00:10,  8.72it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:19<00:10,  8.62it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:19<00:10,  8.58it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:19<00:09,  8.59it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:19<00:09,  8.62it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:19<00:09,  8.55it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:20<00:09,  8.44it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:20<00:09,  8.49it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:20<00:09,  8.52it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:20<00:09,  8.53it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:20<00:09,  8.44it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:20<00:09,  8.41it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:20<00:09,  8.42it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:20<00:08,  8.44it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:20<00:08,  8.58it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:21<00:08,  8.55it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:21<00:08,  8.18it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:21<00:08,  8.26it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:21<00:08,  8.19it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:21<00:08,  8.25it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:21<00:08,  8.37it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:21<00:07,  8.38it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:21<00:07,  8.40it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:22<00:07,  8.37it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:22<00:07,  8.44it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:22<00:07,  8.38it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:22<00:07,  8.41it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:22<00:07,  8.12it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:22<00:07,  8.23it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:22<00:07,  8.33it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:22<00:06,  8.41it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:22<00:06,  8.34it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:23<00:06,  8.27it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:23<00:06,  7.98it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:23<00:06,  8.13it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:23<00:06,  8.29it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:23<00:06,  8.42it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:23<00:05,  8.63it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:23<00:05,  8.67it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:23<00:05,  8.64it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:24<00:05,  8.63it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:24<00:05,  8.68it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:24<00:05,  8.84it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:24<00:05,  8.92it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:24<00:04,  9.01it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:24<00:04,  8.96it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:24<00:04,  8.99it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:24<00:04,  8.96it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:24<00:04,  8.58it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:25<00:04,  8.68it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:25<00:04,  8.74it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:25<00:04,  8.80it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:25<00:04,  8.67it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:25<00:04,  8.64it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:25<00:03,  8.63it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:25<00:03,  8.66it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:25<00:03,  8.60it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:26<00:03,  8.57it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:26<00:03,  8.53it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:26<00:03,  8.57it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:26<00:03,  8.57it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:26<00:03,  8.52it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:26<00:03,  8.48it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:26<00:03,  8.33it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:26<00:02,  8.43it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:26<00:02,  8.51it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:27<00:02,  8.53it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:27<00:02,  8.37it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:27<00:02,  8.37it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:27<00:02,  8.33it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:27<00:02,  8.34it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:27<00:02,  7.91it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:27<00:02,  7.69it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:27<00:02,  7.46it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:28<00:01,  7.42it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:28<00:01,  7.39it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:28<00:01,  7.37it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:28<00:01,  7.32it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:28<00:01,  7.39it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:28<00:01,  7.36it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:28<00:01,  7.39it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:29<00:00,  7.39it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:29<00:00,  7.39it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:29<00:00,  7.38it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:29<00:00,  7.37it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:29<00:00,  7.08it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:29<00:00,  7.15it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:29<00:00,  7.07it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  7.10it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  8.22it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 73.31it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 85.69it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 84.43it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 85.37it/s]saving BB  train1-THALAMUS:  15%|█▍        | 37/247 [00:00<00:02, 86.60it/s]saving BB  train1-THALAMUS:  19%|█▉        | 47/247 [00:00<00:02, 89.07it/s]saving BB  train1-THALAMUS:  23%|██▎       | 57/247 [00:00<00:02, 90.59it/s]saving BB  train1-THALAMUS:  27%|██▋       | 66/247 [00:00<00:02, 87.42it/s]saving BB  train1-THALAMUS:  30%|███       | 75/247 [00:00<00:02, 85.04it/s]saving BB  train1-THALAMUS:  34%|███▍      | 84/247 [00:00<00:01, 84.99it/s]saving BB  train1-THALAMUS:  38%|███▊      | 93/247 [00:01<00:01, 79.75it/s]saving BB  train1-THALAMUS:  41%|████      | 101/247 [00:01<00:01, 77.35it/s]saving BB  train1-THALAMUS:  44%|████▍     | 109/247 [00:01<00:01, 76.59it/s]saving BB  train1-THALAMUS:  47%|████▋     | 117/247 [00:01<00:01, 77.03it/s]saving BB  train1-THALAMUS:  51%|█████     | 125/247 [00:01<00:01, 76.23it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 133/247 [00:01<00:01, 76.38it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 142/247 [00:01<00:01, 79.90it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 152/247 [00:01<00:01, 83.82it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 162/247 [00:01<00:00, 86.69it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 172/247 [00:02<00:00, 88.83it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 181/247 [00:02<00:00, 87.43it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 190/247 [00:02<00:00, 86.29it/s]saving BB  train1-THALAMUS:  81%|████████  | 199/247 [00:02<00:00, 86.57it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 208/247 [00:02<00:00, 87.57it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 217/247 [00:02<00:00, 87.73it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 227/247 [00:02<00:00, 89.32it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 236/247 [00:02<00:00, 85.63it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 245/247 [00:02<00:00, 82.02it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:02<00:00, 84.09it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 76.56it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 87.17it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 85.20it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 84.28it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 36/247 [00:00<00:02, 85.37it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▊        | 46/247 [00:00<00:02, 87.60it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 56/247 [00:00<00:02, 90.15it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 65/247 [00:00<00:02, 87.92it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 74/247 [00:00<00:01, 86.55it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▎      | 83/247 [00:00<00:01, 85.36it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 92/247 [00:01<00:01, 84.92it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 101/247 [00:01<00:01, 84.54it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 110/247 [00:01<00:01, 81.11it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 119/247 [00:01<00:01, 80.62it/s]saving BB  train1-THALAMUS Sagittal:  52%|█████▏    | 128/247 [00:01<00:01, 79.04it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▌    | 136/247 [00:01<00:01, 78.84it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▉    | 146/247 [00:01<00:01, 82.57it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 155/247 [00:01<00:01, 83.76it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 165/247 [00:01<00:00, 86.00it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 174/247 [00:02<00:00, 83.07it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 183/247 [00:02<00:00, 80.05it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 192/247 [00:02<00:00, 79.81it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████▏ | 201/247 [00:02<00:00, 81.31it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 210/247 [00:02<00:00, 82.79it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 220/247 [00:02<00:00, 84.58it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 229/247 [00:02<00:00, 85.78it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▋| 238/247 [00:02<00:00, 82.61it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 81.15it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 83.35it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:29,  1.17it/s]Loading train:   1%|          | 2/247 [00:01<03:16,  1.25it/s]Loading train:   1%|          | 3/247 [00:02<03:09,  1.29it/s]Loading train:   2%|▏         | 4/247 [00:03<03:09,  1.29it/s]Loading train:   2%|▏         | 5/247 [00:03<02:52,  1.40it/s]Loading train:   2%|▏         | 6/247 [00:04<02:35,  1.55it/s]Loading train:   3%|▎         | 7/247 [00:04<02:25,  1.65it/s]Loading train:   3%|▎         | 8/247 [00:05<02:16,  1.75it/s]Loading train:   4%|▎         | 9/247 [00:05<02:10,  1.83it/s]Loading train:   4%|▍         | 10/247 [00:06<02:05,  1.88it/s]Loading train:   4%|▍         | 11/247 [00:06<02:05,  1.89it/s]Loading train:   5%|▍         | 12/247 [00:07<02:03,  1.91it/s]Loading train:   5%|▌         | 13/247 [00:07<02:00,  1.94it/s]Loading train:   6%|▌         | 14/247 [00:08<02:02,  1.91it/s]Loading train:   6%|▌         | 15/247 [00:08<02:01,  1.91it/s]Loading train:   6%|▋         | 16/247 [00:09<02:01,  1.90it/s]Loading train:   7%|▋         | 17/247 [00:09<02:01,  1.89it/s]Loading train:   7%|▋         | 18/247 [00:10<02:01,  1.89it/s]Loading train:   8%|▊         | 19/247 [00:10<02:00,  1.89it/s]Loading train:   8%|▊         | 20/247 [00:11<02:00,  1.88it/s]Loading train:   9%|▊         | 21/247 [00:11<01:58,  1.91it/s]Loading train:   9%|▉         | 22/247 [00:12<02:01,  1.86it/s]Loading train:   9%|▉         | 23/247 [00:12<02:00,  1.86it/s]Loading train:  10%|▉         | 24/247 [00:13<01:57,  1.90it/s]Loading train:  10%|█         | 25/247 [00:13<01:56,  1.90it/s]Loading train:  11%|█         | 26/247 [00:14<01:52,  1.97it/s]Loading train:  11%|█         | 27/247 [00:14<01:49,  2.01it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:47,  2.04it/s]Loading train:  12%|█▏        | 29/247 [00:15<01:47,  2.03it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:44,  2.07it/s]Loading train:  13%|█▎        | 31/247 [00:16<01:44,  2.07it/s]Loading train:  13%|█▎        | 32/247 [00:17<01:44,  2.06it/s]Loading train:  13%|█▎        | 33/247 [00:17<01:45,  2.04it/s]Loading train:  14%|█▍        | 34/247 [00:18<01:43,  2.06it/s]Loading train:  14%|█▍        | 35/247 [00:18<01:43,  2.05it/s]Loading train:  15%|█▍        | 36/247 [00:19<01:42,  2.05it/s]Loading train:  15%|█▍        | 37/247 [00:19<01:43,  2.04it/s]Loading train:  15%|█▌        | 38/247 [00:20<01:43,  2.02it/s]Loading train:  16%|█▌        | 39/247 [00:20<01:43,  2.01it/s]Loading train:  16%|█▌        | 40/247 [00:21<01:41,  2.04it/s]Loading train:  17%|█▋        | 41/247 [00:21<01:38,  2.09it/s]Loading train:  17%|█▋        | 42/247 [00:22<01:36,  2.13it/s]Loading train:  17%|█▋        | 43/247 [00:22<01:34,  2.17it/s]Loading train:  18%|█▊        | 44/247 [00:23<01:33,  2.17it/s]Loading train:  18%|█▊        | 45/247 [00:23<01:33,  2.16it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:33,  2.15it/s]Loading train:  19%|█▉        | 47/247 [00:24<01:31,  2.19it/s]Loading train:  19%|█▉        | 48/247 [00:24<01:30,  2.21it/s]Loading train:  20%|█▉        | 49/247 [00:25<01:29,  2.21it/s]Loading train:  20%|██        | 50/247 [00:25<01:29,  2.21it/s]Loading train:  21%|██        | 51/247 [00:26<01:27,  2.24it/s]Loading train:  21%|██        | 52/247 [00:26<01:25,  2.28it/s]Loading train:  21%|██▏       | 53/247 [00:27<01:25,  2.28it/s]Loading train:  22%|██▏       | 54/247 [00:27<01:23,  2.30it/s]Loading train:  22%|██▏       | 55/247 [00:27<01:23,  2.30it/s]Loading train:  23%|██▎       | 56/247 [00:28<01:24,  2.26it/s]Loading train:  23%|██▎       | 57/247 [00:28<01:24,  2.24it/s]Loading train:  23%|██▎       | 58/247 [00:29<01:24,  2.23it/s]Loading train:  24%|██▍       | 59/247 [00:29<01:27,  2.15it/s]Loading train:  24%|██▍       | 60/247 [00:30<01:29,  2.09it/s]Loading train:  25%|██▍       | 61/247 [00:30<01:30,  2.06it/s]Loading train:  25%|██▌       | 62/247 [00:31<01:31,  2.03it/s]Loading train:  26%|██▌       | 63/247 [00:31<01:30,  2.03it/s]Loading train:  26%|██▌       | 64/247 [00:32<01:30,  2.03it/s]Loading train:  26%|██▋       | 65/247 [00:32<01:29,  2.04it/s]Loading train:  27%|██▋       | 66/247 [00:33<01:29,  2.03it/s]Loading train:  27%|██▋       | 67/247 [00:33<01:29,  2.02it/s]Loading train:  28%|██▊       | 68/247 [00:34<01:29,  2.00it/s]Loading train:  28%|██▊       | 69/247 [00:34<01:28,  2.02it/s]Loading train:  28%|██▊       | 70/247 [00:35<01:28,  1.99it/s]Loading train:  29%|██▊       | 71/247 [00:35<01:28,  1.99it/s]Loading train:  29%|██▉       | 72/247 [00:36<01:28,  1.99it/s]Loading train:  30%|██▉       | 73/247 [00:36<01:27,  1.98it/s]Loading train:  30%|██▉       | 74/247 [00:37<01:27,  1.99it/s]Loading train:  30%|███       | 75/247 [00:37<01:27,  1.96it/s]Loading train:  31%|███       | 76/247 [00:38<01:27,  1.96it/s]Loading train:  31%|███       | 77/247 [00:39<01:41,  1.68it/s]Loading train:  32%|███▏      | 78/247 [00:40<01:57,  1.44it/s]Loading train:  32%|███▏      | 79/247 [00:40<02:00,  1.39it/s]Loading train:  32%|███▏      | 80/247 [00:41<01:56,  1.44it/s]Loading train:  33%|███▎      | 81/247 [00:42<01:57,  1.41it/s]Loading train:  33%|███▎      | 82/247 [00:42<01:47,  1.53it/s]Loading train:  34%|███▎      | 83/247 [00:43<01:40,  1.63it/s]Loading train:  34%|███▍      | 84/247 [00:43<01:35,  1.71it/s]Loading train:  34%|███▍      | 85/247 [00:44<01:30,  1.79it/s]Loading train:  35%|███▍      | 86/247 [00:44<01:29,  1.81it/s]Loading train:  35%|███▌      | 87/247 [00:45<01:27,  1.84it/s]Loading train:  36%|███▌      | 88/247 [00:45<01:25,  1.86it/s]Loading train:  36%|███▌      | 89/247 [00:46<01:23,  1.88it/s]Loading train:  36%|███▋      | 90/247 [00:46<01:21,  1.92it/s]Loading train:  37%|███▋      | 91/247 [00:47<01:21,  1.92it/s]Loading train:  37%|███▋      | 92/247 [00:47<01:20,  1.92it/s]Loading train:  38%|███▊      | 93/247 [00:48<01:19,  1.93it/s]Loading train:  38%|███▊      | 94/247 [00:48<01:19,  1.93it/s]Loading train:  38%|███▊      | 95/247 [00:49<01:19,  1.90it/s]Loading train:  39%|███▉      | 96/247 [00:50<01:18,  1.92it/s]Loading train:  39%|███▉      | 97/247 [00:50<01:18,  1.92it/s]Loading train:  40%|███▉      | 98/247 [00:51<01:18,  1.91it/s]Loading train:  40%|████      | 99/247 [00:51<01:17,  1.90it/s]Loading train:  40%|████      | 100/247 [00:52<01:19,  1.86it/s]Loading train:  41%|████      | 101/247 [00:52<01:20,  1.82it/s]Loading train:  41%|████▏     | 102/247 [00:53<01:21,  1.79it/s]Loading train:  42%|████▏     | 103/247 [00:53<01:20,  1.79it/s]Loading train:  42%|████▏     | 104/247 [00:54<01:20,  1.77it/s]Loading train:  43%|████▎     | 105/247 [00:55<01:20,  1.75it/s]Loading train:  43%|████▎     | 106/247 [00:55<01:21,  1.74it/s]Loading train:  43%|████▎     | 107/247 [00:56<01:20,  1.74it/s]Loading train:  44%|████▎     | 108/247 [00:56<01:19,  1.74it/s]Loading train:  44%|████▍     | 109/247 [00:57<01:18,  1.76it/s]Loading train:  45%|████▍     | 110/247 [00:57<01:17,  1.77it/s]Loading train:  45%|████▍     | 111/247 [00:58<01:16,  1.77it/s]Loading train:  45%|████▌     | 112/247 [00:59<01:16,  1.76it/s]Loading train:  46%|████▌     | 113/247 [00:59<01:15,  1.77it/s]Loading train:  46%|████▌     | 114/247 [01:00<01:14,  1.78it/s]Loading train:  47%|████▋     | 115/247 [01:00<01:14,  1.77it/s]Loading train:  47%|████▋     | 116/247 [01:01<01:13,  1.77it/s]Loading train:  47%|████▋     | 117/247 [01:01<01:13,  1.77it/s]Loading train:  48%|████▊     | 118/247 [01:02<01:11,  1.80it/s]Loading train:  48%|████▊     | 119/247 [01:02<01:09,  1.85it/s]Loading train:  49%|████▊     | 120/247 [01:03<01:07,  1.89it/s]Loading train:  49%|████▉     | 121/247 [01:03<01:06,  1.89it/s]Loading train:  49%|████▉     | 122/247 [01:04<01:06,  1.89it/s]Loading train:  50%|████▉     | 123/247 [01:04<01:05,  1.90it/s]Loading train:  50%|█████     | 124/247 [01:05<01:04,  1.90it/s]Loading train:  51%|█████     | 125/247 [01:05<01:03,  1.92it/s]Loading train:  51%|█████     | 126/247 [01:06<01:03,  1.91it/s]Loading train:  51%|█████▏    | 127/247 [01:07<01:03,  1.89it/s]Loading train:  52%|█████▏    | 128/247 [01:07<01:02,  1.90it/s]Loading train:  52%|█████▏    | 129/247 [01:08<01:02,  1.90it/s]Loading train:  53%|█████▎    | 130/247 [01:08<01:01,  1.90it/s]Loading train:  53%|█████▎    | 131/247 [01:09<01:00,  1.92it/s]Loading train:  53%|█████▎    | 132/247 [01:09<00:59,  1.94it/s]Loading train:  54%|█████▍    | 133/247 [01:10<00:59,  1.93it/s]Loading train:  54%|█████▍    | 134/247 [01:10<00:58,  1.94it/s]Loading train:  55%|█████▍    | 135/247 [01:11<00:57,  1.95it/s]Loading train:  55%|█████▌    | 136/247 [01:11<00:55,  1.98it/s]Loading train:  55%|█████▌    | 137/247 [01:12<00:53,  2.06it/s]Loading train:  56%|█████▌    | 138/247 [01:12<00:51,  2.11it/s]Loading train:  56%|█████▋    | 139/247 [01:13<00:50,  2.15it/s]Loading train:  57%|█████▋    | 140/247 [01:13<00:49,  2.15it/s]Loading train:  57%|█████▋    | 141/247 [01:13<00:48,  2.18it/s]Loading train:  57%|█████▋    | 142/247 [01:14<00:47,  2.22it/s]Loading train:  58%|█████▊    | 143/247 [01:14<00:46,  2.23it/s]Loading train:  58%|█████▊    | 144/247 [01:15<00:46,  2.22it/s]Loading train:  59%|█████▊    | 145/247 [01:15<00:45,  2.23it/s]Loading train:  59%|█████▉    | 146/247 [01:16<00:45,  2.23it/s]Loading train:  60%|█████▉    | 147/247 [01:16<00:45,  2.21it/s]Loading train:  60%|█████▉    | 148/247 [01:17<00:44,  2.22it/s]Loading train:  60%|██████    | 149/247 [01:17<00:44,  2.23it/s]Loading train:  61%|██████    | 150/247 [01:17<00:43,  2.22it/s]Loading train:  61%|██████    | 151/247 [01:18<00:43,  2.20it/s]Loading train:  62%|██████▏   | 152/247 [01:18<00:43,  2.20it/s]Loading train:  62%|██████▏   | 153/247 [01:19<00:42,  2.19it/s]Loading train:  62%|██████▏   | 154/247 [01:19<00:43,  2.13it/s]Loading train:  63%|██████▎   | 155/247 [01:20<00:43,  2.12it/s]Loading train:  63%|██████▎   | 156/247 [01:20<00:43,  2.10it/s]Loading train:  64%|██████▎   | 157/247 [01:21<00:42,  2.10it/s]Loading train:  64%|██████▍   | 158/247 [01:21<00:42,  2.09it/s]Loading train:  64%|██████▍   | 159/247 [01:22<00:41,  2.12it/s]Loading train:  65%|██████▍   | 160/247 [01:22<00:41,  2.09it/s]Loading train:  65%|██████▌   | 161/247 [01:23<00:41,  2.08it/s]Loading train:  66%|██████▌   | 162/247 [01:23<00:40,  2.10it/s]Loading train:  66%|██████▌   | 163/247 [01:24<00:40,  2.10it/s]Loading train:  66%|██████▋   | 164/247 [01:24<00:40,  2.04it/s]Loading train:  67%|██████▋   | 165/247 [01:25<00:39,  2.07it/s]Loading train:  67%|██████▋   | 166/247 [01:25<00:38,  2.08it/s]Loading train:  68%|██████▊   | 167/247 [01:26<00:38,  2.10it/s]Loading train:  68%|██████▊   | 168/247 [01:26<00:38,  2.03it/s]Loading train:  68%|██████▊   | 169/247 [01:27<00:37,  2.07it/s]Loading train:  69%|██████▉   | 170/247 [01:27<00:37,  2.06it/s]Loading train:  69%|██████▉   | 171/247 [01:28<00:37,  2.04it/s]Loading train:  70%|██████▉   | 172/247 [01:28<00:43,  1.71it/s]Loading train:  70%|███████   | 173/247 [01:29<00:45,  1.62it/s]Loading train:  70%|███████   | 174/247 [01:30<00:47,  1.55it/s]Loading train:  71%|███████   | 175/247 [01:31<00:51,  1.40it/s]Loading train:  71%|███████▏  | 176/247 [01:31<00:46,  1.52it/s]Loading train:  72%|███████▏  | 177/247 [01:32<00:43,  1.62it/s]Loading train:  72%|███████▏  | 178/247 [01:32<00:40,  1.70it/s]Loading train:  72%|███████▏  | 179/247 [01:33<00:38,  1.76it/s]Loading train:  73%|███████▎  | 180/247 [01:33<00:36,  1.81it/s]Loading train:  73%|███████▎  | 181/247 [01:34<00:36,  1.83it/s]Loading train:  74%|███████▎  | 182/247 [01:34<00:34,  1.86it/s]Loading train:  74%|███████▍  | 183/247 [01:35<00:33,  1.90it/s]Loading train:  74%|███████▍  | 184/247 [01:35<00:33,  1.89it/s]Loading train:  75%|███████▍  | 185/247 [01:36<00:32,  1.92it/s]Loading train:  75%|███████▌  | 186/247 [01:36<00:31,  1.91it/s]Loading train:  76%|███████▌  | 187/247 [01:37<00:31,  1.92it/s]Loading train:  76%|███████▌  | 188/247 [01:37<00:30,  1.94it/s]Loading train:  77%|███████▋  | 189/247 [01:38<00:29,  1.96it/s]Loading train:  77%|███████▋  | 190/247 [01:38<00:28,  1.97it/s]Loading train:  77%|███████▋  | 191/247 [01:39<00:28,  1.95it/s]Loading train:  78%|███████▊  | 192/247 [01:39<00:28,  1.95it/s]Loading train:  78%|███████▊  | 193/247 [01:40<00:27,  1.94it/s]Loading train:  79%|███████▊  | 194/247 [01:40<00:26,  2.02it/s]Loading train:  79%|███████▉  | 195/247 [01:41<00:24,  2.08it/s]Loading train:  79%|███████▉  | 196/247 [01:41<00:23,  2.14it/s]Loading train:  80%|███████▉  | 197/247 [01:42<00:23,  2.17it/s]Loading train:  80%|████████  | 198/247 [01:42<00:22,  2.21it/s]Loading train:  81%|████████  | 199/247 [01:43<00:21,  2.21it/s]Loading train:  81%|████████  | 200/247 [01:43<00:21,  2.22it/s]Loading train:  81%|████████▏ | 201/247 [01:43<00:20,  2.21it/s]Loading train:  82%|████████▏ | 202/247 [01:44<00:20,  2.20it/s]Loading train:  82%|████████▏ | 203/247 [01:44<00:20,  2.19it/s]Loading train:  83%|████████▎ | 204/247 [01:45<00:19,  2.18it/s]Loading train:  83%|████████▎ | 205/247 [01:45<00:19,  2.14it/s]Loading train:  83%|████████▎ | 206/247 [01:46<00:19,  2.10it/s]Loading train:  84%|████████▍ | 207/247 [01:46<00:18,  2.11it/s]Loading train:  84%|████████▍ | 208/247 [01:47<00:18,  2.10it/s]Loading train:  85%|████████▍ | 209/247 [01:47<00:17,  2.12it/s]Loading train:  85%|████████▌ | 210/247 [01:48<00:17,  2.15it/s]Loading train:  85%|████████▌ | 211/247 [01:48<00:17,  2.10it/s]Loading train:  86%|████████▌ | 212/247 [01:49<00:16,  2.09it/s]Loading train:  86%|████████▌ | 213/247 [01:49<00:16,  2.10it/s]Loading train:  87%|████████▋ | 214/247 [01:50<00:15,  2.10it/s]Loading train:  87%|████████▋ | 215/247 [01:50<00:14,  2.14it/s]Loading train:  87%|████████▋ | 216/247 [01:51<00:14,  2.12it/s]Loading train:  88%|████████▊ | 217/247 [01:51<00:13,  2.14it/s]Loading train:  88%|████████▊ | 218/247 [01:52<00:20,  1.45it/s]Loading train:  89%|████████▊ | 219/247 [01:55<00:36,  1.30s/it]Loading train:  89%|████████▉ | 220/247 [01:59<00:59,  2.22s/it]Loading train:  89%|████████▉ | 221/247 [02:03<01:12,  2.78s/it]Loading train:  90%|████████▉ | 222/247 [02:07<01:16,  3.06s/it]Loading train:  90%|█████████ | 223/247 [02:11<01:18,  3.25s/it]Loading train:  91%|█████████ | 224/247 [02:14<01:15,  3.27s/it]Loading train:  91%|█████████ | 225/247 [02:18<01:14,  3.37s/it]Loading train:  91%|█████████▏| 226/247 [02:21<01:12,  3.43s/it]Loading train:  92%|█████████▏| 227/247 [02:25<01:08,  3.41s/it]Loading train:  92%|█████████▏| 228/247 [02:28<01:04,  3.40s/it]Loading train:  93%|█████████▎| 229/247 [02:31<01:00,  3.36s/it]Loading train:  93%|█████████▎| 230/247 [02:36<01:03,  3.76s/it]Loading train:  94%|█████████▎| 231/247 [02:41<01:05,  4.08s/it]Loading train:  94%|█████████▍| 232/247 [02:46<01:04,  4.32s/it]Loading train:  94%|█████████▍| 233/247 [02:51<01:02,  4.48s/it]Loading train:  95%|█████████▍| 234/247 [02:55<00:58,  4.49s/it]Loading train:  95%|█████████▌| 235/247 [02:59<00:52,  4.34s/it]Loading train:  96%|█████████▌| 236/247 [03:03<00:45,  4.17s/it]Loading train:  96%|█████████▌| 237/247 [03:06<00:39,  3.91s/it]Loading train:  96%|█████████▋| 238/247 [03:09<00:33,  3.71s/it]Loading train:  97%|█████████▋| 239/247 [03:13<00:28,  3.59s/it]Loading train:  97%|█████████▋| 240/247 [03:16<00:25,  3.59s/it]Loading train:  98%|█████████▊| 241/247 [03:20<00:20,  3.50s/it]Loading train:  98%|█████████▊| 242/247 [03:23<00:17,  3.42s/it]Loading train:  98%|█████████▊| 243/247 [03:27<00:15,  3.79s/it]Loading train:  99%|█████████▉| 244/247 [03:31<00:10,  3.60s/it]Loading train:  99%|█████████▉| 245/247 [03:31<00:05,  2.70s/it]Loading train: 100%|█████████▉| 246/247 [03:32<00:02,  2.08s/it]Loading train: 100%|██████████| 247/247 [03:32<00:00,  1.63s/it]Loading train: 100%|██████████| 247/247 [03:32<00:00,  1.16it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/247 [00:00<00:04, 59.12it/s]concatenating: train:   5%|▌         | 13/247 [00:00<00:03, 58.53it/s]concatenating: train:   8%|▊         | 19/247 [00:00<00:03, 57.29it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:03, 56.93it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:03, 57.31it/s]concatenating: train:  15%|█▌        | 38/247 [00:00<00:03, 58.21it/s]concatenating: train:  18%|█▊        | 44/247 [00:00<00:03, 57.78it/s]concatenating: train:  20%|██        | 50/247 [00:00<00:03, 57.78it/s]concatenating: train:  23%|██▎       | 57/247 [00:00<00:03, 60.41it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:02, 61.86it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:02, 63.05it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:02, 62.65it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:02, 62.10it/s]concatenating: train:  37%|███▋      | 92/247 [00:01<00:02, 62.33it/s]concatenating: train:  40%|████      | 99/247 [00:01<00:02, 62.49it/s]concatenating: train:  43%|████▎     | 106/247 [00:01<00:02, 60.85it/s]concatenating: train:  46%|████▌     | 113/247 [00:01<00:02, 59.21it/s]concatenating: train:  49%|████▊     | 120/247 [00:01<00:02, 60.95it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:01, 62.99it/s]concatenating: train:  54%|█████▍    | 134/247 [00:02<00:01, 64.21it/s]concatenating: train:  57%|█████▋    | 141/247 [00:02<00:01, 65.52it/s]concatenating: train:  60%|█████▉    | 148/247 [00:02<00:01, 66.15it/s]concatenating: train:  63%|██████▎   | 156/247 [00:02<00:01, 66.99it/s]concatenating: train:  66%|██████▌   | 163/247 [00:02<00:01, 66.74it/s]concatenating: train:  69%|██████▉   | 171/247 [00:02<00:01, 67.88it/s]concatenating: train:  72%|███████▏  | 178/247 [00:02<00:01, 66.05it/s]concatenating: train:  75%|███████▍  | 185/247 [00:02<00:00, 62.42it/s]concatenating: train:  78%|███████▊  | 192/247 [00:03<00:00, 61.32it/s]concatenating: train:  81%|████████  | 199/247 [00:03<00:00, 61.94it/s]concatenating: train:  83%|████████▎ | 206/247 [00:03<00:00, 61.32it/s]concatenating: train:  86%|████████▌ | 213/247 [00:03<00:00, 58.49it/s]concatenating: train:  89%|████████▊ | 219/247 [00:03<00:00, 57.52it/s]concatenating: train:  91%|█████████ | 225/247 [00:03<00:00, 56.64it/s]concatenating: train:  94%|█████████▎| 231/247 [00:03<00:00, 53.34it/s]concatenating: train:  96%|█████████▌| 237/247 [00:03<00:00, 50.43it/s]concatenating: train:  98%|█████████▊| 243/247 [00:04<00:00, 48.84it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 59.77it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:09<00:38,  9.54s/it]Loading test:  40%|████      | 2/5 [00:18<00:27,  9.30s/it]Loading test:  60%|██████    | 3/5 [00:24<00:16,  8.46s/it]Loading test:  80%|████████  | 4/5 [00:30<00:07,  7.50s/it]Loading test: 100%|██████████| 5/5 [00:38<00:00,  7.91s/it]Loading test: 100%|██████████| 5/5 [00:38<00:00,  7.78s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 57.13it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-21 22:15:19.883556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 22:15:19.883636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 22:15:19.883651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 22:15:19.883660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 22:15:19.883965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.23303687e-02 3.14394979e-02 7.86830490e-02 9.58351009e-03
 2.85559488e-02 7.22734349e-03 8.59702358e-02 1.15117352e-01
 9.00463914e-02 1.30602545e-02 2.93983225e-01 1.83755224e-01
 2.47600815e-04]
Train on 9035 samples, validate on 178 samples
Epoch 1/300
 - 23s - loss: 0.6285 - acc: 0.9074 - mDice: 0.3229 - val_loss: 0.3111 - val_acc: 0.9196 - val_mDice: 0.2749

Epoch 00001: val_mDice improved from -inf to 0.27493, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 19s - loss: 0.5282 - acc: 0.9238 - mDice: 0.4309 - val_loss: 0.3284 - val_acc: 0.9213 - val_mDice: 0.2910

Epoch 00002: val_mDice improved from 0.27493 to 0.29096, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 0.4952 - acc: 0.9293 - mDice: 0.4665 - val_loss: 0.2014 - val_acc: 0.9357 - val_mDice: 0.3126

Epoch 00003: val_mDice improved from 0.29096 to 0.31265, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 19s - loss: 0.4807 - acc: 0.9321 - mDice: 0.4820 - val_loss: 0.2106 - val_acc: 0.9252 - val_mDice: 0.3031

Epoch 00004: val_mDice did not improve from 0.31265
Epoch 5/300
 - 18s - loss: 0.4668 - acc: 0.9342 - mDice: 0.4970 - val_loss: 0.2228 - val_acc: 0.9299 - val_mDice: 0.3041

Epoch 00005: val_mDice did not improve from 0.31265
Epoch 6/300
 - 18s - loss: 0.4502 - acc: 0.9352 - mDice: 0.5148 - val_loss: 0.2020 - val_acc: 0.9397 - val_mDice: 0.3305

Epoch 00006: val_mDice improved from 0.31265 to 0.33055, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 18s - loss: 0.4263 - acc: 0.9370 - mDice: 0.5407 - val_loss: 0.1808 - val_acc: 0.9395 - val_mDice: 0.3342

Epoch 00007: val_mDice improved from 0.33055 to 0.33417, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 0.4181 - acc: 0.9379 - mDice: 0.5496 - val_loss: 0.2106 - val_acc: 0.9323 - val_mDice: 0.3291

Epoch 00008: val_mDice did not improve from 0.33417
Epoch 9/300
 - 19s - loss: 0.4090 - acc: 0.9390 - mDice: 0.5594 - val_loss: 0.1476 - val_acc: 0.9438 - val_mDice: 0.3371

Epoch 00009: val_mDice improved from 0.33417 to 0.33713, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 20s - loss: 0.4071 - acc: 0.9394 - mDice: 0.5611 - val_loss: 0.2592 - val_acc: 0.9304 - val_mDice: 0.3195

Epoch 00010: val_mDice did not improve from 0.33713
Epoch 11/300
 - 20s - loss: 0.4045 - acc: 0.9390 - mDice: 0.5623 - val_loss: 0.2603 - val_acc: 0.9314 - val_mDice: 0.3311

Epoch 00011: val_mDice did not improve from 0.33713
Epoch 12/300
 - 19s - loss: 0.4119 - acc: 0.9381 - mDice: 0.5522 - val_loss: 0.1835 - val_acc: 0.9404 - val_mDice: 0.3406

Epoch 00012: val_mDice improved from 0.33713 to 0.34063, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 13/300
 - 19s - loss: 0.4000 - acc: 0.9391 - mDice: 0.5626 - val_loss: 0.1600 - val_acc: 0.9349 - val_mDice: 0.3190

Epoch 00013: val_mDice did not improve from 0.34063
Epoch 14/300
 - 19s - loss: 0.4141 - acc: 0.9364 - mDice: 0.5443 - val_loss: 0.1931 - val_acc: 0.9369 - val_mDice: 0.3219

Epoch 00014: val_mDice did not improve from 0.34063
Epoch 15/300
 - 19s - loss: 0.3937 - acc: 0.9396 - mDice: 0.5660 - val_loss: 0.1535 - val_acc: 0.9397 - val_mDice: 0.3362

Epoch 00015: val_mDice did not improve from 0.34063
Epoch 16/300
 - 19s - loss: 0.3859 - acc: 0.9409 - mDice: 0.5745 - val_loss: 0.2139 - val_acc: 0.9360 - val_mDice: 0.3365

Epoch 00016: val_mDice did not improve from 0.34063
Epoch 17/300
 - 20s - loss: 0.4173 - acc: 0.9361 - mDice: 0.5386 - val_loss: 0.1505 - val_acc: 0.9410 - val_mDice: 0.3301

Epoch 00017: val_mDice did not improve from 0.34063
Epoch 18/300
 - 20s - loss: 0.3948 - acc: 0.9388 - mDice: 0.5622 - val_loss: 0.2297 - val_acc: 0.9339 - val_mDice: 0.3268

Epoch 00018: val_mDice did not improve from 0.34063
Epoch 19/300
 - 20s - loss: 0.3862 - acc: 0.9397 - mDice: 0.5718 - val_loss: 0.2203 - val_acc: 0.9356 - val_mDice: 0.3367

Epoch 00019: val_mDice did not improve from 0.34063
Epoch 20/300
 - 20s - loss: 0.3911 - acc: 0.9391 - mDice: 0.5670 - val_loss: 0.2345 - val_acc: 0.9363 - val_mDice: 0.3322

Epoch 00020: val_mDice did not improve from 0.34063
Epoch 21/300
 - 20s - loss: 0.3783 - acc: 0.9422 - mDice: 0.5821 - val_loss: 0.1419 - val_acc: 0.9425 - val_mDice: 0.3333

Epoch 00021: val_mDice did not improve from 0.34063
Epoch 22/300
 - 20s - loss: 0.3788 - acc: 0.9414 - mDice: 0.5777 - val_loss: 0.1512 - val_acc: 0.9373 - val_mDice: 0.3387

Epoch 00022: val_mDice did not improve from 0.34063
Epoch 23/300
 - 19s - loss: 0.3725 - acc: 0.9430 - mDice: 0.5861 - val_loss: 0.1534 - val_acc: 0.9415 - val_mDice: 0.3380

Epoch 00023: val_mDice did not improve from 0.34063
Epoch 24/300
 - 19s - loss: 0.3705 - acc: 0.9427 - mDice: 0.5859 - val_loss: 0.2563 - val_acc: 0.9297 - val_mDice: 0.3246

Epoch 00024: val_mDice did not improve from 0.34063
Epoch 25/300
 - 20s - loss: 0.3727 - acc: 0.9428 - mDice: 0.5828 - val_loss: 0.1892 - val_acc: 0.9418 - val_mDice: 0.3236

Epoch 00025: val_mDice did not improve from 0.34063
Epoch 26/300
 - 19s - loss: 0.3711 - acc: 0.9427 - mDice: 0.5846 - val_loss: 0.1266 - val_acc: 0.9446 - val_mDice: 0.3378

Epoch 00026: val_mDice did not improve from 0.34063
Epoch 27/300
 - 18s - loss: 0.3651 - acc: 0.9437 - mDice: 0.5937 - val_loss: 0.1974 - val_acc: 0.9377 - val_mDice: 0.3358

Epoch 00027: val_mDice did not improve from 0.34063

Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 28/300
 - 18s - loss: 0.3594 - acc: 0.9444 - mDice: 0.5986 - val_loss: 0.1508 - val_acc: 0.9370 - val_mDice: 0.3122

Epoch 00028: val_mDice did not improve from 0.34063
Epoch 29/300
 - 18s - loss: 0.3528 - acc: 0.9453 - mDice: 0.6041 - val_loss: 0.1665 - val_acc: 0.9402 - val_mDice: 0.3399

Epoch 00029: val_mDice did not improve from 0.34063
Epoch 30/300
 - 18s - loss: 0.3553 - acc: 0.9449 - mDice: 0.6015 - val_loss: 0.1812 - val_acc: 0.9310 - val_mDice: 0.3132

Epoch 00030: val_mDice did not improve from 0.34063
Epoch 31/300
 - 18s - loss: 0.3530 - acc: 0.9449 - mDice: 0.6047 - val_loss: 0.1790 - val_acc: 0.9412 - val_mDice: 0.3464

Epoch 00031: val_mDice improved from 0.34063 to 0.34636, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 19s - loss: 0.3513 - acc: 0.9455 - mDice: 0.6058 - val_loss: 0.1502 - val_acc: 0.9393 - val_mDice: 0.3399

Epoch 00032: val_mDice did not improve from 0.34636
Epoch 33/300
 - 19s - loss: 0.3490 - acc: 0.9460 - mDice: 0.6091 - val_loss: 0.1392 - val_acc: 0.9367 - val_mDice: 0.3347

Epoch 00033: val_mDice did not improve from 0.34636
Epoch 34/300
 - 19s - loss: 0.3521 - acc: 0.9457 - mDice: 0.6062 - val_loss: 0.1332 - val_acc: 0.9429 - val_mDice: 0.3476

Epoch 00034: val_mDice improved from 0.34636 to 0.34757, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 35/300
 - 18s - loss: 0.3524 - acc: 0.9455 - mDice: 0.6055 - val_loss: 0.1313 - val_acc: 0.9421 - val_mDice: 0.3421

Epoch 00035: val_mDice did not improve from 0.34757
Epoch 36/300
 - 18s - loss: 0.3491 - acc: 0.9461 - mDice: 0.6107 - val_loss: 0.1540 - val_acc: 0.9397 - val_mDice: 0.3337

Epoch 00036: val_mDice did not improve from 0.34757
Epoch 37/300
 - 19s - loss: 0.3440 - acc: 0.9465 - mDice: 0.6145 - val_loss: 0.2116 - val_acc: 0.9372 - val_mDice: 0.3366

Epoch 00037: val_mDice did not improve from 0.34757
Epoch 38/300
 - 18s - loss: 0.3484 - acc: 0.9460 - mDice: 0.6109 - val_loss: 0.1534 - val_acc: 0.9444 - val_mDice: 0.3455

Epoch 00038: val_mDice did not improve from 0.34757
Epoch 39/300
 - 18s - loss: 0.3463 - acc: 0.9463 - mDice: 0.6122 - val_loss: 0.1470 - val_acc: 0.9436 - val_mDice: 0.3417

Epoch 00039: val_mDice did not improve from 0.34757
Epoch 40/300
 - 18s - loss: 0.3448 - acc: 0.9466 - mDice: 0.6158 - val_loss: 0.1677 - val_acc: 0.9419 - val_mDice: 0.3448

Epoch 00040: val_mDice did not improve from 0.34757
Epoch 41/300
 - 18s - loss: 0.3436 - acc: 0.9464 - mDice: 0.6157 - val_loss: 0.1606 - val_acc: 0.9408 - val_mDice: 0.3472

Epoch 00041: val_mDice did not improve from 0.34757
Epoch 42/300
 - 18s - loss: 0.3430 - acc: 0.9470 - mDice: 0.6180 - val_loss: 0.1448 - val_acc: 0.9446 - val_mDice: 0.3456

Epoch 00042: val_mDice did not improve from 0.34757
Epoch 43/300
 - 18s - loss: 0.3403 - acc: 0.9469 - mDice: 0.6184 - val_loss: 0.1675 - val_acc: 0.9407 - val_mDice: 0.3408

Epoch 00043: val_mDice did not improve from 0.34757
Epoch 44/300
 - 18s - loss: 0.3401 - acc: 0.9473 - mDice: 0.6173 - val_loss: 0.1316 - val_acc: 0.9455 - val_mDice: 0.3409

Epoch 00044: val_mDice did not improve from 0.34757
Epoch 45/300
 - 18s - loss: 0.3405 - acc: 0.9473 - mDice: 0.6191 - val_loss: 0.1368 - val_acc: 0.9434 - val_mDice: 0.3354

Epoch 00045: val_mDice did not improve from 0.34757
Epoch 46/300
 - 18s - loss: 0.3378 - acc: 0.9474 - mDice: 0.6218 - val_loss: 0.2097 - val_acc: 0.9344 - val_mDice: 0.3298

Epoch 00046: val_mDice did not improve from 0.34757
Epoch 47/300
 - 18s - loss: 0.3356 - acc: 0.9474 - mDice: 0.6230 - val_loss: 0.1874 - val_acc: 0.9380 - val_mDice: 0.3429

Epoch 00047: val_mDice did not improve from 0.34757
Epoch 48/300
 - 18s - loss: 0.3394 - acc: 0.9468 - mDice: 0.6178 - val_loss: 0.1551 - val_acc: 0.9418 - val_mDice: 0.3343

Epoch 00048: val_mDice did not improve from 0.34757
Epoch 49/300
 - 18s - loss: 0.3373 - acc: 0.9475 - mDice: 0.6230 - val_loss: 0.2011 - val_acc: 0.9347 - val_mDice: 0.3293

Epoch 00049: val_mDice did not improve from 0.34757

Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 50/300
 - 18s - loss: 0.3322 - acc: 0.9480 - mDice: 0.6262 - val_loss: 0.1641 - val_acc: 0.9394 - val_mDice: 0.3414

Epoch 00050: val_mDice did not improve from 0.34757
Epoch 51/300
 - 19s - loss: 0.3283 - acc: 0.9480 - mDice: 0.6305 - val_loss: 0.1407 - val_acc: 0.9372 - val_mDice: 0.3408

Epoch 00051: val_mDice did not improve from 0.34757
Epoch 52/300
 - 18s - loss: 0.3295 - acc: 0.9483 - mDice: 0.6295 - val_loss: 0.1574 - val_acc: 0.9408 - val_mDice: 0.3320

Epoch 00052: val_mDice did not improve from 0.34757
Epoch 53/300
 - 18s - loss: 0.3305 - acc: 0.9481 - mDice: 0.6299 - val_loss: 0.1533 - val_acc: 0.9453 - val_mDice: 0.3334

Epoch 00053: val_mDice did not improve from 0.34757
Epoch 54/300
 - 18s - loss: 0.3385 - acc: 0.9475 - mDice: 0.6225 - val_loss: 0.1456 - val_acc: 0.9417 - val_mDice: 0.3356

Epoch 00054: val_mDice did not improve from 0.34757
Epoch 55/300
 - 18s - loss: 0.3296 - acc: 0.9483 - mDice: 0.6293 - val_loss: 0.1245 - val_acc: 0.9428 - val_mDice: 0.3382

Epoch 00055: val_mDice did not improve from 0.34757
Epoch 56/300
 - 18s - loss: 0.3310 - acc: 0.9483 - mDice: 0.6307 - val_loss: 0.1429 - val_acc: 0.9415 - val_mDice: 0.3369

Epoch 00056: val_mDice did not improve from 0.34757
Epoch 57/300
 - 18s - loss: 0.3258 - acc: 0.9486 - mDice: 0.6324 - val_loss: 0.1456 - val_acc: 0.9410 - val_mDice: 0.3353

Epoch 00057: val_mDice did not improve from 0.34757
Epoch 58/300
 - 18s - loss: 0.3277 - acc: 0.9486 - mDice: 0.6320 - val_loss: 0.1655 - val_acc: 0.9403 - val_mDice: 0.3404

Epoch 00058: val_mDice did not improve from 0.34757
Epoch 59/300
 - 18s - loss: 0.3242 - acc: 0.9487 - mDice: 0.6344 - val_loss: 0.1495 - val_acc: 0.9404 - val_mDice: 0.3311

Epoch 00059: val_mDice did not improve from 0.34757
Epoch 60/300
 - 18s - loss: 0.3224 - acc: 0.9487 - mDice: 0.6353 - val_loss: 0.1256 - val_acc: 0.9413 - val_mDice: 0.3383

Epoch 00060: val_mDice did not improve from 0.34757
Epoch 61/300
 - 18s - loss: 0.3246 - acc: 0.9489 - mDice: 0.6363 - val_loss: 0.1446 - val_acc: 0.9445 - val_mDice: 0.3443

Epoch 00061: val_mDice did not improve from 0.34757
Epoch 62/300
 - 18s - loss: 0.3283 - acc: 0.9489 - mDice: 0.6323 - val_loss: 0.1307 - val_acc: 0.9454 - val_mDice: 0.3429

Epoch 00062: val_mDice did not improve from 0.34757
Epoch 63/300
 - 18s - loss: 0.3234 - acc: 0.9490 - mDice: 0.6356 - val_loss: 0.1879 - val_acc: 0.9363 - val_mDice: 0.3366

Epoch 00063: val_mDice did not improve from 0.34757
Epoch 64/300
 - 18s - loss: 0.3209 - acc: 0.9489 - mDice: 0.6380 - val_loss: 0.1889 - val_acc: 0.9428 - val_mDice: 0.3446

Epoch 00064: val_mDice did not improve from 0.34757

Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 65/300
 - 18s - loss: 0.3227 - acc: 0.9492 - mDice: 0.6373 - val_loss: 0.1533 - val_acc: 0.9439 - val_mDice: 0.3426

Epoch 00065: val_mDice did not improve from 0.34757
Epoch 66/300
 - 18s - loss: 0.3204 - acc: 0.9493 - mDice: 0.6389 - val_loss: 0.1570 - val_acc: 0.9428 - val_mDice: 0.3423

Epoch 00066: val_mDice did not improve from 0.34757
Epoch 67/300
 - 18s - loss: 0.3201 - acc: 0.9493 - mDice: 0.6402 - val_loss: 0.1383 - val_acc: 0.9400 - val_mDice: 0.3433

Epoch 00067: val_mDice did not improve from 0.34757
Epoch 68/300
 - 18s - loss: 0.3205 - acc: 0.9493 - mDice: 0.6390 - val_loss: 0.1318 - val_acc: 0.9413 - val_mDice: 0.3428

Epoch 00068: val_mDice did not improve from 0.34757
Epoch 69/300
 - 18s - loss: 0.3209 - acc: 0.9494 - mDice: 0.6399 - val_loss: 0.1329 - val_acc: 0.9419 - val_mDice: 0.3414

Epoch 00069: val_mDice did not improve from 0.34757
Epoch 70/300
 - 18s - loss: 0.3222 - acc: 0.9492 - mDice: 0.6373 - val_loss: 0.1403 - val_acc: 0.9429 - val_mDice: 0.3410

Epoch 00070: val_mDice did not improve from 0.34757
Epoch 71/300
 - 19s - loss: 0.3189 - acc: 0.9496 - mDice: 0.6424 - val_loss: 0.1321 - val_acc: 0.9440 - val_mDice: 0.3405

Epoch 00071: val_mDice did not improve from 0.34757
Epoch 72/300
 - 18s - loss: 0.3199 - acc: 0.9496 - mDice: 0.6398 - val_loss: 0.1295 - val_acc: 0.9428 - val_mDice: 0.3416

Epoch 00072: val_mDice did not improve from 0.34757
Epoch 73/300
 - 19s - loss: 0.3180 - acc: 0.9497 - mDice: 0.6427 - val_loss: 0.1218 - val_acc: 0.9450 - val_mDice: 0.3413

Epoch 00073: val_mDice did not improve from 0.34757
Epoch 74/300
 - 19s - loss: 0.3175 - acc: 0.9496 - mDice: 0.6421 - val_loss: 0.1377 - val_acc: 0.9434 - val_mDice: 0.3440

Epoch 00074: val_mDice did not improve from 0.34757
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
{'val_loss': [0.3111492851225848, 0.3283602302747496, 0.20136204437258537, 0.2105513365986349, 0.22279825151552646, 0.2019843996366423, 0.18084453569536799, 0.21060969586369027, 0.1476276551969768, 0.2592405624101671, 0.2602730245653833, 0.18346571997645195, 0.15995158085578612, 0.19310725649839708, 0.1535277772234397, 0.21388045865833089, 0.15045554647117518, 0.22965592972599388, 0.2203247316935089, 0.2345425376375572, 0.1419396638828382, 0.15121011546907132, 0.1534337414365806, 0.25626226960356985, 0.18923644639886497, 0.12663023793295528, 0.19738444321778384, 0.15082619704431696, 0.16647143959161942, 0.18116969232227695, 0.17896841194355087, 0.15023758990711042, 0.13918018181745506, 0.13322421137356, 0.13129520464918754, 0.15398953731558965, 0.21159751805361737, 0.15339248567777738, 0.14699206573449158, 0.16773631646601336, 0.16064905632663978, 0.1448410108392493, 0.167538071927625, 0.131646656790968, 0.13683681622189417, 0.20967977372615526, 0.18743734848633242, 0.15509452524312425, 0.20105309390954756, 0.16412076731787972, 0.14070186395658535, 0.15736833034773892, 0.15328422634276362, 0.1455580001655087, 0.12447087024076936, 0.1428904618460978, 0.1456064588568184, 0.16550199583361155, 0.1494513596721998, 0.12557293305152586, 0.14463581651281776, 0.13074903922636857, 0.18791819916347438, 0.1888970813787218, 0.15328177125350143, 0.1569932850307963, 0.13831467273529996, 0.1318399366619212, 0.13292331464086357, 0.14028436825558377, 0.13208372462959436, 0.1295339371381181, 0.12178240374274803, 0.13772795826531528], 'val_acc': [0.919557969221908, 0.9212634275468548, 0.9356530569912342, 0.9251502196440536, 0.9298936088433426, 0.9396877583493007, 0.9394716968697109, 0.932307749651791, 0.9438279411765966, 0.9303784986560264, 0.9313546968310067, 0.9404298890842481, 0.934896798616045, 0.9369147935610139, 0.9397199160597297, 0.9359810338931137, 0.9410305237502194, 0.9338897372899431, 0.9356067622645518, 0.9362858627619368, 0.942500614718105, 0.9373392375667443, 0.9414523853344864, 0.9297212603386869, 0.9418022297741322, 0.944631796204642, 0.9377327976601847, 0.937002255675498, 0.9401700818136837, 0.9309829948993211, 0.9412376003318959, 0.9393482228343406, 0.9366549903087402, 0.9429379072082177, 0.9420568849263566, 0.9397469330369757, 0.9372299072447787, 0.9444041399473555, 0.9436157185040163, 0.9419205563791683, 0.9407591464814176, 0.9445700578475267, 0.9407398473010974, 0.94554112265619, 0.9434112303712395, 0.9343848998626966, 0.9379758814747414, 0.9417700660362672, 0.9346627157725645, 0.93940867466873, 0.9372209022554119, 0.9407501468497715, 0.9453314616439048, 0.9417186245489656, 0.9428067227427879, 0.9415025423082073, 0.9409842276841067, 0.9403064204065987, 0.9404260281766399, 0.9413083343023665, 0.9445031794269433, 0.9454202196571264, 0.9362845748997806, 0.942826015895672, 0.9438716695549783, 0.9428015766518839, 0.9399565846732493, 0.9412929127725322, 0.9418961191445254, 0.9428980397374442, 0.9439784268314919, 0.9427655667401431, 0.9450253616558032, 0.9433893581454673], 'val_mDice': [0.2749270718502864, 0.2909649478250675, 0.3126457803202479, 0.3031432427717059, 0.30405061181341664, 0.330548106117195, 0.3341702169246888, 0.32912351760301695, 0.33713048169117293, 0.3194623930233248, 0.331148923113105, 0.34063095515698527, 0.3189758842580774, 0.3218991905450821, 0.33616814486096414, 0.33651168468628034, 0.33010634126957883, 0.32680726495016826, 0.3367136748654119, 0.3322346326005593, 0.333325428406844, 0.3386753512065062, 0.33800324010715055, 0.32462689590253185, 0.3236174705658066, 0.3378414154220163, 0.335818131736825, 0.3122125528334232, 0.3399371668863832, 0.3131548891660203, 0.3463555938574705, 0.3398891551775879, 0.33465529789917925, 0.3475688910216428, 0.34211365104223906, 0.3337336835566531, 0.33659951305121516, 0.3455320589997795, 0.3416697418086984, 0.3448077156470063, 0.3472076995151766, 0.3456136320581597, 0.34081258189477276, 0.3409008706051312, 0.3353900308354517, 0.3298357334197237, 0.3429018982340781, 0.33428156133113285, 0.3292936841758449, 0.3414223530235585, 0.3408007211564632, 0.33199321738119875, 0.3334205656239156, 0.33560652377900113, 0.3381876940472742, 0.33691733631860005, 0.3353427622592851, 0.34035595096229165, 0.3311266388032543, 0.33827854709678823, 0.34431398341829855, 0.3428556967652246, 0.3365573807713691, 0.34460803456185907, 0.34264685607023454, 0.34230947461021083, 0.34328449475631284, 0.34282473307312206, 0.3413920472846942, 0.3410489789388153, 0.3404981416095509, 0.3415513105606765, 0.3413175234801314, 0.34399515465739067], 'loss': [0.6284757147985859, 0.5282024729627895, 0.4951652055230006, 0.4807043240818452, 0.46676822658989003, 0.45023258783306674, 0.42626334034941377, 0.4180982915749521, 0.40895830397455485, 0.40710714553427685, 0.4044844369962193, 0.4118976019071358, 0.39999218045114876, 0.4140753876325104, 0.3937188915838243, 0.38586296249174845, 0.41730947196318685, 0.39481779255125493, 0.386238282796884, 0.39108472241178427, 0.37830765803479066, 0.37876591986889463, 0.37247107359804893, 0.3705328264220617, 0.37265121201223345, 0.3710832626501631, 0.365059160648556, 0.35943241408337, 0.3528486857707156, 0.355303130858368, 0.3530071403070517, 0.35127122084211765, 0.34897570279862383, 0.3520701381964913, 0.35238557077602056, 0.3490789977469758, 0.34398037963765854, 0.34841442434709907, 0.3462618587669511, 0.34481100374384355, 0.343575778361111, 0.3429688812621602, 0.34027021928722845, 0.3401363617686455, 0.3405005118104062, 0.33777584728445215, 0.33557093535989574, 0.3394420826276759, 0.33729781397614744, 0.3321852007490136, 0.3282797503814423, 0.32953580456111203, 0.3304551096996947, 0.33848324782556766, 0.32955084597629014, 0.3309784048192067, 0.32580766670599653, 0.32774319824225084, 0.3241827962523214, 0.32240248210501393, 0.3246233550533776, 0.3283137679759745, 0.32340914002755233, 0.3209284367848973, 0.3226987731410577, 0.32043729875882027, 0.3201049061757, 0.32047532970527953, 0.32094756637941624, 0.3221866365586055, 0.3189247016855281, 0.3198620909129181, 0.31804107259041575, 0.3175031327300792], 'acc': [0.9073873772499769, 0.9237654602323109, 0.9293283545053922, 0.932126386362212, 0.9342038289050602, 0.9351699025378942, 0.9369864801906655, 0.9378797044461118, 0.9390408638503978, 0.9393957875087635, 0.938989121477183, 0.9381331947210024, 0.9391225554630382, 0.936414299944058, 0.9395718679087691, 0.940916279204062, 0.9361460870250392, 0.938755319866609, 0.9397384449138652, 0.9390875134074892, 0.942193869668341, 0.9414398318242156, 0.9430395578836696, 0.9426569403306384, 0.9427789713904946, 0.9427305745300035, 0.9437336944121977, 0.9443563239377839, 0.945284693658055, 0.944899591049834, 0.9449238168249885, 0.9454902433267138, 0.9459946919160451, 0.945663968601079, 0.9454985040620868, 0.9461341834754395, 0.946466757503081, 0.94604972824578, 0.9462514271311293, 0.9465878009796143, 0.9463502992301206, 0.9469571933933695, 0.9469369229652899, 0.9472804685356739, 0.9472671903228654, 0.9473961418877007, 0.9474471987580224, 0.9468061223700354, 0.9475370513581411, 0.9480316433117544, 0.9480329598916059, 0.9483048490021331, 0.9481219244913693, 0.9475195681316522, 0.9483496214252318, 0.9482756051558054, 0.9485845636054833, 0.9486363325649424, 0.9486797623167265, 0.9487382446987298, 0.9488729733951065, 0.9489263870073539, 0.9489621410530842, 0.948941843708906, 0.9492436555385854, 0.9493023161078, 0.9493367009949275, 0.9493180773636882, 0.94935661788533, 0.9492439860194575, 0.9495545408972469, 0.9495847448830322, 0.9496940824955158, 0.9495590247696252], 'mDice': [0.32289413787222526, 0.4309354027332228, 0.4665123553452864, 0.48201027943010016, 0.49704668801597424, 0.5148344909082676, 0.540653586519576, 0.5496230735327569, 0.5594232835423966, 0.5611100596951462, 0.5623184008432082, 0.552157232460556, 0.5626182485068775, 0.5443117241537498, 0.5660317020318623, 0.5745462511347088, 0.5386162356375065, 0.5621839160739749, 0.5718336631134193, 0.5669547075485089, 0.5820559410014466, 0.5777164272300169, 0.5861079320765096, 0.5859276115993274, 0.5827980798024398, 0.5846200065845011, 0.5936953518096426, 0.5985819283907889, 0.6040580054970822, 0.6015093440698139, 0.6046765117138607, 0.6057568800733046, 0.609124586489165, 0.6062138045632384, 0.6054907978471631, 0.61072235204399, 0.6145388964598655, 0.6108964541767207, 0.6121659000802581, 0.6158237455955974, 0.61570539036441, 0.618002897477902, 0.6183554100673635, 0.6172874622009838, 0.6191231730766698, 0.621762084446365, 0.6230439288746803, 0.6178403071890104, 0.623017441124697, 0.6262040369802242, 0.6305464397957131, 0.6294673723480486, 0.629905648236784, 0.6224903190868232, 0.6293176644799718, 0.6306734165237566, 0.6324416623302896, 0.632019076119092, 0.6344336688881363, 0.6352760170993056, 0.6363359382618311, 0.6322844766026778, 0.6356245276013592, 0.6379944297841192, 0.6373162388999487, 0.6389142474418328, 0.6401922892785297, 0.6389737786280891, 0.6399295355116523, 0.6373216758199205, 0.6423674576772005, 0.639777831762089, 0.6427395399525869, 0.6421397528598238], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.61s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.44s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.27s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.13s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.08s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_b/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_b/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_b/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  2.66it/s] 40%|████      | 2/5 [00:00<00:01,  2.72it/s] 60%|██████    | 3/5 [00:01<00:00,  2.93it/s] 80%|████████  | 4/5 [00:01<00:00,  3.14it/s]100%|██████████| 5/5 [00:01<00:00,  3.02it/s]100%|██████████| 5/5 [00:01<00:00,  3.07it/s]

CrossVal ['b']
Error in label values min 0.0 max 2.0      1-THALAMUS
2020-01-21 22:39:11.708586: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 22:39:15.344654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:09:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 22:39:15.344707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 22:39:15.768737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 22:39:15.768798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 22:39:15.768808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 22:39:15.769280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:09,  3.56it/s]Loading train:   1%|          | 2/247 [00:00<01:05,  3.74it/s]Loading train:   1%|          | 3/247 [00:00<01:03,  3.86it/s]Loading train:   2%|▏         | 4/247 [00:01<01:03,  3.85it/s]Loading train:   2%|▏         | 5/247 [00:01<01:00,  4.00it/s]Loading train:   2%|▏         | 6/247 [00:01<00:57,  4.16it/s]Loading train:   3%|▎         | 7/247 [00:01<00:56,  4.23it/s]Loading train:   3%|▎         | 8/247 [00:01<00:55,  4.29it/s]Loading train:   4%|▎         | 9/247 [00:02<00:54,  4.33it/s]Loading train:   4%|▍         | 10/247 [00:02<00:54,  4.37it/s]Loading train:   4%|▍         | 11/247 [00:02<00:53,  4.42it/s]Loading train:   5%|▍         | 12/247 [00:02<00:52,  4.46it/s]Loading train:   5%|▌         | 13/247 [00:03<00:52,  4.48it/s]Loading train:   6%|▌         | 14/247 [00:03<00:51,  4.50it/s]Loading train:   6%|▌         | 15/247 [00:03<00:51,  4.52it/s]Loading train:   6%|▋         | 16/247 [00:03<00:50,  4.54it/s]Loading train:   7%|▋         | 17/247 [00:03<00:50,  4.54it/s]Loading train:   7%|▋         | 18/247 [00:04<00:50,  4.55it/s]Loading train:   8%|▊         | 19/247 [00:04<00:50,  4.56it/s]Loading train:   8%|▊         | 20/247 [00:04<00:50,  4.54it/s]Loading train:   9%|▊         | 21/247 [00:04<00:49,  4.56it/s]Loading train:   9%|▉         | 22/247 [00:05<00:49,  4.55it/s]Loading train:   9%|▉         | 23/247 [00:05<00:48,  4.57it/s]Loading train:  10%|▉         | 24/247 [00:05<00:48,  4.60it/s]Loading train:  10%|█         | 25/247 [00:05<00:48,  4.62it/s]Loading train:  11%|█         | 26/247 [00:05<00:47,  4.61it/s]Loading train:  11%|█         | 27/247 [00:06<00:47,  4.61it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:47,  4.62it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:47,  4.61it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:47,  4.59it/s]Loading train:  13%|█▎        | 31/247 [00:06<00:47,  4.57it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:47,  4.57it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:46,  4.56it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:46,  4.58it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:46,  4.58it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:46,  4.59it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:45,  4.57it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:45,  4.57it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:45,  4.58it/s]Loading train:  16%|█▌        | 40/247 [00:08<00:45,  4.58it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:45,  4.57it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:44,  4.56it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:44,  4.55it/s]Loading train:  18%|█▊        | 44/247 [00:09<00:44,  4.54it/s]Loading train:  18%|█▊        | 45/247 [00:10<00:44,  4.56it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:44,  4.57it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:43,  4.57it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:43,  4.58it/s]Loading train:  20%|█▉        | 49/247 [00:10<00:43,  4.59it/s]Loading train:  20%|██        | 50/247 [00:11<00:42,  4.60it/s]Loading train:  21%|██        | 51/247 [00:11<00:42,  4.59it/s]Loading train:  21%|██        | 52/247 [00:11<00:42,  4.61it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:41,  4.62it/s]Loading train:  22%|██▏       | 54/247 [00:11<00:41,  4.61it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:41,  4.60it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:41,  4.61it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:41,  4.60it/s]Loading train:  23%|██▎       | 58/247 [00:12<00:41,  4.60it/s]Loading train:  24%|██▍       | 59/247 [00:13<00:41,  4.56it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:41,  4.53it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:41,  4.52it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:40,  4.51it/s]Loading train:  26%|██▌       | 63/247 [00:13<00:40,  4.51it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:40,  4.50it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:40,  4.50it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:40,  4.51it/s]Loading train:  27%|██▋       | 67/247 [00:14<00:40,  4.49it/s]Loading train:  28%|██▊       | 68/247 [00:15<00:39,  4.50it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:39,  4.49it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:39,  4.50it/s]Loading train:  29%|██▊       | 71/247 [00:15<00:39,  4.50it/s]Loading train:  29%|██▉       | 72/247 [00:15<00:39,  4.48it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:38,  4.49it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:38,  4.49it/s]Loading train:  30%|███       | 75/247 [00:16<00:38,  4.47it/s]Loading train:  31%|███       | 76/247 [00:16<00:38,  4.48it/s]Loading train:  31%|███       | 77/247 [00:17<00:41,  4.14it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:42,  3.98it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:40,  4.11it/s]Loading train:  32%|███▏      | 80/247 [00:17<00:39,  4.18it/s]Loading train:  33%|███▎      | 81/247 [00:18<00:40,  4.07it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:41,  4.02it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:41,  3.97it/s]Loading train:  34%|███▍      | 84/247 [00:18<00:41,  3.95it/s]Loading train:  34%|███▍      | 85/247 [00:19<00:41,  3.93it/s]Loading train:  35%|███▍      | 86/247 [00:19<00:40,  3.93it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:40,  3.93it/s]Loading train:  36%|███▌      | 88/247 [00:19<00:40,  3.93it/s]Loading train:  36%|███▌      | 89/247 [00:20<00:40,  3.93it/s]Loading train:  36%|███▋      | 90/247 [00:20<00:39,  3.93it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:39,  3.94it/s]Loading train:  37%|███▋      | 92/247 [00:20<00:39,  3.94it/s]Loading train:  38%|███▊      | 93/247 [00:21<00:39,  3.92it/s]Loading train:  38%|███▊      | 94/247 [00:21<00:38,  3.93it/s]Loading train:  38%|███▊      | 95/247 [00:21<00:38,  3.94it/s]Loading train:  39%|███▉      | 96/247 [00:21<00:38,  3.94it/s]Loading train:  39%|███▉      | 97/247 [00:22<00:38,  3.94it/s]Loading train:  40%|███▉      | 98/247 [00:22<00:37,  3.94it/s]Loading train:  40%|████      | 99/247 [00:22<00:37,  3.94it/s]Loading train:  40%|████      | 100/247 [00:22<00:36,  4.00it/s]Loading train:  41%|████      | 101/247 [00:23<00:36,  4.03it/s]Loading train:  41%|████▏     | 102/247 [00:23<00:35,  4.05it/s]Loading train:  42%|████▏     | 103/247 [00:23<00:35,  4.08it/s]Loading train:  42%|████▏     | 104/247 [00:23<00:34,  4.09it/s]Loading train:  43%|████▎     | 105/247 [00:24<00:34,  4.08it/s]Loading train:  43%|████▎     | 106/247 [00:24<00:34,  4.07it/s]Loading train:  43%|████▎     | 107/247 [00:24<00:34,  4.06it/s]Loading train:  44%|████▎     | 108/247 [00:24<00:34,  4.08it/s]Loading train:  44%|████▍     | 109/247 [00:25<00:33,  4.09it/s]Loading train:  45%|████▍     | 110/247 [00:25<00:33,  4.10it/s]Loading train:  45%|████▍     | 111/247 [00:25<00:33,  4.11it/s]Loading train:  45%|████▌     | 112/247 [00:25<00:32,  4.10it/s]Loading train:  46%|████▌     | 113/247 [00:26<00:32,  4.09it/s]Loading train:  46%|████▌     | 114/247 [00:26<00:32,  4.11it/s]Loading train:  47%|████▋     | 115/247 [00:26<00:32,  4.11it/s]Loading train:  47%|████▋     | 116/247 [00:26<00:31,  4.10it/s]Loading train:  47%|████▋     | 117/247 [00:27<00:31,  4.07it/s]Loading train:  48%|████▊     | 118/247 [00:27<00:30,  4.27it/s]Loading train:  48%|████▊     | 119/247 [00:27<00:28,  4.44it/s]Loading train:  49%|████▊     | 120/247 [00:27<00:27,  4.56it/s]Loading train:  49%|████▉     | 121/247 [00:27<00:27,  4.66it/s]Loading train:  49%|████▉     | 122/247 [00:28<00:26,  4.73it/s]Loading train:  50%|████▉     | 123/247 [00:28<00:25,  4.79it/s]Loading train:  50%|█████     | 124/247 [00:28<00:25,  4.84it/s]Loading train:  51%|█████     | 125/247 [00:28<00:25,  4.88it/s]Loading train:  51%|█████     | 126/247 [00:28<00:25,  4.83it/s]Loading train:  51%|█████▏    | 127/247 [00:29<00:25,  4.78it/s]Loading train:  52%|█████▏    | 128/247 [00:29<00:24,  4.80it/s]Loading train:  52%|█████▏    | 129/247 [00:29<00:24,  4.84it/s]Loading train:  53%|█████▎    | 130/247 [00:29<00:24,  4.86it/s]Loading train:  53%|█████▎    | 131/247 [00:29<00:23,  4.86it/s]Loading train:  53%|█████▎    | 132/247 [00:30<00:23,  4.86it/s]Loading train:  54%|█████▍    | 133/247 [00:30<00:23,  4.82it/s]Loading train:  54%|█████▍    | 134/247 [00:30<00:23,  4.78it/s]Loading train:  55%|█████▍    | 135/247 [00:30<00:23,  4.77it/s]Loading train:  55%|█████▌    | 136/247 [00:31<00:23,  4.71it/s]Loading train:  55%|█████▌    | 137/247 [00:31<00:23,  4.70it/s]Loading train:  56%|█████▌    | 138/247 [00:31<00:23,  4.70it/s]Loading train:  56%|█████▋    | 139/247 [00:31<00:23,  4.67it/s]Loading train:  57%|█████▋    | 140/247 [00:31<00:22,  4.67it/s]Loading train:  57%|█████▋    | 141/247 [00:32<00:22,  4.67it/s]Loading train:  57%|█████▋    | 142/247 [00:32<00:22,  4.65it/s]Loading train:  58%|█████▊    | 143/247 [00:32<00:22,  4.66it/s]Loading train:  58%|█████▊    | 144/247 [00:32<00:22,  4.65it/s]Loading train:  59%|█████▊    | 145/247 [00:32<00:21,  4.66it/s]Loading train:  59%|█████▉    | 146/247 [00:33<00:21,  4.67it/s]Loading train:  60%|█████▉    | 147/247 [00:33<00:21,  4.68it/s]Loading train:  60%|█████▉    | 148/247 [00:33<00:21,  4.68it/s]Loading train:  60%|██████    | 149/247 [00:33<00:20,  4.68it/s]Loading train:  61%|██████    | 150/247 [00:34<00:20,  4.68it/s]Loading train:  61%|██████    | 151/247 [00:34<00:20,  4.67it/s]Loading train:  62%|██████▏   | 152/247 [00:34<00:20,  4.67it/s]Loading train:  62%|██████▏   | 153/247 [00:34<00:20,  4.66it/s]Loading train:  62%|██████▏   | 154/247 [00:34<00:20,  4.47it/s]Loading train:  63%|██████▎   | 155/247 [00:35<00:21,  4.32it/s]Loading train:  63%|██████▎   | 156/247 [00:35<00:21,  4.25it/s]Loading train:  64%|██████▎   | 157/247 [00:35<00:21,  4.19it/s]Loading train:  64%|██████▍   | 158/247 [00:35<00:21,  4.14it/s]Loading train:  64%|██████▍   | 159/247 [00:36<00:21,  4.09it/s]Loading train:  65%|██████▍   | 160/247 [00:36<00:21,  4.10it/s]Loading train:  65%|██████▌   | 161/247 [00:36<00:20,  4.13it/s]Loading train:  66%|██████▌   | 162/247 [00:36<00:20,  4.13it/s]Loading train:  66%|██████▌   | 163/247 [00:37<00:20,  4.14it/s]Loading train:  66%|██████▋   | 164/247 [00:37<00:19,  4.16it/s]Loading train:  67%|██████▋   | 165/247 [00:37<00:19,  4.17it/s]Loading train:  67%|██████▋   | 166/247 [00:37<00:19,  4.17it/s]Loading train:  68%|██████▊   | 167/247 [00:38<00:19,  4.16it/s]Loading train:  68%|██████▊   | 168/247 [00:38<00:18,  4.16it/s]Loading train:  68%|██████▊   | 169/247 [00:38<00:18,  4.14it/s]Loading train:  69%|██████▉   | 170/247 [00:38<00:18,  4.14it/s]Loading train:  69%|██████▉   | 171/247 [00:39<00:18,  4.10it/s]Loading train:  70%|██████▉   | 172/247 [00:39<00:18,  4.16it/s]Loading train:  70%|███████   | 173/247 [00:39<00:17,  4.30it/s]Loading train:  70%|███████   | 174/247 [00:39<00:16,  4.33it/s]Loading train:  71%|███████   | 175/247 [00:40<00:17,  4.15it/s]Loading train:  71%|███████▏  | 176/247 [00:40<00:16,  4.26it/s]Loading train:  72%|███████▏  | 177/247 [00:40<00:16,  4.36it/s]Loading train:  72%|███████▏  | 178/247 [00:40<00:15,  4.46it/s]Loading train:  72%|███████▏  | 179/247 [00:40<00:15,  4.52it/s]Loading train:  73%|███████▎  | 180/247 [00:41<00:14,  4.55it/s]Loading train:  73%|███████▎  | 181/247 [00:41<00:14,  4.56it/s]Loading train:  74%|███████▎  | 182/247 [00:41<00:14,  4.59it/s]Loading train:  74%|███████▍  | 183/247 [00:41<00:13,  4.60it/s]Loading train:  74%|███████▍  | 184/247 [00:41<00:13,  4.62it/s]Loading train:  75%|███████▍  | 185/247 [00:42<00:13,  4.64it/s]Loading train:  75%|███████▌  | 186/247 [00:42<00:13,  4.64it/s]Loading train:  76%|███████▌  | 187/247 [00:42<00:12,  4.65it/s]Loading train:  76%|███████▌  | 188/247 [00:42<00:12,  4.66it/s]Loading train:  77%|███████▋  | 189/247 [00:43<00:12,  4.64it/s]Loading train:  77%|███████▋  | 190/247 [00:43<00:12,  4.58it/s]Loading train:  77%|███████▋  | 191/247 [00:43<00:12,  4.58it/s]Loading train:  78%|███████▊  | 192/247 [00:43<00:11,  4.60it/s]Loading train:  78%|███████▊  | 193/247 [00:43<00:11,  4.58it/s]Loading train:  79%|███████▊  | 194/247 [00:44<00:11,  4.65it/s]Loading train:  79%|███████▉  | 195/247 [00:44<00:11,  4.70it/s]Loading train:  79%|███████▉  | 196/247 [00:44<00:10,  4.74it/s]Loading train:  80%|███████▉  | 197/247 [00:44<00:10,  4.75it/s]Loading train:  80%|████████  | 198/247 [00:44<00:10,  4.73it/s]Loading train:  81%|████████  | 199/247 [00:45<00:10,  4.70it/s]Loading train:  81%|████████  | 200/247 [00:45<00:10,  4.70it/s]Loading train:  81%|████████▏ | 201/247 [00:45<00:09,  4.71it/s]Loading train:  82%|████████▏ | 202/247 [00:45<00:09,  4.75it/s]Loading train:  82%|████████▏ | 203/247 [00:46<00:09,  4.76it/s]Loading train:  83%|████████▎ | 204/247 [00:46<00:08,  4.79it/s]Loading train:  83%|████████▎ | 205/247 [00:46<00:08,  4.80it/s]Loading train:  83%|████████▎ | 206/247 [00:46<00:08,  4.81it/s]Loading train:  84%|████████▍ | 207/247 [00:46<00:08,  4.82it/s]Loading train:  84%|████████▍ | 208/247 [00:47<00:08,  4.82it/s]Loading train:  85%|████████▍ | 209/247 [00:47<00:07,  4.82it/s]Loading train:  85%|████████▌ | 210/247 [00:47<00:07,  4.81it/s]Loading train:  85%|████████▌ | 211/247 [00:47<00:07,  4.81it/s]Loading train:  86%|████████▌ | 212/247 [00:47<00:07,  4.74it/s]Loading train:  86%|████████▌ | 213/247 [00:48<00:07,  4.70it/s]Loading train:  87%|████████▋ | 214/247 [00:48<00:07,  4.67it/s]Loading train:  87%|████████▋ | 215/247 [00:48<00:06,  4.58it/s]Loading train:  87%|████████▋ | 216/247 [00:48<00:06,  4.53it/s]Loading train:  88%|████████▊ | 217/247 [00:48<00:06,  4.53it/s]Loading train:  88%|████████▊ | 218/247 [00:49<00:06,  4.53it/s]Loading train:  89%|████████▊ | 219/247 [00:49<00:06,  4.56it/s]Loading train:  89%|████████▉ | 220/247 [00:49<00:05,  4.59it/s]Loading train:  89%|████████▉ | 221/247 [00:49<00:05,  4.59it/s]Loading train:  90%|████████▉ | 222/247 [00:50<00:05,  4.59it/s]Loading train:  90%|█████████ | 223/247 [00:50<00:05,  4.58it/s]Loading train:  91%|█████████ | 224/247 [00:50<00:05,  4.58it/s]Loading train:  91%|█████████ | 225/247 [00:50<00:04,  4.61it/s]Loading train:  91%|█████████▏| 226/247 [00:50<00:04,  4.62it/s]Loading train:  92%|█████████▏| 227/247 [00:51<00:04,  4.63it/s]Loading train:  92%|█████████▏| 228/247 [00:51<00:04,  4.64it/s]Loading train:  93%|█████████▎| 229/247 [00:51<00:03,  4.63it/s]Loading train:  93%|█████████▎| 230/247 [00:51<00:03,  4.50it/s]Loading train:  94%|█████████▎| 231/247 [00:52<00:03,  4.42it/s]Loading train:  94%|█████████▍| 232/247 [00:52<00:03,  4.36it/s]Loading train:  94%|█████████▍| 233/247 [00:52<00:03,  4.33it/s]Loading train:  95%|█████████▍| 234/247 [00:52<00:03,  4.29it/s]Loading train:  95%|█████████▌| 235/247 [00:53<00:02,  4.28it/s]Loading train:  96%|█████████▌| 236/247 [00:53<00:02,  4.26it/s]Loading train:  96%|█████████▌| 237/247 [00:53<00:02,  4.24it/s]Loading train:  96%|█████████▋| 238/247 [00:53<00:02,  4.23it/s]Loading train:  97%|█████████▋| 239/247 [00:53<00:01,  4.24it/s]Loading train:  97%|█████████▋| 240/247 [00:54<00:01,  4.23it/s]Loading train:  98%|█████████▊| 241/247 [00:54<00:01,  4.23it/s]Loading train:  98%|█████████▊| 242/247 [00:54<00:01,  4.23it/s]Loading train:  98%|█████████▊| 243/247 [00:54<00:00,  4.23it/s]Loading train:  99%|█████████▉| 244/247 [00:55<00:00,  4.23it/s]Loading train:  99%|█████████▉| 245/247 [00:55<00:00,  4.24it/s]Loading train: 100%|█████████▉| 246/247 [00:55<00:00,  4.25it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.23it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.42it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:04, 49.57it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:04, 52.29it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 54.45it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 53.81it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:03, 54.28it/s]concatenating: train:  15%|█▍        | 37/247 [00:00<00:03, 56.09it/s]concatenating: train:  18%|█▊        | 44/247 [00:00<00:03, 57.37it/s]concatenating: train:  21%|██        | 51/247 [00:00<00:03, 58.49it/s]concatenating: train:  23%|██▎       | 58/247 [00:00<00:03, 59.24it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 60.02it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:02, 60.41it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:02, 58.19it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:02, 56.78it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 56.03it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:02, 55.67it/s]concatenating: train:  41%|████▏     | 102/247 [00:01<00:02, 55.60it/s]concatenating: train:  44%|████▎     | 108/247 [00:01<00:02, 55.90it/s]concatenating: train:  46%|████▌     | 114/247 [00:01<00:02, 56.05it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 55.97it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:02, 56.91it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:01, 57.53it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:01, 57.96it/s]concatenating: train:  59%|█████▉    | 146/247 [00:02<00:01, 58.89it/s]concatenating: train:  62%|██████▏   | 153/247 [00:02<00:01, 60.02it/s]concatenating: train:  65%|██████▍   | 160/247 [00:02<00:01, 57.43it/s]concatenating: train:  67%|██████▋   | 166/247 [00:02<00:01, 57.16it/s]concatenating: train:  70%|██████▉   | 172/247 [00:02<00:01, 56.98it/s]concatenating: train:  72%|███████▏  | 178/247 [00:03<00:01, 56.82it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 58.28it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:00, 57.71it/s]concatenating: train:  80%|████████  | 198/247 [00:03<00:00, 59.10it/s]concatenating: train:  83%|████████▎ | 205/247 [00:03<00:00, 60.16it/s]concatenating: train:  86%|████████▌ | 212/247 [00:03<00:00, 60.76it/s]concatenating: train:  89%|████████▊ | 219/247 [00:03<00:00, 58.52it/s]concatenating: train:  91%|█████████▏| 226/247 [00:03<00:00, 59.02it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 58.88it/s]concatenating: train:  96%|█████████▋| 238/247 [00:04<00:00, 58.50it/s]concatenating: train:  99%|█████████▉| 244/247 [00:04<00:00, 58.18it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 57.90it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:00,  4.25it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.96it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.94it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.19it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.17it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.06it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 64.73it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<00:58,  4.22it/s]Loading trainS:   1%|          | 2/247 [00:00<00:57,  4.26it/s]Loading trainS:   1%|          | 3/247 [00:00<00:57,  4.28it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:56,  4.27it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:56,  4.30it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:55,  4.38it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:54,  4.42it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:53,  4.43it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:54,  4.34it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:54,  4.32it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:54,  4.36it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:53,  4.40it/s]Loading trainS:   5%|▌         | 13/247 [00:02<00:53,  4.38it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:53,  4.38it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:54,  4.27it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:54,  4.27it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:54,  4.24it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:53,  4.26it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:52,  4.31it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:52,  4.36it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:51,  4.41it/s]Loading trainS:   9%|▉         | 22/247 [00:05<00:50,  4.45it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:49,  4.50it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:49,  4.52it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:48,  4.55it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:48,  4.56it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:48,  4.57it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:47,  4.59it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:47,  4.59it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:47,  4.60it/s]Loading trainS:  13%|█▎        | 31/247 [00:07<00:47,  4.59it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:46,  4.58it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:46,  4.56it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:46,  4.56it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:46,  4.56it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:46,  4.56it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:46,  4.55it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:46,  4.52it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:45,  4.54it/s]Loading trainS:  16%|█▌        | 40/247 [00:08<00:45,  4.56it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:45,  4.57it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:44,  4.57it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:44,  4.59it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:44,  4.60it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:43,  4.61it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:43,  4.59it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:43,  4.60it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:43,  4.62it/s]Loading trainS:  20%|█▉        | 49/247 [00:10<00:42,  4.62it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:42,  4.62it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:42,  4.63it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:42,  4.62it/s]Loading trainS:  21%|██▏       | 53/247 [00:11<00:42,  4.62it/s]Loading trainS:  22%|██▏       | 54/247 [00:12<00:41,  4.61it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:41,  4.59it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:41,  4.59it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:41,  4.60it/s]Loading trainS:  23%|██▎       | 58/247 [00:12<00:41,  4.59it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:41,  4.53it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:41,  4.50it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:41,  4.50it/s]Loading trainS:  25%|██▌       | 62/247 [00:13<00:41,  4.50it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:40,  4.50it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:40,  4.50it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:40,  4.50it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:40,  4.50it/s]Loading trainS:  27%|██▋       | 67/247 [00:14<00:39,  4.50it/s]Loading trainS:  28%|██▊       | 68/247 [00:15<00:39,  4.49it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:40,  4.44it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:40,  4.41it/s]Loading trainS:  29%|██▊       | 71/247 [00:15<00:39,  4.40it/s]Loading trainS:  29%|██▉       | 72/247 [00:16<00:39,  4.39it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:39,  4.42it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:38,  4.44it/s]Loading trainS:  30%|███       | 75/247 [00:16<00:38,  4.46it/s]Loading trainS:  31%|███       | 76/247 [00:16<00:38,  4.48it/s]Loading trainS:  31%|███       | 77/247 [00:17<00:40,  4.16it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:42,  4.02it/s]Loading trainS:  32%|███▏      | 79/247 [00:17<00:40,  4.15it/s]Loading trainS:  32%|███▏      | 80/247 [00:17<00:39,  4.22it/s]Loading trainS:  33%|███▎      | 81/247 [00:18<00:40,  4.06it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:41,  3.97it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:41,  3.95it/s]Loading trainS:  34%|███▍      | 84/247 [00:18<00:41,  3.93it/s]Loading trainS:  34%|███▍      | 85/247 [00:19<00:41,  3.93it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:40,  3.93it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:41,  3.85it/s]Loading trainS:  36%|███▌      | 88/247 [00:20<00:41,  3.80it/s]Loading trainS:  36%|███▌      | 89/247 [00:20<00:41,  3.77it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:40,  3.84it/s]Loading trainS:  37%|███▋      | 91/247 [00:20<00:40,  3.86it/s]Loading trainS:  37%|███▋      | 92/247 [00:21<00:39,  3.90it/s]Loading trainS:  38%|███▊      | 93/247 [00:21<00:39,  3.90it/s]Loading trainS:  38%|███▊      | 94/247 [00:21<00:39,  3.91it/s]Loading trainS:  38%|███▊      | 95/247 [00:21<00:38,  3.92it/s]Loading trainS:  39%|███▉      | 96/247 [00:22<00:38,  3.90it/s]Loading trainS:  39%|███▉      | 97/247 [00:22<00:38,  3.90it/s]Loading trainS:  40%|███▉      | 98/247 [00:22<00:38,  3.91it/s]Loading trainS:  40%|████      | 99/247 [00:22<00:37,  3.93it/s]Loading trainS:  40%|████      | 100/247 [00:23<00:36,  4.00it/s]Loading trainS:  41%|████      | 101/247 [00:23<00:36,  4.04it/s]Loading trainS:  41%|████▏     | 102/247 [00:23<00:35,  4.08it/s]Loading trainS:  42%|████▏     | 103/247 [00:23<00:35,  4.09it/s]Loading trainS:  42%|████▏     | 104/247 [00:24<00:34,  4.11it/s]Loading trainS:  43%|████▎     | 105/247 [00:24<00:34,  4.11it/s]Loading trainS:  43%|████▎     | 106/247 [00:24<00:34,  4.09it/s]Loading trainS:  43%|████▎     | 107/247 [00:24<00:34,  4.08it/s]Loading trainS:  44%|████▎     | 108/247 [00:25<00:34,  4.05it/s]Loading trainS:  44%|████▍     | 109/247 [00:25<00:33,  4.08it/s]Loading trainS:  45%|████▍     | 110/247 [00:25<00:33,  4.08it/s]Loading trainS:  45%|████▍     | 111/247 [00:25<00:33,  4.10it/s]Loading trainS:  45%|████▌     | 112/247 [00:26<00:32,  4.10it/s]Loading trainS:  46%|████▌     | 113/247 [00:26<00:32,  4.10it/s]Loading trainS:  46%|████▌     | 114/247 [00:26<00:32,  4.12it/s]Loading trainS:  47%|████▋     | 115/247 [00:26<00:32,  4.12it/s]Loading trainS:  47%|████▋     | 116/247 [00:26<00:32,  4.05it/s]Loading trainS:  47%|████▋     | 117/247 [00:27<00:32,  4.00it/s]Loading trainS:  48%|████▊     | 118/247 [00:27<00:30,  4.19it/s]Loading trainS:  48%|████▊     | 119/247 [00:27<00:29,  4.33it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:28,  4.47it/s]Loading trainS:  49%|████▉     | 121/247 [00:28<00:27,  4.58it/s]Loading trainS:  49%|████▉     | 122/247 [00:28<00:26,  4.67it/s]Loading trainS:  50%|████▉     | 123/247 [00:28<00:26,  4.73it/s]Loading trainS:  50%|█████     | 124/247 [00:28<00:25,  4.77it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:25,  4.78it/s]Loading trainS:  51%|█████     | 126/247 [00:29<00:25,  4.81it/s]Loading trainS:  51%|█████▏    | 127/247 [00:29<00:24,  4.82it/s]Loading trainS:  52%|█████▏    | 128/247 [00:29<00:24,  4.81it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:24,  4.76it/s]Loading trainS:  53%|█████▎    | 130/247 [00:29<00:24,  4.70it/s]Loading trainS:  53%|█████▎    | 131/247 [00:30<00:24,  4.70it/s]Loading trainS:  53%|█████▎    | 132/247 [00:30<00:24,  4.63it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:25,  4.55it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:24,  4.67it/s]Loading trainS:  55%|█████▍    | 135/247 [00:31<00:23,  4.72it/s]Loading trainS:  55%|█████▌    | 136/247 [00:31<00:23,  4.65it/s]Loading trainS:  55%|█████▌    | 137/247 [00:31<00:23,  4.66it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:23,  4.64it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:23,  4.60it/s]Loading trainS:  57%|█████▋    | 140/247 [00:32<00:23,  4.60it/s]Loading trainS:  57%|█████▋    | 141/247 [00:32<00:23,  4.54it/s]Loading trainS:  57%|█████▋    | 142/247 [00:32<00:23,  4.56it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:23,  4.50it/s]Loading trainS:  58%|█████▊    | 144/247 [00:33<00:23,  4.32it/s]Loading trainS:  59%|█████▊    | 145/247 [00:33<00:23,  4.40it/s]Loading trainS:  59%|█████▉    | 146/247 [00:33<00:22,  4.45it/s]Loading trainS:  60%|█████▉    | 147/247 [00:33<00:22,  4.44it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:22,  4.38it/s]Loading trainS:  60%|██████    | 149/247 [00:34<00:22,  4.39it/s]Loading trainS:  61%|██████    | 150/247 [00:34<00:21,  4.45it/s]Loading trainS:  61%|██████    | 151/247 [00:34<00:21,  4.44it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:21,  4.50it/s]Loading trainS:  62%|██████▏   | 153/247 [00:35<00:22,  4.23it/s]Loading trainS:  62%|██████▏   | 154/247 [00:35<00:22,  4.09it/s]Loading trainS:  63%|██████▎   | 155/247 [00:35<00:25,  3.68it/s]Loading trainS:  63%|██████▎   | 156/247 [00:35<00:24,  3.66it/s]Loading trainS:  64%|██████▎   | 157/247 [00:36<00:24,  3.68it/s]Loading trainS:  64%|██████▍   | 158/247 [00:36<00:24,  3.67it/s]Loading trainS:  64%|██████▍   | 159/247 [00:36<00:23,  3.73it/s]Loading trainS:  65%|██████▍   | 160/247 [00:37<00:24,  3.57it/s]Loading trainS:  65%|██████▌   | 161/247 [00:37<00:24,  3.53it/s]Loading trainS:  66%|██████▌   | 162/247 [00:37<00:23,  3.54it/s]Loading trainS:  66%|██████▌   | 163/247 [00:37<00:23,  3.59it/s]Loading trainS:  66%|██████▋   | 164/247 [00:38<00:22,  3.66it/s]Loading trainS:  67%|██████▋   | 165/247 [00:38<00:22,  3.72it/s]Loading trainS:  67%|██████▋   | 166/247 [00:38<00:21,  3.81it/s]Loading trainS:  68%|██████▊   | 167/247 [00:38<00:21,  3.81it/s]Loading trainS:  68%|██████▊   | 168/247 [00:39<00:21,  3.74it/s]Loading trainS:  68%|██████▊   | 169/247 [00:39<00:21,  3.67it/s]Loading trainS:  69%|██████▉   | 170/247 [00:39<00:20,  3.75it/s]Loading trainS:  69%|██████▉   | 171/247 [00:40<00:19,  3.86it/s]Loading trainS:  70%|██████▉   | 172/247 [00:40<00:18,  3.98it/s]Loading trainS:  70%|███████   | 173/247 [00:40<00:17,  4.13it/s]Loading trainS:  70%|███████   | 174/247 [00:40<00:17,  4.15it/s]Loading trainS:  71%|███████   | 175/247 [00:40<00:17,  4.04it/s]Loading trainS:  71%|███████▏  | 176/247 [00:41<00:16,  4.18it/s]Loading trainS:  72%|███████▏  | 177/247 [00:41<00:16,  4.29it/s]Loading trainS:  72%|███████▏  | 178/247 [00:41<00:15,  4.33it/s]Loading trainS:  72%|███████▏  | 179/247 [00:41<00:15,  4.40it/s]Loading trainS:  73%|███████▎  | 180/247 [00:42<00:15,  4.44it/s]Loading trainS:  73%|███████▎  | 181/247 [00:42<00:14,  4.45it/s]Loading trainS:  74%|███████▎  | 182/247 [00:42<00:14,  4.45it/s]Loading trainS:  74%|███████▍  | 183/247 [00:42<00:14,  4.43it/s]Loading trainS:  74%|███████▍  | 184/247 [00:42<00:14,  4.46it/s]Loading trainS:  75%|███████▍  | 185/247 [00:43<00:13,  4.50it/s]Loading trainS:  75%|███████▌  | 186/247 [00:43<00:13,  4.53it/s]Loading trainS:  76%|███████▌  | 187/247 [00:43<00:13,  4.56it/s]Loading trainS:  76%|███████▌  | 188/247 [00:43<00:12,  4.57it/s]Loading trainS:  77%|███████▋  | 189/247 [00:44<00:12,  4.56it/s]Loading trainS:  77%|███████▋  | 190/247 [00:44<00:12,  4.48it/s]Loading trainS:  77%|███████▋  | 191/247 [00:44<00:12,  4.47it/s]Loading trainS:  78%|███████▊  | 192/247 [00:44<00:12,  4.49it/s]Loading trainS:  78%|███████▊  | 193/247 [00:44<00:12,  4.44it/s]Loading trainS:  79%|███████▊  | 194/247 [00:45<00:11,  4.53it/s]Loading trainS:  79%|███████▉  | 195/247 [00:45<00:11,  4.55it/s]Loading trainS:  79%|███████▉  | 196/247 [00:45<00:11,  4.59it/s]Loading trainS:  80%|███████▉  | 197/247 [00:45<00:12,  4.02it/s]Loading trainS:  80%|████████  | 198/247 [00:46<00:13,  3.62it/s]Loading trainS:  81%|████████  | 199/247 [00:46<00:19,  2.51it/s]Loading trainS:  81%|████████  | 200/247 [00:47<00:23,  2.02it/s]Loading trainS:  81%|████████▏ | 201/247 [00:48<00:24,  1.90it/s]Loading trainS:  82%|████████▏ | 202/247 [00:48<00:25,  1.76it/s]Loading trainS:  82%|████████▏ | 203/247 [00:49<00:26,  1.64it/s]Loading trainS:  83%|████████▎ | 204/247 [00:50<00:26,  1.63it/s]Loading trainS:  83%|████████▎ | 205/247 [00:50<00:25,  1.64it/s]Loading trainS:  83%|████████▎ | 206/247 [00:51<00:25,  1.59it/s]Loading trainS:  84%|████████▍ | 207/247 [00:52<00:25,  1.55it/s]Loading trainS:  84%|████████▍ | 208/247 [00:52<00:24,  1.58it/s]Loading trainS:  85%|████████▍ | 209/247 [00:53<00:24,  1.56it/s]Loading trainS:  85%|████████▌ | 210/247 [00:54<00:23,  1.60it/s]Loading trainS:  85%|████████▌ | 211/247 [00:54<00:22,  1.62it/s]Loading trainS:  86%|████████▌ | 212/247 [00:55<00:21,  1.66it/s]Loading trainS:  86%|████████▌ | 213/247 [00:56<00:22,  1.53it/s]Loading trainS:  87%|████████▋ | 214/247 [00:56<00:21,  1.50it/s]Loading trainS:  87%|████████▋ | 215/247 [00:57<00:20,  1.55it/s]Loading trainS:  87%|████████▋ | 216/247 [00:57<00:20,  1.52it/s]Loading trainS:  88%|████████▊ | 217/247 [00:58<00:19,  1.51it/s]Loading trainS:  88%|████████▊ | 218/247 [00:59<00:19,  1.51it/s]Loading trainS:  89%|████████▊ | 219/247 [00:59<00:18,  1.51it/s]Loading trainS:  89%|████████▉ | 220/247 [01:00<00:18,  1.49it/s]Loading trainS:  89%|████████▉ | 221/247 [01:01<00:17,  1.49it/s]Loading trainS:  90%|████████▉ | 222/247 [01:02<00:16,  1.50it/s]Loading trainS:  90%|█████████ | 223/247 [01:02<00:16,  1.46it/s]Loading trainS:  91%|█████████ | 224/247 [01:03<00:15,  1.45it/s]Loading trainS:  91%|█████████ | 225/247 [01:04<00:15,  1.43it/s]Loading trainS:  91%|█████████▏| 226/247 [01:04<00:14,  1.47it/s]Loading trainS:  92%|█████████▏| 227/247 [01:05<00:13,  1.45it/s]Loading trainS:  92%|█████████▏| 228/247 [01:06<00:13,  1.42it/s]Loading trainS:  93%|█████████▎| 229/247 [01:06<00:12,  1.47it/s]Loading trainS:  93%|█████████▎| 230/247 [01:07<00:11,  1.45it/s]Loading trainS:  94%|█████████▎| 231/247 [01:08<00:11,  1.45it/s]Loading trainS:  94%|█████████▍| 232/247 [01:08<00:10,  1.46it/s]Loading trainS:  94%|█████████▍| 233/247 [01:09<00:10,  1.37it/s]Loading trainS:  95%|█████████▍| 234/247 [01:10<00:09,  1.36it/s]Loading trainS:  95%|█████████▌| 235/247 [01:11<00:08,  1.38it/s]Loading trainS:  96%|█████████▌| 236/247 [01:11<00:08,  1.36it/s]Loading trainS:  96%|█████████▌| 237/247 [01:12<00:07,  1.39it/s]Loading trainS:  96%|█████████▋| 238/247 [01:13<00:06,  1.38it/s]Loading trainS:  97%|█████████▋| 239/247 [01:14<00:05,  1.35it/s]Loading trainS:  97%|█████████▋| 240/247 [01:14<00:05,  1.34it/s]Loading trainS:  98%|█████████▊| 241/247 [01:15<00:04,  1.30it/s]Loading trainS:  98%|█████████▊| 242/247 [01:16<00:03,  1.27it/s]Loading trainS:  98%|█████████▊| 243/247 [01:17<00:03,  1.27it/s]Loading trainS:  99%|█████████▉| 244/247 [01:18<00:02,  1.31it/s]Loading trainS:  99%|█████████▉| 245/247 [01:18<00:01,  1.33it/s]Loading trainS: 100%|█████████▉| 246/247 [01:19<00:00,  1.36it/s]Loading trainS: 100%|██████████| 247/247 [01:20<00:00,  1.36it/s]Loading trainS: 100%|██████████| 247/247 [01:20<00:00,  3.08it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.41it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.33it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.35it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.56it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.55it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]----------+++ 
CrossVal ['c']
CrossVal ['c']
(0/5) test vimp2_ANON972_CSFn2
(1/5) test vimp2_H_CSFn2
(2/5) test vimp2_I_CSFn2
(3/5) test vimp2_K_CSFn2
(4/5) test vimp2_ANON765_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 76s - loss: 0.0982 - acc: 0.9895 - mDice: 0.8092 - val_loss: 0.2591 - val_acc: 0.9811 - val_mDice: 0.3785

Epoch 00001: val_mDice improved from -inf to 0.37848, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 72s - loss: 0.0633 - acc: 0.9933 - mDice: 0.8769 - val_loss: -7.4626e-03 - val_acc: 0.9928 - val_mDice: 0.4653

Epoch 00002: val_mDice improved from 0.37848 to 0.46527, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 73s - loss: 0.0585 - acc: 0.9939 - mDice: 0.8862 - val_loss: 0.0387 - val_acc: 0.9936 - val_mDice: 0.4920

Epoch 00003: val_mDice improved from 0.46527 to 0.49196, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 76s - loss: 0.0519 - acc: 0.9944 - mDice: 0.8990 - val_loss: 0.0502 - val_acc: 0.9937 - val_mDice: 0.4753

Epoch 00004: val_mDice did not improve from 0.49196
Epoch 5/300
 - 76s - loss: 0.0487 - acc: 0.9947 - mDice: 0.9052 - val_loss: 0.0460 - val_acc: 0.9933 - val_mDice: 0.5000

Epoch 00005: val_mDice improved from 0.49196 to 0.50005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 76s - loss: 0.0489 - acc: 0.9948 - mDice: 0.9049 - val_loss: 0.1643 - val_acc: 0.9928 - val_mDice: 0.4916

Epoch 00006: val_mDice did not improve from 0.50005
Epoch 7/300
 - 76s - loss: 0.0452 - acc: 0.9950 - mDice: 0.9122 - val_loss: 0.1195 - val_acc: 0.9936 - val_mDice: 0.4914

Epoch 00007: val_mDice did not improve from 0.50005
Epoch 8/300
 - 76s - loss: 0.0436 - acc: 0.9951 - mDice: 0.9153 - val_loss: 0.0078 - val_acc: 0.9933 - val_mDice: 0.5106

Epoch 00008: val_mDice improved from 0.50005 to 0.51061, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 76s - loss: 0.0422 - acc: 0.9953 - mDice: 0.9180 - val_loss: 0.1085 - val_acc: 0.9941 - val_mDice: 0.5220

Epoch 00009: val_mDice improved from 0.51061 to 0.52203, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 77s - loss: 0.0407 - acc: 0.9954 - mDice: 0.9208 - val_loss: 0.0098 - val_acc: 0.9935 - val_mDice: 0.4994

Epoch 00010: val_mDice did not improve from 0.52203
Epoch 11/300
 - 76s - loss: 0.0410 - acc: 0.9954 - mDice: 0.9202 - val_loss: 0.0725 - val_acc: 0.9934 - val_mDice: 0.4952

Epoch 00011: val_mDice did not improve from 0.52203
Epoch 12/300
 - 76s - loss: 0.0390 - acc: 0.9956 - mDice: 0.9242 - val_loss: 0.1442 - val_acc: 0.9923 - val_mDice: 0.4885

Epoch 00012: val_mDice did not improve from 0.52203
Epoch 13/300
 - 76s - loss: 0.0386 - acc: 0.9957 - mDice: 0.9249 - val_loss: 0.0022 - val_acc: 0.9941 - val_mDice: 0.5096

Epoch 00013: val_mDice did not improve from 0.52203
Epoch 14/300
 - 76s - loss: 0.0361 - acc: 0.9957 - mDice: 0.9299 - val_loss: -2.3640e-02 - val_acc: 0.9934 - val_mDice: 0.4973

Epoch 00014: val_mDice did not improve from 0.52203
Epoch 15/300
 - 76s - loss: 0.0378 - acc: 0.9957 - mDice: 0.9266 - val_loss: -1.9642e-02 - val_acc: 0.9936 - val_mDice: 0.4892

Epoch 00015: val_mDice did not improve from 0.52203
Epoch 16/300
 - 76s - loss: 0.0365 - acc: 0.9958 - mDice: 0.9290 - val_loss: -1.4503e-03 - val_acc: 0.9939 - val_mDice: 0.5157

Epoch 00016: val_mDice did not improve from 0.52203
Epoch 17/300
 - 76s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9310 - val_loss: 0.0117 - val_acc: 0.9935 - val_mDice: 0.4889

Epoch 00017: val_mDice did not improve from 0.52203
Epoch 18/300
 - 78s - loss: 0.0364 - acc: 0.9958 - mDice: 0.9293 - val_loss: 0.0632 - val_acc: 0.9927 - val_mDice: 0.4984

Epoch 00018: val_mDice did not improve from 0.52203
Epoch 19/300
 - 76s - loss: 0.0351 - acc: 0.9959 - mDice: 0.9317 - val_loss: 0.0744 - val_acc: 0.9932 - val_mDice: 0.4903

Epoch 00019: val_mDice did not improve from 0.52203
Epoch 20/300
 - 76s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9322 - val_loss: -2.2535e-02 - val_acc: 0.9938 - val_mDice: 0.4950

Epoch 00020: val_mDice did not improve from 0.52203
Epoch 21/300
 - 76s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9323 - val_loss: -9.0880e-03 - val_acc: 0.9937 - val_mDice: 0.5081

Epoch 00021: val_mDice did not improve from 0.52203
Epoch 22/300
 - 77s - loss: 0.0342 - acc: 0.9960 - mDice: 0.9335 - val_loss: 0.0314 - val_acc: 0.9938 - val_mDice: 0.5130

Epoch 00022: val_mDice did not improve from 0.52203
Epoch 23/300
 - 77s - loss: 0.0338 - acc: 0.9960 - mDice: 0.9344 - val_loss: -2.7153e-03 - val_acc: 0.9937 - val_mDice: 0.5184

Epoch 00023: val_mDice did not improve from 0.52203
Epoch 24/300
 - 76s - loss: 0.0334 - acc: 0.9961 - mDice: 0.9350 - val_loss: 0.0647 - val_acc: 0.9939 - val_mDice: 0.5093

Epoch 00024: val_mDice did not improve from 0.52203

Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 25/300
 - 76s - loss: 0.0309 - acc: 0.9962 - mDice: 0.9400 - val_loss: -3.5208e-02 - val_acc: 0.9940 - val_mDice: 0.5202

Epoch 00025: val_mDice did not improve from 0.52203
Epoch 26/300
 - 76s - loss: 0.0307 - acc: 0.9963 - mDice: 0.9404 - val_loss: -2.1337e-03 - val_acc: 0.9939 - val_mDice: 0.5170

Epoch 00026: val_mDice did not improve from 0.52203
Epoch 27/300
 - 76s - loss: 0.0307 - acc: 0.9963 - mDice: 0.9404 - val_loss: -3.1920e-02 - val_acc: 0.9940 - val_mDice: 0.5136

Epoch 00027: val_mDice did not improve from 0.52203
Epoch 28/300
 - 76s - loss: 0.0299 - acc: 0.9963 - mDice: 0.9420 - val_loss: 0.0683 - val_acc: 0.9934 - val_mDice: 0.5093

Epoch 00028: val_mDice did not improve from 0.52203
Epoch 29/300
 - 76s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9426 - val_loss: -3.1446e-02 - val_acc: 0.9941 - val_mDice: 0.5126

Epoch 00029: val_mDice did not improve from 0.52203
Epoch 30/300
 - 76s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9420 - val_loss: -3.5507e-02 - val_acc: 0.9942 - val_mDice: 0.5208

Epoch 00030: val_mDice did not improve from 0.52203
Epoch 31/300
 - 76s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9425 - val_loss: -1.3976e-03 - val_acc: 0.9941 - val_mDice: 0.5185

Epoch 00031: val_mDice did not improve from 0.52203
Epoch 32/300
 - 76s - loss: 0.0295 - acc: 0.9964 - mDice: 0.9427 - val_loss: 5.2885e-04 - val_acc: 0.9936 - val_mDice: 0.5118

Epoch 00032: val_mDice did not improve from 0.52203
Epoch 33/300
 - 76s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9445 - val_loss: -1.0309e-03 - val_acc: 0.9940 - val_mDice: 0.5147

Epoch 00033: val_mDice did not improve from 0.52203
Epoch 34/300
 - 76s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9445 - val_loss: 0.0253 - val_acc: 0.9939 - val_mDice: 0.5218

Epoch 00034: val_mDice did not improve from 0.52203
Epoch 35/300
 - 76s - loss: 0.0284 - acc: 0.9964 - mDice: 0.9449 - val_loss: 0.0684 - val_acc: 0.9937 - val_mDice: 0.5019

Epoch 00035: val_mDice did not improve from 0.52203
Epoch 36/300
 - 75s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9444 - val_loss: -2.5935e-02 - val_acc: 0.9940 - val_mDice: 0.5016

Epoch 00036: val_mDice did not improve from 0.52203
Epoch 37/300
 - 75s - loss: 0.0281 - acc: 0.9965 - mDice: 0.9455 - val_loss: 0.0361 - val_acc: 0.9935 - val_mDice: 0.5033

Epoch 00037: val_mDice did not improve from 0.52203
Epoch 38/300
 - 75s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9422 - val_loss: 0.0012 - val_acc: 0.9937 - val_mDice: 0.5127

Epoch 00038: val_mDice did not improve from 0.52203
Epoch 39/300
 - 75s - loss: 0.0288 - acc: 0.9965 - mDice: 0.9441 - val_loss: -6.5504e-03 - val_acc: 0.9921 - val_mDice: 0.4636

Epoch 00039: val_mDice did not improve from 0.52203

Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 40/300
 - 75s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9458 - val_loss: -5.2141e-03 - val_acc: 0.9941 - val_mDice: 0.5231

Epoch 00040: val_mDice improved from 0.52203 to 0.52311, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 41/300
 - 76s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9475 - val_loss: -2.3984e-03 - val_acc: 0.9941 - val_mDice: 0.5177

Epoch 00041: val_mDice did not improve from 0.52311
Epoch 42/300
 - 75s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9474 - val_loss: -2.1179e-02 - val_acc: 0.9934 - val_mDice: 0.5034

Epoch 00042: val_mDice did not improve from 0.52311
Epoch 43/300
 - 75s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9487 - val_loss: -2.9745e-02 - val_acc: 0.9940 - val_mDice: 0.5139

Epoch 00043: val_mDice did not improve from 0.52311
Epoch 44/300
 - 75s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9465 - val_loss: -5.4406e-04 - val_acc: 0.9940 - val_mDice: 0.5138

Epoch 00044: val_mDice did not improve from 0.52311
Epoch 45/300
 - 75s - loss: 0.0266 - acc: 0.9966 - mDice: 0.9484 - val_loss: -3.3675e-04 - val_acc: 0.9942 - val_mDice: 0.5132

Epoch 00045: val_mDice did not improve from 0.52311
Epoch 46/300
 - 75s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9493 - val_loss: -5.7332e-04 - val_acc: 0.9940 - val_mDice: 0.5138

Epoch 00046: val_mDice did not improve from 0.52311
Epoch 47/300
 - 78s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9494 - val_loss: -2.6195e-02 - val_acc: 0.9935 - val_mDice: 0.5023

Epoch 00047: val_mDice did not improve from 0.52311
Epoch 48/300
 - 78s - loss: 0.0259 - acc: 0.9966 - mDice: 0.9498 - val_loss: 0.0254 - val_acc: 0.9922 - val_mDice: 0.4627

Epoch 00048: val_mDice did not improve from 0.52311
Epoch 49/300
 - 78s - loss: 0.0259 - acc: 0.9966 - mDice: 0.9497 - val_loss: -2.7975e-03 - val_acc: 0.9942 - val_mDice: 0.5182

Epoch 00049: val_mDice did not improve from 0.52311
Epoch 50/300
 - 76s - loss: 0.0255 - acc: 0.9966 - mDice: 0.9505 - val_loss: 9.6358e-04 - val_acc: 0.9939 - val_mDice: 0.5108

Epoch 00050: val_mDice did not improve from 0.52311
Epoch 51/300
 - 76s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9495 - val_loss: -3.8674e-04 - val_acc: 0.9940 - val_mDice: 0.5134

Epoch 00051: val_mDice did not improve from 0.52311
Epoch 52/300
 - 76s - loss: 0.0258 - acc: 0.9966 - mDice: 0.9499 - val_loss: -2.5067e-03 - val_acc: 0.9942 - val_mDice: 0.5176

Epoch 00052: val_mDice did not improve from 0.52311
Epoch 53/300
 - 75s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: 0.0027 - val_acc: 0.9939 - val_mDice: 0.5072

Epoch 00053: val_mDice did not improve from 0.52311
Epoch 54/300
 - 75s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9493 - val_loss: -2.2775e-05 - val_acc: 0.9942 - val_mDice: 0.5126

Epoch 00054: val_mDice did not improve from 0.52311
Epoch 55/300
 - 75s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9495 - val_loss: -1.7750e-02 - val_acc: 0.9939 - val_mDice: 0.5032

Epoch 00055: val_mDice did not improve from 0.52311

Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 56/300
 - 75s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: -2.6833e-02 - val_acc: 0.9940 - val_mDice: 0.5114

Epoch 00056: val_mDice did not improve from 0.52311
Epoch 57/300
 - 75s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9510 - val_loss: -2.6713e-02 - val_acc: 0.9939 - val_mDice: 0.5032

Epoch 00057: val_mDice did not improve from 0.52311
Epoch 58/300
 - 75s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9509 - val_loss: 0.0040 - val_acc: 0.9938 - val_mDice: 0.5047

Epoch 00058: val_mDice did not improve from 0.52311
Epoch 59/300
 - 75s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9509 - val_loss: -2.4487e-02 - val_acc: 0.9937 - val_mDice: 0.4988

Epoch 00059: val_mDice did not improve from 0.52311
Epoch 60/300
 - 75s - loss: 0.0247 - acc: 0.9967 - mDice: 0.9521 - val_loss: 0.0035 - val_acc: 0.9940 - val_mDice: 0.5056

Epoch 00060: val_mDice did not improve from 0.52311
Epoch 61/300
 - 75s - loss: 0.0248 - acc: 0.9967 - mDice: 0.9520 - val_loss: 0.0014 - val_acc: 0.9941 - val_mDice: 0.5098

Epoch 00061: val_mDice did not improve from 0.52311
Epoch 62/300
 - 75s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: 0.0016 - val_acc: 0.9941 - val_mDice: 0.5093

Epoch 00062: val_mDice did not improve from 0.52311
Epoch 63/300
 - 75s - loss: 0.0247 - acc: 0.9967 - mDice: 0.9521 - val_loss: 0.0016 - val_acc: 0.9941 - val_mDice: 0.5094

Epoch 00063: val_mDice did not improve from 0.52311
Epoch 64/300
 - 75s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9510 - val_loss: 0.0034 - val_acc: 0.9939 - val_mDice: 0.5058

Epoch 00064: val_mDice did not improve from 0.52311
Epoch 65/300
 - 75s - loss: 0.0243 - acc: 0.9967 - mDice: 0.9530 - val_loss: 0.0016 - val_acc: 0.9939 - val_mDice: 0.5094

Epoch 00065: val_mDice did not improve from 0.52311
Epoch 66/300
 - 75s - loss: 0.0245 - acc: 0.9967 - mDice: 0.9526 - val_loss: 0.0016 - val_acc: 0.9941 - val_mDice: 0.5095

Epoch 00066: val_mDice did not improve from 0.52311
Epoch 67/300
 - 75s - loss: 0.0244 - acc: 0.9967 - mDice: 0.9528 - val_loss: 0.0027 - val_acc: 0.9940 - val_mDice: 0.5072

Epoch 00067: val_mDice did not improve from 0.52311
Epoch 68/300
 - 75s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9514 - val_loss: 0.0056 - val_acc: 0.9940 - val_mDice: 0.5013

Epoch 00068: val_mDice did not improve from 0.52311
Epoch 69/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9517 - val_loss: 0.0027 - val_acc: 0.9940 - val_mDice: 0.5071

Epoch 00069: val_mDice did not improve from 0.52311
Epoch 70/300
 - 75s - loss: 0.0243 - acc: 0.9967 - mDice: 0.9530 - val_loss: 0.0033 - val_acc: 0.9940 - val_mDice: 0.5060

Epoch 00070: val_mDice did not improve from 0.52311

Epoch 00070: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 71/300
 - 75s - loss: 0.0242 - acc: 0.9967 - mDice: 0.9532 - val_loss: 0.0029 - val_acc: 0.9940 - val_mDice: 0.5068

Epoch 00071: val_mDice did not improve from 0.52311
Epoch 72/300
 - 75s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9537 - val_loss: 0.0043 - val_acc: 0.9939 - val_mDice: 0.5040

Epoch 00072: val_mDice did not improve from 0.52311
Epoch 73/300
 - 75s - loss: 0.0242 - acc: 0.9968 - mDice: 0.9531 - val_loss: 7.8469e-04 - val_acc: 0.9941 - val_mDice: 0.5110

Epoch 00073: val_mDice did not improve from 0.52311
Epoch 74/300
 - 75s - loss: 0.0245 - acc: 0.9968 - mDice: 0.9525 - val_loss: 0.0033 - val_acc: 0.9939 - val_mDice: 0.5061

Epoch 00074: val_mDice did not improve from 0.52311
Epoch 75/300
 - 75s - loss: 0.0239 - acc: 0.9967 - mDice: 0.9537 - val_loss: 6.5334e-04 - val_acc: 0.9940 - val_mDice: 0.5113

Epoch 00075: val_mDice did not improve from 0.52311
Epoch 76/300
 - 76s - loss: 0.0241 - acc: 0.9968 - mDice: 0.9534 - val_loss: 0.0010 - val_acc: 0.9940 - val_mDice: 0.5106

Epoch 00076: val_mDice did not improve from 0.52311
Epoch 77/300
 - 76s - loss: 0.0240 - acc: 0.9968 - mDice: 0.9536 - val_loss: 0.0035 - val_acc: 0.9939 - val_mDice: 0.5056

Epoch 00077: val_mDice did not improve from 0.52311
Epoch 78/300
 - 75s - loss: 0.0237 - acc: 0.9968 - mDice: 0.9540 - val_loss: 0.0016 - val_acc: 0.9939 - val_mDice: 0.5094

Epoch 00078: val_mDice did not improve from 0.52311
Epoch 79/300
 - 75s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9538 - val_loss: 0.0043 - val_acc: 0.9939 - val_mDice: 0.5040

Epoch 00079: val_mDice did not improve from 0.52311
Epoch 80/300
 - 75s - loss: 0.0236 - acc: 0.9967 - mDice: 0.9544 - val_loss: 0.0028 - val_acc: 0.9940 - val_mDice: 0.5071

Epoch 00080: val_mDice did not improve from 0.52311
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [0.259117843126351, -0.007462554945136016, 0.03871003824210017, 0.05022531054304831, 0.04601260077840877, 0.1643071231320969, 0.11947703422427927, 0.007791413029409804, 0.10850402014622898, 0.009847299154824431, 0.07247636860833978, 0.14424616768487594, 0.002202200533459022, -0.023640379497090226, -0.019641618589935062, -0.001450340984002599, 0.011732466940609913, 0.0631683277165365, 0.07440792145968983, -0.022535033149164427, -0.009088026137097078, 0.031386760233333276, -0.0027153034630061695, 0.06465152768219042, -0.03520826151910818, -0.0021337038784656885, -0.031919685362270044, 0.06826980093365195, -0.03144571714618671, -0.035506609007247586, -0.0013976258770474848, 0.0005288461469254404, -0.0010309457872648658, 0.02526185816189028, 0.0683534636437518, -0.025934614287982195, 0.03612856744970166, 0.001164023184551383, -0.006550445543520106, -0.005214070514687952, -0.002398378584744795, -0.021178641128090193, -0.029745257781736506, -0.0005440576084005008, -0.0003367484834209178, -0.0005733180064825142, -0.026194772864662628, 0.02536020441999975, -0.0027975058593090224, 0.0009635759037245745, -0.0003867444096121398, -0.002506716680601708, 0.0027350588883244017, -2.277478481988487e-05, -0.01775016907438542, -0.02683264841823458, -0.026713025644890167, 0.0039764743930888625, -0.02448669118138979, 0.0034546816498978333, 0.001399508812142618, 0.0016422562254299908, 0.001595057968823415, 0.0033938853808169094, 0.001637776270977356, 0.001572936398428191, 0.00271681269759652, 0.005649657369409717, 0.0027227122453773547, 0.0033119833506878066, 0.0029059515434241147, 0.004321664946634065, 0.0007846949610320277, 0.0032532342106291333, 0.0006533355083105699, 0.0010069395948506, 0.0035073453056737314, 0.001604079028720376, 0.004330439153332381, 0.002756383106018762], 'val_acc': [0.9811145063466246, 0.9928095655621223, 0.9936414147323033, 0.9936918642535899, 0.9933344294440072, 0.9928128363201453, 0.9935733915874793, 0.9933128443154149, 0.994109793654028, 0.9935379924264344, 0.993399940196823, 0.9922706477297177, 0.9941143149849754, 0.9933778564884977, 0.9936263535007741, 0.9938858979902927, 0.9935154045152964, 0.9927367710467404, 0.9932086711409707, 0.993760643890069, 0.9937408150367018, 0.9937885025012418, 0.9936973842434913, 0.9938615500552099, 0.9939722385046617, 0.9938590384129459, 0.993952917602827, 0.9934132462777432, 0.9941271206118026, 0.9941697847918145, 0.9941376545144327, 0.9935668650663124, 0.9939812822911724, 0.9939471408256195, 0.993663748855111, 0.993951659907335, 0.9934702211955808, 0.9937325303659499, 0.9921466457019062, 0.9940786721571436, 0.9940834461518053, 0.993373082493836, 0.9940362516439186, 0.993985799498528, 0.9942061867354051, 0.9939958404445048, 0.9935480389954909, 0.9922119052904956, 0.994155725218215, 0.9939248003299881, 0.9940036209124439, 0.9941783243755125, 0.9939461399174336, 0.994222750453829, 0.993947390115486, 0.9940314851466965, 0.9939220393978575, 0.993823897913567, 0.9937448280412446, 0.9940041213665368, 0.9940718963461103, 0.9940967466096459, 0.9941032731308127, 0.9939195352530329, 0.9938981994143072, 0.9940515632899303, 0.994030476741071, 0.9939584357183684, 0.9939895669619242, 0.9939777641176427, 0.9939960934830911, 0.9938979388782813, 0.9941225977813672, 0.9939007073078515, 0.994007131588534, 0.994043526034685, 0.9938678235377906, 0.9939077324087515, 0.9939072338290185, 0.9940098981437443], 'val_mDice': [0.3784847472437054, 0.465271938475048, 0.4919580619419052, 0.4753007005121114, 0.5000468401829558, 0.49162132513223206, 0.4913737077009372, 0.5106051170132445, 0.522026446817806, 0.499440868789295, 0.49523548416371616, 0.488538948830756, 0.5096096892214421, 0.497315284450474, 0.4892137686505258, 0.5157000070098061, 0.4888904054865897, 0.4983909395318361, 0.490287659491496, 0.49500021163913066, 0.5081294458242333, 0.5130023923966119, 0.5183532501354158, 0.5092948163221093, 0.5202001494900236, 0.5169613980365999, 0.5136382214303287, 0.509273454033574, 0.5126047654534286, 0.520769549803164, 0.5185385511122035, 0.5117587889281084, 0.5147323601603883, 0.5217909119414084, 0.5018858242569104, 0.5016323637639014, 0.5032620737153404, 0.5127279875132272, 0.46361515260665825, 0.523110346974067, 0.5176620067056245, 0.5033875503958022, 0.5139435550092526, 0.5138033596833922, 0.5132469399422173, 0.513799547118211, 0.5023214530270055, 0.4626563093009985, 0.5181842325430996, 0.5107794964463456, 0.5133742677434435, 0.5176085346149948, 0.5072048596990933, 0.5125999766981827, 0.5031910936974879, 0.511375405128647, 0.5031621568607834, 0.504718339949284, 0.49880406309692366, 0.5056492371613499, 0.5097942131589044, 0.5092708841434814, 0.5093870832110351, 0.5058477126624225, 0.509374386297082, 0.5094811028607611, 0.5071859642769556, 0.5013378110036357, 0.5071415583480079, 0.5059904890990107, 0.5067838922892727, 0.5039747183521589, 0.5110070101167046, 0.506124013812287, 0.511290090240585, 0.5105585567418884, 0.5056288789184589, 0.5094363497066423, 0.5039668324514754, 0.5070755269917302], 'loss': [0.0981775293343678, 0.06325781467840183, 0.05847512459789883, 0.051909640793804515, 0.0487473894558321, 0.048850888323645605, 0.04517905582667111, 0.04358348932166473, 0.04216949976971394, 0.040732222395730926, 0.04101107311340959, 0.038995518022253796, 0.03860349581853562, 0.03611276113379623, 0.0377744791936803, 0.03651980318948645, 0.03550494721786106, 0.03642286240485845, 0.03513896215988621, 0.034905265110720715, 0.03485486662374467, 0.03422864516381612, 0.03377051834350633, 0.03344754462406117, 0.03088803269409515, 0.03067286812228049, 0.03068043654991314, 0.029886134544953827, 0.02956687756687455, 0.029894703907632388, 0.029603706317356503, 0.029498047990100466, 0.028589368254005775, 0.02861259227684086, 0.028386444601409898, 0.028639536960541563, 0.028093478795030404, 0.02979556444161668, 0.02880685421598466, 0.027934071064054832, 0.027052174992515547, 0.027123845954783156, 0.026454212436260623, 0.027577435243275435, 0.026581958411124377, 0.026135545000006474, 0.026109649269405105, 0.0258907794982128, 0.025924942926609417, 0.025526352147749457, 0.026029504626528466, 0.02581894955088831, 0.025386227166104062, 0.02614177789480557, 0.026031314966148734, 0.0253958056615115, 0.025276972907838098, 0.02534212449128326, 0.02534356238550455, 0.02473390137697283, 0.024800138589367363, 0.025370079906920775, 0.02469818914775154, 0.025252723056766332, 0.0242688389163744, 0.02448302484448487, 0.02437051612466581, 0.02504764575707285, 0.024918028815789067, 0.024270586533777196, 0.024159334613910247, 0.02392224577945734, 0.024188600716581365, 0.02451498142168777, 0.023890677957530033, 0.024068736712603712, 0.023956740967767676, 0.023736453755675305, 0.023838001554499662, 0.02357067017502159], 'acc': [0.9894692364491915, 0.9933266907699925, 0.9939278750890626, 0.9944488326564754, 0.9947150463354977, 0.9947989188798142, 0.9950184922959924, 0.9951473724503088, 0.9953117588789097, 0.9954134826054744, 0.9954325760963046, 0.9955680121965734, 0.9956547818923717, 0.9957441352986136, 0.9956793119170535, 0.995791521295998, 0.995824887809625, 0.9957582720662924, 0.995914718209136, 0.9959319361979659, 0.9959466409641597, 0.9960205583359482, 0.9960475812591083, 0.9960938634852217, 0.9962362433481942, 0.9962949293469753, 0.9963110680144812, 0.9963326005603822, 0.9963542525311544, 0.9963519785225198, 0.9963767719509655, 0.9963742475998494, 0.9964324207964845, 0.9964516593143808, 0.996443032750051, 0.9964288981604915, 0.9964587673503997, 0.996343988942874, 0.99648172495876, 0.9965416151304499, 0.9965547311630116, 0.9965818897168456, 0.996552287104957, 0.9965837719985213, 0.99659769919841, 0.996580236918256, 0.9966129554822636, 0.9966144339123638, 0.996629018606941, 0.9966462268945908, 0.9966512276484621, 0.9966407951853108, 0.996658644583434, 0.9966408398256066, 0.9966509735295825, 0.9966771810258169, 0.9966946527246645, 0.9966963656185333, 0.996705145335132, 0.9967267785354218, 0.996698833977858, 0.9967038661323304, 0.9967129853530607, 0.9966992218615142, 0.9967111531458284, 0.9967331749582921, 0.9967190827640044, 0.9967368479216893, 0.9967148115388709, 0.9967452357849536, 0.9967402833660037, 0.9967456384842817, 0.9967502628546696, 0.9967586748853946, 0.9967389438374734, 0.9967597294817188, 0.9967565045864631, 0.9967568477257496, 0.9967618552592961, 0.9967434038602078], 'mDice': [0.80915316633718, 0.8769107717426683, 0.8861515342150358, 0.8990004226010377, 0.9051790936655105, 0.9049265728569753, 0.9121501653977152, 0.9152712099492014, 0.9180018567598857, 0.920817043131413, 0.9202473756203734, 0.9242070797124353, 0.9249453884046492, 0.929873671019336, 0.9265847240162776, 0.9290379453966255, 0.9310438601073853, 0.9292517261257653, 0.9317260708601346, 0.9321796346718785, 0.9322789698935827, 0.9334907004603664, 0.9343959870303352, 0.9350120292390292, 0.9400419224435536, 0.940444305698959, 0.9404204364547292, 0.9419942430856372, 0.9426192422851597, 0.9419604377088389, 0.9425250143741961, 0.9427457310428462, 0.94453104024339, 0.9444793766500588, 0.9449292162791485, 0.9444301820776653, 0.9455032730881607, 0.942164974115709, 0.944068598380021, 0.9457773342338337, 0.9475343113499824, 0.9473765073541573, 0.9487166459065597, 0.9464622604620965, 0.9484493864180293, 0.949343960774037, 0.9493847596478837, 0.9498213745949124, 0.9497497346476148, 0.9505307250083549, 0.949525929740255, 0.9499463821385203, 0.9508079054290798, 0.9493020829394084, 0.9495145434095069, 0.9507697370469228, 0.9510042117060673, 0.9508613667737281, 0.9508626006671871, 0.9520765301012047, 0.9519504001087665, 0.9508066722344032, 0.952145261341094, 0.9510324613713184, 0.9530050595834327, 0.9525678876734458, 0.9527922403815382, 0.9514322504568469, 0.9516980067754095, 0.9529845000287189, 0.9532060673570478, 0.9536776340611411, 0.9531348003699435, 0.9524837762347835, 0.9537376842911507, 0.9533734566837095, 0.9535991743738499, 0.9540379063822617, 0.9538347485372329, 0.9543720751026974], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.08it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.38it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.76it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.08it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.63it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.77it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:37,  6.54it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:36,  6.65it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:36,  6.68it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:36,  6.60it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:36,  6.60it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:36,  6.60it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:36,  6.65it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:35,  6.69it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:36,  6.58it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:35,  6.61it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:35,  6.65it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:35,  6.67it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:34,  6.69it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:34,  6.71it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:34,  6.73it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:34,  6.73it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:34,  6.75it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:33,  6.74it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:33,  6.71it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:34,  6.64it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:33,  6.66it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:33,  6.68it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.78it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:32,  6.88it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:31,  6.95it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:31,  7.01it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:31,  7.02it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:31,  7.03it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:30,  7.04it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:30,  7.05it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:30,  7.07it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:30,  7.04it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:30,  7.01it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:30,  6.92it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:30,  6.85it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:30,  6.86it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:30,  6.87it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:30,  6.92it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:29,  6.96it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:29,  6.96it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:29,  6.96it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:29,  7.00it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:29,  7.00it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:28,  7.00it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:28,  6.99it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:28,  7.03it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:28,  7.06it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:28,  7.05it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:27,  7.07it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:27,  7.07it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:28,  6.84it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.89it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:27,  6.93it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:27,  6.98it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:27,  6.98it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:27,  6.99it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:27,  7.00it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:26,  7.01it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:27,  6.88it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:27,  6.78it/s]predicting train subjects:  25%|██▍       | 61/247 [00:08<00:27,  6.73it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:27,  6.71it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:27,  6.67it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:27,  6.66it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:27,  6.63it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:27,  6.61it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:27,  6.56it/s]predicting train subjects:  28%|██▊       | 68/247 [00:09<00:27,  6.58it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:27,  6.58it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.55it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:26,  6.58it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:26,  6.61it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:26,  6.59it/s]predicting train subjects:  30%|██▉       | 74/247 [00:10<00:26,  6.61it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:25,  6.63it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:25,  6.64it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:27,  6.27it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:27,  6.14it/s]predicting train subjects:  32%|███▏      | 79/247 [00:11<00:34,  4.88it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:40,  4.13it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:39,  4.19it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:36,  4.56it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:33,  4.85it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:31,  5.11it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:30,  5.27it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:29,  5.40it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:29,  5.51it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:28,  5.60it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:28,  5.62it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:27,  5.66it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:27,  5.68it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:27,  5.72it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:26,  5.71it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:26,  5.74it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:26,  5.73it/s]predicting train subjects:  39%|███▉      | 96/247 [00:14<00:26,  5.72it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:26,  5.73it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:25,  5.74it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:25,  5.74it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:25,  5.80it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:24,  5.84it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:24,  5.88it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:24,  5.90it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:24,  5.91it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:23,  5.94it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:23,  5.90it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:24,  5.77it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:23,  5.80it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:24,  5.73it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:23,  5.79it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:23,  5.83it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:23,  5.85it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:22,  5.88it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:23,  5.76it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:23,  5.70it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:22,  5.76it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:22,  5.82it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:20,  6.16it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:20,  6.38it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:19,  6.57it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:18,  6.69it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:18,  6.78it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:18,  6.88it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:17,  6.92it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:17,  6.96it/s]predicting train subjects:  51%|█████     | 126/247 [00:19<00:17,  6.88it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:17,  6.88it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:17,  6.94it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:16,  6.99it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:20<00:16,  7.02it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:16,  7.04it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:16,  7.05it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:20<00:16,  7.08it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:15,  7.07it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:15,  7.10it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:15,  7.09it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:21<00:15,  7.07it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:15,  7.08it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:21<00:15,  7.07it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:21<00:15,  7.07it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:15,  7.03it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:14,  7.04it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:14,  7.04it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:22<00:14,  7.04it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:14,  7.03it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:22<00:14,  7.04it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:22<00:14,  6.97it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:14,  6.96it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:14,  6.82it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:14,  6.89it/s]predicting train subjects:  61%|██████    | 151/247 [00:23<00:13,  6.91it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:13,  6.90it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:23<00:13,  6.93it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:23<00:14,  6.61it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:14,  6.41it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:14,  6.29it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:24<00:14,  6.21it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:24<00:14,  6.15it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:24<00:14,  6.12it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:24<00:14,  6.07it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:14,  6.05it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:14,  6.04it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:25<00:14,  6.00it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:25<00:13,  5.99it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:25<00:13,  5.99it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:25<00:13,  5.99it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:13,  6.00it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:13,  6.02it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:12,  6.01it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:26<00:12,  6.02it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:26<00:12,  6.04it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:26<00:12,  6.24it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:15,  4.91it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:13,  5.32it/s]predicting train subjects:  71%|███████   | 175/247 [00:27<00:14,  5.03it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:27<00:13,  5.43it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:27<00:12,  5.76it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  6.03it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:10,  6.26it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.28it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:28<00:10,  6.45it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:28<00:09,  6.57it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:28<00:09,  6.67it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:28<00:09,  6.73it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.78it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:08,  6.82it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:08,  6.79it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:29<00:08,  6.77it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:29<00:08,  6.71it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:29<00:08,  6.73it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:29<00:08,  6.76it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:08,  6.79it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:07,  6.83it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:30<00:07,  6.93it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:30<00:07,  7.03it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:30<00:07,  6.95it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:30<00:07,  6.92it/s]predicting train subjects:  80%|████████  | 198/247 [00:30<00:07,  6.98it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:06,  7.07it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  7.13it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:31<00:06,  7.14it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:31<00:06,  7.14it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:31<00:06,  7.13it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:31<00:06,  7.15it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:31<00:05,  7.10it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  7.14it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  7.18it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:32<00:05,  7.18it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:32<00:05,  7.20it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:32<00:05,  7.23it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:32<00:04,  7.22it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:32<00:04,  7.10it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:04,  7.07it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  7.06it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:33<00:04,  7.06it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  7.05it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:33<00:04,  7.02it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:33<00:04,  6.52it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:33<00:04,  6.42it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:04,  6.58it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:34<00:03,  6.68it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:34<00:03,  6.76it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  6.47it/s]predicting train subjects:  91%|█████████ | 224/247 [00:34<00:03,  6.58it/s]predicting train subjects:  91%|█████████ | 225/247 [00:34<00:03,  6.42it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:03,  6.01it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:03,  5.83it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:35<00:03,  5.83it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:35<00:03,  5.96it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:03,  5.60it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:35<00:02,  5.44it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  5.18it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  5.03it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:36<00:02,  4.89it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:36<00:02,  5.08it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:02,  5.05it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:02,  4.95it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  5.07it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:37<00:01,  5.28it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:37<00:01,  5.26it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:37<00:01,  5.18it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:38<00:00,  5.14it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  5.20it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  5.42it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:38<00:00,  5.61it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:38<00:00,  5.37it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  5.03it/s]predicting train subjects: 100%|██████████| 247/247 [00:39<00:00,  6.32it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  4.91it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  4.95it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  4.88it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  5.41it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  5.47it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  5.37it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:41,  5.99it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:40,  6.00it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:41,  5.90it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:40,  5.97it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:42,  5.67it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:01<00:44,  5.46it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:43,  5.49it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:43,  5.55it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:41,  5.77it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:40,  5.80it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:41,  5.73it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:02<00:41,  5.70it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:02<00:42,  5.45it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:42,  5.46it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:41,  5.55it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:42,  5.46it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:03<00:39,  5.77it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:03<00:39,  5.81it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:03<00:41,  5.49it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:42,  5.38it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:40,  5.64it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:40,  5.60it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:04<00:39,  5.63it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:04<00:38,  5.75it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:04<00:39,  5.66it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:04<00:39,  5.61it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:37,  5.90it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:39,  5.58it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:05<00:38,  5.61it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:05<00:38,  5.60it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:05<00:38,  5.68it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:05<00:37,  5.77it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:05<00:37,  5.74it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:06<00:36,  5.78it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:06<00:36,  5.86it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:06<00:34,  6.15it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:06<00:32,  6.38it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:06<00:33,  6.30it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:06<00:32,  6.33it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:06<00:35,  5.88it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:07<00:36,  5.67it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:07<00:35,  5.74it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:07<00:35,  5.74it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:07<00:36,  5.54it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:07<00:36,  5.49it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:08<00:36,  5.54it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:08<00:35,  5.67it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:08<00:34,  5.81it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:08<00:32,  6.03it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:08<00:32,  6.10it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:08<00:33,  5.85it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:09<00:31,  6.12it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:09<00:32,  6.03it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:09<00:32,  5.96it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:09<00:31,  6.00it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:09<00:32,  5.85it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:09<00:34,  5.54it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:10<00:35,  5.36it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:10<00:34,  5.49it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:10<00:32,  5.77it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:10<00:30,  6.00it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:10<00:30,  6.15it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:10<00:29,  6.18it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:11<00:29,  6.20it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:11<00:29,  6.23it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:11<00:28,  6.35it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:11<00:28,  6.38it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:11<00:27,  6.43it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:11<00:27,  6.49it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:12<00:27,  6.53it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:12<00:26,  6.54it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:12<00:26,  6.51it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:12<00:26,  6.56it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:12<00:26,  6.54it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:12<00:26,  6.55it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:12<00:26,  6.56it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:13<00:27,  6.25it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:13<00:27,  6.12it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:13<00:26,  6.36it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:13<00:25,  6.45it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:13<00:26,  6.29it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:13<00:26,  6.11it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:14<00:27,  6.02it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:14<00:27,  5.95it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:14<00:27,  5.87it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:14<00:27,  5.82it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:14<00:27,  5.77it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:14<00:27,  5.77it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:15<00:27,  5.75it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:15<00:27,  5.75it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:15<00:27,  5.73it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:15<00:27,  5.68it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:15<00:27,  5.70it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:16<00:26,  5.68it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:16<00:26,  5.66it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:16<00:26,  5.68it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:16<00:26,  5.68it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:16<00:26,  5.69it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:16<00:25,  5.73it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:17<00:25,  5.79it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:17<00:24,  5.86it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:17<00:24,  5.89it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:17<00:24,  5.89it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:17<00:24,  5.92it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:17<00:23,  5.93it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:18<00:24,  5.82it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:18<00:23,  5.84it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:18<00:23,  5.84it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:18<00:23,  5.81it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:18<00:23,  5.84it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:18<00:23,  5.83it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:19<00:23,  5.76it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:19<00:23,  5.82it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:19<00:22,  5.82it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:19<00:22,  5.81it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:19<00:22,  5.83it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:19<00:22,  5.84it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:20<00:20,  6.19it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:20<00:19,  6.44it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:20<00:19,  6.39it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:20<00:19,  6.58it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:20<00:18,  6.76it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:20<00:18,  6.86it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:20<00:17,  6.90it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:21<00:17,  7.00it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:21<00:17,  7.05it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:21<00:16,  7.09it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:21<00:16,  7.11it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:21<00:16,  7.14it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:21<00:16,  7.10it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:21<00:16,  7.10it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:22<00:16,  7.12it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:22<00:15,  7.14it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:22<00:15,  7.13it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:22<00:15,  7.14it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:22<00:15,  7.08it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:22<00:15,  7.09it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:22<00:15,  7.08it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:23<00:15,  7.06it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:23<00:15,  7.06it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:23<00:15,  7.03it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:23<00:14,  7.02it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:23<00:14,  7.00it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:23<00:14,  7.02it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:23<00:14,  7.01it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:24<00:14,  7.02it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:24<00:14,  7.03it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:24<00:14,  7.05it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:24<00:13,  7.06it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:24<00:13,  7.06it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:24<00:13,  7.04it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:24<00:13,  7.03it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:25<00:13,  7.03it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:25<00:13,  6.67it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:25<00:14,  6.39it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:25<00:14,  6.27it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:25<00:14,  6.01it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:25<00:14,  6.00it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:26<00:14,  5.99it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:26<00:14,  5.97it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:26<00:14,  5.97it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:26<00:14,  5.98it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:26<00:14,  5.97it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:26<00:13,  5.97it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:27<00:13,  5.98it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:27<00:13,  5.99it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:27<00:13,  5.97it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:27<00:13,  5.99it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:27<00:13,  5.96it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:27<00:12,  5.93it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:28<00:12,  5.95it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:28<00:12,  6.17it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:28<00:11,  6.45it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:28<00:11,  6.60it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:28<00:11,  6.41it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:28<00:11,  6.32it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:29<00:10,  6.43it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:29<00:10,  6.55it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:29<00:10,  6.62it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:29<00:10,  6.65it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:29<00:09,  6.72it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:29<00:09,  6.75it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:29<00:09,  6.77it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:30<00:09,  6.80it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:30<00:09,  6.82it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:30<00:08,  6.85it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:30<00:08,  6.88it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:30<00:08,  6.90it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:30<00:08,  6.90it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:30<00:08,  6.87it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:31<00:08,  6.88it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:31<00:07,  6.91it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:31<00:07,  6.87it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:31<00:07,  6.96it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:31<00:07,  7.06it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:31<00:07,  6.94it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:31<00:07,  6.84it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:32<00:07,  6.75it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:32<00:07,  6.74it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:32<00:06,  6.84it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:32<00:06,  6.80it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:32<00:06,  6.90it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:32<00:06,  6.89it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:32<00:06,  6.92it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:33<00:06,  6.81it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:33<00:06,  6.75it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:33<00:06,  6.66it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:33<00:05,  6.76it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:33<00:05,  6.83it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:33<00:05,  6.88it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:33<00:05,  6.95it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:34<00:05,  6.76it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:34<00:05,  6.76it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:34<00:04,  6.65it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:34<00:04,  6.64it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:34<00:04,  6.70it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:34<00:04,  6.54it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:35<00:04,  6.57it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:35<00:04,  6.64it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:35<00:04,  6.62it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:35<00:03,  6.71it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:35<00:03,  6.75it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:35<00:03,  6.67it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:35<00:03,  6.71it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:36<00:03,  6.69it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:36<00:03,  6.73it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:36<00:02,  6.73it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:36<00:02,  6.78it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:36<00:02,  6.77it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:36<00:02,  6.26it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:37<00:02,  6.15it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:37<00:02,  6.06it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:37<00:02,  6.01it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:37<00:02,  6.01it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:37<00:01,  6.01it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:37<00:01,  5.99it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:38<00:01,  5.86it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:38<00:01,  5.87it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:38<00:01,  5.90it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:38<00:01,  5.90it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:38<00:01,  5.90it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:38<00:00,  5.91it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:39<00:00,  5.79it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:39<00:00,  5.82it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:39<00:00,  5.85it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:39<00:00,  5.87it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  5.88it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  6.22it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 80.55it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 85.08it/s]saving BB  train1-THALAMUS:   7%|▋         | 17/247 [00:00<00:02, 82.90it/s]saving BB  train1-THALAMUS:  11%|█         | 26/247 [00:00<00:02, 83.65it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 85.56it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 86.44it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 88.98it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 88.17it/s]saving BB  train1-THALAMUS:  30%|██▉       | 73/247 [00:00<00:02, 85.56it/s]saving BB  train1-THALAMUS:  33%|███▎      | 82/247 [00:00<00:01, 84.01it/s]saving BB  train1-THALAMUS:  37%|███▋      | 91/247 [00:01<00:01, 79.75it/s]saving BB  train1-THALAMUS:  40%|████      | 99/247 [00:01<00:01, 76.67it/s]saving BB  train1-THALAMUS:  43%|████▎     | 107/247 [00:01<00:01, 77.13it/s]saving BB  train1-THALAMUS:  47%|████▋     | 115/247 [00:01<00:01, 77.84it/s]saving BB  train1-THALAMUS:  50%|█████     | 124/247 [00:01<00:01, 79.55it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 133/247 [00:01<00:01, 80.07it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 142/247 [00:01<00:01, 82.73it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 152/247 [00:01<00:01, 85.36it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 161/247 [00:01<00:01, 84.15it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 170/247 [00:02<00:00, 82.88it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 179/247 [00:02<00:00, 82.58it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 188/247 [00:02<00:00, 83.15it/s]saving BB  train1-THALAMUS:  80%|███████▉  | 197/247 [00:02<00:00, 83.74it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 206/247 [00:02<00:00, 85.01it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 215/247 [00:02<00:00, 86.41it/s]saving BB  train1-THALAMUS:  91%|█████████ | 225/247 [00:02<00:00, 87.65it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 234/247 [00:02<00:00, 86.51it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 243/247 [00:02<00:00, 80.55it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:02<00:00, 82.99it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 85.66it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 81.15it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 82.31it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 83.80it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 37/247 [00:00<00:02, 85.91it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▊        | 46/247 [00:00<00:02, 86.70it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 56/247 [00:00<00:02, 88.78it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 65/247 [00:00<00:02, 87.38it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 74/247 [00:00<00:02, 85.50it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▎      | 83/247 [00:00<00:01, 82.87it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 91/247 [00:01<00:01, 78.82it/s]saving BB  train1-THALAMUS Sagittal:  40%|████      | 99/247 [00:01<00:01, 75.79it/s]saving BB  train1-THALAMUS Sagittal:  43%|████▎     | 107/247 [00:01<00:01, 76.42it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 115/247 [00:01<00:01, 77.22it/s]saving BB  train1-THALAMUS Sagittal:  50%|█████     | 124/247 [00:01<00:01, 78.80it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 133/247 [00:01<00:01, 79.41it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 143/247 [00:01<00:01, 82.70it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 153/247 [00:01<00:01, 85.20it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 162/247 [00:01<00:01, 82.74it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 171/247 [00:02<00:00, 80.90it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 180/247 [00:02<00:00, 81.25it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 189/247 [00:02<00:00, 80.67it/s]saving BB  train1-THALAMUS Sagittal:  80%|████████  | 198/247 [00:02<00:00, 81.67it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 207/247 [00:02<00:00, 83.64it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 216/247 [00:02<00:00, 84.32it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████ | 225/247 [00:02<00:00, 85.30it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▍| 234/247 [00:02<00:00, 83.78it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 243/247 [00:02<00:00, 79.89it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 82.26it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:12,  1.28it/s]Loading train:   1%|          | 2/247 [00:01<03:04,  1.33it/s]Loading train:   1%|          | 3/247 [00:02<02:58,  1.37it/s]Loading train:   2%|▏         | 4/247 [00:02<03:03,  1.32it/s]Loading train:   2%|▏         | 5/247 [00:03<02:44,  1.47it/s]Loading train:   2%|▏         | 6/247 [00:03<02:29,  1.61it/s]Loading train:   3%|▎         | 7/247 [00:04<02:17,  1.75it/s]Loading train:   3%|▎         | 8/247 [00:04<02:11,  1.81it/s]Loading train:   4%|▎         | 9/247 [00:05<02:07,  1.86it/s]Loading train:   4%|▍         | 10/247 [00:05<02:05,  1.89it/s]Loading train:   4%|▍         | 11/247 [00:06<02:02,  1.93it/s]Loading train:   5%|▍         | 12/247 [00:06<02:00,  1.95it/s]Loading train:   5%|▌         | 13/247 [00:07<02:00,  1.94it/s]Loading train:   6%|▌         | 14/247 [00:07<01:57,  1.98it/s]Loading train:   6%|▌         | 15/247 [00:08<01:57,  1.98it/s]Loading train:   6%|▋         | 16/247 [00:08<01:55,  1.99it/s]Loading train:   7%|▋         | 17/247 [00:09<01:54,  2.01it/s]Loading train:   7%|▋         | 18/247 [00:09<01:52,  2.03it/s]Loading train:   8%|▊         | 19/247 [00:10<01:51,  2.05it/s]Loading train:   8%|▊         | 20/247 [00:10<01:50,  2.06it/s]Loading train:   9%|▊         | 21/247 [00:11<01:50,  2.04it/s]Loading train:   9%|▉         | 22/247 [00:11<01:50,  2.04it/s]Loading train:   9%|▉         | 23/247 [00:12<01:47,  2.09it/s]Loading train:  10%|▉         | 24/247 [00:12<01:44,  2.13it/s]Loading train:  10%|█         | 25/247 [00:13<01:44,  2.13it/s]Loading train:  11%|█         | 26/247 [00:13<01:42,  2.15it/s]Loading train:  11%|█         | 27/247 [00:14<01:41,  2.17it/s]Loading train:  11%|█▏        | 28/247 [00:14<01:42,  2.14it/s]Loading train:  12%|█▏        | 29/247 [00:15<01:41,  2.14it/s]Loading train:  12%|█▏        | 30/247 [00:15<01:40,  2.16it/s]Loading train:  13%|█▎        | 31/247 [00:15<01:40,  2.14it/s]Loading train:  13%|█▎        | 32/247 [00:16<01:41,  2.12it/s]Loading train:  13%|█▎        | 33/247 [00:16<01:40,  2.12it/s]Loading train:  14%|█▍        | 34/247 [00:17<01:40,  2.12it/s]Loading train:  14%|█▍        | 35/247 [00:17<01:39,  2.14it/s]Loading train:  15%|█▍        | 36/247 [00:18<01:37,  2.16it/s]Loading train:  15%|█▍        | 37/247 [00:18<01:38,  2.13it/s]Loading train:  15%|█▌        | 38/247 [00:19<01:36,  2.16it/s]Loading train:  16%|█▌        | 39/247 [00:19<01:35,  2.17it/s]Loading train:  16%|█▌        | 40/247 [00:20<01:35,  2.17it/s]Loading train:  17%|█▋        | 41/247 [00:20<01:35,  2.16it/s]Loading train:  17%|█▋        | 42/247 [00:21<01:39,  2.06it/s]Loading train:  17%|█▋        | 43/247 [00:21<01:46,  1.92it/s]Loading train:  18%|█▊        | 44/247 [00:22<01:51,  1.83it/s]Loading train:  18%|█▊        | 45/247 [00:23<01:56,  1.74it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:54,  1.75it/s]Loading train:  19%|█▉        | 47/247 [00:24<01:55,  1.74it/s]Loading train:  19%|█▉        | 48/247 [00:24<01:56,  1.71it/s]Loading train:  20%|█▉        | 49/247 [00:25<01:58,  1.68it/s]Loading train:  20%|██        | 50/247 [00:26<02:00,  1.64it/s]Loading train:  21%|██        | 51/247 [00:26<01:59,  1.64it/s]Loading train:  21%|██        | 52/247 [00:27<01:58,  1.65it/s]Loading train:  21%|██▏       | 53/247 [00:27<01:57,  1.66it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:54,  1.69it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:54,  1.68it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:56,  1.64it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:52,  1.68it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:56,  1.62it/s]Loading train:  24%|██▍       | 59/247 [00:31<02:00,  1.56it/s]Loading train:  24%|██▍       | 60/247 [00:32<02:05,  1.48it/s]Loading train:  25%|██▍       | 61/247 [00:33<02:08,  1.44it/s]Loading train:  25%|██▌       | 62/247 [00:33<02:07,  1.45it/s]Loading train:  26%|██▌       | 63/247 [00:34<02:05,  1.46it/s]Loading train:  26%|██▌       | 64/247 [00:35<02:07,  1.43it/s]Loading train:  26%|██▋       | 65/247 [00:35<02:09,  1.41it/s]Loading train:  27%|██▋       | 66/247 [00:36<02:06,  1.43it/s]Loading train:  27%|██▋       | 67/247 [00:37<02:08,  1.41it/s]Loading train:  28%|██▊       | 68/247 [00:38<02:08,  1.39it/s]Loading train:  28%|██▊       | 69/247 [00:38<02:07,  1.39it/s]Loading train:  28%|██▊       | 70/247 [00:39<02:06,  1.40it/s]Loading train:  29%|██▊       | 71/247 [00:40<02:05,  1.40it/s]Loading train:  29%|██▉       | 72/247 [00:40<02:06,  1.38it/s]Loading train:  30%|██▉       | 73/247 [00:41<02:06,  1.37it/s]Loading train:  30%|██▉       | 74/247 [00:42<02:06,  1.37it/s]Loading train:  30%|███       | 75/247 [00:43<02:04,  1.38it/s]Loading train:  31%|███       | 76/247 [00:43<02:02,  1.39it/s]Loading train:  31%|███       | 77/247 [00:44<02:24,  1.17it/s]Loading train:  32%|███▏      | 78/247 [00:46<02:39,  1.06it/s]Loading train:  32%|███▏      | 79/247 [00:47<02:41,  1.04it/s]Loading train:  32%|███▏      | 80/247 [00:48<02:38,  1.05it/s]Loading train:  33%|███▎      | 81/247 [00:49<02:48,  1.02s/it]Loading train:  33%|███▎      | 82/247 [00:50<02:36,  1.05it/s]Loading train:  34%|███▎      | 83/247 [00:50<02:24,  1.13it/s]Loading train:  34%|███▍      | 84/247 [00:51<02:18,  1.18it/s]Loading train:  34%|███▍      | 85/247 [00:52<02:15,  1.19it/s]Loading train:  35%|███▍      | 86/247 [00:53<02:11,  1.22it/s]Loading train:  35%|███▌      | 87/247 [00:53<02:07,  1.25it/s]Loading train:  36%|███▌      | 88/247 [00:54<02:06,  1.26it/s]Loading train:  36%|███▌      | 89/247 [00:55<02:03,  1.28it/s]Loading train:  36%|███▋      | 90/247 [00:56<01:59,  1.31it/s]Loading train:  37%|███▋      | 91/247 [00:56<01:56,  1.34it/s]Loading train:  37%|███▋      | 92/247 [00:57<01:55,  1.34it/s]Loading train:  38%|███▊      | 93/247 [00:58<01:53,  1.35it/s]Loading train:  38%|███▊      | 94/247 [00:59<01:54,  1.33it/s]Loading train:  38%|███▊      | 95/247 [00:59<01:53,  1.34it/s]Loading train:  39%|███▉      | 96/247 [01:00<01:51,  1.35it/s]Loading train:  39%|███▉      | 97/247 [01:01<01:50,  1.36it/s]Loading train:  40%|███▉      | 98/247 [01:02<01:50,  1.35it/s]Loading train:  40%|████      | 99/247 [01:02<01:48,  1.36it/s]Loading train:  40%|████      | 100/247 [01:03<01:46,  1.37it/s]Loading train:  41%|████      | 101/247 [01:04<01:45,  1.38it/s]Loading train:  41%|████▏     | 102/247 [01:04<01:47,  1.34it/s]Loading train:  42%|████▏     | 103/247 [01:05<01:46,  1.36it/s]Loading train:  42%|████▏     | 104/247 [01:06<01:42,  1.39it/s]Loading train:  43%|████▎     | 105/247 [01:07<01:42,  1.39it/s]Loading train:  43%|████▎     | 106/247 [01:07<01:43,  1.37it/s]Loading train:  43%|████▎     | 107/247 [01:08<01:41,  1.38it/s]Loading train:  44%|████▎     | 108/247 [01:09<01:41,  1.37it/s]Loading train:  44%|████▍     | 109/247 [01:09<01:39,  1.38it/s]Loading train:  45%|████▍     | 110/247 [01:10<01:38,  1.39it/s]Loading train:  45%|████▍     | 111/247 [01:11<01:36,  1.42it/s]Loading train:  45%|████▌     | 112/247 [01:12<01:35,  1.41it/s]Loading train:  46%|████▌     | 113/247 [01:12<01:35,  1.40it/s]Loading train:  46%|████▌     | 114/247 [01:13<01:34,  1.40it/s]Loading train:  47%|████▋     | 115/247 [01:14<01:33,  1.41it/s]Loading train:  47%|████▋     | 116/247 [01:14<01:33,  1.40it/s]Loading train:  47%|████▋     | 117/247 [01:15<01:33,  1.38it/s]Loading train:  48%|████▊     | 118/247 [01:16<01:32,  1.40it/s]Loading train:  48%|████▊     | 119/247 [01:17<01:29,  1.43it/s]Loading train:  49%|████▊     | 120/247 [01:17<01:28,  1.43it/s]Loading train:  49%|████▉     | 121/247 [01:18<01:26,  1.46it/s]Loading train:  49%|████▉     | 122/247 [01:19<01:25,  1.47it/s]Loading train:  50%|████▉     | 123/247 [01:19<01:23,  1.48it/s]Loading train:  50%|█████     | 124/247 [01:20<01:24,  1.45it/s]Loading train:  51%|█████     | 125/247 [01:21<01:23,  1.46it/s]Loading train:  51%|█████     | 126/247 [01:21<01:22,  1.46it/s]Loading train:  51%|█████▏    | 127/247 [01:22<01:21,  1.47it/s]Loading train:  52%|█████▏    | 128/247 [01:23<01:21,  1.45it/s]Loading train:  52%|█████▏    | 129/247 [01:23<01:19,  1.49it/s]Loading train:  53%|█████▎    | 130/247 [01:24<01:19,  1.47it/s]Loading train:  53%|█████▎    | 131/247 [01:25<01:19,  1.46it/s]Loading train:  53%|█████▎    | 132/247 [01:25<01:20,  1.43it/s]Loading train:  54%|█████▍    | 133/247 [01:26<01:19,  1.44it/s]Loading train:  54%|█████▍    | 134/247 [01:27<01:17,  1.46it/s]Loading train:  55%|█████▍    | 135/247 [01:27<01:15,  1.48it/s]Loading train:  55%|█████▌    | 136/247 [01:28<01:13,  1.50it/s]Loading train:  55%|█████▌    | 137/247 [01:29<01:13,  1.50it/s]Loading train:  56%|█████▌    | 138/247 [01:29<01:11,  1.53it/s]Loading train:  56%|█████▋    | 139/247 [01:30<01:11,  1.51it/s]Loading train:  57%|█████▋    | 140/247 [01:31<01:11,  1.50it/s]Loading train:  57%|█████▋    | 141/247 [01:31<01:10,  1.50it/s]Loading train:  57%|█████▋    | 142/247 [01:32<01:11,  1.47it/s]Loading train:  58%|█████▊    | 143/247 [01:33<01:11,  1.45it/s]Loading train:  58%|█████▊    | 144/247 [01:33<01:10,  1.47it/s]Loading train:  59%|█████▊    | 145/247 [01:34<01:09,  1.47it/s]Loading train:  59%|█████▉    | 146/247 [01:35<01:07,  1.49it/s]Loading train:  60%|█████▉    | 147/247 [01:36<01:07,  1.48it/s]Loading train:  60%|█████▉    | 148/247 [01:36<01:06,  1.50it/s]Loading train:  60%|██████    | 149/247 [01:37<01:05,  1.50it/s]Loading train:  61%|██████    | 150/247 [01:37<01:04,  1.50it/s]Loading train:  61%|██████    | 151/247 [01:38<01:03,  1.52it/s]Loading train:  62%|██████▏   | 152/247 [01:39<01:01,  1.54it/s]Loading train:  62%|██████▏   | 153/247 [01:39<01:00,  1.55it/s]Loading train:  62%|██████▏   | 154/247 [01:40<01:04,  1.43it/s]Loading train:  63%|██████▎   | 155/247 [01:41<01:05,  1.40it/s]Loading train:  63%|██████▎   | 156/247 [01:42<01:06,  1.38it/s]Loading train:  64%|██████▎   | 157/247 [01:42<01:06,  1.36it/s]Loading train:  64%|██████▍   | 158/247 [01:43<01:04,  1.38it/s]Loading train:  64%|██████▍   | 159/247 [01:44<01:05,  1.35it/s]Loading train:  65%|██████▍   | 160/247 [01:45<01:05,  1.34it/s]Loading train:  65%|██████▌   | 161/247 [01:45<01:04,  1.33it/s]Loading train:  66%|██████▌   | 162/247 [01:46<01:03,  1.35it/s]Loading train:  66%|██████▌   | 163/247 [01:47<01:02,  1.34it/s]Loading train:  66%|██████▋   | 164/247 [01:48<01:02,  1.33it/s]Loading train:  67%|██████▋   | 165/247 [01:48<01:01,  1.33it/s]Loading train:  67%|██████▋   | 166/247 [01:49<01:00,  1.33it/s]Loading train:  68%|██████▊   | 167/247 [01:50<00:59,  1.34it/s]Loading train:  68%|██████▊   | 168/247 [01:51<00:59,  1.33it/s]Loading train:  68%|██████▊   | 169/247 [01:51<00:57,  1.35it/s]Loading train:  69%|██████▉   | 170/247 [01:52<00:56,  1.36it/s]Loading train:  69%|██████▉   | 171/247 [01:53<00:55,  1.36it/s]Loading train:  70%|██████▉   | 172/247 [01:54<01:03,  1.17it/s]Loading train:  70%|███████   | 173/247 [01:55<01:05,  1.13it/s]Loading train:  70%|███████   | 174/247 [01:56<01:06,  1.10it/s]Loading train:  71%|███████   | 175/247 [01:57<01:10,  1.03it/s]Loading train:  71%|███████▏  | 176/247 [01:58<01:03,  1.12it/s]Loading train:  72%|███████▏  | 177/247 [01:58<00:58,  1.19it/s]Loading train:  72%|███████▏  | 178/247 [01:59<00:55,  1.23it/s]Loading train:  72%|███████▏  | 179/247 [02:00<00:53,  1.28it/s]Loading train:  73%|███████▎  | 180/247 [02:01<00:51,  1.30it/s]Loading train:  73%|███████▎  | 181/247 [02:01<00:48,  1.35it/s]Loading train:  74%|███████▎  | 182/247 [02:02<00:47,  1.35it/s]Loading train:  74%|███████▍  | 183/247 [02:03<00:47,  1.35it/s]Loading train:  74%|███████▍  | 184/247 [02:04<00:45,  1.39it/s]Loading train:  75%|███████▍  | 185/247 [02:04<00:43,  1.41it/s]Loading train:  75%|███████▌  | 186/247 [02:05<00:43,  1.42it/s]Loading train:  76%|███████▌  | 187/247 [02:06<00:42,  1.43it/s]Loading train:  76%|███████▌  | 188/247 [02:06<00:41,  1.44it/s]Loading train:  77%|███████▋  | 189/247 [02:07<00:40,  1.42it/s]Loading train:  77%|███████▋  | 190/247 [02:08<00:40,  1.40it/s]Loading train:  77%|███████▋  | 191/247 [02:08<00:39,  1.43it/s]Loading train:  78%|███████▊  | 192/247 [02:09<00:38,  1.45it/s]Loading train:  78%|███████▊  | 193/247 [02:10<00:36,  1.47it/s]Loading train:  79%|███████▊  | 194/247 [02:10<00:35,  1.48it/s]Loading train:  79%|███████▉  | 195/247 [02:11<00:35,  1.47it/s]Loading train:  79%|███████▉  | 196/247 [02:12<00:34,  1.49it/s]Loading train:  80%|███████▉  | 197/247 [02:12<00:33,  1.48it/s]Loading train:  80%|████████  | 198/247 [02:13<00:33,  1.45it/s]Loading train:  81%|████████  | 199/247 [02:14<00:33,  1.41it/s]Loading train:  81%|████████  | 200/247 [02:15<00:32,  1.44it/s]Loading train:  81%|████████▏ | 201/247 [02:15<00:32,  1.41it/s]Loading train:  82%|████████▏ | 202/247 [02:16<00:32,  1.40it/s]Loading train:  82%|████████▏ | 203/247 [02:17<00:31,  1.38it/s]Loading train:  83%|████████▎ | 204/247 [02:17<00:31,  1.37it/s]Loading train:  83%|████████▎ | 205/247 [02:18<00:30,  1.38it/s]Loading train:  83%|████████▎ | 206/247 [02:19<00:30,  1.33it/s]Loading train:  84%|████████▍ | 207/247 [02:20<00:29,  1.35it/s]Loading train:  84%|████████▍ | 208/247 [02:20<00:28,  1.36it/s]Loading train:  85%|████████▍ | 209/247 [02:21<00:28,  1.35it/s]Loading train:  85%|████████▌ | 210/247 [02:22<00:27,  1.37it/s]Loading train:  85%|████████▌ | 211/247 [02:23<00:26,  1.37it/s]Loading train:  86%|████████▌ | 212/247 [02:25<00:40,  1.15s/it]Loading train:  86%|████████▌ | 213/247 [02:28<00:56,  1.65s/it]Loading train:  87%|████████▋ | 214/247 [02:29<00:47,  1.43s/it]Loading train:  87%|████████▋ | 215/247 [02:32<01:07,  2.11s/it]Loading train:  87%|████████▋ | 216/247 [02:35<01:08,  2.19s/it]Loading train:  88%|████████▊ | 217/247 [02:39<01:26,  2.88s/it]Loading train:  88%|████████▊ | 218/247 [02:44<01:37,  3.37s/it]Loading train:  89%|████████▊ | 219/247 [02:48<01:44,  3.73s/it]Loading train:  89%|████████▉ | 220/247 [02:52<01:41,  3.75s/it]Loading train:  89%|████████▉ | 221/247 [02:56<01:36,  3.73s/it]Loading train:  90%|████████▉ | 222/247 [02:59<01:33,  3.74s/it]Loading train:  90%|█████████ | 223/247 [03:03<01:25,  3.56s/it]Loading train:  91%|█████████ | 224/247 [03:06<01:22,  3.57s/it]Loading train:  91%|█████████ | 225/247 [03:10<01:18,  3.58s/it]Loading train:  91%|█████████▏| 226/247 [03:13<01:13,  3.49s/it]Loading train:  92%|█████████▏| 227/247 [03:16<01:06,  3.31s/it]Loading train:  92%|█████████▏| 228/247 [03:19<01:00,  3.16s/it]Loading train:  93%|█████████▎| 229/247 [03:21<00:54,  3.03s/it]Loading train:  93%|█████████▎| 230/247 [03:27<01:03,  3.73s/it]Loading train:  94%|█████████▎| 231/247 [03:30<00:57,  3.61s/it]Loading train:  94%|█████████▍| 232/247 [03:34<00:54,  3.62s/it]Loading train:  94%|█████████▍| 233/247 [03:37<00:50,  3.61s/it]Loading train:  95%|█████████▍| 234/247 [03:41<00:46,  3.59s/it]Loading train:  95%|█████████▌| 235/247 [03:44<00:42,  3.57s/it]Loading train:  96%|█████████▌| 236/247 [03:48<00:38,  3.51s/it]Loading train:  96%|█████████▌| 237/247 [03:51<00:33,  3.38s/it]Loading train:  96%|█████████▋| 238/247 [03:55<00:31,  3.48s/it]Loading train:  97%|█████████▋| 239/247 [03:58<00:27,  3.48s/it]Loading train:  97%|█████████▋| 240/247 [04:02<00:24,  3.50s/it]Loading train:  98%|█████████▊| 241/247 [04:05<00:20,  3.49s/it]Loading train:  98%|█████████▊| 242/247 [04:08<00:17,  3.43s/it]Loading train:  98%|█████████▊| 243/247 [04:12<00:13,  3.44s/it]Loading train:  99%|█████████▉| 244/247 [04:15<00:10,  3.47s/it]Loading train:  99%|█████████▉| 245/247 [04:19<00:06,  3.48s/it]Loading train: 100%|█████████▉| 246/247 [04:22<00:03,  3.37s/it]Loading train: 100%|██████████| 247/247 [04:26<00:00,  3.44s/it]Loading train: 100%|██████████| 247/247 [04:26<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/247 [00:00<00:03, 69.37it/s]concatenating: train:   6%|▌         | 14/247 [00:00<00:03, 69.24it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:03, 69.14it/s]concatenating: train:  11%|█▏        | 28/247 [00:00<00:03, 68.88it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:03, 68.67it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:02, 68.99it/s]concatenating: train:  20%|██        | 50/247 [00:00<00:02, 69.80it/s]concatenating: train:  23%|██▎       | 57/247 [00:00<00:02, 68.44it/s]concatenating: train:  26%|██▌       | 64/247 [00:00<00:02, 63.18it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:02, 61.13it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:02, 60.06it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:02, 59.21it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 60.54it/s]concatenating: train:  39%|███▉      | 97/247 [00:01<00:02, 61.42it/s]concatenating: train:  42%|████▏     | 104/247 [00:01<00:02, 62.28it/s]concatenating: train:  45%|████▍     | 111/247 [00:01<00:02, 63.72it/s]concatenating: train:  48%|████▊     | 118/247 [00:01<00:02, 63.95it/s]concatenating: train:  51%|█████     | 125/247 [00:01<00:01, 63.32it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:01, 62.81it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:01, 62.83it/s]concatenating: train:  59%|█████▉    | 146/247 [00:02<00:01, 63.03it/s]concatenating: train:  62%|██████▏   | 154/247 [00:02<00:01, 64.85it/s]concatenating: train:  65%|██████▌   | 161/247 [00:02<00:01, 65.82it/s]concatenating: train:  68%|██████▊   | 168/247 [00:02<00:01, 66.45it/s]concatenating: train:  71%|███████   | 175/247 [00:02<00:01, 66.35it/s]concatenating: train:  74%|███████▎  | 182/247 [00:02<00:00, 65.29it/s]concatenating: train:  77%|███████▋  | 189/247 [00:02<00:00, 63.71it/s]concatenating: train:  79%|███████▉  | 196/247 [00:03<00:00, 60.97it/s]concatenating: train:  82%|████████▏ | 203/247 [00:03<00:00, 54.30it/s]concatenating: train:  85%|████████▍ | 209/247 [00:03<00:00, 52.00it/s]concatenating: train:  87%|████████▋ | 215/247 [00:03<00:00, 51.71it/s]concatenating: train:  89%|████████▉ | 221/247 [00:03<00:00, 51.78it/s]concatenating: train:  92%|█████████▏| 227/247 [00:03<00:00, 51.78it/s]concatenating: train:  94%|█████████▍| 233/247 [00:03<00:00, 52.41it/s]concatenating: train:  97%|█████████▋| 239/247 [00:03<00:00, 52.30it/s]concatenating: train:  99%|█████████▉| 245/247 [00:04<00:00, 52.53it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 60.72it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:07<00:30,  7.54s/it]Loading test:  40%|████      | 2/5 [00:16<00:24,  8.01s/it]Loading test:  60%|██████    | 3/5 [00:20<00:13,  6.66s/it]Loading test:  80%|████████  | 4/5 [00:23<00:05,  5.56s/it]Loading test: 100%|██████████| 5/5 [00:30<00:00,  6.11s/it]Loading test: 100%|██████████| 5/5 [00:30<00:00,  6.11s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 65.27it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   2020-01-22 00:31:44.817586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 00:31:44.817670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 00:31:44.817683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 00:31:44.817690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 00:31:44.817999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.52885422e-02 3.19665416e-02 7.71370780e-02 9.61719447e-03
 2.75348328e-02 7.05211068e-03 8.86280441e-02 1.14511613e-01
 8.20537493e-02 1.27680352e-02 2.89817431e-01 1.93374257e-01
 2.50570883e-04]
Train on 9718 samples, validate on 194 samples
Epoch 1/300
 - 27s - loss: 0.5594 - acc: 0.9262 - mDice: 0.3966 - val_loss: 0.1906 - val_acc: 0.9370 - val_mDice: 0.1997

Epoch 00001: val_mDice improved from -inf to 0.19974, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 23s - loss: 0.4661 - acc: 0.9392 - mDice: 0.4971 - val_loss: 0.4320 - val_acc: 0.9418 - val_mDice: 0.2478

Epoch 00002: val_mDice improved from 0.19974 to 0.24777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 23s - loss: 0.4033 - acc: 0.9428 - mDice: 0.5650 - val_loss: 0.1952 - val_acc: 0.9435 - val_mDice: 0.2612

Epoch 00003: val_mDice improved from 0.24777 to 0.26118, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 23s - loss: 0.3515 - acc: 0.9447 - mDice: 0.6211 - val_loss: 0.0603 - val_acc: 0.9479 - val_mDice: 0.2965

Epoch 00004: val_mDice improved from 0.26118 to 0.29649, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 5/300
 - 23s - loss: 0.3340 - acc: 0.9465 - mDice: 0.6401 - val_loss: 0.0359 - val_acc: 0.9455 - val_mDice: 0.2790

Epoch 00005: val_mDice did not improve from 0.29649
Epoch 6/300
 - 23s - loss: 0.3197 - acc: 0.9479 - mDice: 0.6555 - val_loss: 0.0871 - val_acc: 0.9461 - val_mDice: 0.2900

Epoch 00006: val_mDice did not improve from 0.29649
Epoch 7/300
 - 23s - loss: 0.3143 - acc: 0.9484 - mDice: 0.6613 - val_loss: 0.0435 - val_acc: 0.9464 - val_mDice: 0.2900

Epoch 00007: val_mDice did not improve from 0.29649
Epoch 8/300
 - 23s - loss: 0.3064 - acc: 0.9494 - mDice: 0.6698 - val_loss: 0.0029 - val_acc: 0.9482 - val_mDice: 0.2839

Epoch 00008: val_mDice did not improve from 0.29649
Epoch 9/300
 - 23s - loss: 0.3022 - acc: 0.9496 - mDice: 0.6744 - val_loss: 0.0214 - val_acc: 0.9477 - val_mDice: 0.2856

Epoch 00009: val_mDice did not improve from 0.29649
Epoch 10/300
 - 24s - loss: 0.2940 - acc: 0.9510 - mDice: 0.6831 - val_loss: 0.0628 - val_acc: 0.9468 - val_mDice: 0.2835

Epoch 00010: val_mDice did not improve from 0.29649
Epoch 11/300
 - 24s - loss: 0.2877 - acc: 0.9516 - mDice: 0.6900 - val_loss: 0.0027 - val_acc: 0.9480 - val_mDice: 0.2670

Epoch 00011: val_mDice did not improve from 0.29649
Epoch 12/300
 - 24s - loss: 0.2847 - acc: 0.9518 - mDice: 0.6932 - val_loss: 0.0421 - val_acc: 0.9476 - val_mDice: 0.2804

Epoch 00012: val_mDice did not improve from 0.29649
Epoch 13/300
 - 24s - loss: 0.2800 - acc: 0.9524 - mDice: 0.6983 - val_loss: 0.0231 - val_acc: 0.9480 - val_mDice: 0.2747

Epoch 00013: val_mDice did not improve from 0.29649
Epoch 14/300
 - 24s - loss: 0.2797 - acc: 0.9523 - mDice: 0.6986 - val_loss: 0.0228 - val_acc: 0.9504 - val_mDice: 0.2929

Epoch 00014: val_mDice did not improve from 0.29649
Epoch 15/300
 - 24s - loss: 0.2729 - acc: 0.9530 - mDice: 0.7059 - val_loss: 0.0085 - val_acc: 0.9486 - val_mDice: 0.2734

Epoch 00015: val_mDice did not improve from 0.29649
Epoch 16/300
 - 24s - loss: 0.2730 - acc: 0.9535 - mDice: 0.7058 - val_loss: 0.0053 - val_acc: 0.9487 - val_mDice: 0.2937

Epoch 00016: val_mDice did not improve from 0.29649
Epoch 17/300
 - 24s - loss: 0.2724 - acc: 0.9533 - mDice: 0.7065 - val_loss: 0.0399 - val_acc: 0.9470 - val_mDice: 0.2860

Epoch 00017: val_mDice did not improve from 0.29649
Epoch 18/300
 - 24s - loss: 0.2659 - acc: 0.9537 - mDice: 0.7135 - val_loss: 0.0235 - val_acc: 0.9481 - val_mDice: 0.2790

Epoch 00018: val_mDice did not improve from 0.29649
Epoch 19/300
 - 24s - loss: 0.2725 - acc: 0.9534 - mDice: 0.7064 - val_loss: 0.0801 - val_acc: 0.9446 - val_mDice: 0.2746

Epoch 00019: val_mDice did not improve from 0.29649

Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 20/300
 - 24s - loss: 0.2569 - acc: 0.9550 - mDice: 0.7232 - val_loss: 0.0112 - val_acc: 0.9498 - val_mDice: 0.2799

Epoch 00020: val_mDice did not improve from 0.29649
Epoch 21/300
 - 24s - loss: 0.2512 - acc: 0.9557 - mDice: 0.7293 - val_loss: 0.0109 - val_acc: 0.9483 - val_mDice: 0.2816

Epoch 00021: val_mDice did not improve from 0.29649
Epoch 22/300
 - 24s - loss: 0.2547 - acc: 0.9555 - mDice: 0.7255 - val_loss: -2.4956e-02 - val_acc: 0.9505 - val_mDice: 0.2847

Epoch 00022: val_mDice did not improve from 0.29649
Epoch 23/300
 - 23s - loss: 0.2480 - acc: 0.9560 - mDice: 0.7328 - val_loss: -3.4813e-03 - val_acc: 0.9498 - val_mDice: 0.2887

Epoch 00023: val_mDice did not improve from 0.29649
Epoch 24/300
 - 24s - loss: 0.2452 - acc: 0.9562 - mDice: 0.7358 - val_loss: 0.0325 - val_acc: 0.9492 - val_mDice: 0.2886

Epoch 00024: val_mDice did not improve from 0.29649
Epoch 25/300
 - 23s - loss: 0.2475 - acc: 0.9564 - mDice: 0.7333 - val_loss: 0.0342 - val_acc: 0.9489 - val_mDice: 0.2828

Epoch 00025: val_mDice did not improve from 0.29649
Epoch 26/300
 - 23s - loss: 0.2448 - acc: 0.9567 - mDice: 0.7362 - val_loss: 0.0052 - val_acc: 0.9497 - val_mDice: 0.2859

Epoch 00026: val_mDice did not improve from 0.29649
Epoch 27/300
 - 23s - loss: 0.2474 - acc: 0.9567 - mDice: 0.7334 - val_loss: -1.6341e-02 - val_acc: 0.9506 - val_mDice: 0.2852

Epoch 00027: val_mDice did not improve from 0.29649
Epoch 28/300
 - 23s - loss: 0.2448 - acc: 0.9567 - mDice: 0.7359 - val_loss: -4.7902e-04 - val_acc: 0.9488 - val_mDice: 0.2802

Epoch 00028: val_mDice did not improve from 0.29649
Epoch 29/300
 - 23s - loss: 0.2435 - acc: 0.9559 - mDice: 0.7332 - val_loss: 0.0781 - val_acc: 0.9459 - val_mDice: 0.2795

Epoch 00029: val_mDice did not improve from 0.29649
Epoch 30/300
 - 23s - loss: 0.2381 - acc: 0.9547 - mDice: 0.7212 - val_loss: -2.1982e-02 - val_acc: 0.9494 - val_mDice: 0.2787

Epoch 00030: val_mDice did not improve from 0.29649
Epoch 31/300
 - 23s - loss: 0.2308 - acc: 0.9549 - mDice: 0.7225 - val_loss: -8.4357e-03 - val_acc: 0.9494 - val_mDice: 0.2786

Epoch 00031: val_mDice did not improve from 0.29649
Epoch 32/300
 - 22s - loss: 0.2320 - acc: 0.9538 - mDice: 0.7152 - val_loss: -1.8953e-02 - val_acc: 0.9500 - val_mDice: 0.2854

Epoch 00032: val_mDice did not improve from 0.29649
Epoch 33/300
 - 23s - loss: 0.2276 - acc: 0.9543 - mDice: 0.7105 - val_loss: -3.0741e-02 - val_acc: 0.9494 - val_mDice: 0.2766

Epoch 00033: val_mDice did not improve from 0.29649
Epoch 34/300
 - 22s - loss: 0.2277 - acc: 0.9542 - mDice: 0.7126 - val_loss: -1.8752e-02 - val_acc: 0.9504 - val_mDice: 0.2858

Epoch 00034: val_mDice did not improve from 0.29649

Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 35/300
 - 22s - loss: 0.2129 - acc: 0.9550 - mDice: 0.7241 - val_loss: -4.2349e-02 - val_acc: 0.9503 - val_mDice: 0.2816

Epoch 00035: val_mDice did not improve from 0.29649
Epoch 36/300
 - 23s - loss: 0.2198 - acc: 0.9539 - mDice: 0.7139 - val_loss: -2.7948e-02 - val_acc: 0.9491 - val_mDice: 0.2711

Epoch 00036: val_mDice did not improve from 0.29649
Epoch 37/300
 - 22s - loss: 0.2097 - acc: 0.9549 - mDice: 0.7243 - val_loss: -3.7558e-02 - val_acc: 0.9497 - val_mDice: 0.2768

Epoch 00037: val_mDice did not improve from 0.29649
Epoch 38/300
 - 22s - loss: 0.2084 - acc: 0.9549 - mDice: 0.7215 - val_loss: -3.2703e-02 - val_acc: 0.9495 - val_mDice: 0.2753

Epoch 00038: val_mDice did not improve from 0.29649
Epoch 39/300
 - 23s - loss: 0.2098 - acc: 0.9552 - mDice: 0.7202 - val_loss: -5.2647e-02 - val_acc: 0.9506 - val_mDice: 0.2767

Epoch 00039: val_mDice did not improve from 0.29649
Epoch 40/300
 - 22s - loss: 0.2040 - acc: 0.9552 - mDice: 0.7252 - val_loss: -4.9456e-02 - val_acc: 0.9507 - val_mDice: 0.2772

Epoch 00040: val_mDice did not improve from 0.29649
Epoch 41/300
 - 22s - loss: 0.2029 - acc: 0.9555 - mDice: 0.7289 - val_loss: -5.1152e-02 - val_acc: 0.9498 - val_mDice: 0.2771

Epoch 00041: val_mDice did not improve from 0.29649
Epoch 42/300
 - 23s - loss: 0.1999 - acc: 0.9558 - mDice: 0.7324 - val_loss: -3.9942e-02 - val_acc: 0.9516 - val_mDice: 0.2823

Epoch 00042: val_mDice did not improve from 0.29649
Epoch 43/300
 - 22s - loss: 0.2018 - acc: 0.9556 - mDice: 0.7310 - val_loss: -4.5741e-02 - val_acc: 0.9499 - val_mDice: 0.2800

Epoch 00043: val_mDice did not improve from 0.29649
Epoch 44/300
 - 23s - loss: 0.1965 - acc: 0.9560 - mDice: 0.7321 - val_loss: -2.6435e-02 - val_acc: 0.9500 - val_mDice: 0.2787

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.49s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.35s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.27s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.13s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:14,  3.29it/s]Loading train:   1%|          | 2/247 [00:00<01:12,  3.40it/s]Loading train:   1%|          | 3/247 [00:00<01:08,  3.55it/s]Loading train:   2%|▏         | 4/247 [00:01<01:09,  3.52it/s]Loading train:   2%|▏         | 5/247 [00:01<01:08,  3.54it/s]Loading train:   2%|▏         | 6/247 [00:01<01:07,  3.56it/s]Loading train:   3%|▎         | 7/247 [00:01<01:07,  3.58it/s]Loading train:   3%|▎         | 8/247 [00:02<01:06,  3.59it/s]Loading train:   4%|▎         | 9/247 [00:02<01:06,  3.59it/s]Loading train:   4%|▍         | 10/247 [00:02<01:05,  3.60it/s]Loading train:   4%|▍         | 11/247 [00:03<01:05,  3.62it/s]Loading train:   5%|▍         | 12/247 [00:03<01:05,  3.59it/s]Loading train:   5%|▌         | 13/247 [00:03<01:04,  3.60it/s]Loading train:   6%|▌         | 14/247 [00:03<01:04,  3.63it/s]Loading train:   6%|▌         | 15/247 [00:04<01:03,  3.63it/s]Loading train:   6%|▋         | 16/247 [00:04<01:03,  3.65it/s]Loading train:   7%|▋         | 17/247 [00:04<01:03,  3.63it/s]Loading train:   7%|▋         | 18/247 [00:04<01:02,  3.64it/s]Loading train:   8%|▊         | 19/247 [00:05<01:02,  3.65it/s]Loading train:   8%|▊         | 20/247 [00:05<01:02,  3.66it/s]Loading train:   9%|▊         | 21/247 [00:05<01:01,  3.66it/s]Loading train:   9%|▉         | 22/247 [00:06<01:01,  3.67it/s]Loading train:   9%|▉         | 23/247 [00:06<00:59,  3.80it/s]Loading train:  10%|▉         | 24/247 [00:06<00:57,  3.87it/s]Loading train:  10%|█         | 25/247 [00:06<00:56,  3.94it/s]Loading train:  11%|█         | 26/247 [00:07<00:55,  4.00it/s]Loading train:  11%|█         | 27/247 [00:07<00:54,  4.03it/s]Loading train:  11%|█▏        | 28/247 [00:07<00:53,  4.07it/s]Loading train:  12%|█▏        | 29/247 [00:07<00:53,  4.10it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:52,  4.10it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:52,  4.11it/s]Loading train:  13%|█▎        | 32/247 [00:08<00:52,  4.13it/s]Loading train:  13%|█▎        | 33/247 [00:08<00:51,  4.12it/s]Loading train:  14%|█▍        | 34/247 [00:08<00:51,  4.14it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:51,  4.14it/s]Loading train:  15%|█▍        | 36/247 [00:09<00:51,  4.13it/s]Loading train:  15%|█▍        | 37/247 [00:09<00:50,  4.14it/s]Loading train:  15%|█▌        | 38/247 [00:09<00:50,  4.14it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:50,  4.14it/s]Loading train:  16%|█▌        | 40/247 [00:10<00:49,  4.14it/s]Loading train:  17%|█▋        | 41/247 [00:10<00:50,  4.10it/s]Loading train:  17%|█▋        | 42/247 [00:10<00:50,  4.06it/s]Loading train:  17%|█▋        | 43/247 [00:11<00:50,  4.02it/s]Loading train:  18%|█▊        | 44/247 [00:11<00:50,  3.99it/s]Loading train:  18%|█▊        | 45/247 [00:11<00:50,  3.99it/s]Loading train:  19%|█▊        | 46/247 [00:11<00:50,  3.99it/s]Loading train:  19%|█▉        | 47/247 [00:12<00:50,  3.93it/s]Loading train:  19%|█▉        | 48/247 [00:12<00:50,  3.92it/s]Loading train:  20%|█▉        | 49/247 [00:12<00:50,  3.94it/s]Loading train:  20%|██        | 50/247 [00:12<00:50,  3.93it/s]Loading train:  21%|██        | 51/247 [00:13<00:50,  3.91it/s]Loading train:  21%|██        | 52/247 [00:13<00:49,  3.93it/s]Loading train:  21%|██▏       | 53/247 [00:13<00:49,  3.93it/s]Loading train:  22%|██▏       | 54/247 [00:13<00:49,  3.93it/s]Loading train:  22%|██▏       | 55/247 [00:14<00:48,  3.93it/s]Loading train:  23%|██▎       | 56/247 [00:14<00:48,  3.91it/s]Loading train:  23%|██▎       | 57/247 [00:14<00:48,  3.90it/s]Loading train:  23%|██▎       | 58/247 [00:15<00:48,  3.90it/s]Loading train:  24%|██▍       | 59/247 [00:15<00:49,  3.81it/s]Loading train:  24%|██▍       | 60/247 [00:15<00:50,  3.73it/s]Loading train:  25%|██▍       | 61/247 [00:15<00:50,  3.69it/s]Loading train:  25%|██▌       | 62/247 [00:16<00:50,  3.68it/s]Loading train:  26%|██▌       | 63/247 [00:16<00:50,  3.66it/s]Loading train:  26%|██▌       | 64/247 [00:16<00:49,  3.67it/s]Loading train:  26%|██▋       | 65/247 [00:16<00:49,  3.67it/s]Loading train:  27%|██▋       | 66/247 [00:17<00:49,  3.67it/s]Loading train:  27%|██▋       | 67/247 [00:17<00:48,  3.68it/s]Loading train:  28%|██▊       | 68/247 [00:17<00:48,  3.68it/s]Loading train:  28%|██▊       | 69/247 [00:18<00:48,  3.67it/s]Loading train:  28%|██▊       | 70/247 [00:18<00:48,  3.66it/s]Loading train:  29%|██▊       | 71/247 [00:18<00:47,  3.68it/s]Loading train:  29%|██▉       | 72/247 [00:18<00:47,  3.68it/s]Loading train:  30%|██▉       | 73/247 [00:19<00:47,  3.67it/s]Loading train:  30%|██▉       | 74/247 [00:19<00:46,  3.68it/s]Loading train:  30%|███       | 75/247 [00:19<00:46,  3.69it/s]Loading train:  31%|███       | 76/247 [00:19<00:46,  3.70it/s]Loading train:  31%|███       | 77/247 [00:20<00:49,  3.45it/s]Loading train:  32%|███▏      | 78/247 [00:20<00:50,  3.38it/s]Loading train:  32%|███▏      | 79/247 [00:20<00:49,  3.41it/s]Loading train:  32%|███▏      | 80/247 [00:21<00:47,  3.50it/s]Loading train:  33%|███▎      | 81/247 [00:21<00:49,  3.38it/s]Loading train:  33%|███▎      | 82/247 [00:21<00:49,  3.33it/s]Loading train:  34%|███▎      | 83/247 [00:22<00:49,  3.29it/s]Loading train:  34%|███▍      | 84/247 [00:22<00:49,  3.27it/s]Loading train:  34%|███▍      | 85/247 [00:22<00:50,  3.24it/s]Loading train:  35%|███▍      | 86/247 [00:23<00:49,  3.23it/s]Loading train:  35%|███▌      | 87/247 [00:23<00:49,  3.23it/s]Loading train:  36%|███▌      | 88/247 [00:23<00:49,  3.22it/s]Loading train:  36%|███▌      | 89/247 [00:23<00:49,  3.22it/s]Loading train:  36%|███▋      | 90/247 [00:24<00:48,  3.23it/s]Loading train:  37%|███▋      | 91/247 [00:24<00:48,  3.23it/s]Loading train:  37%|███▋      | 92/247 [00:24<00:47,  3.23it/s]Loading train:  38%|███▊      | 93/247 [00:25<00:47,  3.23it/s]Loading train:  38%|███▊      | 94/247 [00:25<00:47,  3.21it/s]Loading train:  38%|███▊      | 95/247 [00:25<00:47,  3.20it/s]Loading train:  39%|███▉      | 96/247 [00:26<00:47,  3.21it/s]Loading train:  39%|███▉      | 97/247 [00:26<00:46,  3.21it/s]Loading train:  40%|███▉      | 98/247 [00:26<00:46,  3.22it/s]Loading train:  40%|████      | 99/247 [00:27<00:45,  3.23it/s]Loading train:  40%|████      | 100/247 [00:27<00:44,  3.28it/s]Loading train:  41%|████      | 101/247 [00:27<00:44,  3.30it/s]Loading train:  41%|████▏     | 102/247 [00:27<00:43,  3.34it/s]Loading train:  42%|████▏     | 103/247 [00:28<00:42,  3.36it/s]Loading train:  42%|████▏     | 104/247 [00:28<00:42,  3.37it/s]Loading train:  43%|████▎     | 105/247 [00:28<00:41,  3.38it/s]Loading train:  43%|████▎     | 106/247 [00:29<00:41,  3.39it/s]Loading train:  43%|████▎     | 107/247 [00:29<00:41,  3.39it/s]Loading train:  44%|████▎     | 108/247 [00:29<00:40,  3.40it/s]Loading train:  44%|████▍     | 109/247 [00:29<00:40,  3.40it/s]Loading train:  45%|████▍     | 110/247 [00:30<00:40,  3.40it/s]Loading train:  45%|████▍     | 111/247 [00:30<00:40,  3.39it/s]Loading train:  45%|████▌     | 112/247 [00:30<00:39,  3.40it/s]Loading train:  46%|████▌     | 113/247 [00:31<00:39,  3.38it/s]Loading train:  46%|████▌     | 114/247 [00:31<00:39,  3.39it/s]Loading train:  47%|████▋     | 115/247 [00:31<00:38,  3.40it/s]Loading train:  47%|████▋     | 116/247 [00:32<00:38,  3.41it/s]Loading train:  47%|████▋     | 117/247 [00:32<00:38,  3.42it/s]Loading train:  48%|████▊     | 118/247 [00:32<00:36,  3.52it/s]Loading train:  48%|████▊     | 119/247 [00:32<00:35,  3.58it/s]Loading train:  49%|████▊     | 120/247 [00:33<00:34,  3.63it/s]Loading train:  49%|████▉     | 121/247 [00:33<00:34,  3.64it/s]Loading train:  49%|████▉     | 122/247 [00:33<00:34,  3.67it/s]Loading train:  50%|████▉     | 123/247 [00:33<00:33,  3.68it/s]Loading train:  50%|█████     | 124/247 [00:34<00:33,  3.69it/s]Loading train:  51%|█████     | 125/247 [00:34<00:32,  3.70it/s]Loading train:  51%|█████     | 126/247 [00:34<00:32,  3.71it/s]Loading train:  51%|█████▏    | 127/247 [00:35<00:32,  3.72it/s]Loading train:  52%|█████▏    | 128/247 [00:35<00:31,  3.72it/s]Loading train:  52%|█████▏    | 129/247 [00:35<00:31,  3.72it/s]Loading train:  53%|█████▎    | 130/247 [00:35<00:31,  3.72it/s]Loading train:  53%|█████▎    | 131/247 [00:36<00:31,  3.73it/s]Loading train:  53%|█████▎    | 132/247 [00:36<00:30,  3.72it/s]Loading train:  54%|█████▍    | 133/247 [00:36<00:30,  3.73it/s]Loading train:  54%|█████▍    | 134/247 [00:36<00:30,  3.73it/s]Loading train:  55%|█████▍    | 135/247 [00:37<00:30,  3.72it/s]Loading train:  55%|█████▌    | 136/247 [00:37<00:29,  3.78it/s]Loading train:  55%|█████▌    | 137/247 [00:37<00:29,  3.79it/s]Loading train:  56%|█████▌    | 138/247 [00:37<00:28,  3.84it/s]Loading train:  56%|█████▋    | 139/247 [00:38<00:27,  3.86it/s]Loading train:  57%|█████▋    | 140/247 [00:38<00:27,  3.89it/s]Loading train:  57%|█████▋    | 141/247 [00:38<00:27,  3.90it/s]Loading train:  57%|█████▋    | 142/247 [00:38<00:26,  3.92it/s]Loading train:  58%|█████▊    | 143/247 [00:39<00:26,  3.91it/s]Loading train:  58%|█████▊    | 144/247 [00:39<00:26,  3.92it/s]Loading train:  59%|█████▊    | 145/247 [00:39<00:25,  3.93it/s]Loading train:  59%|█████▉    | 146/247 [00:39<00:25,  3.93it/s]Loading train:  60%|█████▉    | 147/247 [00:40<00:25,  3.92it/s]Loading train:  60%|█████▉    | 148/247 [00:40<00:25,  3.91it/s]Loading train:  60%|██████    | 149/247 [00:40<00:25,  3.92it/s]Loading train:  61%|██████    | 150/247 [00:40<00:24,  3.92it/s]Loading train:  61%|██████    | 151/247 [00:41<00:24,  3.93it/s]Loading train:  62%|██████▏   | 152/247 [00:41<00:24,  3.88it/s]Loading train:  62%|██████▏   | 153/247 [00:41<00:24,  3.92it/s]Loading train:  62%|██████▏   | 154/247 [00:42<00:25,  3.70it/s]Loading train:  63%|██████▎   | 155/247 [00:42<00:25,  3.57it/s]Loading train:  63%|██████▎   | 156/247 [00:42<00:26,  3.47it/s]Loading train:  64%|██████▎   | 157/247 [00:42<00:26,  3.39it/s]Loading train:  64%|██████▍   | 158/247 [00:43<00:26,  3.36it/s]Loading train:  64%|██████▍   | 159/247 [00:43<00:26,  3.33it/s]Loading train:  65%|██████▍   | 160/247 [00:43<00:28,  3.09it/s]Loading train:  65%|██████▌   | 161/247 [00:44<00:29,  2.93it/s]Loading train:  66%|██████▌   | 162/247 [00:44<00:29,  2.90it/s]Loading train:  66%|██████▌   | 163/247 [00:45<00:29,  2.87it/s]Loading train:  66%|██████▋   | 164/247 [00:45<00:27,  2.99it/s]Loading train:  67%|██████▋   | 165/247 [00:45<00:27,  3.00it/s]Loading train:  67%|██████▋   | 166/247 [00:46<00:26,  3.04it/s]Loading train:  68%|██████▊   | 167/247 [00:46<00:25,  3.10it/s]Loading train:  68%|██████▊   | 168/247 [00:46<00:25,  3.09it/s]Loading train:  68%|██████▊   | 169/247 [00:46<00:25,  3.09it/s]Loading train:  69%|██████▉   | 170/247 [00:47<00:24,  3.09it/s]Loading train:  69%|██████▉   | 171/247 [00:47<00:25,  2.96it/s]Loading train:  70%|██████▉   | 172/247 [00:48<00:25,  2.96it/s]Loading train:  70%|███████   | 173/247 [00:48<00:23,  3.17it/s]Loading train:  70%|███████   | 174/247 [00:48<00:22,  3.28it/s]Loading train:  71%|███████   | 175/247 [00:48<00:22,  3.21it/s]Loading train:  71%|███████▏  | 176/247 [00:49<00:22,  3.15it/s]Loading train:  72%|███████▏  | 177/247 [00:49<00:21,  3.26it/s]Loading train:  72%|███████▏  | 178/247 [00:49<00:20,  3.32it/s]Loading train:  72%|███████▏  | 179/247 [00:50<00:20,  3.36it/s]Loading train:  73%|███████▎  | 180/247 [00:50<00:19,  3.47it/s]Loading train:  73%|███████▎  | 181/247 [00:50<00:21,  3.08it/s]Loading train:  74%|███████▎  | 182/247 [00:51<00:21,  2.98it/s]Loading train:  74%|███████▍  | 183/247 [00:51<00:20,  3.17it/s]Loading train:  74%|███████▍  | 184/247 [00:51<00:19,  3.27it/s]Loading train:  75%|███████▍  | 185/247 [00:51<00:18,  3.39it/s]Loading train:  75%|███████▌  | 186/247 [00:52<00:17,  3.42it/s]Loading train:  76%|███████▌  | 187/247 [00:52<00:17,  3.45it/s]Loading train:  76%|███████▌  | 188/247 [00:52<00:16,  3.51it/s]Loading train:  77%|███████▋  | 189/247 [00:53<00:16,  3.59it/s]Loading train:  77%|███████▋  | 190/247 [00:53<00:15,  3.63it/s]Loading train:  77%|███████▋  | 191/247 [00:53<00:15,  3.59it/s]Loading train:  78%|███████▊  | 192/247 [00:53<00:15,  3.62it/s]Loading train:  78%|███████▊  | 193/247 [00:54<00:14,  3.63it/s]Loading train:  79%|███████▊  | 194/247 [00:54<00:14,  3.69it/s]Loading train:  79%|███████▉  | 195/247 [00:54<00:13,  3.80it/s]Loading train:  79%|███████▉  | 196/247 [00:54<00:13,  3.85it/s]Loading train:  80%|███████▉  | 197/247 [00:55<00:12,  3.88it/s]Loading train:  80%|████████  | 198/247 [00:55<00:12,  3.95it/s]Loading train:  81%|████████  | 199/247 [00:55<00:12,  3.92it/s]Loading train:  81%|████████  | 200/247 [00:55<00:11,  3.97it/s]Loading train:  81%|████████▏ | 201/247 [00:56<00:11,  3.90it/s]Loading train:  82%|████████▏ | 202/247 [00:56<00:11,  3.95it/s]Loading train:  82%|████████▏ | 203/247 [00:56<00:11,  3.96it/s]Loading train:  83%|████████▎ | 204/247 [00:56<00:11,  3.87it/s]Loading train:  83%|████████▎ | 205/247 [00:57<00:11,  3.81it/s]Loading train:  83%|████████▎ | 206/247 [00:57<00:10,  3.83it/s]Loading train:  84%|████████▍ | 207/247 [00:57<00:10,  3.76it/s]Loading train:  84%|████████▍ | 208/247 [00:58<00:10,  3.74it/s]Loading train:  85%|████████▍ | 209/247 [00:58<00:10,  3.58it/s]Loading train:  85%|████████▌ | 210/247 [00:58<00:10,  3.66it/s]Loading train:  85%|████████▌ | 211/247 [00:58<00:09,  3.80it/s]Loading train:  86%|████████▌ | 212/247 [00:59<00:09,  3.83it/s]Loading train:  86%|████████▌ | 213/247 [00:59<00:08,  3.84it/s]Loading train:  87%|████████▋ | 214/247 [00:59<00:08,  3.83it/s]Loading train:  87%|████████▋ | 215/247 [00:59<00:08,  3.84it/s]Loading train:  87%|████████▋ | 216/247 [01:00<00:08,  3.74it/s]Loading train:  88%|████████▊ | 217/247 [01:00<00:08,  3.64it/s]Loading train:  88%|████████▊ | 218/247 [01:00<00:07,  3.72it/s]Loading train:  89%|████████▊ | 219/247 [01:00<00:07,  3.77it/s]Loading train:  89%|████████▉ | 220/247 [01:01<00:07,  3.81it/s]Loading train:  89%|████████▉ | 221/247 [01:01<00:06,  3.82it/s]Loading train:  90%|████████▉ | 222/247 [01:01<00:06,  3.83it/s]Loading train:  90%|█████████ | 223/247 [01:01<00:06,  3.83it/s]Loading train:  91%|█████████ | 224/247 [01:02<00:05,  3.85it/s]Loading train:  91%|█████████ | 225/247 [01:02<00:05,  3.84it/s]Loading train:  91%|█████████▏| 226/247 [01:02<00:05,  3.86it/s]Loading train:  92%|█████████▏| 227/247 [01:03<00:05,  3.85it/s]Loading train:  92%|█████████▏| 228/247 [01:03<00:04,  3.85it/s]Loading train:  93%|█████████▎| 229/247 [01:03<00:04,  3.85it/s]Loading train:  93%|█████████▎| 230/247 [01:03<00:04,  3.70it/s]Loading train:  94%|█████████▎| 231/247 [01:04<00:04,  3.60it/s]Loading train:  94%|█████████▍| 232/247 [01:04<00:04,  3.54it/s]Loading train:  94%|█████████▍| 233/247 [01:04<00:04,  3.49it/s]Loading train:  95%|█████████▍| 234/247 [01:04<00:03,  3.45it/s]Loading train:  95%|█████████▌| 235/247 [01:05<00:03,  3.43it/s]Loading train:  96%|█████████▌| 236/247 [01:05<00:03,  3.42it/s]Loading train:  96%|█████████▌| 237/247 [01:05<00:02,  3.40it/s]Loading train:  96%|█████████▋| 238/247 [01:06<00:02,  3.38it/s]Loading train:  97%|█████████▋| 239/247 [01:06<00:02,  3.38it/s]Loading train:  97%|█████████▋| 240/247 [01:06<00:02,  3.39it/s]Loading train:  98%|█████████▊| 241/247 [01:07<00:01,  3.37it/s]Loading train:  98%|█████████▊| 242/247 [01:07<00:01,  3.35it/s]Loading train:  98%|█████████▊| 243/247 [01:07<00:01,  3.34it/s]Loading train:  99%|█████████▉| 244/247 [01:07<00:00,  3.36it/s]Loading train:  99%|█████████▉| 245/247 [01:08<00:00,  3.36it/s]Loading train: 100%|█████████▉| 246/247 [01:08<00:00,  3.36it/s]Loading train: 100%|██████████| 247/247 [01:08<00:00,  3.37it/s]Loading train: 100%|██████████| 247/247 [01:08<00:00,  3.59it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 53.29it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 53.08it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 53.48it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 54.36it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:03, 56.72it/s]concatenating: train:  15%|█▌        | 38/247 [00:00<00:03, 58.79it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:03, 59.74it/s]concatenating: train:  21%|██        | 51/247 [00:00<00:03, 57.23it/s]concatenating: train:  23%|██▎       | 57/247 [00:01<00:03, 55.79it/s]concatenating: train:  26%|██▌       | 63/247 [00:01<00:03, 53.47it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:03, 54.35it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 55.62it/s]concatenating: train:  33%|███▎      | 81/247 [00:01<00:02, 55.98it/s]concatenating: train:  35%|███▌      | 87/247 [00:01<00:02, 55.17it/s]concatenating: train:  38%|███▊      | 93/247 [00:01<00:02, 54.07it/s]concatenating: train:  40%|████      | 99/247 [00:01<00:02, 53.91it/s]concatenating: train:  43%|████▎     | 105/247 [00:01<00:02, 54.22it/s]concatenating: train:  45%|████▍     | 111/247 [00:01<00:02, 54.60it/s]concatenating: train:  47%|████▋     | 117/247 [00:02<00:02, 54.19it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 55.58it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 56.51it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:01, 57.49it/s]concatenating: train:  57%|█████▋    | 142/247 [00:02<00:01, 59.06it/s]concatenating: train:  60%|██████    | 149/247 [00:02<00:01, 60.46it/s]concatenating: train:  63%|██████▎   | 156/247 [00:02<00:01, 59.65it/s]concatenating: train:  66%|██████▌   | 162/247 [00:02<00:01, 57.24it/s]concatenating: train:  68%|██████▊   | 168/247 [00:02<00:01, 56.00it/s]concatenating: train:  70%|███████   | 174/247 [00:03<00:01, 55.44it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 56.41it/s]concatenating: train:  76%|███████▌  | 187/247 [00:03<00:01, 58.16it/s]concatenating: train:  78%|███████▊  | 193/247 [00:03<00:00, 58.04it/s]concatenating: train:  81%|████████  | 200/247 [00:03<00:00, 59.96it/s]concatenating: train:  84%|████████▍ | 207/247 [00:03<00:00, 61.75it/s]concatenating: train:  87%|████████▋ | 214/247 [00:03<00:00, 61.21it/s]concatenating: train:  89%|████████▉ | 221/247 [00:03<00:00, 60.70it/s]concatenating: train:  92%|█████████▏| 228/247 [00:03<00:00, 60.94it/s]concatenating: train:  95%|█████████▌| 235/247 [00:04<00:00, 58.37it/s]concatenating: train:  98%|█████████▊| 241/247 [00:04<00:00, 57.39it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 56.81it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 57.14it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.56it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.72it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.80it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.04it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.20it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.17it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 376.98it/s]
Epoch 00044: val_mDice did not improve from 0.29649
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [0.19058735919252193, 0.43198320269584656, 0.1952264048543173, 0.0603353639622939, 0.03587984016222745, 0.08710453605528959, 0.04348199518839108, 0.002867705947191445, 0.021374507010290304, 0.06276955597640313, 0.00272701607690644, 0.04206771991148438, 0.02310635293497867, 0.022844899349759536, 0.0084566782641503, 0.005290711500211475, 0.039852376182361975, 0.02350196207287846, 0.08008221689174816, 0.011249768576517548, 0.010931243707147455, -0.024955754978438244, -0.0034812618834302598, 0.03249035127576172, 0.03422392480862663, 0.00516677903222669, -0.016340642183366203, -0.0004790161553885519, 0.07813797715916923, -0.0219822165738676, -0.008435670940203055, -0.018953364949430982, -0.03074110564343708, -0.018752436590748215, -0.04234888234635402, -0.02794848351748948, -0.037557841804281795, -0.03270328962442119, -0.05264746002161626, -0.049455725847138574, -0.05115237497945422, -0.03994177965466509, -0.04574060432382466, -0.02643542656118108], 'val_acc': [0.9369630653833606, 0.9418006441027847, 0.9435482596613697, 0.947874474771244, 0.9454556771160401, 0.9461358085121077, 0.9463620886360247, 0.9481915266243452, 0.9476801617858336, 0.9468402223488719, 0.9479741933419532, 0.9476124035943415, 0.9479601315616333, 0.950400660947426, 0.9485635609970879, 0.9487374271314168, 0.9470064271356642, 0.9480905330058226, 0.9446131955717028, 0.9498164217496655, 0.9482823026548955, 0.9504543567441174, 0.9498176937250747, 0.9492270602393396, 0.9488524782288935, 0.949666844815323, 0.9506205498557729, 0.9488230845362869, 0.9459146427125046, 0.9494405542452311, 0.9493843101963555, 0.9499890017755253, 0.9493715259217724, 0.9503520825474533, 0.9502740950928521, 0.9490672595722159, 0.9496693936819883, 0.9495019292094043, 0.9505668589749288, 0.9506768025073808, 0.9498368747455558, 0.9515742573541465, 0.9499161354045278, 0.9499557614326477], 'val_mDice': [0.19973844673352942, 0.24777022397779314, 0.2611775193939504, 0.2964924334250775, 0.27899440074550735, 0.28997447326318504, 0.28995854476678, 0.2838852804576613, 0.28560223591696354, 0.2835063175058242, 0.2669645174377665, 0.28037887700286107, 0.27467451847552027, 0.29287336182962986, 0.27339078865215644, 0.29365011531206753, 0.28600699850072575, 0.2790490275575328, 0.2746293607369526, 0.27994848983650356, 0.28163976180031125, 0.28474168702671976, 0.28871240171769125, 0.28858450577431116, 0.28275002387457904, 0.2858634780123986, 0.28521039521264047, 0.28021432749552594, 0.27945923033295217, 0.2787140265548813, 0.2786160535440606, 0.28536506577097265, 0.2765555398886154, 0.2857818863133794, 0.2815940662373587, 0.27108407007090396, 0.27676039518423606, 0.2753169539662981, 0.27674931784870926, 0.27722639294782864, 0.27712676482102305, 0.2822910811867315, 0.2800163699942029, 0.27873358944642174], 'loss': [0.559413152623996, 0.4661263376137042, 0.40333601654520446, 0.3515020856355095, 0.33395831981211144, 0.31968331266440686, 0.31432776685162417, 0.306448756427916, 0.30215171370505794, 0.29403365452021185, 0.28765984416854407, 0.2846833764556063, 0.28004307475728396, 0.27972682412268324, 0.2729151390276713, 0.27304064582885357, 0.2724147851015958, 0.2659270151741197, 0.27246819860676624, 0.2568870456584517, 0.2512412384860823, 0.25473382708086206, 0.24796524536869707, 0.2451996342785983, 0.24752240876254536, 0.24482442940623458, 0.24737361986454584, 0.24480982469197382, 0.2434952433529055, 0.23806714434211185, 0.23078570693016764, 0.23203173293255808, 0.22764432974623366, 0.22773585500117804, 0.21293130251677697, 0.21983026891423918, 0.20969723333177404, 0.20839346076080945, 0.20975911937653588, 0.20404457687647534, 0.20288454364876526, 0.19989910015974743, 0.20176131294060434, 0.196470716168054], 'acc': [0.9262254611531705, 0.9392041575273238, 0.9427830850324849, 0.9447394707708796, 0.9464729018701058, 0.9479392015853029, 0.9483953187632006, 0.9493570882465938, 0.9495574821535759, 0.9510200041683399, 0.9516193464622255, 0.9518389569115899, 0.9523996335902217, 0.95227759128295, 0.9529668951039453, 0.953535587080076, 0.9533092893183195, 0.9537181662394446, 0.9534343168627065, 0.9550003043588088, 0.9556588295507539, 0.9555224186232316, 0.9560445324705814, 0.9561867373645686, 0.9563928221841731, 0.9566511750147652, 0.9566854992921668, 0.9566946371908319, 0.9558680022319763, 0.9546840187820738, 0.9549183551606192, 0.9538043252134745, 0.9543269257114659, 0.9541673913834198, 0.9550413938799276, 0.9538636118645873, 0.9548769339805622, 0.9549004654502594, 0.9551724706762832, 0.9552030965584642, 0.955526962082041, 0.9558223698776577, 0.955595383184833, 0.955985094299285], 'mDice': [0.39655292015135546, 0.4971250628500128, 0.5650244153687973, 0.6211256861232833, 0.640058003548463, 0.655471510058152, 0.6612627234391947, 0.6697647505874716, 0.6743935295205274, 0.6831467112265244, 0.6900224674322105, 0.6932486042082862, 0.6982554289067471, 0.6985915890505933, 0.7059400253309147, 0.7057844687327605, 0.7064749861504468, 0.7134768637236462, 0.7064053698512452, 0.7232318014292884, 0.729314861136421, 0.7255425303653081, 0.7328490181503092, 0.7358205776801937, 0.733306424243383, 0.7362043219943379, 0.733429488950022, 0.7359145071482457, 0.7331533474511486, 0.7212231539544021, 0.7225060910262501, 0.7151763874283786, 0.7105202212650654, 0.7125810453935424, 0.724079176105818, 0.7139480379192543, 0.7242520303423451, 0.7214991505878603, 0.7201648122196115, 0.7252196720179326, 0.7289098540520712, 0.7324087444488147, 0.7309755459872507, 0.732075914670028], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              2020-01-22 00:51:39.959958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 00:51:39.960044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 00:51:39.960056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 00:51:39.960064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 00:51:39.960374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97436874 0.02563126]
Train on 25479 samples, validate on 528 samples
Epoch 1/300
 - 67s - loss: 0.0799 - acc: 0.9918 - mDice: 0.8445 - val_loss: -7.6542e-03 - val_acc: 0.9937 - val_mDice: 0.4971

Epoch 00001: val_mDice improved from -inf to 0.49712, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 64s - loss: 0.0490 - acc: 0.9945 - mDice: 0.9048 - val_loss: 0.0059 - val_acc: 0.9942 - val_mDice: 0.5192

Epoch 00002: val_mDice improved from 0.49712 to 0.51919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 64s - loss: 0.0439 - acc: 0.9950 - mDice: 0.9147 - val_loss: -3.2621e-02 - val_acc: 0.9945 - val_mDice: 0.5076

Epoch 00003: val_mDice did not improve from 0.51919
Epoch 4/300
 - 63s - loss: 0.0415 - acc: 0.9952 - mDice: 0.9194 - val_loss: 0.0962 - val_acc: 0.9938 - val_mDice: 0.5154

Epoch 00004: val_mDice did not improve from 0.51919
Epoch 5/300
 - 63s - loss: 0.0389 - acc: 0.9955 - mDice: 0.9245 - val_loss: 0.0748 - val_acc: 0.9944 - val_mDice: 0.5200

Epoch 00005: val_mDice improved from 0.51919 to 0.52004, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 6/300
 - 64s - loss: 0.0378 - acc: 0.9956 - mDice: 0.9266 - val_loss: 0.0478 - val_acc: 0.9939 - val_mDice: 0.5064

Epoch 00006: val_mDice did not improve from 0.52004
Epoch 7/300
 - 64s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9292 - val_loss: 0.0168 - val_acc: 0.9942 - val_mDice: 0.5194

Epoch 00007: val_mDice did not improve from 0.52004
Epoch 8/300
 - 64s - loss: 0.0355 - acc: 0.9958 - mDice: 0.9310 - val_loss: -7.5201e-05 - val_acc: 0.9943 - val_mDice: 0.5183

Epoch 00008: val_mDice did not improve from 0.52004
Epoch 9/300
 - 64s - loss: 0.0346 - acc: 0.9958 - mDice: 0.9328 - val_loss: 0.0102 - val_acc: 0.9943 - val_mDice: 0.4978

Epoch 00009: val_mDice did not improve from 0.52004
Epoch 10/300
 - 65s - loss: 0.0340 - acc: 0.9959 - mDice: 0.9341 - val_loss: -5.1437e-02 - val_acc: 0.9946 - val_mDice: 0.5073

Epoch 00010: val_mDice did not improve from 0.52004
Epoch 11/300
 - 66s - loss: 0.0331 - acc: 0.9960 - mDice: 0.9358 - val_loss: 0.0414 - val_acc: 0.9944 - val_mDice: 0.5125

Epoch 00011: val_mDice did not improve from 0.52004
Epoch 12/300
 - 66s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9350 - val_loss: 0.0927 - val_acc: 0.9940 - val_mDice: 0.5215

Epoch 00012: val_mDice improved from 0.52004 to 0.52146, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 13/300
 - 65s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9378 - val_loss: -1.6088e-02 - val_acc: 0.9947 - val_mDice: 0.5123

Epoch 00013: val_mDice did not improve from 0.52146
Epoch 14/300
 - 64s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9378 - val_loss: 0.0071 - val_acc: 0.9944 - val_mDice: 0.5039

Epoch 00014: val_mDice did not improve from 0.52146
Epoch 15/300
 - 64s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9389 - val_loss: 0.0112 - val_acc: 0.9942 - val_mDice: 0.5103

Epoch 00015: val_mDice did not improve from 0.52146
Epoch 16/300
 - 65s - loss: 0.0311 - acc: 0.9962 - mDice: 0.9397 - val_loss: -1.7646e-02 - val_acc: 0.9945 - val_mDice: 0.5150

Epoch 00016: val_mDice did not improve from 0.52146
Epoch 17/300
 - 65s - loss: 0.0306 - acc: 0.9962 - mDice: 0.9408 - val_loss: 0.0362 - val_acc: 0.9942 - val_mDice: 0.5214

Epoch 00017: val_mDice did not improve from 0.52146
Epoch 18/300
 - 64s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9407 - val_loss: 0.0744 - val_acc: 0.9944 - val_mDice: 0.5210

Epoch 00018: val_mDice did not improve from 0.52146
Epoch 19/300
 - 64s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9416 - val_loss: 0.0233 - val_acc: 0.9941 - val_mDice: 0.5097

Epoch 00019: val_mDice did not improve from 0.52146
Epoch 20/300
 - 64s - loss: 0.0300 - acc: 0.9963 - mDice: 0.9418 - val_loss: 0.0032 - val_acc: 0.9945 - val_mDice: 0.5166

Epoch 00020: val_mDice did not improve from 0.52146
Epoch 21/300
 - 64s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9427 - val_loss: 0.0185 - val_acc: 0.9942 - val_mDice: 0.5192

Epoch 00021: val_mDice did not improve from 0.52146
Epoch 22/300
 - 64s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9437 - val_loss: 0.0033 - val_acc: 0.9945 - val_mDice: 0.5116

Epoch 00022: val_mDice did not improve from 0.52146
Epoch 23/300
 - 64s - loss: 0.0291 - acc: 0.9964 - mDice: 0.9436 - val_loss: 0.0562 - val_acc: 0.9945 - val_mDice: 0.5042

Epoch 00023: val_mDice did not improve from 0.52146
Epoch 24/300
 - 64s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9441 - val_loss: 0.0040 - val_acc: 0.9943 - val_mDice: 0.5086

Epoch 00024: val_mDice did not improve from 0.52146
Epoch 25/300
 - 64s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9433 - val_loss: 5.2636e-04 - val_acc: 0.9944 - val_mDice: 0.5172

Epoch 00025: val_mDice did not improve from 0.52146
Epoch 26/300
 - 65s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9439 - val_loss: -1.4854e-02 - val_acc: 0.9946 - val_mDice: 0.5202

Epoch 00026: val_mDice did not improve from 0.52146
Epoch 27/300
 - 65s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9439 - val_loss: -3.9266e-02 - val_acc: 0.9945 - val_mDice: 0.4970

Epoch 00027: val_mDice did not improve from 0.52146

Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 28/300
 - 64s - loss: 0.0272 - acc: 0.9965 - mDice: 0.9473 - val_loss: -9.8927e-03 - val_acc: 0.9945 - val_mDice: 0.5090

Epoch 00028: val_mDice did not improve from 0.52146
Epoch 29/300
 - 64s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9478 - val_loss: 0.0239 - val_acc: 0.9944 - val_mDice: 0.5083

Epoch 00029: val_mDice did not improve from 0.52146
Epoch 30/300
 - 64s - loss: 0.0266 - acc: 0.9966 - mDice: 0.9485 - val_loss: -4.9254e-02 - val_acc: 0.9947 - val_mDice: 0.5028

Epoch 00030: val_mDice did not improve from 0.52146
Epoch 31/300
 - 65s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9489 - val_loss: -1.2584e-02 - val_acc: 0.9946 - val_mDice: 0.5054

Epoch 00031: val_mDice did not improve from 0.52146
Epoch 32/300
 - 64s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9492 - val_loss: 0.0127 - val_acc: 0.9946 - val_mDice: 0.5011

Epoch 00032: val_mDice did not improve from 0.52146
Epoch 33/300
 - 64s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9485 - val_loss: 0.0249 - val_acc: 0.9945 - val_mDice: 0.5085

Epoch 00033: val_mDice did not improve from 0.52146
Epoch 34/300
 - 64s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9493 - val_loss: 0.0386 - val_acc: 0.9947 - val_mDice: 0.5211

Epoch 00034: val_mDice did not improve from 0.52146
Epoch 35/300
 - 65s - loss: 0.0263 - acc: 0.9966 - mDice: 0.9490 - val_loss: 0.0054 - val_acc: 0.9947 - val_mDice: 0.5073

Epoch 00035: val_mDice did not improve from 0.52146
Epoch 36/300
 - 65s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9494 - val_loss: -5.0301e-02 - val_acc: 0.9947 - val_mDice: 0.5050

Epoch 00036: val_mDice did not improve from 0.52146
Epoch 37/300
 - 64s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9496 - val_loss: 0.0983 - val_acc: 0.9945 - val_mDice: 0.5078

Epoch 00037: val_mDice did not improve from 0.52146
Epoch 38/300
 - 64s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9494 - val_loss: 0.0044 - val_acc: 0.9945 - val_mDice: 0.4972

Epoch 00038: val_mDice did not improve from 0.52146
Epoch 39/300
 - 64s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9495 - val_loss: 0.0201 - val_acc: 0.9944 - val_mDice: 0.5118

Epoch 00039: val_mDice did not improve from 0.52146
Epoch 40/300
 - 64s - loss: 0.0259 - acc: 0.9967 - mDice: 0.9499 - val_loss: -1.2234e-02 - val_acc: 0.9945 - val_mDice: 0.5047

Epoch 00040: val_mDice did not improve from 0.52146
Epoch 41/300
 - 64s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9505 - val_loss: 0.0204 - val_acc: 0.9946 - val_mDice: 0.5151

Epoch 00041: val_mDice did not improve from 0.52146
Epoch 42/300
 - 64s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -5.8553e-03 - val_acc: 0.9946 - val_mDice: 0.5042

Epoch 00042: val_mDice did not improve from 0.52146

Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 43/300
 - 64s - loss: 0.0248 - acc: 0.9968 - mDice: 0.9520 - val_loss: 0.0047 - val_acc: 0.9946 - val_mDice: 0.5086

Epoch 00043: val_mDice did not improve from 0.52146
Epoch 44/300
 - 64s - loss: 0.0249 - acc: 0.9968 - mDice: 0.9518 - val_loss: 0.0212 - val_acc: 0.9946 - val_mDice: 0.5138

Epoch 00044: val_mDice did not improve from 0.52146
Epoch 45/300
 - 65s - loss: 0.0252 - acc: 0.9968 - mDice: 0.9511 - val_loss: 0.0238 - val_acc: 0.9945 - val_mDice: 0.5085

Epoch 00045: val_mDice did not improve from 0.52146
Epoch 46/300
 - 65s - loss: 0.0245 - acc: 0.9968 - mDice: 0.9525 - val_loss: -1.5070e-02 - val_acc: 0.9946 - val_mDice: 0.5104

Epoch 00046: val_mDice did not improve from 0.52146
Epoch 47/300
 - 65s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: -1.4448e-02 - val_acc: 0.9946 - val_mDice: 0.5091

Epoch 00047: val_mDice did not improve from 0.52146
Epoch 48/300
 - 65s - loss: 0.0248 - acc: 0.9968 - mDice: 0.9520 - val_loss: -1.1986e-02 - val_acc: 0.9946 - val_mDice: 0.5140

Epoch 00048: val_mDice did not improve from 0.52146
Epoch 49/300
 - 66s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9529 - val_loss: 0.0187 - val_acc: 0.9945 - val_mDice: 0.5186

Epoch 00049: val_mDice did not improve from 0.52146
Epoch 50/300
 - 66s - loss: 0.0245 - acc: 0.9968 - mDice: 0.9526 - val_loss: 0.0389 - val_acc: 0.9945 - val_mDice: 0.5161

Epoch 00050: val_mDice did not improve from 0.52146
Epoch 51/300
 - 66s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9526 - val_loss: -1.7030e-02 - val_acc: 0.9945 - val_mDice: 0.5143

Epoch 00051: val_mDice did not improve from 0.52146
Epoch 52/300
 - 65s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9524 - val_loss: -1.3449e-03 - val_acc: 0.9945 - val_mDice: 0.5207

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.50it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.87it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.28it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.80it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.26it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.41it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:36,  6.81it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:35,  6.97it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:39,  6.12it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:42,  5.76it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:40,  5.95it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:39,  6.13it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:38,  6.30it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:37,  6.44it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:36,  6.54it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.54it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:36,  6.55it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:35,  6.60it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:35,  6.61it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:34,  6.67it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:34,  6.71it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:34,  6.67it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:34,  6.68it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:34,  6.69it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:33,  6.74it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:33,  6.74it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.56it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:34,  6.61it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:32,  6.82it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:31,  7.06it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:31,  7.12it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:30,  7.28it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:29,  7.38it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:29,  7.42it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:29,  7.44it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:28,  7.52it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:28,  7.59it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:28,  7.62it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:27,  7.65it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:27,  7.66it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:29,  7.31it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:28,  7.44it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:28,  7.50it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:28,  7.41it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:28,  7.34it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:28,  7.35it/s]predicting train subjects:  17%|█▋        | 41/247 [00:05<00:28,  7.16it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:28,  7.20it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:28,  7.25it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:27,  7.30it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:27,  7.37it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:27,  7.31it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:27,  7.32it/s]predicting train subjects:  19%|█▉        | 48/247 [00:06<00:27,  7.36it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:26,  7.39it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:26,  7.39it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:26,  7.30it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:27,  7.21it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:26,  7.25it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:26,  7.31it/s]predicting train subjects:  22%|██▏       | 55/247 [00:07<00:26,  7.33it/s]predicting train subjects:  23%|██▎       | 56/247 [00:07<00:25,  7.37it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:25,  7.39it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:25,  7.31it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:26,  7.08it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:26,  6.94it/s]predicting train subjects:  25%|██▍       | 61/247 [00:08<00:27,  6.84it/s]predicting train subjects:  25%|██▌       | 62/247 [00:08<00:27,  6.80it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:27,  6.79it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:27,  6.74it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:26,  6.75it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:26,  6.75it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:27,  6.54it/s]predicting train subjects:  28%|██▊       | 68/247 [00:09<00:27,  6.50it/s]predicting train subjects:  28%|██▊       | 69/247 [00:09<00:27,  6.57it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:26,  6.57it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:26,  6.64it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:26,  6.70it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:25,  6.69it/s]predicting train subjects:  30%|██▉       | 74/247 [00:10<00:25,  6.67it/s]predicting train subjects:  30%|███       | 75/247 [00:10<00:25,  6.68it/s]predicting train subjects:  31%|███       | 76/247 [00:10<00:25,  6.69it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:29,  5.74it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:31,  5.40it/s]predicting train subjects:  32%|███▏      | 79/247 [00:11<00:28,  5.81it/s]predicting train subjects:  32%|███▏      | 80/247 [00:11<00:28,  5.83it/s]predicting train subjects:  33%|███▎      | 81/247 [00:11<00:31,  5.30it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:31,  5.31it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:29,  5.47it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:29,  5.53it/s]predicting train subjects:  34%|███▍      | 85/247 [00:12<00:29,  5.57it/s]predicting train subjects:  35%|███▍      | 86/247 [00:12<00:28,  5.67it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:27,  5.72it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:27,  5.77it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:27,  5.81it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:26,  5.84it/s]predicting train subjects:  37%|███▋      | 91/247 [00:13<00:26,  5.80it/s]predicting train subjects:  37%|███▋      | 92/247 [00:13<00:26,  5.82it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:26,  5.82it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:26,  5.78it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:26,  5.76it/s]predicting train subjects:  39%|███▉      | 96/247 [00:14<00:25,  5.81it/s]predicting train subjects:  39%|███▉      | 97/247 [00:14<00:26,  5.74it/s]predicting train subjects:  40%|███▉      | 98/247 [00:14<00:27,  5.48it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:26,  5.54it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:25,  5.69it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:25,  5.83it/s]predicting train subjects:  41%|████▏     | 102/247 [00:15<00:25,  5.70it/s]predicting train subjects:  42%|████▏     | 103/247 [00:15<00:25,  5.73it/s]predicting train subjects:  42%|████▏     | 104/247 [00:15<00:24,  5.88it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:23,  5.98it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:24,  5.84it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:23,  5.94it/s]predicting train subjects:  44%|████▎     | 108/247 [00:16<00:23,  6.02it/s]predicting train subjects:  44%|████▍     | 109/247 [00:16<00:22,  6.09it/s]predicting train subjects:  45%|████▍     | 110/247 [00:16<00:22,  6.14it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:22,  6.17it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:21,  6.19it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:21,  6.21it/s]predicting train subjects:  46%|████▌     | 114/247 [00:17<00:21,  6.22it/s]predicting train subjects:  47%|████▋     | 115/247 [00:17<00:21,  6.21it/s]predicting train subjects:  47%|████▋     | 116/247 [00:17<00:21,  6.23it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:20,  6.23it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:20,  6.41it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:19,  6.55it/s]predicting train subjects:  49%|████▊     | 120/247 [00:18<00:19,  6.65it/s]predicting train subjects:  49%|████▉     | 121/247 [00:18<00:18,  6.70it/s]predicting train subjects:  49%|████▉     | 122/247 [00:18<00:18,  6.63it/s]predicting train subjects:  50%|████▉     | 123/247 [00:18<00:18,  6.70it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:18,  6.66it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:18,  6.74it/s]predicting train subjects:  51%|█████     | 126/247 [00:19<00:17,  6.78it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:19<00:17,  6.79it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:19<00:17,  6.79it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:19<00:17,  6.74it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:19<00:17,  6.77it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:17,  6.54it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:17,  6.63it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:20<00:16,  6.72it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:20<00:16,  6.75it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:20<00:16,  6.75it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:20<00:16,  6.81it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:21<00:15,  6.94it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:16,  6.72it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:21<00:15,  6.85it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:21<00:15,  7.01it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:21<00:14,  7.12it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:21<00:14,  7.13it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:21<00:14,  7.20it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:21<00:14,  7.22it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:14,  7.24it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:22<00:13,  7.25it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:22<00:13,  7.29it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:22<00:13,  7.21it/s]predicting train subjects:  60%|██████    | 149/247 [00:22<00:13,  7.26it/s]predicting train subjects:  61%|██████    | 150/247 [00:22<00:13,  7.19it/s]predicting train subjects:  61%|██████    | 151/247 [00:22<00:13,  7.26it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:13,  7.27it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:23<00:12,  7.26it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:23<00:13,  6.83it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:23<00:13,  6.60it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:23<00:14,  6.46it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:23<00:14,  6.35it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:24<00:14,  6.24it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:24<00:14,  6.13it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:24<00:14,  5.97it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:24<00:14,  6.00it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:24<00:14,  6.00it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:24<00:14,  5.75it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:25<00:14,  5.80it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:25<00:14,  5.84it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:25<00:13,  5.85it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:25<00:13,  5.91it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:25<00:13,  5.93it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:25<00:13,  5.91it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:26<00:13,  5.91it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:26<00:12,  5.94it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:26<00:13,  5.73it/s]predicting train subjects:  70%|███████   | 173/247 [00:26<00:13,  5.37it/s]predicting train subjects:  70%|███████   | 174/247 [00:26<00:12,  5.75it/s]predicting train subjects:  71%|███████   | 175/247 [00:27<00:13,  5.33it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:27<00:12,  5.74it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:27<00:11,  6.04it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:27<00:11,  6.05it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:27<00:10,  6.26it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:27<00:10,  6.43it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:27<00:09,  6.61it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:28<00:09,  6.66it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:28<00:09,  6.73it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:28<00:09,  6.82it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:28<00:09,  6.87it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:28<00:08,  6.80it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:28<00:08,  6.88it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:28<00:08,  6.92it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:29<00:08,  6.94it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:29<00:08,  6.97it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:29<00:08,  6.95it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:29<00:07,  6.90it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:29<00:07,  6.94it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:29<00:07,  7.12it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:29<00:07,  7.31it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:30<00:06,  7.37it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:30<00:06,  7.46it/s]predicting train subjects:  80%|████████  | 198/247 [00:30<00:06,  7.51it/s]predicting train subjects:  81%|████████  | 199/247 [00:30<00:06,  7.55it/s]predicting train subjects:  81%|████████  | 200/247 [00:30<00:06,  7.58it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:30<00:06,  7.61it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:30<00:05,  7.63it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:30<00:05,  7.64it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:31<00:05,  7.23it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:31<00:05,  7.37it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:31<00:05,  7.46it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:31<00:05,  7.41it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:31<00:05,  7.46it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:31<00:05,  7.55it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:31<00:04,  7.61it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:32<00:04,  7.59it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:32<00:04,  7.48it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:32<00:04,  7.18it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:32<00:04,  7.18it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:32<00:04,  7.18it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:32<00:04,  7.17it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:32<00:04,  7.07it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:33<00:04,  7.05it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:33<00:03,  7.07it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:33<00:03,  7.07it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:33<00:03,  7.11it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:33<00:03,  7.11it/s]predicting train subjects:  90%|█████████ | 223/247 [00:33<00:03,  7.15it/s]predicting train subjects:  91%|█████████ | 224/247 [00:33<00:03,  7.20it/s]predicting train subjects:  91%|█████████ | 225/247 [00:34<00:03,  7.15it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:34<00:02,  7.16it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:34<00:02,  7.04it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:34<00:02,  7.09it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:34<00:02,  7.17it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:34<00:02,  6.77it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:34<00:02,  6.09it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:35<00:02,  6.10it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:35<00:02,  5.78it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:35<00:02,  5.69it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:35<00:02,  5.78it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:35<00:01,  5.87it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:35<00:01,  5.97it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:36<00:01,  6.02it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:36<00:01,  6.02it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:36<00:01,  6.10it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:36<00:00,  6.13it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:36<00:00,  6.15it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:36<00:00,  6.19it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:37<00:00,  6.19it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:37<00:00,  6.22it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:37<00:00,  6.13it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  6.15it/s]predicting train subjects: 100%|██████████| 247/247 [00:37<00:00,  6.57it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 77.60it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 81.84it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 81.54it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 81.24it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 82.02it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 83.07it/s]saving BB  train1-THALAMUS:  22%|██▏       | 54/247 [00:00<00:02, 84.87it/s]saving BB  train1-THALAMUS:  26%|██▌       | 63/247 [00:00<00:02, 84.26it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 82.55it/s]saving BB  train1-THALAMUS:  32%|███▏      | 79/247 [00:00<00:02, 81.08it/s]saving BB  train1-THALAMUS:  35%|███▌      | 87/247 [00:01<00:02, 76.20it/s]saving BB  train1-THALAMUS:  38%|███▊      | 95/247 [00:01<00:02, 73.59it/s]saving BB  train1-THALAMUS:  42%|████▏     | 103/247 [00:01<00:01, 73.81it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 75.24it/s]saving BB  train1-THALAMUS:  48%|████▊     | 119/247 [00:01<00:01, 76.37it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 128/247 [00:01<00:01, 78.26it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 80.23it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 147/247 [00:01<00:01, 83.63it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 156/247 [00:01<00:01, 84.40it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 165/247 [00:02<00:01, 81.82it/s]saving BB  train1-THALAMUS:  70%|███████   | 174/247 [00:02<00:00, 80.15it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 183/247 [00:02<00:00, 78.76it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 191/247 [00:02<00:00, 76.70it/s]saving BB  train1-THALAMUS:  81%|████████  | 200/247 [00:02<00:00, 78.46it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 209/247 [00:02<00:00, 79.34it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 218/247 [00:02<00:00, 80.85it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 227/247 [00:02<00:00, 82.31it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 236/247 [00:02<00:00, 81.09it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 245/247 [00:03<00:00, 79.59it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 80.00it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:46,  1.08it/s]Loading train:   1%|          | 2/247 [00:01<03:38,  1.12it/s]Loading train:   1%|          | 3/247 [00:02<03:27,  1.18it/s]Loading train:   2%|▏         | 4/247 [00:03<03:33,  1.14it/s]Loading train:   2%|▏         | 5/247 [00:04<03:15,  1.24it/s]Loading train:   2%|▏         | 6/247 [00:04<03:01,  1.33it/s]Loading train:   3%|▎         | 7/247 [00:05<02:54,  1.37it/s]Loading train:   3%|▎         | 8/247 [00:06<02:47,  1.43it/s]Loading train:   4%|▎         | 9/247 [00:06<02:41,  1.47it/s]Loading train:   4%|▍         | 10/247 [00:07<02:38,  1.49it/s]Loading train:   4%|▍         | 11/247 [00:07<02:35,  1.52it/s]Loading train:   5%|▍         | 12/247 [00:08<02:32,  1.55it/s]Loading train:   5%|▌         | 13/247 [00:09<02:29,  1.56it/s]Loading train:   6%|▌         | 14/247 [00:09<02:28,  1.57it/s]Loading train:   6%|▌         | 15/247 [00:10<02:29,  1.56it/s]Loading train:   6%|▋         | 16/247 [00:11<02:26,  1.57it/s]Loading train:   7%|▋         | 17/247 [00:11<02:27,  1.56it/s]Loading train:   7%|▋         | 18/247 [00:12<02:28,  1.55it/s]Loading train:   8%|▊         | 19/247 [00:13<02:28,  1.54it/s]Loading train:   8%|▊         | 20/247 [00:13<02:27,  1.54it/s]Loading train:   9%|▊         | 21/247 [00:14<02:26,  1.54it/s]Loading train:   9%|▉         | 22/247 [00:14<02:23,  1.57it/s]Loading train:   9%|▉         | 23/247 [00:15<02:17,  1.62it/s]Loading train:  10%|▉         | 24/247 [00:16<02:13,  1.67it/s]Loading train:  10%|█         | 25/247 [00:16<02:09,  1.71it/s]Loading train:  11%|█         | 26/247 [00:17<02:07,  1.73it/s]Loading train:  11%|█         | 27/247 [00:17<02:05,  1.75it/s]Loading train:  11%|█▏        | 28/247 [00:18<02:04,  1.76it/s]Loading train:  12%|█▏        | 29/247 [00:18<02:05,  1.73it/s]Loading train:  12%|█▏        | 30/247 [00:19<02:04,  1.74it/s]Loading train:  13%|█▎        | 31/247 [00:20<02:04,  1.74it/s]Loading train:  13%|█▎        | 32/247 [00:20<02:03,  1.74it/s]Loading train:  13%|█▎        | 33/247 [00:21<02:01,  1.76it/s]Loading train:  14%|█▍        | 34/247 [00:21<02:02,  1.74it/s]Loading train:  14%|█▍        | 35/247 [00:22<02:00,  1.75it/s]Loading train:  15%|█▍        | 36/247 [00:22<02:00,  1.75it/s]Loading train:  15%|█▍        | 37/247 [00:23<02:02,  1.72it/s]Loading train:  15%|█▌        | 38/247 [00:24<01:59,  1.75it/s]Loading train:  16%|█▌        | 39/247 [00:24<01:57,  1.77it/s]Loading train:  16%|█▌        | 40/247 [00:25<01:58,  1.75it/s]Loading train:  17%|█▋        | 41/247 [00:25<01:58,  1.74it/s]Loading train:  17%|█▋        | 42/247 [00:26<01:58,  1.73it/s]Loading train:  17%|█▋        | 43/247 [00:26<01:59,  1.71it/s]Loading train:  18%|█▊        | 44/247 [00:27<01:58,  1.71it/s]Loading train:  18%|█▊        | 45/247 [00:28<01:57,  1.71it/s]Loading train:  19%|█▊        | 46/247 [00:28<01:57,  1.71it/s]Loading train:  19%|█▉        | 47/247 [00:29<01:59,  1.68it/s]Loading train:  19%|█▉        | 48/247 [00:29<01:58,  1.68it/s]Loading train:  20%|█▉        | 49/247 [00:30<01:58,  1.68it/s]Loading train:  20%|██        | 50/247 [00:31<01:56,  1.69it/s]Loading train:  21%|██        | 51/247 [00:31<01:56,  1.68it/s]Loading train:  21%|██        | 52/247 [00:32<01:55,  1.69it/s]Loading train:  21%|██▏       | 53/247 [00:32<01:54,  1.70it/s]Loading train:  22%|██▏       | 54/247 [00:33<01:53,  1.71it/s]Loading train:  22%|██▏       | 55/247 [00:34<01:53,  1.70it/s]Loading train:  23%|██▎       | 56/247 [00:34<01:52,  1.70it/s]Loading train:  23%|██▎       | 57/247 [00:35<01:51,  1.70it/s]Loading train:  23%|██▎       | 58/247 [00:35<01:52,  1.68it/s]Loading train:  24%|██▍       | 59/247 [00:36<01:56,  1.61it/s]Loading train:  24%|██▍       | 60/247 [00:37<01:59,  1.57it/s]Loading train:  25%|██▍       | 61/247 [00:37<02:00,  1.54it/s]Loading train:  25%|██▌       | 62/247 [00:38<02:02,  1.51it/s]Loading train:  26%|██▌       | 63/247 [00:39<02:02,  1.50it/s]Loading train:  26%|██▌       | 64/247 [00:39<02:01,  1.50it/s]Loading train:  26%|██▋       | 65/247 [00:40<02:01,  1.50it/s]Loading train:  27%|██▋       | 66/247 [00:41<02:01,  1.49it/s]Loading train:  27%|██▋       | 67/247 [00:41<02:00,  1.50it/s]Loading train:  28%|██▊       | 68/247 [00:42<02:00,  1.48it/s]Loading train:  28%|██▊       | 69/247 [00:43<01:58,  1.50it/s]Loading train:  28%|██▊       | 70/247 [00:43<02:00,  1.47it/s]Loading train:  29%|██▊       | 71/247 [00:44<01:59,  1.47it/s]Loading train:  29%|██▉       | 72/247 [00:45<01:57,  1.49it/s]Loading train:  30%|██▉       | 73/247 [00:45<01:56,  1.49it/s]Loading train:  30%|██▉       | 74/247 [00:46<01:54,  1.51it/s]Loading train:  30%|███       | 75/247 [00:47<01:55,  1.49it/s]Loading train:  31%|███       | 76/247 [00:47<01:55,  1.49it/s]Loading train:  31%|███       | 77/247 [00:49<02:18,  1.23it/s]Loading train:  32%|███▏      | 78/247 [00:50<02:27,  1.14it/s]Loading train:  32%|███▏      | 79/247 [00:51<02:28,  1.13it/s]Loading train:  32%|███▏      | 80/247 [00:51<02:26,  1.14it/s]Loading train:  33%|███▎      | 81/247 [00:52<02:32,  1.09it/s]Loading train:  33%|███▎      | 82/247 [00:53<02:23,  1.15it/s]Loading train:  34%|███▎      | 83/247 [00:54<02:19,  1.18it/s]Loading train:  34%|███▍      | 84/247 [00:55<02:15,  1.21it/s]Loading train:  34%|███▍      | 85/247 [00:56<02:12,  1.22it/s]Loading train:  35%|███▍      | 86/247 [00:56<02:10,  1.24it/s]Loading train:  35%|███▌      | 87/247 [00:57<02:07,  1.26it/s]Loading train:  36%|███▌      | 88/247 [00:58<02:03,  1.28it/s]Loading train:  36%|███▌      | 89/247 [00:59<02:00,  1.31it/s]Loading train:  36%|███▋      | 90/247 [00:59<01:59,  1.32it/s]Loading train:  37%|███▋      | 91/247 [01:00<01:58,  1.31it/s]Loading train:  37%|███▋      | 92/247 [01:01<01:57,  1.32it/s]Loading train:  38%|███▊      | 93/247 [01:02<01:56,  1.32it/s]Loading train:  38%|███▊      | 94/247 [01:02<01:59,  1.28it/s]Loading train:  38%|███▊      | 95/247 [01:03<01:59,  1.27it/s]Loading train:  39%|███▉      | 96/247 [01:04<01:55,  1.31it/s]Loading train:  39%|███▉      | 97/247 [01:05<01:53,  1.32it/s]Loading train:  40%|███▉      | 98/247 [01:05<01:52,  1.33it/s]Loading train:  40%|████      | 99/247 [01:06<01:53,  1.31it/s]Loading train:  40%|████      | 100/247 [01:07<01:47,  1.36it/s]Loading train:  41%|████      | 101/247 [01:08<01:43,  1.42it/s]Loading train:  41%|████▏     | 102/247 [01:08<01:39,  1.46it/s]Loading train:  42%|████▏     | 103/247 [01:09<01:36,  1.49it/s]Loading train:  42%|████▏     | 104/247 [01:09<01:34,  1.52it/s]Loading train:  43%|████▎     | 105/247 [01:10<01:33,  1.52it/s]Loading train:  43%|████▎     | 106/247 [01:11<01:31,  1.53it/s]Loading train:  43%|████▎     | 107/247 [01:11<01:30,  1.54it/s]Loading train:  44%|████▎     | 108/247 [01:12<01:31,  1.52it/s]Loading train:  44%|████▍     | 109/247 [01:13<01:32,  1.49it/s]Loading train:  45%|████▍     | 110/247 [01:13<01:31,  1.50it/s]Loading train:  45%|████▍     | 111/247 [01:14<01:31,  1.49it/s]Loading train:  45%|████▌     | 112/247 [01:15<01:29,  1.51it/s]Loading train:  46%|████▌     | 113/247 [01:15<01:27,  1.53it/s]Loading train:  46%|████▌     | 114/247 [01:16<01:26,  1.54it/s]Loading train:  47%|████▋     | 115/247 [01:17<01:25,  1.54it/s]Loading train:  47%|████▋     | 116/247 [01:17<01:26,  1.52it/s]Loading train:  47%|████▋     | 117/247 [01:18<01:25,  1.52it/s]Loading train:  48%|████▊     | 118/247 [01:19<01:23,  1.55it/s]Loading train:  48%|████▊     | 119/247 [01:19<01:21,  1.56it/s]Loading train:  49%|████▊     | 120/247 [01:20<01:21,  1.55it/s]Loading train:  49%|████▉     | 121/247 [01:20<01:20,  1.57it/s]Loading train:  49%|████▉     | 122/247 [01:21<01:20,  1.56it/s]Loading train:  50%|████▉     | 123/247 [01:22<01:20,  1.53it/s]Loading train:  50%|█████     | 124/247 [01:22<01:20,  1.53it/s]Loading train:  51%|█████     | 125/247 [01:23<01:19,  1.53it/s]Loading train:  51%|█████     | 126/247 [01:24<01:18,  1.54it/s]Loading train:  51%|█████▏    | 127/247 [01:24<01:17,  1.54it/s]Loading train:  52%|█████▏    | 128/247 [01:25<01:16,  1.55it/s]Loading train:  52%|█████▏    | 129/247 [01:26<01:15,  1.56it/s]Loading train:  53%|█████▎    | 130/247 [01:26<01:14,  1.56it/s]Loading train:  53%|█████▎    | 131/247 [01:27<01:13,  1.58it/s]Loading train:  53%|█████▎    | 132/247 [01:28<01:11,  1.60it/s]Loading train:  54%|█████▍    | 133/247 [01:28<01:10,  1.62it/s]Loading train:  54%|█████▍    | 134/247 [01:29<01:09,  1.63it/s]Loading train:  55%|█████▍    | 135/247 [01:29<01:08,  1.63it/s]Loading train:  55%|█████▌    | 136/247 [01:30<01:06,  1.66it/s]Loading train:  55%|█████▌    | 137/247 [01:30<01:05,  1.69it/s]Loading train:  56%|█████▌    | 138/247 [01:31<01:03,  1.70it/s]Loading train:  56%|█████▋    | 139/247 [01:32<01:03,  1.71it/s]Loading train:  57%|█████▋    | 140/247 [01:32<01:02,  1.72it/s]Loading train:  57%|█████▋    | 141/247 [01:33<01:01,  1.73it/s]Loading train:  57%|█████▋    | 142/247 [01:33<01:01,  1.72it/s]Loading train:  58%|█████▊    | 143/247 [01:34<01:00,  1.72it/s]Loading train:  58%|█████▊    | 144/247 [01:35<00:59,  1.72it/s]Loading train:  59%|█████▊    | 145/247 [01:35<00:58,  1.74it/s]Loading train:  59%|█████▉    | 146/247 [01:36<00:58,  1.72it/s]Loading train:  60%|█████▉    | 147/247 [01:36<00:59,  1.68it/s]Loading train:  60%|█████▉    | 148/247 [01:37<00:58,  1.69it/s]Loading train:  60%|██████    | 149/247 [01:37<00:57,  1.70it/s]Loading train:  61%|██████    | 150/247 [01:38<00:56,  1.70it/s]Loading train:  61%|██████    | 151/247 [01:39<00:56,  1.70it/s]Loading train:  62%|██████▏   | 152/247 [01:39<00:55,  1.71it/s]Loading train:  62%|██████▏   | 153/247 [01:40<00:55,  1.71it/s]Loading train:  62%|██████▏   | 154/247 [01:40<00:55,  1.66it/s]Loading train:  63%|██████▎   | 155/247 [01:41<00:55,  1.65it/s]Loading train:  63%|██████▎   | 156/247 [01:42<00:56,  1.61it/s]Loading train:  64%|██████▎   | 157/247 [01:42<00:57,  1.58it/s]Loading train:  64%|██████▍   | 158/247 [01:43<00:56,  1.57it/s]Loading train:  64%|██████▍   | 159/247 [01:44<00:55,  1.57it/s]Loading train:  65%|██████▍   | 160/247 [01:44<00:55,  1.57it/s]Loading train:  65%|██████▌   | 161/247 [01:45<00:55,  1.56it/s]Loading train:  66%|██████▌   | 162/247 [01:46<00:53,  1.57it/s]Loading train:  66%|██████▌   | 163/247 [01:46<00:53,  1.56it/s]Loading train:  66%|██████▋   | 164/247 [01:47<00:53,  1.55it/s]Loading train:  67%|██████▋   | 165/247 [01:48<00:52,  1.55it/s]Loading train:  67%|██████▋   | 166/247 [01:48<00:52,  1.54it/s]Loading train:  68%|██████▊   | 167/247 [01:49<00:52,  1.53it/s]Loading train:  68%|██████▊   | 168/247 [01:50<00:51,  1.53it/s]Loading train:  68%|██████▊   | 169/247 [01:50<00:50,  1.55it/s]Loading train:  69%|██████▉   | 170/247 [01:51<00:49,  1.56it/s]Loading train:  69%|██████▉   | 171/247 [01:51<00:48,  1.57it/s]Loading train:  70%|██████▉   | 172/247 [01:52<00:53,  1.39it/s]Loading train:  70%|███████   | 173/247 [01:53<00:55,  1.33it/s]Loading train:  70%|███████   | 174/247 [01:54<00:56,  1.30it/s]Loading train:  71%|███████   | 175/247 [01:55<01:00,  1.20it/s]Loading train:  71%|███████▏  | 176/247 [01:56<00:54,  1.31it/s]Loading train:  72%|███████▏  | 177/247 [01:56<00:49,  1.40it/s]Loading train:  72%|███████▏  | 178/247 [01:57<00:46,  1.47it/s]Loading train:  72%|███████▏  | 179/247 [01:57<00:44,  1.51it/s]Loading train:  73%|███████▎  | 180/247 [01:58<00:43,  1.55it/s]Loading train:  73%|███████▎  | 181/247 [01:59<00:41,  1.57it/s]Loading train:  74%|███████▎  | 182/247 [01:59<00:40,  1.61it/s]Loading train:  74%|███████▍  | 183/247 [02:00<00:39,  1.61it/s]Loading train:  74%|███████▍  | 184/247 [02:00<00:39,  1.61it/s]Loading train:  75%|███████▍  | 185/247 [02:01<00:38,  1.62it/s]Loading train:  75%|███████▌  | 186/247 [02:02<00:38,  1.60it/s]Loading train:  76%|███████▌  | 187/247 [02:02<00:37,  1.59it/s]Loading train:  76%|███████▌  | 188/247 [02:03<00:36,  1.60it/s]Loading train:  77%|███████▋  | 189/247 [02:04<00:36,  1.61it/s]Loading train:  77%|███████▋  | 190/247 [02:04<00:34,  1.63it/s]Loading train:  77%|███████▋  | 191/247 [02:05<00:34,  1.65it/s]Loading train:  78%|███████▊  | 192/247 [02:05<00:34,  1.61it/s]Loading train:  78%|███████▊  | 193/247 [02:06<00:33,  1.61it/s]Loading train:  79%|███████▊  | 194/247 [02:07<00:32,  1.62it/s]Loading train:  79%|███████▉  | 195/247 [02:07<00:32,  1.62it/s]Loading train:  79%|███████▉  | 196/247 [02:08<00:31,  1.63it/s]Loading train:  80%|███████▉  | 197/247 [02:08<00:31,  1.61it/s]Loading train:  80%|████████  | 198/247 [02:09<00:30,  1.62it/s]Loading train:  81%|████████  | 199/247 [02:10<00:29,  1.62it/s]Loading train:  81%|████████  | 200/247 [02:10<00:29,  1.61it/s]Loading train:  81%|████████▏ | 201/247 [02:11<00:28,  1.63it/s]Loading train:  82%|████████▏ | 202/247 [02:12<00:27,  1.64it/s]Loading train:  82%|████████▏ | 203/247 [02:12<00:26,  1.65it/s]Loading train:  83%|████████▎ | 204/247 [02:13<00:26,  1.65it/s]Loading train:  83%|████████▎ | 205/247 [02:13<00:25,  1.64it/s]Loading train:  83%|████████▎ | 206/247 [02:14<00:25,  1.64it/s]Loading train:  84%|████████▍ | 207/247 [02:15<00:24,  1.61it/s]Loading train:  84%|████████▍ | 208/247 [02:15<00:24,  1.58it/s]Loading train:  85%|████████▍ | 209/247 [02:16<00:23,  1.59it/s]Loading train:  85%|████████▌ | 210/247 [02:16<00:22,  1.63it/s]Loading train:  85%|████████▌ | 211/247 [02:18<00:28,  1.25it/s]Loading train:  86%|████████▌ | 212/247 [02:20<00:46,  1.33s/it]Loading train:  86%|████████▌ | 213/247 [02:24<01:10,  2.07s/it]Loading train:  87%|████████▋ | 214/247 [02:29<01:33,  2.83s/it]Loading train:  87%|████████▋ | 215/247 [02:32<01:38,  3.08s/it]Loading train:  87%|████████▋ | 216/247 [02:36<01:44,  3.36s/it]Loading train:  88%|████████▊ | 217/247 [02:40<01:45,  3.53s/it]Loading train:  88%|████████▊ | 218/247 [02:44<01:46,  3.67s/it]Loading train:  89%|████████▊ | 219/247 [02:48<01:44,  3.73s/it]Loading train:  89%|████████▉ | 220/247 [02:52<01:40,  3.73s/it]Loading train:  89%|████████▉ | 221/247 [02:56<01:40,  3.85s/it]Loading train:  90%|████████▉ | 222/247 [03:00<01:36,  3.85s/it]Loading train:  90%|█████████ | 223/247 [03:04<01:32,  3.86s/it]Loading train:  91%|█████████ | 224/247 [03:08<01:30,  3.93s/it]Loading train:  91%|█████████ | 225/247 [03:12<01:26,  3.92s/it]Loading train:  91%|█████████▏| 226/247 [03:16<01:23,  3.99s/it]Loading train:  92%|█████████▏| 227/247 [03:20<01:20,  4.03s/it]Loading train:  92%|█████████▏| 228/247 [03:24<01:16,  4.00s/it]Loading train:  93%|█████████▎| 229/247 [03:27<01:07,  3.77s/it]Loading train:  93%|█████████▎| 230/247 [03:32<01:10,  4.16s/it]Loading train:  94%|█████████▎| 231/247 [03:37<01:09,  4.35s/it]Loading train:  94%|█████████▍| 232/247 [03:42<01:06,  4.43s/it]Loading train:  94%|█████████▍| 233/247 [03:47<01:04,  4.60s/it]Loading train:  95%|█████████▍| 234/247 [03:51<01:00,  4.65s/it]Loading train:  95%|█████████▌| 235/247 [03:56<00:56,  4.72s/it]Loading train:  96%|█████████▌| 236/247 [04:01<00:52,  4.77s/it]Loading train:  96%|█████████▌| 237/247 [04:06<00:47,  4.75s/it]Loading train:  96%|█████████▋| 238/247 [04:11<00:42,  4.77s/it]Loading train:  97%|█████████▋| 239/247 [04:16<00:38,  4.78s/it]Loading train:  97%|█████████▋| 240/247 [04:20<00:33,  4.78s/it]Loading train:  98%|█████████▊| 241/247 [04:25<00:29,  4.84s/it]Loading train:  98%|█████████▊| 242/247 [04:29<00:22,  4.60s/it]Loading train:  98%|█████████▊| 243/247 [04:34<00:18,  4.71s/it]Loading train:  99%|█████████▉| 244/247 [04:39<00:13,  4.66s/it]Loading train:  99%|█████████▉| 245/247 [04:43<00:09,  4.66s/it]Loading train: 100%|█████████▉| 246/247 [04:48<00:04,  4.71s/it]Loading train: 100%|██████████| 247/247 [04:53<00:00,  4.73s/it]Loading train: 100%|██████████| 247/247 [04:53<00:00,  1.19s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 57.36it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 57.53it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:03, 57.37it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:03, 58.58it/s]concatenating: train:  13%|█▎        | 32/247 [00:00<00:03, 60.40it/s]concatenating: train:  16%|█▌        | 39/247 [00:00<00:03, 61.27it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:03, 61.56it/s]concatenating: train:  21%|██▏       | 53/247 [00:00<00:03, 61.55it/s]concatenating: train:  24%|██▍       | 59/247 [00:00<00:03, 59.60it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 54.60it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 54.29it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 53.66it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 54.58it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:02, 53.84it/s]concatenating: train:  38%|███▊      | 95/247 [00:01<00:02, 53.21it/s]concatenating: train:  41%|████      | 101/247 [00:01<00:02, 53.85it/s]concatenating: train:  44%|████▎     | 108/247 [00:01<00:02, 56.36it/s]concatenating: train:  47%|████▋     | 115/247 [00:02<00:02, 58.12it/s]concatenating: train:  49%|████▉     | 121/247 [00:02<00:02, 57.22it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:02, 56.98it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:01, 57.35it/s]concatenating: train:  57%|█████▋    | 140/247 [00:02<00:01, 58.96it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:01, 60.53it/s]concatenating: train:  62%|██████▏   | 154/247 [00:02<00:01, 61.68it/s]concatenating: train:  66%|██████▌   | 162/247 [00:02<00:01, 63.92it/s]concatenating: train:  68%|██████▊   | 169/247 [00:02<00:01, 64.84it/s]concatenating: train:  71%|███████▏  | 176/247 [00:02<00:01, 64.37it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:00, 64.12it/s]concatenating: train:  77%|███████▋  | 190/247 [00:03<00:00, 63.59it/s]concatenating: train:  80%|███████▉  | 197/247 [00:03<00:00, 61.52it/s]concatenating: train:  83%|████████▎ | 204/247 [00:03<00:00, 56.48it/s]concatenating: train:  85%|████████▌ | 210/247 [00:03<00:00, 52.91it/s]concatenating: train:  87%|████████▋ | 216/247 [00:03<00:00, 50.54it/s]concatenating: train:  90%|████████▉ | 222/247 [00:03<00:00, 47.61it/s]concatenating: train:  92%|█████████▏| 227/247 [00:03<00:00, 46.40it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 47.06it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 46.46it/s]concatenating: train:  98%|█████████▊| 242/247 [00:04<00:00, 46.53it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 46.47it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 55.88it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:12<00:48, 12.01s/it]Loading test:  40%|████      | 2/5 [00:25<00:37, 12.58s/it]
Epoch 00052: val_mDice did not improve from 0.52146
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [-0.007654216846056057, 0.005894558701777097, -0.03262095805257559, 0.09616627242190368, 0.07484089425115874, 0.04780133277403586, 0.016763847801044132, -7.520122171351404e-05, 0.010206116419849974, -0.051436857066371224, 0.04141192332926122, 0.09266704473305833, -0.01608840333805843, 0.007092614037295182, 0.011194665238938549, -0.017646109064420063, 0.03618973784261581, 0.0743909953726512, 0.023296905399271935, 0.003225180066444657, 0.018501286084453266, 0.003283529824605494, 0.05623775404511076, 0.0039936839461778145, 0.0005263556923830148, -0.014854176703727606, -0.03926610591059381, -0.009892692958766764, 0.02390692981355118, -0.04925395703564087, -0.012584010054442015, 0.012657959973721794, 0.02486883137713779, 0.0386290874219302, 0.005427176302129572, -0.05030098670359814, 0.09829191205966653, 0.004375103804649729, 0.02007523224209294, -0.012234425567316286, 0.020442038859156044, -0.005855345562326185, 0.004705844955010848, 0.021182308368610615, 0.023760254269070698, -0.015070027361313501, -0.014448261735114184, -0.011986309803570763, 0.018730024129829624, 0.03893016998402097, -0.0170295313000679, -0.001344875686547973], 'val_acc': [0.993720097523747, 0.9941808899695223, 0.994479471986944, 0.993830852662072, 0.994438166419665, 0.9939328409505613, 0.9942491869583274, 0.9943467940796505, 0.9942868022304593, 0.994631302401875, 0.9944063287341234, 0.9939962984486059, 0.9946543754953326, 0.9943521020538879, 0.9941596614592003, 0.9944914685505809, 0.9941695831490286, 0.9944273246960207, 0.9941499723177968, 0.9945249318173437, 0.9942157338514472, 0.9945304633089991, 0.9944958553621264, 0.9942974193078099, 0.9943569483179034, 0.9946409949299061, 0.994517777002219, 0.9944891656438509, 0.9944411692294207, 0.9947256752938936, 0.994586305410573, 0.9945613809607246, 0.9945336964094278, 0.9946989073897853, 0.9947404421188615, 0.9947305215579091, 0.9945189318422115, 0.9944554754730427, 0.9944487834970156, 0.9945383078672669, 0.9945973841981455, 0.9945816916949821, 0.9946492989406441, 0.9945955350995064, 0.9945240050102725, 0.9946049950791128, 0.9945853819901292, 0.9946331492427624, 0.9944947016510096, 0.9945420015490416, 0.9945429238406095, 0.9944790102767221], 'val_mDice': [0.4971195971563293, 0.5191901827836973, 0.5075960250183981, 0.5153734361131986, 0.5200439982357912, 0.506351562402085, 0.5194084659557451, 0.518345343739246, 0.4977930668268748, 0.5072531222724348, 0.5124902548724721, 0.5214649300570741, 0.512311387468468, 0.5038762632249818, 0.5103156084166558, 0.5149912408398991, 0.5214453850349583, 0.5209570505107987, 0.5096700211464794, 0.5166120429285578, 0.5191502514188339, 0.5115688381942386, 0.5042180779164173, 0.5085904218933799, 0.5172046115904143, 0.5201825426296939, 0.497025967085442, 0.5089987317523905, 0.5083416755113638, 0.5028133655186277, 0.5053851417257895, 0.5011444801338195, 0.5084537885701925, 0.521116785027764, 0.5072723781186946, 0.5049823495476976, 0.5078165670645454, 0.4971892530043438, 0.5117638594696693, 0.5046824300943986, 0.5151443578532021, 0.5042096514688841, 0.5086220651055012, 0.5137800968079252, 0.5085186496607801, 0.510381049312861, 0.5091492436851028, 0.5139685676180553, 0.5186475601160292, 0.5160755422879116, 0.5143414464934418, 0.5206599269965382], 'loss': [0.0799318004016906, 0.04898832631666042, 0.043916285207598244, 0.04148688673133252, 0.038896157067903496, 0.0377826908585546, 0.036491558866924, 0.035531209601708046, 0.034623118271337926, 0.03397228517998911, 0.03308513764426661, 0.033494439081174575, 0.032063938775856636, 0.03206982136876885, 0.03151576663070461, 0.031113421725952634, 0.030552671823468273, 0.030552876077981586, 0.030106782720795353, 0.030021531710824383, 0.029572526168807334, 0.02901865293319102, 0.029067167941861167, 0.02885726762836023, 0.029231795396417036, 0.028928800486868904, 0.028907002271253368, 0.027198720536972542, 0.02694477874469409, 0.0265856290159282, 0.026386227288965367, 0.02623555705771818, 0.026549932194437326, 0.0261909573518143, 0.02633983844130093, 0.0261006813327186, 0.02602218399055712, 0.026109148361529524, 0.02603563625287858, 0.025867259326022875, 0.025538479787288373, 0.02544915680561734, 0.024789906216217943, 0.024874779033559828, 0.025211397391332414, 0.024518935176443702, 0.024614145061304347, 0.024764485414213725, 0.02430868259104704, 0.024454432119543332, 0.02444732259242406, 0.024557888707858605], 'acc': [0.9917591709540232, 0.994530066767678, 0.995001359355801, 0.9952300379127399, 0.995456942785263, 0.9956037449337979, 0.9956905465072887, 0.9957967004262651, 0.9958459801144071, 0.995933570806701, 0.995985610075969, 0.9959953214666608, 0.9961143706712221, 0.9961016707692838, 0.9961562433470745, 0.996200067697821, 0.9962325497331226, 0.9962652276854457, 0.9962968588029765, 0.9963050593040003, 0.9963477262008077, 0.9963747566814648, 0.9963730215918696, 0.9963969580746973, 0.9963908331623172, 0.9964199585056346, 0.9964007499772042, 0.9965226162597698, 0.9965764195214701, 0.9965936145690206, 0.9966166767919076, 0.9966081310499453, 0.9966257281007523, 0.9966257227365916, 0.9966239588587881, 0.996663039600116, 0.9966674001714986, 0.9966798900219807, 0.996673492323431, 0.9966727459728729, 0.9966745014196101, 0.9966865457710485, 0.9967502238443627, 0.9967511464145009, 0.9967539292652765, 0.9967571237060207, 0.9967865022550344, 0.9967799422303849, 0.9967873439159436, 0.9967853686859977, 0.9967886684331936, 0.9968164735964411], 'mDice': [0.8444931208665711, 0.9048282960561742, 0.9147074342761198, 0.9194377089291607, 0.9244997049852726, 0.9266455652804636, 0.9291768322265515, 0.93103908645877, 0.9328238637201537, 0.9340788971695151, 0.9358233003490195, 0.9350014897375167, 0.93779563729526, 0.9377898521029204, 0.9388655718035683, 0.9396526242117524, 0.9407530411024605, 0.9407362030909197, 0.9416096000404887, 0.9417728719964329, 0.9426500495938305, 0.9437406231373651, 0.9436438617889144, 0.9440502538646034, 0.9433086387889997, 0.9438937759351691, 0.9439476438264672, 0.9472939507207717, 0.9477766077570584, 0.9484809810580299, 0.9488723718079944, 0.9491735595732096, 0.9485366031678993, 0.9492507959007305, 0.9489550404617609, 0.9494151204112111, 0.9495656160148152, 0.9493926486951589, 0.9495360984491205, 0.949879728667922, 0.9505245051329138, 0.9506999538506148, 0.9519889344178675, 0.9518114689862861, 0.9511402864477746, 0.9525196805606294, 0.9523194654685295, 0.9520165921193314, 0.9529271660735728, 0.95263613712105, 0.9526477875049458, 0.9524178822184943], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTTLoading test:  60%|██████    | 3/5 [00:32<00:21, 10.87s/it]Loading test:  80%|████████  | 4/5 [00:38<00:09,  9.37s/it]Loading test: 100%|██████████| 5/5 [00:49<00:00,  9.91s/it]Loading test: 100%|██████████| 5/5 [00:49<00:00,  9.97s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 50.89it/s]
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________2020-01-22 01:57:44.482051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 01:57:44.482152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 01:57:44.482182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 01:57:44.482190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 01:57:44.482505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.53210528e-02 3.19824595e-02 7.71754886e-02 9.62198337e-03
 2.75485438e-02 7.05562229e-03 8.86721766e-02 1.14568634e-01
 8.20946082e-02 1.27743930e-02 2.89961746e-01 1.92994020e-01
 2.29271690e-04]
Train on 15679 samples, validate on 323 samples
Epoch 1/300
 - 36s - loss: 0.4647 - acc: 0.9371 - mDice: 0.4988 - val_loss: -2.0260e-02 - val_acc: 0.9514 - val_mDice: 0.2059

Epoch 00001: val_mDice improved from -inf to 0.20589, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 31s - loss: 0.3790 - acc: 0.9471 - mDice: 0.5914 - val_loss: -4.2294e-02 - val_acc: 0.9554 - val_mDice: 0.2222

Epoch 00002: val_mDice improved from 0.20589 to 0.22221, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 31s - loss: 0.3601 - acc: 0.9493 - mDice: 0.6118 - val_loss: -1.6820e-01 - val_acc: 0.9567 - val_mDice: 0.2117

Epoch 00003: val_mDice did not improve from 0.22221
Epoch 4/300
 - 31s - loss: 0.3483 - acc: 0.9509 - mDice: 0.6246 - val_loss: -1.1287e-01 - val_acc: 0.9539 - val_mDice: 0.2225

Epoch 00004: val_mDice improved from 0.22221 to 0.22253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 31s - loss: 0.3412 - acc: 0.9516 - mDice: 0.6322 - val_loss: -5.3714e-02 - val_acc: 0.9566 - val_mDice: 0.2268

Epoch 00005: val_mDice improved from 0.22253 to 0.22684, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 6/300
 - 31s - loss: 0.3274 - acc: 0.9529 - mDice: 0.6471 - val_loss: -9.4825e-02 - val_acc: 0.9544 - val_mDice: 0.2211

Epoch 00006: val_mDice did not improve from 0.22684
Epoch 7/300
 - 33s - loss: 0.3283 - acc: 0.9531 - mDice: 0.6462 - val_loss: -7.9872e-02 - val_acc: 0.9529 - val_mDice: 0.2178

Epoch 00007: val_mDice did not improve from 0.22684
Epoch 8/300
 - 33s - loss: 0.3259 - acc: 0.9536 - mDice: 0.6487 - val_loss: -8.8780e-02 - val_acc: 0.9527 - val_mDice: 0.2127

Epoch 00008: val_mDice did not improve from 0.22684
Epoch 9/300
 - 31s - loss: 0.3195 - acc: 0.9543 - mDice: 0.6556 - val_loss: -7.0603e-02 - val_acc: 0.9566 - val_mDice: 0.2162

Epoch 00009: val_mDice did not improve from 0.22684
Epoch 10/300
 - 31s - loss: 0.3169 - acc: 0.9546 - mDice: 0.6584 - val_loss: -1.6514e-01 - val_acc: 0.9565 - val_mDice: 0.2088

Epoch 00010: val_mDice did not improve from 0.22684
Epoch 11/300
 - 31s - loss: 0.3152 - acc: 0.9546 - mDice: 0.6603 - val_loss: -1.5309e-01 - val_acc: 0.9552 - val_mDice: 0.2112

Epoch 00011: val_mDice did not improve from 0.22684
Epoch 12/300
 - 31s - loss: 0.3073 - acc: 0.9556 - mDice: 0.6688 - val_loss: -7.6513e-02 - val_acc: 0.9522 - val_mDice: 0.1968

Epoch 00012: val_mDice did not improve from 0.22684
Epoch 13/300
 - 31s - loss: 0.3088 - acc: 0.9553 - mDice: 0.6671 - val_loss: -1.2093e-01 - val_acc: 0.9537 - val_mDice: 0.2115

Epoch 00013: val_mDice did not improve from 0.22684
Epoch 14/300
 - 31s - loss: 0.3038 - acc: 0.9557 - mDice: 0.6726 - val_loss: -1.2588e-01 - val_acc: 0.9560 - val_mDice: 0.2128

Epoch 00014: val_mDice did not improve from 0.22684
Epoch 15/300
 - 31s - loss: 0.3037 - acc: 0.9561 - mDice: 0.6727 - val_loss: -8.7719e-02 - val_acc: 0.9562 - val_mDice: 0.2180

Epoch 00015: val_mDice did not improve from 0.22684
Epoch 16/300
 - 31s - loss: 0.2999 - acc: 0.9565 - mDice: 0.6767 - val_loss: -1.0664e-01 - val_acc: 0.9553 - val_mDice: 0.2141

Epoch 00016: val_mDice did not improve from 0.22684
Epoch 17/300
 - 31s - loss: 0.3026 - acc: 0.9564 - mDice: 0.6738 - val_loss: -1.5646e-01 - val_acc: 0.9567 - val_mDice: 0.2161

Epoch 00017: val_mDice did not improve from 0.22684
Epoch 18/300
 - 30s - loss: 0.2935 - acc: 0.9569 - mDice: 0.6837 - val_loss: -1.1159e-01 - val_acc: 0.9528 - val_mDice: 0.2109

Epoch 00018: val_mDice did not improve from 0.22684
Epoch 19/300
 - 31s - loss: 0.2980 - acc: 0.9568 - mDice: 0.6787 - val_loss: -1.5289e-01 - val_acc: 0.9558 - val_mDice: 0.2122

Epoch 00019: val_mDice did not improve from 0.22684
Epoch 20/300
 - 31s - loss: 0.2995 - acc: 0.9551 - mDice: 0.6620 - val_loss: -2.1859e-01 - val_acc: 0.9555 - val_mDice: 0.2138

Epoch 00020: val_mDice did not improve from 0.22684

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 21/300
 - 32s - loss: 0.2763 - acc: 0.9548 - mDice: 0.6640 - val_loss: -2.5973e-01 - val_acc: 0.9555 - val_mDice: 0.2045

Epoch 00021: val_mDice did not improve from 0.22684
Epoch 22/300
 - 31s - loss: 0.2591 - acc: 0.9544 - mDice: 0.6503 - val_loss: -2.4554e-01 - val_acc: 0.9575 - val_mDice: 0.2178

Epoch 00022: val_mDice did not improve from 0.22684
Epoch 23/300
 - 31s - loss: 0.2556 - acc: 0.9541 - mDice: 0.6499 - val_loss: -2.4156e-01 - val_acc: 0.9548 - val_mDice: 0.2013

Epoch 00023: val_mDice did not improve from 0.22684
Epoch 24/300
 - 31s - loss: 0.2398 - acc: 0.9548 - mDice: 0.6527 - val_loss: -2.5040e-01 - val_acc: 0.9569 - val_mDice: 0.2063

Epoch 00024: val_mDice did not improve from 0.22684
Epoch 25/300
 - 32s - loss: 0.2283 - acc: 0.9552 - mDice: 0.6583 - val_loss: -2.8159e-01 - val_acc: 0.9584 - val_mDice: 0.2097

Epoch 00025: val_mDice did not improve from 0.22684
Epoch 26/300
 - 32s - loss: 0.2260 - acc: 0.9552 - mDice: 0.6639 - val_loss: -2.1645e-01 - val_acc: 0.9561 - val_mDice: 0.2076

Epoch 00026: val_mDice did not improve from 0.22684
Epoch 27/300
 - 32s - loss: 0.2402 - acc: 0.9545 - mDice: 0.6498 - val_loss: -2.7030e-01 - val_acc: 0.9577 - val_mDice: 0.2125

Epoch 00027: val_mDice did not improve from 0.22684
Epoch 28/300
 - 33s - loss: 0.2380 - acc: 0.9550 - mDice: 0.6494 - val_loss: -2.2444e-01 - val_acc: 0.9577 - val_mDice: 0.2219

Epoch 00028: val_mDice did not improve from 0.22684
Epoch 29/300
 - 32s - loss: 0.2219 - acc: 0.9554 - mDice: 0.6610 - val_loss: -2.7955e-01 - val_acc: 0.9562 - val_mDice: 0.2028

Epoch 00029: val_mDice did not improve from 0.22684
Epoch 30/300
 - 33s - loss: 0.2256 - acc: 0.9549 - mDice: 0.6544 - val_loss: -2.4860e-01 - val_acc: 0.9572 - val_mDice: 0.2118

Epoch 00030: val_mDice did not improve from 0.22684
Epoch 31/300
 - 33s - loss: 0.2322 - acc: 0.9547 - mDice: 0.6498 - val_loss: -2.6305e-01 - val_acc: 0.9574 - val_mDice: 0.2119

Epoch 00031: val_mDice did not improve from 0.22684
Epoch 32/300
 - 33s - loss: 0.2171 - acc: 0.9554 - mDice: 0.6590 - val_loss: -2.7790e-01 - val_acc: 0.9574 - val_mDice: 0.2176

Epoch 00032: val_mDice did not improve from 0.22684
Epoch 33/300
 - 33s - loss: 0.2151 - acc: 0.9549 - mDice: 0.6580 - val_loss: -2.6707e-01 - val_acc: 0.9586 - val_mDice: 0.2145

Epoch 00033: val_mDice did not improve from 0.22684
Epoch 34/300
 - 33s - loss: 0.2245 - acc: 0.9549 - mDice: 0.6563 - val_loss: -2.6780e-01 - val_acc: 0.9583 - val_mDice: 0.2110

Epoch 00034: val_mDice did not improve from 0.22684
Epoch 35/300
 - 34s - loss: 0.2195 - acc: 0.9551 - mDice: 0.6588 - val_loss: -2.6099e-01 - val_acc: 0.9580 - val_mDice: 0.2131

Epoch 00035: val_mDice did not improve from 0.22684

Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 36/300
 - 33s - loss: 0.2135 - acc: 0.9557 - mDice: 0.6590 - val_loss: -2.6288e-01 - val_acc: 0.9546 - val_mDice: 0.1960

Epoch 00036: val_mDice did not improve from 0.22684
Epoch 37/300
 - 33s - loss: 0.2060 - acc: 0.9559 - mDice: 0.6670 - val_loss: -2.5718e-01 - val_acc: 0.9578 - val_mDice: 0.2089

Epoch 00037: val_mDice did not improve from 0.22684
Epoch 38/300
 - 33s - loss: 0.2024 - acc: 0.9561 - mDice: 0.6697 - val_loss: -2.6136e-01 - val_acc: 0.9577 - val_mDice: 0.2135

Epoch 00038: val_mDice did not improve from 0.22684
Epoch 39/300
 - 33s - loss: 0.2039 - acc: 0.9561 - mDice: 0.6716 - val_loss: -2.8463e-01 - val_acc: 0.9580 - val_mDice: 0.2080

Epoch 00039: val_mDice did not improve from 0.22684
Epoch 40/300
 - 32s - loss: 0.1999 - acc: 0.9562 - mDice: 0.6698 - val_loss: -2.6890e-01 - val_acc: 0.9584 - val_mDice: 0.2077

Epoch 00040: val_mDice did not improve from 0.22684
Epoch 41/300
 - 32s - loss: 0.2001 - acc: 0.9565 - mDice: 0.6730 - val_loss: -2.6709e-01 - val_acc: 0.9586 - val_mDice: 0.2048

Epoch 00041: val_mDice did not improve from 0.22684
Epoch 42/300
 - 31s - loss: 0.2036 - acc: 0.9564 - mDice: 0.6746 - val_loss: -2.8180e-01 - val_acc: 0.9582 - val_mDice: 0.2099

Epoch 00042: val_mDice did not improve from 0.22684
Epoch 43/300
 - 33s - loss: 0.2026 - acc: 0.9564 - mDice: 0.6712 - val_loss: -2.6935e-01 - val_acc: 0.9582 - val_mDice: 0.2066

Epoch 00043: val_mDice did not improve from 0.22684
Epoch 44/300
 - 32s - loss: 0.2000 - acc: 0.9568 - mDice: 0.6770 - val_loss: -2.5868e-01 - val_acc: 0.9572 - val_mDice: 0.1998

Epoch 00044: val_mDice did not improve from 0.22684
Epoch 45/300
 - 32s - loss: 0.2001 - acc: 0.9565 - mDice: 0.6705 - val_loss: -2.7463e-01 - val_acc: 0.9575 - val_mDice: 0.2073

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.46s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.37s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.29s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.17s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.11s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:05,  3.78it/s]Loading train:   1%|          | 2/247 [00:00<01:04,  3.80it/s]Loading train:   1%|          | 3/247 [00:00<01:04,  3.80it/s]Loading train:   2%|▏         | 4/247 [00:01<01:02,  3.89it/s]Loading train:   2%|▏         | 5/247 [00:01<01:01,  3.96it/s]Loading train:   2%|▏         | 6/247 [00:01<00:58,  4.09it/s]Loading train:   3%|▎         | 7/247 [00:01<00:57,  4.16it/s]Loading train:   3%|▎         | 8/247 [00:01<00:56,  4.24it/s]Loading train:   4%|▎         | 9/247 [00:02<00:55,  4.31it/s]Loading train:   4%|▍         | 10/247 [00:02<00:55,  4.25it/s]Loading train:   4%|▍         | 11/247 [00:02<00:55,  4.26it/s]Loading train:   5%|▍         | 12/247 [00:02<00:54,  4.28it/s]Loading train:   5%|▌         | 13/247 [00:03<00:54,  4.26it/s]Loading train:   6%|▌         | 14/247 [00:03<00:55,  4.21it/s]Loading train:   6%|▌         | 15/247 [00:03<00:54,  4.28it/s]Loading train:   6%|▋         | 16/247 [00:03<00:52,  4.37it/s]Loading train:   7%|▋         | 17/247 [00:04<00:51,  4.43it/s]Loading train:   7%|▋         | 18/247 [00:04<00:51,  4.49it/s]Loading train:   8%|▊         | 19/247 [00:04<00:50,  4.53it/s]Loading train:   8%|▊         | 20/247 [00:04<00:50,  4.51it/s]Loading train:   9%|▊         | 21/247 [00:04<00:50,  4.51it/s]Loading train:   9%|▉         | 22/247 [00:05<00:49,  4.52it/s]Loading train:   9%|▉         | 23/247 [00:05<00:49,  4.55it/s]Loading train:  10%|▉         | 24/247 [00:05<00:48,  4.57it/s]Loading train:  10%|█         | 25/247 [00:05<00:48,  4.58it/s]Loading train:  11%|█         | 26/247 [00:05<00:48,  4.60it/s]Loading train:  11%|█         | 27/247 [00:06<00:47,  4.60it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:47,  4.62it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:47,  4.57it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:48,  4.48it/s]Loading train:  13%|█▎        | 31/247 [00:07<00:47,  4.53it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:47,  4.54it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:46,  4.58it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:46,  4.62it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:46,  4.53it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:48,  4.36it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:47,  4.40it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:47,  4.37it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:48,  4.25it/s]Loading train:  16%|█▌        | 40/247 [00:09<00:47,  4.33it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:47,  4.36it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:46,  4.44it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:45,  4.47it/s]Loading train:  18%|█▊        | 44/247 [00:10<00:45,  4.48it/s]Loading train:  18%|█▊        | 45/247 [00:10<00:45,  4.49it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:44,  4.54it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:44,  4.54it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:43,  4.56it/s]Loading train:  20%|█▉        | 49/247 [00:11<00:43,  4.59it/s]Loading train:  20%|██        | 50/247 [00:11<00:42,  4.59it/s]Loading train:  21%|██        | 51/247 [00:11<00:42,  4.61it/s]Loading train:  21%|██        | 52/247 [00:11<00:42,  4.63it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:41,  4.66it/s]Loading train:  22%|██▏       | 54/247 [00:12<00:41,  4.64it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:42,  4.49it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:42,  4.52it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:41,  4.55it/s]Loading train:  23%|██▎       | 58/247 [00:13<00:41,  4.59it/s]Loading train:  24%|██▍       | 59/247 [00:13<00:41,  4.58it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:40,  4.57it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:40,  4.56it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:40,  4.56it/s]Loading train:  26%|██▌       | 63/247 [00:14<00:40,  4.55it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:40,  4.56it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:39,  4.56it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:39,  4.57it/s]Loading train:  27%|██▋       | 67/247 [00:15<00:39,  4.51it/s]Loading train:  28%|██▊       | 68/247 [00:15<00:40,  4.38it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:41,  4.27it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:41,  4.25it/s]Loading train:  29%|██▊       | 71/247 [00:16<00:40,  4.30it/s]Loading train:  29%|██▉       | 72/247 [00:16<00:40,  4.34it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:40,  4.29it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:40,  4.31it/s]Loading train:  30%|███       | 75/247 [00:16<00:40,  4.28it/s]Loading train:  31%|███       | 76/247 [00:17<00:39,  4.28it/s]Loading train:  31%|███       | 77/247 [00:17<00:43,  3.94it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:43,  3.88it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:41,  4.09it/s]Loading train:  32%|███▏      | 80/247 [00:18<00:39,  4.19it/s]Loading train:  33%|███▎      | 81/247 [00:18<00:40,  4.11it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:40,  4.07it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:40,  4.05it/s]Loading train:  34%|███▍      | 84/247 [00:19<00:40,  4.03it/s]Loading train:  34%|███▍      | 85/247 [00:19<00:40,  4.01it/s]Loading train:  35%|███▍      | 86/247 [00:19<00:40,  4.00it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:40,  3.91it/s]Loading train:  36%|███▌      | 88/247 [00:20<00:40,  3.89it/s]Loading train:  36%|███▌      | 89/247 [00:20<00:40,  3.88it/s]Loading train:  36%|███▋      | 90/247 [00:20<00:40,  3.91it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:39,  3.92it/s]Loading train:  37%|███▋      | 92/247 [00:21<00:39,  3.92it/s]Loading train:  38%|███▊      | 93/247 [00:21<00:39,  3.92it/s]Loading train:  38%|███▊      | 94/247 [00:21<00:39,  3.91it/s]Loading train:  38%|███▊      | 95/247 [00:22<00:38,  3.90it/s]Loading train:  39%|███▉      | 96/247 [00:22<00:38,  3.92it/s]Loading train:  39%|███▉      | 97/247 [00:22<00:38,  3.91it/s]Loading train:  40%|███▉      | 98/247 [00:22<00:38,  3.92it/s]Loading train:  40%|████      | 99/247 [00:23<00:37,  3.91it/s]Loading train:  40%|████      | 100/247 [00:23<00:37,  3.94it/s]Loading train:  41%|████      | 101/247 [00:23<00:36,  3.98it/s]Loading train:  41%|████▏     | 102/247 [00:23<00:36,  4.00it/s]Loading train:  42%|████▏     | 103/247 [00:24<00:35,  4.05it/s]Loading train:  42%|████▏     | 104/247 [00:24<00:35,  4.08it/s]Loading train:  43%|████▎     | 105/247 [00:24<00:34,  4.10it/s]Loading train:  43%|████▎     | 106/247 [00:24<00:34,  4.09it/s]Loading train:  43%|████▎     | 107/247 [00:24<00:34,  4.10it/s]Loading train:  44%|████▎     | 108/247 [00:25<00:33,  4.10it/s]Loading train:  44%|████▍     | 109/247 [00:25<00:33,  4.07it/s]Loading train:  45%|████▍     | 110/247 [00:25<00:34,  4.00it/s]Loading train:  45%|████▍     | 111/247 [00:25<00:33,  4.03it/s]Loading train:  45%|████▌     | 112/247 [00:26<00:33,  4.03it/s]Loading train:  46%|████▌     | 113/247 [00:26<00:33,  4.03it/s]Loading train:  46%|████▌     | 114/247 [00:26<00:32,  4.05it/s]Loading train:  47%|████▋     | 115/247 [00:26<00:32,  4.06it/s]Loading train:  47%|████▋     | 116/247 [00:27<00:32,  4.06it/s]Loading train:  47%|████▋     | 117/247 [00:27<00:31,  4.08it/s]Loading train:  48%|████▊     | 118/247 [00:27<00:30,  4.26it/s]Loading train:  48%|████▊     | 119/247 [00:27<00:29,  4.41it/s]Loading train:  49%|████▊     | 120/247 [00:28<00:28,  4.51it/s]Loading train:  49%|████▉     | 121/247 [00:28<00:27,  4.59it/s]Loading train:  49%|████▉     | 122/247 [00:28<00:26,  4.64it/s]Loading train:  50%|████▉     | 123/247 [00:28<00:26,  4.66it/s]Loading train:  50%|█████     | 124/247 [00:28<00:26,  4.69it/s]Loading train:  51%|█████     | 125/247 [00:29<00:25,  4.71it/s]Loading train:  51%|█████     | 126/247 [00:29<00:25,  4.72it/s]Loading train:  51%|█████▏    | 127/247 [00:29<00:25,  4.70it/s]Loading train:  52%|█████▏    | 128/247 [00:29<00:25,  4.72it/s]Loading train:  52%|█████▏    | 129/247 [00:29<00:24,  4.75it/s]Loading train:  53%|█████▎    | 130/247 [00:30<00:24,  4.75it/s]Loading train:  53%|█████▎    | 131/247 [00:30<00:24,  4.79it/s]Loading train:  53%|█████▎    | 132/247 [00:30<00:23,  4.82it/s]Loading train:  54%|█████▍    | 133/247 [00:30<00:23,  4.85it/s]Loading train:  54%|█████▍    | 134/247 [00:31<00:23,  4.78it/s]Loading train:  55%|█████▍    | 135/247 [00:31<00:24,  4.66it/s]Loading train:  55%|█████▌    | 136/247 [00:31<00:25,  4.35it/s]Loading train:  55%|█████▌    | 137/247 [00:31<00:24,  4.44it/s]Loading train:  56%|█████▌    | 138/247 [00:31<00:24,  4.48it/s]Loading train:  56%|█████▋    | 139/247 [00:32<00:23,  4.52it/s]Loading train:  57%|█████▋    | 140/247 [00:32<00:23,  4.51it/s]Loading train:  57%|█████▋    | 141/247 [00:32<00:23,  4.50it/s]Loading train:  57%|█████▋    | 142/247 [00:32<00:23,  4.55it/s]Loading train:  58%|█████▊    | 143/247 [00:33<00:23,  4.51it/s]Loading train:  58%|█████▊    | 144/247 [00:33<00:23,  4.47it/s]Loading train:  59%|█████▊    | 145/247 [00:33<00:22,  4.48it/s]Loading train:  59%|█████▉    | 146/247 [00:33<00:22,  4.50it/s]Loading train:  60%|█████▉    | 147/247 [00:33<00:22,  4.44it/s]Loading train:  60%|█████▉    | 148/247 [00:34<00:22,  4.50it/s]Loading train:  60%|██████    | 149/247 [00:34<00:21,  4.51it/s]Loading train:  61%|██████    | 150/247 [00:34<00:21,  4.49it/s]Loading train:  61%|██████    | 151/247 [00:34<00:21,  4.46it/s]Loading train:  62%|██████▏   | 152/247 [00:35<00:21,  4.50it/s]Loading train:  62%|██████▏   | 153/247 [00:35<00:20,  4.58it/s]Loading train:  62%|██████▏   | 154/247 [00:35<00:21,  4.43it/s]Loading train:  63%|██████▎   | 155/247 [00:35<00:21,  4.36it/s]Loading train:  63%|██████▎   | 156/247 [00:36<00:21,  4.22it/s]Loading train:  64%|██████▎   | 157/247 [00:36<00:21,  4.13it/s]Loading train:  64%|██████▍   | 158/247 [00:36<00:21,  4.10it/s]Loading train:  64%|██████▍   | 159/247 [00:36<00:21,  4.12it/s]Loading train:  65%|██████▍   | 160/247 [00:36<00:21,  4.14it/s]Loading train:  65%|██████▌   | 161/247 [00:37<00:20,  4.16it/s]Loading train:  66%|██████▌   | 162/247 [00:37<00:20,  4.18it/s]Loading train:  66%|██████▌   | 163/247 [00:37<00:20,  4.17it/s]Loading train:  66%|██████▋   | 164/247 [00:37<00:19,  4.19it/s]Loading train:  67%|██████▋   | 165/247 [00:38<00:19,  4.19it/s]Loading train:  67%|██████▋   | 166/247 [00:38<00:19,  4.19it/s]Loading train:  68%|██████▊   | 167/247 [00:38<00:19,  4.16it/s]Loading train:  68%|██████▊   | 168/247 [00:38<00:19,  4.14it/s]Loading train:  68%|██████▊   | 169/247 [00:39<00:18,  4.12it/s]Loading train:  69%|██████▉   | 170/247 [00:39<00:18,  4.15it/s]Loading train:  69%|██████▉   | 171/247 [00:39<00:18,  4.15it/s]Loading train:  70%|██████▉   | 172/247 [00:39<00:17,  4.21it/s]Loading train:  70%|███████   | 173/247 [00:40<00:17,  4.23it/s]Loading train:  70%|███████   | 174/247 [00:40<00:17,  4.26it/s]Loading train:  71%|███████   | 175/247 [00:40<00:17,  4.17it/s]Loading train:  71%|███████▏  | 176/247 [00:40<00:16,  4.32it/s]Loading train:  72%|███████▏  | 177/247 [00:40<00:15,  4.43it/s]Loading train:  72%|███████▏  | 178/247 [00:41<00:15,  4.50it/s]Loading train:  72%|███████▏  | 179/247 [00:41<00:14,  4.57it/s]Loading train:  73%|███████▎  | 180/247 [00:41<00:14,  4.62it/s]Loading train:  73%|███████▎  | 181/247 [00:41<00:14,  4.62it/s]Loading train:  74%|███████▎  | 182/247 [00:42<00:14,  4.64it/s]Loading train:  74%|███████▍  | 183/247 [00:42<00:13,  4.64it/s]Loading train:  74%|███████▍  | 184/247 [00:42<00:13,  4.65it/s]Loading train:  75%|███████▍  | 185/247 [00:42<00:13,  4.65it/s]Loading train:  75%|███████▌  | 186/247 [00:42<00:13,  4.64it/s]Loading train:  76%|███████▌  | 187/247 [00:43<00:13,  4.54it/s]Loading train:  76%|███████▌  | 188/247 [00:43<00:13,  4.40it/s]Loading train:  77%|███████▋  | 189/247 [00:43<00:13,  4.41it/s]Loading train:  77%|███████▋  | 190/247 [00:43<00:12,  4.45it/s]Loading train:  77%|███████▋  | 191/247 [00:44<00:12,  4.50it/s]Loading train:  78%|███████▊  | 192/247 [00:44<00:12,  4.54it/s]Loading train:  78%|███████▊  | 193/247 [00:44<00:12,  4.49it/s]Loading train:  79%|███████▊  | 194/247 [00:44<00:11,  4.51it/s]Loading train:  79%|███████▉  | 195/247 [00:44<00:11,  4.49it/s]Loading train:  79%|███████▉  | 196/247 [00:45<00:11,  4.41it/s]Loading train:  80%|███████▉  | 197/247 [00:45<00:11,  4.38it/s]Loading train:  80%|████████  | 198/247 [00:45<00:10,  4.50it/s]Loading train:  81%|████████  | 199/247 [00:45<00:10,  4.53it/s]Loading train:  81%|████████  | 200/247 [00:46<00:10,  4.57it/s]Loading train:  81%|████████▏ | 201/247 [00:46<00:09,  4.66it/s]Loading train:  82%|████████▏ | 202/247 [00:46<00:09,  4.72it/s]Loading train:  82%|████████▏ | 203/247 [00:46<00:09,  4.77it/s]Loading train:  83%|████████▎ | 204/247 [00:46<00:08,  4.80it/s]Loading train:  83%|████████▎ | 205/247 [00:47<00:08,  4.80it/s]Loading train:  83%|████████▎ | 206/247 [00:47<00:08,  4.82it/s]Loading train:  84%|████████▍ | 207/247 [00:47<00:08,  4.83it/s]Loading train:  84%|████████▍ | 208/247 [00:47<00:08,  4.82it/s]Loading train:  85%|████████▍ | 209/247 [00:47<00:07,  4.82it/s]Loading train:  85%|████████▌ | 210/247 [00:48<00:07,  4.85it/s]Loading train:  85%|████████▌ | 211/247 [00:48<00:07,  4.85it/s]Loading train:  86%|████████▌ | 212/247 [00:48<00:07,  4.81it/s]Loading train:  86%|████████▌ | 213/247 [00:48<00:07,  4.76it/s]Loading train:  87%|████████▋ | 214/247 [00:48<00:07,  4.68it/s]Loading train:  87%|████████▋ | 215/247 [00:49<00:06,  4.63it/s]Loading train:  87%|████████▋ | 216/247 [00:49<00:06,  4.64it/s]Loading train:  88%|████████▊ | 217/247 [00:49<00:06,  4.63it/s]Loading train:  88%|████████▊ | 218/247 [00:49<00:06,  4.59it/s]Loading train:  89%|████████▊ | 219/247 [00:50<00:06,  4.59it/s]Loading train:  89%|████████▉ | 220/247 [00:50<00:05,  4.53it/s]Loading train:  89%|████████▉ | 221/247 [00:50<00:05,  4.44it/s]Loading train:  90%|████████▉ | 222/247 [00:50<00:05,  4.43it/s]Loading train:  90%|█████████ | 223/247 [00:50<00:05,  4.38it/s]Loading train:  91%|█████████ | 224/247 [00:51<00:05,  4.42it/s]Loading train:  91%|█████████ | 225/247 [00:51<00:05,  4.39it/s]Loading train:  91%|█████████▏| 226/247 [00:51<00:04,  4.35it/s]Loading train:  92%|█████████▏| 227/247 [00:51<00:04,  4.36it/s]Loading train:  92%|█████████▏| 228/247 [00:52<00:04,  4.36it/s]Loading train:  93%|█████████▎| 229/247 [00:52<00:04,  4.41it/s]Loading train:  93%|█████████▎| 230/247 [00:52<00:03,  4.34it/s]Loading train:  94%|█████████▎| 231/247 [00:52<00:03,  4.18it/s]Loading train:  94%|█████████▍| 232/247 [00:53<00:03,  4.17it/s]Loading train:  94%|█████████▍| 233/247 [00:53<00:03,  4.14it/s]Loading train:  95%|█████████▍| 234/247 [00:53<00:03,  4.02it/s]Loading train:  95%|█████████▌| 235/247 [00:53<00:02,  4.06it/s]Loading train:  96%|█████████▌| 236/247 [00:54<00:02,  4.10it/s]Loading train:  96%|█████████▌| 237/247 [00:54<00:02,  4.15it/s]Loading train:  96%|█████████▋| 238/247 [00:54<00:02,  4.18it/s]Loading train:  97%|█████████▋| 239/247 [00:54<00:01,  4.19it/s]Loading train:  97%|█████████▋| 240/247 [00:55<00:01,  4.20it/s]Loading train:  98%|█████████▊| 241/247 [00:55<00:01,  4.22it/s]Loading train:  98%|█████████▊| 242/247 [00:55<00:01,  4.22it/s]Loading train:  98%|█████████▊| 243/247 [00:55<00:00,  4.22it/s]Loading train:  99%|█████████▉| 244/247 [00:55<00:00,  4.23it/s]Loading train:  99%|█████████▉| 245/247 [00:56<00:00,  4.23it/s]Loading train: 100%|█████████▉| 246/247 [00:56<00:00,  4.23it/s]Loading train: 100%|██████████| 247/247 [00:56<00:00,  4.22it/s]Loading train: 100%|██████████| 247/247 [00:56<00:00,  4.36it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 54.97it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 55.66it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 55.71it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:04, 55.67it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:03, 56.75it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:03, 56.27it/s]concatenating: train:  17%|█▋        | 42/247 [00:00<00:03, 56.28it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 54.05it/s]concatenating: train:  22%|██▏       | 54/247 [00:00<00:03, 54.29it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 54.01it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 55.63it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 56.63it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:02, 56.86it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:02, 56.67it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 55.57it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:02, 54.50it/s]concatenating: train:  41%|████▏     | 102/247 [00:01<00:02, 53.07it/s]concatenating: train:  44%|████▎     | 108/247 [00:01<00:02, 53.76it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:02, 52.72it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 53.89it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:02, 56.35it/s]concatenating: train:  54%|█████▍    | 134/247 [00:02<00:01, 58.79it/s]concatenating: train:  57%|█████▋    | 141/247 [00:02<00:01, 59.44it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:01, 59.25it/s]concatenating: train:  62%|██████▏   | 154/247 [00:02<00:01, 59.70it/s]concatenating: train:  65%|██████▍   | 160/247 [00:02<00:01, 58.44it/s]concatenating: train:  67%|██████▋   | 166/247 [00:02<00:01, 57.43it/s]concatenating: train:  70%|██████▉   | 172/247 [00:03<00:01, 56.21it/s]concatenating: train:  72%|███████▏  | 179/247 [00:03<00:01, 57.20it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 58.27it/s]concatenating: train:  78%|███████▊  | 192/247 [00:03<00:00, 57.99it/s]concatenating: train:  81%|████████  | 199/247 [00:03<00:00, 59.32it/s]concatenating: train:  83%|████████▎ | 206/247 [00:03<00:00, 60.73it/s]concatenating: train:  86%|████████▌ | 213/247 [00:03<00:00, 61.44it/s]concatenating: train:  89%|████████▉ | 220/247 [00:03<00:00, 60.31it/s]concatenating: train:  92%|█████████▏| 227/247 [00:03<00:00, 60.92it/s]concatenating: train:  95%|█████████▍| 234/247 [00:04<00:00, 60.48it/s]concatenating: train:  98%|█████████▊| 241/247 [00:04<00:00, 59.92it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 57.39it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:00,  4.16it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.96it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.96it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.19it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.12it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.06it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 390.90it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<00:56,  4.33it/s]Loading trainS:   1%|          | 2/247 [00:00<00:55,  4.38it/s]Loading trainS:   1%|          | 3/247 [00:00<00:56,  4.35it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:56,  4.31it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:55,  4.36it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:54,  4.39it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:54,  4.43it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:53,  4.46it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:52,  4.50it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:52,  4.47it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:53,  4.43it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:53,  4.38it/s]Loading trainS:   5%|▌         | 13/247 [00:02<00:52,  4.45it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:53,  4.38it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:52,  4.38it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:53,  4.30it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:52,  4.40it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:51,  4.46it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:50,  4.52it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:49,  4.56it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:49,  4.55it/s]Loading trainS:   9%|▉         | 22/247 [00:04<00:49,  4.58it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:48,  4.63it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:47,  4.65it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:47,  4.67it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:47,  4.68it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:46,  4.70it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:46,  4.71it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:46,  4.72it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:45,  4.73it/s]Loading trainS:  13%|█▎        | 31/247 [00:06<00:45,  4.74it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:45,  4.73it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:45,  4.72it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:45,  4.73it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:44,  4.72it/s]Loading trainS:  15%|█▍        | 36/247 [00:07<00:44,  4.69it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:44,  4.71it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:44,  4.72it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:43,  4.73it/s]Loading trainS:  16%|█▌        | 40/247 [00:08<00:43,  4.73it/s]Loading trainS:  17%|█▋        | 41/247 [00:08<00:43,  4.72it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:43,  4.71it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:43,  4.71it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:43,  4.70it/s]Loading trainS:  18%|█▊        | 45/247 [00:09<00:42,  4.71it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:42,  4.71it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:42,  4.73it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:42,  4.73it/s]Loading trainS:  20%|█▉        | 49/247 [00:10<00:41,  4.74it/s]Loading trainS:  20%|██        | 50/247 [00:10<00:41,  4.74it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:41,  4.72it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:41,  4.73it/s]Loading trainS:  21%|██▏       | 53/247 [00:11<00:41,  4.71it/s]Loading trainS:  22%|██▏       | 54/247 [00:11<00:42,  4.52it/s]Loading trainS:  22%|██▏       | 55/247 [00:11<00:42,  4.49it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:42,  4.50it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:41,  4.56it/s]Loading trainS:  23%|██▎       | 58/247 [00:12<00:41,  4.51it/s]Loading trainS:  24%|██▍       | 59/247 [00:12<00:43,  4.31it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:43,  4.34it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:42,  4.36it/s]Loading trainS:  25%|██▌       | 62/247 [00:13<00:43,  4.28it/s]Loading trainS:  26%|██▌       | 63/247 [00:13<00:42,  4.28it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:42,  4.29it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:41,  4.35it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:41,  4.38it/s]Loading trainS:  27%|██▋       | 67/247 [00:14<00:41,  4.39it/s]Loading trainS:  28%|██▊       | 68/247 [00:14<00:40,  4.45it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:39,  4.49it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:39,  4.51it/s]Loading trainS:  29%|██▊       | 71/247 [00:15<00:38,  4.54it/s]Loading trainS:  29%|██▉       | 72/247 [00:15<00:38,  4.54it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:38,  4.56it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:37,  4.56it/s]Loading trainS:  30%|███       | 75/247 [00:16<00:37,  4.57it/s]Loading trainS:  31%|███       | 76/247 [00:16<00:37,  4.58it/s]Loading trainS:  31%|███       | 77/247 [00:16<00:39,  4.26it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:40,  4.16it/s]Loading trainS:  32%|███▏      | 79/247 [00:17<00:38,  4.32it/s]Loading trainS:  32%|███▏      | 80/247 [00:17<00:38,  4.38it/s]Loading trainS:  33%|███▎      | 81/247 [00:17<00:39,  4.26it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:39,  4.17it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:39,  4.11it/s]Loading trainS:  34%|███▍      | 84/247 [00:18<00:39,  4.08it/s]Loading trainS:  34%|███▍      | 85/247 [00:18<00:40,  4.03it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:40,  4.02it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:39,  4.02it/s]Loading trainS:  36%|███▌      | 88/247 [00:19<00:39,  4.00it/s]Loading trainS:  36%|███▌      | 89/247 [00:19<00:39,  4.01it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:39,  4.01it/s]Loading trainS:  37%|███▋      | 91/247 [00:20<00:40,  3.87it/s]Loading trainS:  37%|███▋      | 92/247 [00:20<00:39,  3.92it/s]Loading trainS:  38%|███▊      | 93/247 [00:20<00:39,  3.94it/s]Loading trainS:  38%|███▊      | 94/247 [00:21<00:38,  3.94it/s]Loading trainS:  38%|███▊      | 95/247 [00:21<00:38,  3.95it/s]Loading trainS:  39%|███▉      | 96/247 [00:21<00:38,  3.97it/s]Loading trainS:  39%|███▉      | 97/247 [00:21<00:37,  3.98it/s]Loading trainS:  40%|███▉      | 98/247 [00:22<00:37,  3.99it/s]Loading trainS:  40%|████      | 99/247 [00:22<00:36,  4.00it/s]Loading trainS:  40%|████      | 100/247 [00:22<00:36,  4.06it/s]Loading trainS:  41%|████      | 101/247 [00:22<00:35,  4.10it/s]Loading trainS:  41%|████▏     | 102/247 [00:23<00:35,  4.14it/s]Loading trainS:  42%|████▏     | 103/247 [00:23<00:34,  4.16it/s]Loading trainS:  42%|████▏     | 104/247 [00:23<00:34,  4.18it/s]Loading trainS:  43%|████▎     | 105/247 [00:23<00:33,  4.19it/s]Loading trainS:  43%|████▎     | 106/247 [00:24<00:33,  4.19it/s]Loading trainS:  43%|████▎     | 107/247 [00:24<00:33,  4.18it/s]Loading trainS:  44%|████▎     | 108/247 [00:24<00:33,  4.19it/s]Loading trainS:  44%|████▍     | 109/247 [00:24<00:32,  4.20it/s]Loading trainS:  45%|████▍     | 110/247 [00:25<00:32,  4.19it/s]Loading trainS:  45%|████▍     | 111/247 [00:25<00:32,  4.19it/s]Loading trainS:  45%|████▌     | 112/247 [00:25<00:32,  4.19it/s]Loading trainS:  46%|████▌     | 113/247 [00:25<00:31,  4.19it/s]Loading trainS:  46%|████▌     | 114/247 [00:26<00:31,  4.19it/s]Loading trainS:  47%|████▋     | 115/247 [00:26<00:31,  4.19it/s]Loading trainS:  47%|████▋     | 116/247 [00:26<00:31,  4.19it/s]Loading trainS:  47%|████▋     | 117/247 [00:26<00:31,  4.19it/s]Loading trainS:  48%|████▊     | 118/247 [00:26<00:29,  4.40it/s]Loading trainS:  48%|████▊     | 119/247 [00:27<00:28,  4.56it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:27,  4.69it/s]Loading trainS:  49%|████▉     | 121/247 [00:27<00:26,  4.78it/s]Loading trainS:  49%|████▉     | 122/247 [00:27<00:25,  4.82it/s]Loading trainS:  50%|████▉     | 123/247 [00:27<00:25,  4.90it/s]Loading trainS:  50%|█████     | 124/247 [00:28<00:24,  4.92it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:24,  4.96it/s]Loading trainS:  51%|█████     | 126/247 [00:28<00:24,  4.98it/s]Loading trainS:  51%|█████▏    | 127/247 [00:28<00:24,  4.99it/s]Loading trainS:  52%|█████▏    | 128/247 [00:28<00:24,  4.92it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:24,  4.78it/s]Loading trainS:  53%|█████▎    | 130/247 [00:29<00:25,  4.68it/s]Loading trainS:  53%|█████▎    | 131/247 [00:29<00:24,  4.71it/s]Loading trainS:  53%|█████▎    | 132/247 [00:29<00:24,  4.75it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:24,  4.73it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:23,  4.82it/s]Loading trainS:  55%|█████▍    | 135/247 [00:30<00:23,  4.85it/s]Loading trainS:  55%|█████▌    | 136/247 [00:30<00:22,  4.83it/s]Loading trainS:  55%|█████▌    | 137/247 [00:30<00:22,  4.82it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:22,  4.81it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:22,  4.78it/s]Loading trainS:  57%|█████▋    | 140/247 [00:31<00:22,  4.76it/s]Loading trainS:  57%|█████▋    | 141/247 [00:31<00:22,  4.78it/s]Loading trainS:  57%|█████▋    | 142/247 [00:31<00:22,  4.77it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:21,  4.78it/s]Loading trainS:  58%|█████▊    | 144/247 [00:32<00:21,  4.75it/s]Loading trainS:  59%|█████▊    | 145/247 [00:32<00:22,  4.50it/s]Loading trainS:  59%|█████▉    | 146/247 [00:32<00:22,  4.58it/s]Loading trainS:  60%|█████▉    | 147/247 [00:32<00:21,  4.60it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:21,  4.59it/s]Loading trainS:  60%|██████    | 149/247 [00:33<00:21,  4.64it/s]Loading trainS:  61%|██████    | 150/247 [00:33<00:20,  4.68it/s]Loading trainS:  61%|██████    | 151/247 [00:33<00:20,  4.70it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:20,  4.74it/s]Loading trainS:  62%|██████▏   | 153/247 [00:34<00:19,  4.75it/s]Loading trainS:  62%|██████▏   | 154/247 [00:34<00:20,  4.58it/s]Loading trainS:  63%|██████▎   | 155/247 [00:34<00:20,  4.47it/s]Loading trainS:  63%|██████▎   | 156/247 [00:34<00:20,  4.40it/s]Loading trainS:  64%|██████▎   | 157/247 [00:35<00:20,  4.32it/s]Loading trainS:  64%|██████▍   | 158/247 [00:35<00:20,  4.26it/s]Loading trainS:  64%|██████▍   | 159/247 [00:35<00:20,  4.23it/s]Loading trainS:  65%|██████▍   | 160/247 [00:35<00:20,  4.21it/s]Loading trainS:  65%|██████▌   | 161/247 [00:36<00:20,  4.18it/s]Loading trainS:  66%|██████▌   | 162/247 [00:36<00:20,  4.18it/s]Loading trainS:  66%|██████▌   | 163/247 [00:36<00:20,  4.16it/s]Loading trainS:  66%|██████▋   | 164/247 [00:36<00:20,  4.13it/s]Loading trainS:  67%|██████▋   | 165/247 [00:37<00:20,  4.03it/s]Loading trainS:  67%|██████▋   | 166/247 [00:37<00:20,  4.01it/s]Loading trainS:  68%|██████▊   | 167/247 [00:37<00:19,  4.02it/s]Loading trainS:  68%|██████▊   | 168/247 [00:37<00:19,  4.01it/s]Loading trainS:  68%|██████▊   | 169/247 [00:38<00:19,  3.96it/s]Loading trainS:  69%|██████▉   | 170/247 [00:38<00:19,  3.97it/s]Loading trainS:  69%|██████▉   | 171/247 [00:38<00:19,  3.91it/s]Loading trainS:  70%|██████▉   | 172/247 [00:38<00:18,  3.96it/s]Loading trainS:  70%|███████   | 173/247 [00:39<00:18,  4.05it/s]Loading trainS:  70%|███████   | 174/247 [00:39<00:17,  4.14it/s]Loading trainS:  71%|███████   | 175/247 [00:39<00:17,  4.07it/s]Loading trainS:  71%|███████▏  | 176/247 [00:39<00:16,  4.18it/s]Loading trainS:  72%|███████▏  | 177/247 [00:40<00:16,  4.18it/s]Loading trainS:  72%|███████▏  | 178/247 [00:40<00:16,  4.12it/s]Loading trainS:  72%|███████▏  | 179/247 [00:40<00:16,  4.20it/s]Loading trainS:  73%|███████▎  | 180/247 [00:40<00:15,  4.28it/s]Loading trainS:  73%|███████▎  | 181/247 [00:41<00:15,  4.35it/s]Loading trainS:  74%|███████▎  | 182/247 [00:41<00:14,  4.38it/s]Loading trainS:  74%|███████▍  | 183/247 [00:41<00:14,  4.38it/s]Loading trainS:  74%|███████▍  | 184/247 [00:41<00:14,  4.31it/s]Loading trainS:  75%|███████▍  | 185/247 [00:41<00:14,  4.27it/s]Loading trainS:  75%|███████▌  | 186/247 [00:42<00:14,  4.32it/s]Loading trainS:  76%|███████▌  | 187/247 [00:42<00:13,  4.33it/s]Loading trainS:  76%|███████▌  | 188/247 [00:42<00:13,  4.40it/s]Loading trainS:  77%|███████▋  | 189/247 [00:42<00:13,  4.45it/s]Loading trainS:  77%|███████▋  | 190/247 [00:43<00:12,  4.49it/s]Loading trainS:  77%|███████▋  | 191/247 [00:43<00:12,  4.53it/s]Loading trainS:  78%|███████▊  | 192/247 [00:43<00:12,  4.57it/s]Loading trainS:  78%|███████▊  | 193/247 [00:43<00:11,  4.59it/s]Loading trainS:  79%|███████▊  | 194/247 [00:43<00:11,  4.68it/s]Loading trainS:  79%|███████▉  | 195/247 [00:44<00:10,  4.73it/s]Loading trainS:  79%|███████▉  | 196/247 [00:44<00:10,  4.77it/s]Loading trainS:  80%|███████▉  | 197/247 [00:44<00:10,  4.80it/s]Loading trainS:  80%|████████  | 198/247 [00:44<00:10,  4.82it/s]Loading trainS:  81%|████████  | 199/247 [00:44<00:09,  4.85it/s]Loading trainS:  81%|████████  | 200/247 [00:45<00:09,  4.86it/s]Loading trainS:  81%|████████▏ | 201/247 [00:45<00:09,  4.86it/s]Loading trainS:  82%|████████▏ | 202/247 [00:45<00:09,  4.87it/s]Loading trainS:  82%|████████▏ | 203/247 [00:45<00:09,  4.87it/s]Loading trainS:  83%|████████▎ | 204/247 [00:45<00:08,  4.85it/s]Loading trainS:  83%|████████▎ | 205/247 [00:46<00:08,  4.82it/s]Loading trainS:  83%|████████▎ | 206/247 [00:46<00:08,  4.81it/s]Loading trainS:  84%|████████▍ | 207/247 [00:46<00:08,  4.82it/s]Loading trainS:  84%|████████▍ | 208/247 [00:46<00:08,  4.80it/s]Loading trainS:  85%|████████▍ | 209/247 [00:47<00:07,  4.77it/s]Loading trainS:  85%|████████▌ | 210/247 [00:47<00:07,  4.79it/s]Loading trainS:  85%|████████▌ | 211/247 [00:47<00:07,  4.71it/s]Loading trainS:  86%|████████▌ | 212/247 [00:47<00:07,  4.62it/s]Loading trainS:  86%|████████▌ | 213/247 [00:47<00:07,  4.50it/s]Loading trainS:  87%|████████▋ | 214/247 [00:48<00:07,  4.51it/s]Loading trainS:  87%|████████▋ | 215/247 [00:48<00:07,  4.50it/s]Loading trainS:  87%|████████▋ | 216/247 [00:48<00:06,  4.53it/s]Loading trainS:  88%|████████▊ | 217/247 [00:48<00:06,  4.54it/s]Loading trainS:  88%|████████▊ | 218/247 [00:49<00:06,  4.51it/s]Loading trainS:  89%|████████▊ | 219/247 [00:49<00:06,  4.42it/s]Loading trainS:  89%|████████▉ | 220/247 [00:49<00:06,  4.34it/s]Loading trainS:  89%|████████▉ | 221/247 [00:49<00:06,  4.25it/s]Loading trainS:  90%|████████▉ | 222/247 [00:49<00:05,  4.30it/s]Loading trainS:  90%|█████████ | 223/247 [00:50<00:05,  4.36it/s]Loading trainS:  91%|█████████ | 224/247 [00:50<00:05,  4.38it/s]Loading trainS:  91%|█████████ | 225/247 [00:50<00:04,  4.41it/s]Loading trainS:  91%|█████████▏| 226/247 [00:50<00:04,  4.46it/s]Loading trainS:  92%|█████████▏| 227/247 [00:51<00:04,  4.50it/s]Loading trainS:  92%|█████████▏| 228/247 [00:51<00:04,  4.52it/s]Loading trainS:  93%|█████████▎| 229/247 [00:51<00:03,  4.52it/s]Loading trainS:  93%|█████████▎| 230/247 [00:51<00:03,  4.41it/s]Loading trainS:  94%|█████████▎| 231/247 [00:51<00:03,  4.35it/s]Loading trainS:  94%|█████████▍| 232/247 [00:52<00:03,  4.31it/s]Loading trainS:  94%|█████████▍| 233/247 [00:52<00:03,  4.27it/s]Loading trainS:  95%|█████████▍| 234/247 [00:52<00:03,  4.26it/s]Loading trainS:  95%|█████████▌| 235/247 [00:52<00:02,  4.24it/s]Loading trainS:  96%|█████████▌| 236/247 [00:53<00:02,  4.22it/s]Loading trainS:  96%|█████████▌| 237/247 [00:53<00:03,  3.18it/s]Loading trainS:  96%|█████████▋| 238/247 [00:54<00:03,  2.85it/s]Loading trainS:  97%|█████████▋| 239/247 [00:54<00:03,  2.47it/s]Loading trainS:  97%|█████████▋| 240/247 [00:55<00:03,  2.04it/s]Loading trainS:  98%|█████████▊| 241/247 [00:56<00:03,  1.73it/s]Loading trainS:  98%|█████████▊| 242/247 [00:56<00:03,  1.61it/s]Loading trainS:  98%|█████████▊| 243/247 [00:57<00:02,  1.56it/s]Loading trainS:  99%|█████████▉| 244/247 [00:58<00:02,  1.45it/s]Loading trainS:  99%|█████████▉| 245/247 [00:59<00:01,  1.39it/s]Loading trainS: 100%|█████████▉| 246/247 [00:59<00:00,  1.36it/s]Loading trainS: 100%|██████████| 247/247 [01:00<00:00,  1.29it/s]Loading trainS: 100%|██████████| 247/247 [01:00<00:00,  4.07it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.38it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.34it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.35it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.50it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.52it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]
Epoch 00045: val_mDice did not improve from 0.22684
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [-0.020260493960173875, -0.042294365506699946, -0.1681970328600045, -0.1128721068218212, -0.05371408349035694, -0.09482508883941285, -0.07987210358674682, -0.0887801714708968, -0.0706025662806012, -0.16514312897898234, -0.1530873913681221, -0.07651294912024179, -0.12092716531718478, -0.1258802327785883, -0.0877186828689367, -0.10664129231251984, -0.15645902237390677, -0.11159118466730152, -0.152892944601944, -0.21859335908579752, -0.25972887603767886, -0.24553558121986063, -0.24156205801310554, -0.25039675942515444, -0.2815862997368716, -0.21645236403418952, -0.2702970602333361, -0.22444116454513818, -0.27954816063664184, -0.24860038482994937, -0.26304877073656846, -0.2779029646755741, -0.267070002210883, -0.2677997737069075, -0.26099143706293826, -0.2628824403901904, -0.2571783013326107, -0.2613596577823001, -0.28463435489626676, -0.26889727532722335, -0.2670880831005311, -0.28179988914656656, -0.26935189934490655, -0.25867985102532565, -0.2746302466724218], 'val_acc': [0.9514227312046677, 0.9553911665644808, 0.9567078695208665, 0.9539439327576581, 0.9566483320466506, 0.9543950493121663, 0.9529260649769667, 0.9527165376734069, 0.956613980395137, 0.956525817005996, 0.9551598798748878, 0.9521852731704712, 0.9536760137546173, 0.9560220398400959, 0.9561846195359717, 0.9553052902959818, 0.9566987068291419, 0.9528001144574523, 0.9558434261257065, 0.9554987894861322, 0.9555331431675252, 0.9575391101763344, 0.9548186897862437, 0.9569048102795155, 0.958401270695146, 0.9560792859493763, 0.9577085650742239, 0.9577120009221529, 0.9561960704555452, 0.9572196685861877, 0.9574395008500516, 0.9574280528830301, 0.9586039301780724, 0.9583245523204744, 0.958034873746866, 0.9546148773317367, 0.9578310793767404, 0.9577314639608189, 0.9579513017607179, 0.9584138614843505, 0.9586279657972118, 0.958213493919963, 0.9581711247978565, 0.9571864652928922, 0.9574761438665006], 'val_mDice': [0.2058915011930761, 0.2222140534743436, 0.2116581894480407, 0.22252567296980336, 0.22683948509095253, 0.2211135646599365, 0.2177876107187094, 0.2126508243035975, 0.21619337700284302, 0.20876414531801507, 0.21121503767952463, 0.19682748398913688, 0.21152930351510504, 0.21284559931917457, 0.21802459454204276, 0.21407674801977059, 0.21608517358177587, 0.21092635859092324, 0.21223562282305383, 0.21376474146318877, 0.20451553431180977, 0.2178305145295412, 0.20129581792251244, 0.20629481334619848, 0.20965269752331192, 0.20761620726194174, 0.21248565992519214, 0.22188008615845128, 0.20275371443284185, 0.21179598655217202, 0.21185423175432364, 0.21758712459090324, 0.21448260697971558, 0.21099468479769148, 0.21312766180780282, 0.1960067884656298, 0.20888587488755353, 0.213528719064621, 0.20796612850837295, 0.20769926843351624, 0.2048245572914649, 0.20994338780733823, 0.20663913316309637, 0.1998498469545007, 0.2072648722505422], 'loss': [0.46473857718232076, 0.378990517348627, 0.360057902905214, 0.34827366243767277, 0.3411570381461316, 0.32741287495113847, 0.32825185011537017, 0.3258836421954236, 0.3195419562502368, 0.31691137591360385, 0.31517051514450767, 0.30728794987792146, 0.3088448020399769, 0.3037504129217735, 0.3036521589748789, 0.2999403807298665, 0.3025864782161696, 0.29349109208837015, 0.29795492806409696, 0.29953579740816555, 0.2762557083092308, 0.2591385435902466, 0.2556137485257149, 0.23976602199413674, 0.22826417527774007, 0.22596208484243083, 0.24017273749128792, 0.2380485985951344, 0.22187089414365307, 0.22561992391744587, 0.23221186762742765, 0.21712146467661905, 0.21512876860440416, 0.2245380354444553, 0.21945735119510462, 0.2134943371905934, 0.20603360915562788, 0.20239574825945406, 0.20385941271254143, 0.19993935209395466, 0.2001200355565333, 0.20355212514342808, 0.2025783765627883, 0.19998188739101203, 0.2001204751773674], 'acc': [0.9371441406850586, 0.947054364481434, 0.9492587934830441, 0.9508535659764067, 0.9516048389465288, 0.9528875307386281, 0.9530728082737757, 0.9535945310596605, 0.9542688403714106, 0.9546213731472875, 0.9545964415648647, 0.9555743874636177, 0.9552835115927794, 0.9557356518388015, 0.9560979984686899, 0.9565044274948424, 0.9564270611867376, 0.9568565591073962, 0.9568389397478277, 0.9550871959571381, 0.9548339630786661, 0.9544491635513014, 0.9540702124868807, 0.9548079237561421, 0.9552313832081325, 0.955178476716572, 0.9545234868520224, 0.9550366242006882, 0.9553530695631657, 0.9549262833706281, 0.9547223265974396, 0.9554365911352383, 0.9549220610892061, 0.9548785907021362, 0.9551287553384753, 0.9556527668377963, 0.9559390443503777, 0.956114272498318, 0.9561127396944918, 0.9562099180254099, 0.9565028234003788, 0.9563842506248722, 0.9564029789258345, 0.9567972143295963, 0.9565238635738754], 'mDice': [0.4987613058365253, 0.5913820288411528, 0.6118333072099419, 0.6245554246550593, 0.6322182405929387, 0.647086306303023, 0.6461612625316406, 0.6487243648078401, 0.6555775915666292, 0.6583796411617745, 0.6602711036646425, 0.6687760127066684, 0.667109177218871, 0.6726187846286389, 0.6726864110990876, 0.6767033307526031, 0.6738315209251208, 0.683666364678589, 0.6786729028710176, 0.6619799686250687, 0.6639988510627985, 0.6503153649419005, 0.6499372217658071, 0.6527481332646545, 0.6582928753334829, 0.6639145645828254, 0.6498009893342057, 0.6493785797473811, 0.6610200595959115, 0.6543595199568538, 0.6498055866964542, 0.6590329149607395, 0.6579999306865079, 0.6562592009286414, 0.658772052938639, 0.6590327399407611, 0.6669964607071075, 0.6696624417102446, 0.6716091722046601, 0.6697691577651289, 0.6730497586832825, 0.6745762476333208, 0.6711963443733598, 0.6770149203152428, 0.6704678332078016], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              2020-01-22 02:25:35.177140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 02:25:35.177227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 02:25:35.177240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 02:25:35.177247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 02:25:35.177546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 45s - loss: 0.2092 - acc: 0.9835 - mDice: 0.5903 - val_loss: 0.0343 - val_acc: 0.9925 - val_mDice: 0.4448

Epoch 00001: val_mDice improved from -inf to 0.44479, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 41s - loss: 0.0878 - acc: 0.9910 - mDice: 0.8290 - val_loss: 0.0494 - val_acc: 0.9909 - val_mDice: 0.4153

Epoch 00002: val_mDice did not improve from 0.44479
Epoch 3/300
 - 41s - loss: 0.0764 - acc: 0.9920 - mDice: 0.8513 - val_loss: -6.2908e-04 - val_acc: 0.9931 - val_mDice: 0.4515

Epoch 00003: val_mDice improved from 0.44479 to 0.45155, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 41s - loss: 0.0720 - acc: 0.9925 - mDice: 0.8598 - val_loss: 0.0827 - val_acc: 0.9933 - val_mDice: 0.4596

Epoch 00004: val_mDice improved from 0.45155 to 0.45965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 41s - loss: 0.0669 - acc: 0.9930 - mDice: 0.8699 - val_loss: 0.0369 - val_acc: 0.9927 - val_mDice: 0.4393

Epoch 00005: val_mDice did not improve from 0.45965
Epoch 6/300
 - 41s - loss: 0.0637 - acc: 0.9933 - mDice: 0.8761 - val_loss: 0.1089 - val_acc: 0.9933 - val_mDice: 0.4822

Epoch 00006: val_mDice improved from 0.45965 to 0.48215, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 41s - loss: 0.0613 - acc: 0.9934 - mDice: 0.8807 - val_loss: 0.0043 - val_acc: 0.9937 - val_mDice: 0.4735

Epoch 00007: val_mDice did not improve from 0.48215
Epoch 8/300
 - 42s - loss: 0.0599 - acc: 0.9936 - mDice: 0.8834 - val_loss: -8.4894e-03 - val_acc: 0.9937 - val_mDice: 0.4816

Epoch 00008: val_mDice did not improve from 0.48215
Epoch 9/300
 - 40s - loss: 0.0568 - acc: 0.9938 - mDice: 0.8895 - val_loss: 0.0717 - val_acc: 0.9934 - val_mDice: 0.4959

Epoch 00009: val_mDice improved from 0.48215 to 0.49591, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 41s - loss: 0.0561 - acc: 0.9940 - mDice: 0.8909 - val_loss: 0.0424 - val_acc: 0.9938 - val_mDice: 0.4907

Epoch 00010: val_mDice did not improve from 0.49591
Epoch 11/300
 - 40s - loss: 0.0551 - acc: 0.9940 - mDice: 0.8928 - val_loss: 0.0417 - val_acc: 0.9936 - val_mDice: 0.4923

Epoch 00011: val_mDice did not improve from 0.49591
Epoch 12/300
 - 41s - loss: 0.0543 - acc: 0.9942 - mDice: 0.8944 - val_loss: 0.0393 - val_acc: 0.9939 - val_mDice: 0.4969

Epoch 00012: val_mDice improved from 0.49591 to 0.49694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 13/300
 - 41s - loss: 0.0521 - acc: 0.9943 - mDice: 0.8987 - val_loss: 0.1104 - val_acc: 0.9920 - val_mDice: 0.4818

Epoch 00013: val_mDice did not improve from 0.49694
Epoch 14/300
 - 41s - loss: 0.0531 - acc: 0.9943 - mDice: 0.8967 - val_loss: 0.0152 - val_acc: 0.9936 - val_mDice: 0.4824

Epoch 00014: val_mDice did not improve from 0.49694
Epoch 15/300
 - 42s - loss: 0.0500 - acc: 0.9944 - mDice: 0.9028 - val_loss: 0.0099 - val_acc: 0.9939 - val_mDice: 0.4929

Epoch 00015: val_mDice did not improve from 0.49694
Epoch 16/300
 - 41s - loss: 0.0504 - acc: 0.9945 - mDice: 0.9020 - val_loss: 0.0419 - val_acc: 0.9934 - val_mDice: 0.4914

Epoch 00016: val_mDice did not improve from 0.49694
Epoch 17/300
 - 42s - loss: 0.0495 - acc: 0.9945 - mDice: 0.9038 - val_loss: 0.0070 - val_acc: 0.9942 - val_mDice: 0.4985

Epoch 00017: val_mDice improved from 0.49694 to 0.49848, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 18/300
 - 41s - loss: 0.0502 - acc: 0.9945 - mDice: 0.9023 - val_loss: 0.0112 - val_acc: 0.9937 - val_mDice: 0.4906

Epoch 00018: val_mDice did not improve from 0.49848
Epoch 19/300
 - 42s - loss: 0.0488 - acc: 0.9946 - mDice: 0.9051 - val_loss: 0.0053 - val_acc: 0.9937 - val_mDice: 0.5023

Epoch 00019: val_mDice improved from 0.49848 to 0.50225, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 42s - loss: 0.0474 - acc: 0.9947 - mDice: 0.9078 - val_loss: 0.0572 - val_acc: 0.9939 - val_mDice: 0.4941

Epoch 00020: val_mDice did not improve from 0.50225
Epoch 21/300
 - 42s - loss: 0.0474 - acc: 0.9947 - mDice: 0.9080 - val_loss: 0.1002 - val_acc: 0.9937 - val_mDice: 0.5011

Epoch 00021: val_mDice did not improve from 0.50225
Epoch 22/300
 - 42s - loss: 0.0481 - acc: 0.9947 - mDice: 0.9065 - val_loss: 0.0079 - val_acc: 0.9939 - val_mDice: 0.4970

Epoch 00022: val_mDice did not improve from 0.50225
Epoch 23/300
 - 42s - loss: 0.0473 - acc: 0.9948 - mDice: 0.9080 - val_loss: 0.0355 - val_acc: 0.9941 - val_mDice: 0.5043

Epoch 00023: val_mDice improved from 0.50225 to 0.50434, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 24/300
 - 46s - loss: 0.0463 - acc: 0.9949 - mDice: 0.9100 - val_loss: 0.0059 - val_acc: 0.9941 - val_mDice: 0.5008

Epoch 00024: val_mDice did not improve from 0.50434
Epoch 25/300
 - 46s - loss: 0.0460 - acc: 0.9949 - mDice: 0.9105 - val_loss: 0.0297 - val_acc: 0.9916 - val_mDice: 0.4543

Epoch 00025: val_mDice did not improve from 0.50434
Epoch 26/300
 - 42s - loss: 0.0466 - acc: 0.9948 - mDice: 0.9095 - val_loss: 0.0179 - val_acc: 0.9927 - val_mDice: 0.4775

Epoch 00026: val_mDice did not improve from 0.50434
Epoch 27/300
 - 42s - loss: 0.0449 - acc: 0.9950 - mDice: 0.9127 - val_loss: 0.0700 - val_acc: 0.9932 - val_mDice: 0.4996

Epoch 00027: val_mDice did not improve from 0.50434
Epoch 28/300
 - 42s - loss: 0.0445 - acc: 0.9949 - mDice: 0.9135 - val_loss: 0.0346 - val_acc: 0.9942 - val_mDice: 0.5064

Epoch 00028: val_mDice improved from 0.50434 to 0.50635, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 29/300
 - 42s - loss: 0.0453 - acc: 0.9949 - mDice: 0.9120 - val_loss: 0.0082 - val_acc: 0.9935 - val_mDice: 0.4964

Epoch 00029: val_mDice did not improve from 0.50635
Epoch 30/300
 - 42s - loss: 0.0460 - acc: 0.9949 - mDice: 0.9105 - val_loss: 0.0114 - val_acc: 0.9933 - val_mDice: 0.4901

Epoch 00030: val_mDice did not improve from 0.50635
Epoch 31/300
 - 43s - loss: 0.0431 - acc: 0.9951 - mDice: 0.9164 - val_loss: 0.0433 - val_acc: 0.9933 - val_mDice: 0.4876

Epoch 00031: val_mDice did not improve from 0.50635
Epoch 32/300
 - 47s - loss: 0.0444 - acc: 0.9950 - mDice: 0.9137 - val_loss: 0.0796 - val_acc: 0.9929 - val_mDice: 0.4859

Epoch 00032: val_mDice did not improve from 0.50635
Epoch 33/300
 - 50s - loss: 0.0439 - acc: 0.9951 - mDice: 0.9147 - val_loss: 0.0671 - val_acc: 0.9939 - val_mDice: 0.5043

Epoch 00033: val_mDice did not improve from 0.50635
Epoch 34/300
 - 49s - loss: 0.0443 - acc: 0.9951 - mDice: 0.9139 - val_loss: 0.0960 - val_acc: 0.9937 - val_mDice: 0.5095

Epoch 00034: val_mDice improved from 0.50635 to 0.50950, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 35/300
 - 46s - loss: 0.0437 - acc: 0.9951 - mDice: 0.9150 - val_loss: 0.0395 - val_acc: 0.9941 - val_mDice: 0.4966

Epoch 00035: val_mDice did not improve from 0.50950
Epoch 36/300
 - 43s - loss: 0.0428 - acc: 0.9952 - mDice: 0.9169 - val_loss: 0.0776 - val_acc: 0.9935 - val_mDice: 0.4917

Epoch 00036: val_mDice did not improve from 0.50950
Epoch 37/300
 - 43s - loss: 0.0424 - acc: 0.9952 - mDice: 0.9177 - val_loss: 0.0106 - val_acc: 0.9937 - val_mDice: 0.4915

Epoch 00037: val_mDice did not improve from 0.50950
Epoch 38/300
 - 43s - loss: 0.0425 - acc: 0.9952 - mDice: 0.9174 - val_loss: 0.0872 - val_acc: 0.9940 - val_mDice: 0.5045

Epoch 00038: val_mDice did not improve from 0.50950
Epoch 39/300
 - 43s - loss: 0.0445 - acc: 0.9950 - mDice: 0.9135 - val_loss: 0.0350 - val_acc: 0.9941 - val_mDice: 0.5066

Epoch 00039: val_mDice did not improve from 0.50950
Epoch 40/300
 - 43s - loss: 0.0421 - acc: 0.9953 - mDice: 0.9183 - val_loss: 0.0642 - val_acc: 0.9940 - val_mDice: 0.5033

Epoch 00040: val_mDice did not improve from 0.50950
Epoch 41/300
 - 42s - loss: 0.0420 - acc: 0.9952 - mDice: 0.9183 - val_loss: 0.0775 - val_acc: 0.9939 - val_mDice: 0.5036

Epoch 00041: val_mDice did not improve from 0.50950
Epoch 42/300
 - 41s - loss: 0.0416 - acc: 0.9953 - mDice: 0.9192 - val_loss: 0.0762 - val_acc: 0.9932 - val_mDice: 0.4886

Epoch 00042: val_mDice did not improve from 0.50950
Epoch 43/300
 - 41s - loss: 0.0417 - acc: 0.9953 - mDice: 0.9191 - val_loss: 0.0274 - val_acc: 0.9925 - val_mDice: 0.4589

Epoch 00043: val_mDice did not improve from 0.50950
Epoch 44/300
 - 41s - loss: 0.0405 - acc: 0.9953 - mDice: 0.9214 - val_loss: 0.0435 - val_acc: 0.9929 - val_mDice: 0.4774

Epoch 00044: val_mDice did not improve from 0.50950
Epoch 45/300
 - 41s - loss: 0.0422 - acc: 0.9953 - mDice: 0.9180 - val_loss: 0.0132 - val_acc: 0.9937 - val_mDice: 0.4864

Epoch 00045: val_mDice did not improve from 0.50950
Epoch 46/300
 - 41s - loss: 0.0412 - acc: 0.9953 - mDice: 0.9200 - val_loss: 0.2549 - val_acc: 0.9870 - val_mDice: 0.4337

Epoch 00046: val_mDice did not improve from 0.50950
Epoch 47/300
 - 41s - loss: 0.0413 - acc: 0.9953 - mDice: 0.9197 - val_loss: 0.0384 - val_acc: 0.9937 - val_mDice: 0.4988

Epoch 00047: val_mDice did not improve from 0.50950
Epoch 48/300
 - 41s - loss: 0.0408 - acc: 0.9953 - mDice: 0.9207 - val_loss: 0.1155 - val_acc: 0.9922 - val_mDice: 0.4877

Epoch 00048: val_mDice did not improve from 0.50950
Epoch 49/300
 - 42s - loss: 0.0407 - acc: 0.9953 - mDice: 0.9210 - val_loss: 0.0025 - val_acc: 0.9940 - val_mDice: 0.5078

Epoch 00049: val_mDice did not improve from 0.50950

Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 50/300
 - 42s - loss: 0.0389 - acc: 0.9955 - mDice: 0.9244 - val_loss: 0.0058 - val_acc: 0.9941 - val_mDice: 0.5021

Epoch 00050: val_mDice did not improve from 0.50950
Epoch 51/300
 - 41s - loss: 0.0397 - acc: 0.9955 - mDice: 0.9229 - val_loss: 0.0022 - val_acc: 0.9941 - val_mDice: 0.5084

Epoch 00051: val_mDice did not improve from 0.50950
Epoch 52/300
 - 41s - loss: 0.0383 - acc: 0.9956 - mDice: 0.9256 - val_loss: 0.0050 - val_acc: 0.9940 - val_mDice: 0.5082

Epoch 00052: val_mDice did not improve from 0.50950
Epoch 53/300
 - 41s - loss: 0.0388 - acc: 0.9956 - mDice: 0.9245 - val_loss: 0.0112 - val_acc: 0.9933 - val_mDice: 0.4909

Epoch 00053: val_mDice did not improve from 0.50950
Epoch 54/300
 - 42s - loss: 0.0384 - acc: 0.9956 - mDice: 0.9255 - val_loss: 0.0374 - val_acc: 0.9942 - val_mDice: 0.5045

Epoch 00054: val_mDice did not improve from 0.50950
Epoch 55/300
 - 41s - loss: 0.0378 - acc: 0.9956 - mDice: 0.9266 - val_loss: 0.0206 - val_acc: 0.9940 - val_mDice: 0.4924

Epoch 00055: val_mDice did not improve from 0.50950
Epoch 56/300
 - 42s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9263 - val_loss: -1.8226e-02 - val_acc: 0.9939 - val_mDice: 0.4952

Epoch 00056: val_mDice did not improve from 0.50950
Epoch 57/300
 - 47s - loss: 0.0378 - acc: 0.9956 - mDice: 0.9266 - val_loss: -2.3977e-02 - val_acc: 0.9941 - val_mDice: 0.4992

Epoch 00057: val_mDice did not improve from 0.50950
Epoch 58/300
 - 41s - loss: 0.0377 - acc: 0.9956 - mDice: 0.9267 - val_loss: -1.3647e-02 - val_acc: 0.9930 - val_mDice: 0.4775

Epoch 00058: val_mDice did not improve from 0.50950
Epoch 59/300
 - 41s - loss: 0.0376 - acc: 0.9956 - mDice: 0.9269 - val_loss: -3.1855e-04 - val_acc: 0.9944 - val_mDice: 0.5053

Epoch 00059: val_mDice did not improve from 0.50950
Epoch 60/300
 - 41s - loss: 0.0371 - acc: 0.9957 - mDice: 0.9279 - val_loss: 0.0059 - val_acc: 0.9941 - val_mDice: 0.5011

Epoch 00060: val_mDice did not improve from 0.50950
Epoch 61/300
 - 41s - loss: 0.0387 - acc: 0.9956 - mDice: 0.9248 - val_loss: 0.0322 - val_acc: 0.9939 - val_mDice: 0.5130

Epoch 00061: val_mDice improved from 0.50950 to 0.51297, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 62/300
 - 42s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9272 - val_loss: 0.0283 - val_acc: 0.9941 - val_mDice: 0.5008

Epoch 00062: val_mDice did not improve from 0.51297
Epoch 63/300
 - 41s - loss: 0.0378 - acc: 0.9957 - mDice: 0.9265 - val_loss: 0.0247 - val_acc: 0.9941 - val_mDice: 0.4959

Epoch 00063: val_mDice did not improve from 0.51297
Epoch 64/300
 - 42s - loss: 0.0373 - acc: 0.9957 - mDice: 0.9275 - val_loss: 0.0741 - val_acc: 0.9943 - val_mDice: 0.5084

Epoch 00064: val_mDice did not improve from 0.51297
Epoch 65/300
 - 42s - loss: 0.0368 - acc: 0.9957 - mDice: 0.9286 - val_loss: 0.0179 - val_acc: 0.9940 - val_mDice: 0.5025

Epoch 00065: val_mDice did not improve from 0.51297
Epoch 66/300
 - 42s - loss: 0.0364 - acc: 0.9957 - mDice: 0.9293 - val_loss: 0.0635 - val_acc: 0.9941 - val_mDice: 0.5143

Epoch 00066: val_mDice improved from 0.51297 to 0.51428, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 67/300
 - 42s - loss: 0.0370 - acc: 0.9957 - mDice: 0.9280 - val_loss: 0.0696 - val_acc: 0.9942 - val_mDice: 0.5058

Epoch 00067: val_mDice did not improve from 0.51428
Epoch 68/300
 - 42s - loss: 0.0363 - acc: 0.9957 - mDice: 0.9295 - val_loss: 0.0137 - val_acc: 0.9943 - val_mDice: 0.5071

Epoch 00068: val_mDice did not improve from 0.51428
Epoch 69/300
 - 42s - loss: 0.0367 - acc: 0.9957 - mDice: 0.9287 - val_loss: 0.0962 - val_acc: 0.9943 - val_mDice: 0.5085

Epoch 00069: val_mDice did not improve from 0.51428
Epoch 70/300
 - 41s - loss: 0.0374 - acc: 0.9957 - mDice: 0.9274 - val_loss: 0.1724 - val_acc: 0.9937 - val_mDice: 0.4783

Epoch 00070: val_mDice did not improve from 0.51428
Epoch 71/300
 - 41s - loss: 0.0371 - acc: 0.9957 - mDice: 0.9279 - val_loss: 0.1049 - val_acc: 0.9937 - val_mDice: 0.4977

Epoch 00071: val_mDice did not improve from 0.51428
Epoch 72/300
 - 42s - loss: 0.0363 - acc: 0.9957 - mDice: 0.9295 - val_loss: 0.0326 - val_acc: 0.9938 - val_mDice: 0.4965

Epoch 00072: val_mDice did not improve from 0.51428
Epoch 73/300
 - 41s - loss: 0.0363 - acc: 0.9958 - mDice: 0.9294 - val_loss: 0.0827 - val_acc: 0.9942 - val_mDice: 0.5037

Epoch 00073: val_mDice did not improve from 0.51428
Epoch 74/300
 - 41s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9297 - val_loss: 0.0744 - val_acc: 0.9935 - val_mDice: 0.4801

Epoch 00074: val_mDice did not improve from 0.51428
Epoch 75/300
 - 42s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9302 - val_loss: 0.0174 - val_acc: 0.9936 - val_mDice: 0.4929

Epoch 00075: val_mDice did not improve from 0.51428
Epoch 76/300
 - 42s - loss: 0.0356 - acc: 0.9958 - mDice: 0.9308 - val_loss: 0.0464 - val_acc: 0.9936 - val_mDice: 0.4784

Epoch 00076: val_mDice did not improve from 0.51428
Epoch 77/300
 - 41s - loss: 0.0368 - acc: 0.9958 - mDice: 0.9286 - val_loss: 0.1703 - val_acc: 0.9938 - val_mDice: 0.5075

Epoch 00077: val_mDice did not improve from 0.51428
Epoch 78/300
 - 42s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9314 - val_loss: 0.0445 - val_acc: 0.9933 - val_mDice: 0.4823

Epoch 00078: val_mDice did not improve from 0.51428
Epoch 79/300
 - 42s - loss: 0.0359 - acc: 0.9957 - mDice: 0.9304 - val_loss: 0.0046 - val_acc: 0.9942 - val_mDice: 0.5110

Epoch 00079: val_mDice did not improve from 0.51428
Epoch 80/300
 - 42s - loss: 0.0364 - acc: 0.9957 - mDice: 0.9293 - val_loss: 0.0133 - val_acc: 0.9937 - val_mDice: 0.4949

Epoch 00080: val_mDice did not improve from 0.51428
Epoch 81/300
 - 41s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9299 - val_loss: 0.0494 - val_acc: 0.9942 - val_mDice: 0.5080

Epoch 00081: val_mDice did not improve from 0.51428

Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 82/300
 - 41s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9305 - val_loss: 0.0579 - val_acc: 0.9941 - val_mDice: 0.5070

Epoch 00082: val_mDice did not improve from 0.51428
Epoch 83/300
 - 42s - loss: 0.0346 - acc: 0.9959 - mDice: 0.9328 - val_loss: 0.0711 - val_acc: 0.9941 - val_mDice: 0.5086

Epoch 00083: val_mDice did not improve from 0.51428
Epoch 84/300
 - 42s - loss: 0.0354 - acc: 0.9959 - mDice: 0.9312 - val_loss: 0.1367 - val_acc: 0.9940 - val_mDice: 0.5031

Epoch 00084: val_mDice did not improve from 0.51428
Epoch 85/300
 - 41s - loss: 0.0349 - acc: 0.9959 - mDice: 0.9322 - val_loss: 0.0888 - val_acc: 0.9942 - val_mDice: 0.5067

Epoch 00085: val_mDice did not improve from 0.51428
Epoch 86/300
 - 42s - loss: 0.0355 - acc: 0.9959 - mDice: 0.9311 - val_loss: 0.0502 - val_acc: 0.9941 - val_mDice: 0.5083

Epoch 00086: val_mDice did not improve from 0.51428
Epoch 87/300
 - 42s - loss: 0.0357 - acc: 0.9959 - mDice: 0.9307 - val_loss: 0.1031 - val_acc: 0.9941 - val_mDice: 0.5074

Epoch 00087: val_mDice did not improve from 0.51428
Epoch 88/300
 - 42s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9324 - val_loss: 0.1141 - val_acc: 0.9942 - val_mDice: 0.5056

Epoch 00088: val_mDice did not improve from 0.51428
Epoch 89/300
 - 42s - loss: 0.0354 - acc: 0.9959 - mDice: 0.9313 - val_loss: 0.0740 - val_acc: 0.9942 - val_mDice: 0.5051

Epoch 00089: val_mDice did not improve from 0.51428
Epoch 90/300
 - 42s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9321 - val_loss: 0.0906 - val_acc: 0.9940 - val_mDice: 0.5006

Epoch 00090: val_mDice did not improve from 0.51428
Epoch 91/300
 - 42s - loss: 0.0344 - acc: 0.9959 - mDice: 0.9333 - val_loss: 0.0186 - val_acc: 0.9941 - val_mDice: 0.5002

Epoch 00091: val_mDice did not improve from 0.51428
Epoch 92/300
 - 42s - loss: 0.0343 - acc: 0.9959 - mDice: 0.9334 - val_loss: 0.0937 - val_acc: 0.9940 - val_mDice: 0.5011

Epoch 00092: val_mDice did not improve from 0.51428
Epoch 93/300
 - 42s - loss: 0.0338 - acc: 0.9959 - mDice: 0.9344 - val_loss: 0.0441 - val_acc: 0.9942 - val_mDice: 0.5049

Epoch 00093: val_mDice did not improve from 0.51428
Epoch 94/300
 - 42s - loss: 0.0346 - acc: 0.9959 - mDice: 0.9329 - val_loss: 0.0834 - val_acc: 0.9939 - val_mDice: 0.5036

Epoch 00094: val_mDice did not improve from 0.51428
Epoch 95/300
 - 42s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9324 - val_loss: 0.0579 - val_acc: 0.9940 - val_mDice: 0.5024

Epoch 00095: val_mDice did not improve from 0.51428
Epoch 96/300
 - 42s - loss: 0.0346 - acc: 0.9959 - mDice: 0.9328 - val_loss: 0.0546 - val_acc: 0.9938 - val_mDice: 0.4999

Epoch 00096: val_mDice did not improve from 0.51428

Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 97/300
 - 41s - loss: 0.0342 - acc: 0.9959 - mDice: 0.9336 - val_loss: 0.0677 - val_acc: 0.9942 - val_mDice: 0.5083

Epoch 00097: val_mDice did not improve from 0.51428
Epoch 98/300
 - 41s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9342 - val_loss: 0.1003 - val_acc: 0.9940 - val_mDice: 0.5055

Epoch 00098: val_mDice did not improve from 0.51428
Epoch 99/300
 - 42s - loss: 0.0341 - acc: 0.9960 - mDice: 0.9339 - val_loss: 0.1100 - val_acc: 0.9941 - val_mDice: 0.5058

Epoch 00099: val_mDice did not improve from 0.51428
Epoch 100/300
 - 41s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9353 - val_loss: 0.0406 - val_acc: 0.9941 - val_mDice: 0.5046

Epoch 00100: val_mDice did not improve from 0.51428
Epoch 101/300
 - 42s - loss: 0.0344 - acc: 0.9960 - mDice: 0.9331 - val_loss: 0.0438 - val_acc: 0.9940 - val_mDice: 0.5004

Epoch 00101: val_mDice did not improve from 0.51428
Epoch 102/300
 - 41s - loss: 0.0341 - acc: 0.9960 - mDice: 0.9339 - val_loss: 0.0221 - val_acc: 0.9941 - val_mDice: 0.5055

Epoch 00102: val_mDice did not improve from 0.51428
Epoch 103/300
 - 42s - loss: 0.0341 - acc: 0.9960 - mDice: 0.9338 - val_loss: 0.1439 - val_acc: 0.9941 - val_mDice: 0.5079

Epoch 00103: val_mDice did not improve from 0.51428
Epoch 104/300
 - 42s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9342 - val_loss: 0.0843 - val_acc: 0.9942 - val_mDice: 0.5040

Epoch 00104: val_mDice did not improve from 0.51428
Epoch 105/300
 - 42s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9354 - val_loss: 0.0923 - val_acc: 0.9941 - val_mDice: 0.5041

Epoch 00105: val_mDice did not improve from 0.51428
Epoch 106/300
 - 42s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9349 - val_loss: 0.0251 - val_acc: 0.9938 - val_mDice: 0.5025

Epoch 00106: val_mDice did not improve from 0.51428
Restoring model weights from the end of the best epoch
Epoch 00106: early stopping
{'val_loss': [0.03430603266512073, 0.04942758226732038, -0.0006290804946197654, 0.08266150895154702, 0.03694378397187347, 0.10892014875539444, 0.004253669729772603, -0.008489395884222954, 0.07170758677541085, 0.04243911081140146, 0.04169311557175978, 0.039324665734977844, 0.11038417753371053, 0.015155543649346574, 0.009888910506881258, 0.041912086261143476, 0.0070272376233676695, 0.011184349749823037, 0.005273003342016688, 0.05719702194134394, 0.1002001499979751, 0.007861761739418941, 0.03553928228669197, 0.005888907695716282, 0.029707373828633026, 0.01789585304147792, 0.06999420501151175, 0.034553056899106725, 0.008242744226125802, 0.011419567718820751, 0.043260135037719076, 0.07963213868111184, 0.06711718613434138, 0.09602828108289707, 0.039547805703660975, 0.07760134273729984, 0.010623258708408044, 0.0871553436015387, 0.034971817859313775, 0.06415973256968852, 0.0775307963760394, 0.07621352890002653, 0.02740632105360991, 0.043457078062138464, 0.013187231882563178, 0.2549067621804633, 0.038402394491171686, 0.1155407689277481, 0.0024691516029759775, 0.005793133809131646, 0.002160846156144292, 0.004980372089260029, 0.011222623944657404, 0.03742199536389525, 0.02064662131498445, -0.018226204615718913, -0.02397682325645063, -0.013646653285191494, -0.0003185471367536101, 0.0058619431073560655, 0.03221854492553375, 0.02828701009165566, 0.024692066622979986, 0.07410092440978536, 0.017948402689312987, 0.06348494177906767, 0.06962592956030143, 0.013671356598911045, 0.09615285971067236, 0.17240798571762048, 0.10488451942332885, 0.03255486638291077, 0.08271953636932673, 0.07443740237621391, 0.017401117948616075, 0.04642354336174779, 0.17034187294402212, 0.04448617488708136, 0.004622227037852665, 0.013323333653264076, 0.04936865600025129, 0.05789998164341885, 0.07108524413603656, 0.13666453507711301, 0.08876607248430732, 0.05017125072344294, 0.10308552711452328, 0.11408314900765629, 0.07404714166743201, 0.09064324485993236, 0.018563101267289814, 0.09369816509245327, 0.044068065876106045, 0.08340988289447701, 0.057933375333090245, 0.054561691698413226, 0.06770009327234712, 0.10032048348173406, 0.10995921539435596, 0.040589837205110106, 0.04381779562564766, 0.022051450310263242, 0.14388020781788435, 0.08433169585728795, 0.0923285889175703, 0.02514854387479758], 'val_acc': [0.992469701002229, 0.990902138206194, 0.9930520383816845, 0.9933073205767937, 0.992728739414575, 0.9933427084916793, 0.9936592316477554, 0.993651955382629, 0.9934165114126865, 0.993845985370612, 0.9936388985915754, 0.9939019593802638, 0.9920462399908582, 0.9935686213415373, 0.9938991965737732, 0.9933600294515021, 0.9941974016105604, 0.9937209805602547, 0.9936785675444693, 0.9938550197853232, 0.993723490328159, 0.9939117472876543, 0.9940882145233874, 0.9940811856737677, 0.9916212851146482, 0.9926725142406967, 0.9932387921045411, 0.9941685327194022, 0.9935111347234474, 0.9933286564155195, 0.9932704200534701, 0.9929388364156088, 0.9938926756756861, 0.9937227387098396, 0.9941175782455588, 0.993509884525395, 0.9936803219453344, 0.9939757585525513, 0.9940861995864965, 0.9940282200117531, 0.9938954328590969, 0.9932307585980158, 0.992538480638708, 0.9928512344570279, 0.9936634958165247, 0.9870298099967668, 0.9936968837893984, 0.9922109043823099, 0.9940038702023104, 0.994094229344302, 0.9940746572782408, 0.9940189344328154, 0.9933361913423119, 0.9942222499997361, 0.9939973418067836, 0.9939102421766557, 0.9941108024345254, 0.9929950615894869, 0.9943748660057595, 0.9941055336088505, 0.9939456357146209, 0.9941030182178665, 0.9940565865744585, 0.9943176324262559, 0.9940146627666065, 0.9940575837339245, 0.9941871076259973, 0.9942536267844386, 0.9942676826093182, 0.9937234959512387, 0.9936830791287452, 0.9938005527610299, 0.9941557364643745, 0.9935216798722369, 0.9936258474236015, 0.9936035125510497, 0.993826910009924, 0.9933088219390726, 0.9941835969499072, 0.9936534604936276, 0.9941971523206938, 0.9941057791499972, 0.9940954889141539, 0.9940405176870478, 0.9941763169360611, 0.9941258647906706, 0.9940857066298431, 0.9941743113709696, 0.9941735522552106, 0.9939863037013408, 0.9940912209966648, 0.9940294758328851, 0.9941557308412948, 0.9939258049868938, 0.9940176729886037, 0.9938422216559356, 0.9941662797388041, 0.9940254590796225, 0.9940869568278955, 0.9941173270813324, 0.994013155781248, 0.9940972470637387, 0.9940563316615123, 0.9941876099544501, 0.9940867019149492, 0.9938384541925395], 'val_mDice': [0.4447916631212421, 0.41527489375955656, 0.45154599502721016, 0.45964653594946525, 0.4392752453791704, 0.4821529637717601, 0.47348333276667687, 0.48157404944206933, 0.4959095201496058, 0.4907128535820253, 0.49229908359688035, 0.4969444107147133, 0.48176003842608733, 0.4824093504334396, 0.4929102666722903, 0.4914182241795198, 0.498480497384971, 0.49056795290993443, 0.5022539971572049, 0.4940811624317049, 0.5011308935921897, 0.49700286825123074, 0.5043355919102135, 0.5007931522136544, 0.454326037686529, 0.47752319805839527, 0.4996447994391311, 0.506350872276714, 0.4963663792378216, 0.49007497868447936, 0.4876294029208849, 0.4858599267548548, 0.5042678145867497, 0.5094987834633896, 0.4965807444785001, 0.4916786601614652, 0.4915083059162464, 0.5044658533619635, 0.5066194770119663, 0.5032790159373164, 0.5036137941873299, 0.4885662504055965, 0.4588539481350461, 0.4774359112265725, 0.4864088071029891, 0.43365811706526475, 0.49883663232596415, 0.4876896099380843, 0.5077578817382924, 0.502095805867663, 0.5084110993259358, 0.508243979288722, 0.49093073831414274, 0.5045460433367502, 0.49235315911424987, 0.49516329038068185, 0.49919415195033234, 0.47747802621913404, 0.5053014008316604, 0.5010915285198944, 0.5129681534643443, 0.500801849009106, 0.49594065490758643, 0.5084054279814726, 0.5025348910745585, 0.5142800097570479, 0.5058207614757355, 0.5071038605188424, 0.5085114397345778, 0.4783148271670132, 0.4977305290880818, 0.49653208435284774, 0.5037235472579751, 0.4800678875133301, 0.49290606131156284, 0.4783751178275114, 0.5075104740805596, 0.4823038680186062, 0.5109713356883364, 0.4948943826434372, 0.5080368129079634, 0.5069844691820864, 0.5086131870699754, 0.5031060143883452, 0.5066878543053783, 0.5083477896573784, 0.5074251368173264, 0.5055589357730728, 0.5051268493674649, 0.5006086402250536, 0.5002367130990298, 0.5011471440582156, 0.5048713269614199, 0.5036176281905024, 0.5023926345385471, 0.4999136582672971, 0.5082835643640105, 0.5054972210676415, 0.5058411888356479, 0.5045693170911861, 0.5004079684427699, 0.5054556491708605, 0.507921039730123, 0.5039679581217421, 0.504052336474166, 0.5025470836685514], 'loss': [0.2092302990345534, 0.08784266331284889, 0.07642511036976463, 0.07201542155471012, 0.06686863998342821, 0.06366415530532397, 0.06133048164261699, 0.05990687076882342, 0.056815377458182915, 0.05610894045684962, 0.05514330125231938, 0.05427074986845664, 0.05209684854219548, 0.053131243372445215, 0.05000187287208861, 0.05041388603729719, 0.0494761861150819, 0.050234613113568055, 0.048804702154082176, 0.04741978525825497, 0.047356891644903476, 0.048109716988763596, 0.04733916789100009, 0.04630833391047202, 0.04602332525354842, 0.046559585301573954, 0.04491175529861813, 0.044538708680153014, 0.045296622386788096, 0.04601091965772797, 0.04305601308907943, 0.0444135852901455, 0.043881806922459965, 0.04428972242909734, 0.043741686810918445, 0.042770506014518234, 0.04236770516512815, 0.042473621423901924, 0.044507352672898286, 0.04205785497249912, 0.04204953746137461, 0.041585729000023636, 0.04165485591146083, 0.04048830577413707, 0.04215421487109624, 0.04116668344476955, 0.04134665103524693, 0.04083667982376166, 0.040698936423270535, 0.03891612297487574, 0.039661091349760653, 0.03829327802087607, 0.038845918188928574, 0.03836889527171263, 0.03779913109175937, 0.03792086416094878, 0.037783114570844614, 0.037738323419817844, 0.03762621471942229, 0.037134525925292726, 0.03870389168214608, 0.037491694386387796, 0.037825074732623275, 0.0373288197231489, 0.03675603834146959, 0.036402135093139575, 0.03704868469375213, 0.03630192726237216, 0.03672766598045127, 0.03735747517370678, 0.037108824028728546, 0.0363178694949212, 0.036342939240665145, 0.03622143303877429, 0.03593493722068844, 0.035628207160792284, 0.036750638579178936, 0.035334535512722885, 0.03587508766479134, 0.03639069283564628, 0.03606759907060295, 0.035798628128513074, 0.034627247391741126, 0.035397624550027186, 0.03490252632635673, 0.03547980407953084, 0.035679442096705094, 0.03479085213661075, 0.035360372022452215, 0.0349823801633529, 0.034357162588781236, 0.03429254998487111, 0.033822441054984324, 0.03455256488955684, 0.03482583851963988, 0.03461742832565373, 0.03417374580879258, 0.03390671561564344, 0.03406537742994913, 0.03334272602035476, 0.03443433829609014, 0.03405124219550281, 0.03410905475541671, 0.03388583246431734, 0.033294012862515286, 0.0335147998229052], 'acc': [0.9834619835074866, 0.9909513845991452, 0.9919826875425212, 0.9925388232538842, 0.9929904539140867, 0.9932667462939959, 0.9934283152917699, 0.993649271404871, 0.9938491382676784, 0.9939685168037928, 0.994047924931967, 0.994202281418332, 0.9942735266465443, 0.9942732020621586, 0.9944309829684319, 0.9944913225537911, 0.994516807605751, 0.9945113469267403, 0.9946309291355983, 0.9947326372287671, 0.9947276390098402, 0.9947128308387313, 0.9947869722297228, 0.9948591535065827, 0.9948850168525266, 0.9948355443952208, 0.9950136686239673, 0.9949376754598387, 0.9949405920508497, 0.9949346988107177, 0.9950999054164772, 0.9950429521673901, 0.995082499113247, 0.9950729626005325, 0.9951271439214155, 0.995178174655852, 0.9951933150905182, 0.9952398278999282, 0.9950210353729879, 0.9952613056137187, 0.995239030217613, 0.9952878112744202, 0.9952737598325225, 0.9953072891921645, 0.9953055422735441, 0.9953234210130906, 0.9952873885111192, 0.9953156061215899, 0.9953229681426791, 0.9955195405293534, 0.9954863985329978, 0.9955797795643977, 0.995599002307655, 0.995588619197863, 0.9956026463236229, 0.9956227606462106, 0.99558779301415, 0.9956484012738759, 0.9956326461337873, 0.9956878333220788, 0.9956413723192004, 0.9956707601521668, 0.9956614024979897, 0.9956972211874403, 0.9956947222824077, 0.9957249616782663, 0.9957066884612348, 0.9957184007218961, 0.9957238018408652, 0.9956926814143157, 0.99571417007074, 0.9957348123902721, 0.9957521541750797, 0.9957234334785108, 0.995753427572041, 0.9957628070445809, 0.995764733527955, 0.9957822486702478, 0.9957327762055082, 0.9957409794489979, 0.9957872368757729, 0.995836628787266, 0.995864340687488, 0.995886580274717, 0.9958621854049424, 0.9958595112319241, 0.9959039711973025, 0.9958911792510583, 0.9958983624507792, 0.995888511002822, 0.9959064111444355, 0.9959203727482024, 0.9958979941999326, 0.9959320107966951, 0.9958762311748092, 0.995933255164455, 0.9959457194263961, 0.9959843253280553, 0.995962290008278, 0.9959727186727297, 0.9959982434363399, 0.9960034291519433, 0.9959823892401412, 0.9959808064610264, 0.9959707168992781, 0.9959851922195551], 'mDice': [0.5903362866949715, 0.8290169676075845, 0.851295516518869, 0.8598209083271584, 0.8698733112560834, 0.8761346547249458, 0.8807157456770773, 0.8834474197293598, 0.8895216012077606, 0.8908701281858682, 0.8927630997597651, 0.8944252879784184, 0.8987301112319666, 0.896661712901644, 0.9028332876903394, 0.901977043882306, 0.9038409338899311, 0.902324561941249, 0.905121662163116, 0.9078378820544201, 0.9079615468023186, 0.9064625976284295, 0.9079683725414326, 0.9099873006854919, 0.9105413729344916, 0.9094917683874462, 0.9126959417965919, 0.9134802738161389, 0.9119646369102561, 0.9105354132329133, 0.916357996830116, 0.913677823553956, 0.9147121313049642, 0.9139022276336994, 0.9149694496272776, 0.9168822317757966, 0.9176770324818093, 0.9174431553800435, 0.9134939533943367, 0.9182539427089376, 0.9182878238255616, 0.9191980031131954, 0.9190617979732527, 0.9213734266744733, 0.9180411763264372, 0.9200142614820349, 0.9196722242608574, 0.9206730259378434, 0.9209506431439773, 0.9244086663453589, 0.9229265250271174, 0.9256224499940575, 0.9245034248049374, 0.9254612831009031, 0.9265882279524098, 0.9263373869528168, 0.9266224692448561, 0.9266887064154352, 0.9269201050199574, 0.9278750556882821, 0.9247573604939673, 0.9271656544198417, 0.9264960139209298, 0.9274779012648355, 0.9286157646643667, 0.9293204231597028, 0.928027283617761, 0.9295208699820969, 0.9286631926518778, 0.9274202683867585, 0.9279137679683981, 0.9294749296538162, 0.9294217631284005, 0.9296687081601223, 0.9302252891147544, 0.9308435966447275, 0.928591658926926, 0.9314183400631189, 0.9303577585793041, 0.9293286517340514, 0.9299490386989534, 0.930458179110302, 0.9327794241173721, 0.9312317738452139, 0.9322288053815994, 0.9310772627718462, 0.9306643750043723, 0.9324466284818856, 0.9312988957826503, 0.9320570298280761, 0.9332987870486724, 0.933429690192661, 0.934369518635546, 0.9328902560216764, 0.9323668917178751, 0.9327700093340238, 0.9336468290661184, 0.9341635324542259, 0.9338549665119856, 0.9352888429988557, 0.9331009180260419, 0.9338657719650658, 0.9337587622141832, 0.9341979631389814, 0.9353852385622987, 0.9349393654446496], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.53it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.95it/s]predicting test subjects:  60%|██████    | 3/5 [00:00<00:00,  2.45it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.97it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.68it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.87it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:32,  7.66it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:31,  7.80it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:30,  8.11it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:29,  8.11it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:29,  8.26it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:29,  8.30it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:28,  8.37it/s]predicting train subjects:   3%|▎         | 8/247 [00:00<00:28,  8.36it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:28,  8.33it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:28,  8.31it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:28,  8.29it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:29,  8.07it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:28,  8.17it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:28,  8.29it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:27,  8.32it/s]predicting train subjects:   6%|▋         | 16/247 [00:01<00:27,  8.34it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:27,  8.32it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:28,  8.12it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:27,  8.20it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:27,  8.28it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:27,  8.33it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:27,  8.14it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:26,  8.34it/s]predicting train subjects:  10%|▉         | 24/247 [00:02<00:26,  8.47it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:25,  8.58it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:25,  8.54it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:25,  8.63it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:25,  8.72it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:24,  8.78it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:24,  8.81it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:24,  8.76it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:24,  8.82it/s]predicting train subjects:  13%|█▎        | 33/247 [00:03<00:24,  8.78it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:24,  8.84it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:23,  8.88it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:23,  8.86it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:23,  8.87it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:23,  8.89it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:23,  8.86it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:23,  8.80it/s]predicting train subjects:  17%|█▋        | 41/247 [00:04<00:23,  8.80it/s]predicting train subjects:  17%|█▋        | 42/247 [00:04<00:23,  8.64it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:23,  8.50it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:23,  8.53it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:23,  8.63it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:23,  8.70it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:22,  8.79it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:22,  8.80it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:22,  8.79it/s]predicting train subjects:  20%|██        | 50/247 [00:05<00:22,  8.83it/s]predicting train subjects:  21%|██        | 51/247 [00:05<00:22,  8.79it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:22,  8.78it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:22,  8.70it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:22,  8.75it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:21,  8.75it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:21,  8.68it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:21,  8.65it/s]predicting train subjects:  23%|██▎       | 58/247 [00:06<00:21,  8.60it/s]predicting train subjects:  24%|██▍       | 59/247 [00:06<00:22,  8.49it/s]predicting train subjects:  24%|██▍       | 60/247 [00:07<00:22,  8.43it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:22,  8.42it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:22,  8.19it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:22,  8.09it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:22,  8.12it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:22,  8.12it/s]predicting train subjects:  27%|██▋       | 66/247 [00:07<00:22,  8.17it/s]predicting train subjects:  27%|██▋       | 67/247 [00:07<00:22,  8.07it/s]predicting train subjects:  28%|██▊       | 68/247 [00:08<00:22,  8.14it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:22,  7.91it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:22,  7.93it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:22,  7.98it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:21,  8.06it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:21,  8.13it/s]predicting train subjects:  30%|██▉       | 74/247 [00:08<00:21,  8.18it/s]predicting train subjects:  30%|███       | 75/247 [00:08<00:20,  8.19it/s]predicting train subjects:  31%|███       | 76/247 [00:08<00:20,  8.22it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:21,  7.83it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:21,  7.71it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:24,  6.73it/s]predicting train subjects:  32%|███▏      | 80/247 [00:09<00:27,  6.09it/s]predicting train subjects:  33%|███▎      | 81/247 [00:09<00:27,  6.04it/s]predicting train subjects:  33%|███▎      | 82/247 [00:09<00:27,  6.11it/s]predicting train subjects:  34%|███▎      | 83/247 [00:10<00:25,  6.34it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:24,  6.53it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:24,  6.70it/s]predicting train subjects:  35%|███▍      | 86/247 [00:10<00:23,  6.82it/s]predicting train subjects:  35%|███▌      | 87/247 [00:10<00:23,  6.83it/s]predicting train subjects:  36%|███▌      | 88/247 [00:10<00:23,  6.81it/s]predicting train subjects:  36%|███▌      | 89/247 [00:10<00:22,  6.90it/s]predicting train subjects:  36%|███▋      | 90/247 [00:11<00:22,  6.88it/s]predicting train subjects:  37%|███▋      | 91/247 [00:11<00:22,  6.83it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:22,  6.90it/s]predicting train subjects:  38%|███▊      | 93/247 [00:11<00:22,  6.97it/s]predicting train subjects:  38%|███▊      | 94/247 [00:11<00:21,  6.99it/s]predicting train subjects:  38%|███▊      | 95/247 [00:11<00:21,  6.99it/s]predicting train subjects:  39%|███▉      | 96/247 [00:12<00:21,  6.94it/s]predicting train subjects:  39%|███▉      | 97/247 [00:12<00:21,  6.94it/s]predicting train subjects:  40%|███▉      | 98/247 [00:12<00:21,  6.94it/s]predicting train subjects:  40%|████      | 99/247 [00:12<00:21,  6.95it/s]predicting train subjects:  40%|████      | 100/247 [00:12<00:20,  7.05it/s]predicting train subjects:  41%|████      | 101/247 [00:12<00:20,  7.06it/s]predicting train subjects:  41%|████▏     | 102/247 [00:12<00:20,  7.13it/s]predicting train subjects:  42%|████▏     | 103/247 [00:12<00:20,  7.19it/s]predicting train subjects:  42%|████▏     | 104/247 [00:13<00:19,  7.25it/s]predicting train subjects:  43%|████▎     | 105/247 [00:13<00:19,  7.29it/s]predicting train subjects:  43%|████▎     | 106/247 [00:13<00:19,  7.32it/s]predicting train subjects:  43%|████▎     | 107/247 [00:13<00:20,  6.93it/s]predicting train subjects:  44%|████▎     | 108/247 [00:13<00:19,  7.03it/s]predicting train subjects:  44%|████▍     | 109/247 [00:13<00:19,  7.13it/s]predicting train subjects:  45%|████▍     | 110/247 [00:13<00:19,  7.20it/s]predicting train subjects:  45%|████▍     | 111/247 [00:14<00:18,  7.19it/s]predicting train subjects:  45%|████▌     | 112/247 [00:14<00:18,  7.17it/s]predicting train subjects:  46%|████▌     | 113/247 [00:14<00:18,  7.17it/s]predicting train subjects:  46%|████▌     | 114/247 [00:14<00:18,  7.20it/s]predicting train subjects:  47%|████▋     | 115/247 [00:14<00:18,  7.26it/s]predicting train subjects:  47%|████▋     | 116/247 [00:14<00:18,  7.27it/s]predicting train subjects:  47%|████▋     | 117/247 [00:14<00:17,  7.31it/s]predicting train subjects:  48%|████▊     | 118/247 [00:15<00:16,  7.68it/s]predicting train subjects:  48%|████▊     | 119/247 [00:15<00:16,  7.97it/s]predicting train subjects:  49%|████▊     | 120/247 [00:15<00:15,  8.14it/s]predicting train subjects:  49%|████▉     | 121/247 [00:15<00:15,  8.40it/s]predicting train subjects:  49%|████▉     | 122/247 [00:15<00:14,  8.57it/s]predicting train subjects:  50%|████▉     | 123/247 [00:15<00:14,  8.58it/s]predicting train subjects:  50%|█████     | 124/247 [00:15<00:14,  8.61it/s]predicting train subjects:  51%|█████     | 125/247 [00:15<00:14,  8.67it/s]predicting train subjects:  51%|█████     | 126/247 [00:15<00:13,  8.77it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:16<00:13,  8.79it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:16<00:13,  8.85it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:16<00:13,  8.86it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:16<00:13,  8.85it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:16<00:13,  8.84it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:16<00:13,  8.79it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:16<00:12,  8.81it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:16<00:12,  8.85it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:16<00:13,  8.50it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:17<00:13,  8.46it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:17<00:12,  8.51it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:17<00:12,  8.50it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:17<00:12,  8.45it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:17<00:12,  8.55it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:17<00:12,  8.64it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:17<00:12,  8.68it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:17<00:11,  8.71it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:18<00:11,  8.76it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:18<00:11,  8.77it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:18<00:11,  8.46it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:18<00:11,  8.54it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:18<00:11,  8.60it/s]predicting train subjects:  60%|██████    | 149/247 [00:18<00:11,  8.68it/s]predicting train subjects:  61%|██████    | 150/247 [00:18<00:11,  8.69it/s]predicting train subjects:  61%|██████    | 151/247 [00:18<00:10,  8.73it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:18<00:10,  8.79it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:19<00:10,  8.82it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:19<00:11,  8.33it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:19<00:11,  8.04it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:19<00:11,  7.86it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:19<00:11,  7.71it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:19<00:11,  7.57it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:19<00:11,  7.40it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:20<00:11,  7.35it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:20<00:11,  7.34it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:20<00:11,  7.32it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:20<00:11,  7.32it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:20<00:11,  7.32it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:20<00:11,  7.31it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:20<00:11,  7.30it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:20<00:10,  7.30it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:21<00:10,  7.30it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:21<00:10,  7.28it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:21<00:10,  7.32it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:21<00:10,  7.37it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:21<00:09,  7.67it/s]predicting train subjects:  70%|███████   | 173/247 [00:21<00:11,  6.66it/s]predicting train subjects:  70%|███████   | 174/247 [00:21<00:10,  7.19it/s]predicting train subjects:  71%|███████   | 175/247 [00:22<00:10,  6.82it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:22<00:09,  7.28it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:22<00:09,  7.65it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:22<00:08,  7.89it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:22<00:08,  8.10it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:22<00:08,  8.25it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:22<00:07,  8.35it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:22<00:07,  8.42it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:23<00:07,  8.44it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:23<00:07,  8.42it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:23<00:07,  8.44it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:23<00:07,  8.40it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:23<00:07,  8.35it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:23<00:07,  8.05it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:23<00:07,  8.09it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:23<00:06,  8.23it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:24<00:06,  8.29it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:24<00:06,  8.31it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:24<00:06,  8.31it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:24<00:06,  8.55it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:24<00:05,  8.75it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:24<00:05,  8.89it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:24<00:05,  8.92it/s]predicting train subjects:  80%|████████  | 198/247 [00:24<00:05,  8.99it/s]predicting train subjects:  81%|████████  | 199/247 [00:24<00:05,  9.00it/s]predicting train subjects:  81%|████████  | 200/247 [00:25<00:05,  9.03it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:25<00:05,  9.04it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:25<00:05,  8.99it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:25<00:04,  9.02it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:25<00:04,  9.06it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:25<00:04,  9.13it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:25<00:04,  9.17it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:25<00:04,  9.18it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:25<00:04,  9.19it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:26<00:04,  9.16it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:26<00:04,  9.15it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:26<00:03,  9.12it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:26<00:03,  8.99it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:26<00:03,  8.90it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:26<00:03,  8.83it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:26<00:03,  8.78it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:26<00:03,  8.74it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:26<00:03,  8.77it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:27<00:03,  8.79it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:27<00:03,  8.76it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:27<00:03,  8.71it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:27<00:02,  8.74it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:27<00:02,  8.70it/s]predicting train subjects:  90%|█████████ | 223/247 [00:27<00:02,  8.63it/s]predicting train subjects:  91%|█████████ | 224/247 [00:27<00:02,  8.59it/s]predicting train subjects:  91%|█████████ | 225/247 [00:27<00:02,  8.55it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:27<00:02,  8.61it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:28<00:02,  8.66it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:28<00:02,  8.68it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:28<00:02,  8.64it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:28<00:02,  8.17it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:28<00:02,  7.83it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:28<00:01,  7.73it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:28<00:01,  7.67it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:28<00:01,  7.65it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:29<00:01,  7.61it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:29<00:01,  7.60it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:29<00:01,  7.56it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:29<00:01,  7.53it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:29<00:01,  7.53it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:29<00:00,  7.53it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:29<00:00,  7.56it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:30<00:00,  7.50it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:30<00:00,  7.42it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:30<00:00,  7.37it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:30<00:00,  7.29it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:30<00:00,  7.26it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  7.32it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  8.04it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  8.16it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  7.79it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.74it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  8.20it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  8.27it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  8.07it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:30,  8.06it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:29,  8.25it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:29,  8.15it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:29,  8.15it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:29,  8.21it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:29,  8.28it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:29,  8.24it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:28,  8.29it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:28,  8.32it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:28,  8.26it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:28,  8.29it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:28,  8.31it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:28,  8.25it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:27,  8.24it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:27,  8.29it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:27,  8.33it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:27,  8.31it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:27,  8.37it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:26,  8.38it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:26,  8.51it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:02<00:25,  8.60it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:26,  8.41it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:26,  8.34it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:25,  8.48it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:25,  8.61it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:25,  8.59it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:25,  8.59it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:25,  8.57it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:24,  8.63it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:03<00:24,  8.61it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:24,  8.65it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:24,  8.69it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:24,  8.72it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:23,  8.76it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:23,  8.79it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:23,  8.80it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:23,  8.74it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:04<00:23,  8.67it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:04<00:23,  8.60it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:23,  8.63it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:23,  8.67it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:23,  8.68it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:23,  8.73it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:23,  8.53it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:23,  8.30it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:05<00:23,  8.42it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:05<00:23,  8.50it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:06<00:22,  8.64it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:22,  8.76it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:22,  8.78it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:21,  8.85it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:21,  8.90it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:21,  8.87it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:06<00:21,  8.86it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:06<00:21,  8.79it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:06<00:22,  8.51it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:22,  8.37it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:22,  8.28it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:22,  8.23it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:22,  8.17it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:22,  8.17it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:07<00:22,  8.15it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:07<00:22,  8.18it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:07<00:21,  8.22it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:08<00:21,  8.23it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:21,  8.23it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:21,  8.25it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:21,  8.19it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:21,  8.17it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:08<00:21,  8.19it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:08<00:21,  8.24it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:08<00:20,  8.27it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:09<00:20,  8.27it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:21,  7.77it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:22,  7.67it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:21,  8.00it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:20,  8.22it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:09<00:20,  7.96it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:09<00:21,  7.67it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:09<00:21,  7.50it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:10<00:22,  7.35it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:22,  7.25it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:22,  7.20it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:22,  7.12it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:10<00:22,  7.07it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:10<00:22,  7.01it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:10<00:22,  7.05it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:11<00:22,  7.04it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:11<00:22,  7.03it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:21,  7.01it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:22,  6.75it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:11<00:22,  6.79it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:11<00:21,  6.88it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:11<00:21,  6.96it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:12<00:21,  7.02it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:12<00:20,  7.06it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:12<00:20,  7.17it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:20,  7.22it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:12<00:20,  7.25it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:12<00:19,  7.24it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:12<00:19,  7.25it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:13<00:19,  7.29it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:13<00:19,  7.30it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:13<00:19,  7.32it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:18,  7.37it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:13<00:18,  7.38it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:13<00:18,  7.38it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:13<00:18,  7.38it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:13<00:18,  7.37it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:14<00:18,  7.35it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:14<00:18,  7.34it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:17,  7.34it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:17,  7.37it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:14<00:18,  7.15it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:14<00:16,  7.62it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:14<00:16,  7.99it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:15<00:16,  7.88it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:15<00:15,  8.17it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:15<00:14,  8.44it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:14,  8.55it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:14,  8.67it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:15<00:13,  8.75it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:15<00:13,  8.79it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:15<00:14,  8.34it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:15<00:14,  8.21it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:16<00:14,  8.35it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:13,  8.42it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:13,  8.55it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:13,  8.68it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:13,  8.74it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:16<00:12,  8.73it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:16<00:12,  8.84it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:16<00:12,  8.80it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:16<00:12,  8.70it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.75it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.77it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:12,  8.63it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:12,  8.68it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:17<00:12,  8.73it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:17<00:11,  8.69it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:17<00:11,  8.63it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:17<00:11,  8.64it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:18<00:11,  8.61it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:18<00:11,  8.67it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:11,  8.74it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:11,  8.79it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:10,  8.83it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:18<00:10,  8.83it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:18<00:10,  8.81it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:18<00:10,  8.77it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:18<00:11,  7.92it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:19<00:11,  7.76it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:19<00:11,  7.59it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:11,  7.52it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:11,  7.46it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:19<00:11,  7.43it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:19<00:11,  7.41it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:19<00:11,  7.36it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:20<00:11,  7.27it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:20<00:11,  7.30it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:20<00:11,  7.32it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:20<00:11,  7.32it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:20<00:11,  7.21it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:20<00:11,  7.22it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:20<00:10,  7.24it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:21<00:10,  7.26it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:21<00:10,  7.27it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:21<00:10,  7.32it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:21<00:09,  7.66it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:21<00:09,  8.05it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:21<00:08,  8.23it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:21<00:09,  8.00it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:21<00:08,  8.15it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:22<00:08,  8.26it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:22<00:08,  8.34it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:22<00:08,  8.43it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:22<00:07,  8.43it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:22<00:07,  8.47it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:22<00:07,  8.50it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:22<00:07,  8.54it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:22<00:07,  8.56it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:22<00:07,  8.60it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:23<00:07,  8.56it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:23<00:07,  8.47it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:23<00:06,  8.48it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:23<00:06,  8.49it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:23<00:06,  8.44it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:23<00:06,  8.41it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:23<00:06,  8.46it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:23<00:06,  8.39it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:24<00:06,  8.57it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:24<00:05,  8.71it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:24<00:05,  8.82it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:24<00:05,  8.94it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:24<00:05,  9.05it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:24<00:05,  9.08it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:24<00:05,  9.10it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:24<00:05,  9.15it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:24<00:04,  9.15it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:24<00:04,  9.14it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:25<00:04,  9.17it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:25<00:04,  9.16it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:25<00:04,  9.11it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:25<00:04,  9.04it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:25<00:04,  9.05it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:25<00:04,  8.64it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:25<00:04,  8.71it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:25<00:04,  8.81it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:26<00:04,  8.72it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:26<00:03,  8.68it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:26<00:03,  8.68it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:26<00:03,  8.66it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:26<00:03,  8.58it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:26<00:03,  8.53it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:26<00:03,  8.54it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:26<00:03,  8.56it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:26<00:03,  8.54it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:27<00:03,  8.54it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:27<00:02,  8.55it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:27<00:02,  8.59it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:27<00:02,  8.62it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:27<00:02,  8.64it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:27<00:02,  8.64it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:27<00:02,  8.66it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:27<00:02,  8.67it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:27<00:02,  8.64it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:28<00:02,  8.22it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:28<00:02,  7.99it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:28<00:01,  7.80it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:28<00:01,  7.67it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:28<00:01,  7.55it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:28<00:01,  7.49it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:28<00:01,  7.48it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:29<00:01,  7.34it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:29<00:01,  7.34it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:29<00:01,  7.35it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:29<00:00,  7.36it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:29<00:00,  7.37it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:29<00:00,  7.19it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:29<00:00,  7.25it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:30<00:00,  7.28it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:30<00:00,  7.34it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:30<00:00,  7.19it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  7.26it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:30<00:00,  8.11it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 77.27it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 83.38it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 83.07it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 83.67it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 84.93it/s]saving BB  train1-THALAMUS:  19%|█▊        | 46/247 [00:00<00:02, 86.70it/s]saving BB  train1-THALAMUS:  23%|██▎       | 56/247 [00:00<00:02, 88.32it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 85.51it/s]saving BB  train1-THALAMUS:  29%|██▉       | 72/247 [00:00<00:02, 83.76it/s]saving BB  train1-THALAMUS:  32%|███▏      | 80/247 [00:01<00:02, 57.48it/s]saving BB  train1-THALAMUS:  36%|███▌      | 88/247 [00:01<00:02, 60.78it/s]saving BB  train1-THALAMUS:  38%|███▊      | 95/247 [00:01<00:02, 62.89it/s]saving BB  train1-THALAMUS:  42%|████▏     | 103/247 [00:01<00:02, 65.50it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 68.90it/s]saving BB  train1-THALAMUS:  48%|████▊     | 119/247 [00:01<00:01, 71.53it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 128/247 [00:01<00:01, 73.85it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 75.87it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 146/247 [00:01<00:01, 79.41it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 155/247 [00:02<00:01, 81.32it/s]saving BB  train1-THALAMUS:  66%|██████▋   | 164/247 [00:02<00:01, 79.65it/s]saving BB  train1-THALAMUS:  70%|███████   | 173/247 [00:02<00:00, 77.85it/s]saving BB  train1-THALAMUS:  74%|███████▎  | 182/247 [00:02<00:00, 78.84it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 190/247 [00:02<00:00, 78.56it/s]saving BB  train1-THALAMUS:  81%|████████  | 199/247 [00:02<00:00, 79.51it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 208/247 [00:02<00:00, 81.51it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 217/247 [00:02<00:00, 83.21it/s]saving BB  train1-THALAMUS:  91%|█████████▏| 226/247 [00:02<00:00, 85.11it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 235/247 [00:03<00:00, 83.84it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 244/247 [00:03<00:00, 81.89it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 77.66it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 82.22it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 83.39it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 83.47it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 84.39it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 37/247 [00:00<00:02, 86.80it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▉        | 47/247 [00:00<00:02, 88.19it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 56/247 [00:00<00:02, 86.28it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 64/247 [00:00<00:02, 83.45it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 73/247 [00:00<00:02, 82.64it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 81/247 [00:00<00:02, 78.99it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 89/247 [00:01<00:02, 73.47it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 97/247 [00:01<00:02, 67.91it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 104/247 [00:01<00:02, 67.13it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 112/247 [00:01<00:01, 70.36it/s]saving BB  train1-THALAMUS Sagittal:  49%|████▊     | 120/247 [00:01<00:01, 72.36it/s]saving BB  train1-THALAMUS Sagittal:  52%|█████▏    | 128/247 [00:01<00:01, 74.16it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▌    | 137/247 [00:01<00:01, 76.82it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▉    | 146/247 [00:01<00:01, 80.30it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 155/247 [00:01<00:01, 82.93it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▋   | 164/247 [00:02<00:01, 81.54it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 173/247 [00:02<00:00, 76.87it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 182/247 [00:02<00:00, 78.72it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 190/247 [00:02<00:00, 79.07it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 199/247 [00:02<00:00, 80.19it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 208/247 [00:02<00:00, 81.92it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 217/247 [00:02<00:00, 83.97it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████▏| 226/247 [00:02<00:00, 82.11it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 235/247 [00:02<00:00, 81.81it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 244/247 [00:03<00:00, 79.34it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 79.30it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:16,  1.25it/s]Loading train:   1%|          | 2/247 [00:01<03:08,  1.30it/s]Loading train:   1%|          | 3/247 [00:02<03:04,  1.33it/s]Loading train:   2%|▏         | 4/247 [00:03<03:07,  1.29it/s]Loading train:   2%|▏         | 5/247 [00:03<02:47,  1.45it/s]Loading train:   2%|▏         | 6/247 [00:04<02:32,  1.58it/s]Loading train:   3%|▎         | 7/247 [00:04<02:23,  1.68it/s]Loading train:   3%|▎         | 8/247 [00:05<02:15,  1.76it/s]Loading train:   4%|▎         | 9/247 [00:05<02:10,  1.83it/s]Loading train:   4%|▍         | 10/247 [00:06<02:06,  1.87it/s]Loading train:   4%|▍         | 11/247 [00:06<02:03,  1.92it/s]Loading train:   5%|▍         | 12/247 [00:07<02:00,  1.95it/s]Loading train:   5%|▌         | 13/247 [00:07<01:57,  1.99it/s]Loading train:   6%|▌         | 14/247 [00:08<01:58,  1.97it/s]Loading train:   6%|▌         | 15/247 [00:08<01:56,  1.99it/s]Loading train:   6%|▋         | 16/247 [00:09<01:57,  1.97it/s]Loading train:   7%|▋         | 17/247 [00:09<01:57,  1.96it/s]Loading train:   7%|▋         | 18/247 [00:10<01:57,  1.94it/s]Loading train:   8%|▊         | 19/247 [00:10<01:58,  1.93it/s]Loading train:   8%|▊         | 20/247 [00:11<01:56,  1.95it/s]Loading train:   9%|▊         | 21/247 [00:11<01:54,  1.98it/s]Loading train:   9%|▉         | 22/247 [00:12<01:53,  1.98it/s]Loading train:   9%|▉         | 23/247 [00:12<01:55,  1.94it/s]Loading train:  10%|▉         | 24/247 [00:13<01:54,  1.94it/s]Loading train:  10%|█         | 25/247 [00:13<01:52,  1.97it/s]Loading train:  11%|█         | 26/247 [00:14<01:51,  1.98it/s]Loading train:  11%|█         | 27/247 [00:14<01:51,  1.97it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:50,  1.99it/s]Loading train:  12%|█▏        | 29/247 [00:15<01:49,  1.99it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:47,  2.01it/s]Loading train:  13%|█▎        | 31/247 [00:16<01:46,  2.03it/s]Loading train:  13%|█▎        | 32/247 [00:17<01:46,  2.02it/s]Loading train:  13%|█▎        | 33/247 [00:17<01:45,  2.02it/s]Loading train:  14%|█▍        | 34/247 [00:18<01:47,  1.98it/s]Loading train:  14%|█▍        | 35/247 [00:18<01:46,  2.00it/s]Loading train:  15%|█▍        | 36/247 [00:19<01:45,  2.00it/s]Loading train:  15%|█▍        | 37/247 [00:19<01:45,  2.00it/s]Loading train:  15%|█▌        | 38/247 [00:20<01:44,  2.00it/s]Loading train:  16%|█▌        | 39/247 [00:20<01:43,  2.00it/s]Loading train:  16%|█▌        | 40/247 [00:21<01:42,  2.02it/s]Loading train:  17%|█▋        | 41/247 [00:21<01:40,  2.04it/s]Loading train:  17%|█▋        | 42/247 [00:22<01:38,  2.08it/s]Loading train:  17%|█▋        | 43/247 [00:22<01:35,  2.13it/s]Loading train:  18%|█▊        | 44/247 [00:22<01:34,  2.15it/s]Loading train:  18%|█▊        | 45/247 [00:23<01:34,  2.15it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:33,  2.14it/s]Loading train:  19%|█▉        | 47/247 [00:24<01:33,  2.14it/s]Loading train:  19%|█▉        | 48/247 [00:24<01:32,  2.16it/s]Loading train:  20%|█▉        | 49/247 [00:25<01:32,  2.14it/s]Loading train:  20%|██        | 50/247 [00:25<01:34,  2.08it/s]Loading train:  21%|██        | 51/247 [00:26<01:34,  2.07it/s]Loading train:  21%|██        | 52/247 [00:26<01:32,  2.11it/s]Loading train:  21%|██▏       | 53/247 [00:27<01:31,  2.13it/s]Loading train:  22%|██▏       | 54/247 [00:27<01:30,  2.13it/s]Loading train:  22%|██▏       | 55/247 [00:28<01:30,  2.12it/s]Loading train:  23%|██▎       | 56/247 [00:28<01:30,  2.12it/s]Loading train:  23%|██▎       | 57/247 [00:29<01:28,  2.14it/s]Loading train:  23%|██▎       | 58/247 [00:29<01:28,  2.14it/s]Loading train:  24%|██▍       | 59/247 [00:30<01:31,  2.05it/s]Loading train:  24%|██▍       | 60/247 [00:30<01:34,  1.98it/s]Loading train:  25%|██▍       | 61/247 [00:31<01:34,  1.97it/s]Loading train:  25%|██▌       | 62/247 [00:31<01:35,  1.95it/s]Loading train:  26%|██▌       | 63/247 [00:32<01:35,  1.94it/s]Loading train:  26%|██▌       | 64/247 [00:32<01:35,  1.92it/s]Loading train:  26%|██▋       | 65/247 [00:33<01:35,  1.91it/s]Loading train:  27%|██▋       | 66/247 [00:33<01:34,  1.92it/s]Loading train:  27%|██▋       | 67/247 [00:34<01:33,  1.93it/s]Loading train:  28%|██▊       | 68/247 [00:34<01:35,  1.88it/s]Loading train:  28%|██▊       | 69/247 [00:35<01:32,  1.92it/s]Loading train:  28%|██▊       | 70/247 [00:35<01:31,  1.93it/s]Loading train:  29%|██▊       | 71/247 [00:36<01:33,  1.89it/s]Loading train:  29%|██▉       | 72/247 [00:36<01:32,  1.90it/s]Loading train:  30%|██▉       | 73/247 [00:37<01:31,  1.90it/s]Loading train:  30%|██▉       | 74/247 [00:37<01:31,  1.90it/s]Loading train:  30%|███       | 75/247 [00:38<01:29,  1.92it/s]Loading train:  31%|███       | 76/247 [00:38<01:28,  1.93it/s]Loading train:  31%|███       | 77/247 [00:39<01:51,  1.53it/s]Loading train:  32%|███▏      | 78/247 [00:40<02:03,  1.37it/s]Loading train:  32%|███▏      | 79/247 [00:41<02:04,  1.35it/s]Loading train:  32%|███▏      | 80/247 [00:42<02:02,  1.36it/s]Loading train:  33%|███▎      | 81/247 [00:43<02:10,  1.27it/s]Loading train:  33%|███▎      | 82/247 [00:43<02:02,  1.35it/s]Loading train:  34%|███▎      | 83/247 [00:44<01:55,  1.42it/s]Loading train:  34%|███▍      | 84/247 [00:45<01:53,  1.43it/s]Loading train:  34%|███▍      | 85/247 [00:45<01:47,  1.50it/s]Loading train:  35%|███▍      | 86/247 [00:46<01:43,  1.56it/s]Loading train:  35%|███▌      | 87/247 [00:46<01:41,  1.58it/s]Loading train:  36%|███▌      | 88/247 [00:47<01:38,  1.61it/s]Loading train:  36%|███▌      | 89/247 [00:48<01:38,  1.61it/s]Loading train:  36%|███▋      | 90/247 [00:48<01:37,  1.61it/s]Loading train:  37%|███▋      | 91/247 [00:49<01:36,  1.62it/s]Loading train:  37%|███▋      | 92/247 [00:50<01:34,  1.63it/s]Loading train:  38%|███▊      | 93/247 [00:50<01:33,  1.65it/s]Loading train:  38%|███▊      | 94/247 [00:51<01:33,  1.64it/s]Loading train:  38%|███▊      | 95/247 [00:51<01:34,  1.60it/s]Loading train:  39%|███▉      | 96/247 [00:52<01:32,  1.63it/s]Loading train:  39%|███▉      | 97/247 [00:53<01:32,  1.61it/s]Loading train:  40%|███▉      | 98/247 [00:53<01:33,  1.59it/s]Loading train:  40%|████      | 99/247 [00:54<01:33,  1.58it/s]Loading train:  40%|████      | 100/247 [00:55<01:30,  1.62it/s]Loading train:  41%|████      | 101/247 [00:55<01:28,  1.65it/s]Loading train:  41%|████▏     | 102/247 [00:56<01:26,  1.69it/s]Loading train:  42%|████▏     | 103/247 [00:56<01:25,  1.69it/s]Loading train:  42%|████▏     | 104/247 [00:57<01:23,  1.71it/s]Loading train:  43%|████▎     | 105/247 [00:57<01:23,  1.71it/s]Loading train:  43%|████▎     | 106/247 [00:58<01:23,  1.70it/s]Loading train:  43%|████▎     | 107/247 [00:59<01:23,  1.68it/s]Loading train:  44%|████▎     | 108/247 [00:59<01:22,  1.68it/s]Loading train:  44%|████▍     | 109/247 [01:00<01:21,  1.69it/s]Loading train:  45%|████▍     | 110/247 [01:00<01:20,  1.71it/s]Loading train:  45%|████▍     | 111/247 [01:01<01:19,  1.72it/s]Loading train:  45%|████▌     | 112/247 [01:01<01:17,  1.74it/s]Loading train:  46%|████▌     | 113/247 [01:02<01:18,  1.71it/s]Loading train:  46%|████▌     | 114/247 [01:03<01:16,  1.73it/s]Loading train:  47%|████▋     | 115/247 [01:03<01:16,  1.71it/s]Loading train:  47%|████▋     | 116/247 [01:04<01:17,  1.69it/s]Loading train:  47%|████▋     | 117/247 [01:04<01:16,  1.71it/s]Loading train:  48%|████▊     | 118/247 [01:05<01:12,  1.79it/s]Loading train:  48%|████▊     | 119/247 [01:05<01:09,  1.84it/s]Loading train:  49%|████▊     | 120/247 [01:06<01:07,  1.87it/s]Loading train:  49%|████▉     | 121/247 [01:06<01:05,  1.92it/s]Loading train:  49%|████▉     | 122/247 [01:07<01:04,  1.95it/s]Loading train:  50%|████▉     | 123/247 [01:07<01:03,  1.95it/s]Loading train:  50%|█████     | 124/247 [01:08<01:02,  1.97it/s]Loading train:  51%|█████     | 125/247 [01:08<01:03,  1.93it/s]Loading train:  51%|█████     | 126/247 [01:09<01:02,  1.95it/s]Loading train:  51%|█████▏    | 127/247 [01:09<01:01,  1.95it/s]Loading train:  52%|█████▏    | 128/247 [01:10<01:01,  1.95it/s]Loading train:  52%|█████▏    | 129/247 [01:11<01:00,  1.97it/s]Loading train:  53%|█████▎    | 130/247 [01:11<00:58,  1.99it/s]Loading train:  53%|█████▎    | 131/247 [01:12<00:58,  1.99it/s]Loading train:  53%|█████▎    | 132/247 [01:12<00:58,  1.96it/s]Loading train:  54%|█████▍    | 133/247 [01:13<00:57,  1.97it/s]Loading train:  54%|█████▍    | 134/247 [01:13<00:56,  1.98it/s]Loading train:  55%|█████▍    | 135/247 [01:14<00:55,  2.00it/s]Loading train:  55%|█████▌    | 136/247 [01:14<00:55,  1.99it/s]Loading train:  55%|█████▌    | 137/247 [01:14<00:54,  2.02it/s]Loading train:  56%|█████▌    | 138/247 [01:15<00:53,  2.04it/s]Loading train:  56%|█████▋    | 139/247 [01:15<00:52,  2.06it/s]Loading train:  57%|█████▋    | 140/247 [01:16<00:51,  2.09it/s]Loading train:  57%|█████▋    | 141/247 [01:16<00:50,  2.09it/s]Loading train:  57%|█████▋    | 142/247 [01:17<00:49,  2.10it/s]Loading train:  58%|█████▊    | 143/247 [01:17<00:49,  2.11it/s]Loading train:  58%|█████▊    | 144/247 [01:18<00:48,  2.12it/s]Loading train:  59%|█████▊    | 145/247 [01:18<00:48,  2.10it/s]Loading train:  59%|█████▉    | 146/247 [01:19<00:47,  2.11it/s]Loading train:  60%|█████▉    | 147/247 [01:19<00:47,  2.12it/s]Loading train:  60%|█████▉    | 148/247 [01:20<00:47,  2.09it/s]Loading train:  60%|██████    | 149/247 [01:20<00:46,  2.09it/s]Loading train:  61%|██████    | 150/247 [01:21<00:47,  2.04it/s]Loading train:  61%|██████    | 151/247 [01:21<00:47,  2.04it/s]Loading train:  62%|██████▏   | 152/247 [01:22<00:47,  2.00it/s]Loading train:  62%|██████▏   | 153/247 [01:22<00:46,  2.03it/s]Loading train:  62%|██████▏   | 154/247 [01:28<03:00,  1.95s/it]Loading train:  63%|██████▎   | 155/247 [01:35<05:18,  3.46s/it]Loading train:  63%|██████▎   | 156/247 [01:40<06:10,  4.08s/it]Loading train:  64%|██████▎   | 157/247 [01:47<07:13,  4.82s/it]Loading train:  64%|██████▍   | 158/247 [01:52<07:27,  5.03s/it]Loading train:  64%|██████▍   | 159/247 [01:59<08:05,  5.51s/it]Loading train:  65%|██████▍   | 160/247 [02:06<08:33,  5.90s/it]Loading train:  65%|██████▌   | 161/247 [02:12<08:53,  6.21s/it]Loading train:  66%|██████▌   | 162/247 [02:19<08:58,  6.34s/it]Loading train:  66%|██████▌   | 163/247 [02:26<08:59,  6.43s/it]Loading train:  66%|██████▋   | 164/247 [02:33<09:03,  6.55s/it]Loading train:  67%|██████▋   | 165/247 [02:39<09:01,  6.61s/it]Loading train:  67%|██████▋   | 166/247 [02:46<09:00,  6.67s/it]Loading train:  68%|██████▊   | 167/247 [02:52<08:34,  6.43s/it]Loading train:  68%|██████▊   | 168/247 [02:59<08:36,  6.53s/it]Loading train:  68%|██████▊   | 169/247 [03:05<08:15,  6.35s/it]Loading train:  69%|██████▉   | 170/247 [03:11<08:16,  6.45s/it]Loading train:  69%|██████▉   | 171/247 [03:19<08:25,  6.65s/it]Loading train:  70%|██████▉   | 172/247 [03:28<09:17,  7.44s/it]Loading train:  70%|███████   | 173/247 [03:35<08:54,  7.22s/it]Loading train:  70%|███████   | 174/247 [03:41<08:41,  7.15s/it]Loading train:  71%|███████   | 175/247 [03:57<11:25,  9.52s/it]Loading train:  71%|███████▏  | 176/247 [04:00<09:16,  7.84s/it]Loading train:  72%|███████▏  | 177/247 [04:04<07:42,  6.60s/it]Loading train:  72%|███████▏  | 178/247 [04:09<06:54,  6.01s/it]Loading train:  72%|███████▏  | 179/247 [04:13<06:08,  5.42s/it]Loading train:  73%|███████▎  | 180/247 [04:17<05:36,  5.03s/it]Loading train:  73%|███████▎  | 181/247 [04:21<05:16,  4.79s/it]Loading train:  74%|███████▎  | 182/247 [04:26<05:09,  4.76s/it]Loading train:  74%|███████▍  | 183/247 [04:30<04:56,  4.64s/it]Loading train:  74%|███████▍  | 184/247 [04:35<04:53,  4.65s/it]Loading train:  75%|███████▍  | 185/247 [04:39<04:43,  4.57s/it]Loading train:  75%|███████▌  | 186/247 [04:44<04:36,  4.53s/it]Loading train:  76%|███████▌  | 187/247 [04:48<04:30,  4.51s/it]Loading train:  76%|███████▌  | 188/247 [04:53<04:22,  4.45s/it]Loading train:  77%|███████▋  | 189/247 [04:57<04:12,  4.36s/it]Loading train:  77%|███████▋  | 190/247 [05:01<04:11,  4.41s/it]Loading train:  77%|███████▋  | 191/247 [05:06<04:06,  4.41s/it]Loading train:  78%|███████▊  | 192/247 [05:10<03:59,  4.36s/it]Loading train:  78%|███████▊  | 193/247 [05:14<03:45,  4.18s/it]Loading train:  79%|███████▊  | 194/247 [05:14<02:42,  3.07s/it]Loading train:  79%|███████▉  | 195/247 [05:15<02:04,  2.39s/it]Loading train:  79%|███████▉  | 196/247 [05:16<01:42,  2.01s/it]Loading train:  80%|███████▉  | 197/247 [05:17<01:26,  1.73s/it]Loading train:  80%|████████  | 198/247 [05:18<01:18,  1.60s/it]Loading train:  81%|████████  | 199/247 [05:19<01:09,  1.45s/it]Loading train:  81%|████████  | 200/247 [05:21<01:03,  1.35s/it]Loading train:  81%|████████▏ | 201/247 [05:22<01:00,  1.31s/it]Loading train:  82%|████████▏ | 202/247 [05:23<00:56,  1.25s/it]Loading train:  82%|████████▏ | 203/247 [05:24<00:54,  1.25s/it]Loading train:  83%|████████▎ | 204/247 [05:25<00:47,  1.09s/it]Loading train:  83%|████████▎ | 205/247 [05:26<00:41,  1.01it/s]Loading train:  83%|████████▎ | 206/247 [05:27<00:43,  1.06s/it]Loading train:  84%|████████▍ | 207/247 [05:28<00:42,  1.05s/it]Loading train:  84%|████████▍ | 208/247 [05:29<00:42,  1.08s/it]Loading train:  85%|████████▍ | 209/247 [05:30<00:41,  1.10s/it]Loading train:  85%|████████▌ | 210/247 [05:31<00:40,  1.09s/it]Loading train:  85%|████████▌ | 211/247 [05:32<00:39,  1.10s/it]Loading train:  86%|████████▌ | 212/247 [05:36<01:00,  1.72s/it]Loading train:  86%|████████▌ | 213/247 [05:39<01:19,  2.33s/it]Loading train:  87%|████████▋ | 214/247 [05:43<01:29,  2.73s/it]Loading train:  87%|████████▋ | 215/247 [05:47<01:39,  3.11s/it]Loading train:  87%|████████▋ | 216/247 [05:51<01:42,  3.31s/it]Loading train:  88%|████████▊ | 217/247 [05:55<01:46,  3.53s/it]Loading train:  88%|████████▊ | 218/247 [05:59<01:47,  3.70s/it]Loading train:  89%|████████▊ | 219/247 [06:03<01:44,  3.73s/it]Loading train:  89%|████████▉ | 220/247 [06:07<01:42,  3.78s/it]Loading train:  89%|████████▉ | 221/247 [06:10<01:38,  3.79s/it]Loading train:  90%|████████▉ | 222/247 [06:14<01:36,  3.86s/it]Loading train:  90%|█████████ | 223/247 [06:18<01:32,  3.84s/it]Loading train:  91%|█████████ | 224/247 [06:22<01:28,  3.86s/it]Loading train:  91%|█████████ | 225/247 [06:25<01:21,  3.69s/it]Loading train:  91%|█████████▏| 226/247 [06:29<01:15,  3.60s/it]Loading train:  92%|█████████▏| 227/247 [06:33<01:15,  3.75s/it]Loading train:  92%|█████████▏| 228/247 [06:36<01:09,  3.66s/it]Loading train:  93%|█████████▎| 229/247 [06:40<01:04,  3.56s/it]Loading train:  93%|█████████▎| 230/247 [06:45<01:10,  4.16s/it]Loading train:  94%|█████████▎| 231/247 [06:51<01:13,  4.62s/it]Loading train:  94%|█████████▍| 232/247 [06:57<01:14,  4.96s/it]Loading train:  94%|█████████▍| 233/247 [07:02<01:10,  5.05s/it]Loading train:  95%|█████████▍| 234/247 [07:08<01:07,  5.21s/it]Loading train:  95%|█████████▌| 235/247 [07:13<01:02,  5.21s/it]Loading train:  96%|█████████▌| 236/247 [07:18<00:58,  5.34s/it]Loading train:  96%|█████████▌| 237/247 [07:24<00:52,  5.29s/it]Loading train:  96%|█████████▋| 238/247 [07:29<00:48,  5.40s/it]Loading train:  97%|█████████▋| 239/247 [07:35<00:43,  5.47s/it]Loading train:  97%|█████████▋| 240/247 [07:40<00:36,  5.24s/it]Loading train:  98%|█████████▊| 241/247 [07:45<00:32,  5.36s/it]Loading train:  98%|█████████▊| 242/247 [07:50<00:25,  5.18s/it]Loading train:  98%|█████████▊| 243/247 [07:56<00:21,  5.36s/it]Loading train:  99%|█████████▉| 244/247 [08:01<00:16,  5.38s/it]Loading train:  99%|█████████▉| 245/247 [08:07<00:10,  5.41s/it]Loading train: 100%|█████████▉| 246/247 [08:12<00:05,  5.42s/it]Loading train: 100%|██████████| 247/247 [08:18<00:00,  5.57s/it]Loading train: 100%|██████████| 247/247 [08:18<00:00,  2.02s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/247 [00:00<00:03, 64.08it/s]concatenating: train:   6%|▌         | 14/247 [00:00<00:03, 64.08it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:03, 63.81it/s]concatenating: train:  11%|█▏        | 28/247 [00:00<00:03, 63.51it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:03, 63.44it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:03, 61.08it/s]concatenating: train:  19%|█▉        | 48/247 [00:00<00:03, 62.22it/s]concatenating: train:  22%|██▏       | 55/247 [00:00<00:03, 63.95it/s]concatenating: train:  25%|██▌       | 62/247 [00:00<00:02, 64.68it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:02, 65.90it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:02, 66.21it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:02, 64.70it/s]concatenating: train:  36%|███▋      | 90/247 [00:01<00:02, 63.22it/s]concatenating: train:  39%|███▉      | 97/247 [00:01<00:02, 62.65it/s]concatenating: train:  42%|████▏     | 104/247 [00:01<00:02, 60.24it/s]concatenating: train:  45%|████▍     | 111/247 [00:01<00:02, 57.79it/s]concatenating: train:  47%|████▋     | 117/247 [00:01<00:02, 58.12it/s]concatenating: train:  50%|████▉     | 123/247 [00:01<00:02, 57.63it/s]concatenating: train:  53%|█████▎    | 130/247 [00:02<00:01, 59.90it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:01, 59.02it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:01, 59.11it/s]concatenating: train:  61%|██████    | 151/247 [00:02<00:01, 61.55it/s]concatenating: train:  64%|██████▍   | 158/247 [00:02<00:01, 58.81it/s]concatenating: train:  67%|██████▋   | 165/247 [00:02<00:01, 57.59it/s]concatenating: train:  70%|██████▉   | 172/247 [00:02<00:01, 58.47it/s]concatenating: train:  72%|███████▏  | 179/247 [00:02<00:01, 59.75it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 59.79it/s]concatenating: train:  78%|███████▊  | 193/247 [00:03<00:00, 59.83it/s]concatenating: train:  81%|████████  | 200/247 [00:03<00:00, 61.91it/s]concatenating: train:  84%|████████▍ | 207/247 [00:03<00:00, 62.07it/s]concatenating: train:  87%|████████▋ | 214/247 [00:03<00:00, 61.36it/s]concatenating: train:  89%|████████▉ | 221/247 [00:03<00:00, 63.30it/s]concatenating: train:  92%|█████████▏| 228/247 [00:03<00:00, 64.32it/s]concatenating: train:  95%|█████████▌| 235/247 [00:03<00:00, 62.90it/s]concatenating: train:  98%|█████████▊| 242/247 [00:03<00:00, 62.14it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 61.58it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:11<00:47, 11.81s/it]Loading test:  40%|████      | 2/5 [00:26<00:38, 12.68s/it]Loading test:  60%|██████    | 3/5 [00:32<00:21, 10.67s/it]Loading test:  80%|████████  | 4/5 [00:36<00:08,  8.62s/it]Loading test: 100%|██████████| 5/5 [00:45<00:00,  8.77s/it]Loading test: 100%|██████████| 5/5 [00:45<00:00,  9.09s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 65.06it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-22 03:53:43.143000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 03:53:43.143098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 03:53:43.143111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 03:53:43.143118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 03:53:43.146102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.52384806e-02 3.19420305e-02 7.70779312e-02 9.60982025e-03
 2.75137198e-02 7.04670330e-03 8.86713794e-02 1.14423808e-01
 8.19908326e-02 1.27582449e-02 2.89595206e-01 1.93887506e-01
 2.44336333e-04]
Train on 9165 samples, validate on 183 samples
Epoch 1/300
 - 25s - loss: 0.6124 - acc: 0.9083 - mDice: 0.3403 - val_loss: 0.1804 - val_acc: 0.9354 - val_mDice: 0.2150

Epoch 00001: val_mDice improved from -inf to 0.21496, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.5031 - acc: 0.9255 - mDice: 0.4580 - val_loss: 0.1786 - val_acc: 0.9357 - val_mDice: 0.2886

Epoch 00002: val_mDice improved from 0.21496 to 0.28858, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 0.4596 - acc: 0.9309 - mDice: 0.5050 - val_loss: 0.1662 - val_acc: 0.9405 - val_mDice: 0.2947

Epoch 00003: val_mDice improved from 0.28858 to 0.29472, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.4443 - acc: 0.9336 - mDice: 0.5214 - val_loss: 0.1845 - val_acc: 0.9350 - val_mDice: 0.2232

Epoch 00004: val_mDice did not improve from 0.29472
Epoch 5/300
 - 20s - loss: 0.4295 - acc: 0.9354 - mDice: 0.5374 - val_loss: 0.1920 - val_acc: 0.9434 - val_mDice: 0.3100

Epoch 00005: val_mDice improved from 0.29472 to 0.30996, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 19s - loss: 0.4427 - acc: 0.9333 - mDice: 0.5229 - val_loss: 0.1245 - val_acc: 0.9446 - val_mDice: 0.3002

Epoch 00006: val_mDice did not improve from 0.30996
Epoch 7/300
 - 18s - loss: 0.4346 - acc: 0.9338 - mDice: 0.5309 - val_loss: 0.1416 - val_acc: 0.9417 - val_mDice: 0.3116

Epoch 00007: val_mDice improved from 0.30996 to 0.31160, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 19s - loss: 0.4281 - acc: 0.9365 - mDice: 0.5361 - val_loss: 0.1257 - val_acc: 0.9451 - val_mDice: 0.2955

Epoch 00008: val_mDice did not improve from 0.31160
Epoch 9/300
 - 18s - loss: 0.4264 - acc: 0.9360 - mDice: 0.5375 - val_loss: 0.1986 - val_acc: 0.9420 - val_mDice: 0.3177

Epoch 00009: val_mDice improved from 0.31160 to 0.31765, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 10/300
 - 18s - loss: 0.4352 - acc: 0.9345 - mDice: 0.5242 - val_loss: 0.1639 - val_acc: 0.9446 - val_mDice: 0.3110

Epoch 00010: val_mDice did not improve from 0.31765
Epoch 11/300
 - 19s - loss: 0.4183 - acc: 0.9360 - mDice: 0.5393 - val_loss: 0.1127 - val_acc: 0.9452 - val_mDice: 0.3029

Epoch 00011: val_mDice did not improve from 0.31765
Epoch 12/300
 - 18s - loss: 0.4033 - acc: 0.9380 - mDice: 0.5520 - val_loss: 0.0489 - val_acc: 0.9495 - val_mDice: 0.3051

Epoch 00012: val_mDice did not improve from 0.31765
Epoch 13/300
 - 18s - loss: 0.3964 - acc: 0.9387 - mDice: 0.5601 - val_loss: 0.0799 - val_acc: 0.9491 - val_mDice: 0.3174

Epoch 00013: val_mDice did not improve from 0.31765
Epoch 14/300
 - 19s - loss: 0.3932 - acc: 0.9394 - mDice: 0.5610 - val_loss: 0.1858 - val_acc: 0.9409 - val_mDice: 0.3148

Epoch 00014: val_mDice did not improve from 0.31765
Epoch 15/300
 - 19s - loss: 0.4053 - acc: 0.9368 - mDice: 0.5478 - val_loss: 0.1748 - val_acc: 0.9418 - val_mDice: 0.2846

Epoch 00015: val_mDice did not improve from 0.31765
Epoch 16/300
 - 18s - loss: 0.4013 - acc: 0.9374 - mDice: 0.5522 - val_loss: 0.0253 - val_acc: 0.9480 - val_mDice: 0.2956

Epoch 00016: val_mDice did not improve from 0.31765
Epoch 17/300
 - 19s - loss: 0.4071 - acc: 0.9380 - mDice: 0.5476 - val_loss: 0.1556 - val_acc: 0.9430 - val_mDice: 0.3172

Epoch 00017: val_mDice did not improve from 0.31765
Epoch 18/300
 - 19s - loss: 0.3888 - acc: 0.9397 - mDice: 0.5650 - val_loss: 0.0504 - val_acc: 0.9464 - val_mDice: 0.2763

Epoch 00018: val_mDice did not improve from 0.31765
Epoch 19/300
 - 20s - loss: 0.3916 - acc: 0.9388 - mDice: 0.5637 - val_loss: 0.0785 - val_acc: 0.9489 - val_mDice: 0.3098

Epoch 00019: val_mDice did not improve from 0.31765
Epoch 20/300
 - 19s - loss: 0.3726 - acc: 0.9420 - mDice: 0.5824 - val_loss: 0.1767 - val_acc: 0.9447 - val_mDice: 0.3192

Epoch 00020: val_mDice improved from 0.31765 to 0.31919, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 21/300
 - 19s - loss: 0.3847 - acc: 0.9398 - mDice: 0.5691 - val_loss: 0.0592 - val_acc: 0.9502 - val_mDice: 0.3000

Epoch 00021: val_mDice did not improve from 0.31919
Epoch 22/300
 - 20s - loss: 0.3917 - acc: 0.9380 - mDice: 0.5606 - val_loss: 0.0689 - val_acc: 0.9471 - val_mDice: 0.2973

Epoch 00022: val_mDice did not improve from 0.31919
Epoch 23/300
 - 20s - loss: 0.3749 - acc: 0.9420 - mDice: 0.5811 - val_loss: 0.1011 - val_acc: 0.9481 - val_mDice: 0.3188

Epoch 00023: val_mDice did not improve from 0.31919
Epoch 24/300
 - 21s - loss: 0.3669 - acc: 0.9430 - mDice: 0.5869 - val_loss: 0.0498 - val_acc: 0.9467 - val_mDice: 0.2833

Epoch 00024: val_mDice did not improve from 0.31919
Epoch 25/300
 - 19s - loss: 0.3664 - acc: 0.9433 - mDice: 0.5875 - val_loss: 0.0112 - val_acc: 0.9483 - val_mDice: 0.2887

Epoch 00025: val_mDice did not improve from 0.31919
Epoch 26/300
 - 20s - loss: 0.3759 - acc: 0.9418 - mDice: 0.5779 - val_loss: 0.1605 - val_acc: 0.9464 - val_mDice: 0.3145

Epoch 00026: val_mDice did not improve from 0.31919
Epoch 27/300
 - 20s - loss: 0.3883 - acc: 0.9403 - mDice: 0.5642 - val_loss: 0.0359 - val_acc: 0.9503 - val_mDice: 0.3074

Epoch 00027: val_mDice did not improve from 0.31919
Epoch 28/300
 - 21s - loss: 0.3766 - acc: 0.9413 - mDice: 0.5768 - val_loss: 0.1186 - val_acc: 0.9477 - val_mDice: 0.3291

Epoch 00028: val_mDice improved from 0.31919 to 0.32912, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 19s - loss: 0.3800 - acc: 0.9414 - mDice: 0.5722 - val_loss: 0.0776 - val_acc: 0.9510 - val_mDice: 0.3085

Epoch 00029: val_mDice did not improve from 0.32912
Epoch 30/300
 - 20s - loss: 0.3644 - acc: 0.9436 - mDice: 0.5896 - val_loss: 0.0877 - val_acc: 0.9514 - val_mDice: 0.3240

Epoch 00030: val_mDice did not improve from 0.32912
Epoch 31/300
 - 20s - loss: 0.3587 - acc: 0.9441 - mDice: 0.5940 - val_loss: 0.0341 - val_acc: 0.9514 - val_mDice: 0.3183

Epoch 00031: val_mDice did not improve from 0.32912
Epoch 32/300
 - 20s - loss: 0.3619 - acc: 0.9439 - mDice: 0.5911 - val_loss: 0.0669 - val_acc: 0.9510 - val_mDice: 0.3165

Epoch 00032: val_mDice did not improve from 0.32912
Epoch 33/300
 - 20s - loss: 0.3651 - acc: 0.9434 - mDice: 0.5894 - val_loss: 0.2362 - val_acc: 0.9373 - val_mDice: 0.2365

Epoch 00033: val_mDice did not improve from 0.32912
Epoch 34/300
 - 20s - loss: 0.3658 - acc: 0.9430 - mDice: 0.5887 - val_loss: 0.0428 - val_acc: 0.9494 - val_mDice: 0.3089

Epoch 00034: val_mDice did not improve from 0.32912
Epoch 35/300
 - 20s - loss: 0.3579 - acc: 0.9441 - mDice: 0.5955 - val_loss: 0.2312 - val_acc: 0.9417 - val_mDice: 0.3171

Epoch 00035: val_mDice did not improve from 0.32912
Epoch 36/300
 - 20s - loss: 0.3617 - acc: 0.9446 - mDice: 0.5975 - val_loss: 0.0645 - val_acc: 0.9509 - val_mDice: 0.3219

Epoch 00036: val_mDice did not improve from 0.32912
Epoch 37/300
 - 20s - loss: 0.3511 - acc: 0.9455 - mDice: 0.6081 - val_loss: 0.1032 - val_acc: 0.9474 - val_mDice: 0.3106

Epoch 00037: val_mDice did not improve from 0.32912
Epoch 38/300
 - 20s - loss: 0.3498 - acc: 0.9454 - mDice: 0.6055 - val_loss: 0.0717 - val_acc: 0.9516 - val_mDice: 0.3259

Epoch 00038: val_mDice did not improve from 0.32912
Epoch 39/300
 - 20s - loss: 0.3515 - acc: 0.9455 - mDice: 0.6044 - val_loss: 0.0431 - val_acc: 0.9526 - val_mDice: 0.3178

Epoch 00039: val_mDice did not improve from 0.32912
Epoch 40/300
 - 20s - loss: 0.3498 - acc: 0.9455 - mDice: 0.6062 - val_loss: 0.1285 - val_acc: 0.9476 - val_mDice: 0.3192

Epoch 00040: val_mDice did not improve from 0.32912
Epoch 41/300
 - 20s - loss: 0.3538 - acc: 0.9448 - mDice: 0.6023 - val_loss: 0.1469 - val_acc: 0.9492 - val_mDice: 0.3173

Epoch 00041: val_mDice did not improve from 0.32912
Epoch 42/300
 - 20s - loss: 0.3517 - acc: 0.9452 - mDice: 0.6032 - val_loss: 0.0595 - val_acc: 0.9505 - val_mDice: 0.3204

Epoch 00042: val_mDice did not improve from 0.32912
Epoch 43/300
 - 21s - loss: 0.3512 - acc: 0.9455 - mDice: 0.6083 - val_loss: 0.1020 - val_acc: 0.9493 - val_mDice: 0.3043

Epoch 00043: val_mDice did not improve from 0.32912

Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 44/300
 - 21s - loss: 0.3442 - acc: 0.9461 - mDice: 0.6129 - val_loss: 0.0562 - val_acc: 0.9495 - val_mDice: 0.2999

Epoch 00044: val_mDice did not improve from 0.32912
Epoch 45/300
 - 20s - loss: 0.3425 - acc: 0.9458 - mDice: 0.6141 - val_loss: 0.0413 - val_acc: 0.9511 - val_mDice: 0.3106

Epoch 00045: val_mDice did not improve from 0.32912
Epoch 46/300
 - 20s - loss: 0.3465 - acc: 0.9464 - mDice: 0.6112 - val_loss: 0.0675 - val_acc: 0.9522 - val_mDice: 0.3131

Epoch 00046: val_mDice did not improve from 0.32912
Epoch 47/300
 - 20s - loss: 0.3353 - acc: 0.9472 - mDice: 0.6197 - val_loss: 0.0424 - val_acc: 0.9510 - val_mDice: 0.3096

Epoch 00047: val_mDice did not improve from 0.32912
Epoch 48/300
 - 20s - loss: 0.3381 - acc: 0.9475 - mDice: 0.6207 - val_loss: 0.0357 - val_acc: 0.9527 - val_mDice: 0.3152

Epoch 00048: val_mDice did not improve from 0.32912
Epoch 49/300
 - 18s - loss: 0.3357 - acc: 0.9474 - mDice: 0.6218 - val_loss: 0.1539 - val_acc: 0.9494 - val_mDice: 0.3187

Epoch 00049: val_mDice did not improve from 0.32912
Epoch 50/300
 - 19s - loss: 0.3325 - acc: 0.9475 - mDice: 0.6251 - val_loss: 0.0319 - val_acc: 0.9521 - val_mDice: 0.3235

Epoch 00050: val_mDice did not improve from 0.32912
Epoch 51/300
 - 19s - loss: 0.3306 - acc: 0.9477 - mDice: 0.6245 - val_loss: 0.0766 - val_acc: 0.9504 - val_mDice: 0.3216

Epoch 00051: val_mDice did not improve from 0.32912
Epoch 52/300
 - 19s - loss: 0.3325 - acc: 0.9471 - mDice: 0.6237 - val_loss: 0.0242 - val_acc: 0.9522 - val_mDice: 0.3108

Epoch 00052: val_mDice did not improve from 0.32912
Epoch 53/300
 - 19s - loss: 0.3315 - acc: 0.9481 - mDice: 0.6256 - val_loss: 0.0106 - val_acc: 0.9511 - val_mDice: 0.3039

Epoch 00053: val_mDice did not improve from 0.32912
Epoch 54/300
 - 19s - loss: 0.3297 - acc: 0.9483 - mDice: 0.6287 - val_loss: 0.0326 - val_acc: 0.9505 - val_mDice: 0.3045

Epoch 00054: val_mDice did not improve from 0.32912
Epoch 55/300
 - 19s - loss: 0.3296 - acc: 0.9478 - mDice: 0.6278 - val_loss: 0.0187 - val_acc: 0.9512 - val_mDice: 0.2994

Epoch 00055: val_mDice did not improve from 0.32912
Epoch 56/300
 - 19s - loss: 0.3323 - acc: 0.9478 - mDice: 0.6234 - val_loss: 0.0410 - val_acc: 0.9520 - val_mDice: 0.3108

Epoch 00056: val_mDice did not improve from 0.32912
Epoch 57/300
 - 19s - loss: 0.3280 - acc: 0.9486 - mDice: 0.6302 - val_loss: 0.0384 - val_acc: 0.9513 - val_mDice: 0.3165

Epoch 00057: val_mDice did not improve from 0.32912
Epoch 58/300
 - 19s - loss: 0.3287 - acc: 0.9483 - mDice: 0.6267 - val_loss: 0.0320 - val_acc: 0.9508 - val_mDice: 0.3024

Epoch 00058: val_mDice did not improve from 0.32912

Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 59/300
 - 19s - loss: 0.3256 - acc: 0.9487 - mDice: 0.6321 - val_loss: 0.0126 - val_acc: 0.9508 - val_mDice: 0.3080

Epoch 00059: val_mDice did not improve from 0.32912
Epoch 60/300
 - 19s - loss: 0.3233 - acc: 0.9488 - mDice: 0.6348 - val_loss: 0.0091 - val_acc: 0.9520 - val_mDice: 0.3099

Epoch 00060: val_mDice did not improve from 0.32912
Epoch 61/300
 - 20s - loss: 0.3240 - acc: 0.9488 - mDice: 0.6333 - val_loss: 0.0240 - val_acc: 0.9522 - val_mDice: 0.3201

Epoch 00061: val_mDice did not improve from 0.32912
Epoch 62/300
 - 19s - loss: 0.3202 - acc: 0.9493 - mDice: 0.6355 - val_loss: 0.0143 - val_acc: 0.9528 - val_mDice: 0.3216

Epoch 00062: val_mDice did not improve from 0.32912
Epoch 63/300
 - 20s - loss: 0.3222 - acc: 0.9493 - mDice: 0.6363 - val_loss: 0.0077 - val_acc: 0.9523 - val_mDice: 0.3237

Epoch 00063: val_mDice did not improve from 0.32912
Epoch 64/300
 - 19s - loss: 0.3227 - acc: 0.9493 - mDice: 0.6369 - val_loss: 0.0349 - val_acc: 0.9520 - val_mDice: 0.3202

Epoch 00064: val_mDice did not improve from 0.32912
Epoch 65/300
 - 19s - loss: 0.3187 - acc: 0.9496 - mDice: 0.6375 - val_loss: 0.0583 - val_acc: 0.9516 - val_mDice: 0.3194

Epoch 00065: val_mDice did not improve from 0.32912
Epoch 66/300
 - 19s - loss: 0.3191 - acc: 0.9493 - mDice: 0.6393 - val_loss: 0.0317 - val_acc: 0.9518 - val_mDice: 0.3199

Epoch 00066: val_mDice did not improve from 0.32912
Epoch 67/300
 - 20s - loss: 0.3213 - acc: 0.9495 - mDice: 0.6394 - val_loss: 0.0131 - val_acc: 0.9527 - val_mDice: 0.3159

Epoch 00067: val_mDice did not improve from 0.32912
Epoch 68/300
 - 19s - loss: 0.3211 - acc: 0.9495 - mDice: 0.6373 - val_loss: 0.0149 - val_acc: 0.9521 - val_mDice: 0.3119

Epoch 00068: val_mDice did not improve from 0.32912
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
{'val_loss': [0.18043845671081477, 0.17860619822018298, 0.16617101146406976, 0.18453547281157123, 0.19198847505075683, 0.12447239407923459, 0.14158946023287017, 0.12569162678075294, 0.19863858687197739, 0.16392133593943897, 0.11269704630608604, 0.04893767198578256, 0.07989670853817561, 0.18576705038466088, 0.17482834437332762, 0.025267441629793476, 0.1555895308348162, 0.050407882189490105, 0.078494954436936, 0.17670612588850526, 0.05921512939890877, 0.06892657491996823, 0.10109717275723408, 0.0498100347369095, 0.01121561608373956, 0.1604633231448834, 0.035866048655223325, 0.11863428988885846, 0.0776208064135907, 0.08772227720388012, 0.03410318590792232, 0.06691941297282286, 0.23621258245465535, 0.04282463411673333, 0.2311941828436213, 0.06447670107982198, 0.10322249141302917, 0.07172925105633957, 0.04309511834582507, 0.12849606726766447, 0.14694539529826145, 0.05954692992152738, 0.10204702089006296, 0.056163590793279025, 0.041284466742492115, 0.06750087277159665, 0.0423711085376518, 0.03570740738160949, 0.15386516311908233, 0.031873252937478606, 0.0765705304881914, 0.02422025427222252, 0.010615043260686385, 0.03262905394811122, 0.01867262253670093, 0.041048203946137035, 0.03837711966591455, 0.031966611274767444, 0.012593881110024583, 0.009067311027988058, 0.024028565897479082, 0.014277369313227022, 0.007727961437624009, 0.03490854966673043, 0.05831068355203326, 0.031745240764051184, 0.013142136337815738, 0.014881334974954688], 'val_acc': [0.9354395651426471, 0.9356997778506878, 0.940531238832109, 0.9350217196459327, 0.9433560566823991, 0.9446083216067872, 0.941652152707668, 0.9450962318748725, 0.942014947940743, 0.944565791575635, 0.945188801145293, 0.9494848313227378, 0.949080748310506, 0.9409027861767127, 0.941807280472719, 0.9480311359212699, 0.9430495516849997, 0.9464260662188295, 0.9489456291407183, 0.9447034053463753, 0.9501804028703866, 0.9471341462734618, 0.9480524014254086, 0.9466650183083581, 0.948262567728595, 0.946363514238368, 0.9502654710754019, 0.9476583345991666, 0.9510010702362477, 0.9513763821190172, 0.9513563631010837, 0.9510298403885846, 0.937296075247676, 0.9494060124855875, 0.941715958014212, 0.9509172511231052, 0.9473781035246094, 0.9516491030083328, 0.9525998811252782, 0.9476220565415471, 0.949209602152715, 0.9504781384937099, 0.949294677523316, 0.9494585570741872, 0.9511236792705098, 0.9521970569761724, 0.9509973229606294, 0.9526749409613062, 0.9494085175092103, 0.9521057247464123, 0.9503680591374799, 0.9522370790523258, 0.9510548606596357, 0.9505319380369343, 0.9511924822473786, 0.9520031487355467, 0.9513275965315396, 0.9508246834812268, 0.9508059086695395, 0.9520394228846649, 0.9521770337240292, 0.9527875360895376, 0.9522520922572235, 0.951969363976046, 0.9516265841781116, 0.9517742030607547, 0.952734993780897, 0.9520531808092294], 'val_mDice': [0.21495719964977333, 0.2885762679853726, 0.2947216388143477, 0.22319367031256357, 0.3099560970491399, 0.3001861491652786, 0.3116002642636091, 0.29553806838767777, 0.3176521855951007, 0.3109646638234456, 0.30286068314574455, 0.30508942535666167, 0.31737124822178825, 0.31475301351540724, 0.2846154041710447, 0.2956343953767435, 0.31720371890426335, 0.2762667262733308, 0.30980296966319526, 0.31919290679074375, 0.30003518244770705, 0.29730994812126366, 0.31876473438218644, 0.28327041807396164, 0.28865099850980963, 0.3144522799494488, 0.307368750414236, 0.3291217454714202, 0.3084633367879143, 0.32400878205325434, 0.31834223532611555, 0.31652231143960535, 0.23647196187836225, 0.3089005219154671, 0.3170818186522833, 0.32190605900326713, 0.31063314572058087, 0.3259110912029209, 0.31777801189591975, 0.3191920999295073, 0.31734947432748606, 0.3204386211890992, 0.30433769776521485, 0.29993257215602803, 0.3105696459692684, 0.31309091523696814, 0.3095547843704132, 0.3151850527956512, 0.3186759727655864, 0.3235466863776817, 0.3216377681151765, 0.3108062052213755, 0.30391395360719964, 0.30448474502954326, 0.2993778071361161, 0.3108182273845855, 0.3164685731702815, 0.30243696158375244, 0.30800382650452235, 0.3098548299383596, 0.32014160981920897, 0.3215843192785164, 0.3237337600745139, 0.32020299698485705, 0.31943318341436283, 0.31985798722407854, 0.31591673620818744, 0.3118673816241853], 'loss': [0.6124034894501259, 0.5031126615816429, 0.4596275831920751, 0.44432017686779357, 0.4295331207507956, 0.4426852730019003, 0.43456085687183127, 0.42808142039402547, 0.4263699470617312, 0.43515033772000833, 0.4182502954499161, 0.40329571657667246, 0.3963829195050678, 0.393196884703259, 0.4052936821216712, 0.4012831376506797, 0.4071111100915346, 0.388830649043066, 0.39156453370787836, 0.37260600522900306, 0.38469161042019895, 0.39174358058157865, 0.3748897918410075, 0.36687762094727644, 0.3664201064410264, 0.3759281706497829, 0.3882884204355147, 0.3766185586008945, 0.3799803927012369, 0.36436330049465865, 0.3587112788677996, 0.36193206449447274, 0.3650543198225216, 0.36576326510910123, 0.35790600723993954, 0.36165421228882266, 0.3510974217196078, 0.3497712586381952, 0.351492399539833, 0.34975720856661885, 0.3537578562440211, 0.35169960030817426, 0.3512184306759686, 0.3442180015419067, 0.3425032903653185, 0.346475837834533, 0.3352673315751507, 0.3381297757276992, 0.33569334080748653, 0.3324989581686905, 0.3306045683433108, 0.3324823446502727, 0.33154801282151697, 0.32969022215843463, 0.329590485190929, 0.3323120264101731, 0.32804572744832555, 0.32866028614598286, 0.3255581211276348, 0.323269607717719, 0.3240269334896366, 0.32015767229331754, 0.322196950742734, 0.32272823471159345, 0.3187212999310574, 0.3190659177365098, 0.32126019821912294, 0.3210773583129658], 'acc': [0.9082521752002651, 0.9254646444671868, 0.9309165111930398, 0.933646178804846, 0.9353655717506867, 0.9333209927070355, 0.9338404426012804, 0.9365010675483887, 0.9360085708224832, 0.9345452678834423, 0.9360391193247856, 0.9379954697392511, 0.9386840808996397, 0.9394283729762375, 0.9368152347211947, 0.9373618630977908, 0.9380330387126925, 0.9397083433091933, 0.9387857482463235, 0.9419883280521003, 0.9397529327537737, 0.9380457032201593, 0.9419870297244125, 0.9429527894434744, 0.9432837448351642, 0.9418276107122647, 0.9403344299776334, 0.941273364062135, 0.9413834483455714, 0.9435965135913044, 0.9440755959228291, 0.9439139276401501, 0.9434321975356819, 0.9429970279913162, 0.9441103170754411, 0.9445627474485689, 0.9455338041442896, 0.9453606947939447, 0.9454767240635111, 0.9455480663033697, 0.9448200870717866, 0.9451869123631075, 0.9455152687256413, 0.9460732122945187, 0.9458001359720016, 0.9464085629190568, 0.9472476506389299, 0.9474989963696423, 0.9473912580313737, 0.9474848072774672, 0.9477127957916364, 0.9470965260374565, 0.9481231853796755, 0.9482632954785294, 0.9478171857991508, 0.9477693757201828, 0.9486003941808057, 0.9482522293055441, 0.94869669076854, 0.9487642851671884, 0.9487864428443201, 0.9492863332776508, 0.9492901557140901, 0.949287483000196, 0.9495840899552794, 0.9493246521705236, 0.9495157452795068, 0.9495024323073229], 'mDice': [0.34026996488543204, 0.4580364327286347, 0.504968978232916, 0.5214431394791902, 0.5373731972705583, 0.5228955046895157, 0.5309358597191969, 0.5361422755259083, 0.5375041111011162, 0.5242078758560759, 0.5392959918145983, 0.5520465460164392, 0.5601199758846254, 0.5609990682552503, 0.5477898745542007, 0.5521684752516063, 0.547593658599968, 0.5650114369925683, 0.5636909273206635, 0.5824387114001179, 0.5690728748228403, 0.5606407696148508, 0.5811258754116293, 0.5869022809737248, 0.5874525166507374, 0.57786395045102, 0.5642121431285153, 0.5768384768282593, 0.5722110092932581, 0.5895541404936395, 0.5940241488321714, 0.591127990733322, 0.589415641801317, 0.5887449395116795, 0.5954570084631411, 0.5975035335675524, 0.6080736114688734, 0.605494743315691, 0.6043862099213088, 0.6062174887521893, 0.6023163402659348, 0.6031626808922992, 0.6083437091687697, 0.6129239129194196, 0.6140546595796625, 0.611211697032916, 0.6197136745905525, 0.6206520456989411, 0.6218391704026038, 0.6251150907159047, 0.6245225547963781, 0.6236523224627197, 0.6255998387729543, 0.6286971488092613, 0.6278223047084777, 0.6233766942289574, 0.63022350282924, 0.6266602890873891, 0.6320985306564473, 0.6347579347001225, 0.6332611740773582, 0.6355250884585216, 0.6362542136731333, 0.6369281948685841, 0.6374571405664143, 0.6392607539810903, 0.6393503572728813, 0.6373061763414319], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.49s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.38s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.31s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.16s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_c/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_c/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_c/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  3.22it/s] 40%|████      | 2/5 [00:00<00:00,  3.13it/s] 60%|██████    | 3/5 [00:00<00:00,  3.07it/s] 80%|████████  | 4/5 [00:01<00:00,  3.30it/s]100%|██████████| 5/5 [00:01<00:00,  3.34it/s]100%|██████████| 5/5 [00:01<00:00,  3.26it/s]

CrossVal ['c']
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
2020-01-22 04:16:46.296114: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-22 04:16:49.884423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:09:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-22 04:16:49.884485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 04:16:50.312905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 04:16:50.312966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 04:16:50.312977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 04:16:50.313487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:31,  2.90it/s]Loading train:   1%|          | 2/266 [00:00<01:24,  3.11it/s]Loading train:   1%|          | 3/266 [00:00<01:18,  3.35it/s]Loading train:   2%|▏         | 4/266 [00:01<01:14,  3.51it/s]Loading train:   2%|▏         | 5/266 [00:01<01:09,  3.74it/s]Loading train:   2%|▏         | 6/266 [00:01<01:06,  3.90it/s]Loading train:   3%|▎         | 7/266 [00:01<01:04,  4.04it/s]Loading train:   3%|▎         | 8/266 [00:02<01:02,  4.14it/s]Loading train:   3%|▎         | 9/266 [00:02<01:00,  4.21it/s]Loading train:   4%|▍         | 10/266 [00:02<00:59,  4.29it/s]Loading train:   4%|▍         | 11/266 [00:02<00:59,  4.31it/s]Loading train:   5%|▍         | 12/266 [00:02<00:58,  4.35it/s]Loading train:   5%|▍         | 13/266 [00:03<00:58,  4.35it/s]Loading train:   5%|▌         | 14/266 [00:03<00:57,  4.37it/s]Loading train:   6%|▌         | 15/266 [00:03<00:57,  4.37it/s]Loading train:   6%|▌         | 16/266 [00:03<00:56,  4.39it/s]Loading train:   6%|▋         | 17/266 [00:04<00:56,  4.39it/s]Loading train:   7%|▋         | 18/266 [00:04<00:56,  4.37it/s]Loading train:   7%|▋         | 19/266 [00:04<00:56,  4.37it/s]Loading train:   8%|▊         | 20/266 [00:04<00:56,  4.38it/s]Loading train:   8%|▊         | 21/266 [00:04<00:55,  4.39it/s]Loading train:   8%|▊         | 22/266 [00:05<00:55,  4.37it/s]Loading train:   9%|▊         | 23/266 [00:05<00:55,  4.40it/s]Loading train:   9%|▉         | 24/266 [00:05<00:54,  4.42it/s]Loading train:   9%|▉         | 25/266 [00:05<00:54,  4.40it/s]Loading train:  10%|▉         | 26/266 [00:06<00:54,  4.42it/s]Loading train:  10%|█         | 27/266 [00:06<00:53,  4.44it/s]Loading train:  11%|█         | 28/266 [00:06<00:53,  4.45it/s]Loading train:  11%|█         | 29/266 [00:06<00:53,  4.44it/s]Loading train:  11%|█▏        | 30/266 [00:07<00:53,  4.45it/s]Loading train:  12%|█▏        | 31/266 [00:07<00:52,  4.47it/s]Loading train:  12%|█▏        | 32/266 [00:07<00:53,  4.40it/s]Loading train:  12%|█▏        | 33/266 [00:07<00:52,  4.43it/s]Loading train:  13%|█▎        | 34/266 [00:07<00:53,  4.33it/s]Loading train:  13%|█▎        | 35/266 [00:08<00:52,  4.40it/s]Loading train:  14%|█▎        | 36/266 [00:08<00:51,  4.45it/s]Loading train:  14%|█▍        | 37/266 [00:08<00:51,  4.46it/s]Loading train:  14%|█▍        | 38/266 [00:08<00:51,  4.47it/s]Loading train:  15%|█▍        | 39/266 [00:09<00:51,  4.45it/s]Loading train:  15%|█▌        | 40/266 [00:09<00:50,  4.48it/s]Loading train:  15%|█▌        | 41/266 [00:09<00:49,  4.51it/s]Loading train:  16%|█▌        | 42/266 [00:09<00:49,  4.51it/s]Loading train:  16%|█▌        | 43/266 [00:09<00:49,  4.54it/s]Loading train:  17%|█▋        | 44/266 [00:10<00:48,  4.54it/s]Loading train:  17%|█▋        | 45/266 [00:10<00:49,  4.50it/s]Loading train:  17%|█▋        | 46/266 [00:10<00:49,  4.47it/s]Loading train:  18%|█▊        | 47/266 [00:10<00:49,  4.46it/s]Loading train:  18%|█▊        | 48/266 [00:11<00:48,  4.45it/s]Loading train:  18%|█▊        | 49/266 [00:11<00:48,  4.47it/s]Loading train:  19%|█▉        | 50/266 [00:11<00:48,  4.47it/s]Loading train:  19%|█▉        | 51/266 [00:11<00:48,  4.44it/s]Loading train:  20%|█▉        | 52/266 [00:11<00:48,  4.43it/s]Loading train:  20%|█▉        | 53/266 [00:12<00:48,  4.43it/s]Loading train:  20%|██        | 54/266 [00:12<00:47,  4.44it/s]Loading train:  21%|██        | 55/266 [00:12<00:47,  4.44it/s]Loading train:  21%|██        | 56/266 [00:12<00:47,  4.46it/s]Loading train:  21%|██▏       | 57/266 [00:13<00:46,  4.45it/s]Loading train:  22%|██▏       | 58/266 [00:13<00:46,  4.44it/s]Loading train:  22%|██▏       | 59/266 [00:13<00:47,  4.39it/s]Loading train:  23%|██▎       | 60/266 [00:13<00:47,  4.34it/s]Loading train:  23%|██▎       | 61/266 [00:13<00:47,  4.34it/s]Loading train:  23%|██▎       | 62/266 [00:14<00:46,  4.35it/s]Loading train:  24%|██▎       | 63/266 [00:14<00:46,  4.34it/s]Loading train:  24%|██▍       | 64/266 [00:14<00:46,  4.35it/s]Loading train:  24%|██▍       | 65/266 [00:14<00:46,  4.34it/s]Loading train:  25%|██▍       | 66/266 [00:15<00:45,  4.36it/s]Loading train:  25%|██▌       | 67/266 [00:15<00:45,  4.35it/s]Loading train:  26%|██▌       | 68/266 [00:15<00:45,  4.37it/s]Loading train:  26%|██▌       | 69/266 [00:15<00:44,  4.41it/s]Loading train:  26%|██▋       | 70/266 [00:16<00:44,  4.44it/s]Loading train:  27%|██▋       | 71/266 [00:16<00:44,  4.43it/s]Loading train:  27%|██▋       | 72/266 [00:16<00:43,  4.43it/s]Loading train:  27%|██▋       | 73/266 [00:16<00:44,  4.38it/s]Loading train:  28%|██▊       | 74/266 [00:17<00:48,  3.96it/s]Loading train:  28%|██▊       | 75/266 [00:17<00:46,  4.07it/s]Loading train:  29%|██▊       | 76/266 [00:17<00:45,  4.14it/s]Loading train:  29%|██▉       | 77/266 [00:17<00:48,  3.89it/s]Loading train:  29%|██▉       | 78/266 [00:18<00:49,  3.78it/s]Loading train:  30%|██▉       | 79/266 [00:18<00:47,  3.94it/s]Loading train:  30%|███       | 80/266 [00:18<00:46,  3.99it/s]Loading train:  30%|███       | 81/266 [00:18<00:47,  3.90it/s]Loading train:  31%|███       | 82/266 [00:19<00:47,  3.87it/s]Loading train:  31%|███       | 83/266 [00:19<00:47,  3.84it/s]Loading train:  32%|███▏      | 84/266 [00:19<00:47,  3.81it/s]Loading train:  32%|███▏      | 85/266 [00:19<00:47,  3.78it/s]Loading train:  32%|███▏      | 86/266 [00:20<00:48,  3.74it/s]Loading train:  33%|███▎      | 87/266 [00:20<00:47,  3.75it/s]Loading train:  33%|███▎      | 88/266 [00:20<00:47,  3.75it/s]Loading train:  33%|███▎      | 89/266 [00:20<00:47,  3.76it/s]Loading train:  34%|███▍      | 90/266 [00:21<00:46,  3.76it/s]Loading train:  34%|███▍      | 91/266 [00:21<00:46,  3.77it/s]Loading train:  35%|███▍      | 92/266 [00:21<00:46,  3.73it/s]Loading train:  35%|███▍      | 93/266 [00:22<00:46,  3.70it/s]Loading train:  35%|███▌      | 94/266 [00:22<00:46,  3.71it/s]Loading train:  36%|███▌      | 95/266 [00:22<00:46,  3.71it/s]Loading train:  36%|███▌      | 96/266 [00:22<00:45,  3.70it/s]Loading train:  36%|███▋      | 97/266 [00:23<00:45,  3.73it/s]Loading train:  37%|███▋      | 98/266 [00:23<00:44,  3.77it/s]Loading train:  37%|███▋      | 99/266 [00:23<00:44,  3.78it/s]Loading train:  38%|███▊      | 100/266 [00:23<00:43,  3.86it/s]Loading train:  38%|███▊      | 101/266 [00:24<00:42,  3.88it/s]Loading train:  38%|███▊      | 102/266 [00:24<00:42,  3.89it/s]Loading train:  39%|███▊      | 103/266 [00:24<00:41,  3.91it/s]Loading train:  39%|███▉      | 104/266 [00:24<00:41,  3.93it/s]Loading train:  39%|███▉      | 105/266 [00:25<00:40,  3.96it/s]Loading train:  40%|███▉      | 106/266 [00:25<00:40,  3.91it/s]Loading train:  40%|████      | 107/266 [00:25<00:40,  3.95it/s]Loading train:  41%|████      | 108/266 [00:25<00:39,  3.96it/s]Loading train:  41%|████      | 109/266 [00:26<00:40,  3.86it/s]Loading train:  41%|████▏     | 110/266 [00:26<00:40,  3.83it/s]Loading train:  42%|████▏     | 111/266 [00:26<00:40,  3.84it/s]Loading train:  42%|████▏     | 112/266 [00:26<00:39,  3.89it/s]Loading train:  42%|████▏     | 113/266 [00:27<00:38,  3.93it/s]Loading train:  43%|████▎     | 114/266 [00:27<00:39,  3.85it/s]Loading train:  43%|████▎     | 115/266 [00:27<00:38,  3.87it/s]Loading train:  44%|████▎     | 116/266 [00:27<00:39,  3.82it/s]Loading train:  44%|████▍     | 117/266 [00:28<00:41,  3.60it/s]Loading train:  44%|████▍     | 118/266 [00:28<00:39,  3.72it/s]Loading train:  45%|████▍     | 119/266 [00:28<00:37,  3.97it/s]Loading train:  45%|████▌     | 120/266 [00:28<00:35,  4.14it/s]Loading train:  45%|████▌     | 121/266 [00:29<00:34,  4.20it/s]Loading train:  46%|████▌     | 122/266 [00:29<00:32,  4.37it/s]Loading train:  46%|████▌     | 123/266 [00:29<00:31,  4.51it/s]Loading train:  47%|████▋     | 124/266 [00:29<00:30,  4.60it/s]Loading train:  47%|████▋     | 125/266 [00:30<00:30,  4.65it/s]Loading train:  47%|████▋     | 126/266 [00:30<00:29,  4.71it/s]Loading train:  48%|████▊     | 127/266 [00:30<00:29,  4.75it/s]Loading train:  48%|████▊     | 128/266 [00:30<00:28,  4.77it/s]Loading train:  48%|████▊     | 129/266 [00:30<00:28,  4.81it/s]Loading train:  49%|████▉     | 130/266 [00:31<00:28,  4.81it/s]Loading train:  49%|████▉     | 131/266 [00:31<00:28,  4.82it/s]Loading train:  50%|████▉     | 132/266 [00:31<00:27,  4.81it/s]Loading train:  50%|█████     | 133/266 [00:31<00:27,  4.80it/s]Loading train:  50%|█████     | 134/266 [00:31<00:27,  4.82it/s]Loading train:  51%|█████     | 135/266 [00:32<00:27,  4.82it/s]Loading train:  51%|█████     | 136/266 [00:32<00:27,  4.77it/s]Loading train:  52%|█████▏    | 137/266 [00:32<00:27,  4.72it/s]Loading train:  52%|█████▏    | 138/266 [00:32<00:27,  4.62it/s]Loading train:  52%|█████▏    | 139/266 [00:33<00:28,  4.51it/s]Loading train:  53%|█████▎    | 140/266 [00:33<00:28,  4.50it/s]Loading train:  53%|█████▎    | 141/266 [00:33<00:27,  4.49it/s]Loading train:  53%|█████▎    | 142/266 [00:33<00:27,  4.49it/s]Loading train:  54%|█████▍    | 143/266 [00:33<00:27,  4.51it/s]Loading train:  54%|█████▍    | 144/266 [00:34<00:26,  4.52it/s]Loading train:  55%|█████▍    | 145/266 [00:34<00:26,  4.53it/s]Loading train:  55%|█████▍    | 146/266 [00:34<00:26,  4.53it/s]Loading train:  55%|█████▌    | 147/266 [00:34<00:26,  4.54it/s]Loading train:  56%|█████▌    | 148/266 [00:34<00:25,  4.54it/s]Loading train:  56%|█████▌    | 149/266 [00:35<00:25,  4.54it/s]Loading train:  56%|█████▋    | 150/266 [00:35<00:25,  4.53it/s]Loading train:  57%|█████▋    | 151/266 [00:35<00:25,  4.53it/s]Loading train:  57%|█████▋    | 152/266 [00:35<00:25,  4.53it/s]Loading train:  58%|█████▊    | 153/266 [00:36<00:24,  4.55it/s]Loading train:  58%|█████▊    | 154/266 [00:36<00:25,  4.40it/s]Loading train:  58%|█████▊    | 155/266 [00:36<00:25,  4.30it/s]Loading train:  59%|█████▊    | 156/266 [00:36<00:25,  4.23it/s]Loading train:  59%|█████▉    | 157/266 [00:37<00:26,  4.19it/s]Loading train:  59%|█████▉    | 158/266 [00:37<00:25,  4.16it/s]Loading train:  60%|█████▉    | 159/266 [00:37<00:26,  4.11it/s]Loading train:  60%|██████    | 160/266 [00:37<00:25,  4.09it/s]Loading train:  61%|██████    | 161/266 [00:38<00:25,  4.07it/s]Loading train:  61%|██████    | 162/266 [00:38<00:26,  3.99it/s]Loading train:  61%|██████▏   | 163/266 [00:38<00:25,  3.98it/s]Loading train:  62%|██████▏   | 164/266 [00:38<00:25,  4.00it/s]Loading train:  62%|██████▏   | 165/266 [00:39<00:25,  4.00it/s]Loading train:  62%|██████▏   | 166/266 [00:39<00:24,  4.01it/s]Loading train:  63%|██████▎   | 167/266 [00:39<00:24,  4.02it/s]Loading train:  63%|██████▎   | 168/266 [00:39<00:24,  4.02it/s]Loading train:  64%|██████▎   | 169/266 [00:40<00:24,  4.03it/s]Loading train:  64%|██████▍   | 170/266 [00:40<00:23,  4.03it/s]Loading train:  64%|██████▍   | 171/266 [00:40<00:23,  4.03it/s]Loading train:  65%|██████▍   | 172/266 [00:40<00:22,  4.09it/s]Loading train:  65%|██████▌   | 173/266 [00:41<00:23,  3.91it/s]Loading train:  65%|██████▌   | 174/266 [00:41<00:23,  3.96it/s]Loading train:  66%|██████▌   | 175/266 [00:41<00:21,  4.18it/s]Loading train:  66%|██████▌   | 176/266 [00:41<00:21,  4.16it/s]Loading train:  67%|██████▋   | 177/266 [00:42<00:21,  4.23it/s]Loading train:  67%|██████▋   | 178/266 [00:42<00:20,  4.28it/s]Loading train:  67%|██████▋   | 179/266 [00:42<00:20,  4.32it/s]Loading train:  68%|██████▊   | 180/266 [00:42<00:19,  4.37it/s]Loading train:  68%|██████▊   | 181/266 [00:42<00:19,  4.40it/s]Loading train:  68%|██████▊   | 182/266 [00:43<00:18,  4.45it/s]Loading train:  69%|██████▉   | 183/266 [00:43<00:18,  4.49it/s]Loading train:  69%|██████▉   | 184/266 [00:43<00:18,  4.48it/s]Loading train:  70%|██████▉   | 185/266 [00:43<00:18,  4.47it/s]Loading train:  70%|██████▉   | 186/266 [00:44<00:17,  4.51it/s]Loading train:  70%|███████   | 187/266 [00:44<00:17,  4.45it/s]Loading train:  71%|███████   | 188/266 [00:44<00:17,  4.48it/s]Loading train:  71%|███████   | 189/266 [00:44<00:17,  4.51it/s]Loading train:  71%|███████▏  | 190/266 [00:44<00:16,  4.50it/s]Loading train:  72%|███████▏  | 191/266 [00:45<00:16,  4.53it/s]Loading train:  72%|███████▏  | 192/266 [00:45<00:17,  4.31it/s]Loading train:  73%|███████▎  | 193/266 [00:45<00:16,  4.37it/s]Loading train:  73%|███████▎  | 194/266 [00:45<00:16,  4.42it/s]Loading train:  73%|███████▎  | 195/266 [00:46<00:16,  4.22it/s]Loading train:  74%|███████▎  | 196/266 [00:46<00:17,  4.07it/s]Loading train:  74%|███████▍  | 197/266 [00:46<00:17,  3.97it/s]Loading train:  74%|███████▍  | 198/266 [00:46<00:17,  3.92it/s]Loading train:  75%|███████▍  | 199/266 [00:47<00:17,  3.89it/s]Loading train:  75%|███████▌  | 200/266 [00:47<00:16,  3.89it/s]Loading train:  76%|███████▌  | 201/266 [00:47<00:16,  3.89it/s]Loading train:  76%|███████▌  | 202/266 [00:47<00:16,  3.87it/s]Loading train:  76%|███████▋  | 203/266 [00:48<00:16,  3.87it/s]Loading train:  77%|███████▋  | 204/266 [00:48<00:16,  3.86it/s]Loading train:  77%|███████▋  | 205/266 [00:48<00:15,  3.84it/s]Loading train:  77%|███████▋  | 206/266 [00:48<00:15,  3.85it/s]Loading train:  78%|███████▊  | 207/266 [00:49<00:15,  3.85it/s]Loading train:  78%|███████▊  | 208/266 [00:49<00:15,  3.86it/s]Loading train:  79%|███████▊  | 209/266 [00:49<00:14,  3.84it/s]Loading train:  79%|███████▉  | 210/266 [00:50<00:14,  3.80it/s]Loading train:  79%|███████▉  | 211/266 [00:50<00:14,  3.80it/s]Loading train:  80%|███████▉  | 212/266 [00:50<00:14,  3.81it/s]Loading train:  80%|████████  | 213/266 [00:50<00:13,  3.95it/s]Loading train:  80%|████████  | 214/266 [00:50<00:12,  4.06it/s]Loading train:  81%|████████  | 215/266 [00:51<00:12,  4.13it/s]Loading train:  81%|████████  | 216/266 [00:51<00:11,  4.19it/s]Loading train:  82%|████████▏ | 217/266 [00:51<00:11,  4.20it/s]Loading train:  82%|████████▏ | 218/266 [00:51<00:11,  4.22it/s]Loading train:  82%|████████▏ | 219/266 [00:52<00:11,  3.96it/s]Loading train:  83%|████████▎ | 220/266 [00:52<00:11,  3.92it/s]Loading train:  83%|████████▎ | 221/266 [00:52<00:11,  3.97it/s]Loading train:  83%|████████▎ | 222/266 [00:52<00:11,  3.99it/s]Loading train:  84%|████████▍ | 223/266 [00:53<00:10,  4.02it/s]Loading train:  84%|████████▍ | 224/266 [00:53<00:10,  4.12it/s]Loading train:  85%|████████▍ | 225/266 [00:53<00:09,  4.19it/s]Loading train:  85%|████████▍ | 226/266 [00:53<00:09,  4.25it/s]Loading train:  85%|████████▌ | 227/266 [00:54<00:09,  4.27it/s]Loading train:  86%|████████▌ | 228/266 [00:54<00:08,  4.28it/s]Loading train:  86%|████████▌ | 229/266 [00:54<00:08,  4.30it/s]Loading train:  86%|████████▋ | 230/266 [00:54<00:08,  4.30it/s]Loading train:  87%|████████▋ | 231/266 [00:55<00:07,  4.51it/s]Loading train:  87%|████████▋ | 232/266 [00:55<00:07,  4.59it/s]Loading train:  88%|████████▊ | 233/266 [00:55<00:07,  4.69it/s]Loading train:  88%|████████▊ | 234/266 [00:55<00:06,  4.74it/s]Loading train:  88%|████████▊ | 235/266 [00:55<00:06,  4.82it/s]Loading train:  89%|████████▊ | 236/266 [00:56<00:06,  4.88it/s]Loading train:  89%|████████▉ | 237/266 [00:56<00:05,  4.96it/s]Loading train:  89%|████████▉ | 238/266 [00:56<00:05,  5.02it/s]Loading train:  90%|████████▉ | 239/266 [00:56<00:05,  5.07it/s]Loading train:  90%|█████████ | 240/266 [00:56<00:05,  5.06it/s]Loading train:  91%|█████████ | 241/266 [00:57<00:04,  5.04it/s]Loading train:  91%|█████████ | 242/266 [00:57<00:04,  5.05it/s]Loading train:  91%|█████████▏| 243/266 [00:57<00:04,  5.04it/s]Loading train:  92%|█████████▏| 244/266 [00:57<00:04,  5.06it/s]Loading train:  92%|█████████▏| 245/266 [00:57<00:04,  5.05it/s]Loading train:  92%|█████████▏| 246/266 [00:58<00:03,  5.05it/s]Loading train:  93%|█████████▎| 247/266 [00:58<00:03,  5.04it/s]Loading train:  93%|█████████▎| 248/266 [00:58<00:03,  5.03it/s]Loading train:  94%|█████████▎| 249/266 [00:58<00:03,  4.86it/s]Loading train:  94%|█████████▍| 250/266 [00:58<00:03,  4.77it/s]Loading train:  94%|█████████▍| 251/266 [00:59<00:03,  4.72it/s]Loading train:  95%|█████████▍| 252/266 [00:59<00:03,  4.66it/s]Loading train:  95%|█████████▌| 253/266 [00:59<00:02,  4.63it/s]Loading train:  95%|█████████▌| 254/266 [00:59<00:02,  4.57it/s]Loading train:  96%|█████████▌| 255/266 [00:59<00:02,  4.57it/s]Loading train:  96%|█████████▌| 256/266 [01:00<00:02,  4.47it/s]Loading train:  97%|█████████▋| 257/266 [01:00<00:01,  4.52it/s]Loading train:  97%|█████████▋| 258/266 [01:00<00:01,  4.52it/s]Loading train:  97%|█████████▋| 259/266 [01:00<00:01,  4.55it/s]Loading train:  98%|█████████▊| 260/266 [01:01<00:01,  4.47it/s]Loading train:  98%|█████████▊| 261/266 [01:01<00:01,  4.48it/s]Loading train:  98%|█████████▊| 262/266 [01:01<00:00,  4.49it/s]Loading train:  99%|█████████▉| 263/266 [01:01<00:00,  4.51it/s]Loading train:  99%|█████████▉| 264/266 [01:01<00:00,  4.45it/s]Loading train: 100%|█████████▉| 265/266 [01:02<00:00,  4.42it/s]Loading train: 100%|██████████| 266/266 [01:02<00:00,  4.48it/s]Loading train: 100%|██████████| 266/266 [01:02<00:00,  4.26it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 52.84it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:05, 49.32it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 45.53it/s]concatenating: train:   7%|▋         | 19/266 [00:00<00:05, 42.67it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:05, 42.87it/s]concatenating: train:  11%|█         | 28/266 [00:00<00:05, 40.40it/s]concatenating: train:  12%|█▏        | 33/266 [00:00<00:05, 41.04it/s]concatenating: train:  14%|█▍        | 38/266 [00:00<00:05, 42.35it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:05, 44.12it/s]concatenating: train:  18%|█▊        | 48/266 [00:01<00:04, 44.88it/s]concatenating: train:  20%|█▉        | 53/266 [00:01<00:04, 45.05it/s]concatenating: train:  22%|██▏       | 58/266 [00:01<00:04, 45.11it/s]concatenating: train:  24%|██▎       | 63/266 [00:01<00:04, 45.62it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:04, 45.40it/s]concatenating: train:  27%|██▋       | 73/266 [00:01<00:04, 46.02it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:04, 45.23it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:04, 42.36it/s]concatenating: train:  33%|███▎      | 88/266 [00:02<00:04, 41.57it/s]concatenating: train:  35%|███▍      | 93/266 [00:02<00:04, 40.39it/s]concatenating: train:  37%|███▋      | 98/266 [00:02<00:04, 41.35it/s]concatenating: train:  39%|███▊      | 103/266 [00:02<00:03, 43.28it/s]concatenating: train:  41%|████      | 109/266 [00:02<00:03, 46.03it/s]concatenating: train:  43%|████▎     | 115/266 [00:02<00:03, 47.66it/s]concatenating: train:  45%|████▌     | 121/266 [00:02<00:02, 49.30it/s]concatenating: train:  48%|████▊     | 128/266 [00:02<00:02, 52.16it/s]concatenating: train:  51%|█████     | 135/266 [00:02<00:02, 54.98it/s]concatenating: train:  53%|█████▎    | 141/266 [00:03<00:02, 54.87it/s]concatenating: train:  56%|█████▌    | 148/266 [00:03<00:02, 56.53it/s]concatenating: train:  58%|█████▊    | 154/266 [00:03<00:01, 57.07it/s]concatenating: train:  60%|██████    | 160/266 [00:03<00:01, 56.35it/s]concatenating: train:  62%|██████▏   | 166/266 [00:03<00:01, 54.54it/s]concatenating: train:  65%|██████▍   | 172/266 [00:03<00:01, 54.53it/s]concatenating: train:  67%|██████▋   | 179/266 [00:03<00:01, 55.65it/s]concatenating: train:  70%|██████▉   | 186/266 [00:03<00:01, 57.36it/s]concatenating: train:  72%|███████▏  | 192/266 [00:03<00:01, 56.96it/s]concatenating: train:  74%|███████▍  | 198/266 [00:04<00:01, 55.89it/s]concatenating: train:  77%|███████▋  | 204/266 [00:04<00:01, 54.70it/s]concatenating: train:  79%|███████▉  | 210/266 [00:04<00:01, 52.90it/s]concatenating: train:  81%|████████  | 216/266 [00:04<00:00, 53.05it/s]concatenating: train:  83%|████████▎ | 222/266 [00:04<00:00, 53.48it/s]concatenating: train:  86%|████████▌ | 228/266 [00:04<00:00, 54.83it/s]concatenating: train:  88%|████████▊ | 235/266 [00:04<00:00, 57.02it/s]concatenating: train:  91%|█████████ | 242/266 [00:04<00:00, 58.11it/s]concatenating: train:  94%|█████████▎| 249/266 [00:04<00:00, 59.07it/s]concatenating: train:  96%|█████████▌| 255/266 [00:05<00:00, 57.65it/s]concatenating: train:  98%|█████████▊| 261/266 [00:05<00:00, 58.32it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 50.62it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  4.13it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  4.19it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  4.13it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  3.98it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 67.34it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<01:06,  4.00it/s]Loading trainS:   1%|          | 2/266 [00:00<01:05,  4.05it/s]Loading trainS:   1%|          | 3/266 [00:00<01:04,  4.10it/s]Loading trainS:   2%|▏         | 4/266 [00:00<01:04,  4.08it/s]Loading trainS:   2%|▏         | 5/266 [00:01<01:02,  4.17it/s]Loading trainS:   2%|▏         | 6/266 [00:01<01:00,  4.26it/s]Loading trainS:   3%|▎         | 7/266 [00:01<01:00,  4.31it/s]Loading trainS:   3%|▎         | 8/266 [00:01<00:59,  4.35it/s]Loading trainS:   3%|▎         | 9/266 [00:02<00:58,  4.37it/s]Loading trainS:   4%|▍         | 10/266 [00:02<00:58,  4.40it/s]Loading trainS:   4%|▍         | 11/266 [00:02<00:58,  4.35it/s]Loading trainS:   5%|▍         | 12/266 [00:02<00:58,  4.37it/s]Loading trainS:   5%|▍         | 13/266 [00:03<00:57,  4.39it/s]Loading trainS:   5%|▌         | 14/266 [00:03<00:57,  4.41it/s]Loading trainS:   6%|▌         | 15/266 [00:03<00:57,  4.40it/s]Loading trainS:   6%|▌         | 16/266 [00:03<00:56,  4.42it/s]Loading trainS:   6%|▋         | 17/266 [00:03<00:56,  4.44it/s]Loading trainS:   7%|▋         | 18/266 [00:04<00:55,  4.45it/s]Loading trainS:   7%|▋         | 19/266 [00:04<00:55,  4.46it/s]Loading trainS:   8%|▊         | 20/266 [00:04<00:55,  4.46it/s]Loading trainS:   8%|▊         | 21/266 [00:04<00:55,  4.40it/s]Loading trainS:   8%|▊         | 22/266 [00:05<00:56,  4.35it/s]Loading trainS:   9%|▊         | 23/266 [00:05<00:55,  4.37it/s]Loading trainS:   9%|▉         | 24/266 [00:05<00:55,  4.38it/s]Loading trainS:   9%|▉         | 25/266 [00:05<00:55,  4.37it/s]Loading trainS:  10%|▉         | 26/266 [00:05<00:54,  4.39it/s]Loading trainS:  10%|█         | 27/266 [00:06<00:54,  4.42it/s]Loading trainS:  11%|█         | 28/266 [00:06<00:53,  4.45it/s]Loading trainS:  11%|█         | 29/266 [00:06<00:53,  4.46it/s]Loading trainS:  11%|█▏        | 30/266 [00:06<00:52,  4.49it/s]Loading trainS:  12%|█▏        | 31/266 [00:07<00:52,  4.51it/s]Loading trainS:  12%|█▏        | 32/266 [00:07<00:51,  4.54it/s]Loading trainS:  12%|█▏        | 33/266 [00:07<00:51,  4.54it/s]Loading trainS:  13%|█▎        | 34/266 [00:07<00:51,  4.51it/s]Loading trainS:  13%|█▎        | 35/266 [00:07<00:51,  4.46it/s]Loading trainS:  14%|█▎        | 36/266 [00:08<00:52,  4.42it/s]Loading trainS:  14%|█▍        | 37/266 [00:08<00:51,  4.44it/s]Loading trainS:  14%|█▍        | 38/266 [00:08<00:52,  4.35it/s]Loading trainS:  15%|█▍        | 39/266 [00:08<00:51,  4.38it/s]Loading trainS:  15%|█▌        | 40/266 [00:09<00:51,  4.38it/s]Loading trainS:  15%|█▌        | 41/266 [00:09<00:51,  4.39it/s]Loading trainS:  16%|█▌        | 42/266 [00:09<00:50,  4.42it/s]Loading trainS:  16%|█▌        | 43/266 [00:09<00:50,  4.44it/s]Loading trainS:  17%|█▋        | 44/266 [00:10<00:50,  4.36it/s]Loading trainS:  17%|█▋        | 45/266 [00:10<00:50,  4.39it/s]Loading trainS:  17%|█▋        | 46/266 [00:10<00:49,  4.44it/s]Loading trainS:  18%|█▊        | 47/266 [00:10<00:49,  4.44it/s]Loading trainS:  18%|█▊        | 48/266 [00:10<00:49,  4.42it/s]Loading trainS:  18%|█▊        | 49/266 [00:11<00:48,  4.43it/s]Loading trainS:  19%|█▉        | 50/266 [00:11<00:48,  4.46it/s]Loading trainS:  19%|█▉        | 51/266 [00:11<00:48,  4.44it/s]Loading trainS:  20%|█▉        | 52/266 [00:11<00:48,  4.43it/s]Loading trainS:  20%|█▉        | 53/266 [00:12<00:48,  4.38it/s]Loading trainS:  20%|██        | 54/266 [00:12<00:48,  4.38it/s]Loading trainS:  21%|██        | 55/266 [00:12<00:48,  4.32it/s]Loading trainS:  21%|██        | 56/266 [00:12<00:48,  4.35it/s]Loading trainS:  21%|██▏       | 57/266 [00:12<00:47,  4.40it/s]Loading trainS:  22%|██▏       | 58/266 [00:13<00:47,  4.42it/s]Loading trainS:  22%|██▏       | 59/266 [00:13<00:47,  4.38it/s]Loading trainS:  23%|██▎       | 60/266 [00:13<00:47,  4.35it/s]Loading trainS:  23%|██▎       | 61/266 [00:13<00:47,  4.35it/s]Loading trainS:  23%|██▎       | 62/266 [00:14<00:46,  4.34it/s]Loading trainS:  24%|██▎       | 63/266 [00:14<00:47,  4.30it/s]Loading trainS:  24%|██▍       | 64/266 [00:14<00:46,  4.30it/s]Loading trainS:  24%|██▍       | 65/266 [00:14<00:49,  4.07it/s]Loading trainS:  25%|██▍       | 66/266 [00:15<00:55,  3.61it/s]Loading trainS:  25%|██▌       | 67/266 [00:15<01:02,  3.20it/s]Loading trainS:  26%|██▌       | 68/266 [00:16<01:36,  2.06it/s]Loading trainS:  26%|██▌       | 69/266 [00:17<01:47,  1.82it/s]Loading trainS:  26%|██▋       | 70/266 [00:17<01:52,  1.74it/s]Loading trainS:  27%|██▋       | 71/266 [00:18<01:57,  1.66it/s]Loading trainS:  27%|██▋       | 72/266 [00:19<02:00,  1.61it/s]Loading trainS:  27%|██▋       | 73/266 [00:19<02:00,  1.60it/s]Loading trainS:  28%|██▊       | 74/266 [00:20<01:56,  1.65it/s]Loading trainS:  28%|██▊       | 75/266 [00:21<01:59,  1.60it/s]Loading trainS:  29%|██▊       | 76/266 [00:21<01:53,  1.67it/s]Loading trainS:  29%|██▉       | 77/266 [00:22<02:09,  1.46it/s]Loading trainS:  29%|██▉       | 78/266 [00:24<03:11,  1.02s/it]Loading trainS:  30%|██▉       | 79/266 [00:25<03:22,  1.08s/it]Loading trainS:  30%|███       | 80/266 [00:26<03:25,  1.10s/it]Loading trainS:  30%|███       | 81/266 [00:27<03:22,  1.10s/it]Loading trainS:  31%|███       | 82/266 [00:29<03:51,  1.26s/it]Loading trainS:  31%|███       | 83/266 [00:30<03:50,  1.26s/it]Loading trainS:  32%|███▏      | 84/266 [00:32<04:04,  1.35s/it]Loading trainS:  32%|███▏      | 85/266 [00:33<03:51,  1.28s/it]Loading trainS:  32%|███▏      | 86/266 [00:34<03:51,  1.29s/it]Loading trainS:  33%|███▎      | 87/266 [00:35<03:55,  1.32s/it]Loading trainS:  33%|███▎      | 88/266 [00:37<03:57,  1.33s/it]Loading trainS:  33%|███▎      | 89/266 [00:38<03:51,  1.31s/it]Loading trainS:  34%|███▍      | 90/266 [00:40<04:06,  1.40s/it]Loading trainS:  34%|███▍      | 91/266 [00:41<04:13,  1.45s/it]Loading trainS:  35%|███▍      | 92/266 [00:43<04:12,  1.45s/it]Loading trainS:  35%|███▍      | 93/266 [00:44<04:13,  1.46s/it]Loading trainS:  35%|███▌      | 94/266 [00:46<04:07,  1.44s/it]Loading trainS:  36%|███▌      | 95/266 [00:47<04:00,  1.41s/it]Loading trainS:  36%|███▌      | 96/266 [00:48<03:46,  1.33s/it]Loading trainS:  36%|███▋      | 97/266 [00:49<03:47,  1.34s/it]Loading trainS:  37%|███▋      | 98/266 [00:51<03:44,  1.34s/it]Loading trainS:  37%|███▋      | 99/266 [00:52<03:36,  1.30s/it]Loading trainS:  38%|███▊      | 100/266 [00:53<03:19,  1.20s/it]Loading trainS:  38%|███▊      | 101/266 [00:54<03:14,  1.18s/it]Loading trainS:  38%|███▊      | 102/266 [00:55<03:08,  1.15s/it]Loading trainS:  39%|███▊      | 103/266 [00:56<02:56,  1.08s/it]Loading trainS:  39%|███▉      | 104/266 [00:57<02:59,  1.11s/it]Loading trainS:  39%|███▉      | 105/266 [00:58<02:59,  1.11s/it]Loading trainS:  40%|███▉      | 106/266 [00:59<02:51,  1.07s/it]Loading trainS:  40%|████      | 107/266 [01:00<02:39,  1.00s/it]Loading trainS:  41%|████      | 108/266 [01:01<02:33,  1.03it/s]Loading trainS:  41%|████      | 109/266 [01:02<02:21,  1.11it/s]Loading trainS:  41%|████▏     | 110/266 [01:03<02:09,  1.20it/s]Loading trainS:  42%|████▏     | 111/266 [01:03<02:07,  1.21it/s]Loading trainS:  42%|████▏     | 112/266 [01:04<02:14,  1.14it/s]Loading trainS:  42%|████▏     | 113/266 [01:05<02:02,  1.25it/s]Loading trainS:  43%|████▎     | 114/266 [01:06<02:02,  1.25it/s]Loading trainS:  43%|████▎     | 115/266 [01:06<01:58,  1.28it/s]Loading trainS:  44%|████▎     | 116/266 [01:07<01:59,  1.25it/s]Loading trainS:  44%|████▍     | 117/266 [01:08<01:49,  1.37it/s]Loading trainS:  44%|████▍     | 118/266 [01:08<01:25,  1.74it/s]Loading trainS:  45%|████▍     | 119/266 [01:08<01:08,  2.15it/s]Loading trainS:  45%|████▌     | 120/266 [01:09<00:56,  2.59it/s]Loading trainS:  45%|████▌     | 121/266 [01:09<00:48,  3.00it/s]Loading trainS:  46%|████▌     | 122/266 [01:09<00:42,  3.40it/s]Loading trainS:  46%|████▌     | 123/266 [01:09<00:38,  3.73it/s]Loading trainS:  47%|████▋     | 124/266 [01:09<00:35,  4.00it/s]Loading trainS:  47%|████▋     | 125/266 [01:10<00:33,  4.20it/s]Loading trainS:  47%|████▋     | 126/266 [01:10<00:32,  4.37it/s]Loading trainS:  48%|████▊     | 127/266 [01:10<00:31,  4.47it/s]Loading trainS:  48%|████▊     | 128/266 [01:10<00:30,  4.53it/s]Loading trainS:  48%|████▊     | 129/266 [01:10<00:30,  4.55it/s]Loading trainS:  49%|████▉     | 130/266 [01:11<00:30,  4.53it/s]Loading trainS:  49%|████▉     | 131/266 [01:11<00:29,  4.60it/s]Loading trainS:  50%|████▉     | 132/266 [01:11<00:28,  4.65it/s]Loading trainS:  50%|█████     | 133/266 [01:11<00:28,  4.63it/s]Loading trainS:  50%|█████     | 134/266 [01:11<00:28,  4.67it/s]Loading trainS:  51%|█████     | 135/266 [01:12<00:27,  4.72it/s]Loading trainS:  51%|█████     | 136/266 [01:12<00:27,  4.68it/s]Loading trainS:  52%|█████▏    | 137/266 [01:12<00:27,  4.63it/s]Loading trainS:  52%|█████▏    | 138/266 [01:12<00:27,  4.58it/s]Loading trainS:  52%|█████▏    | 139/266 [01:13<00:29,  4.36it/s]Loading trainS:  53%|█████▎    | 140/266 [01:13<00:28,  4.36it/s]Loading trainS:  53%|█████▎    | 141/266 [01:13<00:28,  4.42it/s]Loading trainS:  53%|█████▎    | 142/266 [01:13<00:27,  4.46it/s]Loading trainS:  54%|█████▍    | 143/266 [01:13<00:27,  4.49it/s]Loading trainS:  54%|█████▍    | 144/266 [01:14<00:27,  4.52it/s]Loading trainS:  55%|█████▍    | 145/266 [01:14<00:27,  4.48it/s]Loading trainS:  55%|█████▍    | 146/266 [01:14<00:26,  4.48it/s]Loading trainS:  55%|█████▌    | 147/266 [01:14<00:26,  4.48it/s]Loading trainS:  56%|█████▌    | 148/266 [01:15<00:26,  4.52it/s]Loading trainS:  56%|█████▌    | 149/266 [01:15<00:25,  4.53it/s]Loading trainS:  56%|█████▋    | 150/266 [01:15<00:25,  4.56it/s]Loading trainS:  57%|█████▋    | 151/266 [01:15<00:25,  4.57it/s]Loading trainS:  57%|█████▋    | 152/266 [01:15<00:24,  4.59it/s]Loading trainS:  58%|█████▊    | 153/266 [01:16<00:24,  4.60it/s]Loading trainS:  58%|█████▊    | 154/266 [01:16<00:25,  4.39it/s]Loading trainS:  58%|█████▊    | 155/266 [01:16<00:26,  4.24it/s]Loading trainS:  59%|█████▊    | 156/266 [01:16<00:26,  4.15it/s]Loading trainS:  59%|█████▉    | 157/266 [01:17<00:26,  4.06it/s]Loading trainS:  59%|█████▉    | 158/266 [01:17<00:26,  4.07it/s]Loading trainS:  60%|█████▉    | 159/266 [01:17<00:26,  4.07it/s]Loading trainS:  60%|██████    | 160/266 [01:17<00:26,  4.03it/s]Loading trainS:  61%|██████    | 161/266 [01:18<00:26,  4.01it/s]Loading trainS:  61%|██████    | 162/266 [01:18<00:26,  3.99it/s]Loading trainS:  61%|██████▏   | 163/266 [01:18<00:25,  4.02it/s]Loading trainS:  62%|██████▏   | 164/266 [01:18<00:25,  4.00it/s]Loading trainS:  62%|██████▏   | 165/266 [01:19<00:25,  3.99it/s]Loading trainS:  62%|██████▏   | 166/266 [01:19<00:25,  3.98it/s]Loading trainS:  63%|██████▎   | 167/266 [01:19<00:24,  3.99it/s]Loading trainS:  63%|██████▎   | 168/266 [01:19<00:24,  3.97it/s]Loading trainS:  64%|██████▎   | 169/266 [01:20<00:24,  4.01it/s]Loading trainS:  64%|██████▍   | 170/266 [01:20<00:23,  4.01it/s]Loading trainS:  64%|██████▍   | 171/266 [01:20<00:23,  4.04it/s]Loading trainS:  65%|██████▍   | 172/266 [01:20<00:22,  4.10it/s]Loading trainS:  65%|██████▌   | 173/266 [01:21<00:23,  3.89it/s]Loading trainS:  65%|██████▌   | 174/266 [01:21<00:23,  3.91it/s]Loading trainS:  66%|██████▌   | 175/266 [01:21<00:21,  4.17it/s]Loading trainS:  66%|██████▌   | 176/266 [01:21<00:21,  4.19it/s]Loading trainS:  67%|██████▋   | 177/266 [01:22<00:20,  4.31it/s]Loading trainS:  67%|██████▋   | 178/266 [01:22<00:20,  4.38it/s]Loading trainS:  67%|██████▋   | 179/266 [01:22<00:19,  4.42it/s]Loading trainS:  68%|██████▊   | 180/266 [01:22<00:19,  4.46it/s]Loading trainS:  68%|██████▊   | 181/266 [01:23<00:18,  4.48it/s]Loading trainS:  68%|██████▊   | 182/266 [01:23<00:18,  4.51it/s]Loading trainS:  69%|██████▉   | 183/266 [01:23<00:18,  4.48it/s]Loading trainS:  69%|██████▉   | 184/266 [01:23<00:18,  4.48it/s]Loading trainS:  70%|██████▉   | 185/266 [01:24<00:22,  3.63it/s]Loading trainS:  70%|██████▉   | 186/266 [01:24<00:31,  2.53it/s]Loading trainS:  70%|███████   | 187/266 [01:25<00:38,  2.07it/s]Loading trainS:  71%|███████   | 188/266 [01:26<00:40,  1.93it/s]Loading trainS:  71%|███████   | 189/266 [01:26<00:42,  1.82it/s]Loading trainS:  71%|███████▏  | 190/266 [01:27<00:44,  1.69it/s]Loading trainS:  72%|███████▏  | 191/266 [01:27<00:45,  1.66it/s]Loading trainS:  72%|███████▏  | 192/266 [01:28<00:45,  1.63it/s]Loading trainS:  73%|███████▎  | 193/266 [01:29<00:45,  1.61it/s]Loading trainS:  73%|███████▎  | 194/266 [01:29<00:44,  1.61it/s]Loading trainS:  73%|███████▎  | 195/266 [01:30<00:48,  1.48it/s]Loading trainS:  74%|███████▎  | 196/266 [01:31<00:48,  1.43it/s]Loading trainS:  74%|███████▍  | 197/266 [01:32<00:48,  1.42it/s]Loading trainS:  74%|███████▍  | 198/266 [01:32<00:48,  1.39it/s]Loading trainS:  75%|███████▍  | 199/266 [01:33<00:49,  1.35it/s]Loading trainS:  75%|███████▌  | 200/266 [01:34<00:49,  1.32it/s]Loading trainS:  76%|███████▌  | 201/266 [01:35<00:49,  1.32it/s]Loading trainS:  76%|███████▌  | 202/266 [01:35<00:47,  1.35it/s]Loading trainS:  76%|███████▋  | 203/266 [01:36<00:46,  1.36it/s]Loading trainS:  77%|███████▋  | 204/266 [01:37<00:46,  1.32it/s]Loading trainS:  77%|███████▋  | 205/266 [01:38<00:44,  1.36it/s]Loading trainS:  77%|███████▋  | 206/266 [01:38<00:42,  1.42it/s]Loading trainS:  78%|███████▊  | 207/266 [01:39<00:39,  1.49it/s]Loading trainS:  78%|███████▊  | 208/266 [01:40<00:38,  1.53it/s]Loading trainS:  79%|███████▊  | 209/266 [01:40<00:36,  1.56it/s]Loading trainS:  79%|███████▉  | 210/266 [01:41<00:35,  1.59it/s]Loading trainS:  79%|███████▉  | 211/266 [01:41<00:34,  1.61it/s]Loading trainS:  80%|███████▉  | 212/266 [01:42<00:31,  1.69it/s]Loading trainS:  80%|████████  | 213/266 [01:42<00:29,  1.77it/s]Loading trainS:  80%|████████  | 214/266 [01:43<00:28,  1.83it/s]Loading trainS:  81%|████████  | 215/266 [01:43<00:27,  1.89it/s]Loading trainS:  81%|████████  | 216/266 [01:44<00:26,  1.88it/s]Loading trainS:  82%|████████▏ | 217/266 [01:44<00:25,  1.90it/s]Loading trainS:  82%|████████▏ | 218/266 [01:45<00:24,  1.95it/s]Loading trainS:  82%|████████▏ | 219/266 [01:45<00:24,  1.92it/s]Loading trainS:  83%|████████▎ | 220/266 [01:46<00:24,  1.91it/s]Loading trainS:  83%|████████▎ | 221/266 [01:47<00:24,  1.86it/s]Loading trainS:  83%|████████▎ | 222/266 [01:47<00:24,  1.81it/s]Loading trainS:  84%|████████▍ | 223/266 [01:48<00:23,  1.81it/s]Loading trainS:  84%|████████▍ | 224/266 [01:48<00:23,  1.76it/s]Loading trainS:  85%|████████▍ | 225/266 [01:49<00:22,  1.82it/s]Loading trainS:  85%|████████▍ | 226/266 [01:49<00:21,  1.83it/s]Loading trainS:  85%|████████▌ | 227/266 [01:50<00:20,  1.88it/s]Loading trainS:  86%|████████▌ | 228/266 [01:50<00:20,  1.83it/s]Loading trainS:  86%|████████▌ | 229/266 [01:51<00:20,  1.84it/s]Loading trainS:  86%|████████▋ | 230/266 [01:51<00:19,  1.80it/s]Loading trainS:  87%|████████▋ | 231/266 [01:52<00:18,  1.91it/s]Loading trainS:  87%|████████▋ | 232/266 [01:52<00:17,  1.96it/s]Loading trainS:  88%|████████▊ | 233/266 [01:53<00:16,  2.03it/s]Loading trainS:  88%|████████▊ | 234/266 [01:53<00:14,  2.15it/s]Loading trainS:  88%|████████▊ | 235/266 [01:54<00:14,  2.17it/s]Loading trainS:  89%|████████▊ | 236/266 [01:54<00:13,  2.16it/s]Loading trainS:  89%|████████▉ | 237/266 [01:55<00:13,  2.18it/s]Loading trainS:  89%|████████▉ | 238/266 [01:55<00:12,  2.17it/s]Loading trainS:  90%|████████▉ | 239/266 [01:56<00:12,  2.19it/s]Loading trainS:  90%|█████████ | 240/266 [01:56<00:11,  2.19it/s]Loading trainS:  91%|█████████ | 241/266 [01:56<00:11,  2.20it/s]Loading trainS:  91%|█████████ | 242/266 [01:57<00:10,  2.28it/s]Loading trainS:  91%|█████████▏| 243/266 [01:57<00:10,  2.26it/s]Loading trainS:  92%|█████████▏| 244/266 [01:58<00:10,  2.18it/s]Loading trainS:  92%|█████████▏| 245/266 [01:58<00:09,  2.21it/s]Loading trainS:  92%|█████████▏| 246/266 [01:59<00:08,  2.23it/s]Loading trainS:  93%|█████████▎| 247/266 [01:59<00:08,  2.29it/s]Loading trainS:  93%|█████████▎| 248/266 [02:00<00:07,  2.30it/s]Loading trainS:  94%|█████████▎| 249/266 [02:00<00:07,  2.24it/s]Loading trainS:  94%|█████████▍| 250/266 [02:01<00:07,  2.10it/s]Loading trainS:  94%|█████████▍| 251/266 [02:01<00:07,  2.05it/s]Loading trainS:  95%|█████████▍| 252/266 [02:02<00:07,  1.99it/s]Loading trainS:  95%|█████████▌| 253/266 [02:02<00:06,  1.90it/s]Loading trainS:  95%|█████████▌| 254/266 [02:03<00:05,  2.02it/s]Loading trainS:  96%|█████████▌| 255/266 [02:03<00:05,  2.07it/s]Loading trainS:  96%|█████████▌| 256/266 [02:04<00:04,  2.08it/s]Loading trainS:  97%|█████████▋| 257/266 [02:04<00:04,  2.04it/s]Loading trainS:  97%|█████████▋| 258/266 [02:04<00:03,  2.11it/s]Loading trainS:  97%|█████████▋| 259/266 [02:05<00:03,  2.18it/s]Loading trainS:  98%|█████████▊| 260/266 [02:05<00:02,  2.10it/s]Loading trainS:  98%|█████████▊| 261/266 [02:06<00:02,  2.10it/s]Loading trainS:  98%|█████████▊| 262/266 [02:06<00:01,  2.17it/s]Loading trainS:  99%|█████████▉| 263/266 [02:07<00:01,  2.15it/s]Loading trainS:  99%|█████████▉| 264/266 [02:07<00:00,  2.14it/s]Loading trainS: 100%|█████████▉| 265/266 [02:08<00:00,  2.20it/s]Loading trainS: 100%|██████████| 266/266 [02:08<00:00,  2.17it/s]Loading trainS: 100%|██████████| 266/266 [02:08<00:00,  2.07it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  2.11it/s]Loading testS:  50%|█████     | 2/4 [00:00<00:00,  2.19it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  2.12it/s]Loading testS: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]Loading testS: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]----------+++ 
CrossVal ['d']
CrossVal ['d']
(0/4) test vimp2_ANON988_CSFn2
(1/4) test vimp2_M_CSFn2
(2/4) test vimp2_N_CSFn2
(3/4) test vimp2_L_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 82s - loss: 0.0992 - acc: 0.9898 - mDice: 0.8069 - val_loss: 0.2698 - val_acc: 0.9912 - val_mDice: 0.4638

Epoch 00001: val_mDice improved from -inf to 0.46382, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 78s - loss: 0.0655 - acc: 0.9934 - mDice: 0.8724 - val_loss: 0.2257 - val_acc: 0.9922 - val_mDice: 0.4762

Epoch 00002: val_mDice improved from 0.46382 to 0.47617, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 79s - loss: 0.0583 - acc: 0.9940 - mDice: 0.8865 - val_loss: 0.1256 - val_acc: 0.9926 - val_mDice: 0.4644

Epoch 00003: val_mDice did not improve from 0.47617
Epoch 4/300
 - 81s - loss: 0.0540 - acc: 0.9944 - mDice: 0.8949 - val_loss: 0.1046 - val_acc: 0.9934 - val_mDice: 0.4842

Epoch 00004: val_mDice improved from 0.47617 to 0.48422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 82s - loss: 0.0504 - acc: 0.9947 - mDice: 0.9019 - val_loss: 0.0261 - val_acc: 0.9935 - val_mDice: 0.4810

Epoch 00005: val_mDice did not improve from 0.48422
Epoch 6/300
 - 81s - loss: 0.0487 - acc: 0.9949 - mDice: 0.9053 - val_loss: 0.2251 - val_acc: 0.9918 - val_mDice: 0.4757

Epoch 00006: val_mDice did not improve from 0.48422
Epoch 7/300
 - 82s - loss: 0.0474 - acc: 0.9951 - mDice: 0.9077 - val_loss: 0.0784 - val_acc: 0.9901 - val_mDice: 0.4168

Epoch 00007: val_mDice did not improve from 0.48422
Epoch 8/300
 - 82s - loss: 0.0448 - acc: 0.9952 - mDice: 0.9128 - val_loss: 0.1621 - val_acc: 0.9907 - val_mDice: 0.4462

Epoch 00008: val_mDice did not improve from 0.48422
Epoch 9/300
 - 82s - loss: 0.0441 - acc: 0.9952 - mDice: 0.9141 - val_loss: 0.0809 - val_acc: 0.9936 - val_mDice: 0.4964

Epoch 00009: val_mDice improved from 0.48422 to 0.49644, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 82s - loss: 0.0419 - acc: 0.9954 - mDice: 0.9185 - val_loss: 0.0981 - val_acc: 0.9937 - val_mDice: 0.4894

Epoch 00010: val_mDice did not improve from 0.49644
Epoch 11/300
 - 82s - loss: 0.0411 - acc: 0.9955 - mDice: 0.9201 - val_loss: 0.1009 - val_acc: 0.9936 - val_mDice: 0.4880

Epoch 00011: val_mDice did not improve from 0.49644
Epoch 12/300
 - 83s - loss: 0.0427 - acc: 0.9954 - mDice: 0.9169 - val_loss: 0.0964 - val_acc: 0.9935 - val_mDice: 0.4976

Epoch 00012: val_mDice improved from 0.49644 to 0.49758, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 13/300
 - 82s - loss: 0.0389 - acc: 0.9957 - mDice: 0.9243 - val_loss: 0.0130 - val_acc: 0.9935 - val_mDice: 0.4840

Epoch 00013: val_mDice did not improve from 0.49758
Epoch 14/300
 - 82s - loss: 0.0392 - acc: 0.9957 - mDice: 0.9237 - val_loss: 0.1030 - val_acc: 0.9929 - val_mDice: 0.5026

Epoch 00014: val_mDice improved from 0.49758 to 0.50256, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 15/300
 - 82s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9271 - val_loss: 0.1384 - val_acc: 0.9926 - val_mDice: 0.4954

Epoch 00015: val_mDice did not improve from 0.50256
Epoch 16/300
 - 82s - loss: 0.0378 - acc: 0.9958 - mDice: 0.9266 - val_loss: -2.3616e-03 - val_acc: 0.9939 - val_mDice: 0.4985

Epoch 00016: val_mDice did not improve from 0.50256
Epoch 17/300
 - 82s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9277 - val_loss: 0.0569 - val_acc: 0.9927 - val_mDice: 0.4590

Epoch 00017: val_mDice did not improve from 0.50256
Epoch 18/300
 - 82s - loss: 0.0363 - acc: 0.9958 - mDice: 0.9294 - val_loss: 0.0566 - val_acc: 0.9938 - val_mDice: 0.4980

Epoch 00018: val_mDice did not improve from 0.50256
Epoch 19/300
 - 82s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9297 - val_loss: 0.0586 - val_acc: 0.9938 - val_mDice: 0.4942

Epoch 00019: val_mDice did not improve from 0.50256
Epoch 20/300
 - 82s - loss: 0.0366 - acc: 0.9960 - mDice: 0.9288 - val_loss: 0.0621 - val_acc: 0.9934 - val_mDice: 0.4873

Epoch 00020: val_mDice did not improve from 0.50256
Epoch 21/300
 - 82s - loss: 0.0353 - acc: 0.9960 - mDice: 0.9314 - val_loss: -4.2698e-02 - val_acc: 0.9939 - val_mDice: 0.5008

Epoch 00021: val_mDice did not improve from 0.50256
Epoch 22/300
 - 82s - loss: 0.0358 - acc: 0.9960 - mDice: 0.9304 - val_loss: 0.0562 - val_acc: 0.9936 - val_mDice: 0.4981

Epoch 00022: val_mDice did not improve from 0.50256
Epoch 23/300
 - 82s - loss: 0.0344 - acc: 0.9961 - mDice: 0.9331 - val_loss: 0.1324 - val_acc: 0.9927 - val_mDice: 0.5044

Epoch 00023: val_mDice improved from 0.50256 to 0.50439, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 24/300
 - 82s - loss: 0.0339 - acc: 0.9961 - mDice: 0.9340 - val_loss: 0.0975 - val_acc: 0.9933 - val_mDice: 0.4948

Epoch 00024: val_mDice did not improve from 0.50439
Epoch 25/300
 - 82s - loss: 0.0353 - acc: 0.9960 - mDice: 0.9313 - val_loss: 0.1963 - val_acc: 0.9871 - val_mDice: 0.4585

Epoch 00025: val_mDice did not improve from 0.50439
Epoch 26/300
 - 82s - loss: 0.0340 - acc: 0.9961 - mDice: 0.9339 - val_loss: 0.0470 - val_acc: 0.9936 - val_mDice: 0.5174

Epoch 00026: val_mDice improved from 0.50439 to 0.51736, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 27/300
 - 82s - loss: 0.0326 - acc: 0.9962 - mDice: 0.9367 - val_loss: 0.1711 - val_acc: 0.9930 - val_mDice: 0.5049

Epoch 00027: val_mDice did not improve from 0.51736
Epoch 28/300
 - 82s - loss: 0.0327 - acc: 0.9962 - mDice: 0.9365 - val_loss: 0.0889 - val_acc: 0.9931 - val_mDice: 0.4995

Epoch 00028: val_mDice did not improve from 0.51736
Epoch 29/300
 - 82s - loss: 0.0328 - acc: 0.9961 - mDice: 0.9362 - val_loss: 0.0950 - val_acc: 0.9933 - val_mDice: 0.5001

Epoch 00029: val_mDice did not improve from 0.51736
Epoch 30/300
 - 82s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9368 - val_loss: 0.0655 - val_acc: 0.9936 - val_mDice: 0.4802

Epoch 00030: val_mDice did not improve from 0.51736
Epoch 31/300
 - 82s - loss: 0.0331 - acc: 0.9962 - mDice: 0.9357 - val_loss: -6.4815e-04 - val_acc: 0.9938 - val_mDice: 0.4948

Epoch 00031: val_mDice did not improve from 0.51736
Epoch 32/300
 - 82s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9368 - val_loss: 0.0630 - val_acc: 0.9934 - val_mDice: 0.4855

Epoch 00032: val_mDice did not improve from 0.51736
Epoch 33/300
 - 81s - loss: 0.0322 - acc: 0.9963 - mDice: 0.9373 - val_loss: -2.7467e-02 - val_acc: 0.9932 - val_mDice: 0.4702

Epoch 00033: val_mDice did not improve from 0.51736
Epoch 34/300
 - 81s - loss: 0.0319 - acc: 0.9963 - mDice: 0.9380 - val_loss: 0.0574 - val_acc: 0.9933 - val_mDice: 0.4967

Epoch 00034: val_mDice did not improve from 0.51736
Epoch 35/300
 - 81s - loss: 0.0313 - acc: 0.9963 - mDice: 0.9392 - val_loss: 0.0123 - val_acc: 0.9929 - val_mDice: 0.4686

Epoch 00035: val_mDice did not improve from 0.51736
Epoch 36/300
 - 81s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9395 - val_loss: 0.0655 - val_acc: 0.9929 - val_mDice: 0.4808

Epoch 00036: val_mDice did not improve from 0.51736
Epoch 37/300
 - 81s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9412 - val_loss: -2.4732e-03 - val_acc: 0.9921 - val_mDice: 0.4600

Epoch 00037: val_mDice did not improve from 0.51736
Epoch 38/300
 - 82s - loss: 0.0306 - acc: 0.9964 - mDice: 0.9406 - val_loss: -4.5270e-03 - val_acc: 0.9938 - val_mDice: 0.5044

Epoch 00038: val_mDice did not improve from 0.51736
Epoch 39/300
 - 82s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9368 - val_loss: 0.0359 - val_acc: 0.9936 - val_mDice: 0.5003

Epoch 00039: val_mDice did not improve from 0.51736
Epoch 40/300
 - 82s - loss: 0.0307 - acc: 0.9964 - mDice: 0.9404 - val_loss: 0.0253 - val_acc: 0.9937 - val_mDice: 0.4821

Epoch 00040: val_mDice did not improve from 0.51736
Epoch 41/300
 - 81s - loss: 0.0312 - acc: 0.9964 - mDice: 0.9395 - val_loss: 0.0543 - val_acc: 0.9935 - val_mDice: 0.5027

Epoch 00041: val_mDice did not improve from 0.51736

Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 42/300
 - 81s - loss: 0.0288 - acc: 0.9965 - mDice: 0.9441 - val_loss: 0.0523 - val_acc: 0.9934 - val_mDice: 0.5068

Epoch 00042: val_mDice did not improve from 0.51736
Epoch 43/300
 - 81s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9449 - val_loss: 0.0076 - val_acc: 0.9937 - val_mDice: 0.4783

Epoch 00043: val_mDice did not improve from 0.51736
Epoch 44/300
 - 81s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9439 - val_loss: 0.0241 - val_acc: 0.9937 - val_mDice: 0.4846

Epoch 00044: val_mDice did not improve from 0.51736
Epoch 45/300
 - 81s - loss: 0.0279 - acc: 0.9966 - mDice: 0.9459 - val_loss: -2.1244e-03 - val_acc: 0.9938 - val_mDice: 0.4977

Epoch 00045: val_mDice did not improve from 0.51736
Epoch 46/300
 - 81s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9466 - val_loss: -3.9361e-02 - val_acc: 0.9939 - val_mDice: 0.4937

Epoch 00046: val_mDice did not improve from 0.51736
Epoch 47/300
 - 81s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9464 - val_loss: 0.0212 - val_acc: 0.9935 - val_mDice: 0.4905

Epoch 00047: val_mDice did not improve from 0.51736
Epoch 48/300
 - 81s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9469 - val_loss: -1.3346e-02 - val_acc: 0.9937 - val_mDice: 0.4809

Epoch 00048: val_mDice did not improve from 0.51736
Epoch 49/300
 - 81s - loss: 0.0279 - acc: 0.9966 - mDice: 0.9458 - val_loss: -1.6842e-02 - val_acc: 0.9937 - val_mDice: 0.4880

Epoch 00049: val_mDice did not improve from 0.51736
Epoch 50/300
 - 81s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9473 - val_loss: -1.4179e-02 - val_acc: 0.9937 - val_mDice: 0.4826

Epoch 00050: val_mDice did not improve from 0.51736
Epoch 51/300
 - 81s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9481 - val_loss: -2.9097e-02 - val_acc: 0.9935 - val_mDice: 0.4733

Epoch 00051: val_mDice did not improve from 0.51736
Epoch 52/300
 - 81s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9472 - val_loss: -3.2787e-02 - val_acc: 0.9938 - val_mDice: 0.4806

Epoch 00052: val_mDice did not improve from 0.51736
Epoch 53/300
 - 81s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9469 - val_loss: 0.1142 - val_acc: 0.9927 - val_mDice: 0.4896

Epoch 00053: val_mDice did not improve from 0.51736
Epoch 54/300
 - 81s - loss: 0.0263 - acc: 0.9966 - mDice: 0.9490 - val_loss: -1.3572e-02 - val_acc: 0.9938 - val_mDice: 0.4809

Epoch 00054: val_mDice did not improve from 0.51736
Epoch 55/300
 - 81s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9472 - val_loss: 0.0575 - val_acc: 0.9933 - val_mDice: 0.4965

Epoch 00055: val_mDice did not improve from 0.51736
Epoch 56/300
 - 81s - loss: 0.0267 - acc: 0.9967 - mDice: 0.9483 - val_loss: -3.7477e-02 - val_acc: 0.9937 - val_mDice: 0.4900

Epoch 00056: val_mDice did not improve from 0.51736

Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 57/300
 - 81s - loss: 0.0262 - acc: 0.9967 - mDice: 0.9493 - val_loss: 0.0565 - val_acc: 0.9933 - val_mDice: 0.4985

Epoch 00057: val_mDice did not improve from 0.51736
Epoch 58/300
 - 81s - loss: 0.0258 - acc: 0.9967 - mDice: 0.9500 - val_loss: 0.0556 - val_acc: 0.9935 - val_mDice: 0.5000

Epoch 00058: val_mDice did not improve from 0.51736
Epoch 59/300
 - 81s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9504 - val_loss: -2.3434e-02 - val_acc: 0.9937 - val_mDice: 0.5012

Epoch 00059: val_mDice did not improve from 0.51736
Epoch 60/300
 - 81s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: 0.0280 - val_acc: 0.9935 - val_mDice: 0.4984

Epoch 00060: val_mDice did not improve from 0.51736
Epoch 61/300
 - 81s - loss: 0.0255 - acc: 0.9968 - mDice: 0.9505 - val_loss: -3.5417e-02 - val_acc: 0.9938 - val_mDice: 0.4858

Epoch 00061: val_mDice did not improve from 0.51736
Epoch 62/300
 - 81s - loss: 0.0254 - acc: 0.9968 - mDice: 0.9508 - val_loss: -1.9777e-02 - val_acc: 0.9937 - val_mDice: 0.4960

Epoch 00062: val_mDice did not improve from 0.51736
Epoch 63/300
 - 81s - loss: 0.0259 - acc: 0.9968 - mDice: 0.9497 - val_loss: 0.0202 - val_acc: 0.9936 - val_mDice: 0.4924

Epoch 00063: val_mDice did not improve from 0.51736
Epoch 64/300
 - 81s - loss: 0.0250 - acc: 0.9968 - mDice: 0.9515 - val_loss: 0.0054 - val_acc: 0.9937 - val_mDice: 0.4827

Epoch 00064: val_mDice did not improve from 0.51736
Epoch 65/300
 - 81s - loss: 0.0248 - acc: 0.9967 - mDice: 0.9520 - val_loss: 0.0011 - val_acc: 0.9938 - val_mDice: 0.4913

Epoch 00065: val_mDice did not improve from 0.51736
Epoch 66/300
 - 81s - loss: 0.0259 - acc: 0.9968 - mDice: 0.9497 - val_loss: 0.0199 - val_acc: 0.9935 - val_mDice: 0.4932

Epoch 00066: val_mDice did not improve from 0.51736
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
{'val_loss': [0.2698218390053394, 0.2256825464028938, 0.12559610955855427, 0.10463564974420211, 0.026134441296259563, 0.2251410279788223, 0.07842363212622848, 0.16205366452534994, 0.08088444319425844, 0.09813770418073617, 0.10086248026174657, 0.09637439835305307, 0.012970141336029651, 0.10300720351583817, 0.13840324387830846, -0.002361562322167789, 0.056893052423701566, 0.05660092217080733, 0.05857034232102189, 0.06208400983436435, -0.04269848647070866, 0.05616280231990066, 0.13235031360504673, 0.09752398787760268, 0.19625827261045867, 0.04701770082408307, 0.17108516804143495, 0.08886056700173546, 0.09495817124843597, 0.06548589117386762, -0.0006481549319098977, 0.06297487487979964, -0.02746708486594406, 0.05740706330420924, 0.012309569061971178, 0.06548567700619791, -0.0024731723116893393, -0.004527010461863349, 0.03585994944852941, 0.02530421141315909, 0.05433932998601128, 0.05230036056509205, 0.007557096726754133, 0.024121470311108756, -0.002124426703827054, -0.03936098253025728, 0.02119994718654483, -0.013346342187301786, -0.016841517651782316, -0.01417929372366737, -0.029097069127886902, -0.03278734841767479, 0.11416948396785587, -0.013571919471609826, 0.057510244203548805, -0.03747666641777637, 0.05646957866117066, 0.05564860035391415, -0.023433928104007944, 0.027974283286169462, -0.035417173715198744, -0.01977748847475239, 0.02020002463284661, 0.005376874231824688, 0.0010667563069100474, 0.01986598588672339], 'val_acc': [0.9911933763354432, 0.992201940686095, 0.9925882068334841, 0.9934296175545337, 0.9935451255125158, 0.9917705923903222, 0.9901068584591735, 0.9907135121962604, 0.9935679739596797, 0.993693188125012, 0.9935867611099692, 0.9934581038998622, 0.9934868999555999, 0.9929297204111137, 0.9925753754727981, 0.9939135546777763, 0.9926526897093829, 0.9937726995524239, 0.9938271618356892, 0.9933948727215037, 0.9938738018858666, 0.9935642176983404, 0.9927237594828886, 0.9933400902093625, 0.9871105960771149, 0.9935839363172942, 0.9929776121588314, 0.9930539925893148, 0.9932796826549605, 0.9936452940398571, 0.9937933543149162, 0.993447462717692, 0.9931547898872226, 0.9933397781615164, 0.9929459936478559, 0.9928630461879805, 0.9921133564967736, 0.9937607914793725, 0.9936452917024201, 0.9936565663300309, 0.9934693680090063, 0.9934217906465718, 0.9937360660702574, 0.9936997563231225, 0.9937611140456855, 0.9939129235697728, 0.9934887780862696, 0.9937182325942844, 0.9936844157237633, 0.9937323156525107, 0.9934612372342277, 0.9937955444934321, 0.9927431543668112, 0.9937698794346229, 0.9932665369089912, 0.9936922484753179, 0.993342283894034, 0.9934887850985807, 0.9936769067072401, 0.9935150765905193, 0.993750156140795, 0.9937294978721469, 0.9935861311706842, 0.9937085263869342, 0.9938418724957634, 0.9935078749469682], 'val_mDice': [0.4638155362769669, 0.4761708540951504, 0.4643623980821353, 0.4842248523936552, 0.48101493891547714, 0.47573747003779815, 0.4168370342823786, 0.44621003258462044, 0.4964377351251303, 0.4893862307071686, 0.48799543667283807, 0.49758463572053346, 0.4840120955463955, 0.5025646861861733, 0.4954423238249386, 0.4984852946272083, 0.45902491689604874, 0.4979972003721723, 0.49415224089342, 0.4873270907749732, 0.5007882281845691, 0.4981097687839293, 0.5043884965718961, 0.4947638815935409, 0.4584958009860095, 0.5173597195569206, 0.5049142133371503, 0.49954524460960836, 0.5000631258476014, 0.480246466127973, 0.4948466271162033, 0.4854992230733236, 0.4701697171903124, 0.49665331431463655, 0.4685947567808862, 0.48079613318630293, 0.46001040665592596, 0.5044306601379432, 0.5003300320868399, 0.48214738742977964, 0.5026658498773388, 0.5068385834787407, 0.4783256938404413, 0.4846116592879318, 0.4976903130026437, 0.49368686586910604, 0.49050772306965845, 0.48094170467526304, 0.4880380628393123, 0.4826344860814496, 0.4732543667076457, 0.48062506610271977, 0.48958485558921216, 0.4808944876068363, 0.496497796738849, 0.48999250738644134, 0.49845240455047757, 0.500044327521441, 0.5012287766346527, 0.49843060502818987, 0.48581235958080665, 0.4960424008907056, 0.49241893051886093, 0.4827418108196819, 0.4912763524289225, 0.4932163901188794], 'loss': [0.09919584762359712, 0.06551222220000087, 0.05829022717370053, 0.05395323957955852, 0.05040714405496503, 0.04865109079420093, 0.04738027639745428, 0.044830439699710935, 0.04413862210200528, 0.041881523574594626, 0.04109252866938851, 0.042672511279455004, 0.038914518158344374, 0.039204075494970826, 0.03750414425114944, 0.03775735985279526, 0.037192415695289215, 0.036307968302583246, 0.036133606170795855, 0.03657315692801723, 0.03530489170982952, 0.03577398882116021, 0.034394660443525835, 0.033938751443515824, 0.03531514055694463, 0.03403101705227851, 0.0325717027286406, 0.032704941411735855, 0.032828712558667476, 0.03252792887241366, 0.03308290844884896, 0.032491679254331086, 0.032246628367519695, 0.03192616054391664, 0.031310691666023405, 0.0311521193097875, 0.030293499922604345, 0.03055783468893357, 0.03250242576201088, 0.030692460445922477, 0.031150177067551785, 0.028802880554179018, 0.028371894114190287, 0.028854270611534002, 0.02787084846102838, 0.027521307807856065, 0.027636744257937954, 0.027335594570180886, 0.027928847446670204, 0.02714144885159546, 0.02673522812335246, 0.027189157501547042, 0.02735450320382047, 0.026316285743831252, 0.027208972840537974, 0.026664806178924496, 0.026152721770972002, 0.025779757426265554, 0.025549726226834366, 0.025415170960042272, 0.02548923924446853, 0.02535185427803507, 0.025905583404674273, 0.025037269934908967, 0.024765445396882607, 0.025902399095788627], 'acc': [0.9898397472567037, 0.9933889490158111, 0.9939957946748179, 0.9944408637056609, 0.9946985996475778, 0.9948649158302355, 0.9950719751650671, 0.9951680404756832, 0.9952324933995499, 0.9954034979701879, 0.9954688542020484, 0.9954097272971651, 0.995650061377174, 0.9956671677130758, 0.9957262976236132, 0.9957671742143754, 0.9958099183539302, 0.9958358925971471, 0.995919641439577, 0.9959602770592023, 0.9959992088914879, 0.9959791150668892, 0.9960740046548752, 0.996112147477031, 0.9959905610817512, 0.9960846160767367, 0.9961897919017938, 0.9961764107506986, 0.9961335649135074, 0.9962209040598564, 0.9962011584484078, 0.9962466253439078, 0.9962937311232972, 0.9962916834739152, 0.9963071175974092, 0.9963362104125026, 0.9963498190594433, 0.9963661693678587, 0.9962371987930712, 0.9963580352655589, 0.9963540430513903, 0.9964715767597104, 0.9965297720398109, 0.9965289287618881, 0.9965623379071867, 0.9965653819153232, 0.9965847803719992, 0.9966067676479718, 0.9965925752193121, 0.9966283889570288, 0.9966356194504234, 0.9966387966135308, 0.9966334899670082, 0.9966220437895849, 0.9966470003197226, 0.9966676449606908, 0.9967227133713727, 0.9967042547055892, 0.9967224300893428, 0.9967484522846747, 0.9967628065828507, 0.9967529777205496, 0.9967533436736303, 0.9967507875602769, 0.9967487683971629, 0.9967694808054266], 'mDice': [0.8069279696891091, 0.8723675525261771, 0.8864877210717168, 0.8949215397820666, 0.9018693459101066, 0.9052981499055456, 0.9077225901453014, 0.9127604672520434, 0.9141099656727395, 0.9185348312337891, 0.9200754132099536, 0.9169456391034175, 0.9243192676049893, 0.9237358910980775, 0.9271011817602635, 0.9265791141813218, 0.9276843439859611, 0.929433902708824, 0.9297440238718521, 0.9288446707221377, 0.9313571127971949, 0.9304303557125129, 0.9331269773141718, 0.934023214525848, 0.9313474630065051, 0.9338558041709759, 0.9367108732757653, 0.9364562679214237, 0.9362275277524417, 0.9367814419758352, 0.9356842416947201, 0.9368432726377481, 0.9373071460606833, 0.9379515316366963, 0.9391756159979918, 0.9394719673484185, 0.9411806442993111, 0.940649574817607, 0.9368395639792831, 0.9403803059528081, 0.9394634928601205, 0.9440926590031121, 0.9449262120059312, 0.9439448553397856, 0.9459070820232321, 0.9466010405433052, 0.9463575069739553, 0.9469496642298785, 0.9457685818164713, 0.9473296851585533, 0.9481289673825547, 0.947226446040002, 0.9468930426327646, 0.9489680683834876, 0.9471709632571932, 0.9482570440052681, 0.9492510584014585, 0.949994047267213, 0.950444799266993, 0.9507041791737034, 0.9505489081056134, 0.9508315348579528, 0.9497135109905025, 0.9514523971615503, 0.9519967538408551, 0.949715830137952], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.12it/s]predicting test subjects:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  1.82it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:41,  6.40it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:40,  6.49it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:40,  6.46it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:41,  6.36it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:40,  6.43it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:40,  6.48it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:39,  6.51it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:39,  6.50it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:39,  6.51it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:40,  6.25it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:40,  6.36it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:39,  6.36it/s]predicting train subjects:   5%|▍         | 13/266 [00:02<00:39,  6.43it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:39,  6.46it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:38,  6.50it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:39,  6.32it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:39,  6.37it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:38,  6.44it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:37,  6.50it/s]predicting train subjects:   8%|▊         | 20/266 [00:03<00:37,  6.56it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:37,  6.60it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:36,  6.60it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:36,  6.70it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:35,  6.78it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:35,  6.85it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:34,  6.89it/s]predicting train subjects:  10%|█         | 27/266 [00:04<00:34,  6.93it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:34,  6.95it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:34,  6.93it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:33,  6.95it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:33,  6.96it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:33,  6.90it/s]predicting train subjects:  12%|█▏        | 33/266 [00:04<00:33,  6.86it/s]predicting train subjects:  13%|█▎        | 34/266 [00:05<00:33,  6.84it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:33,  6.86it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:33,  6.89it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:33,  6.89it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:33,  6.90it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:32,  6.91it/s]predicting train subjects:  15%|█▌        | 40/266 [00:06<00:32,  6.87it/s]predicting train subjects:  15%|█▌        | 41/266 [00:06<00:32,  6.89it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:32,  6.84it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:34,  6.52it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:33,  6.63it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:32,  6.73it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:32,  6.80it/s]predicting train subjects:  18%|█▊        | 47/266 [00:07<00:31,  6.85it/s]predicting train subjects:  18%|█▊        | 48/266 [00:07<00:31,  6.85it/s]predicting train subjects:  18%|█▊        | 49/266 [00:07<00:31,  6.85it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:31,  6.86it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:31,  6.88it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:31,  6.89it/s]predicting train subjects:  20%|█▉        | 53/266 [00:07<00:30,  6.89it/s]predicting train subjects:  20%|██        | 54/266 [00:08<00:30,  6.91it/s]predicting train subjects:  21%|██        | 55/266 [00:08<00:31,  6.69it/s]predicting train subjects:  21%|██        | 56/266 [00:08<00:31,  6.76it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:30,  6.79it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:30,  6.84it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:30,  6.76it/s]predicting train subjects:  23%|██▎       | 60/266 [00:08<00:30,  6.65it/s]predicting train subjects:  23%|██▎       | 61/266 [00:09<00:31,  6.59it/s]predicting train subjects:  23%|██▎       | 62/266 [00:09<00:31,  6.58it/s]predicting train subjects:  24%|██▎       | 63/266 [00:09<00:31,  6.53it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:30,  6.54it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:30,  6.49it/s]predicting train subjects:  25%|██▍       | 66/266 [00:09<00:30,  6.48it/s]predicting train subjects:  25%|██▌       | 67/266 [00:10<00:30,  6.47it/s]predicting train subjects:  26%|██▌       | 68/266 [00:10<00:30,  6.47it/s]predicting train subjects:  26%|██▌       | 69/266 [00:10<00:30,  6.48it/s]predicting train subjects:  26%|██▋       | 70/266 [00:10<00:30,  6.47it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:30,  6.47it/s]predicting train subjects:  27%|██▋       | 72/266 [00:10<00:30,  6.46it/s]predicting train subjects:  27%|██▋       | 73/266 [00:10<00:30,  6.43it/s]predicting train subjects:  28%|██▊       | 74/266 [00:11<00:29,  6.41it/s]predicting train subjects:  28%|██▊       | 75/266 [00:11<00:29,  6.44it/s]predicting train subjects:  29%|██▊       | 76/266 [00:11<00:29,  6.41it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:34,  5.50it/s]predicting train subjects:  29%|██▉       | 78/266 [00:11<00:37,  5.03it/s]predicting train subjects:  30%|██▉       | 79/266 [00:12<00:43,  4.34it/s]predicting train subjects:  30%|███       | 80/266 [00:12<00:48,  3.87it/s]predicting train subjects:  30%|███       | 81/266 [00:12<00:43,  4.23it/s]predicting train subjects:  31%|███       | 82/266 [00:12<00:40,  4.54it/s]predicting train subjects:  31%|███       | 83/266 [00:13<00:38,  4.79it/s]predicting train subjects:  32%|███▏      | 84/266 [00:13<00:36,  4.98it/s]predicting train subjects:  32%|███▏      | 85/266 [00:13<00:35,  5.17it/s]predicting train subjects:  32%|███▏      | 86/266 [00:13<00:33,  5.30it/s]predicting train subjects:  33%|███▎      | 87/266 [00:13<00:33,  5.42it/s]predicting train subjects:  33%|███▎      | 88/266 [00:13<00:32,  5.47it/s]predicting train subjects:  33%|███▎      | 89/266 [00:14<00:32,  5.51it/s]predicting train subjects:  34%|███▍      | 90/266 [00:14<00:31,  5.54it/s]predicting train subjects:  34%|███▍      | 91/266 [00:14<00:31,  5.55it/s]predicting train subjects:  35%|███▍      | 92/266 [00:14<00:31,  5.59it/s]predicting train subjects:  35%|███▍      | 93/266 [00:14<00:30,  5.60it/s]predicting train subjects:  35%|███▌      | 94/266 [00:15<00:30,  5.60it/s]predicting train subjects:  36%|███▌      | 95/266 [00:15<00:30,  5.64it/s]predicting train subjects:  36%|███▌      | 96/266 [00:15<00:30,  5.63it/s]predicting train subjects:  36%|███▋      | 97/266 [00:15<00:30,  5.61it/s]predicting train subjects:  37%|███▋      | 98/266 [00:15<00:29,  5.62it/s]predicting train subjects:  37%|███▋      | 99/266 [00:15<00:29,  5.64it/s]predicting train subjects:  38%|███▊      | 100/266 [00:16<00:29,  5.67it/s]predicting train subjects:  38%|███▊      | 101/266 [00:16<00:28,  5.72it/s]predicting train subjects:  38%|███▊      | 102/266 [00:16<00:28,  5.76it/s]predicting train subjects:  39%|███▊      | 103/266 [00:16<00:28,  5.78it/s]predicting train subjects:  39%|███▉      | 104/266 [00:16<00:27,  5.81it/s]predicting train subjects:  39%|███▉      | 105/266 [00:16<00:27,  5.81it/s]predicting train subjects:  40%|███▉      | 106/266 [00:17<00:27,  5.82it/s]predicting train subjects:  40%|████      | 107/266 [00:17<00:27,  5.84it/s]predicting train subjects:  41%|████      | 108/266 [00:17<00:27,  5.85it/s]predicting train subjects:  41%|████      | 109/266 [00:17<00:27,  5.76it/s]predicting train subjects:  41%|████▏     | 110/266 [00:17<00:26,  5.79it/s]predicting train subjects:  42%|████▏     | 111/266 [00:18<00:26,  5.82it/s]predicting train subjects:  42%|████▏     | 112/266 [00:18<00:26,  5.83it/s]predicting train subjects:  42%|████▏     | 113/266 [00:18<00:26,  5.85it/s]predicting train subjects:  43%|████▎     | 114/266 [00:18<00:25,  5.86it/s]predicting train subjects:  43%|████▎     | 115/266 [00:18<00:25,  5.88it/s]predicting train subjects:  44%|████▎     | 116/266 [00:18<00:25,  5.87it/s]predicting train subjects:  44%|████▍     | 117/266 [00:19<00:25,  5.87it/s]predicting train subjects:  44%|████▍     | 118/266 [00:19<00:24,  6.16it/s]predicting train subjects:  45%|████▍     | 119/266 [00:19<00:23,  6.32it/s]predicting train subjects:  45%|████▌     | 120/266 [00:19<00:22,  6.49it/s]predicting train subjects:  45%|████▌     | 121/266 [00:19<00:21,  6.62it/s]predicting train subjects:  46%|████▌     | 122/266 [00:19<00:21,  6.75it/s]predicting train subjects:  46%|████▌     | 123/266 [00:19<00:20,  6.83it/s]predicting train subjects:  47%|████▋     | 124/266 [00:20<00:20,  6.88it/s]predicting train subjects:  47%|████▋     | 125/266 [00:20<00:20,  6.93it/s]predicting train subjects:  47%|████▋     | 126/266 [00:20<00:20,  6.99it/s]predicting train subjects:  48%|████▊     | 127/266 [00:20<00:19,  7.06it/s]predicting train subjects:  48%|████▊     | 128/266 [00:20<00:19,  7.03it/s]predicting train subjects:  48%|████▊     | 129/266 [00:20<00:19,  7.07it/s]predicting train subjects:  49%|████▉     | 130/266 [00:20<00:19,  7.07it/s]predicting train subjects:  49%|████▉     | 131/266 [00:21<00:19,  7.10it/s]predicting train subjects:  50%|████▉     | 132/266 [00:21<00:18,  7.09it/s]predicting train subjects:  50%|█████     | 133/266 [00:21<00:18,  7.07it/s]predicting train subjects:  50%|█████     | 134/266 [00:21<00:18,  7.08it/s]predicting train subjects:  51%|█████     | 135/266 [00:21<00:18,  7.10it/s]predicting train subjects:  51%|█████     | 136/266 [00:21<00:18,  7.06it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:21<00:18,  7.01it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:22<00:18,  6.99it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:22<00:18,  6.98it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:22<00:18,  6.97it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:22<00:18,  6.94it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:22<00:17,  6.89it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:22<00:17,  6.86it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:22<00:17,  6.86it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:23<00:17,  6.89it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:23<00:17,  6.90it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:23<00:17,  6.90it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:23<00:17,  6.93it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:23<00:16,  6.96it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:23<00:16,  6.84it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:23<00:16,  6.81it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:24<00:16,  6.84it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:24<00:16,  6.76it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:24<00:17,  6.38it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:24<00:17,  6.19it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:24<00:18,  5.83it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:24<00:18,  5.84it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:25<00:18,  5.83it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:25<00:18,  5.85it/s]predicting train subjects:  60%|██████    | 160/266 [00:25<00:18,  5.85it/s]predicting train subjects:  61%|██████    | 161/266 [00:25<00:18,  5.83it/s]predicting train subjects:  61%|██████    | 162/266 [00:25<00:17,  5.84it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:25<00:17,  5.85it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:26<00:17,  5.88it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:26<00:17,  5.87it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:26<00:16,  5.90it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:26<00:16,  5.92it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:26<00:16,  5.92it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:26<00:16,  5.89it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:27<00:16,  5.88it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:27<00:16,  5.92it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:27<00:15,  6.12it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:27<00:17,  5.28it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:27<00:17,  5.14it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:28<00:19,  4.63it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:28<00:17,  5.14it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:28<00:16,  5.54it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:28<00:15,  5.81it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:28<00:14,  6.08it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:28<00:13,  6.25it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:29<00:13,  6.39it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:29<00:12,  6.49it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:29<00:12,  6.56it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:29<00:12,  6.62it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:29<00:12,  6.66it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:29<00:11,  6.67it/s]predicting train subjects:  70%|███████   | 187/266 [00:29<00:11,  6.69it/s]predicting train subjects:  71%|███████   | 188/266 [00:30<00:11,  6.65it/s]predicting train subjects:  71%|███████   | 189/266 [00:30<00:11,  6.69it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:30<00:11,  6.59it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:30<00:12,  6.17it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:30<00:11,  6.33it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:30<00:11,  6.41it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:31<00:11,  6.47it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:31<00:11,  6.20it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:31<00:11,  6.01it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:31<00:11,  5.91it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:31<00:11,  5.85it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:31<00:11,  5.79it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:32<00:11,  5.77it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:32<00:11,  5.70it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:32<00:11,  5.73it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:32<00:11,  5.71it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:32<00:10,  5.74it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:32<00:10,  5.69it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:33<00:10,  5.67it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:33<00:10,  5.69it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:33<00:10,  5.71it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:33<00:09,  5.71it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:33<00:09,  5.72it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:34<00:09,  5.72it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:34<00:09,  5.74it/s]predicting train subjects:  80%|████████  | 213/266 [00:34<00:08,  5.89it/s]predicting train subjects:  80%|████████  | 214/266 [00:34<00:08,  6.02it/s]predicting train subjects:  81%|████████  | 215/266 [00:34<00:08,  6.12it/s]predicting train subjects:  81%|████████  | 216/266 [00:34<00:08,  6.17it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:34<00:07,  6.21it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:35<00:07,  6.26it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:35<00:07,  6.26it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:35<00:07,  6.27it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:35<00:07,  6.28it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:35<00:06,  6.29it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:35<00:06,  6.27it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:36<00:06,  6.28it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:36<00:06,  6.29it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:36<00:06,  6.10it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:36<00:06,  6.16it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:36<00:06,  6.17it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:36<00:05,  6.20it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:37<00:05,  6.23it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:37<00:05,  6.52it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:37<00:04,  6.81it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:37<00:04,  7.03it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:37<00:04,  7.22it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:37<00:04,  7.37it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:37<00:04,  7.43it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:38<00:03,  7.50it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:38<00:03,  7.52it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:38<00:03,  7.58it/s]predicting train subjects:  90%|█████████ | 240/266 [00:38<00:03,  7.62it/s]predicting train subjects:  91%|█████████ | 241/266 [00:38<00:03,  7.64it/s]predicting train subjects:  91%|█████████ | 242/266 [00:38<00:03,  7.64it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:38<00:02,  7.68it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:38<00:02,  7.68it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:39<00:02,  7.71it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:39<00:02,  7.74it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:39<00:02,  7.75it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:39<00:02,  7.72it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:39<00:02,  7.42it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:39<00:02,  7.26it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:39<00:02,  7.15it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:40<00:01,  7.08it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:40<00:01,  7.03it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:40<00:01,  7.00it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:40<00:01,  6.95it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:40<00:01,  6.90it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:40<00:01,  6.90it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:40<00:01,  6.88it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:41<00:01,  6.91it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:41<00:00,  6.79it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:41<00:00,  6.60it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:41<00:00,  6.68it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:41<00:00,  6.77it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:41<00:00,  6.82it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:41<00:00,  6.86it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.87it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.32it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  6.18it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  6.25it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  6.36it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.24it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.28it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:43,  6.04it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:42,  6.17it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:41,  6.34it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:41,  6.32it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:41,  6.22it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:41,  6.33it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:01<00:40,  6.40it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:01<00:39,  6.50it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:39,  6.55it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:38,  6.58it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:38,  6.62it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:38,  6.65it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:01<00:37,  6.67it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:02<00:37,  6.68it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:02<00:37,  6.68it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:02<00:37,  6.71it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:37,  6.70it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:37,  6.69it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:36,  6.71it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:03<00:37,  6.60it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:03<00:36,  6.63it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:03<00:36,  6.64it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:03<00:36,  6.64it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:03<00:36,  6.71it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:35,  6.80it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:03<00:34,  6.87it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:04<00:34,  6.89it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:04<00:34,  6.83it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:04<00:34,  6.87it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:04<00:34,  6.91it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:04<00:33,  6.92it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:04<00:33,  6.95it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:04<00:33,  6.90it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:05<00:33,  6.93it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:05<00:33,  6.94it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:05<00:33,  6.96it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:05<00:32,  6.98it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:05<00:32,  6.97it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:05<00:32,  6.94it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:05<00:32,  6.94it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:06<00:32,  6.95it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:06<00:32,  6.96it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:06<00:32,  6.96it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:06<00:32,  6.86it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:06<00:32,  6.79it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:06<00:32,  6.84it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:06<00:31,  6.91it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:07<00:31,  6.95it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:07<00:31,  6.91it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:07<00:31,  6.92it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:07<00:31,  6.93it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:07<00:30,  6.94it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:07<00:30,  6.95it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:07<00:30,  6.94it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:08<00:30,  6.93it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:08<00:30,  6.90it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:08<00:30,  6.92it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:08<00:30,  6.92it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:08<00:30,  6.77it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:08<00:30,  6.68it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:09<00:31,  6.44it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:09<00:31,  6.48it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:09<00:31,  6.52it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:09<00:30,  6.55it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:09<00:30,  6.55it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:09<00:30,  6.54it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:09<00:30,  6.52it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:10<00:30,  6.49it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:10<00:30,  6.46it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:10<00:30,  6.45it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:10<00:30,  6.45it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:10<00:30,  6.45it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:10<00:29,  6.45it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:11<00:29,  6.45it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:11<00:29,  6.42it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:11<00:29,  6.43it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:11<00:31,  6.08it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:11<00:31,  5.96it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:11<00:29,  6.26it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:11<00:29,  6.33it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:12<00:30,  6.05it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:12<00:32,  5.73it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:12<00:32,  5.69it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:12<00:32,  5.66it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:12<00:32,  5.64it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:13<00:32,  5.58it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:13<00:32,  5.54it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:13<00:32,  5.46it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:13<00:32,  5.50it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:13<00:31,  5.55it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:13<00:31,  5.57it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:14<00:31,  5.56it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:14<00:30,  5.58it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:14<00:31,  5.55it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:14<00:30,  5.55it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:14<00:30,  5.58it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:15<00:30,  5.61it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:15<00:29,  5.62it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:15<00:29,  5.63it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:15<00:29,  5.67it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:15<00:28,  5.69it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:15<00:28,  5.71it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:16<00:29,  5.57it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:16<00:28,  5.60it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:16<00:28,  5.64it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:16<00:28,  5.61it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:16<00:28,  5.65it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:17<00:28,  5.59it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:17<00:28,  5.60it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:17<00:27,  5.66it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:17<00:27,  5.69it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:17<00:27,  5.69it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:17<00:26,  5.73it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:18<00:26,  5.76it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:18<00:26,  5.77it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:18<00:25,  5.79it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:18<00:25,  5.77it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:18<00:24,  6.07it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:18<00:23,  6.36it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:19<00:22,  6.55it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:19<00:21,  6.72it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:19<00:21,  6.85it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:19<00:20,  6.94it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:19<00:20,  7.02it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:19<00:19,  7.07it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:19<00:19,  7.10it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:19<00:19,  7.08it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:20<00:19,  7.10it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:20<00:19,  7.10it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:20<00:19,  7.07it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:20<00:19,  7.06it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:20<00:18,  7.06it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:20<00:18,  7.08it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:20<00:18,  7.07it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:21<00:19,  6.85it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:21<00:18,  6.86it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:21<00:18,  6.80it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:21<00:18,  6.86it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:21<00:18,  6.91it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:21<00:18,  6.92it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:22<00:18,  6.92it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:22<00:17,  6.94it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:22<00:17,  6.96it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:22<00:17,  6.95it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:22<00:17,  6.94it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:22<00:17,  6.94it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:22<00:17,  6.95it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:23<00:16,  6.95it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:23<00:16,  6.96it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:23<00:16,  6.95it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:23<00:16,  6.92it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:23<00:16,  6.94it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:23<00:16,  6.96it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:23<00:17,  6.58it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:24<00:17,  6.35it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:24<00:17,  6.24it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:24<00:17,  6.15it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:24<00:17,  6.09it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:24<00:17,  6.05it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:24<00:17,  5.97it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:25<00:17,  5.92it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:25<00:17,  5.91it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:25<00:17,  5.91it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:25<00:17,  5.90it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:25<00:17,  5.85it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:25<00:17,  5.83it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:26<00:16,  5.86it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:26<00:16,  5.89it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:26<00:16,  5.90it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:26<00:16,  5.92it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:26<00:16,  5.93it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:26<00:15,  6.06it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:27<00:15,  5.82it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:27<00:15,  5.85it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:27<00:14,  6.20it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:27<00:14,  6.19it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:27<00:14,  6.32it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:27<00:13,  6.42it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:28<00:13,  6.48it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:28<00:13,  6.59it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:28<00:12,  6.57it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:28<00:12,  6.65it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:28<00:12,  6.70it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:28<00:12,  6.73it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:28<00:12,  6.74it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:29<00:11,  6.73it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:29<00:11,  6.71it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:29<00:11,  6.69it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:29<00:11,  6.67it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:29<00:11,  6.68it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:29<00:11,  6.69it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:29<00:11,  6.69it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:30<00:10,  6.71it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:30<00:10,  6.71it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:30<00:11,  6.33it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:30<00:11,  6.11it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:30<00:11,  5.95it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:30<00:11,  5.83it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:31<00:11,  5.76it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:31<00:11,  5.73it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:31<00:11,  5.71it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:31<00:11,  5.70it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:31<00:11,  5.68it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:32<00:10,  5.67it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:32<00:10,  5.64it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:32<00:10,  5.63it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:32<00:10,  5.62it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:32<00:10,  5.63it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:32<00:10,  5.64it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:33<00:09,  5.65it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:33<00:09,  5.62it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:33<00:09,  5.60it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:33<00:09,  5.76it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:33<00:08,  5.81it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:33<00:08,  5.91it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:34<00:08,  6.00it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:34<00:08,  6.07it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:34<00:07,  6.09it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:34<00:07,  6.13it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:34<00:07,  6.15it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:34<00:07,  6.17it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:35<00:07,  6.14it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:35<00:06,  6.16it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:35<00:06,  6.17it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:35<00:06,  6.14it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:35<00:06,  6.15it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:35<00:06,  6.15it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:36<00:06,  6.14it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:36<00:06,  6.13it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:36<00:05,  6.11it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:36<00:05,  6.45it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:36<00:05,  6.73it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:36<00:04,  6.97it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:36<00:04,  7.11it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:37<00:04,  7.22it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:37<00:04,  7.32it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:37<00:03,  7.39it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:37<00:03,  7.43it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:37<00:03,  7.45it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:37<00:03,  7.49it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:37<00:03,  7.27it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:38<00:03,  7.33it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:38<00:03,  7.35it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:38<00:02,  7.42it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:38<00:02,  7.40it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:38<00:02,  7.37it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:38<00:02,  7.42it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:38<00:02,  7.45it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:38<00:02,  7.18it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:39<00:02,  6.95it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:39<00:02,  6.80it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:39<00:02,  6.55it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:39<00:02,  6.43it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:39<00:01,  6.02it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:39<00:01,  6.21it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:40<00:01,  6.35it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:40<00:01,  6.48it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:40<00:01,  6.59it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:40<00:01,  6.66it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:40<00:00,  6.71it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:40<00:00,  6.73it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:40<00:00,  6.68it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:41<00:00,  6.71it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:41<00:00,  6.75it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:41<00:00,  6.75it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:41<00:00,  6.74it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:41<00:00,  6.40it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 73.71it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/266 [00:00<00:03, 77.98it/s]saving BB  train1-THALAMUS:   6%|▌         | 16/266 [00:00<00:03, 78.02it/s]saving BB  train1-THALAMUS:   9%|▉         | 24/266 [00:00<00:03, 78.01it/s]saving BB  train1-THALAMUS:  12%|█▏        | 33/266 [00:00<00:02, 79.54it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:02, 81.41it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:02, 83.13it/s]saving BB  train1-THALAMUS:  23%|██▎       | 60/266 [00:00<00:02, 83.40it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 80.88it/s]saving BB  train1-THALAMUS:  29%|██▊       | 76/266 [00:00<00:02, 80.11it/s]saving BB  train1-THALAMUS:  32%|███▏      | 84/266 [00:01<00:02, 77.70it/s]saving BB  train1-THALAMUS:  35%|███▍      | 92/266 [00:01<00:02, 74.34it/s]saving BB  train1-THALAMUS:  38%|███▊      | 100/266 [00:01<00:02, 68.96it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:01<00:02, 69.11it/s]saving BB  train1-THALAMUS:  43%|████▎     | 115/266 [00:01<00:02, 70.46it/s]saving BB  train1-THALAMUS:  46%|████▌     | 123/266 [00:01<00:01, 72.26it/s]saving BB  train1-THALAMUS:  49%|████▉     | 131/266 [00:01<00:01, 74.21it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 140/266 [00:01<00:01, 76.37it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:01<00:01, 78.65it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 78.15it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 165/266 [00:02<00:01, 76.70it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 173/266 [00:02<00:01, 75.76it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 181/266 [00:02<00:01, 75.86it/s]saving BB  train1-THALAMUS:  71%|███████   | 189/266 [00:02<00:01, 76.15it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 197/266 [00:02<00:00, 75.02it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 205/266 [00:02<00:00, 74.28it/s]saving BB  train1-THALAMUS:  80%|████████  | 213/266 [00:02<00:00, 73.47it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 221/266 [00:02<00:00, 73.57it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 229/266 [00:03<00:00, 72.62it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 75.65it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 78.65it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 256/266 [00:03<00:00, 80.56it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 265/266 [00:03<00:00, 81.78it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 77.06it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 75.61it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 76.58it/s]saving BB  train1-THALAMUS Sagittal:   6%|▌         | 16/266 [00:00<00:03, 76.95it/s]saving BB  train1-THALAMUS Sagittal:   9%|▉         | 24/266 [00:00<00:03, 76.96it/s]saving BB  train1-THALAMUS Sagittal:  12%|█▏        | 33/266 [00:00<00:02, 79.58it/s]saving BB  train1-THALAMUS Sagittal:  16%|█▌        | 42/266 [00:00<00:02, 79.00it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 52/266 [00:00<00:02, 82.51it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 61/266 [00:00<00:02, 82.38it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 69/266 [00:00<00:02, 79.70it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 77/266 [00:00<00:02, 78.40it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 85/266 [00:01<00:02, 77.07it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 93/266 [00:01<00:02, 74.47it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 101/266 [00:01<00:02, 73.44it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 109/266 [00:01<00:02, 74.32it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▍     | 117/266 [00:01<00:01, 75.36it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 126/266 [00:01<00:01, 77.29it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 135/266 [00:01<00:01, 79.19it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 144/266 [00:01<00:01, 82.15it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:01<00:01, 84.30it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████▏   | 163/266 [00:02<00:01, 82.20it/s]saving BB  train1-THALAMUS Sagittal:  65%|██████▍   | 172/266 [00:02<00:01, 79.72it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 181/266 [00:02<00:01, 78.75it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 189/266 [00:02<00:00, 78.68it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 197/266 [00:02<00:00, 78.54it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 205/266 [00:02<00:00, 77.88it/s]saving BB  train1-THALAMUS Sagittal:  80%|████████  | 213/266 [00:02<00:00, 77.61it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 221/266 [00:02<00:00, 77.41it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 229/266 [00:02<00:00, 76.81it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 238/266 [00:03<00:00, 80.03it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 247/266 [00:03<00:00, 82.61it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 256/266 [00:03<00:00, 84.63it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 86.29it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 79.99it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:38,  1.21it/s]Loading train:   1%|          | 2/266 [00:01<03:31,  1.25it/s]Loading train:   1%|          | 3/266 [00:02<03:23,  1.29it/s]Loading train:   2%|▏         | 4/266 [00:03<03:33,  1.23it/s]Loading train:   2%|▏         | 5/266 [00:03<03:11,  1.36it/s]Loading train:   2%|▏         | 6/266 [00:04<02:53,  1.50it/s]Loading train:   3%|▎         | 7/266 [00:04<02:40,  1.62it/s]Loading train:   3%|▎         | 8/266 [00:05<02:29,  1.72it/s]Loading train:   3%|▎         | 9/266 [00:05<02:24,  1.78it/s]Loading train:   4%|▍         | 10/266 [00:06<02:20,  1.82it/s]Loading train:   4%|▍         | 11/266 [00:06<02:16,  1.86it/s]Loading train:   5%|▍         | 12/266 [00:07<02:19,  1.82it/s]Loading train:   5%|▍         | 13/266 [00:07<02:20,  1.80it/s]Loading train:   5%|▌         | 14/266 [00:08<02:16,  1.84it/s]Loading train:   6%|▌         | 15/266 [00:08<02:13,  1.88it/s]Loading train:   6%|▌         | 16/266 [00:09<02:11,  1.90it/s]Loading train:   6%|▋         | 17/266 [00:09<02:10,  1.91it/s]Loading train:   7%|▋         | 18/266 [00:10<02:07,  1.94it/s]Loading train:   7%|▋         | 19/266 [00:10<02:05,  1.96it/s]Loading train:   8%|▊         | 20/266 [00:11<02:06,  1.94it/s]Loading train:   8%|▊         | 21/266 [00:12<02:08,  1.91it/s]Loading train:   8%|▊         | 22/266 [00:12<02:07,  1.91it/s]Loading train:   9%|▊         | 23/266 [00:13<02:05,  1.94it/s]Loading train:   9%|▉         | 24/266 [00:13<02:01,  1.99it/s]Loading train:   9%|▉         | 25/266 [00:14<01:59,  2.02it/s]Loading train:  10%|▉         | 26/266 [00:14<01:56,  2.06it/s]Loading train:  10%|█         | 27/266 [00:14<01:55,  2.07it/s]Loading train:  11%|█         | 28/266 [00:15<01:55,  2.06it/s]Loading train:  11%|█         | 29/266 [00:15<01:56,  2.04it/s]Loading train:  11%|█▏        | 30/266 [00:16<01:55,  2.05it/s]Loading train:  12%|█▏        | 31/266 [00:16<01:56,  2.02it/s]Loading train:  12%|█▏        | 32/266 [00:17<01:58,  1.98it/s]Loading train:  12%|█▏        | 33/266 [00:17<01:58,  1.96it/s]Loading train:  13%|█▎        | 34/266 [00:18<01:57,  1.98it/s]Loading train:  13%|█▎        | 35/266 [00:18<01:54,  2.01it/s]Loading train:  14%|█▎        | 36/266 [00:19<01:55,  1.99it/s]Loading train:  14%|█▍        | 37/266 [00:19<01:54,  2.01it/s]Loading train:  14%|█▍        | 38/266 [00:20<01:52,  2.02it/s]Loading train:  15%|█▍        | 39/266 [00:20<01:53,  2.01it/s]Loading train:  15%|█▌        | 40/266 [00:21<01:54,  1.97it/s]Loading train:  15%|█▌        | 41/266 [00:21<01:52,  2.00it/s]Loading train:  16%|█▌        | 42/266 [00:22<01:50,  2.03it/s]Loading train:  16%|█▌        | 43/266 [00:22<01:47,  2.07it/s]Loading train:  17%|█▋        | 44/266 [00:23<01:47,  2.06it/s]Loading train:  17%|█▋        | 45/266 [00:23<01:46,  2.07it/s]Loading train:  17%|█▋        | 46/266 [00:24<01:45,  2.09it/s]Loading train:  18%|█▊        | 47/266 [00:24<01:45,  2.08it/s]Loading train:  18%|█▊        | 48/266 [00:25<01:45,  2.07it/s]Loading train:  18%|█▊        | 49/266 [00:25<01:44,  2.07it/s]Loading train:  19%|█▉        | 50/266 [00:26<01:42,  2.10it/s]Loading train:  19%|█▉        | 51/266 [00:26<01:41,  2.11it/s]Loading train:  20%|█▉        | 52/266 [00:27<01:42,  2.10it/s]Loading train:  20%|█▉        | 53/266 [00:27<01:42,  2.08it/s]Loading train:  20%|██        | 54/266 [00:28<01:42,  2.08it/s]Loading train:  21%|██        | 55/266 [00:28<01:42,  2.06it/s]Loading train:  21%|██        | 56/266 [00:29<01:42,  2.06it/s]Loading train:  21%|██▏       | 57/266 [00:29<01:40,  2.07it/s]Loading train:  22%|██▏       | 58/266 [00:30<01:39,  2.08it/s]Loading train:  22%|██▏       | 59/266 [00:30<01:45,  1.96it/s]Loading train:  23%|██▎       | 60/266 [00:31<01:48,  1.91it/s]Loading train:  23%|██▎       | 61/266 [00:31<01:49,  1.87it/s]Loading train:  23%|██▎       | 62/266 [00:32<01:50,  1.84it/s]Loading train:  24%|██▎       | 63/266 [00:32<01:53,  1.78it/s]Loading train:  24%|██▍       | 64/266 [00:33<01:55,  1.75it/s]Loading train:  24%|██▍       | 65/266 [00:34<01:53,  1.78it/s]Loading train:  25%|██▍       | 66/266 [00:34<01:52,  1.78it/s]Loading train:  25%|██▌       | 67/266 [00:35<01:54,  1.74it/s]Loading train:  26%|██▌       | 68/266 [00:35<01:53,  1.75it/s]Loading train:  26%|██▌       | 69/266 [00:36<01:51,  1.76it/s]Loading train:  26%|██▋       | 70/266 [00:37<01:52,  1.74it/s]Loading train:  27%|██▋       | 71/266 [00:37<01:52,  1.73it/s]Loading train:  27%|██▋       | 72/266 [00:38<01:51,  1.74it/s]Loading train:  27%|██▋       | 73/266 [00:38<01:48,  1.78it/s]Loading train:  28%|██▊       | 74/266 [00:39<01:48,  1.77it/s]Loading train:  28%|██▊       | 75/266 [00:39<01:47,  1.77it/s]Loading train:  29%|██▊       | 76/266 [00:40<01:45,  1.80it/s]Loading train:  29%|██▉       | 77/266 [00:41<02:11,  1.44it/s]Loading train:  29%|██▉       | 78/266 [00:42<02:21,  1.33it/s]Loading train:  30%|██▉       | 79/266 [00:43<02:22,  1.32it/s]Loading train:  30%|███       | 80/266 [00:43<02:22,  1.31it/s]Loading train:  30%|███       | 81/266 [00:44<02:32,  1.21it/s]Loading train:  31%|███       | 82/266 [00:45<02:20,  1.31it/s]Loading train:  31%|███       | 83/266 [00:46<02:11,  1.39it/s]Loading train:  32%|███▏      | 84/266 [00:46<02:02,  1.48it/s]Loading train:  32%|███▏      | 85/266 [00:47<01:57,  1.54it/s]Loading train:  32%|███▏      | 86/266 [00:47<01:54,  1.57it/s]Loading train:  33%|███▎      | 87/266 [00:48<01:51,  1.60it/s]Loading train:  33%|███▎      | 88/266 [00:48<01:49,  1.62it/s]Loading train:  33%|███▎      | 89/266 [00:49<01:48,  1.63it/s]Loading train:  34%|███▍      | 90/266 [00:50<01:48,  1.63it/s]Loading train:  34%|███▍      | 91/266 [00:50<01:47,  1.63it/s]Loading train:  35%|███▍      | 92/266 [00:51<01:46,  1.63it/s]Loading train:  35%|███▍      | 93/266 [00:52<01:44,  1.65it/s]Loading train:  35%|███▌      | 94/266 [00:52<01:44,  1.65it/s]Loading train:  36%|███▌      | 95/266 [00:53<01:44,  1.64it/s]Loading train:  36%|███▌      | 96/266 [00:53<01:45,  1.62it/s]Loading train:  36%|███▋      | 97/266 [00:54<01:43,  1.64it/s]Loading train:  37%|███▋      | 98/266 [00:55<01:41,  1.66it/s]Loading train:  37%|███▋      | 99/266 [00:55<01:40,  1.66it/s]Loading train:  38%|███▊      | 100/266 [00:56<01:39,  1.68it/s]Loading train:  38%|███▊      | 101/266 [00:56<01:37,  1.70it/s]Loading train:  38%|███▊      | 102/266 [00:57<01:34,  1.73it/s]Loading train:  39%|███▊      | 103/266 [00:57<01:33,  1.74it/s]Loading train:  39%|███▉      | 104/266 [00:58<01:34,  1.72it/s]Loading train:  39%|███▉      | 105/266 [00:59<01:33,  1.73it/s]Loading train:  40%|███▉      | 106/266 [00:59<01:31,  1.75it/s]Loading train:  40%|████      | 107/266 [01:00<01:30,  1.76it/s]Loading train:  41%|████      | 108/266 [01:00<01:30,  1.74it/s]Loading train:  41%|████      | 109/266 [01:01<01:29,  1.76it/s]Loading train:  41%|████▏     | 110/266 [01:01<01:27,  1.78it/s]Loading train:  42%|████▏     | 111/266 [01:02<01:27,  1.77it/s]Loading train:  42%|████▏     | 112/266 [01:03<01:28,  1.74it/s]Loading train:  42%|████▏     | 113/266 [01:03<01:30,  1.70it/s]Loading train:  43%|████▎     | 114/266 [01:04<01:30,  1.69it/s]Loading train:  43%|████▎     | 115/266 [01:04<01:28,  1.71it/s]Loading train:  44%|████▎     | 116/266 [01:05<01:26,  1.73it/s]Loading train:  44%|████▍     | 117/266 [01:06<01:26,  1.72it/s]Loading train:  44%|████▍     | 118/266 [01:06<01:24,  1.75it/s]Loading train:  45%|████▍     | 119/266 [01:07<01:22,  1.79it/s]Loading train:  45%|████▌     | 120/266 [01:07<01:20,  1.81it/s]Loading train:  45%|████▌     | 121/266 [01:08<01:20,  1.81it/s]Loading train:  46%|████▌     | 122/266 [01:08<01:20,  1.80it/s]Loading train:  46%|████▌     | 123/266 [01:09<01:20,  1.78it/s]Loading train:  47%|████▋     | 124/266 [01:09<01:19,  1.79it/s]Loading train:  47%|████▋     | 125/266 [01:10<01:18,  1.80it/s]Loading train:  47%|████▋     | 126/266 [01:10<01:17,  1.82it/s]Loading train:  48%|████▊     | 127/266 [01:11<01:16,  1.82it/s]Loading train:  48%|████▊     | 128/266 [01:12<01:15,  1.83it/s]Loading train:  48%|████▊     | 129/266 [01:12<01:14,  1.84it/s]Loading train:  49%|████▉     | 130/266 [01:13<01:13,  1.85it/s]Loading train:  49%|████▉     | 131/266 [01:13<01:13,  1.83it/s]Loading train:  50%|████▉     | 132/266 [01:14<01:13,  1.82it/s]Loading train:  50%|█████     | 133/266 [01:14<01:12,  1.83it/s]Loading train:  50%|█████     | 134/266 [01:15<01:11,  1.85it/s]Loading train:  51%|█████     | 135/266 [01:15<01:10,  1.86it/s]Loading train:  51%|█████     | 136/266 [01:16<01:08,  1.89it/s]Loading train:  52%|█████▏    | 137/266 [01:16<01:07,  1.92it/s]Loading train:  52%|█████▏    | 138/266 [01:17<01:05,  1.94it/s]Loading train:  52%|█████▏    | 139/266 [01:17<01:05,  1.93it/s]Loading train:  53%|█████▎    | 140/266 [01:18<01:04,  1.95it/s]Loading train:  53%|█████▎    | 141/266 [01:18<01:03,  1.95it/s]Loading train:  53%|█████▎    | 142/266 [01:19<01:03,  1.97it/s]Loading train:  54%|█████▍    | 143/266 [01:19<01:01,  1.98it/s]Loading train:  54%|█████▍    | 144/266 [01:20<01:01,  1.98it/s]Loading train:  55%|█████▍    | 145/266 [01:20<01:01,  1.97it/s]Loading train:  55%|█████▍    | 146/266 [01:21<01:00,  1.99it/s]Loading train:  55%|█████▌    | 147/266 [01:21<01:00,  1.98it/s]Loading train:  56%|█████▌    | 148/266 [01:22<00:59,  1.99it/s]Loading train:  56%|█████▌    | 149/266 [01:22<00:58,  1.99it/s]Loading train:  56%|█████▋    | 150/266 [01:23<00:58,  1.97it/s]Loading train:  57%|█████▋    | 151/266 [01:23<00:59,  1.93it/s]Loading train:  57%|█████▋    | 152/266 [01:24<00:58,  1.94it/s]Loading train:  58%|█████▊    | 153/266 [01:24<00:58,  1.93it/s]Loading train:  58%|█████▊    | 154/266 [01:25<01:00,  1.86it/s]Loading train:  58%|█████▊    | 155/266 [01:26<01:00,  1.83it/s]Loading train:  59%|█████▊    | 156/266 [01:26<01:00,  1.80it/s]Loading train:  59%|█████▉    | 157/266 [01:27<01:00,  1.79it/s]Loading train:  59%|█████▉    | 158/266 [01:27<01:00,  1.78it/s]Loading train:  60%|█████▉    | 159/266 [01:28<00:59,  1.80it/s]Loading train:  60%|██████    | 160/266 [01:28<00:59,  1.77it/s]Loading train:  61%|██████    | 161/266 [01:29<01:00,  1.75it/s]Loading train:  61%|██████    | 162/266 [01:30<00:58,  1.77it/s]Loading train:  61%|██████▏   | 163/266 [01:30<00:57,  1.79it/s]Loading train:  62%|██████▏   | 164/266 [01:31<00:56,  1.79it/s]Loading train:  62%|██████▏   | 165/266 [01:31<00:56,  1.79it/s]Loading train:  62%|██████▏   | 166/266 [01:32<00:55,  1.80it/s]Loading train:  63%|██████▎   | 167/266 [01:32<00:54,  1.82it/s]Loading train:  63%|██████▎   | 168/266 [01:33<00:54,  1.80it/s]Loading train:  64%|██████▎   | 169/266 [01:33<00:54,  1.79it/s]Loading train:  64%|██████▍   | 170/266 [01:34<00:53,  1.80it/s]Loading train:  64%|██████▍   | 171/266 [01:35<00:53,  1.79it/s]Loading train:  65%|██████▍   | 172/266 [01:35<00:59,  1.59it/s]Loading train:  65%|██████▌   | 173/266 [01:36<01:06,  1.40it/s]Loading train:  65%|██████▌   | 174/266 [01:37<01:07,  1.36it/s]Loading train:  66%|██████▌   | 175/266 [01:38<01:04,  1.40it/s]Loading train:  66%|██████▌   | 176/266 [01:38<01:04,  1.39it/s]Loading train:  67%|██████▋   | 177/266 [01:39<00:58,  1.53it/s]Loading train:  67%|██████▋   | 178/266 [01:40<00:53,  1.64it/s]Loading train:  67%|██████▋   | 179/266 [01:40<00:50,  1.72it/s]Loading train:  68%|██████▊   | 180/266 [01:41<00:48,  1.76it/s]Loading train:  68%|██████▊   | 181/266 [01:41<00:48,  1.76it/s]Loading train:  68%|██████▊   | 182/266 [01:42<00:46,  1.82it/s]Loading train:  69%|██████▉   | 183/266 [01:42<00:44,  1.87it/s]Loading train:  69%|██████▉   | 184/266 [01:43<00:43,  1.88it/s]Loading train:  70%|██████▉   | 185/266 [01:43<00:42,  1.90it/s]Loading train:  70%|██████▉   | 186/266 [01:44<00:41,  1.93it/s]Loading train:  70%|███████   | 187/266 [01:44<00:40,  1.96it/s]Loading train:  71%|███████   | 188/266 [01:45<00:39,  1.96it/s]Loading train:  71%|███████   | 189/266 [01:45<00:38,  1.98it/s]Loading train:  71%|███████▏  | 190/266 [01:46<00:38,  1.98it/s]Loading train:  72%|███████▏  | 191/266 [01:46<00:37,  1.99it/s]Loading train:  72%|███████▏  | 192/266 [01:47<00:37,  1.98it/s]Loading train:  73%|███████▎  | 193/266 [01:47<00:37,  1.95it/s]Loading train:  73%|███████▎  | 194/266 [01:48<00:36,  1.97it/s]Loading train:  73%|███████▎  | 195/266 [01:48<00:37,  1.90it/s]Loading train:  74%|███████▎  | 196/266 [01:49<00:36,  1.90it/s]Loading train:  74%|███████▍  | 197/266 [01:49<00:36,  1.88it/s]Loading train:  74%|███████▍  | 198/266 [01:50<00:36,  1.87it/s]Loading train:  75%|███████▍  | 199/266 [01:50<00:35,  1.87it/s]Loading train:  75%|███████▌  | 200/266 [01:51<00:35,  1.87it/s]Loading train:  76%|███████▌  | 201/266 [01:51<00:34,  1.86it/s]Loading train:  76%|███████▌  | 202/266 [01:52<00:34,  1.85it/s]Loading train:  76%|███████▋  | 203/266 [01:53<00:34,  1.81it/s]Loading train:  77%|███████▋  | 204/266 [01:53<00:34,  1.81it/s]Loading train:  77%|███████▋  | 205/266 [01:54<00:33,  1.83it/s]Loading train:  77%|███████▋  | 206/266 [01:54<00:32,  1.83it/s]Loading train:  78%|███████▊  | 207/266 [01:55<00:32,  1.84it/s]Loading train:  78%|███████▊  | 208/266 [01:55<00:31,  1.83it/s]Loading train:  79%|███████▊  | 209/266 [01:56<00:31,  1.82it/s]Loading train:  79%|███████▉  | 210/266 [01:56<00:30,  1.84it/s]Loading train:  79%|███████▉  | 211/266 [01:57<00:29,  1.85it/s]Loading train:  80%|███████▉  | 212/266 [01:58<00:29,  1.85it/s]Loading train:  80%|████████  | 213/266 [01:58<00:29,  1.82it/s]Loading train:  80%|████████  | 214/266 [01:59<00:28,  1.80it/s]Loading train:  81%|████████  | 215/266 [01:59<00:28,  1.80it/s]Loading train:  81%|████████  | 216/266 [02:00<00:28,  1.78it/s]Loading train:  82%|████████▏ | 217/266 [02:00<00:28,  1.74it/s]Loading train:  82%|████████▏ | 218/266 [02:01<00:27,  1.75it/s]Loading train:  82%|████████▏ | 219/266 [02:02<00:26,  1.75it/s]Loading train:  83%|████████▎ | 220/266 [02:02<00:26,  1.73it/s]Loading train:  83%|████████▎ | 221/266 [02:03<00:25,  1.74it/s]Loading train:  83%|████████▎ | 222/266 [02:03<00:25,  1.76it/s]Loading train:  84%|████████▍ | 223/266 [02:04<00:24,  1.77it/s]Loading train:  84%|████████▍ | 224/266 [02:04<00:23,  1.78it/s]Loading train:  85%|████████▍ | 225/266 [02:05<00:22,  1.79it/s]Loading train:  85%|████████▍ | 226/266 [02:05<00:22,  1.80it/s]Loading train:  85%|████████▌ | 227/266 [02:06<00:21,  1.78it/s]Loading train:  86%|████████▌ | 228/266 [02:07<00:22,  1.72it/s]Loading train:  86%|████████▌ | 229/266 [02:07<00:21,  1.69it/s]Loading train:  86%|████████▋ | 230/266 [02:08<00:21,  1.67it/s]Loading train:  87%|████████▋ | 231/266 [02:08<00:20,  1.73it/s]Loading train:  87%|████████▋ | 232/266 [02:09<00:18,  1.80it/s]Loading train:  88%|████████▊ | 233/266 [02:09<00:17,  1.86it/s]Loading train:  88%|████████▊ | 234/266 [02:10<00:16,  1.90it/s]Loading train:  88%|████████▊ | 235/266 [02:10<00:16,  1.91it/s]Loading train:  89%|████████▊ | 236/266 [02:11<00:15,  1.91it/s]Loading train:  89%|████████▉ | 237/266 [02:11<00:15,  1.92it/s]Loading train:  89%|████████▉ | 238/266 [02:12<00:14,  1.95it/s]Loading train:  90%|████████▉ | 239/266 [02:12<00:13,  1.94it/s]Loading train:  90%|█████████ | 240/266 [02:13<00:13,  1.94it/s]Loading train:  91%|█████████ | 241/266 [02:14<00:12,  1.94it/s]Loading train:  91%|█████████ | 242/266 [02:14<00:12,  1.95it/s]Loading train:  91%|█████████▏| 243/266 [02:15<00:11,  1.97it/s]Loading train:  92%|█████████▏| 244/266 [02:15<00:11,  1.95it/s]Loading train:  92%|█████████▏| 245/266 [02:16<00:10,  1.96it/s]Loading train:  92%|█████████▏| 246/266 [02:16<00:10,  1.98it/s]Loading train:  93%|█████████▎| 247/266 [02:17<00:09,  1.98it/s]Loading train:  93%|█████████▎| 248/266 [02:17<00:09,  1.99it/s]Loading train:  94%|█████████▎| 249/266 [02:18<00:08,  1.94it/s]Loading train:  94%|█████████▍| 250/266 [02:18<00:08,  1.95it/s]Loading train:  94%|█████████▍| 251/266 [02:19<00:07,  1.96it/s]Loading train:  95%|█████████▍| 252/266 [02:19<00:07,  1.97it/s]Loading train:  95%|█████████▌| 253/266 [02:20<00:06,  1.94it/s]Loading train:  95%|█████████▌| 254/266 [02:20<00:06,  1.94it/s]Loading train:  96%|█████████▌| 255/266 [02:21<00:05,  1.95it/s]Loading train:  96%|█████████▌| 256/266 [02:21<00:05,  1.92it/s]Loading train:  97%|█████████▋| 257/266 [02:22<00:04,  1.90it/s]Loading train:  97%|█████████▋| 258/266 [02:22<00:04,  1.93it/s]Loading train:  97%|█████████▋| 259/266 [02:23<00:03,  1.93it/s]Loading train:  98%|█████████▊| 260/266 [02:23<00:03,  1.90it/s]Loading train:  98%|█████████▊| 261/266 [02:24<00:02,  1.90it/s]Loading train:  98%|█████████▊| 262/266 [02:24<00:02,  1.92it/s]Loading train:  99%|█████████▉| 263/266 [02:25<00:01,  1.92it/s]Loading train:  99%|█████████▉| 264/266 [02:25<00:01,  1.93it/s]Loading train: 100%|█████████▉| 265/266 [02:26<00:00,  1.93it/s]Loading train: 100%|██████████| 266/266 [02:26<00:00,  1.93it/s]Loading train: 100%|██████████| 266/266 [02:26<00:00,  1.81it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 59.95it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 59.01it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 59.10it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:04, 59.56it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:03, 60.42it/s]concatenating: train:  14%|█▍        | 38/266 [00:00<00:03, 58.20it/s]concatenating: train:  17%|█▋        | 44/266 [00:00<00:03, 58.51it/s]concatenating: train:  19%|█▉        | 51/266 [00:00<00:03, 59.81it/s]concatenating: train:  22%|██▏       | 58/266 [00:00<00:03, 61.84it/s]concatenating: train:  24%|██▍       | 64/266 [00:01<00:03, 60.71it/s]concatenating: train:  26%|██▋       | 70/266 [00:01<00:03, 57.49it/s]concatenating: train:  29%|██▊       | 76/266 [00:01<00:03, 55.80it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:03, 57.35it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:02, 59.03it/s]concatenating: train:  36%|███▋      | 97/266 [00:01<00:02, 59.87it/s]concatenating: train:  39%|███▊      | 103/266 [00:01<00:02, 59.32it/s]concatenating: train:  41%|████▏     | 110/266 [00:01<00:02, 60.07it/s]concatenating: train:  44%|████▍     | 117/266 [00:01<00:02, 61.30it/s]concatenating: train:  47%|████▋     | 124/266 [00:02<00:02, 60.06it/s]concatenating: train:  49%|████▉     | 131/266 [00:02<00:02, 58.48it/s]concatenating: train:  52%|█████▏    | 137/266 [00:02<00:02, 56.96it/s]concatenating: train:  54%|█████▍    | 144/266 [00:02<00:02, 57.48it/s]concatenating: train:  56%|█████▋    | 150/266 [00:02<00:02, 56.02it/s]concatenating: train:  59%|█████▊    | 156/266 [00:02<00:01, 56.60it/s]concatenating: train:  61%|██████▏   | 163/266 [00:02<00:01, 58.11it/s]concatenating: train:  64%|██████▍   | 170/266 [00:02<00:01, 60.83it/s]concatenating: train:  67%|██████▋   | 177/266 [00:02<00:01, 61.97it/s]concatenating: train:  69%|██████▉   | 184/266 [00:03<00:01, 63.49it/s]concatenating: train:  72%|███████▏  | 192/266 [00:03<00:01, 65.64it/s]concatenating: train:  75%|███████▌  | 200/266 [00:03<00:00, 68.38it/s]concatenating: train:  78%|███████▊  | 208/266 [00:03<00:00, 70.28it/s]concatenating: train:  81%|████████  | 216/266 [00:03<00:00, 70.06it/s]concatenating: train:  84%|████████▍ | 224/266 [00:03<00:00, 67.42it/s]concatenating: train:  87%|████████▋ | 231/266 [00:03<00:00, 65.57it/s]concatenating: train:  89%|████████▉ | 238/266 [00:03<00:00, 58.72it/s]concatenating: train:  92%|█████████▏| 245/266 [00:04<00:00, 54.69it/s]concatenating: train:  94%|█████████▍| 251/266 [00:04<00:00, 55.23it/s]concatenating: train:  97%|█████████▋| 257/266 [00:04<00:00, 56.43it/s]concatenating: train:  99%|█████████▉| 263/266 [00:04<00:00, 57.24it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 60.13it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:06<00:19,  6.52s/it]Loading test:  50%|█████     | 2/4 [00:12<00:12,  6.26s/it]Loading test:  75%|███████▌  | 3/4 [00:22<00:07,  7.58s/it]Loading test: 100%|██████████| 4/4 [00:36<00:00,  9.45s/it]Loading test: 100%|██████████| 4/4 [00:36<00:00,  9.16s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 59.25it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   2020-01-22 05:56:47.465796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 05:56:47.465881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 05:56:47.465895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 05:56:47.465903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 05:56:47.466233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0
------------------------------------------------------------------
class_weights [6.83810829e-02 3.27984228e-02 8.45346529e-02 1.02665395e-02
 2.87979279e-02 7.66861256e-03 8.69426602e-02 1.12941456e-01
 9.17047115e-02 1.37614129e-02 2.76991425e-01 1.84941390e-01
 2.69705517e-04]
Train on 10099 samples, validate on 154 samples
Epoch 1/300
 - 28s - loss: 0.5768 - acc: 0.9237 - mDice: 0.3778 - val_loss: 0.1920 - val_acc: 0.9425 - val_mDice: 0.2525

Epoch 00001: val_mDice improved from -inf to 0.25248, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 24s - loss: 0.4292 - acc: 0.9372 - mDice: 0.5372 - val_loss: 0.1119 - val_acc: 0.9433 - val_mDice: 0.2570

Epoch 00002: val_mDice improved from 0.25248 to 0.25705, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 24s - loss: 0.3758 - acc: 0.9411 - mDice: 0.5949 - val_loss: 0.2216 - val_acc: 0.9490 - val_mDice: 0.2997

Epoch 00003: val_mDice improved from 0.25705 to 0.29971, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 4/300
 - 24s - loss: 0.3412 - acc: 0.9434 - mDice: 0.6324 - val_loss: -3.0107e-03 - val_acc: 0.9482 - val_mDice: 0.2901

Epoch 00004: val_mDice did not improve from 0.29971
Epoch 5/300
 - 24s - loss: 0.3327 - acc: 0.9448 - mDice: 0.6414 - val_loss: 0.0828 - val_acc: 0.9472 - val_mDice: 0.2921

Epoch 00005: val_mDice did not improve from 0.29971
Epoch 6/300
 - 23s - loss: 0.3184 - acc: 0.9463 - mDice: 0.6569 - val_loss: 0.0131 - val_acc: 0.9491 - val_mDice: 0.2986

Epoch 00006: val_mDice did not improve from 0.29971
Epoch 7/300
 - 24s - loss: 0.3083 - acc: 0.9473 - mDice: 0.6678 - val_loss: -2.0972e-02 - val_acc: 0.9488 - val_mDice: 0.2895

Epoch 00007: val_mDice did not improve from 0.29971
Epoch 8/300
 - 23s - loss: 0.3050 - acc: 0.9480 - mDice: 0.6714 - val_loss: -7.1101e-03 - val_acc: 0.9491 - val_mDice: 0.2941

Epoch 00008: val_mDice did not improve from 0.29971
Epoch 9/300
 - 23s - loss: 0.2973 - acc: 0.9489 - mDice: 0.6796 - val_loss: 0.1011 - val_acc: 0.9467 - val_mDice: 0.2946

Epoch 00009: val_mDice did not improve from 0.29971
Epoch 10/300
 - 23s - loss: 0.2931 - acc: 0.9493 - mDice: 0.6842 - val_loss: -4.3725e-03 - val_acc: 0.9478 - val_mDice: 0.2891

Epoch 00010: val_mDice did not improve from 0.29971
Epoch 11/300
 - 23s - loss: 0.2838 - acc: 0.9503 - mDice: 0.6942 - val_loss: 0.0391 - val_acc: 0.9466 - val_mDice: 0.2801

Epoch 00011: val_mDice did not improve from 0.29971
Epoch 12/300
 - 24s - loss: 0.2852 - acc: 0.9504 - mDice: 0.6927 - val_loss: 0.0320 - val_acc: 0.9461 - val_mDice: 0.2882

Epoch 00012: val_mDice did not improve from 0.29971
Epoch 13/300
 - 23s - loss: 0.2795 - acc: 0.9508 - mDice: 0.6989 - val_loss: -1.0581e-02 - val_acc: 0.9488 - val_mDice: 0.2970

Epoch 00013: val_mDice did not improve from 0.29971
Epoch 14/300
 - 24s - loss: 0.2773 - acc: 0.9514 - mDice: 0.7012 - val_loss: -2.6950e-02 - val_acc: 0.9476 - val_mDice: 0.2762

Epoch 00014: val_mDice did not improve from 0.29971
Epoch 15/300
 - 23s - loss: 0.2765 - acc: 0.9514 - mDice: 0.7021 - val_loss: 0.0032 - val_acc: 0.9500 - val_mDice: 0.2989

Epoch 00015: val_mDice did not improve from 0.29971
Epoch 16/300
 - 23s - loss: 0.2743 - acc: 0.9516 - mDice: 0.7045 - val_loss: 0.0532 - val_acc: 0.9493 - val_mDice: 0.3021

Epoch 00016: val_mDice improved from 0.29971 to 0.30209, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 17/300
 - 24s - loss: 0.2694 - acc: 0.9524 - mDice: 0.7098 - val_loss: 0.0378 - val_acc: 0.9500 - val_mDice: 0.2931

Epoch 00017: val_mDice did not improve from 0.30209
Epoch 18/300
 - 23s - loss: 0.2702 - acc: 0.9524 - mDice: 0.7089 - val_loss: 0.0184 - val_acc: 0.9511 - val_mDice: 0.2975

Epoch 00018: val_mDice did not improve from 0.30209
Epoch 19/300
 - 23s - loss: 0.2640 - acc: 0.9522 - mDice: 0.7156 - val_loss: 0.0145 - val_acc: 0.9496 - val_mDice: 0.2857

Epoch 00019: val_mDice did not improve from 0.30209
Epoch 20/300
 - 24s - loss: 0.2648 - acc: 0.9529 - mDice: 0.7147 - val_loss: 0.0125 - val_acc: 0.9503 - val_mDice: 0.2979

Epoch 00020: val_mDice did not improve from 0.30209
Epoch 21/300
 - 24s - loss: 0.2648 - acc: 0.9524 - mDice: 0.7131 - val_loss: 0.1461 - val_acc: 0.9451 - val_mDice: 0.2895

Epoch 00021: val_mDice did not improve from 0.30209
Epoch 22/300
 - 24s - loss: 0.3084 - acc: 0.9463 - mDice: 0.6507 - val_loss: -5.0845e-02 - val_acc: 0.9484 - val_mDice: 0.2775

Epoch 00022: val_mDice did not improve from 0.30209
Epoch 23/300
 - 24s - loss: 0.2842 - acc: 0.9473 - mDice: 0.6698 - val_loss: -2.8530e-02 - val_acc: 0.9499 - val_mDice: 0.2961

Epoch 00023: val_mDice did not improve from 0.30209
Epoch 24/300
 - 23s - loss: 0.2559 - acc: 0.9509 - mDice: 0.6999 - val_loss: -3.5969e-02 - val_acc: 0.9502 - val_mDice: 0.2962

Epoch 00024: val_mDice did not improve from 0.30209
Epoch 25/300
 - 23s - loss: 0.2569 - acc: 0.9508 - mDice: 0.6984 - val_loss: -2.1753e-02 - val_acc: 0.9478 - val_mDice: 0.2845

Epoch 00025: val_mDice did not improve from 0.30209
Epoch 26/300
 - 24s - loss: 0.2606 - acc: 0.9496 - mDice: 0.6896 - val_loss: -4.9880e-02 - val_acc: 0.9487 - val_mDice: 0.2899

Epoch 00026: val_mDice did not improve from 0.30209
Epoch 27/300
 - 23s - loss: 0.2523 - acc: 0.9504 - mDice: 0.6963 - val_loss: -4.0391e-02 - val_acc: 0.9484 - val_mDice: 0.2969

Epoch 00027: val_mDice did not improve from 0.30209
Epoch 28/300
 - 23s - loss: 0.2653 - acc: 0.9483 - mDice: 0.6821 - val_loss: -2.3814e-02 - val_acc: 0.9384 - val_mDice: 0.2613

Epoch 00028: val_mDice did not improve from 0.30209
Epoch 29/300
 - 24s - loss: 0.2615 - acc: 0.9481 - mDice: 0.6836 - val_loss: -1.3095e-02 - val_acc: 0.9483 - val_mDice: 0.2784

Epoch 00029: val_mDice did not improve from 0.30209
Epoch 30/300
 - 23s - loss: 0.2815 - acc: 0.9461 - mDice: 0.6592 - val_loss: -6.7513e-02 - val_acc: 0.9510 - val_mDice: 0.2978

Epoch 00030: val_mDice did not improve from 0.30209
Epoch 31/300
 - 23s - loss: 0.2875 - acc: 0.9463 - mDice: 0.6430 - val_loss: -3.5713e-02 - val_acc: 0.9492 - val_mDice: 0.2851

Epoch 00031: val_mDice did not improve from 0.30209

Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 32/300
 - 23s - loss: 0.2654 - acc: 0.9479 - mDice: 0.6717 - val_loss: -6.1243e-02 - val_acc: 0.9495 - val_mDice: 0.2915

Epoch 00032: val_mDice did not improve from 0.30209
Epoch 33/300
 - 23s - loss: 0.2485 - acc: 0.9499 - mDice: 0.6888 - val_loss: -5.4889e-02 - val_acc: 0.9473 - val_mDice: 0.2943

Epoch 00033: val_mDice did not improve from 0.30209
Epoch 34/300
 - 23s - loss: 0.2490 - acc: 0.9498 - mDice: 0.6866 - val_loss: -3.5389e-02 - val_acc: 0.9393 - val_mDice: 0.2314

Epoch 00034: val_mDice did not improve from 0.30209
Epoch 35/300
 - 23s - loss: 0.2390 - acc: 0.9505 - mDice: 0.6902 - val_loss: -5.2633e-02 - val_acc: 0.9431 - val_mDice: 0.2623

Epoch 00035: val_mDice did not improve from 0.30209
Epoch 36/300
 - 24s - loss: 0.2401 - acc: 0.9503 - mDice: 0.6973 - val_loss: -7.7268e-02 - val_acc: 0.9507 - val_mDice: 0.2979

Epoch 00036: val_mDice did not improve from 0.30209
Epoch 37/300
 - 23s - loss: 0.2355 - acc: 0.9509 - mDice: 0.7057 - val_loss: -9.5242e-02 - val_acc: 0.9515 - val_mDice: 0.2957

Epoch 00037: val_mDice did not improve from 0.30209
Epoch 38/300
 - 23s - loss: 0.2374 - acc: 0.9509 - mDice: 0.7021 - val_loss: -5.9050e-02 - val_acc: 0.9493 - val_mDice: 0.2889

Epoch 00038: val_mDice did not improve from 0.30209
Epoch 39/300
 - 24s - loss: 0.2287 - acc: 0.9514 - mDice: 0.7056 - val_loss: -7.0947e-02 - val_acc: 0.9512 - val_mDice: 0.3016

Epoch 00039: val_mDice did not improve from 0.30209
Epoch 40/300
 - 24s - loss: 0.2316 - acc: 0.9516 - mDice: 0.7053 - val_loss: -4.2957e-02 - val_acc: 0.9494 - val_mDice: 0.2935

Epoch 00040: val_mDice did not improve from 0.30209
Epoch 41/300
 - 23s - loss: 0.2435 - acc: 0.9502 - mDice: 0.6918 - val_loss: -7.8642e-03 - val_acc: 0.9390 - val_mDice: 0.2419

Epoch 00041: val_mDice did not improve from 0.30209
Epoch 42/300
 - 24s - loss: 0.2425 - acc: 0.9500 - mDice: 0.6933 - val_loss: 0.0521 - val_acc: 0.9434 - val_mDice: 0.2661

Epoch 00042: val_mDice did not improve from 0.30209
Epoch 43/300
 - 24s - loss: 0.2304 - acc: 0.9510 - mDice: 0.7013 - val_loss: -6.2396e-02 - val_acc: 0.9500 - val_mDice: 0.3032

Epoch 00043: val_mDice improved from 0.30209 to 0.30325, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 44/300
 - 24s - loss: 0.2303 - acc: 0.9514 - mDice: 0.7031 - val_loss: -6.0071e-02 - val_acc: 0.9488 - val_mDice: 0.2822

Epoch 00044: val_mDice did not improve from 0.30325
Epoch 45/300
 - 24s - loss: 0.2318 - acc: 0.9511 - mDice: 0.6992 - val_loss: -4.0663e-02 - val_acc: 0.9459 - val_mDice: 0.2800

Epoch 00045: val_mDice did not improve from 0.30325
Epoch 46/300
 - 24s - loss: 0.2331 - acc: 0.9505 - mDice: 0.6969 - val_loss: -7.3723e-02 - val_acc: 0.9510 - val_mDice: 0.2944

Epoch 00046: val_mDice did not improve from 0.30325
Epoch 47/300
 - 24s - loss: 0.2466 - acc: 0.9489 - mDice: 0.6854 - val_loss: -7.1730e-02 - val_acc: 0.9470 - val_mDice: 0.2703

Epoch 00047: val_mDice did not improve from 0.30325
Epoch 48/300
 - 24s - loss: 0.2318 - acc: 0.9510 - mDice: 0.7017 - val_loss: -4.5264e-02 - val_acc: 0.9481 - val_mDice: 0.2847

Epoch 00048: val_mDice did not improve from 0.30325
Epoch 49/300
 - 24s - loss: 0.2248 - acc: 0.9516 - mDice: 0.7060 - val_loss: -5.0196e-02 - val_acc: 0.9504 - val_mDice: 0.2898

Epoch 00049: val_mDice did not improve from 0.30325
Epoch 50/300
 - 25s - loss: 0.2183 - acc: 0.9523 - mDice: 0.7103 - val_loss: -6.5653e-02 - val_acc: 0.9498 - val_mDice: 0.2852

Epoch 00050: val_mDice did not improve from 0.30325
Epoch 51/300
 - 24s - loss: 0.2185 - acc: 0.9522 - mDice: 0.7106 - val_loss: -7.6362e-02 - val_acc: 0.9502 - val_mDice: 0.2861

Epoch 00051: val_mDice did not improve from 0.30325
Epoch 52/300
 - 24s - loss: 0.2325 - acc: 0.9510 - mDice: 0.6975 - val_loss: -3.9040e-02 - val_acc: 0.9478 - val_mDice: 0.2780

Epoch 00052: val_mDice did not improve from 0.30325
Epoch 53/300
 - 24s - loss: 0.2334 - acc: 0.9510 - mDice: 0.6948 - val_loss: -2.8243e-02 - val_acc: 0.9492 - val_mDice: 0.2772

Epoch 00053: val_mDice did not improve from 0.30325
Epoch 54/300
 - 25s - loss: 0.2249 - acc: 0.9513 - mDice: 0.6958 - val_loss: -5.0141e-02 - val_acc: 0.9502 - val_mDice: 0.2797

Epoch 00054: val_mDice did not improve from 0.30325
Epoch 55/300
 - 24s - loss: 0.2263 - acc: 0.9510 - mDice: 0.6940 - val_loss: -6.1239e-02 - val_acc: 0.9498 - val_mDice: 0.2913

Epoch 00055: val_mDice did not improve from 0.30325
Epoch 56/300
 - 24s - loss: 0.2221 - acc: 0.9519 - mDice: 0.7061 - val_loss: -3.3294e-02 - val_acc: 0.9489 - val_mDice: 0.2742

Epoch 00056: val_mDice did not improve from 0.30325
Epoch 57/300
 - 24s - loss: 0.2296 - acc: 0.9510 - mDice: 0.6914 - val_loss: -8.1974e-02 - val_acc: 0.9512 - val_mDice: 0.2921

Epoch 00057: val_mDice did not improve from 0.30325
Epoch 58/300
 - 24s - loss: 0.2405 - acc: 0.9509 - mDice: 0.6900 - val_loss: -6.6695e-02 - val_acc: 0.9490 - val_mDice: 0.2863

Epoch 00058: val_mDice did not improve from 0.30325

Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 59/300
 - 24s - loss: 0.2279 - acc: 0.9516 - mDice: 0.6970 - val_loss: -7.5239e-02 - val_acc: 0.9498 - val_mDice: 0.2883

Epoch 00059: val_mDice did not improve from 0.30325
Epoch 60/300
 - 24s - loss: 0.2274 - acc: 0.9517 - mDice: 0.7005 - val_loss: -7.6227e-02 - val_acc: 0.9511 - val_mDice: 0.2858

Epoch 00060: val_mDice did not improve from 0.30325
Epoch 61/300
 - 24s - loss: 0.2199 - acc: 0.9523 - mDice: 0.7100 - val_loss: -7.2673e-02 - val_acc: 0.9504 - val_mDice: 0.2820

Epoch 00061: val_mDice did not improve from 0.30325
Epoch 62/300
 - 24s - loss: 0.2157 - acc: 0.9525 - mDice: 0.7098 - val_loss: -6.7028e-02 - val_acc: 0.9509 - val_mDice: 0.2867

Epoch 00062: val_mDice did not improve from 0.30325
Epoch 63/300
 - 24s - loss: 0.2152 - acc: 0.9525 - mDice: 0.7146 - val_loss: -6.4939e-02 - val_acc: 0.9505 - val_mDice: 0.2844

Epoch 00063: val_mDice did not improve from 0.30325
Epoch 64/300
 - 25s - loss: 0.2098 - acc: 0.9530 - mDice: 0.7217 - val_loss: -6.9465e-02 - val_acc: 0.9512 - val_mDice: 0.2893

Epoch 00064: val_mDice did not improve from 0.30325
Epoch 65/300
 - 25s - loss: 0.2116 - acc: 0.9526 - mDice: 0.7117 - val_loss: -8.7586e-02 - val_acc: 0.9509 - val_mDice: 0.2873

Epoch 00065: val_mDice did not improve from 0.30325
Epoch 66/300
 - 24s - loss: 0.2113 - acc: 0.9526 - mDice: 0.7111 - val_loss: -5.8427e-02 - val_acc: 0.9504 - val_mDice: 0.2774

Epoch 00066: val_mDice did not improve from 0.30325
Epoch 67/300
 - 25s - loss: 0.2205 - acc: 0.9523 - mDice: 0.7038 - val_loss: -7.0724e-02 - val_acc: 0.9503 - val_mDice: 0.2799

Epoch 00067: val_mDice did not improve from 0.30325
Epoch 68/300
 - 23s - loss: 0.2128 - acc: 0.9528 - mDice: 0.7132 - val_loss: -8.8131e-02 - val_acc: 0.9510 - val_mDice: 0.2879

Epoch 00068: val_mDice did not improve from 0.30325
Epoch 69/300
 - 23s - loss: 0.2085 - acc: 0.9529 - mDice: 0.7144 - val_loss: -3.0773e-02 - val_acc: 0.9465 - val_mDice: 0.2584

Epoch 00069: val_mDice did not improve from 0.30325
Epoch 70/300
 - 24s - loss: 0.2183 - acc: 0.9525 - mDice: 0.7075 - val_loss: -8.8791e-02 - val_acc: 0.9508 - val_mDice: 0.2886

Epoch 00070: val_mDice did not improve from 0.30325
Epoch 71/300
 - 23s - loss: 0.2085 - acc: 0.9531 - mDice: 0.7160 - val_loss: -7.6200e-02 - val_acc: 0.9504 - val_mDice: 0.2858

Epoch 00071: val_mDice did not improve from 0.30325
Epoch 72/300
 - 24s - loss: 0.2036 - acc: 0.9533 - mDice: 0.7211 - val_loss: -8.5983e-02 - val_acc: 0.9513 - val_mDice: 0.2964

Epoch 00072: val_mDice did not improve from 0.30325
Epoch 73/300
 - 24s - loss: 0.2081 - acc: 0.9533 - mDice: 0.7189 - val_loss: -5.6070e-02 - val_acc: 0.9438 - val_mDice: 0.2542

Epoch 00073: val_mDice did not improve from 0.30325

Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 74/300
 - 23s - loss: 0.2132 - acc: 0.9526 - mDice: 0.7173 - val_loss: -8.7443e-02 - val_acc: 0.9509 - val_mDice: 0.2872

Epoch 00074: val_mDice did not improve from 0.30325
Epoch 75/300
 - 24s - loss: 0.2059 - acc: 0.9533 - mDice: 0.7188 - val_loss: -9.1561e-02 - val_acc: 0.9511 - val_mDice: 0.2918

Epoch 00075: val_mDice did not improve from 0.30325
Epoch 76/300
 - 23s - loss: 0.2013 - acc: 0.9535 - mDice: 0.7256 - val_loss: -8.7668e-02 - val_acc: 0.9507 - val_mDice: 0.2874

Epoch 00076: val_mDice did not improve from 0.30325
Epoch 77/300
 - 24s - loss: 0.2043 - acc: 0.9538 - mDice: 0.7275 - val_loss: -8.9036e-02 - val_acc: 0.9511 - val_mDice: 0.2889

Epoch 00077: val_mDice did not improve from 0.30325
Epoch 78/300
 - 24s - loss: 0.2016 - acc: 0.9539 - mDice: 0.7268 - val_loss: -9.2928e-02 - val_acc: 0.9516 - val_mDice: 0.2931

Epoch 00078: val_mDice did not improve from 0.30325
Epoch 79/300
 - 23s - loss: 0.2009 - acc: 0.9540 - mDice: 0.7280 - val_loss: -8.7114e-02 - val_acc: 0.9512 - val_mDice: 0.2868

Epoch 00079: val_mDice did not improve from 0.30325
Epoch 80/300
 - 24s - loss: 0.2007 - acc: 0.9541 - mDice: 0.7248 - val_loss: -8.9289e-02 - val_acc: 0.9515 - val_mDice: 0.2892

Epoch 00080: val_mDice did not improve from 0.30325
Epoch 81/300
 - 23s - loss: 0.1994 - acc: 0.9541 - mDice: 0.7270 - val_loss: -9.2458e-02 - val_acc: 0.9515 - val_mDice: 0.2926

Epoch 00081: val_mDice did not improve from 0.30325
Epoch 82/300
 - 24s - loss: 0.2031 - acc: 0.9540 - mDice: 0.7275 - val_loss: -7.4121e-02 - val_acc: 0.9512 - val_mDice: 0.2835

Epoch 00082: val_mDice did not improve from 0.30325
Epoch 83/300
 - 24s - loss: 0.1988 - acc: 0.9542 - mDice: 0.7307 - val_loss: -8.0241e-02 - val_acc: 0.9514 - val_mDice: 0.2902

Epoch 00083: val_mDice did not improve from 0.30325
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [0.19200390407984907, 0.11194840180022377, 0.22161324114187972, -0.003010658716613596, 0.08284090875418156, 0.013148630062093982, -0.020972300768382364, -0.00711011044777833, 0.10108096109304045, -0.0043725356907136255, 0.03906177927727823, 0.03197276768843075, -0.010580727757958623, -0.026950078472108036, 0.003164073331402494, 0.05323966569569591, 0.03782543628295133, 0.01840353710576892, 0.014454264919479171, 0.012507867225288571, 0.14606710637060852, -0.050845359146667574, -0.028530322202759518, -0.035968655212358994, -0.02175296446332684, -0.049879602688763826, -0.040390523791603454, -0.023814145245819124, -0.013094626451757822, -0.06751312562204026, -0.035712844728455914, -0.06124278641753383, -0.05488886335840473, -0.03538933178627646, -0.05263308159910239, -0.07726820504637556, -0.09524248504116163, -0.05905012649713785, -0.0709474411272964, -0.04295654257142602, -0.007864243924684291, 0.052114334598473915, -0.06239563271451693, -0.06007052751185445, -0.0406628661333922, -0.07372257377092073, -0.07172953937347833, -0.04526365882801739, -0.05019628673235511, -0.06565347277595625, -0.07636239521157046, -0.039039734847746886, -0.02824298320217179, -0.05014110227151738, -0.06123899047069445, -0.033294008065063455, -0.08197374269366264, -0.06669452439316294, -0.075239006841144, -0.0762266468524316, -0.07267336454242468, -0.06702761428261345, -0.0649388607639771, -0.0694647885907393, -0.08758574983637248, -0.058426509287764695, -0.07072352958153691, -0.08813100115867792, -0.030773149041289635, -0.08879085310867854, -0.07620024114889516, -0.08598289658109863, -0.05606959664637779, -0.08744318451877538, -0.09156112750242283, -0.08766812146678875, -0.08903631425232857, -0.0929284732631565, -0.08711428949367497, -0.08928884154445697, -0.09245828049130399, -0.07412097828051487, -0.08024054104250601], 'val_acc': [0.9424989711154591, 0.9433203269908954, 0.9489683176015878, 0.9481582393893948, 0.9472048313586743, 0.9491374229455923, 0.9488443066547443, 0.9491180916885277, 0.9467297320242052, 0.9478248752556838, 0.9466089428245247, 0.9460871467342624, 0.9487718397920782, 0.9476428790525957, 0.9499877528710798, 0.9493097391995516, 0.9499942056544415, 0.9510587430619574, 0.9496221828770328, 0.9503082540128138, 0.9450789790648919, 0.9483885455441166, 0.9499152906529316, 0.9501939021147691, 0.9478136076555623, 0.9487412347422017, 0.9484062574126504, 0.9384179889381706, 0.9483144492297978, 0.9509653317463862, 0.9492195565979202, 0.949548099722181, 0.9473385013543166, 0.9393279111230528, 0.9430674678319461, 0.9506883226431809, 0.9514581344344399, 0.9493435675447638, 0.9511763027736119, 0.9494385843153124, 0.9389929314712425, 0.9433911860763252, 0.9499732612015365, 0.9487927803745517, 0.9458761795774683, 0.9509524455318203, 0.9470115729740688, 0.9480600047421146, 0.9504209826518963, 0.9498379896213482, 0.9502035658080856, 0.9477829909943914, 0.9492131185221981, 0.950248658657074, 0.9497655165659917, 0.9489409412656512, 0.9512085171488972, 0.9490311308340593, 0.9497896788956283, 0.9511360409971955, 0.9504499675391557, 0.9509331158229283, 0.9505095489613422, 0.9511763089663022, 0.9508896400402118, 0.9504048770124262, 0.9503356311228368, 0.9509717667257631, 0.9464833318413078, 0.950751142842429, 0.9504129367989379, 0.9512809824633908, 0.943777694330587, 0.9508719235271602, 0.9511231470417667, 0.9507092663219997, 0.9511006141637827, 0.9516046937409933, 0.9512197855231049, 0.9515290082275093, 0.951512899491694, 0.9512101164111844, 0.9514339813938388], 'val_mDice': [0.2524824608949969, 0.2570457036619069, 0.2997115155222354, 0.29010630713461283, 0.2921194034543904, 0.2985879114599197, 0.28947558858758443, 0.29408983513712883, 0.2945650639375309, 0.2890669016481994, 0.2800779656640121, 0.28820771946535484, 0.2969733423420361, 0.2761805879992324, 0.2988688721285238, 0.30209270177723524, 0.2930648224307345, 0.2974943479934296, 0.28566520380509364, 0.2979291699729957, 0.2895192697450712, 0.27751662838575125, 0.29606442192158144, 0.29617234822604566, 0.2845327143932318, 0.2898712752314357, 0.2968733703548258, 0.26129701871473293, 0.2784498443270659, 0.2978445144442769, 0.28514492956848886, 0.29146373968619804, 0.29433575016144037, 0.23136970318563574, 0.2623286216289966, 0.2979255328801545, 0.29566015240240406, 0.2889244809940264, 0.3016077856738846, 0.2935213605788621, 0.24188151817720432, 0.2660861306085989, 0.3032458024946126, 0.28217633697506667, 0.2800349233696213, 0.2944383522519818, 0.27033608087471556, 0.2847374559126117, 0.289753962259788, 0.28524224339173987, 0.28614717659044575, 0.27803953659611863, 0.27716452425176447, 0.2797199507038315, 0.2913176109167663, 0.2741595014155685, 0.29205551903162685, 0.2863415773329023, 0.28833836762161996, 0.2858091859364664, 0.2820191369331502, 0.28669847180316976, 0.28444669545664414, 0.28933199988557146, 0.28731202237404785, 0.27739322432256364, 0.2798825731718695, 0.28791294251750044, 0.2584043370148578, 0.28863876612929557, 0.2858399869753169, 0.29641044381764026, 0.2542116375422323, 0.28716751754090386, 0.29183439620129475, 0.2874235153778807, 0.2888925338720346, 0.293128502736618, 0.28680153370097083, 0.28915149873340285, 0.2925924818430628, 0.283542340597162, 0.29016301311649284], 'loss': [0.5767816795324474, 0.4292395380372186, 0.3758324952701116, 0.34116302200893045, 0.33273403647394745, 0.31837390047900216, 0.30834196061294306, 0.3050083404059976, 0.2973404976858669, 0.2930666995687123, 0.28383522783131726, 0.2852129281859715, 0.2794915520356355, 0.2773302494963156, 0.2765077430519188, 0.2742830891487138, 0.2693952932409372, 0.27018794987812905, 0.2640231576461298, 0.26477296651442556, 0.2648415707803526, 0.30843500805226914, 0.28421088202301964, 0.25589216876111415, 0.2568768202271399, 0.2605588769399833, 0.2522686757431348, 0.2652918587096905, 0.2615279907000833, 0.28147002660953147, 0.28751962584669233, 0.2654198096919477, 0.24847016709573622, 0.2489912313948886, 0.23896894884554068, 0.2400979260302706, 0.23551363361630884, 0.23742337542550893, 0.22873319257409486, 0.2315607070126077, 0.24349142651677025, 0.24253443485784898, 0.23040330524392466, 0.23026869813920378, 0.23184365293221146, 0.23305655546476786, 0.24661401679196138, 0.23182559766489336, 0.2247752392560713, 0.21831014268282856, 0.2185138105458612, 0.23249017484116305, 0.23344575875123452, 0.22489874555990033, 0.22627575572180605, 0.22213558279619625, 0.22959368129860022, 0.24050990309621958, 0.22787496047059422, 0.2274282332404453, 0.21993877322141256, 0.21565946295249888, 0.21524765475537191, 0.209820963293207, 0.2116259671166703, 0.2113080515169992, 0.22053498287226608, 0.21280278499565664, 0.20850801967687152, 0.21831155537603844, 0.20851555087183385, 0.20360896152374258, 0.20814622865904225, 0.21324511608850322, 0.20593563970495601, 0.2013395272540885, 0.2042926760535969, 0.20160614808654137, 0.2008631529577179, 0.20066062513149957, 0.19942253114312927, 0.20311021881153307, 0.19879909029021323], 'acc': [0.9237371452292165, 0.9371938548804345, 0.9411051324398544, 0.9433627179889753, 0.9447813375195202, 0.946344998416623, 0.9472769681847159, 0.9479713839036968, 0.948890555535275, 0.9493299813680879, 0.9503024969021628, 0.9503990368024349, 0.9507936159269988, 0.9513945864420006, 0.9513997188097464, 0.9516168900711346, 0.9524060517257364, 0.9524304127738031, 0.9521660904020752, 0.9528695430150302, 0.9524329178096493, 0.9463171234566665, 0.947265549200173, 0.9508996114115607, 0.9508185677214865, 0.9496423405094281, 0.9503739133295723, 0.9482537313538832, 0.9480821419581409, 0.9461133147374345, 0.9462522908961115, 0.9479407827114513, 0.9499156503987107, 0.9497526066234081, 0.9505031151468889, 0.9502839799599667, 0.9509093367542321, 0.9508938405145241, 0.951439553557652, 0.9515686321345895, 0.9502415420194819, 0.9499764337387636, 0.9510267744891561, 0.9513993510362807, 0.9510913138484492, 0.9505321919439995, 0.9489052921182414, 0.9510267002061519, 0.9515791426071827, 0.9523115987730022, 0.95220882226387, 0.9509889537809579, 0.9509537375578846, 0.9512992017587136, 0.9510231636068421, 0.9519422158107556, 0.9510250309632903, 0.9509220817193192, 0.9516479074276253, 0.9517136254644899, 0.9522760633029894, 0.9525458137638936, 0.9525073066077878, 0.9530398307348056, 0.9526421314761808, 0.9525867281001161, 0.952320882472346, 0.9527648995862006, 0.9529260026073559, 0.9524765340558774, 0.9530648076719596, 0.9533423668666102, 0.9533009364269951, 0.9526395764855161, 0.9533444303535615, 0.9534667551204679, 0.9538140118517537, 0.9539107971409073, 0.9540187570290679, 0.9540619043350598, 0.9541112430875449, 0.9540024007980346, 0.9542469032413476], 'mDice': [0.377803363173784, 0.5371576132001422, 0.5948721588820629, 0.6323675364005069, 0.641444515466029, 0.6569380552972446, 0.6677777505190092, 0.6713591930606316, 0.679631341151736, 0.6842450582104067, 0.6942117757898284, 0.6927197870434788, 0.6989099927462733, 0.7012160339087753, 0.7021053887815898, 0.7045076644376949, 0.7097727632756303, 0.7089069976595583, 0.7155917546680415, 0.7146932727653846, 0.7131334357255047, 0.6506730403885037, 0.669804140091745, 0.6998863960093868, 0.6984098954582725, 0.6896009770038399, 0.6963081747361346, 0.6821184443983658, 0.6835853995893459, 0.6592414672982163, 0.6430187553199804, 0.6716822244788364, 0.6888367469115522, 0.6865657902918354, 0.6901580845203621, 0.6973069637574139, 0.7057246308076948, 0.7020753428763429, 0.705611288748185, 0.7052672651513093, 0.6918311903282892, 0.6932892345511, 0.7013309890237795, 0.703092314651879, 0.6991543460392765, 0.6969043026821297, 0.6853878430144977, 0.7017412957064834, 0.7059737109927827, 0.7103166545496233, 0.7106201193193148, 0.697489326042, 0.6948005923930696, 0.6958291737298373, 0.6940329294828439, 0.7061171207891642, 0.6913897551006699, 0.6899724792980867, 0.6970482674290939, 0.7005453514502726, 0.7099556210891175, 0.7097899798166989, 0.7146090482860429, 0.7217462555301438, 0.7117077436868785, 0.7111473098605302, 0.7038254931027588, 0.7131889885292748, 0.7143637522669969, 0.7074530874458749, 0.7160361769093371, 0.7211472448682724, 0.718948905604206, 0.7173274538401082, 0.7188044323084531, 0.7256065291076005, 0.7274911136411891, 0.7267813899573955, 0.7280022692699245, 0.724757773248922, 0.7270441548058698, 0.7274780399032791, 0.7306763292751828], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.26s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:22,  3.21it/s]Loading train:   1%|          | 2/266 [00:00<01:20,  3.27it/s]Loading train:   1%|          | 3/266 [00:00<01:17,  3.40it/s]Loading train:   2%|▏         | 4/266 [00:01<01:17,  3.39it/s]Loading train:   2%|▏         | 5/266 [00:01<01:16,  3.41it/s]Loading train:   2%|▏         | 6/266 [00:01<01:15,  3.42it/s]Loading train:   3%|▎         | 7/266 [00:02<01:15,  3.45it/s]Loading train:   3%|▎         | 8/266 [00:02<01:14,  3.46it/s]Loading train:   3%|▎         | 9/266 [00:02<01:14,  3.45it/s]Loading train:   4%|▍         | 10/266 [00:02<01:13,  3.47it/s]Loading train:   4%|▍         | 11/266 [00:03<01:12,  3.50it/s]Loading train:   5%|▍         | 12/266 [00:03<01:12,  3.51it/s]Loading train:   5%|▍         | 13/266 [00:03<01:12,  3.49it/s]Loading train:   5%|▌         | 14/266 [00:04<01:11,  3.52it/s]Loading train:   6%|▌         | 15/266 [00:04<01:11,  3.52it/s]Loading train:   6%|▌         | 16/266 [00:04<01:11,  3.52it/s]Loading train:   6%|▋         | 17/266 [00:04<01:10,  3.55it/s]Loading train:   7%|▋         | 18/266 [00:05<01:09,  3.57it/s]Loading train:   7%|▋         | 19/266 [00:05<01:09,  3.58it/s]Loading train:   8%|▊         | 20/266 [00:05<01:08,  3.59it/s]Loading train:   8%|▊         | 21/266 [00:05<01:08,  3.59it/s]Loading train:   8%|▊         | 22/266 [00:06<01:07,  3.59it/s]Loading train:   9%|▊         | 23/266 [00:06<01:05,  3.68it/s]Loading train:   9%|▉         | 24/266 [00:06<01:03,  3.80it/s]Loading train:   9%|▉         | 25/266 [00:07<01:04,  3.71it/s]Loading train:  10%|▉         | 26/266 [00:07<01:05,  3.64it/s]Loading train:  10%|█         | 27/266 [00:07<01:04,  3.73it/s]Loading train:  11%|█         | 28/266 [00:07<01:04,  3.68it/s]Loading train:  11%|█         | 29/266 [00:08<01:03,  3.74it/s]Loading train:  11%|█▏        | 30/266 [00:08<01:02,  3.81it/s]Loading train:  12%|█▏        | 31/266 [00:08<01:01,  3.80it/s]Loading train:  12%|█▏        | 32/266 [00:08<01:01,  3.81it/s]Loading train:  12%|█▏        | 33/266 [00:09<01:00,  3.82it/s]Loading train:  13%|█▎        | 34/266 [00:09<01:01,  3.77it/s]Loading train:  13%|█▎        | 35/266 [00:09<01:01,  3.73it/s]Loading train:  14%|█▎        | 36/266 [00:09<01:01,  3.74it/s]Loading train:  14%|█▍        | 37/266 [00:10<01:00,  3.80it/s]Loading train:  14%|█▍        | 38/266 [00:10<00:58,  3.87it/s]Loading train:  15%|█▍        | 39/266 [00:10<00:58,  3.91it/s]Loading train:  15%|█▌        | 40/266 [00:10<00:57,  3.93it/s]Loading train:  15%|█▌        | 41/266 [00:11<00:58,  3.88it/s]Loading train:  16%|█▌        | 42/266 [00:11<00:58,  3.85it/s]Loading train:  16%|█▌        | 43/266 [00:11<00:58,  3.84it/s]Loading train:  17%|█▋        | 44/266 [00:12<00:58,  3.83it/s]Loading train:  17%|█▋        | 45/266 [00:12<00:57,  3.81it/s]Loading train:  17%|█▋        | 46/266 [00:12<00:57,  3.80it/s]Loading train:  18%|█▊        | 47/266 [00:12<00:57,  3.79it/s]Loading train:  18%|█▊        | 48/266 [00:13<00:57,  3.78it/s]Loading train:  18%|█▊        | 49/266 [00:13<00:57,  3.78it/s]Loading train:  19%|█▉        | 50/266 [00:13<00:57,  3.77it/s]Loading train:  19%|█▉        | 51/266 [00:13<00:56,  3.77it/s]Loading train:  20%|█▉        | 52/266 [00:14<00:56,  3.77it/s]Loading train:  20%|█▉        | 53/266 [00:14<00:56,  3.77it/s]Loading train:  20%|██        | 54/266 [00:14<00:56,  3.78it/s]Loading train:  21%|██        | 55/266 [00:14<00:56,  3.72it/s]Loading train:  21%|██        | 56/266 [00:15<00:56,  3.73it/s]Loading train:  21%|██▏       | 57/266 [00:15<00:55,  3.78it/s]Loading train:  22%|██▏       | 58/266 [00:15<00:55,  3.72it/s]Loading train:  22%|██▏       | 59/266 [00:16<00:56,  3.67it/s]Loading train:  23%|██▎       | 60/266 [00:16<00:56,  3.64it/s]Loading train:  23%|██▎       | 61/266 [00:16<00:56,  3.63it/s]Loading train:  23%|██▎       | 62/266 [00:16<00:56,  3.61it/s]Loading train:  24%|██▎       | 63/266 [00:17<00:56,  3.61it/s]Loading train:  24%|██▍       | 64/266 [00:17<00:56,  3.58it/s]Loading train:  24%|██▍       | 65/266 [00:17<00:56,  3.58it/s]Loading train:  25%|██▍       | 66/266 [00:18<00:56,  3.57it/s]Loading train:  25%|██▌       | 67/266 [00:18<00:55,  3.56it/s]Loading train:  26%|██▌       | 68/266 [00:18<00:55,  3.54it/s]Loading train:  26%|██▌       | 69/266 [00:18<00:55,  3.54it/s]Loading train:  26%|██▋       | 70/266 [00:19<00:54,  3.57it/s]Loading train:  27%|██▋       | 71/266 [00:19<00:54,  3.59it/s]Loading train:  27%|██▋       | 72/266 [00:19<00:54,  3.58it/s]Loading train:  27%|██▋       | 73/266 [00:19<00:53,  3.59it/s]Loading train:  28%|██▊       | 74/266 [00:20<00:53,  3.58it/s]Loading train:  28%|██▊       | 75/266 [00:20<00:53,  3.60it/s]Loading train:  29%|██▊       | 76/266 [00:20<00:52,  3.59it/s]Loading train:  29%|██▉       | 77/266 [00:21<00:56,  3.37it/s]Loading train:  29%|██▉       | 78/266 [00:21<00:56,  3.31it/s]Loading train:  30%|██▉       | 79/266 [00:21<00:55,  3.36it/s]Loading train:  30%|███       | 80/266 [00:22<00:53,  3.45it/s]Loading train:  30%|███       | 81/266 [00:22<00:56,  3.28it/s]Loading train:  31%|███       | 82/266 [00:22<00:57,  3.20it/s]Loading train:  31%|███       | 83/266 [00:23<00:58,  3.13it/s]Loading train:  32%|███▏      | 84/266 [00:23<00:58,  3.10it/s]Loading train:  32%|███▏      | 85/266 [00:23<00:59,  3.06it/s]Loading train:  32%|███▏      | 86/266 [00:24<00:58,  3.05it/s]Loading train:  33%|███▎      | 87/266 [00:24<00:58,  3.07it/s]Loading train:  33%|███▎      | 88/266 [00:24<00:57,  3.08it/s]Loading train:  33%|███▎      | 89/266 [00:24<00:57,  3.06it/s]Loading train:  34%|███▍      | 90/266 [00:25<00:57,  3.04it/s]Loading train:  34%|███▍      | 91/266 [00:25<00:57,  3.02it/s]Loading train:  35%|███▍      | 92/266 [00:26<00:58,  2.98it/s]Loading train:  35%|███▍      | 93/266 [00:26<00:57,  3.00it/s]Loading train:  35%|███▌      | 94/266 [00:26<00:56,  3.03it/s]Loading train:  36%|███▌      | 95/266 [00:26<00:56,  3.04it/s]Loading train:  36%|███▌      | 96/266 [00:27<00:56,  2.99it/s]Loading train:  36%|███▋      | 97/266 [00:27<00:56,  3.00it/s]Loading train:  37%|███▋      | 98/266 [00:27<00:55,  3.03it/s]Loading train:  37%|███▋      | 99/266 [00:28<00:54,  3.06it/s]Loading train:  38%|███▊      | 100/266 [00:28<00:53,  3.12it/s]Loading train:  38%|███▊      | 101/266 [00:28<00:51,  3.18it/s]Loading train:  38%|███▊      | 102/266 [00:29<00:51,  3.20it/s]Loading train:  39%|███▊      | 103/266 [00:29<00:50,  3.21it/s]Loading train:  39%|███▉      | 104/266 [00:29<00:49,  3.25it/s]Loading train:  39%|███▉      | 105/266 [00:30<00:49,  3.25it/s]Loading train:  40%|███▉      | 106/266 [00:30<00:49,  3.25it/s]Loading train:  40%|████      | 107/266 [00:30<00:48,  3.25it/s]Loading train:  41%|████      | 108/266 [00:31<00:49,  3.21it/s]Loading train:  41%|████      | 109/266 [00:31<00:49,  3.19it/s]Loading train:  41%|████▏     | 110/266 [00:31<00:49,  3.17it/s]Loading train:  42%|████▏     | 111/266 [00:32<00:48,  3.19it/s]Loading train:  42%|████▏     | 112/266 [00:32<00:48,  3.19it/s]Loading train:  42%|████▏     | 113/266 [00:32<00:48,  3.18it/s]Loading train:  43%|████▎     | 114/266 [00:32<00:47,  3.21it/s]Loading train:  43%|████▎     | 115/266 [00:33<00:47,  3.20it/s]Loading train:  44%|████▎     | 116/266 [00:33<00:47,  3.19it/s]Loading train:  44%|████▍     | 117/266 [00:33<00:46,  3.21it/s]Loading train:  44%|████▍     | 118/266 [00:34<00:44,  3.30it/s]Loading train:  45%|████▍     | 119/266 [00:34<00:43,  3.37it/s]Loading train:  45%|████▌     | 120/266 [00:34<00:42,  3.42it/s]Loading train:  45%|████▌     | 121/266 [00:35<00:42,  3.43it/s]Loading train:  46%|████▌     | 122/266 [00:35<00:41,  3.46it/s]Loading train:  46%|████▌     | 123/266 [00:35<00:41,  3.47it/s]Loading train:  47%|████▋     | 124/266 [00:35<00:40,  3.50it/s]Loading train:  47%|████▋     | 125/266 [00:36<00:41,  3.42it/s]Loading train:  47%|████▋     | 126/266 [00:36<00:40,  3.42it/s]Loading train:  48%|████▊     | 127/266 [00:36<00:41,  3.35it/s]Loading train:  48%|████▊     | 128/266 [00:37<00:40,  3.41it/s]Loading train:  48%|████▊     | 129/266 [00:37<00:40,  3.40it/s]Loading train:  49%|████▉     | 130/266 [00:37<00:39,  3.45it/s]Loading train:  49%|████▉     | 131/266 [00:37<00:39,  3.41it/s]Loading train:  50%|████▉     | 132/266 [00:38<00:39,  3.43it/s]Loading train:  50%|█████     | 133/266 [00:38<00:38,  3.43it/s]Loading train:  50%|█████     | 134/266 [00:38<00:38,  3.44it/s]Loading train:  51%|█████     | 135/266 [00:39<00:38,  3.41it/s]Loading train:  51%|█████     | 136/266 [00:39<00:37,  3.48it/s]Loading train:  52%|█████▏    | 137/266 [00:39<00:36,  3.51it/s]Loading train:  52%|█████▏    | 138/266 [00:39<00:35,  3.61it/s]Loading train:  52%|█████▏    | 139/266 [00:40<00:34,  3.66it/s]Loading train:  53%|█████▎    | 140/266 [00:40<00:34,  3.68it/s]Loading train:  53%|█████▎    | 141/266 [00:40<00:33,  3.73it/s]Loading train:  53%|█████▎    | 142/266 [00:40<00:33,  3.70it/s]Loading train:  54%|█████▍    | 143/266 [00:41<00:33,  3.69it/s]Loading train:  54%|█████▍    | 144/266 [00:41<00:32,  3.71it/s]Loading train:  55%|█████▍    | 145/266 [00:41<00:32,  3.71it/s]Loading train:  55%|█████▍    | 146/266 [00:42<00:32,  3.70it/s]Loading train:  55%|█████▌    | 147/266 [00:42<00:31,  3.73it/s]Loading train:  56%|█████▌    | 148/266 [00:42<00:31,  3.74it/s]Loading train:  56%|█████▌    | 149/266 [00:42<00:31,  3.77it/s]Loading train:  56%|█████▋    | 150/266 [00:43<00:30,  3.77it/s]Loading train:  57%|█████▋    | 151/266 [00:43<00:30,  3.78it/s]Loading train:  57%|█████▋    | 152/266 [00:43<00:30,  3.76it/s]Loading train:  58%|█████▊    | 153/266 [00:43<00:30,  3.72it/s]Loading train:  58%|█████▊    | 154/266 [00:44<00:32,  3.48it/s]Loading train:  58%|█████▊    | 155/266 [00:44<00:33,  3.36it/s]Loading train:  59%|█████▊    | 156/266 [00:44<00:33,  3.25it/s]Loading train:  59%|█████▉    | 157/266 [00:45<00:34,  3.19it/s]Loading train:  59%|█████▉    | 158/266 [00:45<00:34,  3.13it/s]Loading train:  60%|█████▉    | 159/266 [00:45<00:34,  3.13it/s]Loading train:  60%|██████    | 160/266 [00:46<00:33,  3.12it/s]Loading train:  61%|██████    | 161/266 [00:46<00:33,  3.13it/s]Loading train:  61%|██████    | 162/266 [00:46<00:33,  3.12it/s]Loading train:  61%|██████▏   | 163/266 [00:47<00:33,  3.10it/s]Loading train:  62%|██████▏   | 164/266 [00:47<00:33,  3.00it/s]Loading train:  62%|██████▏   | 165/266 [00:47<00:33,  3.01it/s]Loading train:  62%|██████▏   | 166/266 [00:48<00:33,  3.01it/s]Loading train:  63%|██████▎   | 167/266 [00:48<00:32,  3.03it/s]Loading train:  63%|██████▎   | 168/266 [00:48<00:32,  3.05it/s]Loading train:  64%|██████▎   | 169/266 [00:49<00:31,  3.05it/s]Loading train:  64%|██████▍   | 170/266 [00:49<00:31,  3.08it/s]Loading train:  64%|██████▍   | 171/266 [00:49<00:30,  3.09it/s]Loading train:  65%|██████▍   | 172/266 [00:50<00:30,  3.08it/s]Loading train:  65%|██████▌   | 173/266 [00:50<00:30,  3.03it/s]Loading train:  65%|██████▌   | 174/266 [00:50<00:30,  3.06it/s]Loading train:  66%|██████▌   | 175/266 [00:51<00:29,  3.12it/s]Loading train:  66%|██████▌   | 176/266 [00:51<00:28,  3.17it/s]Loading train:  67%|██████▋   | 177/266 [00:51<00:28,  3.18it/s]Loading train:  67%|██████▋   | 178/266 [00:52<00:27,  3.22it/s]Loading train:  67%|██████▋   | 179/266 [00:52<00:26,  3.25it/s]Loading train:  68%|██████▊   | 180/266 [00:52<00:26,  3.25it/s]Loading train:  68%|██████▊   | 181/266 [00:52<00:25,  3.27it/s]Loading train:  68%|██████▊   | 182/266 [00:53<00:25,  3.27it/s]Loading train:  69%|██████▉   | 183/266 [00:53<00:25,  3.28it/s]Loading train:  69%|██████▉   | 184/266 [00:53<00:24,  3.31it/s]Loading train:  70%|██████▉   | 185/266 [00:54<00:24,  3.31it/s]Loading train:  70%|██████▉   | 186/266 [00:54<00:24,  3.31it/s]Loading train:  70%|███████   | 187/266 [00:54<00:23,  3.34it/s]Loading train:  71%|███████   | 188/266 [00:55<00:23,  3.34it/s]Loading train:  71%|███████   | 189/266 [00:55<00:23,  3.33it/s]Loading train:  71%|███████▏  | 190/266 [00:55<00:23,  3.30it/s]Loading train:  72%|███████▏  | 191/266 [00:55<00:23,  3.26it/s]Loading train:  72%|███████▏  | 192/266 [00:56<00:22,  3.28it/s]Loading train:  73%|███████▎  | 193/266 [00:56<00:22,  3.30it/s]Loading train:  73%|███████▎  | 194/266 [00:56<00:21,  3.32it/s]Loading train:  73%|███████▎  | 195/266 [00:57<00:21,  3.26it/s]Loading train:  74%|███████▎  | 196/266 [00:57<00:21,  3.22it/s]Loading train:  74%|███████▍  | 197/266 [00:57<00:21,  3.23it/s]Loading train:  74%|███████▍  | 198/266 [00:58<00:21,  3.23it/s]Loading train:  75%|███████▍  | 199/266 [00:58<00:20,  3.23it/s]Loading train:  75%|███████▌  | 200/266 [00:58<00:20,  3.23it/s]Loading train:  76%|███████▌  | 201/266 [00:59<00:20,  3.24it/s]Loading train:  76%|███████▌  | 202/266 [00:59<00:19,  3.25it/s]Loading train:  76%|███████▋  | 203/266 [00:59<00:19,  3.25it/s]Loading train:  77%|███████▋  | 204/266 [00:59<00:19,  3.25it/s]Loading train:  77%|███████▋  | 205/266 [01:00<00:18,  3.25it/s]Loading train:  77%|███████▋  | 206/266 [01:00<00:18,  3.25it/s]Loading train:  78%|███████▊  | 207/266 [01:00<00:18,  3.25it/s]Loading train:  78%|███████▊  | 208/266 [01:01<00:18,  3.21it/s]Loading train:  79%|███████▊  | 209/266 [01:01<00:17,  3.20it/s]Loading train:  79%|███████▉  | 210/266 [01:01<00:17,  3.19it/s]Loading train:  79%|███████▉  | 211/266 [01:02<00:17,  3.18it/s]Loading train:  80%|███████▉  | 212/266 [01:02<00:16,  3.18it/s]Loading train:  80%|████████  | 213/266 [01:02<00:16,  3.15it/s]Loading train:  80%|████████  | 214/266 [01:03<00:16,  3.14it/s]Loading train:  81%|████████  | 215/266 [01:03<00:16,  3.16it/s]Loading train:  81%|████████  | 216/266 [01:03<00:15,  3.24it/s]Loading train:  82%|████████▏ | 217/266 [01:04<00:14,  3.28it/s]Loading train:  82%|████████▏ | 218/266 [01:04<00:14,  3.32it/s]Loading train:  82%|████████▏ | 219/266 [01:04<00:14,  3.32it/s]Loading train:  83%|████████▎ | 220/266 [01:04<00:13,  3.34it/s]Loading train:  83%|████████▎ | 221/266 [01:05<00:13,  3.34it/s]Loading train:  83%|████████▎ | 222/266 [01:05<00:13,  3.35it/s]Loading train:  84%|████████▍ | 223/266 [01:05<00:13,  3.27it/s]Loading train:  84%|████████▍ | 224/266 [01:06<00:12,  3.30it/s]Loading train:  85%|████████▍ | 225/266 [01:06<00:12,  3.32it/s]Loading train:  85%|████████▍ | 226/266 [01:06<00:11,  3.34it/s]Loading train:  85%|████████▌ | 227/266 [01:06<00:11,  3.37it/s]Loading train:  86%|████████▌ | 228/266 [01:07<00:11,  3.39it/s]Loading train:  86%|████████▌ | 229/266 [01:07<00:10,  3.40it/s]Loading train:  86%|████████▋ | 230/266 [01:07<00:10,  3.40it/s]Loading train:  87%|████████▋ | 231/266 [01:08<00:09,  3.52it/s]Loading train:  87%|████████▋ | 232/266 [01:08<00:09,  3.61it/s]Loading train:  88%|████████▊ | 233/266 [01:08<00:09,  3.66it/s]Loading train:  88%|████████▊ | 234/266 [01:08<00:08,  3.61it/s]Loading train:  88%|████████▊ | 235/266 [01:09<00:08,  3.63it/s]Loading train:  89%|████████▊ | 236/266 [01:09<00:08,  3.60it/s]Loading train:  89%|████████▉ | 237/266 [01:09<00:07,  3.63it/s]Loading train:  89%|████████▉ | 238/266 [01:10<00:07,  3.68it/s]Loading train:  90%|████████▉ | 239/266 [01:10<00:07,  3.71it/s]Loading train:  90%|█████████ | 240/266 [01:10<00:06,  3.73it/s]Loading train:  91%|█████████ | 241/266 [01:10<00:06,  3.76it/s]Loading train:  91%|█████████ | 242/266 [01:11<00:06,  3.75it/s]Loading train:  91%|█████████▏| 243/266 [01:11<00:06,  3.76it/s]Loading train:  92%|█████████▏| 244/266 [01:11<00:05,  3.76it/s]Loading train:  92%|█████████▏| 245/266 [01:11<00:05,  3.76it/s]Loading train:  92%|█████████▏| 246/266 [01:12<00:05,  3.74it/s]Loading train:  93%|█████████▎| 247/266 [01:12<00:05,  3.73it/s]Loading train:  93%|█████████▎| 248/266 [01:12<00:04,  3.76it/s]Loading train:  94%|█████████▎| 249/266 [01:12<00:04,  3.73it/s]Loading train:  94%|█████████▍| 250/266 [01:13<00:04,  3.71it/s]Loading train:  94%|█████████▍| 251/266 [01:13<00:04,  3.69it/s]Loading train:  95%|█████████▍| 252/266 [01:13<00:03,  3.68it/s]Loading train:  95%|█████████▌| 253/266 [01:14<00:03,  3.66it/s]Loading train:  95%|█████████▌| 254/266 [01:14<00:03,  3.66it/s]Loading train:  96%|█████████▌| 255/266 [01:14<00:03,  3.64it/s]Loading train:  96%|█████████▌| 256/266 [01:14<00:02,  3.65it/s]Loading train:  97%|█████████▋| 257/266 [01:15<00:02,  3.64it/s]Loading train:  97%|█████████▋| 258/266 [01:15<00:02,  3.66it/s]Loading train:  97%|█████████▋| 259/266 [01:15<00:01,  3.65it/s]Loading train:  98%|█████████▊| 260/266 [01:15<00:01,  3.63it/s]Loading train:  98%|█████████▊| 261/266 [01:16<00:01,  3.63it/s]Loading train:  98%|█████████▊| 262/266 [01:16<00:01,  3.64it/s]Loading train:  99%|█████████▉| 263/266 [01:16<00:00,  3.64it/s]Loading train:  99%|█████████▉| 264/266 [01:17<00:00,  3.64it/s]Loading train: 100%|█████████▉| 265/266 [01:17<00:00,  3.65it/s]Loading train: 100%|██████████| 266/266 [01:17<00:00,  3.62it/s]Loading train: 100%|██████████| 266/266 [01:17<00:00,  3.43it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:05, 51.57it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:05, 49.42it/s]concatenating: train:   6%|▌         | 16/266 [00:00<00:05, 49.18it/s]concatenating: train:   8%|▊         | 22/266 [00:00<00:04, 50.60it/s]concatenating: train:  11%|█         | 28/266 [00:00<00:04, 52.01it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 54.75it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:04, 55.06it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:03, 55.98it/s]concatenating: train:  20%|█▉        | 53/266 [00:00<00:03, 55.67it/s]concatenating: train:  22%|██▏       | 59/266 [00:01<00:03, 56.03it/s]concatenating: train:  24%|██▍       | 65/266 [00:01<00:03, 54.74it/s]concatenating: train:  27%|██▋       | 71/266 [00:01<00:03, 54.32it/s]concatenating: train:  29%|██▉       | 77/266 [00:01<00:03, 52.48it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:03, 52.01it/s]concatenating: train:  33%|███▎      | 89/266 [00:01<00:03, 50.33it/s]concatenating: train:  36%|███▌      | 95/266 [00:01<00:03, 48.62it/s]concatenating: train:  38%|███▊      | 100/266 [00:01<00:03, 44.41it/s]concatenating: train:  39%|███▉      | 105/266 [00:02<00:03, 44.14it/s]concatenating: train:  41%|████▏     | 110/266 [00:02<00:03, 43.11it/s]concatenating: train:  43%|████▎     | 115/266 [00:02<00:03, 44.44it/s]concatenating: train:  45%|████▌     | 120/266 [00:02<00:03, 45.20it/s]concatenating: train:  47%|████▋     | 126/266 [00:02<00:02, 47.29it/s]concatenating: train:  50%|████▉     | 132/266 [00:02<00:02, 47.89it/s]concatenating: train:  52%|█████▏    | 138/266 [00:02<00:02, 50.12it/s]concatenating: train:  54%|█████▍    | 144/266 [00:02<00:02, 51.12it/s]concatenating: train:  56%|█████▋    | 150/266 [00:02<00:02, 50.83it/s]concatenating: train:  59%|█████▊    | 156/266 [00:03<00:02, 50.84it/s]concatenating: train:  61%|██████    | 162/266 [00:03<00:02, 49.75it/s]concatenating: train:  63%|██████▎   | 167/266 [00:03<00:02, 49.14it/s]concatenating: train:  65%|██████▍   | 172/266 [00:03<00:01, 48.09it/s]concatenating: train:  67%|██████▋   | 177/266 [00:03<00:01, 46.95it/s]concatenating: train:  68%|██████▊   | 182/266 [00:03<00:01, 45.71it/s]concatenating: train:  70%|███████   | 187/266 [00:03<00:01, 46.54it/s]concatenating: train:  72%|███████▏  | 192/266 [00:03<00:01, 46.13it/s]concatenating: train:  74%|███████▍  | 198/266 [00:03<00:01, 47.71it/s]concatenating: train:  77%|███████▋  | 204/266 [00:04<00:01, 49.20it/s]concatenating: train:  79%|███████▉  | 210/266 [00:04<00:01, 48.99it/s]concatenating: train:  81%|████████  | 216/266 [00:04<00:01, 49.85it/s]concatenating: train:  83%|████████▎ | 222/266 [00:04<00:00, 48.30it/s]concatenating: train:  86%|████████▌ | 228/266 [00:04<00:00, 49.46it/s]concatenating: train:  88%|████████▊ | 235/266 [00:04<00:00, 51.87it/s]concatenating: train:  91%|█████████ | 241/266 [00:04<00:00, 50.74it/s]concatenating: train:  93%|█████████▎| 247/266 [00:04<00:00, 50.09it/s]concatenating: train:  95%|█████████▌| 253/266 [00:05<00:00, 52.25it/s]concatenating: train:  98%|█████████▊| 260/266 [00:05<00:00, 55.63it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 50.63it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  3.52it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  3.61it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  3.62it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.45it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.51it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 298.11it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2020-01-22 06:32:37.151209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 06:32:37.151301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 06:32:37.151315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 06:32:37.151324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 06:32:37.151653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1
------------------------------------------------------------------
class_weights [0.97555386 0.02444614]
Train on 27854 samples, validate on 403 samples
Epoch 1/300
 - 73s - loss: 0.0716 - acc: 0.9925 - mDice: 0.8607 - val_loss: -1.9073e-02 - val_acc: 0.9939 - val_mDice: 0.5324

Epoch 00001: val_mDice improved from -inf to 0.53238, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 70s - loss: 0.0510 - acc: 0.9946 - mDice: 0.9008 - val_loss: 0.0732 - val_acc: 0.9938 - val_mDice: 0.5415

Epoch 00002: val_mDice improved from 0.53238 to 0.54147, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 69s - loss: 0.0463 - acc: 0.9950 - mDice: 0.9100 - val_loss: 0.0485 - val_acc: 0.9938 - val_mDice: 0.5410

Epoch 00003: val_mDice did not improve from 0.54147
Epoch 4/300
 - 69s - loss: 0.0436 - acc: 0.9953 - mDice: 0.9151 - val_loss: -2.0686e-02 - val_acc: 0.9938 - val_mDice: 0.5349

Epoch 00004: val_mDice did not improve from 0.54147
Epoch 5/300
 - 69s - loss: 0.0413 - acc: 0.9955 - mDice: 0.9197 - val_loss: -2.0680e-02 - val_acc: 0.9940 - val_mDice: 0.5352

Epoch 00005: val_mDice did not improve from 0.54147
Epoch 6/300
 - 70s - loss: 0.0395 - acc: 0.9956 - mDice: 0.9232 - val_loss: 0.0217 - val_acc: 0.9943 - val_mDice: 0.5422

Epoch 00006: val_mDice improved from 0.54147 to 0.54217, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 7/300
 - 70s - loss: 0.0381 - acc: 0.9957 - mDice: 0.9258 - val_loss: 0.0469 - val_acc: 0.9940 - val_mDice: 0.5469

Epoch 00007: val_mDice improved from 0.54217 to 0.54689, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 8/300
 - 70s - loss: 0.0370 - acc: 0.9958 - mDice: 0.9281 - val_loss: 0.0539 - val_acc: 0.9936 - val_mDice: 0.5348

Epoch 00008: val_mDice did not improve from 0.54689
Epoch 9/300
 - 70s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9297 - val_loss: 0.0281 - val_acc: 0.9941 - val_mDice: 0.5376

Epoch 00009: val_mDice did not improve from 0.54689
Epoch 10/300
 - 70s - loss: 0.0356 - acc: 0.9960 - mDice: 0.9308 - val_loss: -3.9123e-02 - val_acc: 0.9942 - val_mDice: 0.5389

Epoch 00010: val_mDice did not improve from 0.54689
Epoch 11/300
 - 70s - loss: 0.0350 - acc: 0.9960 - mDice: 0.9320 - val_loss: -3.9670e-02 - val_acc: 0.9943 - val_mDice: 0.5399

Epoch 00011: val_mDice did not improve from 0.54689
Epoch 12/300
 - 70s - loss: 0.0350 - acc: 0.9960 - mDice: 0.9319 - val_loss: 5.6392e-04 - val_acc: 0.9942 - val_mDice: 0.5407

Epoch 00012: val_mDice did not improve from 0.54689
Epoch 13/300
 - 70s - loss: 0.0336 - acc: 0.9961 - mDice: 0.9347 - val_loss: -5.5780e-03 - val_acc: 0.9941 - val_mDice: 0.5436

Epoch 00013: val_mDice did not improve from 0.54689
Epoch 14/300
 - 70s - loss: 0.0336 - acc: 0.9962 - mDice: 0.9347 - val_loss: -1.6721e-02 - val_acc: 0.9941 - val_mDice: 0.5423

Epoch 00014: val_mDice did not improve from 0.54689
Epoch 15/300
 - 69s - loss: 0.0333 - acc: 0.9962 - mDice: 0.9353 - val_loss: -2.0848e-02 - val_acc: 0.9939 - val_mDice: 0.5348

Epoch 00015: val_mDice did not improve from 0.54689
Epoch 16/300
 - 70s - loss: 0.0325 - acc: 0.9963 - mDice: 0.9368 - val_loss: 0.0184 - val_acc: 0.9941 - val_mDice: 0.5409

Epoch 00016: val_mDice did not improve from 0.54689
Epoch 17/300
 - 70s - loss: 0.0323 - acc: 0.9963 - mDice: 0.9373 - val_loss: -2.4905e-02 - val_acc: 0.9943 - val_mDice: 0.5431

Epoch 00017: val_mDice did not improve from 0.54689
Epoch 18/300
 - 71s - loss: 0.0317 - acc: 0.9963 - mDice: 0.9385 - val_loss: 0.0471 - val_acc: 0.9938 - val_mDice: 0.5470

Epoch 00018: val_mDice improved from 0.54689 to 0.54697, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 19/300
 - 72s - loss: 0.0316 - acc: 0.9963 - mDice: 0.9385 - val_loss: 0.0746 - val_acc: 0.9943 - val_mDice: 0.5443

Epoch 00019: val_mDice did not improve from 0.54697
Epoch 20/300
 - 72s - loss: 0.0310 - acc: 0.9964 - mDice: 0.9397 - val_loss: 0.0278 - val_acc: 0.9941 - val_mDice: 0.5402

Epoch 00020: val_mDice did not improve from 0.54697
Epoch 21/300
 - 71s - loss: 0.0312 - acc: 0.9964 - mDice: 0.9394 - val_loss: -2.2461e-02 - val_acc: 0.9942 - val_mDice: 0.5418

Epoch 00021: val_mDice did not improve from 0.54697
Epoch 22/300
 - 71s - loss: 0.0311 - acc: 0.9964 - mDice: 0.9395 - val_loss: -1.1223e-02 - val_acc: 0.9942 - val_mDice: 0.5437

Epoch 00022: val_mDice did not improve from 0.54697

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 23/300
 - 71s - loss: 0.0294 - acc: 0.9965 - mDice: 0.9429 - val_loss: 0.0850 - val_acc: 0.9939 - val_mDice: 0.5401

Epoch 00023: val_mDice did not improve from 0.54697
Epoch 24/300
 - 72s - loss: 0.0292 - acc: 0.9965 - mDice: 0.9433 - val_loss: 0.0256 - val_acc: 0.9941 - val_mDice: 0.5413

Epoch 00024: val_mDice did not improve from 0.54697
Epoch 25/300
 - 72s - loss: 0.0289 - acc: 0.9966 - mDice: 0.9439 - val_loss: 0.0012 - val_acc: 0.9940 - val_mDice: 0.5392

Epoch 00025: val_mDice did not improve from 0.54697
Epoch 26/300
 - 72s - loss: 0.0287 - acc: 0.9966 - mDice: 0.9443 - val_loss: -2.1060e-04 - val_acc: 0.9942 - val_mDice: 0.5417

Epoch 00026: val_mDice did not improve from 0.54697
Epoch 27/300
 - 70s - loss: 0.0285 - acc: 0.9966 - mDice: 0.9447 - val_loss: 0.0279 - val_acc: 0.9939 - val_mDice: 0.5355

Epoch 00027: val_mDice did not improve from 0.54697
Epoch 28/300
 - 70s - loss: 0.0281 - acc: 0.9966 - mDice: 0.9454 - val_loss: 0.0017 - val_acc: 0.9941 - val_mDice: 0.5386

Epoch 00028: val_mDice did not improve from 0.54697
Epoch 29/300
 - 71s - loss: 0.0282 - acc: 0.9966 - mDice: 0.9452 - val_loss: -2.4137e-02 - val_acc: 0.9942 - val_mDice: 0.5405

Epoch 00029: val_mDice did not improve from 0.54697
Epoch 30/300
 - 70s - loss: 0.0284 - acc: 0.9966 - mDice: 0.9449 - val_loss: 0.0263 - val_acc: 0.9941 - val_mDice: 0.5386

Epoch 00030: val_mDice did not improve from 0.54697
Epoch 31/300
 - 70s - loss: 0.0279 - acc: 0.9967 - mDice: 0.9457 - val_loss: 0.0494 - val_acc: 0.9941 - val_mDice: 0.5410

Epoch 00031: val_mDice did not improve from 0.54697
Epoch 32/300
 - 70s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9465 - val_loss: 0.0240 - val_acc: 0.9942 - val_mDice: 0.5424

Epoch 00032: val_mDice did not improve from 0.54697
Epoch 33/300
 - 70s - loss: 0.0279 - acc: 0.9967 - mDice: 0.9458 - val_loss: 0.0243 - val_acc: 0.9942 - val_mDice: 0.5425

Epoch 00033: val_mDice did not improve from 0.54697
Epoch 34/300
 - 70s - loss: 0.0278 - acc: 0.9967 - mDice: 0.9460 - val_loss: 0.0218 - val_acc: 0.9942 - val_mDice: 0.5406

Epoch 00034: val_mDice did not improve from 0.54697
Epoch 35/300
 - 70s - loss: 0.0275 - acc: 0.9967 - mDice: 0.9465 - val_loss: 9.5738e-04 - val_acc: 0.9941 - val_mDice: 0.5396

Epoch 00035: val_mDice did not improve from 0.54697
Epoch 36/300
 - 70s - loss: 0.0273 - acc: 0.9967 - mDice: 0.9470 - val_loss: 0.0120 - val_acc: 0.9942 - val_mDice: 0.5408

Epoch 00036: val_mDice did not improve from 0.54697
Epoch 37/300
 - 70s - loss: 0.0276 - acc: 0.9967 - mDice: 0.9464 - val_loss: -2.6242e-02 - val_acc: 0.9943 - val_mDice: 0.5443

Epoch 00037: val_mDice did not improve from 0.54697

Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 38/300
 - 70s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9480 - val_loss: 0.0043 - val_acc: 0.9942 - val_mDice: 0.5413

Epoch 00038: val_mDice did not improve from 0.54697
Epoch 39/300
 - 70s - loss: 0.0266 - acc: 0.9968 - mDice: 0.9485 - val_loss: -2.1381e-02 - val_acc: 0.9941 - val_mDice: 0.5406

Epoch 00039: val_mDice did not improve from 0.54697
Epoch 40/300
 - 70s - loss: 0.0266 - acc: 0.9968 - mDice: 0.9484 - val_loss: 0.0253 - val_acc: 0.9941 - val_mDice: 0.5406

Epoch 00040: val_mDice did not improve from 0.54697
Epoch 41/300
 - 70s - loss: 0.0266 - acc: 0.9968 - mDice: 0.9483 - val_loss: 3.1332e-04 - val_acc: 0.9941 - val_mDice: 0.5409

Epoch 00041: val_mDice did not improve from 0.54697
Epoch 42/300
 - 70s - loss: 0.0261 - acc: 0.9968 - mDice: 0.9493 - val_loss: 0.0092 - val_acc: 0.9940 - val_mDice: 0.5388

Epoch 00042: val_mDice did not improve from 0.54697
Epoch 43/300
 - 70s - loss: 0.0262 - acc: 0.9968 - mDice: 0.9491 - val_loss: 8.3108e-04 - val_acc: 0.9941 - val_mDice: 0.5387

Epoch 00043: val_mDice did not improve from 0.54697
Epoch 44/300
 - 70s - loss: 0.0264 - acc: 0.9968 - mDice: 0.9487 - val_loss: -2.4869e-02 - val_acc: 0.9940 - val_mDice: 0.5417

Epoch 00044: val_mDice did not improve from 0.54697
Epoch 45/300
 - 70s - loss: 0.0260 - acc: 0.9968 - mDice: 0.9496 - val_loss: -3.5361e-02 - val_acc: 0.9942 - val_mDice: 0.5380

Epoch 00045: val_mDice did not improve from 0.54697
Epoch 46/300
 - 70s - loss: 0.0260 - acc: 0.9968 - mDice: 0.9496 - val_loss: -5.4509e-02 - val_acc: 0.9940 - val_mDice: 0.5385

Epoch 00046: val_mDice did not improve from 0.54697
Epoch 47/300
 - 70s - loss: 0.0260 - acc: 0.9968 - mDice: 0.9496 - val_loss: -7.2246e-02 - val_acc: 0.9942 - val_mDice: 0.5371

Epoch 00047: val_mDice did not improve from 0.54697
Epoch 48/300
 - 70s - loss: 0.0262 - acc: 0.9968 - mDice: 0.9492 - val_loss: -2.5151e-02 - val_acc: 0.9942 - val_mDice: 0.5412

Epoch 00048: val_mDice did not improve from 0.54697
Epoch 49/300
 - 70s - loss: 0.0257 - acc: 0.9968 - mDice: 0.9502 - val_loss: -4.1529e-03 - val_acc: 0.9942 - val_mDice: 0.5412

Epoch 00049: val_mDice did not improve from 0.54697
Epoch 50/300
 - 69s - loss: 0.0261 - acc: 0.9968 - mDice: 0.9494 - val_loss: -7.2236e-02 - val_acc: 0.9942 - val_mDice: 0.5388

Epoch 00050: val_mDice did not improve from 0.54697
Epoch 51/300
 - 70s - loss: 0.0258 - acc: 0.9968 - mDice: 0.9500 - val_loss: -7.3476e-02 - val_acc: 0.9942 - val_mDice: 0.5409

Epoch 00051: val_mDice did not improve from 0.54697
Epoch 52/300
 - 70s - loss: 0.0257 - acc: 0.9968 - mDice: 0.9502 - val_loss: -2.7350e-02 - val_acc: 0.9942 - val_mDice: 0.5438

Epoch 00052: val_mDice did not improve from 0.54697

Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 53/300
 - 70s - loss: 0.0254 - acc: 0.9969 - mDice: 0.9507 - val_loss: -4.7780e-02 - val_acc: 0.9942 - val_mDice: 0.5413

Epoch 00053: val_mDice did not improve from 0.54697
Epoch 54/300
 - 70s - loss: 0.0255 - acc: 0.9969 - mDice: 0.9504 - val_loss: -4.9397e-02 - val_acc: 0.9942 - val_mDice: 0.5410

Epoch 00054: val_mDice did not improve from 0.54697
Epoch 55/300
 - 70s - loss: 0.0252 - acc: 0.9968 - mDice: 0.9511 - val_loss: -4.9565e-02 - val_acc: 0.9942 - val_mDice: 0.5406

Epoch 00055: val_mDice did not improve from 0.54697
Epoch 56/300
 - 71s - loss: 0.0254 - acc: 0.9969 - mDice: 0.9507 - val_loss: -4.8646e-02 - val_acc: 0.9941 - val_mDice: 0.5395

Epoch 00056: val_mDice did not improve from 0.54697
Epoch 57/300
 - 72s - loss: 0.0257 - acc: 0.9968 - mDice: 0.9502 - val_loss: -2.3910e-02 - val_acc: 0.9942 - val_mDice: 0.5397

Epoch 00057: val_mDice did not improve from 0.54697
Epoch 58/300
 - 71s - loss: 0.0251 - acc: 0.9969 - mDice: 0.9512 - val_loss: -4.8585e-02 - val_acc: 0.9941 - val_mDice: 0.5394

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:01,  1.60it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:01,  1.99it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:00<00:00,  2.53it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.92it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.31it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:50,  5.20it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:49,  5.35it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:50,  5.16it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:51,  5.12it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:47,  5.50it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<00:44,  5.78it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:43,  5.99it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:42,  6.12it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:41,  6.24it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:40,  6.29it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:40,  6.36it/s]predicting train subjects:   5%|▍         | 12/266 [00:02<00:39,  6.41it/s]predicting train subjects:   5%|▍         | 13/266 [00:02<00:38,  6.50it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:38,  6.57it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:37,  6.62it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:37,  6.60it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:38,  6.54it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:37,  6.54it/s]predicting train subjects:   7%|▋         | 19/266 [00:03<00:37,  6.57it/s]predicting train subjects:   8%|▊         | 20/266 [00:03<00:37,  6.57it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:37,  6.55it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:36,  6.61it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:35,  6.82it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:34,  7.02it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:33,  7.12it/s]predicting train subjects:  10%|▉         | 26/266 [00:04<00:33,  7.22it/s]predicting train subjects:  10%|█         | 27/266 [00:04<00:33,  7.21it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:32,  7.26it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:32,  7.35it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:32,  7.35it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:31,  7.38it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:32,  7.30it/s]predicting train subjects:  12%|█▏        | 33/266 [00:05<00:31,  7.32it/s]predicting train subjects:  13%|█▎        | 34/266 [00:05<00:31,  7.35it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:31,  7.30it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:31,  7.29it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:31,  7.33it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:31,  7.34it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:30,  7.34it/s]predicting train subjects:  15%|█▌        | 40/266 [00:05<00:30,  7.39it/s]predicting train subjects:  15%|█▌        | 41/266 [00:06<00:30,  7.33it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:30,  7.33it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:30,  7.40it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:29,  7.43it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:29,  7.48it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:29,  7.51it/s]predicting train subjects:  18%|█▊        | 47/266 [00:06<00:29,  7.46it/s]predicting train subjects:  18%|█▊        | 48/266 [00:07<00:29,  7.34it/s]predicting train subjects:  18%|█▊        | 49/266 [00:07<00:29,  7.27it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:29,  7.20it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:30,  7.13it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:30,  7.12it/s]predicting train subjects:  20%|█▉        | 53/266 [00:07<00:29,  7.13it/s]predicting train subjects:  20%|██        | 54/266 [00:07<00:29,  7.13it/s]predicting train subjects:  21%|██        | 55/266 [00:08<00:29,  7.07it/s]predicting train subjects:  21%|██        | 56/266 [00:08<00:29,  7.05it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:29,  7.06it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:29,  7.07it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:30,  6.83it/s]predicting train subjects:  23%|██▎       | 60/266 [00:08<00:30,  6.70it/s]predicting train subjects:  23%|██▎       | 61/266 [00:08<00:31,  6.57it/s]predicting train subjects:  23%|██▎       | 62/266 [00:09<00:31,  6.49it/s]predicting train subjects:  24%|██▎       | 63/266 [00:09<00:31,  6.47it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:31,  6.47it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:30,  6.53it/s]predicting train subjects:  25%|██▍       | 66/266 [00:09<00:30,  6.53it/s]predicting train subjects:  25%|██▌       | 67/266 [00:09<00:30,  6.50it/s]predicting train subjects:  26%|██▌       | 68/266 [00:10<00:30,  6.44it/s]predicting train subjects:  26%|██▌       | 69/266 [00:10<00:30,  6.40it/s]predicting train subjects:  26%|██▋       | 70/266 [00:10<00:30,  6.42it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:30,  6.39it/s]predicting train subjects:  27%|██▋       | 72/266 [00:10<00:30,  6.39it/s]predicting train subjects:  27%|██▋       | 73/266 [00:10<00:30,  6.37it/s]predicting train subjects:  28%|██▊       | 74/266 [00:10<00:29,  6.47it/s]predicting train subjects:  28%|██▊       | 75/266 [00:11<00:29,  6.55it/s]predicting train subjects:  29%|██▊       | 76/266 [00:11<00:29,  6.54it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:33,  5.59it/s]predicting train subjects:  29%|██▉       | 78/266 [00:11<00:36,  5.19it/s]predicting train subjects:  30%|██▉       | 79/266 [00:11<00:33,  5.54it/s]predicting train subjects:  30%|███       | 80/266 [00:12<00:33,  5.56it/s]predicting train subjects:  30%|███       | 81/266 [00:12<00:36,  5.06it/s]predicting train subjects:  31%|███       | 82/266 [00:12<00:35,  5.22it/s]predicting train subjects:  31%|███       | 83/266 [00:12<00:34,  5.36it/s]predicting train subjects:  32%|███▏      | 84/266 [00:12<00:33,  5.51it/s]predicting train subjects:  32%|███▏      | 85/266 [00:12<00:32,  5.59it/s]predicting train subjects:  32%|███▏      | 86/266 [00:13<00:32,  5.61it/s]predicting train subjects:  33%|███▎      | 87/266 [00:13<00:31,  5.60it/s]predicting train subjects:  33%|███▎      | 88/266 [00:13<00:31,  5.62it/s]predicting train subjects:  33%|███▎      | 89/266 [00:13<00:31,  5.63it/s]predicting train subjects:  34%|███▍      | 90/266 [00:13<00:31,  5.63it/s]predicting train subjects:  34%|███▍      | 91/266 [00:14<00:30,  5.65it/s]predicting train subjects:  35%|███▍      | 92/266 [00:14<00:30,  5.65it/s]predicting train subjects:  35%|███▍      | 93/266 [00:14<00:31,  5.52it/s]predicting train subjects:  35%|███▌      | 94/266 [00:14<00:30,  5.55it/s]predicting train subjects:  36%|███▌      | 95/266 [00:14<00:30,  5.57it/s]predicting train subjects:  36%|███▌      | 96/266 [00:14<00:30,  5.52it/s]predicting train subjects:  36%|███▋      | 97/266 [00:15<00:30,  5.56it/s]predicting train subjects:  37%|███▋      | 98/266 [00:15<00:29,  5.64it/s]predicting train subjects:  37%|███▋      | 99/266 [00:15<00:29,  5.67it/s]predicting train subjects:  38%|███▊      | 100/266 [00:15<00:28,  5.83it/s]predicting train subjects:  38%|███▊      | 101/266 [00:15<00:27,  5.93it/s]predicting train subjects:  38%|███▊      | 102/266 [00:15<00:27,  5.99it/s]predicting train subjects:  39%|███▊      | 103/266 [00:16<00:27,  5.99it/s]predicting train subjects:  39%|███▉      | 104/266 [00:16<00:27,  5.97it/s]predicting train subjects:  39%|███▉      | 105/266 [00:16<00:26,  5.99it/s]predicting train subjects:  40%|███▉      | 106/266 [00:16<00:26,  6.00it/s]predicting train subjects:  40%|████      | 107/266 [00:16<00:26,  6.04it/s]predicting train subjects:  41%|████      | 108/266 [00:16<00:26,  6.02it/s]predicting train subjects:  41%|████      | 109/266 [00:17<00:26,  6.01it/s]predicting train subjects:  41%|████▏     | 110/266 [00:17<00:26,  5.97it/s]predicting train subjects:  42%|████▏     | 111/266 [00:17<00:26,  5.87it/s]predicting train subjects:  42%|████▏     | 112/266 [00:17<00:26,  5.91it/s]predicting train subjects:  42%|████▏     | 113/266 [00:17<00:25,  5.92it/s]predicting train subjects:  43%|████▎     | 114/266 [00:17<00:25,  5.91it/s]predicting train subjects:  43%|████▎     | 115/266 [00:18<00:25,  6.00it/s]predicting train subjects:  44%|████▎     | 116/266 [00:18<00:24,  6.08it/s]predicting train subjects:  44%|████▍     | 117/266 [00:18<00:24,  6.05it/s]predicting train subjects:  44%|████▍     | 118/266 [00:18<00:23,  6.22it/s]predicting train subjects:  45%|████▍     | 119/266 [00:18<00:23,  6.34it/s]predicting train subjects:  45%|████▌     | 120/266 [00:18<00:22,  6.45it/s]predicting train subjects:  45%|████▌     | 121/266 [00:19<00:22,  6.56it/s]predicting train subjects:  46%|████▌     | 122/266 [00:19<00:21,  6.57it/s]predicting train subjects:  46%|████▌     | 123/266 [00:19<00:21,  6.58it/s]predicting train subjects:  47%|████▋     | 124/266 [00:19<00:21,  6.59it/s]predicting train subjects:  47%|████▋     | 125/266 [00:19<00:21,  6.61it/s]predicting train subjects:  47%|████▋     | 126/266 [00:19<00:21,  6.60it/s]predicting train subjects:  48%|████▊     | 127/266 [00:19<00:21,  6.58it/s]predicting train subjects:  48%|████▊     | 128/266 [00:20<00:20,  6.61it/s]predicting train subjects:  48%|████▊     | 129/266 [00:20<00:21,  6.44it/s]predicting train subjects:  49%|████▉     | 130/266 [00:20<00:21,  6.44it/s]predicting train subjects:  49%|████▉     | 131/266 [00:20<00:21,  6.38it/s]predicting train subjects:  50%|████▉     | 132/266 [00:20<00:20,  6.38it/s]predicting train subjects:  50%|█████     | 133/266 [00:20<00:20,  6.42it/s]predicting train subjects:  50%|█████     | 134/266 [00:21<00:20,  6.46it/s]predicting train subjects:  51%|█████     | 135/266 [00:21<00:20,  6.47it/s]predicting train subjects:  51%|█████     | 136/266 [00:21<00:19,  6.64it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:21<00:19,  6.76it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:21<00:18,  6.84it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:21<00:18,  6.91it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:21<00:18,  6.92it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:22<00:18,  6.92it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:22<00:17,  6.94it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:22<00:17,  6.90it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:22<00:17,  6.90it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:22<00:17,  6.91it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:22<00:17,  6.89it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:22<00:17,  6.92it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:23<00:16,  6.95it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:23<00:16,  6.92it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:23<00:16,  6.92it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:23<00:16,  6.95it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:23<00:16,  6.97it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:23<00:16,  6.96it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:23<00:17,  6.50it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:24<00:17,  6.20it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:24<00:18,  6.03it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:24<00:18,  5.97it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:24<00:18,  5.89it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:24<00:18,  5.84it/s]predicting train subjects:  60%|██████    | 160/266 [00:25<00:18,  5.82it/s]predicting train subjects:  61%|██████    | 161/266 [00:25<00:18,  5.79it/s]predicting train subjects:  61%|██████    | 162/266 [00:25<00:17,  5.79it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:25<00:17,  5.79it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:25<00:17,  5.78it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:25<00:17,  5.75it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:26<00:17,  5.72it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:26<00:17,  5.72it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:26<00:17,  5.75it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:26<00:16,  5.73it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:26<00:16,  5.72it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:26<00:16,  5.71it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:27<00:17,  5.39it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:27<00:18,  4.99it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:27<00:18,  4.90it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:27<00:16,  5.41it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:27<00:16,  5.37it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:28<00:15,  5.58it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:28<00:15,  5.75it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:28<00:14,  5.88it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:28<00:14,  5.94it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:28<00:14,  6.01it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:28<00:13,  6.06it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:29<00:13,  6.11it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:29<00:13,  6.18it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:29<00:12,  6.25it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:29<00:12,  6.29it/s]predicting train subjects:  70%|███████   | 187/266 [00:29<00:12,  6.25it/s]predicting train subjects:  71%|███████   | 188/266 [00:29<00:12,  6.22it/s]predicting train subjects:  71%|███████   | 189/266 [00:30<00:12,  6.17it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:30<00:12,  6.15it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:30<00:12,  6.21it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:30<00:11,  6.25it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:30<00:11,  6.32it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:30<00:11,  6.26it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:30<00:11,  6.07it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:31<00:11,  5.99it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:31<00:11,  5.90it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:31<00:11,  5.87it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:31<00:11,  5.69it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:31<00:11,  5.71it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:32<00:11,  5.51it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:32<00:11,  5.59it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:32<00:10,  5.74it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:32<00:10,  5.82it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:32<00:10,  5.80it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:32<00:10,  5.82it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:33<00:10,  5.84it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:33<00:09,  5.88it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:33<00:09,  5.88it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:33<00:09,  5.86it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:33<00:09,  5.85it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:33<00:09,  5.85it/s]predicting train subjects:  80%|████████  | 213/266 [00:34<00:08,  5.96it/s]predicting train subjects:  80%|████████  | 214/266 [00:34<00:08,  6.02it/s]predicting train subjects:  81%|████████  | 215/266 [00:34<00:08,  6.03it/s]predicting train subjects:  81%|████████  | 216/266 [00:34<00:08,  6.03it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:34<00:08,  6.04it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:34<00:07,  6.00it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:35<00:07,  6.02it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:35<00:07,  6.05it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:35<00:07,  6.06it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:35<00:07,  6.06it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:35<00:07,  6.01it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:35<00:07,  5.98it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:36<00:06,  6.01it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:36<00:06,  5.99it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:36<00:06,  6.04it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:36<00:06,  6.09it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:36<00:06,  6.12it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:36<00:05,  6.22it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:37<00:05,  6.51it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:37<00:05,  6.73it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:37<00:04,  6.90it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:37<00:04,  7.03it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:37<00:04,  7.07it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:37<00:04,  7.11it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:37<00:04,  7.11it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:38<00:03,  7.11it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:38<00:03,  7.14it/s]predicting train subjects:  90%|█████████ | 240/266 [00:38<00:03,  7.13it/s]predicting train subjects:  91%|█████████ | 241/266 [00:38<00:03,  7.13it/s]predicting train subjects:  91%|█████████ | 242/266 [00:38<00:03,  7.14it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:38<00:03,  7.15it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:38<00:03,  7.16it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:38<00:02,  7.16it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:39<00:02,  7.11it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:39<00:02,  7.11it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:39<00:02,  7.12it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:39<00:02,  7.02it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:39<00:02,  6.95it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:39<00:02,  6.87it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:40<00:02,  6.83it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:40<00:01,  6.82it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:40<00:01,  6.79it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:40<00:01,  6.75it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:40<00:01,  6.76it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:40<00:01,  6.76it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:40<00:01,  6.75it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:41<00:01,  6.74it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:41<00:00,  6.70it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:41<00:00,  6.69it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:41<00:00,  6.72it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:41<00:00,  6.72it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:41<00:00,  6.71it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:41<00:00,  6.72it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.72it/s]predicting train subjects: 100%|██████████| 266/266 [00:42<00:00,  6.32it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 74.32it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/266 [00:00<00:03, 77.83it/s]saving BB  train1-THALAMUS:   6%|▌         | 16/266 [00:00<00:03, 77.86it/s]saving BB  train1-THALAMUS:   9%|▉         | 24/266 [00:00<00:03, 78.16it/s]saving BB  train1-THALAMUS:  12%|█▏        | 33/266 [00:00<00:02, 80.14it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:02, 80.67it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:02, 82.04it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:00<00:02, 84.79it/s]saving BB  train1-THALAMUS:  26%|██▋       | 70/266 [00:00<00:02, 84.28it/s]saving BB  train1-THALAMUS:  30%|██▉       | 79/266 [00:00<00:02, 79.76it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:02, 75.22it/s]saving BB  train1-THALAMUS:  36%|███▌      | 95/266 [00:01<00:02, 72.02it/s]saving BB  train1-THALAMUS:  39%|███▊      | 103/266 [00:01<00:02, 70.06it/s]saving BB  train1-THALAMUS:  41%|████▏     | 110/266 [00:01<00:02, 69.51it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:01<00:02, 70.55it/s]saving BB  train1-THALAMUS:  47%|████▋     | 126/266 [00:01<00:01, 70.83it/s]saving BB  train1-THALAMUS:  50%|█████     | 134/266 [00:01<00:01, 69.81it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 143/266 [00:01<00:01, 72.99it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 152/266 [00:01<00:01, 75.28it/s]saving BB  train1-THALAMUS:  60%|██████    | 160/266 [00:02<00:01, 73.56it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 168/266 [00:02<00:01, 73.00it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 176/266 [00:02<00:01, 73.58it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 74.59it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 192/266 [00:02<00:00, 75.34it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 200/266 [00:02<00:00, 74.44it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 208/266 [00:02<00:00, 73.77it/s]saving BB  train1-THALAMUS:  81%|████████  | 216/266 [00:02<00:00, 73.30it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 224/266 [00:02<00:00, 72.10it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 232/266 [00:03<00:00, 72.54it/s]saving BB  train1-THALAMUS:  91%|█████████ | 241/266 [00:03<00:00, 75.94it/s]saving BB  train1-THALAMUS:  94%|█████████▍| 250/266 [00:03<00:00, 78.91it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 259/266 [00:03<00:00, 80.14it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 76.12it/s]
Epoch 00058: val_mDice did not improve from 0.54697
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [-0.0190734961636309, 0.07320765233956851, 0.048503680316449395, -0.020685989788684894, -0.020680305827640126, 0.021719411791997868, 0.04690563039063816, 0.053933377893036115, 0.02812963938594752, -0.03912267392089882, -0.03966966411907679, 0.0005639199879270037, -0.005578042111976567, -0.016721069812774658, -0.02084753634616104, 0.01838217224583732, -0.024905187431399342, 0.04713095388104839, 0.07455097179554827, 0.027783370676170805, -0.022461211932799954, -0.011222561483939292, 0.08498392625718791, 0.025624803625620328, 0.0011669472414565737, -0.0002106022524182909, 0.02785711829774729, 0.0016521536386930025, -0.024137243887330996, 0.026331604525409915, 0.04937454333376352, 0.023999912234453056, 0.02433435733501728, 0.02175520445513666, 0.0009573845946167598, 0.012030326551006686, -0.026241815119759912, 0.004291017653036946, -0.021380735575117486, 0.025311950418552748, 0.0003133201717442969, 0.009212886170477193, 0.000831083572532048, -0.024869201311994132, -0.03536145074787566, -0.0545086467976014, -0.07224595265707957, -0.0251512142919725, -0.004152936283175466, -0.07223572687386874, -0.07347585937521298, -0.027349951249494152, -0.047780106588273724, -0.0493971510205612, -0.049564563163160984, -0.048645894743372727, -0.02390951568967947, -0.04858520726855872], 'val_acc': [0.9939343813926943, 0.99379562385029, 0.9937590387263902, 0.993785940683805, 0.9939742884032484, 0.9942533224451335, 0.9940362594855334, 0.9935997183210501, 0.9940861425092143, 0.9942397139504293, 0.9942596689347298, 0.9941753231857906, 0.9940568179113989, 0.9941333056087825, 0.9939301484275989, 0.9941444899840627, 0.9942766007951116, 0.9938409662719991, 0.9942829517217783, 0.9941160720276182, 0.9941979980942037, 0.9941904388053837, 0.9939286383446629, 0.9941142572658529, 0.9940017982392986, 0.9942243025261475, 0.993867264787849, 0.9940510719053207, 0.994175021465008, 0.9940562129908105, 0.9940894688329389, 0.9942040458210645, 0.9941662567720816, 0.9941828839536341, 0.9941063977352739, 0.9941674666132584, 0.9943292052219287, 0.9941828839536341, 0.9941218180336964, 0.9940755571384288, 0.9940791910990296, 0.9940193305831985, 0.9940586326731642, 0.9940111708108604, 0.9942055573830237, 0.9940223581441875, 0.9941593009248265, 0.9941992064563572, 0.9942143235549737, 0.9941762342642317, 0.9941874171604885, 0.994233067219074, 0.9942097888690958, 0.9942070659869362, 0.9941729064614838, 0.9941496295905291, 0.9941765330269674, 0.9941463032668045], 'val_mDice': [0.5323831910826732, 0.5414663775877163, 0.5409598842300197, 0.5348709910858431, 0.5352410550458038, 0.5421650943995705, 0.5468926806160002, 0.5348385191954691, 0.5376482680532388, 0.5389164773650265, 0.5399365418084502, 0.540710856347829, 0.5436338698745661, 0.542297100823918, 0.5348406423336223, 0.5408676240417561, 0.5431211372564729, 0.5469670233596348, 0.5442857733065674, 0.5402158862603805, 0.5418046898492809, 0.5436864595111487, 0.540140211656135, 0.5413342076850588, 0.5392315044592391, 0.5417246147805349, 0.5355337313919473, 0.5385992981068254, 0.5404642849199234, 0.5385623779841155, 0.5410339322782332, 0.5424496938217959, 0.5425444762996645, 0.5405665586515337, 0.5395853915078468, 0.5408180266544778, 0.5442795871061368, 0.5413309268413051, 0.5406299078139123, 0.5405652507820841, 0.5409259240029846, 0.5387893086963705, 0.5387107055477114, 0.54173125707482, 0.5380478632583215, 0.538478863446353, 0.5370734683781049, 0.5411790322429193, 0.5412186748780329, 0.5388067540696477, 0.5409188294972734, 0.5437823745512194, 0.5412625275533784, 0.5410423682590572, 0.5405837323322485, 0.5395431842460822, 0.5396776361663643, 0.5394135263979566], 'loss': [0.07161483447644341, 0.05099326495458075, 0.04625633464184736, 0.04361816534817052, 0.04126118804232049, 0.03947993037617539, 0.03813932994087026, 0.03699885351807917, 0.036143821623830875, 0.03559443371083822, 0.0349631870472141, 0.03503424872480343, 0.03360748647308199, 0.0336064468434496, 0.03329492853010874, 0.03254600702579993, 0.03225422030059487, 0.0316776683074048, 0.031646070791508864, 0.031014736608840236, 0.031168127891071873, 0.03111007336294128, 0.029412154643527224, 0.029168147019442238, 0.028887450966269577, 0.028670024255964294, 0.02847894151631745, 0.02814017096390597, 0.02821612104943643, 0.028387755746174467, 0.027948792310972057, 0.027567272042221543, 0.027898808237620743, 0.027813776417547044, 0.027547350577427496, 0.027290559828456875, 0.027592439454019718, 0.026800459314335907, 0.02655057906205736, 0.026593710590827196, 0.026611059889119243, 0.02610517891583032, 0.026224609202537275, 0.02641974288496513, 0.025957390307575528, 0.02596611653114158, 0.02596361088275122, 0.0261937790354558, 0.025666390483408637, 0.026063400568602253, 0.025774364999839903, 0.025667572869738888, 0.02542702611924981, 0.025546561381732467, 0.025198523098284714, 0.025378771458489047, 0.02567316750840873, 0.025147968315381436], 'acc': [0.9925103060536847, 0.9945584448890196, 0.9950290611318037, 0.9952795097274448, 0.9954889135084415, 0.9956262819969176, 0.9957486705717715, 0.9958363814022516, 0.9959236030612166, 0.9959755739974319, 0.9960368925785397, 0.9960386681738165, 0.9961385384459861, 0.9961697911038389, 0.9961956541271351, 0.9962534032130247, 0.9962504422441237, 0.9962972217129302, 0.9963247425516638, 0.996369611226606, 0.9963560345279534, 0.9963956101931732, 0.9965123154884727, 0.9965499364363366, 0.9965602407856375, 0.9965928629037508, 0.996601203492498, 0.9966214067023321, 0.9966125103870451, 0.9966272414222798, 0.9966517747745294, 0.9966489061506719, 0.9966546093569317, 0.9966686058474125, 0.9966923484013395, 0.9966861501088939, 0.99669380046584, 0.9967362360541028, 0.9967515363785339, 0.9967773731624334, 0.9967744343970866, 0.9967830859297457, 0.996788513782833, 0.9967922709425927, 0.9967937583110864, 0.9967996280654006, 0.9968086656437385, 0.9968074358972445, 0.9968119758735172, 0.9968103267931328, 0.9968157505632996, 0.9968288205218964, 0.9968501303058487, 0.9968575217568576, 0.9968484368654337, 0.9968619571179269, 0.9968461409203669, 0.9968515122074607], 'mDice': [0.8606523638232859, 0.90078031380911, 0.909996571910692, 0.9151382392256705, 0.9197404361679351, 0.9232285366188797, 0.9258419882329323, 0.9280741033374669, 0.929738403637736, 0.9308071918306771, 0.9320360629704247, 0.9318922003190139, 0.9346915709875658, 0.9346783126497026, 0.9352865272832934, 0.9367512605756407, 0.9373326724032844, 0.9384614968921291, 0.9385130919086503, 0.9397495937011876, 0.9394496419822321, 0.9395486896957526, 0.9428776283740757, 0.9433434774521787, 0.9438968822622176, 0.9443210721991723, 0.9446934482265017, 0.9453625778992023, 0.9452113969212862, 0.9448614373119442, 0.9457288110830543, 0.9464934674041684, 0.945824003475536, 0.9459887898224224, 0.9465108180436398, 0.9470248101446987, 0.946417913254913, 0.9479729642244562, 0.94846456419106, 0.9483691783306406, 0.9483331398910174, 0.9493391617523791, 0.9490988697377061, 0.9487053580668273, 0.9496281902429027, 0.9496082518536764, 0.9496083277600438, 0.9491505494170464, 0.9502017923898328, 0.9494083578232041, 0.9499820587648222, 0.9501910993670616, 0.950662158444067, 0.9504162012148358, 0.9511142062072634, 0.9507495905446195, 0.950159706404831, 0.9512144325023801], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<04:17,  1.03it/s]Loading train:   1%|          | 2/266 [00:01<04:04,  1.08it/s]Loading train:   1%|          | 3/266 [00:02<03:53,  1.13it/s]Loading train:   2%|▏         | 4/266 [00:03<03:56,  1.11it/s]Loading train:   2%|▏         | 5/266 [00:04<03:35,  1.21it/s]Loading train:   2%|▏         | 6/266 [00:04<03:20,  1.30it/s]Loading train:   3%|▎         | 7/266 [00:05<03:08,  1.37it/s]Loading train:   3%|▎         | 8/266 [00:06<03:00,  1.43it/s]Loading train:   3%|▎         | 9/266 [00:06<02:54,  1.47it/s]Loading train:   4%|▍         | 10/266 [00:07<02:50,  1.50it/s]Loading train:   4%|▍         | 11/266 [00:07<02:47,  1.52it/s]Loading train:   5%|▍         | 12/266 [00:08<02:45,  1.54it/s]Loading train:   5%|▍         | 13/266 [00:09<02:42,  1.55it/s]Loading train:   5%|▌         | 14/266 [00:09<02:42,  1.55it/s]Loading train:   6%|▌         | 15/266 [00:10<02:39,  1.57it/s]Loading train:   6%|▌         | 16/266 [00:11<02:40,  1.56it/s]Loading train:   6%|▋         | 17/266 [00:11<02:37,  1.58it/s]Loading train:   7%|▋         | 18/266 [00:12<02:35,  1.59it/s]Loading train:   7%|▋         | 19/266 [00:13<02:34,  1.59it/s]Loading train:   8%|▊         | 20/266 [00:13<02:34,  1.59it/s]Loading train:   8%|▊         | 21/266 [00:14<02:32,  1.60it/s]Loading train:   8%|▊         | 22/266 [00:14<02:32,  1.60it/s]Loading train:   9%|▊         | 23/266 [00:15<02:26,  1.66it/s]Loading train:   9%|▉         | 24/266 [00:15<02:21,  1.72it/s]Loading train:   9%|▉         | 25/266 [00:16<02:19,  1.73it/s]Loading train:  10%|▉         | 26/266 [00:17<02:16,  1.76it/s]Loading train:  10%|█         | 27/266 [00:17<02:15,  1.77it/s]Loading train:  11%|█         | 28/266 [00:18<02:13,  1.78it/s]Loading train:  11%|█         | 29/266 [00:18<02:13,  1.78it/s]Loading train:  11%|█▏        | 30/266 [00:19<02:13,  1.77it/s]Loading train:  12%|█▏        | 31/266 [00:19<02:12,  1.78it/s]Loading train:  12%|█▏        | 32/266 [00:20<02:11,  1.78it/s]Loading train:  12%|█▏        | 33/266 [00:21<02:11,  1.78it/s]Loading train:  13%|█▎        | 34/266 [00:21<02:09,  1.80it/s]Loading train:  13%|█▎        | 35/266 [00:22<02:08,  1.80it/s]Loading train:  14%|█▎        | 36/266 [00:22<02:08,  1.79it/s]Loading train:  14%|█▍        | 37/266 [00:23<02:07,  1.79it/s]Loading train:  14%|█▍        | 38/266 [00:23<02:07,  1.79it/s]Loading train:  15%|█▍        | 39/266 [00:24<02:06,  1.80it/s]Loading train:  15%|█▌        | 40/266 [00:24<02:04,  1.81it/s]Loading train:  15%|█▌        | 41/266 [00:25<02:06,  1.78it/s]Loading train:  16%|█▌        | 42/266 [00:26<02:05,  1.78it/s]Loading train:  16%|█▌        | 43/266 [00:26<02:06,  1.77it/s]Loading train:  17%|█▋        | 44/266 [00:27<02:06,  1.75it/s]Loading train:  17%|█▋        | 45/266 [00:27<02:07,  1.74it/s]Loading train:  17%|█▋        | 46/266 [00:28<02:07,  1.73it/s]Loading train:  18%|█▊        | 47/266 [00:28<02:06,  1.73it/s]Loading train:  18%|█▊        | 48/266 [00:29<02:07,  1.71it/s]Loading train:  18%|█▊        | 49/266 [00:30<02:08,  1.69it/s]Loading train:  19%|█▉        | 50/266 [00:30<02:07,  1.69it/s]Loading train:  19%|█▉        | 51/266 [00:31<02:05,  1.71it/s]Loading train:  20%|█▉        | 52/266 [00:31<02:04,  1.71it/s]Loading train:  20%|█▉        | 53/266 [00:32<02:04,  1.70it/s]Loading train:  20%|██        | 54/266 [00:33<02:03,  1.72it/s]Loading train:  21%|██        | 55/266 [00:33<02:02,  1.72it/s]Loading train:  21%|██        | 56/266 [00:34<02:01,  1.73it/s]Loading train:  21%|██▏       | 57/266 [00:34<02:01,  1.73it/s]Loading train:  22%|██▏       | 58/266 [00:35<01:59,  1.74it/s]Loading train:  22%|██▏       | 59/266 [00:35<02:02,  1.69it/s]Loading train:  23%|██▎       | 60/266 [00:36<02:04,  1.66it/s]Loading train:  23%|██▎       | 61/266 [00:37<02:05,  1.63it/s]Loading train:  23%|██▎       | 62/266 [00:37<02:07,  1.61it/s]Loading train:  24%|██▎       | 63/266 [00:38<02:07,  1.59it/s]Loading train:  24%|██▍       | 64/266 [00:39<02:08,  1.58it/s]Loading train:  24%|██▍       | 65/266 [00:39<02:07,  1.57it/s]Loading train:  25%|██▍       | 66/266 [00:40<02:10,  1.53it/s]Loading train:  25%|██▌       | 67/266 [00:41<02:15,  1.47it/s]Loading train:  26%|██▌       | 68/266 [00:41<02:16,  1.45it/s]Loading train:  26%|██▌       | 69/266 [00:42<02:18,  1.42it/s]Loading train:  26%|██▋       | 70/266 [00:43<02:19,  1.40it/s]Loading train:  27%|██▋       | 71/266 [00:44<02:21,  1.38it/s]Loading train:  27%|██▋       | 72/266 [00:44<02:23,  1.35it/s]Loading train:  27%|██▋       | 73/266 [00:45<02:23,  1.34it/s]Loading train:  28%|██▊       | 74/266 [00:46<02:17,  1.40it/s]Loading train:  28%|██▊       | 75/266 [00:47<02:11,  1.45it/s]Loading train:  29%|██▊       | 76/266 [00:47<02:08,  1.48it/s]Loading train:  29%|██▉       | 77/266 [00:48<02:32,  1.24it/s]Loading train:  29%|██▉       | 78/266 [00:49<02:40,  1.17it/s]Loading train:  30%|██▉       | 79/266 [00:50<02:41,  1.16it/s]Loading train:  30%|███       | 80/266 [00:51<02:39,  1.17it/s]Loading train:  30%|███       | 81/266 [00:52<02:47,  1.10it/s]Loading train:  31%|███       | 82/266 [00:53<02:38,  1.16it/s]Loading train:  31%|███       | 83/266 [00:53<02:31,  1.21it/s]Loading train:  32%|███▏      | 84/266 [00:54<02:25,  1.25it/s]Loading train:  32%|███▏      | 85/266 [00:55<02:21,  1.28it/s]Loading train:  32%|███▏      | 86/266 [00:56<02:17,  1.30it/s]Loading train:  33%|███▎      | 87/266 [00:56<02:15,  1.32it/s]Loading train:  33%|███▎      | 88/266 [00:57<02:14,  1.33it/s]Loading train:  33%|███▎      | 89/266 [00:58<02:14,  1.31it/s]Loading train:  34%|███▍      | 90/266 [00:59<02:13,  1.32it/s]Loading train:  34%|███▍      | 91/266 [00:59<02:12,  1.32it/s]Loading train:  35%|███▍      | 92/266 [01:00<02:10,  1.34it/s]Loading train:  35%|███▍      | 93/266 [01:01<02:08,  1.34it/s]Loading train:  35%|███▌      | 94/266 [01:02<02:08,  1.34it/s]Loading train:  36%|███▌      | 95/266 [01:02<02:08,  1.33it/s]Loading train:  36%|███▌      | 96/266 [01:03<02:07,  1.33it/s]Loading train:  36%|███▋      | 97/266 [01:04<02:07,  1.32it/s]Loading train:  37%|███▋      | 98/266 [01:05<02:06,  1.33it/s]Loading train:  37%|███▋      | 99/266 [01:05<02:05,  1.33it/s]Loading train:  38%|███▊      | 100/266 [01:06<01:59,  1.39it/s]Loading train:  38%|███▊      | 101/266 [01:07<01:56,  1.41it/s]Loading train:  38%|███▊      | 102/266 [01:07<01:54,  1.43it/s]Loading train:  39%|███▊      | 103/266 [01:08<01:51,  1.46it/s]Loading train:  39%|███▉      | 104/266 [01:09<01:48,  1.49it/s]Loading train:  39%|███▉      | 105/266 [01:09<01:47,  1.49it/s]Loading train:  40%|███▉      | 106/266 [01:10<01:45,  1.52it/s]Loading train:  40%|████      | 107/266 [01:11<01:43,  1.54it/s]Loading train:  41%|████      | 108/266 [01:11<01:42,  1.54it/s]Loading train:  41%|████      | 109/266 [01:12<01:41,  1.54it/s]Loading train:  41%|████▏     | 110/266 [01:13<01:40,  1.55it/s]Loading train:  42%|████▏     | 111/266 [01:13<01:40,  1.54it/s]Loading train:  42%|████▏     | 112/266 [01:14<01:40,  1.53it/s]Loading train:  42%|████▏     | 113/266 [01:15<01:39,  1.53it/s]Loading train:  43%|████▎     | 114/266 [01:15<01:38,  1.54it/s]Loading train:  43%|████▎     | 115/266 [01:16<01:37,  1.54it/s]Loading train:  44%|████▎     | 116/266 [01:16<01:36,  1.55it/s]Loading train:  44%|████▍     | 117/266 [01:17<01:36,  1.55it/s]Loading train:  44%|████▍     | 118/266 [01:18<01:34,  1.57it/s]Loading train:  45%|████▍     | 119/266 [01:18<01:33,  1.58it/s]Loading train:  45%|████▌     | 120/266 [01:19<01:31,  1.59it/s]Loading train:  45%|████▌     | 121/266 [01:20<01:30,  1.60it/s]Loading train:  46%|████▌     | 122/266 [01:20<01:31,  1.58it/s]Loading train:  46%|████▌     | 123/266 [01:21<01:30,  1.58it/s]Loading train:  47%|████▋     | 124/266 [01:22<01:29,  1.59it/s]Loading train:  47%|████▋     | 125/266 [01:22<01:27,  1.61it/s]Loading train:  47%|████▋     | 126/266 [01:23<01:26,  1.62it/s]Loading train:  48%|████▊     | 127/266 [01:23<01:27,  1.59it/s]Loading train:  48%|████▊     | 128/266 [01:24<01:26,  1.60it/s]Loading train:  48%|████▊     | 129/266 [01:25<01:27,  1.56it/s]Loading train:  49%|████▉     | 130/266 [01:25<01:26,  1.58it/s]Loading train:  49%|████▉     | 131/266 [01:26<01:24,  1.59it/s]Loading train:  50%|████▉     | 132/266 [01:27<01:24,  1.59it/s]Loading train:  50%|█████     | 133/266 [01:27<01:23,  1.60it/s]Loading train:  50%|█████     | 134/266 [01:28<01:22,  1.60it/s]Loading train:  51%|█████     | 135/266 [01:28<01:21,  1.61it/s]Loading train:  51%|█████     | 136/266 [01:29<01:18,  1.65it/s]Loading train:  52%|█████▏    | 137/266 [01:30<01:16,  1.70it/s]Loading train:  52%|█████▏    | 138/266 [01:30<01:14,  1.72it/s]Loading train:  52%|█████▏    | 139/266 [01:31<01:12,  1.74it/s]Loading train:  53%|█████▎    | 140/266 [01:31<01:11,  1.76it/s]Loading train:  53%|█████▎    | 141/266 [01:32<01:11,  1.75it/s]Loading train:  53%|█████▎    | 142/266 [01:32<01:11,  1.74it/s]Loading train:  54%|█████▍    | 143/266 [01:33<01:10,  1.74it/s]Loading train:  54%|█████▍    | 144/266 [01:34<01:10,  1.74it/s]Loading train:  55%|█████▍    | 145/266 [01:34<01:10,  1.71it/s]Loading train:  55%|█████▍    | 146/266 [01:35<01:11,  1.68it/s]Loading train:  55%|█████▌    | 147/266 [01:35<01:10,  1.69it/s]Loading train:  56%|█████▌    | 148/266 [01:36<01:08,  1.71it/s]Loading train:  56%|█████▌    | 149/266 [01:36<01:07,  1.73it/s]Loading train:  56%|█████▋    | 150/266 [01:37<01:06,  1.75it/s]Loading train:  57%|█████▋    | 151/266 [01:38<01:04,  1.77it/s]Loading train:  57%|█████▋    | 152/266 [01:38<01:04,  1.77it/s]Loading train:  58%|█████▊    | 153/266 [01:39<01:03,  1.77it/s]Loading train:  58%|█████▊    | 154/266 [01:39<01:05,  1.71it/s]Loading train:  58%|█████▊    | 155/266 [01:40<01:06,  1.68it/s]Loading train:  59%|█████▊    | 156/266 [01:41<01:06,  1.65it/s]Loading train:  59%|█████▉    | 157/266 [01:41<01:07,  1.62it/s]Loading train:  59%|█████▉    | 158/266 [01:42<01:07,  1.60it/s]Loading train:  60%|█████▉    | 159/266 [01:43<01:08,  1.57it/s]Loading train:  60%|██████    | 160/266 [01:43<01:09,  1.53it/s]Loading train:  61%|██████    | 161/266 [01:44<01:09,  1.52it/s]Loading train:  61%|██████    | 162/266 [01:45<01:07,  1.54it/s]Loading train:  61%|██████▏   | 163/266 [01:45<01:06,  1.54it/s]Loading train:  62%|██████▏   | 164/266 [01:46<01:06,  1.53it/s]Loading train:  62%|██████▏   | 165/266 [01:46<01:05,  1.54it/s]Loading train:  62%|██████▏   | 166/266 [01:47<01:04,  1.54it/s]Loading train:  63%|██████▎   | 167/266 [01:48<01:03,  1.55it/s]Loading train:  63%|██████▎   | 168/266 [01:48<01:04,  1.53it/s]Loading train:  64%|██████▎   | 169/266 [01:49<01:02,  1.54it/s]Loading train:  64%|██████▍   | 170/266 [01:50<01:02,  1.54it/s]Loading train:  64%|██████▍   | 171/266 [01:50<01:01,  1.54it/s]Loading train:  65%|██████▍   | 172/266 [01:51<01:09,  1.36it/s]Loading train:  65%|██████▌   | 173/266 [01:52<01:16,  1.22it/s]Loading train:  65%|██████▌   | 174/266 [01:53<01:19,  1.16it/s]Loading train:  66%|██████▌   | 175/266 [01:54<01:16,  1.19it/s]Loading train:  66%|██████▌   | 176/266 [01:55<01:14,  1.20it/s]Loading train:  67%|██████▋   | 177/266 [01:56<01:09,  1.27it/s]Loading train:  67%|██████▋   | 178/266 [01:56<01:05,  1.34it/s]Loading train:  67%|██████▋   | 179/266 [01:57<01:02,  1.38it/s]Loading train:  68%|██████▊   | 180/266 [01:58<01:00,  1.42it/s]Loading train:  68%|██████▊   | 181/266 [01:58<00:58,  1.46it/s]Loading train:  68%|██████▊   | 182/266 [01:59<00:56,  1.48it/s]Loading train:  69%|██████▉   | 183/266 [01:59<00:55,  1.50it/s]Loading train:  69%|██████▉   | 184/266 [02:00<00:54,  1.52it/s]Loading train:  70%|██████▉   | 185/266 [02:01<00:52,  1.54it/s]Loading train:  70%|██████▉   | 186/266 [02:01<00:52,  1.54it/s]Loading train:  70%|███████   | 187/266 [02:02<00:51,  1.54it/s]Loading train:  71%|███████   | 188/266 [02:03<00:50,  1.54it/s]Loading train:  71%|███████   | 189/266 [02:03<00:50,  1.54it/s]Loading train:  71%|███████▏  | 190/266 [02:04<00:49,  1.54it/s]Loading train:  72%|███████▏  | 191/266 [02:05<00:48,  1.54it/s]Loading train:  72%|███████▏  | 192/266 [02:05<00:47,  1.54it/s]Loading train:  73%|███████▎  | 193/266 [02:06<00:47,  1.55it/s]Loading train:  73%|███████▎  | 194/266 [02:07<00:46,  1.55it/s]Loading train:  73%|███████▎  | 195/266 [02:07<00:45,  1.55it/s]Loading train:  74%|███████▎  | 196/266 [02:08<00:45,  1.54it/s]Loading train:  74%|███████▍  | 197/266 [02:09<00:45,  1.53it/s]Loading train:  74%|███████▍  | 198/266 [02:09<00:44,  1.53it/s]Loading train:  75%|███████▍  | 199/266 [02:10<00:44,  1.51it/s]Loading train:  75%|███████▌  | 200/266 [02:11<00:43,  1.52it/s]Loading train:  76%|███████▌  | 201/266 [02:11<00:42,  1.53it/s]Loading train:  76%|███████▌  | 202/266 [02:12<00:41,  1.53it/s]Loading train:  76%|███████▋  | 203/266 [02:12<00:40,  1.54it/s]Loading train:  77%|███████▋  | 204/266 [02:13<00:40,  1.53it/s]Loading train:  77%|███████▋  | 205/266 [02:14<00:39,  1.53it/s]Loading train:  77%|███████▋  | 206/266 [02:14<00:39,  1.52it/s]Loading train:  78%|███████▊  | 207/266 [02:15<00:38,  1.52it/s]Loading train:  78%|███████▊  | 208/266 [02:16<00:37,  1.53it/s]Loading train:  79%|███████▊  | 209/266 [02:16<00:37,  1.52it/s]Loading train:  79%|███████▉  | 210/266 [02:17<00:37,  1.51it/s]Loading train:  79%|███████▉  | 211/266 [02:18<00:36,  1.51it/s]Loading train:  80%|███████▉  | 212/266 [02:18<00:36,  1.49it/s]Loading train:  80%|████████  | 213/266 [02:19<00:36,  1.47it/s]Loading train:  80%|████████  | 214/266 [02:20<00:35,  1.45it/s]Loading train:  81%|████████  | 215/266 [02:21<00:35,  1.45it/s]Loading train:  81%|████████  | 216/266 [02:21<00:34,  1.44it/s]Loading train:  82%|████████▏ | 217/266 [02:22<00:34,  1.44it/s]Loading train:  82%|████████▏ | 218/266 [02:23<00:33,  1.43it/s]Loading train:  82%|████████▏ | 219/266 [02:23<00:33,  1.42it/s]Loading train:  83%|████████▎ | 220/266 [02:24<00:32,  1.41it/s]Loading train:  83%|████████▎ | 221/266 [02:25<00:31,  1.41it/s]Loading train:  83%|████████▎ | 222/266 [02:26<00:31,  1.41it/s]Loading train:  84%|████████▍ | 223/266 [02:26<00:30,  1.42it/s]Loading train:  84%|████████▍ | 224/266 [02:27<00:29,  1.43it/s]Loading train:  85%|████████▍ | 225/266 [02:28<00:29,  1.41it/s]Loading train:  85%|████████▍ | 226/266 [02:28<00:28,  1.41it/s]Loading train:  85%|████████▌ | 227/266 [02:29<00:27,  1.41it/s]Loading train:  86%|████████▌ | 228/266 [02:30<00:26,  1.42it/s]Loading train:  86%|████████▌ | 229/266 [02:30<00:26,  1.42it/s]Loading train:  86%|████████▋ | 230/266 [02:31<00:25,  1.43it/s]Loading train:  87%|████████▋ | 231/266 [02:32<00:24,  1.46it/s]Loading train:  87%|████████▋ | 232/266 [02:32<00:23,  1.48it/s]Loading train:  88%|████████▊ | 233/266 [02:33<00:21,  1.50it/s]Loading train:  88%|████████▊ | 234/266 [02:34<00:20,  1.53it/s]Loading train:  88%|████████▊ | 235/266 [02:34<00:20,  1.55it/s]Loading train:  89%|████████▊ | 236/266 [02:35<00:19,  1.58it/s]Loading train:  89%|████████▉ | 237/266 [02:36<00:18,  1.60it/s]Loading train:  89%|████████▉ | 238/266 [02:36<00:17,  1.61it/s]Loading train:  90%|████████▉ | 239/266 [02:37<00:16,  1.62it/s]Loading train:  90%|█████████ | 240/266 [02:37<00:16,  1.62it/s]Loading train:  91%|█████████ | 241/266 [02:38<00:15,  1.62it/s]Loading train:  91%|█████████ | 242/266 [02:39<00:14,  1.62it/s]Loading train:  91%|█████████▏| 243/266 [02:39<00:14,  1.62it/s]Loading train:  92%|█████████▏| 244/266 [02:40<00:13,  1.62it/s]Loading train:  92%|█████████▏| 245/266 [02:40<00:12,  1.62it/s]Loading train:  92%|█████████▏| 246/266 [02:41<00:12,  1.63it/s]Loading train:  93%|█████████▎| 247/266 [02:42<00:11,  1.63it/s]Loading train:  93%|█████████▎| 248/266 [02:42<00:11,  1.62it/s]Loading train:  94%|█████████▎| 249/266 [02:43<00:10,  1.64it/s]Loading train:  94%|█████████▍| 250/266 [02:44<00:09,  1.64it/s]Loading train:  94%|█████████▍| 251/266 [02:44<00:09,  1.63it/s]Loading train:  95%|█████████▍| 252/266 [02:45<00:08,  1.63it/s]Loading train:  95%|█████████▌| 253/266 [02:46<00:10,  1.23it/s]Loading train:  95%|█████████▌| 254/266 [02:48<00:14,  1.22s/it]Loading train:  96%|█████████▌| 255/266 [02:51<00:19,  1.81s/it]Loading train:  96%|█████████▌| 256/266 [02:57<00:30,  3.06s/it]Loading train:  97%|█████████▋| 257/266 [03:02<00:32,  3.66s/it]Loading train:  97%|█████████▋| 258/266 [03:06<00:29,  3.69s/it]Loading train:  97%|█████████▋| 259/266 [03:10<00:25,  3.61s/it]Loading train:  98%|█████████▊| 260/266 [03:13<00:21,  3.62s/it]Loading train:  98%|█████████▊| 261/266 [03:17<00:17,  3.51s/it]Loading train:  98%|█████████▊| 262/266 [03:19<00:12,  3.11s/it]Loading train:  99%|█████████▉| 263/266 [03:21<00:08,  2.81s/it]Loading train:  99%|█████████▉| 264/266 [03:23<00:05,  2.64s/it]Loading train: 100%|█████████▉| 265/266 [03:25<00:02,  2.51s/it]Loading train: 100%|██████████| 266/266 [03:28<00:00,  2.44s/it]Loading train: 100%|██████████| 266/266 [03:28<00:00,  1.28it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:04, 64.05it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:04, 62.71it/s]concatenating: train:   7%|▋         | 19/266 [00:00<00:04, 59.98it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:03, 61.26it/s]concatenating: train:  12%|█▏        | 33/266 [00:00<00:03, 61.86it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:03, 63.69it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:03, 63.84it/s]concatenating: train:  21%|██        | 55/266 [00:00<00:03, 64.39it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:03, 63.92it/s]concatenating: train:  26%|██▌       | 69/266 [00:01<00:03, 63.75it/s]concatenating: train:  29%|██▊       | 76/266 [00:01<00:03, 63.19it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:02, 61.12it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:02, 58.67it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:02, 58.35it/s]concatenating: train:  39%|███▊      | 103/266 [00:01<00:02, 59.75it/s]concatenating: train:  41%|████▏     | 110/266 [00:01<00:02, 60.79it/s]concatenating: train:  44%|████▍     | 117/266 [00:01<00:02, 61.48it/s]concatenating: train:  47%|████▋     | 124/266 [00:02<00:02, 61.52it/s]concatenating: train:  49%|████▉     | 131/266 [00:02<00:02, 60.90it/s]concatenating: train:  52%|█████▏    | 138/266 [00:02<00:02, 61.85it/s]concatenating: train:  55%|█████▍    | 145/266 [00:02<00:01, 61.97it/s]concatenating: train:  57%|█████▋    | 152/266 [00:02<00:01, 63.50it/s]concatenating: train:  60%|█████▉    | 159/266 [00:02<00:01, 63.27it/s]concatenating: train:  63%|██████▎   | 167/266 [00:02<00:01, 64.71it/s]concatenating: train:  65%|██████▌   | 174/266 [00:02<00:01, 63.54it/s]concatenating: train:  68%|██████▊   | 181/266 [00:02<00:01, 60.13it/s]concatenating: train:  71%|███████   | 188/266 [00:03<00:01, 58.98it/s]concatenating: train:  73%|███████▎  | 194/266 [00:03<00:01, 58.37it/s]concatenating: train:  76%|███████▌  | 201/266 [00:03<00:01, 60.79it/s]concatenating: train:  78%|███████▊  | 208/266 [00:03<00:00, 62.77it/s]concatenating: train:  81%|████████  | 215/266 [00:03<00:00, 62.49it/s]concatenating: train:  83%|████████▎ | 222/266 [00:03<00:00, 58.17it/s]concatenating: train:  86%|████████▌ | 228/266 [00:03<00:00, 55.71it/s]concatenating: train:  88%|████████▊ | 234/266 [00:03<00:00, 54.51it/s]concatenating: train:  90%|█████████ | 240/266 [00:03<00:00, 53.28it/s]concatenating: train:  92%|█████████▏| 246/266 [00:04<00:00, 53.16it/s]concatenating: train:  95%|█████████▌| 253/266 [00:04<00:00, 55.71it/s]concatenating: train:  98%|█████████▊| 260/266 [00:04<00:00, 58.24it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 60.65it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:06<00:18,  6.18s/it]Loading test:  50%|█████     | 2/4 [00:10<00:11,  5.60s/it]Loading test:  75%|███████▌  | 3/4 [00:13<00:04,  4.97s/it]Loading test: 100%|██████████| 4/4 [00:21<00:00,  5.65s/it]Loading test: 100%|██████████| 4/4 [00:21<00:00,  5.29s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 80.16it/s] 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   2020-01-22 07:48:02.705496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 07:48:02.705586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 07:48:02.705599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 07:48:02.705607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 07:48:02.705906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1
------------------------------------------------------------------
class_weights [6.84497473e-02 3.28313571e-02 8.46195378e-02 1.02768486e-02
 2.88268451e-02 7.67631294e-03 8.69082241e-02 1.13054865e-01
 9.17967962e-02 1.37752314e-02 2.77269564e-01 1.84252219e-01
 2.62450832e-04]
Train on 16724 samples, validate on 249 samples
Epoch 1/300
 - 38s - loss: 0.4661 - acc: 0.9317 - mDice: 0.4975 - val_loss: 0.0164 - val_acc: 0.9485 - val_mDice: 0.2431

Epoch 00001: val_mDice improved from -inf to 0.24306, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 34s - loss: 0.3832 - acc: 0.9425 - mDice: 0.5869 - val_loss: -6.5418e-02 - val_acc: 0.9495 - val_mDice: 0.2387

Epoch 00002: val_mDice did not improve from 0.24306
Epoch 3/300
 - 34s - loss: 0.3632 - acc: 0.9449 - mDice: 0.6085 - val_loss: -6.3444e-02 - val_acc: 0.9481 - val_mDice: 0.2412

Epoch 00003: val_mDice did not improve from 0.24306
Epoch 4/300
 - 34s - loss: 0.3502 - acc: 0.9467 - mDice: 0.6226 - val_loss: -1.3677e-01 - val_acc: 0.9493 - val_mDice: 0.2437

Epoch 00004: val_mDice improved from 0.24306 to 0.24367, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 33s - loss: 0.3412 - acc: 0.9479 - mDice: 0.6323 - val_loss: -8.1638e-02 - val_acc: 0.9476 - val_mDice: 0.2367

Epoch 00005: val_mDice did not improve from 0.24367
Epoch 6/300
 - 33s - loss: 0.3360 - acc: 0.9487 - mDice: 0.6379 - val_loss: -1.0448e-01 - val_acc: 0.9493 - val_mDice: 0.2432

Epoch 00006: val_mDice did not improve from 0.24367
Epoch 7/300
 - 33s - loss: 0.3281 - acc: 0.9494 - mDice: 0.6464 - val_loss: -1.5647e-01 - val_acc: 0.9497 - val_mDice: 0.2426

Epoch 00007: val_mDice did not improve from 0.24367
Epoch 8/300
 - 33s - loss: 0.3270 - acc: 0.9499 - mDice: 0.6476 - val_loss: -1.3673e-01 - val_acc: 0.9506 - val_mDice: 0.2377

Epoch 00008: val_mDice did not improve from 0.24367
Epoch 9/300
 - 33s - loss: 0.3216 - acc: 0.9503 - mDice: 0.6534 - val_loss: -2.0261e-01 - val_acc: 0.9522 - val_mDice: 0.2409

Epoch 00009: val_mDice did not improve from 0.24367
Epoch 10/300
 - 34s - loss: 0.3172 - acc: 0.9507 - mDice: 0.6583 - val_loss: -1.0250e-01 - val_acc: 0.9507 - val_mDice: 0.2383

Epoch 00010: val_mDice did not improve from 0.24367
Epoch 11/300
 - 33s - loss: 0.3156 - acc: 0.9510 - mDice: 0.6600 - val_loss: -1.9970e-01 - val_acc: 0.9504 - val_mDice: 0.2372

Epoch 00011: val_mDice did not improve from 0.24367
Epoch 12/300
 - 34s - loss: 0.3137 - acc: 0.9514 - mDice: 0.6620 - val_loss: -1.6180e-01 - val_acc: 0.9522 - val_mDice: 0.2406

Epoch 00012: val_mDice did not improve from 0.24367
Epoch 13/300
 - 33s - loss: 0.3100 - acc: 0.9520 - mDice: 0.6660 - val_loss: -1.6721e-01 - val_acc: 0.9510 - val_mDice: 0.2426

Epoch 00013: val_mDice did not improve from 0.24367
Epoch 14/300
 - 32s - loss: 0.3115 - acc: 0.9517 - mDice: 0.6643 - val_loss: -9.2614e-02 - val_acc: 0.9505 - val_mDice: 0.2356

Epoch 00014: val_mDice did not improve from 0.24367
Epoch 15/300
 - 33s - loss: 0.3079 - acc: 0.9520 - mDice: 0.6682 - val_loss: -1.5978e-01 - val_acc: 0.9529 - val_mDice: 0.2430

Epoch 00015: val_mDice did not improve from 0.24367
Epoch 16/300
 - 34s - loss: 0.3018 - acc: 0.9521 - mDice: 0.6749 - val_loss: -1.7896e-01 - val_acc: 0.9524 - val_mDice: 0.2428

Epoch 00016: val_mDice did not improve from 0.24367

Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 17/300
 - 35s - loss: 0.2948 - acc: 0.9536 - mDice: 0.6824 - val_loss: -2.0307e-01 - val_acc: 0.9531 - val_mDice: 0.2449

Epoch 00017: val_mDice improved from 0.24367 to 0.24492, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 18/300
 - 33s - loss: 0.2888 - acc: 0.9542 - mDice: 0.6889 - val_loss: -1.6157e-01 - val_acc: 0.9509 - val_mDice: 0.2429

Epoch 00018: val_mDice did not improve from 0.24492
Epoch 19/300
 - 33s - loss: 0.2873 - acc: 0.9544 - mDice: 0.6905 - val_loss: -1.7906e-01 - val_acc: 0.9514 - val_mDice: 0.2418

Epoch 00019: val_mDice did not improve from 0.24492
Epoch 20/300
 - 32s - loss: 0.2874 - acc: 0.9545 - mDice: 0.6902 - val_loss: -1.5949e-01 - val_acc: 0.9521 - val_mDice: 0.2432

Epoch 00020: val_mDice did not improve from 0.24492
Epoch 21/300
 - 33s - loss: 0.2873 - acc: 0.9541 - mDice: 0.6854 - val_loss: -1.4642e-01 - val_acc: 0.9497 - val_mDice: 0.2440

Epoch 00021: val_mDice did not improve from 0.24492
Epoch 22/300
 - 32s - loss: 0.2776 - acc: 0.9530 - mDice: 0.6733 - val_loss: -1.6331e-01 - val_acc: 0.9512 - val_mDice: 0.2383

Epoch 00022: val_mDice did not improve from 0.24492
Epoch 23/300
 - 33s - loss: 0.2693 - acc: 0.9521 - mDice: 0.6630 - val_loss: -1.7638e-01 - val_acc: 0.9519 - val_mDice: 0.2446

Epoch 00023: val_mDice did not improve from 0.24492
Epoch 24/300
 - 33s - loss: 0.2546 - acc: 0.9512 - mDice: 0.6581 - val_loss: -2.2143e-01 - val_acc: 0.9510 - val_mDice: 0.2377

Epoch 00024: val_mDice did not improve from 0.24492
Epoch 25/300
 - 33s - loss: 0.2482 - acc: 0.9511 - mDice: 0.6560 - val_loss: -2.2862e-01 - val_acc: 0.9528 - val_mDice: 0.2382

Epoch 00025: val_mDice did not improve from 0.24492
Epoch 26/300
 - 32s - loss: 0.2373 - acc: 0.9514 - mDice: 0.6581 - val_loss: -2.3066e-01 - val_acc: 0.9533 - val_mDice: 0.2370

Epoch 00026: val_mDice did not improve from 0.24492
Epoch 27/300
 - 33s - loss: 0.2387 - acc: 0.9513 - mDice: 0.6545 - val_loss: -2.1449e-01 - val_acc: 0.9517 - val_mDice: 0.2353

Epoch 00027: val_mDice did not improve from 0.24492
Epoch 28/300
 - 32s - loss: 0.2371 - acc: 0.9513 - mDice: 0.6543 - val_loss: -2.1735e-01 - val_acc: 0.9511 - val_mDice: 0.2358

Epoch 00028: val_mDice did not improve from 0.24492
Epoch 29/300
 - 33s - loss: 0.2326 - acc: 0.9515 - mDice: 0.6518 - val_loss: -2.2319e-01 - val_acc: 0.9514 - val_mDice: 0.2237

Epoch 00029: val_mDice did not improve from 0.24492
Epoch 30/300
 - 33s - loss: 0.2312 - acc: 0.9520 - mDice: 0.6546 - val_loss: -2.3077e-01 - val_acc: 0.9519 - val_mDice: 0.2332

Epoch 00030: val_mDice did not improve from 0.24492
Epoch 31/300
 - 33s - loss: 0.2267 - acc: 0.9517 - mDice: 0.6538 - val_loss: -2.4518e-01 - val_acc: 0.9534 - val_mDice: 0.2392

Epoch 00031: val_mDice did not improve from 0.24492
Epoch 32/300
 - 32s - loss: 0.2311 - acc: 0.9514 - mDice: 0.6535 - val_loss: -2.0284e-01 - val_acc: 0.9524 - val_mDice: 0.2337

Epoch 00032: val_mDice did not improve from 0.24492

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 33/300
 - 32s - loss: 0.2210 - acc: 0.9521 - mDice: 0.6622 - val_loss: -2.1453e-01 - val_acc: 0.9527 - val_mDice: 0.2350

Epoch 00033: val_mDice did not improve from 0.24492
Epoch 34/300
 - 32s - loss: 0.2186 - acc: 0.9523 - mDice: 0.6616 - val_loss: -2.0913e-01 - val_acc: 0.9496 - val_mDice: 0.2328

Epoch 00034: val_mDice did not improve from 0.24492
Epoch 35/300
 - 34s - loss: 0.2181 - acc: 0.9523 - mDice: 0.6581 - val_loss: -2.3018e-01 - val_acc: 0.9526 - val_mDice: 0.2347

Epoch 00035: val_mDice did not improve from 0.24492
Epoch 36/300
 - 33s - loss: 0.2204 - acc: 0.9522 - mDice: 0.6579 - val_loss: -2.3977e-01 - val_acc: 0.9523 - val_mDice: 0.2299

Epoch 00036: val_mDice did not improve from 0.24492
Epoch 37/300
 - 33s - loss: 0.2136 - acc: 0.9527 - mDice: 0.6722 - val_loss: -2.4171e-01 - val_acc: 0.9531 - val_mDice: 0.2349

Epoch 00037: val_mDice did not improve from 0.24492
Epoch 38/300
 - 33s - loss: 0.2100 - acc: 0.9529 - mDice: 0.6657 - val_loss: -2.1850e-01 - val_acc: 0.9526 - val_mDice: 0.2326

Epoch 00038: val_mDice did not improve from 0.24492
Epoch 39/300
 - 33s - loss: 0.2044 - acc: 0.9532 - mDice: 0.6725 - val_loss: -2.4046e-01 - val_acc: 0.9535 - val_mDice: 0.2288

Epoch 00039: val_mDice did not improve from 0.24492
Epoch 40/300
 - 33s - loss: 0.2059 - acc: 0.9531 - mDice: 0.6688 - val_loss: -2.5254e-01 - val_acc: 0.9538 - val_mDice: 0.2364

Epoch 00040: val_mDice did not improve from 0.24492
Epoch 41/300
 - 33s - loss: 0.2044 - acc: 0.9531 - mDice: 0.6754 - val_loss: -2.3092e-01 - val_acc: 0.9523 - val_mDice: 0.2324

Epoch 00041: val_mDice did not improve from 0.24492
Epoch 42/300
 - 32s - loss: 0.2043 - acc: 0.9529 - mDice: 0.6694 - val_loss: -2.2992e-01 - val_acc: 0.9529 - val_mDice: 0.2382

Epoch 00042: val_mDice did not improve from 0.24492
Epoch 43/300
 - 33s - loss: 0.2044 - acc: 0.9530 - mDice: 0.6712 - val_loss: -2.5599e-01 - val_acc: 0.9534 - val_mDice: 0.2289

Epoch 00043: val_mDice did not improve from 0.24492
Epoch 44/300
 - 32s - loss: 0.2065 - acc: 0.9531 - mDice: 0.6709 - val_loss: -2.3732e-01 - val_acc: 0.9538 - val_mDice: 0.2396

Epoch 00044: val_mDice did not improve from 0.24492
Epoch 45/300
 - 33s - loss: 0.2014 - acc: 0.9534 - mDice: 0.6770 - val_loss: -2.4934e-01 - val_acc: 0.9532 - val_mDice: 0.2341

Epoch 00045: val_mDice did not improve from 0.24492
Epoch 46/300
 - 32s - loss: 0.2083 - acc: 0.9531 - mDice: 0.6750 - val_loss: -2.3793e-01 - val_acc: 0.9539 - val_mDice: 0.2401

Epoch 00046: val_mDice did not improve from 0.24492
Epoch 47/300
 - 33s - loss: 0.2019 - acc: 0.9532 - mDice: 0.6712 - val_loss: -2.4975e-01 - val_acc: 0.9527 - val_mDice: 0.2330

Epoch 00047: val_mDice did not improve from 0.24492

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 48/300
 - 33s - loss: 0.1991 - acc: 0.9536 - mDice: 0.6757 - val_loss: -2.5830e-01 - val_acc: 0.9535 - val_mDice: 0.2356

Epoch 00048: val_mDice did not improve from 0.24492
Epoch 49/300
 - 33s - loss: 0.1973 - acc: 0.9536 - mDice: 0.6772 - val_loss: -2.4154e-01 - val_acc: 0.9539 - val_mDice: 0.2332

Epoch 00049: val_mDice did not improve from 0.24492
Epoch 50/300
 - 33s - loss: 0.2014 - acc: 0.9537 - mDice: 0.6767 - val_loss: -2.3389e-01 - val_acc: 0.9539 - val_mDice: 0.2425

Epoch 00050: val_mDice did not improve from 0.24492
Epoch 51/300
 - 33s - loss: 0.1942 - acc: 0.9540 - mDice: 0.6813 - val_loss: -2.4887e-01 - val_acc: 0.9537 - val_mDice: 0.2387

Epoch 00051: val_mDice did not improve from 0.24492
Epoch 52/300
 - 33s - loss: 0.1948 - acc: 0.9539 - mDice: 0.6800 - val_loss: -2.3251e-01 - val_acc: 0.9534 - val_mDice: 0.2410

Epoch 00052: val_mDice did not improve from 0.24492
Epoch 53/300
 - 33s - loss: 0.1935 - acc: 0.9540 - mDice: 0.6817 - val_loss: -2.4318e-01 - val_acc: 0.9536 - val_mDice: 0.2327

Epoch 00053: val_mDice did not improve from 0.24492
Epoch 54/300
 - 33s - loss: 0.1938 - acc: 0.9540 - mDice: 0.6785 - val_loss: -2.4133e-01 - val_acc: 0.9537 - val_mDice: 0.2372

Epoch 00054: val_mDice did not improve from 0.24492
Epoch 55/300
 - 33s - loss: 0.1975 - acc: 0.9542 - mDice: 0.6817 - val_loss: -2.3444e-01 - val_acc: 0.9527 - val_mDice: 0.2355

Epoch 00055: val_mDice did not improve from 0.24492
Epoch 56/300
 - 34s - loss: 0.1955 - acc: 0.9542 - mDice: 0.6821 - val_loss: -2.3108e-01 - val_acc: 0.9531 - val_mDice: 0.2321

Epoch 00056: val_mDice did not improve from 0.24492
Epoch 57/300
 - 33s - loss: 0.1960 - acc: 0.9540 - mDice: 0.6809 - val_loss: -2.3505e-01 - val_acc: 0.9531 - val_mDice: 0.2306

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.30s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]
Epoch 00057: val_mDice did not improve from 0.24492
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [0.016374504470442194, -0.06541751149338651, -0.06344391052502706, -0.13677239902018304, -0.0816380288377105, -0.10447927486585326, -0.15647423505244484, -0.13673334735554146, -0.20260604692017098, -0.10250404712755277, -0.19970166651778912, -0.16179684233518848, -0.16721049938949356, -0.09261372922564366, -0.15978138039943324, -0.17895913089674162, -0.20307369327479338, -0.16157350398181194, -0.1790581318329137, -0.15948845992934513, -0.14642174567383934, -0.16330709320354653, -0.17637778742306204, -0.22142749910343842, -0.22861653367379103, -0.23066339195971508, -0.21448625274092317, -0.21735420981683884, -0.22319294908738518, -0.23076604586468644, -0.24517715183726277, -0.20284389952818552, -0.21453463441755877, -0.20913191088853988, -0.23017628161782722, -0.2397730104834679, -0.24170590874301381, -0.2184998235519392, -0.2404603567946867, -0.2525359746143521, -0.23092067765210378, -0.2299196039995994, -0.2559901250144803, -0.23731675872721347, -0.2493410409394517, -0.2379257679584036, -0.24975352813492072, -0.2583010546623703, -0.24153902412328615, -0.23388996552750768, -0.24887394421849865, -0.23250677692423383, -0.24317602851682985, -0.24132707979844278, -0.2344433548878953, -0.2310810321156519, -0.23505101268400388], 'val_acc': [0.9485280882402596, 0.9494918793080801, 0.9480904393406757, 0.9492505245419391, 0.9475980836703596, 0.9492714457722553, 0.949697830112105, 0.9505747386729382, 0.9522046547338187, 0.9506777125190061, 0.9503655653880781, 0.952182122502461, 0.9509914558096583, 0.9505345055377148, 0.9528691660927002, 0.9524089916642889, 0.9530606403887032, 0.9509319277652296, 0.9513985476340635, 0.9521032808774925, 0.9496656479126957, 0.9512167225879837, 0.9519488189115103, 0.9510493850612257, 0.95281607151989, 0.9532730289731159, 0.9517026435898011, 0.9510912260856016, 0.9513776244887386, 0.9518538909743589, 0.9534339270438535, 0.9524234849286367, 0.9526567822958092, 0.9496447305123968, 0.9525988578317635, 0.9523430279938572, 0.9531185593470991, 0.9525731122158617, 0.9535288643166722, 0.9538023881165378, 0.9523381957088608, 0.9529464038979097, 0.9534114024725305, 0.9538297394672072, 0.9531604046802444, 0.9539295004074833, 0.9527259662926916, 0.95354172814802, 0.9538892797198162, 0.9538780168357145, 0.953673673920842, 0.9534323179578207, 0.9536350544197971, 0.9536945829429779, 0.9526970082497501, 0.9531137395096592, 0.9530525944797869], 'val_mDice': [0.24306089083952118, 0.23873709848367544, 0.24122117770962925, 0.24367277144667615, 0.23667128246472063, 0.2432047458417923, 0.24264026451182652, 0.23765719134405436, 0.24088003070478936, 0.23831934736196295, 0.23724010823122468, 0.24056391516722828, 0.24260684955550962, 0.23563864593764386, 0.24301649929289837, 0.2427769181240036, 0.2449181277349771, 0.24288084363961315, 0.24180825757812782, 0.24323494071103482, 0.24403887765713964, 0.23825376250418315, 0.24459328457533594, 0.2376868670065719, 0.2382130262004324, 0.23695732512507572, 0.23531918652565126, 0.23581868437040282, 0.22368512823280082, 0.2331827267046913, 0.23918752479984098, 0.23372453026264067, 0.2349798121007092, 0.23283532770522627, 0.23469426506853486, 0.22989362684718098, 0.234868818377874, 0.23256528640846652, 0.22883868839846078, 0.23642319090754152, 0.23242460840557475, 0.2382306778526689, 0.22890611405832223, 0.23956589538409528, 0.23408245717186527, 0.24013204223300558, 0.23295707129929438, 0.23562379821716065, 0.23324570242300569, 0.242519595626607, 0.23867745182839742, 0.24104092524472967, 0.23274506335277634, 0.23718718768482705, 0.23551607808195443, 0.23211015659163756, 0.23061776188123656], 'loss': [0.46605496658816403, 0.38321226386184526, 0.36324206879908205, 0.3502093012257787, 0.3412148640828536, 0.33599739219513103, 0.3281311094832175, 0.32703718460545644, 0.32162664291983273, 0.3171595152475508, 0.31556827174729063, 0.3136639089279698, 0.310002039530807, 0.3115219630495238, 0.30792873122708647, 0.3017714197300348, 0.29477438216067137, 0.288758982977095, 0.28726661729202463, 0.2873977279814913, 0.28725390746936474, 0.2776290951503846, 0.2692705212167405, 0.2546128674477359, 0.24818055396559086, 0.23730917498621937, 0.2386946067218133, 0.2371097141378968, 0.23259329979590398, 0.2312349046683509, 0.22670987561653388, 0.2311239961069857, 0.22100167916261268, 0.21863601633721905, 0.21806146871639137, 0.22041816097900468, 0.21363137482636632, 0.2100379299442462, 0.20438909442561057, 0.20590423532347232, 0.2043823142417801, 0.20432897616579085, 0.20437694178744556, 0.2064748004124522, 0.2014492907211726, 0.20827497585190916, 0.20193975639719533, 0.19910121733494035, 0.19732550080075745, 0.2013933902904618, 0.19415867085509522, 0.1947787797043379, 0.19348429814366938, 0.19384103755878618, 0.19750887453893737, 0.1954811933550416, 0.19596540637191137], 'acc': [0.931748727460821, 0.9424850631846505, 0.9449308078145331, 0.9466596210838305, 0.947857016034173, 0.948732873207928, 0.9494321742245411, 0.9498566032325614, 0.9502864713746947, 0.9507150447588165, 0.9510124113479319, 0.9514113751375285, 0.9519518012779234, 0.9517210078664272, 0.9520491815816555, 0.9521156353504, 0.9536186616847288, 0.954209993670244, 0.954419777071724, 0.9544774867777789, 0.9541360651283451, 0.9529828677776755, 0.9521072272463468, 0.9512294064053392, 0.9511009771212012, 0.951393096705311, 0.9512658667917943, 0.9513243430041719, 0.9515496742223558, 0.952033657565467, 0.9516794199266094, 0.9513959718203893, 0.9520839657603312, 0.9522811001395244, 0.9522771474220798, 0.9521880312645672, 0.952730323845791, 0.9528708028981515, 0.9531670196351182, 0.9530803462273479, 0.9530747166392165, 0.9528665621438628, 0.9529533311599923, 0.9531163271178871, 0.9533691116424019, 0.953122556558838, 0.9532493794685744, 0.9535685707738142, 0.9536435766899822, 0.9536868649659844, 0.9539692592917376, 0.95386210376211, 0.9539979353058826, 0.9540082356827706, 0.954178515567759, 0.9541671846335483, 0.9539836811922406], 'mDice': [0.49753432435911754, 0.5869332936371208, 0.6085046540800535, 0.622572250840653, 0.6322823349289334, 0.6379115560270902, 0.6464254438050253, 0.6475924644579131, 0.6534380173282571, 0.6582550688476775, 0.6599644031558303, 0.6620148967624537, 0.6659629408201513, 0.6643258368489959, 0.6681984124308253, 0.6748682981157839, 0.6823793384581769, 0.6888641669145186, 0.6904625820574707, 0.6902418855958167, 0.6853605413324266, 0.673263791762337, 0.6629749025362754, 0.6580933535093327, 0.6559563450082242, 0.6580505632300663, 0.6544830797320774, 0.6542981111370356, 0.6517918733846512, 0.6545912083135897, 0.6538452103473843, 0.6534697968896797, 0.6621812330788329, 0.6616325065710988, 0.6580929096286532, 0.6578810437070328, 0.6721541846776459, 0.6656606049878093, 0.6724938880032941, 0.6688435579160275, 0.6754206827997847, 0.6693669488001771, 0.6712011970905731, 0.6708572142804475, 0.6770435043269155, 0.6749683173827309, 0.6712006773497607, 0.6757403335693749, 0.6772467428290425, 0.6767436011902198, 0.6813221806702617, 0.6800051315553278, 0.6817466834285162, 0.6784662989851847, 0.681684367827353, 0.682109132640757, 0.6809305695113427], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:05,  4.04it/s]Loading train:   1%|          | 2/266 [00:00<01:04,  4.08it/s]Loading train:   1%|          | 3/266 [00:00<01:03,  4.15it/s]Loading train:   2%|▏         | 4/266 [00:00<01:03,  4.15it/s]Loading train:   2%|▏         | 5/266 [00:01<01:01,  4.25it/s]Loading train:   2%|▏         | 6/266 [00:01<01:00,  4.33it/s]Loading train:   3%|▎         | 7/266 [00:01<01:00,  4.31it/s]Loading train:   3%|▎         | 8/266 [00:01<00:59,  4.36it/s]Loading train:   3%|▎         | 9/266 [00:02<00:58,  4.41it/s]Loading train:   4%|▍         | 10/266 [00:02<00:57,  4.45it/s]Loading train:   4%|▍         | 11/266 [00:02<00:56,  4.48it/s]Loading train:   5%|▍         | 12/266 [00:02<00:56,  4.49it/s]Loading train:   5%|▍         | 13/266 [00:02<00:56,  4.50it/s]Loading train:   5%|▌         | 14/266 [00:03<00:55,  4.52it/s]Loading train:   6%|▌         | 15/266 [00:03<00:55,  4.52it/s]Loading train:   6%|▌         | 16/266 [00:03<00:55,  4.51it/s]Loading train:   6%|▋         | 17/266 [00:03<00:55,  4.48it/s]Loading train:   7%|▋         | 18/266 [00:04<00:55,  4.47it/s]Loading train:   7%|▋         | 19/266 [00:04<00:55,  4.42it/s]Loading train:   8%|▊         | 20/266 [00:04<00:55,  4.42it/s]Loading train:   8%|▊         | 21/266 [00:04<00:55,  4.44it/s]Loading train:   8%|▊         | 22/266 [00:04<00:54,  4.47it/s]Loading train:   9%|▊         | 23/266 [00:05<00:53,  4.51it/s]Loading train:   9%|▉         | 24/266 [00:05<00:53,  4.49it/s]Loading train:   9%|▉         | 25/266 [00:05<00:53,  4.49it/s]Loading train:  10%|▉         | 26/266 [00:05<00:53,  4.52it/s]Loading train:  10%|█         | 27/266 [00:06<00:52,  4.54it/s]Loading train:  11%|█         | 28/266 [00:06<00:52,  4.55it/s]Loading train:  11%|█         | 29/266 [00:06<00:51,  4.58it/s]Loading train:  11%|█▏        | 30/266 [00:06<00:52,  4.51it/s]Loading train:  12%|█▏        | 31/266 [00:06<00:51,  4.55it/s]Loading train:  12%|█▏        | 32/266 [00:07<00:51,  4.58it/s]Loading train:  12%|█▏        | 33/266 [00:07<00:50,  4.58it/s]Loading train:  13%|█▎        | 34/266 [00:07<00:50,  4.61it/s]Loading train:  13%|█▎        | 35/266 [00:07<00:49,  4.62it/s]Loading train:  14%|█▎        | 36/266 [00:08<00:49,  4.64it/s]Loading train:  14%|█▍        | 37/266 [00:08<00:49,  4.64it/s]Loading train:  14%|█▍        | 38/266 [00:08<00:48,  4.65it/s]Loading train:  15%|█▍        | 39/266 [00:08<00:48,  4.67it/s]Loading train:  15%|█▌        | 40/266 [00:08<00:48,  4.68it/s]Loading train:  15%|█▌        | 41/266 [00:09<00:48,  4.66it/s]Loading train:  16%|█▌        | 42/266 [00:09<00:48,  4.65it/s]Loading train:  16%|█▌        | 43/266 [00:09<00:47,  4.65it/s]Loading train:  17%|█▋        | 44/266 [00:09<00:47,  4.67it/s]Loading train:  17%|█▋        | 45/266 [00:09<00:47,  4.66it/s]Loading train:  17%|█▋        | 46/266 [00:10<00:47,  4.67it/s]Loading train:  18%|█▊        | 47/266 [00:10<00:46,  4.66it/s]Loading train:  18%|█▊        | 48/266 [00:10<00:46,  4.68it/s]Loading train:  18%|█▊        | 49/266 [00:10<00:46,  4.69it/s]Loading train:  19%|█▉        | 50/266 [00:11<00:46,  4.68it/s]Loading train:  19%|█▉        | 51/266 [00:11<00:45,  4.69it/s]Loading train:  20%|█▉        | 52/266 [00:11<00:45,  4.68it/s]Loading train:  20%|█▉        | 53/266 [00:11<00:45,  4.67it/s]Loading train:  20%|██        | 54/266 [00:11<00:45,  4.69it/s]Loading train:  21%|██        | 55/266 [00:12<00:45,  4.69it/s]Loading train:  21%|██        | 56/266 [00:12<00:44,  4.70it/s]Loading train:  21%|██▏       | 57/266 [00:12<00:44,  4.71it/s]Loading train:  22%|██▏       | 58/266 [00:12<00:44,  4.70it/s]Loading train:  22%|██▏       | 59/266 [00:12<00:44,  4.65it/s]Loading train:  23%|██▎       | 60/266 [00:13<00:44,  4.62it/s]Loading train:  23%|██▎       | 61/266 [00:13<00:44,  4.60it/s]Loading train:  23%|██▎       | 62/266 [00:13<00:44,  4.59it/s]Loading train:  24%|██▎       | 63/266 [00:13<00:44,  4.59it/s]Loading train:  24%|██▍       | 64/266 [00:14<00:44,  4.59it/s]Loading train:  24%|██▍       | 65/266 [00:14<00:43,  4.58it/s]Loading train:  25%|██▍       | 66/266 [00:14<00:43,  4.59it/s]Loading train:  25%|██▌       | 67/266 [00:14<00:43,  4.58it/s]Loading train:  26%|██▌       | 68/266 [00:14<00:43,  4.58it/s]Loading train:  26%|██▌       | 69/266 [00:15<00:42,  4.58it/s]Loading train:  26%|██▋       | 70/266 [00:15<00:42,  4.57it/s]Loading train:  27%|██▋       | 71/266 [00:15<00:42,  4.55it/s]Loading train:  27%|██▋       | 72/266 [00:15<00:42,  4.56it/s]Loading train:  27%|██▋       | 73/266 [00:16<00:42,  4.55it/s]Loading train:  28%|██▊       | 74/266 [00:16<00:42,  4.55it/s]Loading train:  28%|██▊       | 75/266 [00:16<00:41,  4.56it/s]Loading train:  29%|██▊       | 76/266 [00:16<00:41,  4.57it/s]Loading train:  29%|██▉       | 77/266 [00:16<00:44,  4.25it/s]Loading train:  29%|██▉       | 78/266 [00:17<00:45,  4.09it/s]Loading train:  30%|██▉       | 79/266 [00:17<00:44,  4.22it/s]Loading train:  30%|███       | 80/266 [00:17<00:43,  4.31it/s]Loading train:  30%|███       | 81/266 [00:17<00:44,  4.16it/s]Loading train:  31%|███       | 82/266 [00:18<00:44,  4.12it/s]Loading train:  31%|███       | 83/266 [00:18<00:44,  4.09it/s]Loading train:  32%|███▏      | 84/266 [00:18<00:44,  4.06it/s]Loading train:  32%|███▏      | 85/266 [00:18<00:44,  4.03it/s]Loading train:  32%|███▏      | 86/266 [00:19<00:44,  4.01it/s]Loading train:  33%|███▎      | 87/266 [00:19<00:44,  3.99it/s]Loading train:  33%|███▎      | 88/266 [00:19<00:44,  4.00it/s]Loading train:  33%|███▎      | 89/266 [00:19<00:44,  3.96it/s]Loading train:  34%|███▍      | 90/266 [00:20<00:44,  3.95it/s]Loading train:  34%|███▍      | 91/266 [00:20<00:44,  3.97it/s]Loading train:  35%|███▍      | 92/266 [00:20<00:43,  3.98it/s]Loading train:  35%|███▍      | 93/266 [00:20<00:43,  3.99it/s]Loading train:  35%|███▌      | 94/266 [00:21<00:43,  4.00it/s]Loading train:  36%|███▌      | 95/266 [00:21<00:42,  3.98it/s]Loading train:  36%|███▌      | 96/266 [00:21<00:42,  3.97it/s]Loading train:  36%|███▋      | 97/266 [00:21<00:42,  3.95it/s]Loading train:  37%|███▋      | 98/266 [00:22<00:42,  3.95it/s]Loading train:  37%|███▋      | 99/266 [00:22<00:42,  3.97it/s]Loading train:  38%|███▊      | 100/266 [00:22<00:41,  4.04it/s]Loading train:  38%|███▊      | 101/266 [00:22<00:40,  4.06it/s]Loading train:  38%|███▊      | 102/266 [00:23<00:40,  4.07it/s]Loading train:  39%|███▊      | 103/266 [00:23<00:39,  4.08it/s]Loading train:  39%|███▉      | 104/266 [00:23<00:39,  4.09it/s]Loading train:  39%|███▉      | 105/266 [00:23<00:39,  4.09it/s]Loading train:  40%|███▉      | 106/266 [00:24<00:38,  4.12it/s]Loading train:  40%|████      | 107/266 [00:24<00:38,  4.10it/s]Loading train:  41%|████      | 108/266 [00:24<00:38,  4.11it/s]Loading train:  41%|████      | 109/266 [00:24<00:38,  4.10it/s]Loading train:  41%|████▏     | 110/266 [00:25<00:38,  4.10it/s]Loading train:  42%|████▏     | 111/266 [00:25<00:37,  4.08it/s]Loading train:  42%|████▏     | 112/266 [00:25<00:37,  4.09it/s]Loading train:  42%|████▏     | 113/266 [00:25<00:37,  4.11it/s]Loading train:  43%|████▎     | 114/266 [00:26<00:36,  4.13it/s]Loading train:  43%|████▎     | 115/266 [00:26<00:36,  4.10it/s]Loading train:  44%|████▎     | 116/266 [00:26<00:36,  4.10it/s]Loading train:  44%|████▍     | 117/266 [00:26<00:36,  4.12it/s]Loading train:  44%|████▍     | 118/266 [00:27<00:34,  4.32it/s]Loading train:  45%|████▍     | 119/266 [00:27<00:32,  4.52it/s]Loading train:  45%|████▌     | 120/266 [00:27<00:31,  4.63it/s]Loading train:  45%|████▌     | 121/266 [00:27<00:30,  4.74it/s]Loading train:  46%|████▌     | 122/266 [00:27<00:30,  4.73it/s]Loading train:  46%|████▌     | 123/266 [00:28<00:29,  4.81it/s]Loading train:  47%|████▋     | 124/266 [00:28<00:29,  4.85it/s]Loading train:  47%|████▋     | 125/266 [00:28<00:29,  4.86it/s]Loading train:  47%|████▋     | 126/266 [00:28<00:28,  4.88it/s]Loading train:  48%|████▊     | 127/266 [00:28<00:28,  4.91it/s]Loading train:  48%|████▊     | 128/266 [00:29<00:27,  4.93it/s]Loading train:  48%|████▊     | 129/266 [00:29<00:27,  4.94it/s]Loading train:  49%|████▉     | 130/266 [00:29<00:27,  4.92it/s]Loading train:  49%|████▉     | 131/266 [00:29<00:27,  4.93it/s]Loading train:  50%|████▉     | 132/266 [00:29<00:27,  4.95it/s]Loading train:  50%|█████     | 133/266 [00:30<00:26,  4.96it/s]Loading train:  50%|█████     | 134/266 [00:30<00:26,  4.97it/s]Loading train:  51%|█████     | 135/266 [00:30<00:26,  4.97it/s]Loading train:  51%|█████     | 136/266 [00:30<00:26,  4.91it/s]Loading train:  52%|█████▏    | 137/266 [00:30<00:26,  4.85it/s]Loading train:  52%|█████▏    | 138/266 [00:31<00:26,  4.81it/s]Loading train:  52%|█████▏    | 139/266 [00:31<00:26,  4.78it/s]Loading train:  53%|█████▎    | 140/266 [00:31<00:26,  4.74it/s]Loading train:  53%|█████▎    | 141/266 [00:31<00:26,  4.72it/s]Loading train:  53%|█████▎    | 142/266 [00:31<00:26,  4.71it/s]Loading train:  54%|█████▍    | 143/266 [00:32<00:26,  4.73it/s]Loading train:  54%|█████▍    | 144/266 [00:32<00:25,  4.75it/s]Loading train:  55%|█████▍    | 145/266 [00:32<00:25,  4.72it/s]Loading train:  55%|█████▍    | 146/266 [00:32<00:25,  4.73it/s]Loading train:  55%|█████▌    | 147/266 [00:33<00:25,  4.71it/s]Loading train:  56%|█████▌    | 148/266 [00:33<00:25,  4.69it/s]Loading train:  56%|█████▌    | 149/266 [00:33<00:25,  4.64it/s]Loading train:  56%|█████▋    | 150/266 [00:33<00:24,  4.67it/s]Loading train:  57%|█████▋    | 151/266 [00:33<00:24,  4.63it/s]Loading train:  57%|█████▋    | 152/266 [00:34<00:24,  4.65it/s]Loading train:  58%|█████▊    | 153/266 [00:34<00:24,  4.64it/s]Loading train:  58%|█████▊    | 154/266 [00:34<00:24,  4.51it/s]Loading train:  58%|█████▊    | 155/266 [00:34<00:25,  4.37it/s]Loading train:  59%|█████▊    | 156/266 [00:35<00:25,  4.31it/s]Loading train:  59%|█████▉    | 157/266 [00:35<00:25,  4.25it/s]Loading train:  59%|█████▉    | 158/266 [00:35<00:25,  4.22it/s]Loading train:  60%|█████▉    | 159/266 [00:35<00:25,  4.22it/s]Loading train:  60%|██████    | 160/266 [00:35<00:25,  4.22it/s]Loading train:  61%|██████    | 161/266 [00:36<00:24,  4.23it/s]Loading train:  61%|██████    | 162/266 [00:36<00:24,  4.19it/s]Loading train:  61%|██████▏   | 163/266 [00:36<00:24,  4.21it/s]Loading train:  62%|██████▏   | 164/266 [00:36<00:24,  4.21it/s]Loading train:  62%|██████▏   | 165/266 [00:37<00:23,  4.22it/s]Loading train:  62%|██████▏   | 166/266 [00:37<00:23,  4.20it/s]Loading train:  63%|██████▎   | 167/266 [00:37<00:23,  4.23it/s]Loading train:  63%|██████▎   | 168/266 [00:37<00:23,  4.22it/s]Loading train:  64%|██████▎   | 169/266 [00:38<00:22,  4.23it/s]Loading train:  64%|██████▍   | 170/266 [00:38<00:22,  4.19it/s]Loading train:  64%|██████▍   | 171/266 [00:38<00:22,  4.20it/s]Loading train:  65%|██████▍   | 172/266 [00:38<00:22,  4.25it/s]Loading train:  65%|██████▌   | 173/266 [00:39<00:22,  4.08it/s]Loading train:  65%|██████▌   | 174/266 [00:39<00:22,  4.09it/s]Loading train:  66%|██████▌   | 175/266 [00:39<00:20,  4.34it/s]Loading train:  66%|██████▌   | 176/266 [00:39<00:20,  4.38it/s]Loading train:  67%|██████▋   | 177/266 [00:39<00:19,  4.46it/s]Loading train:  67%|██████▋   | 178/266 [00:40<00:19,  4.55it/s]Loading train:  67%|██████▋   | 179/266 [00:40<00:18,  4.59it/s]Loading train:  68%|██████▊   | 180/266 [00:40<00:18,  4.62it/s]Loading train:  68%|██████▊   | 181/266 [00:40<00:18,  4.65it/s]Loading train:  68%|██████▊   | 182/266 [00:41<00:17,  4.67it/s]Loading train:  69%|██████▉   | 183/266 [00:41<00:17,  4.66it/s]Loading train:  69%|██████▉   | 184/266 [00:41<00:17,  4.69it/s]Loading train:  70%|██████▉   | 185/266 [00:41<00:17,  4.66it/s]Loading train:  70%|██████▉   | 186/266 [00:41<00:17,  4.68it/s]Loading train:  70%|███████   | 187/266 [00:42<00:16,  4.69it/s]Loading train:  71%|███████   | 188/266 [00:42<00:16,  4.63it/s]Loading train:  71%|███████   | 189/266 [00:42<00:16,  4.66it/s]Loading train:  71%|███████▏  | 190/266 [00:42<00:16,  4.64it/s]Loading train:  72%|███████▏  | 191/266 [00:42<00:16,  4.64it/s]Loading train:  72%|███████▏  | 192/266 [00:43<00:16,  4.60it/s]Loading train:  73%|███████▎  | 193/266 [00:43<00:15,  4.63it/s]Loading train:  73%|███████▎  | 194/266 [00:43<00:15,  4.63it/s]Loading train:  73%|███████▎  | 195/266 [00:43<00:16,  4.41it/s]Loading train:  74%|███████▎  | 196/266 [00:44<00:16,  4.20it/s]Loading train:  74%|███████▍  | 197/266 [00:44<00:16,  4.11it/s]Loading train:  74%|███████▍  | 198/266 [00:44<00:16,  4.06it/s]Loading train:  75%|███████▍  | 199/266 [00:44<00:16,  4.02it/s]Loading train:  75%|███████▌  | 200/266 [00:45<00:16,  4.02it/s]Loading train:  76%|███████▌  | 201/266 [00:45<00:16,  4.03it/s]Loading train:  76%|███████▌  | 202/266 [00:45<00:15,  4.01it/s]Loading train:  76%|███████▋  | 203/266 [00:45<00:15,  4.01it/s]Loading train:  77%|███████▋  | 204/266 [00:46<00:15,  4.02it/s]Loading train:  77%|███████▋  | 205/266 [00:46<00:15,  4.03it/s]Loading train:  77%|███████▋  | 206/266 [00:46<00:14,  4.03it/s]Loading train:  78%|███████▊  | 207/266 [00:46<00:14,  4.04it/s]Loading train:  78%|███████▊  | 208/266 [00:47<00:14,  4.04it/s]Loading train:  79%|███████▊  | 209/266 [00:47<00:14,  4.01it/s]Loading train:  79%|███████▉  | 210/266 [00:47<00:14,  4.00it/s]Loading train:  79%|███████▉  | 211/266 [00:47<00:13,  4.00it/s]Loading train:  80%|███████▉  | 212/266 [00:48<00:13,  4.00it/s]Loading train:  80%|████████  | 213/266 [00:48<00:13,  4.01it/s]Loading train:  80%|████████  | 214/266 [00:48<00:12,  4.03it/s]Loading train:  81%|████████  | 215/266 [00:48<00:12,  4.04it/s]Loading train:  81%|████████  | 216/266 [00:49<00:12,  4.06it/s]Loading train:  82%|████████▏ | 217/266 [00:49<00:12,  4.07it/s]Loading train:  82%|████████▏ | 218/266 [00:49<00:11,  4.08it/s]Loading train:  82%|████████▏ | 219/266 [00:49<00:11,  4.09it/s]Loading train:  83%|████████▎ | 220/266 [00:50<00:11,  4.10it/s]Loading train:  83%|████████▎ | 221/266 [00:50<00:11,  4.09it/s]Loading train:  83%|████████▎ | 222/266 [00:50<00:10,  4.07it/s]Loading train:  84%|████████▍ | 223/266 [00:50<00:10,  4.04it/s]Loading train:  84%|████████▍ | 224/266 [00:51<00:10,  4.05it/s]Loading train:  85%|████████▍ | 225/266 [00:51<00:10,  4.08it/s]Loading train:  85%|████████▍ | 226/266 [00:51<00:09,  4.09it/s]Loading train:  85%|████████▌ | 227/266 [00:51<00:09,  4.10it/s]Loading train:  86%|████████▌ | 228/266 [00:52<00:09,  4.09it/s]Loading train:  86%|████████▌ | 229/266 [00:52<00:09,  4.09it/s]Loading train:  86%|████████▋ | 230/266 [00:52<00:08,  4.09it/s]Loading train:  87%|████████▋ | 231/266 [00:52<00:08,  4.30it/s]Loading train:  87%|████████▋ | 232/266 [00:52<00:07,  4.46it/s]Loading train:  88%|████████▊ | 233/266 [00:53<00:07,  4.60it/s]Loading train:  88%|████████▊ | 234/266 [00:53<00:06,  4.65it/s]Loading train:  88%|████████▊ | 235/266 [00:53<00:06,  4.67it/s]Loading train:  89%|████████▊ | 236/266 [00:53<00:06,  4.70it/s]Loading train:  89%|████████▉ | 237/266 [00:53<00:06,  4.73it/s]Loading train:  89%|████████▉ | 238/266 [00:54<00:05,  4.74it/s]Loading train:  90%|████████▉ | 239/266 [00:54<00:05,  4.76it/s]Loading train:  90%|█████████ | 240/266 [00:54<00:05,  4.77it/s]Loading train:  91%|█████████ | 241/266 [00:54<00:05,  4.77it/s]Loading train:  91%|█████████ | 242/266 [00:55<00:05,  4.76it/s]Loading train:  91%|█████████▏| 243/266 [00:55<00:04,  4.71it/s]Loading train:  92%|█████████▏| 244/266 [00:55<00:04,  4.70it/s]Loading train:  92%|█████████▏| 245/266 [00:55<00:04,  4.67it/s]Loading train:  92%|█████████▏| 246/266 [00:55<00:04,  4.62it/s]Loading train:  93%|█████████▎| 247/266 [00:56<00:04,  4.63it/s]Loading train:  93%|█████████▎| 248/266 [00:56<00:03,  4.64it/s]Loading train:  94%|█████████▎| 249/266 [00:56<00:03,  4.48it/s]Loading train:  94%|█████████▍| 250/266 [00:56<00:03,  4.38it/s]Loading train:  94%|█████████▍| 251/266 [00:57<00:03,  4.34it/s]Loading train:  95%|█████████▍| 252/266 [00:57<00:03,  4.32it/s]Loading train:  95%|█████████▌| 253/266 [00:57<00:03,  4.32it/s]Loading train:  95%|█████████▌| 254/266 [00:57<00:02,  4.31it/s]Loading train:  96%|█████████▌| 255/266 [00:57<00:02,  4.32it/s]Loading train:  96%|█████████▌| 256/266 [00:58<00:02,  4.29it/s]Loading train:  97%|█████████▋| 257/266 [00:58<00:02,  4.32it/s]Loading train:  97%|█████████▋| 258/266 [00:58<00:01,  4.34it/s]Loading train:  97%|█████████▋| 259/266 [00:58<00:01,  4.35it/s]Loading train:  98%|█████████▊| 260/266 [00:59<00:01,  4.36it/s]Loading train:  98%|█████████▊| 261/266 [00:59<00:01,  4.37it/s]Loading train:  98%|█████████▊| 262/266 [00:59<00:00,  4.39it/s]Loading train:  99%|█████████▉| 263/266 [00:59<00:00,  4.39it/s]Loading train:  99%|█████████▉| 264/266 [01:00<00:00,  4.44it/s]Loading train: 100%|█████████▉| 265/266 [01:00<00:00,  4.49it/s]Loading train: 100%|██████████| 266/266 [01:00<00:00,  4.51it/s]Loading train: 100%|██████████| 266/266 [01:00<00:00,  4.40it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:04, 59.53it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:04, 60.04it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:04, 57.90it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:04, 59.23it/s]concatenating: train:  13%|█▎        | 34/266 [00:00<00:03, 60.32it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:03, 61.13it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:03, 59.98it/s]concatenating: train:  20%|██        | 54/266 [00:00<00:03, 62.59it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:03, 65.37it/s]concatenating: train:  26%|██▋       | 70/266 [00:01<00:02, 67.41it/s]concatenating: train:  29%|██▉       | 77/266 [00:01<00:02, 67.82it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:02, 65.54it/s]concatenating: train:  34%|███▍      | 91/266 [00:01<00:02, 62.45it/s]concatenating: train:  37%|███▋      | 98/266 [00:01<00:02, 60.46it/s]concatenating: train:  39%|███▉      | 105/266 [00:01<00:02, 60.06it/s]concatenating: train:  42%|████▏     | 112/266 [00:01<00:02, 57.71it/s]concatenating: train:  45%|████▍     | 119/266 [00:01<00:02, 59.32it/s]concatenating: train:  47%|████▋     | 126/266 [00:02<00:02, 61.80it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:02, 64.94it/s]concatenating: train:  53%|█████▎    | 141/266 [00:02<00:01, 65.63it/s]concatenating: train:  56%|█████▌    | 148/266 [00:02<00:01, 66.41it/s]concatenating: train:  58%|█████▊    | 155/266 [00:02<00:01, 64.67it/s]concatenating: train:  61%|██████    | 162/266 [00:02<00:01, 63.74it/s]concatenating: train:  64%|██████▍   | 170/266 [00:02<00:01, 66.67it/s]concatenating: train:  67%|██████▋   | 177/266 [00:02<00:01, 66.84it/s]concatenating: train:  70%|██████▉   | 186/266 [00:02<00:01, 70.01it/s]concatenating: train:  73%|███████▎  | 194/266 [00:03<00:01, 68.52it/s]concatenating: train:  76%|███████▌  | 201/266 [00:03<00:01, 62.09it/s]concatenating: train:  78%|███████▊  | 208/266 [00:03<00:00, 62.05it/s]concatenating: train:  81%|████████  | 215/266 [00:03<00:00, 62.71it/s]concatenating: train:  84%|████████▍ | 223/266 [00:03<00:00, 65.22it/s]concatenating: train:  86%|████████▋ | 230/266 [00:03<00:00, 65.34it/s]concatenating: train:  90%|█████████ | 240/266 [00:03<00:00, 71.67it/s]concatenating: train:  93%|█████████▎| 248/266 [00:03<00:00, 71.16it/s]concatenating: train:  97%|█████████▋| 257/266 [00:03<00:00, 73.77it/s]concatenating: train: 100%|█████████▉| 265/266 [00:04<00:00, 75.18it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 65.68it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  4.08it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  4.17it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  4.16it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.04it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.08it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 304.02it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<01:03,  4.19it/s]Loading trainS:   1%|          | 2/266 [00:00<01:04,  4.09it/s]Loading trainS:   1%|          | 3/266 [00:00<01:03,  4.16it/s]Loading trainS:   2%|▏         | 4/266 [00:00<01:02,  4.17it/s]Loading trainS:   2%|▏         | 5/266 [00:01<01:00,  4.28it/s]Loading trainS:   2%|▏         | 6/266 [00:01<00:59,  4.35it/s]Loading trainS:   3%|▎         | 7/266 [00:01<00:59,  4.38it/s]Loading trainS:   3%|▎         | 8/266 [00:01<00:58,  4.43it/s]Loading trainS:   3%|▎         | 9/266 [00:02<00:57,  4.47it/s]Loading trainS:   4%|▍         | 10/266 [00:02<00:56,  4.50it/s]Loading trainS:   4%|▍         | 11/266 [00:02<00:56,  4.53it/s]Loading trainS:   5%|▍         | 12/266 [00:02<00:55,  4.55it/s]Loading trainS:   5%|▍         | 13/266 [00:02<00:55,  4.53it/s]Loading trainS:   5%|▌         | 14/266 [00:03<00:55,  4.55it/s]Loading trainS:   6%|▌         | 15/266 [00:03<00:55,  4.55it/s]Loading trainS:   6%|▌         | 16/266 [00:03<00:54,  4.57it/s]Loading trainS:   6%|▋         | 17/266 [00:03<00:54,  4.55it/s]Loading trainS:   7%|▋         | 18/266 [00:04<00:54,  4.57it/s]Loading trainS:   7%|▋         | 19/266 [00:04<00:53,  4.58it/s]Loading trainS:   8%|▊         | 20/266 [00:04<00:53,  4.59it/s]Loading trainS:   8%|▊         | 21/266 [00:04<00:53,  4.58it/s]Loading trainS:   8%|▊         | 22/266 [00:04<00:53,  4.58it/s]Loading trainS:   9%|▊         | 23/266 [00:05<00:52,  4.60it/s]Loading trainS:   9%|▉         | 24/266 [00:05<00:52,  4.60it/s]Loading trainS:   9%|▉         | 25/266 [00:05<00:52,  4.62it/s]Loading trainS:  10%|▉         | 26/266 [00:05<00:51,  4.64it/s]Loading trainS:  10%|█         | 27/266 [00:05<00:51,  4.65it/s]Loading trainS:  11%|█         | 28/266 [00:06<00:51,  4.66it/s]Loading trainS:  11%|█         | 29/266 [00:06<00:50,  4.65it/s]Loading trainS:  11%|█▏        | 30/266 [00:06<00:50,  4.66it/s]Loading trainS:  12%|█▏        | 31/266 [00:06<00:50,  4.65it/s]Loading trainS:  12%|█▏        | 32/266 [00:07<00:50,  4.67it/s]Loading trainS:  12%|█▏        | 33/266 [00:07<00:49,  4.68it/s]Loading trainS:  13%|█▎        | 34/266 [00:07<00:49,  4.68it/s]Loading trainS:  13%|█▎        | 35/266 [00:07<00:49,  4.65it/s]Loading trainS:  14%|█▎        | 36/266 [00:07<00:49,  4.62it/s]Loading trainS:  14%|█▍        | 37/266 [00:08<00:49,  4.59it/s]Loading trainS:  14%|█▍        | 38/266 [00:08<00:50,  4.56it/s]Loading trainS:  15%|█▍        | 39/266 [00:08<00:50,  4.54it/s]Loading trainS:  15%|█▌        | 40/266 [00:08<00:49,  4.53it/s]Loading trainS:  15%|█▌        | 41/266 [00:09<00:49,  4.54it/s]Loading trainS:  16%|█▌        | 42/266 [00:09<00:49,  4.55it/s]Loading trainS:  16%|█▌        | 43/266 [00:09<00:49,  4.54it/s]Loading trainS:  17%|█▋        | 44/266 [00:09<00:48,  4.54it/s]Loading trainS:  17%|█▋        | 45/266 [00:09<00:48,  4.54it/s]Loading trainS:  17%|█▋        | 46/266 [00:10<00:48,  4.49it/s]Loading trainS:  18%|█▊        | 47/266 [00:10<00:48,  4.54it/s]Loading trainS:  18%|█▊        | 48/266 [00:10<00:48,  4.54it/s]Loading trainS:  18%|█▊        | 49/266 [00:10<00:47,  4.55it/s]Loading trainS:  19%|█▉        | 50/266 [00:11<00:47,  4.55it/s]Loading trainS:  19%|█▉        | 51/266 [00:11<00:47,  4.55it/s]Loading trainS:  20%|█▉        | 52/266 [00:11<00:46,  4.56it/s]Loading trainS:  20%|█▉        | 53/266 [00:11<00:46,  4.57it/s]Loading trainS:  20%|██        | 54/266 [00:11<00:46,  4.56it/s]Loading trainS:  21%|██        | 55/266 [00:12<00:46,  4.54it/s]Loading trainS:  21%|██        | 56/266 [00:12<00:46,  4.52it/s]Loading trainS:  21%|██▏       | 57/266 [00:12<00:46,  4.51it/s]Loading trainS:  22%|██▏       | 58/266 [00:12<00:46,  4.48it/s]Loading trainS:  22%|██▏       | 59/266 [00:13<00:46,  4.44it/s]Loading trainS:  23%|██▎       | 60/266 [00:13<00:46,  4.43it/s]Loading trainS:  23%|██▎       | 61/266 [00:13<00:46,  4.42it/s]Loading trainS:  23%|██▎       | 62/266 [00:13<00:46,  4.43it/s]Loading trainS:  24%|██▎       | 63/266 [00:13<00:45,  4.44it/s]Loading trainS:  24%|██▍       | 64/266 [00:14<00:45,  4.45it/s]Loading trainS:  24%|██▍       | 65/266 [00:14<00:45,  4.46it/s]Loading trainS:  25%|██▍       | 66/266 [00:14<00:44,  4.46it/s]Loading trainS:  25%|██▌       | 67/266 [00:14<00:44,  4.48it/s]Loading trainS:  26%|██▌       | 68/266 [00:15<00:44,  4.40it/s]Loading trainS:  26%|██▌       | 69/266 [00:15<00:44,  4.42it/s]Loading trainS:  26%|██▋       | 70/266 [00:15<00:44,  4.45it/s]Loading trainS:  27%|██▋       | 71/266 [00:15<00:43,  4.47it/s]Loading trainS:  27%|██▋       | 72/266 [00:15<00:43,  4.47it/s]Loading trainS:  27%|██▋       | 73/266 [00:16<00:43,  4.46it/s]Loading trainS:  28%|██▊       | 74/266 [00:16<00:42,  4.47it/s]Loading trainS:  28%|██▊       | 75/266 [00:16<00:42,  4.45it/s]Loading trainS:  29%|██▊       | 76/266 [00:16<00:43,  4.39it/s]Loading trainS:  29%|██▉       | 77/266 [00:17<00:46,  4.08it/s]Loading trainS:  29%|██▉       | 78/266 [00:17<00:46,  4.03it/s]Loading trainS:  30%|██▉       | 79/266 [00:17<00:44,  4.20it/s]Loading trainS:  30%|███       | 80/266 [00:17<00:43,  4.24it/s]Loading trainS:  30%|███       | 81/266 [00:18<00:44,  4.11it/s]Loading trainS:  31%|███       | 82/266 [00:18<00:45,  4.03it/s]Loading trainS:  31%|███       | 83/266 [00:18<00:45,  4.01it/s]Loading trainS:  32%|███▏      | 84/266 [00:18<00:45,  4.02it/s]Loading trainS:  32%|███▏      | 85/266 [00:19<00:45,  4.00it/s]Loading trainS:  32%|███▏      | 86/266 [00:19<00:45,  4.00it/s]Loading trainS:  33%|███▎      | 87/266 [00:19<00:44,  4.00it/s]Loading trainS:  33%|███▎      | 88/266 [00:19<00:44,  3.99it/s]Loading trainS:  33%|███▎      | 89/266 [00:20<00:44,  3.98it/s]Loading trainS:  34%|███▍      | 90/266 [00:20<00:44,  3.99it/s]Loading trainS:  34%|███▍      | 91/266 [00:20<00:43,  4.00it/s]Loading trainS:  35%|███▍      | 92/266 [00:20<00:43,  4.00it/s]Loading trainS:  35%|███▍      | 93/266 [00:21<00:43,  4.00it/s]Loading trainS:  35%|███▌      | 94/266 [00:21<00:43,  3.98it/s]Loading trainS:  36%|███▌      | 95/266 [00:21<00:42,  3.99it/s]Loading trainS:  36%|███▌      | 96/266 [00:21<00:42,  3.99it/s]Loading trainS:  36%|███▋      | 97/266 [00:22<00:42,  4.00it/s]Loading trainS:  37%|███▋      | 98/266 [00:22<00:41,  4.00it/s]Loading trainS:  37%|███▋      | 99/266 [00:22<00:41,  4.00it/s]Loading trainS:  38%|███▊      | 100/266 [00:22<00:40,  4.06it/s]Loading trainS:  38%|███▊      | 101/266 [00:23<00:40,  4.08it/s]Loading trainS:  38%|███▊      | 102/266 [00:23<00:39,  4.11it/s]Loading trainS:  39%|███▊      | 103/266 [00:23<00:39,  4.13it/s]Loading trainS:  39%|███▉      | 104/266 [00:23<00:39,  4.14it/s]Loading trainS:  39%|███▉      | 105/266 [00:24<00:38,  4.15it/s]Loading trainS:  40%|███▉      | 106/266 [00:24<00:38,  4.16it/s]Loading trainS:  40%|████      | 107/266 [00:24<00:38,  4.17it/s]Loading trainS:  41%|████      | 108/266 [00:24<00:37,  4.18it/s]Loading trainS:  41%|████      | 109/266 [00:25<00:37,  4.18it/s]Loading trainS:  41%|████▏     | 110/266 [00:25<00:37,  4.17it/s]Loading trainS:  42%|████▏     | 111/266 [00:25<00:37,  4.18it/s]Loading trainS:  42%|████▏     | 112/266 [00:25<00:36,  4.18it/s]Loading trainS:  42%|████▏     | 113/266 [00:25<00:36,  4.17it/s]Loading trainS:  43%|████▎     | 114/266 [00:26<00:36,  4.18it/s]Loading trainS:  43%|████▎     | 115/266 [00:26<00:36,  4.14it/s]Loading trainS:  44%|████▎     | 116/266 [00:26<00:36,  4.15it/s]Loading trainS:  44%|████▍     | 117/266 [00:26<00:35,  4.16it/s]Loading trainS:  44%|████▍     | 118/266 [00:27<00:33,  4.37it/s]Loading trainS:  45%|████▍     | 119/266 [00:27<00:32,  4.53it/s]Loading trainS:  45%|████▌     | 120/266 [00:27<00:31,  4.64it/s]Loading trainS:  45%|████▌     | 121/266 [00:27<00:30,  4.74it/s]Loading trainS:  46%|████▌     | 122/266 [00:27<00:29,  4.80it/s]Loading trainS:  46%|████▌     | 123/266 [00:28<00:29,  4.86it/s]Loading trainS:  47%|████▋     | 124/266 [00:28<00:28,  4.91it/s]Loading trainS:  47%|████▋     | 125/266 [00:28<00:28,  4.92it/s]Loading trainS:  47%|████▋     | 126/266 [00:28<00:28,  4.93it/s]Loading trainS:  48%|████▊     | 127/266 [00:28<00:28,  4.94it/s]Loading trainS:  48%|████▊     | 128/266 [00:29<00:27,  4.94it/s]Loading trainS:  48%|████▊     | 129/266 [00:29<00:27,  4.93it/s]Loading trainS:  49%|████▉     | 130/266 [00:29<00:27,  4.92it/s]Loading trainS:  49%|████▉     | 131/266 [00:29<00:27,  4.90it/s]Loading trainS:  50%|████▉     | 132/266 [00:29<00:27,  4.90it/s]Loading trainS:  50%|█████     | 133/266 [00:30<00:27,  4.89it/s]Loading trainS:  50%|█████     | 134/266 [00:30<00:27,  4.88it/s]Loading trainS:  51%|█████     | 135/266 [00:30<00:26,  4.87it/s]Loading trainS:  51%|█████     | 136/266 [00:30<00:27,  4.81it/s]Loading trainS:  52%|█████▏    | 137/266 [00:31<00:27,  4.74it/s]Loading trainS:  52%|█████▏    | 138/266 [00:31<00:27,  4.72it/s]Loading trainS:  52%|█████▏    | 139/266 [00:31<00:26,  4.71it/s]Loading trainS:  53%|█████▎    | 140/266 [00:31<00:26,  4.70it/s]Loading trainS:  53%|█████▎    | 141/266 [00:31<00:26,  4.69it/s]Loading trainS:  53%|█████▎    | 142/266 [00:32<00:26,  4.66it/s]Loading trainS:  54%|█████▍    | 143/266 [00:32<00:26,  4.66it/s]Loading trainS:  54%|█████▍    | 144/266 [00:32<00:26,  4.67it/s]Loading trainS:  55%|█████▍    | 145/266 [00:32<00:25,  4.66it/s]Loading trainS:  55%|█████▍    | 146/266 [00:32<00:25,  4.66it/s]Loading trainS:  55%|█████▌    | 147/266 [00:33<00:25,  4.67it/s]Loading trainS:  56%|█████▌    | 148/266 [00:33<00:25,  4.62it/s]Loading trainS:  56%|█████▌    | 149/266 [00:33<00:25,  4.60it/s]Loading trainS:  56%|█████▋    | 150/266 [00:33<00:25,  4.61it/s]Loading trainS:  57%|█████▋    | 151/266 [00:34<00:24,  4.65it/s]Loading trainS:  57%|█████▋    | 152/266 [00:34<00:24,  4.60it/s]Loading trainS:  58%|█████▊    | 153/266 [00:34<00:24,  4.64it/s]Loading trainS:  58%|█████▊    | 154/266 [00:34<00:25,  4.35it/s]Loading trainS:  58%|█████▊    | 155/266 [00:34<00:25,  4.31it/s]Loading trainS:  59%|█████▊    | 156/266 [00:35<00:25,  4.28it/s]Loading trainS:  59%|█████▉    | 157/266 [00:35<00:25,  4.26it/s]Loading trainS:  59%|█████▉    | 158/266 [00:35<00:25,  4.22it/s]Loading trainS:  60%|█████▉    | 159/266 [00:35<00:25,  4.22it/s]Loading trainS:  60%|██████    | 160/266 [00:36<00:25,  4.22it/s]Loading trainS:  61%|██████    | 161/266 [00:36<00:24,  4.22it/s]Loading trainS:  61%|██████    | 162/266 [00:36<00:24,  4.21it/s]Loading trainS:  61%|██████▏   | 163/266 [00:36<00:24,  4.14it/s]Loading trainS:  62%|██████▏   | 164/266 [00:37<00:24,  4.14it/s]Loading trainS:  62%|██████▏   | 165/266 [00:37<00:24,  4.14it/s]Loading trainS:  62%|██████▏   | 166/266 [00:37<00:24,  4.16it/s]Loading trainS:  63%|██████▎   | 167/266 [00:37<00:23,  4.17it/s]Loading trainS:  63%|██████▎   | 168/266 [00:38<00:23,  4.17it/s]Loading trainS:  64%|██████▎   | 169/266 [00:38<00:23,  4.16it/s]Loading trainS:  64%|██████▍   | 170/266 [00:38<00:23,  4.17it/s]Loading trainS:  64%|██████▍   | 171/266 [00:38<00:22,  4.18it/s]Loading trainS:  65%|██████▍   | 172/266 [00:39<00:22,  4.23it/s]Loading trainS:  65%|██████▌   | 173/266 [00:39<00:22,  4.07it/s]Loading trainS:  65%|██████▌   | 174/266 [00:39<00:22,  4.10it/s]Loading trainS:  66%|██████▌   | 175/266 [00:39<00:21,  4.32it/s]Loading trainS:  66%|██████▌   | 176/266 [00:39<00:20,  4.30it/s]Loading trainS:  67%|██████▋   | 177/266 [00:40<00:20,  4.38it/s]Loading trainS:  67%|██████▋   | 178/266 [00:40<00:19,  4.46it/s]Loading trainS:  67%|██████▋   | 179/266 [00:40<00:19,  4.49it/s]Loading trainS:  68%|██████▊   | 180/266 [00:40<00:18,  4.54it/s]Loading trainS:  68%|██████▊   | 181/266 [00:41<00:19,  4.36it/s]Loading trainS:  68%|██████▊   | 182/266 [00:41<00:19,  4.36it/s]Loading trainS:  69%|██████▉   | 183/266 [00:41<00:18,  4.39it/s]Loading trainS:  69%|██████▉   | 184/266 [00:41<00:18,  4.43it/s]Loading trainS:  70%|██████▉   | 185/266 [00:41<00:18,  4.31it/s]Loading trainS:  70%|██████▉   | 186/266 [00:42<00:18,  4.39it/s]Loading trainS:  70%|███████   | 187/266 [00:42<00:18,  4.37it/s]Loading trainS:  71%|███████   | 188/266 [00:42<00:17,  4.42it/s]Loading trainS:  71%|███████   | 189/266 [00:42<00:17,  4.33it/s]Loading trainS:  71%|███████▏  | 190/266 [00:43<00:17,  4.39it/s]Loading trainS:  72%|███████▏  | 191/266 [00:43<00:17,  4.39it/s]Loading trainS:  72%|███████▏  | 192/266 [00:43<00:16,  4.36it/s]Loading trainS:  73%|███████▎  | 193/266 [00:43<00:16,  4.37it/s]Loading trainS:  73%|███████▎  | 194/266 [00:44<00:16,  4.40it/s]Loading trainS:  73%|███████▎  | 195/266 [00:44<00:16,  4.25it/s]Loading trainS:  74%|███████▎  | 196/266 [00:44<00:16,  4.16it/s]Loading trainS:  74%|███████▍  | 197/266 [00:44<00:16,  4.10it/s]Loading trainS:  74%|███████▍  | 198/266 [00:45<00:16,  4.03it/s]Loading trainS:  75%|███████▍  | 199/266 [00:45<00:16,  4.02it/s]Loading trainS:  75%|███████▌  | 200/266 [00:45<00:16,  4.01it/s]Loading trainS:  76%|███████▌  | 201/266 [00:45<00:16,  3.99it/s]Loading trainS:  76%|███████▌  | 202/266 [00:46<00:16,  3.97it/s]Loading trainS:  76%|███████▋  | 203/266 [00:46<00:16,  3.92it/s]Loading trainS:  77%|███████▋  | 204/266 [00:46<00:16,  3.87it/s]Loading trainS:  77%|███████▋  | 205/266 [00:46<00:15,  3.82it/s]Loading trainS:  77%|███████▋  | 206/266 [00:47<00:15,  3.80it/s]Loading trainS:  78%|███████▊  | 207/266 [00:47<00:15,  3.76it/s]Loading trainS:  78%|███████▊  | 208/266 [00:47<00:15,  3.82it/s]Loading trainS:  79%|███████▊  | 209/266 [00:47<00:14,  3.86it/s]Loading trainS:  79%|███████▉  | 210/266 [00:48<00:14,  3.89it/s]Loading trainS:  79%|███████▉  | 211/266 [00:48<00:14,  3.92it/s]Loading trainS:  80%|███████▉  | 212/266 [00:48<00:13,  3.93it/s]Loading trainS:  80%|████████  | 213/266 [00:48<00:13,  4.06it/s]Loading trainS:  80%|████████  | 214/266 [00:49<00:12,  4.17it/s]Loading trainS:  81%|████████  | 215/266 [00:49<00:12,  4.24it/s]Loading trainS:  81%|████████  | 216/266 [00:49<00:11,  4.29it/s]Loading trainS:  82%|████████▏ | 217/266 [00:49<00:11,  4.32it/s]Loading trainS:  82%|████████▏ | 218/266 [00:50<00:11,  4.35it/s]Loading trainS:  82%|████████▏ | 219/266 [00:50<00:10,  4.38it/s]Loading trainS:  83%|████████▎ | 220/266 [00:50<00:10,  4.39it/s]Loading trainS:  83%|████████▎ | 221/266 [00:50<00:10,  4.40it/s]Loading trainS:  83%|████████▎ | 222/266 [00:50<00:09,  4.41it/s]Loading trainS:  84%|████████▍ | 223/266 [00:51<00:09,  4.41it/s]Loading trainS:  84%|████████▍ | 224/266 [00:51<00:09,  4.40it/s]Loading trainS:  85%|████████▍ | 225/266 [00:51<00:09,  4.41it/s]Loading trainS:  85%|████████▍ | 226/266 [00:51<00:09,  4.43it/s]Loading trainS:  85%|████████▌ | 227/266 [00:52<00:08,  4.41it/s]Loading trainS:  86%|████████▌ | 228/266 [00:52<00:08,  4.38it/s]Loading trainS:  86%|████████▌ | 229/266 [00:52<00:08,  4.37it/s]Loading trainS:  86%|████████▋ | 230/266 [00:52<00:08,  4.40it/s]Loading trainS:  87%|████████▋ | 231/266 [00:52<00:07,  4.59it/s]Loading trainS:  87%|████████▋ | 232/266 [00:53<00:07,  4.76it/s]Loading trainS:  88%|████████▊ | 233/266 [00:53<00:06,  4.91it/s]Loading trainS:  88%|████████▊ | 234/266 [00:53<00:06,  5.01it/s]Loading trainS:  88%|████████▊ | 235/266 [00:53<00:06,  5.07it/s]Loading trainS:  89%|████████▊ | 236/266 [00:53<00:05,  5.12it/s]Loading trainS:  89%|████████▉ | 237/266 [00:54<00:05,  5.15it/s]Loading trainS:  89%|████████▉ | 238/266 [00:54<00:05,  5.18it/s]Loading trainS:  90%|████████▉ | 239/266 [00:54<00:05,  5.20it/s]Loading trainS:  90%|█████████ | 240/266 [00:54<00:04,  5.21it/s]Loading trainS:  91%|█████████ | 241/266 [00:54<00:04,  5.22it/s]Loading trainS:  91%|█████████ | 242/266 [00:55<00:04,  5.23it/s]Loading trainS:  91%|█████████▏| 243/266 [00:55<00:04,  5.24it/s]Loading trainS:  92%|█████████▏| 244/266 [00:55<00:04,  5.23it/s]Loading trainS:  92%|█████████▏| 245/266 [00:55<00:04,  5.23it/s]Loading trainS:  92%|█████████▏| 246/266 [00:55<00:03,  5.20it/s]Loading trainS:  93%|█████████▎| 247/266 [00:56<00:03,  5.10it/s]Loading trainS:  93%|█████████▎| 248/266 [00:56<00:03,  5.02it/s]Loading trainS:  94%|█████████▎| 249/266 [00:56<00:03,  4.92it/s]Loading trainS:  94%|█████████▍| 250/266 [00:56<00:03,  4.86it/s]Loading trainS:  94%|█████████▍| 251/266 [00:56<00:03,  4.80it/s]Loading trainS:  95%|█████████▍| 252/266 [00:57<00:02,  4.77it/s]Loading trainS:  95%|█████████▌| 253/266 [00:57<00:02,  4.74it/s]Loading trainS:  95%|█████████▌| 254/266 [00:57<00:02,  4.74it/s]Loading trainS:  96%|█████████▌| 255/266 [00:57<00:02,  4.71it/s]Loading trainS:  96%|█████████▌| 256/266 [00:57<00:02,  4.72it/s]Loading trainS:  97%|█████████▋| 257/266 [00:58<00:01,  4.71it/s]Loading trainS:  97%|█████████▋| 258/266 [00:58<00:01,  4.70it/s]Loading trainS:  97%|█████████▋| 259/266 [00:58<00:01,  4.69it/s]Loading trainS:  98%|█████████▊| 260/266 [00:58<00:01,  4.69it/s]Loading trainS:  98%|█████████▊| 261/266 [00:58<00:01,  4.69it/s]Loading trainS:  98%|█████████▊| 262/266 [00:59<00:00,  4.68it/s]Loading trainS:  99%|█████████▉| 263/266 [00:59<00:00,  4.69it/s]Loading trainS:  99%|█████████▉| 264/266 [00:59<00:00,  4.67it/s]Loading trainS: 100%|█████████▉| 265/266 [00:59<00:00,  4.67it/s]Loading trainS: 100%|██████████| 266/266 [01:00<00:00,  4.63it/s]Loading trainS: 100%|██████████| 266/266 [01:00<00:00,  4.43it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  1.59it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]Loading testS:  75%|███████▌  | 3/4 [00:02<00:00,  1.46it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.40it/s]
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         2020-01-22 08:23:07.873123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 08:23:07.873206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 08:23:07.873221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 08:23:07.873228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 08:23:07.873531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 47s - loss: 0.2059 - acc: 0.9841 - mDice: 0.5967 - val_loss: 0.1064 - val_acc: 0.9924 - val_mDice: 0.4611

Epoch 00001: val_mDice improved from -inf to 0.46115, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 44s - loss: 0.0867 - acc: 0.9912 - mDice: 0.8312 - val_loss: 0.1777 - val_acc: 0.9921 - val_mDice: 0.4539

Epoch 00002: val_mDice did not improve from 0.46115
Epoch 3/300
 - 44s - loss: 0.0793 - acc: 0.9921 - mDice: 0.8455 - val_loss: 0.1778 - val_acc: 0.9928 - val_mDice: 0.4695

Epoch 00003: val_mDice improved from 0.46115 to 0.46947, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 44s - loss: 0.0723 - acc: 0.9927 - mDice: 0.8592 - val_loss: 0.2224 - val_acc: 0.9891 - val_mDice: 0.4555

Epoch 00004: val_mDice did not improve from 0.46947
Epoch 5/300
 - 44s - loss: 0.0694 - acc: 0.9930 - mDice: 0.8649 - val_loss: 0.1195 - val_acc: 0.9923 - val_mDice: 0.4704

Epoch 00005: val_mDice improved from 0.46947 to 0.47043, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 44s - loss: 0.0651 - acc: 0.9933 - mDice: 0.8732 - val_loss: 0.0145 - val_acc: 0.9929 - val_mDice: 0.4745

Epoch 00006: val_mDice improved from 0.47043 to 0.47446, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 43s - loss: 0.0629 - acc: 0.9936 - mDice: 0.8775 - val_loss: 0.1793 - val_acc: 0.9922 - val_mDice: 0.4800

Epoch 00007: val_mDice improved from 0.47446 to 0.48001, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 44s - loss: 0.0598 - acc: 0.9937 - mDice: 0.8836 - val_loss: 0.1374 - val_acc: 0.9932 - val_mDice: 0.4870

Epoch 00008: val_mDice improved from 0.48001 to 0.48698, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 43s - loss: 0.0597 - acc: 0.9939 - mDice: 0.8838 - val_loss: 0.0282 - val_acc: 0.9929 - val_mDice: 0.4780

Epoch 00009: val_mDice did not improve from 0.48698
Epoch 10/300
 - 44s - loss: 0.0583 - acc: 0.9940 - mDice: 0.8864 - val_loss: 0.1439 - val_acc: 0.9926 - val_mDice: 0.4809

Epoch 00010: val_mDice did not improve from 0.48698
Epoch 11/300
 - 44s - loss: 0.0558 - acc: 0.9941 - mDice: 0.8914 - val_loss: 0.0650 - val_acc: 0.9927 - val_mDice: 0.4817

Epoch 00011: val_mDice did not improve from 0.48698
Epoch 12/300
 - 44s - loss: 0.0546 - acc: 0.9942 - mDice: 0.8938 - val_loss: 0.1045 - val_acc: 0.9930 - val_mDice: 0.4811

Epoch 00012: val_mDice did not improve from 0.48698
Epoch 13/300
 - 44s - loss: 0.0550 - acc: 0.9943 - mDice: 0.8930 - val_loss: 0.1066 - val_acc: 0.9926 - val_mDice: 0.4769

Epoch 00013: val_mDice did not improve from 0.48698
Epoch 14/300
 - 44s - loss: 0.0542 - acc: 0.9943 - mDice: 0.8945 - val_loss: 0.1489 - val_acc: 0.9908 - val_mDice: 0.4720

Epoch 00014: val_mDice did not improve from 0.48698
Epoch 15/300
 - 44s - loss: 0.0522 - acc: 0.9945 - mDice: 0.8984 - val_loss: 0.1006 - val_acc: 0.9932 - val_mDice: 0.4886

Epoch 00015: val_mDice improved from 0.48698 to 0.48863, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 16/300
 - 44s - loss: 0.0516 - acc: 0.9946 - mDice: 0.8997 - val_loss: 0.0810 - val_acc: 0.9937 - val_mDice: 0.4883

Epoch 00016: val_mDice did not improve from 0.48863
Epoch 17/300
 - 45s - loss: 0.0538 - acc: 0.9945 - mDice: 0.8953 - val_loss: 0.0396 - val_acc: 0.9937 - val_mDice: 0.4927

Epoch 00017: val_mDice improved from 0.48863 to 0.49269, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 18/300
 - 46s - loss: 0.0507 - acc: 0.9947 - mDice: 0.9014 - val_loss: 0.1458 - val_acc: 0.9925 - val_mDice: 0.4771

Epoch 00018: val_mDice did not improve from 0.49269
Epoch 19/300
 - 45s - loss: 0.0508 - acc: 0.9947 - mDice: 0.9010 - val_loss: 0.0426 - val_acc: 0.9936 - val_mDice: 0.4868

Epoch 00019: val_mDice did not improve from 0.49269
Epoch 20/300
 - 46s - loss: 0.0502 - acc: 0.9947 - mDice: 0.9023 - val_loss: 0.1007 - val_acc: 0.9934 - val_mDice: 0.4883

Epoch 00020: val_mDice did not improve from 0.49269
Epoch 21/300
 - 46s - loss: 0.0486 - acc: 0.9948 - mDice: 0.9054 - val_loss: 0.0022 - val_acc: 0.9932 - val_mDice: 0.4892

Epoch 00021: val_mDice did not improve from 0.49269
Epoch 22/300
 - 46s - loss: 0.0484 - acc: 0.9948 - mDice: 0.9057 - val_loss: 0.1449 - val_acc: 0.9924 - val_mDice: 0.4790

Epoch 00022: val_mDice did not improve from 0.49269
Epoch 23/300
 - 45s - loss: 0.0475 - acc: 0.9948 - mDice: 0.9075 - val_loss: 0.1436 - val_acc: 0.9923 - val_mDice: 0.4816

Epoch 00023: val_mDice did not improve from 0.49269
Epoch 24/300
 - 44s - loss: 0.0469 - acc: 0.9949 - mDice: 0.9088 - val_loss: 0.0079 - val_acc: 0.9928 - val_mDice: 0.4781

Epoch 00024: val_mDice did not improve from 0.49269
Epoch 25/300
 - 44s - loss: 0.0496 - acc: 0.9948 - mDice: 0.9033 - val_loss: 0.1380 - val_acc: 0.9928 - val_mDice: 0.4926

Epoch 00025: val_mDice did not improve from 0.49269
Epoch 26/300
 - 44s - loss: 0.0471 - acc: 0.9950 - mDice: 0.9084 - val_loss: 0.1540 - val_acc: 0.9897 - val_mDice: 0.4625

Epoch 00026: val_mDice did not improve from 0.49269
Epoch 27/300
 - 44s - loss: 0.0476 - acc: 0.9950 - mDice: 0.9074 - val_loss: 0.1002 - val_acc: 0.9931 - val_mDice: 0.4896

Epoch 00027: val_mDice did not improve from 0.49269
Epoch 28/300
 - 44s - loss: 0.0470 - acc: 0.9950 - mDice: 0.9085 - val_loss: 0.1075 - val_acc: 0.9930 - val_mDice: 0.4913

Epoch 00028: val_mDice did not improve from 0.49269
Epoch 29/300
 - 44s - loss: 0.0472 - acc: 0.9950 - mDice: 0.9082 - val_loss: 0.0508 - val_acc: 0.9926 - val_mDice: 0.4709

Epoch 00029: val_mDice did not improve from 0.49269
Epoch 30/300
 - 44s - loss: 0.0460 - acc: 0.9951 - mDice: 0.9105 - val_loss: 0.0836 - val_acc: 0.9934 - val_mDice: 0.4834

Epoch 00030: val_mDice did not improve from 0.49269
Epoch 31/300
 - 44s - loss: 0.0482 - acc: 0.9949 - mDice: 0.9062 - val_loss: 0.0101 - val_acc: 0.9924 - val_mDice: 0.4739

Epoch 00031: val_mDice did not improve from 0.49269
Epoch 32/300
 - 44s - loss: 0.0455 - acc: 0.9951 - mDice: 0.9115 - val_loss: 0.0442 - val_acc: 0.9932 - val_mDice: 0.4838

Epoch 00032: val_mDice did not improve from 0.49269

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 33/300
 - 44s - loss: 0.0448 - acc: 0.9952 - mDice: 0.9129 - val_loss: 0.0431 - val_acc: 0.9933 - val_mDice: 0.4860

Epoch 00033: val_mDice did not improve from 0.49269
Epoch 34/300
 - 45s - loss: 0.0438 - acc: 0.9953 - mDice: 0.9149 - val_loss: 0.1401 - val_acc: 0.9927 - val_mDice: 0.4884

Epoch 00034: val_mDice did not improve from 0.49269
Epoch 35/300
 - 44s - loss: 0.0439 - acc: 0.9953 - mDice: 0.9146 - val_loss: 0.0406 - val_acc: 0.9936 - val_mDice: 0.4908

Epoch 00035: val_mDice did not improve from 0.49269
Epoch 36/300
 - 44s - loss: 0.0447 - acc: 0.9953 - mDice: 0.9131 - val_loss: 0.0980 - val_acc: 0.9932 - val_mDice: 0.4939

Epoch 00036: val_mDice improved from 0.49269 to 0.49394, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 37/300
 - 44s - loss: 0.0436 - acc: 0.9953 - mDice: 0.9151 - val_loss: 0.1018 - val_acc: 0.9930 - val_mDice: 0.4865

Epoch 00037: val_mDice did not improve from 0.49394
Epoch 38/300
 - 44s - loss: 0.0433 - acc: 0.9953 - mDice: 0.9157 - val_loss: 0.1399 - val_acc: 0.9929 - val_mDice: 0.4887

Epoch 00038: val_mDice did not improve from 0.49394
Epoch 39/300
 - 44s - loss: 0.0418 - acc: 0.9953 - mDice: 0.9187 - val_loss: 0.1026 - val_acc: 0.9931 - val_mDice: 0.4851

Epoch 00039: val_mDice did not improve from 0.49394
Epoch 40/300
 - 44s - loss: 0.0420 - acc: 0.9954 - mDice: 0.9184 - val_loss: 0.0042 - val_acc: 0.9933 - val_mDice: 0.4853

Epoch 00040: val_mDice did not improve from 0.49394
Epoch 41/300
 - 44s - loss: 0.0421 - acc: 0.9954 - mDice: 0.9182 - val_loss: 0.1462 - val_acc: 0.9915 - val_mDice: 0.4768

Epoch 00041: val_mDice did not improve from 0.49394
Epoch 42/300
 - 44s - loss: 0.0421 - acc: 0.9954 - mDice: 0.9182 - val_loss: 0.0390 - val_acc: 0.9933 - val_mDice: 0.4942

Epoch 00042: val_mDice improved from 0.49394 to 0.49416, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 43/300
 - 44s - loss: 0.0414 - acc: 0.9954 - mDice: 0.9196 - val_loss: 0.1410 - val_acc: 0.9930 - val_mDice: 0.4865

Epoch 00043: val_mDice did not improve from 0.49416
Epoch 44/300
 - 44s - loss: 0.0413 - acc: 0.9954 - mDice: 0.9197 - val_loss: 0.0458 - val_acc: 0.9934 - val_mDice: 0.4802

Epoch 00044: val_mDice did not improve from 0.49416
Epoch 45/300
 - 44s - loss: 0.0403 - acc: 0.9954 - mDice: 0.9218 - val_loss: 0.0797 - val_acc: 0.9936 - val_mDice: 0.4910

Epoch 00045: val_mDice did not improve from 0.49416
Epoch 46/300
 - 44s - loss: 0.0411 - acc: 0.9954 - mDice: 0.9201 - val_loss: 0.1013 - val_acc: 0.9933 - val_mDice: 0.4872

Epoch 00046: val_mDice did not improve from 0.49416
Epoch 47/300
 - 44s - loss: 0.0409 - acc: 0.9955 - mDice: 0.9204 - val_loss: 0.1227 - val_acc: 0.9927 - val_mDice: 0.4840

Epoch 00047: val_mDice did not improve from 0.49416
Epoch 48/300
 - 44s - loss: 0.0419 - acc: 0.9954 - mDice: 0.9185 - val_loss: 0.0404 - val_acc: 0.9935 - val_mDice: 0.4912

Epoch 00048: val_mDice did not improve from 0.49416
Epoch 49/300
 - 44s - loss: 0.0408 - acc: 0.9955 - mDice: 0.9207 - val_loss: 0.0817 - val_acc: 0.9935 - val_mDice: 0.4870

Epoch 00049: val_mDice did not improve from 0.49416
Epoch 50/300
 - 44s - loss: 0.0413 - acc: 0.9955 - mDice: 0.9196 - val_loss: 0.0775 - val_acc: 0.9935 - val_mDice: 0.4954

Epoch 00050: val_mDice improved from 0.49416 to 0.49544, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 51/300
 - 44s - loss: 0.0406 - acc: 0.9955 - mDice: 0.9212 - val_loss: 0.0403 - val_acc: 0.9936 - val_mDice: 0.4913

Epoch 00051: val_mDice did not improve from 0.49544
Epoch 52/300
 - 44s - loss: 0.0405 - acc: 0.9955 - mDice: 0.9212 - val_loss: 0.0994 - val_acc: 0.9932 - val_mDice: 0.4910

Epoch 00052: val_mDice did not improve from 0.49544
Epoch 53/300
 - 44s - loss: 0.0403 - acc: 0.9955 - mDice: 0.9217 - val_loss: 0.0407 - val_acc: 0.9938 - val_mDice: 0.4905

Epoch 00053: val_mDice did not improve from 0.49544
Epoch 54/300
 - 44s - loss: 0.0400 - acc: 0.9955 - mDice: 0.9222 - val_loss: 0.0967 - val_acc: 0.9936 - val_mDice: 0.4964

Epoch 00054: val_mDice improved from 0.49544 to 0.49635, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 55/300
 - 44s - loss: 0.0398 - acc: 0.9955 - mDice: 0.9227 - val_loss: 0.0965 - val_acc: 0.9932 - val_mDice: 0.4969

Epoch 00055: val_mDice improved from 0.49635 to 0.49692, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 56/300
 - 44s - loss: 0.0404 - acc: 0.9956 - mDice: 0.9215 - val_loss: 0.0470 - val_acc: 0.9930 - val_mDice: 0.4783

Epoch 00056: val_mDice did not improve from 0.49692
Epoch 57/300
 - 44s - loss: 0.0406 - acc: 0.9955 - mDice: 0.9211 - val_loss: 0.0974 - val_acc: 0.9936 - val_mDice: 0.4949

Epoch 00057: val_mDice did not improve from 0.49692
Epoch 58/300
 - 44s - loss: 0.0404 - acc: 0.9955 - mDice: 0.9214 - val_loss: 0.1395 - val_acc: 0.9928 - val_mDice: 0.4895

Epoch 00058: val_mDice did not improve from 0.49692
Epoch 59/300
 - 44s - loss: 0.0400 - acc: 0.9956 - mDice: 0.9223 - val_loss: 0.0396 - val_acc: 0.9937 - val_mDice: 0.4924

Epoch 00059: val_mDice did not improve from 0.49692
Epoch 60/300
 - 44s - loss: 0.0401 - acc: 0.9956 - mDice: 0.9221 - val_loss: 0.1004 - val_acc: 0.9930 - val_mDice: 0.4892

Epoch 00060: val_mDice did not improve from 0.49692
Epoch 61/300
 - 45s - loss: 0.0391 - acc: 0.9956 - mDice: 0.9239 - val_loss: 0.0580 - val_acc: 0.9938 - val_mDice: 0.4951

Epoch 00061: val_mDice did not improve from 0.49692
Epoch 62/300
 - 45s - loss: 0.0394 - acc: 0.9956 - mDice: 0.9234 - val_loss: 0.1013 - val_acc: 0.9933 - val_mDice: 0.4873

Epoch 00062: val_mDice did not improve from 0.49692
Epoch 63/300
 - 44s - loss: 0.0393 - acc: 0.9956 - mDice: 0.9235 - val_loss: 0.0444 - val_acc: 0.9934 - val_mDice: 0.4832

Epoch 00063: val_mDice did not improve from 0.49692
Epoch 64/300
 - 44s - loss: 0.0397 - acc: 0.9956 - mDice: 0.9228 - val_loss: 0.1024 - val_acc: 0.9931 - val_mDice: 0.4851

Epoch 00064: val_mDice did not improve from 0.49692
Epoch 65/300
 - 44s - loss: 0.0398 - acc: 0.9956 - mDice: 0.9227 - val_loss: 0.1462 - val_acc: 0.9918 - val_mDice: 0.4769

Epoch 00065: val_mDice did not improve from 0.49692
Epoch 66/300
 - 44s - loss: 0.0389 - acc: 0.9956 - mDice: 0.9245 - val_loss: 0.0379 - val_acc: 0.9935 - val_mDice: 0.4963

Epoch 00066: val_mDice did not improve from 0.49692
Epoch 67/300
 - 44s - loss: 0.0395 - acc: 0.9956 - mDice: 0.9231 - val_loss: 0.0396 - val_acc: 0.9938 - val_mDice: 0.4926

Epoch 00067: val_mDice did not improve from 0.49692
Epoch 68/300
 - 44s - loss: 0.0379 - acc: 0.9957 - mDice: 0.9264 - val_loss: 0.0995 - val_acc: 0.9932 - val_mDice: 0.4909

Epoch 00068: val_mDice did not improve from 0.49692
Epoch 69/300
 - 45s - loss: 0.0401 - acc: 0.9956 - mDice: 0.9220 - val_loss: 0.0403 - val_acc: 0.9935 - val_mDice: 0.4916

Epoch 00069: val_mDice did not improve from 0.49692
Epoch 70/300
 - 44s - loss: 0.0386 - acc: 0.9956 - mDice: 0.9249 - val_loss: 0.0408 - val_acc: 0.9935 - val_mDice: 0.4905

Epoch 00070: val_mDice did not improve from 0.49692

Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 71/300
 - 44s - loss: 0.0382 - acc: 0.9957 - mDice: 0.9258 - val_loss: 0.0418 - val_acc: 0.9934 - val_mDice: 0.4885

Epoch 00071: val_mDice did not improve from 0.49692
Epoch 72/300
 - 44s - loss: 0.0384 - acc: 0.9957 - mDice: 0.9253 - val_loss: 0.0415 - val_acc: 0.9935 - val_mDice: 0.4890

Epoch 00072: val_mDice did not improve from 0.49692
Epoch 73/300
 - 45s - loss: 0.0382 - acc: 0.9957 - mDice: 0.9257 - val_loss: 0.0992 - val_acc: 0.9932 - val_mDice: 0.4916

Epoch 00073: val_mDice did not improve from 0.49692
Epoch 74/300
 - 45s - loss: 0.0388 - acc: 0.9957 - mDice: 0.9246 - val_loss: 0.0795 - val_acc: 0.9936 - val_mDice: 0.4914

Epoch 00074: val_mDice did not improve from 0.49692
Epoch 75/300
 - 45s - loss: 0.0372 - acc: 0.9957 - mDice: 0.9277 - val_loss: 0.0411 - val_acc: 0.9937 - val_mDice: 0.4898

Epoch 00075: val_mDice did not improve from 0.49692
Epoch 76/300
 - 44s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9277 - val_loss: 0.0416 - val_acc: 0.9935 - val_mDice: 0.4888

Epoch 00076: val_mDice did not improve from 0.49692
Epoch 77/300
 - 44s - loss: 0.0373 - acc: 0.9958 - mDice: 0.9275 - val_loss: 0.0707 - val_acc: 0.9937 - val_mDice: 0.4902

Epoch 00077: val_mDice did not improve from 0.49692
Epoch 78/300
 - 44s - loss: 0.0379 - acc: 0.9957 - mDice: 0.9262 - val_loss: 0.0600 - val_acc: 0.9932 - val_mDice: 0.4915

Epoch 00078: val_mDice did not improve from 0.49692
Epoch 79/300
 - 44s - loss: 0.0378 - acc: 0.9957 - mDice: 0.9264 - val_loss: 0.0399 - val_acc: 0.9937 - val_mDice: 0.4921

Epoch 00079: val_mDice did not improve from 0.49692
Epoch 80/300
 - 44s - loss: 0.0373 - acc: 0.9958 - mDice: 0.9275 - val_loss: 0.0401 - val_acc: 0.9939 - val_mDice: 0.4917

Epoch 00080: val_mDice did not improve from 0.49692
Epoch 81/300
 - 44s - loss: 0.0379 - acc: 0.9958 - mDice: 0.9263 - val_loss: 0.1011 - val_acc: 0.9933 - val_mDice: 0.4877

Epoch 00081: val_mDice did not improve from 0.49692
Epoch 82/300
 - 44s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9277 - val_loss: 0.0381 - val_acc: 0.9938 - val_mDice: 0.4957

Epoch 00082: val_mDice did not improve from 0.49692
Epoch 83/300
 - 44s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9278 - val_loss: 0.1414 - val_acc: 0.9930 - val_mDice: 0.4857

Epoch 00083: val_mDice did not improve from 0.49692
Epoch 84/300
 - 44s - loss: 0.0370 - acc: 0.9958 - mDice: 0.9281 - val_loss: 0.0395 - val_acc: 0.9938 - val_mDice: 0.4930

Epoch 00084: val_mDice did not improve from 0.49692
Epoch 85/300
 - 44s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9277 - val_loss: 0.0016 - val_acc: 0.9938 - val_mDice: 0.4902

Epoch 00085: val_mDice did not improve from 0.49692

Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 86/300
 - 44s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9283 - val_loss: 0.0476 - val_acc: 0.9938 - val_mDice: 0.4921

Epoch 00086: val_mDice did not improve from 0.49692
Epoch 87/300
 - 45s - loss: 0.0370 - acc: 0.9958 - mDice: 0.9282 - val_loss: 0.0386 - val_acc: 0.9936 - val_mDice: 0.4948

Epoch 00087: val_mDice did not improve from 0.49692
Epoch 88/300
 - 44s - loss: 0.0378 - acc: 0.9958 - mDice: 0.9265 - val_loss: 0.0395 - val_acc: 0.9938 - val_mDice: 0.4930

Epoch 00088: val_mDice did not improve from 0.49692
Epoch 89/300
 - 44s - loss: 0.0367 - acc: 0.9959 - mDice: 0.9287 - val_loss: 0.0391 - val_acc: 0.9938 - val_mDice: 0.4925

Epoch 00089: val_mDice did not improve from 0.49692
Epoch 90/300
 - 44s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9300 - val_loss: 0.0403 - val_acc: 0.9937 - val_mDice: 0.4913

Epoch 00090: val_mDice did not improve from 0.49692
Epoch 91/300
 - 44s - loss: 0.0367 - acc: 0.9958 - mDice: 0.9287 - val_loss: 0.0788 - val_acc: 0.9935 - val_mDice: 0.4930

Epoch 00091: val_mDice did not improve from 0.49692
Epoch 92/300
 - 44s - loss: 0.0363 - acc: 0.9958 - mDice: 0.9294 - val_loss: 0.1005 - val_acc: 0.9936 - val_mDice: 0.4884

Epoch 00092: val_mDice did not improve from 0.49692
Epoch 93/300
 - 44s - loss: 0.0365 - acc: 0.9958 - mDice: 0.9290 - val_loss: 0.0791 - val_acc: 0.9937 - val_mDice: 0.4922

Epoch 00093: val_mDice did not improve from 0.49692
Epoch 94/300
 - 44s - loss: 0.0367 - acc: 0.9958 - mDice: 0.9286 - val_loss: 0.1009 - val_acc: 0.9935 - val_mDice: 0.4879

Epoch 00094: val_mDice did not improve from 0.49692
Epoch 95/300
 - 44s - loss: 0.0371 - acc: 0.9959 - mDice: 0.9279 - val_loss: 0.0405 - val_acc: 0.9938 - val_mDice: 0.4909

Epoch 00095: val_mDice did not improve from 0.49692
Restoring model weights from the end of the best epoch
Epoch 00095: early stopping
{'val_loss': [0.1064049960935817, 0.17771472416672052, 0.17778994435188816, 0.22235972478109248, 0.11951428505719877, 0.014528922006195667, 0.17926813457526414, 0.13744473457336426, 0.028163724962402794, 0.14389159866407805, 0.06501479680631675, 0.10450886160719629, 0.10662815413054298, 0.14885450198369868, 0.10062193987416286, 0.08104165745716468, 0.039621747884095886, 0.14578413232868792, 0.042589470744132996, 0.10069046534743964, 0.0022322383581423293, 0.14487576952167586, 0.14364844151571685, 0.007899862001923955, 0.13796543841268502, 0.15396356582641602, 0.10019267832531649, 0.10745041861253626, 0.05076536886832293, 0.08358919123808543, 0.010103382024110532, 0.044157878440969134, 0.04305332460824181, 0.14012150554095998, 0.040598827834222834, 0.09797921718335618, 0.10176042306656931, 0.13989837964375815, 0.10259237534859601, 0.004216384069592345, 0.14624316552106073, 0.03900160538215263, 0.14096025888826333, 0.04576363049301447, 0.07969266935890797, 0.10132457491229563, 0.12270214481681001, 0.040437338106772476, 0.08172077641767614, 0.07751449007613986, 0.04033012717377906, 0.0994136210750131, 0.040710860607670804, 0.09666976274228563, 0.09650494099832048, 0.046955317551014474, 0.0973948947354859, 0.13950563704266267, 0.03960928729936188, 0.10044706715088264, 0.057996487208441194, 0.10129077323511534, 0.04442693088568893, 0.10238896105803695, 0.14615947125004788, 0.03785131550302692, 0.03960565492218616, 0.099496797895899, 0.0402598871904261, 0.04081279448434418, 0.041786701655855366, 0.041536048346874764, 0.09916494436123792, 0.07953184550883723, 0.041068922363075556, 0.04162440609698202, 0.07065321534287695, 0.059984543452075885, 0.0399319190605014, 0.040095186701007916, 0.10105549471051085, 0.03810241643120261, 0.14136851681213752, 0.039474105718089084, 0.0016360014092688467, 0.047564471177026335, 0.03858032793390984, 0.039459180305985844, 0.03914900912958033, 0.04030173432593252, 0.07876645846694123, 0.10045494022322636, 0.07912469582230437, 0.10091882388965756, 0.040491293750557246], 'val_acc': [0.9924066557603723, 0.9920504373662612, 0.9927735211802464, 0.9890932990055458, 0.992272367664412, 0.9929400518828747, 0.9921650068432677, 0.9931901553097893, 0.9929409868576947, 0.9926066737548978, 0.9927437831373775, 0.9929860631624857, 0.9926010417003258, 0.9907927022260778, 0.9932076860876644, 0.9936981925777361, 0.9936772234299603, 0.992514965580959, 0.993626825949725, 0.9933973761165843, 0.9932427453059777, 0.9923903766800376, 0.992275499830059, 0.9927854140599569, 0.9928135848512837, 0.9897378087043762, 0.9930737053646761, 0.9929882556784386, 0.9926001067255058, 0.9933588738534965, 0.9923734735040104, 0.9932152009477803, 0.9932959593978583, 0.9927106102307638, 0.9936380923963061, 0.9932092486643324, 0.9930183069378722, 0.9928646052584928, 0.993083727126028, 0.9932737327089497, 0.9915461516847798, 0.9933332087946873, 0.9929791747354993, 0.9934361915962369, 0.9936227541343838, 0.9932590197114384, 0.9926633390725828, 0.9934928487328922, 0.9935203930910896, 0.9935247804604325, 0.9935632827235203, 0.9932392975863289, 0.9937579795426014, 0.9935717278835821, 0.9931607293147667, 0.9929582020815682, 0.9936224444239747, 0.9928257944537144, 0.9936966241574755, 0.9929970234048133, 0.9937830193369996, 0.9932662260298636, 0.9934030070024378, 0.9931366338449366, 0.9918472836999332, 0.9934562281066296, 0.9938434339037129, 0.9932036177784789, 0.9935000480390063, 0.9934643623875636, 0.9933973737791473, 0.9935016141218298, 0.993177637165668, 0.9936293293448055, 0.9936831675323785, 0.9935153863009285, 0.9936503125172035, 0.9931788853570527, 0.9937492141536638, 0.993853767712911, 0.993336024237614, 0.9937633042242012, 0.9930492884972516, 0.993762359899633, 0.993814325800129, 0.9938293508454865, 0.9936371574214861, 0.9937920991112205, 0.9938190240485996, 0.9936928749084473, 0.9934997371598786, 0.993556394296534, 0.9937053895464131, 0.9935038136500939, 0.993799929525338], 'val_mDice': [0.4611494173021877, 0.4538833732698478, 0.46946678208369835, 0.45546146891280714, 0.4704255777246812, 0.47446129850897134, 0.4800057013829549, 0.4869844976301287, 0.47796055090193657, 0.4809405219321157, 0.481670045166039, 0.4811101782263494, 0.4769220936532114, 0.4720344856089237, 0.48862869847638934, 0.4882525902460603, 0.4926883014028563, 0.47714904447396594, 0.4868050325004494, 0.48831256741986556, 0.48923983171299174, 0.4790022244640425, 0.4815926054215036, 0.4781185084698247, 0.4926469472109103, 0.46246709820686605, 0.48956481148214903, 0.4912548702137143, 0.47092134019761694, 0.483364276661008, 0.4739118253483492, 0.483838640555155, 0.4860024082602239, 0.48835188617893294, 0.49075767149527866, 0.49394101371954363, 0.48647617329569426, 0.4887479643026988, 0.48507148290381713, 0.4853052385516611, 0.47678931729466306, 0.4941552994298, 0.48651162082073734, 0.4802129350456537, 0.4910369810520434, 0.48718055133141724, 0.48400353508837085, 0.491184069537649, 0.48697875892999126, 0.4954438969200733, 0.4913370828418171, 0.49103055222361697, 0.49046145467197194, 0.4963505309002072, 0.49692118869108315, 0.4782802167476392, 0.4948732741907534, 0.48954175208129136, 0.49239637103735234, 0.4891640906240433, 0.49511093719332827, 0.48726901353574265, 0.4832055332029567, 0.4851492621442851, 0.4768761308754192, 0.49630700796842575, 0.49262672969523597, 0.490862423006226, 0.4915500854452451, 0.49046502160091027, 0.48851601487281276, 0.48899269863670947, 0.49158853175602063, 0.49137023558803633, 0.48984720017395766, 0.48880588497016947, 0.490243587715953, 0.49153946135558335, 0.49207832649642347, 0.49169163259805415, 0.48771680745424006, 0.4957091361284256, 0.48571476240313666, 0.4929823910488802, 0.490178186665563, 0.49213287205088374, 0.49484945249323753, 0.4929847734815934, 0.4925081724045323, 0.49132144246615617, 0.49300874419072094, 0.4884137416294977, 0.4921617420280681, 0.4878714727420433, 0.49092912557078344], 'loss': [0.20591763868086616, 0.08665349927956705, 0.07928351045730518, 0.07229462175262595, 0.06936152908956016, 0.0651243393329032, 0.06291384444264149, 0.059822252331203106, 0.05965269988577067, 0.05833614069330971, 0.05577799170709546, 0.054553321164572836, 0.054954366079577925, 0.05421252874422425, 0.05222625652663092, 0.051557907107771084, 0.053769124643390225, 0.05066434730349958, 0.05084478463256642, 0.050210346373271826, 0.04862854043626539, 0.04844561286747494, 0.04753897316926369, 0.04688555583714927, 0.049646951251697366, 0.04707645415578392, 0.04759504401745373, 0.04704471106458816, 0.047177987410880654, 0.04599845223399011, 0.04818226352592564, 0.045482138057977524, 0.044759362856468636, 0.04375580878841727, 0.04388695152846408, 0.0446696944371785, 0.04364307692200629, 0.043331662715536276, 0.04179906391477665, 0.0419804839180522, 0.042073322978111304, 0.042059341559163556, 0.04136368458341447, 0.04133190031320173, 0.040270121043400664, 0.04112205386545725, 0.04093903196357445, 0.041890046863265924, 0.040772101688438964, 0.04131174192929831, 0.04056014671471228, 0.04052322089104853, 0.04028255406282689, 0.04002759455406665, 0.039770481848698754, 0.04037784497307478, 0.040566152721420355, 0.04041636737492304, 0.039976285639859555, 0.04006976369712825, 0.03914706171534297, 0.03941023228878638, 0.03933778692438731, 0.039699507818539974, 0.0397617714788151, 0.03886083285955768, 0.03952786544136721, 0.03786962148393777, 0.04008601966034562, 0.0386400535164005, 0.03819000971910121, 0.03839976906600032, 0.038198816154911136, 0.03877965260705841, 0.03720186229650166, 0.037210405590584986, 0.037296022543854314, 0.03794545349152389, 0.037846747034176974, 0.03728295217271898, 0.03791165829088755, 0.03720130567721383, 0.03716740733058926, 0.037024028949893054, 0.0371937635331189, 0.036901173428429926, 0.036951754518665635, 0.03776579546473926, 0.03667467042586728, 0.03602871932087167, 0.036678799232139965, 0.036340530820159346, 0.036519149068766986, 0.03671760282347416, 0.03709303736358125], 'acc': [0.9840979056917825, 0.9912303814427018, 0.9920667923452102, 0.9927001562915703, 0.9930117337043637, 0.9933464697715694, 0.9935527461905893, 0.9937473918421383, 0.9938895395052092, 0.994013719454815, 0.9941405367119386, 0.9942405491934175, 0.9943133101912679, 0.994332866418841, 0.9945001558523422, 0.9945603979344307, 0.9944729157272498, 0.9946516784478595, 0.9946587701208501, 0.9946794050358124, 0.9947927889250868, 0.9948401868582007, 0.9948444893430282, 0.9948806788532177, 0.9948492561893013, 0.9949522000343353, 0.9949520372517088, 0.9949682253654852, 0.9949803567628579, 0.9950637678998211, 0.9948670371198712, 0.9950670978947302, 0.9951939187697068, 0.9952660416419525, 0.995274884456034, 0.9952637257872334, 0.9953431160577402, 0.9953391930981299, 0.9953403876605731, 0.9953942806011137, 0.9953765677871731, 0.9953778836929549, 0.9954225119694687, 0.9953975911197995, 0.9954306907000243, 0.9954310106690192, 0.9954545128949387, 0.9954453186891156, 0.9954605761431005, 0.9954722396649369, 0.9954723595383066, 0.9954758894282334, 0.9955175760583275, 0.9955107531233215, 0.9955411014682507, 0.9955537183323636, 0.9955047368034846, 0.9955319029735771, 0.995576229861503, 0.9955580636226854, 0.9955634680861267, 0.9955801162724984, 0.9955784437591794, 0.9955601941921483, 0.9955768547573874, 0.9955977444127716, 0.9956193618756982, 0.9956709609591718, 0.9956295246353818, 0.9956357580436844, 0.9957052321115263, 0.9957442518410344, 0.9957253438870394, 0.9957096746826604, 0.9957462605345113, 0.9957863272173741, 0.9957682351134114, 0.9957358074438646, 0.9957290957215174, 0.9957762848775427, 0.9957902276639784, 0.9957750160349769, 0.9957739918229058, 0.9957635434084896, 0.9957926453339315, 0.9958335124546353, 0.9958408443447552, 0.9958301775655944, 0.99585348021816, 0.9958442855972868, 0.9958243220223087, 0.995849034070678, 0.9958189643177133, 0.9958418591213553, 0.9958773670674947], 'mDice': [0.5967050038549682, 0.8312338791604305, 0.8455351259654313, 0.8591765390459042, 0.8648787862613952, 0.8731748606143448, 0.8774851356509087, 0.8835641888472814, 0.8838300435778809, 0.8863928579531148, 0.891442808428803, 0.8938351185511486, 0.8930000395997809, 0.8944677473349337, 0.8983573750148265, 0.8996590319246959, 0.8952839026976749, 0.90139743285372, 0.9010348797816392, 0.9022922845660987, 0.9053940001916451, 0.9057320800818438, 0.9075440777950899, 0.9088307454804208, 0.9033241502361937, 0.9084118224508784, 0.9073736278385293, 0.908465605745574, 0.9081891325320742, 0.9105082382897385, 0.9062409055895007, 0.9115357901370305, 0.9129101551949428, 0.9148817969590852, 0.9146108293048408, 0.9130553548705631, 0.9150664990103432, 0.915687909350853, 0.918747586187937, 0.9183583347469366, 0.918179938764544, 0.9182061266651462, 0.9195771368113119, 0.9196501656928356, 0.9217542677811653, 0.9200544096440854, 0.920404349437048, 0.9185062312785148, 0.9207329312148653, 0.919644961636307, 0.921152744274259, 0.9212265686718218, 0.9216843513529888, 0.9221927808994468, 0.9226940483596745, 0.921476772302871, 0.921120784986955, 0.92140610852959, 0.9222629789321592, 0.9220858359132095, 0.9239229484421959, 0.923392493100311, 0.9235360781300997, 0.9228227524861701, 0.9226886217879009, 0.9244774593214258, 0.9231340405917905, 0.9264272184419817, 0.9220203282088362, 0.9249014149676181, 0.9257610658017134, 0.9253227361374318, 0.9257329817000306, 0.9245758330988703, 0.9277136215259933, 0.9276824807830885, 0.9275172191509303, 0.9262355976993497, 0.9264275410707556, 0.9275329704625839, 0.9262748669396519, 0.9277009587919333, 0.9277647438829887, 0.9280529198889764, 0.9277061175630434, 0.9282696877873131, 0.9281634126122924, 0.9265436245821235, 0.9287097984479901, 0.930003725847019, 0.9287131172667279, 0.9293806223475579, 0.9290392831945488, 0.9286288387201407, 0.9278607200823609], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.50it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:01,  1.90it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:00<00:00,  2.47it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.99it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:34,  7.78it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:34,  7.76it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:32,  8.01it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:32,  8.09it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:32,  8.08it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:31,  8.13it/s]predicting train subjects:   3%|▎         | 7/266 [00:00<00:31,  8.17it/s]predicting train subjects:   3%|▎         | 8/266 [00:00<00:31,  8.21it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:31,  8.24it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:30,  8.30it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:31,  8.19it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:30,  8.26it/s]predicting train subjects:   5%|▍         | 13/266 [00:01<00:30,  8.31it/s]predicting train subjects:   5%|▌         | 14/266 [00:01<00:30,  8.24it/s]predicting train subjects:   6%|▌         | 15/266 [00:01<00:30,  8.20it/s]predicting train subjects:   6%|▌         | 16/266 [00:01<00:30,  8.24it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:30,  8.25it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:30,  8.24it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:29,  8.28it/s]predicting train subjects:   8%|▊         | 20/266 [00:02<00:29,  8.29it/s]predicting train subjects:   8%|▊         | 21/266 [00:02<00:29,  8.32it/s]predicting train subjects:   8%|▊         | 22/266 [00:02<00:29,  8.32it/s]predicting train subjects:   9%|▊         | 23/266 [00:02<00:28,  8.44it/s]predicting train subjects:   9%|▉         | 24/266 [00:02<00:28,  8.56it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:28,  8.56it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:27,  8.62it/s]predicting train subjects:  10%|█         | 27/266 [00:03<00:27,  8.66it/s]predicting train subjects:  11%|█         | 28/266 [00:03<00:27,  8.71it/s]predicting train subjects:  11%|█         | 29/266 [00:03<00:27,  8.65it/s]predicting train subjects:  11%|█▏        | 30/266 [00:03<00:27,  8.69it/s]predicting train subjects:  12%|█▏        | 31/266 [00:03<00:27,  8.70it/s]predicting train subjects:  12%|█▏        | 32/266 [00:03<00:26,  8.77it/s]predicting train subjects:  12%|█▏        | 33/266 [00:03<00:26,  8.81it/s]predicting train subjects:  13%|█▎        | 34/266 [00:04<00:26,  8.80it/s]predicting train subjects:  13%|█▎        | 35/266 [00:04<00:26,  8.83it/s]predicting train subjects:  14%|█▎        | 36/266 [00:04<00:26,  8.84it/s]predicting train subjects:  14%|█▍        | 37/266 [00:04<00:25,  8.84it/s]predicting train subjects:  14%|█▍        | 38/266 [00:04<00:25,  8.86it/s]predicting train subjects:  15%|█▍        | 39/266 [00:04<00:25,  8.89it/s]predicting train subjects:  15%|█▌        | 40/266 [00:04<00:25,  8.85it/s]predicting train subjects:  15%|█▌        | 41/266 [00:04<00:25,  8.78it/s]predicting train subjects:  16%|█▌        | 42/266 [00:04<00:26,  8.48it/s]predicting train subjects:  16%|█▌        | 43/266 [00:05<00:26,  8.52it/s]predicting train subjects:  17%|█▋        | 44/266 [00:05<00:25,  8.61it/s]predicting train subjects:  17%|█▋        | 45/266 [00:05<00:25,  8.64it/s]predicting train subjects:  17%|█▋        | 46/266 [00:05<00:25,  8.67it/s]predicting train subjects:  18%|█▊        | 47/266 [00:05<00:25,  8.55it/s]predicting train subjects:  18%|█▊        | 48/266 [00:05<00:26,  8.21it/s]predicting train subjects:  18%|█▊        | 49/266 [00:05<00:26,  8.31it/s]predicting train subjects:  19%|█▉        | 50/266 [00:05<00:25,  8.41it/s]predicting train subjects:  19%|█▉        | 51/266 [00:06<00:25,  8.54it/s]predicting train subjects:  20%|█▉        | 52/266 [00:06<00:24,  8.67it/s]predicting train subjects:  20%|█▉        | 53/266 [00:06<00:24,  8.62it/s]predicting train subjects:  20%|██        | 54/266 [00:06<00:24,  8.65it/s]predicting train subjects:  21%|██        | 55/266 [00:06<00:24,  8.72it/s]predicting train subjects:  21%|██        | 56/266 [00:06<00:24,  8.64it/s]predicting train subjects:  21%|██▏       | 57/266 [00:06<00:23,  8.71it/s]predicting train subjects:  22%|██▏       | 58/266 [00:06<00:23,  8.72it/s]predicting train subjects:  22%|██▏       | 59/266 [00:06<00:24,  8.51it/s]predicting train subjects:  23%|██▎       | 60/266 [00:07<00:24,  8.40it/s]predicting train subjects:  23%|██▎       | 61/266 [00:07<00:24,  8.36it/s]predicting train subjects:  23%|██▎       | 62/266 [00:07<00:24,  8.31it/s]predicting train subjects:  24%|██▎       | 63/266 [00:07<00:24,  8.23it/s]predicting train subjects:  24%|██▍       | 64/266 [00:07<00:24,  8.23it/s]predicting train subjects:  24%|██▍       | 65/266 [00:07<00:24,  8.20it/s]predicting train subjects:  25%|██▍       | 66/266 [00:07<00:24,  8.18it/s]predicting train subjects:  25%|██▌       | 67/266 [00:07<00:24,  8.11it/s]predicting train subjects:  26%|██▌       | 68/266 [00:08<00:24,  8.03it/s]predicting train subjects:  26%|██▌       | 69/266 [00:08<00:24,  8.04it/s]predicting train subjects:  26%|██▋       | 70/266 [00:08<00:24,  8.10it/s]predicting train subjects:  27%|██▋       | 71/266 [00:08<00:24,  8.12it/s]predicting train subjects:  27%|██▋       | 72/266 [00:08<00:23,  8.14it/s]predicting train subjects:  27%|██▋       | 73/266 [00:08<00:23,  8.12it/s]predicting train subjects:  28%|██▊       | 74/266 [00:08<00:23,  8.06it/s]predicting train subjects:  28%|██▊       | 75/266 [00:08<00:23,  8.06it/s]predicting train subjects:  29%|██▊       | 76/266 [00:09<00:23,  8.10it/s]predicting train subjects:  29%|██▉       | 77/266 [00:09<00:26,  7.18it/s]predicting train subjects:  29%|██▉       | 78/266 [00:09<00:28,  6.65it/s]predicting train subjects:  30%|██▉       | 79/266 [00:09<00:30,  6.20it/s]predicting train subjects:  30%|███       | 80/266 [00:09<00:31,  5.83it/s]predicting train subjects:  30%|███       | 81/266 [00:09<00:29,  6.21it/s]predicting train subjects:  31%|███       | 82/266 [00:10<00:29,  6.23it/s]predicting train subjects:  31%|███       | 83/266 [00:10<00:28,  6.49it/s]predicting train subjects:  32%|███▏      | 84/266 [00:10<00:27,  6.61it/s]predicting train subjects:  32%|███▏      | 85/266 [00:10<00:26,  6.74it/s]predicting train subjects:  32%|███▏      | 86/266 [00:10<00:26,  6.77it/s]predicting train subjects:  33%|███▎      | 87/266 [00:10<00:26,  6.84it/s]predicting train subjects:  33%|███▎      | 88/266 [00:10<00:26,  6.84it/s]predicting train subjects:  33%|███▎      | 89/266 [00:11<00:25,  6.90it/s]predicting train subjects:  34%|███▍      | 90/266 [00:11<00:25,  6.94it/s]predicting train subjects:  34%|███▍      | 91/266 [00:11<00:25,  6.95it/s]predicting train subjects:  35%|███▍      | 92/266 [00:11<00:24,  7.00it/s]predicting train subjects:  35%|███▍      | 93/266 [00:11<00:24,  6.96it/s]predicting train subjects:  35%|███▌      | 94/266 [00:11<00:24,  6.98it/s]predicting train subjects:  36%|███▌      | 95/266 [00:11<00:24,  7.03it/s]predicting train subjects:  36%|███▌      | 96/266 [00:12<00:24,  7.00it/s]predicting train subjects:  36%|███▋      | 97/266 [00:12<00:24,  6.95it/s]predicting train subjects:  37%|███▋      | 98/266 [00:12<00:24,  6.89it/s]predicting train subjects:  37%|███▋      | 99/266 [00:12<00:24,  6.72it/s]predicting train subjects:  38%|███▊      | 100/266 [00:12<00:24,  6.83it/s]predicting train subjects:  38%|███▊      | 101/266 [00:12<00:23,  6.95it/s]predicting train subjects:  38%|███▊      | 102/266 [00:12<00:23,  7.05it/s]predicting train subjects:  39%|███▊      | 103/266 [00:13<00:22,  7.12it/s]predicting train subjects:  39%|███▉      | 104/266 [00:13<00:22,  7.12it/s]predicting train subjects:  39%|███▉      | 105/266 [00:13<00:22,  7.09it/s]predicting train subjects:  40%|███▉      | 106/266 [00:13<00:22,  7.10it/s]predicting train subjects:  40%|████      | 107/266 [00:13<00:22,  7.17it/s]predicting train subjects:  41%|████      | 108/266 [00:13<00:21,  7.20it/s]predicting train subjects:  41%|████      | 109/266 [00:13<00:21,  7.17it/s]predicting train subjects:  41%|████▏     | 110/266 [00:14<00:21,  7.12it/s]predicting train subjects:  42%|████▏     | 111/266 [00:14<00:21,  7.11it/s]predicting train subjects:  42%|████▏     | 112/266 [00:14<00:21,  7.11it/s]predicting train subjects:  42%|████▏     | 113/266 [00:14<00:21,  7.11it/s]predicting train subjects:  43%|████▎     | 114/266 [00:14<00:21,  7.10it/s]predicting train subjects:  43%|████▎     | 115/266 [00:14<00:21,  6.92it/s]predicting train subjects:  44%|████▎     | 116/266 [00:14<00:21,  6.98it/s]predicting train subjects:  44%|████▍     | 117/266 [00:15<00:21,  6.98it/s]predicting train subjects:  44%|████▍     | 118/266 [00:15<00:20,  7.37it/s]predicting train subjects:  45%|████▍     | 119/266 [00:15<00:19,  7.71it/s]predicting train subjects:  45%|████▌     | 120/266 [00:15<00:18,  8.01it/s]predicting train subjects:  45%|████▌     | 121/266 [00:15<00:17,  8.18it/s]predicting train subjects:  46%|████▌     | 122/266 [00:15<00:17,  8.39it/s]predicting train subjects:  46%|████▌     | 123/266 [00:15<00:16,  8.51it/s]predicting train subjects:  47%|████▋     | 124/266 [00:15<00:16,  8.57it/s]predicting train subjects:  47%|████▋     | 125/266 [00:15<00:16,  8.59it/s]predicting train subjects:  47%|████▋     | 126/266 [00:16<00:16,  8.63it/s]predicting train subjects:  48%|████▊     | 127/266 [00:16<00:15,  8.69it/s]predicting train subjects:  48%|████▊     | 128/266 [00:16<00:15,  8.70it/s]predicting train subjects:  48%|████▊     | 129/266 [00:16<00:15,  8.71it/s]predicting train subjects:  49%|████▉     | 130/266 [00:16<00:15,  8.60it/s]predicting train subjects:  49%|████▉     | 131/266 [00:16<00:15,  8.54it/s]predicting train subjects:  50%|████▉     | 132/266 [00:16<00:15,  8.58it/s]predicting train subjects:  50%|█████     | 133/266 [00:16<00:15,  8.67it/s]predicting train subjects:  50%|█████     | 134/266 [00:17<00:15,  8.65it/s]predicting train subjects:  51%|█████     | 135/266 [00:17<00:15,  8.67it/s]predicting train subjects:  51%|█████     | 136/266 [00:17<00:14,  8.72it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:17<00:14,  8.70it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:17<00:14,  8.75it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:17<00:14,  8.77it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:17<00:14,  8.73it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:17<00:14,  8.69it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:17<00:14,  8.68it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:18<00:14,  8.68it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:18<00:14,  8.65it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:18<00:13,  8.67it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:18<00:13,  8.64it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:18<00:13,  8.64it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:18<00:13,  8.58it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:18<00:13,  8.53it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:18<00:13,  8.49it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:18<00:13,  8.49it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:19<00:13,  8.46it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:19<00:13,  8.49it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:19<00:14,  7.97it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:19<00:14,  7.78it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:19<00:14,  7.58it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:19<00:14,  7.46it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:19<00:14,  7.43it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:20<00:14,  7.32it/s]predicting train subjects:  60%|██████    | 160/266 [00:20<00:14,  7.26it/s]predicting train subjects:  61%|██████    | 161/266 [00:20<00:14,  7.22it/s]predicting train subjects:  61%|██████    | 162/266 [00:20<00:14,  7.23it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:20<00:14,  7.23it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:20<00:14,  7.22it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:20<00:13,  7.26it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:21<00:13,  7.24it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:21<00:13,  7.22it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:21<00:13,  7.21it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:21<00:13,  7.26it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:21<00:13,  7.27it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:21<00:13,  7.26it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:21<00:12,  7.54it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:22<00:13,  6.75it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:22<00:14,  6.51it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:22<00:14,  6.09it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:22<00:13,  6.69it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:22<00:12,  7.17it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:22<00:11,  7.51it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:22<00:11,  7.80it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:22<00:10,  8.03it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:23<00:10,  8.22it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:23<00:10,  8.32it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:23<00:09,  8.41it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:23<00:09,  8.46it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:23<00:09,  8.51it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:23<00:09,  8.49it/s]predicting train subjects:  70%|███████   | 187/266 [00:23<00:09,  8.36it/s]predicting train subjects:  71%|███████   | 188/266 [00:23<00:09,  8.30it/s]predicting train subjects:  71%|███████   | 189/266 [00:24<00:09,  8.27it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:24<00:09,  8.22it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:24<00:09,  8.19it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:24<00:08,  8.27it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:24<00:08,  8.38it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:24<00:08,  8.37it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:24<00:09,  7.83it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:24<00:09,  7.51it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:25<00:09,  7.26it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:25<00:09,  7.17it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:25<00:09,  7.11it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:25<00:09,  7.06it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:25<00:09,  7.02it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:25<00:09,  7.00it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:25<00:09,  6.97it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:26<00:08,  7.00it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:26<00:08,  7.02it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:26<00:08,  7.01it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:26<00:08,  6.87it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:26<00:08,  6.89it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:26<00:08,  6.97it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:26<00:08,  6.97it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:27<00:07,  6.98it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:27<00:07,  6.98it/s]predicting train subjects:  80%|████████  | 213/266 [00:27<00:07,  7.18it/s]predicting train subjects:  80%|████████  | 214/266 [00:27<00:07,  7.36it/s]predicting train subjects:  81%|████████  | 215/266 [00:27<00:06,  7.42it/s]predicting train subjects:  81%|████████  | 216/266 [00:27<00:06,  7.29it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:27<00:06,  7.42it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:28<00:06,  7.50it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:28<00:06,  7.57it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:28<00:06,  7.47it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:28<00:05,  7.54it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:28<00:05,  7.61it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:28<00:05,  7.63it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:28<00:05,  7.53it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:28<00:05,  7.47it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:29<00:05,  7.56it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:29<00:05,  7.54it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:29<00:05,  7.55it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:29<00:04,  7.53it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:29<00:04,  7.63it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:29<00:04,  8.12it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:29<00:03,  8.52it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:29<00:03,  8.76it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:30<00:03,  8.75it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:30<00:03,  8.75it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:30<00:03,  8.96it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:30<00:03,  9.08it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:30<00:03,  9.03it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:30<00:02,  9.13it/s]predicting train subjects:  90%|█████████ | 240/266 [00:30<00:02,  9.21it/s]predicting train subjects:  91%|█████████ | 241/266 [00:30<00:02,  9.31it/s]predicting train subjects:  91%|█████████ | 242/266 [00:30<00:02,  9.21it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:31<00:02,  9.17it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:31<00:02,  9.23it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:31<00:02,  9.37it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:31<00:02,  9.36it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:31<00:02,  9.30it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:31<00:01,  9.27it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:31<00:01,  9.02it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:31<00:01,  8.89it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:31<00:01,  8.72it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:32<00:01,  8.57it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:32<00:01,  8.51it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:32<00:01,  8.53it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:32<00:01,  8.53it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:32<00:01,  8.40it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:32<00:01,  8.32it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:32<00:00,  8.43it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:32<00:00,  8.55it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:32<00:00,  8.56it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:33<00:00,  8.51it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:33<00:00,  8.50it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:33<00:00,  8.56it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:33<00:00,  8.59it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:33<00:00,  8.53it/s]predicting train subjects: 100%|██████████| 266/266 [00:33<00:00,  8.46it/s]predicting train subjects: 100%|██████████| 266/266 [00:33<00:00,  7.90it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  8.34it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  8.55it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  8.50it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  8.06it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  8.18it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:34,  7.78it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:32,  8.04it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:31,  8.23it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:32,  8.16it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:32,  8.14it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:31,  8.15it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:00<00:31,  8.25it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:00<00:31,  8.22it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:31,  8.17it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:31,  8.16it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:31,  8.22it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:30,  8.21it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:01<00:30,  8.21it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:01<00:30,  8.17it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:01<00:30,  8.23it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:01<00:30,  8.24it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:30,  8.23it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:30,  8.22it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:29,  8.23it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:02<00:29,  8.29it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:02<00:29,  8.33it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:02<00:29,  8.28it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:02<00:28,  8.40it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:02<00:28,  8.53it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:27,  8.61it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:03<00:27,  8.60it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:03<00:27,  8.60it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:03<00:27,  8.56it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:03<00:27,  8.64it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:03<00:27,  8.71it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:03<00:26,  8.71it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:03<00:26,  8.69it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:03<00:26,  8.78it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:04<00:26,  8.79it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:04<00:26,  8.77it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:04<00:26,  8.66it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:04<00:26,  8.61it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:04<00:26,  8.65it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:04<00:26,  8.61it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:04<00:26,  8.58it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:04<00:26,  8.56it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:04<00:25,  8.63it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:05<00:25,  8.68it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:05<00:25,  8.59it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:05<00:25,  8.53it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:05<00:25,  8.51it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:05<00:25,  8.59it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:05<00:25,  8.54it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:05<00:25,  8.54it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:05<00:25,  8.59it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:06<00:24,  8.65it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:06<00:24,  8.62it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:06<00:24,  8.58it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:06<00:25,  8.41it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:06<00:24,  8.50it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:06<00:24,  8.50it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:06<00:24,  8.42it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:06<00:24,  8.45it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:06<00:24,  8.33it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:07<00:25,  8.08it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:07<00:25,  7.98it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:07<00:25,  7.97it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:07<00:25,  8.08it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:07<00:25,  8.02it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:07<00:25,  7.99it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:07<00:24,  8.06it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:07<00:24,  8.12it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:08<00:24,  8.13it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:08<00:24,  8.11it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:08<00:23,  8.18it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:08<00:23,  8.21it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:08<00:23,  8.16it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:08<00:23,  8.07it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:08<00:23,  8.09it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:08<00:23,  8.11it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:09<00:23,  8.11it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:09<00:24,  7.74it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:09<00:24,  7.61it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:09<00:23,  7.94it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:09<00:22,  8.09it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:09<00:23,  7.75it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:09<00:24,  7.55it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:10<00:24,  7.41it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:10<00:25,  7.27it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:10<00:25,  7.20it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:10<00:25,  7.19it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:10<00:24,  7.17it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:10<00:24,  7.12it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:10<00:25,  7.04it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:11<00:25,  7.03it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:11<00:24,  7.02it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:11<00:24,  7.00it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:11<00:24,  7.01it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:11<00:24,  7.09it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:11<00:24,  7.04it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:11<00:24,  7.00it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:12<00:24,  7.04it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:12<00:24,  6.98it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:12<00:24,  6.93it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:12<00:23,  7.05it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:12<00:23,  7.10it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:12<00:23,  7.11it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:12<00:22,  7.15it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:12<00:22,  7.19it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:13<00:22,  7.20it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:13<00:22,  7.18it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:13<00:22,  7.21it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:13<00:21,  7.22it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:13<00:21,  7.18it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:13<00:21,  7.22it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:13<00:21,  7.25it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:14<00:21,  7.20it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:14<00:21,  7.21it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:14<00:20,  7.28it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:14<00:20,  7.24it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:14<00:20,  7.21it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:14<00:20,  7.27it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:14<00:19,  7.64it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:15<00:18,  7.86it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:15<00:18,  8.06it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:15<00:17,  8.30it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:15<00:17,  8.42it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:15<00:16,  8.45it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:15<00:16,  8.53it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:15<00:16,  8.67it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:15<00:16,  8.64it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:15<00:16,  8.60it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:16<00:16,  8.61it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:16<00:15,  8.75it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:16<00:15,  8.75it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:16<00:15,  8.66it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:16<00:15,  8.62it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:16<00:15,  8.65it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:16<00:15,  8.61it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:16<00:15,  8.52it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:16<00:15,  8.51it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:17<00:15,  8.50it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:17<00:15,  8.02it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:17<00:15,  8.13it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:17<00:15,  8.29it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:17<00:15,  8.13it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:17<00:16,  7.71it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:17<00:15,  7.93it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:17<00:15,  8.13it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:18<00:14,  8.24it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:18<00:14,  8.29it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:18<00:14,  8.35it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:18<00:13,  8.45it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:18<00:13,  8.42it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:18<00:13,  8.44it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:18<00:13,  8.48it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:18<00:13,  8.56it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:19<00:13,  8.62it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:19<00:13,  8.12it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:19<00:14,  7.86it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:19<00:14,  7.65it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:19<00:14,  7.32it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:19<00:14,  7.28it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:19<00:14,  7.29it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:20<00:14,  7.26it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:20<00:14,  7.27it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:20<00:14,  7.30it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:20<00:14,  7.32it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:20<00:14,  7.27it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:20<00:13,  7.23it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:20<00:13,  7.26it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:20<00:13,  7.28it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:21<00:13,  7.23it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:21<00:13,  7.19it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:21<00:13,  7.23it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:21<00:13,  7.25it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:21<00:12,  7.49it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:21<00:12,  7.32it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:21<00:12,  7.47it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:22<00:11,  8.03it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:22<00:11,  8.14it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:22<00:10,  8.17it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:22<00:10,  8.21it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:22<00:10,  8.28it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:22<00:10,  8.35it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:22<00:10,  8.35it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:22<00:10,  8.24it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:23<00:10,  8.04it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:23<00:10,  8.07it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:23<00:10,  8.05it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:23<00:09,  8.07it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:23<00:09,  8.14it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:23<00:09,  8.15it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:23<00:09,  8.17it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:23<00:09,  8.18it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:23<00:09,  8.22it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:24<00:08,  8.26it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:24<00:08,  8.23it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:24<00:08,  8.15it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:24<00:09,  7.65it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:24<00:09,  7.50it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:24<00:09,  7.33it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:24<00:09,  7.24it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:25<00:09,  7.19it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:25<00:09,  7.18it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:25<00:09,  7.13it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:25<00:09,  7.08it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:25<00:08,  7.07it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:25<00:08,  7.07it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:25<00:08,  7.08it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:26<00:08,  7.09it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:26<00:08,  7.14it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:26<00:08,  7.08it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:26<00:08,  7.02it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:26<00:07,  7.02it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:26<00:07,  7.10it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:26<00:07,  7.11it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:27<00:07,  7.23it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:27<00:07,  7.34it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:27<00:07,  7.25it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:27<00:06,  7.37it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:27<00:06,  7.29it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:27<00:06,  7.38it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:27<00:06,  7.46it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:27<00:06,  7.46it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:28<00:06,  7.36it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:28<00:05,  7.37it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:28<00:05,  7.46it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:28<00:05,  7.43it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:28<00:05,  7.40it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:28<00:05,  7.44it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:28<00:05,  7.49it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:29<00:05,  7.54it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:29<00:04,  7.52it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:29<00:04,  7.41it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:29<00:04,  7.83it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:29<00:04,  8.26it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:29<00:03,  8.57it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:29<00:03,  8.66it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:29<00:03,  8.99it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:29<00:03,  9.24it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:30<00:03,  9.42it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:30<00:02,  9.42it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:30<00:02,  9.46it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:30<00:02,  9.52it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:30<00:02,  9.52it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:30<00:02,  9.46it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:30<00:02,  9.41it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:30<00:02,  9.40it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:30<00:02,  9.40it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:31<00:02,  9.38it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:31<00:02,  9.28it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:31<00:01,  9.36it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:31<00:01,  9.10it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:31<00:01,  8.95it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:31<00:01,  8.80it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:31<00:01,  8.64it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:31<00:01,  8.51it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:31<00:01,  8.44it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:32<00:01,  8.43it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:32<00:01,  8.47it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:32<00:01,  8.47it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:32<00:00,  8.44it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:32<00:00,  8.38it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:32<00:00,  8.32it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:32<00:00,  8.38it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:32<00:00,  8.44it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:33<00:00,  8.44it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:33<00:00,  8.41it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:33<00:00,  8.34it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:33<00:00,  8.31it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:33<00:00,  7.97it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 77.80it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/266 [00:00<00:03, 79.90it/s]saving BB  train1-THALAMUS:   6%|▋         | 17/266 [00:00<00:03, 80.07it/s]saving BB  train1-THALAMUS:  10%|▉         | 26/266 [00:00<00:02, 81.84it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:02, 83.90it/s]saving BB  train1-THALAMUS:  17%|█▋        | 44/266 [00:00<00:02, 83.46it/s]saving BB  train1-THALAMUS:  20%|██        | 54/266 [00:00<00:02, 86.14it/s]saving BB  train1-THALAMUS:  24%|██▎       | 63/266 [00:00<00:02, 86.11it/s]saving BB  train1-THALAMUS:  27%|██▋       | 72/266 [00:00<00:02, 84.41it/s]saving BB  train1-THALAMUS:  30%|███       | 81/266 [00:00<00:02, 81.75it/s]saving BB  train1-THALAMUS:  33%|███▎      | 89/266 [00:01<00:02, 75.12it/s]saving BB  train1-THALAMUS:  36%|███▋      | 97/266 [00:01<00:02, 71.44it/s]saving BB  train1-THALAMUS:  39%|███▉      | 105/266 [00:01<00:02, 72.38it/s]saving BB  train1-THALAMUS:  42%|████▏     | 113/266 [00:01<00:02, 73.96it/s]saving BB  train1-THALAMUS:  45%|████▌     | 121/266 [00:01<00:01, 74.19it/s]saving BB  train1-THALAMUS:  48%|████▊     | 129/266 [00:01<00:01, 74.31it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 137/266 [00:01<00:01, 75.14it/s]saving BB  train1-THALAMUS:  55%|█████▍    | 146/266 [00:01<00:01, 78.34it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 155/266 [00:01<00:01, 80.02it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 164/266 [00:02<00:01, 76.24it/s]saving BB  train1-THALAMUS:  65%|██████▍   | 172/266 [00:02<00:01, 75.68it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 181/266 [00:02<00:01, 77.13it/s]saving BB  train1-THALAMUS:  71%|███████   | 189/266 [00:02<00:01, 76.24it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 197/266 [00:02<00:00, 76.11it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 205/266 [00:02<00:00, 74.69it/s]saving BB  train1-THALAMUS:  80%|████████  | 213/266 [00:02<00:00, 73.21it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 221/266 [00:02<00:00, 72.73it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 229/266 [00:02<00:00, 73.48it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 77.58it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 80.38it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 256/266 [00:03<00:00, 81.62it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 265/266 [00:03<00:00, 82.60it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 78.39it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 79.57it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 9/266 [00:00<00:03, 80.45it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/266 [00:00<00:03, 80.50it/s]saving BB  train1-THALAMUS Sagittal:  10%|█         | 27/266 [00:00<00:02, 81.22it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▎        | 36/266 [00:00<00:02, 81.54it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:00<00:02, 82.18it/s]saving BB  train1-THALAMUS Sagittal:  20%|██        | 54/266 [00:00<00:02, 84.16it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▎       | 63/266 [00:00<00:02, 84.20it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 72/266 [00:00<00:02, 83.29it/s]saving BB  train1-THALAMUS Sagittal:  30%|███       | 80/266 [00:00<00:02, 81.70it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 88/266 [00:01<00:02, 76.69it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 96/266 [00:01<00:02, 74.53it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 104/266 [00:01<00:02, 72.10it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 112/266 [00:01<00:02, 71.54it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 120/266 [00:01<00:02, 72.18it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 128/266 [00:01<00:01, 72.33it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 136/266 [00:01<00:01, 72.14it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 145/266 [00:01<00:01, 76.67it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:01<00:01, 79.34it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████▏   | 163/266 [00:02<00:01, 77.82it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 171/266 [00:02<00:01, 77.26it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 180/266 [00:02<00:01, 78.25it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 188/266 [00:02<00:00, 78.10it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 196/266 [00:02<00:00, 77.14it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 204/266 [00:02<00:00, 75.83it/s]saving BB  train1-THALAMUS Sagittal:  80%|███████▉  | 212/266 [00:02<00:00, 75.75it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:02<00:00, 75.77it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 228/266 [00:02<00:00, 75.65it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 237/266 [00:03<00:00, 77.34it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 246/266 [00:03<00:00, 78.43it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 255/266 [00:03<00:00, 79.81it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 264/266 [00:03<00:00, 82.24it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 78.25it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:55,  1.12it/s]Loading train:   1%|          | 2/266 [00:01<03:44,  1.17it/s]Loading train:   1%|          | 3/266 [00:02<03:40,  1.19it/s]Loading train:   2%|▏         | 4/266 [00:03<03:43,  1.17it/s]Loading train:   2%|▏         | 5/266 [00:03<03:23,  1.28it/s]Loading train:   2%|▏         | 6/266 [00:04<03:07,  1.39it/s]Loading train:   3%|▎         | 7/266 [00:05<02:50,  1.52it/s]Loading train:   3%|▎         | 8/266 [00:05<02:40,  1.61it/s]Loading train:   3%|▎         | 9/266 [00:06<02:33,  1.67it/s]Loading train:   4%|▍         | 10/266 [00:06<02:30,  1.70it/s]Loading train:   4%|▍         | 11/266 [00:07<02:28,  1.72it/s]Loading train:   5%|▍         | 12/266 [00:07<02:23,  1.77it/s]Loading train:   5%|▍         | 13/266 [00:08<02:21,  1.79it/s]Loading train:   5%|▌         | 14/266 [00:08<02:19,  1.81it/s]Loading train:   6%|▌         | 15/266 [00:09<02:17,  1.82it/s]Loading train:   6%|▌         | 16/266 [00:09<02:15,  1.84it/s]Loading train:   6%|▋         | 17/266 [00:10<02:15,  1.84it/s]Loading train:   7%|▋         | 18/266 [00:11<02:14,  1.85it/s]Loading train:   7%|▋         | 19/266 [00:11<02:13,  1.84it/s]Loading train:   8%|▊         | 20/266 [00:12<02:14,  1.83it/s]Loading train:   8%|▊         | 21/266 [00:12<02:13,  1.84it/s]Loading train:   8%|▊         | 22/266 [00:13<02:17,  1.78it/s]Loading train:   9%|▊         | 23/266 [00:13<02:16,  1.78it/s]Loading train:   9%|▉         | 24/266 [00:14<02:10,  1.86it/s]Loading train:   9%|▉         | 25/266 [00:14<02:05,  1.92it/s]Loading train:  10%|▉         | 26/266 [00:15<02:01,  1.97it/s]Loading train:  10%|█         | 27/266 [00:15<01:59,  2.00it/s]Loading train:  11%|█         | 28/266 [00:16<01:57,  2.02it/s]Loading train:  11%|█         | 29/266 [00:16<01:56,  2.04it/s]Loading train:  11%|█▏        | 30/266 [00:17<01:55,  2.05it/s]Loading train:  12%|█▏        | 31/266 [00:17<01:54,  2.06it/s]Loading train:  12%|█▏        | 32/266 [00:18<01:52,  2.08it/s]Loading train:  12%|█▏        | 33/266 [00:18<01:52,  2.07it/s]Loading train:  13%|█▎        | 34/266 [00:19<01:52,  2.05it/s]Loading train:  13%|█▎        | 35/266 [00:19<01:53,  2.04it/s]Loading train:  14%|█▎        | 36/266 [00:20<01:52,  2.04it/s]Loading train:  14%|█▍        | 37/266 [00:20<01:54,  1.99it/s]Loading train:  14%|█▍        | 38/266 [00:21<01:56,  1.96it/s]Loading train:  15%|█▍        | 39/266 [00:21<01:54,  1.97it/s]Loading train:  15%|█▌        | 40/266 [00:22<01:51,  2.02it/s]Loading train:  15%|█▌        | 41/266 [00:22<01:48,  2.08it/s]Loading train:  16%|█▌        | 42/266 [00:23<01:45,  2.12it/s]Loading train:  16%|█▌        | 43/266 [00:23<01:42,  2.17it/s]Loading train:  17%|█▋        | 44/266 [00:23<01:41,  2.18it/s]Loading train:  17%|█▋        | 45/266 [00:24<01:40,  2.19it/s]Loading train:  17%|█▋        | 46/266 [00:24<01:40,  2.18it/s]Loading train:  18%|█▊        | 47/266 [00:25<01:39,  2.19it/s]Loading train:  18%|█▊        | 48/266 [00:25<01:38,  2.22it/s]Loading train:  18%|█▊        | 49/266 [00:26<01:37,  2.22it/s]Loading train:  19%|█▉        | 50/266 [00:26<01:37,  2.22it/s]Loading train:  19%|█▉        | 51/266 [00:27<01:37,  2.21it/s]Loading train:  20%|█▉        | 52/266 [00:27<01:38,  2.17it/s]Loading train:  20%|█▉        | 53/266 [00:28<01:39,  2.14it/s]Loading train:  20%|██        | 54/266 [00:28<01:38,  2.15it/s]Loading train:  21%|██        | 55/266 [00:28<01:39,  2.13it/s]Loading train:  21%|██        | 56/266 [00:29<01:42,  2.04it/s]Loading train:  21%|██▏       | 57/266 [00:29<01:40,  2.08it/s]Loading train:  22%|██▏       | 58/266 [00:30<01:38,  2.10it/s]Loading train:  22%|██▏       | 59/266 [00:30<01:43,  2.00it/s]Loading train:  23%|██▎       | 60/266 [00:31<01:43,  1.98it/s]Loading train:  23%|██▎       | 61/266 [00:32<01:43,  1.99it/s]Loading train:  23%|██▎       | 62/266 [00:32<01:44,  1.95it/s]Loading train:  24%|██▎       | 63/266 [00:33<01:45,  1.93it/s]Loading train:  24%|██▍       | 64/266 [00:33<01:44,  1.93it/s]Loading train:  24%|██▍       | 65/266 [00:34<01:46,  1.90it/s]Loading train:  25%|██▍       | 66/266 [00:34<01:45,  1.90it/s]Loading train:  25%|██▌       | 67/266 [00:35<01:45,  1.89it/s]Loading train:  26%|██▌       | 68/266 [00:35<01:47,  1.84it/s]Loading train:  26%|██▌       | 69/266 [00:36<01:46,  1.85it/s]Loading train:  26%|██▋       | 70/266 [00:36<01:45,  1.85it/s]Loading train:  27%|██▋       | 71/266 [00:37<01:46,  1.84it/s]Loading train:  27%|██▋       | 72/266 [00:37<01:46,  1.82it/s]Loading train:  27%|██▋       | 73/266 [00:38<01:48,  1.77it/s]Loading train:  28%|██▊       | 74/266 [00:39<01:46,  1.80it/s]Loading train:  28%|██▊       | 75/266 [00:39<01:45,  1.81it/s]Loading train:  29%|██▊       | 76/266 [00:40<01:46,  1.78it/s]Loading train:  29%|██▉       | 77/266 [00:41<02:15,  1.40it/s]Loading train:  29%|██▉       | 78/266 [00:42<02:30,  1.25it/s]Loading train:  30%|██▉       | 79/266 [00:43<02:29,  1.25it/s]Loading train:  30%|███       | 80/266 [00:43<02:25,  1.28it/s]Loading train:  30%|███       | 81/266 [00:44<02:36,  1.18it/s]Loading train:  31%|███       | 82/266 [00:45<02:23,  1.28it/s]Loading train:  31%|███       | 83/266 [00:46<02:16,  1.34it/s]Loading train:  32%|███▏      | 84/266 [00:46<02:08,  1.42it/s]Loading train:  32%|███▏      | 85/266 [00:47<02:01,  1.48it/s]Loading train:  32%|███▏      | 86/266 [00:47<01:56,  1.54it/s]Loading train:  33%|███▎      | 87/266 [00:48<01:54,  1.56it/s]Loading train:  33%|███▎      | 88/266 [00:49<01:52,  1.58it/s]Loading train:  33%|███▎      | 89/266 [00:49<01:51,  1.59it/s]Loading train:  34%|███▍      | 90/266 [00:50<01:48,  1.61it/s]Loading train:  34%|███▍      | 91/266 [00:50<01:45,  1.65it/s]Loading train:  35%|███▍      | 92/266 [00:51<01:45,  1.65it/s]Loading train:  35%|███▍      | 93/266 [00:52<01:44,  1.66it/s]Loading train:  35%|███▌      | 94/266 [00:52<01:42,  1.68it/s]Loading train:  36%|███▌      | 95/266 [00:53<01:43,  1.65it/s]Loading train:  36%|███▌      | 96/266 [00:53<01:41,  1.67it/s]Loading train:  36%|███▋      | 97/266 [00:54<01:39,  1.69it/s]Loading train:  37%|███▋      | 98/266 [00:55<01:39,  1.69it/s]Loading train:  37%|███▋      | 99/266 [00:55<01:39,  1.68it/s]Loading train:  38%|███▊      | 100/266 [00:56<01:39,  1.67it/s]Loading train:  38%|███▊      | 101/266 [00:56<01:38,  1.68it/s]Loading train:  38%|███▊      | 102/266 [00:57<01:36,  1.69it/s]Loading train:  39%|███▊      | 103/266 [00:58<01:35,  1.71it/s]Loading train:  39%|███▉      | 104/266 [00:58<01:32,  1.74it/s]Loading train:  39%|███▉      | 105/266 [00:59<01:33,  1.73it/s]Loading train:  40%|███▉      | 106/266 [00:59<01:32,  1.73it/s]Loading train:  40%|████      | 107/266 [01:00<01:32,  1.72it/s]Loading train:  41%|████      | 108/266 [01:00<01:30,  1.74it/s]Loading train:  41%|████      | 109/266 [01:01<01:29,  1.75it/s]Loading train:  41%|████▏     | 110/266 [01:02<01:31,  1.71it/s]Loading train:  42%|████▏     | 111/266 [01:02<01:31,  1.70it/s]Loading train:  42%|████▏     | 112/266 [01:03<01:30,  1.70it/s]Loading train:  42%|████▏     | 113/266 [01:03<01:31,  1.68it/s]Loading train:  43%|████▎     | 114/266 [01:04<01:30,  1.68it/s]Loading train:  43%|████▎     | 115/266 [01:05<01:28,  1.70it/s]Loading train:  44%|████▎     | 116/266 [01:05<01:28,  1.69it/s]Loading train:  44%|████▍     | 117/266 [01:06<01:26,  1.72it/s]Loading train:  44%|████▍     | 118/266 [01:06<01:23,  1.77it/s]Loading train:  45%|████▍     | 119/266 [01:07<01:21,  1.81it/s]Loading train:  45%|████▌     | 120/266 [01:07<01:17,  1.88it/s]Loading train:  45%|████▌     | 121/266 [01:08<01:16,  1.89it/s]Loading train:  46%|████▌     | 122/266 [01:08<01:14,  1.93it/s]Loading train:  46%|████▌     | 123/266 [01:09<01:14,  1.92it/s]Loading train:  47%|████▋     | 124/266 [01:09<01:13,  1.94it/s]Loading train:  47%|████▋     | 125/266 [01:10<01:13,  1.92it/s]Loading train:  47%|████▋     | 126/266 [01:10<01:11,  1.95it/s]Loading train:  48%|████▊     | 127/266 [01:11<01:10,  1.97it/s]Loading train:  48%|████▊     | 128/266 [01:11<01:09,  1.98it/s]Loading train:  48%|████▊     | 129/266 [01:12<01:09,  1.98it/s]Loading train:  49%|████▉     | 130/266 [01:12<01:08,  1.97it/s]Loading train:  49%|████▉     | 131/266 [01:13<01:08,  1.98it/s]Loading train:  50%|████▉     | 132/266 [01:13<01:07,  1.99it/s]Loading train:  50%|█████     | 133/266 [01:14<01:06,  2.01it/s]Loading train:  50%|█████     | 134/266 [01:14<01:05,  2.01it/s]Loading train:  51%|█████     | 135/266 [01:15<01:05,  2.00it/s]Loading train:  51%|█████     | 136/266 [01:15<01:07,  1.92it/s]Loading train:  52%|█████▏    | 137/266 [01:16<01:04,  1.99it/s]Loading train:  52%|█████▏    | 138/266 [01:16<01:03,  2.02it/s]Loading train:  52%|█████▏    | 139/266 [01:17<01:03,  2.00it/s]Loading train:  53%|█████▎    | 140/266 [01:17<01:02,  2.03it/s]Loading train:  53%|█████▎    | 141/266 [01:18<01:01,  2.04it/s]Loading train:  53%|█████▎    | 142/266 [01:18<00:59,  2.08it/s]Loading train:  54%|█████▍    | 143/266 [01:19<00:58,  2.09it/s]Loading train:  54%|█████▍    | 144/266 [01:19<00:57,  2.12it/s]Loading train:  55%|█████▍    | 145/266 [01:20<00:58,  2.07it/s]Loading train:  55%|█████▍    | 146/266 [01:20<00:58,  2.07it/s]Loading train:  55%|█████▌    | 147/266 [01:21<00:56,  2.11it/s]Loading train:  56%|█████▌    | 148/266 [01:21<00:55,  2.12it/s]Loading train:  56%|█████▌    | 149/266 [01:22<00:54,  2.13it/s]Loading train:  56%|█████▋    | 150/266 [01:22<00:54,  2.13it/s]Loading train:  57%|█████▋    | 151/266 [01:23<00:54,  2.10it/s]Loading train:  57%|█████▋    | 152/266 [01:23<00:54,  2.11it/s]Loading train:  58%|█████▊    | 153/266 [01:23<00:54,  2.08it/s]Loading train:  58%|█████▊    | 154/266 [01:24<00:58,  1.92it/s]Loading train:  58%|█████▊    | 155/266 [01:25<00:59,  1.87it/s]Loading train:  59%|█████▊    | 156/266 [01:25<01:01,  1.78it/s]Loading train:  59%|█████▉    | 157/266 [01:26<01:01,  1.78it/s]Loading train:  59%|█████▉    | 158/266 [01:26<01:02,  1.73it/s]Loading train:  60%|█████▉    | 159/266 [01:27<01:01,  1.75it/s]Loading train:  60%|██████    | 160/266 [01:28<01:00,  1.76it/s]Loading train:  61%|██████    | 161/266 [01:28<01:00,  1.73it/s]Loading train:  61%|██████    | 162/266 [01:29<01:00,  1.73it/s]Loading train:  61%|██████▏   | 163/266 [01:29<00:58,  1.76it/s]Loading train:  62%|██████▏   | 164/266 [01:30<00:58,  1.75it/s]Loading train:  62%|██████▏   | 165/266 [01:30<00:57,  1.75it/s]Loading train:  62%|██████▏   | 166/266 [01:31<00:56,  1.76it/s]Loading train:  63%|██████▎   | 167/266 [01:32<00:56,  1.74it/s]Loading train:  63%|██████▎   | 168/266 [01:32<00:56,  1.73it/s]Loading train:  64%|██████▎   | 169/266 [01:33<00:56,  1.73it/s]Loading train:  64%|██████▍   | 170/266 [01:33<00:55,  1.72it/s]Loading train:  64%|██████▍   | 171/266 [01:34<00:55,  1.72it/s]Loading train:  65%|██████▍   | 172/266 [01:35<01:01,  1.53it/s]Loading train:  65%|██████▌   | 173/266 [01:36<01:07,  1.38it/s]Loading train:  65%|██████▌   | 174/266 [01:36<01:07,  1.35it/s]Loading train:  66%|██████▌   | 175/266 [01:37<01:04,  1.40it/s]Loading train:  66%|██████▌   | 176/266 [01:38<01:04,  1.39it/s]Loading train:  67%|██████▋   | 177/266 [01:38<00:59,  1.50it/s]Loading train:  67%|██████▋   | 178/266 [01:39<00:54,  1.60it/s]Loading train:  67%|██████▋   | 179/266 [01:39<00:51,  1.69it/s]Loading train:  68%|██████▊   | 180/266 [01:40<00:49,  1.75it/s]Loading train:  68%|██████▊   | 181/266 [01:40<00:47,  1.80it/s]Loading train:  68%|██████▊   | 182/266 [01:41<00:46,  1.82it/s]Loading train:  69%|██████▉   | 183/266 [01:42<00:45,  1.82it/s]Loading train:  69%|██████▉   | 184/266 [01:42<00:43,  1.87it/s]Loading train:  70%|██████▉   | 185/266 [01:43<00:42,  1.89it/s]Loading train:  70%|██████▉   | 186/266 [01:43<00:41,  1.92it/s]Loading train:  70%|███████   | 187/266 [01:44<00:41,  1.92it/s]Loading train:  71%|███████   | 188/266 [01:44<00:40,  1.94it/s]Loading train:  71%|███████   | 189/266 [01:45<00:39,  1.96it/s]Loading train:  71%|███████▏  | 190/266 [01:45<00:38,  1.97it/s]Loading train:  72%|███████▏  | 191/266 [01:46<00:38,  1.97it/s]Loading train:  72%|███████▏  | 192/266 [01:46<00:37,  1.98it/s]Loading train:  73%|███████▎  | 193/266 [01:47<00:36,  1.99it/s]Loading train:  73%|███████▎  | 194/266 [01:47<00:36,  1.98it/s]Loading train:  73%|███████▎  | 195/266 [01:48<00:37,  1.91it/s]Loading train:  74%|███████▎  | 196/266 [01:48<00:36,  1.90it/s]Loading train:  74%|███████▍  | 197/266 [01:49<00:37,  1.86it/s]Loading train:  74%|███████▍  | 198/266 [01:49<00:37,  1.84it/s]Loading train:  75%|███████▍  | 199/266 [01:50<00:36,  1.82it/s]Loading train:  75%|███████▌  | 200/266 [01:50<00:36,  1.78it/s]Loading train:  76%|███████▌  | 201/266 [01:51<00:37,  1.74it/s]Loading train:  76%|███████▌  | 202/266 [01:52<00:36,  1.74it/s]Loading train:  76%|███████▋  | 203/266 [01:52<00:36,  1.73it/s]Loading train:  77%|███████▋  | 204/266 [01:53<00:35,  1.73it/s]Loading train:  77%|███████▋  | 205/266 [01:53<00:35,  1.72it/s]Loading train:  77%|███████▋  | 206/266 [01:54<00:35,  1.68it/s]Loading train:  78%|███████▊  | 207/266 [01:55<00:35,  1.68it/s]Loading train:  78%|███████▊  | 208/266 [01:55<00:34,  1.67it/s]Loading train:  79%|███████▊  | 209/266 [01:56<00:34,  1.66it/s]Loading train:  79%|███████▉  | 210/266 [01:56<00:33,  1.69it/s]Loading train:  79%|███████▉  | 211/266 [01:57<00:32,  1.67it/s]Loading train:  80%|███████▉  | 212/266 [01:58<00:31,  1.69it/s]Loading train:  80%|████████  | 213/266 [01:58<00:34,  1.53it/s]Loading train:  80%|████████  | 214/266 [01:59<00:38,  1.35it/s]Loading train:  81%|████████  | 215/266 [02:00<00:41,  1.23it/s]Loading train:  81%|████████  | 216/266 [02:02<00:54,  1.08s/it]Loading train:  82%|████████▏ | 217/266 [02:05<01:17,  1.57s/it]Loading train:  82%|████████▏ | 218/266 [02:08<01:35,  2.00s/it]Loading train:  82%|████████▏ | 219/266 [02:10<01:41,  2.16s/it]Loading train:  83%|████████▎ | 220/266 [02:13<01:46,  2.31s/it]Loading train:  83%|████████▎ | 221/266 [02:16<01:50,  2.46s/it]Loading train:  83%|████████▎ | 222/266 [02:19<01:53,  2.57s/it]Loading train:  84%|████████▍ | 223/266 [02:21<01:54,  2.67s/it]Loading train:  84%|████████▍ | 224/266 [02:24<01:52,  2.68s/it]Loading train:  85%|████████▍ | 225/266 [02:27<01:48,  2.65s/it]Loading train:  85%|████████▍ | 226/266 [02:30<01:51,  2.79s/it]Loading train:  85%|████████▌ | 227/266 [02:33<01:49,  2.82s/it]Loading train:  86%|████████▌ | 228/266 [02:35<01:45,  2.79s/it]Loading train:  86%|████████▌ | 229/266 [02:38<01:43,  2.78s/it]Loading train:  86%|████████▋ | 230/266 [02:41<01:38,  2.72s/it]Loading train:  87%|████████▋ | 231/266 [02:41<01:12,  2.08s/it]Loading train:  87%|████████▋ | 232/266 [02:42<00:54,  1.61s/it]Loading train:  88%|████████▊ | 233/266 [02:42<00:41,  1.27s/it]Loading train:  88%|████████▊ | 234/266 [02:43<00:32,  1.03s/it]Loading train:  88%|████████▊ | 235/266 [02:43<00:26,  1.16it/s]Loading train:  89%|████████▊ | 236/266 [02:44<00:25,  1.19it/s]Loading train:  89%|████████▉ | 237/266 [02:45<00:24,  1.20it/s]Loading train:  89%|████████▉ | 238/266 [02:46<00:23,  1.21it/s]Loading train:  90%|████████▉ | 239/266 [02:47<00:22,  1.22it/s]Loading train:  90%|█████████ | 240/266 [02:47<00:21,  1.23it/s]Loading train:  91%|█████████ | 241/266 [02:48<00:20,  1.23it/s]Loading train:  91%|█████████ | 242/266 [02:49<00:20,  1.18it/s]Loading train:  91%|█████████▏| 243/266 [02:50<00:19,  1.20it/s]Loading train:  92%|█████████▏| 244/266 [02:51<00:17,  1.24it/s]Loading train:  92%|█████████▏| 245/266 [02:51<00:16,  1.25it/s]Loading train:  92%|█████████▏| 246/266 [02:52<00:15,  1.26it/s]Loading train:  93%|█████████▎| 247/266 [02:53<00:15,  1.25it/s]Loading train:  93%|█████████▎| 248/266 [02:54<00:14,  1.27it/s]Loading train:  94%|█████████▎| 249/266 [02:56<00:19,  1.16s/it]Loading train:  94%|█████████▍| 250/266 [02:58<00:24,  1.53s/it]Loading train:  94%|█████████▍| 251/266 [03:01<00:26,  1.77s/it]Loading train:  95%|█████████▍| 252/266 [03:03<00:28,  2.05s/it]Loading train:  95%|█████████▌| 253/266 [03:06<00:28,  2.20s/it]Loading train:  95%|█████████▌| 254/266 [03:08<00:27,  2.25s/it]Loading train:  96%|█████████▌| 255/266 [03:11<00:25,  2.31s/it]Loading train:  96%|█████████▌| 256/266 [03:13<00:22,  2.27s/it]Loading train:  97%|█████████▋| 257/266 [03:15<00:20,  2.27s/it]Loading train:  97%|█████████▋| 258/266 [03:19<00:22,  2.83s/it]Loading train:  97%|█████████▋| 259/266 [03:23<00:22,  3.21s/it]Loading train:  98%|█████████▊| 260/266 [03:27<00:20,  3.43s/it]Loading train:  98%|█████████▊| 261/266 [03:32<00:18,  3.71s/it]Loading train:  98%|█████████▊| 262/266 [03:36<00:15,  3.84s/it]Loading train:  99%|█████████▉| 263/266 [03:40<00:12,  4.08s/it]Loading train:  99%|█████████▉| 264/266 [03:45<00:08,  4.19s/it]Loading train: 100%|█████████▉| 265/266 [03:49<00:04,  4.17s/it]Loading train: 100%|██████████| 266/266 [03:54<00:00,  4.30s/it]Loading train: 100%|██████████| 266/266 [03:54<00:00,  1.14it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 48.54it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 47.43it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:04, 51.01it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:04, 54.51it/s]concatenating: train:  12%|█▏        | 31/266 [00:00<00:04, 56.36it/s]concatenating: train:  14%|█▍        | 37/266 [00:00<00:04, 56.05it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:03, 57.13it/s]concatenating: train:  19%|█▉        | 50/266 [00:00<00:03, 59.61it/s]concatenating: train:  21%|██▏       | 57/266 [00:00<00:03, 62.26it/s]concatenating: train:  24%|██▍       | 64/266 [00:01<00:03, 63.22it/s]concatenating: train:  27%|██▋       | 71/266 [00:01<00:03, 61.96it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:03, 60.30it/s]concatenating: train:  32%|███▏      | 85/266 [00:01<00:03, 60.26it/s]concatenating: train:  35%|███▍      | 92/266 [00:01<00:02, 60.27it/s]concatenating: train:  37%|███▋      | 99/266 [00:01<00:02, 59.49it/s]concatenating: train:  40%|███▉      | 106/266 [00:01<00:02, 60.21it/s]concatenating: train:  42%|████▏     | 113/266 [00:01<00:02, 58.42it/s]concatenating: train:  45%|████▍     | 119/266 [00:02<00:02, 56.15it/s]concatenating: train:  47%|████▋     | 125/266 [00:02<00:02, 55.24it/s]concatenating: train:  49%|████▉     | 131/266 [00:02<00:02, 54.81it/s]concatenating: train:  52%|█████▏    | 138/266 [00:02<00:02, 57.25it/s]concatenating: train:  54%|█████▍    | 144/266 [00:02<00:02, 57.25it/s]concatenating: train:  57%|█████▋    | 151/266 [00:02<00:01, 59.39it/s]concatenating: train:  59%|█████▉    | 157/266 [00:02<00:01, 58.16it/s]concatenating: train:  62%|██████▏   | 164/266 [00:02<00:01, 59.06it/s]concatenating: train:  64%|██████▍   | 170/266 [00:02<00:01, 57.21it/s]concatenating: train:  66%|██████▌   | 176/266 [00:03<00:01, 55.69it/s]concatenating: train:  68%|██████▊   | 182/266 [00:03<00:01, 52.15it/s]concatenating: train:  71%|███████   | 188/266 [00:03<00:01, 51.72it/s]concatenating: train:  73%|███████▎  | 195/266 [00:03<00:01, 54.18it/s]concatenating: train:  76%|███████▌  | 201/266 [00:03<00:01, 55.66it/s]concatenating: train:  78%|███████▊  | 208/266 [00:03<00:01, 57.26it/s]concatenating: train:  80%|████████  | 214/266 [00:03<00:00, 57.11it/s]concatenating: train:  83%|████████▎ | 221/266 [00:03<00:00, 58.46it/s]concatenating: train:  85%|████████▌ | 227/266 [00:03<00:00, 56.34it/s]concatenating: train:  88%|████████▊ | 234/266 [00:04<00:00, 57.19it/s]concatenating: train:  90%|█████████ | 240/266 [00:04<00:00, 57.67it/s]concatenating: train:  92%|█████████▏| 246/266 [00:04<00:00, 56.94it/s]concatenating: train:  95%|█████████▌| 253/266 [00:04<00:00, 58.18it/s]concatenating: train:  97%|█████████▋| 259/266 [00:04<00:00, 57.38it/s]concatenating: train: 100%|█████████▉| 265/266 [00:04<00:00, 57.45it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 57.71it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:11<00:33, 11.13s/it]Loading test:  50%|█████     | 2/4 [00:18<00:19,  9.89s/it]Loading test:  75%|███████▌  | 3/4 [00:25<00:09,  9.24s/it]Loading test: 100%|██████████| 4/4 [00:38<00:00, 10.12s/it]Loading test: 100%|██████████| 4/4 [00:38<00:00,  9.50s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 63.30it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-22 09:42:59.905286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 09:42:59.905390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 09:42:59.905405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 09:42:59.905413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 09:42:59.905719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2
------------------------------------------------------------------
class_weights [6.83776381e-02 3.27967705e-02 8.45303943e-02 1.02660223e-02
 2.87964771e-02 7.66822624e-03 8.69461378e-02 1.12935766e-01
 9.17000917e-02 1.37607197e-02 2.76977471e-01 1.84992530e-01
 2.51755238e-04]
Train on 9904 samples, validate on 144 samples
Epoch 1/300
 - 27s - loss: 0.6100 - acc: 0.9097 - mDice: 0.3428 - val_loss: 0.2715 - val_acc: 0.9330 - val_mDice: 0.2943

Epoch 00001: val_mDice improved from -inf to 0.29428, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.4912 - acc: 0.9267 - mDice: 0.4709 - val_loss: 0.1707 - val_acc: 0.9413 - val_mDice: 0.3082

Epoch 00002: val_mDice improved from 0.29428 to 0.30823, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 0.4620 - acc: 0.9312 - mDice: 0.5024 - val_loss: 0.1392 - val_acc: 0.9441 - val_mDice: 0.3192

Epoch 00003: val_mDice improved from 0.30823 to 0.31918, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.4415 - acc: 0.9343 - mDice: 0.5244 - val_loss: 0.0847 - val_acc: 0.9425 - val_mDice: 0.3181

Epoch 00004: val_mDice did not improve from 0.31918
Epoch 5/300
 - 20s - loss: 0.4303 - acc: 0.9360 - mDice: 0.5365 - val_loss: 0.1329 - val_acc: 0.9441 - val_mDice: 0.3192

Epoch 00005: val_mDice improved from 0.31918 to 0.31923, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 21s - loss: 0.4240 - acc: 0.9375 - mDice: 0.5430 - val_loss: 0.0941 - val_acc: 0.9422 - val_mDice: 0.2986

Epoch 00006: val_mDice did not improve from 0.31923
Epoch 7/300
 - 20s - loss: 0.4319 - acc: 0.9358 - mDice: 0.5340 - val_loss: 0.0949 - val_acc: 0.9405 - val_mDice: 0.3325

Epoch 00007: val_mDice improved from 0.31923 to 0.33253, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 21s - loss: 0.4271 - acc: 0.9360 - mDice: 0.5378 - val_loss: 0.1200 - val_acc: 0.9453 - val_mDice: 0.3259

Epoch 00008: val_mDice did not improve from 0.33253
Epoch 9/300
 - 21s - loss: 0.4262 - acc: 0.9360 - mDice: 0.5350 - val_loss: 0.0836 - val_acc: 0.9449 - val_mDice: 0.3214

Epoch 00009: val_mDice did not improve from 0.33253
Epoch 10/300
 - 20s - loss: 0.4060 - acc: 0.9386 - mDice: 0.5559 - val_loss: 0.0740 - val_acc: 0.9468 - val_mDice: 0.3082

Epoch 00010: val_mDice did not improve from 0.33253
Epoch 11/300
 - 20s - loss: 0.4179 - acc: 0.9371 - mDice: 0.5405 - val_loss: 0.1322 - val_acc: 0.9478 - val_mDice: 0.3244

Epoch 00011: val_mDice did not improve from 0.33253
Epoch 12/300
 - 21s - loss: 0.4069 - acc: 0.9389 - mDice: 0.5532 - val_loss: 0.1249 - val_acc: 0.9449 - val_mDice: 0.3315

Epoch 00012: val_mDice did not improve from 0.33253
Epoch 13/300
 - 20s - loss: 0.4032 - acc: 0.9393 - mDice: 0.5551 - val_loss: 0.0529 - val_acc: 0.9468 - val_mDice: 0.3314

Epoch 00013: val_mDice did not improve from 0.33253
Epoch 14/300
 - 20s - loss: 0.4241 - acc: 0.9383 - mDice: 0.5331 - val_loss: 0.0693 - val_acc: 0.9463 - val_mDice: 0.3189

Epoch 00014: val_mDice did not improve from 0.33253
Epoch 15/300
 - 20s - loss: 0.3962 - acc: 0.9408 - mDice: 0.5629 - val_loss: 0.1973 - val_acc: 0.9442 - val_mDice: 0.3232

Epoch 00015: val_mDice did not improve from 0.33253
Epoch 16/300
 - 22s - loss: 0.3955 - acc: 0.9403 - mDice: 0.5637 - val_loss: 0.1422 - val_acc: 0.9462 - val_mDice: 0.3273

Epoch 00016: val_mDice did not improve from 0.33253
Epoch 17/300
 - 21s - loss: 0.4157 - acc: 0.9389 - mDice: 0.5393 - val_loss: 0.0394 - val_acc: 0.9494 - val_mDice: 0.3278

Epoch 00017: val_mDice did not improve from 0.33253
Epoch 18/300
 - 21s - loss: 0.3835 - acc: 0.9424 - mDice: 0.5740 - val_loss: 0.0422 - val_acc: 0.9477 - val_mDice: 0.3356

Epoch 00018: val_mDice improved from 0.33253 to 0.33562, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 19/300
 - 21s - loss: 0.3795 - acc: 0.9428 - mDice: 0.5788 - val_loss: 0.0754 - val_acc: 0.9471 - val_mDice: 0.3302

Epoch 00019: val_mDice did not improve from 0.33562
Epoch 20/300
 - 21s - loss: 0.3899 - acc: 0.9410 - mDice: 0.5661 - val_loss: 0.0390 - val_acc: 0.9492 - val_mDice: 0.3279

Epoch 00020: val_mDice did not improve from 0.33562
Epoch 21/300
 - 20s - loss: 0.3837 - acc: 0.9422 - mDice: 0.5746 - val_loss: 0.0121 - val_acc: 0.9488 - val_mDice: 0.3176

Epoch 00021: val_mDice did not improve from 0.33562
Epoch 22/300
 - 21s - loss: 0.3916 - acc: 0.9411 - mDice: 0.5659 - val_loss: 0.2629 - val_acc: 0.9232 - val_mDice: 0.2024

Epoch 00022: val_mDice did not improve from 0.33562
Epoch 23/300
 - 20s - loss: 0.3879 - acc: 0.9415 - mDice: 0.5706 - val_loss: 0.0512 - val_acc: 0.9479 - val_mDice: 0.3216

Epoch 00023: val_mDice did not improve from 0.33562
Epoch 24/300
 - 20s - loss: 0.3790 - acc: 0.9431 - mDice: 0.5777 - val_loss: 0.0296 - val_acc: 0.9495 - val_mDice: 0.3335

Epoch 00024: val_mDice did not improve from 0.33562
Epoch 25/300
 - 20s - loss: 0.3716 - acc: 0.9437 - mDice: 0.5846 - val_loss: 0.0374 - val_acc: 0.9489 - val_mDice: 0.3079

Epoch 00025: val_mDice did not improve from 0.33562
Epoch 26/300
 - 21s - loss: 0.3696 - acc: 0.9439 - mDice: 0.5891 - val_loss: 0.0264 - val_acc: 0.9489 - val_mDice: 0.3137

Epoch 00026: val_mDice did not improve from 0.33562
Epoch 27/300
 - 21s - loss: 0.3802 - acc: 0.9427 - mDice: 0.5767 - val_loss: 0.1762 - val_acc: 0.9445 - val_mDice: 0.3215

Epoch 00027: val_mDice did not improve from 0.33562
Epoch 28/300
 - 21s - loss: 0.3669 - acc: 0.9445 - mDice: 0.5932 - val_loss: 0.0388 - val_acc: 0.9491 - val_mDice: 0.3281

Epoch 00028: val_mDice did not improve from 0.33562
Epoch 29/300
 - 21s - loss: 0.3632 - acc: 0.9452 - mDice: 0.5967 - val_loss: 0.0714 - val_acc: 0.9493 - val_mDice: 0.3227

Epoch 00029: val_mDice did not improve from 0.33562
Epoch 30/300
 - 21s - loss: 0.3671 - acc: 0.9448 - mDice: 0.5896 - val_loss: 0.2460 - val_acc: 0.9181 - val_mDice: 0.2298

Epoch 00030: val_mDice did not improve from 0.33562
Epoch 31/300
 - 21s - loss: 0.3683 - acc: 0.9446 - mDice: 0.5896 - val_loss: 0.0794 - val_acc: 0.9478 - val_mDice: 0.3374

Epoch 00031: val_mDice improved from 0.33562 to 0.33738, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 32/300
 - 20s - loss: 0.3589 - acc: 0.9459 - mDice: 0.5984 - val_loss: 0.0469 - val_acc: 0.9494 - val_mDice: 0.3124

Epoch 00032: val_mDice did not improve from 0.33738
Epoch 33/300
 - 20s - loss: 0.3579 - acc: 0.9464 - mDice: 0.6023 - val_loss: 0.0496 - val_acc: 0.9495 - val_mDice: 0.3233

Epoch 00033: val_mDice did not improve from 0.33738
Epoch 34/300
 - 20s - loss: 0.3516 - acc: 0.9462 - mDice: 0.6046 - val_loss: 0.0271 - val_acc: 0.9475 - val_mDice: 0.3233

Epoch 00034: val_mDice did not improve from 0.33738
Epoch 35/300
 - 20s - loss: 0.3554 - acc: 0.9462 - mDice: 0.6044 - val_loss: 0.1690 - val_acc: 0.9453 - val_mDice: 0.3331

Epoch 00035: val_mDice did not improve from 0.33738
Epoch 36/300
 - 21s - loss: 0.3542 - acc: 0.9466 - mDice: 0.6067 - val_loss: 0.0177 - val_acc: 0.9488 - val_mDice: 0.3346

Epoch 00036: val_mDice did not improve from 0.33738
Epoch 37/300
 - 20s - loss: 0.3501 - acc: 0.9470 - mDice: 0.6074 - val_loss: 0.0164 - val_acc: 0.9503 - val_mDice: 0.3246

Epoch 00037: val_mDice did not improve from 0.33738
Epoch 38/300
 - 21s - loss: 0.3588 - acc: 0.9450 - mDice: 0.5990 - val_loss: 0.1680 - val_acc: 0.9444 - val_mDice: 0.3276

Epoch 00038: val_mDice did not improve from 0.33738
Epoch 39/300
 - 21s - loss: 0.3553 - acc: 0.9464 - mDice: 0.6055 - val_loss: 0.0749 - val_acc: 0.9480 - val_mDice: 0.3354

Epoch 00039: val_mDice did not improve from 0.33738
Epoch 40/300
 - 21s - loss: 0.3630 - acc: 0.9443 - mDice: 0.5933 - val_loss: 0.0437 - val_acc: 0.9457 - val_mDice: 0.2954

Epoch 00040: val_mDice did not improve from 0.33738
Epoch 41/300
 - 21s - loss: 0.3631 - acc: 0.9433 - mDice: 0.5945 - val_loss: 0.0184 - val_acc: 0.9483 - val_mDice: 0.3341

Epoch 00041: val_mDice did not improve from 0.33738
Epoch 42/300
 - 21s - loss: 0.3517 - acc: 0.9467 - mDice: 0.6081 - val_loss: 0.0392 - val_acc: 0.9482 - val_mDice: 0.3314

Epoch 00042: val_mDice did not improve from 0.33738
Epoch 43/300
 - 20s - loss: 0.3500 - acc: 0.9476 - mDice: 0.6121 - val_loss: 0.2178 - val_acc: 0.9349 - val_mDice: 0.3197

Epoch 00043: val_mDice did not improve from 0.33738
Epoch 44/300
 - 21s - loss: 0.3466 - acc: 0.9477 - mDice: 0.6141 - val_loss: 0.0655 - val_acc: 0.9478 - val_mDice: 0.3265

Epoch 00044: val_mDice did not improve from 0.33738
Epoch 45/300
 - 20s - loss: 0.3437 - acc: 0.9479 - mDice: 0.6167 - val_loss: 0.1534 - val_acc: 0.9384 - val_mDice: 0.3015

Epoch 00045: val_mDice did not improve from 0.33738
Epoch 46/300
 - 21s - loss: 0.3524 - acc: 0.9468 - mDice: 0.6061 - val_loss: 0.0381 - val_acc: 0.9482 - val_mDice: 0.3242

Epoch 00046: val_mDice did not improve from 0.33738

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 47/300
 - 21s - loss: 0.3402 - acc: 0.9483 - mDice: 0.6165 - val_loss: 0.0310 - val_acc: 0.9495 - val_mDice: 0.3318

Epoch 00047: val_mDice did not improve from 0.33738
Epoch 48/300
 - 21s - loss: 0.3365 - acc: 0.9490 - mDice: 0.6236 - val_loss: 0.0554 - val_acc: 0.9479 - val_mDice: 0.3287

Epoch 00048: val_mDice did not improve from 0.33738
Epoch 49/300
 - 21s - loss: 0.3346 - acc: 0.9491 - mDice: 0.6268 - val_loss: 0.0540 - val_acc: 0.9487 - val_mDice: 0.3348

Epoch 00049: val_mDice did not improve from 0.33738
Epoch 50/300
 - 21s - loss: 0.3342 - acc: 0.9493 - mDice: 0.6261 - val_loss: 0.0580 - val_acc: 0.9498 - val_mDice: 0.3258

Epoch 00050: val_mDice did not improve from 0.33738
Epoch 51/300
 - 20s - loss: 0.3299 - acc: 0.9493 - mDice: 0.6294 - val_loss: 0.0613 - val_acc: 0.9482 - val_mDice: 0.3283

Epoch 00051: val_mDice did not improve from 0.33738
Epoch 52/300
 - 21s - loss: 0.3297 - acc: 0.9497 - mDice: 0.6310 - val_loss: 0.0671 - val_acc: 0.9489 - val_mDice: 0.3309

Epoch 00052: val_mDice did not improve from 0.33738
Epoch 53/300
 - 21s - loss: 0.3306 - acc: 0.9496 - mDice: 0.6307 - val_loss: 0.0510 - val_acc: 0.9500 - val_mDice: 0.3218

Epoch 00053: val_mDice did not improve from 0.33738
Epoch 54/300
 - 20s - loss: 0.3315 - acc: 0.9493 - mDice: 0.6283 - val_loss: 0.0545 - val_acc: 0.9489 - val_mDice: 0.3298

Epoch 00054: val_mDice did not improve from 0.33738
Epoch 55/300
 - 21s - loss: 0.3261 - acc: 0.9498 - mDice: 0.6351 - val_loss: 0.0240 - val_acc: 0.9505 - val_mDice: 0.3278

Epoch 00055: val_mDice did not improve from 0.33738
Epoch 56/300
 - 20s - loss: 0.3264 - acc: 0.9495 - mDice: 0.6327 - val_loss: 0.0542 - val_acc: 0.9500 - val_mDice: 0.3352

Epoch 00056: val_mDice did not improve from 0.33738
Epoch 57/300
 - 21s - loss: 0.3272 - acc: 0.9498 - mDice: 0.6332 - val_loss: 0.0568 - val_acc: 0.9489 - val_mDice: 0.3272

Epoch 00057: val_mDice did not improve from 0.33738
Epoch 58/300
 - 21s - loss: 0.3264 - acc: 0.9499 - mDice: 0.6353 - val_loss: 0.0413 - val_acc: 0.9492 - val_mDice: 0.3325

Epoch 00058: val_mDice did not improve from 0.33738
Epoch 59/300
 - 21s - loss: 0.3281 - acc: 0.9498 - mDice: 0.6316 - val_loss: 0.0374 - val_acc: 0.9484 - val_mDice: 0.3250

Epoch 00059: val_mDice did not improve from 0.33738
Epoch 60/300
 - 20s - loss: 0.3320 - acc: 0.9495 - mDice: 0.6307 - val_loss: 0.0305 - val_acc: 0.9493 - val_mDice: 0.3321

Epoch 00060: val_mDice did not improve from 0.33738
Epoch 61/300
 - 21s - loss: 0.3224 - acc: 0.9504 - mDice: 0.6397 - val_loss: 0.0690 - val_acc: 0.9473 - val_mDice: 0.3302

Epoch 00061: val_mDice did not improve from 0.33738

Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 62/300
 - 21s - loss: 0.3256 - acc: 0.9501 - mDice: 0.6377 - val_loss: 0.0673 - val_acc: 0.9486 - val_mDice: 0.3320

Epoch 00062: val_mDice did not improve from 0.33738
Epoch 63/300
 - 21s - loss: 0.3187 - acc: 0.9505 - mDice: 0.6432 - val_loss: 0.0574 - val_acc: 0.9492 - val_mDice: 0.3299

Epoch 00063: val_mDice did not improve from 0.33738
Epoch 64/300
 - 20s - loss: 0.3202 - acc: 0.9507 - mDice: 0.6417 - val_loss: 0.0615 - val_acc: 0.9490 - val_mDice: 0.3315

Epoch 00064: val_mDice did not improve from 0.33738
Epoch 65/300
 - 21s - loss: 0.3209 - acc: 0.9504 - mDice: 0.6380 - val_loss: 0.0401 - val_acc: 0.9480 - val_mDice: 0.3249

Epoch 00065: val_mDice did not improve from 0.33738
Epoch 66/300
 - 20s - loss: 0.3217 - acc: 0.9503 - mDice: 0.6381 - val_loss: 0.0492 - val_acc: 0.9490 - val_mDice: 0.3304

Epoch 00066: val_mDice did not improve from 0.33738
Epoch 67/300
 - 20s - loss: 0.3186 - acc: 0.9510 - mDice: 0.6436 - val_loss: 0.0251 - val_acc: 0.9495 - val_mDice: 0.3320

Epoch 00067: val_mDice did not improve from 0.33738
Epoch 68/300
 - 21s - loss: 0.3183 - acc: 0.9509 - mDice: 0.6420 - val_loss: 0.0304 - val_acc: 0.9500 - val_mDice: 0.3325

Epoch 00068: val_mDice did not improve from 0.33738
Epoch 69/300
 - 21s - loss: 0.3190 - acc: 0.9510 - mDice: 0.6438 - val_loss: 0.0300 - val_acc: 0.9500 - val_mDice: 0.3330

Epoch 00069: val_mDice did not improve from 0.33738
Epoch 70/300
 - 20s - loss: 0.3177 - acc: 0.9509 - mDice: 0.6430 - val_loss: 0.0371 - val_acc: 0.9498 - val_mDice: 0.3300

Epoch 00070: val_mDice did not improve from 0.33738
Epoch 71/300
 - 20s - loss: 0.3165 - acc: 0.9510 - mDice: 0.6455 - val_loss: 0.0211 - val_acc: 0.9499 - val_mDice: 0.3306

Epoch 00071: val_mDice did not improve from 0.33738
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
{'val_loss': [0.2714655385611372, 0.17070411776108407, 0.1391947076246854, 0.08473745005257013, 0.132894060412784, 0.09408785585158815, 0.09489598902614994, 0.11999660355245902, 0.08362885611131787, 0.07395721454587248, 0.13222439065834302, 0.12485739865547253, 0.05290058812695659, 0.0693009422134815, 0.19728095907097062, 0.14219158290264508, 0.0393533949714361, 0.0421809460191677, 0.07535270282015619, 0.039000839790484555, 0.012097939499653876, 0.2629407012136653, 0.05121949172785713, 0.02958865018768443, 0.03735743067227304, 0.026426038496235076, 0.1761755828039087, 0.038835005603484914, 0.07138963987947339, 0.24604727338171667, 0.0794036688360696, 0.04685625653817422, 0.04960311104595247, 0.027133393424770072, 0.16898778634559777, 0.017706447242138285, 0.016369425562313862, 0.16795408538180506, 0.07488463037750787, 0.043690275400877, 0.018373819255632244, 0.03915508081101709, 0.21784953866153955, 0.06548780134309912, 0.153445719068663, 0.038082163884407945, 0.03104830312076956, 0.05538715868412206, 0.054001214545375355, 0.058003188136758074, 0.06130981406507393, 0.06706243944871756, 0.050993800641865365, 0.05450061243997576, 0.023960632996426687, 0.05423794914450911, 0.05676206013756908, 0.04132228951332056, 0.03742622312468787, 0.030533207101850875, 0.06898981335365938, 0.06729302076726323, 0.05743732404274245, 0.061458423791918904, 0.04008138611809247, 0.04915539106069547, 0.0250964644494363, 0.030417746320987742, 0.03004697579631789, 0.03707612450751993, 0.021055239925367966], 'val_acc': [0.9330261664258109, 0.9412933753596412, 0.9440501605470976, 0.9424921116895146, 0.9441073934237162, 0.94217732300361, 0.9404730084869597, 0.9453458935022354, 0.9448514415158166, 0.9467560831043456, 0.947765637603071, 0.9449070990085602, 0.9468260324663587, 0.9462711802787251, 0.9441741738054488, 0.9462457390295135, 0.9494222501913706, 0.9476845504509078, 0.9471122059557173, 0.9491662813557519, 0.9487926670246654, 0.9232216055194536, 0.9478673777646489, 0.9494874336653285, 0.9488960065775447, 0.9488546699285507, 0.9445000936587652, 0.9490995084246, 0.9493475216958258, 0.9181499928236008, 0.9477958306670189, 0.9493554714653227, 0.9495430754290687, 0.94748741057184, 0.9453363468249639, 0.9488467284374766, 0.950272824201319, 0.944433308309979, 0.948000930249691, 0.9457417635454072, 0.9482727828953001, 0.9482203324635824, 0.9348608545131154, 0.9478355786866612, 0.9383601049582163, 0.9481710468729337, 0.949539900653892, 0.9478832690252198, 0.9486591236458884, 0.9498006304105123, 0.9481774047017097, 0.9488626238372591, 0.9499802879161305, 0.9488594399558173, 0.9504556556542715, 0.9499723356631067, 0.9489373539884886, 0.9491503917508655, 0.9484301871723599, 0.9493284498651823, 0.9473474986023374, 0.9485589688022932, 0.9491519770688481, 0.9490295565790601, 0.9479961569110552, 0.9489596080448892, 0.9495240011148982, 0.9499627989199426, 0.9500407055020332, 0.949819717142317, 0.949919865363174], 'val_mDice': [0.2942763747026523, 0.3082311201012797, 0.3191757067624066, 0.31810463240577114, 0.31922998941606945, 0.2986409014297856, 0.3325308933854103, 0.32589189739276964, 0.3213535562778513, 0.30820813681930304, 0.3243592075175709, 0.3315459458778302, 0.33140667900443077, 0.31888130617638427, 0.3232389622264438, 0.3273017199503051, 0.32775677740573883, 0.33562482955555123, 0.33023567363205886, 0.3278673058375716, 0.31762215546849704, 0.202350165332771, 0.3216116404574778, 0.33346224431362415, 0.30790930800139904, 0.31372831016778946, 0.3214737703609798, 0.32805408413211506, 0.3227263680762715, 0.22981904747171533, 0.3373823660529322, 0.31239291715125245, 0.3233179949844877, 0.3233375417896443, 0.3331301748338673, 0.33464549978574115, 0.32458211864448255, 0.3275521451400386, 0.33541184901777243, 0.29541621677991414, 0.3341424000552959, 0.33143235536085236, 0.31968206343137556, 0.3264593258500099, 0.3015188837630881, 0.32422623835090136, 0.331817255458898, 0.32867469514409703, 0.3348272902270158, 0.32578211526076, 0.3282703904228078, 0.3309425753023889, 0.32176370204736787, 0.3298089323151443, 0.32784462151014143, 0.33523438146544826, 0.32721012830734253, 0.3325205936820971, 0.3249804154038429, 0.3321416638791561, 0.3302070415682263, 0.33197272568941116, 0.3299216532872783, 0.3315492203045223, 0.32494145683530307, 0.33041467765967053, 0.3319509108033445, 0.3324940481947528, 0.3329502296530538, 0.3299577257906397, 0.33062320119804806], 'loss': [0.6099907378568307, 0.49120977898888135, 0.4619512232697549, 0.4415347802968807, 0.43031586151756646, 0.4240147887107725, 0.431904328400224, 0.42709665384402373, 0.42619829340830373, 0.4059636953267267, 0.4179325624939313, 0.40687346964268095, 0.40318110253005884, 0.4240804622687026, 0.39624334711984693, 0.39551363502943554, 0.41574255206738037, 0.38352974547563734, 0.37951359583398925, 0.3898826104638457, 0.3837126751847096, 0.3916321221185376, 0.38792488356278865, 0.37899575381267436, 0.3716091133190713, 0.3695622451049735, 0.3802073103870733, 0.3668768438051706, 0.3631550335356896, 0.3671158569081053, 0.3682858036930322, 0.35890157183147786, 0.35789993610864984, 0.3516004332228412, 0.35537781646724953, 0.35421591007447106, 0.35013803762349155, 0.3588254928426375, 0.3552852028466292, 0.36297877079029367, 0.363052593908229, 0.3516826991124232, 0.35003741079210177, 0.34656233169583783, 0.34371985811649886, 0.352427000083595, 0.34019377111172927, 0.3364724458130573, 0.33458355497057296, 0.334157669841521, 0.32988815981539654, 0.3297110420918041, 0.3306195861065643, 0.3315406992688462, 0.32605960116885685, 0.3264278992032557, 0.32720186273975116, 0.32636913888589725, 0.3280993167623902, 0.33197759208006117, 0.3223624968982523, 0.32556514152188776, 0.31870752749347725, 0.3202262729111463, 0.320867925668692, 0.3217394198042751, 0.3186093141311277, 0.3182570291352075, 0.31896594724947397, 0.31771333151390124, 0.31645927735888707], 'acc': [0.9097352898250874, 0.9267232140980552, 0.9311633208625151, 0.9342817650545202, 0.9359828944232237, 0.9374702494465091, 0.9358465579821336, 0.9360142634017017, 0.9360275770957327, 0.9385676672968033, 0.9371015555879796, 0.938902797529501, 0.9392810168650501, 0.9382942082640235, 0.9407823348902347, 0.9402765629629519, 0.9389378651976585, 0.9424319847671974, 0.9427765238675047, 0.940955886945297, 0.9421865900493978, 0.9411025560537717, 0.9415068500020778, 0.9431419373040053, 0.9436917899354016, 0.9438838119316179, 0.9427204460435229, 0.9445385176911107, 0.9452238050266883, 0.9448242964454729, 0.9446365967248483, 0.9458746267828687, 0.9463730946616518, 0.9462135729285165, 0.9462343544273462, 0.9466044126207879, 0.946965063102122, 0.9450049213403069, 0.9463986822664257, 0.9443290434861992, 0.9433024057543721, 0.9466945862153813, 0.9475775594689156, 0.9476652604818152, 0.9478854130538292, 0.9468181392536025, 0.948264164931362, 0.9489707418255544, 0.9490650310053194, 0.9492640324863748, 0.949315997890779, 0.9496543428624389, 0.949618951136153, 0.9493477340420536, 0.9498014961142147, 0.9494881864534827, 0.9498396135854605, 0.9499319150610579, 0.9498109045244381, 0.9494595691104313, 0.9504100398456915, 0.9501148988650766, 0.9505223361278774, 0.9507242291804662, 0.9503708128638337, 0.9503478818664836, 0.9510257717625198, 0.950873971623346, 0.9509640072798883, 0.9508792195764034, 0.9510212639686749], 'mDice': [0.3428107577508469, 0.4708798416199611, 0.5024222600031554, 0.5244087750883547, 0.5365048196582012, 0.543044113706021, 0.533989409102136, 0.5377694471515053, 0.5349918861327293, 0.5558755700935358, 0.5405417659014512, 0.5531650610111641, 0.5550735365172099, 0.5331495547116477, 0.5629167225458607, 0.5636990699309236, 0.5393236555754898, 0.5740092868505946, 0.5788120658637923, 0.5660502369574275, 0.5746242044394255, 0.5658748660760184, 0.5705820828020236, 0.5777477703759859, 0.5846445904758808, 0.5890501178740878, 0.5767376685217144, 0.5931719771747347, 0.5966998652369988, 0.5896436929859233, 0.5895764860467495, 0.5983807948720378, 0.60229998169187, 0.6046112181561636, 0.6044413056555588, 0.6066880621894688, 0.6074353597323998, 0.5990244644018483, 0.6054835571322187, 0.5933252383799853, 0.594538614256172, 0.6080976324712614, 0.6121415560026932, 0.6140672584366721, 0.6167271696753283, 0.6061202683854662, 0.6164799945636597, 0.6236496686586367, 0.6268120119182666, 0.6260542104529256, 0.6294284289242378, 0.630967039344095, 0.6306646716914867, 0.6283354071632437, 0.6351006299449862, 0.6326824650649878, 0.6332416599721727, 0.6353185218736312, 0.6315868537277224, 0.6306835379397349, 0.6397475235597478, 0.6376962355113858, 0.6432017332878752, 0.6417492678169288, 0.6380186701593665, 0.6380871665846068, 0.6435661126824881, 0.6419598929921048, 0.6437857161743961, 0.6429722703547971, 0.6454608157903005], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.03s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_d/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_d/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_Init_Main_wBiasCorrection_CV_d/sd2/vimp*': No such file or directory

  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.31it/s] 50%|█████     | 2/4 [00:00<00:00,  3.47it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.58it/s]100%|██████████| 4/4 [00:01<00:00,  3.36it/s]100%|██████████| 4/4 [00:01<00:00,  3.45it/s]

CrossVal ['d']
