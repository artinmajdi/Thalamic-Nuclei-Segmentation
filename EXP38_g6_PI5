2019-08-17 16:59:25.781384: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-17 16:59:26.115190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:88:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-08-17 16:59:26.115241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 16:59:26.489428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 16:59:26.489477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 16:59:26.489488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 16:59:26.489963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:12,  1.38it/s]Loading train:   1%|          | 2/266 [00:01<02:52,  1.53it/s]Loading train:   1%|          | 3/266 [00:01<02:30,  1.75it/s]Loading train:   2%|▏         | 4/266 [00:02<02:19,  1.88it/s]Loading train:   2%|▏         | 5/266 [00:02<02:16,  1.92it/s]Loading train:   2%|▏         | 6/266 [00:03<02:15,  1.92it/s]Loading train:   3%|▎         | 7/266 [00:03<02:20,  1.84it/s]Loading train:   3%|▎         | 8/266 [00:04<02:13,  1.93it/s]Loading train:   3%|▎         | 9/266 [00:04<02:35,  1.66it/s]Loading train:   4%|▍         | 10/266 [00:05<02:22,  1.80it/s]Loading train:   4%|▍         | 11/266 [00:06<02:31,  1.68it/s]Loading train:   5%|▍         | 12/266 [00:06<02:48,  1.51it/s]Loading train:   5%|▍         | 13/266 [00:07<03:05,  1.36it/s]Loading train:   5%|▌         | 14/266 [00:08<03:19,  1.26it/s]Loading train:   6%|▌         | 15/266 [00:09<03:21,  1.25it/s]Loading train:   6%|▌         | 16/266 [00:10<03:22,  1.23it/s]Loading train:   6%|▋         | 17/266 [00:10<02:55,  1.42it/s]Loading train:   7%|▋         | 18/266 [00:11<02:43,  1.51it/s]Loading train:   7%|▋         | 19/266 [00:12<02:58,  1.38it/s]Loading train:   8%|▊         | 20/266 [00:13<03:02,  1.34it/s]Loading train:   8%|▊         | 21/266 [00:13<03:04,  1.33it/s]Loading train:   8%|▊         | 22/266 [00:14<03:09,  1.29it/s]Loading train:   9%|▊         | 23/266 [00:15<03:02,  1.33it/s]Loading train:   9%|▉         | 24/266 [00:16<03:03,  1.32it/s]Loading train:   9%|▉         | 25/266 [00:17<03:20,  1.20it/s]Loading train:  10%|▉         | 26/266 [00:17<03:22,  1.19it/s]Loading train:  10%|█         | 27/266 [00:19<03:53,  1.02it/s]Loading train:  11%|█         | 28/266 [00:20<03:51,  1.03it/s]Loading train:  11%|█         | 29/266 [00:21<03:37,  1.09it/s]Loading train:  11%|█▏        | 30/266 [00:21<03:40,  1.07it/s]Loading train:  12%|█▏        | 31/266 [00:23<03:58,  1.01s/it]Loading train:  12%|█▏        | 32/266 [00:24<04:11,  1.08s/it]Loading train:  12%|█▏        | 33/266 [00:25<04:18,  1.11s/it]Loading train:  13%|█▎        | 34/266 [00:26<04:03,  1.05s/it]Loading train:  13%|█▎        | 35/266 [00:27<03:43,  1.03it/s]Loading train:  14%|█▎        | 36/266 [00:28<03:56,  1.03s/it]Loading train:  14%|█▍        | 37/266 [00:29<04:26,  1.16s/it]Loading train:  14%|█▍        | 38/266 [00:31<04:26,  1.17s/it]Loading train:  15%|█▍        | 39/266 [00:32<04:44,  1.25s/it]Loading train:  15%|█▌        | 40/266 [00:33<04:12,  1.12s/it]Loading train:  15%|█▌        | 41/266 [00:34<04:31,  1.21s/it]Loading train:  16%|█▌        | 42/266 [00:36<04:40,  1.25s/it]Loading train:  16%|█▌        | 43/266 [00:37<04:53,  1.32s/it]Loading train:  17%|█▋        | 44/266 [00:38<04:38,  1.25s/it]Loading train:  17%|█▋        | 45/266 [00:39<04:21,  1.18s/it]Loading train:  17%|█▋        | 46/266 [00:40<04:24,  1.20s/it]Loading train:  18%|█▊        | 47/266 [00:42<04:41,  1.29s/it]Loading train:  18%|█▊        | 48/266 [00:43<04:33,  1.26s/it]Loading train:  18%|█▊        | 49/266 [00:44<04:00,  1.11s/it]Loading train:  19%|█▉        | 50/266 [00:45<04:17,  1.19s/it]Loading train:  19%|█▉        | 51/266 [00:46<04:13,  1.18s/it]Loading train:  20%|█▉        | 52/266 [00:48<04:31,  1.27s/it]Loading train:  20%|█▉        | 53/266 [00:49<04:24,  1.24s/it]Loading train:  20%|██        | 54/266 [00:50<04:13,  1.20s/it]Loading train:  21%|██        | 55/266 [00:52<04:32,  1.29s/it]Loading train:  21%|██        | 56/266 [00:53<04:21,  1.25s/it]Loading train:  21%|██▏       | 57/266 [00:54<04:10,  1.20s/it]Loading train:  22%|██▏       | 58/266 [00:55<04:24,  1.27s/it]Loading train:  22%|██▏       | 59/266 [00:56<04:00,  1.16s/it]Loading train:  23%|██▎       | 60/266 [00:57<04:00,  1.17s/it]Loading train:  23%|██▎       | 61/266 [00:59<04:16,  1.25s/it]Loading train:  23%|██▎       | 62/266 [01:00<04:20,  1.28s/it]Loading train:  24%|██▎       | 63/266 [01:02<04:37,  1.37s/it]Loading train:  24%|██▍       | 64/266 [01:03<04:39,  1.38s/it]Loading train:  24%|██▍       | 65/266 [01:05<04:45,  1.42s/it]Loading train:  25%|██▍       | 66/266 [01:06<04:48,  1.44s/it]Loading train:  25%|██▌       | 67/266 [01:08<04:53,  1.47s/it]Loading train:  26%|██▌       | 68/266 [01:09<04:29,  1.36s/it]Loading train:  26%|██▌       | 69/266 [01:10<04:21,  1.33s/it]Loading train:  26%|██▋       | 70/266 [01:11<04:07,  1.27s/it]Loading train:  27%|██▋       | 71/266 [01:13<04:13,  1.30s/it]Loading train:  27%|██▋       | 72/266 [01:14<04:00,  1.24s/it]Loading train:  27%|██▋       | 73/266 [01:15<04:09,  1.29s/it]Loading train:  28%|██▊       | 74/266 [01:17<04:30,  1.41s/it]Loading train:  28%|██▊       | 75/266 [01:18<04:34,  1.44s/it]Loading train:  29%|██▊       | 76/266 [01:20<04:28,  1.41s/it]Loading train:  29%|██▉       | 77/266 [01:21<04:07,  1.31s/it]Loading train:  29%|██▉       | 78/266 [01:22<04:12,  1.34s/it]Loading train:  30%|██▉       | 79/266 [01:24<04:10,  1.34s/it]Loading train:  30%|███       | 80/266 [01:24<03:31,  1.14s/it]Loading train:  30%|███       | 81/266 [01:25<03:32,  1.15s/it]Loading train:  31%|███       | 82/266 [01:27<03:49,  1.25s/it]Loading train:  31%|███       | 83/266 [01:28<03:57,  1.30s/it]Loading train:  32%|███▏      | 84/266 [01:30<04:08,  1.37s/it]Loading train:  32%|███▏      | 85/266 [01:31<03:46,  1.25s/it]Loading train:  32%|███▏      | 86/266 [01:32<03:41,  1.23s/it]Loading train:  33%|███▎      | 87/266 [01:33<03:48,  1.28s/it]Loading train:  33%|███▎      | 88/266 [01:35<03:45,  1.27s/it]Loading train:  33%|███▎      | 89/266 [01:36<03:43,  1.26s/it]Loading train:  34%|███▍      | 90/266 [01:37<03:36,  1.23s/it]Loading train:  34%|███▍      | 91/266 [01:39<03:52,  1.33s/it]Loading train:  35%|███▍      | 92/266 [01:40<04:00,  1.38s/it]Loading train:  35%|███▍      | 93/266 [01:41<03:59,  1.39s/it]Loading train:  35%|███▌      | 94/266 [01:42<03:31,  1.23s/it]Loading train:  36%|███▌      | 95/266 [01:44<03:33,  1.25s/it]Loading train:  36%|███▌      | 96/266 [01:45<03:51,  1.36s/it]Loading train:  36%|███▋      | 97/266 [01:47<04:01,  1.43s/it]Loading train:  37%|███▋      | 98/266 [01:48<03:50,  1.37s/it]Loading train:  37%|███▋      | 99/266 [01:49<03:45,  1.35s/it]Loading train:  38%|███▊      | 100/266 [01:51<04:00,  1.45s/it]Loading train:  38%|███▊      | 101/266 [01:53<04:05,  1.49s/it]Loading train:  38%|███▊      | 102/266 [01:54<04:02,  1.48s/it]Loading train:  39%|███▊      | 103/266 [01:55<03:52,  1.43s/it]Loading train:  39%|███▉      | 104/266 [01:57<04:00,  1.49s/it]Loading train:  39%|███▉      | 105/266 [01:58<03:50,  1.43s/it]Loading train:  40%|███▉      | 106/266 [02:00<03:40,  1.38s/it]Loading train:  40%|████      | 107/266 [02:01<03:39,  1.38s/it]Loading train:  41%|████      | 108/266 [02:02<03:39,  1.39s/it]Loading train:  41%|████      | 109/266 [02:04<03:41,  1.41s/it]Loading train:  41%|████▏     | 110/266 [02:05<03:51,  1.49s/it]Loading train:  42%|████▏     | 111/266 [02:07<03:51,  1.50s/it]Loading train:  42%|████▏     | 112/266 [02:08<03:43,  1.45s/it]Loading train:  42%|████▏     | 113/266 [02:10<03:54,  1.53s/it]Loading train:  43%|████▎     | 114/266 [02:12<04:14,  1.67s/it]Loading train:  43%|████▎     | 115/266 [02:14<04:03,  1.61s/it]Loading train:  44%|████▎     | 116/266 [02:15<03:57,  1.58s/it]Loading train:  44%|████▍     | 117/266 [02:16<03:40,  1.48s/it]Loading train:  44%|████▍     | 118/266 [02:17<03:20,  1.35s/it]Loading train:  45%|████▍     | 119/266 [02:19<03:19,  1.36s/it]Loading train:  45%|████▌     | 120/266 [02:20<03:12,  1.32s/it]Loading train:  45%|████▌     | 121/266 [02:22<03:29,  1.44s/it]Loading train:  46%|████▌     | 122/266 [02:23<03:33,  1.49s/it]Loading train:  46%|████▌     | 123/266 [02:25<03:26,  1.45s/it]Loading train:  47%|████▋     | 124/266 [02:26<03:24,  1.44s/it]Loading train:  47%|████▋     | 125/266 [02:28<03:27,  1.47s/it]Loading train:  47%|████▋     | 126/266 [02:29<03:27,  1.48s/it]Loading train:  48%|████▊     | 127/266 [02:31<03:30,  1.51s/it]Loading train:  48%|████▊     | 128/266 [02:32<03:13,  1.40s/it]Loading train:  48%|████▊     | 129/266 [02:33<03:21,  1.47s/it]Loading train:  49%|████▉     | 130/266 [02:35<03:14,  1.43s/it]Loading train:  49%|████▉     | 131/266 [02:36<03:13,  1.44s/it]Loading train:  50%|████▉     | 132/266 [02:38<03:13,  1.45s/it]Loading train:  50%|█████     | 133/266 [02:39<03:12,  1.45s/it]Loading train:  50%|█████     | 134/266 [02:41<03:21,  1.52s/it]Loading train:  51%|█████     | 135/266 [02:42<03:14,  1.49s/it]Loading train:  51%|█████     | 136/266 [02:43<02:56,  1.36s/it]Loading train:  52%|█████▏    | 137/266 [02:44<02:34,  1.20s/it]Loading train:  52%|█████▏    | 138/266 [02:46<02:41,  1.26s/it]Loading train:  52%|█████▏    | 139/266 [02:47<02:48,  1.33s/it]Loading train:  53%|█████▎    | 140/266 [02:48<02:52,  1.37s/it]Loading train:  53%|█████▎    | 141/266 [02:50<02:41,  1.29s/it]Loading train:  53%|█████▎    | 142/266 [02:51<02:45,  1.33s/it]Loading train:  54%|█████▍    | 143/266 [02:53<02:51,  1.40s/it]Loading train:  54%|█████▍    | 144/266 [02:53<02:14,  1.10s/it]Loading train:  55%|█████▍    | 145/266 [02:55<02:30,  1.25s/it]Loading train:  55%|█████▍    | 146/266 [02:56<02:31,  1.26s/it]Loading train:  55%|█████▌    | 147/266 [02:57<02:39,  1.34s/it]Loading train:  56%|█████▌    | 148/266 [02:59<02:44,  1.39s/it]Loading train:  56%|█████▌    | 149/266 [03:00<02:45,  1.42s/it]Loading train:  56%|█████▋    | 150/266 [03:02<02:41,  1.40s/it]Loading train:  57%|█████▋    | 151/266 [03:03<02:38,  1.38s/it]Loading train:  57%|█████▋    | 152/266 [03:04<02:37,  1.38s/it]Loading train:  58%|█████▊    | 153/266 [03:06<02:36,  1.38s/it]Loading train:  58%|█████▊    | 154/266 [03:07<02:18,  1.24s/it]Loading train:  58%|█████▊    | 155/266 [03:08<02:06,  1.14s/it]Loading train:  59%|█████▊    | 156/266 [03:09<02:08,  1.17s/it]Loading train:  59%|█████▉    | 157/266 [03:10<02:12,  1.22s/it]Loading train:  59%|█████▉    | 158/266 [03:12<02:16,  1.26s/it]Loading train:  60%|█████▉    | 159/266 [03:13<02:28,  1.39s/it]Loading train:  60%|██████    | 160/266 [03:14<02:06,  1.19s/it]Loading train:  61%|██████    | 161/266 [03:15<02:06,  1.21s/it]Loading train:  61%|██████    | 162/266 [03:17<02:14,  1.29s/it]Loading train:  61%|██████▏   | 163/266 [03:18<02:13,  1.29s/it]Loading train:  62%|██████▏   | 164/266 [03:19<02:11,  1.29s/it]Loading train:  62%|██████▏   | 165/266 [03:20<02:05,  1.24s/it]Loading train:  62%|██████▏   | 166/266 [03:22<02:11,  1.31s/it]Loading train:  63%|██████▎   | 167/266 [03:24<02:18,  1.40s/it]Loading train:  63%|██████▎   | 168/266 [03:25<02:18,  1.41s/it]Loading train:  64%|██████▎   | 169/266 [03:27<02:21,  1.46s/it]Loading train:  64%|██████▍   | 170/266 [03:28<02:11,  1.37s/it]Loading train:  64%|██████▍   | 171/266 [03:29<02:10,  1.37s/it]Loading train:  65%|██████▍   | 172/266 [03:30<02:08,  1.37s/it]Loading train:  65%|██████▌   | 173/266 [03:32<02:11,  1.42s/it]Loading train:  65%|██████▌   | 174/266 [03:33<02:12,  1.44s/it]Loading train:  66%|██████▌   | 175/266 [03:35<02:13,  1.47s/it]Loading train:  66%|██████▌   | 176/266 [03:37<02:18,  1.54s/it]Loading train:  67%|██████▋   | 177/266 [03:38<02:10,  1.47s/it]Loading train:  67%|██████▋   | 178/266 [03:39<02:05,  1.43s/it]Loading train:  67%|██████▋   | 179/266 [03:41<02:03,  1.42s/it]Loading train:  68%|██████▊   | 180/266 [03:42<02:03,  1.44s/it]Loading train:  68%|██████▊   | 181/266 [03:44<02:08,  1.51s/it]Loading train:  68%|██████▊   | 182/266 [03:45<02:06,  1.51s/it]Loading train:  69%|██████▉   | 183/266 [03:47<02:01,  1.47s/it]Loading train:  69%|██████▉   | 184/266 [03:48<01:51,  1.36s/it]Loading train:  70%|██████▉   | 185/266 [03:49<01:44,  1.29s/it]Loading train:  70%|██████▉   | 186/266 [03:50<01:34,  1.18s/it]Loading train:  70%|███████   | 187/266 [03:51<01:33,  1.18s/it]Loading train:  71%|███████   | 188/266 [03:52<01:35,  1.23s/it]Loading train:  71%|███████   | 189/266 [03:54<01:46,  1.38s/it]Loading train:  71%|███████▏  | 190/266 [03:56<01:50,  1.45s/it]Loading train:  72%|███████▏  | 191/266 [03:57<01:44,  1.39s/it]Loading train:  72%|███████▏  | 192/266 [03:58<01:44,  1.41s/it]Loading train:  73%|███████▎  | 193/266 [04:00<01:43,  1.42s/it]Loading train:  73%|███████▎  | 194/266 [04:02<01:45,  1.47s/it]Loading train:  73%|███████▎  | 195/266 [04:02<01:32,  1.30s/it]Loading train:  74%|███████▎  | 196/266 [04:04<01:34,  1.35s/it]Loading train:  74%|███████▍  | 197/266 [04:06<01:39,  1.44s/it]Loading train:  74%|███████▍  | 198/266 [04:07<01:39,  1.47s/it]Loading train:  75%|███████▍  | 199/266 [04:08<01:35,  1.43s/it]Loading train:  75%|███████▌  | 200/266 [04:10<01:32,  1.41s/it]Loading train:  76%|███████▌  | 201/266 [04:11<01:31,  1.41s/it]Loading train:  76%|███████▌  | 202/266 [04:13<01:30,  1.41s/it]Loading train:  76%|███████▋  | 203/266 [04:14<01:31,  1.46s/it]Loading train:  77%|███████▋  | 204/266 [04:16<01:28,  1.43s/it]Loading train:  77%|███████▋  | 205/266 [04:17<01:21,  1.33s/it]Loading train:  77%|███████▋  | 206/266 [04:18<01:24,  1.41s/it]Loading train:  78%|███████▊  | 207/266 [04:20<01:24,  1.43s/it]Loading train:  78%|███████▊  | 208/266 [04:21<01:22,  1.43s/it]Loading train:  79%|███████▊  | 209/266 [04:22<01:19,  1.39s/it]Loading train:  79%|███████▉  | 210/266 [04:24<01:16,  1.36s/it]Loading train:  79%|███████▉  | 211/266 [04:25<01:13,  1.34s/it]Loading train:  80%|███████▉  | 212/266 [04:27<01:16,  1.42s/it]Loading train:  80%|████████  | 213/266 [04:28<01:18,  1.49s/it]Loading train:  80%|████████  | 214/266 [04:29<01:08,  1.31s/it]Loading train:  81%|████████  | 215/266 [04:31<01:07,  1.32s/it]Loading train:  81%|████████  | 216/266 [04:32<01:04,  1.29s/it]Loading train:  82%|████████▏ | 217/266 [04:33<01:09,  1.41s/it]Loading train:  82%|████████▏ | 218/266 [04:35<01:03,  1.33s/it]Loading train:  82%|████████▏ | 219/266 [04:36<01:02,  1.33s/it]Loading train:  83%|████████▎ | 220/266 [04:37<01:01,  1.33s/it]Loading train:  83%|████████▎ | 221/266 [04:39<01:01,  1.37s/it]Loading train:  83%|████████▎ | 222/266 [04:40<00:55,  1.25s/it]Loading train:  84%|████████▍ | 223/266 [04:41<00:52,  1.21s/it]Loading train:  84%|████████▍ | 224/266 [04:42<00:51,  1.24s/it]Loading train:  85%|████████▍ | 225/266 [04:43<00:49,  1.21s/it]Loading train:  85%|████████▍ | 226/266 [04:45<00:49,  1.23s/it]Loading train:  85%|████████▌ | 227/266 [04:46<00:52,  1.35s/it]Loading train:  86%|████████▌ | 228/266 [04:47<00:48,  1.26s/it]Loading train:  86%|████████▌ | 229/266 [04:49<00:48,  1.30s/it]Loading train:  86%|████████▋ | 230/266 [04:50<00:45,  1.26s/it]Loading train:  87%|████████▋ | 231/266 [04:51<00:44,  1.28s/it]Loading train:  87%|████████▋ | 232/266 [04:53<00:46,  1.37s/it]Loading train:  88%|████████▊ | 233/266 [04:54<00:43,  1.31s/it]Loading train:  88%|████████▊ | 234/266 [04:55<00:43,  1.37s/it]Loading train:  88%|████████▊ | 235/266 [04:57<00:43,  1.40s/it]Loading train:  89%|████████▊ | 236/266 [04:58<00:42,  1.42s/it]Loading train:  89%|████████▉ | 237/266 [05:00<00:39,  1.38s/it]Loading train:  89%|████████▉ | 238/266 [05:01<00:40,  1.45s/it]Loading train:  90%|████████▉ | 239/266 [05:03<00:39,  1.45s/it]Loading train:  90%|█████████ | 240/266 [05:04<00:34,  1.31s/it]Loading train:  91%|█████████ | 241/266 [05:05<00:30,  1.21s/it]Loading train:  91%|█████████ | 242/266 [05:06<00:30,  1.27s/it]Loading train:  91%|█████████▏| 243/266 [05:08<00:31,  1.35s/it]Loading train:  92%|█████████▏| 244/266 [05:09<00:31,  1.43s/it]Loading train:  92%|█████████▏| 245/266 [05:10<00:28,  1.37s/it]Loading train:  92%|█████████▏| 246/266 [05:12<00:28,  1.42s/it]Loading train:  93%|█████████▎| 247/266 [05:14<00:28,  1.51s/it]Loading train:  93%|█████████▎| 248/266 [05:15<00:24,  1.37s/it]Loading train:  94%|█████████▎| 249/266 [05:16<00:24,  1.46s/it]Loading train:  94%|█████████▍| 250/266 [05:17<00:21,  1.33s/it]Loading train:  94%|█████████▍| 251/266 [05:19<00:20,  1.40s/it]Loading train:  95%|█████████▍| 252/266 [05:20<00:18,  1.29s/it]Loading train:  95%|█████████▌| 253/266 [05:21<00:15,  1.22s/it]Loading train:  95%|█████████▌| 254/266 [05:23<00:15,  1.32s/it]Loading train:  96%|█████████▌| 255/266 [05:24<00:15,  1.37s/it]Loading train:  96%|█████████▌| 256/266 [05:26<00:14,  1.43s/it]Loading train:  97%|█████████▋| 257/266 [05:27<00:12,  1.43s/it]Loading train:  97%|█████████▋| 258/266 [05:28<00:11,  1.40s/it]Loading train:  97%|█████████▋| 259/266 [05:30<00:09,  1.41s/it]Loading train:  98%|█████████▊| 260/266 [05:31<00:08,  1.34s/it]Loading train:  98%|█████████▊| 261/266 [05:33<00:07,  1.44s/it]Loading train:  98%|█████████▊| 262/266 [05:34<00:05,  1.35s/it]Loading train:  99%|█████████▉| 263/266 [05:35<00:03,  1.30s/it]Loading train:  99%|█████████▉| 264/266 [05:36<00:02,  1.26s/it]Loading train: 100%|█████████▉| 265/266 [05:37<00:01,  1.26s/it]Loading train: 100%|██████████| 266/266 [05:39<00:00,  1.28s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:34,  7.60it/s]concatenating: train:   1%|          | 2/266 [00:00<00:36,  7.33it/s]concatenating: train:   1%|          | 3/266 [00:00<00:36,  7.27it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:33,  7.84it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:31,  8.22it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:33,  7.86it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:40,  6.40it/s]concatenating: train:   3%|▎         | 8/266 [00:01<00:43,  5.91it/s]concatenating: train:   3%|▎         | 9/266 [00:01<00:48,  5.35it/s]concatenating: train:   4%|▍         | 10/266 [00:01<00:44,  5.75it/s]concatenating: train:   4%|▍         | 11/266 [00:01<00:42,  5.97it/s]concatenating: train:   5%|▌         | 14/266 [00:01<00:33,  7.55it/s]concatenating: train:   6%|▌         | 16/266 [00:02<00:36,  6.79it/s]concatenating: train:   6%|▋         | 17/266 [00:02<00:53,  4.68it/s]concatenating: train:   7%|▋         | 18/266 [00:02<00:53,  4.67it/s]concatenating: train:   7%|▋         | 19/266 [00:03<01:06,  3.69it/s]concatenating: train:   8%|▊         | 20/266 [00:03<00:59,  4.16it/s]concatenating: train:   8%|▊         | 22/266 [00:03<00:46,  5.20it/s]concatenating: train:   9%|▉         | 25/266 [00:03<00:35,  6.88it/s]concatenating: train:  10%|█         | 27/266 [00:04<00:41,  5.72it/s]concatenating: train:  11%|█         | 29/266 [00:04<00:41,  5.71it/s]concatenating: train:  11%|█▏        | 30/266 [00:04<00:41,  5.70it/s]concatenating: train:  12%|█▏        | 31/266 [00:04<00:42,  5.54it/s]concatenating: train:  12%|█▏        | 32/266 [00:05<00:39,  5.98it/s]concatenating: train:  12%|█▏        | 33/266 [00:05<00:35,  6.59it/s]concatenating: train:  13%|█▎        | 34/266 [00:05<00:31,  7.33it/s]concatenating: train:  14%|█▎        | 36/266 [00:05<00:35,  6.51it/s]concatenating: train:  14%|█▍        | 37/266 [00:05<00:38,  5.97it/s]concatenating: train:  14%|█▍        | 38/266 [00:06<00:51,  4.39it/s]concatenating: train:  15%|█▍        | 39/266 [00:06<00:49,  4.56it/s]concatenating: train:  15%|█▌        | 40/266 [00:06<00:48,  4.68it/s]concatenating: train:  15%|█▌        | 41/266 [00:06<00:44,  5.09it/s]concatenating: train:  16%|█▌        | 42/266 [00:06<00:38,  5.81it/s]concatenating: train:  16%|█▌        | 43/266 [00:06<00:34,  6.49it/s]concatenating: train:  17%|█▋        | 46/266 [00:07<00:30,  7.17it/s]concatenating: train:  18%|█▊        | 47/266 [00:07<00:32,  6.65it/s]concatenating: train:  18%|█▊        | 48/266 [00:07<00:42,  5.15it/s]concatenating: train:  18%|█▊        | 49/266 [00:07<00:41,  5.27it/s]concatenating: train:  19%|█▉        | 50/266 [00:08<00:38,  5.57it/s]concatenating: train:  19%|█▉        | 51/266 [00:08<00:45,  4.74it/s]concatenating: train:  20%|█▉        | 52/266 [00:08<00:39,  5.35it/s]concatenating: train:  20%|█▉        | 53/266 [00:08<00:34,  6.11it/s]concatenating: train:  21%|██        | 56/266 [00:08<00:28,  7.30it/s]concatenating: train:  21%|██▏       | 57/266 [00:08<00:30,  6.89it/s]concatenating: train:  22%|██▏       | 58/266 [00:09<00:32,  6.38it/s]concatenating: train:  22%|██▏       | 59/266 [00:09<00:35,  5.90it/s]concatenating: train:  23%|██▎       | 60/266 [00:09<00:36,  5.59it/s]concatenating: train:  23%|██▎       | 61/266 [00:09<00:35,  5.81it/s]concatenating: train:  23%|██▎       | 62/266 [00:09<00:38,  5.30it/s]concatenating: train:  24%|██▎       | 63/266 [00:10<00:37,  5.37it/s]concatenating: train:  24%|██▍       | 64/266 [00:10<00:34,  5.88it/s]concatenating: train:  25%|██▍       | 66/266 [00:10<00:30,  6.53it/s]concatenating: train:  25%|██▌       | 67/266 [00:10<00:28,  7.10it/s]concatenating: train:  26%|██▌       | 68/266 [00:10<00:26,  7.37it/s]concatenating: train:  26%|██▌       | 69/266 [00:10<00:29,  6.66it/s]concatenating: train:  26%|██▋       | 70/266 [00:11<00:32,  6.10it/s]concatenating: train:  27%|██▋       | 71/266 [00:11<00:32,  6.05it/s]concatenating: train:  27%|██▋       | 72/266 [00:11<00:30,  6.30it/s]concatenating: train:  27%|██▋       | 73/266 [00:11<00:30,  6.38it/s]concatenating: train:  28%|██▊       | 74/266 [00:11<00:31,  6.11it/s]concatenating: train:  28%|██▊       | 75/266 [00:11<00:30,  6.24it/s]concatenating: train:  29%|██▊       | 76/266 [00:12<00:29,  6.54it/s]concatenating: train:  29%|██▉       | 77/266 [00:12<00:34,  5.51it/s]concatenating: train:  29%|██▉       | 78/266 [00:12<00:32,  5.71it/s]concatenating: train:  30%|██▉       | 79/266 [00:12<00:33,  5.52it/s]concatenating: train:  30%|███       | 80/266 [00:12<00:32,  5.79it/s]concatenating: train:  30%|███       | 81/266 [00:12<00:30,  6.10it/s]concatenating: train:  31%|███       | 82/266 [00:13<00:29,  6.33it/s]concatenating: train:  31%|███       | 83/266 [00:13<00:28,  6.50it/s]concatenating: train:  32%|███▏      | 84/266 [00:13<00:25,  7.08it/s]concatenating: train:  32%|███▏      | 85/266 [00:13<00:23,  7.61it/s]concatenating: train:  32%|███▏      | 86/266 [00:13<00:24,  7.21it/s]concatenating: train:  33%|███▎      | 88/266 [00:13<00:23,  7.61it/s]concatenating: train:  33%|███▎      | 89/266 [00:13<00:21,  8.13it/s]concatenating: train:  34%|███▍      | 90/266 [00:14<00:28,  6.18it/s]concatenating: train:  34%|███▍      | 91/266 [00:14<00:39,  4.47it/s]concatenating: train:  35%|███▍      | 92/266 [00:14<00:44,  3.90it/s]concatenating: train:  35%|███▍      | 93/266 [00:15<00:41,  4.20it/s]concatenating: train:  35%|███▌      | 94/266 [00:15<00:36,  4.69it/s]concatenating: train:  36%|███▌      | 95/266 [00:15<00:32,  5.32it/s]concatenating: train:  36%|███▌      | 96/266 [00:15<00:30,  5.57it/s]concatenating: train:  36%|███▋      | 97/266 [00:15<00:27,  6.23it/s]concatenating: train:  37%|███▋      | 98/266 [00:15<00:29,  5.65it/s]concatenating: train:  37%|███▋      | 99/266 [00:16<00:41,  4.06it/s]concatenating: train:  38%|███▊      | 100/266 [00:16<00:41,  4.01it/s]concatenating: train:  38%|███▊      | 101/266 [00:16<00:37,  4.38it/s]concatenating: train:  38%|███▊      | 102/266 [00:16<00:35,  4.57it/s]concatenating: train:  39%|███▊      | 103/266 [00:17<00:32,  5.00it/s]concatenating: train:  39%|███▉      | 104/266 [00:17<00:31,  5.13it/s]concatenating: train:  39%|███▉      | 105/266 [00:17<00:30,  5.35it/s]concatenating: train:  40%|███▉      | 106/266 [00:17<00:31,  5.05it/s]concatenating: train:  40%|████      | 107/266 [00:17<00:32,  4.87it/s]concatenating: train:  41%|████      | 108/266 [00:18<00:32,  4.89it/s]concatenating: train:  41%|████      | 109/266 [00:18<00:31,  4.99it/s]concatenating: train:  41%|████▏     | 110/266 [00:18<00:29,  5.21it/s]concatenating: train:  42%|████▏     | 111/266 [00:18<00:27,  5.63it/s]concatenating: train:  42%|████▏     | 112/266 [00:18<00:26,  5.76it/s]concatenating: train:  42%|████▏     | 113/266 [00:18<00:24,  6.21it/s]concatenating: train:  43%|████▎     | 114/266 [00:19<00:26,  5.79it/s]concatenating: train:  43%|████▎     | 115/266 [00:19<00:23,  6.33it/s]concatenating: train:  44%|████▎     | 116/266 [00:19<00:21,  6.93it/s]concatenating: train:  44%|████▍     | 117/266 [00:19<00:20,  7.11it/s]concatenating: train:  44%|████▍     | 118/266 [00:19<00:20,  7.18it/s]concatenating: train:  45%|████▍     | 119/266 [00:19<00:24,  5.99it/s]concatenating: train:  45%|████▌     | 120/266 [00:20<00:34,  4.24it/s]concatenating: train:  45%|████▌     | 121/266 [00:20<00:35,  4.04it/s]concatenating: train:  46%|████▌     | 122/266 [00:20<00:32,  4.49it/s]concatenating: train:  46%|████▌     | 123/266 [00:20<00:31,  4.51it/s]concatenating: train:  47%|████▋     | 124/266 [00:21<00:30,  4.70it/s]concatenating: train:  47%|████▋     | 125/266 [00:21<00:33,  4.16it/s]concatenating: train:  47%|████▋     | 126/266 [00:21<00:28,  4.87it/s]concatenating: train:  48%|████▊     | 127/266 [00:21<00:25,  5.53it/s]concatenating: train:  48%|████▊     | 128/266 [00:21<00:28,  4.80it/s]concatenating: train:  48%|████▊     | 129/266 [00:22<00:27,  5.04it/s]concatenating: train:  49%|████▉     | 130/266 [00:22<00:26,  5.15it/s]concatenating: train:  49%|████▉     | 131/266 [00:22<00:25,  5.36it/s]concatenating: train:  50%|████▉     | 132/266 [00:22<00:24,  5.55it/s]concatenating: train:  50%|█████     | 133/266 [00:22<00:26,  5.03it/s]concatenating: train:  50%|█████     | 134/266 [00:23<00:26,  4.99it/s]concatenating: train:  51%|█████     | 135/266 [00:23<00:23,  5.52it/s]concatenating: train:  51%|█████     | 136/266 [00:23<00:28,  4.56it/s]concatenating: train:  52%|█████▏    | 137/266 [00:23<00:30,  4.23it/s]concatenating: train:  52%|█████▏    | 138/266 [00:23<00:31,  4.11it/s]concatenating: train:  52%|█████▏    | 139/266 [00:24<00:36,  3.52it/s]concatenating: train:  53%|█████▎    | 140/266 [00:24<00:35,  3.50it/s]concatenating: train:  53%|█████▎    | 141/266 [00:24<00:35,  3.52it/s]concatenating: train:  53%|█████▎    | 142/266 [00:25<00:34,  3.65it/s]concatenating: train:  54%|█████▍    | 143/266 [00:25<00:30,  4.05it/s]concatenating: train:  54%|█████▍    | 144/266 [00:25<00:29,  4.20it/s]concatenating: train:  55%|█████▍    | 145/266 [00:25<00:28,  4.28it/s]concatenating: train:  55%|█████▍    | 146/266 [00:26<00:27,  4.36it/s]concatenating: train:  55%|█████▌    | 147/266 [00:26<00:28,  4.21it/s]concatenating: train:  56%|█████▌    | 148/266 [00:26<00:25,  4.54it/s]concatenating: train:  56%|█████▌    | 149/266 [00:26<00:26,  4.35it/s]concatenating: train:  56%|█████▋    | 150/266 [00:26<00:26,  4.39it/s]concatenating: train:  57%|█████▋    | 151/266 [00:27<00:24,  4.68it/s]concatenating: train:  57%|█████▋    | 152/266 [00:27<00:23,  4.86it/s]concatenating: train:  58%|█████▊    | 153/266 [00:27<00:21,  5.27it/s]concatenating: train:  58%|█████▊    | 154/266 [00:27<00:21,  5.12it/s]concatenating: train:  58%|█████▊    | 155/266 [00:27<00:21,  5.08it/s]concatenating: train:  59%|█████▊    | 156/266 [00:28<00:22,  4.97it/s]concatenating: train:  59%|█████▉    | 157/266 [00:28<00:22,  4.86it/s]concatenating: train:  59%|█████▉    | 158/266 [00:28<00:22,  4.78it/s]concatenating: train:  60%|█████▉    | 159/266 [00:28<00:25,  4.26it/s]concatenating: train:  60%|██████    | 160/266 [00:29<00:28,  3.72it/s]concatenating: train:  61%|██████    | 161/266 [00:29<00:24,  4.32it/s]concatenating: train:  61%|██████    | 162/266 [00:29<00:23,  4.48it/s]concatenating: train:  61%|██████▏   | 163/266 [00:29<00:22,  4.50it/s]concatenating: train:  62%|██████▏   | 164/266 [00:29<00:21,  4.83it/s]concatenating: train:  62%|██████▏   | 165/266 [00:30<00:20,  4.85it/s]concatenating: train:  62%|██████▏   | 166/266 [00:30<00:18,  5.30it/s]concatenating: train:  63%|██████▎   | 167/266 [00:30<00:17,  5.70it/s]concatenating: train:  63%|██████▎   | 168/266 [00:30<00:18,  5.17it/s]concatenating: train:  64%|██████▎   | 169/266 [00:30<00:18,  5.12it/s]concatenating: train:  64%|██████▍   | 170/266 [00:30<00:16,  5.74it/s]concatenating: train:  64%|██████▍   | 171/266 [00:31<00:18,  5.26it/s]concatenating: train:  65%|██████▍   | 172/266 [00:31<00:21,  4.41it/s]concatenating: train:  65%|██████▌   | 173/266 [00:31<00:19,  4.70it/s]concatenating: train:  65%|██████▌   | 174/266 [00:31<00:17,  5.20it/s]concatenating: train:  66%|██████▌   | 175/266 [00:31<00:16,  5.63it/s]concatenating: train:  66%|██████▌   | 176/266 [00:32<00:15,  5.97it/s]concatenating: train:  67%|██████▋   | 177/266 [00:32<00:17,  5.15it/s]concatenating: train:  67%|██████▋   | 178/266 [00:32<00:16,  5.23it/s]concatenating: train:  67%|██████▋   | 179/266 [00:32<00:14,  6.06it/s]concatenating: train:  68%|██████▊   | 180/266 [00:32<00:14,  5.94it/s]concatenating: train:  68%|██████▊   | 181/266 [00:33<00:16,  5.30it/s]concatenating: train:  68%|██████▊   | 182/266 [00:33<00:17,  4.93it/s]concatenating: train:  69%|██████▉   | 183/266 [00:33<00:14,  5.66it/s]concatenating: train:  70%|██████▉   | 185/266 [00:33<00:13,  5.97it/s]concatenating: train:  70%|██████▉   | 186/266 [00:33<00:14,  5.64it/s]concatenating: train:  70%|███████   | 187/266 [00:34<00:14,  5.47it/s]concatenating: train:  71%|███████   | 188/266 [00:34<00:13,  5.72it/s]concatenating: train:  71%|███████   | 189/266 [00:34<00:14,  5.36it/s]concatenating: train:  71%|███████▏  | 190/266 [00:34<00:17,  4.38it/s]concatenating: train:  72%|███████▏  | 191/266 [00:34<00:16,  4.68it/s]concatenating: train:  72%|███████▏  | 192/266 [00:35<00:15,  4.87it/s]concatenating: train:  73%|███████▎  | 193/266 [00:35<00:13,  5.26it/s]concatenating: train:  73%|███████▎  | 194/266 [00:35<00:14,  5.08it/s]concatenating: train:  73%|███████▎  | 195/266 [00:35<00:12,  5.84it/s]concatenating: train:  74%|███████▎  | 196/266 [00:35<00:12,  5.52it/s]concatenating: train:  74%|███████▍  | 197/266 [00:36<00:13,  5.19it/s]concatenating: train:  74%|███████▍  | 198/266 [00:36<00:12,  5.47it/s]concatenating: train:  75%|███████▍  | 199/266 [00:36<00:11,  5.96it/s]concatenating: train:  75%|███████▌  | 200/266 [00:36<00:11,  5.88it/s]concatenating: train:  76%|███████▌  | 201/266 [00:36<00:10,  6.16it/s]concatenating: train:  76%|███████▌  | 202/266 [00:36<00:10,  5.84it/s]concatenating: train:  76%|███████▋  | 203/266 [00:37<00:10,  6.00it/s]concatenating: train:  77%|███████▋  | 204/266 [00:37<00:11,  5.58it/s]concatenating: train:  77%|███████▋  | 205/266 [00:37<00:11,  5.47it/s]concatenating: train:  77%|███████▋  | 206/266 [00:37<00:11,  5.35it/s]concatenating: train:  78%|███████▊  | 207/266 [00:37<00:11,  5.31it/s]concatenating: train:  78%|███████▊  | 208/266 [00:37<00:10,  5.60it/s]concatenating: train:  79%|███████▊  | 209/266 [00:38<00:09,  5.94it/s]concatenating: train:  79%|███████▉  | 210/266 [00:38<00:08,  6.35it/s]concatenating: train:  79%|███████▉  | 211/266 [00:38<00:08,  6.37it/s]concatenating: train:  80%|███████▉  | 212/266 [00:38<00:08,  6.19it/s]concatenating: train:  80%|████████  | 213/266 [00:38<00:08,  6.26it/s]concatenating: train:  80%|████████  | 214/266 [00:38<00:07,  6.76it/s]concatenating: train:  81%|████████  | 215/266 [00:39<00:08,  5.98it/s]concatenating: train:  81%|████████  | 216/266 [00:39<00:08,  5.73it/s]concatenating: train:  82%|████████▏ | 217/266 [00:39<00:08,  5.68it/s]concatenating: train:  82%|████████▏ | 218/266 [00:39<00:08,  5.45it/s]concatenating: train:  82%|████████▏ | 219/266 [00:39<00:07,  6.08it/s]concatenating: train:  83%|████████▎ | 221/266 [00:39<00:06,  6.95it/s]concatenating: train:  83%|████████▎ | 222/266 [00:40<00:06,  6.32it/s]concatenating: train:  84%|████████▍ | 223/266 [00:40<00:08,  5.01it/s]concatenating: train:  84%|████████▍ | 224/266 [00:40<00:08,  4.92it/s]concatenating: train:  85%|████████▍ | 225/266 [00:40<00:08,  5.06it/s]concatenating: train:  85%|████████▍ | 226/266 [00:41<00:07,  5.01it/s]concatenating: train:  85%|████████▌ | 227/266 [00:41<00:07,  5.51it/s]concatenating: train:  86%|████████▌ | 228/266 [00:41<00:07,  5.38it/s]concatenating: train:  86%|████████▌ | 229/266 [00:41<00:06,  5.85it/s]concatenating: train:  86%|████████▋ | 230/266 [00:41<00:05,  6.52it/s]concatenating: train:  87%|████████▋ | 231/266 [00:41<00:04,  7.22it/s]concatenating: train:  87%|████████▋ | 232/266 [00:41<00:04,  6.90it/s]concatenating: train:  88%|████████▊ | 233/266 [00:42<00:05,  5.57it/s]concatenating: train:  88%|████████▊ | 234/266 [00:42<00:05,  5.92it/s]concatenating: train:  88%|████████▊ | 235/266 [00:42<00:05,  5.81it/s]concatenating: train:  89%|████████▊ | 236/266 [00:42<00:05,  5.77it/s]concatenating: train:  89%|████████▉ | 237/266 [00:42<00:05,  5.51it/s]concatenating: train:  89%|████████▉ | 238/266 [00:43<00:05,  5.12it/s]concatenating: train:  90%|████████▉ | 239/266 [00:43<00:05,  5.02it/s]concatenating: train:  90%|█████████ | 240/266 [00:43<00:04,  5.37it/s]concatenating: train:  91%|█████████ | 241/266 [00:43<00:04,  6.04it/s]concatenating: train:  91%|█████████ | 242/266 [00:43<00:03,  6.50it/s]concatenating: train:  91%|█████████▏| 243/266 [00:43<00:03,  6.01it/s]concatenating: train:  92%|█████████▏| 244/266 [00:44<00:03,  5.78it/s]concatenating: train:  92%|█████████▏| 245/266 [00:44<00:03,  5.91it/s]concatenating: train:  92%|█████████▏| 246/266 [00:44<00:03,  5.68it/s]concatenating: train:  93%|█████████▎| 247/266 [00:44<00:03,  6.19it/s]concatenating: train:  93%|█████████▎| 248/266 [00:44<00:02,  6.21it/s]concatenating: train:  94%|█████████▎| 249/266 [00:44<00:02,  6.62it/s]concatenating: train:  94%|█████████▍| 250/266 [00:45<00:02,  6.12it/s]concatenating: train:  94%|█████████▍| 251/266 [00:45<00:02,  6.30it/s]concatenating: train:  95%|█████████▍| 252/266 [00:45<00:02,  6.69it/s]concatenating: train:  95%|█████████▌| 253/266 [00:45<00:02,  6.21it/s]concatenating: train:  95%|█████████▌| 254/266 [00:45<00:01,  6.56it/s]concatenating: train:  96%|█████████▌| 255/266 [00:45<00:01,  6.62it/s]concatenating: train:  96%|█████████▌| 256/266 [00:45<00:01,  5.91it/s]concatenating: train:  97%|█████████▋| 257/266 [00:46<00:01,  6.32it/s]concatenating: train:  97%|█████████▋| 258/266 [00:46<00:01,  6.60it/s]concatenating: train:  98%|█████████▊| 260/266 [00:46<00:00,  7.87it/s]concatenating: train:  98%|█████████▊| 261/266 [00:46<00:00,  6.94it/s]concatenating: train:  98%|█████████▊| 262/266 [00:46<00:00,  6.12it/s]concatenating: train:  99%|█████████▉| 263/266 [00:46<00:00,  5.98it/s]concatenating: train:  99%|█████████▉| 264/266 [00:47<00:00,  4.89it/s]concatenating: train: 100%|█████████▉| 265/266 [00:47<00:00,  4.60it/s]concatenating: train: 100%|██████████| 266/266 [00:47<00:00,  5.41it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.38s/it]Loading test:  40%|████      | 2/5 [00:03<00:04,  1.47s/it]Loading test:  60%|██████    | 3/5 [00:04<00:03,  1.56s/it]Loading test:  80%|████████  | 4/5 [00:05<00:01,  1.40s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.29s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  4.64it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  5.18it/s]concatenating: validation:  60%|██████    | 3/5 [00:00<00:00,  5.39it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  5.58it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  6.11it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<03:35,  1.23it/s]Loading trainS:   1%|          | 2/266 [00:01<04:01,  1.09it/s]Loading trainS:   1%|          | 3/266 [00:03<04:30,  1.03s/it]Loading trainS:   2%|▏         | 4/266 [00:04<04:16,  1.02it/s]Loading trainS:   2%|▏         | 5/266 [00:04<03:48,  1.14it/s]Loading trainS:   2%|▏         | 6/266 [00:05<03:37,  1.20it/s]Loading trainS:   3%|▎         | 7/266 [00:06<04:22,  1.01s/it]Loading trainS:   3%|▎         | 8/266 [00:08<05:02,  1.17s/it]Loading trainS:   3%|▎         | 9/266 [00:09<05:18,  1.24s/it]Loading trainS:   4%|▍         | 10/266 [00:11<05:27,  1.28s/it]Loading trainS:   4%|▍         | 11/266 [00:12<05:10,  1.22s/it]Loading trainS:   5%|▍         | 12/266 [00:13<05:25,  1.28s/it]Loading trainS:   5%|▍         | 13/266 [00:15<06:08,  1.46s/it]Loading trainS:   5%|▌         | 14/266 [00:17<06:11,  1.48s/it]Loading trainS:   6%|▌         | 15/266 [00:18<06:24,  1.53s/it]Loading trainS:   6%|▌         | 16/266 [00:20<06:26,  1.54s/it]Loading trainS:   6%|▋         | 17/266 [00:21<06:27,  1.55s/it]Loading trainS:   7%|▋         | 18/266 [00:23<06:48,  1.65s/it]Loading trainS:   7%|▋         | 19/266 [00:25<06:32,  1.59s/it]Loading trainS:   8%|▊         | 20/266 [00:27<07:01,  1.71s/it]Loading trainS:   8%|▊         | 21/266 [00:28<06:35,  1.62s/it]Loading trainS:   8%|▊         | 22/266 [00:29<05:23,  1.32s/it]Loading trainS:   9%|▊         | 23/266 [00:30<05:00,  1.23s/it]Loading trainS:   9%|▉         | 24/266 [00:31<04:54,  1.22s/it]Loading trainS:   9%|▉         | 25/266 [00:32<05:08,  1.28s/it]Loading trainS:  10%|▉         | 26/266 [00:34<05:22,  1.34s/it]Loading trainS:  10%|█         | 27/266 [00:35<04:43,  1.19s/it]Loading trainS:  11%|█         | 28/266 [00:36<04:49,  1.22s/it]Loading trainS:  11%|█         | 29/266 [00:37<05:00,  1.27s/it]Loading trainS:  11%|█▏        | 30/266 [00:39<05:09,  1.31s/it]Loading trainS:  12%|█▏        | 31/266 [00:40<04:34,  1.17s/it]Loading trainS:  12%|█▏        | 32/266 [00:41<04:38,  1.19s/it]Loading trainS:  12%|█▏        | 33/266 [00:42<04:38,  1.20s/it]Loading trainS:  13%|█▎        | 34/266 [00:44<04:50,  1.25s/it]Loading trainS:  13%|█▎        | 35/266 [00:45<05:12,  1.35s/it]Loading trainS:  14%|█▎        | 36/266 [00:47<05:21,  1.40s/it]Loading trainS:  14%|█▍        | 37/266 [00:48<05:25,  1.42s/it]Loading trainS:  14%|█▍        | 38/266 [00:49<05:23,  1.42s/it]Loading trainS:  15%|█▍        | 39/266 [00:51<05:19,  1.41s/it]Loading trainS:  15%|█▌        | 40/266 [00:52<05:33,  1.47s/it]Loading trainS:  15%|█▌        | 41/266 [00:54<05:46,  1.54s/it]Loading trainS:  16%|█▌        | 42/266 [00:56<05:30,  1.48s/it]Loading trainS:  16%|█▌        | 43/266 [00:56<04:52,  1.31s/it]Loading trainS:  17%|█▋        | 44/266 [00:58<04:49,  1.31s/it]Loading trainS:  17%|█▋        | 45/266 [00:59<04:39,  1.27s/it]Loading trainS:  17%|█▋        | 46/266 [01:00<04:25,  1.21s/it]Loading trainS:  18%|█▊        | 47/266 [01:01<04:32,  1.24s/it]Loading trainS:  18%|█▊        | 48/266 [01:03<04:45,  1.31s/it]Loading trainS:  18%|█▊        | 49/266 [01:04<04:35,  1.27s/it]Loading trainS:  19%|█▉        | 50/266 [01:05<04:46,  1.32s/it]Loading trainS:  19%|█▉        | 51/266 [01:06<04:29,  1.25s/it]Loading trainS:  20%|█▉        | 52/266 [01:08<04:44,  1.33s/it]Loading trainS:  20%|█▉        | 53/266 [01:09<04:52,  1.37s/it]Loading trainS:  20%|██        | 54/266 [01:10<03:58,  1.13s/it]Loading trainS:  21%|██        | 55/266 [01:12<04:35,  1.30s/it]Loading trainS:  21%|██        | 56/266 [01:13<04:48,  1.38s/it]Loading trainS:  21%|██▏       | 57/266 [01:15<05:15,  1.51s/it]Loading trainS:  22%|██▏       | 58/266 [01:17<05:19,  1.54s/it]Loading trainS:  22%|██▏       | 59/266 [01:18<05:09,  1.49s/it]Loading trainS:  23%|██▎       | 60/266 [01:20<05:03,  1.47s/it]Loading trainS:  23%|██▎       | 61/266 [01:21<04:43,  1.38s/it]Loading trainS:  23%|██▎       | 62/266 [01:22<04:58,  1.47s/it]Loading trainS:  24%|██▎       | 63/266 [01:23<04:26,  1.31s/it]Loading trainS:  24%|██▍       | 64/266 [01:24<04:16,  1.27s/it]Loading trainS:  24%|██▍       | 65/266 [01:26<04:09,  1.24s/it]Loading trainS:  25%|██▍       | 66/266 [01:27<04:18,  1.29s/it]Loading trainS:  25%|██▌       | 67/266 [01:29<04:26,  1.34s/it]Loading trainS:  26%|██▌       | 68/266 [01:30<04:25,  1.34s/it]Loading trainS:  26%|██▌       | 69/266 [01:31<04:31,  1.38s/it]Loading trainS:  26%|██▋       | 70/266 [01:33<04:27,  1.37s/it]Loading trainS:  27%|██▋       | 71/266 [01:34<04:36,  1.42s/it]Loading trainS:  27%|██▋       | 72/266 [01:36<04:40,  1.45s/it]Loading trainS:  27%|██▋       | 73/266 [01:37<04:57,  1.54s/it]Loading trainS:  28%|██▊       | 74/266 [01:39<04:41,  1.47s/it]Loading trainS:  28%|██▊       | 75/266 [01:40<04:16,  1.34s/it]Loading trainS:  29%|██▊       | 76/266 [01:41<04:18,  1.36s/it]Loading trainS:  29%|██▉       | 77/266 [01:42<04:03,  1.29s/it]Loading trainS:  29%|██▉       | 78/266 [01:44<03:59,  1.27s/it]Loading trainS:  30%|██▉       | 79/266 [01:45<04:09,  1.33s/it]Loading trainS:  30%|███       | 80/266 [01:46<04:01,  1.30s/it]Loading trainS:  30%|███       | 81/266 [01:48<04:15,  1.38s/it]Loading trainS:  31%|███       | 82/266 [01:49<04:21,  1.42s/it]Loading trainS:  31%|███       | 83/266 [01:51<04:15,  1.40s/it]Loading trainS:  32%|███▏      | 84/266 [01:52<04:10,  1.38s/it]Loading trainS:  32%|███▏      | 85/266 [01:53<03:54,  1.30s/it]Loading trainS:  32%|███▏      | 86/266 [01:54<03:44,  1.25s/it]Loading trainS:  33%|███▎      | 87/266 [01:56<03:55,  1.32s/it]Loading trainS:  33%|███▎      | 88/266 [01:57<03:42,  1.25s/it]Loading trainS:  33%|███▎      | 89/266 [01:58<03:34,  1.21s/it]Loading trainS:  34%|███▍      | 90/266 [01:59<03:26,  1.18s/it]Loading trainS:  34%|███▍      | 91/266 [02:00<03:08,  1.08s/it]Loading trainS:  35%|███▍      | 92/266 [02:01<03:18,  1.14s/it]Loading trainS:  35%|███▍      | 93/266 [02:02<03:23,  1.18s/it]Loading trainS:  35%|███▌      | 94/266 [02:04<03:21,  1.17s/it]Loading trainS:  36%|███▌      | 95/266 [02:05<03:50,  1.35s/it]Loading trainS:  36%|███▌      | 96/266 [02:06<03:32,  1.25s/it]Loading trainS:  36%|███▋      | 97/266 [02:08<03:51,  1.37s/it]Loading trainS:  37%|███▋      | 98/266 [02:09<03:41,  1.32s/it]Loading trainS:  37%|███▋      | 99/266 [02:10<03:32,  1.27s/it]Loading trainS:  38%|███▊      | 100/266 [02:12<03:29,  1.26s/it]Loading trainS:  38%|███▊      | 101/266 [02:13<03:40,  1.34s/it]Loading trainS:  38%|███▊      | 102/266 [02:14<03:38,  1.33s/it]Loading trainS:  39%|███▊      | 103/266 [02:16<03:45,  1.39s/it]Loading trainS:  39%|███▉      | 104/266 [02:17<03:34,  1.33s/it]Loading trainS:  39%|███▉      | 105/266 [02:18<02:59,  1.12s/it]Loading trainS:  40%|███▉      | 106/266 [02:19<03:05,  1.16s/it]Loading trainS:  40%|████      | 107/266 [02:20<03:10,  1.20s/it]Loading trainS:  41%|████      | 108/266 [02:22<03:18,  1.26s/it]Loading trainS:  41%|████      | 109/266 [02:23<03:16,  1.25s/it]Loading trainS:  41%|████▏     | 110/266 [02:25<03:32,  1.36s/it]Loading trainS:  42%|████▏     | 111/266 [02:26<03:19,  1.29s/it]Loading trainS:  42%|████▏     | 112/266 [02:27<03:11,  1.25s/it]Loading trainS:  42%|████▏     | 113/266 [02:28<03:00,  1.18s/it]Loading trainS:  43%|████▎     | 114/266 [02:29<02:59,  1.18s/it]Loading trainS:  43%|████▎     | 115/266 [02:30<02:58,  1.18s/it]Loading trainS:  44%|████▎     | 116/266 [02:32<03:08,  1.26s/it]Loading trainS:  44%|████▍     | 117/266 [02:32<02:38,  1.06s/it]Loading trainS:  44%|████▍     | 118/266 [02:34<02:51,  1.16s/it]Loading trainS:  45%|████▍     | 119/266 [02:35<03:00,  1.23s/it]Loading trainS:  45%|████▌     | 120/266 [02:37<03:25,  1.41s/it]Loading trainS:  45%|████▌     | 121/266 [02:38<03:30,  1.45s/it]Loading trainS:  46%|████▌     | 122/266 [02:40<03:22,  1.40s/it]Loading trainS:  46%|████▌     | 123/266 [02:41<03:27,  1.45s/it]Loading trainS:  47%|████▋     | 124/266 [02:43<03:37,  1.53s/it]Loading trainS:  47%|████▋     | 125/266 [02:44<03:26,  1.46s/it]Loading trainS:  47%|████▋     | 126/266 [02:46<03:21,  1.44s/it]Loading trainS:  48%|████▊     | 127/266 [02:47<03:12,  1.39s/it]Loading trainS:  48%|████▊     | 128/266 [02:48<02:52,  1.25s/it]Loading trainS:  48%|████▊     | 129/266 [02:49<02:50,  1.24s/it]Loading trainS:  49%|████▉     | 130/266 [02:51<02:54,  1.29s/it]Loading trainS:  49%|████▉     | 131/266 [02:52<02:59,  1.33s/it]Loading trainS:  50%|████▉     | 132/266 [02:53<03:06,  1.39s/it]Loading trainS:  50%|█████     | 133/266 [02:55<03:03,  1.38s/it]Loading trainS:  50%|█████     | 134/266 [02:56<02:57,  1.34s/it]Loading trainS:  51%|█████     | 135/266 [02:58<02:57,  1.36s/it]Loading trainS:  51%|█████     | 136/266 [02:59<02:51,  1.32s/it]Loading trainS:  52%|█████▏    | 137/266 [02:59<02:25,  1.13s/it]Loading trainS:  52%|█████▏    | 138/266 [03:01<02:39,  1.25s/it]Loading trainS:  52%|█████▏    | 139/266 [03:02<02:41,  1.27s/it]Loading trainS:  53%|█████▎    | 140/266 [03:04<02:44,  1.31s/it]Loading trainS:  53%|█████▎    | 141/266 [03:05<02:57,  1.42s/it]Loading trainS:  53%|█████▎    | 142/266 [03:07<02:58,  1.44s/it]Loading trainS:  54%|█████▍    | 143/266 [03:08<02:51,  1.39s/it]Loading trainS:  54%|█████▍    | 144/266 [03:09<02:34,  1.27s/it]Loading trainS:  55%|█████▍    | 145/266 [03:11<02:40,  1.33s/it]Loading trainS:  55%|█████▍    | 146/266 [03:12<02:41,  1.34s/it]Loading trainS:  55%|█████▌    | 147/266 [03:13<02:42,  1.37s/it]Loading trainS:  56%|█████▌    | 148/266 [03:15<02:40,  1.36s/it]Loading trainS:  56%|█████▌    | 149/266 [03:16<02:27,  1.26s/it]Loading trainS:  56%|█████▋    | 150/266 [03:17<02:33,  1.33s/it]Loading trainS:  57%|█████▋    | 151/266 [03:19<02:36,  1.36s/it]Loading trainS:  57%|█████▋    | 152/266 [03:20<02:27,  1.29s/it]Loading trainS:  58%|█████▊    | 153/266 [03:21<02:21,  1.25s/it]Loading trainS:  58%|█████▊    | 154/266 [03:22<02:21,  1.27s/it]Loading trainS:  58%|█████▊    | 155/266 [03:24<02:23,  1.30s/it]Loading trainS:  59%|█████▊    | 156/266 [03:25<02:19,  1.26s/it]Loading trainS:  59%|█████▉    | 157/266 [03:26<02:00,  1.11s/it]Loading trainS:  59%|█████▉    | 158/266 [03:27<02:05,  1.16s/it]Loading trainS:  60%|█████▉    | 159/266 [03:28<02:03,  1.16s/it]Loading trainS:  60%|██████    | 160/266 [03:29<02:05,  1.19s/it]Loading trainS:  61%|██████    | 161/266 [03:31<02:09,  1.24s/it]Loading trainS:  61%|██████    | 162/266 [03:32<02:14,  1.30s/it]Loading trainS:  61%|██████▏   | 163/266 [03:33<02:07,  1.24s/it]Loading trainS:  62%|██████▏   | 164/266 [03:34<02:08,  1.26s/it]Loading trainS:  62%|██████▏   | 165/266 [03:36<02:05,  1.24s/it]Loading trainS:  62%|██████▏   | 166/266 [03:37<02:02,  1.23s/it]Loading trainS:  63%|██████▎   | 167/266 [03:38<02:06,  1.28s/it]Loading trainS:  63%|██████▎   | 168/266 [03:40<02:07,  1.30s/it]Loading trainS:  64%|██████▎   | 169/266 [03:41<02:05,  1.29s/it]Loading trainS:  64%|██████▍   | 170/266 [03:42<02:04,  1.29s/it]Loading trainS:  64%|██████▍   | 171/266 [03:43<02:02,  1.29s/it]Loading trainS:  65%|██████▍   | 172/266 [03:44<01:54,  1.22s/it]Loading trainS:  65%|██████▌   | 173/266 [03:46<01:53,  1.22s/it]Loading trainS:  65%|██████▌   | 174/266 [03:47<01:59,  1.30s/it]Loading trainS:  66%|██████▌   | 175/266 [03:48<01:49,  1.21s/it]Loading trainS:  66%|██████▌   | 176/266 [03:50<02:00,  1.34s/it]Loading trainS:  67%|██████▋   | 177/266 [03:51<01:56,  1.31s/it]Loading trainS:  67%|██████▋   | 178/266 [03:52<01:50,  1.25s/it]Loading trainS:  67%|██████▋   | 179/266 [03:54<01:52,  1.30s/it]Loading trainS:  68%|██████▊   | 180/266 [03:55<01:53,  1.32s/it]Loading trainS:  68%|██████▊   | 181/266 [03:56<01:48,  1.28s/it]Loading trainS:  68%|██████▊   | 182/266 [03:57<01:39,  1.19s/it]Loading trainS:  69%|██████▉   | 183/266 [03:58<01:39,  1.20s/it]Loading trainS:  69%|██████▉   | 184/266 [04:00<01:39,  1.21s/it]Loading trainS:  70%|██████▉   | 185/266 [04:01<01:43,  1.28s/it]Loading trainS:  70%|██████▉   | 186/266 [04:02<01:34,  1.18s/it]Loading trainS:  70%|███████   | 187/266 [04:03<01:22,  1.05s/it]Loading trainS:  71%|███████   | 188/266 [04:04<01:22,  1.06s/it]Loading trainS:  71%|███████   | 189/266 [04:05<01:29,  1.17s/it]Loading trainS:  71%|███████▏  | 190/266 [04:07<01:34,  1.25s/it]Loading trainS:  72%|███████▏  | 191/266 [04:08<01:34,  1.26s/it]Loading trainS:  72%|███████▏  | 192/266 [04:09<01:28,  1.20s/it]Loading trainS:  73%|███████▎  | 193/266 [04:11<01:38,  1.35s/it]Loading trainS:  73%|███████▎  | 194/266 [04:12<01:36,  1.33s/it]Loading trainS:  73%|███████▎  | 195/266 [04:13<01:29,  1.27s/it]Loading trainS:  74%|███████▎  | 196/266 [04:14<01:29,  1.28s/it]Loading trainS:  74%|███████▍  | 197/266 [04:16<01:34,  1.36s/it]Loading trainS:  74%|███████▍  | 198/266 [04:18<01:42,  1.50s/it]Loading trainS:  75%|███████▍  | 199/266 [04:19<01:37,  1.46s/it]Loading trainS:  75%|███████▌  | 200/266 [04:20<01:33,  1.42s/it]Loading trainS:  76%|███████▌  | 201/266 [04:22<01:25,  1.32s/it]Loading trainS:  76%|███████▌  | 202/266 [04:23<01:24,  1.32s/it]Loading trainS:  76%|███████▋  | 203/266 [04:24<01:25,  1.35s/it]Loading trainS:  77%|███████▋  | 204/266 [04:26<01:27,  1.42s/it]Loading trainS:  77%|███████▋  | 205/266 [04:27<01:26,  1.42s/it]Loading trainS:  77%|███████▋  | 206/266 [04:29<01:22,  1.38s/it]Loading trainS:  78%|███████▊  | 207/266 [04:30<01:24,  1.43s/it]Loading trainS:  78%|███████▊  | 208/266 [04:32<01:21,  1.41s/it]Loading trainS:  79%|███████▊  | 209/266 [04:32<01:12,  1.28s/it]Loading trainS:  79%|███████▉  | 210/266 [04:33<01:00,  1.09s/it]Loading trainS:  79%|███████▉  | 211/266 [04:34<01:03,  1.15s/it]Loading trainS:  80%|███████▉  | 212/266 [04:36<01:03,  1.18s/it]Loading trainS:  80%|████████  | 213/266 [04:37<01:07,  1.27s/it]Loading trainS:  80%|████████  | 214/266 [04:39<01:08,  1.31s/it]Loading trainS:  81%|████████  | 215/266 [04:40<01:05,  1.28s/it]Loading trainS:  81%|████████  | 216/266 [04:41<01:05,  1.32s/it]Loading trainS:  82%|████████▏ | 217/266 [04:43<01:05,  1.34s/it]Loading trainS:  82%|████████▏ | 218/266 [04:44<01:04,  1.34s/it]Loading trainS:  82%|████████▏ | 219/266 [04:45<00:57,  1.22s/it]Loading trainS:  83%|████████▎ | 220/266 [04:46<00:56,  1.22s/it]Loading trainS:  83%|████████▎ | 221/266 [04:47<00:53,  1.20s/it]Loading trainS:  83%|████████▎ | 222/266 [04:49<00:54,  1.24s/it]Loading trainS:  84%|████████▍ | 223/266 [04:50<00:55,  1.30s/it]Loading trainS:  84%|████████▍ | 224/266 [04:51<00:53,  1.28s/it]Loading trainS:  85%|████████▍ | 225/266 [04:53<00:54,  1.32s/it]Loading trainS:  85%|████████▍ | 226/266 [04:54<00:51,  1.28s/it]Loading trainS:  85%|████████▌ | 227/266 [04:55<00:48,  1.25s/it]Loading trainS:  86%|████████▌ | 228/266 [04:56<00:47,  1.24s/it]Loading trainS:  86%|████████▌ | 229/266 [04:57<00:44,  1.20s/it]Loading trainS:  86%|████████▋ | 230/266 [04:58<00:42,  1.18s/it]Loading trainS:  87%|████████▋ | 231/266 [04:59<00:39,  1.12s/it]Loading trainS:  87%|████████▋ | 232/266 [05:01<00:40,  1.21s/it]Loading trainS:  88%|████████▊ | 233/266 [05:02<00:41,  1.27s/it]Loading trainS:  88%|████████▊ | 234/266 [05:04<00:43,  1.36s/it]Loading trainS:  88%|████████▊ | 235/266 [05:05<00:43,  1.39s/it]Loading trainS:  89%|████████▊ | 236/266 [05:07<00:42,  1.40s/it]Loading trainS:  89%|████████▉ | 237/266 [05:08<00:38,  1.32s/it]Loading trainS:  89%|████████▉ | 238/266 [05:09<00:39,  1.41s/it]Loading trainS:  90%|████████▉ | 239/266 [05:11<00:40,  1.49s/it]Loading trainS:  90%|█████████ | 240/266 [05:13<00:40,  1.56s/it]Loading trainS:  91%|█████████ | 241/266 [05:14<00:35,  1.44s/it]Loading trainS:  91%|█████████ | 242/266 [05:15<00:28,  1.20s/it]Loading trainS:  91%|█████████▏| 243/266 [05:16<00:28,  1.22s/it]Loading trainS:  92%|█████████▏| 244/266 [05:17<00:27,  1.27s/it]Loading trainS:  92%|█████████▏| 245/266 [05:18<00:26,  1.25s/it]Loading trainS:  92%|█████████▏| 246/266 [05:20<00:25,  1.27s/it]Loading trainS:  93%|█████████▎| 247/266 [05:21<00:25,  1.34s/it]Loading trainS:  93%|█████████▎| 248/266 [05:23<00:24,  1.39s/it]Loading trainS:  94%|█████████▎| 249/266 [05:24<00:22,  1.31s/it]Loading trainS:  94%|█████████▍| 250/266 [05:25<00:21,  1.34s/it]Loading trainS:  94%|█████████▍| 251/266 [05:27<00:19,  1.32s/it]Loading trainS:  95%|█████████▍| 252/266 [05:28<00:18,  1.34s/it]Loading trainS:  95%|█████████▌| 253/266 [05:29<00:17,  1.36s/it]Loading trainS:  95%|█████████▌| 254/266 [05:31<00:16,  1.34s/it]Loading trainS:  96%|█████████▌| 255/266 [05:32<00:14,  1.29s/it]Loading trainS:  96%|█████████▌| 256/266 [05:33<00:12,  1.25s/it]Loading trainS:  97%|█████████▋| 257/266 [05:34<00:10,  1.13s/it]Loading trainS:  97%|█████████▋| 258/266 [05:35<00:09,  1.22s/it]Loading trainS:  97%|█████████▋| 259/266 [05:36<00:08,  1.16s/it]Loading trainS:  98%|█████████▊| 260/266 [05:37<00:06,  1.10s/it]Loading trainS:  98%|█████████▊| 261/266 [05:38<00:05,  1.04s/it]Loading trainS:  98%|█████████▊| 262/266 [05:39<00:04,  1.02s/it]Loading trainS:  99%|█████████▉| 263/266 [05:40<00:03,  1.06s/it]Loading trainS:  99%|█████████▉| 264/266 [05:41<00:02,  1.08s/it]Loading trainS: 100%|█████████▉| 265/266 [05:42<00:00,  1.01it/s]Loading trainS: 100%|██████████| 266/266 [05:43<00:00,  1.04s/it]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.31it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.29it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.30it/s]Loading testS:  80%|████████  | 4/5 [00:03<00:00,  1.14it/s]Loading testS: 100%|██████████| 5/5 [00:04<00:00,  1.11it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.41it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.52it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.77it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.54it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  7.55it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.19it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.39it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.95it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.19it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.30it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.95it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.34it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  9.04it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 11.22it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 11.39it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.28it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.02it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.94it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 95,902
Non-trainable params: 127,260
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 37s - loss: 0.3802 - acc: 0.9528 - mDice: 0.5570 - val_loss: 0.9900 - val_acc: 0.9786 - val_mDice: 0.5898

Epoch 00001: val_mDice improved from -inf to 0.58981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 33s - loss: 0.1433 - acc: 0.9857 - mDice: 0.7590 - val_loss: 0.8271 - val_acc: 0.9871 - val_mDice: 0.6789

Epoch 00002: val_mDice improved from 0.58981 to 0.67887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 32s - loss: 0.1203 - acc: 0.9878 - mDice: 0.7925 - val_loss: 0.8761 - val_acc: 0.9852 - val_mDice: 0.6751

Epoch 00003: val_mDice did not improve from 0.67887
Epoch 4/300
 - 32s - loss: 0.1089 - acc: 0.9888 - mDice: 0.8099 - val_loss: 0.8374 - val_acc: 0.9873 - val_mDice: 0.7051

Epoch 00004: val_mDice improved from 0.67887 to 0.70507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 32s - loss: 0.1017 - acc: 0.9895 - mDice: 0.8213 - val_loss: 0.8307 - val_acc: 0.9872 - val_mDice: 0.7059

Epoch 00005: val_mDice improved from 0.70507 to 0.70591, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 32s - loss: 0.0953 - acc: 0.9900 - mDice: 0.8314 - val_loss: 0.8069 - val_acc: 0.9892 - val_mDice: 0.7353

Epoch 00006: val_mDice improved from 0.70591 to 0.73533, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 32s - loss: 0.0905 - acc: 0.9905 - mDice: 0.8392 - val_loss: 0.8175 - val_acc: 0.9882 - val_mDice: 0.7226

Epoch 00007: val_mDice did not improve from 0.73533
Epoch 8/300
 - 32s - loss: 0.0880 - acc: 0.9907 - mDice: 0.8432 - val_loss: 0.7164 - val_acc: 0.9906 - val_mDice: 0.7497

Epoch 00008: val_mDice improved from 0.73533 to 0.74966, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 32s - loss: 0.0843 - acc: 0.9910 - mDice: 0.8492 - val_loss: 0.7702 - val_acc: 0.9904 - val_mDice: 0.7559

Epoch 00009: val_mDice improved from 0.74966 to 0.75590, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 32s - loss: 0.0813 - acc: 0.9913 - mDice: 0.8541 - val_loss: 0.7681 - val_acc: 0.9898 - val_mDice: 0.7459

Epoch 00010: val_mDice did not improve from 0.75590
Epoch 11/300
 - 32s - loss: 0.0797 - acc: 0.9915 - mDice: 0.8568 - val_loss: 0.7683 - val_acc: 0.9904 - val_mDice: 0.7565

Epoch 00011: val_mDice improved from 0.75590 to 0.75648, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 32s - loss: 0.0772 - acc: 0.9917 - mDice: 0.8610 - val_loss: 0.8074 - val_acc: 0.9892 - val_mDice: 0.7416

Epoch 00012: val_mDice did not improve from 0.75648
Epoch 13/300
 - 32s - loss: 0.0765 - acc: 0.9917 - mDice: 0.8622 - val_loss: 0.7894 - val_acc: 0.9893 - val_mDice: 0.7429

Epoch 00013: val_mDice did not improve from 0.75648
Epoch 14/300
 - 32s - loss: 0.0747 - acc: 0.9919 - mDice: 0.8651 - val_loss: 0.7542 - val_acc: 0.9906 - val_mDice: 0.7604

Epoch 00014: val_mDice improved from 0.75648 to 0.76037, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 32s - loss: 0.0734 - acc: 0.9921 - mDice: 0.8674 - val_loss: 0.8014 - val_acc: 0.9893 - val_mDice: 0.7439

Epoch 00015: val_mDice did not improve from 0.76037
Epoch 16/300
 - 32s - loss: 0.0721 - acc: 0.9921 - mDice: 0.8696 - val_loss: 0.7033 - val_acc: 0.9914 - val_mDice: 0.7678

Epoch 00016: val_mDice improved from 0.76037 to 0.76776, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 32s - loss: 0.0709 - acc: 0.9923 - mDice: 0.8715 - val_loss: 0.7412 - val_acc: 0.9909 - val_mDice: 0.7667

Epoch 00017: val_mDice did not improve from 0.76776
Epoch 18/300
 - 33s - loss: 0.0698 - acc: 0.9923 - mDice: 0.8734 - val_loss: 0.7505 - val_acc: 0.9906 - val_mDice: 0.7590

Epoch 00018: val_mDice did not improve from 0.76776
Epoch 19/300
 - 32s - loss: 0.0687 - acc: 0.9925 - mDice: 0.8754 - val_loss: 0.7278 - val_acc: 0.9914 - val_mDice: 0.7742

Epoch 00019: val_mDice improved from 0.76776 to 0.77423, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 32s - loss: 0.0677 - acc: 0.9925 - mDice: 0.8770 - val_loss: 0.7434 - val_acc: 0.9912 - val_mDice: 0.7701

Epoch 00020: val_mDice did not improve from 0.77423
Epoch 21/300
 - 32s - loss: 0.0675 - acc: 0.9926 - mDice: 0.8773 - val_loss: 0.7239 - val_acc: 0.9919 - val_mDice: 0.7818

Epoch 00021: val_mDice improved from 0.77423 to 0.78176, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 32s - loss: 0.0656 - acc: 0.9927 - mDice: 0.8806 - val_loss: 0.7310 - val_acc: 0.9918 - val_mDice: 0.7784

Epoch 00022: val_mDice did not improve from 0.78176
Epoch 23/300
 - 32s - loss: 0.0645 - acc: 0.9928 - mDice: 0.8825 - val_loss: 0.6762 - val_acc: 0.9920 - val_mDice: 0.7802

Epoch 00023: val_mDice did not improve from 0.78176
Epoch 24/300
 - 32s - loss: 0.0643 - acc: 0.9929 - mDice: 0.8828 - val_loss: 0.7362 - val_acc: 0.9916 - val_mDice: 0.7768

Epoch 00024: val_mDice did not improve from 0.78176
Epoch 25/300
 - 32s - loss: 0.0636 - acc: 0.9929 - mDice: 0.8839 - val_loss: 0.7396 - val_acc: 0.9914 - val_mDice: 0.7718

Epoch 00025: val_mDice did not improve from 0.78176
Epoch 26/300
 - 33s - loss: 0.0632 - acc: 0.9930 - mDice: 0.8846 - val_loss: 0.7396 - val_acc: 0.9917 - val_mDice: 0.7800

Epoch 00026: val_mDice did not improve from 0.78176
Epoch 27/300
 - 33s - loss: 0.0626 - acc: 0.9930 - mDice: 0.8857 - val_loss: 0.6670 - val_acc: 0.9921 - val_mDice: 0.7850

Epoch 00027: val_mDice improved from 0.78176 to 0.78502, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 32s - loss: 0.0618 - acc: 0.9931 - mDice: 0.8871 - val_loss: 0.7429 - val_acc: 0.9918 - val_mDice: 0.7846

Epoch 00028: val_mDice did not improve from 0.78502
Epoch 29/300
 - 32s - loss: 0.0617 - acc: 0.9931 - mDice: 0.8873 - val_loss: 0.7093 - val_acc: 0.9921 - val_mDice: 0.7813

Epoch 00029: val_mDice did not improve from 0.78502
Epoch 30/300
 - 33s - loss: 0.0603 - acc: 0.9932 - mDice: 0.8896 - val_loss: 0.7707 - val_acc: 0.9903 - val_mDice: 0.7610

Epoch 00030: val_mDice did not improve from 0.78502
Epoch 31/300
 - 33s - loss: 0.0603 - acc: 0.9932 - mDice: 0.8897 - val_loss: 0.7319 - val_acc: 0.9920 - val_mDice: 0.7814

Epoch 00031: val_mDice did not improve from 0.78502
Epoch 32/300
 - 33s - loss: 0.0592 - acc: 0.9933 - mDice: 0.8917 - val_loss: 0.7565 - val_acc: 0.9913 - val_mDice: 0.7768

Epoch 00032: val_mDice did not improve from 0.78502
Epoch 33/300
 - 33s - loss: 0.0589 - acc: 0.9933 - mDice: 0.8920 - val_loss: 0.7047 - val_acc: 0.9921 - val_mDice: 0.7804

Epoch 00033: val_mDice did not improve from 0.78502
Epoch 34/300
 - 33s - loss: 0.0580 - acc: 0.9934 - mDice: 0.8937 - val_loss: 0.7161 - val_acc: 0.9921 - val_mDice: 0.7840

Epoch 00034: val_mDice did not improve from 0.78502
Epoch 35/300
 - 32s - loss: 0.0580 - acc: 0.9934 - mDice: 0.8937 - val_loss: 0.7181 - val_acc: 0.9922 - val_mDice: 0.7889

Epoch 00035: val_mDice improved from 0.78502 to 0.78886, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 33s - loss: 0.0580 - acc: 0.9934 - mDice: 0.8936 - val_loss: 0.6511 - val_acc: 0.9924 - val_mDice: 0.7862

Epoch 00036: val_mDice did not improve from 0.78886
Epoch 37/300
 - 33s - loss: 0.0566 - acc: 0.9935 - mDice: 0.8960 - val_loss: 0.7120 - val_acc: 0.9922 - val_mDice: 0.7882

Epoch 00037: val_mDice did not improve from 0.78886
Epoch 38/300
 - 32s - loss: 0.0565 - acc: 0.9936 - mDice: 0.8963 - val_loss: 0.7112 - val_acc: 0.9922 - val_mDice: 0.7910

Epoch 00038: val_mDice improved from 0.78886 to 0.79100, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 33s - loss: 0.0560 - acc: 0.9936 - mDice: 0.8972 - val_loss: 0.7194 - val_acc: 0.9918 - val_mDice: 0.7828

Epoch 00039: val_mDice did not improve from 0.79100
Epoch 40/300
 - 33s - loss: 0.0559 - acc: 0.9936 - mDice: 0.8974 - val_loss: 0.7443 - val_acc: 0.9917 - val_mDice: 0.7840

Epoch 00040: val_mDice did not improve from 0.79100
Epoch 41/300
 - 32s - loss: 0.0551 - acc: 0.9937 - mDice: 0.8988 - val_loss: 0.7278 - val_acc: 0.9919 - val_mDice: 0.7844

Epoch 00041: val_mDice did not improve from 0.79100
Epoch 42/300
 - 32s - loss: 0.0557 - acc: 0.9936 - mDice: 0.8976 - val_loss: 0.6689 - val_acc: 0.9924 - val_mDice: 0.7894

Epoch 00042: val_mDice did not improve from 0.79100
Epoch 43/300
 - 33s - loss: 0.0544 - acc: 0.9938 - mDice: 0.9000 - val_loss: 0.7090 - val_acc: 0.9923 - val_mDice: 0.7916

Epoch 00043: val_mDice improved from 0.79100 to 0.79159, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 32s - loss: 0.0544 - acc: 0.9938 - mDice: 0.8999 - val_loss: 0.7484 - val_acc: 0.9917 - val_mDice: 0.7862

Epoch 00044: val_mDice did not improve from 0.79159
Epoch 45/300
 - 32s - loss: 0.0539 - acc: 0.9938 - mDice: 0.9007 - val_loss: 0.7552 - val_acc: 0.9908 - val_mDice: 0.7692

Epoch 00045: val_mDice did not improve from 0.79159
Epoch 46/300
 - 32s - loss: 0.0531 - acc: 0.9939 - mDice: 0.9023 - val_loss: 0.6331 - val_acc: 0.9926 - val_mDice: 0.7905

Epoch 00046: val_mDice did not improve from 0.79159
Epoch 47/300
 - 33s - loss: 0.0534 - acc: 0.9939 - mDice: 0.9016 - val_loss: 0.7377 - val_acc: 0.9920 - val_mDice: 0.7920

Epoch 00047: val_mDice improved from 0.79159 to 0.79198, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 32s - loss: 0.0529 - acc: 0.9939 - mDice: 0.9025 - val_loss: 0.7345 - val_acc: 0.9919 - val_mDice: 0.7909

Epoch 00048: val_mDice did not improve from 0.79198
Epoch 49/300
 - 32s - loss: 0.0526 - acc: 0.9939 - mDice: 0.9031 - val_loss: 0.6977 - val_acc: 0.9924 - val_mDice: 0.7944

Epoch 00049: val_mDice improved from 0.79198 to 0.79437, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 50/300
 - 32s - loss: 0.0522 - acc: 0.9940 - mDice: 0.9038 - val_loss: 0.6777 - val_acc: 0.9925 - val_mDice: 0.7922

Epoch 00050: val_mDice did not improve from 0.79437
Epoch 51/300
 - 32s - loss: 0.0523 - acc: 0.9940 - mDice: 0.9036 - val_loss: 0.6913 - val_acc: 0.9925 - val_mDice: 0.7918

Epoch 00051: val_mDice did not improve from 0.79437
Epoch 52/300
 - 32s - loss: 0.0521 - acc: 0.9940 - mDice: 0.9040 - val_loss: 0.6651 - val_acc: 0.9926 - val_mDice: 0.7889

Epoch 00052: val_mDice did not improve from 0.79437
Epoch 53/300
 - 32s - loss: 0.0520 - acc: 0.9940 - mDice: 0.9042 - val_loss: 0.6999 - val_acc: 0.9922 - val_mDice: 0.7913

Epoch 00053: val_mDice did not improve from 0.79437
Epoch 54/300
 - 32s - loss: 0.0517 - acc: 0.9940 - mDice: 0.9046 - val_loss: 0.7154 - val_acc: 0.9924 - val_mDice: 0.7979

Epoch 00054: val_mDice improved from 0.79437 to 0.79793, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 55/300
 - 32s - loss: 0.0510 - acc: 0.9941 - mDice: 0.9060 - val_loss: 0.6549 - val_acc: 0.9924 - val_mDice: 0.7899

Epoch 00055: val_mDice did not improve from 0.79793
Epoch 56/300
 - 32s - loss: 0.0518 - acc: 0.9940 - mDice: 0.9045 - val_loss: 0.6783 - val_acc: 0.9925 - val_mDice: 0.7977

Epoch 00056: val_mDice did not improve from 0.79793
Epoch 57/300
 - 31s - loss: 0.0506 - acc: 0.9941 - mDice: 0.9065 - val_loss: 0.6650 - val_acc: 0.9925 - val_mDice: 0.7983

Epoch 00057: val_mDice improved from 0.79793 to 0.79827, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 58/300
 - 32s - loss: 0.0508 - acc: 0.9941 - mDice: 0.9062 - val_loss: 0.7262 - val_acc: 0.9920 - val_mDice: 0.7902

Epoch 00058: val_mDice did not improve from 0.79827
Epoch 59/300
 - 32s - loss: 0.0504 - acc: 0.9941 - mDice: 0.9070 - val_loss: 0.6414 - val_acc: 0.9925 - val_mDice: 0.7976

Epoch 00059: val_mDice did not improve from 0.79827
Epoch 60/300
 - 32s - loss: 0.0506 - acc: 0.9942 - mDice: 0.9067 - val_loss: 0.6940 - val_acc: 0.9924 - val_mDice: 0.7957

Epoch 00060: val_mDice did not improve from 0.79827
Epoch 61/300
 - 32s - loss: 0.0496 - acc: 0.9942 - mDice: 0.9084 - val_loss: 0.6834 - val_acc: 0.9927 - val_mDice: 0.7997

Epoch 00061: val_mDice improved from 0.79827 to 0.79974, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 32s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.6710 - val_acc: 0.9926 - val_mDice: 0.7964

Epoch 00062: val_mDice did not improve from 0.79974
Epoch 63/300
 - 31s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9079 - val_loss: 0.7021 - val_acc: 0.9924 - val_mDice: 0.7978

Epoch 00063: val_mDice did not improve from 0.79974
Epoch 64/300
 - 32s - loss: 0.0495 - acc: 0.9942 - mDice: 0.9085 - val_loss: 0.6939 - val_acc: 0.9925 - val_mDice: 0.7988

Epoch 00064: val_mDice did not improve from 0.79974
Epoch 65/300
 - 32s - loss: 0.0490 - acc: 0.9943 - mDice: 0.9095 - val_loss: 0.6953 - val_acc: 0.9926 - val_mDice: 0.7988

Epoch 00065: val_mDice did not improve from 0.79974
Epoch 66/300
 - 31s - loss: 0.0491 - acc: 0.9943 - mDice: 0.9092 - val_loss: 0.6925 - val_acc: 0.9922 - val_mDice: 0.7953

Epoch 00066: val_mDice did not improve from 0.79974
Epoch 67/300
 - 32s - loss: 0.0485 - acc: 0.9943 - mDice: 0.9102 - val_loss: 0.6868 - val_acc: 0.9925 - val_mDice: 0.7968

Epoch 00067: val_mDice did not improve from 0.79974
Epoch 68/300
 - 31s - loss: 0.0482 - acc: 0.9944 - mDice: 0.9108 - val_loss: 0.6531 - val_acc: 0.9927 - val_mDice: 0.7994

Epoch 00068: val_mDice did not improve from 0.79974
Epoch 69/300
 - 31s - loss: 0.0485 - acc: 0.9943 - mDice: 0.9102 - val_loss: 0.5992 - val_acc: 0.9926 - val_mDice: 0.7974

Epoch 00069: val_mDice did not improve from 0.79974
Epoch 70/300
 - 31s - loss: 0.0483 - acc: 0.9944 - mDice: 0.9107 - val_loss: 0.6844 - val_acc: 0.9925 - val_mDice: 0.7969

Epoch 00070: val_mDice did not improve from 0.79974
Epoch 71/300
 - 32s - loss: 0.0481 - acc: 0.9944 - mDice: 0.9109 - val_loss: 0.6461 - val_acc: 0.9926 - val_mDice: 0.7967

Epoch 00071: val_mDice did not improve from 0.79974
Epoch 72/300
 - 31s - loss: 0.0479 - acc: 0.9944 - mDice: 0.9114 - val_loss: 0.6781 - val_acc: 0.9927 - val_mDice: 0.7998

Epoch 00072: val_mDice improved from 0.79974 to 0.79985, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 73/300
 - 31s - loss: 0.0474 - acc: 0.9944 - mDice: 0.9123 - val_loss: 0.7063 - val_acc: 0.9924 - val_mDice: 0.8002

Epoch 00073: val_mDice improved from 0.79985 to 0.80024, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 32s - loss: 0.0470 - acc: 0.9945 - mDice: 0.9129 - val_loss: 0.6824 - val_acc: 0.9917 - val_mDice: 0.7864

Epoch 00074: val_mDice did not improve from 0.80024
Epoch 75/300
 - 31s - loss: 0.0476 - acc: 0.9944 - mDice: 0.9120 - val_loss: 0.6431 - val_acc: 0.9927 - val_mDice: 0.7992

Epoch 00075: val_mDice did not improve from 0.80024
Epoch 76/300
 - 32s - loss: 0.0470 - acc: 0.9945 - mDice: 0.9130 - val_loss: 0.6957 - val_acc: 0.9925 - val_mDice: 0.7998

Epoch 00076: val_mDice did not improve from 0.80024
Epoch 77/300
 - 32s - loss: 0.0469 - acc: 0.9945 - mDice: 0.9131 - val_loss: 0.6687 - val_acc: 0.9924 - val_mDice: 0.7922

Epoch 00077: val_mDice did not improve from 0.80024
Epoch 78/300
 - 31s - loss: 0.0469 - acc: 0.9945 - mDice: 0.9132 - val_loss: 0.6821 - val_acc: 0.9925 - val_mDice: 0.7957

Epoch 00078: val_mDice did not improve from 0.80024
Epoch 79/300
 - 32s - loss: 0.0465 - acc: 0.9945 - mDice: 0.9139 - val_loss: 0.6988 - val_acc: 0.9924 - val_mDice: 0.7979

Epoch 00079: val_mDice did not improve from 0.80024
Epoch 80/300
 - 31s - loss: 0.0466 - acc: 0.9945 - mDice: 0.9137 - val_loss: 0.7004 - val_acc: 0.9923 - val_mDice: 0.7972

Epoch 00080: val_mDice did not improve from 0.80024
Epoch 81/300
 - 31s - loss: 0.0463 - acc: 0.9945 - mDice: 0.9142 - val_loss: 0.7046 - val_acc: 0.9923 - val_mDice: 0.7944

Epoch 00081: val_mDice did not improve from 0.80024
Epoch 82/300
 - 31s - loss: 0.0463 - acc: 0.9945 - mDice: 0.9142 - val_loss: 0.6606 - val_acc: 0.9925 - val_mDice: 0.7951

Epoch 00082: val_mDice did not improve from 0.80024
Epoch 83/300
 - 32s - loss: 0.0461 - acc: 0.9946 - mDice: 0.9145 - val_loss: 0.6517 - val_acc: 0.9924 - val_mDice: 0.7921

Epoch 00083: val_mDice did not improve from 0.80024
Epoch 84/300
 - 31s - loss: 0.0460 - acc: 0.9946 - mDice: 0.9148 - val_loss: 0.6681 - val_acc: 0.9925 - val_mDice: 0.8000

Epoch 00084: val_mDice did not improve from 0.80024
Epoch 85/300
 - 31s - loss: 0.0455 - acc: 0.9946 - mDice: 0.9156 - val_loss: 0.7187 - val_acc: 0.9921 - val_mDice: 0.7929

Epoch 00085: val_mDice did not improve from 0.80024
Epoch 86/300
 - 31s - loss: 0.0455 - acc: 0.9946 - mDice: 0.9156 - val_loss: 0.6844 - val_acc: 0.9925 - val_mDice: 0.7963

Epoch 00086: val_mDice did not improve from 0.80024
Epoch 87/300
 - 31s - loss: 0.0457 - acc: 0.9946 - mDice: 0.9153 - val_loss: 0.7004 - val_acc: 0.9922 - val_mDice: 0.7957

Epoch 00087: val_mDice did not improve from 0.80024
Epoch 88/300
 - 31s - loss: 0.0456 - acc: 0.9946 - mDice: 0.9154 - val_loss: 0.6194 - val_acc: 0.9927 - val_mDice: 0.8004

Epoch 00088: val_mDice improved from 0.80024 to 0.80038, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 89/300
 - 31s - loss: 0.0450 - acc: 0.9947 - mDice: 0.9165 - val_loss: 0.6077 - val_acc: 0.9926 - val_mDice: 0.7999

Epoch 00089: val_mDice did not improve from 0.80038
Epoch 90/300
 - 32s - loss: 0.0454 - acc: 0.9946 - mDice: 0.9157 - val_loss: 0.6823 - val_acc: 0.9926 - val_mDice: 0.7987

Epoch 00090: val_mDice did not improve from 0.80038
Epoch 91/300
 - 31s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9161 - val_loss: 0.6845 - val_acc: 0.9922 - val_mDice: 0.7894

Epoch 00091: val_mDice did not improve from 0.80038
Epoch 92/300
 - 32s - loss: 0.0449 - acc: 0.9947 - mDice: 0.9167 - val_loss: 0.6689 - val_acc: 0.9925 - val_mDice: 0.7975

Epoch 00092: val_mDice did not improve from 0.80038
Epoch 93/300
 - 32s - loss: 0.0446 - acc: 0.9947 - mDice: 0.9172 - val_loss: 0.7034 - val_acc: 0.9922 - val_mDice: 0.7979

Epoch 00093: val_mDice did not improve from 0.80038
Epoch 94/300
 - 31s - loss: 0.0452 - acc: 0.9946 - mDice: 0.9161 - val_loss: 0.6765 - val_acc: 0.9926 - val_mDice: 0.8008

Epoch 00094: val_mDice improved from 0.80038 to 0.80078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 95/300
 - 32s - loss: 0.0446 - acc: 0.9947 - mDice: 0.9172 - val_loss: 0.6737 - val_acc: 0.9924 - val_mDice: 0.7986

Epoch 00095: val_mDice did not improve from 0.80078
Epoch 96/300
 - 32s - loss: 0.0445 - acc: 0.9947 - mDice: 0.9173 - val_loss: 0.6798 - val_acc: 0.9925 - val_mDice: 0.7975

Epoch 00096: val_mDice did not improve from 0.80078
Epoch 97/300
 - 31s - loss: 0.0443 - acc: 0.9947 - mDice: 0.9178 - val_loss: 0.6867 - val_acc: 0.9922 - val_mDice: 0.7939

Epoch 00097: val_mDice did not improve from 0.80078
Epoch 98/300
 - 32s - loss: 0.0443 - acc: 0.9947 - mDice: 0.9178 - val_loss: 0.6951 - val_acc: 0.9924 - val_mDice: 0.7988

Epoch 00098: val_mDice did not improve from 0.80078
Epoch 99/300
 - 31s - loss: 0.0441 - acc: 0.9947 - mDice: 0.9182 - val_loss: 0.5411 - val_acc: 0.9924 - val_mDice: 0.7927

Epoch 00099: val_mDice did not improve from 0.80078
Epoch 100/300
 - 31s - loss: 0.0444 - acc: 0.9947 - mDice: 0.9176 - val_loss: 0.6896 - val_acc: 0.9924 - val_mDice: 0.7961

Epoch 00100: val_mDice did not improve from 0.80078
Epoch 101/300
 - 32s - loss: 0.0442 - acc: 0.9947 - mDice: 0.9179 - val_loss: 0.6590 - val_acc: 0.9924 - val_mDice: 0.7968

Epoch 00101: val_mDice did not improve from 0.80078
Epoch 102/300
 - 31s - loss: 0.0438 - acc: 0.9948 - mDice: 0.9186 - val_loss: 0.6512 - val_acc: 0.9925 - val_mDice: 0.8000

Epoch 00102: val_mDice did not improve from 0.80078
Epoch 103/300
 - 31s - loss: 0.0435 - acc: 0.9948 - mDice: 0.9192 - val_loss: 0.6834 - val_acc: 0.9923 - val_mDice: 0.7947

Epoch 00103: val_mDice did not improve from 0.80078
Epoch 104/300
 - 31s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9191 - val_loss: 0.6772 - val_acc: 0.9925 - val_mDice: 0.7987

Epoch 00104: val_mDice did not improve from 0.80078
Epoch 105/300
 - 32s - loss: 0.0431 - acc: 0.9948 - mDice: 0.9199 - val_loss: 0.6114 - val_acc: 0.9928 - val_mDice: 0.8040

Epoch 00105: val_mDice improved from 0.80078 to 0.80397, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 106/300
 - 31s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9195 - val_loss: 0.6264 - val_acc: 0.9926 - val_mDice: 0.8010

Epoch 00106: val_mDice did not improve from 0.80397
Epoch 107/300
 - 31s - loss: 0.0438 - acc: 0.9948 - mDice: 0.9187 - val_loss: 0.6764 - val_acc: 0.9922 - val_mDice: 0.7938

Epoch 00107: val_mDice did not improve from 0.80397
Epoch 108/300
 - 31s - loss: 0.0430 - acc: 0.9948 - mDice: 0.9201 - val_loss: 0.7146 - val_acc: 0.9917 - val_mDice: 0.7881

Epoch 00108: val_mDice did not improve from 0.80397
Epoch 109/300
 - 31s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9196 - val_loss: 0.6999 - val_acc: 0.9922 - val_mDice: 0.7981

Epoch 00109: val_mDice did not improve from 0.80397
Epoch 110/300
 - 32s - loss: 0.0429 - acc: 0.9948 - mDice: 0.9202 - val_loss: 0.6881 - val_acc: 0.9924 - val_mDice: 0.7988

Epoch 00110: val_mDice did not improve from 0.80397
Epoch 111/300
 - 31s - loss: 0.0432 - acc: 0.9948 - mDice: 0.9197 - val_loss: 0.6774 - val_acc: 0.9924 - val_mDice: 0.7940

Epoch 00111: val_mDice did not improve from 0.80397
Epoch 112/300
 - 31s - loss: 0.0432 - acc: 0.9948 - mDice: 0.9198 - val_loss: 0.6439 - val_acc: 0.9927 - val_mDice: 0.7995

Epoch 00112: val_mDice did not improve from 0.80397
Epoch 113/300
 - 31s - loss: 0.0430 - acc: 0.9948 - mDice: 0.9201 - val_loss: 0.6133 - val_acc: 0.9927 - val_mDice: 0.8000

Epoch 00113: val_mDice did not improve from 0.80397
Epoch 114/300
 - 31s - loss: 0.0426 - acc: 0.9949 - mDice: 0.9209 - val_loss: 0.6433 - val_acc: 0.9923 - val_mDice: 0.7981

Epoch 00114: val_mDice did not improve from 0.80397
Epoch 115/300
 - 31s - loss: 0.0432 - acc: 0.9948 - mDice: 0.9198 - val_loss: 0.6900 - val_acc: 0.9922 - val_mDice: 0.7932

Epoch 00115: val_mDice did not improve from 0.80397
Epoch 116/300
 - 31s - loss: 0.0425 - acc: 0.9949 - mDice: 0.9210 - val_loss: 0.6229 - val_acc: 0.9927 - val_mDice: 0.8012

Epoch 00116: val_mDice did not improve from 0.80397
Epoch 117/300
 - 31s - loss: 0.0426 - acc: 0.9949 - mDice: 0.9208 - val_loss: 0.7263 - val_acc: 0.9917 - val_mDice: 0.7858

Epoch 00117: val_mDice did not improve from 0.80397
Epoch 118/300
 - 31s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9214 - val_loss: 0.6922 - val_acc: 0.9924 - val_mDice: 0.7967

Epoch 00118: val_mDice did not improve from 0.80397
Epoch 119/300
 - 31s - loss: 0.0426 - acc: 0.9949 - mDice: 0.9207 - val_loss: 0.6363 - val_acc: 0.9928 - val_mDice: 0.8029

Epoch 00119: val_mDice did not improve from 0.80397
Epoch 120/300
 - 31s - loss: 0.0426 - acc: 0.9949 - mDice: 0.9209 - val_loss: 0.6832 - val_acc: 0.9923 - val_mDice: 0.7969

Epoch 00120: val_mDice did not improve from 0.80397
Epoch 121/300
 - 31s - loss: 0.0424 - acc: 0.9949 - mDice: 0.9211 - val_loss: 0.6930 - val_acc: 0.9922 - val_mDice: 0.7967

Epoch 00121: val_mDice did not improve from 0.80397
Epoch 122/300
 - 31s - loss: 0.0423 - acc: 0.9949 - mDice: 0.9212 - val_loss: 0.6922 - val_acc: 0.9922 - val_mDice: 0.7948

Epoch 00122: val_mDice did not improve from 0.80397
Epoch 123/300
 - 31s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9218 - val_loss: 0.7100 - val_acc: 0.9922 - val_mDice: 0.7973

Epoch 00123: val_mDice did not improve from 0.80397
Epoch 124/300
 - 32s - loss: 0.0423 - acc: 0.9949 - mDice: 0.9212 - val_loss: 0.6880 - val_acc: 0.9925 - val_mDice: 0.8021

Epoch 00124: val_mDice did not improve from 0.80397
Epoch 125/300
 - 32s - loss: 0.0419 - acc: 0.9949 - mDice: 0.9220 - val_loss: 0.6337 - val_acc: 0.9924 - val_mDice: 0.7939

Epoch 00125: val_mDice did not improve from 0.80397
Epoch 126/300
 - 32s - loss: 0.0418 - acc: 0.9949 - mDice: 0.9222 - val_loss: 0.6490 - val_acc: 0.9926 - val_mDice: 0.7992

Epoch 00126: val_mDice did not improve from 0.80397
Epoch 127/300
 - 32s - loss: 0.0419 - acc: 0.9949 - mDice: 0.9220 - val_loss: 0.6619 - val_acc: 0.9926 - val_mDice: 0.7982

Epoch 00127: val_mDice did not improve from 0.80397
Epoch 128/300
 - 32s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.7100 - val_acc: 0.9922 - val_mDice: 0.7966

Epoch 00128: val_mDice did not improve from 0.80397
Epoch 129/300
 - 33s - loss: 0.0419 - acc: 0.9949 - mDice: 0.9221 - val_loss: 0.6848 - val_acc: 0.9923 - val_mDice: 0.7978

Epoch 00129: val_mDice did not improve from 0.80397
Epoch 130/300
 - 33s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9227 - val_loss: 0.6959 - val_acc: 0.9923 - val_mDice: 0.7961

Epoch 00130: val_mDice did not improve from 0.80397
Epoch 131/300
 - 33s - loss: 0.0420 - acc: 0.9949 - mDice: 0.9218 - val_loss: 0.6501 - val_acc: 0.9927 - val_mDice: 0.7995

Epoch 00131: val_mDice did not improve from 0.80397
Epoch 132/300
 - 33s - loss: 0.0413 - acc: 0.9950 - mDice: 0.9232 - val_loss: 0.6711 - val_acc: 0.9925 - val_mDice: 0.7975

Epoch 00132: val_mDice did not improve from 0.80397
Epoch 133/300
 - 33s - loss: 0.0411 - acc: 0.9950 - mDice: 0.9234 - val_loss: 0.6877 - val_acc: 0.9925 - val_mDice: 0.7993

Epoch 00133: val_mDice did not improve from 0.80397
Epoch 134/300
 - 35s - loss: 0.0413 - acc: 0.9950 - mDice: 0.9231 - val_loss: 0.6596 - val_acc: 0.9926 - val_mDice: 0.7986

Epoch 00134: val_mDice did not improve from 0.80397
Epoch 135/300
 - 33s - loss: 0.0414 - acc: 0.9950 - mDice: 0.9229 - val_loss: 0.6416 - val_acc: 0.9925 - val_mDice: 0.7996

Epoch 00135: val_mDice did not improve from 0.80397
Epoch 136/300
 - 33s - loss: 0.0409 - acc: 0.9950 - mDice: 0.9238 - val_loss: 0.6944 - val_acc: 0.9922 - val_mDice: 0.7922

Epoch 00136: val_mDice did not improve from 0.80397
Epoch 137/300
 - 33s - loss: 0.0410 - acc: 0.9950 - mDice: 0.9236 - val_loss: 0.6822 - val_acc: 0.9926 - val_mDice: 0.8015

Epoch 00137: val_mDice did not improve from 0.80397
Epoch 138/300
 - 32s - loss: 0.0411 - acc: 0.9950 - mDice: 0.9235 - val_loss: 0.6437 - val_acc: 0.9926 - val_mDice: 0.8023

Epoch 00138: val_mDice did not improve from 0.80397
Epoch 139/300
 - 33s - loss: 0.0412 - acc: 0.9950 - mDice: 0.9233 - val_loss: 0.7284 - val_acc: 0.9921 - val_mDice: 0.7934

Epoch 00139: val_mDice did not improve from 0.80397
Epoch 140/300
 - 33s - loss: 0.0412 - acc: 0.9950 - mDice: 0.9234 - val_loss: 0.6825 - val_acc: 0.9924 - val_mDice: 0.8002

Epoch 00140: val_mDice did not improve from 0.80397
Epoch 141/300
 - 33s - loss: 0.0413 - acc: 0.9950 - mDice: 0.9231 - val_loss: 0.6927 - val_acc: 0.9926 - val_mDice: 0.8025

Epoch 00141: val_mDice did not improve from 0.80397
Epoch 142/300
 - 33s - loss: 0.0407 - acc: 0.9950 - mDice: 0.9242 - val_loss: 0.6452 - val_acc: 0.9926 - val_mDice: 0.7995

Epoch 00142: val_mDice did not improve from 0.80397
Epoch 143/300
 - 32s - loss: 0.0408 - acc: 0.9950 - mDice: 0.9240 - val_loss: 0.6462 - val_acc: 0.9926 - val_mDice: 0.8013

Epoch 00143: val_mDice did not improve from 0.80397
Epoch 144/300
 - 32s - loss: 0.0409 - acc: 0.9950 - mDice: 0.9239 - val_loss: 0.6880 - val_acc: 0.9925 - val_mDice: 0.8026

Epoch 00144: val_mDice did not improve from 0.80397
Epoch 145/300
 - 31s - loss: 0.0408 - acc: 0.9950 - mDice: 0.9240 - val_loss: 0.6789 - val_acc: 0.9925 - val_mDice: 0.7993

Epoch 00145: val_mDice did not improve from 0.80397
Restoring model weights from the end of the best epoch
Epoch 00145: early stopping
{'val_loss': [0.9899936374276876, 0.8271357351914048, 0.8761455067433417, 0.8374481832142919, 0.8307225268799812, 0.8068661512807012, 0.817530547035858, 0.7163829058408737, 0.77016572188586, 0.7680672646965832, 0.7683343775570393, 0.8074092466849834, 0.789397343294695, 0.7542258778121322, 0.8013860948849469, 0.7033487698063254, 0.741233252803795, 0.7505057114176452, 0.727773514110595, 0.7434436264447868, 0.723926090169698, 0.7309947512112558, 0.6761993672698736, 0.7361759560881183, 0.7396255249623209, 0.7395829297602177, 0.6670438396977261, 0.7428763521602377, 0.7092951615341008, 0.7706980739021674, 0.7319161868654191, 0.7565055900486186, 0.7046738057397306, 0.7161470025312155, 0.7180862817913294, 0.6511056362651289, 0.7120435538236052, 0.7112046420807019, 0.7194331367500126, 0.7442749787587672, 0.7277810550294816, 0.6688607309479266, 0.7089889459311962, 0.7484107124619186, 0.755177030689083, 0.6331051883753389, 0.7376661557937041, 0.7345479101641104, 0.6976702257525176, 0.6776592415990308, 0.6912570432759821, 0.6651244158856571, 0.6998767422046512, 0.7153597879223526, 0.6549432517495006, 0.6783307150471956, 0.6650430818554014, 0.7261826347094029, 0.6414338517934084, 0.6940053685102612, 0.6833925419487059, 0.6710069046821445, 0.7021021507680416, 0.6938751428388059, 0.6953212406951934, 0.6924762018024921, 0.6867654114030302, 0.6531208644155413, 0.5992422197014093, 0.6843929472379386, 0.646092691575177, 0.6781323719769716, 0.7063372754491866, 0.6824355500284582, 0.643082317430526, 0.6956874497700483, 0.6687200132291764, 0.6821393952704966, 0.6988464843016118, 0.7004054496064782, 0.7045614286325872, 0.660581644391641, 0.6516916849650443, 0.6681304923258722, 0.7187475904356688, 0.6843634729739279, 0.7004048252711073, 0.6193724561017007, 0.6077258069999516, 0.6823107295203954, 0.6844923610333353, 0.6688774835783988, 0.7033924080897123, 0.6765047509688884, 0.6737481155432761, 0.6798435379751027, 0.6867436256725341, 0.6950609707273543, 0.5410717527847737, 0.6896006816532463, 0.6589783770032227, 0.6512289135716856, 0.6833712684456259, 0.6771878248546273, 0.6113648116588593, 0.6263651712797582, 0.6763973985798657, 0.7145933727733791, 0.6998994264286011, 0.6881109061650932, 0.6774392323568463, 0.6439222062472254, 0.6133371975738555, 0.6432997875381261, 0.6899987494107336, 0.622901456663385, 0.7263440026436001, 0.6922396370209754, 0.6362942152190953, 0.6831716555170715, 0.6930236264597625, 0.6922443332150578, 0.710038383025676, 0.6880024031270295, 0.6337307221256196, 0.6489619400817901, 0.6618578045163304, 0.7100123567506671, 0.6847716141492128, 0.6959479285869747, 0.6501302269753069, 0.6710618273355067, 0.6877030034083873, 0.6596230268478394, 0.6415823048446327, 0.6943702856078744, 0.6822059568949044, 0.6437336325179785, 0.7283945155795664, 0.6825315649621189, 0.6927470241207629, 0.6451599125284702, 0.6461938449647278, 0.687976834597066, 0.6788931265473366], 'val_acc': [0.9786356035619974, 0.9870924297720194, 0.9852011483162642, 0.9873191677033901, 0.9872291162610054, 0.9891737494617701, 0.9881727509200573, 0.990622503682971, 0.990432184189558, 0.989779893308878, 0.9904000069946051, 0.9891612753272057, 0.9892622996121645, 0.9906215127557516, 0.9893032126128674, 0.9913618434220552, 0.9908554870635271, 0.9905521553009748, 0.9914134815335274, 0.9911882299929857, 0.9919310696423054, 0.991848012432456, 0.9919881969690323, 0.9915821198374033, 0.9913803040981293, 0.9917108248919249, 0.9921308867633343, 0.9917958807200193, 0.9920879732817411, 0.9903194438666105, 0.9920031670480967, 0.9912578370422125, 0.992119399830699, 0.99210618250072, 0.9922017119824886, 0.9923858195543289, 0.9921732749789953, 0.9922151826322079, 0.9918100982904434, 0.9917023349553347, 0.9918983969837427, 0.992416251450777, 0.992307735607028, 0.9917350150644779, 0.9907701816409826, 0.9926020707935095, 0.9919989127665758, 0.9918861817568541, 0.9923937879502773, 0.9925140142440796, 0.9924681354314089, 0.9925920944660902, 0.9921875055879354, 0.9923573713749647, 0.9924389291554689, 0.9924953114241362, 0.9924923181533813, 0.9919827152043581, 0.992513271048665, 0.9924374278634787, 0.9926584400236607, 0.9925801139324903, 0.9923563785851002, 0.9925411995500326, 0.9925514366477728, 0.9922403860837221, 0.9925442021340132, 0.9927287884056568, 0.9925908446311951, 0.9925364665687084, 0.9925711527466774, 0.9926851373165846, 0.9924446698278189, 0.9916808791458607, 0.992673410102725, 0.9924970529973507, 0.9924177341163158, 0.9924651123583317, 0.99242146871984, 0.992321191355586, 0.9922870229929686, 0.9924953188747168, 0.9924017693847418, 0.9925000444054604, 0.9921203963458538, 0.9925135187804699, 0.9921860136091709, 0.9926913678646088, 0.9926155470311642, 0.9926265086978674, 0.9922423753887415, 0.9925449453294277, 0.9922206699848175, 0.9926075525581837, 0.9923815596848726, 0.9925429504364729, 0.9922144338488579, 0.9923883005976677, 0.9924217313528061, 0.9923843126744032, 0.9923967700451612, 0.9925424661487341, 0.9922740608453751, 0.99252700060606, 0.9927806612104177, 0.992600329220295, 0.9922116994857788, 0.9916649162769318, 0.992249608039856, 0.9923546221107244, 0.9924352020025253, 0.9926589503884315, 0.9926771502941847, 0.992319205775857, 0.9921909812837839, 0.9927203096449375, 0.9916806370019913, 0.9923613537102938, 0.9927572309970856, 0.9923152178525925, 0.992237875238061, 0.9922281447798014, 0.9921682942658663, 0.9925237484276295, 0.9924164935946465, 0.9925651624798775, 0.9925561789423227, 0.9922328870743513, 0.9923349134624004, 0.9922890234738588, 0.9926529601216316, 0.9925205130130053, 0.9925349708646536, 0.9926025755703449, 0.9924913346767426, 0.9922074675559998, 0.9925631638616323, 0.9926472324877977, 0.9920899793505669, 0.9924157317727804, 0.9925803709775209, 0.9925870988518, 0.9925965890288353, 0.9925454463809729, 0.9924943167716265], 'val_mDice': [0.5898111080750823, 0.6788740307092667, 0.6750961765646935, 0.7050735875964165, 0.705906068906188, 0.7353332079946995, 0.722585404291749, 0.7496633473783731, 0.7559029944241047, 0.7459349650889635, 0.7564809452742338, 0.741552384570241, 0.7429184950888157, 0.7603739108890295, 0.7438750751316547, 0.7677566632628441, 0.7667187880724669, 0.7590286526829004, 0.7742292247712612, 0.7700645830482244, 0.7817629538476467, 0.7784366048872471, 0.7802057266235352, 0.7768100500106812, 0.7718017976731062, 0.7800297811627388, 0.7850198075175285, 0.784600330516696, 0.7812775764614344, 0.7610443327575922, 0.7814245950430632, 0.7768208719789982, 0.7804378774017096, 0.7839966099709272, 0.7888647727668285, 0.7862349972128868, 0.7882239762693644, 0.7910043094307184, 0.7827835809439421, 0.7839656993746758, 0.7843910064548254, 0.7894023600965738, 0.7915919180959463, 0.7861559558659792, 0.769214928150177, 0.7904601749032736, 0.7919784635305405, 0.7908638473600149, 0.7943724095821381, 0.7922030054032803, 0.7917937356978655, 0.7889215461909771, 0.7912823371589184, 0.7979341316968203, 0.7898539770394564, 0.7977434620261192, 0.798269035294652, 0.7901966013014317, 0.7976245321333408, 0.7957242615520954, 0.7997368555516005, 0.7963597122579813, 0.7977844774723053, 0.7987993583083153, 0.7987864129245281, 0.7952622789889574, 0.7968480605632067, 0.799444979056716, 0.7974344864487648, 0.7969334442168474, 0.796728515997529, 0.7998453080654144, 0.8002415392547846, 0.7863681390881538, 0.7992009539157152, 0.7998262345790863, 0.7921947538852692, 0.7956652902066708, 0.7978972978889942, 0.7972416840493679, 0.7944102305918932, 0.79511065967381, 0.7921275682747364, 0.7999772392213345, 0.792885348200798, 0.7962610945105553, 0.7956991344690323, 0.8003821782767773, 0.7999143656343222, 0.7986860815435648, 0.7894385699182749, 0.797541281208396, 0.7978833932429552, 0.8007789775729179, 0.798553079366684, 0.7975130900740623, 0.7939110323786736, 0.7988369464874268, 0.792687376961112, 0.7960834633558989, 0.7967880927026272, 0.7999607734382153, 0.794735923409462, 0.7986608985811472, 0.8039730321615934, 0.8010387420654297, 0.7938088476657867, 0.7881163153797388, 0.7980522885918617, 0.798839395865798, 0.7940170634537935, 0.7994628045707941, 0.8000276889652014, 0.7981101982295513, 0.7931756321340799, 0.8012140914797783, 0.785761009901762, 0.7967427652329206, 0.8029241114854813, 0.7969021517783403, 0.7967290561646223, 0.7948206085711718, 0.7972712256014347, 0.8020834345370531, 0.7939443830400705, 0.7991513516753912, 0.7982267718762159, 0.7965806033462286, 0.7978182006627321, 0.7960645481944084, 0.7995191775262356, 0.797450290992856, 0.7993402052670717, 0.7986380439251661, 0.7995802629739046, 0.7921552658081055, 0.8014879375696182, 0.8023172989487648, 0.7933610770851374, 0.8001673687249422, 0.8024575747549534, 0.7995440810918808, 0.8012774400413036, 0.8026313129812479, 0.7992877811193466], 'loss': [0.38020843208404015, 0.14333902128526416, 0.12028218659409887, 0.10894630477221928, 0.10170271050778362, 0.0953084038700586, 0.09046572631897377, 0.0880492119744214, 0.08430528603524465, 0.08134963852843023, 0.07971853499190516, 0.07721128714660104, 0.07651378100570644, 0.07473498426331894, 0.07339963872183473, 0.07206417418963557, 0.07092994897371734, 0.06981078324664397, 0.068671459697193, 0.06770748732929877, 0.06752456626090367, 0.06557154556903202, 0.06448716933170207, 0.06427202001127463, 0.06362620968619637, 0.06322953521736174, 0.06261500145491648, 0.061798997348462496, 0.06174297425370052, 0.06034416122879455, 0.06028363829238622, 0.05915508996095823, 0.05893512607612814, 0.05798001258230533, 0.05799335446691311, 0.05801038393531996, 0.05661404845655913, 0.056482409507181634, 0.05595769397408009, 0.05585508024166572, 0.055054951597239284, 0.055729071071571185, 0.05436687951532476, 0.05443536678825339, 0.0539403649626348, 0.05305683062058771, 0.0534162384828922, 0.05293405355338755, 0.05261390899521515, 0.052177052792112794, 0.05228316765510137, 0.052086786132951195, 0.051956536786106386, 0.051711023610422416, 0.05096746918687882, 0.05178755958014572, 0.05062275792980521, 0.050841258352498385, 0.05035807933574827, 0.05057588234271989, 0.04957090838367243, 0.0498173758539053, 0.04982762104106985, 0.04953031570404903, 0.048950221528900446, 0.049129664099796785, 0.04854262086758772, 0.04820698416707781, 0.0485419381374825, 0.04827922264156655, 0.048148580478073424, 0.04789473138861267, 0.04737174459536676, 0.047046819709148764, 0.04755829968942545, 0.04696878650037097, 0.04689397822870317, 0.046886835271083366, 0.046464021535045155, 0.04658060189259929, 0.046314017782040806, 0.04628316512840148, 0.04614500472703205, 0.04597582634327628, 0.04552166377605081, 0.0454950596205782, 0.04567027049541882, 0.045594188175551, 0.0449905712655232, 0.045430289277361285, 0.04521511811548802, 0.04491043435129413, 0.04462532751089925, 0.04523836788250149, 0.04459589056409242, 0.04453317432395878, 0.044286324925555356, 0.04429678855055063, 0.04407156116747996, 0.04439107649655026, 0.04424182315257156, 0.04380838526147742, 0.0434838797796686, 0.04356292894094286, 0.04309984079587123, 0.04330839866957758, 0.04376436378670491, 0.042971237080109595, 0.04325681555363946, 0.04289529153297445, 0.04323984985036919, 0.04317263818574385, 0.042992261753561356, 0.04255434954622259, 0.04315707547995041, 0.04249718940279148, 0.04260254333574168, 0.04224981529787711, 0.04262892702496798, 0.042562900933006284, 0.042401018561246756, 0.042342294597258356, 0.042033917895702516, 0.04234202137684156, 0.041935633986788415, 0.041798725337278304, 0.04193890050111595, 0.04217890413497277, 0.04187485658950724, 0.041526987061659346, 0.04204169137850689, 0.041250591883826467, 0.04114151362576862, 0.04130733532235295, 0.04144358227902226, 0.04094296067142003, 0.0410442321001964, 0.04111230413699844, 0.04117813465533127, 0.041156774987519115, 0.041329930607972624, 0.04068324468602276, 0.04079055296201088, 0.04087583014623163, 0.04081566242839389], 'acc': [0.952842594356477, 0.9856928091881872, 0.9877767229420917, 0.9888147665009178, 0.9894754911349932, 0.9900275304492819, 0.990490102956308, 0.9907436389062717, 0.9910398646695724, 0.9913164004155453, 0.9914621862160754, 0.9916785726691838, 0.9917446444421553, 0.9918916760815607, 0.9920500699715068, 0.9921416496169599, 0.99226776287228, 0.9923460268110047, 0.9924718615650591, 0.9925364998487475, 0.9925856704466487, 0.9927475862114136, 0.9928281472592705, 0.9928676204093037, 0.9929146148871223, 0.992962356864111, 0.9930381682036271, 0.9930791614486931, 0.993105198844767, 0.993211557623594, 0.9932257849275131, 0.9933365992626081, 0.9933483257822228, 0.9934283175700576, 0.9934213719426707, 0.9934426381624823, 0.9935368737637602, 0.993562613739097, 0.9936384342682685, 0.9936285392047222, 0.9936906050705004, 0.9936471720931283, 0.9937630945400479, 0.9937714661706459, 0.9938016327759579, 0.9938966645531861, 0.9938558420542711, 0.9939107191926915, 0.9939110911486663, 0.9939650686011299, 0.9939816221828534, 0.9939980523240294, 0.9939997125768878, 0.9940420248595156, 0.9941016183825228, 0.9940139475607825, 0.9941364956730346, 0.9941335172067055, 0.9941365921401778, 0.9941568094858299, 0.9942014452138817, 0.9942087484483618, 0.9942068333505019, 0.9942424318869937, 0.9942960700354981, 0.9942816318057895, 0.9943324674625935, 0.9943583500334039, 0.9943322028046745, 0.9943619346776545, 0.9943585038268221, 0.9943852315827697, 0.9944210027628997, 0.994467176307407, 0.9944186790543206, 0.9944797577696755, 0.9944840003364632, 0.9944696763507218, 0.9945097388990722, 0.9945185964456817, 0.994523563956472, 0.9945325305531966, 0.9945639257745709, 0.9945624858864622, 0.994602928569373, 0.9945805624025242, 0.9945897892943323, 0.9946024934700091, 0.994654271416206, 0.9946355965961019, 0.9946434194927807, 0.9946669397335289, 0.9946772961080788, 0.994648061210552, 0.9946688438965993, 0.9947004226687008, 0.9947236119641291, 0.9947105945160791, 0.9947442135717224, 0.9947178977159337, 0.9947231591571924, 0.9947786622447974, 0.994800153005216, 0.9947773410188926, 0.9948161606161495, 0.9947996901499071, 0.9947821441408067, 0.994848542981022, 0.9948245003772721, 0.9948379429940412, 0.9948155408303359, 0.994828051552341, 0.9948451332795547, 0.9948665374203732, 0.994827893950098, 0.9948653047254059, 0.9948610485922769, 0.9949150409753333, 0.9948689530601316, 0.9948740769751163, 0.9949054104173531, 0.9949096330605249, 0.9949297310168338, 0.9948971094923927, 0.994941688586683, 0.9949495899174512, 0.9949405477674937, 0.9949218650319593, 0.9949444573529717, 0.994961132401579, 0.9949178737160275, 0.9949826525037985, 0.9949874656810098, 0.9949775105419094, 0.9949654956180847, 0.9950171473952305, 0.9950040158209408, 0.9949901318029339, 0.9949901840738599, 0.9949796477981293, 0.9949842851738405, 0.9950299177475059, 0.9950358249507633, 0.9950188345522419, 0.9950153011193713], 'mDice': [0.5569801781120077, 0.7590110208724481, 0.7924721418419296, 0.8098816813402674, 0.8212586549207338, 0.8314240397553252, 0.8392284523530803, 0.8431679997777113, 0.8492438051361815, 0.8541477109630501, 0.8568440998723812, 0.8609863911839025, 0.8621560441460138, 0.8651253711516619, 0.8674134992411899, 0.8696164114904331, 0.87154445247782, 0.873410995502124, 0.8753978639886093, 0.8769787006072359, 0.8773149070430054, 0.880610381724514, 0.8824782198877358, 0.8828444733386451, 0.8839391091358264, 0.8846420676738415, 0.8857221583241409, 0.8870833189808507, 0.8872625617126673, 0.8896295026271922, 0.8896960075050887, 0.8916598004345779, 0.8920364433898873, 0.8936873497178472, 0.8936513747171172, 0.8936436056010438, 0.8960398644246996, 0.8962878048717733, 0.8972009438746508, 0.8973922926304551, 0.8987668194227328, 0.8976394435912596, 0.899961506301024, 0.8998525083875274, 0.9007273020541555, 0.9022701096905916, 0.9016474866764573, 0.9024747082119802, 0.90305357814126, 0.903820114482276, 0.9036227830530833, 0.9039667696505179, 0.904212952615825, 0.9046399109009265, 0.9059661436097552, 0.9044936391428343, 0.9065409993770799, 0.9061635669147261, 0.9070209624931568, 0.9066513600672969, 0.9084085209992645, 0.9079745132305127, 0.9079498192277037, 0.9084696051508511, 0.9094782824423222, 0.9091700866716282, 0.9102163953801626, 0.9108025494166972, 0.9102250596323785, 0.9106930482466489, 0.9109058714888023, 0.9113549925495111, 0.9122937400124693, 0.9128686811874951, 0.911966369655388, 0.9129873738965326, 0.9131227484408109, 0.9131635558706301, 0.9139032064448724, 0.9137103374901585, 0.9141710893997294, 0.9142149143605693, 0.9144557249577907, 0.9147814249028392, 0.9155860401147249, 0.9156279007815395, 0.9153068206154318, 0.915444219203808, 0.9165127617536943, 0.9157416454324936, 0.9161262302029156, 0.9166542242542022, 0.9171633663127076, 0.9160911737591378, 0.9172274344984325, 0.9173272129369416, 0.9177737363237696, 0.9177559737171932, 0.918153457508916, 0.9175799213400893, 0.9178534376644791, 0.9186210871379911, 0.9191999004750603, 0.919063544756751, 0.9198910273352718, 0.9195142225880123, 0.9187179059811664, 0.9201217901904755, 0.9196090963059385, 0.9202472464512266, 0.91965356769359, 0.9197672990344329, 0.920084339187053, 0.9208697420774858, 0.9197879630790516, 0.9209708134250191, 0.9207850078942539, 0.9214052229416804, 0.920735753446807, 0.9208517996597556, 0.9211467385389005, 0.9212455813430723, 0.9217925483831146, 0.9212440282705424, 0.9219672488351863, 0.9222213131730199, 0.9219767807930815, 0.9215447530591891, 0.9220765985594376, 0.9226981768960444, 0.9217963205323453, 0.9231990507577816, 0.9233950812032418, 0.9230978826522495, 0.9228600817121694, 0.9237506853948283, 0.9235756793226586, 0.9234577916606705, 0.9233379897110634, 0.9233724180173137, 0.923068383055253, 0.9242225321408167, 0.9240271074646952, 0.9238781535045132, 0.9239817151932458]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.12it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.42it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.80it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.10it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.43it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:25,  3.10it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:24,  3.11it/s]predicting train subjects:   1%|          | 3/266 [00:00<01:24,  3.12it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:22,  3.18it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:23,  3.12it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<01:22,  3.15it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:19,  3.27it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:18,  3.29it/s]predicting train subjects:   3%|▎         | 9/266 [00:02<01:17,  3.32it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:16,  3.34it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:14,  3.42it/s]predicting train subjects:   5%|▍         | 12/266 [00:03<01:14,  3.40it/s]predicting train subjects:   5%|▍         | 13/266 [00:03<01:12,  3.47it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:11,  3.53it/s]predicting train subjects:   6%|▌         | 15/266 [00:04<01:10,  3.56it/s]predicting train subjects:   6%|▌         | 16/266 [00:04<01:13,  3.42it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:14,  3.34it/s]predicting train subjects:   7%|▋         | 18/266 [00:05<01:11,  3.45it/s]predicting train subjects:   7%|▋         | 19/266 [00:05<01:12,  3.41it/s]predicting train subjects:   8%|▊         | 20/266 [00:05<01:12,  3.42it/s]predicting train subjects:   8%|▊         | 21/266 [00:06<01:10,  3.49it/s]predicting train subjects:   8%|▊         | 22/266 [00:06<01:09,  3.52it/s]predicting train subjects:   9%|▊         | 23/266 [00:06<01:09,  3.51it/s]predicting train subjects:   9%|▉         | 24/266 [00:07<01:08,  3.53it/s]predicting train subjects:   9%|▉         | 25/266 [00:07<01:07,  3.59it/s]predicting train subjects:  10%|▉         | 26/266 [00:07<01:06,  3.59it/s]predicting train subjects:  10%|█         | 27/266 [00:07<01:06,  3.57it/s]predicting train subjects:  11%|█         | 28/266 [00:08<01:05,  3.61it/s]predicting train subjects:  11%|█         | 29/266 [00:08<01:04,  3.67it/s]predicting train subjects:  11%|█▏        | 30/266 [00:08<01:05,  3.62it/s]predicting train subjects:  12%|█▏        | 31/266 [00:08<01:04,  3.67it/s]predicting train subjects:  12%|█▏        | 32/266 [00:09<01:04,  3.61it/s]predicting train subjects:  12%|█▏        | 33/266 [00:09<01:04,  3.61it/s]predicting train subjects:  13%|█▎        | 34/266 [00:09<01:04,  3.61it/s]predicting train subjects:  13%|█▎        | 35/266 [00:10<01:03,  3.64it/s]predicting train subjects:  14%|█▎        | 36/266 [00:10<01:02,  3.66it/s]predicting train subjects:  14%|█▍        | 37/266 [00:10<01:03,  3.61it/s]predicting train subjects:  14%|█▍        | 38/266 [00:10<01:06,  3.43it/s]predicting train subjects:  15%|█▍        | 39/266 [00:11<01:04,  3.54it/s]predicting train subjects:  15%|█▌        | 40/266 [00:11<01:02,  3.62it/s]predicting train subjects:  15%|█▌        | 41/266 [00:11<01:01,  3.66it/s]predicting train subjects:  16%|█▌        | 42/266 [00:12<01:01,  3.65it/s]predicting train subjects:  16%|█▌        | 43/266 [00:12<00:57,  3.88it/s]predicting train subjects:  17%|█▋        | 44/266 [00:12<00:54,  4.09it/s]predicting train subjects:  17%|█▋        | 45/266 [00:12<00:52,  4.18it/s]predicting train subjects:  17%|█▋        | 46/266 [00:12<00:51,  4.28it/s]predicting train subjects:  18%|█▊        | 47/266 [00:13<00:50,  4.36it/s]predicting train subjects:  18%|█▊        | 48/266 [00:13<00:50,  4.30it/s]predicting train subjects:  18%|█▊        | 49/266 [00:13<00:49,  4.35it/s]predicting train subjects:  19%|█▉        | 50/266 [00:13<00:49,  4.40it/s]predicting train subjects:  19%|█▉        | 51/266 [00:14<00:48,  4.45it/s]predicting train subjects:  20%|█▉        | 52/266 [00:14<00:48,  4.45it/s]predicting train subjects:  20%|█▉        | 53/266 [00:14<00:47,  4.50it/s]predicting train subjects:  20%|██        | 54/266 [00:14<00:47,  4.49it/s]predicting train subjects:  21%|██        | 55/266 [00:14<00:47,  4.40it/s]predicting train subjects:  21%|██        | 56/266 [00:15<00:46,  4.47it/s]predicting train subjects:  21%|██▏       | 57/266 [00:15<00:49,  4.25it/s]predicting train subjects:  22%|██▏       | 58/266 [00:15<00:49,  4.19it/s]predicting train subjects:  22%|██▏       | 59/266 [00:15<00:48,  4.28it/s]predicting train subjects:  23%|██▎       | 60/266 [00:16<00:47,  4.35it/s]predicting train subjects:  23%|██▎       | 61/266 [00:16<00:48,  4.21it/s]predicting train subjects:  23%|██▎       | 62/266 [00:16<00:47,  4.25it/s]predicting train subjects:  24%|██▎       | 63/266 [00:16<00:49,  4.12it/s]predicting train subjects:  24%|██▍       | 64/266 [00:17<00:51,  3.95it/s]predicting train subjects:  24%|██▍       | 65/266 [00:17<00:49,  4.04it/s]predicting train subjects:  25%|██▍       | 66/266 [00:17<00:48,  4.15it/s]predicting train subjects:  25%|██▌       | 67/266 [00:17<00:45,  4.35it/s]predicting train subjects:  26%|██▌       | 68/266 [00:18<00:46,  4.29it/s]predicting train subjects:  26%|██▌       | 69/266 [00:18<00:46,  4.25it/s]predicting train subjects:  26%|██▋       | 70/266 [00:18<00:44,  4.38it/s]predicting train subjects:  27%|██▋       | 71/266 [00:18<00:43,  4.52it/s]predicting train subjects:  27%|██▋       | 72/266 [00:18<00:43,  4.45it/s]predicting train subjects:  27%|██▋       | 73/266 [00:19<00:42,  4.57it/s]predicting train subjects:  28%|██▊       | 74/266 [00:19<00:41,  4.58it/s]predicting train subjects:  28%|██▊       | 75/266 [00:19<00:41,  4.63it/s]predicting train subjects:  29%|██▊       | 76/266 [00:19<00:40,  4.65it/s]predicting train subjects:  29%|██▉       | 77/266 [00:19<00:40,  4.70it/s]predicting train subjects:  29%|██▉       | 78/266 [00:20<00:45,  4.17it/s]predicting train subjects:  30%|██▉       | 79/266 [00:20<00:48,  3.89it/s]predicting train subjects:  30%|███       | 80/266 [00:20<00:48,  3.80it/s]predicting train subjects:  30%|███       | 81/266 [00:21<00:50,  3.65it/s]predicting train subjects:  31%|███       | 82/266 [00:21<00:50,  3.65it/s]predicting train subjects:  31%|███       | 83/266 [00:21<00:50,  3.60it/s]predicting train subjects:  32%|███▏      | 84/266 [00:22<00:50,  3.63it/s]predicting train subjects:  32%|███▏      | 85/266 [00:22<00:49,  3.64it/s]predicting train subjects:  32%|███▏      | 86/266 [00:22<00:49,  3.65it/s]predicting train subjects:  33%|███▎      | 87/266 [00:22<00:49,  3.61it/s]predicting train subjects:  33%|███▎      | 88/266 [00:23<00:50,  3.55it/s]predicting train subjects:  33%|███▎      | 89/266 [00:23<00:49,  3.59it/s]predicting train subjects:  34%|███▍      | 90/266 [00:23<00:48,  3.61it/s]predicting train subjects:  34%|███▍      | 91/266 [00:23<00:50,  3.46it/s]predicting train subjects:  35%|███▍      | 92/266 [00:24<00:49,  3.53it/s]predicting train subjects:  35%|███▍      | 93/266 [00:24<00:48,  3.58it/s]predicting train subjects:  35%|███▌      | 94/266 [00:24<00:47,  3.61it/s]predicting train subjects:  36%|███▌      | 95/266 [00:25<00:47,  3.62it/s]predicting train subjects:  36%|███▌      | 96/266 [00:25<00:50,  3.37it/s]predicting train subjects:  36%|███▋      | 97/266 [00:25<00:50,  3.36it/s]predicting train subjects:  37%|███▋      | 98/266 [00:26<00:51,  3.28it/s]predicting train subjects:  37%|███▋      | 99/266 [00:26<00:48,  3.42it/s]predicting train subjects:  38%|███▊      | 100/266 [00:26<00:45,  3.68it/s]predicting train subjects:  38%|███▊      | 101/266 [00:26<00:42,  3.89it/s]predicting train subjects:  38%|███▊      | 102/266 [00:26<00:40,  4.05it/s]predicting train subjects:  39%|███▊      | 103/266 [00:27<00:39,  4.15it/s]predicting train subjects:  39%|███▉      | 104/266 [00:27<00:38,  4.24it/s]predicting train subjects:  39%|███▉      | 105/266 [00:27<00:37,  4.31it/s]predicting train subjects:  40%|███▉      | 106/266 [00:27<00:37,  4.32it/s]predicting train subjects:  40%|████      | 107/266 [00:28<00:37,  4.27it/s]predicting train subjects:  41%|████      | 108/266 [00:28<00:37,  4.26it/s]predicting train subjects:  41%|████      | 109/266 [00:28<00:36,  4.33it/s]predicting train subjects:  41%|████▏     | 110/266 [00:28<00:36,  4.33it/s]predicting train subjects:  42%|████▏     | 111/266 [00:29<00:36,  4.27it/s]predicting train subjects:  42%|████▏     | 112/266 [00:29<00:35,  4.32it/s]predicting train subjects:  42%|████▏     | 113/266 [00:29<00:37,  4.09it/s]predicting train subjects:  43%|████▎     | 114/266 [00:29<00:38,  3.91it/s]predicting train subjects:  43%|████▎     | 115/266 [00:30<00:37,  3.99it/s]predicting train subjects:  44%|████▎     | 116/266 [00:30<00:38,  3.89it/s]predicting train subjects:  44%|████▍     | 117/266 [00:30<00:36,  4.08it/s]predicting train subjects:  44%|████▍     | 118/266 [00:30<00:35,  4.13it/s]predicting train subjects:  45%|████▍     | 119/266 [00:31<00:36,  3.99it/s]predicting train subjects:  45%|████▌     | 120/266 [00:31<00:37,  3.85it/s]predicting train subjects:  45%|████▌     | 121/266 [00:31<00:38,  3.81it/s]predicting train subjects:  46%|████▌     | 122/266 [00:31<00:40,  3.57it/s]predicting train subjects:  46%|████▌     | 123/266 [00:32<00:42,  3.39it/s]predicting train subjects:  47%|████▋     | 124/266 [00:32<00:41,  3.45it/s]predicting train subjects:  47%|████▋     | 125/266 [00:32<00:42,  3.35it/s]predicting train subjects:  47%|████▋     | 126/266 [00:33<00:41,  3.34it/s]predicting train subjects:  48%|████▊     | 127/266 [00:33<00:42,  3.26it/s]predicting train subjects:  48%|████▊     | 128/266 [00:33<00:41,  3.32it/s]predicting train subjects:  48%|████▊     | 129/266 [00:34<00:40,  3.42it/s]predicting train subjects:  49%|████▉     | 130/266 [00:34<00:38,  3.51it/s]predicting train subjects:  49%|████▉     | 131/266 [00:34<00:38,  3.51it/s]predicting train subjects:  50%|████▉     | 132/266 [00:34<00:38,  3.48it/s]predicting train subjects:  50%|█████     | 133/266 [00:35<00:37,  3.52it/s]predicting train subjects:  50%|█████     | 134/266 [00:35<00:37,  3.49it/s]predicting train subjects:  51%|█████     | 135/266 [00:35<00:37,  3.51it/s]predicting train subjects:  51%|█████     | 136/266 [00:36<00:38,  3.41it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:36<00:37,  3.46it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:36<00:35,  3.61it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:36<00:35,  3.61it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:37<00:33,  3.73it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:37<00:33,  3.77it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:37<00:34,  3.55it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:37<00:34,  3.54it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:38<00:33,  3.67it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:38<00:33,  3.56it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:38<00:32,  3.66it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:39<00:33,  3.56it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:39<00:32,  3.60it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:39<00:31,  3.69it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:39<00:32,  3.58it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:40<00:32,  3.51it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:40<00:31,  3.64it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:40<00:30,  3.73it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:40<00:29,  3.77it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:41<00:26,  4.12it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:41<00:24,  4.43it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:41<00:24,  4.52it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:41<00:24,  4.40it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:42<00:24,  4.35it/s]predicting train subjects:  60%|██████    | 160/266 [00:42<00:22,  4.61it/s]predicting train subjects:  61%|██████    | 161/266 [00:42<00:21,  4.83it/s]predicting train subjects:  61%|██████    | 162/266 [00:42<00:21,  4.95it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:42<00:20,  5.06it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:42<00:20,  4.90it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:43<00:19,  5.07it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:43<00:20,  4.79it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:43<00:20,  4.93it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:43<00:19,  5.03it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:43<00:19,  5.04it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:44<00:18,  5.08it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:44<00:18,  5.12it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:44<00:18,  5.20it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:44<00:18,  4.92it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:45<00:19,  4.79it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:45<00:19,  4.74it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:45<00:19,  4.65it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:45<00:19,  4.60it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:45<00:20,  4.21it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:46<00:21,  3.95it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:46<00:21,  4.00it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:46<00:23,  3.58it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:47<00:25,  3.27it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:47<00:26,  3.14it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:47<00:26,  3.06it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:48<00:26,  3.05it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:48<00:25,  3.16it/s]predicting train subjects:  70%|███████   | 187/266 [00:48<00:26,  3.00it/s]predicting train subjects:  71%|███████   | 188/266 [00:49<00:27,  2.86it/s]predicting train subjects:  71%|███████   | 189/266 [00:49<00:26,  2.88it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:49<00:25,  2.94it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:50<00:24,  3.06it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:50<00:26,  2.80it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:50<00:25,  2.90it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:51<00:25,  2.84it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:51<00:24,  2.96it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:51<00:23,  3.04it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:52<00:22,  3.04it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:52<00:21,  3.13it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:52<00:21,  3.17it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:53<00:21,  3.11it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:53<00:20,  3.17it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:53<00:21,  2.91it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:54<00:20,  3.02it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:54<00:20,  3.08it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:54<00:20,  2.97it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:55<00:19,  3.04it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:55<00:19,  3.10it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:55<00:19,  2.97it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:56<00:19,  2.92it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:56<00:19,  2.90it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:56<00:18,  3.00it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:57<00:18,  2.99it/s]predicting train subjects:  80%|████████  | 213/266 [00:57<00:18,  2.88it/s]predicting train subjects:  80%|████████  | 214/266 [00:57<00:17,  3.00it/s]predicting train subjects:  81%|████████  | 215/266 [00:58<00:16,  3.18it/s]predicting train subjects:  81%|████████  | 216/266 [00:58<00:15,  3.17it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:58<00:15,  3.16it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:59<00:16,  2.97it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:59<00:14,  3.21it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:59<00:13,  3.33it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:00<00:13,  3.39it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:00<00:13,  3.32it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:00<00:13,  3.13it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:01<00:13,  3.20it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:01<00:12,  3.19it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:01<00:12,  3.08it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:01<00:12,  3.17it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:02<00:11,  3.18it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:02<00:12,  3.03it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:02<00:12,  2.98it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:03<00:12,  2.84it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:03<00:12,  2.78it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:04<00:11,  2.77it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:04<00:11,  2.85it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:04<00:11,  2.77it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:05<00:11,  2.68it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:05<00:10,  2.66it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:05<00:10,  2.68it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:06<00:09,  2.75it/s]predicting train subjects:  90%|█████████ | 240/266 [01:06<00:10,  2.55it/s]predicting train subjects:  91%|█████████ | 241/266 [01:07<00:09,  2.62it/s]predicting train subjects:  91%|█████████ | 242/266 [01:07<00:08,  2.75it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:07<00:08,  2.66it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:08<00:08,  2.67it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:08<00:08,  2.55it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:09<00:08,  2.45it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:09<00:07,  2.67it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:09<00:06,  2.73it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:10<00:06,  2.60it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:10<00:06,  2.43it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:11<00:06,  2.36it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:11<00:05,  2.34it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:12<00:05,  2.27it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:12<00:05,  2.36it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:12<00:05,  2.12it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:13<00:04,  2.20it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:13<00:03,  2.34it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:14<00:03,  2.29it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:14<00:03,  2.27it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:15<00:02,  2.13it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:15<00:02,  1.99it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:16<00:01,  2.00it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:16<00:01,  1.92it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:17<00:00,  2.02it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:17<00:00,  2.09it/s]predicting train subjects: 100%|██████████| 266/266 [01:18<00:00,  2.24it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:01,  2.06it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:01,  2.22it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:01<00:00,  2.38it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:01<00:00,  2.43it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:02<00:00,  2.34it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<02:14,  1.96it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<02:10,  2.03it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<02:01,  2.17it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:53,  2.31it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:02<01:54,  2.27it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:02<02:03,  2.11it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:03<02:02,  2.11it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:03<02:02,  2.10it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:04<02:00,  2.13it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:04<01:58,  2.15it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:05<01:59,  2.13it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:05<01:56,  2.18it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:05<01:55,  2.18it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:06<01:54,  2.21it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:06<01:56,  2.15it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:07<01:52,  2.23it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:07<01:54,  2.18it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:08<01:53,  2.18it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:08<01:51,  2.21it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:09<01:56,  2.12it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:09<01:56,  2.10it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:10<01:47,  2.27it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:10<01:46,  2.29it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:10<01:50,  2.19it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:11<01:53,  2.13it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:11<01:56,  2.07it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:12<01:53,  2.11it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:12<01:55,  2.05it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:13<01:55,  2.05it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:13<01:57,  2.02it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:14<02:02,  1.92it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:15<02:01,  1.92it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:15<01:57,  1.98it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:16<01:55,  2.00it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:16<01:51,  2.06it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:16<01:51,  2.06it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:17<01:48,  2.11it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:17<01:47,  2.12it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:18<01:46,  2.14it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:18<01:44,  2.16it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:19<01:37,  2.31it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:19<01:33,  2.39it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:19<01:34,  2.35it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:20<01:34,  2.34it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:20<01:35,  2.31it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:21<01:34,  2.34it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:21<01:32,  2.37it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:22<01:26,  2.52it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:22<01:22,  2.64it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:22<01:21,  2.66it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:23<01:19,  2.71it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:23<01:16,  2.82it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:23<01:14,  2.85it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:24<01:13,  2.87it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:24<01:12,  2.93it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:24<01:16,  2.76it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:25<01:16,  2.74it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:25<01:18,  2.65it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:26<01:21,  2.53it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:26<01:24,  2.43it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:26<01:23,  2.45it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:27<01:21,  2.50it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:27<01:19,  2.56it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:28<01:21,  2.46it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:28<01:19,  2.51it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:28<01:14,  2.68it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:29<01:14,  2.69it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:29<01:14,  2.65it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:29<01:14,  2.65it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:30<01:14,  2.62it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:30<01:14,  2.61it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:31<01:17,  2.51it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:31<01:19,  2.41it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:31<01:15,  2.53it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:32<01:16,  2.51it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:32<01:19,  2.39it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:33<01:17,  2.43it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:33<01:22,  2.29it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:34<01:27,  2.14it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:34<01:27,  2.14it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:35<01:34,  1.97it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:35<01:38,  1.87it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:36<01:32,  1.98it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:36<01:36,  1.88it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:37<01:32,  1.95it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:37<01:33,  1.93it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:38<01:27,  2.04it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:38<01:31,  1.95it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:39<01:28,  1.99it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:39<01:34,  1.86it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:40<01:37,  1.79it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:41<01:31,  1.91it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:41<01:32,  1.87it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:42<01:33,  1.84it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:42<01:33,  1.84it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:43<01:26,  1.96it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:43<01:26,  1.96it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:44<01:26,  1.95it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:44<01:23,  2.00it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:45<01:19,  2.08it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:45<01:21,  2.04it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:45<01:15,  2.17it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:46<01:16,  2.13it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:46<01:17,  2.08it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:47<01:15,  2.13it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:47<01:13,  2.19it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:48<01:07,  2.36it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:48<01:06,  2.37it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:49<01:07,  2.31it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:49<01:08,  2.27it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:49<01:08,  2.26it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:50<01:10,  2.19it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:50<01:10,  2.16it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:51<01:15,  2.02it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:51<01:12,  2.08it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:52<01:12,  2.06it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:52<01:12,  2.07it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:53<01:13,  2.02it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:53<01:12,  2.02it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:54<01:11,  2.04it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:54<01:11,  2.03it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:55<01:12,  1.98it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:56<01:15,  1.89it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:56<01:15,  1.88it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:57<01:16,  1.84it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:57<01:13,  1.90it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:58<01:13,  1.90it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:58<01:14,  1.86it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:59<01:12,  1.89it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:59<01:09,  1.94it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [01:00<01:14,  1.82it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [01:00<01:11,  1.87it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [01:01<01:07,  1.96it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [01:01<01:09,  1.89it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [01:02<01:13,  1.78it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [01:03<01:11,  1.81it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [01:03<01:08,  1.87it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [01:04<01:09,  1.85it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [01:04<01:04,  1.96it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [01:05<01:05,  1.93it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [01:05<01:04,  1.93it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [01:06<01:02,  1.97it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [01:06<01:00,  2.04it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [01:07<00:58,  2.07it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [01:07<01:01,  1.98it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [01:07<00:57,  2.09it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [01:08<00:59,  2.01it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [01:09<01:00,  1.95it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [01:09<01:00,  1.93it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [01:10<00:57,  2.00it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [01:10<00:55,  2.07it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [01:11<00:55,  2.04it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [01:11<00:56,  1.99it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [01:12<00:57,  1.96it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [01:12<00:58,  1.91it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [01:13<00:55,  1.99it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [01:13<00:50,  2.17it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [01:13<00:47,  2.26it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [01:14<00:45,  2.34it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [01:14<00:46,  2.28it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [01:15<00:47,  2.23it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [01:15<00:42,  2.45it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [01:15<00:42,  2.43it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [01:16<00:43,  2.37it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [01:16<00:42,  2.38it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [01:17<00:43,  2.28it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [01:17<00:42,  2.32it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [01:17<00:36,  2.66it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [01:18<00:38,  2.49it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [01:18<00:38,  2.52it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [01:19<00:37,  2.56it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [01:19<00:33,  2.82it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [01:19<00:35,  2.63it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [01:20<00:38,  2.37it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [01:20<00:40,  2.24it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [01:21<00:40,  2.20it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [01:21<00:38,  2.33it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [01:22<00:38,  2.31it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [01:22<00:38,  2.28it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [01:23<00:37,  2.31it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [01:23<00:37,  2.29it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [01:23<00:36,  2.29it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [01:24<00:35,  2.33it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [01:24<00:33,  2.42it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [01:25<00:36,  2.22it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [01:25<00:34,  2.31it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [01:26<00:35,  2.21it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [01:26<00:34,  2.29it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [01:26<00:33,  2.27it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [01:27<00:34,  2.19it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [01:27<00:33,  2.22it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [01:28<00:32,  2.25it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [01:28<00:30,  2.39it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [01:29<00:31,  2.25it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [01:29<00:31,  2.25it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [01:30<00:29,  2.36it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [01:30<00:28,  2.43it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [01:30<00:28,  2.41it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [01:31<00:27,  2.41it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [01:31<00:30,  2.19it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [01:32<00:30,  2.16it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [01:32<00:28,  2.25it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [01:33<00:26,  2.34it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [01:33<00:28,  2.19it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [01:33<00:26,  2.28it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [01:34<00:27,  2.20it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [01:34<00:26,  2.24it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [01:35<00:25,  2.26it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [01:35<00:25,  2.26it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [01:36<00:24,  2.24it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [01:36<00:24,  2.26it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [01:37<00:23,  2.27it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [01:37<00:23,  2.28it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [01:38<00:23,  2.20it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:38<00:20,  2.48it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:38<00:20,  2.43it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:39<00:20,  2.34it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:39<00:20,  2.32it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:39<00:18,  2.53it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:40<00:18,  2.49it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:40<00:17,  2.56it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:41<00:17,  2.48it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:41<00:18,  2.38it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:42<00:17,  2.39it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:42<00:17,  2.34it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:42<00:16,  2.38it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:43<00:16,  2.37it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:43<00:15,  2.42it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:44<00:14,  2.50it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:44<00:15,  2.33it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:45<00:15,  2.28it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:45<00:15,  2.26it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:45<00:15,  2.15it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:46<00:15,  2.11it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:46<00:14,  2.19it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:47<00:13,  2.21it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:47<00:12,  2.31it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:48<00:12,  2.18it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:48<00:11,  2.29it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:49<00:11,  2.25it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:49<00:10,  2.35it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:49<00:10,  2.32it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:50<00:10,  2.22it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:50<00:10,  2.06it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:51<00:10,  2.06it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:51<00:09,  2.22it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:52<00:07,  2.38it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:52<00:07,  2.46it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:53<00:07,  2.40it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:53<00:07,  2.28it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:53<00:06,  2.34it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:54<00:06,  2.20it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:54<00:06,  2.15it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:55<00:06,  1.99it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:56<00:05,  1.94it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:56<00:05,  1.80it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:57<00:04,  1.87it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:57<00:04,  1.95it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:58<00:03,  1.98it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:58<00:02,  2.15it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:58<00:02,  2.18it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:59<00:01,  2.12it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:59<00:01,  2.19it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [02:00<00:00,  2.07it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [02:00<00:00,  2.05it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [02:01<00:00,  1.93it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 61.95it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 4/266 [00:00<00:06, 37.61it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:06, 38.94it/s]saving BB  train1-THALAMUS:   5%|▍         | 13/266 [00:00<00:06, 38.60it/s]saving BB  train1-THALAMUS:   7%|▋         | 19/266 [00:00<00:06, 40.06it/s]saving BB  train1-THALAMUS:   9%|▊         | 23/266 [00:00<00:06, 37.61it/s]saving BB  train1-THALAMUS:  11%|█         | 29/266 [00:00<00:05, 42.24it/s]saving BB  train1-THALAMUS:  12%|█▏        | 33/266 [00:00<00:06, 35.89it/s]saving BB  train1-THALAMUS:  14%|█▍        | 37/266 [00:00<00:06, 36.71it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:01<00:05, 40.27it/s]saving BB  train1-THALAMUS:  18%|█▊        | 48/266 [00:01<00:05, 40.57it/s]saving BB  train1-THALAMUS:  20%|█▉        | 53/266 [00:01<00:05, 42.14it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:01<00:04, 48.16it/s]saving BB  train1-THALAMUS:  25%|██▌       | 67/266 [00:01<00:04, 49.65it/s]saving BB  train1-THALAMUS:  27%|██▋       | 73/266 [00:01<00:04, 47.82it/s]saving BB  train1-THALAMUS:  30%|███       | 81/266 [00:01<00:03, 48.98it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:03, 45.57it/s]saving BB  train1-THALAMUS:  35%|███▍      | 92/266 [00:02<00:03, 44.14it/s]saving BB  train1-THALAMUS:  37%|███▋      | 99/266 [00:02<00:03, 49.23it/s]saving BB  train1-THALAMUS:  40%|███▉      | 106/266 [00:02<00:02, 53.85it/s]saving BB  train1-THALAMUS:  42%|████▏     | 112/266 [00:02<00:03, 51.08it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:02<00:02, 49.89it/s]saving BB  train1-THALAMUS:  47%|████▋     | 124/266 [00:02<00:03, 47.14it/s]saving BB  train1-THALAMUS:  49%|████▉     | 130/266 [00:02<00:02, 48.90it/s]saving BB  train1-THALAMUS:  51%|█████     | 136/266 [00:02<00:03, 41.45it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:03<00:02, 44.31it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 148/266 [00:03<00:02, 45.00it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 153/266 [00:03<00:02, 45.84it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 159/266 [00:03<00:02, 47.70it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:03<00:01, 52.34it/s]saving BB  train1-THALAMUS:  65%|██████▍   | 172/266 [00:03<00:01, 49.97it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 180/266 [00:03<00:01, 54.48it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:03<00:01, 51.10it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 192/266 [00:04<00:01, 46.71it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 197/266 [00:04<00:01, 40.61it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 204/266 [00:04<00:01, 45.99it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:04<00:01, 44.97it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 217/266 [00:04<00:01, 48.10it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 223/266 [00:04<00:00, 48.19it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 229/266 [00:04<00:00, 48.98it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:05<00:00, 43.75it/s]saving BB  train1-THALAMUS:  91%|█████████ | 242/266 [00:05<00:00, 47.91it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 248/266 [00:05<00:00, 48.72it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 254/266 [00:05<00:00, 48.71it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:05<00:00, 49.41it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:05<00:00, 46.51it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 46.61it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   1%|          | 3/266 [00:00<00:09, 26.80it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:08, 28.96it/s]saving BB  train1-THALAMUS Sagittal:   5%|▍         | 13/266 [00:00<00:07, 33.35it/s]saving BB  train1-THALAMUS Sagittal:   6%|▌         | 16/266 [00:00<00:08, 30.82it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 20/266 [00:00<00:07, 33.00it/s]saving BB  train1-THALAMUS Sagittal:  10%|▉         | 26/266 [00:00<00:06, 37.57it/s]saving BB  train1-THALAMUS Sagittal:  11%|█▏        | 30/266 [00:00<00:06, 38.06it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 35/266 [00:00<00:06, 36.53it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▌        | 41/266 [00:01<00:05, 40.61it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 47/266 [00:01<00:04, 44.02it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 52/266 [00:01<00:04, 43.47it/s]saving BB  train1-THALAMUS Sagittal:  21%|██▏       | 57/266 [00:01<00:04, 42.44it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▎       | 63/266 [00:01<00:04, 45.19it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:01<00:03, 50.01it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▊       | 76/266 [00:01<00:03, 51.97it/s]saving BB  train1-THALAMUS Sagittal:  31%|███       | 82/266 [00:01<00:03, 48.79it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 88/266 [00:01<00:03, 50.49it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▌      | 94/266 [00:02<00:03, 46.18it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 99/266 [00:02<00:03, 46.16it/s]saving BB  train1-THALAMUS Sagittal:  40%|███▉      | 106/266 [00:02<00:03, 49.36it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 113/266 [00:02<00:02, 52.34it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 119/266 [00:02<00:02, 53.50it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 125/266 [00:02<00:03, 46.86it/s]saving BB  train1-THALAMUS Sagittal:  49%|████▉     | 130/266 [00:02<00:02, 47.71it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 135/266 [00:02<00:03, 43.49it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 140/266 [00:03<00:02, 44.56it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 145/266 [00:03<00:02, 44.59it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▋    | 150/266 [00:03<00:02, 45.26it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▊    | 156/266 [00:03<00:02, 47.92it/s]saving BB  train1-THALAMUS Sagittal:  61%|██████    | 162/266 [00:03<00:02, 49.06it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 167/266 [00:03<00:02, 47.70it/s]saving BB  train1-THALAMUS Sagittal:  65%|██████▍   | 172/266 [00:03<00:01, 47.55it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 177/266 [00:03<00:02, 44.18it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 184/266 [00:03<00:01, 48.63it/s]saving BB  train1-THALAMUS Sagittal:  72%|███████▏  | 191/266 [00:04<00:01, 52.11it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 197/266 [00:04<00:01, 43.98it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▌  | 202/266 [00:04<00:01, 43.33it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▊  | 209/266 [00:04<00:01, 47.51it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 215/266 [00:04<00:01, 45.01it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:04<00:01, 45.58it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 227/266 [00:04<00:00, 50.82it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 234/266 [00:04<00:00, 53.39it/s]saving BB  train1-THALAMUS Sagittal:  90%|█████████ | 240/266 [00:05<00:00, 50.33it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 248/266 [00:05<00:00, 54.80it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 254/266 [00:05<00:00, 47.65it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 260/266 [00:05<00:00, 49.28it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:05<00:00, 42.73it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<11:32,  2.61s/it]Loading train:   1%|          | 2/266 [00:05<11:22,  2.58s/it]Loading train:   1%|          | 3/266 [00:06<10:21,  2.36s/it]Loading train:   2%|▏         | 4/266 [00:08<09:28,  2.17s/it]Loading train:   2%|▏         | 5/266 [00:11<09:42,  2.23s/it]Loading train:   2%|▏         | 6/266 [00:12<09:09,  2.11s/it]Loading train:   3%|▎         | 7/266 [00:14<08:50,  2.05s/it]Loading train:   3%|▎         | 8/266 [00:16<08:49,  2.05s/it]Loading train:   3%|▎         | 9/266 [00:18<08:51,  2.07s/it]Loading train:   4%|▍         | 10/266 [00:20<08:28,  1.99s/it]Loading train:   4%|▍         | 11/266 [00:22<08:30,  2.00s/it]Loading train:   5%|▍         | 12/266 [00:24<08:23,  1.98s/it]Loading train:   5%|▍         | 13/266 [00:26<08:38,  2.05s/it]Loading train:   5%|▌         | 14/266 [00:28<08:25,  2.01s/it]Loading train:   6%|▌         | 15/266 [00:30<08:07,  1.94s/it]Loading train:   6%|▌         | 16/266 [00:32<08:03,  1.93s/it]Loading train:   6%|▋         | 17/266 [00:34<07:41,  1.85s/it]Loading train:   7%|▋         | 18/266 [00:35<07:29,  1.81s/it]Loading train:   7%|▋         | 19/266 [00:37<07:34,  1.84s/it]Loading train:   8%|▊         | 20/266 [00:39<07:37,  1.86s/it]Loading train:   8%|▊         | 21/266 [00:41<07:41,  1.88s/it]Loading train:   8%|▊         | 22/266 [00:43<07:41,  1.89s/it]Loading train:   9%|▊         | 23/266 [00:45<07:40,  1.89s/it]Loading train:   9%|▉         | 24/266 [00:47<07:24,  1.84s/it]Loading train:   9%|▉         | 25/266 [00:48<07:17,  1.82s/it]Loading train:  10%|▉         | 26/266 [00:50<07:20,  1.84s/it]Loading train:  10%|█         | 27/266 [00:52<07:19,  1.84s/it]Loading train:  11%|█         | 28/266 [00:54<07:10,  1.81s/it]Loading train:  11%|█         | 29/266 [00:56<06:52,  1.74s/it]Loading train:  11%|█▏        | 30/266 [00:57<06:53,  1.75s/it]Loading train:  12%|█▏        | 31/266 [00:59<06:41,  1.71s/it]Loading train:  12%|█▏        | 32/266 [01:00<06:27,  1.66s/it]Loading train:  12%|█▏        | 33/266 [01:02<06:21,  1.64s/it]Loading train:  13%|█▎        | 34/266 [01:03<06:07,  1.58s/it]Loading train:  13%|█▎        | 35/266 [01:05<05:36,  1.46s/it]Loading train:  14%|█▎        | 36/266 [01:06<05:08,  1.34s/it]Loading train:  14%|█▍        | 37/266 [01:07<04:47,  1.25s/it]Loading train:  14%|█▍        | 38/266 [01:08<04:37,  1.22s/it]Loading train:  15%|█▍        | 39/266 [01:09<04:36,  1.22s/it]Loading train:  15%|█▌        | 40/266 [01:10<04:31,  1.20s/it]Loading train:  15%|█▌        | 41/266 [01:11<04:23,  1.17s/it]Loading train:  16%|█▌        | 42/266 [01:12<04:11,  1.12s/it]Loading train:  16%|█▌        | 43/266 [01:13<04:05,  1.10s/it]Loading train:  17%|█▋        | 44/266 [01:14<03:51,  1.04s/it]Loading train:  17%|█▋        | 45/266 [01:15<03:44,  1.02s/it]Loading train:  17%|█▋        | 46/266 [01:16<03:41,  1.00s/it]Loading train:  18%|█▊        | 47/266 [01:17<03:32,  1.03it/s]Loading train:  18%|█▊        | 48/266 [01:18<03:29,  1.04it/s]Loading train:  18%|█▊        | 49/266 [01:19<03:27,  1.05it/s]Loading train:  19%|█▉        | 50/266 [01:21<04:03,  1.13s/it]Loading train:  19%|█▉        | 51/266 [01:22<04:35,  1.28s/it]Loading train:  20%|█▉        | 52/266 [01:24<05:03,  1.42s/it]Loading train:  20%|█▉        | 53/266 [01:25<05:01,  1.42s/it]Loading train:  20%|██        | 54/266 [01:27<05:36,  1.59s/it]Loading train:  21%|██        | 55/266 [01:29<06:09,  1.75s/it]Loading train:  21%|██        | 56/266 [01:31<05:50,  1.67s/it]Loading train:  21%|██▏       | 57/266 [01:33<05:41,  1.64s/it]Loading train:  22%|██▏       | 58/266 [01:34<05:59,  1.73s/it]Loading train:  22%|██▏       | 59/266 [01:36<05:49,  1.69s/it]Loading train:  23%|██▎       | 60/266 [01:38<05:35,  1.63s/it]Loading train:  23%|██▎       | 61/266 [01:40<05:54,  1.73s/it]Loading train:  23%|██▎       | 62/266 [01:42<06:22,  1.87s/it]Loading train:  24%|██▎       | 63/266 [01:43<05:59,  1.77s/it]Loading train:  24%|██▍       | 64/266 [01:45<05:39,  1.68s/it]Loading train:  24%|██▍       | 65/266 [01:47<05:45,  1.72s/it]Loading train:  25%|██▍       | 66/266 [01:48<05:45,  1.73s/it]Loading train:  25%|██▌       | 67/266 [01:50<05:50,  1.76s/it]Loading train:  26%|██▌       | 68/266 [01:52<05:47,  1.75s/it]Loading train:  26%|██▌       | 69/266 [01:53<05:16,  1.61s/it]Loading train:  26%|██▋       | 70/266 [01:55<05:41,  1.74s/it]Loading train:  27%|██▋       | 71/266 [01:58<06:14,  1.92s/it]Loading train:  27%|██▋       | 72/266 [02:00<06:35,  2.04s/it]Loading train:  27%|██▋       | 73/266 [02:02<06:53,  2.14s/it]Loading train:  28%|██▊       | 74/266 [02:04<06:40,  2.09s/it]Loading train:  28%|██▊       | 75/266 [02:06<06:29,  2.04s/it]Loading train:  29%|██▊       | 76/266 [02:08<05:53,  1.86s/it]Loading train:  29%|██▉       | 77/266 [02:09<05:33,  1.77s/it]Loading train:  29%|██▉       | 78/266 [02:11<05:52,  1.87s/it]Loading train:  30%|██▉       | 79/266 [02:13<05:52,  1.89s/it]Loading train:  30%|███       | 80/266 [02:15<05:30,  1.78s/it]Loading train:  30%|███       | 81/266 [02:16<05:21,  1.74s/it]Loading train:  31%|███       | 82/266 [02:18<05:41,  1.86s/it]Loading train:  31%|███       | 83/266 [02:20<05:40,  1.86s/it]Loading train:  32%|███▏      | 84/266 [02:22<05:47,  1.91s/it]Loading train:  32%|███▏      | 85/266 [02:24<05:43,  1.90s/it]Loading train:  32%|███▏      | 86/266 [02:26<05:33,  1.85s/it]Loading train:  33%|███▎      | 87/266 [02:27<05:10,  1.73s/it]Loading train:  33%|███▎      | 88/266 [02:29<05:01,  1.69s/it]Loading train:  33%|███▎      | 89/266 [02:31<04:48,  1.63s/it]Loading train:  34%|███▍      | 90/266 [02:33<05:26,  1.86s/it]Loading train:  34%|███▍      | 91/266 [02:35<05:42,  1.96s/it]Loading train:  35%|███▍      | 92/266 [02:37<05:51,  2.02s/it]Loading train:  35%|███▍      | 93/266 [02:39<05:59,  2.08s/it]Loading train:  35%|███▌      | 94/266 [02:41<05:52,  2.05s/it]Loading train:  36%|███▌      | 95/266 [02:43<05:46,  2.02s/it]Loading train:  36%|███▌      | 96/266 [02:46<05:55,  2.09s/it]Loading train:  36%|███▋      | 97/266 [02:48<06:17,  2.23s/it]Loading train:  37%|███▋      | 98/266 [02:51<06:45,  2.41s/it]Loading train:  37%|███▋      | 99/266 [02:53<06:35,  2.37s/it]Loading train:  38%|███▊      | 100/266 [02:55<06:15,  2.26s/it]Loading train:  38%|███▊      | 101/266 [02:57<05:53,  2.14s/it]Loading train:  38%|███▊      | 102/266 [02:59<05:32,  2.03s/it]Loading train:  39%|███▊      | 103/266 [03:01<05:36,  2.07s/it]Loading train:  39%|███▉      | 104/266 [03:03<05:27,  2.02s/it]Loading train:  39%|███▉      | 105/266 [03:05<05:24,  2.01s/it]Loading train:  40%|███▉      | 106/266 [03:07<05:23,  2.02s/it]Loading train:  40%|████      | 107/266 [03:09<04:59,  1.89s/it]Loading train:  41%|████      | 108/266 [03:10<04:34,  1.74s/it]Loading train:  41%|████      | 109/266 [03:12<04:21,  1.67s/it]Loading train:  41%|████▏     | 110/266 [03:13<04:00,  1.54s/it]Loading train:  42%|████▏     | 111/266 [03:14<03:58,  1.54s/it]Loading train:  42%|████▏     | 112/266 [03:16<03:46,  1.47s/it]Loading train:  42%|████▏     | 113/266 [03:17<03:39,  1.44s/it]Loading train:  43%|████▎     | 114/266 [03:19<04:06,  1.62s/it]Loading train:  43%|████▎     | 115/266 [03:21<04:06,  1.63s/it]Loading train:  44%|████▎     | 116/266 [03:22<03:59,  1.60s/it]Loading train:  44%|████▍     | 117/266 [03:24<03:47,  1.52s/it]Loading train:  44%|████▍     | 118/266 [03:25<04:02,  1.64s/it]Loading train:  45%|████▍     | 119/266 [03:28<04:32,  1.85s/it]Loading train:  45%|████▌     | 120/266 [03:30<04:23,  1.81s/it]Loading train:  45%|████▌     | 121/266 [03:32<04:29,  1.86s/it]Loading train:  46%|████▌     | 122/266 [03:33<04:17,  1.79s/it]Loading train:  46%|████▌     | 123/266 [03:35<04:25,  1.85s/it]Loading train:  47%|████▋     | 124/266 [03:37<04:41,  1.98s/it]Loading train:  47%|████▋     | 125/266 [03:39<04:39,  1.98s/it]Loading train:  47%|████▋     | 126/266 [03:41<04:36,  1.97s/it]Loading train:  48%|████▊     | 127/266 [03:44<05:00,  2.16s/it]Loading train:  48%|████▊     | 128/266 [03:47<05:21,  2.33s/it]Loading train:  48%|████▊     | 129/266 [03:49<05:11,  2.27s/it]Loading train:  49%|████▉     | 130/266 [03:51<04:50,  2.14s/it]Loading train:  49%|████▉     | 131/266 [03:53<04:47,  2.13s/it]Loading train:  50%|████▉     | 132/266 [03:55<04:39,  2.08s/it]Loading train:  50%|█████     | 133/266 [03:57<04:31,  2.04s/it]Loading train:  50%|█████     | 134/266 [03:58<04:18,  1.95s/it]Loading train:  51%|█████     | 135/266 [04:00<04:00,  1.83s/it]Loading train:  51%|█████     | 136/266 [04:02<03:48,  1.76s/it]Loading train:  52%|█████▏    | 137/266 [04:03<03:48,  1.77s/it]Loading train:  52%|█████▏    | 138/266 [04:05<03:54,  1.83s/it]Loading train:  52%|█████▏    | 139/266 [04:07<03:46,  1.79s/it]Loading train:  53%|█████▎    | 140/266 [04:09<03:44,  1.78s/it]Loading train:  53%|█████▎    | 141/266 [04:10<03:37,  1.74s/it]Loading train:  53%|█████▎    | 142/266 [04:12<03:43,  1.81s/it]Loading train:  54%|█████▍    | 143/266 [04:15<03:55,  1.91s/it]Loading train:  54%|█████▍    | 144/266 [04:16<03:41,  1.81s/it]Loading train:  55%|█████▍    | 145/266 [04:17<03:22,  1.68s/it]Loading train:  55%|█████▍    | 146/266 [04:19<03:25,  1.71s/it]Loading train:  55%|█████▌    | 147/266 [04:22<03:47,  1.91s/it]Loading train:  56%|█████▌    | 148/266 [04:24<03:51,  1.96s/it]Loading train:  56%|█████▌    | 149/266 [04:25<03:39,  1.87s/it]Loading train:  56%|█████▋    | 150/266 [04:28<03:48,  1.97s/it]Loading train:  57%|█████▋    | 151/266 [04:29<03:39,  1.91s/it]Loading train:  57%|█████▋    | 152/266 [04:31<03:32,  1.87s/it]Loading train:  58%|█████▊    | 153/266 [04:33<03:31,  1.87s/it]Loading train:  58%|█████▊    | 154/266 [04:35<03:27,  1.85s/it]Loading train:  58%|█████▊    | 155/266 [04:37<03:28,  1.88s/it]Loading train:  59%|█████▊    | 156/266 [04:39<03:25,  1.87s/it]Loading train:  59%|█████▉    | 157/266 [04:41<03:31,  1.94s/it]Loading train:  59%|█████▉    | 158/266 [04:42<03:15,  1.81s/it]Loading train:  60%|█████▉    | 159/266 [04:44<03:09,  1.77s/it]Loading train:  60%|██████    | 160/266 [04:46<03:21,  1.90s/it]Loading train:  61%|██████    | 161/266 [04:48<03:21,  1.92s/it]Loading train:  61%|██████    | 162/266 [04:50<03:22,  1.95s/it]Loading train:  61%|██████▏   | 163/266 [04:52<03:11,  1.86s/it]Loading train:  62%|██████▏   | 164/266 [04:53<02:55,  1.72s/it]Loading train:  62%|██████▏   | 165/266 [04:55<02:54,  1.73s/it]Loading train:  62%|██████▏   | 166/266 [04:56<02:42,  1.63s/it]Loading train:  63%|██████▎   | 167/266 [04:58<02:36,  1.58s/it]Loading train:  63%|██████▎   | 168/266 [04:59<02:31,  1.55s/it]Loading train:  64%|██████▎   | 169/266 [05:01<02:27,  1.52s/it]Loading train:  64%|██████▍   | 170/266 [05:02<02:29,  1.56s/it]Loading train:  64%|██████▍   | 171/266 [05:04<02:26,  1.54s/it]Loading train:  65%|██████▍   | 172/266 [05:05<02:25,  1.55s/it]Loading train:  65%|██████▌   | 173/266 [05:07<02:25,  1.57s/it]Loading train:  65%|██████▌   | 174/266 [05:09<02:26,  1.59s/it]Loading train:  66%|██████▌   | 175/266 [05:10<02:14,  1.48s/it]Loading train:  66%|██████▌   | 176/266 [05:11<02:16,  1.52s/it]Loading train:  67%|██████▋   | 177/266 [05:13<02:11,  1.48s/it]Loading train:  67%|██████▋   | 178/266 [05:15<02:19,  1.58s/it]Loading train:  67%|██████▋   | 179/266 [05:16<02:19,  1.61s/it]Loading train:  68%|██████▊   | 180/266 [05:18<02:27,  1.72s/it]Loading train:  68%|██████▊   | 181/266 [05:21<02:39,  1.88s/it]Loading train:  68%|██████▊   | 182/266 [05:22<02:35,  1.85s/it]Loading train:  69%|██████▉   | 183/266 [05:24<02:39,  1.93s/it]Loading train:  69%|██████▉   | 184/266 [05:27<02:45,  2.02s/it]Loading train:  70%|██████▉   | 185/266 [05:29<02:47,  2.07s/it]Loading train:  70%|██████▉   | 186/266 [05:31<02:39,  2.00s/it]Loading train:  70%|███████   | 187/266 [05:32<02:23,  1.82s/it]Loading train:  71%|███████   | 188/266 [05:34<02:13,  1.72s/it]Loading train:  71%|███████   | 189/266 [05:35<01:59,  1.55s/it]Loading train:  71%|███████▏  | 190/266 [05:36<02:01,  1.60s/it]Loading train:  72%|███████▏  | 191/266 [05:39<02:15,  1.81s/it]Loading train:  72%|███████▏  | 192/266 [05:40<02:01,  1.64s/it]Loading train:  73%|███████▎  | 193/266 [05:42<02:02,  1.67s/it]Loading train:  73%|███████▎  | 194/266 [05:44<02:16,  1.90s/it]Loading train:  73%|███████▎  | 195/266 [05:46<02:16,  1.93s/it]Loading train:  74%|███████▎  | 196/266 [05:48<02:13,  1.91s/it]Loading train:  74%|███████▍  | 197/266 [05:50<02:11,  1.91s/it]Loading train:  74%|███████▍  | 198/266 [05:52<02:15,  2.00s/it]Loading train:  75%|███████▍  | 199/266 [05:54<02:15,  2.03s/it]Loading train:  75%|███████▌  | 200/266 [05:56<02:06,  1.92s/it]Loading train:  76%|███████▌  | 201/266 [05:58<02:05,  1.93s/it]Loading train:  76%|███████▌  | 202/266 [05:59<01:57,  1.84s/it]Loading train:  76%|███████▋  | 203/266 [06:01<01:55,  1.84s/it]Loading train:  77%|███████▋  | 204/266 [06:03<01:56,  1.88s/it]Loading train:  77%|███████▋  | 205/266 [06:05<01:55,  1.89s/it]Loading train:  77%|███████▋  | 206/266 [06:07<01:47,  1.79s/it]Loading train:  78%|███████▊  | 207/266 [06:08<01:44,  1.76s/it]Loading train:  78%|███████▊  | 208/266 [06:11<01:47,  1.86s/it]Loading train:  79%|███████▊  | 209/266 [06:13<01:48,  1.90s/it]Loading train:  79%|███████▉  | 210/266 [06:14<01:45,  1.88s/it]Loading train:  79%|███████▉  | 211/266 [06:16<01:37,  1.77s/it]Loading train:  80%|███████▉  | 212/266 [06:18<01:34,  1.74s/it]Loading train:  80%|████████  | 213/266 [06:20<01:39,  1.87s/it]Loading train:  80%|████████  | 214/266 [06:21<01:34,  1.81s/it]Loading train:  81%|████████  | 215/266 [06:23<01:29,  1.76s/it]Loading train:  81%|████████  | 216/266 [06:24<01:21,  1.63s/it]Loading train:  82%|████████▏ | 217/266 [06:26<01:22,  1.68s/it]Loading train:  82%|████████▏ | 218/266 [06:28<01:23,  1.73s/it]Loading train:  82%|████████▏ | 219/266 [06:30<01:18,  1.66s/it]Loading train:  83%|████████▎ | 220/266 [06:31<01:18,  1.70s/it]Loading train:  83%|████████▎ | 221/266 [06:33<01:16,  1.70s/it]Loading train:  83%|████████▎ | 222/266 [06:35<01:18,  1.78s/it]Loading train:  84%|████████▍ | 223/266 [06:37<01:16,  1.78s/it]Loading train:  84%|████████▍ | 224/266 [06:39<01:22,  1.95s/it]Loading train:  85%|████████▍ | 225/266 [06:41<01:20,  1.97s/it]Loading train:  85%|████████▍ | 226/266 [06:43<01:21,  2.04s/it]Loading train:  85%|████████▌ | 227/266 [06:45<01:16,  1.95s/it]Loading train:  86%|████████▌ | 228/266 [06:47<01:13,  1.94s/it]Loading train:  86%|████████▌ | 229/266 [06:49<01:08,  1.84s/it]Loading train:  86%|████████▋ | 230/266 [06:50<01:05,  1.81s/it]Loading train:  87%|████████▋ | 231/266 [06:52<01:03,  1.81s/it]Loading train:  87%|████████▋ | 232/266 [06:54<00:58,  1.73s/it]Loading train:  88%|████████▊ | 233/266 [06:55<00:52,  1.59s/it]Loading train:  88%|████████▊ | 234/266 [06:56<00:50,  1.57s/it]Loading train:  88%|████████▊ | 235/266 [06:58<00:49,  1.59s/it]Loading train:  89%|████████▊ | 236/266 [07:00<00:50,  1.70s/it]Loading train:  89%|████████▉ | 237/266 [07:02<00:47,  1.65s/it]Loading train:  89%|████████▉ | 238/266 [07:03<00:45,  1.61s/it]Loading train:  90%|████████▉ | 239/266 [07:05<00:44,  1.64s/it]Loading train:  90%|█████████ | 240/266 [07:07<00:43,  1.66s/it]Loading train:  91%|█████████ | 241/266 [07:08<00:42,  1.69s/it]Loading train:  91%|█████████ | 242/266 [07:09<00:36,  1.51s/it]Loading train:  91%|█████████▏| 243/266 [07:11<00:34,  1.50s/it]Loading train:  92%|█████████▏| 244/266 [07:12<00:31,  1.43s/it]Loading train:  92%|█████████▏| 245/266 [07:14<00:31,  1.48s/it]Loading train:  92%|█████████▏| 246/266 [07:15<00:27,  1.37s/it]Loading train:  93%|█████████▎| 247/266 [07:16<00:25,  1.35s/it]Loading train:  93%|█████████▎| 248/266 [07:18<00:25,  1.42s/it]Loading train:  94%|█████████▎| 249/266 [07:20<00:29,  1.73s/it]Loading train:  94%|█████████▍| 250/266 [07:22<00:29,  1.82s/it]Loading train:  94%|█████████▍| 251/266 [07:25<00:30,  2.01s/it]Loading train:  95%|█████████▍| 252/266 [07:27<00:28,  2.01s/it]Loading train:  95%|█████████▌| 253/266 [07:29<00:26,  2.04s/it]Loading train:  95%|█████████▌| 254/266 [07:31<00:23,  1.98s/it]Loading train:  96%|█████████▌| 255/266 [07:32<00:21,  1.93s/it]Loading train:  96%|█████████▌| 256/266 [07:34<00:18,  1.84s/it]Loading train:  97%|█████████▋| 257/266 [07:36<00:16,  1.87s/it]Loading train:  97%|█████████▋| 258/266 [07:38<00:14,  1.87s/it]Loading train:  97%|█████████▋| 259/266 [07:40<00:14,  2.00s/it]Loading train:  98%|█████████▊| 260/266 [07:42<00:11,  1.98s/it]Loading train:  98%|█████████▊| 261/266 [07:44<00:09,  1.98s/it]Loading train:  98%|█████████▊| 262/266 [07:46<00:07,  1.95s/it]Loading train:  99%|█████████▉| 263/266 [07:48<00:06,  2.02s/it]Loading train:  99%|█████████▉| 264/266 [07:50<00:03,  1.97s/it]Loading train: 100%|█████████▉| 265/266 [07:52<00:01,  1.95s/it]Loading train: 100%|██████████| 266/266 [07:54<00:00,  2.00s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/266 [00:00<00:14, 18.09it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:16, 16.10it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:14, 17.50it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:13, 19.41it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:11, 21.71it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:14, 17.41it/s]concatenating: train:   7%|▋         | 19/266 [00:01<00:14, 16.66it/s]concatenating: train:   8%|▊         | 21/266 [00:01<00:16, 14.62it/s]concatenating: train:   9%|▉         | 24/266 [00:01<00:16, 15.00it/s]concatenating: train:  10%|█         | 27/266 [00:01<00:14, 17.03it/s]concatenating: train:  12%|█▏        | 31/266 [00:01<00:11, 20.33it/s]concatenating: train:  13%|█▎        | 34/266 [00:01<00:10, 21.52it/s]concatenating: train:  14%|█▍        | 38/266 [00:01<00:09, 23.57it/s]concatenating: train:  15%|█▌        | 41/266 [00:02<00:09, 23.56it/s]concatenating: train:  17%|█▋        | 44/266 [00:02<00:09, 23.52it/s]concatenating: train:  18%|█▊        | 48/266 [00:02<00:08, 25.21it/s]concatenating: train:  19%|█▉        | 51/266 [00:02<00:12, 16.62it/s]concatenating: train:  20%|██        | 54/266 [00:02<00:11, 17.68it/s]concatenating: train:  21%|██▏       | 57/266 [00:02<00:11, 17.57it/s]concatenating: train:  22%|██▏       | 59/266 [00:03<00:11, 18.12it/s]concatenating: train:  23%|██▎       | 62/266 [00:03<00:10, 19.28it/s]concatenating: train:  24%|██▍       | 65/266 [00:03<00:12, 16.48it/s]concatenating: train:  25%|██▌       | 67/266 [00:03<00:12, 16.21it/s]concatenating: train:  26%|██▋       | 70/266 [00:03<00:11, 17.13it/s]concatenating: train:  27%|██▋       | 72/266 [00:03<00:12, 14.96it/s]concatenating: train:  28%|██▊       | 74/266 [00:04<00:13, 13.81it/s]concatenating: train:  29%|██▉       | 78/266 [00:04<00:11, 16.75it/s]concatenating: train:  32%|███▏      | 84/266 [00:04<00:08, 21.28it/s]concatenating: train:  33%|███▎      | 89/266 [00:04<00:07, 23.14it/s]concatenating: train:  35%|███▍      | 93/266 [00:04<00:07, 23.26it/s]concatenating: train:  36%|███▌      | 96/266 [00:04<00:07, 24.03it/s]concatenating: train:  37%|███▋      | 99/266 [00:04<00:07, 22.14it/s]concatenating: train:  38%|███▊      | 102/266 [00:05<00:08, 19.90it/s]concatenating: train:  39%|███▉      | 105/266 [00:05<00:08, 19.52it/s]concatenating: train:  41%|████      | 108/266 [00:05<00:08, 19.57it/s]concatenating: train:  42%|████▏     | 111/266 [00:05<00:08, 18.89it/s]concatenating: train:  43%|████▎     | 114/266 [00:05<00:07, 20.56it/s]concatenating: train:  44%|████▍     | 118/266 [00:05<00:07, 19.67it/s]concatenating: train:  45%|████▌     | 121/266 [00:06<00:07, 18.84it/s]concatenating: train:  46%|████▌     | 123/266 [00:06<00:07, 18.09it/s]concatenating: train:  47%|████▋     | 126/266 [00:06<00:06, 20.35it/s]concatenating: train:  50%|████▉     | 132/266 [00:06<00:05, 25.10it/s]concatenating: train:  52%|█████▏    | 138/266 [00:06<00:04, 29.92it/s]concatenating: train:  53%|█████▎    | 142/266 [00:06<00:03, 31.43it/s]concatenating: train:  55%|█████▍    | 146/266 [00:06<00:04, 26.42it/s]concatenating: train:  56%|█████▋    | 150/266 [00:07<00:04, 25.02it/s]concatenating: train:  58%|█████▊    | 153/266 [00:07<00:05, 21.92it/s]concatenating: train:  59%|█████▊    | 156/266 [00:07<00:04, 22.76it/s]concatenating: train:  60%|█████▉    | 159/266 [00:07<00:05, 19.55it/s]concatenating: train:  61%|██████    | 162/266 [00:07<00:05, 20.06it/s]concatenating: train:  62%|██████▏   | 165/266 [00:07<00:04, 20.63it/s]concatenating: train:  63%|██████▎   | 168/266 [00:07<00:05, 19.26it/s]concatenating: train:  64%|██████▍   | 171/266 [00:08<00:05, 17.03it/s]concatenating: train:  67%|██████▋   | 179/266 [00:08<00:03, 21.92it/s]concatenating: train:  71%|███████   | 188/266 [00:08<00:02, 28.35it/s]concatenating: train:  73%|███████▎  | 193/266 [00:08<00:02, 30.09it/s]concatenating: train:  74%|███████▍  | 198/266 [00:08<00:02, 28.49it/s]concatenating: train:  76%|███████▌  | 202/266 [00:08<00:02, 24.17it/s]concatenating: train:  77%|███████▋  | 206/266 [00:09<00:02, 21.16it/s]concatenating: train:  79%|███████▊  | 209/266 [00:09<00:02, 20.21it/s]concatenating: train:  80%|███████▉  | 212/266 [00:09<00:02, 20.06it/s]concatenating: train:  81%|████████  | 215/266 [00:09<00:02, 19.05it/s]concatenating: train:  82%|████████▏ | 218/266 [00:09<00:02, 20.69it/s]concatenating: train:  83%|████████▎ | 221/266 [00:10<00:02, 17.33it/s]concatenating: train:  85%|████████▍ | 225/266 [00:10<00:02, 19.27it/s]concatenating: train:  86%|████████▌ | 228/266 [00:10<00:02, 17.49it/s]concatenating: train:  87%|████████▋ | 231/266 [00:10<00:01, 17.61it/s]concatenating: train:  88%|████████▊ | 234/266 [00:10<00:01, 19.48it/s]concatenating: train:  94%|█████████▎| 249/266 [00:10<00:00, 26.07it/s]concatenating: train:  96%|█████████▌| 256/266 [00:11<00:00, 28.54it/s]concatenating: train:  98%|█████████▊| 261/266 [00:11<00:00, 23.65it/s]concatenating: train: 100%|█████████▉| 265/266 [00:11<00:00, 21.83it/s]concatenating: train: 100%|██████████| 266/266 [00:11<00:00, 22.97it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:07,  1.79s/it]Loading test:  40%|████      | 2/5 [00:03<00:05,  1.91s/it]Loading test:  60%|██████    | 3/5 [00:06<00:04,  2.01s/it]Loading test:  80%|████████  | 4/5 [00:08<00:02,  2.06s/it]Loading test: 100%|██████████| 5/5 [00:10<00:00,  2.06s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 14.77it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 21.93it/s]2019-08-17 18:41:39.912786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 18:41:39.912923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 18:41:39.912942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 18:41:39.912955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 18:41:39.913523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.26it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  3.96it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:09,  4.11it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.93it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  4.01it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:07,  4.67it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:09,  3.33it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:06,  4.44it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:07,  3.31it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:06,  3.85it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:06,  3.70it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:04,  4.27it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:03,  5.22it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:05<00:04,  3.50it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  3.94it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.78it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:02,  4.38it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  4.47it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:07<00:01,  3.07it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:01,  3.83it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:07<00:00,  3.77it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:07<00:00,  5.54it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 96,573
Non-trainable params: 127,260
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33718155e-02 3.28447321e-02 7.68028886e-02 9.54314511e-03
 2.76200350e-02 7.22600361e-03 8.44866790e-02 1.14154850e-01
 8.96340889e-02 1.36185373e-02 2.90611346e-01 1.89830814e-01
 2.55064471e-04]
Train on 9859 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.2489 - acc: 0.7968 - mDice: 0.1612 - val_loss: 0.9424 - val_acc: 0.9101 - val_mDice: 0.3845

Epoch 00001: val_mDice improved from -inf to 0.38454, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 0.9377 - acc: 0.8882 - mDice: 0.3800 - val_loss: 0.7307 - val_acc: 0.9182 - val_mDice: 0.4701

Epoch 00002: val_mDice improved from 0.38454 to 0.47007, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.7452 - acc: 0.8992 - mDice: 0.4585 - val_loss: 0.6436 - val_acc: 0.9219 - val_mDice: 0.5131

Epoch 00003: val_mDice improved from 0.47007 to 0.51307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6593 - acc: 0.9072 - mDice: 0.5004 - val_loss: 0.6323 - val_acc: 0.9226 - val_mDice: 0.5225

Epoch 00004: val_mDice improved from 0.51307 to 0.52247, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.6055 - acc: 0.9124 - mDice: 0.5288 - val_loss: 0.6209 - val_acc: 0.9256 - val_mDice: 0.5307

Epoch 00005: val_mDice improved from 0.52247 to 0.53066, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.6034 - acc: 0.9135 - mDice: 0.5341 - val_loss: 0.6342 - val_acc: 0.9272 - val_mDice: 0.5299

Epoch 00006: val_mDice did not improve from 0.53066
Epoch 7/300
 - 9s - loss: 0.5528 - acc: 0.9179 - mDice: 0.5584 - val_loss: 0.5835 - val_acc: 0.9287 - val_mDice: 0.5488

Epoch 00007: val_mDice improved from 0.53066 to 0.54882, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.5312 - acc: 0.9198 - mDice: 0.5710 - val_loss: 0.5784 - val_acc: 0.9294 - val_mDice: 0.5503

Epoch 00008: val_mDice improved from 0.54882 to 0.55028, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.5140 - acc: 0.9217 - mDice: 0.5821 - val_loss: 0.5585 - val_acc: 0.9313 - val_mDice: 0.5595

Epoch 00009: val_mDice improved from 0.55028 to 0.55948, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.4986 - acc: 0.9231 - mDice: 0.5911 - val_loss: 0.5550 - val_acc: 0.9299 - val_mDice: 0.5617

Epoch 00010: val_mDice improved from 0.55948 to 0.56174, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4903 - acc: 0.9241 - mDice: 0.5969 - val_loss: 0.5505 - val_acc: 0.9319 - val_mDice: 0.5651

Epoch 00011: val_mDice improved from 0.56174 to 0.56506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4761 - acc: 0.9254 - mDice: 0.6063 - val_loss: 0.5479 - val_acc: 0.9337 - val_mDice: 0.5692

Epoch 00012: val_mDice improved from 0.56506 to 0.56916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.4696 - acc: 0.9260 - mDice: 0.6098 - val_loss: 0.5417 - val_acc: 0.9379 - val_mDice: 0.5738

Epoch 00013: val_mDice improved from 0.56916 to 0.57384, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 9s - loss: 0.4589 - acc: 0.9269 - mDice: 0.6169 - val_loss: 0.5464 - val_acc: 0.9335 - val_mDice: 0.5683

Epoch 00014: val_mDice did not improve from 0.57384
Epoch 15/300
 - 9s - loss: 0.4468 - acc: 0.9279 - mDice: 0.6240 - val_loss: 0.5477 - val_acc: 0.9357 - val_mDice: 0.5703

Epoch 00015: val_mDice did not improve from 0.57384
Epoch 16/300
 - 9s - loss: 0.4421 - acc: 0.9288 - mDice: 0.6277 - val_loss: 0.5573 - val_acc: 0.9340 - val_mDice: 0.5670

Epoch 00016: val_mDice did not improve from 0.57384
Epoch 17/300
 - 9s - loss: 0.4357 - acc: 0.9290 - mDice: 0.6313 - val_loss: 0.5160 - val_acc: 0.9374 - val_mDice: 0.5843

Epoch 00017: val_mDice improved from 0.57384 to 0.58429, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.4284 - acc: 0.9296 - mDice: 0.6359 - val_loss: 0.5281 - val_acc: 0.9364 - val_mDice: 0.5786

Epoch 00018: val_mDice did not improve from 0.58429
Epoch 19/300
 - 9s - loss: 0.4222 - acc: 0.9305 - mDice: 0.6425 - val_loss: 0.5373 - val_acc: 0.9379 - val_mDice: 0.5791

Epoch 00019: val_mDice did not improve from 0.58429
Epoch 20/300
 - 9s - loss: 0.4366 - acc: 0.9292 - mDice: 0.6316 - val_loss: 0.5501 - val_acc: 0.9370 - val_mDice: 0.5688

Epoch 00020: val_mDice did not improve from 0.58429
Epoch 21/300
 - 9s - loss: 0.4108 - acc: 0.9315 - mDice: 0.6482 - val_loss: 0.5440 - val_acc: 0.9381 - val_mDice: 0.5758

Epoch 00021: val_mDice did not improve from 0.58429
Epoch 22/300
 - 9s - loss: 0.4051 - acc: 0.9319 - mDice: 0.6517 - val_loss: 0.5302 - val_acc: 0.9361 - val_mDice: 0.5773

Epoch 00022: val_mDice did not improve from 0.58429
Epoch 23/300
 - 9s - loss: 0.4004 - acc: 0.9322 - mDice: 0.6545 - val_loss: 0.5500 - val_acc: 0.9363 - val_mDice: 0.5744

Epoch 00023: val_mDice did not improve from 0.58429
Epoch 24/300
 - 9s - loss: 0.3931 - acc: 0.9329 - mDice: 0.6595 - val_loss: 0.5394 - val_acc: 0.9370 - val_mDice: 0.5801

Epoch 00024: val_mDice did not improve from 0.58429
Epoch 25/300
 - 9s - loss: 0.3904 - acc: 0.9330 - mDice: 0.6614 - val_loss: 0.5279 - val_acc: 0.9376 - val_mDice: 0.5793

Epoch 00025: val_mDice did not improve from 0.58429
Epoch 26/300
 - 9s - loss: 0.3862 - acc: 0.9335 - mDice: 0.6642 - val_loss: 0.5267 - val_acc: 0.9365 - val_mDice: 0.5824

Epoch 00026: val_mDice did not improve from 0.58429
Epoch 27/300
 - 9s - loss: 0.3846 - acc: 0.9337 - mDice: 0.6654 - val_loss: 0.5299 - val_acc: 0.9394 - val_mDice: 0.5806

Epoch 00027: val_mDice did not improve from 0.58429
Epoch 28/300
 - 9s - loss: 0.3812 - acc: 0.9341 - mDice: 0.6678 - val_loss: 0.5054 - val_acc: 0.9405 - val_mDice: 0.5907

Epoch 00028: val_mDice improved from 0.58429 to 0.59074, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 9s - loss: 0.3772 - acc: 0.9344 - mDice: 0.6711 - val_loss: 0.5215 - val_acc: 0.9394 - val_mDice: 0.5885

Epoch 00029: val_mDice did not improve from 0.59074
Epoch 30/300
 - 9s - loss: 0.3829 - acc: 0.9339 - mDice: 0.6669 - val_loss: 0.5203 - val_acc: 0.9368 - val_mDice: 0.5822

Epoch 00030: val_mDice did not improve from 0.59074
Epoch 31/300
 - 9s - loss: 0.3751 - acc: 0.9352 - mDice: 0.6735 - val_loss: 0.5404 - val_acc: 0.9364 - val_mDice: 0.5717

Epoch 00031: val_mDice did not improve from 0.59074
Epoch 32/300
 - 9s - loss: 0.3963 - acc: 0.9336 - mDice: 0.6592 - val_loss: 0.5555 - val_acc: 0.9424 - val_mDice: 0.5818

Epoch 00032: val_mDice did not improve from 0.59074
Epoch 33/300
 - 9s - loss: 0.3723 - acc: 0.9354 - mDice: 0.6756 - val_loss: 0.5338 - val_acc: 0.9407 - val_mDice: 0.5866

Epoch 00033: val_mDice did not improve from 0.59074
Epoch 34/300
 - 9s - loss: 0.3693 - acc: 0.9357 - mDice: 0.6773 - val_loss: 0.5192 - val_acc: 0.9399 - val_mDice: 0.5870

Epoch 00034: val_mDice did not improve from 0.59074
Epoch 35/300
 - 9s - loss: 0.3621 - acc: 0.9361 - mDice: 0.6812 - val_loss: 0.5297 - val_acc: 0.9405 - val_mDice: 0.5874

Epoch 00035: val_mDice did not improve from 0.59074
Epoch 36/300
 - 9s - loss: 0.3630 - acc: 0.9363 - mDice: 0.6815 - val_loss: 0.5284 - val_acc: 0.9401 - val_mDice: 0.5837

Epoch 00036: val_mDice did not improve from 0.59074
Epoch 37/300
 - 9s - loss: 0.3997 - acc: 0.9320 - mDice: 0.6563 - val_loss: 0.5454 - val_acc: 0.9393 - val_mDice: 0.5763

Epoch 00037: val_mDice did not improve from 0.59074
Epoch 38/300
 - 9s - loss: 0.3621 - acc: 0.9363 - mDice: 0.6820 - val_loss: 0.5374 - val_acc: 0.9405 - val_mDice: 0.5807

Epoch 00038: val_mDice did not improve from 0.59074
Epoch 39/300
 - 9s - loss: 0.3570 - acc: 0.9369 - mDice: 0.6849 - val_loss: 0.5406 - val_acc: 0.9395 - val_mDice: 0.5804

Epoch 00039: val_mDice did not improve from 0.59074
Epoch 40/300
 - 10s - loss: 0.3542 - acc: 0.9373 - mDice: 0.6878 - val_loss: 0.5373 - val_acc: 0.9406 - val_mDice: 0.5884

Epoch 00040: val_mDice did not improve from 0.59074
Epoch 41/300
 - 9s - loss: 0.3564 - acc: 0.9370 - mDice: 0.6855 - val_loss: 0.5410 - val_acc: 0.9412 - val_mDice: 0.5803

Epoch 00041: val_mDice did not improve from 0.59074
Epoch 42/300
 - 9s - loss: 0.3496 - acc: 0.9376 - mDice: 0.6903 - val_loss: 0.5332 - val_acc: 0.9390 - val_mDice: 0.5823

Epoch 00042: val_mDice did not improve from 0.59074
Epoch 43/300
 - 10s - loss: 0.3466 - acc: 0.9379 - mDice: 0.6924 - val_loss: 0.5243 - val_acc: 0.9412 - val_mDice: 0.5869

Epoch 00043: val_mDice did not improve from 0.59074
Epoch 44/300
 - 9s - loss: 0.3580 - acc: 0.9373 - mDice: 0.6871 - val_loss: 0.5385 - val_acc: 0.9408 - val_mDice: 0.5842

Epoch 00044: val_mDice did not improve from 0.59074
Epoch 45/300
 - 10s - loss: 0.3505 - acc: 0.9378 - mDice: 0.6902 - val_loss: 0.5172 - val_acc: 0.9415 - val_mDice: 0.5902

Epoch 00045: val_mDice did not improve from 0.59074
Epoch 46/300
 - 9s - loss: 0.3437 - acc: 0.9385 - mDice: 0.6951 - val_loss: 0.5271 - val_acc: 0.9426 - val_mDice: 0.5834

Epoch 00046: val_mDice did not improve from 0.59074
Epoch 47/300
 - 10s - loss: 0.3782 - acc: 0.9351 - mDice: 0.6728 - val_loss: 0.5891 - val_acc: 0.9407 - val_mDice: 0.5709

Epoch 00047: val_mDice did not improve from 0.59074
Epoch 48/300
 - 9s - loss: 0.4194 - acc: 0.9330 - mDice: 0.6472 - val_loss: 0.5328 - val_acc: 0.9365 - val_mDice: 0.5748

Epoch 00048: val_mDice did not improve from 0.59074
Epoch 49/300
 - 10s - loss: 0.3580 - acc: 0.9372 - mDice: 0.6837 - val_loss: 0.5324 - val_acc: 0.9397 - val_mDice: 0.5809

Epoch 00049: val_mDice did not improve from 0.59074
Epoch 50/300
 - 9s - loss: 0.3516 - acc: 0.9382 - mDice: 0.6901 - val_loss: 0.5204 - val_acc: 0.9412 - val_mDice: 0.5856

Epoch 00050: val_mDice did not improve from 0.59074
Epoch 51/300
 - 9s - loss: 0.3484 - acc: 0.9385 - mDice: 0.6910 - val_loss: 0.5306 - val_acc: 0.9412 - val_mDice: 0.5832

Epoch 00051: val_mDice did not improve from 0.59074
Epoch 52/300
 - 9s - loss: 0.3432 - acc: 0.9389 - mDice: 0.6961 - val_loss: 0.5374 - val_acc: 0.9407 - val_mDice: 0.5837

Epoch 00052: val_mDice did not improve from 0.59074
Epoch 53/300
 - 9s - loss: 0.3389 - acc: 0.9392 - mDice: 0.6978 - val_loss: 0.5158 - val_acc: 0.9424 - val_mDice: 0.5898

Epoch 00053: val_mDice did not improve from 0.59074
Epoch 54/300
 - 10s - loss: 0.3341 - acc: 0.9397 - mDice: 0.7015 - val_loss: 0.5468 - val_acc: 0.9400 - val_mDice: 0.5804

Epoch 00054: val_mDice did not improve from 0.59074
Epoch 55/300
 - 9s - loss: 0.3701 - acc: 0.9361 - mDice: 0.6794 - val_loss: 0.5004 - val_acc: 0.9395 - val_mDice: 0.5960

Epoch 00055: val_mDice improved from 0.59074 to 0.59596, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 56/300
 - 9s - loss: 0.3413 - acc: 0.9388 - mDice: 0.6969 - val_loss: 0.5147 - val_acc: 0.9413 - val_mDice: 0.5896

Epoch 00056: val_mDice did not improve from 0.59596
Epoch 57/300
 - 10s - loss: 0.3349 - acc: 0.9395 - mDice: 0.7017 - val_loss: 0.5107 - val_acc: 0.9401 - val_mDice: 0.5904

Epoch 00057: val_mDice did not improve from 0.59596
Epoch 58/300
 - 9s - loss: 0.3339 - acc: 0.9397 - mDice: 0.7017 - val_loss: 0.5197 - val_acc: 0.9404 - val_mDice: 0.5903

Epoch 00058: val_mDice did not improve from 0.59596
Epoch 59/300
 - 9s - loss: 0.3334 - acc: 0.9395 - mDice: 0.7034 - val_loss: 0.5493 - val_acc: 0.9417 - val_mDice: 0.5833

Epoch 00059: val_mDice did not improve from 0.59596
Epoch 60/300
 - 9s - loss: 0.3398 - acc: 0.9393 - mDice: 0.6981 - val_loss: 0.5019 - val_acc: 0.9439 - val_mDice: 0.5967

Epoch 00060: val_mDice improved from 0.59596 to 0.59667, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 61/300
 - 9s - loss: 0.3323 - acc: 0.9399 - mDice: 0.7050 - val_loss: 0.5173 - val_acc: 0.9422 - val_mDice: 0.5950

Epoch 00061: val_mDice did not improve from 0.59667
Epoch 62/300
 - 9s - loss: 0.3339 - acc: 0.9397 - mDice: 0.7027 - val_loss: 0.5129 - val_acc: 0.9421 - val_mDice: 0.5945

Epoch 00062: val_mDice did not improve from 0.59667
Epoch 63/300
 - 9s - loss: 0.3275 - acc: 0.9402 - mDice: 0.7063 - val_loss: 0.5215 - val_acc: 0.9404 - val_mDice: 0.5862

Epoch 00063: val_mDice did not improve from 0.59667
Epoch 64/300
 - 9s - loss: 0.3275 - acc: 0.9405 - mDice: 0.7079 - val_loss: 0.4982 - val_acc: 0.9428 - val_mDice: 0.6002

Epoch 00064: val_mDice improved from 0.59667 to 0.60021, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 65/300
 - 9s - loss: 0.3724 - acc: 0.9369 - mDice: 0.6768 - val_loss: 0.5231 - val_acc: 0.9417 - val_mDice: 0.5862

Epoch 00065: val_mDice did not improve from 0.60021
Epoch 66/300
 - 9s - loss: 0.3320 - acc: 0.9399 - mDice: 0.7029 - val_loss: 0.5276 - val_acc: 0.9436 - val_mDice: 0.5945

Epoch 00066: val_mDice did not improve from 0.60021
Epoch 67/300
 - 9s - loss: 0.3297 - acc: 0.9403 - mDice: 0.7059 - val_loss: 0.5541 - val_acc: 0.9410 - val_mDice: 0.5817

Epoch 00067: val_mDice did not improve from 0.60021
Epoch 68/300
 - 9s - loss: 0.3295 - acc: 0.9399 - mDice: 0.7049 - val_loss: 0.5427 - val_acc: 0.9430 - val_mDice: 0.5874

Epoch 00068: val_mDice did not improve from 0.60021
Epoch 69/300
 - 9s - loss: 0.3221 - acc: 0.9409 - mDice: 0.7110 - val_loss: 0.5115 - val_acc: 0.9429 - val_mDice: 0.5926

Epoch 00069: val_mDice did not improve from 0.60021
Epoch 70/300
 - 10s - loss: 0.3325 - acc: 0.9399 - mDice: 0.7030 - val_loss: 0.5494 - val_acc: 0.9416 - val_mDice: 0.5833

Epoch 00070: val_mDice did not improve from 0.60021
Epoch 71/300
 - 9s - loss: 0.3195 - acc: 0.9411 - mDice: 0.7122 - val_loss: 0.5445 - val_acc: 0.9424 - val_mDice: 0.5818

Epoch 00071: val_mDice did not improve from 0.60021
Epoch 72/300
 - 9s - loss: 0.3185 - acc: 0.9412 - mDice: 0.7131 - val_loss: 0.5279 - val_acc: 0.9407 - val_mDice: 0.5839

Epoch 00072: val_mDice did not improve from 0.60021
Epoch 73/300
 - 9s - loss: 0.3176 - acc: 0.9413 - mDice: 0.7146 - val_loss: 0.5138 - val_acc: 0.9430 - val_mDice: 0.5919

Epoch 00073: val_mDice did not improve from 0.60021
Epoch 74/300
 - 9s - loss: 0.3194 - acc: 0.9414 - mDice: 0.7137 - val_loss: 0.5256 - val_acc: 0.9415 - val_mDice: 0.5861

Epoch 00074: val_mDice did not improve from 0.60021
Epoch 75/300
 - 9s - loss: 0.3308 - acc: 0.9400 - mDice: 0.7058 - val_loss: 0.5483 - val_acc: 0.9397 - val_mDice: 0.5764

Epoch 00075: val_mDice did not improve from 0.60021
Epoch 76/300
 - 9s - loss: 0.3521 - acc: 0.9381 - mDice: 0.6911 - val_loss: 0.5256 - val_acc: 0.9427 - val_mDice: 0.5837

Epoch 00076: val_mDice did not improve from 0.60021
Epoch 77/300
 - 9s - loss: 0.3409 - acc: 0.9395 - mDice: 0.6978 - val_loss: 0.4961 - val_acc: 0.9426 - val_mDice: 0.5989

Epoch 00077: val_mDice did not improve from 0.60021
Epoch 78/300
 - 9s - loss: 0.3167 - acc: 0.9415 - mDice: 0.7143 - val_loss: 0.5019 - val_acc: 0.9432 - val_mDice: 0.5957

Epoch 00078: val_mDice did not improve from 0.60021
Epoch 79/300
 - 9s - loss: 0.3162 - acc: 0.9417 - mDice: 0.7157 - val_loss: 0.5431 - val_acc: 0.9413 - val_mDice: 0.5805

Epoch 00079: val_mDice did not improve from 0.60021
Epoch 80/300
 - 9s - loss: 0.3269 - acc: 0.9408 - mDice: 0.7081 - val_loss: 0.4991 - val_acc: 0.9421 - val_mDice: 0.5988

Epoch 00080: val_mDice did not improve from 0.60021
Epoch 81/300
 - 9s - loss: 0.3168 - acc: 0.9416 - mDice: 0.7155 - val_loss: 0.5641 - val_acc: 0.9407 - val_mDice: 0.5788

Epoch 00081: val_mDice did not improve from 0.60021
Epoch 82/300
 - 9s - loss: 0.3416 - acc: 0.9371 - mDice: 0.6969 - val_loss: 0.5140 - val_acc: 0.9421 - val_mDice: 0.5916

Epoch 00082: val_mDice did not improve from 0.60021
Epoch 83/300
 - 9s - loss: 0.3217 - acc: 0.9404 - mDice: 0.7106 - val_loss: 0.5156 - val_acc: 0.9422 - val_mDice: 0.5925

Epoch 00083: val_mDice did not improve from 0.60021
Epoch 84/300
 - 9s - loss: 0.3110 - acc: 0.9418 - mDice: 0.7186 - val_loss: 0.5100 - val_acc: 0.9426 - val_mDice: 0.5928

Epoch 00084: val_mDice did not improve from 0.60021
Epoch 85/300
 - 9s - loss: 0.3103 - acc: 0.9420 - mDice: 0.7191 - val_loss: 0.5074 - val_acc: 0.9417 - val_mDice: 0.5942

Epoch 00085: val_mDice did not improve from 0.60021
Epoch 86/300
 - 9s - loss: 0.3105 - acc: 0.9420 - mDice: 0.7197 - val_loss: 0.5203 - val_acc: 0.9441 - val_mDice: 0.5953

Epoch 00086: val_mDice did not improve from 0.60021
Epoch 87/300
 - 9s - loss: 0.3139 - acc: 0.9420 - mDice: 0.7174 - val_loss: 0.5173 - val_acc: 0.9436 - val_mDice: 0.5925

Epoch 00087: val_mDice did not improve from 0.60021
Epoch 88/300
 - 9s - loss: 0.3464 - acc: 0.9380 - mDice: 0.6951 - val_loss: 0.5365 - val_acc: 0.9424 - val_mDice: 0.5905

Epoch 00088: val_mDice did not improve from 0.60021
Epoch 89/300
 - 9s - loss: 0.3152 - acc: 0.9416 - mDice: 0.7165 - val_loss: 0.5402 - val_acc: 0.9411 - val_mDice: 0.5852

Epoch 00089: val_mDice did not improve from 0.60021
Epoch 90/300
 - 9s - loss: 0.3111 - acc: 0.9422 - mDice: 0.7196 - val_loss: 0.5171 - val_acc: 0.9430 - val_mDice: 0.5923

Epoch 00090: val_mDice did not improve from 0.60021
Epoch 91/300
 - 9s - loss: 0.3085 - acc: 0.9423 - mDice: 0.7206 - val_loss: 0.4988 - val_acc: 0.9438 - val_mDice: 0.6017

Epoch 00091: val_mDice improved from 0.60021 to 0.60165, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 92/300
 - 9s - loss: 0.3125 - acc: 0.9424 - mDice: 0.7190 - val_loss: 0.5124 - val_acc: 0.9419 - val_mDice: 0.5910

Epoch 00092: val_mDice did not improve from 0.60165
Epoch 93/300
 - 9s - loss: 0.3236 - acc: 0.9417 - mDice: 0.7118 - val_loss: 0.6918 - val_acc: 0.9433 - val_mDice: 0.5870

Epoch 00093: val_mDice did not improve from 0.60165
Epoch 94/300
 - 9s - loss: 0.3364 - acc: 0.9399 - mDice: 0.7030 - val_loss: 0.5163 - val_acc: 0.9437 - val_mDice: 0.5946

Epoch 00094: val_mDice did not improve from 0.60165
Epoch 95/300
 - 9s - loss: 0.3287 - acc: 0.9395 - mDice: 0.7063 - val_loss: 0.5371 - val_acc: 0.9437 - val_mDice: 0.6011

Epoch 00095: val_mDice did not improve from 0.60165
Epoch 96/300
 - 9s - loss: 0.3101 - acc: 0.9421 - mDice: 0.7195 - val_loss: 0.5047 - val_acc: 0.9423 - val_mDice: 0.5955

Epoch 00096: val_mDice did not improve from 0.60165
Epoch 97/300
 - 9s - loss: 0.3090 - acc: 0.9425 - mDice: 0.7219 - val_loss: 0.5076 - val_acc: 0.9438 - val_mDice: 0.5974

Epoch 00097: val_mDice did not improve from 0.60165
Epoch 98/300
 - 9s - loss: 0.3058 - acc: 0.9428 - mDice: 0.7235 - val_loss: 0.5197 - val_acc: 0.9425 - val_mDice: 0.5921

Epoch 00098: val_mDice did not improve from 0.60165
Epoch 99/300
 - 9s - loss: 0.3062 - acc: 0.9428 - mDice: 0.7232 - val_loss: 0.5132 - val_acc: 0.9422 - val_mDice: 0.5943

Epoch 00099: val_mDice did not improve from 0.60165
Epoch 100/300
 - 10s - loss: 0.3063 - acc: 0.9428 - mDice: 0.7222 - val_loss: 0.5232 - val_acc: 0.9427 - val_mDice: 0.5919

Epoch 00100: val_mDice did not improve from 0.60165
Epoch 101/300
 - 11s - loss: 0.3024 - acc: 0.9430 - mDice: 0.7259 - val_loss: 0.5165 - val_acc: 0.9415 - val_mDice: 0.5949

Epoch 00101: val_mDice did not improve from 0.60165
Epoch 102/300
 - 11s - loss: 0.3036 - acc: 0.9432 - mDice: 0.7249 - val_loss: 0.5031 - val_acc: 0.9435 - val_mDice: 0.5956

Epoch 00102: val_mDice did not improve from 0.60165
Epoch 103/300
 - 11s - loss: 0.3023 - acc: 0.9432 - mDice: 0.7263 - val_loss: 0.5258 - val_acc: 0.9447 - val_mDice: 0.5912

Epoch 00103: val_mDice did not improve from 0.60165
Epoch 104/300
 - 10s - loss: 0.3633 - acc: 0.9381 - mDice: 0.6895 - val_loss: 0.5165 - val_acc: 0.9412 - val_mDice: 0.5931

Epoch 00104: val_mDice did not improve from 0.60165
Epoch 105/300
 - 11s - loss: 0.3105 - acc: 0.9423 - mDice: 0.7189 - val_loss: 0.5204 - val_acc: 0.9417 - val_mDice: 0.5880

Epoch 00105: val_mDice did not improve from 0.60165
Epoch 106/300
 - 11s - loss: 0.3088 - acc: 0.9427 - mDice: 0.7223 - val_loss: 0.5291 - val_acc: 0.9440 - val_mDice: 0.5901

Epoch 00106: val_mDice did not improve from 0.60165
Epoch 107/300
 - 11s - loss: 0.3345 - acc: 0.9399 - mDice: 0.7022 - val_loss: 0.5227 - val_acc: 0.9417 - val_mDice: 0.5901

Epoch 00107: val_mDice did not improve from 0.60165
Epoch 108/300
 - 11s - loss: 0.3080 - acc: 0.9425 - mDice: 0.7217 - val_loss: 0.5140 - val_acc: 0.9419 - val_mDice: 0.5936

Epoch 00108: val_mDice did not improve from 0.60165
Epoch 109/300
 - 11s - loss: 0.3038 - acc: 0.9429 - mDice: 0.7240 - val_loss: 0.4972 - val_acc: 0.9435 - val_mDice: 0.6029

Epoch 00109: val_mDice improved from 0.60165 to 0.60291, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 110/300
 - 11s - loss: 0.3004 - acc: 0.9434 - mDice: 0.7267 - val_loss: 0.4968 - val_acc: 0.9439 - val_mDice: 0.6014

Epoch 00110: val_mDice did not improve from 0.60291
Epoch 111/300
 - 11s - loss: 0.2969 - acc: 0.9436 - mDice: 0.7292 - val_loss: 0.5094 - val_acc: 0.9426 - val_mDice: 0.5938

Epoch 00111: val_mDice did not improve from 0.60291
Epoch 112/300
 - 10s - loss: 0.2991 - acc: 0.9436 - mDice: 0.7277 - val_loss: 0.5147 - val_acc: 0.9429 - val_mDice: 0.5916

Epoch 00112: val_mDice did not improve from 0.60291
Epoch 113/300
 - 12s - loss: 0.2973 - acc: 0.9437 - mDice: 0.7300 - val_loss: 0.5038 - val_acc: 0.9447 - val_mDice: 0.5978

Epoch 00113: val_mDice did not improve from 0.60291
Epoch 114/300
 - 10s - loss: 0.2974 - acc: 0.9434 - mDice: 0.7292 - val_loss: 0.5141 - val_acc: 0.9430 - val_mDice: 0.5952

Epoch 00114: val_mDice did not improve from 0.60291
Epoch 115/300
 - 12s - loss: 0.2939 - acc: 0.9439 - mDice: 0.7315 - val_loss: 0.4984 - val_acc: 0.9439 - val_mDice: 0.5997

Epoch 00115: val_mDice did not improve from 0.60291
Epoch 116/300
 - 10s - loss: 0.3086 - acc: 0.9429 - mDice: 0.7224 - val_loss: 0.5264 - val_acc: 0.9446 - val_mDice: 0.5913

Epoch 00116: val_mDice did not improve from 0.60291
Epoch 117/300
 - 11s - loss: 0.3265 - acc: 0.9407 - mDice: 0.7099 - val_loss: 0.5219 - val_acc: 0.9428 - val_mDice: 0.5904

Epoch 00117: val_mDice did not improve from 0.60291
Epoch 118/300
 - 11s - loss: 0.3004 - acc: 0.9431 - mDice: 0.7266 - val_loss: 0.5200 - val_acc: 0.9426 - val_mDice: 0.5904

Epoch 00118: val_mDice did not improve from 0.60291
Epoch 119/300
 - 11s - loss: 0.2971 - acc: 0.9437 - mDice: 0.7292 - val_loss: 0.5056 - val_acc: 0.9439 - val_mDice: 0.5957

Epoch 00119: val_mDice did not improve from 0.60291
Epoch 120/300
 - 11s - loss: 0.3002 - acc: 0.9437 - mDice: 0.7300 - val_loss: 0.5079 - val_acc: 0.9437 - val_mDice: 0.5968

Epoch 00120: val_mDice did not improve from 0.60291
Epoch 121/300
 - 10s - loss: 0.3033 - acc: 0.9428 - mDice: 0.7246 - val_loss: 0.5078 - val_acc: 0.9445 - val_mDice: 0.5968

Epoch 00121: val_mDice did not improve from 0.60291
Epoch 122/300
 - 12s - loss: 0.2952 - acc: 0.9438 - mDice: 0.7307 - val_loss: 0.5196 - val_acc: 0.9431 - val_mDice: 0.5920

Epoch 00122: val_mDice did not improve from 0.60291
Epoch 123/300
 - 11s - loss: 0.2933 - acc: 0.9439 - mDice: 0.7322 - val_loss: 0.5024 - val_acc: 0.9437 - val_mDice: 0.5994

Epoch 00123: val_mDice did not improve from 0.60291
Epoch 124/300
 - 10s - loss: 0.2916 - acc: 0.9442 - mDice: 0.7335 - val_loss: 0.4964 - val_acc: 0.9443 - val_mDice: 0.6004

Epoch 00124: val_mDice did not improve from 0.60291
Epoch 125/300
 - 11s - loss: 0.2936 - acc: 0.9442 - mDice: 0.7328 - val_loss: 0.5010 - val_acc: 0.9429 - val_mDice: 0.5985

Epoch 00125: val_mDice did not improve from 0.60291
Epoch 126/300
 - 11s - loss: 0.2979 - acc: 0.9439 - mDice: 0.7305 - val_loss: 0.5055 - val_acc: 0.9441 - val_mDice: 0.5959

Epoch 00126: val_mDice did not improve from 0.60291
Epoch 127/300
 - 12s - loss: 0.2938 - acc: 0.9439 - mDice: 0.7318 - val_loss: 0.5242 - val_acc: 0.9432 - val_mDice: 0.5888

Epoch 00127: val_mDice did not improve from 0.60291
Epoch 128/300
 - 10s - loss: 0.2933 - acc: 0.9443 - mDice: 0.7338 - val_loss: 0.5629 - val_acc: 0.9449 - val_mDice: 0.5860

Epoch 00128: val_mDice did not improve from 0.60291
Epoch 129/300
 - 11s - loss: 0.3965 - acc: 0.9334 - mDice: 0.6682 - val_loss: 0.5435 - val_acc: 0.9425 - val_mDice: 0.5880

Epoch 00129: val_mDice did not improve from 0.60291
Epoch 130/300
 - 11s - loss: 0.3087 - acc: 0.9424 - mDice: 0.7211 - val_loss: 0.5088 - val_acc: 0.9457 - val_mDice: 0.6009

Epoch 00130: val_mDice did not improve from 0.60291
Epoch 131/300
 - 11s - loss: 0.3018 - acc: 0.9432 - mDice: 0.7257 - val_loss: 0.5118 - val_acc: 0.9435 - val_mDice: 0.5945

Epoch 00131: val_mDice did not improve from 0.60291
Epoch 132/300
 - 11s - loss: 0.2963 - acc: 0.9439 - mDice: 0.7307 - val_loss: 0.5127 - val_acc: 0.9441 - val_mDice: 0.5948

Epoch 00132: val_mDice did not improve from 0.60291
Epoch 133/300
 - 11s - loss: 0.2984 - acc: 0.9439 - mDice: 0.7290 - val_loss: 0.5267 - val_acc: 0.9439 - val_mDice: 0.5898

Epoch 00133: val_mDice did not improve from 0.60291
Epoch 134/300
 - 11s - loss: 0.2959 - acc: 0.9442 - mDice: 0.7319 - val_loss: 0.5198 - val_acc: 0.9437 - val_mDice: 0.5932

Epoch 00134: val_mDice did not improve from 0.60291
Epoch 135/300
 - 11s - loss: 0.2967 - acc: 0.9440 - mDice: 0.7297 - val_loss: 0.5005 - val_acc: 0.9456 - val_mDice: 0.5995

Epoch 00135: val_mDice did not improve from 0.60291
Epoch 136/300
 - 11s - loss: 0.2886 - acc: 0.9447 - mDice: 0.7358 - val_loss: 0.5271 - val_acc: 0.9435 - val_mDice: 0.5894

Epoch 00136: val_mDice did not improve from 0.60291
Epoch 137/300
 - 11s - loss: 0.2905 - acc: 0.9445 - mDice: 0.7350 - val_loss: 0.5284 - val_acc: 0.9427 - val_mDice: 0.5871

Epoch 00137: val_mDice did not improve from 0.60291
Epoch 138/300
 - 11s - loss: 0.2891 - acc: 0.9446 - mDice: 0.7354 - val_loss: 0.5130 - val_acc: 0.9443 - val_mDice: 0.5942

Epoch 00138: val_mDice did not improve from 0.60291
Epoch 139/300
 - 11s - loss: 0.2870 - acc: 0.9447 - mDice: 0.7370 - val_loss: 0.5144 - val_acc: 0.9431 - val_mDice: 0.5910

Epoch 00139: val_mDice did not improve from 0.60291
Epoch 140/300
 - 12s - loss: 0.2874 - acc: 0.9448 - mDice: 0.7376 - val_loss: 0.5385 - val_acc: 0.9438 - val_mDice: 0.5860

Epoch 00140: val_mDice did not improve from 0.60291
Epoch 141/300
 - 12s - loss: 0.2985 - acc: 0.9437 - mDice: 0.7287 - val_loss: 0.5293 - val_acc: 0.9429 - val_mDice: 0.5892

Epoch 00141: val_mDice did not improve from 0.60291
Epoch 142/300
 - 12s - loss: 0.2877 - acc: 0.9448 - mDice: 0.7375 - val_loss: 0.5232 - val_acc: 0.9443 - val_mDice: 0.5933

Epoch 00142: val_mDice did not improve from 0.60291
Epoch 143/300
 - 12s - loss: 0.3617 - acc: 0.9348 - mDice: 0.6881 - val_loss: 0.5088 - val_acc: 0.9435 - val_mDice: 0.5945

Epoch 00143: val_mDice did not improve from 0.60291
Epoch 144/300
 - 11s - loss: 0.3017 - acc: 0.9427 - mDice: 0.7259 - val_loss: 0.5182 - val_acc: 0.9421 - val_mDice: 0.5884

Epoch 00144: val_mDice did not improve from 0.60291
Epoch 145/300
 - 12s - loss: 0.2962 - acc: 0.9438 - mDice: 0.7310 - val_loss: 0.5001 - val_acc: 0.9431 - val_mDice: 0.5966

Epoch 00145: val_mDice did not improve from 0.60291
Epoch 146/300
 - 11s - loss: 0.2936 - acc: 0.9442 - mDice: 0.7331 - val_loss: 0.5167 - val_acc: 0.9439 - val_mDice: 0.5909

Epoch 00146: val_mDice did not improve from 0.60291
Epoch 147/300
 - 11s - loss: 0.2921 - acc: 0.9441 - mDice: 0.7332 - val_loss: 0.5114 - val_acc: 0.9442 - val_mDice: 0.5927

Epoch 00147: val_mDice did not improve from 0.60291
Epoch 148/300
 - 11s - loss: 0.2864 - acc: 0.9448 - mDice: 0.7382 - val_loss: 0.4991 - val_acc: 0.9435 - val_mDice: 0.6010

Epoch 00148: val_mDice did not improve from 0.60291
Epoch 149/300
 - 11s - loss: 0.2926 - acc: 0.9444 - mDice: 0.7328 - val_loss: 0.5010 - val_acc: 0.9450 - val_mDice: 0.6000

Epoch 00149: val_mDice did not improve from 0.60291
Restoring model weights from the end of the best epoch
Epoch 00149: early stopping
{'val_loss': [0.9424129731162301, 0.7306690102848927, 0.6435627897358474, 0.6323486763005816, 0.6209220683108495, 0.6341852918683484, 0.5834520385918005, 0.5784367839051359, 0.5584793000913865, 0.5549626070693885, 0.5504510712357207, 0.5479346433831327, 0.5417482175307566, 0.5463518958184972, 0.5476621166287854, 0.5573071645957798, 0.5159577209523271, 0.5280940812393273, 0.5373492527274446, 0.5501408007557832, 0.5440270014981318, 0.530238873798754, 0.5500030304466546, 0.5394493308147239, 0.5279203350317545, 0.526749319204405, 0.5299429397343257, 0.50542974671838, 0.5214764186123896, 0.5203087974194042, 0.540433737319275, 0.5555479767935236, 0.5337854778633437, 0.5192146938939334, 0.5296836861685001, 0.5283655720716082, 0.5454147436432333, 0.5373743066574608, 0.5405556161643407, 0.5372583366639121, 0.5410039989308938, 0.5331690477925306, 0.5243421130340192, 0.5384505815679135, 0.5172252934738244, 0.5271477992308207, 0.589051773428251, 0.5328007292148121, 0.5324148878704902, 0.5204013459509311, 0.530594815921517, 0.5374084697755356, 0.5157595546551923, 0.5467704462938469, 0.5003703436372, 0.5147318756780145, 0.5106630238740804, 0.5197239448238351, 0.549337063754737, 0.5018532599150801, 0.5172559379199364, 0.5129301787754676, 0.5215200803466349, 0.4982491558490519, 0.523104854968673, 0.5275620192122858, 0.5541380996810658, 0.5427166762964686, 0.5114753923935598, 0.549446410639992, 0.5445205604230892, 0.5279311592685444, 0.5138095041227074, 0.5256265721507578, 0.5483335869272328, 0.5255875810564563, 0.49607016753884003, 0.5018956388175154, 0.5430949756553053, 0.4990674134073311, 0.5641209035279364, 0.5140290936278231, 0.5155930848760978, 0.5099813035746527, 0.5073835641645187, 0.5202586004853914, 0.5173278314441276, 0.536515611510037, 0.5402080852892146, 0.5170952427986614, 0.49875168144369925, 0.5124155834067468, 0.6918194557035435, 0.5163356881567885, 0.5370878210946834, 0.5046850646008326, 0.5075752422130307, 0.5197187082727528, 0.5131844000776387, 0.5232390951177928, 0.5164593141838159, 0.5031456194776397, 0.5258063167833084, 0.5164989955598416, 0.5203968657794611, 0.5290789164644379, 0.5226787951405488, 0.5139845068561298, 0.4971719372538881, 0.4967889292946075, 0.509389541335612, 0.5146606459630935, 0.503773200445335, 0.5140782148478418, 0.49844580955345535, 0.526412445406674, 0.5218874122843397, 0.5200469140899914, 0.5056452759484339, 0.5078621992851768, 0.5077646094993506, 0.5195509854641707, 0.5023658059162801, 0.496352271993733, 0.5010013650249503, 0.5055417518375972, 0.5242255348400031, 0.5629147058092682, 0.5434959540819989, 0.5088075356110514, 0.511827262420228, 0.5126922436932612, 0.5267441226117437, 0.5198421015419774, 0.5005372123345316, 0.5270682663224929, 0.5284203174393937, 0.5130430594835867, 0.514378102132062, 0.5384783858027538, 0.5292663081398223, 0.5232305952956556, 0.50880042401106, 0.5181752116986493, 0.5000649595726802, 0.5166755225405347, 0.5114367774078966, 0.4990696582381286, 0.5010486922783559], 'val_acc': [0.9100735284096702, 0.9181745864825541, 0.9219283884464029, 0.922643339500747, 0.9255555974704593, 0.927160703270129, 0.9286635075201536, 0.9293579948681027, 0.9313084466497326, 0.9299220392823885, 0.9318929414509395, 0.9336745555840391, 0.937860661045799, 0.9335031702531783, 0.9356595460929018, 0.9339943138580749, 0.9373567623799074, 0.9364384479362872, 0.9378798480806404, 0.9370395624437812, 0.938124128893101, 0.9360956822693681, 0.9362990246804733, 0.9369666559736156, 0.9375626637948958, 0.9365394838029446, 0.9394031313544545, 0.9405260738713781, 0.9393903313402358, 0.9368400347299416, 0.9364461199531342, 0.9423575767591679, 0.9407460582988888, 0.9399492660714261, 0.9404531760588705, 0.9400950433821652, 0.9393340678854362, 0.9404889844649331, 0.9395169612415676, 0.9406156083725018, 0.9411655627815417, 0.9390386119901135, 0.9412218285672491, 0.9408163887828422, 0.9415032141035495, 0.9426402203197586, 0.9406552451282906, 0.9365087694295958, 0.9396525434941553, 0.9411809111440648, 0.9412448655959614, 0.940656536784252, 0.9423563064143644, 0.9400400492732085, 0.9394568471269235, 0.9413471771352118, 0.9400669213113838, 0.9404122433182913, 0.9417116685286581, 0.9439012947695216, 0.9422092168024798, 0.9420570135116577, 0.9404160656742544, 0.9427860246024318, 0.9416682054210641, 0.9436454992720534, 0.9409737237338913, 0.9430200770580569, 0.9429164895132267, 0.9416247243321808, 0.9423793198010109, 0.9407025815388343, 0.9430073006859039, 0.9415185541414016, 0.9397254466344525, 0.9427374324985056, 0.9425570871576917, 0.9432260061109532, 0.9413164744164024, 0.9420633992003329, 0.9406795461750563, 0.9421145632946292, 0.9422348018465095, 0.9425749915272164, 0.9416656537428915, 0.9440586117392812, 0.9435674831187925, 0.9423997768476688, 0.9411387137194586, 0.9429996226752937, 0.9438450299827746, 0.9418523901001701, 0.9432822938737923, 0.9437196704262462, 0.9436646853079343, 0.9422705962671248, 0.9438040922473929, 0.9424650186266978, 0.9421925857746402, 0.9427361498331891, 0.9415134444583062, 0.9434996909935381, 0.9447351947177056, 0.9412167268758379, 0.9417334278868563, 0.9439690838978944, 0.9416681894376957, 0.9419431809606499, 0.9435073716680431, 0.9438539929896094, 0.9425954625593217, 0.9429408118711503, 0.9447377414010757, 0.9430315984028012, 0.9438770127030058, 0.9446200921548812, 0.9427770842387023, 0.9425519628231752, 0.9438910737383965, 0.9436710913088069, 0.944479404548027, 0.9431492483149694, 0.9436659619794877, 0.9443374402696194, 0.9428896251337489, 0.9441174654987271, 0.943233674464945, 0.9449014736953394, 0.9424675579843574, 0.9457494260212562, 0.9435431967234479, 0.9441072141657995, 0.9438897850793168, 0.9436966736889418, 0.9455652776377161, 0.943524000031988, 0.9427092911144874, 0.9442888551584169, 0.9430827491776237, 0.9438437423226553, 0.9429190338656889, 0.9442555741224875, 0.9435150560054033, 0.9421478236853743, 0.9431083312247719, 0.9439370941849394, 0.9442236090505589, 0.9434907353124139, 0.9449539207879392], 'val_mDice': [0.3845411862074996, 0.4700720976184866, 0.5130695787222026, 0.5224675765916622, 0.5306621340400014, 0.5298906178447788, 0.548818568943599, 0.5502796426165704, 0.5594766326456763, 0.5617407563678379, 0.5650588134147602, 0.5691641918773758, 0.573837855674701, 0.568339821679632, 0.5703265613683776, 0.5670482043447441, 0.584292173718607, 0.5785552696142783, 0.5790784838479325, 0.5687889992857779, 0.5758362255948882, 0.577259154959098, 0.5744388756139318, 0.580056455881236, 0.5793371813257313, 0.5824131366260891, 0.5805525153708857, 0.5907449669012145, 0.588530721278164, 0.5821618344530713, 0.571741305916003, 0.5818193764659946, 0.5866394778869671, 0.5870245139026109, 0.5874456826535017, 0.5836942472271414, 0.5763448506760198, 0.5806924850581079, 0.58041509170106, 0.5884370111220376, 0.5803036759685538, 0.5822564746414483, 0.5868781625225558, 0.5841807989434823, 0.5901737835820161, 0.5834013323544124, 0.5709403453592482, 0.5748215987029688, 0.580869125920301, 0.585568568892985, 0.5832448588403244, 0.5837458228931747, 0.5897693594074782, 0.5803883891531875, 0.595959279790271, 0.5896425610148041, 0.5903971731329763, 0.5902871592750762, 0.5832814197966506, 0.5966734423317723, 0.595018919619768, 0.5944547733115084, 0.5861689391748865, 0.6002076125011764, 0.5862448988014093, 0.5944763445321408, 0.5816825105491297, 0.5874218877467363, 0.5925785246508082, 0.5833416624442159, 0.5818165334243348, 0.5838627112644345, 0.5918518611172724, 0.5860909483286255, 0.576428044441692, 0.5837019169130805, 0.5989301657543502, 0.5956941686529021, 0.580530197260766, 0.5988251267198744, 0.5787628189811493, 0.5915855961804949, 0.5925043708119313, 0.592774768115422, 0.5941917100432199, 0.5952686720720216, 0.5925464876537216, 0.5904775514948968, 0.585176116927376, 0.5923029041157089, 0.6016532858656771, 0.5910402459805238, 0.5870375653218957, 0.5945656642567512, 0.6010854054429677, 0.5955149421478783, 0.5974491035472081, 0.5921313782644005, 0.5943305938603491, 0.5918778467444734, 0.5948843399905626, 0.59556546557549, 0.5911948191387028, 0.5931336406888909, 0.5880190916567541, 0.59013844901623, 0.5900875596360787, 0.5936117648412396, 0.6029089845758576, 0.6014282969789132, 0.5938439525705476, 0.5916392660007797, 0.5978390780907104, 0.5951665813030478, 0.5996995794706504, 0.5912688647568559, 0.5903733532521978, 0.5904114732529198, 0.5956795658479189, 0.5967584528736563, 0.5968335810320338, 0.592038585154038, 0.5994095086385418, 0.6003783485076947, 0.598499207523282, 0.5958514010440038, 0.5888430536126291, 0.5860126504684959, 0.5879955438262258, 0.6008872729439975, 0.5945126001395327, 0.5947810714471273, 0.5898159442667189, 0.5931797906673154, 0.5995460086028669, 0.5893585944974888, 0.587084619692584, 0.5942372073674335, 0.5910148504060074, 0.5859555189169985, 0.5892361442470018, 0.5932968412031675, 0.5945250888110539, 0.5884378269398013, 0.5966369832694197, 0.5908798072591174, 0.5926964799119108, 0.6009853425638636, 0.5999993738515417], 'loss': [2.2488566778871517, 0.9377267885454795, 0.7451905804844098, 0.6592871641421103, 0.6055343481913724, 0.6033723599553555, 0.5528213447574815, 0.5311918375711918, 0.5140210886443649, 0.4985981154410396, 0.49032562084814174, 0.4760520586571837, 0.46955665462954627, 0.45887292155098364, 0.44684024045863735, 0.4421005768349838, 0.4357086756381994, 0.4284052928921562, 0.42223943331769037, 0.43660165444628585, 0.41075850165462213, 0.40514957867634566, 0.400402849580734, 0.39305648438610574, 0.39037657525563824, 0.38624989720106195, 0.3846213473444452, 0.38118887716041444, 0.37717014547535294, 0.3828646807499379, 0.37505709329958753, 0.39633835899453823, 0.3722762568254042, 0.3692718393445462, 0.3620502236697383, 0.36302832616295677, 0.3997161303182949, 0.3620556975574205, 0.35702267854133185, 0.35419397072879594, 0.35642586726907277, 0.34957009312080944, 0.3466385596149627, 0.35796281670276214, 0.3504620248211701, 0.3436599331981138, 0.3782114278340342, 0.41939356405590644, 0.35798101562287576, 0.3516395977948691, 0.34839980527478986, 0.34319477020720823, 0.33889707351918275, 0.3341448384482886, 0.37006487274692274, 0.3412582122272356, 0.3348512513628595, 0.33387356789470723, 0.33342458861076585, 0.33980328000296756, 0.33225282950821605, 0.3338592667489691, 0.32753673789829835, 0.3274850486947286, 0.3724396737869207, 0.3319544817597499, 0.32967902074443944, 0.329513128917543, 0.32213885495889766, 0.33250476886200997, 0.31951564823061257, 0.31854389676373995, 0.3176156778293977, 0.31944109945778965, 0.3307515038705426, 0.35212528714665486, 0.34087624128117067, 0.3166816340569901, 0.31619710109214266, 0.32692023266859915, 0.31680597510755226, 0.3416380538443714, 0.3216915180703933, 0.31095883494785437, 0.3103330146983449, 0.31048566425217855, 0.31390698282674406, 0.3463630400978173, 0.31523007243941215, 0.3110935599872362, 0.30850481249725303, 0.3125389899319042, 0.3235793536726753, 0.3363910418202928, 0.32872259220555583, 0.31012318110185483, 0.30901118498422125, 0.3057666095858813, 0.3062164895021114, 0.3063458684842816, 0.3024437639181023, 0.30363116050083333, 0.30231139303547505, 0.3632561707970627, 0.3104975612280347, 0.3087545272991785, 0.3345080726842438, 0.3079593222751157, 0.3038377095815291, 0.30041207020526267, 0.296931614848225, 0.29909357845704637, 0.297318313097371, 0.2974358499866311, 0.29392083057683505, 0.30863736393195595, 0.326498263698887, 0.30041358599750806, 0.29710998180514964, 0.300154767845112, 0.3033417075591296, 0.29516243736332093, 0.29326610488284127, 0.29156219381289256, 0.29358398489323817, 0.29793564109062737, 0.2938277118557159, 0.29330017336581227, 0.3965355123300946, 0.30872215642710465, 0.3018110962562888, 0.2963351709253346, 0.29838875284638944, 0.29586836450517584, 0.29672069465646106, 0.288551255910969, 0.29051896104803915, 0.2890987738215762, 0.28695104337147276, 0.2874201185346097, 0.2985124800519366, 0.2877412967422403, 0.36170144343015836, 0.3016559454838298, 0.29618887542070127, 0.2935610888683599, 0.2921103987336848, 0.2863693212759109, 0.2926242556662888], 'acc': [0.7967979214667597, 0.8881714311559201, 0.8992482654486603, 0.9072067000184222, 0.9124268718212707, 0.9134944415573707, 0.9178840835095178, 0.919790545170321, 0.9217197617793835, 0.9231475630352083, 0.9241278926527443, 0.9253574299490686, 0.9259642468273598, 0.926867107830421, 0.9279364682511078, 0.9287636986379993, 0.9289602439898557, 0.9296398340101985, 0.9305136255577595, 0.9291696294179395, 0.9315257441781092, 0.9318629406881521, 0.9321988121722506, 0.9328704146079425, 0.9330377701040045, 0.933498965695127, 0.9337436474231716, 0.9340534417270611, 0.9344056625917095, 0.9338889887093748, 0.9351765566380515, 0.9336051550788369, 0.9354292272203458, 0.9356913691070503, 0.9361066808261885, 0.9363231262941609, 0.9319627203144762, 0.9363468604114914, 0.9369021017334502, 0.9372670234839686, 0.937045143286371, 0.9376132504392776, 0.9378650846279638, 0.9373058224863376, 0.9377757989619057, 0.9385339952359179, 0.9350883624522001, 0.9330448291765796, 0.9372480047899009, 0.938227846180163, 0.9385258409468877, 0.9388860498677525, 0.9392112841022366, 0.9397117258907755, 0.9360651648882522, 0.938829019697458, 0.9394924011841327, 0.9397165090259788, 0.93950563829416, 0.9393214466835642, 0.9398727895993709, 0.9397129787370004, 0.9402428884174437, 0.9404641384768406, 0.9368620670607153, 0.939877918416122, 0.9403237647320559, 0.9398801691791617, 0.9408948448381677, 0.9399428702728394, 0.941097798109514, 0.9412315513616354, 0.9412735124572149, 0.9414178336811714, 0.9399811380629438, 0.9381301550077297, 0.939463721852187, 0.9414665285297262, 0.9417103731386777, 0.9407888871441629, 0.9415770391746109, 0.9371110887069927, 0.9404282145174199, 0.9418037031966225, 0.9420342171200633, 0.9420293626334026, 0.9419753751777492, 0.9380128864935366, 0.9416177660205662, 0.9422338265702332, 0.9423162369290863, 0.9424136516131111, 0.9416899620029648, 0.9399048554593814, 0.9395476449441567, 0.9420904813534421, 0.942492533756664, 0.9428012830053458, 0.9428457728577551, 0.9428451944466403, 0.943049029496732, 0.9432029387798303, 0.9432283453276801, 0.9381328449612978, 0.9422678444385286, 0.9427221671528211, 0.9399283577116814, 0.9425338413292405, 0.9429009712326417, 0.9433673922811733, 0.9436045738235789, 0.9435951916087362, 0.9437344497811638, 0.9434007826411515, 0.9439075404423126, 0.9428843462221738, 0.9407396115568954, 0.9430914080182876, 0.9437426904089637, 0.9436699408693601, 0.9428201594317899, 0.9437644061663533, 0.9439198917229696, 0.9441879805075807, 0.9441577010820236, 0.9438751952947304, 0.9438649044158747, 0.9443359484427333, 0.9334307662951485, 0.9424019724762407, 0.9431579570122647, 0.9439042422904218, 0.9438794192562651, 0.9441825495746607, 0.9439574876957557, 0.9446507815609042, 0.9445056921873026, 0.9446019459621988, 0.9447188652762415, 0.9447737378297344, 0.9437096948942387, 0.9447778006187135, 0.9347690715244714, 0.942697089545951, 0.9437910851968908, 0.9442259487025768, 0.9441411441583302, 0.9448120749580751, 0.944362838238777], 'mDice': [0.16116272532925704, 0.3799961550093795, 0.4584912506776379, 0.5003868884955159, 0.5287656242724835, 0.5340735809969145, 0.5583738256315754, 0.5710117066229365, 0.5821461661832427, 0.5911362660150038, 0.5968854489245706, 0.6063299114690348, 0.6097894597094639, 0.6169360784188598, 0.6240495910314677, 0.6277332822937235, 0.6312986811223772, 0.6358849379097137, 0.6424895488885755, 0.6315708637104543, 0.6482198177613427, 0.6517079399025988, 0.6544715726226855, 0.6594850520826956, 0.6613991009329356, 0.6641741580297623, 0.6653935782311352, 0.6677874406509291, 0.671091574855479, 0.6669253070258456, 0.6735388876664153, 0.6592135929543828, 0.6755602489694015, 0.6772655893960944, 0.6812358100221539, 0.6814961306208928, 0.6563375188559762, 0.6820155211486008, 0.6849168492253453, 0.6878295795213065, 0.6855098513261169, 0.6903254351614455, 0.6923795936678109, 0.6871414055252597, 0.6901924487954161, 0.6950753780441021, 0.6728360906692218, 0.6471629223834188, 0.6836974778491182, 0.6901485244011901, 0.6910018170021383, 0.6960842013842726, 0.6978092650175457, 0.7014695562785774, 0.6793577895649113, 0.6969398618022549, 0.701692680471482, 0.7017284713950768, 0.7034290241220561, 0.6980508246266076, 0.7049981314677207, 0.7026960909977225, 0.7063056382413253, 0.7078851820525636, 0.676847071891407, 0.7028609619371329, 0.7058636783429026, 0.7049201670809273, 0.7110225983233829, 0.7030481526425795, 0.7122245104478065, 0.7130701374253124, 0.7145549702177619, 0.713709131368385, 0.7058080005795686, 0.6911377727846331, 0.6978344511993033, 0.7142772739128719, 0.7156916894611886, 0.7081320666918612, 0.7154615293386827, 0.6968984280255035, 0.71055153810007, 0.7185893550292995, 0.7191037238520823, 0.7197169975596492, 0.7174191453724341, 0.6951295983139624, 0.7164882494283866, 0.7195640995543825, 0.7205574240727071, 0.7189786100087706, 0.7118474610232233, 0.7030194577368873, 0.7062790685172061, 0.7195177890064871, 0.7218528126761014, 0.7234926951416415, 0.7232467075404585, 0.7222461716883781, 0.725943082552288, 0.7249037558897742, 0.7263241091888397, 0.6894714602568968, 0.7188804651602901, 0.7222863775967512, 0.7022217212324029, 0.7216794780766411, 0.7239981885492736, 0.7266535964768102, 0.729222436084964, 0.7277242992988089, 0.7300004972165177, 0.7291663059635474, 0.7315468999565415, 0.7223969442339695, 0.7099334887116588, 0.7266032189442138, 0.7291916901241368, 0.7299664826310422, 0.7246187084078342, 0.7306650881895925, 0.7321977738567994, 0.7334835949262338, 0.7328161700089402, 0.7304531713022472, 0.7318497615129448, 0.733815656942605, 0.6681785374858678, 0.7210674314363961, 0.7257327941794317, 0.7306866480039648, 0.7290078844353277, 0.7319395049117209, 0.7297353381462012, 0.7357820042890109, 0.734963220507224, 0.7354114920834957, 0.7369619176080423, 0.7375891090636443, 0.7286862893549034, 0.7375275721075036, 0.6880690149402918, 0.7259431915987408, 0.7309860501512817, 0.7330858469771159, 0.733160178618301, 0.7381843393950981, 0.7328275183850725]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:04<00:17,  4.50s/it]predicting test subjects:  40%|████      | 2/5 [00:08<00:12,  4.29s/it]predicting test subjects:  60%|██████    | 3/5 [00:11<00:07,  3.93s/it]predicting test subjects:  80%|████████  | 4/5 [00:14<00:03,  3.73s/it]predicting test subjects: 100%|██████████| 5/5 [00:18<00:00,  3.75s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:04<20:13,  4.58s/it]predicting train subjects:   1%|          | 2/266 [00:08<19:38,  4.47s/it]predicting train subjects:   1%|          | 3/266 [00:12<18:29,  4.22s/it]predicting train subjects:   2%|▏         | 4/266 [00:15<17:22,  3.98s/it]predicting train subjects:   2%|▏         | 5/266 [00:20<17:36,  4.05s/it]predicting train subjects:   2%|▏         | 6/266 [00:24<18:14,  4.21s/it]predicting train subjects:   3%|▎         | 7/266 [00:28<18:20,  4.25s/it]predicting train subjects:   3%|▎         | 8/266 [00:33<18:15,  4.24s/it]predicting train subjects:   3%|▎         | 9/266 [00:37<18:06,  4.23s/it]predicting train subjects:   4%|▍         | 10/266 [00:41<17:48,  4.17s/it]predicting train subjects:   4%|▍         | 11/266 [00:45<17:50,  4.20s/it]predicting train subjects:   5%|▍         | 12/266 [00:50<18:19,  4.33s/it]predicting train subjects:   5%|▍         | 13/266 [00:54<18:22,  4.36s/it]predicting train subjects:   5%|▌         | 14/266 [00:59<18:27,  4.40s/it]predicting train subjects:   6%|▌         | 15/266 [01:03<18:35,  4.44s/it]predicting train subjects:   6%|▌         | 16/266 [01:08<18:25,  4.42s/it]predicting train subjects:   6%|▋         | 17/266 [01:12<18:07,  4.37s/it]predicting train subjects:   7%|▋         | 18/266 [01:16<17:48,  4.31s/it]predicting train subjects:   7%|▋         | 19/266 [01:20<17:48,  4.33s/it]predicting train subjects:   8%|▊         | 20/266 [01:25<17:36,  4.29s/it]predicting train subjects:   8%|▊         | 21/266 [01:29<17:14,  4.22s/it]predicting train subjects:   8%|▊         | 22/266 [01:33<17:15,  4.24s/it]predicting train subjects:   9%|▊         | 23/266 [01:37<16:50,  4.16s/it]predicting train subjects:   9%|▉         | 24/266 [01:41<16:26,  4.08s/it]predicting train subjects:   9%|▉         | 25/266 [01:45<16:00,  3.99s/it]predicting train subjects:  10%|▉         | 26/266 [01:49<15:48,  3.95s/it]predicting train subjects:  10%|█         | 27/266 [01:52<15:40,  3.93s/it]predicting train subjects:  11%|█         | 28/266 [01:57<16:07,  4.06s/it]predicting train subjects:  11%|█         | 29/266 [02:01<16:19,  4.13s/it]predicting train subjects:  11%|█▏        | 30/266 [02:05<16:02,  4.08s/it]predicting train subjects:  12%|█▏        | 31/266 [02:09<15:50,  4.05s/it]predicting train subjects:  12%|█▏        | 32/266 [02:13<15:35,  4.00s/it]predicting train subjects:  12%|█▏        | 33/266 [02:17<15:50,  4.08s/it]predicting train subjects:  13%|█▎        | 34/266 [02:21<15:42,  4.06s/it]predicting train subjects:  13%|█▎        | 35/266 [02:26<16:05,  4.18s/it]predicting train subjects:  14%|█▎        | 36/266 [02:30<15:53,  4.15s/it]predicting train subjects:  14%|█▍        | 37/266 [02:34<15:52,  4.16s/it]predicting train subjects:  14%|█▍        | 38/266 [02:38<15:20,  4.04s/it]predicting train subjects:  15%|█▍        | 39/266 [02:42<15:14,  4.03s/it]predicting train subjects:  15%|█▌        | 40/266 [02:46<15:06,  4.01s/it]predicting train subjects:  15%|█▌        | 41/266 [02:49<14:53,  3.97s/it]predicting train subjects:  16%|█▌        | 42/266 [02:53<14:16,  3.82s/it]predicting train subjects:  16%|█▌        | 43/266 [02:56<13:48,  3.72s/it]predicting train subjects:  17%|█▋        | 44/266 [03:00<13:33,  3.66s/it]predicting train subjects:  17%|█▋        | 45/266 [03:04<13:36,  3.69s/it]predicting train subjects:  17%|█▋        | 46/266 [03:07<13:13,  3.61s/it]predicting train subjects:  18%|█▊        | 47/266 [03:11<12:54,  3.54s/it]predicting train subjects:  18%|█▊        | 48/266 [03:14<13:04,  3.60s/it]predicting train subjects:  18%|█▊        | 49/266 [03:18<12:56,  3.58s/it]predicting train subjects:  19%|█▉        | 50/266 [03:21<12:51,  3.57s/it]predicting train subjects:  19%|█▉        | 51/266 [03:25<13:02,  3.64s/it]predicting train subjects:  20%|█▉        | 52/266 [03:29<13:03,  3.66s/it]predicting train subjects:  20%|█▉        | 53/266 [03:32<12:31,  3.53s/it]predicting train subjects:  20%|██        | 54/266 [03:36<12:27,  3.53s/it]predicting train subjects:  21%|██        | 55/266 [03:39<12:18,  3.50s/it]predicting train subjects:  21%|██        | 56/266 [03:42<12:13,  3.49s/it]predicting train subjects:  21%|██▏       | 57/266 [03:46<12:00,  3.45s/it]predicting train subjects:  22%|██▏       | 58/266 [03:49<12:03,  3.48s/it]predicting train subjects:  22%|██▏       | 59/266 [03:53<11:58,  3.47s/it]predicting train subjects:  23%|██▎       | 60/266 [03:56<11:59,  3.49s/it]predicting train subjects:  23%|██▎       | 61/266 [04:00<11:47,  3.45s/it]predicting train subjects:  23%|██▎       | 62/266 [04:03<11:35,  3.41s/it]predicting train subjects:  24%|██▎       | 63/266 [04:07<11:39,  3.45s/it]predicting train subjects:  24%|██▍       | 64/266 [04:10<11:31,  3.43s/it]predicting train subjects:  24%|██▍       | 65/266 [04:14<11:37,  3.47s/it]predicting train subjects:  25%|██▍       | 66/266 [04:17<11:20,  3.40s/it]predicting train subjects:  25%|██▌       | 67/266 [04:20<11:25,  3.45s/it]predicting train subjects:  26%|██▌       | 68/266 [04:24<11:26,  3.47s/it]predicting train subjects:  26%|██▌       | 69/266 [04:27<11:11,  3.41s/it]predicting train subjects:  26%|██▋       | 70/266 [04:31<11:25,  3.50s/it]predicting train subjects:  27%|██▋       | 71/266 [04:34<11:14,  3.46s/it]predicting train subjects:  27%|██▋       | 72/266 [04:37<10:53,  3.37s/it]predicting train subjects:  27%|██▋       | 73/266 [04:41<10:37,  3.30s/it]predicting train subjects:  28%|██▊       | 74/266 [04:44<10:22,  3.24s/it]predicting train subjects:  28%|██▊       | 75/266 [04:47<10:24,  3.27s/it]predicting train subjects:  29%|██▊       | 76/266 [04:50<10:10,  3.22s/it]predicting train subjects:  29%|██▉       | 77/266 [04:53<10:00,  3.18s/it]predicting train subjects:  29%|██▉       | 78/266 [04:57<10:27,  3.34s/it]predicting train subjects:  30%|██▉       | 79/266 [05:01<11:05,  3.56s/it]predicting train subjects:  30%|███       | 80/266 [05:05<11:29,  3.71s/it]predicting train subjects:  30%|███       | 81/266 [05:09<11:35,  3.76s/it]predicting train subjects:  31%|███       | 82/266 [05:13<11:40,  3.81s/it]predicting train subjects:  31%|███       | 83/266 [05:17<11:41,  3.83s/it]predicting train subjects:  32%|███▏      | 84/266 [05:21<11:48,  3.89s/it]predicting train subjects:  32%|███▏      | 85/266 [05:25<11:49,  3.92s/it]predicting train subjects:  32%|███▏      | 86/266 [05:28<11:38,  3.88s/it]predicting train subjects:  33%|███▎      | 87/266 [05:33<11:44,  3.93s/it]predicting train subjects:  33%|███▎      | 88/266 [05:37<11:47,  3.97s/it]predicting train subjects:  33%|███▎      | 89/266 [05:40<11:33,  3.92s/it]predicting train subjects:  34%|███▍      | 90/266 [05:44<11:23,  3.88s/it]predicting train subjects:  34%|███▍      | 91/266 [05:48<11:19,  3.88s/it]predicting train subjects:  35%|███▍      | 92/266 [05:52<11:26,  3.94s/it]predicting train subjects:  35%|███▍      | 93/266 [05:56<11:26,  3.97s/it]predicting train subjects:  35%|███▌      | 94/266 [06:00<11:21,  3.96s/it]predicting train subjects:  36%|███▌      | 95/266 [06:04<11:34,  4.06s/it]predicting train subjects:  36%|███▌      | 96/266 [06:08<11:08,  3.93s/it]predicting train subjects:  36%|███▋      | 97/266 [06:12<11:15,  4.00s/it]predicting train subjects:  37%|███▋      | 98/266 [06:16<11:00,  3.93s/it]predicting train subjects:  37%|███▋      | 99/266 [06:19<10:13,  3.67s/it]predicting train subjects:  38%|███▊      | 100/266 [06:23<10:13,  3.70s/it]predicting train subjects:  38%|███▊      | 101/266 [06:26<10:00,  3.64s/it]predicting train subjects:  38%|███▊      | 102/266 [06:30<09:59,  3.66s/it]predicting train subjects:  39%|███▊      | 103/266 [06:34<10:00,  3.68s/it]predicting train subjects:  39%|███▉      | 104/266 [06:37<09:58,  3.69s/it]predicting train subjects:  39%|███▉      | 105/266 [06:41<09:52,  3.68s/it]predicting train subjects:  40%|███▉      | 106/266 [06:45<09:44,  3.65s/it]predicting train subjects:  40%|████      | 107/266 [06:48<09:24,  3.55s/it]predicting train subjects:  41%|████      | 108/266 [06:52<09:35,  3.65s/it]predicting train subjects:  41%|████      | 109/266 [06:55<09:27,  3.62s/it]predicting train subjects:  41%|████▏     | 110/266 [06:59<09:29,  3.65s/it]predicting train subjects:  42%|████▏     | 111/266 [07:03<09:27,  3.66s/it]predicting train subjects:  42%|████▏     | 112/266 [07:07<09:24,  3.66s/it]predicting train subjects:  42%|████▏     | 113/266 [07:10<09:21,  3.67s/it]predicting train subjects:  43%|████▎     | 114/266 [07:14<09:26,  3.72s/it]predicting train subjects:  43%|████▎     | 115/266 [07:18<09:17,  3.69s/it]predicting train subjects:  44%|████▎     | 116/266 [07:22<09:23,  3.76s/it]predicting train subjects:  44%|████▍     | 117/266 [07:26<09:28,  3.82s/it]predicting train subjects:  44%|████▍     | 118/266 [07:29<09:25,  3.82s/it]predicting train subjects:  45%|████▍     | 119/266 [07:33<09:35,  3.91s/it]predicting train subjects:  45%|████▌     | 120/266 [07:38<09:45,  4.01s/it]predicting train subjects:  45%|████▌     | 121/266 [07:42<09:44,  4.03s/it]predicting train subjects:  46%|████▌     | 122/266 [07:46<09:41,  4.04s/it]predicting train subjects:  46%|████▌     | 123/266 [07:50<09:47,  4.11s/it]predicting train subjects:  47%|████▋     | 124/266 [07:54<09:49,  4.15s/it]predicting train subjects:  47%|████▋     | 125/266 [07:58<09:34,  4.07s/it]predicting train subjects:  47%|████▋     | 126/266 [08:03<09:36,  4.12s/it]predicting train subjects:  48%|████▊     | 127/266 [08:07<09:29,  4.10s/it]predicting train subjects:  48%|████▊     | 128/266 [08:11<09:29,  4.13s/it]predicting train subjects:  48%|████▊     | 129/266 [08:15<09:21,  4.10s/it]predicting train subjects:  49%|████▉     | 130/266 [08:19<09:14,  4.08s/it]predicting train subjects:  49%|████▉     | 131/266 [08:23<09:08,  4.06s/it]predicting train subjects:  50%|████▉     | 132/266 [08:27<09:07,  4.08s/it]predicting train subjects:  50%|█████     | 133/266 [08:31<08:48,  3.98s/it]predicting train subjects:  50%|█████     | 134/266 [08:35<09:04,  4.13s/it]predicting train subjects:  51%|█████     | 135/266 [08:39<08:58,  4.11s/it]predicting train subjects:  51%|█████     | 136/266 [08:43<08:52,  4.10s/it]predicting train subjects:  52%|█████▏    | 137/266 [08:47<08:15,  3.84s/it]predicting train subjects:  52%|█████▏    | 138/266 [08:50<07:54,  3.70s/it]predicting train subjects:  52%|█████▏    | 139/266 [08:53<07:39,  3.62s/it]predicting train subjects:  53%|█████▎    | 140/266 [08:57<07:21,  3.50s/it]predicting train subjects:  53%|█████▎    | 141/266 [09:00<07:11,  3.45s/it]predicting train subjects:  53%|█████▎    | 142/266 [09:03<07:01,  3.40s/it]predicting train subjects:  54%|█████▍    | 143/266 [09:06<06:51,  3.35s/it]predicting train subjects:  54%|█████▍    | 144/266 [09:10<06:43,  3.31s/it]predicting train subjects:  55%|█████▍    | 145/266 [09:13<06:41,  3.32s/it]predicting train subjects:  55%|█████▍    | 146/266 [09:16<06:36,  3.30s/it]predicting train subjects:  55%|█████▌    | 147/266 [09:20<06:34,  3.31s/it]predicting train subjects:  56%|█████▌    | 148/266 [09:23<06:25,  3.26s/it]predicting train subjects:  56%|█████▌    | 149/266 [09:26<06:15,  3.21s/it]predicting train subjects:  56%|█████▋    | 150/266 [09:29<06:12,  3.21s/it]predicting train subjects:  57%|█████▋    | 151/266 [09:32<06:15,  3.27s/it]predicting train subjects:  57%|█████▋    | 152/266 [09:36<06:10,  3.25s/it]predicting train subjects:  58%|█████▊    | 153/266 [09:39<06:05,  3.23s/it]predicting train subjects:  58%|█████▊    | 154/266 [09:42<06:04,  3.26s/it]predicting train subjects:  58%|█████▊    | 155/266 [09:44<05:30,  2.98s/it]predicting train subjects:  59%|█████▊    | 156/266 [09:47<05:06,  2.79s/it]predicting train subjects:  59%|█████▉    | 157/266 [09:49<04:37,  2.55s/it]predicting train subjects:  59%|█████▉    | 158/266 [09:51<04:18,  2.39s/it]predicting train subjects:  60%|█████▉    | 159/266 [09:53<04:11,  2.35s/it]predicting train subjects:  60%|██████    | 160/266 [09:55<04:05,  2.31s/it]predicting train subjects:  61%|██████    | 161/266 [09:58<04:06,  2.35s/it]predicting train subjects:  61%|██████    | 162/266 [10:00<04:00,  2.32s/it]predicting train subjects:  61%|██████▏   | 163/266 [10:02<03:59,  2.33s/it]predicting train subjects:  62%|██████▏   | 164/266 [10:05<03:54,  2.30s/it]predicting train subjects:  62%|██████▏   | 165/266 [10:07<03:54,  2.32s/it]predicting train subjects:  62%|██████▏   | 166/266 [10:09<03:54,  2.34s/it]predicting train subjects:  63%|██████▎   | 167/266 [10:12<03:51,  2.34s/it]predicting train subjects:  63%|██████▎   | 168/266 [10:14<03:48,  2.33s/it]predicting train subjects:  64%|██████▎   | 169/266 [10:16<03:45,  2.32s/it]predicting train subjects:  64%|██████▍   | 170/266 [10:19<03:41,  2.31s/it]predicting train subjects:  64%|██████▍   | 171/266 [10:21<03:35,  2.26s/it]predicting train subjects:  65%|██████▍   | 172/266 [10:23<03:38,  2.33s/it]predicting train subjects:  65%|██████▌   | 173/266 [10:26<03:50,  2.48s/it]predicting train subjects:  65%|██████▌   | 174/266 [10:28<03:47,  2.47s/it]predicting train subjects:  66%|██████▌   | 175/266 [10:31<03:44,  2.47s/it]predicting train subjects:  66%|██████▌   | 176/266 [10:33<03:44,  2.49s/it]predicting train subjects:  67%|██████▋   | 177/266 [10:36<03:49,  2.57s/it]predicting train subjects:  67%|██████▋   | 178/266 [10:39<03:52,  2.64s/it]predicting train subjects:  67%|██████▋   | 179/266 [10:42<03:56,  2.71s/it]predicting train subjects:  68%|██████▊   | 180/266 [10:44<03:47,  2.65s/it]predicting train subjects:  68%|██████▊   | 181/266 [10:47<03:42,  2.62s/it]predicting train subjects:  68%|██████▊   | 182/266 [10:50<03:39,  2.61s/it]predicting train subjects:  69%|██████▉   | 183/266 [10:52<03:39,  2.64s/it]predicting train subjects:  69%|██████▉   | 184/266 [10:55<03:34,  2.62s/it]predicting train subjects:  70%|██████▉   | 185/266 [10:58<03:33,  2.63s/it]predicting train subjects:  70%|██████▉   | 186/266 [11:00<03:29,  2.62s/it]predicting train subjects:  70%|███████   | 187/266 [11:03<03:24,  2.59s/it]predicting train subjects:  71%|███████   | 188/266 [11:05<03:20,  2.57s/it]predicting train subjects:  71%|███████   | 189/266 [11:08<03:23,  2.65s/it]predicting train subjects:  71%|███████▏  | 190/266 [11:11<03:18,  2.62s/it]predicting train subjects:  72%|███████▏  | 191/266 [11:13<03:23,  2.71s/it]predicting train subjects:  72%|███████▏  | 192/266 [11:16<03:14,  2.63s/it]predicting train subjects:  73%|███████▎  | 193/266 [11:18<03:10,  2.61s/it]predicting train subjects:  73%|███████▎  | 194/266 [11:22<03:19,  2.77s/it]predicting train subjects:  73%|███████▎  | 195/266 [11:24<03:18,  2.80s/it]predicting train subjects:  74%|███████▎  | 196/266 [11:27<03:14,  2.78s/it]predicting train subjects:  74%|███████▍  | 197/266 [11:30<03:11,  2.77s/it]predicting train subjects:  74%|███████▍  | 198/266 [11:33<03:08,  2.77s/it]predicting train subjects:  75%|███████▍  | 199/266 [11:36<03:06,  2.78s/it]predicting train subjects:  75%|███████▌  | 200/266 [11:38<03:01,  2.76s/it]predicting train subjects:  76%|███████▌  | 201/266 [11:41<03:01,  2.79s/it]predicting train subjects:  76%|███████▌  | 202/266 [11:44<03:00,  2.83s/it]predicting train subjects:  76%|███████▋  | 203/266 [11:47<03:01,  2.87s/it]predicting train subjects:  77%|███████▋  | 204/266 [11:50<02:58,  2.89s/it]predicting train subjects:  77%|███████▋  | 205/266 [11:53<02:56,  2.89s/it]predicting train subjects:  77%|███████▋  | 206/266 [11:56<02:50,  2.85s/it]predicting train subjects:  78%|███████▊  | 207/266 [11:58<02:49,  2.88s/it]predicting train subjects:  78%|███████▊  | 208/266 [12:01<02:44,  2.83s/it]predicting train subjects:  79%|███████▊  | 209/266 [12:04<02:41,  2.84s/it]predicting train subjects:  79%|███████▉  | 210/266 [12:07<02:37,  2.81s/it]predicting train subjects:  79%|███████▉  | 211/266 [12:10<02:37,  2.86s/it]predicting train subjects:  80%|███████▉  | 212/266 [12:13<02:36,  2.90s/it]predicting train subjects:  80%|████████  | 213/266 [12:15<02:29,  2.81s/it]predicting train subjects:  80%|████████  | 214/266 [12:18<02:19,  2.67s/it]predicting train subjects:  81%|████████  | 215/266 [12:20<02:13,  2.62s/it]predicting train subjects:  81%|████████  | 216/266 [12:23<02:07,  2.55s/it]predicting train subjects:  82%|████████▏ | 217/266 [12:25<02:03,  2.52s/it]predicting train subjects:  82%|████████▏ | 218/266 [12:27<01:59,  2.49s/it]predicting train subjects:  82%|████████▏ | 219/266 [12:30<01:55,  2.45s/it]predicting train subjects:  83%|████████▎ | 220/266 [12:32<01:51,  2.42s/it]predicting train subjects:  83%|████████▎ | 221/266 [12:34<01:47,  2.39s/it]predicting train subjects:  83%|████████▎ | 222/266 [12:37<01:46,  2.42s/it]predicting train subjects:  84%|████████▍ | 223/266 [12:39<01:44,  2.43s/it]predicting train subjects:  84%|████████▍ | 224/266 [12:42<01:41,  2.42s/it]predicting train subjects:  85%|████████▍ | 225/266 [12:44<01:36,  2.36s/it]predicting train subjects:  85%|████████▍ | 226/266 [12:46<01:34,  2.37s/it]predicting train subjects:  85%|████████▌ | 227/266 [12:49<01:37,  2.49s/it]predicting train subjects:  86%|████████▌ | 228/266 [12:51<01:30,  2.39s/it]predicting train subjects:  86%|████████▌ | 229/266 [12:54<01:28,  2.39s/it]predicting train subjects:  86%|████████▋ | 230/266 [12:56<01:20,  2.23s/it]predicting train subjects:  87%|████████▋ | 231/266 [12:58<01:19,  2.28s/it]predicting train subjects:  87%|████████▋ | 232/266 [13:00<01:13,  2.17s/it]predicting train subjects:  88%|████████▊ | 233/266 [13:02<01:09,  2.11s/it]predicting train subjects:  88%|████████▊ | 234/266 [13:04<01:05,  2.04s/it]predicting train subjects:  88%|████████▊ | 235/266 [13:06<01:06,  2.15s/it]predicting train subjects:  89%|████████▊ | 236/266 [13:09<01:07,  2.23s/it]predicting train subjects:  89%|████████▉ | 237/266 [13:11<01:02,  2.16s/it]predicting train subjects:  89%|████████▉ | 238/266 [13:13<01:00,  2.18s/it]predicting train subjects:  90%|████████▉ | 239/266 [13:15<00:56,  2.09s/it]predicting train subjects:  90%|█████████ | 240/266 [13:17<00:57,  2.22s/it]predicting train subjects:  91%|█████████ | 241/266 [13:19<00:53,  2.14s/it]predicting train subjects:  91%|█████████ | 242/266 [13:21<00:49,  2.08s/it]predicting train subjects:  91%|█████████▏| 243/266 [13:23<00:47,  2.06s/it]predicting train subjects:  92%|█████████▏| 244/266 [13:25<00:46,  2.13s/it]predicting train subjects:  92%|█████████▏| 245/266 [13:28<00:44,  2.12s/it]predicting train subjects:  92%|█████████▏| 246/266 [13:29<00:41,  2.07s/it]predicting train subjects:  93%|█████████▎| 247/266 [13:31<00:39,  2.05s/it]predicting train subjects:  93%|█████████▎| 248/266 [13:34<00:36,  2.04s/it]predicting train subjects:  94%|█████████▎| 249/266 [13:36<00:37,  2.23s/it]predicting train subjects:  94%|█████████▍| 250/266 [13:39<00:37,  2.34s/it]predicting train subjects:  94%|█████████▍| 251/266 [13:41<00:35,  2.39s/it]predicting train subjects:  95%|█████████▍| 252/266 [13:44<00:34,  2.49s/it]predicting train subjects:  95%|█████████▌| 253/266 [13:47<00:32,  2.50s/it]predicting train subjects:  95%|█████████▌| 254/266 [13:49<00:30,  2.56s/it]predicting train subjects:  96%|█████████▌| 255/266 [13:52<00:27,  2.54s/it]predicting train subjects:  96%|█████████▌| 256/266 [13:54<00:25,  2.57s/it]predicting train subjects:  97%|█████████▋| 257/266 [13:57<00:23,  2.57s/it]predicting train subjects:  97%|█████████▋| 258/266 [14:00<00:20,  2.59s/it]predicting train subjects:  97%|█████████▋| 259/266 [14:02<00:17,  2.56s/it]predicting train subjects:  98%|█████████▊| 260/266 [14:05<00:15,  2.54s/it]predicting train subjects:  98%|█████████▊| 261/266 [14:07<00:12,  2.58s/it]predicting train subjects:  98%|█████████▊| 262/266 [14:10<00:10,  2.53s/it]predicting train subjects:  99%|█████████▉| 263/266 [14:12<00:07,  2.50s/it]predicting train subjects:  99%|█████████▉| 264/266 [14:15<00:05,  2.58s/it]predicting train subjects: 100%|█████████▉| 265/266 [14:17<00:02,  2.60s/it]predicting train subjects: 100%|██████████| 266/266 [14:20<00:00,  2.54s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:12,  1.99it/s]Loading train:   1%|          | 2/266 [00:00<02:07,  2.08it/s]Loading train:   1%|          | 3/266 [00:01<02:04,  2.12it/s]Loading train:   2%|▏         | 4/266 [00:01<01:57,  2.23it/s]Loading train:   2%|▏         | 5/266 [00:02<02:02,  2.14it/s]Loading train:   2%|▏         | 6/266 [00:02<01:58,  2.20it/s]Loading train:   3%|▎         | 7/266 [00:03<01:54,  2.27it/s]Loading train:   3%|▎         | 8/266 [00:03<01:56,  2.21it/s]Loading train:   3%|▎         | 9/266 [00:04<01:52,  2.28it/s]Loading train:   4%|▍         | 10/266 [00:04<01:50,  2.31it/s]Loading train:   4%|▍         | 11/266 [00:04<01:49,  2.34it/s]Loading train:   5%|▍         | 12/266 [00:05<01:47,  2.37it/s]Loading train:   5%|▍         | 13/266 [00:05<01:46,  2.38it/s]Loading train:   5%|▌         | 14/266 [00:06<01:44,  2.40it/s]Loading train:   6%|▌         | 15/266 [00:06<01:44,  2.41it/s]Loading train:   6%|▌         | 16/266 [00:06<01:45,  2.37it/s]Loading train:   6%|▋         | 17/266 [00:07<01:43,  2.40it/s]Loading train:   7%|▋         | 18/266 [00:07<01:42,  2.42it/s]Loading train:   7%|▋         | 19/266 [00:08<01:41,  2.44it/s]Loading train:   8%|▊         | 20/266 [00:08<01:40,  2.45it/s]Loading train:   8%|▊         | 21/266 [00:08<01:38,  2.48it/s]Loading train:   8%|▊         | 22/266 [00:09<01:37,  2.50it/s]Loading train:   9%|▊         | 23/266 [00:09<01:41,  2.40it/s]Loading train:   9%|▉         | 24/266 [00:10<01:39,  2.43it/s]Loading train:   9%|▉         | 25/266 [00:10<01:45,  2.28it/s]Loading train:  10%|▉         | 26/266 [00:11<01:42,  2.34it/s]Loading train:  10%|█         | 27/266 [00:11<01:39,  2.41it/s]Loading train:  11%|█         | 28/266 [00:11<01:36,  2.47it/s]Loading train:  11%|█         | 29/266 [00:12<01:35,  2.49it/s]Loading train:  11%|█▏        | 30/266 [00:12<01:33,  2.52it/s]Loading train:  12%|█▏        | 31/266 [00:13<01:32,  2.54it/s]Loading train:  12%|█▏        | 32/266 [00:13<01:32,  2.54it/s]Loading train:  12%|█▏        | 33/266 [00:13<01:30,  2.56it/s]Loading train:  13%|█▎        | 34/266 [00:14<01:30,  2.58it/s]Loading train:  13%|█▎        | 35/266 [00:14<01:32,  2.51it/s]Loading train:  14%|█▎        | 36/266 [00:14<01:30,  2.54it/s]Loading train:  14%|█▍        | 37/266 [00:15<01:29,  2.55it/s]Loading train:  14%|█▍        | 38/266 [00:15<01:29,  2.56it/s]Loading train:  15%|█▍        | 39/266 [00:16<01:28,  2.56it/s]Loading train:  15%|█▌        | 40/266 [00:16<01:27,  2.58it/s]Loading train:  15%|█▌        | 41/266 [00:16<01:27,  2.58it/s]Loading train:  16%|█▌        | 42/266 [00:17<01:38,  2.26it/s]Loading train:  16%|█▌        | 43/266 [00:17<01:33,  2.38it/s]Loading train:  17%|█▋        | 44/266 [00:18<01:28,  2.50it/s]Loading train:  17%|█▋        | 45/266 [00:18<01:28,  2.49it/s]Loading train:  17%|█▋        | 46/266 [00:18<01:26,  2.55it/s]Loading train:  18%|█▊        | 47/266 [00:19<01:27,  2.50it/s]Loading train:  18%|█▊        | 48/266 [00:19<01:30,  2.40it/s]Loading train:  18%|█▊        | 49/266 [00:20<01:30,  2.40it/s]Loading train:  19%|█▉        | 50/266 [00:20<01:29,  2.41it/s]Loading train:  19%|█▉        | 51/266 [00:21<01:27,  2.44it/s]Loading train:  20%|█▉        | 52/266 [00:21<01:28,  2.41it/s]Loading train:  20%|█▉        | 53/266 [00:21<01:27,  2.43it/s]Loading train:  20%|██        | 54/266 [00:22<01:23,  2.55it/s]Loading train:  21%|██        | 55/266 [00:22<01:20,  2.62it/s]Loading train:  21%|██        | 56/266 [00:23<01:22,  2.55it/s]Loading train:  21%|██▏       | 57/266 [00:23<01:28,  2.37it/s]Loading train:  22%|██▏       | 58/266 [00:23<01:27,  2.37it/s]Loading train:  22%|██▏       | 59/266 [00:24<01:23,  2.48it/s]Loading train:  23%|██▎       | 60/266 [00:24<01:20,  2.56it/s]Loading train:  23%|██▎       | 61/266 [00:25<01:20,  2.56it/s]Loading train:  23%|██▎       | 62/266 [00:25<01:20,  2.54it/s]Loading train:  24%|██▎       | 63/266 [00:25<01:17,  2.62it/s]Loading train:  24%|██▍       | 64/266 [00:26<01:13,  2.74it/s]Loading train:  24%|██▍       | 65/266 [00:26<01:12,  2.76it/s]Loading train:  25%|██▍       | 66/266 [00:26<01:10,  2.86it/s]Loading train:  25%|██▌       | 67/266 [00:27<01:08,  2.92it/s]Loading train:  26%|██▌       | 68/266 [00:27<01:07,  2.92it/s]Loading train:  26%|██▌       | 69/266 [00:27<01:08,  2.88it/s]Loading train:  26%|██▋       | 70/266 [00:28<01:06,  2.93it/s]Loading train:  27%|██▋       | 71/266 [00:28<01:07,  2.90it/s]Loading train:  27%|██▋       | 72/266 [00:28<01:05,  2.95it/s]Loading train:  27%|██▋       | 73/266 [00:29<01:06,  2.92it/s]Loading train:  28%|██▊       | 74/266 [00:29<01:04,  2.97it/s]Loading train:  28%|██▊       | 75/266 [00:29<01:05,  2.92it/s]Loading train:  29%|██▊       | 76/266 [00:30<01:07,  2.82it/s]Loading train:  29%|██▉       | 77/266 [00:30<01:09,  2.73it/s]Loading train:  29%|██▉       | 78/266 [00:31<01:13,  2.56it/s]Loading train:  30%|██▉       | 79/266 [00:31<01:18,  2.39it/s]Loading train:  30%|███       | 80/266 [00:32<01:18,  2.37it/s]Loading train:  30%|███       | 81/266 [00:32<01:17,  2.37it/s]Loading train:  31%|███       | 82/266 [00:32<01:21,  2.26it/s]Loading train:  31%|███       | 83/266 [00:33<01:23,  2.20it/s]Loading train:  32%|███▏      | 84/266 [00:33<01:20,  2.25it/s]Loading train:  32%|███▏      | 85/266 [00:34<01:24,  2.14it/s]Loading train:  32%|███▏      | 86/266 [00:34<01:22,  2.17it/s]Loading train:  33%|███▎      | 87/266 [00:35<01:21,  2.21it/s]Loading train:  33%|███▎      | 88/266 [00:35<01:20,  2.22it/s]Loading train:  33%|███▎      | 89/266 [00:36<01:19,  2.22it/s]Loading train:  34%|███▍      | 90/266 [00:36<01:22,  2.14it/s]Loading train:  34%|███▍      | 91/266 [00:37<01:21,  2.15it/s]Loading train:  35%|███▍      | 92/266 [00:37<01:20,  2.15it/s]Loading train:  35%|███▍      | 93/266 [00:38<01:22,  2.09it/s]Loading train:  35%|███▌      | 94/266 [00:38<01:20,  2.14it/s]Loading train:  36%|███▌      | 95/266 [00:38<01:16,  2.24it/s]Loading train:  36%|███▌      | 96/266 [00:39<01:14,  2.27it/s]Loading train:  36%|███▋      | 97/266 [00:39<01:16,  2.22it/s]Loading train:  37%|███▋      | 98/266 [00:40<01:14,  2.25it/s]Loading train:  37%|███▋      | 99/266 [00:40<01:10,  2.35it/s]Loading train:  38%|███▊      | 100/266 [00:41<01:09,  2.40it/s]Loading train:  38%|███▊      | 101/266 [00:41<01:09,  2.37it/s]Loading train:  38%|███▊      | 102/266 [00:41<01:08,  2.39it/s]Loading train:  39%|███▊      | 103/266 [00:42<01:09,  2.33it/s]Loading train:  39%|███▉      | 104/266 [00:42<01:08,  2.35it/s]Loading train:  39%|███▉      | 105/266 [00:43<01:06,  2.43it/s]Loading train:  40%|███▉      | 106/266 [00:43<01:03,  2.52it/s]Loading train:  40%|████      | 107/266 [00:43<01:06,  2.40it/s]Loading train:  41%|████      | 108/266 [00:44<01:05,  2.40it/s]Loading train:  41%|████      | 109/266 [00:44<01:05,  2.39it/s]Loading train:  41%|████▏     | 110/266 [00:45<01:03,  2.46it/s]Loading train:  42%|████▏     | 111/266 [00:45<01:00,  2.55it/s]Loading train:  42%|████▏     | 112/266 [00:45<00:58,  2.62it/s]Loading train:  42%|████▏     | 113/266 [00:46<00:57,  2.66it/s]Loading train:  43%|████▎     | 114/266 [00:46<00:56,  2.68it/s]Loading train:  43%|████▎     | 115/266 [00:46<00:57,  2.62it/s]Loading train:  44%|████▎     | 116/266 [00:47<00:57,  2.63it/s]Loading train:  44%|████▍     | 117/266 [00:47<00:55,  2.67it/s]Loading train:  44%|████▍     | 118/266 [00:48<00:56,  2.63it/s]Loading train:  45%|████▍     | 119/266 [00:48<00:58,  2.52it/s]Loading train:  45%|████▌     | 120/266 [00:49<01:04,  2.26it/s]Loading train:  45%|████▌     | 121/266 [00:49<01:04,  2.25it/s]Loading train:  46%|████▌     | 122/266 [00:49<01:03,  2.26it/s]Loading train:  46%|████▌     | 123/266 [00:50<01:03,  2.27it/s]Loading train:  47%|████▋     | 124/266 [00:50<01:06,  2.15it/s]Loading train:  47%|████▋     | 125/266 [00:51<01:05,  2.16it/s]Loading train:  47%|████▋     | 126/266 [00:51<01:08,  2.04it/s]Loading train:  48%|████▊     | 127/266 [00:52<01:06,  2.10it/s]Loading train:  48%|████▊     | 128/266 [00:52<01:04,  2.15it/s]Loading train:  48%|████▊     | 129/266 [00:53<01:01,  2.21it/s]Loading train:  49%|████▉     | 130/266 [00:53<00:59,  2.27it/s]Loading train:  49%|████▉     | 131/266 [00:54<00:57,  2.34it/s]Loading train:  50%|████▉     | 132/266 [00:54<00:58,  2.30it/s]Loading train:  50%|█████     | 133/266 [00:55<00:59,  2.25it/s]Loading train:  50%|█████     | 134/266 [00:55<00:59,  2.22it/s]Loading train:  51%|█████     | 135/266 [00:55<00:59,  2.22it/s]Loading train:  51%|█████     | 136/266 [00:56<00:57,  2.28it/s]Loading train:  52%|█████▏    | 137/266 [00:56<00:55,  2.31it/s]Loading train:  52%|█████▏    | 138/266 [00:57<00:56,  2.28it/s]Loading train:  52%|█████▏    | 139/266 [00:57<00:54,  2.33it/s]Loading train:  53%|█████▎    | 140/266 [00:58<00:55,  2.28it/s]Loading train:  53%|█████▎    | 141/266 [00:58<00:54,  2.31it/s]Loading train:  53%|█████▎    | 142/266 [00:58<00:56,  2.21it/s]Loading train:  54%|█████▍    | 143/266 [00:59<00:53,  2.29it/s]Loading train:  54%|█████▍    | 144/266 [00:59<00:50,  2.42it/s]Loading train:  55%|█████▍    | 145/266 [01:00<00:47,  2.52it/s]Loading train:  55%|█████▍    | 146/266 [01:00<00:46,  2.60it/s]Loading train:  55%|█████▌    | 147/266 [01:00<00:44,  2.66it/s]Loading train:  56%|█████▌    | 148/266 [01:01<00:43,  2.70it/s]Loading train:  56%|█████▌    | 149/266 [01:01<00:44,  2.60it/s]Loading train:  56%|█████▋    | 150/266 [01:01<00:44,  2.61it/s]Loading train:  57%|█████▋    | 151/266 [01:02<00:43,  2.62it/s]Loading train:  57%|█████▋    | 152/266 [01:02<00:43,  2.61it/s]Loading train:  58%|█████▊    | 153/266 [01:03<00:43,  2.61it/s]Loading train:  58%|█████▊    | 154/266 [01:03<00:42,  2.63it/s]Loading train:  58%|█████▊    | 155/266 [01:03<00:40,  2.72it/s]Loading train:  59%|█████▊    | 156/266 [01:04<00:38,  2.84it/s]Loading train:  59%|█████▉    | 157/266 [01:04<00:38,  2.85it/s]Loading train:  59%|█████▉    | 158/266 [01:04<00:36,  2.94it/s]Loading train:  60%|█████▉    | 159/266 [01:05<00:36,  2.91it/s]Loading train:  60%|██████    | 160/266 [01:05<00:35,  2.99it/s]Loading train:  61%|██████    | 161/266 [01:05<00:34,  3.06it/s]Loading train:  61%|██████    | 162/266 [01:06<00:33,  3.10it/s]Loading train:  61%|██████▏   | 163/266 [01:06<00:33,  3.11it/s]Loading train:  62%|██████▏   | 164/266 [01:06<00:32,  3.15it/s]Loading train:  62%|██████▏   | 165/266 [01:07<00:31,  3.16it/s]Loading train:  62%|██████▏   | 166/266 [01:07<00:31,  3.16it/s]Loading train:  63%|██████▎   | 167/266 [01:07<00:31,  3.17it/s]Loading train:  63%|██████▎   | 168/266 [01:07<00:30,  3.18it/s]Loading train:  64%|██████▎   | 169/266 [01:08<00:30,  3.19it/s]Loading train:  64%|██████▍   | 170/266 [01:08<00:30,  3.18it/s]Loading train:  64%|██████▍   | 171/266 [01:08<00:29,  3.17it/s]Loading train:  65%|██████▍   | 172/266 [01:09<00:31,  3.02it/s]Loading train:  65%|██████▌   | 173/266 [01:09<00:33,  2.80it/s]Loading train:  65%|██████▌   | 174/266 [01:10<00:32,  2.84it/s]Loading train:  66%|██████▌   | 175/266 [01:10<00:31,  2.86it/s]Loading train:  66%|██████▌   | 176/266 [01:10<00:31,  2.86it/s]Loading train:  67%|██████▋   | 177/266 [01:11<00:31,  2.85it/s]Loading train:  67%|██████▋   | 178/266 [01:11<00:30,  2.87it/s]Loading train:  67%|██████▋   | 179/266 [01:11<00:30,  2.88it/s]Loading train:  68%|██████▊   | 180/266 [01:12<00:29,  2.89it/s]Loading train:  68%|██████▊   | 181/266 [01:12<00:29,  2.89it/s]Loading train:  68%|██████▊   | 182/266 [01:12<00:29,  2.89it/s]Loading train:  69%|██████▉   | 183/266 [01:13<00:28,  2.90it/s]Loading train:  69%|██████▉   | 184/266 [01:13<00:28,  2.91it/s]Loading train:  70%|██████▉   | 185/266 [01:13<00:27,  2.91it/s]Loading train:  70%|██████▉   | 186/266 [01:14<00:27,  2.90it/s]Loading train:  70%|███████   | 187/266 [01:14<00:27,  2.90it/s]Loading train:  71%|███████   | 188/266 [01:14<00:26,  2.90it/s]Loading train:  71%|███████   | 189/266 [01:15<00:26,  2.90it/s]Loading train:  71%|███████▏  | 190/266 [01:15<00:26,  2.91it/s]Loading train:  72%|███████▏  | 191/266 [01:15<00:26,  2.79it/s]Loading train:  72%|███████▏  | 192/266 [01:16<00:26,  2.80it/s]Loading train:  73%|███████▎  | 193/266 [01:16<00:26,  2.78it/s]Loading train:  73%|███████▎  | 194/266 [01:17<00:27,  2.64it/s]Loading train:  73%|███████▎  | 195/266 [01:17<00:26,  2.69it/s]Loading train:  74%|███████▎  | 196/266 [01:17<00:25,  2.75it/s]Loading train:  74%|███████▍  | 197/266 [01:18<00:24,  2.79it/s]Loading train:  74%|███████▍  | 198/266 [01:18<00:24,  2.81it/s]Loading train:  75%|███████▍  | 199/266 [01:18<00:23,  2.84it/s]Loading train:  75%|███████▌  | 200/266 [01:19<00:23,  2.86it/s]Loading train:  76%|███████▌  | 201/266 [01:19<00:22,  2.90it/s]Loading train:  76%|███████▌  | 202/266 [01:19<00:21,  2.92it/s]Loading train:  76%|███████▋  | 203/266 [01:20<00:21,  2.91it/s]Loading train:  77%|███████▋  | 204/266 [01:20<00:21,  2.91it/s]Loading train:  77%|███████▋  | 205/266 [01:20<00:20,  2.93it/s]Loading train:  77%|███████▋  | 206/266 [01:21<00:20,  2.92it/s]Loading train:  78%|███████▊  | 207/266 [01:21<00:20,  2.90it/s]Loading train:  78%|███████▊  | 208/266 [01:21<00:19,  2.91it/s]Loading train:  79%|███████▊  | 209/266 [01:22<00:19,  2.91it/s]Loading train:  79%|███████▉  | 210/266 [01:22<00:19,  2.83it/s]Loading train:  79%|███████▉  | 211/266 [01:23<00:19,  2.81it/s]Loading train:  80%|███████▉  | 212/266 [01:23<00:19,  2.82it/s]Loading train:  80%|████████  | 213/266 [01:23<00:18,  2.82it/s]Loading train:  80%|████████  | 214/266 [01:24<00:17,  2.90it/s]Loading train:  81%|████████  | 215/266 [01:24<00:17,  2.88it/s]Loading train:  81%|████████  | 216/266 [01:24<00:16,  2.96it/s]Loading train:  82%|████████▏ | 217/266 [01:25<00:16,  3.01it/s]Loading train:  82%|████████▏ | 218/266 [01:25<00:15,  3.06it/s]Loading train:  82%|████████▏ | 219/266 [01:25<00:15,  2.99it/s]Loading train:  83%|████████▎ | 220/266 [01:25<00:15,  3.04it/s]Loading train:  83%|████████▎ | 221/266 [01:26<00:14,  3.08it/s]Loading train:  83%|████████▎ | 222/266 [01:26<00:14,  3.11it/s]Loading train:  84%|████████▍ | 223/266 [01:26<00:13,  3.12it/s]Loading train:  84%|████████▍ | 224/266 [01:27<00:13,  3.14it/s]Loading train:  85%|████████▍ | 225/266 [01:27<00:13,  3.14it/s]Loading train:  85%|████████▍ | 226/266 [01:27<00:12,  3.16it/s]Loading train:  85%|████████▌ | 227/266 [01:28<00:12,  3.16it/s]Loading train:  86%|████████▌ | 228/266 [01:28<00:12,  3.11it/s]Loading train:  86%|████████▌ | 229/266 [01:28<00:11,  3.11it/s]Loading train:  86%|████████▋ | 230/266 [01:29<00:11,  3.00it/s]Loading train:  87%|████████▋ | 231/266 [01:29<00:11,  2.99it/s]Loading train:  87%|████████▋ | 232/266 [01:29<00:11,  2.97it/s]Loading train:  88%|████████▊ | 233/266 [01:30<00:11,  2.96it/s]Loading train:  88%|████████▊ | 234/266 [01:30<00:10,  2.97it/s]Loading train:  88%|████████▊ | 235/266 [01:30<00:10,  2.98it/s]Loading train:  89%|████████▊ | 236/266 [01:31<00:10,  2.99it/s]Loading train:  89%|████████▉ | 237/266 [01:31<00:09,  2.99it/s]Loading train:  89%|████████▉ | 238/266 [01:31<00:09,  2.92it/s]Loading train:  90%|████████▉ | 239/266 [01:32<00:09,  2.99it/s]Loading train:  90%|█████████ | 240/266 [01:32<00:08,  3.05it/s]Loading train:  91%|█████████ | 241/266 [01:32<00:08,  3.08it/s]Loading train:  91%|█████████ | 242/266 [01:33<00:07,  3.11it/s]Loading train:  91%|█████████▏| 243/266 [01:33<00:07,  3.13it/s]Loading train:  92%|█████████▏| 244/266 [01:33<00:07,  3.14it/s]Loading train:  92%|█████████▏| 245/266 [01:34<00:06,  3.15it/s]Loading train:  92%|█████████▏| 246/266 [01:34<00:06,  3.15it/s]Loading train:  93%|█████████▎| 247/266 [01:34<00:06,  3.16it/s]Loading train:  93%|█████████▎| 248/266 [01:35<00:05,  3.17it/s]Loading train:  94%|█████████▎| 249/266 [01:35<00:05,  2.95it/s]Loading train:  94%|█████████▍| 250/266 [01:35<00:05,  2.70it/s]Loading train:  94%|█████████▍| 251/266 [01:36<00:05,  2.71it/s]Loading train:  95%|█████████▍| 252/266 [01:36<00:05,  2.71it/s]Loading train:  95%|█████████▌| 253/266 [01:37<00:05,  2.56it/s]Loading train:  95%|█████████▌| 254/266 [01:37<00:04,  2.46it/s]Loading train:  96%|█████████▌| 255/266 [01:37<00:04,  2.53it/s]Loading train:  96%|█████████▌| 256/266 [01:38<00:03,  2.57it/s]Loading train:  97%|█████████▋| 257/266 [01:38<00:03,  2.60it/s]Loading train:  97%|█████████▋| 258/266 [01:39<00:03,  2.61it/s]Loading train:  97%|█████████▋| 259/266 [01:39<00:02,  2.65it/s]Loading train:  98%|█████████▊| 260/266 [01:39<00:02,  2.67it/s]Loading train:  98%|█████████▊| 261/266 [01:40<00:01,  2.69it/s]Loading train:  98%|█████████▊| 262/266 [01:40<00:01,  2.69it/s]Loading train:  99%|█████████▉| 263/266 [01:40<00:01,  2.70it/s]Loading train:  99%|█████████▉| 264/266 [01:41<00:00,  2.70it/s]Loading train: 100%|█████████▉| 265/266 [01:41<00:00,  2.71it/s]Loading train: 100%|██████████| 266/266 [01:41<00:00,  2.70it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:02, 109.53it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:02, 114.29it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:02, 112.54it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:02, 107.91it/s]concatenating: train:  23%|██▎       | 61/266 [00:00<00:01, 118.73it/s]concatenating: train:  30%|██▉       | 79/266 [00:00<00:01, 130.80it/s]concatenating: train:  35%|███▍      | 92/266 [00:00<00:01, 128.79it/s]concatenating: train:  40%|████      | 107/266 [00:00<00:01, 133.00it/s]concatenating: train:  46%|████▌     | 122/266 [00:00<00:01, 135.88it/s]concatenating: train:  51%|█████     | 136/266 [00:01<00:00, 134.94it/s]concatenating: train:  57%|█████▋    | 151/266 [00:01<00:00, 138.18it/s]concatenating: train:  62%|██████▏   | 165/266 [00:01<00:00, 138.53it/s]concatenating: train:  68%|██████▊   | 180/266 [00:01<00:00, 140.94it/s]concatenating: train:  73%|███████▎  | 195/266 [00:01<00:00, 142.93it/s]concatenating: train:  79%|███████▉  | 211/266 [00:01<00:00, 145.26it/s]concatenating: train:  87%|████████▋ | 231/266 [00:01<00:00, 156.78it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 152.24it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.31it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.42it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.53it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  2.67it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  2.65it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 697.12it/s]2019-08-17 19:23:05.476667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 19:23:05.476757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:23:05.476773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 19:23:05.476783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 19:23:05.477197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.79it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.78it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.20it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.92it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.50it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.13it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.17it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.46it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.77it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.18it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.51it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.28it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00, 10.23it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.55it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.53it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.18it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.45it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 214,952
Non-trainable params: 285,390
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 51s - loss: 0.2698 - acc: 0.9429 - mDice: 0.6814 - val_loss: 0.1029 - val_acc: 0.9920 - val_mDice: 0.8224

Epoch 00001: val_mDice improved from -inf to 0.82237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 48s - loss: 0.0840 - acc: 0.9914 - mDice: 0.8499 - val_loss: 0.1081 - val_acc: 0.9905 - val_mDice: 0.8132

Epoch 00002: val_mDice did not improve from 0.82237
Epoch 3/300
 - 47s - loss: 0.0658 - acc: 0.9930 - mDice: 0.8801 - val_loss: 0.0711 - val_acc: 0.9940 - val_mDice: 0.8726

Epoch 00003: val_mDice improved from 0.82237 to 0.87262, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 48s - loss: 0.0573 - acc: 0.9938 - mDice: 0.8949 - val_loss: 0.0903 - val_acc: 0.9921 - val_mDice: 0.8428

Epoch 00004: val_mDice did not improve from 0.87262
Epoch 5/300
 - 48s - loss: 0.0515 - acc: 0.9943 - mDice: 0.9049 - val_loss: 0.0845 - val_acc: 0.9927 - val_mDice: 0.8530

Epoch 00005: val_mDice did not improve from 0.87262
Epoch 6/300
 - 48s - loss: 0.0483 - acc: 0.9946 - mDice: 0.9106 - val_loss: 0.0715 - val_acc: 0.9939 - val_mDice: 0.8719

Epoch 00006: val_mDice did not improve from 0.87262
Epoch 7/300
 - 48s - loss: 0.0456 - acc: 0.9948 - mDice: 0.9153 - val_loss: 0.0761 - val_acc: 0.9933 - val_mDice: 0.8646

Epoch 00007: val_mDice did not improve from 0.87262
Epoch 8/300
 - 48s - loss: 0.0436 - acc: 0.9950 - mDice: 0.9189 - val_loss: 0.0688 - val_acc: 0.9939 - val_mDice: 0.8760

Epoch 00008: val_mDice improved from 0.87262 to 0.87604, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 48s - loss: 0.0421 - acc: 0.9952 - mDice: 0.9216 - val_loss: 0.0773 - val_acc: 0.9930 - val_mDice: 0.8623

Epoch 00009: val_mDice did not improve from 0.87604
Epoch 10/300
 - 48s - loss: 0.0406 - acc: 0.9953 - mDice: 0.9243 - val_loss: 0.0736 - val_acc: 0.9932 - val_mDice: 0.8685

Epoch 00010: val_mDice did not improve from 0.87604
Epoch 11/300
 - 48s - loss: 0.0394 - acc: 0.9954 - mDice: 0.9263 - val_loss: 0.0807 - val_acc: 0.9928 - val_mDice: 0.8573

Epoch 00011: val_mDice did not improve from 0.87604
Epoch 12/300
 - 47s - loss: 0.0385 - acc: 0.9955 - mDice: 0.9280 - val_loss: 0.0751 - val_acc: 0.9932 - val_mDice: 0.8659

Epoch 00012: val_mDice did not improve from 0.87604
Epoch 13/300
 - 48s - loss: 0.0376 - acc: 0.9956 - mDice: 0.9297 - val_loss: 0.0704 - val_acc: 0.9932 - val_mDice: 0.8733

Epoch 00013: val_mDice did not improve from 0.87604
Epoch 14/300
 - 48s - loss: 0.0371 - acc: 0.9956 - mDice: 0.9306 - val_loss: 0.0679 - val_acc: 0.9940 - val_mDice: 0.8772

Epoch 00014: val_mDice improved from 0.87604 to 0.87717, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 48s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9316 - val_loss: 0.0669 - val_acc: 0.9938 - val_mDice: 0.8789

Epoch 00015: val_mDice improved from 0.87717 to 0.87893, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 47s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9329 - val_loss: 0.0681 - val_acc: 0.9938 - val_mDice: 0.8771

Epoch 00016: val_mDice did not improve from 0.87893
Epoch 17/300
 - 48s - loss: 0.0350 - acc: 0.9958 - mDice: 0.9344 - val_loss: 0.0697 - val_acc: 0.9939 - val_mDice: 0.8744

Epoch 00017: val_mDice did not improve from 0.87893
Epoch 18/300
 - 47s - loss: 0.0347 - acc: 0.9959 - mDice: 0.9350 - val_loss: 0.0660 - val_acc: 0.9940 - val_mDice: 0.8804

Epoch 00018: val_mDice improved from 0.87893 to 0.88038, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 48s - loss: 0.0345 - acc: 0.9959 - mDice: 0.9353 - val_loss: 0.0703 - val_acc: 0.9932 - val_mDice: 0.8737

Epoch 00019: val_mDice did not improve from 0.88038
Epoch 20/300
 - 48s - loss: 0.0338 - acc: 0.9959 - mDice: 0.9365 - val_loss: 0.0659 - val_acc: 0.9941 - val_mDice: 0.8806

Epoch 00020: val_mDice improved from 0.88038 to 0.88061, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 48s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9374 - val_loss: 0.0793 - val_acc: 0.9929 - val_mDice: 0.8601

Epoch 00021: val_mDice did not improve from 0.88061
Epoch 22/300
 - 48s - loss: 0.0329 - acc: 0.9960 - mDice: 0.9382 - val_loss: 0.0691 - val_acc: 0.9935 - val_mDice: 0.8751

Epoch 00022: val_mDice did not improve from 0.88061
Epoch 23/300
 - 48s - loss: 0.0330 - acc: 0.9960 - mDice: 0.9379 - val_loss: 0.0681 - val_acc: 0.9938 - val_mDice: 0.8773

Epoch 00023: val_mDice did not improve from 0.88061
Epoch 24/300
 - 48s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9388 - val_loss: 0.0661 - val_acc: 0.9942 - val_mDice: 0.8803

Epoch 00024: val_mDice did not improve from 0.88061
Epoch 25/300
 - 49s - loss: 0.0322 - acc: 0.9961 - mDice: 0.9394 - val_loss: 0.0684 - val_acc: 0.9937 - val_mDice: 0.8765

Epoch 00025: val_mDice did not improve from 0.88061
Epoch 26/300
 - 48s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9398 - val_loss: 0.0664 - val_acc: 0.9939 - val_mDice: 0.8797

Epoch 00026: val_mDice did not improve from 0.88061
Epoch 27/300
 - 49s - loss: 0.0316 - acc: 0.9962 - mDice: 0.9406 - val_loss: 0.0645 - val_acc: 0.9939 - val_mDice: 0.8828

Epoch 00027: val_mDice improved from 0.88061 to 0.88281, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 49s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9408 - val_loss: 0.0718 - val_acc: 0.9932 - val_mDice: 0.8712

Epoch 00028: val_mDice did not improve from 0.88281
Epoch 29/300
 - 48s - loss: 0.0314 - acc: 0.9962 - mDice: 0.9410 - val_loss: 0.0697 - val_acc: 0.9937 - val_mDice: 0.8752

Epoch 00029: val_mDice did not improve from 0.88281
Epoch 30/300
 - 49s - loss: 0.0312 - acc: 0.9962 - mDice: 0.9412 - val_loss: 0.0655 - val_acc: 0.9942 - val_mDice: 0.8809

Epoch 00030: val_mDice did not improve from 0.88281
Epoch 31/300
 - 49s - loss: 0.0308 - acc: 0.9962 - mDice: 0.9419 - val_loss: 0.0704 - val_acc: 0.9937 - val_mDice: 0.8729

Epoch 00031: val_mDice did not improve from 0.88281
Epoch 32/300
 - 50s - loss: 0.0307 - acc: 0.9962 - mDice: 0.9423 - val_loss: 0.0641 - val_acc: 0.9941 - val_mDice: 0.8836

Epoch 00032: val_mDice improved from 0.88281 to 0.88356, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 49s - loss: 0.0306 - acc: 0.9962 - mDice: 0.9423 - val_loss: 0.0653 - val_acc: 0.9940 - val_mDice: 0.8815

Epoch 00033: val_mDice did not improve from 0.88356
Epoch 34/300
 - 50s - loss: 0.0304 - acc: 0.9963 - mDice: 0.9428 - val_loss: 0.0659 - val_acc: 0.9939 - val_mDice: 0.8805

Epoch 00034: val_mDice did not improve from 0.88356
Epoch 35/300
 - 52s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9430 - val_loss: 0.0643 - val_acc: 0.9944 - val_mDice: 0.8832

Epoch 00035: val_mDice did not improve from 0.88356
Epoch 36/300
 - 52s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9429 - val_loss: 0.0686 - val_acc: 0.9937 - val_mDice: 0.8762

Epoch 00036: val_mDice did not improve from 0.88356
Epoch 37/300
 - 52s - loss: 0.0300 - acc: 0.9963 - mDice: 0.9434 - val_loss: 0.0687 - val_acc: 0.9938 - val_mDice: 0.8761

Epoch 00037: val_mDice did not improve from 0.88356
Epoch 38/300
 - 52s - loss: 0.0299 - acc: 0.9963 - mDice: 0.9436 - val_loss: 0.0701 - val_acc: 0.9934 - val_mDice: 0.8738

Epoch 00038: val_mDice did not improve from 0.88356
Epoch 39/300
 - 52s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9440 - val_loss: 0.0647 - val_acc: 0.9942 - val_mDice: 0.8824

Epoch 00039: val_mDice did not improve from 0.88356
Epoch 40/300
 - 49s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9441 - val_loss: 0.0648 - val_acc: 0.9939 - val_mDice: 0.8824

Epoch 00040: val_mDice did not improve from 0.88356
Epoch 41/300
 - 50s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9443 - val_loss: 0.0662 - val_acc: 0.9939 - val_mDice: 0.8800

Epoch 00041: val_mDice did not improve from 0.88356
Epoch 42/300
 - 49s - loss: 0.0295 - acc: 0.9963 - mDice: 0.9444 - val_loss: 0.0671 - val_acc: 0.9938 - val_mDice: 0.8786

Epoch 00042: val_mDice did not improve from 0.88356
Epoch 43/300
 - 49s - loss: 0.0293 - acc: 0.9963 - mDice: 0.9449 - val_loss: 0.0674 - val_acc: 0.9937 - val_mDice: 0.8781

Epoch 00043: val_mDice did not improve from 0.88356
Epoch 44/300
 - 48s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9449 - val_loss: 0.0716 - val_acc: 0.9935 - val_mDice: 0.8716

Epoch 00044: val_mDice did not improve from 0.88356
Epoch 45/300
 - 47s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9455 - val_loss: 0.0665 - val_acc: 0.9938 - val_mDice: 0.8794

Epoch 00045: val_mDice did not improve from 0.88356
Epoch 46/300
 - 47s - loss: 0.0291 - acc: 0.9964 - mDice: 0.9451 - val_loss: 0.0648 - val_acc: 0.9938 - val_mDice: 0.8823

Epoch 00046: val_mDice did not improve from 0.88356
Epoch 47/300
 - 48s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9456 - val_loss: 0.0700 - val_acc: 0.9932 - val_mDice: 0.8741

Epoch 00047: val_mDice did not improve from 0.88356
Epoch 48/300
 - 47s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9457 - val_loss: 0.0683 - val_acc: 0.9937 - val_mDice: 0.8766

Epoch 00048: val_mDice did not improve from 0.88356
Epoch 49/300
 - 49s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9458 - val_loss: 0.0643 - val_acc: 0.9939 - val_mDice: 0.8834

Epoch 00049: val_mDice did not improve from 0.88356
Epoch 50/300
 - 49s - loss: 0.0287 - acc: 0.9964 - mDice: 0.9460 - val_loss: 0.0691 - val_acc: 0.9937 - val_mDice: 0.8753

Epoch 00050: val_mDice did not improve from 0.88356
Epoch 51/300
 - 48s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9463 - val_loss: 0.0674 - val_acc: 0.9939 - val_mDice: 0.8783

Epoch 00051: val_mDice did not improve from 0.88356
Epoch 52/300
 - 49s - loss: 0.0284 - acc: 0.9964 - mDice: 0.9465 - val_loss: 0.0619 - val_acc: 0.9942 - val_mDice: 0.8870

Epoch 00052: val_mDice improved from 0.88356 to 0.88698, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 53/300
 - 48s - loss: 0.0284 - acc: 0.9964 - mDice: 0.9465 - val_loss: 0.0617 - val_acc: 0.9943 - val_mDice: 0.8872

Epoch 00053: val_mDice improved from 0.88698 to 0.88722, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 48s - loss: 0.0282 - acc: 0.9964 - mDice: 0.9467 - val_loss: 0.0631 - val_acc: 0.9940 - val_mDice: 0.8850

Epoch 00054: val_mDice did not improve from 0.88722
Epoch 55/300
 - 48s - loss: 0.0283 - acc: 0.9964 - mDice: 0.9467 - val_loss: 0.0653 - val_acc: 0.9942 - val_mDice: 0.8815

Epoch 00055: val_mDice did not improve from 0.88722
Epoch 56/300
 - 49s - loss: 0.0282 - acc: 0.9964 - mDice: 0.9468 - val_loss: 0.0684 - val_acc: 0.9937 - val_mDice: 0.8769

Epoch 00056: val_mDice did not improve from 0.88722
Epoch 57/300
 - 48s - loss: 0.0280 - acc: 0.9964 - mDice: 0.9471 - val_loss: 0.0680 - val_acc: 0.9942 - val_mDice: 0.8773

Epoch 00057: val_mDice did not improve from 0.88722
Epoch 58/300
 - 48s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9473 - val_loss: 0.0643 - val_acc: 0.9940 - val_mDice: 0.8830

Epoch 00058: val_mDice did not improve from 0.88722
Epoch 59/300
 - 48s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9474 - val_loss: 0.0640 - val_acc: 0.9942 - val_mDice: 0.8836

Epoch 00059: val_mDice did not improve from 0.88722
Epoch 60/300
 - 48s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9472 - val_loss: 0.0630 - val_acc: 0.9940 - val_mDice: 0.8854

Epoch 00060: val_mDice did not improve from 0.88722
Epoch 61/300
 - 49s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9476 - val_loss: 0.0612 - val_acc: 0.9944 - val_mDice: 0.8883

Epoch 00061: val_mDice improved from 0.88722 to 0.88834, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 62/300
 - 48s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9478 - val_loss: 0.0624 - val_acc: 0.9940 - val_mDice: 0.8864

Epoch 00062: val_mDice did not improve from 0.88834
Epoch 63/300
 - 48s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9481 - val_loss: 0.0660 - val_acc: 0.9941 - val_mDice: 0.8805

Epoch 00063: val_mDice did not improve from 0.88834
Epoch 64/300
 - 48s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9477 - val_loss: 0.0682 - val_acc: 0.9937 - val_mDice: 0.8770

Epoch 00064: val_mDice did not improve from 0.88834
Epoch 65/300
 - 48s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9483 - val_loss: 0.0671 - val_acc: 0.9939 - val_mDice: 0.8786

Epoch 00065: val_mDice did not improve from 0.88834
Epoch 66/300
 - 49s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9480 - val_loss: 0.0650 - val_acc: 0.9941 - val_mDice: 0.8822

Epoch 00066: val_mDice did not improve from 0.88834
Epoch 67/300
 - 49s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9483 - val_loss: 0.0634 - val_acc: 0.9941 - val_mDice: 0.8848

Epoch 00067: val_mDice did not improve from 0.88834
Epoch 68/300
 - 49s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9485 - val_loss: 0.0624 - val_acc: 0.9943 - val_mDice: 0.8862

Epoch 00068: val_mDice did not improve from 0.88834
Epoch 69/300
 - 49s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9485 - val_loss: 0.0675 - val_acc: 0.9940 - val_mDice: 0.8781

Epoch 00069: val_mDice did not improve from 0.88834
Epoch 70/300
 - 50s - loss: 0.0271 - acc: 0.9965 - mDice: 0.9489 - val_loss: 0.0645 - val_acc: 0.9939 - val_mDice: 0.8830

Epoch 00070: val_mDice did not improve from 0.88834
Epoch 71/300
 - 50s - loss: 0.0273 - acc: 0.9965 - mDice: 0.9486 - val_loss: 0.0660 - val_acc: 0.9938 - val_mDice: 0.8807

Epoch 00071: val_mDice did not improve from 0.88834
Epoch 72/300
 - 50s - loss: 0.0270 - acc: 0.9965 - mDice: 0.9490 - val_loss: 0.0686 - val_acc: 0.9940 - val_mDice: 0.8765

Epoch 00072: val_mDice did not improve from 0.88834
Epoch 73/300
 - 50s - loss: 0.0270 - acc: 0.9965 - mDice: 0.9490 - val_loss: 0.0642 - val_acc: 0.9941 - val_mDice: 0.8834

Epoch 00073: val_mDice did not improve from 0.88834
Epoch 74/300
 - 49s - loss: 0.0271 - acc: 0.9965 - mDice: 0.9488 - val_loss: 0.0689 - val_acc: 0.9937 - val_mDice: 0.8758

Epoch 00074: val_mDice did not improve from 0.88834
Epoch 75/300
 - 49s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9492 - val_loss: 0.0678 - val_acc: 0.9939 - val_mDice: 0.8775

Epoch 00075: val_mDice did not improve from 0.88834
Epoch 76/300
 - 49s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9492 - val_loss: 0.0656 - val_acc: 0.9940 - val_mDice: 0.8812

Epoch 00076: val_mDice did not improve from 0.88834
Epoch 77/300
 - 49s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9492 - val_loss: 0.0636 - val_acc: 0.9942 - val_mDice: 0.8843

Epoch 00077: val_mDice did not improve from 0.88834
Epoch 78/300
 - 49s - loss: 0.0268 - acc: 0.9965 - mDice: 0.9494 - val_loss: 0.0618 - val_acc: 0.9943 - val_mDice: 0.8873

Epoch 00078: val_mDice did not improve from 0.88834
Epoch 79/300
 - 49s - loss: 0.0268 - acc: 0.9965 - mDice: 0.9494 - val_loss: 0.0651 - val_acc: 0.9939 - val_mDice: 0.8819

Epoch 00079: val_mDice did not improve from 0.88834
Epoch 80/300
 - 49s - loss: 0.0267 - acc: 0.9965 - mDice: 0.9496 - val_loss: 0.0637 - val_acc: 0.9941 - val_mDice: 0.8844

Epoch 00080: val_mDice did not improve from 0.88834
Epoch 81/300
 - 49s - loss: 0.0268 - acc: 0.9965 - mDice: 0.9494 - val_loss: 0.0682 - val_acc: 0.9939 - val_mDice: 0.8772

Epoch 00081: val_mDice did not improve from 0.88834
Epoch 82/300
 - 49s - loss: 0.0267 - acc: 0.9965 - mDice: 0.9496 - val_loss: 0.0689 - val_acc: 0.9937 - val_mDice: 0.8760

Epoch 00082: val_mDice did not improve from 0.88834
Epoch 83/300
 - 49s - loss: 0.0267 - acc: 0.9965 - mDice: 0.9496 - val_loss: 0.0658 - val_acc: 0.9941 - val_mDice: 0.8811

Epoch 00083: val_mDice did not improve from 0.88834
Epoch 84/300
 - 49s - loss: 0.0266 - acc: 0.9965 - mDice: 0.9497 - val_loss: 0.0677 - val_acc: 0.9940 - val_mDice: 0.8777

Epoch 00084: val_mDice did not improve from 0.88834
Epoch 85/300
 - 53s - loss: 0.0266 - acc: 0.9966 - mDice: 0.9498 - val_loss: 0.0649 - val_acc: 0.9940 - val_mDice: 0.8821

Epoch 00085: val_mDice did not improve from 0.88834
Epoch 86/300
 - 53s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9500 - val_loss: 0.0656 - val_acc: 0.9940 - val_mDice: 0.8811

Epoch 00086: val_mDice did not improve from 0.88834
Epoch 87/300
 - 53s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9501 - val_loss: 0.0711 - val_acc: 0.9938 - val_mDice: 0.8725

Epoch 00087: val_mDice did not improve from 0.88834
Epoch 88/300
 - 51s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9502 - val_loss: 0.0701 - val_acc: 0.9936 - val_mDice: 0.8744

Epoch 00088: val_mDice did not improve from 0.88834
Epoch 89/300
 - 49s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9502 - val_loss: 0.0701 - val_acc: 0.9935 - val_mDice: 0.8742

Epoch 00089: val_mDice did not improve from 0.88834
Epoch 90/300
 - 48s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9501 - val_loss: 0.0645 - val_acc: 0.9941 - val_mDice: 0.8831

Epoch 00090: val_mDice did not improve from 0.88834
Epoch 91/300
 - 48s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9500 - val_loss: 0.0676 - val_acc: 0.9939 - val_mDice: 0.8783

Epoch 00091: val_mDice did not improve from 0.88834
Epoch 92/300
 - 48s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9502 - val_loss: 0.0678 - val_acc: 0.9939 - val_mDice: 0.8774

Epoch 00092: val_mDice did not improve from 0.88834
Epoch 93/300
 - 47s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9505 - val_loss: 0.0631 - val_acc: 0.9942 - val_mDice: 0.8850

Epoch 00093: val_mDice did not improve from 0.88834
Epoch 94/300
 - 48s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9505 - val_loss: 0.0658 - val_acc: 0.9941 - val_mDice: 0.8806

Epoch 00094: val_mDice did not improve from 0.88834
Epoch 95/300
 - 48s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9506 - val_loss: 0.0673 - val_acc: 0.9939 - val_mDice: 0.8790

Epoch 00095: val_mDice did not improve from 0.88834
Epoch 96/300
 - 48s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0663 - val_acc: 0.9940 - val_mDice: 0.8801

Epoch 00096: val_mDice did not improve from 0.88834
Epoch 97/300
 - 49s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9507 - val_loss: 0.0641 - val_acc: 0.9942 - val_mDice: 0.8834

Epoch 00097: val_mDice did not improve from 0.88834
Epoch 98/300
 - 49s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9508 - val_loss: 0.0641 - val_acc: 0.9940 - val_mDice: 0.8837

Epoch 00098: val_mDice did not improve from 0.88834
Epoch 99/300
 - 49s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9509 - val_loss: 0.0649 - val_acc: 0.9943 - val_mDice: 0.8822

Epoch 00099: val_mDice did not improve from 0.88834
Epoch 100/300
 - 49s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9509 - val_loss: 0.0629 - val_acc: 0.9942 - val_mDice: 0.8853

Epoch 00100: val_mDice did not improve from 0.88834
Epoch 101/300
 - 49s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9509 - val_loss: 0.0678 - val_acc: 0.9940 - val_mDice: 0.8774

Epoch 00101: val_mDice did not improve from 0.88834
Restoring model weights from the end of the best epoch
Epoch 00101: early stopping
{'val_loss': [0.10291454941034317, 0.108076161891222, 0.07106311619281769, 0.09026382640004157, 0.08451672978699207, 0.07148528136312962, 0.07607414349913597, 0.06882970929145812, 0.07729756087064743, 0.07355708181858063, 0.08068094328045845, 0.07514605484902859, 0.07038995958864688, 0.06785456091165543, 0.06688997223973274, 0.06811744421720504, 0.06969091333448887, 0.0660023543983698, 0.07027531452476979, 0.06589034907519817, 0.07932257391512394, 0.06908606328070163, 0.068118167668581, 0.0660736620426178, 0.06840437427163124, 0.06641718633472919, 0.06450037695467473, 0.07179301716387272, 0.06968990601599216, 0.06548246331512927, 0.07043561786413192, 0.06411922611296177, 0.06525233238935471, 0.06592719666659833, 0.06432339549064636, 0.06864641159772873, 0.06866650953888893, 0.07011337764561176, 0.0647166557610035, 0.06477375738322735, 0.06618399024009705, 0.06710627861320972, 0.06741629838943482, 0.07159015275537968, 0.06653777584433555, 0.06479309611022473, 0.0700429230928421, 0.06832226067781448, 0.06432855688035488, 0.06909217238426209, 0.06741203516721725, 0.06191690266132355, 0.06172132268548012, 0.06311816945672036, 0.06529351025819778, 0.06840458065271378, 0.0680310983210802, 0.06434203274548053, 0.06401598043739795, 0.0629646647721529, 0.061186736822128295, 0.062402496859431264, 0.06599149890244008, 0.06816290654242038, 0.06713906563818454, 0.06496925577521324, 0.06341833509504795, 0.06243675947189331, 0.0675173431634903, 0.06452846862375736, 0.06601467393338681, 0.06863648444414139, 0.06419960334897042, 0.06893879063427448, 0.06779832057654858, 0.06560616977512837, 0.06356038749217988, 0.06178832352161408, 0.06510542333126068, 0.0636689804494381, 0.06819458939135074, 0.06891805827617645, 0.0658363677561283, 0.06766780950129032, 0.06491998955607414, 0.06558362543582916, 0.07107526063919067, 0.07007390074431896, 0.07011054158210754, 0.06450014598667622, 0.06758455745875835, 0.06780726313591004, 0.06312775239348412, 0.06581401601433753, 0.06733457446098327, 0.0662555992603302, 0.06413774713873863, 0.06406490355730057, 0.06489932350814342, 0.06287957169115543, 0.06783044822514057], 'val_acc': [0.992039966583252, 0.9905319154262543, 0.9939598023891449, 0.9920723676681519, 0.9927429318428039, 0.993900591135025, 0.9932750999927521, 0.9939069151878357, 0.9930299699306488, 0.9931530177593231, 0.9928065299987793, 0.9931535124778748, 0.9932156383991242, 0.9939505338668824, 0.9937707126140595, 0.993828946352005, 0.993884015083313, 0.9939834296703338, 0.9932302713394165, 0.9941249966621399, 0.9928978979587555, 0.9935029327869416, 0.9937707245349884, 0.994198340177536, 0.9936639904975891, 0.9939227521419525, 0.9939278721809387, 0.9932441473007202, 0.9937012672424317, 0.9941827416419983, 0.9936812996864319, 0.9940696835517884, 0.9940233945846557, 0.9939222753047943, 0.9943847417831421, 0.9937017560005188, 0.9937526762485505, 0.9934376180171967, 0.9941598415374756, 0.9939076483249665, 0.9938593983650208, 0.9937694907188416, 0.9937400102615357, 0.9935272991657257, 0.9937565863132477, 0.9938460052013397, 0.9931988179683685, 0.993712717294693, 0.9939390778541565, 0.9936915159225463, 0.9938640356063843, 0.9941951751708984, 0.9943123757839203, 0.9940414309501648, 0.9941515505313874, 0.993729043006897, 0.9941956639289856, 0.994046539068222, 0.9941683650016785, 0.9939520001411438, 0.9943550050258636, 0.9940475165843964, 0.9940609216690064, 0.9936627626419068, 0.9938749969005585, 0.9940723598003387, 0.9941133081912994, 0.9942923963069916, 0.9939573585987092, 0.9939188599586487, 0.9937979996204376, 0.9939946353435516, 0.9940696775913238, 0.9936708152294159, 0.993878161907196, 0.9939785480499268, 0.9941708028316498, 0.9943452715873718, 0.9939171552658081, 0.9941052675247193, 0.9939215362071991, 0.9937098026275635, 0.9940660297870636, 0.9940112113952637, 0.9940319240093232, 0.9940043866634369, 0.993751710653305, 0.9936223149299621, 0.9935426354408264, 0.9941128194332123, 0.9938503921031951, 0.9939212918281555, 0.9941778719425202, 0.9940728664398193, 0.993867689371109, 0.9939929366111755, 0.9942468225955963, 0.9940358221530914, 0.9942551136016846, 0.9942402541637421, 0.99396613240242], 'val_mDice': [0.8223745942115783, 0.8131884217262269, 0.8726215422153473, 0.8428443491458892, 0.8530273020267487, 0.8718998789787292, 0.8645628690719604, 0.8760376334190368, 0.8623350918292999, 0.8684771060943604, 0.8572847306728363, 0.8659077763557435, 0.8733047664165496, 0.877169394493103, 0.8789274156093597, 0.8771113693714142, 0.8743760108947753, 0.8803827047348023, 0.8736988008022308, 0.8806101739406585, 0.8601402878761292, 0.8750753581523896, 0.8772768497467041, 0.8802844822406769, 0.8765425264835358, 0.8796755850315094, 0.8828065752983093, 0.8712349653244018, 0.8751866579055786, 0.8808808386325836, 0.8729107856750489, 0.883563494682312, 0.8815346598625183, 0.8805342495441437, 0.8832356691360473, 0.8761924505233765, 0.8760699570178986, 0.8737992763519287, 0.8823934912681579, 0.8824257791042328, 0.8800125360488892, 0.8786494016647339, 0.8780843198299408, 0.871563297510147, 0.8794339597225189, 0.8823118567466736, 0.8740681529045105, 0.8765531182289124, 0.8833976924419403, 0.8753489792346955, 0.8783149898052216, 0.8869799315929413, 0.8872241616249085, 0.8850417852401733, 0.8814557790756226, 0.8769090890884399, 0.8772990465164184, 0.883037519454956, 0.8835874319076538, 0.8854115605354309, 0.8883425831794739, 0.8864168345928192, 0.8804652214050293, 0.8770241141319275, 0.8786294758319855, 0.8822140753269195, 0.884769082069397, 0.8862206041812897, 0.8781354069709778, 0.8829619586467743, 0.8807075440883636, 0.8764879941940308, 0.8833824992179871, 0.8757571280002594, 0.8775488197803497, 0.881210058927536, 0.8842911183834076, 0.8872753500938415, 0.8818569958209992, 0.8843968033790588, 0.877183997631073, 0.8760096788406372, 0.8811087787151337, 0.8777037501335144, 0.8821323275566101, 0.8811031997203826, 0.8725328862667083, 0.874409806728363, 0.8742187082767486, 0.8831365644931793, 0.8782925367355346, 0.8773946702480316, 0.8850240767002105, 0.8805976867675781, 0.8790318310260773, 0.8800817906856537, 0.8833832740783691, 0.8837136328220367, 0.8821618497371674, 0.8853394567966462, 0.8774066209793091], 'loss': [0.2698299422240928, 0.08402931068575634, 0.06583620069191959, 0.05726541287503016, 0.05151783377645602, 0.04828709415543304, 0.0456149743092351, 0.043592645107952264, 0.04206442782139499, 0.04059196012763151, 0.03943234245356168, 0.03848803861726049, 0.03758421083939873, 0.0370554631432119, 0.036493815311151555, 0.03582203793740585, 0.034970896480347506, 0.03465827813106266, 0.03448974213756544, 0.033810764610928155, 0.033307581325082415, 0.03288533338811631, 0.03302311294219261, 0.03255724226846595, 0.03223536012351287, 0.032001672184301305, 0.031588099074301094, 0.03148055554935607, 0.03136187739266694, 0.031219606315364034, 0.030840601260935664, 0.03065939180974379, 0.030618739938287228, 0.030362379572643733, 0.030263442665660105, 0.03032183568994813, 0.030041866026163596, 0.02992077427595938, 0.029707669647348018, 0.02964427556632122, 0.02956214178515008, 0.029485641342991118, 0.029250175209791368, 0.029209761262018803, 0.02893259075503579, 0.02910231607038862, 0.028839225248905285, 0.028795848555010214, 0.0287702574102172, 0.028652735181877192, 0.02845440403744565, 0.028366856618077932, 0.028351795094564047, 0.02824686338093651, 0.0282612550425607, 0.028203457612087073, 0.028045481192470172, 0.027938720561167574, 0.027872357272495794, 0.0279688649495152, 0.02775410048564584, 0.02768771246333327, 0.0275232778918623, 0.027692502197266204, 0.027395272045724877, 0.027537440367869086, 0.027421446244837697, 0.02730318518356088, 0.02726719724451328, 0.027086004960444634, 0.027260718561101155, 0.02704308359320779, 0.02702107637321738, 0.027113344935161144, 0.026920690543276875, 0.02691359631038355, 0.026917805424140517, 0.026829725558934998, 0.02681276238440464, 0.02670559776043033, 0.0267923363606003, 0.026672075233996013, 0.026708509739073467, 0.026628304638537444, 0.026562783230199526, 0.02648177393363527, 0.02642626190460175, 0.02638068527770461, 0.02636097435856013, 0.026400293055411323, 0.026456649616154612, 0.026378765337066144, 0.02619296938504908, 0.026225186466577587, 0.026178634237437746, 0.026122237549260203, 0.02608813627860586, 0.026040362308986036, 0.026001550337470015, 0.025993237790160485, 0.025986995674662023], 'acc': [0.9428589477648999, 0.9914462771404465, 0.9930349346968412, 0.9938113018260719, 0.9943166067074037, 0.9946156307236577, 0.9948455865080642, 0.9950331390515254, 0.9951710433388683, 0.9953169360286737, 0.9954024403557907, 0.9955001041837822, 0.9955814949342597, 0.9956436755125871, 0.9956866851185033, 0.9957503982839483, 0.9958355328671848, 0.9958570600109699, 0.9958851332555788, 0.9959392683569137, 0.9959803366557141, 0.9960261994897819, 0.9960143403143652, 0.9960619817529924, 0.9960884707561067, 0.9961212975472743, 0.9961528096691599, 0.9961604763956602, 0.9961700090476204, 0.996173160313904, 0.9962105557062143, 0.9962340933263598, 0.9962370962550897, 0.9962635959962831, 0.9962570309515453, 0.9962636514309242, 0.9962874491268336, 0.9963037392187294, 0.9963142689488242, 0.9963197693882015, 0.9963162334869924, 0.9963181398793782, 0.9963499645683872, 0.9963586674087721, 0.9963752055456091, 0.996352778115482, 0.9963685073290973, 0.996393988305155, 0.9963880512229405, 0.9963941684501681, 0.9964121553182866, 0.9964221592339118, 0.9964183881129721, 0.9964263595287391, 0.9964354884314819, 0.9964251092432073, 0.9964382618076826, 0.9964526130097018, 0.9964530845502312, 0.9964511338212071, 0.9964573679299337, 0.9964621042108026, 0.9964859073460326, 0.996458524752435, 0.9964805774700306, 0.9964692905094266, 0.996483503958631, 0.9964974646732373, 0.9964974568273263, 0.9965186422522967, 0.9964991136094222, 0.9965271960821345, 0.9965070624990761, 0.9965068967786979, 0.9965153209614585, 0.9965271826116168, 0.9965252597756157, 0.9965236803110966, 0.9965303885905643, 0.9965428941272082, 0.996533500369596, 0.9965403312680448, 0.9965369218406209, 0.9965463814749214, 0.9965510560171599, 0.9965743071912727, 0.9965628102503222, 0.9965653265153377, 0.9965835670955985, 0.9965804753977544, 0.996561633536179, 0.9965681164671968, 0.9965856064936396, 0.9965782156646386, 0.9965942737356526, 0.9965835698727614, 0.9965886857538833, 0.9965996153847804, 0.996593878377556, 0.9966074656127423, 0.9965948579429528], 'mDice': [0.6813570096544136, 0.849878567163084, 0.8801401474086802, 0.8948518866940992, 0.9048683943100015, 0.9105540738039497, 0.9152967721851035, 0.918893799134107, 0.9216243944146112, 0.924256326738063, 0.9263483748672118, 0.928043501461528, 0.9296776382648902, 0.9306272314467751, 0.9316454216564746, 0.9328645000858322, 0.9344036321648193, 0.9349754980430217, 0.9352743046057205, 0.9365139615051437, 0.9374339154271207, 0.9382017906291328, 0.9379485055352218, 0.9387948110768337, 0.9393853588720505, 0.9398070891945249, 0.940567388662585, 0.9407657729973257, 0.9409841960528641, 0.9412469860803498, 0.9419393370434944, 0.942273414828844, 0.9423453873426375, 0.9428181924032629, 0.9430036551018605, 0.9428916213898924, 0.9434027018158425, 0.9436276256644117, 0.944021918452744, 0.9441391116008628, 0.9442987382938, 0.9444354313420096, 0.9448672928802282, 0.9449385452100981, 0.9454547411806736, 0.9451403112581366, 0.9456286175750129, 0.9457039632533837, 0.9457508245243513, 0.9459681567597304, 0.9463357744707778, 0.9464998136814902, 0.946527308667124, 0.9467209096050647, 0.9466927471632666, 0.9468041756177216, 0.9470953439475256, 0.9472901034586025, 0.9474123186180351, 0.9472321478075147, 0.9476331182796693, 0.9477578593730739, 0.9480590862907022, 0.94774867939098, 0.9482998574696268, 0.9480359394731691, 0.9482507420134799, 0.9484671328907488, 0.9485377098461326, 0.9488722076070829, 0.9485505663467322, 0.9489512715636289, 0.9489961005072461, 0.9488197444578832, 0.9491815696610436, 0.9491928480132947, 0.949185043227299, 0.949350217990938, 0.9493782816901145, 0.9495795432188148, 0.9494180902197127, 0.9496405995594503, 0.949571617594289, 0.9497236706361462, 0.9498444967882066, 0.9499897488031535, 0.9500964931273429, 0.950179271373087, 0.9502109498563983, 0.9501425699264745, 0.9500402153298612, 0.9501852511371426, 0.9505277631554304, 0.9504679131555579, 0.9505537818745537, 0.9506581863559795, 0.9507259164745199, 0.9508170603376861, 0.9508890708010692, 0.9508991293313909, 0.950912745665025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:04,  1.02s/it]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.24it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.52it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  1.79it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.98it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:56,  2.27it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:58,  2.23it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:44,  2.52it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:48,  2.41it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<01:47,  2.42it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:39,  2.61it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:38,  2.63it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:33,  2.77it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:29,  2.88it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:28,  2.91it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:27,  2.92it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:36,  2.63it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:33,  2.69it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:29,  2.81it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:26,  2.91it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:28,  2.82it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:26,  2.87it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:25,  2.90it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:28,  2.78it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:24,  2.91it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:22,  2.95it/s]predicting train subjects:   8%|▊         | 22/266 [00:07<01:23,  2.92it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:20,  3.00it/s]predicting train subjects:   9%|▉         | 24/266 [00:08<01:20,  3.02it/s]predicting train subjects:   9%|▉         | 25/266 [00:08<01:22,  2.94it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:20,  2.99it/s]predicting train subjects:  10%|█         | 27/266 [00:09<01:22,  2.90it/s]predicting train subjects:  11%|█         | 28/266 [00:09<01:23,  2.85it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:24,  2.80it/s]predicting train subjects:  11%|█▏        | 30/266 [00:10<01:19,  2.96it/s]predicting train subjects:  12%|█▏        | 31/266 [00:10<01:17,  3.03it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:16,  3.04it/s]predicting train subjects:  12%|█▏        | 33/266 [00:11<01:16,  3.06it/s]predicting train subjects:  13%|█▎        | 34/266 [00:11<01:14,  3.11it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:12,  3.17it/s]predicting train subjects:  14%|█▎        | 36/266 [00:12<01:14,  3.08it/s]predicting train subjects:  14%|█▍        | 37/266 [00:12<01:12,  3.16it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:11,  3.17it/s]predicting train subjects:  15%|█▍        | 39/266 [00:13<01:12,  3.14it/s]predicting train subjects:  15%|█▌        | 40/266 [00:13<01:14,  3.04it/s]predicting train subjects:  15%|█▌        | 41/266 [00:14<01:11,  3.14it/s]predicting train subjects:  16%|█▌        | 42/266 [00:14<01:12,  3.10it/s]predicting train subjects:  16%|█▌        | 43/266 [00:14<01:07,  3.29it/s]predicting train subjects:  17%|█▋        | 44/266 [00:14<01:04,  3.47it/s]predicting train subjects:  17%|█▋        | 45/266 [00:15<01:13,  3.01it/s]predicting train subjects:  17%|█▋        | 46/266 [00:15<01:12,  3.03it/s]predicting train subjects:  18%|█▊        | 47/266 [00:16<01:12,  3.02it/s]predicting train subjects:  18%|█▊        | 48/266 [00:16<01:10,  3.09it/s]predicting train subjects:  18%|█▊        | 49/266 [00:16<01:09,  3.13it/s]predicting train subjects:  19%|█▉        | 50/266 [00:17<01:07,  3.19it/s]predicting train subjects:  19%|█▉        | 51/266 [00:17<01:03,  3.39it/s]predicting train subjects:  20%|█▉        | 52/266 [00:17<01:03,  3.39it/s]predicting train subjects:  20%|█▉        | 53/266 [00:17<01:03,  3.38it/s]predicting train subjects:  20%|██        | 54/266 [00:18<01:03,  3.32it/s]predicting train subjects:  21%|██        | 55/266 [00:18<01:03,  3.31it/s]predicting train subjects:  21%|██        | 56/266 [00:18<01:00,  3.48it/s]predicting train subjects:  21%|██▏       | 57/266 [00:18<00:58,  3.57it/s]predicting train subjects:  22%|██▏       | 58/266 [00:19<00:56,  3.70it/s]predicting train subjects:  22%|██▏       | 59/266 [00:19<00:56,  3.69it/s]predicting train subjects:  23%|██▎       | 60/266 [00:19<00:54,  3.81it/s]predicting train subjects:  23%|██▎       | 61/266 [00:19<00:52,  3.92it/s]predicting train subjects:  23%|██▎       | 62/266 [00:20<00:51,  3.95it/s]predicting train subjects:  24%|██▎       | 63/266 [00:20<00:50,  4.03it/s]predicting train subjects:  24%|██▍       | 64/266 [00:20<00:50,  3.98it/s]predicting train subjects:  24%|██▍       | 65/266 [00:21<00:59,  3.39it/s]predicting train subjects:  25%|██▍       | 66/266 [00:21<00:57,  3.50it/s]predicting train subjects:  25%|██▌       | 67/266 [00:21<00:57,  3.46it/s]predicting train subjects:  26%|██▌       | 68/266 [00:21<00:56,  3.50it/s]predicting train subjects:  26%|██▌       | 69/266 [00:22<00:54,  3.63it/s]predicting train subjects:  26%|██▋       | 70/266 [00:22<00:52,  3.76it/s]predicting train subjects:  27%|██▋       | 71/266 [00:22<00:50,  3.87it/s]predicting train subjects:  27%|██▋       | 72/266 [00:22<00:49,  3.93it/s]predicting train subjects:  27%|██▋       | 73/266 [00:23<00:48,  3.98it/s]predicting train subjects:  28%|██▊       | 74/266 [00:23<00:47,  4.01it/s]predicting train subjects:  28%|██▊       | 75/266 [00:23<00:51,  3.74it/s]predicting train subjects:  29%|██▊       | 76/266 [00:24<00:56,  3.37it/s]predicting train subjects:  29%|██▉       | 77/266 [00:24<00:52,  3.57it/s]predicting train subjects:  29%|██▉       | 78/266 [00:24<00:57,  3.24it/s]predicting train subjects:  30%|██▉       | 79/266 [00:25<00:57,  3.25it/s]predicting train subjects:  30%|███       | 80/266 [00:25<00:57,  3.23it/s]predicting train subjects:  30%|███       | 81/266 [00:25<00:58,  3.15it/s]predicting train subjects:  31%|███       | 82/266 [00:25<00:58,  3.14it/s]predicting train subjects:  31%|███       | 83/266 [00:26<00:58,  3.10it/s]predicting train subjects:  32%|███▏      | 84/266 [00:26<01:05,  2.78it/s]predicting train subjects:  32%|███▏      | 85/266 [00:27<01:02,  2.92it/s]predicting train subjects:  32%|███▏      | 86/266 [00:27<01:00,  2.99it/s]predicting train subjects:  33%|███▎      | 87/266 [00:27<00:58,  3.07it/s]predicting train subjects:  33%|███▎      | 88/266 [00:28<00:56,  3.14it/s]predicting train subjects:  33%|███▎      | 89/266 [00:28<00:55,  3.18it/s]predicting train subjects:  34%|███▍      | 90/266 [00:28<00:56,  3.11it/s]predicting train subjects:  34%|███▍      | 91/266 [00:28<00:55,  3.13it/s]predicting train subjects:  35%|███▍      | 92/266 [00:29<00:56,  3.06it/s]predicting train subjects:  35%|███▍      | 93/266 [00:29<00:58,  2.97it/s]predicting train subjects:  35%|███▌      | 94/266 [00:29<00:56,  3.02it/s]predicting train subjects:  36%|███▌      | 95/266 [00:30<00:57,  2.95it/s]predicting train subjects:  36%|███▌      | 96/266 [00:30<00:58,  2.93it/s]predicting train subjects:  36%|███▋      | 97/266 [00:31<00:59,  2.84it/s]predicting train subjects:  37%|███▋      | 98/266 [00:31<01:00,  2.80it/s]predicting train subjects:  37%|███▋      | 99/266 [00:31<00:55,  3.03it/s]predicting train subjects:  38%|███▊      | 100/266 [00:32<00:54,  3.04it/s]predicting train subjects:  38%|███▊      | 101/266 [00:32<00:56,  2.94it/s]predicting train subjects:  38%|███▊      | 102/266 [00:32<00:52,  3.13it/s]predicting train subjects:  39%|███▊      | 103/266 [00:32<00:49,  3.29it/s]predicting train subjects:  39%|███▉      | 104/266 [00:33<00:47,  3.38it/s]predicting train subjects:  39%|███▉      | 105/266 [00:33<00:45,  3.51it/s]predicting train subjects:  40%|███▉      | 106/266 [00:33<00:46,  3.45it/s]predicting train subjects:  40%|████      | 107/266 [00:34<00:45,  3.48it/s]predicting train subjects:  41%|████      | 108/266 [00:34<00:45,  3.49it/s]predicting train subjects:  41%|████      | 109/266 [00:34<00:45,  3.47it/s]predicting train subjects:  41%|████▏     | 110/266 [00:35<00:51,  3.06it/s]predicting train subjects:  42%|████▏     | 111/266 [00:35<00:49,  3.13it/s]predicting train subjects:  42%|████▏     | 112/266 [00:35<00:47,  3.24it/s]predicting train subjects:  42%|████▏     | 113/266 [00:35<00:45,  3.38it/s]predicting train subjects:  43%|████▎     | 114/266 [00:36<00:43,  3.47it/s]predicting train subjects:  43%|████▎     | 115/266 [00:36<00:45,  3.35it/s]predicting train subjects:  44%|████▎     | 116/266 [00:36<00:43,  3.45it/s]predicting train subjects:  44%|████▍     | 117/266 [00:37<00:46,  3.22it/s]predicting train subjects:  44%|████▍     | 118/266 [00:37<00:46,  3.21it/s]predicting train subjects:  45%|████▍     | 119/266 [00:37<00:52,  2.79it/s]predicting train subjects:  45%|████▌     | 120/266 [00:38<00:52,  2.79it/s]predicting train subjects:  45%|████▌     | 121/266 [00:38<00:49,  2.91it/s]predicting train subjects:  46%|████▌     | 122/266 [00:38<00:48,  2.95it/s]predicting train subjects:  46%|████▌     | 123/266 [00:39<00:48,  2.98it/s]predicting train subjects:  47%|████▋     | 124/266 [00:39<00:48,  2.94it/s]predicting train subjects:  47%|████▋     | 125/266 [00:39<00:50,  2.80it/s]predicting train subjects:  47%|████▋     | 126/266 [00:40<00:49,  2.81it/s]predicting train subjects:  48%|████▊     | 127/266 [00:40<00:49,  2.82it/s]predicting train subjects:  48%|████▊     | 128/266 [00:40<00:46,  2.94it/s]predicting train subjects:  48%|████▊     | 129/266 [00:41<00:45,  3.03it/s]predicting train subjects:  49%|████▉     | 130/266 [00:41<00:45,  3.01it/s]predicting train subjects:  49%|████▉     | 131/266 [00:42<00:50,  2.66it/s]predicting train subjects:  50%|████▉     | 132/266 [00:42<00:49,  2.72it/s]predicting train subjects:  50%|█████     | 133/266 [00:42<00:48,  2.76it/s]predicting train subjects:  50%|█████     | 134/266 [00:43<00:48,  2.73it/s]predicting train subjects:  51%|█████     | 135/266 [00:43<00:47,  2.78it/s]predicting train subjects:  51%|█████     | 136/266 [00:44<00:51,  2.52it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:44<00:48,  2.67it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:44<00:45,  2.83it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:44<00:44,  2.84it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:45<00:44,  2.80it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:45<00:43,  2.88it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:46<00:46,  2.69it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:46<00:42,  2.88it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:46<00:42,  2.88it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:47<00:42,  2.87it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:47<00:41,  2.90it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:47<00:41,  2.85it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:48<00:42,  2.76it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:48<00:39,  2.93it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:48<00:38,  3.01it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:49<00:37,  3.05it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:49<00:37,  3.03it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:49<00:36,  3.10it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:50<00:38,  2.90it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:50<00:35,  3.09it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:50<00:34,  3.20it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:50<00:31,  3.45it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:51<00:29,  3.69it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:51<00:28,  3.74it/s]predicting train subjects:  60%|██████    | 160/266 [00:51<00:27,  3.87it/s]predicting train subjects:  61%|██████    | 161/266 [00:51<00:27,  3.88it/s]predicting train subjects:  61%|██████    | 162/266 [00:52<00:31,  3.35it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:52<00:30,  3.42it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:52<00:29,  3.49it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:53<00:28,  3.49it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:53<00:26,  3.73it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:53<00:25,  3.92it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:53<00:24,  4.01it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:54<00:23,  4.06it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:54<00:25,  3.82it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:54<00:25,  3.70it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:54<00:25,  3.66it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:55<00:25,  3.70it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:55<00:25,  3.64it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:55<00:25,  3.53it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:56<00:26,  3.45it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:56<00:26,  3.35it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:56<00:28,  3.12it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:57<00:27,  3.17it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:57<00:27,  3.15it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:57<00:25,  3.29it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:57<00:25,  3.33it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:58<00:24,  3.38it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:58<00:23,  3.42it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:59<00:27,  2.92it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:59<00:25,  3.09it/s]predicting train subjects:  70%|███████   | 187/266 [00:59<00:26,  3.03it/s]predicting train subjects:  71%|███████   | 188/266 [00:59<00:24,  3.18it/s]predicting train subjects:  71%|███████   | 189/266 [01:00<00:22,  3.36it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:00<00:21,  3.46it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:00<00:22,  3.31it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:01<00:24,  3.04it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:01<00:22,  3.20it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:01<00:24,  2.93it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:02<00:22,  3.11it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:02<00:21,  3.25it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:02<00:19,  3.46it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:02<00:20,  3.36it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:03<00:19,  3.45it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:03<00:19,  3.42it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:03<00:19,  3.40it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:04<00:19,  3.36it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:04<00:18,  3.48it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:04<00:17,  3.59it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:04<00:17,  3.53it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:05<00:18,  3.26it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:05<00:17,  3.47it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:05<00:16,  3.53it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:06<00:16,  3.45it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:06<00:15,  3.53it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:06<00:15,  3.62it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:06<00:14,  3.73it/s]predicting train subjects:  80%|████████  | 213/266 [01:07<00:14,  3.73it/s]predicting train subjects:  80%|████████  | 214/266 [01:07<00:15,  3.41it/s]predicting train subjects:  81%|████████  | 215/266 [01:07<00:14,  3.60it/s]predicting train subjects:  81%|████████  | 216/266 [01:08<00:14,  3.49it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:08<00:13,  3.71it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:08<00:13,  3.57it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:08<00:13,  3.58it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:09<00:12,  3.73it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:09<00:12,  3.73it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:09<00:12,  3.41it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:10<00:12,  3.56it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:10<00:11,  3.73it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:10<00:11,  3.68it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:10<00:10,  3.88it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:10<00:09,  4.01it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:11<00:09,  4.14it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:11<00:08,  4.21it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:11<00:09,  3.97it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:12<00:09,  3.81it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:12<00:08,  3.92it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:12<00:08,  3.98it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:12<00:07,  4.01it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:12<00:07,  3.93it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:13<00:08,  3.65it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:13<00:07,  3.74it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:13<00:07,  3.68it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:14<00:07,  3.62it/s]predicting train subjects:  90%|█████████ | 240/266 [01:14<00:06,  3.76it/s]predicting train subjects:  91%|█████████ | 241/266 [01:14<00:06,  3.85it/s]predicting train subjects:  91%|█████████ | 242/266 [01:14<00:06,  3.93it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:15<00:05,  3.95it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:15<00:05,  4.03it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:15<00:05,  3.84it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:15<00:05,  3.79it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:16<00:05,  3.56it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:16<00:04,  3.65it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:16<00:04,  3.52it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:17<00:04,  3.29it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:17<00:04,  3.29it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:17<00:04,  3.29it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:18<00:03,  3.29it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:18<00:03,  3.21it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:18<00:03,  2.75it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:19<00:03,  2.92it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:19<00:02,  3.05it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:19<00:02,  3.15it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:20<00:02,  2.99it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:20<00:01,  3.08it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:20<00:01,  2.96it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:21<00:01,  2.97it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:21<00:00,  3.04it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:21<00:00,  3.14it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:22<00:00,  3.02it/s]predicting train subjects: 100%|██████████| 266/266 [01:22<00:00,  3.13it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 61.48it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 61.50it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:04, 61.98it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 62.80it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:03, 60.97it/s]saving BB  train1-THALAMUS:  13%|█▎        | 34/266 [00:00<00:03, 63.31it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:03, 65.71it/s]saving BB  train1-THALAMUS:  19%|█▉        | 50/266 [00:00<00:03, 68.41it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 70.82it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 73.95it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 76.58it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 74.33it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 72.86it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 70.57it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 71.28it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 71.97it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 70.65it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 70.32it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:02<00:01, 69.86it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 148/266 [00:02<00:01, 67.53it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 155/266 [00:02<00:01, 67.65it/s]saving BB  train1-THALAMUS:  61%|██████▏   | 163/266 [00:02<00:01, 69.67it/s]saving BB  train1-THALAMUS:  65%|██████▍   | 172/266 [00:02<00:01, 73.26it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 181/266 [00:02<00:01, 75.58it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 190/266 [00:02<00:00, 77.62it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 198/266 [00:02<00:00, 75.36it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 206/266 [00:02<00:00, 75.07it/s]saving BB  train1-THALAMUS:  80%|████████  | 214/266 [00:02<00:00, 75.37it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 222/266 [00:03<00:00, 75.92it/s]saving BB  train1-THALAMUS:  86%|████████▋ | 230/266 [00:03<00:00, 75.93it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 238/266 [00:03<00:00, 62.79it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 246/266 [00:03<00:00, 66.43it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 254/266 [00:03<00:00, 67.69it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 69.18it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 70.89it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:25,  1.91s/it]Loading train:   1%|          | 2/266 [00:03<07:56,  1.81s/it]Loading train:   1%|          | 3/266 [00:04<07:26,  1.70s/it]Loading train:   2%|▏         | 4/266 [00:06<06:56,  1.59s/it]Loading train:   2%|▏         | 5/266 [00:07<06:45,  1.55s/it]Loading train:   2%|▏         | 6/266 [00:09<06:33,  1.51s/it]Loading train:   3%|▎         | 7/266 [00:10<05:58,  1.38s/it]Loading train:   3%|▎         | 8/266 [00:11<05:46,  1.34s/it]Loading train:   3%|▎         | 9/266 [00:12<05:30,  1.29s/it]Loading train:   4%|▍         | 10/266 [00:13<05:29,  1.29s/it]Loading train:   4%|▍         | 11/266 [00:15<05:19,  1.25s/it]Loading train:   5%|▍         | 12/266 [00:16<05:19,  1.26s/it]Loading train:   5%|▍         | 13/266 [00:17<05:15,  1.25s/it]Loading train:   5%|▌         | 14/266 [00:18<05:18,  1.26s/it]Loading train:   6%|▌         | 15/266 [00:20<05:07,  1.23s/it]Loading train:   6%|▌         | 16/266 [00:21<05:06,  1.23s/it]Loading train:   6%|▋         | 17/266 [00:22<05:03,  1.22s/it]Loading train:   7%|▋         | 18/266 [00:23<05:00,  1.21s/it]Loading train:   7%|▋         | 19/266 [00:24<04:51,  1.18s/it]Loading train:   8%|▊         | 20/266 [00:26<04:55,  1.20s/it]Loading train:   8%|▊         | 21/266 [00:27<04:45,  1.17s/it]Loading train:   8%|▊         | 22/266 [00:28<04:51,  1.19s/it]Loading train:   9%|▊         | 23/266 [00:29<04:41,  1.16s/it]Loading train:   9%|▉         | 24/266 [00:30<04:42,  1.17s/it]Loading train:   9%|▉         | 25/266 [00:31<04:22,  1.09s/it]Loading train:  10%|▉         | 26/266 [00:32<04:08,  1.03s/it]Loading train:  10%|█         | 27/266 [00:33<04:04,  1.02s/it]Loading train:  11%|█         | 28/266 [00:34<04:01,  1.02s/it]Loading train:  11%|█         | 29/266 [00:35<04:06,  1.04s/it]Loading train:  11%|█▏        | 30/266 [00:36<03:58,  1.01s/it]Loading train:  12%|█▏        | 31/266 [00:37<04:08,  1.06s/it]Loading train:  12%|█▏        | 32/266 [00:38<04:03,  1.04s/it]Loading train:  12%|█▏        | 33/266 [00:39<03:56,  1.02s/it]Loading train:  13%|█▎        | 34/266 [00:40<03:57,  1.03s/it]Loading train:  13%|█▎        | 35/266 [00:41<03:48,  1.01it/s]Loading train:  14%|█▎        | 36/266 [00:42<03:47,  1.01it/s]Loading train:  14%|█▍        | 37/266 [00:43<03:44,  1.02it/s]Loading train:  14%|█▍        | 38/266 [00:44<03:39,  1.04it/s]Loading train:  15%|█▍        | 39/266 [00:45<03:51,  1.02s/it]Loading train:  15%|█▌        | 40/266 [00:46<03:49,  1.02s/it]Loading train:  15%|█▌        | 41/266 [00:47<03:52,  1.03s/it]Loading train:  16%|█▌        | 42/266 [00:48<03:55,  1.05s/it]Loading train:  16%|█▌        | 43/266 [00:49<03:45,  1.01s/it]Loading train:  17%|█▋        | 44/266 [00:50<03:37,  1.02it/s]Loading train:  17%|█▋        | 45/266 [00:51<03:26,  1.07it/s]Loading train:  17%|█▋        | 46/266 [00:52<03:22,  1.09it/s]Loading train:  18%|█▊        | 47/266 [00:53<03:18,  1.11it/s]Loading train:  18%|█▊        | 48/266 [00:54<03:15,  1.12it/s]Loading train:  18%|█▊        | 49/266 [00:55<03:24,  1.06it/s]Loading train:  19%|█▉        | 50/266 [00:55<03:16,  1.10it/s]Loading train:  19%|█▉        | 51/266 [00:56<03:14,  1.10it/s]Loading train:  20%|█▉        | 52/266 [00:57<03:10,  1.13it/s]Loading train:  20%|█▉        | 53/266 [00:58<03:09,  1.13it/s]Loading train:  20%|██        | 54/266 [00:59<03:11,  1.11it/s]Loading train:  21%|██        | 55/266 [01:00<03:11,  1.10it/s]Loading train:  21%|██        | 56/266 [01:01<03:07,  1.12it/s]Loading train:  21%|██▏       | 57/266 [01:02<03:12,  1.08it/s]Loading train:  22%|██▏       | 58/266 [01:03<03:08,  1.10it/s]Loading train:  22%|██▏       | 59/266 [01:04<03:09,  1.09it/s]Loading train:  23%|██▎       | 60/266 [01:04<03:10,  1.08it/s]Loading train:  23%|██▎       | 61/266 [01:05<03:01,  1.13it/s]Loading train:  23%|██▎       | 62/266 [01:06<03:03,  1.11it/s]Loading train:  24%|██▎       | 63/266 [01:07<03:00,  1.12it/s]Loading train:  24%|██▍       | 64/266 [01:08<02:57,  1.14it/s]Loading train:  24%|██▍       | 65/266 [01:09<02:51,  1.17it/s]Loading train:  25%|██▍       | 66/266 [01:10<02:46,  1.20it/s]Loading train:  25%|██▌       | 67/266 [01:10<02:44,  1.21it/s]Loading train:  26%|██▌       | 68/266 [01:11<02:44,  1.20it/s]Loading train:  26%|██▌       | 69/266 [01:12<02:41,  1.22it/s]Loading train:  26%|██▋       | 70/266 [01:13<02:37,  1.25it/s]Loading train:  27%|██▋       | 71/266 [01:14<02:36,  1.25it/s]Loading train:  27%|██▋       | 72/266 [01:14<02:36,  1.24it/s]Loading train:  27%|██▋       | 73/266 [01:15<02:31,  1.27it/s]Loading train:  28%|██▊       | 74/266 [01:16<02:29,  1.28it/s]Loading train:  28%|██▊       | 75/266 [01:17<02:43,  1.17it/s]Loading train:  29%|██▊       | 76/266 [01:18<02:34,  1.23it/s]Loading train:  29%|██▉       | 77/266 [01:18<02:31,  1.25it/s]Loading train:  29%|██▉       | 78/266 [01:20<02:49,  1.11it/s]Loading train:  30%|██▉       | 79/266 [01:20<02:49,  1.10it/s]Loading train:  30%|███       | 80/266 [01:22<03:05,  1.00it/s]Loading train:  30%|███       | 81/266 [01:23<03:04,  1.00it/s]Loading train:  31%|███       | 82/266 [01:24<03:02,  1.01it/s]Loading train:  31%|███       | 83/266 [01:25<03:01,  1.01it/s]Loading train:  32%|███▏      | 84/266 [01:26<02:57,  1.03it/s]Loading train:  32%|███▏      | 85/266 [01:27<03:05,  1.03s/it]Loading train:  32%|███▏      | 86/266 [01:28<03:02,  1.02s/it]Loading train:  33%|███▎      | 87/266 [01:29<03:05,  1.04s/it]Loading train:  33%|███▎      | 88/266 [01:30<03:02,  1.02s/it]Loading train:  33%|███▎      | 89/266 [01:31<02:59,  1.01s/it]Loading train:  34%|███▍      | 90/266 [01:32<02:56,  1.01s/it]Loading train:  34%|███▍      | 91/266 [01:33<03:03,  1.05s/it]Loading train:  35%|███▍      | 92/266 [01:34<03:03,  1.05s/it]Loading train:  35%|███▍      | 93/266 [01:35<02:59,  1.04s/it]Loading train:  35%|███▌      | 94/266 [01:36<02:58,  1.04s/it]Loading train:  36%|███▌      | 95/266 [01:37<02:52,  1.01s/it]Loading train:  36%|███▌      | 96/266 [01:38<03:19,  1.18s/it]Loading train:  36%|███▋      | 97/266 [01:40<03:43,  1.32s/it]Loading train:  37%|███▋      | 98/266 [01:41<03:38,  1.30s/it]Loading train:  37%|███▋      | 99/266 [01:43<03:30,  1.26s/it]Loading train:  38%|███▊      | 100/266 [01:44<03:25,  1.24s/it]Loading train:  38%|███▊      | 101/266 [01:45<03:17,  1.19s/it]Loading train:  38%|███▊      | 102/266 [01:46<03:04,  1.12s/it]Loading train:  39%|███▊      | 103/266 [01:47<02:53,  1.06s/it]Loading train:  39%|███▉      | 104/266 [01:48<02:43,  1.01s/it]Loading train:  39%|███▉      | 105/266 [01:49<02:37,  1.02it/s]Loading train:  40%|███▉      | 106/266 [01:49<02:35,  1.03it/s]Loading train:  40%|████      | 107/266 [01:50<02:31,  1.05it/s]Loading train:  41%|████      | 108/266 [01:51<02:36,  1.01it/s]Loading train:  41%|████      | 109/266 [01:52<02:31,  1.03it/s]Loading train:  41%|████▏     | 110/266 [01:53<02:35,  1.00it/s]Loading train:  42%|████▏     | 111/266 [01:54<02:31,  1.02it/s]Loading train:  42%|████▏     | 112/266 [01:55<02:27,  1.05it/s]Loading train:  42%|████▏     | 113/266 [01:56<02:24,  1.06it/s]Loading train:  43%|████▎     | 114/266 [01:57<02:21,  1.07it/s]Loading train:  43%|████▎     | 115/266 [01:58<02:31,  1.00s/it]Loading train:  44%|████▎     | 116/266 [01:59<02:29,  1.00it/s]Loading train:  44%|████▍     | 117/266 [02:00<02:31,  1.02s/it]Loading train:  44%|████▍     | 118/266 [02:01<02:26,  1.01it/s]Loading train:  45%|████▍     | 119/266 [02:02<02:34,  1.05s/it]Loading train:  45%|████▌     | 120/266 [02:03<02:31,  1.04s/it]Loading train:  45%|████▌     | 121/266 [02:04<02:29,  1.03s/it]Loading train:  46%|████▌     | 122/266 [02:05<02:26,  1.02s/it]Loading train:  46%|████▌     | 123/266 [02:06<02:24,  1.01s/it]Loading train:  47%|████▋     | 124/266 [02:08<02:26,  1.03s/it]Loading train:  47%|████▋     | 125/266 [02:09<02:25,  1.03s/it]Loading train:  47%|████▋     | 126/266 [02:10<02:24,  1.03s/it]Loading train:  48%|████▊     | 127/266 [02:11<02:22,  1.02s/it]Loading train:  48%|████▊     | 128/266 [02:12<02:29,  1.08s/it]Loading train:  48%|████▊     | 129/266 [02:13<02:28,  1.08s/it]Loading train:  49%|████▉     | 130/266 [02:14<02:21,  1.04s/it]Loading train:  49%|████▉     | 131/266 [02:15<02:19,  1.03s/it]Loading train:  50%|████▉     | 132/266 [02:16<02:21,  1.06s/it]Loading train:  50%|█████     | 133/266 [02:17<02:21,  1.06s/it]Loading train:  50%|█████     | 134/266 [02:18<02:25,  1.10s/it]Loading train:  51%|█████     | 135/266 [02:19<02:20,  1.07s/it]Loading train:  51%|█████     | 136/266 [02:20<02:24,  1.11s/it]Loading train:  52%|█████▏    | 137/266 [02:22<02:24,  1.12s/it]Loading train:  52%|█████▏    | 138/266 [02:23<02:26,  1.14s/it]Loading train:  52%|█████▏    | 139/266 [02:24<02:17,  1.08s/it]Loading train:  53%|█████▎    | 140/266 [02:25<02:11,  1.04s/it]Loading train:  53%|█████▎    | 141/266 [02:26<02:04,  1.01it/s]Loading train:  53%|█████▎    | 142/266 [02:27<02:02,  1.01it/s]Loading train:  54%|█████▍    | 143/266 [02:28<02:06,  1.03s/it]Loading train:  54%|█████▍    | 144/266 [02:29<02:02,  1.00s/it]Loading train:  55%|█████▍    | 145/266 [02:30<02:08,  1.06s/it]Loading train:  55%|█████▍    | 146/266 [02:31<02:06,  1.05s/it]Loading train:  55%|█████▌    | 147/266 [02:32<02:07,  1.07s/it]Loading train:  56%|█████▌    | 148/266 [02:33<02:04,  1.06s/it]Loading train:  56%|█████▌    | 149/266 [02:34<02:02,  1.05s/it]Loading train:  56%|█████▋    | 150/266 [02:35<01:59,  1.03s/it]Loading train:  57%|█████▋    | 151/266 [02:36<01:58,  1.03s/it]Loading train:  57%|█████▋    | 152/266 [02:37<01:55,  1.01s/it]Loading train:  58%|█████▊    | 153/266 [02:38<01:54,  1.01s/it]Loading train:  58%|█████▊    | 154/266 [02:39<01:51,  1.00it/s]Loading train:  58%|█████▊    | 155/266 [02:40<01:47,  1.04it/s]Loading train:  59%|█████▊    | 156/266 [02:41<01:46,  1.04it/s]Loading train:  59%|█████▉    | 157/266 [02:42<01:44,  1.05it/s]Loading train:  59%|█████▉    | 158/266 [02:43<01:39,  1.08it/s]Loading train:  60%|█████▉    | 159/266 [02:43<01:35,  1.12it/s]Loading train:  60%|██████    | 160/266 [02:44<01:33,  1.14it/s]Loading train:  61%|██████    | 161/266 [02:45<01:31,  1.14it/s]Loading train:  61%|██████    | 162/266 [02:46<01:29,  1.16it/s]Loading train:  61%|██████▏   | 163/266 [02:47<01:26,  1.19it/s]Loading train:  62%|██████▏   | 164/266 [02:47<01:23,  1.23it/s]Loading train:  62%|██████▏   | 165/266 [02:48<01:27,  1.16it/s]Loading train:  62%|██████▏   | 166/266 [02:49<01:25,  1.16it/s]Loading train:  63%|██████▎   | 167/266 [02:50<01:24,  1.17it/s]Loading train:  63%|██████▎   | 168/266 [02:51<01:23,  1.18it/s]Loading train:  64%|██████▎   | 169/266 [02:52<01:21,  1.19it/s]Loading train:  64%|██████▍   | 170/266 [02:53<01:18,  1.22it/s]Loading train:  64%|██████▍   | 171/266 [02:53<01:16,  1.25it/s]Loading train:  65%|██████▍   | 172/266 [02:54<01:17,  1.21it/s]Loading train:  65%|██████▌   | 173/266 [02:55<01:17,  1.20it/s]Loading train:  65%|██████▌   | 174/266 [02:56<01:17,  1.19it/s]Loading train:  66%|██████▌   | 175/266 [02:57<01:19,  1.15it/s]Loading train:  66%|██████▌   | 176/266 [02:58<01:15,  1.20it/s]Loading train:  67%|██████▋   | 177/266 [02:58<01:12,  1.23it/s]Loading train:  67%|██████▋   | 178/266 [02:59<01:11,  1.24it/s]Loading train:  67%|██████▋   | 179/266 [03:00<01:11,  1.21it/s]Loading train:  68%|██████▊   | 180/266 [03:01<01:14,  1.16it/s]Loading train:  68%|██████▊   | 181/266 [03:02<01:10,  1.21it/s]Loading train:  68%|██████▊   | 182/266 [03:03<01:11,  1.18it/s]Loading train:  69%|██████▉   | 183/266 [03:03<01:07,  1.23it/s]Loading train:  69%|██████▉   | 184/266 [03:04<01:03,  1.29it/s]Loading train:  70%|██████▉   | 185/266 [03:05<01:00,  1.33it/s]Loading train:  70%|██████▉   | 186/266 [03:06<01:03,  1.26it/s]Loading train:  70%|███████   | 187/266 [03:07<01:06,  1.20it/s]Loading train:  71%|███████   | 188/266 [03:07<01:04,  1.20it/s]Loading train:  71%|███████   | 189/266 [03:08<01:05,  1.18it/s]Loading train:  71%|███████▏  | 190/266 [03:09<01:02,  1.21it/s]Loading train:  72%|███████▏  | 191/266 [03:10<01:13,  1.02it/s]Loading train:  72%|███████▏  | 192/266 [03:12<01:19,  1.07s/it]Loading train:  73%|███████▎  | 193/266 [03:13<01:21,  1.12s/it]Loading train:  73%|███████▎  | 194/266 [03:15<01:32,  1.28s/it]Loading train:  73%|███████▎  | 195/266 [03:15<01:23,  1.18s/it]Loading train:  74%|███████▎  | 196/266 [03:16<01:15,  1.08s/it]Loading train:  74%|███████▍  | 197/266 [03:17<01:13,  1.06s/it]Loading train:  74%|███████▍  | 198/266 [03:18<01:07,  1.01it/s]Loading train:  75%|███████▍  | 199/266 [03:19<01:04,  1.04it/s]Loading train:  75%|███████▌  | 200/266 [03:20<01:02,  1.06it/s]Loading train:  76%|███████▌  | 201/266 [03:21<00:59,  1.09it/s]Loading train:  76%|███████▌  | 202/266 [03:22<00:58,  1.10it/s]Loading train:  76%|███████▋  | 203/266 [03:23<00:56,  1.11it/s]Loading train:  77%|███████▋  | 204/266 [03:24<00:55,  1.12it/s]Loading train:  77%|███████▋  | 205/266 [03:24<00:54,  1.11it/s]Loading train:  77%|███████▋  | 206/266 [03:25<00:52,  1.14it/s]Loading train:  78%|███████▊  | 207/266 [03:26<00:54,  1.08it/s]Loading train:  78%|███████▊  | 208/266 [03:27<00:52,  1.11it/s]Loading train:  79%|███████▊  | 209/266 [03:28<00:50,  1.14it/s]Loading train:  79%|███████▉  | 210/266 [03:29<00:51,  1.09it/s]Loading train:  79%|███████▉  | 211/266 [03:30<00:49,  1.10it/s]Loading train:  80%|███████▉  | 212/266 [03:31<00:48,  1.12it/s]Loading train:  80%|████████  | 213/266 [03:32<00:47,  1.12it/s]Loading train:  80%|████████  | 214/266 [03:32<00:44,  1.16it/s]Loading train:  81%|████████  | 215/266 [03:33<00:42,  1.19it/s]Loading train:  81%|████████  | 216/266 [03:34<00:41,  1.21it/s]Loading train:  82%|████████▏ | 217/266 [03:35<00:42,  1.16it/s]Loading train:  82%|████████▏ | 218/266 [03:36<00:40,  1.18it/s]Loading train:  82%|████████▏ | 219/266 [03:37<00:39,  1.18it/s]Loading train:  83%|████████▎ | 220/266 [03:37<00:39,  1.18it/s]Loading train:  83%|████████▎ | 221/266 [03:38<00:38,  1.17it/s]Loading train:  83%|████████▎ | 222/266 [03:39<00:36,  1.20it/s]Loading train:  84%|████████▍ | 223/266 [03:40<00:35,  1.22it/s]Loading train:  84%|████████▍ | 224/266 [03:41<00:41,  1.02it/s]Loading train:  85%|████████▍ | 225/266 [03:42<00:42,  1.03s/it]Loading train:  85%|████████▍ | 226/266 [03:44<00:43,  1.09s/it]Loading train:  85%|████████▌ | 227/266 [03:45<00:48,  1.24s/it]Loading train:  86%|████████▌ | 228/266 [03:46<00:48,  1.26s/it]Loading train:  86%|████████▌ | 229/266 [03:48<00:44,  1.21s/it]Loading train:  86%|████████▋ | 230/266 [03:49<00:45,  1.27s/it]Loading train:  87%|████████▋ | 231/266 [03:50<00:43,  1.25s/it]Loading train:  87%|████████▋ | 232/266 [03:51<00:40,  1.19s/it]Loading train:  88%|████████▊ | 233/266 [03:52<00:38,  1.18s/it]Loading train:  88%|████████▊ | 234/266 [03:54<00:38,  1.21s/it]Loading train:  88%|████████▊ | 235/266 [03:55<00:37,  1.22s/it]Loading train:  89%|████████▊ | 236/266 [03:56<00:34,  1.16s/it]Loading train:  89%|████████▉ | 237/266 [03:57<00:33,  1.14s/it]Loading train:  89%|████████▉ | 238/266 [03:58<00:32,  1.15s/it]Loading train:  90%|████████▉ | 239/266 [03:59<00:30,  1.13s/it]Loading train:  90%|█████████ | 240/266 [04:00<00:28,  1.11s/it]Loading train:  91%|█████████ | 241/266 [04:02<00:28,  1.14s/it]Loading train:  91%|█████████ | 242/266 [04:03<00:28,  1.21s/it]Loading train:  91%|█████████▏| 243/266 [04:04<00:28,  1.25s/it]Loading train:  92%|█████████▏| 244/266 [04:06<00:28,  1.29s/it]Loading train:  92%|█████████▏| 245/266 [04:07<00:26,  1.26s/it]Loading train:  92%|█████████▏| 246/266 [04:08<00:24,  1.23s/it]Loading train:  93%|█████████▎| 247/266 [04:09<00:22,  1.20s/it]Loading train:  93%|█████████▎| 248/266 [04:10<00:21,  1.19s/it]Loading train:  94%|█████████▎| 249/266 [04:12<00:21,  1.29s/it]Loading train:  94%|█████████▍| 250/266 [04:13<00:22,  1.39s/it]Loading train:  94%|█████████▍| 251/266 [04:15<00:22,  1.48s/it]Loading train:  95%|█████████▍| 252/266 [04:17<00:21,  1.55s/it]Loading train:  95%|█████████▌| 253/266 [04:18<00:19,  1.51s/it]Loading train:  95%|█████████▌| 254/266 [04:20<00:17,  1.47s/it]Loading train:  96%|█████████▌| 255/266 [04:21<00:16,  1.52s/it]Loading train:  96%|█████████▌| 256/266 [04:23<00:15,  1.54s/it]Loading train:  97%|█████████▋| 257/266 [04:24<00:13,  1.47s/it]Loading train:  97%|█████████▋| 258/266 [04:26<00:11,  1.42s/it]Loading train:  97%|█████████▋| 259/266 [04:27<00:09,  1.40s/it]Loading train:  98%|█████████▊| 260/266 [04:28<00:08,  1.41s/it]Loading train:  98%|█████████▊| 261/266 [04:30<00:07,  1.51s/it]Loading train:  98%|█████████▊| 262/266 [04:31<00:05,  1.44s/it]Loading train:  99%|█████████▉| 263/266 [04:33<00:04,  1.43s/it]Loading train:  99%|█████████▉| 264/266 [04:34<00:02,  1.40s/it]Loading train: 100%|█████████▉| 265/266 [04:36<00:01,  1.49s/it]Loading train: 100%|██████████| 266/266 [04:37<00:00,  1.55s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/266 [00:00<00:11, 23.03it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:07, 31.53it/s]concatenating: train:  19%|█▉        | 51/266 [00:00<00:05, 42.43it/s]concatenating: train:  26%|██▋       | 70/266 [00:00<00:03, 53.30it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:04, 38.92it/s]concatenating: train:  35%|███▍      | 93/266 [00:01<00:04, 41.01it/s]concatenating: train:  44%|████▍     | 118/266 [00:01<00:02, 54.71it/s]concatenating: train:  54%|█████▍    | 144/266 [00:01<00:01, 71.53it/s]concatenating: train:  63%|██████▎   | 168/266 [00:01<00:01, 90.35it/s]concatenating: train:  70%|███████   | 187/266 [00:02<00:01, 51.49it/s]concatenating: train:  76%|███████▌  | 201/266 [00:02<00:01, 40.07it/s]concatenating: train:  83%|████████▎ | 222/266 [00:02<00:00, 52.88it/s]concatenating: train:  92%|█████████▏| 245/266 [00:03<00:00, 68.61it/s]concatenating: train:  99%|█████████▉| 263/266 [00:03<00:00, 82.78it/s]concatenating: train: 100%|██████████| 266/266 [00:03<00:00, 83.15it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:02<00:08,  2.05s/it]Loading test:  40%|████      | 2/5 [00:03<00:05,  1.90s/it]Loading test:  60%|██████    | 3/5 [00:05<00:03,  1.86s/it]Loading test:  80%|████████  | 4/5 [00:06<00:01,  1.79s/it]Loading test: 100%|██████████| 5/5 [00:08<00:00,  1.82s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00, 18.01it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 32.97it/s]2019-08-17 20:52:01.891788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 20:52:01.891900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 20:52:01.891915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 20:52:01.891923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 20:52:01.892454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.65it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.48it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.42it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.94it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.40it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.98it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.10it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.77it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.69it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.55it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.95it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.11it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.91it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.73it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.94it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.51it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.20it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.56it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.66it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.57it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 215,953
Non-trainable params: 285,390
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34826189e-02 3.29021600e-02 7.69371759e-02 9.55983097e-03
 2.76683277e-02 7.23863803e-03 8.42870784e-02 1.14354446e-01
 8.97908111e-02 1.36423488e-02 2.91119470e-01 1.88779320e-01
 2.37774536e-04]
Train on 16969 samples, validate on 312 samples
Epoch 1/300
 - 20s - loss: 1.2453 - acc: 0.7668 - mDice: 0.3742 - val_loss: 1.2853 - val_acc: 0.9312 - val_mDice: 0.4791

Epoch 00001: val_mDice improved from -inf to 0.47910, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.5868 - acc: 0.9156 - mDice: 0.5526 - val_loss: 1.1190 - val_acc: 0.9505 - val_mDice: 0.5510

Epoch 00002: val_mDice improved from 0.47910 to 0.55095, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.4820 - acc: 0.9344 - mDice: 0.6093 - val_loss: 1.0745 - val_acc: 0.9508 - val_mDice: 0.5643

Epoch 00003: val_mDice improved from 0.55095 to 0.56432, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4394 - acc: 0.9406 - mDice: 0.6388 - val_loss: 1.2943 - val_acc: 0.9407 - val_mDice: 0.5232

Epoch 00004: val_mDice did not improve from 0.56432
Epoch 5/300
 - 15s - loss: 0.4361 - acc: 0.9415 - mDice: 0.6449 - val_loss: 0.9792 - val_acc: 0.9466 - val_mDice: 0.5725

Epoch 00005: val_mDice improved from 0.56432 to 0.57246, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.3818 - acc: 0.9450 - mDice: 0.6726 - val_loss: 0.9204 - val_acc: 0.9513 - val_mDice: 0.5825

Epoch 00006: val_mDice improved from 0.57246 to 0.58254, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 0.3697 - acc: 0.9462 - mDice: 0.6836 - val_loss: 0.9117 - val_acc: 0.9527 - val_mDice: 0.5882

Epoch 00007: val_mDice improved from 0.58254 to 0.58825, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 15s - loss: 0.3376 - acc: 0.9479 - mDice: 0.7006 - val_loss: 0.9287 - val_acc: 0.9512 - val_mDice: 0.5811

Epoch 00008: val_mDice did not improve from 0.58825
Epoch 9/300
 - 15s - loss: 0.3427 - acc: 0.9484 - mDice: 0.7003 - val_loss: 0.9626 - val_acc: 0.9507 - val_mDice: 0.5720

Epoch 00009: val_mDice did not improve from 0.58825
Epoch 10/300
 - 14s - loss: 0.3227 - acc: 0.9495 - mDice: 0.7127 - val_loss: 0.9417 - val_acc: 0.9494 - val_mDice: 0.5752

Epoch 00010: val_mDice did not improve from 0.58825
Epoch 11/300
 - 15s - loss: 0.3269 - acc: 0.9492 - mDice: 0.7123 - val_loss: 0.8943 - val_acc: 0.9526 - val_mDice: 0.5739

Epoch 00011: val_mDice did not improve from 0.58825
Epoch 12/300
 - 14s - loss: 0.2990 - acc: 0.9513 - mDice: 0.7291 - val_loss: 0.9088 - val_acc: 0.9513 - val_mDice: 0.5850

Epoch 00012: val_mDice did not improve from 0.58825
Epoch 13/300
 - 14s - loss: 0.3206 - acc: 0.9494 - mDice: 0.7181 - val_loss: 0.8600 - val_acc: 0.9523 - val_mDice: 0.5685

Epoch 00013: val_mDice did not improve from 0.58825
Epoch 14/300
 - 14s - loss: 0.2911 - acc: 0.9519 - mDice: 0.7354 - val_loss: 0.8324 - val_acc: 0.9509 - val_mDice: 0.5787

Epoch 00014: val_mDice did not improve from 0.58825
Epoch 15/300
 - 14s - loss: 0.3405 - acc: 0.9486 - mDice: 0.7053 - val_loss: 0.8513 - val_acc: 0.9523 - val_mDice: 0.5895

Epoch 00015: val_mDice improved from 0.58825 to 0.58954, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 14s - loss: 0.2968 - acc: 0.9520 - mDice: 0.7347 - val_loss: 0.8489 - val_acc: 0.9511 - val_mDice: 0.5666

Epoch 00016: val_mDice did not improve from 0.58954
Epoch 17/300
 - 14s - loss: 0.2939 - acc: 0.9526 - mDice: 0.7385 - val_loss: 0.8610 - val_acc: 0.9518 - val_mDice: 0.5850

Epoch 00017: val_mDice did not improve from 0.58954
Epoch 18/300
 - 14s - loss: 0.2823 - acc: 0.9533 - mDice: 0.7466 - val_loss: 0.9623 - val_acc: 0.9474 - val_mDice: 0.5798

Epoch 00018: val_mDice did not improve from 0.58954
Epoch 19/300
 - 14s - loss: 0.2715 - acc: 0.9537 - mDice: 0.7510 - val_loss: 0.8026 - val_acc: 0.9518 - val_mDice: 0.5872

Epoch 00019: val_mDice did not improve from 0.58954
Epoch 20/300
 - 15s - loss: 0.2665 - acc: 0.9540 - mDice: 0.7539 - val_loss: 0.7661 - val_acc: 0.9522 - val_mDice: 0.5899

Epoch 00020: val_mDice improved from 0.58954 to 0.58990, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 14s - loss: 0.2826 - acc: 0.9525 - mDice: 0.7446 - val_loss: 0.8427 - val_acc: 0.9527 - val_mDice: 0.5869

Epoch 00021: val_mDice did not improve from 0.58990
Epoch 22/300
 - 14s - loss: 0.2713 - acc: 0.9538 - mDice: 0.7515 - val_loss: 0.8758 - val_acc: 0.9514 - val_mDice: 0.5863

Epoch 00022: val_mDice did not improve from 0.58990
Epoch 23/300
 - 15s - loss: 0.2698 - acc: 0.9543 - mDice: 0.7542 - val_loss: 0.8632 - val_acc: 0.9531 - val_mDice: 0.5822

Epoch 00023: val_mDice did not improve from 0.58990
Epoch 24/300
 - 14s - loss: 0.2874 - acc: 0.9524 - mDice: 0.7409 - val_loss: 0.8031 - val_acc: 0.9544 - val_mDice: 0.5748

Epoch 00024: val_mDice did not improve from 0.58990
Epoch 25/300
 - 14s - loss: 0.2924 - acc: 0.9529 - mDice: 0.7421 - val_loss: 0.8041 - val_acc: 0.9509 - val_mDice: 0.5880

Epoch 00025: val_mDice did not improve from 0.58990
Epoch 26/300
 - 15s - loss: 0.2627 - acc: 0.9549 - mDice: 0.7609 - val_loss: 0.7811 - val_acc: 0.9531 - val_mDice: 0.5714

Epoch 00026: val_mDice did not improve from 0.58990
Epoch 27/300
 - 15s - loss: 0.2755 - acc: 0.9544 - mDice: 0.7547 - val_loss: 0.7945 - val_acc: 0.9519 - val_mDice: 0.5772

Epoch 00027: val_mDice did not improve from 0.58990
Epoch 28/300
 - 15s - loss: 0.2774 - acc: 0.9540 - mDice: 0.7520 - val_loss: 0.7217 - val_acc: 0.9529 - val_mDice: 0.5663

Epoch 00028: val_mDice did not improve from 0.58990
Epoch 29/300
 - 14s - loss: 0.2595 - acc: 0.9551 - mDice: 0.7620 - val_loss: 0.8065 - val_acc: 0.9500 - val_mDice: 0.5767

Epoch 00029: val_mDice did not improve from 0.58990
Epoch 30/300
 - 14s - loss: 0.2706 - acc: 0.9545 - mDice: 0.7574 - val_loss: 0.7608 - val_acc: 0.9520 - val_mDice: 0.5224

Epoch 00030: val_mDice did not improve from 0.58990
Epoch 31/300
 - 14s - loss: 0.2709 - acc: 0.9547 - mDice: 0.7583 - val_loss: 0.8179 - val_acc: 0.9514 - val_mDice: 0.5814

Epoch 00031: val_mDice did not improve from 0.58990
Epoch 32/300
 - 14s - loss: 0.2594 - acc: 0.9555 - mDice: 0.7652 - val_loss: 0.8056 - val_acc: 0.9515 - val_mDice: 0.5768

Epoch 00032: val_mDice did not improve from 0.58990
Epoch 33/300
 - 14s - loss: 0.3015 - acc: 0.9496 - mDice: 0.7368 - val_loss: 0.8017 - val_acc: 0.9532 - val_mDice: 0.5834

Epoch 00033: val_mDice did not improve from 0.58990
Epoch 34/300
 - 14s - loss: 0.2795 - acc: 0.9535 - mDice: 0.7530 - val_loss: 0.9559 - val_acc: 0.9534 - val_mDice: 0.5554

Epoch 00034: val_mDice did not improve from 0.58990
Epoch 35/300
 - 14s - loss: 0.3057 - acc: 0.9516 - mDice: 0.7353 - val_loss: 0.9486 - val_acc: 0.9502 - val_mDice: 0.5734

Epoch 00035: val_mDice did not improve from 0.58990
Epoch 36/300
 - 15s - loss: 0.2569 - acc: 0.9545 - mDice: 0.7616 - val_loss: 0.8865 - val_acc: 0.9525 - val_mDice: 0.5732

Epoch 00036: val_mDice did not improve from 0.58990
Epoch 37/300
 - 14s - loss: 0.2491 - acc: 0.9554 - mDice: 0.7688 - val_loss: 0.9159 - val_acc: 0.9517 - val_mDice: 0.5688

Epoch 00037: val_mDice did not improve from 0.58990
Epoch 38/300
 - 14s - loss: 0.2502 - acc: 0.9556 - mDice: 0.7702 - val_loss: 0.8448 - val_acc: 0.9520 - val_mDice: 0.5748

Epoch 00038: val_mDice did not improve from 0.58990
Epoch 39/300
 - 15s - loss: 0.2730 - acc: 0.9534 - mDice: 0.7544 - val_loss: 0.8389 - val_acc: 0.9538 - val_mDice: 0.5274

Epoch 00039: val_mDice did not improve from 0.58990
Epoch 40/300
 - 14s - loss: 0.2589 - acc: 0.9547 - mDice: 0.7638 - val_loss: 0.9092 - val_acc: 0.9517 - val_mDice: 0.5735

Epoch 00040: val_mDice did not improve from 0.58990
Epoch 41/300
 - 14s - loss: 0.2539 - acc: 0.9556 - mDice: 0.7678 - val_loss: 0.8244 - val_acc: 0.9516 - val_mDice: 0.5706

Epoch 00041: val_mDice did not improve from 0.58990
Epoch 42/300
 - 14s - loss: 0.2542 - acc: 0.9557 - mDice: 0.7703 - val_loss: 0.8700 - val_acc: 0.9508 - val_mDice: 0.5720

Epoch 00042: val_mDice did not improve from 0.58990
Epoch 43/300
 - 14s - loss: 0.2616 - acc: 0.9548 - mDice: 0.7657 - val_loss: 0.7880 - val_acc: 0.9542 - val_mDice: 0.5638

Epoch 00043: val_mDice did not improve from 0.58990
Epoch 44/300
 - 14s - loss: 0.2672 - acc: 0.9541 - mDice: 0.7603 - val_loss: 0.7968 - val_acc: 0.9511 - val_mDice: 0.5816

Epoch 00044: val_mDice did not improve from 0.58990
Epoch 45/300
 - 15s - loss: 0.2560 - acc: 0.9559 - mDice: 0.7711 - val_loss: 0.7165 - val_acc: 0.9516 - val_mDice: 0.5762

Epoch 00045: val_mDice did not improve from 0.58990
Epoch 46/300
 - 14s - loss: 0.2468 - acc: 0.9561 - mDice: 0.7745 - val_loss: 0.7582 - val_acc: 0.9525 - val_mDice: 0.5799

Epoch 00046: val_mDice did not improve from 0.58990
Epoch 47/300
 - 14s - loss: 0.2599 - acc: 0.9554 - mDice: 0.7683 - val_loss: 0.8981 - val_acc: 0.9519 - val_mDice: 0.5502

Epoch 00047: val_mDice did not improve from 0.58990
Epoch 48/300
 - 15s - loss: 0.2528 - acc: 0.9561 - mDice: 0.7733 - val_loss: 0.9155 - val_acc: 0.9529 - val_mDice: 0.5650

Epoch 00048: val_mDice did not improve from 0.58990
Epoch 49/300
 - 14s - loss: 0.2507 - acc: 0.9561 - mDice: 0.7731 - val_loss: 0.8280 - val_acc: 0.9516 - val_mDice: 0.5717

Epoch 00049: val_mDice did not improve from 0.58990
Epoch 50/300
 - 14s - loss: 0.2365 - acc: 0.9569 - mDice: 0.7800 - val_loss: 0.8249 - val_acc: 0.9520 - val_mDice: 0.5824

Epoch 00050: val_mDice did not improve from 0.58990
Epoch 51/300
 - 15s - loss: 0.2420 - acc: 0.9569 - mDice: 0.7809 - val_loss: 0.8758 - val_acc: 0.9515 - val_mDice: 0.5633

Epoch 00051: val_mDice did not improve from 0.58990
Epoch 52/300
 - 14s - loss: 0.2438 - acc: 0.9569 - mDice: 0.7800 - val_loss: 0.8123 - val_acc: 0.9522 - val_mDice: 0.5815

Epoch 00052: val_mDice did not improve from 0.58990
Epoch 53/300
 - 14s - loss: 0.2548 - acc: 0.9562 - mDice: 0.7751 - val_loss: 0.8438 - val_acc: 0.9521 - val_mDice: 0.5764

Epoch 00053: val_mDice did not improve from 0.58990
Epoch 54/300
 - 15s - loss: 0.2351 - acc: 0.9569 - mDice: 0.7830 - val_loss: 0.8179 - val_acc: 0.9542 - val_mDice: 0.5714

Epoch 00054: val_mDice did not improve from 0.58990
Epoch 55/300
 - 15s - loss: 0.3164 - acc: 0.9494 - mDice: 0.7306 - val_loss: 0.6985 - val_acc: 0.9519 - val_mDice: 0.5752

Epoch 00055: val_mDice did not improve from 0.58990
Epoch 56/300
 - 14s - loss: 0.2669 - acc: 0.9546 - mDice: 0.7595 - val_loss: 0.7268 - val_acc: 0.9501 - val_mDice: 0.5740

Epoch 00056: val_mDice did not improve from 0.58990
Epoch 57/300
 - 14s - loss: 0.2704 - acc: 0.9542 - mDice: 0.7581 - val_loss: 0.7360 - val_acc: 0.9518 - val_mDice: 0.5765

Epoch 00057: val_mDice did not improve from 0.58990
Epoch 58/300
 - 14s - loss: 0.2466 - acc: 0.9557 - mDice: 0.7704 - val_loss: 0.7120 - val_acc: 0.9525 - val_mDice: 0.5846

Epoch 00058: val_mDice did not improve from 0.58990
Epoch 59/300
 - 14s - loss: 0.2557 - acc: 0.9553 - mDice: 0.7702 - val_loss: 0.7958 - val_acc: 0.9522 - val_mDice: 0.5826

Epoch 00059: val_mDice did not improve from 0.58990
Epoch 60/300
 - 14s - loss: 0.2434 - acc: 0.9561 - mDice: 0.7735 - val_loss: 0.7063 - val_acc: 0.9517 - val_mDice: 0.5778

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:12,  3.02s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.79s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.54s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.36s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.40s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:23,  2.81s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:04,  2.74s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:21,  2.59s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:33,  2.42s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:42,  2.46s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:17,  2.61s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:28,  2.66s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:40,  2.72s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:41,  2.73s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:48,  2.77s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:50,  2.79s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<11:52,  2.81s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:44,  2.78s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:40,  2.78s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<11:39,  2.79s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:35,  2.78s/it]predicting train subjects:   6%|▋         | 17/266 [00:45<11:33,  2.78s/it]predicting train subjects:   7%|▋         | 18/266 [00:48<11:35,  2.80s/it]predicting train subjects:   7%|▋         | 19/266 [00:51<11:38,  2.83s/it]predicting train subjects:   8%|▊         | 20/266 [00:54<11:29,  2.80s/it]predicting train subjects:   8%|▊         | 21/266 [00:57<11:28,  2.81s/it]predicting train subjects:   8%|▊         | 22/266 [01:00<11:21,  2.79s/it]predicting train subjects:   9%|▊         | 23/266 [01:02<11:20,  2.80s/it]predicting train subjects:   9%|▉         | 24/266 [01:05<11:00,  2.73s/it]predicting train subjects:   9%|▉         | 25/266 [01:07<10:46,  2.68s/it]predicting train subjects:  10%|▉         | 26/266 [01:10<10:35,  2.65s/it]predicting train subjects:  10%|█         | 27/266 [01:13<10:20,  2.60s/it]predicting train subjects:  11%|█         | 28/266 [01:15<10:14,  2.58s/it]predicting train subjects:  11%|█         | 29/266 [01:18<10:04,  2.55s/it]predicting train subjects:  11%|█▏        | 30/266 [01:20<10:02,  2.55s/it]predicting train subjects:  12%|█▏        | 31/266 [01:23<10:00,  2.55s/it]predicting train subjects:  12%|█▏        | 32/266 [01:25<09:58,  2.56s/it]predicting train subjects:  12%|█▏        | 33/266 [01:28<09:57,  2.56s/it]predicting train subjects:  13%|█▎        | 34/266 [01:30<09:57,  2.57s/it]predicting train subjects:  13%|█▎        | 35/266 [01:33<09:51,  2.56s/it]predicting train subjects:  14%|█▎        | 36/266 [01:35<09:47,  2.56s/it]predicting train subjects:  14%|█▍        | 37/266 [01:38<09:44,  2.55s/it]predicting train subjects:  14%|█▍        | 38/266 [01:41<09:45,  2.57s/it]predicting train subjects:  15%|█▍        | 39/266 [01:43<09:39,  2.55s/it]predicting train subjects:  15%|█▌        | 40/266 [01:46<09:40,  2.57s/it]predicting train subjects:  15%|█▌        | 41/266 [01:48<09:34,  2.55s/it]predicting train subjects:  16%|█▌        | 42/266 [01:51<09:11,  2.46s/it]predicting train subjects:  16%|█▌        | 43/266 [01:53<08:56,  2.41s/it]predicting train subjects:  17%|█▋        | 44/266 [01:55<08:44,  2.36s/it]predicting train subjects:  17%|█▋        | 45/266 [01:57<08:29,  2.30s/it]predicting train subjects:  17%|█▋        | 46/266 [01:59<08:16,  2.26s/it]predicting train subjects:  18%|█▊        | 47/266 [02:02<08:09,  2.24s/it]predicting train subjects:  18%|█▊        | 48/266 [02:04<08:10,  2.25s/it]predicting train subjects:  18%|█▊        | 49/266 [02:06<08:03,  2.23s/it]predicting train subjects:  19%|█▉        | 50/266 [02:08<08:03,  2.24s/it]predicting train subjects:  19%|█▉        | 51/266 [02:10<07:56,  2.21s/it]predicting train subjects:  20%|█▉        | 52/266 [02:13<07:49,  2.19s/it]predicting train subjects:  20%|█▉        | 53/266 [02:15<07:45,  2.19s/it]predicting train subjects:  20%|██        | 54/266 [02:17<07:44,  2.19s/it]predicting train subjects:  21%|██        | 55/266 [02:19<07:39,  2.18s/it]predicting train subjects:  21%|██        | 56/266 [02:21<07:42,  2.20s/it]predicting train subjects:  21%|██▏       | 57/266 [02:24<07:42,  2.21s/it]predicting train subjects:  22%|██▏       | 58/266 [02:26<07:40,  2.21s/it]predicting train subjects:  22%|██▏       | 59/266 [02:28<07:38,  2.21s/it]predicting train subjects:  23%|██▎       | 60/266 [02:30<07:24,  2.16s/it]predicting train subjects:  23%|██▎       | 61/266 [02:32<07:13,  2.12s/it]predicting train subjects:  23%|██▎       | 62/266 [02:34<07:07,  2.09s/it]predicting train subjects:  24%|██▎       | 63/266 [02:36<06:59,  2.07s/it]predicting train subjects:  24%|██▍       | 64/266 [02:38<06:50,  2.03s/it]predicting train subjects:  24%|██▍       | 65/266 [02:40<06:53,  2.06s/it]predicting train subjects:  25%|██▍       | 66/266 [02:42<06:52,  2.06s/it]predicting train subjects:  25%|██▌       | 67/266 [02:44<06:47,  2.05s/it]predicting train subjects:  26%|██▌       | 68/266 [02:46<06:45,  2.05s/it]predicting train subjects:  26%|██▌       | 69/266 [02:48<06:42,  2.04s/it]predicting train subjects:  26%|██▋       | 70/266 [02:50<06:40,  2.04s/it]predicting train subjects:  27%|██▋       | 71/266 [02:53<06:42,  2.06s/it]predicting train subjects:  27%|██▋       | 72/266 [02:55<06:39,  2.06s/it]predicting train subjects:  27%|██▋       | 73/266 [02:57<06:38,  2.06s/it]predicting train subjects:  28%|██▊       | 74/266 [02:59<06:36,  2.07s/it]predicting train subjects:  28%|██▊       | 75/266 [03:01<06:33,  2.06s/it]predicting train subjects:  29%|██▊       | 76/266 [03:03<06:26,  2.03s/it]predicting train subjects:  29%|██▉       | 77/266 [03:05<06:24,  2.04s/it]predicting train subjects:  29%|██▉       | 78/266 [03:07<06:55,  2.21s/it]predicting train subjects:  30%|██▉       | 79/266 [03:10<07:18,  2.34s/it]predicting train subjects:  30%|███       | 80/266 [03:13<07:29,  2.42s/it]predicting train subjects:  30%|███       | 81/266 [03:15<07:39,  2.49s/it]predicting train subjects:  31%|███       | 82/266 [03:18<07:43,  2.52s/it]predicting train subjects:  31%|███       | 83/266 [03:20<07:43,  2.53s/it]predicting train subjects:  32%|███▏      | 84/266 [03:23<07:38,  2.52s/it]predicting train subjects:  32%|███▏      | 85/266 [03:25<07:39,  2.54s/it]predicting train subjects:  32%|███▏      | 86/266 [03:28<07:35,  2.53s/it]predicting train subjects:  33%|███▎      | 87/266 [03:31<07:36,  2.55s/it]predicting train subjects:  33%|███▎      | 88/266 [03:33<07:34,  2.55s/it]predicting train subjects:  33%|███▎      | 89/266 [03:36<07:33,  2.56s/it]predicting train subjects:  34%|███▍      | 90/266 [03:38<07:36,  2.59s/it]predicting train subjects:  34%|███▍      | 91/266 [03:41<07:28,  2.57s/it]predicting train subjects:  35%|███▍      | 92/266 [03:43<07:27,  2.57s/it]predicting train subjects:  35%|███▍      | 93/266 [03:46<07:25,  2.57s/it]predicting train subjects:  35%|███▌      | 94/266 [03:49<07:21,  2.57s/it]predicting train subjects:  36%|███▌      | 95/266 [03:51<07:14,  2.54s/it]predicting train subjects:  36%|███▌      | 96/266 [03:53<07:02,  2.49s/it]predicting train subjects:  36%|███▋      | 97/266 [03:56<07:06,  2.53s/it]predicting train subjects:  37%|███▋      | 98/266 [03:59<07:04,  2.53s/it]predicting train subjects:  37%|███▋      | 99/266 [04:00<06:29,  2.33s/it]predicting train subjects:  38%|███▊      | 100/266 [04:03<06:11,  2.24s/it]predicting train subjects:  38%|███▊      | 101/266 [04:05<06:06,  2.22s/it]predicting train subjects:  38%|███▊      | 102/266 [04:07<06:05,  2.23s/it]predicting train subjects:  39%|███▊      | 103/266 [04:09<06:10,  2.27s/it]predicting train subjects:  39%|███▉      | 104/266 [04:12<06:06,  2.26s/it]predicting train subjects:  39%|███▉      | 105/266 [04:14<06:03,  2.26s/it]predicting train subjects:  40%|███▉      | 106/266 [04:16<06:01,  2.26s/it]predicting train subjects:  40%|████      | 107/266 [04:18<05:58,  2.26s/it]predicting train subjects:  41%|████      | 108/266 [04:21<05:56,  2.26s/it]predicting train subjects:  41%|████      | 109/266 [04:23<05:53,  2.25s/it]predicting train subjects:  41%|████▏     | 110/266 [04:25<05:52,  2.26s/it]predicting train subjects:  42%|████▏     | 111/266 [04:27<05:50,  2.26s/it]predicting train subjects:  42%|████▏     | 112/266 [04:30<05:47,  2.26s/it]predicting train subjects:  42%|████▏     | 113/266 [04:32<05:45,  2.26s/it]predicting train subjects:  43%|████▎     | 114/266 [04:34<05:43,  2.26s/it]predicting train subjects:  43%|████▎     | 115/266 [04:36<05:42,  2.27s/it]predicting train subjects:  44%|████▎     | 116/266 [04:39<05:42,  2.28s/it]predicting train subjects:  44%|████▍     | 117/266 [04:41<05:35,  2.25s/it]predicting train subjects:  44%|████▍     | 118/266 [04:43<05:32,  2.25s/it]predicting train subjects:  45%|████▍     | 119/266 [04:46<05:46,  2.36s/it]predicting train subjects:  45%|████▌     | 120/266 [04:48<05:51,  2.41s/it]predicting train subjects:  45%|████▌     | 121/266 [04:51<05:55,  2.45s/it]predicting train subjects:  46%|████▌     | 122/266 [04:53<05:55,  2.47s/it]predicting train subjects:  46%|████▌     | 123/266 [04:56<05:56,  2.50s/it]predicting train subjects:  47%|████▋     | 124/266 [04:58<05:57,  2.52s/it]predicting train subjects:  47%|████▋     | 125/266 [05:01<05:53,  2.51s/it]predicting train subjects:  47%|████▋     | 126/266 [05:03<05:51,  2.51s/it]predicting train subjects:  48%|████▊     | 127/266 [05:06<05:51,  2.53s/it]predicting train subjects:  48%|████▊     | 128/266 [05:09<05:48,  2.53s/it]predicting train subjects:  48%|████▊     | 129/266 [05:11<05:46,  2.53s/it]predicting train subjects:  49%|████▉     | 130/266 [05:14<05:45,  2.54s/it]predicting train subjects:  49%|████▉     | 131/266 [05:16<05:42,  2.54s/it]predicting train subjects:  50%|████▉     | 132/266 [05:19<05:40,  2.54s/it]predicting train subjects:  50%|█████     | 133/266 [05:21<05:37,  2.54s/it]predicting train subjects:  50%|█████     | 134/266 [05:24<05:35,  2.55s/it]predicting train subjects:  51%|█████     | 135/266 [05:26<05:30,  2.53s/it]predicting train subjects:  51%|█████     | 136/266 [05:29<05:30,  2.54s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:31<05:23,  2.51s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:34<05:19,  2.49s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:36<05:14,  2.48s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:39<05:11,  2.47s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:41<05:05,  2.45s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:44<05:04,  2.45s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:46<05:01,  2.45s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:49<05:02,  2.48s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:51<04:57,  2.46s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:53<04:54,  2.46s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:56<04:51,  2.45s/it]predicting train subjects:  56%|█████▌    | 148/266 [05:58<04:48,  2.44s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:01<04:43,  2.42s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:03<04:40,  2.41s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:05<04:36,  2.41s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:08<04:37,  2.44s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:11<04:40,  2.48s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:13<04:41,  2.51s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:15<04:21,  2.35s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:17<04:04,  2.22s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:19<03:52,  2.13s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:21<03:41,  2.05s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:23<03:37,  2.03s/it]predicting train subjects:  60%|██████    | 160/266 [06:25<03:34,  2.03s/it]predicting train subjects:  61%|██████    | 161/266 [06:27<03:26,  1.97s/it]predicting train subjects:  61%|██████    | 162/266 [06:29<03:22,  1.95s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:30<03:20,  1.95s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:32<03:17,  1.93s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:34<03:16,  1.95s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:36<03:17,  1.98s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:38<03:14,  1.97s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:40<03:08,  1.93s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:42<03:15,  2.02s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:44<03:08,  1.96s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:46<03:05,  1.95s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:48<03:01,  1.93s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:50<03:03,  1.97s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:52<03:03,  1.99s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:54<03:04,  2.03s/it]predicting train subjects:  66%|██████▌   | 176/266 [06:56<03:04,  2.05s/it]predicting train subjects:  67%|██████▋   | 177/266 [06:58<03:04,  2.07s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:01<03:03,  2.08s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:03<02:59,  2.06s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:05<03:00,  2.10s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:07<02:58,  2.10s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:09<02:54,  2.08s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:11<02:51,  2.07s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:13<02:51,  2.10s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:15<02:49,  2.09s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:17<02:46,  2.08s/it]predicting train subjects:  70%|███████   | 187/266 [07:19<02:42,  2.06s/it]predicting train subjects:  71%|███████   | 188/266 [07:21<02:42,  2.09s/it]predicting train subjects:  71%|███████   | 189/266 [07:23<02:40,  2.08s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:25<02:36,  2.06s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:28<02:37,  2.10s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:30<02:35,  2.10s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:32<02:31,  2.07s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:34<02:39,  2.21s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:37<02:38,  2.24s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:39<02:37,  2.25s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:41<02:35,  2.25s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:43<02:33,  2.25s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:46<02:31,  2.26s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:48<02:28,  2.25s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:50<02:24,  2.22s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:52<02:23,  2.24s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:55<02:21,  2.24s/it]predicting train subjects:  77%|███████▋  | 204/266 [07:57<02:18,  2.24s/it]predicting train subjects:  77%|███████▋  | 205/266 [07:59<02:15,  2.21s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:01<02:12,  2.21s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:03<02:11,  2.23s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:06<02:11,  2.26s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:08<02:09,  2.28s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:10<02:06,  2.26s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:13<02:02,  2.23s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:15<02:00,  2.24s/it]predicting train subjects:  80%|████████  | 213/266 [08:17<01:56,  2.19s/it]predicting train subjects:  80%|████████  | 214/266 [08:19<01:51,  2.15s/it]predicting train subjects:  81%|████████  | 215/266 [08:21<01:48,  2.12s/it]predicting train subjects:  81%|████████  | 216/266 [08:23<01:44,  2.08s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:25<01:42,  2.09s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:27<01:39,  2.07s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:29<01:36,  2.06s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:31<01:33,  2.03s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:33<01:31,  2.02s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:35<01:28,  2.01s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:37<01:25,  1.99s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:39<01:24,  2.00s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:41<01:22,  2.02s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:43<01:21,  2.03s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:45<01:19,  2.03s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:47<01:16,  2.02s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:49<01:14,  2.01s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:51<01:12,  2.01s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:53<01:10,  2.01s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:55<01:08,  2.01s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:57<01:06,  2.02s/it]predicting train subjects:  88%|████████▊ | 234/266 [08:59<01:04,  2.03s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:01<01:03,  2.04s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:03<01:01,  2.04s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:05<00:59,  2.05s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:07<00:57,  2.05s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:10<00:55,  2.05s/it]predicting train subjects:  90%|█████████ | 240/266 [09:12<00:53,  2.05s/it]predicting train subjects:  91%|█████████ | 241/266 [09:14<00:51,  2.07s/it]predicting train subjects:  91%|█████████ | 242/266 [09:16<00:49,  2.05s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:18<00:47,  2.05s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:20<00:44,  2.04s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:22<00:42,  2.04s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:24<00:40,  2.03s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:26<00:38,  2.04s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:28<00:36,  2.02s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:31<00:37,  2.21s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:33<00:37,  2.33s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:36<00:35,  2.40s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:38<00:33,  2.43s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:41<00:32,  2.47s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:43<00:29,  2.49s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:46<00:27,  2.49s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:48<00:24,  2.50s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:51<00:22,  2.50s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:53<00:20,  2.52s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:56<00:17,  2.55s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:59<00:15,  2.58s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:01<00:12,  2.59s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:04<00:10,  2.59s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:06<00:07,  2.59s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:09<00:05,  2.58s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:12<00:02,  2.58s/it]predicting train subjects: 100%|██████████| 266/266 [10:14<00:00,  2.57s/it]
Epoch 00060: val_mDice did not improve from 0.58990
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
{'val_loss': [1.285305291796342, 1.119005149946763, 1.0744859003103697, 1.294300041710719, 0.9791871981743054, 0.9203771507510772, 0.9116746603678434, 0.9287059656702555, 0.9625715920940424, 0.941700813288872, 0.8942640448609988, 0.9088466014617529, 0.8600002586459502, 0.8323650190081352, 0.8513049725920726, 0.8489169787902099, 0.8609871858587632, 0.9622620936387625, 0.8026288012281443, 0.7660713705878991, 0.8426561028911517, 0.8757814476505305, 0.863179338666109, 0.8030845280259084, 0.8040841046052102, 0.7811177779848759, 0.7945482451946307, 0.7217144969946299, 0.8065205728396391, 0.7608377366111829, 0.8179398475167079, 0.8055593436345075, 0.8016733179489771, 0.9558640582821308, 0.9486323314217421, 0.8864965438842773, 0.915942574158693, 0.8447662011170999, 0.8389398700151688, 0.9091910347342491, 0.8244478654785034, 0.8699641332794459, 0.7880058739429865, 0.7967576869787314, 0.7165164886376797, 0.7582096100235597, 0.898070137279156, 0.9155291475546665, 0.828021999161977, 0.8248564522617903, 0.8758370608855517, 0.8122793225905834, 0.8437857599212573, 0.817922446017082, 0.6984789663782487, 0.7267771411018494, 0.7359835597184988, 0.7119771956633298, 0.7957578007227335, 0.7062884678061192], 'val_acc': [0.9311644259171609, 0.9505409884911317, 0.9508230942182052, 0.940673121657127, 0.9466009579407864, 0.951338706490321, 0.9527279226443707, 0.9512249185488775, 0.9506583366638575, 0.9494410012012873, 0.9526425745242681, 0.9513149964503753, 0.9522822296772248, 0.9509333226925287, 0.9522502315350068, 0.9510862342058084, 0.9518460344809753, 0.9473500763758634, 0.9517772778486594, 0.952226520730899, 0.9527279180593979, 0.9513920610531782, 0.9531012838467573, 0.9544241275542822, 0.9508752341453846, 0.9530574522721462, 0.9518898950937467, 0.9528737129309238, 0.9499767732161742, 0.9519764230801508, 0.951388479807438, 0.9514821408650814, 0.9531570080763254, 0.9533585019600697, 0.950190123075094, 0.9524872849384943, 0.9516623123334005, 0.9519704821018072, 0.9538089361710426, 0.9517298711416049, 0.9516184547772775, 0.9508053156045767, 0.9542451321314542, 0.9511241725622079, 0.9516184490460616, 0.9525240468673217, 0.9519218966746942, 0.9528713321838623, 0.9515994829245102, 0.9520048648118973, 0.9515402126006591, 0.9521660697765839, 0.9520629552694467, 0.9542380235134027, 0.9519088531915958, 0.9501000398244613, 0.9517571318608063, 0.952497959901125, 0.9522063747430459, 0.9517263135848901], 'val_mDice': [0.4790963154190626, 0.5509536323639063, 0.5643217416527944, 0.523216592386747, 0.5724588791147257, 0.5825387155398344, 0.588249765527554, 0.5810862622964077, 0.5720373684397111, 0.5752418025946006, 0.5739251738175367, 0.5849717450447571, 0.5684836739913012, 0.5787349433088914, 0.5895394835716639, 0.5665617703627317, 0.5850450599040741, 0.579843374590079, 0.5871551843025745, 0.5898951055147709, 0.5869269755024177, 0.5862742700637915, 0.5822123065590858, 0.5747773845990499, 0.5879647674468848, 0.5713670788667141, 0.5771834151102946, 0.5663302149146031, 0.5766760450907242, 0.5223511488009722, 0.5814241654215715, 0.5767878618759986, 0.5834012058300849, 0.5554086172427887, 0.5733909935523303, 0.5731513731372662, 0.5688420568521206, 0.5748132239931669, 0.5273789602976579, 0.5734754017530344, 0.5705933062694012, 0.5720322048052763, 0.5637625390902544, 0.5815547313063573, 0.5761912724910638, 0.5799368306612357, 0.5501744928650367, 0.5649995864965976, 0.5716841530341369, 0.5823935337173634, 0.5632584658570778, 0.5815315235119599, 0.5763549235386726, 0.5714236516983081, 0.5752034208331352, 0.5739980309437482, 0.5764752462124213, 0.5845845811642133, 0.5825926940410565, 0.577774778008461], 'loss': [1.2453410631429118, 0.5868205199174759, 0.48202035565523527, 0.439386034139698, 0.43608568353309846, 0.38184317094111137, 0.3697008843838245, 0.33758964750170883, 0.34273225556940723, 0.3227459579570958, 0.326937233255203, 0.2990451529968943, 0.3206064160760652, 0.2911459989378143, 0.34048894142576264, 0.2968450771142305, 0.2939234945594446, 0.28232850624462763, 0.27146563979786803, 0.2665445074510178, 0.28256024476023284, 0.27127890959816736, 0.26980411202528626, 0.2874061598933869, 0.29237784132931327, 0.26266695963584, 0.2755406259001092, 0.277359488214978, 0.2595041157504666, 0.2706130962245655, 0.27093769033955967, 0.25937582867597536, 0.3015179547325204, 0.27953987644883344, 0.30573508782359804, 0.2569470251904077, 0.24912650262616098, 0.25017485914208426, 0.27302233510808704, 0.25886120695884873, 0.25391683395258474, 0.25417260281011445, 0.2616154002106403, 0.26717209242202195, 0.25595345547413656, 0.24681506924099797, 0.2598625736302187, 0.25280081381555564, 0.2506706270141898, 0.23647238423480219, 0.24198339401628885, 0.24378852736332413, 0.2548496886192997, 0.23507738198934178, 0.3164484445983684, 0.2669295797723726, 0.27040633395717284, 0.24660238595518594, 0.25565033970268203, 0.24340944159950503], 'acc': [0.7667843475801731, 0.9156388463124803, 0.9343923045684203, 0.9405707315421005, 0.9414537385017394, 0.9449812716498907, 0.9461859132216629, 0.9478890928404945, 0.9483541340009937, 0.9494995183237694, 0.9492158473883305, 0.9513328728569622, 0.9493848611093296, 0.9519049001538105, 0.948569176027606, 0.9520025808034631, 0.9525665221325853, 0.9532635612411641, 0.9536902417985698, 0.9539969093152296, 0.9525341593605915, 0.953758567640135, 0.9542508726444837, 0.9524091695023662, 0.9528619183719288, 0.95486557276432, 0.9544478034789087, 0.9540085650915051, 0.9550848861527195, 0.954501285867142, 0.954725001614772, 0.9554599157289594, 0.9496008821112342, 0.9534922222143015, 0.9515948577722148, 0.9544873604496842, 0.9553762064340351, 0.9556140662314467, 0.9533892694883309, 0.9547390151658935, 0.9555681892293914, 0.9556749138696367, 0.9547897083173834, 0.9541432549742848, 0.9558538882366664, 0.9561285152025879, 0.955443855619394, 0.9561147826774082, 0.9561326329495519, 0.9568800357630274, 0.9569209435663477, 0.9568643674585476, 0.9562283744127202, 0.9568791208217193, 0.9493707575874749, 0.954592078785433, 0.9542319350064458, 0.9557069517402912, 0.9553258837523363, 0.9560826588403399], 'mDice': [0.37421629618137864, 0.5525557298828601, 0.6092654548260942, 0.6387836613563201, 0.6448805456598743, 0.6725664740671244, 0.6836286766006836, 0.7005729027225495, 0.7003213541945668, 0.7126568167483184, 0.7123076627500224, 0.7291237937096708, 0.718066072128891, 0.735443332777805, 0.7053025555010711, 0.7346679744515887, 0.7385381347682496, 0.7466264166044595, 0.7510108051348382, 0.7538760108590596, 0.7446098328830989, 0.7514812485928232, 0.7542097543643033, 0.7409346300020363, 0.742118793888599, 0.7608617553903988, 0.7547444077399085, 0.7519917224164323, 0.7619704031425821, 0.7574153723731629, 0.7583420763798908, 0.7652259672585188, 0.7368183160820133, 0.7529959684410502, 0.7353403332785744, 0.7615901591627604, 0.7687525641546553, 0.7701670800700298, 0.7544161160943841, 0.7637947313955139, 0.7678255421593079, 0.7703262689546505, 0.7656779837696854, 0.7602861283544702, 0.7710766508201443, 0.774456853025389, 0.768277376505557, 0.7733446177227116, 0.7730604768101458, 0.7799790739781294, 0.7808503863160826, 0.7800362705973634, 0.7750559830273587, 0.7829890388641298, 0.730627806966886, 0.7594563556346919, 0.7580833115275055, 0.7703664575330397, 0.7701989120132929, 0.7734959384429658]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 6  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:06,  1.61s/it]Loading train:   1%|          | 2/266 [00:03<07:11,  1.63s/it]Loading train:   1%|          | 3/266 [00:04<06:47,  1.55s/it]Loading train:   2%|▏         | 4/266 [00:05<06:16,  1.44s/it]Loading train:   2%|▏         | 5/266 [00:07<06:11,  1.42s/it]Loading train:   2%|▏         | 6/266 [00:08<05:29,  1.27s/it]Loading train:   3%|▎         | 7/266 [00:09<05:05,  1.18s/it]Loading train:   3%|▎         | 8/266 [00:09<04:40,  1.09s/it]Loading train:   3%|▎         | 9/266 [00:10<04:27,  1.04s/it]Loading train:   4%|▍         | 10/266 [00:11<04:19,  1.01s/it]Loading train:   4%|▍         | 11/266 [00:12<04:12,  1.01it/s]Loading train:   5%|▍         | 12/266 [00:13<04:07,  1.02it/s]Loading train:   5%|▍         | 13/266 [00:14<04:01,  1.05it/s]Loading train:   5%|▌         | 14/266 [00:15<03:54,  1.08it/s]Loading train:   6%|▌         | 15/266 [00:16<03:53,  1.08it/s]Loading train:   6%|▌         | 16/266 [00:17<03:49,  1.09it/s]Loading train:   6%|▋         | 17/266 [00:18<04:16,  1.03s/it]Loading train:   7%|▋         | 18/266 [00:19<04:09,  1.01s/it]Loading train:   7%|▋         | 19/266 [00:20<04:00,  1.03it/s]Loading train:   8%|▊         | 20/266 [00:21<03:59,  1.03it/s]Loading train:   8%|▊         | 21/266 [00:22<03:56,  1.04it/s]Loading train:   8%|▊         | 22/266 [00:23<03:57,  1.03it/s]Loading train:   9%|▊         | 23/266 [00:24<03:45,  1.08it/s]Loading train:   9%|▉         | 24/266 [00:25<03:38,  1.11it/s]Loading train:   9%|▉         | 25/266 [00:25<03:39,  1.10it/s]Loading train:  10%|▉         | 26/266 [00:26<03:28,  1.15it/s]Loading train:  10%|█         | 27/266 [00:27<03:26,  1.15it/s]Loading train:  11%|█         | 28/266 [00:28<03:26,  1.16it/s]Loading train:  11%|█         | 29/266 [00:29<03:25,  1.16it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:27,  1.14it/s]Loading train:  12%|█▏        | 31/266 [00:31<03:19,  1.18it/s]Loading train:  12%|█▏        | 32/266 [00:31<03:15,  1.20it/s]Loading train:  12%|█▏        | 33/266 [00:32<03:15,  1.19it/s]Loading train:  13%|█▎        | 34/266 [00:33<03:13,  1.20it/s]Loading train:  13%|█▎        | 35/266 [00:34<03:11,  1.20it/s]Loading train:  14%|█▎        | 36/266 [00:35<03:14,  1.18it/s]Loading train:  14%|█▍        | 37/266 [00:36<03:20,  1.14it/s]Loading train:  14%|█▍        | 38/266 [00:36<03:15,  1.17it/s]Loading train:  15%|█▍        | 39/266 [00:37<03:16,  1.15it/s]Loading train:  15%|█▌        | 40/266 [00:38<03:10,  1.19it/s]Loading train:  15%|█▌        | 41/266 [00:39<03:06,  1.21it/s]Loading train:  16%|█▌        | 42/266 [00:40<03:06,  1.20it/s]Loading train:  16%|█▌        | 43/266 [00:41<03:03,  1.21it/s]Loading train:  17%|█▋        | 44/266 [00:41<02:56,  1.26it/s]Loading train:  17%|█▋        | 45/266 [00:42<02:50,  1.30it/s]Loading train:  17%|█▋        | 46/266 [00:43<02:44,  1.34it/s]Loading train:  18%|█▊        | 47/266 [00:43<02:41,  1.35it/s]Loading train:  18%|█▊        | 48/266 [00:44<02:48,  1.30it/s]Loading train:  18%|█▊        | 49/266 [00:45<02:56,  1.23it/s]Loading train:  19%|█▉        | 50/266 [00:46<02:50,  1.27it/s]Loading train:  19%|█▉        | 51/266 [00:47<02:46,  1.29it/s]Loading train:  20%|█▉        | 52/266 [00:47<02:40,  1.33it/s]Loading train:  20%|█▉        | 53/266 [00:48<02:38,  1.34it/s]Loading train:  20%|██        | 54/266 [00:49<02:37,  1.34it/s]Loading train:  21%|██        | 55/266 [00:50<02:38,  1.33it/s]Loading train:  21%|██        | 56/266 [00:50<02:35,  1.35it/s]Loading train:  21%|██▏       | 57/266 [00:51<02:34,  1.35it/s]Loading train:  22%|██▏       | 58/266 [00:52<02:30,  1.38it/s]Loading train:  22%|██▏       | 59/266 [00:53<02:34,  1.34it/s]Loading train:  23%|██▎       | 60/266 [00:53<02:37,  1.31it/s]Loading train:  23%|██▎       | 61/266 [00:54<02:36,  1.31it/s]Loading train:  23%|██▎       | 62/266 [00:55<02:33,  1.33it/s]Loading train:  24%|██▎       | 63/266 [00:56<02:30,  1.35it/s]Loading train:  24%|██▍       | 64/266 [00:56<02:24,  1.39it/s]Loading train:  24%|██▍       | 65/266 [00:57<02:20,  1.43it/s]Loading train:  25%|██▍       | 66/266 [00:58<02:18,  1.44it/s]Loading train:  25%|██▌       | 67/266 [00:58<02:20,  1.42it/s]Loading train:  26%|██▌       | 68/266 [00:59<02:20,  1.41it/s]Loading train:  26%|██▌       | 69/266 [01:00<02:21,  1.39it/s]Loading train:  26%|██▋       | 70/266 [01:00<02:18,  1.42it/s]Loading train:  27%|██▋       | 71/266 [01:01<02:23,  1.36it/s]Loading train:  27%|██▋       | 72/266 [01:02<02:20,  1.38it/s]Loading train:  27%|██▋       | 73/266 [01:03<02:17,  1.40it/s]Loading train:  28%|██▊       | 74/266 [01:03<02:17,  1.40it/s]Loading train:  28%|██▊       | 75/266 [01:04<02:19,  1.37it/s]Loading train:  29%|██▊       | 76/266 [01:05<02:15,  1.40it/s]Loading train:  29%|██▉       | 77/266 [01:05<02:13,  1.41it/s]Loading train:  29%|██▉       | 78/266 [01:07<02:33,  1.22it/s]Loading train:  30%|██▉       | 79/266 [01:07<02:35,  1.20it/s]Loading train:  30%|███       | 80/266 [01:08<02:34,  1.20it/s]Loading train:  30%|███       | 81/266 [01:09<02:35,  1.19it/s]Loading train:  31%|███       | 82/266 [01:10<02:35,  1.19it/s]Loading train:  31%|███       | 83/266 [01:11<02:34,  1.18it/s]Loading train:  32%|███▏      | 84/266 [01:12<02:31,  1.20it/s]Loading train:  32%|███▏      | 85/266 [01:12<02:34,  1.17it/s]Loading train:  32%|███▏      | 86/266 [01:13<02:36,  1.15it/s]Loading train:  33%|███▎      | 87/266 [01:14<02:31,  1.18it/s]Loading train:  33%|███▎      | 88/266 [01:15<02:34,  1.15it/s]Loading train:  33%|███▎      | 89/266 [01:16<02:32,  1.16it/s]Loading train:  34%|███▍      | 90/266 [01:17<02:33,  1.15it/s]Loading train:  34%|███▍      | 91/266 [01:18<02:30,  1.16it/s]Loading train:  35%|███▍      | 92/266 [01:19<02:33,  1.13it/s]Loading train:  35%|███▍      | 93/266 [01:19<02:28,  1.16it/s]Loading train:  35%|███▌      | 94/266 [01:20<02:28,  1.16it/s]Loading train:  36%|███▌      | 95/266 [01:21<02:26,  1.16it/s]Loading train:  36%|███▌      | 96/266 [01:23<02:54,  1.02s/it]Loading train:  36%|███▋      | 97/266 [01:24<03:21,  1.19s/it]Loading train:  37%|███▋      | 98/266 [01:25<03:24,  1.22s/it]Loading train:  37%|███▋      | 99/266 [01:26<03:14,  1.16s/it]Loading train:  38%|███▊      | 100/266 [01:28<03:11,  1.15s/it]Loading train:  38%|███▊      | 101/266 [01:28<02:51,  1.04s/it]Loading train:  38%|███▊      | 102/266 [01:29<02:36,  1.05it/s]Loading train:  39%|███▊      | 103/266 [01:30<02:26,  1.11it/s]Loading train:  39%|███▉      | 104/266 [01:31<02:20,  1.15it/s]Loading train:  39%|███▉      | 105/266 [01:31<02:14,  1.20it/s]Loading train:  40%|███▉      | 106/266 [01:32<02:10,  1.22it/s]Loading train:  40%|████      | 107/266 [01:33<02:05,  1.27it/s]Loading train:  41%|████      | 108/266 [01:34<02:02,  1.29it/s]Loading train:  41%|████      | 109/266 [01:34<02:02,  1.28it/s]Loading train:  41%|████▏     | 110/266 [01:35<01:57,  1.33it/s]Loading train:  42%|████▏     | 111/266 [01:36<01:54,  1.36it/s]Loading train:  42%|████▏     | 112/266 [01:37<01:54,  1.35it/s]Loading train:  42%|████▏     | 113/266 [01:37<01:58,  1.29it/s]Loading train:  43%|████▎     | 114/266 [01:38<01:59,  1.27it/s]Loading train:  43%|████▎     | 115/266 [01:39<01:56,  1.29it/s]Loading train:  44%|████▎     | 116/266 [01:40<01:55,  1.30it/s]Loading train:  44%|████▍     | 117/266 [01:40<01:52,  1.32it/s]Loading train:  44%|████▍     | 118/266 [01:41<01:49,  1.35it/s]Loading train:  45%|████▍     | 119/266 [01:42<02:00,  1.22it/s]Loading train:  45%|████▌     | 120/266 [01:43<02:06,  1.16it/s]Loading train:  45%|████▌     | 121/266 [01:44<02:03,  1.17it/s]Loading train:  46%|████▌     | 122/266 [01:45<02:02,  1.18it/s]Loading train:  46%|████▌     | 123/266 [01:46<02:04,  1.15it/s]Loading train:  47%|████▋     | 124/266 [01:47<02:05,  1.14it/s]Loading train:  47%|████▋     | 125/266 [01:48<02:04,  1.13it/s]Loading train:  47%|████▋     | 126/266 [01:49<02:07,  1.10it/s]Loading train:  48%|████▊     | 127/266 [01:49<02:04,  1.12it/s]Loading train:  48%|████▊     | 128/266 [01:50<02:00,  1.15it/s]Loading train:  48%|████▊     | 129/266 [01:51<02:03,  1.11it/s]Loading train:  49%|████▉     | 130/266 [01:52<02:00,  1.13it/s]Loading train:  49%|████▉     | 131/266 [01:53<01:56,  1.16it/s]Loading train:  50%|████▉     | 132/266 [01:54<02:02,  1.10it/s]Loading train:  50%|█████     | 133/266 [01:55<01:55,  1.15it/s]Loading train:  50%|█████     | 134/266 [01:55<01:51,  1.19it/s]Loading train:  51%|█████     | 135/266 [01:56<01:55,  1.14it/s]Loading train:  51%|█████     | 136/266 [01:57<01:53,  1.14it/s]Loading train:  52%|█████▏    | 137/266 [01:58<01:51,  1.15it/s]Loading train:  52%|█████▏    | 138/266 [01:59<01:56,  1.10it/s]Loading train:  52%|█████▏    | 139/266 [02:00<01:51,  1.14it/s]Loading train:  53%|█████▎    | 140/266 [02:01<01:47,  1.17it/s]Loading train:  53%|█████▎    | 141/266 [02:02<01:49,  1.15it/s]Loading train:  53%|█████▎    | 142/266 [02:02<01:46,  1.17it/s]Loading train:  54%|█████▍    | 143/266 [02:03<01:44,  1.18it/s]Loading train:  54%|█████▍    | 144/266 [02:04<01:48,  1.13it/s]Loading train:  55%|█████▍    | 145/266 [02:05<01:47,  1.12it/s]Loading train:  55%|█████▍    | 146/266 [02:06<01:44,  1.14it/s]Loading train:  55%|█████▌    | 147/266 [02:07<01:48,  1.09it/s]Loading train:  56%|█████▌    | 148/266 [02:08<01:44,  1.13it/s]Loading train:  56%|█████▌    | 149/266 [02:09<01:41,  1.15it/s]Loading train:  56%|█████▋    | 150/266 [02:10<01:42,  1.14it/s]Loading train:  57%|█████▋    | 151/266 [02:10<01:43,  1.11it/s]Loading train:  57%|█████▋    | 152/266 [02:11<01:41,  1.12it/s]Loading train:  58%|█████▊    | 153/266 [02:12<01:39,  1.14it/s]Loading train:  58%|█████▊    | 154/266 [02:13<01:38,  1.14it/s]Loading train:  58%|█████▊    | 155/266 [02:14<01:32,  1.20it/s]Loading train:  59%|█████▊    | 156/266 [02:14<01:26,  1.28it/s]Loading train:  59%|█████▉    | 157/266 [02:15<01:24,  1.29it/s]Loading train:  59%|█████▉    | 158/266 [02:16<01:21,  1.32it/s]Loading train:  60%|█████▉    | 159/266 [02:17<01:16,  1.40it/s]Loading train:  60%|██████    | 160/266 [02:17<01:13,  1.44it/s]Loading train:  61%|██████    | 161/266 [02:18<01:09,  1.51it/s]Loading train:  61%|██████    | 162/266 [02:18<01:07,  1.53it/s]Loading train:  61%|██████▏   | 163/266 [02:19<01:09,  1.48it/s]Loading train:  62%|██████▏   | 164/266 [02:20<01:06,  1.54it/s]Loading train:  62%|██████▏   | 165/266 [02:20<01:08,  1.48it/s]Loading train:  62%|██████▏   | 166/266 [02:21<01:07,  1.49it/s]Loading train:  63%|██████▎   | 167/266 [02:22<01:08,  1.46it/s]Loading train:  63%|██████▎   | 168/266 [02:23<01:06,  1.47it/s]Loading train:  64%|██████▎   | 169/266 [02:23<01:05,  1.48it/s]Loading train:  64%|██████▍   | 170/266 [02:24<01:04,  1.49it/s]Loading train:  64%|██████▍   | 171/266 [02:25<01:05,  1.44it/s]Loading train:  65%|██████▍   | 172/266 [02:25<01:03,  1.48it/s]Loading train:  65%|██████▌   | 173/266 [02:26<01:05,  1.43it/s]Loading train:  65%|██████▌   | 174/266 [02:27<01:05,  1.41it/s]Loading train:  66%|██████▌   | 175/266 [02:27<01:04,  1.41it/s]Loading train:  66%|██████▌   | 176/266 [02:28<01:03,  1.41it/s]Loading train:  67%|██████▋   | 177/266 [02:29<01:04,  1.37it/s]Loading train:  67%|██████▋   | 178/266 [02:30<01:02,  1.41it/s]Loading train:  67%|██████▋   | 179/266 [02:30<00:59,  1.46it/s]Loading train:  68%|██████▊   | 180/266 [02:31<01:00,  1.42it/s]Loading train:  68%|██████▊   | 181/266 [02:32<01:01,  1.39it/s]Loading train:  68%|██████▊   | 182/266 [02:32<01:00,  1.38it/s]Loading train:  69%|██████▉   | 183/266 [02:33<00:58,  1.42it/s]Loading train:  69%|██████▉   | 184/266 [02:34<00:59,  1.37it/s]Loading train:  70%|██████▉   | 185/266 [02:35<00:59,  1.36it/s]Loading train:  70%|██████▉   | 186/266 [02:35<00:57,  1.39it/s]Loading train:  70%|███████   | 187/266 [02:36<00:55,  1.43it/s]Loading train:  71%|███████   | 188/266 [02:37<00:53,  1.45it/s]Loading train:  71%|███████   | 189/266 [02:37<00:53,  1.43it/s]Loading train:  71%|███████▏  | 190/266 [02:38<00:53,  1.42it/s]Loading train:  72%|███████▏  | 191/266 [02:39<01:06,  1.13it/s]Loading train:  72%|███████▏  | 192/266 [02:41<01:10,  1.04it/s]Loading train:  73%|███████▎  | 193/266 [02:42<01:13,  1.01s/it]Loading train:  73%|███████▎  | 194/266 [02:43<01:22,  1.15s/it]Loading train:  73%|███████▎  | 195/266 [02:44<01:14,  1.05s/it]Loading train:  74%|███████▎  | 196/266 [02:45<01:09,  1.01it/s]Loading train:  74%|███████▍  | 197/266 [02:46<01:06,  1.03it/s]Loading train:  74%|███████▍  | 198/266 [02:46<01:00,  1.12it/s]Loading train:  75%|███████▍  | 199/266 [02:47<00:58,  1.15it/s]Loading train:  75%|███████▌  | 200/266 [02:48<00:54,  1.21it/s]Loading train:  76%|███████▌  | 201/266 [02:49<00:54,  1.19it/s]Loading train:  76%|███████▌  | 202/266 [02:50<00:52,  1.22it/s]Loading train:  76%|███████▋  | 203/266 [02:50<00:49,  1.26it/s]Loading train:  77%|███████▋  | 204/266 [02:51<00:48,  1.27it/s]Loading train:  77%|███████▋  | 205/266 [02:52<00:47,  1.28it/s]Loading train:  77%|███████▋  | 206/266 [02:53<00:48,  1.25it/s]Loading train:  78%|███████▊  | 207/266 [02:54<00:47,  1.24it/s]Loading train:  78%|███████▊  | 208/266 [02:54<00:48,  1.20it/s]Loading train:  79%|███████▊  | 209/266 [02:55<00:46,  1.24it/s]Loading train:  79%|███████▉  | 210/266 [02:56<00:43,  1.28it/s]Loading train:  79%|███████▉  | 211/266 [02:57<00:43,  1.26it/s]Loading train:  80%|███████▉  | 212/266 [02:57<00:41,  1.31it/s]Loading train:  80%|████████  | 213/266 [02:58<00:41,  1.29it/s]Loading train:  80%|████████  | 214/266 [02:59<00:41,  1.25it/s]Loading train:  81%|████████  | 215/266 [03:00<00:39,  1.30it/s]Loading train:  81%|████████  | 216/266 [03:01<00:38,  1.31it/s]Loading train:  82%|████████▏ | 217/266 [03:01<00:36,  1.33it/s]Loading train:  82%|████████▏ | 218/266 [03:02<00:35,  1.37it/s]Loading train:  82%|████████▏ | 219/266 [03:03<00:34,  1.37it/s]Loading train:  83%|████████▎ | 220/266 [03:03<00:34,  1.35it/s]Loading train:  83%|████████▎ | 221/266 [03:04<00:32,  1.37it/s]Loading train:  83%|████████▎ | 222/266 [03:05<00:31,  1.41it/s]Loading train:  84%|████████▍ | 223/266 [03:06<00:32,  1.32it/s]Loading train:  84%|████████▍ | 224/266 [03:06<00:31,  1.34it/s]Loading train:  85%|████████▍ | 225/266 [03:07<00:30,  1.33it/s]Loading train:  85%|████████▍ | 226/266 [03:08<00:29,  1.35it/s]Loading train:  85%|████████▌ | 227/266 [03:09<00:28,  1.38it/s]Loading train:  86%|████████▌ | 228/266 [03:09<00:27,  1.40it/s]Loading train:  86%|████████▌ | 229/266 [03:10<00:26,  1.38it/s]Loading train:  86%|████████▋ | 230/266 [03:11<00:25,  1.39it/s]Loading train:  87%|████████▋ | 231/266 [03:11<00:25,  1.38it/s]Loading train:  87%|████████▋ | 232/266 [03:12<00:25,  1.34it/s]Loading train:  88%|████████▊ | 233/266 [03:13<00:24,  1.36it/s]Loading train:  88%|████████▊ | 234/266 [03:14<00:22,  1.40it/s]Loading train:  88%|████████▊ | 235/266 [03:14<00:23,  1.33it/s]Loading train:  89%|████████▊ | 236/266 [03:15<00:22,  1.33it/s]Loading train:  89%|████████▉ | 237/266 [03:16<00:21,  1.34it/s]Loading train:  89%|████████▉ | 238/266 [03:17<00:21,  1.29it/s]Loading train:  90%|████████▉ | 239/266 [03:18<00:20,  1.30it/s]Loading train:  90%|█████████ | 240/266 [03:18<00:18,  1.37it/s]Loading train:  91%|█████████ | 241/266 [03:19<00:18,  1.35it/s]Loading train:  91%|█████████ | 242/266 [03:20<00:17,  1.34it/s]Loading train:  91%|█████████▏| 243/266 [03:20<00:16,  1.37it/s]Loading train:  92%|█████████▏| 244/266 [03:21<00:16,  1.35it/s]Loading train:  92%|█████████▏| 245/266 [03:22<00:14,  1.40it/s]Loading train:  92%|█████████▏| 246/266 [03:22<00:14,  1.43it/s]Loading train:  93%|█████████▎| 247/266 [03:23<00:13,  1.42it/s]Loading train:  93%|█████████▎| 248/266 [03:24<00:12,  1.43it/s]Loading train:  94%|█████████▎| 249/266 [03:25<00:12,  1.34it/s]Loading train:  94%|█████████▍| 250/266 [03:26<00:13,  1.21it/s]Loading train:  94%|█████████▍| 251/266 [03:27<00:12,  1.19it/s]Loading train:  95%|█████████▍| 252/266 [03:27<00:11,  1.19it/s]Loading train:  95%|█████████▌| 253/266 [03:28<00:10,  1.21it/s]Loading train:  95%|█████████▌| 254/266 [03:29<00:09,  1.23it/s]Loading train:  96%|█████████▌| 255/266 [03:30<00:09,  1.20it/s]Loading train:  96%|█████████▌| 256/266 [03:31<00:08,  1.22it/s]Loading train:  97%|█████████▋| 257/266 [03:32<00:07,  1.21it/s]Loading train:  97%|█████████▋| 258/266 [03:32<00:06,  1.16it/s]Loading train:  97%|█████████▋| 259/266 [03:33<00:05,  1.20it/s]Loading train:  98%|█████████▊| 260/266 [03:34<00:05,  1.16it/s]Loading train:  98%|█████████▊| 261/266 [03:35<00:04,  1.19it/s]Loading train:  98%|█████████▊| 262/266 [03:36<00:03,  1.23it/s]Loading train:  99%|█████████▉| 263/266 [03:37<00:02,  1.18it/s]Loading train:  99%|█████████▉| 264/266 [03:37<00:01,  1.19it/s]Loading train: 100%|█████████▉| 265/266 [03:38<00:00,  1.19it/s]Loading train: 100%|██████████| 266/266 [03:39<00:00,  1.19it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:02, 109.30it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:01, 123.58it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:01, 129.19it/s]concatenating: train:  23%|██▎       | 60/266 [00:00<00:01, 132.34it/s]concatenating: train:  28%|██▊       | 74/266 [00:00<00:01, 133.81it/s]concatenating: train:  33%|███▎      | 87/266 [00:00<00:01, 132.59it/s]concatenating: train:  38%|███▊      | 100/266 [00:00<00:01, 130.59it/s]concatenating: train:  44%|████▎     | 116/266 [00:00<00:01, 137.65it/s]concatenating: train:  50%|█████     | 133/266 [00:00<00:00, 144.49it/s]concatenating: train:  56%|█████▋    | 150/266 [00:01<00:00, 150.82it/s]concatenating: train:  63%|██████▎   | 168/266 [00:01<00:00, 158.25it/s]concatenating: train:  70%|██████▉   | 185/266 [00:01<00:00, 161.21it/s]concatenating: train:  76%|███████▌  | 202/266 [00:01<00:00, 131.55it/s]concatenating: train:  85%|████████▍ | 225/266 [00:01<00:00, 149.29it/s]concatenating: train:  95%|█████████▌| 253/266 [00:01<00:00, 173.34it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 160.57it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.19s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.17s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.17s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.14s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 120.59it/s]2019-08-17 21:21:21.798266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 21:21:21.798364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 21:21:21.798380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 21:21:21.798389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 21:21:21.798804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:88:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.31it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.38it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.86it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.48it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.77it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.60it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.54it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.49it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.18it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.47it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.28it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.82it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.04it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.14it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.92it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.98it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.95it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.81it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.15it/s]
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 382,733
Non-trainable params: 506,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34129399e-02 3.28660463e-02 7.68527290e-02 9.54933802e-03
 2.76379587e-02 7.23085008e-03 8.44970561e-02 1.14228929e-01
 8.96922559e-02 1.36273748e-02 2.90799935e-01 1.89334859e-01
 2.69727513e-04]
Train on 10177 samples, validate on 186 samples
Epoch 1/300
 - 19s - loss: 1.4590 - acc: 0.7949 - mDice: 0.3237 - val_loss: 0.6744 - val_acc: 0.9267 - val_mDice: 0.5064

Epoch 00001: val_mDice improved from -inf to 0.50636, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.5665 - acc: 0.9162 - mDice: 0.5559 - val_loss: 0.6025 - val_acc: 0.9319 - val_mDice: 0.5468

Epoch 00002: val_mDice improved from 0.50636 to 0.54678, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.4577 - acc: 0.9273 - mDice: 0.6178 - val_loss: 0.5184 - val_acc: 0.9367 - val_mDice: 0.5897

Epoch 00003: val_mDice improved from 0.54678 to 0.58972, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4189 - acc: 0.9321 - mDice: 0.6469 - val_loss: 0.5186 - val_acc: 0.9390 - val_mDice: 0.5894

Epoch 00004: val_mDice did not improve from 0.58972
Epoch 5/300
 - 15s - loss: 0.3743 - acc: 0.9356 - mDice: 0.6735 - val_loss: 0.5025 - val_acc: 0.9426 - val_mDice: 0.5973

Epoch 00005: val_mDice improved from 0.58972 to 0.59735, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.3474 - acc: 0.9382 - mDice: 0.6923 - val_loss: 0.4894 - val_acc: 0.9423 - val_mDice: 0.6057

Epoch 00006: val_mDice improved from 0.59735 to 0.60568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 15s - loss: 0.3290 - acc: 0.9402 - mDice: 0.7058 - val_loss: 0.4981 - val_acc: 0.9401 - val_mDice: 0.6007

Epoch 00007: val_mDice did not improve from 0.60568
Epoch 8/300
 - 15s - loss: 0.3108 - acc: 0.9420 - mDice: 0.7191 - val_loss: 0.4852 - val_acc: 0.9417 - val_mDice: 0.6064

Epoch 00008: val_mDice improved from 0.60568 to 0.60640, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 15s - loss: 0.3038 - acc: 0.9429 - mDice: 0.7248 - val_loss: 0.5039 - val_acc: 0.9415 - val_mDice: 0.5971

Epoch 00009: val_mDice did not improve from 0.60640
Epoch 10/300
 - 14s - loss: 0.3044 - acc: 0.9432 - mDice: 0.7262 - val_loss: 0.4897 - val_acc: 0.9442 - val_mDice: 0.6086

Epoch 00010: val_mDice improved from 0.60640 to 0.60856, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.2853 - acc: 0.9447 - mDice: 0.7384 - val_loss: 0.4887 - val_acc: 0.9420 - val_mDice: 0.6057

Epoch 00011: val_mDice did not improve from 0.60856
Epoch 12/300
 - 15s - loss: 0.2725 - acc: 0.9461 - mDice: 0.7481 - val_loss: 0.4862 - val_acc: 0.9446 - val_mDice: 0.6071

Epoch 00012: val_mDice did not improve from 0.60856
Epoch 13/300
 - 14s - loss: 0.2652 - acc: 0.9468 - mDice: 0.7540 - val_loss: 0.4750 - val_acc: 0.9449 - val_mDice: 0.6154

Epoch 00013: val_mDice improved from 0.60856 to 0.61541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute5_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 14s - loss: 0.2637 - acc: 0.9476 - mDice: 0.7597 - val_loss: 0.4771 - val_acc: 0.9430 - val_mDice: 0.6129

Epoch 00014: val_mDice did not improve from 0.61541
Epoch 15/300
 - 14s - loss: 0.2537 - acc: 0.9481 - mDice: 0.7632 - val_loss: 0.4946 - val_acc: 0.9428 - val_mDice: 0.6041

Epoch 00015: val_mDice did not improve from 0.61541
Epoch 16/300
 - 14s - loss: 0.2460 - acc: 0.9489 - mDice: 0.7694 - val_loss: 0.4874 - val_acc: 0.9449 - val_mDice: 0.6090

Epoch 00016: val_mDice did not improve from 0.61541
Epoch 17/300
 - 14s - loss: 0.2441 - acc: 0.9494 - mDice: 0.7734 - val_loss: 0.5001 - val_acc: 0.9434 - val_mDice: 0.6015

Epoch 00017: val_mDice did not improve from 0.61541
Epoch 18/300
 - 14s - loss: 0.2493 - acc: 0.9493 - mDice: 0.7678 - val_loss: 0.4838 - val_acc: 0.9437 - val_mDice: 0.6091

Epoch 00018: val_mDice did not improve from 0.61541
Epoch 19/300
 - 14s - loss: 0.2366 - acc: 0.9501 - mDice: 0.7771 - val_loss: 0.4889 - val_acc: 0.9447 - val_mDice: 0.6062

Epoch 00019: val_mDice did not improve from 0.61541
Epoch 20/300
 - 14s - loss: 0.2343 - acc: 0.9507 - mDice: 0.7815 - val_loss: 0.5081 - val_acc: 0.9437 - val_mDice: 0.5958

Epoch 00020: val_mDice did not improve from 0.61541
Epoch 21/300
 - 14s - loss: 0.2516 - acc: 0.9487 - mDice: 0.7666 - val_loss: 0.5003 - val_acc: 0.9456 - val_mDice: 0.6007

Epoch 00021: val_mDice did not improve from 0.61541
Epoch 22/300
 - 14s - loss: 0.2427 - acc: 0.9500 - mDice: 0.7762 - val_loss: 0.6683 - val_acc: 0.9447 - val_mDice: 0.5472

Epoch 00022: val_mDice did not improve from 0.61541
Epoch 23/300
 - 14s - loss: 0.2466 - acc: 0.9495 - mDice: 0.7724 - val_loss: 0.4881 - val_acc: 0.9437 - val_mDice: 0.6077

Epoch 00023: val_mDice did not improve from 0.61541
Epoch 24/300
 - 14s - loss: 0.2273 - acc: 0.9509 - mDice: 0.7846 - val_loss: 0.4818 - val_acc: 0.9436 - val_mDice: 0.6088

Epoch 00024: val_mDice did not improve from 0.61541
Epoch 25/300
 - 14s - loss: 0.2222 - acc: 0.9515 - mDice: 0.7889 - val_loss: 0.4821 - val_acc: 0.9458 - val_mDice: 0.6107

Epoch 00025: val_mDice did not improve from 0.61541
Epoch 26/300
 - 14s - loss: 0.2181 - acc: 0.9520 - mDice: 0.7922 - val_loss: 0.4809 - val_acc: 0.9453 - val_mDice: 0.6134

Epoch 00026: val_mDice did not improve from 0.61541
Epoch 27/300
 - 14s - loss: 0.2163 - acc: 0.9523 - mDice: 0.7938 - val_loss: 0.4819 - val_acc: 0.9445 - val_mDice: 0.6117

Epoch 00027: val_mDice did not improve from 0.61541
Epoch 28/300
 - 14s - loss: 0.2153 - acc: 0.9523 - mDice: 0.7946 - val_loss: 0.4898 - val_acc: 0.9438 - val_mDice: 0.6077

Epoch 00028: val_mDice did not improve from 0.61541
Epoch 29/300
 - 14s - loss: 0.2115 - acc: 0.9527 - mDice: 0.7977 - val_loss: 0.4848 - val_acc: 0.9438 - val_mDice: 0.6090

Epoch 00029: val_mDice did not improve from 0.61541
Epoch 30/300
 - 14s - loss: 0.2092 - acc: 0.9530 - mDice: 0.7998 - val_loss: 0.4807 - val_acc: 0.9458 - val_mDice: 0.6121

Epoch 00030: val_mDice did not improve from 0.61541
Epoch 31/300
 - 14s - loss: 0.2149 - acc: 0.9526 - mDice: 0.7953 - val_loss: 0.5025 - val_acc: 0.9440 - val_mDice: 0.6007

Epoch 00031: val_mDice did not improve from 0.61541
Epoch 32/300
 - 14s - loss: 0.2091 - acc: 0.9532 - mDice: 0.7998 - val_loss: 0.5001 - val_acc: 0.9430 - val_mDice: 0.6029

Epoch 00032: val_mDice did not improve from 0.61541
Epoch 33/300
 - 14s - loss: 0.2062 - acc: 0.9535 - mDice: 0.8024 - val_loss: 0.5054 - val_acc: 0.9449 - val_mDice: 0.6017

Epoch 00033: val_mDice did not improve from 0.61541
Epoch 34/300
 - 14s - loss: 0.2037 - acc: 0.9537 - mDice: 0.8044 - val_loss: 0.4948 - val_acc: 0.9436 - val_mDice: 0.6069

Epoch 00034: val_mDice did not improve from 0.61541
Epoch 35/300
 - 14s - loss: 0.2028 - acc: 0.9537 - mDice: 0.8053 - val_loss: 0.4821 - val_acc: 0.9432 - val_mDice: 0.6122

Epoch 00035: val_mDice did not improve from 0.61541
Epoch 36/300
 - 14s - loss: 0.1994 - acc: 0.9541 - mDice: 0.8082 - val_loss: 0.4965 - val_acc: 0.9450 - val_mDice: 0.6024

Epoch 00036: val_mDice did not improve from 0.61541
Epoch 37/300
 - 14s - loss: 0.1989 - acc: 0.9541 - mDice: 0.8085 - val_loss: 0.4980 - val_acc: 0.9443 - val_mDice: 0.6021

Epoch 00037: val_mDice did not improve from 0.61541
Epoch 38/300
 - 14s - loss: 0.1982 - acc: 0.9544 - mDice: 0.8092 - val_loss: 0.4962 - val_acc: 0.9456 - val_mDice: 0.6045

Epoch 00038: val_mDice did not improve from 0.61541
Epoch 39/300
 - 14s - loss: 0.1957 - acc: 0.9546 - mDice: 0.8113 - val_loss: 0.5047 - val_acc: 0.9438 - val_mDice: 0.5981

Epoch 00039: val_mDice did not improve from 0.61541
Epoch 40/300
 - 14s - loss: 0.1946 - acc: 0.9548 - mDice: 0.8123 - val_loss: 0.4946 - val_acc: 0.9448 - val_mDice: 0.6049

Epoch 00040: val_mDice did not improve from 0.61541
Epoch 41/300
 - 14s - loss: 0.1978 - acc: 0.9545 - mDice: 0.8098 - val_loss: 0.4948 - val_acc: 0.9452 - val_mDice: 0.6045

Epoch 00041: val_mDice did not improve from 0.61541
Epoch 42/300
 - 14s - loss: 0.1937 - acc: 0.9549 - mDice: 0.8130 - val_loss: 0.4905 - val_acc: 0.9437 - val_mDice: 0.6080

Epoch 00042: val_mDice did not improve from 0.61541
Epoch 43/300
 - 14s - loss: 0.1921 - acc: 0.9550 - mDice: 0.8145 - val_loss: 0.4824 - val_acc: 0.9451 - val_mDice: 0.6113

Epoch 00043: val_mDice did not improve from 0.61541
Epoch 44/300
 - 15s - loss: 0.1905 - acc: 0.9553 - mDice: 0.8159 - val_loss: 0.4992 - val_acc: 0.9446 - val_mDice: 0.6024

Epoch 00044: val_mDice did not improve from 0.61541
Epoch 45/300
 - 14s - loss: 0.1887 - acc: 0.9554 - mDice: 0.8173 - val_loss: 0.5033 - val_acc: 0.9438 - val_mDice: 0.6017

Epoch 00045: val_mDice did not improve from 0.61541
Epoch 46/300
 - 14s - loss: 0.1882 - acc: 0.9555 - mDice: 0.8178 - val_loss: 0.4953 - val_acc: 0.9443 - val_mDice: 0.6062

Epoch 00046: val_mDice did not improve from 0.61541
Epoch 47/300
 - 14s - loss: 0.1881 - acc: 0.9555 - mDice: 0.8179 - val_loss: 0.5171 - val_acc: 0.9451 - val_mDice: 0.5935

Epoch 00047: val_mDice did not improve from 0.61541
Epoch 48/300
 - 14s - loss: 0.1864 - acc: 0.9557 - mDice: 0.8193 - val_loss: 0.5035 - val_acc: 0.9444 - val_mDice: 0.6037

Epoch 00048: val_mDice did not improve from 0.61541
Epoch 49/300
 - 14s - loss: 0.1855 - acc: 0.9558 - mDice: 0.8202 - val_loss: 0.5100 - val_acc: 0.9458 - val_mDice: 0.5983

Epoch 00049: val_mDice did not improve from 0.61541
Epoch 50/300
 - 14s - loss: 0.1834 - acc: 0.9560 - mDice: 0.8220 - val_loss: 0.4999 - val_acc: 0.9467 - val_mDice: 0.6042

Epoch 00050: val_mDice did not improve from 0.61541
Epoch 51/300
 - 14s - loss: 0.1832 - acc: 0.9561 - mDice: 0.8222 - val_loss: 0.4948 - val_acc: 0.9439 - val_mDice: 0.6045

Epoch 00051: val_mDice did not improve from 0.61541
Epoch 52/300
 - 15s - loss: 0.1820 - acc: 0.9562 - mDice: 0.8232 - val_loss: 0.5010 - val_acc: 0.9446 - val_mDice: 0.6025

Epoch 00052: val_mDice did not improve from 0.61541
Epoch 53/300
 - 14s - loss: 0.1863 - acc: 0.9562 - mDice: 0.8227 - val_loss: 0.4875 - val_acc: 0.9426 - val_mDice: 0.6081

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.80s/it]predicting test subjects:  40%|████      | 2/5 [00:04<00:07,  2.59s/it]predicting test subjects:  60%|██████    | 3/5 [00:06<00:04,  2.37s/it]predicting test subjects:  80%|████████  | 4/5 [00:08<00:02,  2.21s/it]predicting test subjects: 100%|██████████| 5/5 [00:10<00:00,  2.24s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:01,  2.72s/it]predicting train subjects:   1%|          | 2/266 [00:05<11:42,  2.66s/it]predicting train subjects:   1%|          | 3/266 [00:07<10:57,  2.50s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:04,  2.31s/it]predicting train subjects:   2%|▏         | 5/266 [00:11<10:18,  2.37s/it]predicting train subjects:   2%|▏         | 6/266 [00:14<10:41,  2.47s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<10:53,  2.52s/it]predicting train subjects:   3%|▎         | 8/266 [00:19<10:58,  2.55s/it]predicting train subjects:   3%|▎         | 9/266 [00:22<11:03,  2.58s/it]predicting train subjects:   4%|▍         | 10/266 [00:24<11:05,  2.60s/it]predicting train subjects:   4%|▍         | 11/266 [00:27<11:09,  2.62s/it]predicting train subjects:   5%|▍         | 12/266 [00:30<11:04,  2.62s/it]predicting train subjects:   5%|▍         | 13/266 [00:32<11:06,  2.63s/it]predicting train subjects:   5%|▌         | 14/266 [00:35<11:08,  2.65s/it]predicting train subjects:   6%|▌         | 15/266 [00:38<11:04,  2.65s/it]predicting train subjects:   6%|▌         | 16/266 [00:40<11:01,  2.64s/it]predicting train subjects:   6%|▋         | 17/266 [00:43<10:56,  2.63s/it]predicting train subjects:   7%|▋         | 18/266 [00:46<10:56,  2.65s/it]predicting train subjects:   7%|▋         | 19/266 [00:48<10:51,  2.64s/it]predicting train subjects:   8%|▊         | 20/266 [00:51<10:44,  2.62s/it]predicting train subjects:   8%|▊         | 21/266 [00:54<10:40,  2.61s/it]predicting train subjects:   8%|▊         | 22/266 [00:56<10:38,  2.62s/it]predicting train subjects:   9%|▊         | 23/266 [00:59<10:35,  2.62s/it]predicting train subjects:   9%|▉         | 24/266 [01:01<10:23,  2.58s/it]predicting train subjects:   9%|▉         | 25/266 [01:04<10:11,  2.54s/it]predicting train subjects:  10%|▉         | 26/266 [01:06<10:03,  2.51s/it]predicting train subjects:  10%|█         | 27/266 [01:09<09:58,  2.50s/it]predicting train subjects:  11%|█         | 28/266 [01:11<09:50,  2.48s/it]predicting train subjects:  11%|█         | 29/266 [01:13<09:44,  2.46s/it]predicting train subjects:  11%|█▏        | 30/266 [01:16<09:36,  2.44s/it]predicting train subjects:  12%|█▏        | 31/266 [01:18<09:31,  2.43s/it]predicting train subjects:  12%|█▏        | 32/266 [01:21<09:29,  2.43s/it]predicting train subjects:  12%|█▏        | 33/266 [01:23<09:23,  2.42s/it]predicting train subjects:  13%|█▎        | 34/266 [01:25<09:19,  2.41s/it]predicting train subjects:  13%|█▎        | 35/266 [01:28<09:19,  2.42s/it]predicting train subjects:  14%|█▎        | 36/266 [01:30<09:15,  2.42s/it]predicting train subjects:  14%|█▍        | 37/266 [01:33<09:13,  2.42s/it]predicting train subjects:  14%|█▍        | 38/266 [01:35<09:13,  2.43s/it]predicting train subjects:  15%|█▍        | 39/266 [01:38<09:11,  2.43s/it]predicting train subjects:  15%|█▌        | 40/266 [01:40<09:06,  2.42s/it]predicting train subjects:  15%|█▌        | 41/266 [01:42<09:06,  2.43s/it]predicting train subjects:  16%|█▌        | 42/266 [01:45<08:38,  2.32s/it]predicting train subjects:  16%|█▌        | 43/266 [01:47<08:21,  2.25s/it]predicting train subjects:  17%|█▋        | 44/266 [01:49<08:04,  2.18s/it]predicting train subjects:  17%|█▋        | 45/266 [01:51<07:50,  2.13s/it]predicting train subjects:  17%|█▋        | 46/266 [01:53<07:40,  2.09s/it]predicting train subjects:  18%|█▊        | 47/266 [01:55<07:34,  2.07s/it]predicting train subjects:  18%|█▊        | 48/266 [01:57<07:28,  2.06s/it]predicting train subjects:  18%|█▊        | 49/266 [01:59<07:23,  2.04s/it]predicting train subjects:  19%|█▉        | 50/266 [02:01<07:17,  2.03s/it]predicting train subjects:  19%|█▉        | 51/266 [02:03<07:15,  2.03s/it]predicting train subjects:  20%|█▉        | 52/266 [02:05<07:14,  2.03s/it]predicting train subjects:  20%|█▉        | 53/266 [02:07<07:08,  2.01s/it]predicting train subjects:  20%|██        | 54/266 [02:09<07:08,  2.02s/it]predicting train subjects:  21%|██        | 55/266 [02:11<07:06,  2.02s/it]predicting train subjects:  21%|██        | 56/266 [02:13<07:05,  2.03s/it]predicting train subjects:  21%|██▏       | 57/266 [02:15<07:02,  2.02s/it]predicting train subjects:  22%|██▏       | 58/266 [02:17<07:01,  2.02s/it]predicting train subjects:  22%|██▏       | 59/266 [02:19<06:56,  2.01s/it]predicting train subjects:  23%|██▎       | 60/266 [02:21<06:46,  1.97s/it]predicting train subjects:  23%|██▎       | 61/266 [02:23<06:42,  1.96s/it]predicting train subjects:  23%|██▎       | 62/266 [02:25<06:35,  1.94s/it]predicting train subjects:  24%|██▎       | 63/266 [02:27<06:33,  1.94s/it]predicting train subjects:  24%|██▍       | 64/266 [02:29<07:18,  2.17s/it]predicting train subjects:  24%|██▍       | 65/266 [02:31<06:59,  2.09s/it]predicting train subjects:  25%|██▍       | 66/266 [02:33<06:49,  2.05s/it]predicting train subjects:  25%|██▌       | 67/266 [02:35<06:40,  2.01s/it]predicting train subjects:  26%|██▌       | 68/266 [02:37<06:32,  1.98s/it]predicting train subjects:  26%|██▌       | 69/266 [02:39<06:26,  1.96s/it]predicting train subjects:  26%|██▋       | 70/266 [02:41<06:20,  1.94s/it]predicting train subjects:  27%|██▋       | 71/266 [02:43<06:14,  1.92s/it]predicting train subjects:  27%|██▋       | 72/266 [02:44<06:10,  1.91s/it]predicting train subjects:  27%|██▋       | 73/266 [02:46<06:04,  1.89s/it]predicting train subjects:  28%|██▊       | 74/266 [02:48<06:03,  1.90s/it]predicting train subjects:  28%|██▊       | 75/266 [02:50<06:00,  1.89s/it]predicting train subjects:  29%|██▊       | 76/266 [02:52<05:59,  1.89s/it]predicting train subjects:  29%|██▉       | 77/266 [02:54<05:54,  1.88s/it]predicting train subjects:  29%|██▉       | 78/266 [02:56<06:26,  2.05s/it]predicting train subjects:  30%|██▉       | 79/266 [02:59<06:52,  2.20s/it]predicting train subjects:  30%|███       | 80/266 [03:01<07:09,  2.31s/it]predicting train subjects:  30%|███       | 81/266 [03:04<07:16,  2.36s/it]predicting train subjects:  31%|███       | 82/266 [03:06<07:18,  2.38s/it]predicting train subjects:  31%|███       | 83/266 [03:09<07:23,  2.43s/it]predicting train subjects:  32%|███▏      | 84/266 [03:11<07:27,  2.46s/it]predicting train subjects:  32%|███▏      | 85/266 [03:14<07:25,  2.46s/it]predicting train subjects:  32%|███▏      | 86/266 [03:16<07:21,  2.45s/it]predicting train subjects:  33%|███▎      | 87/266 [03:19<07:19,  2.45s/it]predicting train subjects:  33%|███▎      | 88/266 [03:21<07:17,  2.46s/it]predicting train subjects:  33%|███▎      | 89/266 [03:24<07:14,  2.46s/it]predicting train subjects:  34%|███▍      | 90/266 [03:26<07:14,  2.47s/it]predicting train subjects:  34%|███▍      | 91/266 [03:29<07:12,  2.47s/it]predicting train subjects:  35%|███▍      | 92/266 [03:31<07:10,  2.47s/it]predicting train subjects:  35%|███▍      | 93/266 [03:34<07:14,  2.51s/it]predicting train subjects:  35%|███▌      | 94/266 [03:36<07:09,  2.50s/it]predicting train subjects:  36%|███▌      | 95/266 [03:39<07:05,  2.49s/it]predicting train subjects:  36%|███▌      | 96/266 [03:41<06:46,  2.39s/it]predicting train subjects:  36%|███▋      | 97/266 [03:43<06:51,  2.43s/it]predicting train subjects:  37%|███▋      | 98/266 [03:46<06:48,  2.43s/it]predicting train subjects:  37%|███▋      | 99/266 [03:48<06:15,  2.25s/it]predicting train subjects:  38%|███▊      | 100/266 [03:50<06:00,  2.17s/it]predicting train subjects:  38%|███▊      | 101/266 [03:52<05:57,  2.17s/it]predicting train subjects:  38%|███▊      | 102/266 [03:54<05:56,  2.18s/it]predicting train subjects:  39%|███▊      | 103/266 [03:56<05:54,  2.18s/it]predicting train subjects:  39%|███▉      | 104/266 [03:58<05:51,  2.17s/it]predicting train subjects:  39%|███▉      | 105/266 [04:00<05:45,  2.15s/it]predicting train subjects:  40%|███▉      | 106/266 [04:02<05:39,  2.12s/it]predicting train subjects:  40%|████      | 107/266 [04:04<05:33,  2.10s/it]predicting train subjects:  41%|████      | 108/266 [04:07<05:32,  2.10s/it]predicting train subjects:  41%|████      | 109/266 [04:09<05:28,  2.09s/it]predicting train subjects:  41%|████▏     | 110/266 [04:11<05:27,  2.10s/it]predicting train subjects:  42%|████▏     | 111/266 [04:13<05:26,  2.11s/it]predicting train subjects:  42%|████▏     | 112/266 [04:15<05:25,  2.11s/it]predicting train subjects:  42%|████▏     | 113/266 [04:17<05:23,  2.11s/it]predicting train subjects:  43%|████▎     | 114/266 [04:19<05:20,  2.11s/it]predicting train subjects:  43%|████▎     | 115/266 [04:21<05:18,  2.11s/it]predicting train subjects:  44%|████▎     | 116/266 [04:23<05:14,  2.09s/it]predicting train subjects:  44%|████▍     | 117/266 [04:25<05:11,  2.09s/it]predicting train subjects:  44%|████▍     | 118/266 [04:28<05:07,  2.08s/it]predicting train subjects:  45%|████▍     | 119/266 [04:30<05:19,  2.17s/it]predicting train subjects:  45%|████▌     | 120/266 [04:32<05:27,  2.24s/it]predicting train subjects:  45%|████▌     | 121/266 [04:35<05:34,  2.31s/it]predicting train subjects:  46%|████▌     | 122/266 [04:37<05:37,  2.35s/it]predicting train subjects:  46%|████▌     | 123/266 [04:40<05:37,  2.36s/it]predicting train subjects:  47%|████▋     | 124/266 [04:42<05:36,  2.37s/it]predicting train subjects:  47%|████▋     | 125/266 [04:44<05:35,  2.38s/it]predicting train subjects:  47%|████▋     | 126/266 [04:47<05:36,  2.40s/it]predicting train subjects:  48%|████▊     | 127/266 [04:49<05:38,  2.43s/it]predicting train subjects:  48%|████▊     | 128/266 [04:52<05:38,  2.45s/it]predicting train subjects:  48%|████▊     | 129/266 [04:54<05:34,  2.44s/it]predicting train subjects:  49%|████▉     | 130/266 [04:57<05:36,  2.48s/it]predicting train subjects:  49%|████▉     | 131/266 [04:59<05:35,  2.48s/it]predicting train subjects:  50%|████▉     | 132/266 [05:02<05:30,  2.46s/it]predicting train subjects:  50%|█████     | 133/266 [05:04<05:27,  2.46s/it]predicting train subjects:  50%|█████     | 134/266 [05:07<05:26,  2.47s/it]predicting train subjects:  51%|█████     | 135/266 [05:09<05:24,  2.48s/it]predicting train subjects:  51%|█████     | 136/266 [05:12<05:21,  2.48s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:14<05:17,  2.46s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:17<05:12,  2.44s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:19<05:09,  2.43s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:21<05:09,  2.46s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:24<05:06,  2.45s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:26<05:04,  2.46s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:29<05:03,  2.46s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:31<05:07,  2.52s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:34<05:07,  2.54s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:36<04:58,  2.49s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:39<04:56,  2.49s/it]predicting train subjects:  56%|█████▌    | 148/266 [05:41<04:50,  2.46s/it]predicting train subjects:  56%|█████▌    | 149/266 [05:44<04:47,  2.45s/it]predicting train subjects:  56%|█████▋    | 150/266 [05:46<04:48,  2.49s/it]predicting train subjects:  57%|█████▋    | 151/266 [05:49<04:44,  2.47s/it]predicting train subjects:  57%|█████▋    | 152/266 [05:51<04:40,  2.46s/it]predicting train subjects:  58%|█████▊    | 153/266 [05:54<04:35,  2.44s/it]predicting train subjects:  58%|█████▊    | 154/266 [05:56<04:31,  2.43s/it]predicting train subjects:  58%|█████▊    | 155/266 [05:58<04:06,  2.22s/it]predicting train subjects:  59%|█████▊    | 156/266 [05:59<03:48,  2.08s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:01<03:35,  1.98s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:03<03:25,  1.90s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:05<03:20,  1.87s/it]predicting train subjects:  60%|██████    | 160/266 [06:07<03:15,  1.85s/it]predicting train subjects:  61%|██████    | 161/266 [06:08<03:11,  1.82s/it]predicting train subjects:  61%|██████    | 162/266 [06:10<03:07,  1.81s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:12<03:05,  1.80s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:14<03:02,  1.79s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:15<03:01,  1.79s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:17<02:57,  1.77s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:19<02:54,  1.77s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:21<02:53,  1.77s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:22<02:51,  1.77s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:24<02:50,  1.77s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:26<02:48,  1.77s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:28<02:47,  1.79s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:30<02:53,  1.86s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:32<02:54,  1.89s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:34<02:54,  1.92s/it]predicting train subjects:  66%|██████▌   | 176/266 [06:36<02:51,  1.91s/it]predicting train subjects:  67%|██████▋   | 177/266 [06:38<02:50,  1.92s/it]predicting train subjects:  67%|██████▋   | 178/266 [06:40<02:49,  1.92s/it]predicting train subjects:  67%|██████▋   | 179/266 [06:41<02:47,  1.92s/it]predicting train subjects:  68%|██████▊   | 180/266 [06:43<02:46,  1.94s/it]predicting train subjects:  68%|██████▊   | 181/266 [06:45<02:46,  1.95s/it]predicting train subjects:  68%|██████▊   | 182/266 [06:47<02:43,  1.95s/it]predicting train subjects:  69%|██████▉   | 183/266 [06:49<02:42,  1.95s/it]predicting train subjects:  69%|██████▉   | 184/266 [06:51<02:41,  1.97s/it]predicting train subjects:  70%|██████▉   | 185/266 [06:53<02:40,  1.98s/it]predicting train subjects:  70%|██████▉   | 186/266 [06:55<02:36,  1.96s/it]predicting train subjects:  70%|███████   | 187/266 [06:57<02:35,  1.96s/it]predicting train subjects:  71%|███████   | 188/266 [06:59<02:33,  1.97s/it]predicting train subjects:  71%|███████   | 189/266 [07:01<02:30,  1.95s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:03<02:28,  1.95s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:05<02:31,  2.02s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:07<02:26,  1.98s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:09<02:22,  1.96s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:11<02:30,  2.10s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:13<02:27,  2.07s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:16<02:25,  2.08s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:18<02:24,  2.09s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:20<02:21,  2.08s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:22<02:20,  2.09s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:24<02:17,  2.08s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:26<02:15,  2.08s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:28<02:13,  2.08s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:30<02:10,  2.07s/it]predicting train subjects:  77%|███████▋  | 204/266 [07:32<02:09,  2.09s/it]predicting train subjects:  77%|███████▋  | 205/266 [07:34<02:06,  2.08s/it]predicting train subjects:  77%|███████▋  | 206/266 [07:36<02:04,  2.08s/it]predicting train subjects:  78%|███████▊  | 207/266 [07:38<02:02,  2.08s/it]predicting train subjects:  78%|███████▊  | 208/266 [07:41<02:00,  2.08s/it]predicting train subjects:  79%|███████▊  | 209/266 [07:43<01:59,  2.09s/it]predicting train subjects:  79%|███████▉  | 210/266 [07:45<01:57,  2.10s/it]predicting train subjects:  79%|███████▉  | 211/266 [07:47<01:55,  2.10s/it]predicting train subjects:  80%|███████▉  | 212/266 [07:49<01:52,  2.09s/it]predicting train subjects:  80%|████████  | 213/266 [07:51<01:47,  2.03s/it]predicting train subjects:  80%|████████  | 214/266 [07:53<01:42,  1.98s/it]predicting train subjects:  81%|████████  | 215/266 [07:55<01:39,  1.95s/it]predicting train subjects:  81%|████████  | 216/266 [07:56<01:35,  1.92s/it]predicting train subjects:  82%|████████▏ | 217/266 [07:58<01:32,  1.88s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:00<01:30,  1.89s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:02<01:29,  1.90s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:04<01:26,  1.88s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:06<01:24,  1.88s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:08<01:22,  1.87s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:09<01:19,  1.85s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:11<01:17,  1.84s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:13<01:15,  1.84s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:15<01:14,  1.86s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:17<01:12,  1.85s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:19<01:11,  1.87s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:21<01:09,  1.87s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:22<01:06,  1.86s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:24<01:05,  1.86s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:26<01:03,  1.87s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:28<01:02,  1.88s/it]predicting train subjects:  88%|████████▊ | 234/266 [08:30<01:00,  1.88s/it]predicting train subjects:  88%|████████▊ | 235/266 [08:32<00:58,  1.89s/it]predicting train subjects:  89%|████████▊ | 236/266 [08:34<00:56,  1.88s/it]predicting train subjects:  89%|████████▉ | 237/266 [08:36<00:54,  1.87s/it]predicting train subjects:  89%|████████▉ | 238/266 [08:37<00:51,  1.86s/it]predicting train subjects:  90%|████████▉ | 239/266 [08:39<00:50,  1.86s/it]predicting train subjects:  90%|█████████ | 240/266 [08:41<00:48,  1.88s/it]predicting train subjects:  91%|█████████ | 241/266 [08:43<00:47,  1.90s/it]predicting train subjects:  91%|█████████ | 242/266 [08:45<00:45,  1.91s/it]predicting train subjects:  91%|█████████▏| 243/266 [08:47<00:43,  1.90s/it]predicting train subjects:  92%|█████████▏| 244/266 [08:49<00:41,  1.88s/it]predicting train subjects:  92%|█████████▏| 245/266 [08:51<00:39,  1.89s/it]predicting train subjects:  92%|█████████▏| 246/266 [08:53<00:38,  1.91s/it]predicting train subjects:  93%|█████████▎| 247/266 [08:55<00:36,  1.90s/it]predicting train subjects:  93%|█████████▎| 248/266 [08:56<00:34,  1.89s/it]predicting train subjects:  94%|█████████▎| 249/266 [08:59<00:34,  2.04s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:01<00:34,  2.15s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:04<00:33,  2.23s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:06<00:31,  2.28s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:08<00:30,  2.32s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:11<00:28,  2.34s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:13<00:25,  2.36s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:16<00:23,  2.39s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:18<00:21,  2.40s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:21<00:19,  2.40s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:23<00:16,  2.41s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:25<00:14,  2.42s/it]predicting train subjects:  98%|█████████▊| 261/266 [09:28<00:12,  2.43s/it]predicting train subjects:  98%|█████████▊| 262/266 [09:30<00:09,  2.44s/it]predicting train subjects:  99%|█████████▉| 263/266 [09:33<00:07,  2.42s/it]predicting train subjects:  99%|█████████▉| 264/266 [09:35<00:04,  2.44s/it]predicting train subjects: 100%|█████████▉| 265/266 [09:38<00:02,  2.45s/it]predicting train subjects: 100%|██████████| 266/266 [09:40<00:00,  2.46s/it]

Epoch 00053: val_mDice did not improve from 0.61541
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [0.6743662363739424, 0.6024623625381018, 0.5184449034352456, 0.5186492762257976, 0.5025029089502109, 0.48941442049959655, 0.49806491341642156, 0.4851511015046027, 0.5039126123151472, 0.4896514758627902, 0.4887428947033421, 0.4861769477526347, 0.4750046662745937, 0.4771005469624714, 0.4945539973115408, 0.4873937605529703, 0.5000823447781224, 0.48380882220883525, 0.48891882101694745, 0.5080790833760334, 0.5003039824065342, 0.6682955289399752, 0.4880854589964754, 0.48175492850683066, 0.48209376873508575, 0.48087308451693545, 0.48192046470539546, 0.48979384219774635, 0.48482653562740613, 0.4806950835771458, 0.5025315166160624, 0.5001021120496976, 0.5053637626991477, 0.4947954089410843, 0.4821439125845509, 0.4965202484720497, 0.497964572201493, 0.49621765812238056, 0.5046574851518036, 0.49463533233570794, 0.4947691546973362, 0.49053021175886996, 0.4823577551431553, 0.4991940042024018, 0.5032606688878869, 0.49532229861905497, 0.5171130587977748, 0.5035079881068198, 0.5099905466520658, 0.49989623151799684, 0.4948228549572729, 0.5010042408461212, 0.48750493987914056], 'val_acc': [0.9266899587005697, 0.9319489732865365, 0.9366679300544083, 0.9389587506171195, 0.9426323322839635, 0.9422723151022389, 0.940141499042511, 0.9417282913320808, 0.9414509073380501, 0.9442070991762223, 0.9420203053823082, 0.9445577834242134, 0.9449151363424075, 0.942960343053264, 0.9428243406357304, 0.944883131852714, 0.9433577035063057, 0.9436763896737047, 0.9447111224615445, 0.9436750687578673, 0.9456031796752765, 0.9446831326330861, 0.9437430699666342, 0.943560383653128, 0.9457938690339366, 0.9452965016006142, 0.9445497887108916, 0.9437923995397424, 0.9437617351931911, 0.9457645364986953, 0.943973736096454, 0.9429963647678334, 0.9449458186344434, 0.9436390694751534, 0.9431963665511018, 0.9450071511730072, 0.9442577650470119, 0.9456178603633758, 0.9438110666890298, 0.9447631162981833, 0.9451898355637828, 0.9437124030564421, 0.9451324914091377, 0.9445711310191821, 0.9437617326295504, 0.9442711017465079, 0.9451178273847026, 0.9444311068904016, 0.945768521037153, 0.9467352500525854, 0.9439084106876005, 0.9446471256594504, 0.9426056723440847], 'val_mDice': [0.5063613521796401, 0.546781365589429, 0.5897237395727506, 0.5893811432905095, 0.5973474626900047, 0.6056778341211299, 0.6006709029597621, 0.6063956983627812, 0.597053788682466, 0.6085595584684803, 0.6057472389231446, 0.6071375518716792, 0.6154085961721276, 0.6129007576614298, 0.6040894248152292, 0.6090048179831556, 0.6014888171226748, 0.6090566663331883, 0.6061638484718979, 0.5957660165525251, 0.6007277555363153, 0.5472221521921056, 0.6077481706937155, 0.6088069036442746, 0.6106773999429518, 0.6134217016158565, 0.6116910557593068, 0.6077442656281173, 0.6089693756513698, 0.6120926987740302, 0.6007303653224823, 0.6028684720557224, 0.6016859200692946, 0.6069117521726957, 0.6122123509325007, 0.6023651592193111, 0.6020750211131188, 0.6044657794378137, 0.598127761835693, 0.6049062942945829, 0.604483482017312, 0.6079767160518195, 0.6112655715275837, 0.6024293476535428, 0.6016635100046793, 0.6061503278311863, 0.5934777612327248, 0.6036649096396661, 0.5982545492469623, 0.6041636402888965, 0.6044646719450592, 0.6024760841041483, 0.608063155604947], 'loss': [1.4590313970087976, 0.5665210365569696, 0.45772851123736724, 0.4188887044337898, 0.3742588297597104, 0.34736003362208273, 0.32898592776137997, 0.31077108366662537, 0.3037774456534789, 0.3044225649092443, 0.28532652969654126, 0.27254578824934445, 0.2652047934420418, 0.2636705932365814, 0.25374978416599975, 0.24603925881819674, 0.24412860131936093, 0.24930503267318616, 0.2365682813338661, 0.2342974390650447, 0.2515935774277971, 0.2427370042630822, 0.24659247774734377, 0.22726801215835085, 0.2221992866919389, 0.2181127815633365, 0.21634944601624492, 0.21526738013378516, 0.21154513410141113, 0.20922942189145582, 0.21486555528339707, 0.2091255689652411, 0.2061767435394805, 0.20368047935784395, 0.20275536312345463, 0.19935123840729638, 0.19891920222788156, 0.1981788099798974, 0.1957360634804826, 0.1946085625943728, 0.19777359649388182, 0.19370858683425177, 0.19210934955683465, 0.1905443989669479, 0.18868697905916473, 0.188159166703562, 0.18814844948885612, 0.18643316366946144, 0.18549583119751956, 0.18335211603817447, 0.18316565920207406, 0.18201864346125346, 0.18627864454324838], 'acc': [0.7948600205039069, 0.9162220805488074, 0.9273252829102551, 0.9320915626427672, 0.9355534526188294, 0.9381973812607518, 0.9401785094447275, 0.9420438299915159, 0.9428702733295775, 0.9431943476662791, 0.9447410293607964, 0.9460565092592444, 0.9468223214782009, 0.9475921275831926, 0.9481371901493779, 0.9488620120954031, 0.9493788825665568, 0.9493397655029762, 0.9500899320561467, 0.9506805691115102, 0.9487441819180578, 0.9499709807527409, 0.9494657365842618, 0.950927755424336, 0.9515135913978945, 0.9519722869567931, 0.9522629524010554, 0.952344983069405, 0.9526907230297358, 0.9530126552831522, 0.9525837368565481, 0.9531758354819921, 0.9534534125439578, 0.9536694807634731, 0.9537408833034242, 0.9540600119715205, 0.9541485980321467, 0.9543769736590784, 0.9545632329028823, 0.9547626316529824, 0.9545375224214951, 0.9549271059701587, 0.9550292653560498, 0.9552503287634072, 0.9554285238156258, 0.9555077278345803, 0.95546485838422, 0.9557038361587892, 0.9558195901184123, 0.9560260097884682, 0.9561020667442606, 0.95619048257702, 0.9561735682992578], 'mDice': [0.3237057605624152, 0.5558895408621094, 0.6178012167094346, 0.646890384837922, 0.6735496651895554, 0.6923125393793369, 0.7057705898117174, 0.719087617528735, 0.7248172846514689, 0.7262389779243158, 0.7384079529117645, 0.7481293476458394, 0.7540262722132705, 0.7596565355038237, 0.7631574766251923, 0.7693931159516783, 0.7734324495181173, 0.7677944601431359, 0.7770766374977467, 0.7815473321157225, 0.7666358278614606, 0.776180617617427, 0.7724008969805195, 0.7846045008843782, 0.7888594219149758, 0.7922291954221761, 0.7937657505762862, 0.7946451222415147, 0.7977450486425216, 0.7997734192617869, 0.7952819480471496, 0.7998335031684354, 0.8024300552543681, 0.8044055871730634, 0.8052847672799628, 0.8081872664231664, 0.8085020362387897, 0.8091964635701876, 0.8113016327272947, 0.812266667535547, 0.8098000586472127, 0.8130473519772529, 0.8144846993906741, 0.8158884242673373, 0.8173157031812309, 0.8178452406438405, 0.8178643015380505, 0.8193345265502345, 0.8201835604879258, 0.8220365621479717, 0.8222139655073675, 0.8232215532469845, 0.8227018379879288]}
