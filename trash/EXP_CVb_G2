2020-01-22 14:56:44.141563: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-22 14:56:46.182993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-22 14:56:46.183054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 14:56:46.592974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 14:56:46.593047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 14:56:46.593059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 14:56:46.593502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/25 [00:00<?, ?it/s]Loading train:   4%|▍         | 1/25 [00:00<00:09,  2.63it/s]Loading train:   8%|▊         | 2/25 [00:00<00:08,  2.85it/s]Loading train:  12%|█▏        | 3/25 [00:00<00:07,  3.12it/s]Loading train:  16%|█▌        | 4/25 [00:01<00:06,  3.26it/s]Loading train:  20%|██        | 5/25 [00:01<00:05,  3.47it/s]Loading train:  24%|██▍       | 6/25 [00:01<00:05,  3.59it/s]Loading train:  28%|██▊       | 7/25 [00:01<00:04,  3.67it/s]Loading train:  32%|███▏      | 8/25 [00:02<00:04,  3.54it/s]Loading train:  36%|███▌      | 9/25 [00:02<00:04,  3.69it/s]Loading train:  40%|████      | 10/25 [00:02<00:03,  3.83it/s]Loading train:  44%|████▍     | 11/25 [00:02<00:03,  4.07it/s]Loading train:  48%|████▊     | 12/25 [00:04<00:06,  2.03it/s]Loading train:  52%|█████▏    | 13/25 [00:04<00:07,  1.64it/s]Loading train:  56%|█████▌    | 14/25 [00:05<00:06,  1.60it/s]Loading train:  60%|██████    | 15/25 [00:06<00:06,  1.54it/s]Loading train:  64%|██████▍   | 16/25 [00:07<00:06,  1.45it/s]Loading train:  68%|██████▊   | 17/25 [00:07<00:05,  1.50it/s]Loading train:  72%|███████▏  | 18/25 [00:08<00:05,  1.39it/s]Loading train:  76%|███████▌  | 19/25 [00:09<00:04,  1.46it/s]Loading train:  80%|████████  | 20/25 [00:10<00:03,  1.33it/s]Loading train:  84%|████████▍ | 21/25 [00:10<00:02,  1.38it/s]Loading train:  88%|████████▊ | 22/25 [00:11<00:02,  1.41it/s]Loading train:  92%|█████████▏| 23/25 [00:12<00:01,  1.42it/s]Loading train:  96%|█████████▌| 24/25 [00:12<00:00,  1.38it/s]Loading train: 100%|██████████| 25/25 [00:13<00:00,  1.37it/s]Loading train: 100%|██████████| 25/25 [00:13<00:00,  1.84it/s]
concatenating: train:   0%|          | 0/25 [00:00<?, ?it/s]concatenating: train:  16%|█▌        | 4/25 [00:00<00:00, 38.10it/s]concatenating: train:  36%|███▌      | 9/25 [00:00<00:00, 40.73it/s]concatenating: train:  56%|█████▌    | 14/25 [00:00<00:00, 42.79it/s]concatenating: train:  80%|████████  | 20/25 [00:00<00:00, 45.40it/s]concatenating: train: 100%|██████████| 25/25 [00:00<00:00, 48.37it/s]
Loading test:   0%|          | 0/9 [00:00<?, ?it/s]Loading test:  11%|█         | 1/9 [00:00<00:07,  1.14it/s]Loading test:  22%|██▏       | 2/9 [00:01<00:05,  1.23it/s]Loading test:  33%|███▎      | 3/9 [00:02<00:04,  1.21it/s]Loading test:  44%|████▍     | 4/9 [00:03<00:04,  1.20it/s]Loading test:  56%|█████▌    | 5/9 [00:04<00:03,  1.22it/s]Loading test:  67%|██████▋   | 6/9 [00:04<00:02,  1.26it/s]Loading test:  78%|███████▊  | 7/9 [00:05<00:01,  1.36it/s]Loading test:  89%|████████▉ | 8/9 [00:06<00:00,  1.24it/s]Loading test: 100%|██████████| 9/9 [00:06<00:00,  1.39it/s]Loading test: 100%|██████████| 9/9 [00:06<00:00,  1.31it/s]
concatenating: validation:   0%|          | 0/9 [00:00<?, ?it/s]concatenating: validation:  78%|███████▊  | 7/9 [00:00<00:00, 64.82it/s]concatenating: validation: 100%|██████████| 9/9 [00:00<00:00, 65.49it/s]
Loading trainS:   0%|          | 0/25 [00:00<?, ?it/s]Loading trainS:   4%|▍         | 1/25 [00:00<00:22,  1.06it/s]Loading trainS:   8%|▊         | 2/25 [00:01<00:20,  1.10it/s]Loading trainS:  12%|█▏        | 3/25 [00:02<00:18,  1.16it/s]Loading trainS:  16%|█▌        | 4/25 [00:03<00:17,  1.22it/s]Loading trainS:  20%|██        | 5/25 [00:03<00:15,  1.27it/s]Loading trainS:  24%|██▍       | 6/25 [00:04<00:15,  1.21it/s]Loading trainS:  28%|██▊       | 7/25 [00:05<00:15,  1.17it/s]Loading trainS:  32%|███▏      | 8/25 [00:06<00:14,  1.18it/s]Loading trainS:  36%|███▌      | 9/25 [00:07<00:13,  1.22it/s]Loading trainS:  40%|████      | 10/25 [00:08<00:13,  1.15it/s]Loading trainS:  44%|████▍     | 11/25 [00:09<00:11,  1.19it/s]Loading trainS:  48%|████▊     | 12/25 [00:09<00:10,  1.18it/s]Loading trainS:  52%|█████▏    | 13/25 [00:10<00:09,  1.25it/s]Loading trainS:  56%|█████▌    | 14/25 [00:11<00:08,  1.32it/s]Loading trainS:  60%|██████    | 15/25 [00:12<00:07,  1.31it/s]Loading trainS:  64%|██████▍   | 16/25 [00:12<00:07,  1.26it/s]Loading trainS:  68%|██████▊   | 17/25 [00:13<00:05,  1.36it/s]Loading trainS:  72%|███████▏  | 18/25 [00:14<00:05,  1.31it/s]Loading trainS:  76%|███████▌  | 19/25 [00:15<00:04,  1.33it/s]Loading trainS:  80%|████████  | 20/25 [00:15<00:03,  1.37it/s]Loading trainS:  84%|████████▍ | 21/25 [00:16<00:02,  1.34it/s]Loading trainS:  88%|████████▊ | 22/25 [00:17<00:02,  1.33it/s]Loading trainS:  92%|█████████▏| 23/25 [00:18<00:01,  1.37it/s]Loading trainS:  96%|█████████▌| 24/25 [00:18<00:00,  1.31it/s]Loading trainS: 100%|██████████| 25/25 [00:19<00:00,  1.33it/s]Loading trainS: 100%|██████████| 25/25 [00:19<00:00,  1.28it/s]
Loading testS:   0%|          | 0/9 [00:00<?, ?it/s]Loading testS:  11%|█         | 1/9 [00:00<00:06,  1.16it/s]Loading testS:  22%|██▏       | 2/9 [00:01<00:05,  1.22it/s]Loading testS:  33%|███▎      | 3/9 [00:02<00:04,  1.27it/s]Loading testS:  44%|████▍     | 4/9 [00:03<00:04,  1.22it/s]Loading testS:  56%|█████▌    | 5/9 [00:04<00:03,  1.19it/s]Loading testS:  67%|██████▋   | 6/9 [00:04<00:02,  1.21it/s]Loading testS:  78%|███████▊  | 7/9 [00:05<00:01,  1.30it/s]Loading testS:  89%|████████▉ | 8/9 [00:06<00:00,  1.25it/s]Loading testS: 100%|██████████| 9/9 [00:06<00:00,  1.39it/s]Loading testS: 100%|██████████| 9/9 [00:06<00:00,  1.30it/s]----------+++ 
CrossVal ['b']
CrossVal ['b']
(0/9) test vimp2_884_06272013_TS
(1/9) test vimp2_F_ET_CSFn2
(2/9) test vimp2_ctrl_918_07112013_TQ
(3/9) test vimp2_845_05312013_VZ
(4/9) test vimp2_G_ET_CSFn2
(5/9) test vimp2_E_ET_CSFn2
(6/9) test vimp2_901_07052013_AS
(7/9) test vimp2_ctrl_925_07152013_LS
(8/9) test vimp2_869_06142013_BL
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 2  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 2  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_WITH_NEW_CASES_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 112, 120, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 112, 120, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 112, 120, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 112, 120, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 112, 120, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 112, 120, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 112, 120, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 56, 60, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 56, 60, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 56, 60, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 56, 60, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 56, 60, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 56, 60, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 56, 60, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 56, 60, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 60, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 30, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 28, 30, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 28, 30, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 28, 30, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 28, 30, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 28, 30, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 28, 30, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 28, 30, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 28, 30, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 28, 30, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 56, 60, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 56, 60, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 56, 60, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 56, 60, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 56, 60, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 56, 60, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 56, 60, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 56, 60, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 56, 60, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 56, 60, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 112, 120, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 112, 120, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 112, 120, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 112, 120, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 112, 120, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 112, 120, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 112, 120, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 112, 120, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 112, 120, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 112, 120, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 112, 120, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
 --- initialized from Model_7T /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2
------------------------------------------------------------------
class_weights [0.97541534 0.02458466]
Train on 1606 samples, validate on 567 samples
Epoch 1/300
 - 13s - loss: 0.2320 - acc: 0.9802 - mDice: 0.5461 - val_loss: 0.1739 - val_acc: 0.9866 - val_mDice: 0.3533

Epoch 00001: val_mDice improved from -inf to 0.35331, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_WITH_NEW_CASES_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 8s - loss: 0.1217 - acc: 0.9889 - mDice: 0.7625 - val_loss: 0.1601 - val_acc: 0.9909 - val_mDice: 0.4390

Epoch 00002: val_mDice improved from 0.35331 to 0.43904, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_WITH_NEW_CASES_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 8s - loss: 0.1155 - acc: 0.9899 - mDice: 0.7743 - val_loss: 0.2370 - val_acc: 0.9911 - val_mDice: 0.4677

Epoch 00003: val_mDice improved from 0.43904 to 0.46774, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_WITH_NEW_CASES_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 8s - loss: 0.0984 - acc: 0.9916 - mDice: 0.8076 - val_loss: 0.2447 - val_acc: 0.9856 - val_mDice: 0.4383

Epoch 00004: val_mDice did not improve from 0.46774
Epoch 5/300
 - 8s - loss: 0.0946 - acc: 0.9919 - mDice: 0.8150 - val_loss: 0.1091 - val_acc: 0.9915 - val_mDice: 0.4725


Epoch 00005: val_mDice improved from 0.46774 to 0.47245, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_Init_Main_WITH_NEW_CASES_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
Traceback (most recent call last):
  File "main.py", line 1956, in <module>
    Run_Csfn_with_Best_WMn_architecture(UserInfoB)
  File "main.py", line 1933, in Run_Csfn_with_Best_WMn_architecture
    predict_Thalamus_For_SD0(UserInfoB)
  File "main.py", line 1883, in predict_Thalamus_For_SD0
    Run(UserI, IV)
  File "main.py", line 230, in Run
    else: Loop_Over_Nuclei(UserInfoB)
  File "main.py", line 104, in Loop_Over_Nuclei
    Run_Main(UserI)
  File "main.py", line 224, in Run_Main
    Loop_slicing_orientations(UserInfoB, InitValues)
  File "main.py", line 222, in Loop_slicing_orientations
    subRun(UserInfoB)
  File "main.py", line 216, in subRun
    else: normal_run(params)
  File "main.py", line 203, in normal_run
    choosingModel.check_Run(params, Data)              
  File "/array/ssd/msmajdi/code/thalamus/keras/modelFuncs/choosingModel.py", line 53, in check_Run
    model      = trainingExperiment(Data, params) if not params.preprocess.TestOnly else loadModel(params)
  File "/array/ssd/msmajdi/code/thalamus/keras/modelFuncs/choosingModel.py", line 484, in trainingExperiment
    model, hist = modelTrain_Unet(Data, params, model)
  File "/array/ssd/msmajdi/code/thalamus/keras/modelFuncs/choosingModel.py", line 456, in modelTrain_Unet
    model, hist = modelFit(model)
  File "/array/ssd/msmajdi/code/thalamus/keras/modelFuncs/choosingModel.py", line 452, in modelFit
    else: hist = func_without_Generator()
  File "/array/ssd/msmajdi/code/thalamus/keras/modelFuncs/choosingModel.py", line 445, in func_without_Generator
    hist = model.fit(x=Data.Train.Image, y=Data.Train.Mask, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(Data.Validation.Image, Data.Validation.Mask), verbose=verbose, callbacks=callbacks) # , callbacks=[TQDMCallback()])        
  File "/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/engine/training.py", line 1039, in fit
    validation_steps=validation_steps)
  File "/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/engine/training_arrays.py", line 199, in fit_loop
    outs = f(ins_batch)
  File "/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1439, in __call__
    run_metadata_ptr)
KeyboardInterrupt
