*** DATASET ALREADY EXIST; PLEASE REMOVE 'train' & 'test' SUBFOLDERS ***
(0/456) train vimp2_845_05312013_VZ
(1/456) train vimp2_823_05202013_AJ
(2/456) train vimp2_915_07112013_LC
(3/456) train vimp2_901_07052013_AS
(4/456) train vimp2_ctrl_911_07082013_TTO
(5/456) train vimp2_ctrl_925_07152013_LS
(6/456) train vimp2_869_06142013_BL
(7/456) train vimp2_ANON724_03272013
(8/456) train vimp2_819_05172013_DS
(9/456) train vimp2_ctrl_918_07112013_TQ
(10/456) train vimp2_ctrl_902_07052013_SI
(11/456) train vimp2_ANON606_20130110
(12/456) train vimp2_943_07242013_PA
(13/456) train vimp2_824_05212013_JS
(14/456) train vimp2_ANON624_20130117
(15/456) train vimp2_ctrl_920_07122013_SW
(16/456) train vimp2_884_06272013_TS
(17/456) train vimp2_668_02282013_CD
(18/456) train vimp2_964_08092013_TG
(19/456) train vimp2_ctrl_921_07122013_MP
(20/456) train vimp2_972_08152013_DC
(21/456) train vimp2_988_08302013_CB
(22/456) train vimp2_ANON702_03152013
(23/456) train vimp2_ANON714_03222013
(24/456) train vimp2_972_08152013_DC_Aug0_Rot_-1_sd0
(25/456) train vimp2_972_08152013_DC_Aug0_Rot_1_sd2
(26/456) train vimp2_972_08152013_DC_Aug0_Rot_-7_sd1
(27/456) train vimp2_972_08152013_DC_Aug1_Rot_2_sd0
(28/456) train vimp2_972_08152013_DC_Aug1_Rot_5_sd1
(29/456) train vimp2_972_08152013_DC_Aug1_Rot_6_sd2
(30/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd1
(31/456) train vimp2_972_08152013_DC_Aug2_Rot_-3_sd2
(32/456) train vimp2_972_08152013_DC_Aug2_Rot_-5_sd0
(33/456) train vimp2_972_08152013_DC_Aug3_Rot_2_sd1
(34/456) train vimp2_972_08152013_DC_Aug3_Rot_-3_sd0
(35/456) train vimp2_972_08152013_DC_Aug3_Rot_-6_sd2
(36/456) train vimp2_972_08152013_DC_Aug4_Rot_-2_sd2
(37/456) train vimp2_972_08152013_DC_Aug4_Rot_3_sd0
(38/456) train vimp2_972_08152013_DC_Aug4_Rot_6_sd1
(39/456) train vimp2_972_08152013_DC_Aug5_Rot_-1_sd2
(40/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd0
(41/456) train vimp2_972_08152013_DC_Aug5_Rot_7_sd1
(42/456) train vimp2_988_08302013_CB_Aug0_Rot_-3_sd2
(43/456) train vimp2_988_08302013_CB_Aug0_Rot_4_sd0
(44/456) train vimp2_988_08302013_CB_Aug0_Rot_-5_sd1
(45/456) train vimp2_988_08302013_CB_Aug1_Rot_-2_sd2
(46/456) train vimp2_988_08302013_CB_Aug1_Rot_-3_sd0
(47/456) train vimp2_988_08302013_CB_Aug1_Rot_-6_sd1
(48/456) train vimp2_988_08302013_CB_Aug2_Rot_-2_sd0
(49/456) train vimp2_988_08302013_CB_Aug2_Rot_4_sd1
(50/456) train vimp2_988_08302013_CB_Aug2_Rot_-5_sd2
(51/456) train vimp2_988_08302013_CB_Aug3_Rot_2_sd2
(52/456) train vimp2_988_08302013_CB_Aug3_Rot_-3_sd0
(53/456) train vimp2_988_08302013_CB_Aug3_Rot_3_sd1
(54/456) train vimp2_988_08302013_CB_Aug4_Rot_-2_sd0
(55/456) train vimp2_988_08302013_CB_Aug4_Rot_-6_sd1
(56/456) train vimp2_988_08302013_CB_Aug4_Rot_7_sd2
(57/456) train vimp2_988_08302013_CB_Aug5_Rot_-1_sd0
(58/456) train vimp2_988_08302013_CB_Aug5_Rot_-6_sd1
(59/456) train vimp2_988_08302013_CB_Aug5_Rot_7_sd2
(60/456) train vimp2_ANON702_03152013_Aug0_Rot_-2_sd1
(61/456) train vimp2_ANON702_03152013_Aug0_Rot_-3_sd2
(62/456) train vimp2_ANON702_03152013_Aug0_Rot_-4_sd0
(63/456) train vimp2_ANON702_03152013_Aug1_Rot_-4_sd1
(64/456) train vimp2_ANON702_03152013_Aug1_Rot_-5_sd2
(65/456) train vimp2_ANON702_03152013_Aug1_Rot_-7_sd0
(66/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd0
(67/456) train vimp2_ANON702_03152013_Aug2_Rot_6_sd2
(68/456) train vimp2_ANON702_03152013_Aug2_Rot_-7_sd1
(69/456) train vimp2_ANON702_03152013_Aug3_Rot_-1_sd2
(70/456) train vimp2_ANON702_03152013_Aug3_Rot_-3_sd0
(71/456) train vimp2_ANON702_03152013_Aug3_Rot_-6_sd1
(72/456) train vimp2_ANON702_03152013_Aug4_Rot_-2_sd0
(73/456) train vimp2_ANON702_03152013_Aug4_Rot_-3_sd2
(74/456) train vimp2_ANON702_03152013_Aug4_Rot_-7_sd1
(75/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd0
(76/456) train vimp2_ANON702_03152013_Aug5_Rot_3_sd2
(77/456) train vimp2_ANON702_03152013_Aug5_Rot_4_sd1
(78/456) train vimp2_ANON714_03222013_Aug0_Rot_-1_sd2
(79/456) train vimp2_ANON714_03222013_Aug0_Rot_-2_sd1
(80/456) train vimp2_ANON714_03222013_Aug0_Rot_4_sd0
(81/456) train vimp2_ANON714_03222013_Aug1_Rot_0_sd0
(82/456) train vimp2_ANON714_03222013_Aug1_Rot_1_sd1
(83/456) train vimp2_ANON714_03222013_Aug1_Rot_-6_sd2
(84/456) train vimp2_ANON714_03222013_Aug2_Rot_-2_sd0
(85/456) train vimp2_ANON714_03222013_Aug2_Rot_4_sd1
(86/456) train vimp2_ANON714_03222013_Aug2_Rot_6_sd2
(87/456) train vimp2_ANON714_03222013_Aug3_Rot_2_sd0
(88/456) train vimp2_ANON714_03222013_Aug3_Rot_-3_sd2
(89/456) train vimp2_ANON714_03222013_Aug3_Rot_-7_sd1
(90/456) train vimp2_ANON714_03222013_Aug4_Rot_1_sd0
(91/456) train vimp2_ANON714_03222013_Aug4_Rot_-2_sd1
(92/456) train vimp2_ANON714_03222013_Aug4_Rot_4_sd2
(93/456) train vimp2_ANON714_03222013_Aug5_Rot_1_sd0
(94/456) train vimp2_ANON714_03222013_Aug5_Rot_6_sd1
(95/456) train vimp2_ANON714_03222013_Aug5_Rot_-7_sd2
(96/456) train vimp2_668_02282013_CD_Aug0_Rot_7_sd0
(97/456) train vimp2_668_02282013_CD_Aug1_Rot_-1_sd0
(98/456) train vimp2_668_02282013_CD_Aug2_Rot_-4_sd0
(99/456) train vimp2_668_02282013_CD_Aug3_Rot_3_sd0
(100/456) train vimp2_668_02282013_CD_Aug4_Rot_-5_sd0
(101/456) train vimp2_668_02282013_CD_Aug5_Rot_-6_sd0
(102/456) train vimp2_819_05172013_DS_Aug0_Rot_1_sd0
(103/456) train vimp2_819_05172013_DS_Aug1_Rot_5_sd0
(104/456) train vimp2_819_05172013_DS_Aug2_Rot_-4_sd0
(105/456) train vimp2_819_05172013_DS_Aug3_Rot_2_sd0
(106/456) train vimp2_819_05172013_DS_Aug4_Rot_5_sd0
(107/456) train vimp2_819_05172013_DS_Aug5_Rot_4_sd0
(108/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd0
(109/456) train vimp2_823_05202013_AJ_Aug1_Rot_7_sd0
(110/456) train vimp2_823_05202013_AJ_Aug2_Rot_3_sd0
(111/456) train vimp2_823_05202013_AJ_Aug3_Rot_-5_sd0
(112/456) train vimp2_823_05202013_AJ_Aug4_Rot_-3_sd0
(113/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd0
(114/456) train vimp2_824_05212013_JS_Aug0_Rot_-2_sd0
(115/456) train vimp2_824_05212013_JS_Aug1_Rot_6_sd0
(116/456) train vimp2_824_05212013_JS_Aug2_Rot_1_sd0
(117/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd0
(118/456) train vimp2_824_05212013_JS_Aug4_Rot_7_sd0
(119/456) train vimp2_824_05212013_JS_Aug5_Rot_2_sd0
(120/456) train vimp2_845_05312013_VZ_Aug0_Rot_1_sd0
(121/456) train vimp2_845_05312013_VZ_Aug1_Rot_5_sd0
(122/456) train vimp2_845_05312013_VZ_Aug2_Rot_-6_sd0
(123/456) train vimp2_845_05312013_VZ_Aug3_Rot_3_sd0
(124/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd0
(125/456) train vimp2_845_05312013_VZ_Aug5_Rot_5_sd0
(126/456) train vimp2_869_06142013_BL_Aug0_Rot_-2_sd0
(127/456) train vimp2_869_06142013_BL_Aug1_Rot_-4_sd0
(128/456) train vimp2_869_06142013_BL_Aug2_Rot_-1_sd0
(129/456) train vimp2_869_06142013_BL_Aug3_Rot_3_sd0
(130/456) train vimp2_869_06142013_BL_Aug4_Rot_3_sd0
(131/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd0
(132/456) train vimp2_884_06272013_TS_Aug0_Rot_-7_sd0
(133/456) train vimp2_884_06272013_TS_Aug1_Rot_7_sd0
(134/456) train vimp2_884_06272013_TS_Aug2_Rot_-5_sd0
(135/456) train vimp2_884_06272013_TS_Aug3_Rot_-2_sd0
(136/456) train vimp2_884_06272013_TS_Aug4_Rot_6_sd0
(137/456) train vimp2_884_06272013_TS_Aug5_Rot_-1_sd0
(138/456) train vimp2_901_07052013_AS_Aug0_Rot_-4_sd0
(139/456) train vimp2_901_07052013_AS_Aug1_Rot_-2_sd0
(140/456) train vimp2_901_07052013_AS_Aug2_Rot_1_sd0
(141/456) train vimp2_901_07052013_AS_Aug3_Rot_2_sd0
(142/456) train vimp2_901_07052013_AS_Aug4_Rot_-7_sd0
(143/456) train vimp2_901_07052013_AS_Aug5_Rot_-5_sd0
(144/456) train vimp2_915_07112013_LC_Aug0_Rot_-2_sd0
(145/456) train vimp2_915_07112013_LC_Aug1_Rot_4_sd0
(146/456) train vimp2_915_07112013_LC_Aug2_Rot_-2_sd0
(147/456) train vimp2_915_07112013_LC_Aug3_Rot_-1_sd0
(148/456) train vimp2_915_07112013_LC_Aug4_Rot_1_sd0
(149/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd0
(150/456) train vimp2_943_07242013_PA_Aug0_Rot_-5_sd0
(151/456) train vimp2_943_07242013_PA_Aug1_Rot_-7_sd0
(152/456) train vimp2_943_07242013_PA_Aug2_Rot_-4_sd0
(153/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd0
(154/456) train vimp2_943_07242013_PA_Aug4_Rot_6_sd0
(155/456) train vimp2_943_07242013_PA_Aug5_Rot_5_sd0
(156/456) train vimp2_964_08092013_TG_Aug0_Rot_5_sd0
(157/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd0
(158/456) train vimp2_964_08092013_TG_Aug2_Rot_7_sd0
(159/456) train vimp2_964_08092013_TG_Aug3_Rot_-1_sd0
(160/456) train vimp2_964_08092013_TG_Aug4_Rot_-1_sd0
(161/456) train vimp2_964_08092013_TG_Aug5_Rot_2_sd0
(162/456) train vimp2_ANON606_20130110_Aug0_Rot_1_sd0
(163/456) train vimp2_ANON606_20130110_Aug1_Rot_2_sd0
(164/456) train vimp2_ANON606_20130110_Aug2_Rot_-5_sd0
(165/456) train vimp2_ANON606_20130110_Aug3_Rot_-5_sd0
(166/456) train vimp2_ANON606_20130110_Aug4_Rot_3_sd0
(167/456) train vimp2_ANON606_20130110_Aug5_Rot_-1_sd0
(168/456) train vimp2_ANON624_20130117_Aug0_Rot_1_sd0
(169/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd0
(170/456) train vimp2_ANON624_20130117_Aug2_Rot_5_sd0
(171/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd0
(172/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd0
(173/456) train vimp2_ANON624_20130117_Aug5_Rot_3_sd0
(174/456) train vimp2_ANON724_03272013_Aug0_Rot_-4_sd0
(175/456) train vimp2_ANON724_03272013_Aug1_Rot_-3_sd0
(176/456) train vimp2_ANON724_03272013_Aug2_Rot_-4_sd0
(177/456) train vimp2_ANON724_03272013_Aug3_Rot_5_sd0
(178/456) train vimp2_ANON724_03272013_Aug4_Rot_5_sd0
(179/456) train vimp2_ANON724_03272013_Aug5_Rot_-6_sd0
(180/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_5_sd0
(181/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd0
(182/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_4_sd0
(183/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd0
(184/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_3_sd0
(185/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-7_sd0
(186/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_6_sd0
(187/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_1_sd0
(188/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_4_sd0
(189/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-2_sd0
(190/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd0
(191/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_-2_sd0
(192/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_5_sd0
(193/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-3_sd0
(194/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_-4_sd0
(195/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_1_sd0
(196/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_3_sd0
(197/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_7_sd0
(198/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd0
(199/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-6_sd0
(200/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd0
(201/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_1_sd0
(202/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-2_sd0
(203/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_4_sd0
(204/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_-1_sd0
(205/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-3_sd0
(206/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd0
(207/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_3_sd0
(208/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_1_sd0
(209/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_-5_sd0
(210/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-5_sd0
(211/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_-2_sd0
(212/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_5_sd0
(213/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_3_sd0
(214/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_4_sd0
(215/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-7_sd0
(216/456) train vimp2_668_02282013_CD_Aug0_Rot_-5_sd1
(217/456) train vimp2_668_02282013_CD_Aug1_Rot_-6_sd1
(218/456) train vimp2_668_02282013_CD_Aug2_Rot_3_sd1
(219/456) train vimp2_668_02282013_CD_Aug3_Rot_4_sd1
(220/456) train vimp2_668_02282013_CD_Aug4_Rot_-6_sd1
(221/456) train vimp2_668_02282013_CD_Aug5_Rot_-2_sd1
(222/456) train vimp2_819_05172013_DS_Aug0_Rot_-1_sd1
(223/456) train vimp2_819_05172013_DS_Aug1_Rot_3_sd1
(224/456) train vimp2_819_05172013_DS_Aug2_Rot_6_sd1
(225/456) train vimp2_819_05172013_DS_Aug3_Rot_3_sd1
(226/456) train vimp2_819_05172013_DS_Aug4_Rot_-7_sd1
(227/456) train vimp2_819_05172013_DS_Aug5_Rot_-5_sd1
(228/456) train vimp2_823_05202013_AJ_Aug0_Rot_-7_sd1
(229/456) train vimp2_823_05202013_AJ_Aug1_Rot_3_sd1
(230/456) train vimp2_823_05202013_AJ_Aug2_Rot_6_sd1
(231/456) train vimp2_823_05202013_AJ_Aug3_Rot_-7_sd1
(232/456) train vimp2_823_05202013_AJ_Aug4_Rot_-4_sd1
(233/456) train vimp2_823_05202013_AJ_Aug5_Rot_-4_sd1
(234/456) train vimp2_824_05212013_JS_Aug0_Rot_7_sd1
(235/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd1
(236/456) train vimp2_824_05212013_JS_Aug2_Rot_3_sd1
(237/456) train vimp2_824_05212013_JS_Aug3_Rot_-4_sd1
(238/456) train vimp2_824_05212013_JS_Aug4_Rot_4_sd1
(239/456) train vimp2_824_05212013_JS_Aug5_Rot_6_sd1
(240/456) train vimp2_845_05312013_VZ_Aug0_Rot_5_sd1
(241/456) train vimp2_845_05312013_VZ_Aug1_Rot_6_sd1
(242/456) train vimp2_845_05312013_VZ_Aug2_Rot_1_sd1
(243/456) train vimp2_845_05312013_VZ_Aug3_Rot_-6_sd1
(244/456) train vimp2_845_05312013_VZ_Aug4_Rot_-2_sd1
(245/456) train vimp2_845_05312013_VZ_Aug5_Rot_-6_sd1
(246/456) train vimp2_869_06142013_BL_Aug0_Rot_-4_sd1
(247/456) train vimp2_869_06142013_BL_Aug1_Rot_-3_sd1
(248/456) train vimp2_869_06142013_BL_Aug2_Rot_-4_sd1
(249/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd1
(250/456) train vimp2_869_06142013_BL_Aug4_Rot_7_sd1
(251/456) train vimp2_869_06142013_BL_Aug5_Rot_5_sd1
(252/456) train vimp2_884_06272013_TS_Aug0_Rot_5_sd1
(253/456) train vimp2_884_06272013_TS_Aug1_Rot_-1_sd1
(254/456) train vimp2_884_06272013_TS_Aug2_Rot_-1_sd1
(255/456) train vimp2_884_06272013_TS_Aug3_Rot_3_sd1
(256/456) train vimp2_884_06272013_TS_Aug4_Rot_4_sd1
(257/456) train vimp2_884_06272013_TS_Aug5_Rot_3_sd1
(258/456) train vimp2_901_07052013_AS_Aug0_Rot_3_sd1
(259/456) train vimp2_901_07052013_AS_Aug1_Rot_5_sd1
(260/456) train vimp2_901_07052013_AS_Aug2_Rot_-5_sd1
(261/456) train vimp2_901_07052013_AS_Aug3_Rot_7_sd1
(262/456) train vimp2_901_07052013_AS_Aug4_Rot_7_sd1
(263/456) train vimp2_901_07052013_AS_Aug5_Rot_6_sd1
(264/456) train vimp2_915_07112013_LC_Aug0_Rot_-6_sd1
(265/456) train vimp2_915_07112013_LC_Aug1_Rot_-5_sd1
(266/456) train vimp2_915_07112013_LC_Aug2_Rot_7_sd1
(267/456) train vimp2_915_07112013_LC_Aug3_Rot_1_sd1
(268/456) train vimp2_915_07112013_LC_Aug4_Rot_6_sd1
(269/456) train vimp2_915_07112013_LC_Aug5_Rot_-7_sd1
(270/456) train vimp2_943_07242013_PA_Aug0_Rot_1_sd1
(271/456) train vimp2_943_07242013_PA_Aug1_Rot_6_sd1
(272/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd1
(273/456) train vimp2_943_07242013_PA_Aug3_Rot_6_sd1
(274/456) train vimp2_943_07242013_PA_Aug4_Rot_3_sd1
(275/456) train vimp2_943_07242013_PA_Aug5_Rot_3_sd1
(276/456) train vimp2_964_08092013_TG_Aug0_Rot_6_sd1
(277/456) train vimp2_964_08092013_TG_Aug1_Rot_-4_sd1
(278/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd1
(279/456) train vimp2_964_08092013_TG_Aug3_Rot_0_sd1
(280/456) train vimp2_964_08092013_TG_Aug4_Rot_3_sd1
(281/456) train vimp2_964_08092013_TG_Aug5_Rot_-1_sd1
(282/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd1
(283/456) train vimp2_ANON606_20130110_Aug1_Rot_7_sd1
(284/456) train vimp2_ANON606_20130110_Aug2_Rot_1_sd1
(285/456) train vimp2_ANON606_20130110_Aug3_Rot_1_sd1
(286/456) train vimp2_ANON606_20130110_Aug4_Rot_4_sd1
(287/456) train vimp2_ANON606_20130110_Aug5_Rot_4_sd1
(288/456) train vimp2_ANON624_20130117_Aug0_Rot_7_sd1
(289/456) train vimp2_ANON624_20130117_Aug1_Rot_6_sd1
(290/456) train vimp2_ANON624_20130117_Aug2_Rot_-1_sd1
(291/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd1
(292/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd1
(293/456) train vimp2_ANON624_20130117_Aug5_Rot_4_sd1
(294/456) train vimp2_ANON724_03272013_Aug0_Rot_-2_sd1
(295/456) train vimp2_ANON724_03272013_Aug1_Rot_4_sd1
(296/456) train vimp2_ANON724_03272013_Aug2_Rot_-1_sd1
(297/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd1
(298/456) train vimp2_ANON724_03272013_Aug4_Rot_-5_sd1
(299/456) train vimp2_ANON724_03272013_Aug5_Rot_-4_sd1
(300/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-2_sd1
(301/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_7_sd1
(302/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_2_sd1
(303/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_-4_sd1
(304/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-1_sd1
(305/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_-4_sd1
(306/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_7_sd1
(307/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_-1_sd1
(308/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_-5_sd1
(309/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_-3_sd1
(310/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_6_sd1
(311/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_6_sd1
(312/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_1_sd1
(313/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_-2_sd1
(314/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_3_sd1
(315/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_-1_sd1
(316/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_7_sd1
(317/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_6_sd1
(318/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_-3_sd1
(319/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_7_sd1
(320/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_-4_sd1
(321/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-1_sd1
(322/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-5_sd1
(323/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_-5_sd1
(324/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_4_sd1
(325/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_3_sd1
(326/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_-1_sd1
(327/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd1
(328/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_2_sd1
(329/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_4_sd1
(330/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_-2_sd1
(331/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_4_sd1
(332/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_-2_sd1
(333/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_2_sd1
(334/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_3_sd1
(335/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-4_sd1
(336/456) train vimp2_668_02282013_CD_Aug0_Rot_-3_sd2
(337/456) train vimp2_668_02282013_CD_Aug1_Rot_6_sd2
(338/456) train vimp2_668_02282013_CD_Aug2_Rot_-6_sd2
(339/456) train vimp2_668_02282013_CD_Aug3_Rot_7_sd2
(340/456) train vimp2_668_02282013_CD_Aug4_Rot_1_sd2
(341/456) train vimp2_668_02282013_CD_Aug5_Rot_7_sd2
(342/456) train vimp2_819_05172013_DS_Aug0_Rot_3_sd2
(343/456) train vimp2_819_05172013_DS_Aug1_Rot_-1_sd2
(344/456) train vimp2_819_05172013_DS_Aug2_Rot_-2_sd2
(345/456) train vimp2_819_05172013_DS_Aug3_Rot_-1_sd2
(346/456) train vimp2_819_05172013_DS_Aug4_Rot_7_sd2
(347/456) train vimp2_819_05172013_DS_Aug5_Rot_3_sd2
(348/456) train vimp2_823_05202013_AJ_Aug0_Rot_-6_sd2
(349/456) train vimp2_823_05202013_AJ_Aug1_Rot_-7_sd2
(350/456) train vimp2_823_05202013_AJ_Aug2_Rot_7_sd2
(351/456) train vimp2_823_05202013_AJ_Aug3_Rot_-2_sd2
(352/456) train vimp2_823_05202013_AJ_Aug4_Rot_1_sd2
(353/456) train vimp2_823_05202013_AJ_Aug5_Rot_1_sd2
(354/456) train vimp2_824_05212013_JS_Aug0_Rot_-5_sd2
(355/456) train vimp2_824_05212013_JS_Aug1_Rot_3_sd2
(356/456) train vimp2_824_05212013_JS_Aug2_Rot_5_sd2
(357/456) train vimp2_824_05212013_JS_Aug3_Rot_2_sd2
(358/456) train vimp2_824_05212013_JS_Aug4_Rot_5_sd2
(359/456) train vimp2_824_05212013_JS_Aug5_Rot_-7_sd2
(360/456) train vimp2_845_05312013_VZ_Aug0_Rot_-5_sd2
(361/456) train vimp2_845_05312013_VZ_Aug1_Rot_3_sd2
(362/456) train vimp2_845_05312013_VZ_Aug2_Rot_-3_sd2
(363/456) train vimp2_845_05312013_VZ_Aug3_Rot_-1_sd2
(364/456) train vimp2_845_05312013_VZ_Aug4_Rot_4_sd2
(365/456) train vimp2_845_05312013_VZ_Aug5_Rot_-2_sd2
(366/456) train vimp2_869_06142013_BL_Aug0_Rot_3_sd2
(367/456) train vimp2_869_06142013_BL_Aug1_Rot_7_sd2
(368/456) train vimp2_869_06142013_BL_Aug2_Rot_4_sd2
(369/456) train vimp2_869_06142013_BL_Aug3_Rot_1_sd2
(370/456) train vimp2_869_06142013_BL_Aug4_Rot_1_sd2
(371/456) train vimp2_869_06142013_BL_Aug5_Rot_1_sd2
(372/456) train vimp2_884_06272013_TS_Aug0_Rot_3_sd2
(373/456) train vimp2_884_06272013_TS_Aug1_Rot_-5_sd2
(374/456) train vimp2_884_06272013_TS_Aug2_Rot_-7_sd2
(375/456) train vimp2_884_06272013_TS_Aug3_Rot_-6_sd2
(376/456) train vimp2_884_06272013_TS_Aug4_Rot_-2_sd2
(377/456) train vimp2_884_06272013_TS_Aug5_Rot_-6_sd2
(378/456) train vimp2_901_07052013_AS_Aug0_Rot_2_sd2
(379/456) train vimp2_901_07052013_AS_Aug1_Rot_-3_sd2
(380/456) train vimp2_901_07052013_AS_Aug2_Rot_-6_sd2
(381/456) train vimp2_901_07052013_AS_Aug3_Rot_6_sd2
(382/456) train vimp2_901_07052013_AS_Aug4_Rot_-5_sd2
(383/456) train vimp2_901_07052013_AS_Aug5_Rot_1_sd2
(384/456) train vimp2_915_07112013_LC_Aug0_Rot_1_sd2
(385/456) train vimp2_915_07112013_LC_Aug1_Rot_7_sd2
(386/456) train vimp2_915_07112013_LC_Aug2_Rot_3_sd2
(387/456) train vimp2_915_07112013_LC_Aug3_Rot_6_sd2
(388/456) train vimp2_915_07112013_LC_Aug4_Rot_4_sd2
(389/456) train vimp2_915_07112013_LC_Aug5_Rot_4_sd2
(390/456) train vimp2_943_07242013_PA_Aug0_Rot_3_sd2
(391/456) train vimp2_943_07242013_PA_Aug1_Rot_-4_sd2
(392/456) train vimp2_943_07242013_PA_Aug2_Rot_3_sd2
(393/456) train vimp2_943_07242013_PA_Aug3_Rot_2_sd2
(394/456) train vimp2_943_07242013_PA_Aug4_Rot_-1_sd2
(395/456) train vimp2_943_07242013_PA_Aug5_Rot_-3_sd2
(396/456) train vimp2_964_08092013_TG_Aug0_Rot_2_sd2
(397/456) train vimp2_964_08092013_TG_Aug1_Rot_-6_sd2
(398/456) train vimp2_964_08092013_TG_Aug2_Rot_5_sd2
(399/456) train vimp2_964_08092013_TG_Aug3_Rot_-7_sd2
(400/456) train vimp2_964_08092013_TG_Aug4_Rot_-6_sd2
(401/456) train vimp2_964_08092013_TG_Aug5_Rot_5_sd2
(402/456) train vimp2_ANON606_20130110_Aug0_Rot_-6_sd2
(403/456) train vimp2_ANON606_20130110_Aug1_Rot_-5_sd2
(404/456) train vimp2_ANON606_20130110_Aug2_Rot_-3_sd2
(405/456) train vimp2_ANON606_20130110_Aug3_Rot_3_sd2
(406/456) train vimp2_ANON606_20130110_Aug4_Rot_-2_sd2
(407/456) train vimp2_ANON606_20130110_Aug5_Rot_-3_sd2
(408/456) train vimp2_ANON624_20130117_Aug0_Rot_2_sd2
(409/456) train vimp2_ANON624_20130117_Aug1_Rot_-2_sd2
(410/456) train vimp2_ANON624_20130117_Aug2_Rot_-6_sd2
(411/456) train vimp2_ANON624_20130117_Aug3_Rot_1_sd2
(412/456) train vimp2_ANON624_20130117_Aug4_Rot_-5_sd2
(413/456) train vimp2_ANON624_20130117_Aug5_Rot_-7_sd2
(414/456) train vimp2_ANON724_03272013_Aug0_Rot_-5_sd2
(415/456) train vimp2_ANON724_03272013_Aug1_Rot_6_sd2
(416/456) train vimp2_ANON724_03272013_Aug2_Rot_-3_sd2
(417/456) train vimp2_ANON724_03272013_Aug3_Rot_-6_sd2
(418/456) train vimp2_ANON724_03272013_Aug4_Rot_-1_sd2
(419/456) train vimp2_ANON724_03272013_Aug5_Rot_-7_sd2
(420/456) train vimp2_ctrl_902_07052013_SI_Aug0_Rot_-4_sd2
(421/456) train vimp2_ctrl_902_07052013_SI_Aug1_Rot_-3_sd2
(422/456) train vimp2_ctrl_902_07052013_SI_Aug2_Rot_-5_sd2
(423/456) train vimp2_ctrl_902_07052013_SI_Aug3_Rot_5_sd2
(424/456) train vimp2_ctrl_902_07052013_SI_Aug4_Rot_-2_sd2
(425/456) train vimp2_ctrl_902_07052013_SI_Aug5_Rot_5_sd2
(426/456) train vimp2_ctrl_911_07082013_TTO_Aug0_Rot_-3_sd2
(427/456) train vimp2_ctrl_911_07082013_TTO_Aug1_Rot_7_sd2
(428/456) train vimp2_ctrl_911_07082013_TTO_Aug2_Rot_3_sd2
(429/456) train vimp2_ctrl_911_07082013_TTO_Aug3_Rot_5_sd2
(430/456) train vimp2_ctrl_911_07082013_TTO_Aug4_Rot_7_sd2
(431/456) train vimp2_ctrl_911_07082013_TTO_Aug5_Rot_2_sd2
(432/456) train vimp2_ctrl_918_07112013_TQ_Aug0_Rot_-7_sd2
(433/456) train vimp2_ctrl_918_07112013_TQ_Aug1_Rot_5_sd2
(434/456) train vimp2_ctrl_918_07112013_TQ_Aug2_Rot_5_sd2
(435/456) train vimp2_ctrl_918_07112013_TQ_Aug3_Rot_4_sd2
(436/456) train vimp2_ctrl_918_07112013_TQ_Aug4_Rot_5_sd2
(437/456) train vimp2_ctrl_918_07112013_TQ_Aug5_Rot_-4_sd2
(438/456) train vimp2_ctrl_920_07122013_SW_Aug0_Rot_7_sd2
(439/456) train vimp2_ctrl_920_07122013_SW_Aug1_Rot_-2_sd2
(440/456) train vimp2_ctrl_920_07122013_SW_Aug2_Rot_1_sd2
(441/456) train vimp2_ctrl_920_07122013_SW_Aug3_Rot_-7_sd2
(442/456) train vimp2_ctrl_920_07122013_SW_Aug4_Rot_-3_sd2
(443/456) train vimp2_ctrl_920_07122013_SW_Aug5_Rot_7_sd2
(444/456) train vimp2_ctrl_921_07122013_MP_Aug0_Rot_1_sd2
(445/456) train vimp2_ctrl_921_07122013_MP_Aug1_Rot_-7_sd2
(446/456) train vimp2_ctrl_921_07122013_MP_Aug2_Rot_6_sd2
(447/456) train vimp2_ctrl_921_07122013_MP_Aug3_Rot_-2_sd2
(448/456) train vimp2_ctrl_921_07122013_MP_Aug4_Rot_-5_sd2
(449/456) train vimp2_ctrl_921_07122013_MP_Aug5_Rot_6_sd2
(450/456) train vimp2_ctrl_925_07152013_LS_Aug0_Rot_2_sd2
(451/456) train vimp2_ctrl_925_07152013_LS_Aug1_Rot_5_sd2
(452/456) train vimp2_ctrl_925_07152013_LS_Aug2_Rot_2_sd2
(453/456) train vimp2_ctrl_925_07152013_LS_Aug3_Rot_5_sd2
(454/456) train vimp2_ctrl_925_07152013_LS_Aug4_Rot_-4_sd2
(455/456) train vimp2_ctrl_925_07152013_LS_Aug5_Rot_-3_sd22019-07-07 21:30:51.307578: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-07 21:30:53.603942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-07 21:30:53.604014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 21:30:53.975568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 21:30:53.975641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 21:30:53.975656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 21:30:53.976254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:50,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<06:58,  1.48s/it]Loading train:   1%|          | 3/285 [00:04<06:41,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:04<06:01,  1.29s/it]Loading train:   2%|▏         | 5/285 [00:06<06:16,  1.35s/it]Loading train:   2%|▏         | 6/285 [00:07<05:59,  1.29s/it]Loading train:   2%|▏         | 7/285 [00:09<06:13,  1.34s/it]Loading train:   3%|▎         | 8/285 [00:10<05:52,  1.27s/it]Loading train:   3%|▎         | 9/285 [00:11<06:20,  1.38s/it]Loading train:   4%|▎         | 10/285 [00:12<05:40,  1.24s/it]Loading train:   4%|▍         | 11/285 [00:13<04:56,  1.08s/it]Loading train:   4%|▍         | 12/285 [00:14<04:49,  1.06s/it]Loading train:   5%|▍         | 13/285 [00:15<04:28,  1.01it/s]Loading train:   5%|▍         | 14/285 [00:16<04:34,  1.01s/it]Loading train:   5%|▌         | 15/285 [00:17<04:27,  1.01it/s]Loading train:   6%|▌         | 16/285 [00:18<04:47,  1.07s/it]Loading train:   6%|▌         | 17/285 [00:19<04:25,  1.01it/s]Loading train:   6%|▋         | 18/285 [00:20<04:31,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:21<04:10,  1.06it/s]Loading train:   7%|▋         | 20/285 [00:22<04:35,  1.04s/it]Loading train:   7%|▋         | 21/285 [00:23<04:31,  1.03s/it]Loading train:   8%|▊         | 22/285 [00:24<04:10,  1.05it/s]Loading train:   8%|▊         | 23/285 [00:25<04:13,  1.03it/s]Loading train:   8%|▊         | 24/285 [00:26<03:58,  1.09it/s]Loading train:   9%|▉         | 25/285 [00:27<04:12,  1.03it/s]Loading train:   9%|▉         | 26/285 [00:28<04:09,  1.04it/s]Loading train:   9%|▉         | 27/285 [00:28<03:59,  1.08it/s]Loading train:  10%|▉         | 28/285 [00:29<04:01,  1.06it/s]Loading train:  10%|█         | 29/285 [00:30<03:59,  1.07it/s]Loading train:  11%|█         | 30/285 [00:31<03:53,  1.09it/s]Loading train:  11%|█         | 31/285 [00:32<03:52,  1.09it/s]Loading train:  11%|█         | 32/285 [00:33<03:43,  1.13it/s]Loading train:  12%|█▏        | 33/285 [00:34<03:46,  1.11it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:51,  1.08it/s]Loading train:  12%|█▏        | 35/285 [00:36<03:55,  1.06it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:50,  1.08it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:48,  1.08it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:51,  1.07it/s]Loading train:  14%|█▎        | 39/285 [00:39<03:32,  1.16it/s]Loading train:  14%|█▍        | 40/285 [00:40<03:43,  1.10it/s]Loading train:  14%|█▍        | 41/285 [00:41<03:37,  1.12it/s]Loading train:  15%|█▍        | 42/285 [00:42<03:28,  1.16it/s]Loading train:  15%|█▌        | 43/285 [00:43<03:34,  1.13it/s]Loading train:  15%|█▌        | 44/285 [00:44<03:38,  1.10it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:35,  1.11it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:44,  1.06it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:35,  1.10it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:45,  1.05it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:51,  1.02it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:38,  1.07it/s]Loading train:  18%|█▊        | 51/285 [00:50<03:41,  1.06it/s]Loading train:  18%|█▊        | 52/285 [00:51<03:24,  1.14it/s]Loading train:  19%|█▊        | 53/285 [00:52<03:32,  1.09it/s]Loading train:  19%|█▉        | 54/285 [00:53<03:29,  1.10it/s]Loading train:  19%|█▉        | 55/285 [00:54<03:17,  1.16it/s]Loading train:  20%|█▉        | 56/285 [00:55<03:20,  1.14it/s]Loading train:  20%|██        | 57/285 [00:56<03:10,  1.20it/s]Loading train:  20%|██        | 58/285 [00:56<03:12,  1.18it/s]Loading train:  21%|██        | 59/285 [00:57<03:15,  1.15it/s]Loading train:  21%|██        | 60/285 [00:58<03:19,  1.13it/s]Loading train:  21%|██▏       | 61/285 [00:59<03:11,  1.17it/s]Loading train:  22%|██▏       | 62/285 [01:00<03:09,  1.18it/s]Loading train:  22%|██▏       | 63/285 [01:01<03:09,  1.17it/s]Loading train:  22%|██▏       | 64/285 [01:02<03:31,  1.05it/s]Loading train:  23%|██▎       | 65/285 [01:03<04:08,  1.13s/it]Loading train:  23%|██▎       | 66/285 [01:05<04:11,  1.15s/it]Loading train:  24%|██▎       | 67/285 [01:06<03:52,  1.07s/it]Loading train:  24%|██▍       | 68/285 [01:06<03:27,  1.05it/s]Loading train:  24%|██▍       | 69/285 [01:07<03:21,  1.07it/s]Loading train:  25%|██▍       | 70/285 [01:08<03:25,  1.05it/s]Loading train:  25%|██▍       | 71/285 [01:09<03:29,  1.02it/s]Loading train:  25%|██▌       | 72/285 [01:10<03:14,  1.09it/s]Loading train:  26%|██▌       | 73/285 [01:11<03:13,  1.09it/s]Loading train:  26%|██▌       | 74/285 [01:12<03:11,  1.10it/s]Loading train:  26%|██▋       | 75/285 [01:13<03:11,  1.10it/s]Loading train:  27%|██▋       | 76/285 [01:14<03:11,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:14<03:02,  1.14it/s]Loading train:  27%|██▋       | 78/285 [01:15<02:57,  1.17it/s]Loading train:  28%|██▊       | 79/285 [01:16<03:00,  1.14it/s]Loading train:  28%|██▊       | 80/285 [01:17<03:11,  1.07it/s]Loading train:  28%|██▊       | 81/285 [01:18<03:05,  1.10it/s]Loading train:  29%|██▉       | 82/285 [01:19<03:05,  1.09it/s]Loading train:  29%|██▉       | 83/285 [01:20<02:57,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:20<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:21<02:52,  1.16it/s]Loading train:  30%|███       | 86/285 [01:22<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:23<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:24<03:03,  1.07it/s]Loading train:  31%|███       | 89/285 [01:25<03:03,  1.07it/s]Loading train:  32%|███▏      | 90/285 [01:26<03:05,  1.05it/s]Loading train:  32%|███▏      | 91/285 [01:27<02:59,  1.08it/s]Loading train:  32%|███▏      | 92/285 [01:28<03:10,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:29<03:03,  1.05it/s]Loading train:  33%|███▎      | 94/285 [01:30<03:01,  1.05it/s]Loading train:  33%|███▎      | 95/285 [01:31<02:55,  1.08it/s]Loading train:  34%|███▎      | 96/285 [01:32<02:43,  1.16it/s]Loading train:  34%|███▍      | 97/285 [01:33<02:42,  1.16it/s]Loading train:  34%|███▍      | 98/285 [01:33<02:39,  1.17it/s]Loading train:  35%|███▍      | 99/285 [01:34<02:42,  1.15it/s]Loading train:  35%|███▌      | 100/285 [01:35<02:42,  1.14it/s]Loading train:  35%|███▌      | 101/285 [01:36<02:37,  1.17it/s]Loading train:  36%|███▌      | 102/285 [01:37<02:35,  1.17it/s]Loading train:  36%|███▌      | 103/285 [01:38<02:28,  1.23it/s]Loading train:  36%|███▋      | 104/285 [01:39<02:36,  1.16it/s]Loading train:  37%|███▋      | 105/285 [01:40<02:43,  1.10it/s]Loading train:  37%|███▋      | 106/285 [01:40<02:40,  1.11it/s]Loading train:  38%|███▊      | 107/285 [01:41<02:40,  1.11it/s]Loading train:  38%|███▊      | 108/285 [01:42<02:37,  1.12it/s]Loading train:  38%|███▊      | 109/285 [01:43<02:39,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:44<02:41,  1.08it/s]Loading train:  39%|███▉      | 111/285 [01:45<02:40,  1.08it/s]Loading train:  39%|███▉      | 112/285 [01:46<02:42,  1.06it/s]Loading train:  40%|███▉      | 113/285 [01:47<02:45,  1.04it/s]Loading train:  40%|████      | 114/285 [01:48<02:44,  1.04it/s]Loading train:  40%|████      | 115/285 [01:49<02:43,  1.04it/s]Loading train:  41%|████      | 116/285 [01:50<03:01,  1.07s/it]Loading train:  41%|████      | 117/285 [01:51<02:46,  1.01it/s]Loading train:  41%|████▏     | 118/285 [01:52<02:34,  1.08it/s]Loading train:  42%|████▏     | 119/285 [01:53<02:42,  1.02it/s]Loading train:  42%|████▏     | 120/285 [01:54<02:36,  1.05it/s]Loading train:  42%|████▏     | 121/285 [01:55<02:49,  1.04s/it]Loading train:  43%|████▎     | 122/285 [01:56<02:52,  1.06s/it]Loading train:  43%|████▎     | 123/285 [01:57<02:51,  1.06s/it]Loading train:  44%|████▎     | 124/285 [01:58<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [01:59<02:28,  1.08it/s]Loading train:  44%|████▍     | 126/285 [02:00<02:18,  1.15it/s]Loading train:  45%|████▍     | 127/285 [02:00<02:13,  1.19it/s]Loading train:  45%|████▍     | 128/285 [02:01<02:09,  1.21it/s]Loading train:  45%|████▌     | 129/285 [02:02<02:06,  1.23it/s]Loading train:  46%|████▌     | 130/285 [02:03<02:00,  1.28it/s]Loading train:  46%|████▌     | 131/285 [02:03<01:57,  1.32it/s]Loading train:  46%|████▋     | 132/285 [02:04<01:55,  1.32it/s]Loading train:  47%|████▋     | 133/285 [02:05<02:00,  1.26it/s]Loading train:  47%|████▋     | 134/285 [02:06<01:55,  1.31it/s]Loading train:  47%|████▋     | 135/285 [02:06<01:56,  1.29it/s]Loading train:  48%|████▊     | 136/285 [02:07<01:52,  1.32it/s]Loading train:  48%|████▊     | 137/285 [02:08<01:57,  1.26it/s]Loading train:  48%|████▊     | 138/285 [02:09<01:58,  1.24it/s]Loading train:  49%|████▉     | 139/285 [02:10<01:59,  1.22it/s]Loading train:  49%|████▉     | 140/285 [02:10<01:54,  1.26it/s]Loading train:  49%|████▉     | 141/285 [02:11<01:50,  1.30it/s]Loading train:  50%|████▉     | 142/285 [02:12<01:48,  1.32it/s]Loading train:  50%|█████     | 143/285 [02:13<01:52,  1.26it/s]Loading train:  51%|█████     | 144/285 [02:14<01:53,  1.24it/s]Loading train:  51%|█████     | 145/285 [02:14<01:52,  1.24it/s]Loading train:  51%|█████     | 146/285 [02:15<01:52,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:16<01:51,  1.24it/s]Loading train:  52%|█████▏    | 148/285 [02:17<01:46,  1.29it/s]Loading train:  52%|█████▏    | 149/285 [02:18<01:44,  1.30it/s]Loading train:  53%|█████▎    | 150/285 [02:18<01:44,  1.29it/s]Loading train:  53%|█████▎    | 151/285 [02:19<01:45,  1.27it/s]Loading train:  53%|█████▎    | 152/285 [02:20<01:40,  1.32it/s]Loading train:  54%|█████▎    | 153/285 [02:20<01:36,  1.37it/s]Loading train:  54%|█████▍    | 154/285 [02:21<01:40,  1.30it/s]Loading train:  54%|█████▍    | 155/285 [02:22<01:38,  1.33it/s]Loading train:  55%|█████▍    | 156/285 [02:23<01:37,  1.32it/s]Loading train:  55%|█████▌    | 157/285 [02:24<01:36,  1.33it/s]Loading train:  55%|█████▌    | 158/285 [02:24<01:35,  1.33it/s]Loading train:  56%|█████▌    | 159/285 [02:25<01:34,  1.33it/s]Loading train:  56%|█████▌    | 160/285 [02:26<01:41,  1.23it/s]Loading train:  56%|█████▋    | 161/285 [02:27<01:44,  1.19it/s]Loading train:  57%|█████▋    | 162/285 [02:28<01:39,  1.24it/s]Loading train:  57%|█████▋    | 163/285 [02:29<01:44,  1.17it/s]Loading train:  58%|█████▊    | 164/285 [02:29<01:37,  1.24it/s]Loading train:  58%|█████▊    | 165/285 [02:30<01:38,  1.22it/s]Loading train:  58%|█████▊    | 166/285 [02:31<01:36,  1.23it/s]Loading train:  59%|█████▊    | 167/285 [02:32<01:40,  1.17it/s]Loading train:  59%|█████▉    | 168/285 [02:33<01:39,  1.17it/s]Loading train:  59%|█████▉    | 169/285 [02:34<01:34,  1.22it/s]Loading train:  60%|█████▉    | 170/285 [02:34<01:29,  1.29it/s]Loading train:  60%|██████    | 171/285 [02:35<01:27,  1.30it/s]Loading train:  60%|██████    | 172/285 [02:36<01:24,  1.34it/s]Loading train:  61%|██████    | 173/285 [02:36<01:19,  1.40it/s]Loading train:  61%|██████    | 174/285 [02:37<01:17,  1.42it/s]Loading train:  61%|██████▏   | 175/285 [02:38<01:22,  1.34it/s]Loading train:  62%|██████▏   | 176/285 [02:39<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:39<01:23,  1.30it/s]Loading train:  62%|██████▏   | 178/285 [02:40<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [02:41<01:25,  1.24it/s]Loading train:  63%|██████▎   | 180/285 [02:42<01:34,  1.11it/s]Loading train:  64%|██████▎   | 181/285 [02:43<01:36,  1.08it/s]Loading train:  64%|██████▍   | 182/285 [02:44<01:35,  1.08it/s]Loading train:  64%|██████▍   | 183/285 [02:45<01:27,  1.17it/s]Loading train:  65%|██████▍   | 184/285 [02:46<01:31,  1.10it/s]Loading train:  65%|██████▍   | 185/285 [02:47<01:30,  1.11it/s]Loading train:  65%|██████▌   | 186/285 [02:48<01:38,  1.01it/s]Loading train:  66%|██████▌   | 187/285 [02:49<01:37,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [02:50<01:36,  1.00it/s]Loading train:  66%|██████▋   | 189/285 [02:51<01:30,  1.06it/s]Loading train:  67%|██████▋   | 190/285 [02:52<01:32,  1.03it/s]Loading train:  67%|██████▋   | 191/285 [02:53<01:27,  1.08it/s]Loading train:  67%|██████▋   | 192/285 [02:54<01:31,  1.02it/s]Loading train:  68%|██████▊   | 193/285 [02:55<01:26,  1.06it/s]Loading train:  68%|██████▊   | 194/285 [02:55<01:19,  1.14it/s]Loading train:  68%|██████▊   | 195/285 [02:56<01:15,  1.19it/s]Loading train:  69%|██████▉   | 196/285 [02:57<01:19,  1.12it/s]Loading train:  69%|██████▉   | 197/285 [02:58<01:24,  1.04it/s]Loading train:  69%|██████▉   | 198/285 [02:59<01:25,  1.02it/s]Loading train:  70%|██████▉   | 199/285 [03:00<01:18,  1.10it/s]Loading train:  70%|███████   | 200/285 [03:01<01:12,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:02<01:14,  1.13it/s]Loading train:  71%|███████   | 202/285 [03:02<01:11,  1.16it/s]Loading train:  71%|███████   | 203/285 [03:03<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:04<01:05,  1.23it/s]Loading train:  72%|███████▏  | 205/285 [03:05<01:06,  1.20it/s]Loading train:  72%|███████▏  | 206/285 [03:06<01:05,  1.20it/s]Loading train:  73%|███████▎  | 207/285 [03:07<01:10,  1.10it/s]Loading train:  73%|███████▎  | 208/285 [03:08<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [03:09<01:12,  1.04it/s]Loading train:  74%|███████▎  | 210/285 [03:10<01:08,  1.09it/s]Loading train:  74%|███████▍  | 211/285 [03:11<01:10,  1.05it/s]Loading train:  74%|███████▍  | 212/285 [03:11<01:04,  1.12it/s]Loading train:  75%|███████▍  | 213/285 [03:12<01:02,  1.14it/s]Loading train:  75%|███████▌  | 214/285 [03:13<01:01,  1.15it/s]Loading train:  75%|███████▌  | 215/285 [03:14<01:02,  1.12it/s]Loading train:  76%|███████▌  | 216/285 [03:15<00:58,  1.18it/s]Loading train:  76%|███████▌  | 217/285 [03:16<00:58,  1.17it/s]Loading train:  76%|███████▋  | 218/285 [03:17<01:00,  1.11it/s]Loading train:  77%|███████▋  | 219/285 [03:18<00:59,  1.10it/s]Loading train:  77%|███████▋  | 220/285 [03:19<00:59,  1.10it/s]Loading train:  78%|███████▊  | 221/285 [03:19<00:57,  1.11it/s]Loading train:  78%|███████▊  | 222/285 [03:20<00:55,  1.14it/s]Loading train:  78%|███████▊  | 223/285 [03:21<00:52,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [03:22<00:50,  1.21it/s]Loading train:  79%|███████▉  | 225/285 [03:22<00:47,  1.26it/s]Loading train:  79%|███████▉  | 226/285 [03:23<00:49,  1.18it/s]Loading train:  80%|███████▉  | 227/285 [03:24<00:51,  1.13it/s]Loading train:  80%|████████  | 228/285 [03:25<00:52,  1.08it/s]Loading train:  80%|████████  | 229/285 [03:26<00:52,  1.06it/s]Loading train:  81%|████████  | 230/285 [03:27<00:49,  1.12it/s]Loading train:  81%|████████  | 231/285 [03:28<00:45,  1.18it/s]Loading train:  81%|████████▏ | 232/285 [03:29<00:43,  1.22it/s]Loading train:  82%|████████▏ | 233/285 [03:29<00:40,  1.28it/s]Loading train:  82%|████████▏ | 234/285 [03:30<00:42,  1.21it/s]Loading train:  82%|████████▏ | 235/285 [03:31<00:38,  1.30it/s]Loading train:  83%|████████▎ | 236/285 [03:32<00:39,  1.25it/s]Loading train:  83%|████████▎ | 237/285 [03:33<00:40,  1.18it/s]Loading train:  84%|████████▎ | 238/285 [03:34<00:41,  1.14it/s]Loading train:  84%|████████▍ | 239/285 [03:35<00:39,  1.16it/s]Loading train:  84%|████████▍ | 240/285 [03:35<00:36,  1.23it/s]Loading train:  85%|████████▍ | 241/285 [03:36<00:36,  1.20it/s]Loading train:  85%|████████▍ | 242/285 [03:37<00:35,  1.20it/s]Loading train:  85%|████████▌ | 243/285 [03:38<00:33,  1.26it/s]Loading train:  86%|████████▌ | 244/285 [03:39<00:34,  1.19it/s]Loading train:  86%|████████▌ | 245/285 [03:39<00:32,  1.22it/s]Loading train:  86%|████████▋ | 246/285 [03:40<00:34,  1.14it/s]Loading train:  87%|████████▋ | 247/285 [03:41<00:35,  1.08it/s]Loading train:  87%|████████▋ | 248/285 [03:42<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [03:43<00:30,  1.19it/s]Loading train:  88%|████████▊ | 250/285 [03:44<00:28,  1.25it/s]Loading train:  88%|████████▊ | 251/285 [03:44<00:26,  1.26it/s]Loading train:  88%|████████▊ | 252/285 [03:45<00:26,  1.25it/s]Loading train:  89%|████████▉ | 253/285 [03:46<00:27,  1.16it/s]Loading train:  89%|████████▉ | 254/285 [03:47<00:28,  1.07it/s]Loading train:  89%|████████▉ | 255/285 [03:48<00:27,  1.08it/s]Loading train:  90%|████████▉ | 256/285 [03:49<00:26,  1.10it/s]Loading train:  90%|█████████ | 257/285 [03:50<00:24,  1.14it/s]Loading train:  91%|█████████ | 258/285 [03:51<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [03:52<00:23,  1.13it/s]Loading train:  91%|█████████ | 260/285 [03:53<00:20,  1.19it/s]Loading train:  92%|█████████▏| 261/285 [03:53<00:20,  1.17it/s]Loading train:  92%|█████████▏| 262/285 [03:54<00:18,  1.25it/s]Loading train:  92%|█████████▏| 263/285 [03:55<00:16,  1.31it/s]Loading train:  93%|█████████▎| 264/285 [03:56<00:17,  1.23it/s]Loading train:  93%|█████████▎| 265/285 [03:57<00:16,  1.20it/s]Loading train:  93%|█████████▎| 266/285 [03:57<00:14,  1.27it/s]Loading train:  94%|█████████▎| 267/285 [03:58<00:13,  1.32it/s]Loading train:  94%|█████████▍| 268/285 [03:59<00:13,  1.23it/s]Loading train:  94%|█████████▍| 269/285 [04:00<00:13,  1.22it/s]Loading train:  95%|█████████▍| 270/285 [04:00<00:11,  1.28it/s]Loading train:  95%|█████████▌| 271/285 [04:01<00:10,  1.36it/s]Loading train:  95%|█████████▌| 272/285 [04:02<00:09,  1.34it/s]Loading train:  96%|█████████▌| 273/285 [04:03<00:08,  1.36it/s]Loading train:  96%|█████████▌| 274/285 [04:03<00:07,  1.39it/s]Loading train:  96%|█████████▋| 275/285 [04:04<00:07,  1.28it/s]Loading train:  97%|█████████▋| 276/285 [04:05<00:07,  1.20it/s]Loading train:  97%|█████████▋| 277/285 [04:06<00:06,  1.20it/s]Loading train:  98%|█████████▊| 278/285 [04:07<00:06,  1.13it/s]Loading train:  98%|█████████▊| 279/285 [04:08<00:05,  1.15it/s]Loading train:  98%|█████████▊| 280/285 [04:09<00:04,  1.18it/s]Loading train:  99%|█████████▊| 281/285 [04:09<00:03,  1.23it/s]Loading train:  99%|█████████▉| 282/285 [04:10<00:02,  1.24it/s]Loading train:  99%|█████████▉| 283/285 [04:11<00:01,  1.15it/s]Loading train: 100%|█████████▉| 284/285 [04:12<00:00,  1.13it/s]Loading train: 100%|██████████| 285/285 [04:13<00:00,  1.11it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:01, 195.86it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:01, 210.82it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:00, 219.97it/s]concatenating: train:  33%|███▎      | 94/285 [00:00<00:00, 222.76it/s]concatenating: train:  40%|████      | 115/285 [00:00<00:00, 218.08it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:00, 218.48it/s]concatenating: train:  55%|█████▌    | 158/285 [00:00<00:00, 213.61it/s]concatenating: train:  62%|██████▏   | 178/285 [00:00<00:00, 195.51it/s]concatenating: train:  72%|███████▏  | 204/285 [00:00<00:00, 208.01it/s]concatenating: train:  79%|███████▉  | 226/285 [00:01<00:00, 210.35it/s]concatenating: train:  87%|████████▋ | 247/285 [00:01<00:00, 207.10it/s]concatenating: train:  94%|█████████▍| 268/285 [00:01<00:00, 198.86it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 212.45it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.21s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 457.46it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/45 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/45 [00:00<00:08,  5.06it/s]loading the weights for Res Unet:   7%|▋         | 3/45 [00:00<00:07,  5.99it/s]loading the weights for Res Unet:   9%|▉         | 4/45 [00:00<00:07,  5.57it/s]loading the weights for Res Unet:  20%|██        | 9/45 [00:00<00:04,  7.30it/s]loading the weights for Res Unet:  24%|██▍       | 11/45 [00:00<00:04,  7.94it/s]loading the weights for Res Unet:  29%|██▉       | 13/45 [00:03<00:14,  2.15it/s]loading the weights for Res Unet:  40%|████      | 18/45 [00:03<00:09,  2.84it/s]loading the weights for Res Unet:  42%|████▏     | 19/45 [00:04<00:12,  2.08it/s]loading the weights for Res Unet:  47%|████▋     | 21/45 [00:04<00:08,  2.73it/s]loading the weights for Res Unet:  49%|████▉     | 22/45 [00:05<00:07,  3.19it/s]loading the weights for Res Unet:  58%|█████▊    | 26/45 [00:05<00:04,  4.26it/s]loading the weights for Res Unet:  62%|██████▏   | 28/45 [00:05<00:03,  5.14it/s]loading the weights for Res Unet:  67%|██████▋   | 30/45 [00:05<00:02,  5.96it/s]loading the weights for Res Unet:  71%|███████   | 32/45 [00:06<00:02,  5.57it/s]loading the weights for Res Unet:  80%|████████  | 36/45 [00:07<00:01,  4.85it/s]loading the weights for Res Unet:  84%|████████▍ | 38/45 [00:08<00:02,  2.72it/s]loading the weights for Res Unet:  87%|████████▋ | 39/45 [00:09<00:03,  1.99it/s]loading the weights for Res Unet:  91%|█████████ | 41/45 [00:09<00:01,  2.43it/s]loading the weights for Res Unet:  93%|█████████▎| 42/45 [00:10<00:01,  2.84it/s]loading the weights for Res Unet: 100%|██████████| 45/45 [00:10<00:00,  4.45it/s]
(0/4) test vimp2_ctrl_991_08302013_JF
(1/4) test vimp2_967_08132013_KW
(2/4) test vimp2_765_04162013_AW
(3/4) test vimp2_ANON695_03132013
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 13,106
Non-trainable params: 44,560
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 19s - loss: 17015.8603 - acc: 0.4511 - mDice: 0.0551 - val_loss: 16944.6780 - val_acc: 0.9034 - val_mDice: 0.0506

Epoch 00001: val_mDice improved from -inf to 0.05058, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 7s - loss: 9776.2276 - acc: 0.8272 - mDice: 0.1661 - val_loss: 30901.0277 - val_acc: 0.9047 - val_mDice: 0.0046

Epoch 00002: val_mDice did not improve from 0.05058
Epoch 3/300
 - 7s - loss: 6739.2130 - acc: 0.8680 - mDice: 0.2666 - val_loss: 12523.5882 - val_acc: 0.9047 - val_mDice: 0.1390

Epoch 00003: val_mDice improved from 0.05058 to 0.13904, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 7s - loss: 5734.6727 - acc: 0.8736 - mDice: 0.3203 - val_loss: 5175.6330 - val_acc: 0.9075 - val_mDice: 0.3490

Epoch 00004: val_mDice improved from 0.13904 to 0.34897, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 7s - loss: 5079.4536 - acc: 0.8775 - mDice: 0.3616 - val_loss: 5014.1998 - val_acc: 0.9098 - val_mDice: 0.3537

Epoch 00005: val_mDice improved from 0.34897 to 0.35372, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 7s - loss: 4565.3422 - acc: 0.8810 - mDice: 0.3999 - val_loss: 3710.7502 - val_acc: 0.9139 - val_mDice: 0.4567

Epoch 00006: val_mDice improved from 0.35372 to 0.45672, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 7s - loss: 4089.1550 - acc: 0.8849 - mDice: 0.4383 - val_loss: 3384.4497 - val_acc: 0.9161 - val_mDice: 0.4820

Epoch 00007: val_mDice improved from 0.45672 to 0.48198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 7s - loss: 3740.3564 - acc: 0.8884 - mDice: 0.4687 - val_loss: 3175.3704 - val_acc: 0.9197 - val_mDice: 0.5023

Epoch 00008: val_mDice improved from 0.48198 to 0.50232, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 7s - loss: 3486.4365 - acc: 0.8922 - mDice: 0.4928 - val_loss: 3064.1968 - val_acc: 0.9258 - val_mDice: 0.5153

Epoch 00009: val_mDice improved from 0.50232 to 0.51529, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 7s - loss: 3320.4381 - acc: 0.8967 - mDice: 0.5094 - val_loss: 3254.6469 - val_acc: 0.9277 - val_mDice: 0.4944

Epoch 00010: val_mDice did not improve from 0.51529
Epoch 11/300
 - 7s - loss: 3174.8867 - acc: 0.9009 - mDice: 0.5248 - val_loss: 2882.8547 - val_acc: 0.9248 - val_mDice: 0.5335

Epoch 00011: val_mDice improved from 0.51529 to 0.53351, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 7s - loss: 3068.0201 - acc: 0.9035 - mDice: 0.5364 - val_loss: 3123.7413 - val_acc: 0.9283 - val_mDice: 0.5072

Epoch 00012: val_mDice did not improve from 0.53351
Epoch 13/300
 - 7s - loss: 2981.0501 - acc: 0.9055 - mDice: 0.5460 - val_loss: 2947.1484 - val_acc: 0.9285 - val_mDice: 0.5293

Epoch 00013: val_mDice did not improve from 0.53351
Epoch 14/300
 - 7s - loss: 2903.7333 - acc: 0.9069 - mDice: 0.5547 - val_loss: 3047.4050 - val_acc: 0.9207 - val_mDice: 0.5180

Epoch 00014: val_mDice did not improve from 0.53351
Epoch 15/300
 - 7s - loss: 2854.0932 - acc: 0.9077 - mDice: 0.5604 - val_loss: 2919.7721 - val_acc: 0.9302 - val_mDice: 0.5336

Epoch 00015: val_mDice improved from 0.53351 to 0.53360, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 7s - loss: 2803.0129 - acc: 0.9087 - mDice: 0.5665 - val_loss: 2856.5469 - val_acc: 0.9260 - val_mDice: 0.5390

Epoch 00016: val_mDice improved from 0.53360 to 0.53898, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 7s - loss: 2756.3787 - acc: 0.9093 - mDice: 0.5719 - val_loss: 2924.8366 - val_acc: 0.9284 - val_mDice: 0.5325

Epoch 00017: val_mDice did not improve from 0.53898
Epoch 18/300
 - 7s - loss: 2719.0083 - acc: 0.9098 - mDice: 0.5763 - val_loss: 2853.9427 - val_acc: 0.9296 - val_mDice: 0.5400

Epoch 00018: val_mDice improved from 0.53898 to 0.53998, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 7s - loss: 2670.6919 - acc: 0.9106 - mDice: 0.5819 - val_loss: 2939.8713 - val_acc: 0.9312 - val_mDice: 0.5288

Epoch 00019: val_mDice did not improve from 0.53998
Epoch 20/300
 - 7s - loss: 2636.6474 - acc: 0.9110 - mDice: 0.5860 - val_loss: 2629.7416 - val_acc: 0.9322 - val_mDice: 0.5618

Epoch 00020: val_mDice improved from 0.53998 to 0.56182, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 7s - loss: 2615.9513 - acc: 0.9117 - mDice: 0.5884 - val_loss: 2668.7580 - val_acc: 0.9315 - val_mDice: 0.5569

Epoch 00021: val_mDice did not improve from 0.56182
Epoch 22/300
 - 7s - loss: 2580.4063 - acc: 0.9125 - mDice: 0.5928 - val_loss: 2736.7571 - val_acc: 0.9261 - val_mDice: 0.5486

Epoch 00022: val_mDice did not improve from 0.56182
Epoch 23/300
 - 7s - loss: 2571.6641 - acc: 0.9124 - mDice: 0.5938 - val_loss: 2843.6195 - val_acc: 0.9256 - val_mDice: 0.5394

Epoch 00023: val_mDice did not improve from 0.56182
Epoch 24/300
 - 7s - loss: 2543.6214 - acc: 0.9129 - mDice: 0.5972 - val_loss: 2622.1303 - val_acc: 0.9291 - val_mDice: 0.5600

Epoch 00024: val_mDice did not improve from 0.56182
Epoch 25/300
 - 7s - loss: 2520.9429 - acc: 0.9133 - mDice: 0.5999 - val_loss: 2511.0098 - val_acc: 0.9341 - val_mDice: 0.5720

Epoch 00025: val_mDice improved from 0.56182 to 0.57202, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 7s - loss: 2512.0532 - acc: 0.9135 - mDice: 0.6011 - val_loss: 2704.6514 - val_acc: 0.9323 - val_mDice: 0.5516

Epoch 00026: val_mDice did not improve from 0.57202
Epoch 27/300
 - 7s - loss: 2485.5385 - acc: 0.9142 - mDice: 0.6043 - val_loss: 2743.0162 - val_acc: 0.9300 - val_mDice: 0.5471

Epoch 00027: val_mDice did not improve from 0.57202
Epoch 28/300
 - 7s - loss: 2457.0177 - acc: 0.9145 - mDice: 0.6078 - val_loss: 2847.7611 - val_acc: 0.9345 - val_mDice: 0.5362

Epoch 00028: val_mDice did not improve from 0.57202
Epoch 29/300
 - 7s - loss: 2435.7436 - acc: 0.9151 - mDice: 0.6104 - val_loss: 2531.1514 - val_acc: 0.9334 - val_mDice: 0.5690

Epoch 00029: val_mDice did not improve from 0.57202
Epoch 30/300
 - 7s - loss: 2418.1774 - acc: 0.9154 - mDice: 0.6125 - val_loss: 2743.3254 - val_acc: 0.9343 - val_mDice: 0.5452

Epoch 00030: val_mDice did not improve from 0.57202
Epoch 31/300
 - 7s - loss: 2415.3534 - acc: 0.9157 - mDice: 0.6129 - val_loss: 2620.9366 - val_acc: 0.9362 - val_mDice: 0.5599

Epoch 00031: val_mDice did not improve from 0.57202
Epoch 32/300
 - 7s - loss: 2400.4657 - acc: 0.9161 - mDice: 0.6146 - val_loss: 2660.2201 - val_acc: 0.9353 - val_mDice: 0.5543

Epoch 00032: val_mDice did not improve from 0.57202
Epoch 33/300
 - 7s - loss: 2379.8015 - acc: 0.9165 - mDice: 0.6171 - val_loss: 2966.4572 - val_acc: 0.9341 - val_mDice: 0.5216

Epoch 00033: val_mDice did not improve from 0.57202
Epoch 34/300
 - 7s - loss: 2364.9033 - acc: 0.9170 - mDice: 0.6191 - val_loss: 2587.2511 - val_acc: 0.9361 - val_mDice: 0.5605

Epoch 00034: val_mDice did not improve from 0.57202
Epoch 35/300
 - 7s - loss: 2343.5854 - acc: 0.9172 - mDice: 0.6217 - val_loss: 2799.8522 - val_acc: 0.9367 - val_mDice: 0.5379

Epoch 00035: val_mDice did not improve from 0.57202
Epoch 36/300
 - 7s - loss: 2337.2246 - acc: 0.9177 - mDice: 0.6226 - val_loss: 3552.4821 - val_acc: 0.9285 - val_mDice: 0.4570

Epoch 00036: val_mDice did not improve from 0.57202
Epoch 37/300
 - 7s - loss: 2340.3927 - acc: 0.9178 - mDice: 0.6222 - val_loss: 2937.9221 - val_acc: 0.9354 - val_mDice: 0.5218

Epoch 00037: val_mDice did not improve from 0.57202
Epoch 38/300
 - 7s - loss: 2323.0884 - acc: 0.9181 - mDice: 0.6242 - val_loss: 2676.5975 - val_acc: 0.9365 - val_mDice: 0.5519

Epoch 00038: val_mDice did not improve from 0.57202
Epoch 39/300
 - 7s - loss: 2306.9435 - acc: 0.9187 - mDice: 0.6263 - val_loss: 2725.0186 - val_acc: 0.9373 - val_mDice: 0.5484

Epoch 00039: val_mDice did not improve from 0.57202
Epoch 40/300
 - 7s - loss: 2309.8325 - acc: 0.9189 - mDice: 0.6260 - val_loss: 2567.6082 - val_acc: 0.9396 - val_mDice: 0.5637

Epoch 00040: val_mDice did not improve from 0.57202
Epoch 41/300
 - 7s - loss: 2288.2921 - acc: 0.9192 - mDice: 0.6286 - val_loss: 2573.4359 - val_acc: 0.9378 - val_mDice: 0.5632

Epoch 00041: val_mDice did not improve from 0.57202
Epoch 42/300
 - 7s - loss: 2274.1603 - acc: 0.9195 - mDice: 0.6305 - val_loss: 2775.5011 - val_acc: 0.9358 - val_mDice: 0.5426

Epoch 00042: val_mDice did not improve from 0.57202
Epoch 43/300
 - 7s - loss: 2281.3160 - acc: 0.9197 - mDice: 0.6297 - val_loss: 2951.4431 - val_acc: 0.9368 - val_mDice: 0.5200

Epoch 00043: val_mDice did not improve from 0.57202
Epoch 44/300
 - 7s - loss: 2275.2442 - acc: 0.9202 - mDice: 0.6303 - val_loss: 2771.3045 - val_acc: 0.9391 - val_mDice: 0.5408

Epoch 00044: val_mDice did not improve from 0.57202
Epoch 45/300
 - 7s - loss: 2265.7781 - acc: 0.9204 - mDice: 0.6315 - val_loss: 2465.1128 - val_acc: 0.9425 - val_mDice: 0.5753

Epoch 00045: val_mDice improved from 0.57202 to 0.57535, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 7s - loss: 2258.5759 - acc: 0.9205 - mDice: 0.6325 - val_loss: 2646.8140 - val_acc: 0.9395 - val_mDice: 0.5552

Epoch 00046: val_mDice did not improve from 0.57535
Epoch 47/300
 - 7s - loss: 2244.2154 - acc: 0.9209 - mDice: 0.6344 - val_loss: 2618.5441 - val_acc: 0.9413 - val_mDice: 0.5571

Epoch 00047: val_mDice did not improve from 0.57535
Epoch 48/300
 - 7s - loss: 2246.6140 - acc: 0.9212 - mDice: 0.6340 - val_loss: 3509.7730 - val_acc: 0.9285 - val_mDice: 0.4623

Epoch 00048: val_mDice did not improve from 0.57535
Epoch 49/300
 - 7s - loss: 2234.2039 - acc: 0.9214 - mDice: 0.6356 - val_loss: 5346.1415 - val_acc: 0.9177 - val_mDice: 0.3232

Epoch 00049: val_mDice did not improve from 0.57535
Epoch 50/300
 - 6s - loss: 2230.0205 - acc: 0.9215 - mDice: 0.6362 - val_loss: 2736.1629 - val_acc: 0.9417 - val_mDice: 0.5448

Epoch 00050: val_mDice did not improve from 0.57535
Epoch 51/300
 - 7s - loss: 2229.7934 - acc: 0.9215 - mDice: 0.6362 - val_loss: 2888.2450 - val_acc: 0.9382 - val_mDice: 0.5244

Epoch 00051: val_mDice did not improve from 0.57535
Epoch 52/300
 - 7s - loss: 2199.6856 - acc: 0.9219 - mDice: 0.6398 - val_loss: 2475.1495 - val_acc: 0.9416 - val_mDice: 0.5739

Epoch 00052: val_mDice did not improve from 0.57535
Epoch 53/300
 - 7s - loss: 2208.0740 - acc: 0.9220 - mDice: 0.6389 - val_loss: 2775.5664 - val_acc: 0.9401 - val_mDice: 0.5381

Epoch 00053: val_mDice did not improve from 0.57535
Epoch 54/300
 - 7s - loss: 2205.0309 - acc: 0.9222 - mDice: 0.6392 - val_loss: 2794.6008 - val_acc: 0.9312 - val_mDice: 0.5379

Epoch 00054: val_mDice did not improve from 0.57535
Epoch 55/300
 - 7s - loss: 2204.7388 - acc: 0.9221 - mDice: 0.6395 - val_loss: 2532.3080 - val_acc: 0.9421 - val_mDice: 0.5686

Epoch 00055: val_mDice did not improve from 0.57535
Epoch 56/300
 - 7s - loss: 2201.9531 - acc: 0.9223 - mDice: 0.6398 - val_loss: 2679.9564 - val_acc: 0.9408 - val_mDice: 0.5514

Epoch 00056: val_mDice did not improve from 0.57535
Epoch 57/300
 - 7s - loss: 2182.6035 - acc: 0.9229 - mDice: 0.6422 - val_loss: 2577.8190 - val_acc: 0.9412 - val_mDice: 0.5610

Epoch 00057: val_mDice did not improve from 0.57535
Epoch 58/300
 - 6s - loss: 2178.0949 - acc: 0.9226 - mDice: 0.6429 - val_loss: 2756.2929 - val_acc: 0.9374 - val_mDice: 0.5420

Epoch 00058: val_mDice did not improve from 0.57535
Epoch 59/300
 - 7s - loss: 2174.2591 - acc: 0.9231 - mDice: 0.6433 - val_loss: 2610.4190 - val_acc: 0.9428 - val_mDice: 0.5585

Epoch 00059: val_mDice did not improve from 0.57535
Epoch 60/300
 - 7s - loss: 2170.0042 - acc: 0.9235 - mDice: 0.6439 - val_loss: 2561.3902 - val_acc: 0.9431 - val_mDice: 0.5650

Epoch 00060: val_mDice did not improve from 0.57535
Epoch 61/300
 - 7s - loss: 2178.6648 - acc: 0.9233 - mDice: 0.6429 - val_loss: 2600.2238 - val_acc: 0.9418 - val_mDice: 0.5597

Epoch 00061: val_mDice did not improve from 0.57535
Epoch 62/300
 - 7s - loss: 2157.8464 - acc: 0.9238 - mDice: 0.6454 - val_loss: 2507.1701 - val_acc: 0.9419 - val_mDice: 0.5689

Epoch 00062: val_mDice did not improve from 0.57535
Epoch 63/300
 - 7s - loss: 2155.2184 - acc: 0.9237 - mDice: 0.6457 - val_loss: 2642.6888 - val_acc: 0.9401 - val_mDice: 0.5533

Epoch 00063: val_mDice did not improve from 0.57535
Epoch 64/300
 - 7s - loss: 2152.0489 - acc: 0.9241 - mDice: 0.6462 - val_loss: 2558.5202 - val_acc: 0.9420 - val_mDice: 0.5631

Epoch 00064: val_mDice did not improve from 0.57535
Epoch 65/300
 - 7s - loss: 2144.8841 - acc: 0.9243 - mDice: 0.6470 - val_loss: 2721.6428 - val_acc: 0.9427 - val_mDice: 0.5443

Epoch 00065: val_mDice did not improve from 0.57535
Epoch 66/300
 - 7s - loss: 2154.5418 - acc: 0.9243 - mDice: 0.6459 - val_loss: 2827.2165 - val_acc: 0.9402 - val_mDice: 0.5327

Epoch 00066: val_mDice did not improve from 0.57535
Epoch 67/300
 - 7s - loss: 2147.4434 - acc: 0.9246 - mDice: 0.6470 - val_loss: 2632.1836 - val_acc: 0.9371 - val_mDice: 0.5564

Epoch 00067: val_mDice did not improve from 0.57535
Epoch 68/300
 - 7s - loss: 2135.2103 - acc: 0.9249 - mDice: 0.6485 - val_loss: 2659.5410 - val_acc: 0.9412 - val_mDice: 0.5514

Epoch 00068: val_mDice did not improve from 0.57535
Epoch 69/300
 - 7s - loss: 2131.1474 - acc: 0.9252 - mDice: 0.6490 - val_loss: 2558.2237 - val_acc: 0.9412 - val_mDice: 0.5661

Epoch 00069: val_mDice did not improve from 0.57535
Epoch 70/300
 - 7s - loss: 2138.1942 - acc: 0.9250 - mDice: 0.6479 - val_loss: 2718.5702 - val_acc: 0.9377 - val_mDice: 0.5456

Epoch 00070: val_mDice did not improve from 0.57535
Epoch 71/300
 - 7s - loss: 2146.4374 - acc: 0.9249 - mDice: 0.6470 - val_loss: 2721.1332 - val_acc: 0.9361 - val_mDice: 0.5455

Epoch 00071: val_mDice did not improve from 0.57535
Epoch 72/300
 - 7s - loss: 2119.0597 - acc: 0.9254 - mDice: 0.6505 - val_loss: 2627.4788 - val_acc: 0.9391 - val_mDice: 0.5538

Epoch 00072: val_mDice did not improve from 0.57535
Epoch 73/300
 - 7s - loss: 2132.3356 - acc: 0.9253 - mDice: 0.6489 - val_loss: 2579.5507 - val_acc: 0.9425 - val_mDice: 0.5611

Epoch 00073: val_mDice did not improve from 0.57535
Epoch 74/300
 - 7s - loss: 2122.3569 - acc: 0.9256 - mDice: 0.6500 - val_loss: 2691.9907 - val_acc: 0.9374 - val_mDice: 0.5472

Epoch 00074: val_mDice did not improve from 0.57535
Epoch 75/300
 - 7s - loss: 2122.4240 - acc: 0.9255 - mDice: 0.6501 - val_loss: 2629.8176 - val_acc: 0.9432 - val_mDice: 0.5563

Epoch 00075: val_mDice did not improve from 0.57535
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [16944.67804827009, 30901.02771577381, 12523.588192894345, 5175.632963634673, 5014.199776785715, 3710.750197637649, 3384.449730282738, 3175.3703729538693, 3064.1968122209823, 3254.6469377790177, 2882.8546549479165, 3123.741257440476, 2947.1484375, 3047.405006045387, 2919.7721237909227, 2856.5469098772323, 2924.8365769159227, 2853.9427373976932, 2939.871308826265, 2629.7416178385415, 2668.757986886161, 2736.7571149553573, 2843.6195475260415, 2622.130330403646, 2511.009835379464, 2704.6514253162204, 2743.0161714099704, 2847.7611316499256, 2531.151373000372, 2743.3253813244046, 2620.93655250186, 2660.2200608026415, 2966.4572085425966, 2587.2511247907364, 2799.852207728795, 3552.4821196056546, 2937.9220842633927, 2676.597476050967, 2725.018592471168, 2567.608157203311, 2573.4358956473216, 2775.5010753813244, 2951.443068731399, 2771.304481143043, 2465.1127813430057, 2646.813996814546, 2618.5441458565847, 3509.7730465843565, 5346.141502743676, 2736.162850516183, 2888.2449922107517, 2475.1494896298364, 2775.566425141834, 2794.600812639509, 2532.308026994978, 2679.9563743954614, 2577.8190336681546, 2756.2929338727677, 2610.4190383184523, 2561.390177408854, 2600.2237781343006, 2507.1701456705728, 2642.6887933640255, 2558.520222981771, 2721.6427946544827, 2827.216545468285, 2632.1835588727677, 2659.541038876488, 2558.2236851283483, 2718.570248558408, 2721.1332077752977, 2627.4788208007812, 2579.550731840588, 2691.99070812407, 2629.8175746372767], 'val_acc': [0.9033882674716768, 0.9047275696481977, 0.9047252989950634, 0.9075137547084263, 0.9097665094193959, 0.9138965010643005, 0.9160783120564052, 0.9197367145901635, 0.9258081373714265, 0.9276625258581979, 0.9247893634296599, 0.9282669425010681, 0.9285142052741278, 0.9206501955077762, 0.930153367065248, 0.9259569503012157, 0.9284432076272511, 0.9295673228445507, 0.9312316945620945, 0.9322321670395988, 0.931488091037387, 0.9260782769748143, 0.9256249921662467, 0.9291094371250698, 0.9340705020087106, 0.9322550410316104, 0.9299770991007487, 0.9345352564539228, 0.933447812284742, 0.9342651140122187, 0.9362271059127081, 0.9353319576808384, 0.934095717611767, 0.9360737204551697, 0.9367330613590422, 0.9285348256429037, 0.9353983686083839, 0.9365178772381374, 0.9373214102926708, 0.9395535730180287, 0.9378457069396973, 0.9358150362968445, 0.9368406676110768, 0.9390819753919329, 0.9424542387326559, 0.9394826179458982, 0.9412706011817569, 0.9284935763904026, 0.9176854491233826, 0.9417468139103481, 0.938246352331979, 0.9416094138508752, 0.9400778412818909, 0.9312362387066796, 0.9421291408084688, 0.9407921234766642, 0.9411767664409819, 0.937367232072921, 0.9427541125388372, 0.9430562995728993, 0.9418177576292128, 0.9419253695578802, 0.9401053133464995, 0.942010087626321, 0.942692294007256, 0.9402426963760739, 0.9370627403259277, 0.9412041987691607, 0.9411561091740926, 0.9377220698765346, 0.9361286702610198, 0.9391346148082188, 0.9425434952690488, 0.9373992426054818, 0.9431593503270831], 'val_mDice': [0.05057701947433608, 0.0045951755254507246, 0.13904408403184443, 0.3489656744613534, 0.35372396132775713, 0.456722671077365, 0.4819757118821144, 0.502315372583412, 0.5152897295497713, 0.4944447007562433, 0.5335112297463984, 0.5071615537717229, 0.5292935433487097, 0.5179507347444693, 0.5335993800489676, 0.5389795150785219, 0.5324860374842372, 0.5399777632029283, 0.5287785790860653, 0.5618245289439247, 0.5568720176815987, 0.548640560890947, 0.5394395259874207, 0.5600419519912629, 0.572015292942524, 0.5516091915113586, 0.5471182818568888, 0.5361694015917324, 0.5689782241270656, 0.5452099958700793, 0.559896610854637, 0.5542841635289646, 0.5215655490756035, 0.5605028963514737, 0.5378918097842307, 0.4569611989316486, 0.5218112181339946, 0.551925561257771, 0.5483733726044496, 0.5636506098366919, 0.5631651621134508, 0.5426396617577189, 0.5200297035986469, 0.5407782535822618, 0.5753492099188623, 0.5552044303289482, 0.5570588090590068, 0.46228244865224477, 0.32318126587841783, 0.5448025512908187, 0.5243945632662091, 0.5739116611934844, 0.5381327253722009, 0.5379233495110557, 0.5686263951162497, 0.5514272291745458, 0.5609997259009452, 0.5419651447307496, 0.5584589892200061, 0.5649850487354255, 0.5596772904197375, 0.5688995632032553, 0.5533472744836694, 0.5631180196290925, 0.5443318450734729, 0.5326587887746947, 0.556398901024035, 0.551434643921398, 0.5661045628644171, 0.5455955987175306, 0.5454632398628053, 0.5538255795836449, 0.5610934105657396, 0.5471632186146009, 0.5563092338187354], 'loss': [17015.860254414583, 9776.227559207515, 6739.212960756006, 5734.672688990355, 5079.453637615297, 4565.342242042155, 4089.154965755359, 3740.3563563543776, 3486.436529038567, 3320.438051163817, 3174.8866795895988, 3068.0201234569295, 2981.0500928835763, 2903.733264812045, 2854.093155016071, 2803.012931639872, 2756.378683995897, 2719.008265645145, 2670.6919057804516, 2636.647364942743, 2615.9513379536957, 2580.4062539536944, 2571.664142397573, 2543.621357753232, 2520.9428525490407, 2512.0531792126803, 2485.5384510423446, 2457.017682850832, 2435.74364340087, 2418.17742996407, 2415.3534015326777, 2400.4656689424883, 2379.8014906086582, 2364.90332212461, 2343.5853976324524, 2337.2245669198537, 2340.3926807798493, 2323.088384295512, 2306.9434861050236, 2309.832498774355, 2288.2921341910214, 2274.160314162434, 2281.316003443856, 2275.2441600169295, 2265.778145738068, 2258.575861886537, 2244.215356106424, 2246.614049043319, 2234.20387914366, 2230.0204781833263, 2229.7934168353577, 2199.685612416897, 2208.0739507930734, 2205.0309128534227, 2204.7388342965287, 2201.953126364966, 2182.603484301386, 2178.0949344138594, 2174.25907631722, 2170.004150367091, 2178.664771011438, 2157.846434181909, 2155.218351171084, 2152.048851235285, 2144.884058737401, 2154.541813376967, 2147.4434257641174, 2135.210305332517, 2131.1474143403884, 2138.1942395897345, 2146.437402946218, 2119.0597129749704, 2132.3355590279034, 2122.3569062238303, 2122.4239640803103], 'acc': [0.45112464544640724, 0.8271829273191885, 0.8680448551294728, 0.8736375431828768, 0.8774511174634401, 0.8809565520939258, 0.884899817566571, 0.8883891981163304, 0.8922250848389187, 0.8967055899342613, 0.9009384152883276, 0.9035101385734342, 0.9054785609727929, 0.9069340105964104, 0.9077254681084366, 0.9086788958590316, 0.9093326857284427, 0.909814872435115, 0.9105638532894114, 0.911027569876072, 0.9116749423120623, 0.912519511504051, 0.9123791347516165, 0.9129320628982714, 0.9133217680171571, 0.9135229205129141, 0.9141701542620992, 0.9145477887222204, 0.9151414505475193, 0.9153794010457262, 0.9156791962868496, 0.9161123017688374, 0.9164876858692121, 0.917026012302801, 0.9172081469409333, 0.9177426737076932, 0.9178069527838211, 0.9180526201242837, 0.9187423751628626, 0.9188589518852079, 0.9191629447320167, 0.9194503197762831, 0.9197098265522496, 0.9202337833597225, 0.9203744861623192, 0.9204813062351794, 0.9209420579188082, 0.9212116117948095, 0.9213648957394441, 0.9215269612627083, 0.9215375944348643, 0.9219443325433792, 0.9220155134282867, 0.9221864084368246, 0.9221439547039582, 0.9223130861182697, 0.9229120548943093, 0.9225963151406663, 0.923086470035728, 0.92352638937316, 0.9232938839724143, 0.9238406639235176, 0.9237416528979776, 0.9241212744898527, 0.9243080161177218, 0.9243120516865658, 0.9245946564287355, 0.9248713287218747, 0.9251998107006307, 0.9249720782909132, 0.9249484863542329, 0.9254356089276294, 0.9252635127596711, 0.9255786211200594, 0.9255153850620138], 'mDice': [0.05507038495694945, 0.16606719082310087, 0.2665697179055292, 0.3202888366859819, 0.36155273685318345, 0.399925483791084, 0.43829127080941077, 0.46867833717585944, 0.49281283194374803, 0.5094258391675587, 0.5247591805350051, 0.5363642105091875, 0.5460426104144598, 0.554700559840764, 0.5604014880560211, 0.5664959852466102, 0.5718855263296524, 0.5763206754733722, 0.581873137964227, 0.5859733181053075, 0.5883892895928554, 0.5928174260495968, 0.593804767188342, 0.5971884045592617, 0.5999471245989626, 0.6010947494992223, 0.6043445142174539, 0.6078487755315989, 0.6103501059840313, 0.6125330825704174, 0.6128914093543781, 0.6146225862496617, 0.6170929823166285, 0.6190762867788738, 0.6216573914926314, 0.6225836171059566, 0.6221504618097919, 0.6242445851190485, 0.6262639804867299, 0.6260361427605348, 0.6285881106279386, 0.6304579315007204, 0.629732356702107, 0.6303335165664918, 0.6315333044365786, 0.632515281295188, 0.6343536546332817, 0.6339715433093148, 0.6355710014663544, 0.6361614933403696, 0.6362156790530541, 0.6397891488635106, 0.6388949323348602, 0.6392251715072668, 0.6394842160053742, 0.639818185460988, 0.6421766671597532, 0.6428793725743099, 0.6433417175876536, 0.6438997786859109, 0.6428665973580777, 0.6454159473209958, 0.6457108715055351, 0.6462473872081609, 0.647024395816561, 0.6459132753426063, 0.6469745391109717, 0.6484599327085012, 0.6489709551356904, 0.6479486630834871, 0.6469922004027336, 0.6505490007004298, 0.648941018044983, 0.6500318445220765, 0.6501237170439316]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.30s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.06s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:04,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:10,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:02,  1.71s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:36,  1.62s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:58,  1.71s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:38,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:59,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:49,  1.69s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:11,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:25,  1.84s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:56,  1.74s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:20,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:58,  1.76s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:08,  1.80s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:20,  1.86s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:32,  1.91s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:09,  1.83s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:13,  1.85s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:47,  1.76s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:52,  1.78s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:05,  1.84s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:50,  1.80s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:29,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:45,  1.79s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<08:02,  1.86s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:42,  1.79s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:51,  1.83s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:52,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:53<08:02,  1.89s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:12,  1.94s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:43,  1.83s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:41,  1.83s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:52,  1.89s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:42,  1.86s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:53,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:31,  1.84s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:33,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:17,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<07:03,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:13,  1.79s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:35,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:14,  1.81s/it]predicting train subjects:  16%|█▌        | 46/285 [01:22<07:22,  1.85s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<07:01,  1.77s/it]predicting train subjects:  17%|█▋        | 48/285 [01:26<07:03,  1.79s/it]predicting train subjects:  17%|█▋        | 49/285 [01:28<07:14,  1.84s/it]predicting train subjects:  18%|█▊        | 50/285 [01:30<07:10,  1.83s/it]predicting train subjects:  18%|█▊        | 51/285 [01:32<07:20,  1.88s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:58,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:35<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:37<07:19,  1.90s/it]predicting train subjects:  19%|█▉        | 55/285 [01:39<06:56,  1.81s/it]predicting train subjects:  20%|█▉        | 56/285 [01:41<07:04,  1.85s/it]predicting train subjects:  20%|██        | 57/285 [01:42<06:42,  1.77s/it]predicting train subjects:  20%|██        | 58/285 [01:44<06:48,  1.80s/it]predicting train subjects:  21%|██        | 59/285 [01:46<06:58,  1.85s/it]predicting train subjects:  21%|██        | 60/285 [01:48<07:06,  1.90s/it]predicting train subjects:  21%|██▏       | 61/285 [01:50<06:45,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [01:52<06:47,  1.83s/it]predicting train subjects:  22%|██▏       | 63/285 [01:54<06:51,  1.85s/it]predicting train subjects:  22%|██▏       | 64/285 [01:55<06:35,  1.79s/it]predicting train subjects:  23%|██▎       | 65/285 [01:57<06:42,  1.83s/it]predicting train subjects:  23%|██▎       | 66/285 [01:59<06:36,  1.81s/it]predicting train subjects:  24%|██▎       | 67/285 [02:01<06:42,  1.85s/it]predicting train subjects:  24%|██▍       | 68/285 [02:02<06:25,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:04<06:25,  1.78s/it]predicting train subjects:  25%|██▍       | 70/285 [02:06<06:28,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:08<06:33,  1.84s/it]predicting train subjects:  25%|██▌       | 72/285 [02:10<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 73/285 [02:11<06:17,  1.78s/it]predicting train subjects:  26%|██▌       | 74/285 [02:13<06:13,  1.77s/it]predicting train subjects:  26%|██▋       | 75/285 [02:15<06:20,  1.81s/it]predicting train subjects:  27%|██▋       | 76/285 [02:17<06:20,  1.82s/it]predicting train subjects:  27%|██▋       | 77/285 [02:19<06:10,  1.78s/it]predicting train subjects:  27%|██▋       | 78/285 [02:20<05:58,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:22<06:02,  1.76s/it]predicting train subjects:  28%|██▊       | 80/285 [02:24<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:25<05:50,  1.72s/it]predicting train subjects:  29%|██▉       | 82/285 [02:27<05:49,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:29<05:44,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:31<05:41,  1.70s/it]predicting train subjects:  30%|██▉       | 85/285 [02:32<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:34<05:53,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:36<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:38<05:47,  1.76s/it]predicting train subjects:  31%|███       | 89/285 [02:40<05:46,  1.77s/it]predicting train subjects:  32%|███▏      | 90/285 [02:41<05:49,  1.79s/it]predicting train subjects:  32%|███▏      | 91/285 [02:43<05:38,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:45<05:50,  1.81s/it]predicting train subjects:  33%|███▎      | 93/285 [02:47<05:40,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:48<05:39,  1.78s/it]predicting train subjects:  33%|███▎      | 95/285 [02:50<05:46,  1.83s/it]predicting train subjects:  34%|███▎      | 96/285 [02:52<05:39,  1.80s/it]predicting train subjects:  34%|███▍      | 97/285 [02:54<05:40,  1.81s/it]predicting train subjects:  34%|███▍      | 98/285 [02:56<05:38,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [02:58<05:34,  1.80s/it]predicting train subjects:  35%|███▌      | 100/285 [02:59<05:34,  1.81s/it]predicting train subjects:  35%|███▌      | 101/285 [03:01<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:03<05:37,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:05<05:27,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:07<05:25,  1.80s/it]predicting train subjects:  37%|███▋      | 105/285 [03:09<05:28,  1.82s/it]predicting train subjects:  37%|███▋      | 106/285 [03:10<05:18,  1.78s/it]predicting train subjects:  38%|███▊      | 107/285 [03:12<05:20,  1.80s/it]predicting train subjects:  38%|███▊      | 108/285 [03:14<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:16<05:16,  1.80s/it]predicting train subjects:  39%|███▊      | 110/285 [03:17<05:18,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:19<05:08,  1.77s/it]predicting train subjects:  39%|███▉      | 112/285 [03:21<05:14,  1.82s/it]predicting train subjects:  40%|███▉      | 113/285 [03:23<05:20,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:25<05:16,  1.85s/it]predicting train subjects:  40%|████      | 115/285 [03:27<05:24,  1.91s/it]predicting train subjects:  41%|████      | 116/285 [03:29<05:26,  1.93s/it]predicting train subjects:  41%|████      | 117/285 [03:31<05:12,  1.86s/it]predicting train subjects:  41%|████▏     | 118/285 [03:32<05:01,  1.81s/it]predicting train subjects:  42%|████▏     | 119/285 [03:34<05:04,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:36<04:53,  1.78s/it]predicting train subjects:  42%|████▏     | 121/285 [03:38<04:49,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:39<04:35,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:41<04:21,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:42<04:21,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:44<04:12,  1.58s/it]predicting train subjects:  44%|████▍     | 126/285 [03:45<04:05,  1.54s/it]predicting train subjects:  45%|████▍     | 127/285 [03:47<03:59,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:48<04:06,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:50<03:58,  1.53s/it]predicting train subjects:  46%|████▌     | 130/285 [03:51<03:54,  1.51s/it]predicting train subjects:  46%|████▌     | 131/285 [03:53<03:50,  1.50s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<03:53,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [03:56<03:49,  1.51s/it]predicting train subjects:  47%|████▋     | 134/285 [03:57<03:44,  1.49s/it]predicting train subjects:  47%|████▋     | 135/285 [03:59<03:39,  1.46s/it]predicting train subjects:  48%|████▊     | 136/285 [04:00<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [04:02<03:43,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [04:03<03:45,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [04:05<03:49,  1.57s/it]predicting train subjects:  49%|████▉     | 140/285 [04:07<03:51,  1.60s/it]predicting train subjects:  49%|████▉     | 141/285 [04:08<03:40,  1.53s/it]predicting train subjects:  50%|████▉     | 142/285 [04:09<03:36,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:11<03:34,  1.51s/it]predicting train subjects:  51%|█████     | 144/285 [04:12<03:37,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:14<03:33,  1.52s/it]predicting train subjects:  51%|█████     | 146/285 [04:16<03:40,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:17<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:19<03:33,  1.56s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:20<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:22<03:22,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:23<03:25,  1.53s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:25<03:21,  1.51s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:26<03:18,  1.50s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:28<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:29<03:16,  1.51s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:31<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:32<03:13,  1.51s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:10,  1.50s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:35<03:04,  1.47s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:03,  1.47s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:38<03:11,  1.54s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<03:07,  1.53s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:41<03:09,  1.55s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<03:04,  1.52s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:44<03:00,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:46<03:01,  1.52s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:47<03:01,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:49<02:54,  1.49s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:50<02:53,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:52<02:48,  1.47s/it]predicting train subjects:  60%|██████    | 171/285 [04:53<02:47,  1.47s/it]predicting train subjects:  60%|██████    | 172/285 [04:55<02:51,  1.52s/it]predicting train subjects:  61%|██████    | 173/285 [04:56<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [04:58<02:45,  1.49s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:59<02:48,  1.53s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:01<02:51,  1.57s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:03<02:47,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:04<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:05<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:07<02:49,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:09<02:50,  1.64s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:11<02:50,  1.65s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:12<02:41,  1.58s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:14<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:15<02:31,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:17<02:39,  1.62s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:19<02:45,  1.69s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:21<02:49,  1.74s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:22<02:38,  1.65s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:24<02:33,  1.61s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:25<02:34,  1.64s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:27<02:34,  1.66s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:28<02:24,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:30<02:20,  1.54s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:31<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:33<02:25,  1.64s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:35<02:29,  1.70s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:37<02:31,  1.74s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:38<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:40<02:13,  1.57s/it]predicting train subjects:  71%|███████   | 201/285 [05:42<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:43<02:17,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:45<02:15,  1.65s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:46<02:07,  1.57s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:48<02:01,  1.52s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:49<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:51<02:03,  1.58s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:53<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:54<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:56<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:57<01:52,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:59<01:52,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:00<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:02<01:47,  1.52s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:04<01:52,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:05<01:45,  1.52s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:07<01:49,  1.61s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:08<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:10<01:52,  1.70s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:12<01:46,  1.63s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:13<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:15<01:42,  1.62s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:16<01:36,  1.55s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:18<01:33,  1.53s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:19<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:21<01:34,  1.61s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:23<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:25<01:37,  1.72s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:33,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [06:28<01:27,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:22,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:31<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:32<01:19,  1.53s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:34<01:22,  1.62s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:36<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:37<01:22,  1.68s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:39<01:22,  1.72s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:41<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:43<01:20,  1.75s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:44<01:14,  1.65s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:46<01:10,  1.59s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:47<01:06,  1.56s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:49<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:50<01:06,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:52<01:01,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:54<01:04,  1.65s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:56<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:57<01:02,  1.70s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:59<00:57,  1.61s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:00<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:02<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:03<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:05<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:07<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:08<00:50,  1.69s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:10<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [07:11<00:43,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [07:13<00:44,  1.64s/it]predicting train subjects:  91%|█████████ | 259/285 [07:15<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:16<00:39,  1.56s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:17<00:36,  1.53s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:19<00:34,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:20<00:31,  1.45s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:22<00:33,  1.59s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:24<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:25<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:27<00:27,  1.55s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:29<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:30<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:32<00:23,  1.59s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:33<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:35<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:36<00:18,  1.56s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:38<00:16,  1.52s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:40<00:16,  1.62s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:42<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:43<00:12,  1.60s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:44<00:10,  1.55s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:46<00:09,  1.56s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:47<00:07,  1.52s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:49<00:05,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:50<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:52<00:03,  1.58s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:54<00:01,  1.65s/it]predicting train subjects: 100%|██████████| 285/285 [07:56<00:00,  1.71s/it]
Loading train:   0%|          | 0/114 [00:00<?, ?it/s]Loading train:   1%|          | 1/114 [00:01<03:02,  1.61s/it]Loading train:   2%|▏         | 2/114 [00:03<02:58,  1.59s/it]Loading train:   3%|▎         | 3/114 [00:04<02:54,  1.57s/it]Loading train:   4%|▎         | 4/114 [00:05<02:38,  1.44s/it]Loading train:   4%|▍         | 5/114 [00:07<02:45,  1.52s/it]Loading train:   5%|▌         | 6/114 [00:09<02:45,  1.53s/it]Loading train:   6%|▌         | 7/114 [00:09<02:21,  1.33s/it]Loading train:   7%|▋         | 8/114 [00:10<02:04,  1.18s/it]Loading train:   8%|▊         | 9/114 [00:11<01:59,  1.14s/it]Loading train:   9%|▉         | 10/114 [00:12<01:52,  1.08s/it]Loading train:  10%|▉         | 11/114 [00:13<01:55,  1.12s/it]Loading train:  11%|█         | 12/114 [00:14<01:46,  1.05s/it]Loading train:  11%|█▏        | 13/114 [00:15<01:39,  1.01it/s]Loading train:  12%|█▏        | 14/114 [00:16<01:40,  1.00s/it]Loading train:  13%|█▎        | 15/114 [00:18<01:49,  1.11s/it]Loading train:  14%|█▍        | 16/114 [00:19<01:53,  1.15s/it]Loading train:  15%|█▍        | 17/114 [00:20<01:54,  1.18s/it]Loading train:  16%|█▌        | 18/114 [00:21<01:45,  1.10s/it]Loading train:  17%|█▋        | 19/114 [00:22<01:36,  1.02s/it]Loading train:  18%|█▊        | 20/114 [00:23<01:37,  1.04s/it]Loading train:  18%|█▊        | 21/114 [00:24<01:36,  1.03s/it]Loading train:  19%|█▉        | 22/114 [00:25<01:37,  1.06s/it]Loading train:  20%|██        | 23/114 [00:26<01:30,  1.00it/s]Loading train:  21%|██        | 24/114 [00:27<01:28,  1.01it/s]Loading train:  22%|██▏       | 25/114 [00:28<01:29,  1.01s/it]Loading train:  23%|██▎       | 26/114 [00:29<01:32,  1.05s/it]Loading train:  24%|██▎       | 27/114 [00:30<01:33,  1.07s/it]Loading train:  25%|██▍       | 28/114 [00:31<01:31,  1.06s/it]Loading train:  25%|██▌       | 29/114 [00:32<01:26,  1.01s/it]Loading train:  26%|██▋       | 30/114 [00:34<01:37,  1.16s/it]Loading train:  27%|██▋       | 31/114 [00:35<01:39,  1.20s/it]Loading train:  28%|██▊       | 32/114 [00:36<01:38,  1.20s/it]Loading train:  29%|██▉       | 33/114 [00:37<01:29,  1.11s/it]Loading train:  30%|██▉       | 34/114 [00:38<01:26,  1.08s/it]Loading train:  31%|███       | 35/114 [00:39<01:21,  1.04s/it]Loading train:  32%|███▏      | 36/114 [00:40<01:24,  1.09s/it]Loading train:  32%|███▏      | 37/114 [00:41<01:23,  1.09s/it]Loading train:  33%|███▎      | 38/114 [00:42<01:21,  1.08s/it]Loading train:  34%|███▍      | 39/114 [00:43<01:17,  1.03s/it]Loading train:  35%|███▌      | 40/114 [00:44<01:18,  1.07s/it]Loading train:  36%|███▌      | 41/114 [00:46<01:19,  1.09s/it]Loading train:  37%|███▋      | 42/114 [00:47<01:20,  1.11s/it]Loading train:  38%|███▊      | 43/114 [00:48<01:15,  1.07s/it]Loading train:  39%|███▊      | 44/114 [00:49<01:17,  1.11s/it]Loading train:  39%|███▉      | 45/114 [00:50<01:13,  1.07s/it]Loading train:  40%|████      | 46/114 [00:51<01:12,  1.07s/it]Loading train:  41%|████      | 47/114 [00:52<01:14,  1.11s/it]Loading train:  42%|████▏     | 48/114 [00:53<01:09,  1.05s/it]Loading train:  43%|████▎     | 49/114 [00:54<01:06,  1.02s/it]Loading train:  44%|████▍     | 50/114 [00:55<01:01,  1.03it/s]Loading train:  45%|████▍     | 51/114 [00:56<01:04,  1.02s/it]Loading train:  46%|████▌     | 52/114 [00:57<01:00,  1.03it/s]Loading train:  46%|████▋     | 53/114 [00:58<00:58,  1.04it/s]Loading train:  47%|████▋     | 54/114 [00:59<00:55,  1.08it/s]Loading train:  48%|████▊     | 55/114 [01:00<00:55,  1.06it/s]Loading train:  49%|████▉     | 56/114 [01:01<00:55,  1.04it/s]Loading train:  50%|█████     | 57/114 [01:02<00:56,  1.02it/s]Loading train:  51%|█████     | 58/114 [01:03<00:56,  1.00s/it]Loading train:  52%|█████▏    | 59/114 [01:03<00:52,  1.06it/s]Loading train:  53%|█████▎    | 60/114 [01:04<00:50,  1.07it/s]Loading train:  54%|█████▎    | 61/114 [01:05<00:50,  1.06it/s]Loading train:  54%|█████▍    | 62/114 [01:06<00:47,  1.10it/s]Loading train:  55%|█████▌    | 63/114 [01:07<00:51,  1.01s/it]Loading train:  56%|█████▌    | 64/114 [01:08<00:48,  1.02it/s]Loading train:  57%|█████▋    | 65/114 [01:10<00:51,  1.05s/it]Loading train:  58%|█████▊    | 66/114 [01:11<00:50,  1.06s/it]Loading train:  59%|█████▉    | 67/114 [01:12<00:53,  1.13s/it]Loading train:  60%|█████▉    | 68/114 [01:13<00:50,  1.09s/it]Loading train:  61%|██████    | 69/114 [01:14<00:47,  1.07s/it]Loading train:  61%|██████▏   | 70/114 [01:15<00:43,  1.00it/s]Loading train:  62%|██████▏   | 71/114 [01:16<00:40,  1.07it/s]Loading train:  63%|██████▎   | 72/114 [01:16<00:37,  1.13it/s]Loading train:  64%|██████▍   | 73/114 [01:17<00:38,  1.06it/s]Loading train:  65%|██████▍   | 74/114 [01:18<00:36,  1.10it/s]Loading train:  66%|██████▌   | 75/114 [01:19<00:37,  1.03it/s]Loading train:  67%|██████▋   | 76/114 [01:20<00:37,  1.01it/s]Loading train:  68%|██████▊   | 77/114 [01:21<00:35,  1.04it/s]Loading train:  68%|██████▊   | 78/114 [01:22<00:35,  1.01it/s]Loading train:  69%|██████▉   | 79/114 [01:23<00:32,  1.07it/s]Loading train:  70%|███████   | 80/114 [01:24<00:33,  1.00it/s]Loading train:  71%|███████   | 81/114 [01:25<00:32,  1.01it/s]Loading train:  72%|███████▏  | 82/114 [01:26<00:34,  1.06s/it]Loading train:  73%|███████▎  | 83/114 [01:28<00:34,  1.10s/it]Loading train:  74%|███████▎  | 84/114 [01:29<00:33,  1.10s/it]Loading train:  75%|███████▍  | 85/114 [01:30<00:30,  1.04s/it]Loading train:  75%|███████▌  | 86/114 [01:31<00:28,  1.00s/it]Loading train:  76%|███████▋  | 87/114 [01:32<00:29,  1.09s/it]Loading train:  77%|███████▋  | 88/114 [01:33<00:27,  1.05s/it]Loading train:  78%|███████▊  | 89/114 [01:34<00:27,  1.09s/it]Loading train:  79%|███████▉  | 90/114 [01:35<00:24,  1.04s/it]Loading train:  80%|███████▉  | 91/114 [01:36<00:23,  1.02s/it]Loading train:  81%|████████  | 92/114 [01:37<00:21,  1.01it/s]Loading train:  82%|████████▏ | 93/114 [01:38<00:21,  1.03s/it]Loading train:  82%|████████▏ | 94/114 [01:39<00:21,  1.08s/it]Loading train:  83%|████████▎ | 95/114 [01:40<00:21,  1.11s/it]Loading train:  84%|████████▍ | 96/114 [01:41<00:20,  1.11s/it]Loading train:  85%|████████▌ | 97/114 [01:43<00:18,  1.09s/it]Loading train:  86%|████████▌ | 98/114 [01:44<00:18,  1.15s/it]Loading train:  87%|████████▋ | 99/114 [01:45<00:16,  1.08s/it]Loading train:  88%|████████▊ | 100/114 [01:46<00:15,  1.11s/it]Loading train:  89%|████████▊ | 101/114 [01:47<00:13,  1.07s/it]Loading train:  89%|████████▉ | 102/114 [01:48<00:12,  1.06s/it]Loading train:  90%|█████████ | 103/114 [01:49<00:11,  1.04s/it]Loading train:  91%|█████████ | 104/114 [01:50<00:11,  1.14s/it]Loading train:  92%|█████████▏| 105/114 [01:52<00:10,  1.17s/it]Loading train:  93%|█████████▎| 106/114 [01:52<00:08,  1.09s/it]Loading train:  94%|█████████▍| 107/114 [01:53<00:07,  1.02s/it]Loading train:  95%|█████████▍| 108/114 [01:54<00:06,  1.03s/it]Loading train:  96%|█████████▌| 109/114 [01:55<00:05,  1.03s/it]Loading train:  96%|█████████▋| 110/114 [01:56<00:04,  1.00s/it]Loading train:  97%|█████████▋| 111/114 [01:57<00:02,  1.05it/s]Loading train:  98%|█████████▊| 112/114 [01:58<00:01,  1.01it/s]Loading train:  99%|█████████▉| 113/114 [01:59<00:01,  1.03s/it]Loading train: 100%|██████████| 114/114 [02:01<00:00,  1.13s/it]
concatenating: train:   0%|          | 0/114 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 11/114 [00:00<00:00, 106.16it/s]concatenating: train:  29%|██▉       | 33/114 [00:00<00:00, 125.55it/s]concatenating: train:  54%|█████▎    | 61/114 [00:00<00:00, 150.31it/s]concatenating: train:  81%|████████  | 92/114 [00:00<00:00, 177.22it/s]concatenating: train: 100%|██████████| 114/114 [00:00<00:00, 237.64it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 80.96it/s]2019-07-07 21:55:03.487759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 21:55:03.487890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 21:55:03.487910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 21:55:03.487922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 21:55:03.568026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/45 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/45 [00:00<00:08,  5.19it/s]loading the weights for Res Unet:   7%|▋         | 3/45 [00:00<00:06,  6.18it/s]loading the weights for Res Unet:   9%|▉         | 4/45 [00:00<00:07,  5.28it/s]loading the weights for Res Unet:  20%|██        | 9/45 [00:00<00:05,  6.89it/s]loading the weights for Res Unet:  24%|██▍       | 11/45 [00:01<00:04,  7.41it/s]loading the weights for Res Unet:  27%|██▋       | 12/45 [00:01<00:04,  6.67it/s]loading the weights for Res Unet:  29%|██▉       | 13/45 [00:01<00:05,  5.80it/s]loading the weights for Res Unet:  40%|████      | 18/45 [00:01<00:03,  7.49it/s]loading the weights for Res Unet:  44%|████▍     | 20/45 [00:01<00:03,  7.89it/s]loading the weights for Res Unet:  49%|████▉     | 22/45 [00:05<00:13,  1.70it/s]loading the weights for Res Unet:  58%|█████▊    | 26/45 [00:05<00:08,  2.33it/s]loading the weights for Res Unet:  62%|██████▏   | 28/45 [00:05<00:05,  3.03it/s]loading the weights for Res Unet:  67%|██████▋   | 30/45 [00:05<00:03,  3.80it/s]loading the weights for Res Unet:  71%|███████   | 32/45 [00:06<00:03,  3.98it/s]loading the weights for Res Unet:  80%|████████  | 36/45 [00:06<00:01,  5.23it/s]loading the weights for Res Unet:  84%|████████▍ | 38/45 [00:06<00:01,  6.08it/s]loading the weights for Res Unet:  89%|████████▉ | 40/45 [00:06<00:00,  6.75it/s]loading the weights for Res Unet:  93%|█████████▎| 42/45 [00:08<00:00,  3.42it/s]loading the weights for Res Unet: 100%|██████████| 45/45 [00:08<00:00,  5.49it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 48, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 48, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 48, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 48, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 48, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 48, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 48, 48, 21)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 21)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 24, 21)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 24, 40)   7600        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 24, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 24, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 24, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 24, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 24, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 24, 24, 61)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 61)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 12, 61)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 12, 80)   44000       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 12, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 12, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 12, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 12, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 12, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 12, 12, 141)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 12, 141)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 24, 40)   22600       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 24, 101)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 24, 40)   36400       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 24, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 24, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 24, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 24, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 24, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 24, 24, 141)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 24, 141)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 48, 20)   11300       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 48, 41)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 48, 20)   7400        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 48, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 48, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 48, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 48, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 48, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 48, 48, 61)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 48, 61)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 48, 13)   806         dropout_5[0][0]                  
==================================================================================================
Total params: 225,706
Trainable params: 49,786
Non-trainable params: 175,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.73254098e-02 3.02898814e-02 7.22497368e-02 9.58419340e-03
 2.74806820e-02 7.57157277e-03 8.31531159e-02 1.00270585e-01
 9.14302159e-02 1.28144660e-02 2.77094786e-01 2.20481136e-01
 2.54218542e-04]
Train on 7083 samples, validate on 179 samples
Epoch 1/300
 - 14s - loss: 14580.2854 - acc: 0.4768 - mDice: 0.0729 - val_loss: 6200.5723 - val_acc: 0.9176 - val_mDice: 0.2776

Epoch 00001: val_mDice improved from -inf to 0.27760, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 4s - loss: 5710.8371 - acc: 0.8968 - mDice: 0.3213 - val_loss: 4088.3713 - val_acc: 0.9233 - val_mDice: 0.4090

Epoch 00002: val_mDice improved from 0.27760 to 0.40900, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 4s - loss: 3229.5348 - acc: 0.9115 - mDice: 0.4970 - val_loss: 3006.2908 - val_acc: 0.9322 - val_mDice: 0.5096

Epoch 00003: val_mDice improved from 0.40900 to 0.50958, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 5s - loss: 2553.4372 - acc: 0.9175 - mDice: 0.5724 - val_loss: 2958.6784 - val_acc: 0.9330 - val_mDice: 0.5216

Epoch 00004: val_mDice improved from 0.50958 to 0.52163, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 4s - loss: 2241.5436 - acc: 0.9228 - mDice: 0.6119 - val_loss: 2264.8169 - val_acc: 0.9395 - val_mDice: 0.5844

Epoch 00005: val_mDice improved from 0.52163 to 0.58440, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 4s - loss: 2060.4469 - acc: 0.9277 - mDice: 0.6361 - val_loss: 2264.2689 - val_acc: 0.9425 - val_mDice: 0.5890

Epoch 00006: val_mDice improved from 0.58440 to 0.58895, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 4s - loss: 1933.6650 - acc: 0.9317 - mDice: 0.6541 - val_loss: 2147.5879 - val_acc: 0.9452 - val_mDice: 0.6046

Epoch 00007: val_mDice improved from 0.58895 to 0.60465, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 4s - loss: 1821.3158 - acc: 0.9350 - mDice: 0.6700 - val_loss: 2209.1504 - val_acc: 0.9456 - val_mDice: 0.5975

Epoch 00008: val_mDice did not improve from 0.60465
Epoch 9/300
 - 4s - loss: 1740.9059 - acc: 0.9372 - mDice: 0.6817 - val_loss: 2188.6631 - val_acc: 0.9465 - val_mDice: 0.6003

Epoch 00009: val_mDice did not improve from 0.60465
Epoch 10/300
 - 4s - loss: 1697.5722 - acc: 0.9387 - mDice: 0.6884 - val_loss: 2120.3476 - val_acc: 0.9462 - val_mDice: 0.6085

Epoch 00010: val_mDice improved from 0.60465 to 0.60850, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 4s - loss: 1624.2456 - acc: 0.9404 - mDice: 0.6992 - val_loss: 2164.7073 - val_acc: 0.9469 - val_mDice: 0.6017

Epoch 00011: val_mDice did not improve from 0.60850
Epoch 12/300
 - 4s - loss: 1581.6849 - acc: 0.9413 - mDice: 0.7056 - val_loss: 2136.4059 - val_acc: 0.9465 - val_mDice: 0.6034

Epoch 00012: val_mDice did not improve from 0.60850
Epoch 13/300
 - 4s - loss: 1556.6424 - acc: 0.9425 - mDice: 0.7099 - val_loss: 2414.9701 - val_acc: 0.9470 - val_mDice: 0.5861

Epoch 00013: val_mDice did not improve from 0.60850
Epoch 14/300
 - 4s - loss: 1505.8626 - acc: 0.9433 - mDice: 0.7175 - val_loss: 2294.3545 - val_acc: 0.9448 - val_mDice: 0.5867

Epoch 00014: val_mDice did not improve from 0.60850
Epoch 15/300
 - 4s - loss: 1486.2950 - acc: 0.9440 - mDice: 0.7206 - val_loss: 2269.8783 - val_acc: 0.9459 - val_mDice: 0.5967

Epoch 00015: val_mDice did not improve from 0.60850
Epoch 16/300
 - 4s - loss: 1455.6304 - acc: 0.9447 - mDice: 0.7253 - val_loss: 2248.4252 - val_acc: 0.9466 - val_mDice: 0.5962

Epoch 00016: val_mDice did not improve from 0.60850
Epoch 17/300
 - 4s - loss: 1425.1360 - acc: 0.9454 - mDice: 0.7301 - val_loss: 2295.4312 - val_acc: 0.9435 - val_mDice: 0.5807

Epoch 00017: val_mDice did not improve from 0.60850
Epoch 18/300
 - 4s - loss: 1418.1034 - acc: 0.9457 - mDice: 0.7311 - val_loss: 2263.3160 - val_acc: 0.9450 - val_mDice: 0.5916

Epoch 00018: val_mDice did not improve from 0.60850
Epoch 19/300
 - 4s - loss: 1380.1854 - acc: 0.9465 - mDice: 0.7372 - val_loss: 2336.4385 - val_acc: 0.9469 - val_mDice: 0.5955

Epoch 00019: val_mDice did not improve from 0.60850
Epoch 20/300
 - 4s - loss: 1367.4863 - acc: 0.9468 - mDice: 0.7393 - val_loss: 2384.2429 - val_acc: 0.9447 - val_mDice: 0.5847

Epoch 00020: val_mDice did not improve from 0.60850
Epoch 21/300
 - 4s - loss: 1348.6785 - acc: 0.9473 - mDice: 0.7424 - val_loss: 2318.5353 - val_acc: 0.9447 - val_mDice: 0.5869

Epoch 00021: val_mDice did not improve from 0.60850
Epoch 22/300
 - 4s - loss: 1325.4504 - acc: 0.9477 - mDice: 0.7461 - val_loss: 2136.6737 - val_acc: 0.9481 - val_mDice: 0.6088

Epoch 00022: val_mDice improved from 0.60850 to 0.60877, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 4s - loss: 1322.3257 - acc: 0.9479 - mDice: 0.7466 - val_loss: 2361.8755 - val_acc: 0.9470 - val_mDice: 0.5833

Epoch 00023: val_mDice did not improve from 0.60877
Epoch 24/300
 - 4s - loss: 1305.5265 - acc: 0.9485 - mDice: 0.7494 - val_loss: 2325.7603 - val_acc: 0.9480 - val_mDice: 0.5914

Epoch 00024: val_mDice did not improve from 0.60877
Epoch 25/300
 - 4s - loss: 1289.4445 - acc: 0.9489 - mDice: 0.7520 - val_loss: 2220.7760 - val_acc: 0.9462 - val_mDice: 0.5967

Epoch 00025: val_mDice did not improve from 0.60877
Epoch 26/300
 - 4s - loss: 1273.2599 - acc: 0.9491 - mDice: 0.7545 - val_loss: 2142.1424 - val_acc: 0.9478 - val_mDice: 0.6052

Epoch 00026: val_mDice did not improve from 0.60877
Epoch 27/300
 - 4s - loss: 1263.8638 - acc: 0.9496 - mDice: 0.7562 - val_loss: 2261.2977 - val_acc: 0.9475 - val_mDice: 0.5930

Epoch 00027: val_mDice did not improve from 0.60877
Epoch 28/300
 - 4s - loss: 1245.4144 - acc: 0.9500 - mDice: 0.7594 - val_loss: 2227.0435 - val_acc: 0.9465 - val_mDice: 0.5937

Epoch 00028: val_mDice did not improve from 0.60877
Epoch 29/300
 - 4s - loss: 1233.4450 - acc: 0.9502 - mDice: 0.7610 - val_loss: 2387.3010 - val_acc: 0.9447 - val_mDice: 0.5788

Epoch 00029: val_mDice did not improve from 0.60877
Epoch 30/300
 - 4s - loss: 1221.8259 - acc: 0.9504 - mDice: 0.7630 - val_loss: 2282.3155 - val_acc: 0.9471 - val_mDice: 0.5880

Epoch 00030: val_mDice did not improve from 0.60877
Epoch 31/300
 - 4s - loss: 1220.4350 - acc: 0.9506 - mDice: 0.7634 - val_loss: 2171.0223 - val_acc: 0.9452 - val_mDice: 0.5919

Epoch 00031: val_mDice did not improve from 0.60877
Epoch 32/300
 - 4s - loss: 1209.7366 - acc: 0.9507 - mDice: 0.7651 - val_loss: 2444.8062 - val_acc: 0.9469 - val_mDice: 0.5663

Epoch 00032: val_mDice did not improve from 0.60877
Epoch 33/300
 - 4s - loss: 1195.8787 - acc: 0.9511 - mDice: 0.7675 - val_loss: 2237.5796 - val_acc: 0.9464 - val_mDice: 0.5874

Epoch 00033: val_mDice did not improve from 0.60877
Epoch 34/300
 - 4s - loss: 1171.6612 - acc: 0.9515 - mDice: 0.7714 - val_loss: 2361.5205 - val_acc: 0.9462 - val_mDice: 0.5757

Epoch 00034: val_mDice did not improve from 0.60877
Epoch 35/300
 - 4s - loss: 1173.5818 - acc: 0.9516 - mDice: 0.7711 - val_loss: 2205.7898 - val_acc: 0.9473 - val_mDice: 0.5939

Epoch 00035: val_mDice did not improve from 0.60877
Epoch 36/300
 - 4s - loss: 1169.8538 - acc: 0.9518 - mDice: 0.7718 - val_loss: 2456.3106 - val_acc: 0.9465 - val_mDice: 0.5663

Epoch 00036: val_mDice did not improve from 0.60877
Epoch 37/300
 - 4s - loss: 1153.9308 - acc: 0.9521 - mDice: 0.7745 - val_loss: 2312.7923 - val_acc: 0.9474 - val_mDice: 0.5822

Epoch 00037: val_mDice did not improve from 0.60877
Epoch 38/300
 - 4s - loss: 1142.2784 - acc: 0.9522 - mDice: 0.7763 - val_loss: 2206.2445 - val_acc: 0.9458 - val_mDice: 0.5896

Epoch 00038: val_mDice did not improve from 0.60877
Epoch 39/300
 - 4s - loss: 1142.7381 - acc: 0.9524 - mDice: 0.7763 - val_loss: 2269.7635 - val_acc: 0.9470 - val_mDice: 0.5862

Epoch 00039: val_mDice did not improve from 0.60877
Epoch 40/300
 - 4s - loss: 1131.2911 - acc: 0.9527 - mDice: 0.7782 - val_loss: 2280.5882 - val_acc: 0.9462 - val_mDice: 0.5850

Epoch 00040: val_mDice did not improve from 0.60877
Epoch 41/300
 - 4s - loss: 1137.6455 - acc: 0.9527 - mDice: 0.7772 - val_loss: 2244.7338 - val_acc: 0.9469 - val_mDice: 0.5882

Epoch 00041: val_mDice did not improve from 0.60877
Epoch 42/300
 - 4s - loss: 1123.7005 - acc: 0.9529 - mDice: 0.7795 - val_loss: 2215.2657 - val_acc: 0.9474 - val_mDice: 0.5932

Epoch 00042: val_mDice did not improve from 0.60877
Epoch 43/300
 - 4s - loss: 1132.9729 - acc: 0.9530 - mDice: 0.7780 - val_loss: 2362.8993 - val_acc: 0.9479 - val_mDice: 0.5753

Epoch 00043: val_mDice did not improve from 0.60877
Epoch 44/300
 - 4s - loss: 1108.5953 - acc: 0.9533 - mDice: 0.7821 - val_loss: 2302.8702 - val_acc: 0.9462 - val_mDice: 0.5829

Epoch 00044: val_mDice did not improve from 0.60877
Epoch 45/300
 - 4s - loss: 1102.0968 - acc: 0.9534 - mDice: 0.7833 - val_loss: 2184.7212 - val_acc: 0.9482 - val_mDice: 0.5968

Epoch 00045: val_mDice did not improve from 0.60877
Epoch 46/300
 - 4s - loss: 1096.1334 - acc: 0.9535 - mDice: 0.7843 - val_loss: 2231.7439 - val_acc: 0.9476 - val_mDice: 0.5914

Epoch 00046: val_mDice did not improve from 0.60877
Epoch 47/300
 - 4s - loss: 1087.2860 - acc: 0.9537 - mDice: 0.7859 - val_loss: 2173.6353 - val_acc: 0.9479 - val_mDice: 0.6001

Epoch 00047: val_mDice did not improve from 0.60877
Epoch 48/300
 - 4s - loss: 1084.5061 - acc: 0.9539 - mDice: 0.7863 - val_loss: 2174.2793 - val_acc: 0.9474 - val_mDice: 0.5953

Epoch 00048: val_mDice did not improve from 0.60877
Epoch 49/300
 - 4s - loss: 1074.5818 - acc: 0.9541 - mDice: 0.7879 - val_loss: 2352.4569 - val_acc: 0.9473 - val_mDice: 0.5780

Epoch 00049: val_mDice did not improve from 0.60877
Epoch 50/300
 - 4s - loss: 1075.7549 - acc: 0.9540 - mDice: 0.7879 - val_loss: 2163.2681 - val_acc: 0.9459 - val_mDice: 0.5965

Epoch 00050: val_mDice did not improve from 0.60877
Epoch 51/300
 - 4s - loss: 1072.6158 - acc: 0.9543 - mDice: 0.7884 - val_loss: 2253.7571 - val_acc: 0.9468 - val_mDice: 0.5850

Epoch 00051: val_mDice did not improve from 0.60877
Epoch 52/300
 - 4s - loss: 1067.1415 - acc: 0.9542 - mDice: 0.7894 - val_loss: 2164.9478 - val_acc: 0.9478 - val_mDice: 0.5969

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.64s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.33s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.10s/it]
predicting train subjects:   0%|          | 0/114 [00:00<?, ?it/s]predicting train subjects:   1%|          | 1/114 [00:01<03:44,  1.99s/it]predicting train subjects:   2%|▏         | 2/114 [00:03<03:27,  1.85s/it]predicting train subjects:   3%|▎         | 3/114 [00:05<03:26,  1.86s/it]predicting train subjects:   4%|▎         | 4/114 [00:06<03:14,  1.76s/it]predicting train subjects:   4%|▍         | 5/114 [00:08<03:19,  1.83s/it]predicting train subjects:   5%|▌         | 6/114 [00:10<03:08,  1.74s/it]predicting train subjects:   6%|▌         | 7/114 [00:12<03:01,  1.70s/it]predicting train subjects:   7%|▋         | 8/114 [00:13<02:56,  1.66s/it]predicting train subjects:   8%|▊         | 9/114 [00:15<03:06,  1.78s/it]predicting train subjects:   9%|▉         | 10/114 [00:17<03:04,  1.77s/it]predicting train subjects:  10%|▉         | 11/114 [00:19<03:01,  1.76s/it]predicting train subjects:  11%|█         | 12/114 [00:20<02:53,  1.70s/it]predicting train subjects:  11%|█▏        | 13/114 [00:22<02:46,  1.65s/it]predicting train subjects:  12%|█▏        | 14/114 [00:23<02:39,  1.59s/it]predicting train subjects:  13%|█▎        | 15/114 [00:25<02:57,  1.79s/it]predicting train subjects:  14%|█▍        | 16/114 [00:28<03:12,  1.97s/it]predicting train subjects:  15%|█▍        | 17/114 [00:30<03:19,  2.06s/it]predicting train subjects:  16%|█▌        | 18/114 [00:32<03:06,  1.94s/it]predicting train subjects:  17%|█▋        | 19/114 [00:33<02:55,  1.85s/it]predicting train subjects:  18%|█▊        | 20/114 [00:35<02:53,  1.85s/it]predicting train subjects:  18%|█▊        | 21/114 [00:37<02:52,  1.86s/it]predicting train subjects:  19%|█▉        | 22/114 [00:39<02:44,  1.78s/it]predicting train subjects:  20%|██        | 23/114 [00:40<02:35,  1.70s/it]predicting train subjects:  21%|██        | 24/114 [00:42<02:27,  1.64s/it]predicting train subjects:  22%|██▏       | 25/114 [00:44<02:35,  1.75s/it]predicting train subjects:  23%|██▎       | 26/114 [00:46<02:42,  1.84s/it]predicting train subjects:  24%|██▎       | 27/114 [00:48<02:44,  1.89s/it]predicting train subjects:  25%|██▍       | 28/114 [00:49<02:31,  1.77s/it]predicting train subjects:  25%|██▌       | 29/114 [00:51<02:22,  1.68s/it]predicting train subjects:  26%|██▋       | 30/114 [00:53<02:23,  1.71s/it]predicting train subjects:  27%|██▋       | 31/114 [00:54<02:24,  1.74s/it]predicting train subjects:  28%|██▊       | 32/114 [00:56<02:22,  1.74s/it]predicting train subjects:  29%|██▉       | 33/114 [00:58<02:15,  1.68s/it]predicting train subjects:  30%|██▉       | 34/114 [00:59<02:10,  1.63s/it]predicting train subjects:  31%|███       | 35/114 [01:01<02:05,  1.59s/it]predicting train subjects:  32%|███▏      | 36/114 [01:03<02:14,  1.72s/it]predicting train subjects:  32%|███▏      | 37/114 [01:05<02:15,  1.76s/it]predicting train subjects:  33%|███▎      | 38/114 [01:07<02:21,  1.87s/it]predicting train subjects:  34%|███▍      | 39/114 [01:08<02:12,  1.77s/it]predicting train subjects:  35%|███▌      | 40/114 [01:10<02:07,  1.72s/it]predicting train subjects:  36%|███▌      | 41/114 [01:12<02:07,  1.75s/it]predicting train subjects:  37%|███▋      | 42/114 [01:13<02:07,  1.77s/it]predicting train subjects:  38%|███▊      | 43/114 [01:15<02:01,  1.72s/it]predicting train subjects:  39%|███▊      | 44/114 [01:17<02:07,  1.82s/it]predicting train subjects:  39%|███▉      | 45/114 [01:19<01:59,  1.73s/it]predicting train subjects:  40%|████      | 46/114 [01:21<02:03,  1.81s/it]predicting train subjects:  41%|████      | 47/114 [01:23<02:04,  1.86s/it]predicting train subjects:  42%|████▏     | 48/114 [01:25<02:05,  1.91s/it]predicting train subjects:  43%|████▎     | 49/114 [01:26<01:56,  1.79s/it]predicting train subjects:  44%|████▍     | 50/114 [01:28<01:49,  1.71s/it]predicting train subjects:  45%|████▍     | 51/114 [01:30<01:50,  1.76s/it]predicting train subjects:  46%|████▌     | 52/114 [01:31<01:43,  1.67s/it]predicting train subjects:  46%|████▋     | 53/114 [01:33<01:42,  1.69s/it]predicting train subjects:  47%|████▋     | 54/114 [01:34<01:39,  1.66s/it]predicting train subjects:  48%|████▊     | 55/114 [01:37<01:49,  1.86s/it]predicting train subjects:  49%|████▉     | 56/114 [01:39<01:52,  1.93s/it]predicting train subjects:  50%|█████     | 57/114 [01:41<01:53,  1.99s/it]predicting train subjects:  51%|█████     | 58/114 [01:43<01:50,  1.97s/it]predicting train subjects:  52%|█████▏    | 59/114 [01:44<01:42,  1.87s/it]predicting train subjects:  53%|█████▎    | 60/114 [01:46<01:36,  1.79s/it]predicting train subjects:  54%|█████▎    | 61/114 [01:48<01:35,  1.80s/it]predicting train subjects:  54%|█████▍    | 62/114 [01:49<01:30,  1.73s/it]predicting train subjects:  55%|█████▌    | 63/114 [01:51<01:30,  1.78s/it]predicting train subjects:  56%|█████▌    | 64/114 [01:53<01:24,  1.69s/it]predicting train subjects:  57%|█████▋    | 65/114 [01:55<01:28,  1.80s/it]predicting train subjects:  58%|█████▊    | 66/114 [01:57<01:29,  1.87s/it]predicting train subjects:  59%|█████▉    | 67/114 [01:59<01:29,  1.90s/it]predicting train subjects:  60%|█████▉    | 68/114 [02:01<01:25,  1.86s/it]predicting train subjects:  61%|██████    | 69/114 [02:02<01:19,  1.76s/it]predicting train subjects:  61%|██████▏   | 70/114 [02:04<01:14,  1.70s/it]predicting train subjects:  62%|██████▏   | 71/114 [02:05<01:10,  1.65s/it]predicting train subjects:  63%|██████▎   | 72/114 [02:07<01:07,  1.60s/it]predicting train subjects:  64%|██████▍   | 73/114 [02:09<01:09,  1.70s/it]predicting train subjects:  65%|██████▍   | 74/114 [02:10<01:06,  1.66s/it]predicting train subjects:  66%|██████▌   | 75/114 [02:12<01:09,  1.78s/it]predicting train subjects:  67%|██████▋   | 76/114 [02:14<01:08,  1.81s/it]predicting train subjects:  68%|██████▊   | 77/114 [02:16<01:05,  1.77s/it]predicting train subjects:  68%|██████▊   | 78/114 [02:17<01:00,  1.67s/it]predicting train subjects:  69%|██████▉   | 79/114 [02:19<00:56,  1.60s/it]predicting train subjects:  70%|███████   | 80/114 [02:20<00:53,  1.57s/it]predicting train subjects:  71%|███████   | 81/114 [02:22<00:51,  1.55s/it]predicting train subjects:  72%|███████▏  | 82/114 [02:24<00:52,  1.65s/it]predicting train subjects:  73%|███████▎  | 83/114 [02:26<00:54,  1.74s/it]predicting train subjects:  74%|███████▎  | 84/114 [02:27<00:52,  1.75s/it]predicting train subjects:  75%|███████▍  | 85/114 [02:29<00:48,  1.67s/it]predicting train subjects:  75%|███████▌  | 86/114 [02:30<00:45,  1.62s/it]predicting train subjects:  76%|███████▋  | 87/114 [02:32<00:45,  1.70s/it]predicting train subjects:  77%|███████▋  | 88/114 [02:34<00:44,  1.71s/it]predicting train subjects:  78%|███████▊  | 89/114 [02:35<00:41,  1.65s/it]predicting train subjects:  79%|███████▉  | 90/114 [02:37<00:38,  1.62s/it]predicting train subjects:  80%|███████▉  | 91/114 [02:39<00:36,  1.60s/it]predicting train subjects:  81%|████████  | 92/114 [02:40<00:34,  1.58s/it]predicting train subjects:  82%|████████▏ | 93/114 [02:42<00:35,  1.70s/it]predicting train subjects:  82%|████████▏ | 94/114 [02:44<00:35,  1.78s/it]predicting train subjects:  83%|████████▎ | 95/114 [02:46<00:32,  1.69s/it]predicting train subjects:  84%|████████▍ | 96/114 [02:47<00:29,  1.63s/it]predicting train subjects:  85%|████████▌ | 97/114 [02:49<00:29,  1.71s/it]predicting train subjects:  86%|████████▌ | 98/114 [02:51<00:27,  1.71s/it]predicting train subjects:  87%|████████▋ | 99/114 [02:52<00:24,  1.63s/it]predicting train subjects:  88%|████████▊ | 100/114 [02:54<00:22,  1.58s/it]predicting train subjects:  89%|████████▊ | 101/114 [02:55<00:21,  1.62s/it]predicting train subjects:  89%|████████▉ | 102/114 [02:57<00:18,  1.57s/it]predicting train subjects:  90%|█████████ | 103/114 [02:58<00:17,  1.55s/it]predicting train subjects:  91%|█████████ | 104/114 [03:00<00:16,  1.66s/it]predicting train subjects:  92%|█████████▏| 105/114 [03:02<00:15,  1.72s/it]predicting train subjects:  93%|█████████▎| 106/114 [03:03<00:13,  1.65s/it]predicting train subjects:  94%|█████████▍| 107/114 [03:05<00:11,  1.61s/it]predicting train subjects:  95%|█████████▍| 108/114 [03:07<00:09,  1.66s/it]predicting train subjects:  96%|█████████▌| 109/114 [03:08<00:08,  1.61s/it]predicting train subjects:  96%|█████████▋| 110/114 [03:10<00:06,  1.60s/it]predicting train subjects:  97%|█████████▋| 111/114 [03:11<00:04,  1.58s/it]predicting train subjects:  98%|█████████▊| 112/114 [03:13<00:03,  1.69s/it]predicting train subjects:  99%|█████████▉| 113/114 [03:15<00:01,  1.77s/it]predicting train subjects: 100%|██████████| 114/114 [03:17<00:00,  1.83s/it]
Loading train:   0%|          | 0/114 [00:00<?, ?it/s]Loading train:   1%|          | 1/114 [00:01<03:04,  1.63s/it]Loading train:   2%|▏         | 2/114 [00:02<02:46,  1.48s/it]Loading train:   3%|▎         | 3/114 [00:04<02:42,  1.46s/it]Loading train:   4%|▎         | 4/114 [00:05<02:33,  1.40s/it]Loading train:   4%|▍         | 5/114 [00:06<02:36,  1.43s/it]Loading train:   5%|▌         | 6/114 [00:08<02:27,  1.37s/it]Loading train:   6%|▌         | 7/114 [00:09<02:10,  1.22s/it]Loading train:   7%|▋         | 8/114 [00:09<01:57,  1.11s/it]Loading train:   8%|▊         | 9/114 [00:10<01:55,  1.10s/it]Loading train:   9%|▉         | 10/114 [00:11<01:51,  1.07s/it]Loading train:  10%|▉         | 11/114 [00:12<01:42,  1.01it/s]Loading train:  11%|█         | 12/114 [00:13<01:36,  1.06it/s]Loading train:  11%|█▏        | 13/114 [00:14<01:34,  1.07it/s]Loading train:  12%|█▏        | 14/114 [00:15<01:29,  1.12it/s]Loading train:  13%|█▎        | 15/114 [00:16<01:34,  1.05it/s]Loading train:  14%|█▍        | 16/114 [00:17<01:30,  1.08it/s]Loading train:  15%|█▍        | 17/114 [00:18<01:39,  1.03s/it]Loading train:  16%|█▌        | 18/114 [00:19<01:31,  1.05it/s]Loading train:  17%|█▋        | 19/114 [00:20<01:25,  1.12it/s]Loading train:  18%|█▊        | 20/114 [00:21<01:28,  1.06it/s]Loading train:  18%|█▊        | 21/114 [00:21<01:25,  1.09it/s]Loading train:  19%|█▉        | 22/114 [00:22<01:26,  1.06it/s]Loading train:  20%|██        | 23/114 [00:23<01:19,  1.14it/s]Loading train:  21%|██        | 24/114 [00:24<01:13,  1.23it/s]Loading train:  22%|██▏       | 25/114 [00:25<01:14,  1.20it/s]Loading train:  23%|██▎       | 26/114 [00:26<01:13,  1.20it/s]Loading train:  24%|██▎       | 27/114 [00:27<01:15,  1.15it/s]Loading train:  25%|██▍       | 28/114 [00:27<01:10,  1.23it/s]Loading train:  25%|██▌       | 29/114 [00:28<01:10,  1.21it/s]Loading train:  26%|██▋       | 30/114 [00:29<01:13,  1.15it/s]Loading train:  27%|██▋       | 31/114 [00:30<01:14,  1.11it/s]Loading train:  28%|██▊       | 32/114 [00:31<01:12,  1.13it/s]Loading train:  29%|██▉       | 33/114 [00:32<01:10,  1.15it/s]Loading train:  30%|██▉       | 34/114 [00:33<01:09,  1.14it/s]Loading train:  31%|███       | 35/114 [00:33<01:06,  1.19it/s]Loading train:  32%|███▏      | 36/114 [00:34<01:10,  1.11it/s]Loading train:  32%|███▏      | 37/114 [00:35<01:10,  1.10it/s]Loading train:  33%|███▎      | 38/114 [00:36<01:14,  1.01it/s]Loading train:  34%|███▍      | 39/114 [00:37<01:06,  1.13it/s]Loading train:  35%|███▌      | 40/114 [00:38<01:07,  1.10it/s]Loading train:  36%|███▌      | 41/114 [00:39<01:05,  1.12it/s]Loading train:  37%|███▋      | 42/114 [00:40<01:05,  1.10it/s]Loading train:  38%|███▊      | 43/114 [00:41<01:03,  1.13it/s]Loading train:  39%|███▊      | 44/114 [00:42<01:06,  1.05it/s]Loading train:  39%|███▉      | 45/114 [00:43<01:05,  1.06it/s]Loading train:  40%|████      | 46/114 [00:44<01:04,  1.05it/s]Loading train:  41%|████      | 47/114 [00:45<01:07,  1.00s/it]Loading train:  42%|████▏     | 48/114 [00:46<01:04,  1.03it/s]Loading train:  43%|████▎     | 49/114 [00:47<01:01,  1.06it/s]Loading train:  44%|████▍     | 50/114 [00:47<00:58,  1.10it/s]Loading train:  45%|████▍     | 51/114 [00:48<00:56,  1.12it/s]Loading train:  46%|████▌     | 52/114 [00:49<00:57,  1.08it/s]Loading train:  46%|████▋     | 53/114 [00:50<00:53,  1.14it/s]Loading train:  47%|████▋     | 54/114 [00:51<00:50,  1.20it/s]Loading train:  48%|████▊     | 55/114 [00:52<00:55,  1.06it/s]Loading train:  49%|████▉     | 56/114 [00:53<00:54,  1.07it/s]Loading train:  50%|█████     | 57/114 [00:54<00:55,  1.02it/s]Loading train:  51%|█████     | 58/114 [00:55<00:53,  1.05it/s]Loading train:  52%|█████▏    | 59/114 [00:56<00:50,  1.09it/s]Loading train:  53%|█████▎    | 60/114 [00:57<00:48,  1.12it/s]Loading train:  54%|█████▎    | 61/114 [00:57<00:46,  1.13it/s]Loading train:  54%|█████▍    | 62/114 [00:58<00:45,  1.14it/s]Loading train:  55%|█████▌    | 63/114 [00:59<00:47,  1.07it/s]Loading train:  56%|█████▌    | 64/114 [01:00<00:46,  1.09it/s]Loading train:  57%|█████▋    | 65/114 [01:02<00:50,  1.02s/it]Loading train:  58%|█████▊    | 66/114 [01:03<00:48,  1.02s/it]Loading train:  59%|█████▉    | 67/114 [01:04<00:47,  1.01s/it]Loading train:  60%|█████▉    | 68/114 [01:04<00:43,  1.05it/s]Loading train:  61%|██████    | 69/114 [01:05<00:40,  1.11it/s]Loading train:  61%|██████▏   | 70/114 [01:06<00:37,  1.16it/s]Loading train:  62%|██████▏   | 71/114 [01:07<00:36,  1.18it/s]Loading train:  63%|██████▎   | 72/114 [01:08<00:35,  1.18it/s]Loading train:  64%|██████▍   | 73/114 [01:09<00:36,  1.13it/s]Loading train:  65%|██████▍   | 74/114 [01:09<00:33,  1.20it/s]Loading train:  66%|██████▌   | 75/114 [01:10<00:34,  1.13it/s]Loading train:  67%|██████▋   | 76/114 [01:11<00:34,  1.11it/s]Loading train:  68%|██████▊   | 77/114 [01:12<00:34,  1.06it/s]Loading train:  68%|██████▊   | 78/114 [01:13<00:31,  1.14it/s]Loading train:  69%|██████▉   | 79/114 [01:14<00:32,  1.08it/s]Loading train:  70%|███████   | 80/114 [01:15<00:31,  1.08it/s]Loading train:  71%|███████   | 81/114 [01:16<00:30,  1.08it/s]Loading train:  72%|███████▏  | 82/114 [01:17<00:29,  1.07it/s]Loading train:  73%|███████▎  | 83/114 [01:18<00:30,  1.02it/s]Loading train:  74%|███████▎  | 84/114 [01:19<00:29,  1.03it/s]Loading train:  75%|███████▍  | 85/114 [01:20<00:27,  1.06it/s]Loading train:  75%|███████▌  | 86/114 [01:21<00:25,  1.11it/s]Loading train:  76%|███████▋  | 87/114 [01:21<00:24,  1.10it/s]Loading train:  77%|███████▋  | 88/114 [01:23<00:25,  1.04it/s]Loading train:  78%|███████▊  | 89/114 [01:24<00:24,  1.03it/s]Loading train:  79%|███████▉  | 90/114 [01:25<00:24,  1.02s/it]Loading train:  80%|███████▉  | 91/114 [01:25<00:22,  1.03it/s]Loading train:  81%|████████  | 92/114 [01:26<00:19,  1.10it/s]Loading train:  82%|████████▏ | 93/114 [01:27<00:20,  1.05it/s]Loading train:  82%|████████▏ | 94/114 [01:28<00:19,  1.04it/s]Loading train:  83%|████████▎ | 95/114 [01:29<00:17,  1.11it/s]Loading train:  84%|████████▍ | 96/114 [01:30<00:15,  1.18it/s]Loading train:  85%|████████▌ | 97/114 [01:31<00:14,  1.16it/s]Loading train:  86%|████████▌ | 98/114 [01:32<00:14,  1.09it/s]Loading train:  87%|████████▋ | 99/114 [01:33<00:13,  1.13it/s]Loading train:  88%|████████▊ | 100/114 [01:34<00:13,  1.03it/s]Loading train:  89%|████████▊ | 101/114 [01:35<00:12,  1.04it/s]Loading train:  89%|████████▉ | 102/114 [01:35<00:10,  1.11it/s]Loading train:  90%|█████████ | 103/114 [01:36<00:09,  1.16it/s]Loading train:  91%|█████████ | 104/114 [01:37<00:09,  1.10it/s]Loading train:  92%|█████████▏| 105/114 [01:38<00:08,  1.06it/s]Loading train:  93%|█████████▎| 106/114 [01:39<00:07,  1.08it/s]Loading train:  94%|█████████▍| 107/114 [01:40<00:06,  1.16it/s]Loading train:  95%|█████████▍| 108/114 [01:41<00:05,  1.14it/s]Loading train:  96%|█████████▌| 109/114 [01:42<00:04,  1.09it/s]Loading train:  96%|█████████▋| 110/114 [01:43<00:03,  1.09it/s]Loading train:  97%|█████████▋| 111/114 [01:44<00:02,  1.11it/s]Loading train:  98%|█████████▊| 112/114 [01:45<00:01,  1.04it/s]Loading train:  99%|█████████▉| 113/114 [01:46<00:01,  1.04s/it]Loading train: 100%|██████████| 114/114 [01:47<00:00,  1.04s/it]
concatenating: train:   0%|          | 0/114 [00:00<?, ?it/s]concatenating: train:   5%|▌         | 6/114 [00:00<00:01, 59.99it/s]concatenating: train:  11%|█▏        | 13/114 [00:00<00:01, 60.72it/s]concatenating: train:  35%|███▌      | 40/114 [00:00<00:00, 79.01it/s]concatenating: train:  46%|████▌     | 52/114 [00:00<00:00, 86.74it/s]concatenating: train:  55%|█████▌    | 63/114 [00:00<00:00, 92.62it/s]concatenating: train:  65%|██████▍   | 74/114 [00:00<00:00, 95.21it/s]concatenating: train:  91%|█████████ | 104/114 [00:00<00:00, 119.65it/s]concatenating: train: 100%|██████████| 114/114 [00:00<00:00, 150.73it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.40s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.35s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 820.38it/s]2019-07-07 22:04:37.868628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 22:04:37.868756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 22:04:37.868774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 22:04:37.868784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 22:04:38.018654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/45 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/45 [00:00<00:09,  4.56it/s]loading the weights for Res Unet:   7%|▋         | 3/45 [00:00<00:07,  5.39it/s]loading the weights for Res Unet:   9%|▉         | 4/45 [00:00<00:07,  5.14it/s]loading the weights for Res Unet:  20%|██        | 9/45 [00:00<00:05,  6.71it/s]loading the weights for Res Unet:  22%|██▏       | 10/45 [00:01<00:15,  2.27it/s]loading the weights for Res Unet:  27%|██▋       | 12/45 [00:02<00:15,  2.19it/s]loading the weights for Res Unet:  29%|██▉       | 13/45 [00:03<00:16,  1.92it/s]loading the weights for Res Unet:  40%|████      | 18/45 [00:03<00:10,  2.65it/s]loading the weights for Res Unet:  44%|████▍     | 20/45 [00:04<00:07,  3.38it/s]loading the weights for Res Unet:  49%|████▉     | 22/45 [00:04<00:06,  3.78it/s]loading the weights for Res Unet:  58%|█████▊    | 26/45 [00:04<00:03,  4.89it/s]loading the weights for Res Unet:  62%|██████▏   | 28/45 [00:04<00:02,  5.95it/s]loading the weights for Res Unet:  67%|██████▋   | 30/45 [00:05<00:02,  6.76it/s]loading the weights for Res Unet:  71%|███████   | 32/45 [00:06<00:03,  3.30it/s]loading the weights for Res Unet:  80%|████████  | 36/45 [00:07<00:02,  3.58it/s]loading the weights for Res Unet:  84%|████████▍ | 38/45 [00:07<00:02,  3.36it/s]loading the weights for Res Unet:  87%|████████▋ | 39/45 [00:08<00:01,  3.80it/s]loading the weights for Res Unet:  91%|█████████ | 41/45 [00:08<00:00,  4.71it/s]loading the weights for Res Unet:  93%|█████████▎| 42/45 [00:08<00:00,  4.91it/s]loading the weights for Res Unet: 100%|██████████| 45/45 [00:08<00:00,  5.27it/s]
Epoch 00052: val_mDice did not improve from 0.60877
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [6200.572262897172, 4088.371339254539, 3006.290823313111, 2958.6783576837465, 2264.816859069483, 2264.2689379473636, 2147.5879219950243, 2209.1504492733065, 2188.6630927570704, 2120.3475730512396, 2164.7073081245635, 2136.405903565817, 2414.9701098223636, 2294.354531741009, 2269.878342953474, 2248.4251934030203, 2295.4311755302897, 2263.315973889228, 2336.4385147520948, 2384.2429472001572, 2318.5352503600734, 2136.6737231036136, 2361.875508739962, 2325.760304371072, 2220.7759866554643, 2142.1423612626572, 2261.297670161924, 2227.0435061321577, 2387.3009721979747, 2282.3155360728, 2171.022309543034, 2444.806227359026, 2237.579599391149, 2361.520451892022, 2205.7897894662187, 2456.310647804644, 2312.7923331660263, 2206.2444543252445, 2269.7634713796265, 2280.588247970496, 2244.7338485291552, 2215.265738204871, 2362.899311768942, 2302.8702413036835, 2184.721226868017, 2231.7439346739698, 2173.63525390625, 2174.2793405202515, 2352.4568662163933, 2163.268067770164, 2253.757119631634, 2164.9478125545565], 'val_acc': [0.9175565332673782, 0.9233346811219967, 0.9322431820064949, 0.9329609028453933, 0.9395440770261114, 0.9424513278726759, 0.9452494526042619, 0.9455574271399215, 0.9465272809540093, 0.9461563096366115, 0.9469443476399896, 0.9465006183645579, 0.946954069523838, 0.9447572584258778, 0.9459065695048711, 0.9466315614444584, 0.9434697021985187, 0.9450482136710396, 0.9468618897752389, 0.944657828221774, 0.9446675204697934, 0.9481179044899328, 0.9470316154996776, 0.9479578713465003, 0.9462048051743533, 0.9478099662498389, 0.9474705234586194, 0.9465176083522135, 0.9447305658676105, 0.9470558815828248, 0.9452106553083025, 0.9469443642893317, 0.9463915272131979, 0.9462363433571501, 0.9472571424931787, 0.9464715136496048, 0.9473953237080707, 0.9458192809999988, 0.9470146741281008, 0.9462435958105758, 0.9468522008570879, 0.9474292940267638, 0.9478802987317133, 0.9461829565756814, 0.9482100519388081, 0.9476014668715067, 0.9478536384731697, 0.9474147501604517, 0.9473468568071973, 0.9459380863765099, 0.9468061351243344, 0.9477978475266995], 'val_mDice': [0.27760121642544283, 0.40900435494311027, 0.5095760497633971, 0.5216290724344094, 0.5843967199325562, 0.5889523938381472, 0.6046450514367173, 0.597458083203385, 0.6003028467380801, 0.6084962553818133, 0.6016536015372037, 0.6034240696017302, 0.5860913785476258, 0.5867299254380125, 0.5966850862156745, 0.5961796884430187, 0.5807071031804857, 0.5916483855114303, 0.5954706782069286, 0.5846740416974329, 0.5868984577376083, 0.6087675291066729, 0.5832895286922348, 0.5914273035592873, 0.5967464040777537, 0.6051612606261696, 0.5929802020168837, 0.5936887760402104, 0.5788062691022564, 0.5880038385284679, 0.5918859166805971, 0.566348272661923, 0.5873985223929975, 0.5757472714898306, 0.5938860477681932, 0.5662669158181665, 0.5822462063261916, 0.5896198613017631, 0.5862251410271202, 0.5850292127891625, 0.5881976555179618, 0.5931895005636375, 0.5752988774017249, 0.5828638103421174, 0.5968139994077842, 0.5913502770429216, 0.6001481224038747, 0.595260583155648, 0.5779602577566435, 0.5965120139734705, 0.5849544072950352, 0.5968703804069391], 'loss': [14580.285394427568, 5710.837110222926, 3229.5348103927317, 2553.437246053077, 2241.5435972492455, 2060.446868926644, 1933.6649679883833, 1821.3157709604534, 1740.9059474007418, 1697.5722413936207, 1624.245646606945, 1581.6849444167317, 1556.6424477133023, 1505.8626173171017, 1486.2950298821506, 1455.6303822960235, 1425.1359773835404, 1418.103368599469, 1380.1854133783686, 1367.486281316731, 1348.6785310806906, 1325.4503565045984, 1322.3256712540149, 1305.5264748671996, 1289.4445288923523, 1273.2598790264763, 1263.8637985020528, 1245.4143745953395, 1233.444956974308, 1221.8259078546482, 1220.435040058296, 1209.7366464419097, 1195.87867321686, 1171.6611590516713, 1173.5817605858383, 1169.8537946822498, 1153.930778610055, 1142.2783623641112, 1142.7380608840463, 1131.2911157819422, 1137.6454847271996, 1123.7005150340026, 1132.9729164529617, 1108.595274448462, 1102.0967806630697, 1096.1334419471302, 1087.2859967134943, 1084.5060776039047, 1074.581791245599, 1075.7548707226617, 1072.6157813475459, 1067.1415080493678], 'acc': [0.4768136735291833, 0.8967533508179198, 0.9115460214516579, 0.9175374803613106, 0.9227863165023854, 0.9277340982082485, 0.9316887587170033, 0.9350163671368851, 0.9371812357229986, 0.938691479412829, 0.9403685787951696, 0.94131660124819, 0.942464389471824, 0.9432555421351646, 0.944019427318686, 0.9446685340602099, 0.9453580930090617, 0.9457341470187218, 0.9464593706588094, 0.9468047898922805, 0.947296724529164, 0.9477176996975922, 0.9479158126532014, 0.948534955644143, 0.9488761460530325, 0.9490904987119239, 0.9495858585583731, 0.9499962978758213, 0.9502447797099901, 0.9504055731228881, 0.9506117711796963, 0.9507187590934993, 0.9511116679300785, 0.9515352824574791, 0.9515902474911793, 0.9518348009812198, 0.9521111675562973, 0.9522218895584584, 0.9523926156650706, 0.9527042706891606, 0.9526971614362493, 0.9528536664030907, 0.952976220512094, 0.9532760499763435, 0.9533742769414484, 0.9535011263717017, 0.9536981900903307, 0.9538595929887022, 0.9541101537568075, 0.9540265142942879, 0.9542586315777213, 0.9542240060841686], 'mDice': [0.07292398588857324, 0.32128023446557147, 0.4970494628575298, 0.5724042121357253, 0.6119174717863821, 0.6361424410627603, 0.6541033539919467, 0.6699609547773526, 0.6817156407904796, 0.688398707490275, 0.699176440766752, 0.705602269379345, 0.7099155836752978, 0.7174738095033207, 0.7205899068818798, 0.725336939176395, 0.7300741282809374, 0.731141121470287, 0.7372217050770759, 0.7392514046598723, 0.7423579927623802, 0.7460656676456684, 0.7466183760383953, 0.7494361655499728, 0.7520351424217897, 0.7544969730284293, 0.7562174129230262, 0.7593588357959346, 0.7610089662097596, 0.7630210806467465, 0.7633726677365447, 0.7650920786494743, 0.7674729989760848, 0.7714279617913847, 0.77112306274298, 0.7717613281207991, 0.7744516382004671, 0.7763324804466255, 0.7762510508244175, 0.7781935404388141, 0.777195159550459, 0.7794899715721548, 0.7780288956721725, 0.7821392138327782, 0.7832525510429814, 0.7842756190930116, 0.7858655232755744, 0.7863363770295482, 0.7879465559891148, 0.7878711755525152, 0.7884146503753856, 0.789351215659436]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 48, 15)   150         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 48, 15)   60          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 48, 15)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 48, 15)   2040        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 48, 15)   60          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 48, 15)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 76, 48, 16)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 24, 16)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 24, 16)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 24, 30)   4350        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 24, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 24, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 24, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 24, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 24, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 38, 24, 46)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 12, 46)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 12, 46)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 12, 60)   24900       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 12, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 12, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 12, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 12, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 12, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 19, 12, 106)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 12, 106)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 24, 30)   12750       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 24, 76)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 24, 30)   20550       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 24, 30)   120         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 24, 30)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 24, 30)   8130        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 24, 30)   120         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 24, 30)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 38, 24, 106)  0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 24, 106)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 48, 15)   6375        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 48, 31)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 48, 15)   4200        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 48, 15)   60          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 48, 15)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 48, 15)   2040        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 48, 15)   60          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 48, 15)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 76, 48, 46)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 48, 46)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 48, 13)   611         dropout_5[0][0]                  
==================================================================================================
Total params: 127,886
Trainable params: 28,496
Non-trainable params: 99,390
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.73072345e-02 3.02817043e-02 7.22302321e-02 9.58160602e-03
 2.74732633e-02 7.56952873e-03 8.31306677e-02 1.00243516e-01
 9.14055332e-02 1.28110066e-02 2.77019981e-01 2.20675511e-01
 2.70216389e-04]
Train on 4240 samples, validate on 104 samples
Epoch 1/300
 - 12s - loss: 29351.5333 - acc: 0.2715 - mDice: 0.0441 - val_loss: 21688.4204 - val_acc: 0.6590 - val_mDice: 0.1058

Epoch 00001: val_mDice improved from -inf to 0.10579, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 3s - loss: 21387.9649 - acc: 0.7522 - mDice: 0.1038 - val_loss: 15495.4390 - val_acc: 0.8120 - val_mDice: 0.1853

Epoch 00002: val_mDice improved from 0.10579 to 0.18531, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 3s - loss: 15177.5264 - acc: 0.8568 - mDice: 0.1897 - val_loss: 12659.0272 - val_acc: 0.8807 - val_mDice: 0.2349

Epoch 00003: val_mDice improved from 0.18531 to 0.23493, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 3s - loss: 11225.5225 - acc: 0.8838 - mDice: 0.2604 - val_loss: 8737.5596 - val_acc: 0.9011 - val_mDice: 0.3047

Epoch 00004: val_mDice improved from 0.23493 to 0.30470, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 3s - loss: 8522.9666 - acc: 0.8883 - mDice: 0.3242 - val_loss: 7579.2686 - val_acc: 0.8817 - val_mDice: 0.3528

Epoch 00005: val_mDice improved from 0.30470 to 0.35279, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 3s - loss: 7352.4731 - acc: 0.8899 - mDice: 0.3694 - val_loss: 9165.1338 - val_acc: 0.8749 - val_mDice: 0.3241

Epoch 00006: val_mDice did not improve from 0.35279
Epoch 7/300
 - 3s - loss: 6707.3553 - acc: 0.8926 - mDice: 0.4005 - val_loss: 6578.4750 - val_acc: 0.9010 - val_mDice: 0.4030

Epoch 00007: val_mDice improved from 0.35279 to 0.40302, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 3s - loss: 6213.2156 - acc: 0.8944 - mDice: 0.4267 - val_loss: 9117.0674 - val_acc: 0.9018 - val_mDice: 0.3386

Epoch 00008: val_mDice did not improve from 0.40302
Epoch 9/300
 - 3s - loss: 5716.9329 - acc: 0.8967 - mDice: 0.4545 - val_loss: 6613.2348 - val_acc: 0.9068 - val_mDice: 0.4072

Epoch 00009: val_mDice improved from 0.40302 to 0.40719, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 3s - loss: 5370.0816 - acc: 0.8994 - mDice: 0.4764 - val_loss: 5734.0445 - val_acc: 0.8994 - val_mDice: 0.4410

Epoch 00010: val_mDice improved from 0.40719 to 0.44098, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 3s - loss: 5098.0674 - acc: 0.9016 - mDice: 0.4937 - val_loss: 7455.1736 - val_acc: 0.9065 - val_mDice: 0.3891

Epoch 00011: val_mDice did not improve from 0.44098
Epoch 12/300
 - 3s - loss: 4905.7484 - acc: 0.9040 - mDice: 0.5069 - val_loss: 5924.4861 - val_acc: 0.9075 - val_mDice: 0.4332

Epoch 00012: val_mDice did not improve from 0.44098
Epoch 13/300
 - 3s - loss: 4696.9840 - acc: 0.9060 - mDice: 0.5211 - val_loss: 6837.0839 - val_acc: 0.9087 - val_mDice: 0.4113

Epoch 00013: val_mDice did not improve from 0.44098
Epoch 14/300
 - 3s - loss: 4566.2850 - acc: 0.9088 - mDice: 0.5314 - val_loss: 8255.0601 - val_acc: 0.9110 - val_mDice: 0.3978

Epoch 00014: val_mDice did not improve from 0.44098
Epoch 15/300
 - 3s - loss: 4372.2288 - acc: 0.9116 - mDice: 0.5444 - val_loss: 5199.1665 - val_acc: 0.8994 - val_mDice: 0.4726

Epoch 00015: val_mDice improved from 0.44098 to 0.47262, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 3s - loss: 4266.5895 - acc: 0.9138 - mDice: 0.5532 - val_loss: 4841.4429 - val_acc: 0.9098 - val_mDice: 0.4968

Epoch 00016: val_mDice improved from 0.47262 to 0.49681, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 3s - loss: 4173.5131 - acc: 0.9157 - mDice: 0.5599 - val_loss: 4853.0387 - val_acc: 0.9207 - val_mDice: 0.4952

Epoch 00017: val_mDice did not improve from 0.49681
Epoch 18/300
 - 3s - loss: 4045.9695 - acc: 0.9176 - mDice: 0.5694 - val_loss: 5024.8838 - val_acc: 0.9041 - val_mDice: 0.4864

Epoch 00018: val_mDice did not improve from 0.49681
Epoch 19/300
 - 3s - loss: 4058.8491 - acc: 0.9179 - mDice: 0.5694 - val_loss: 5001.0753 - val_acc: 0.9039 - val_mDice: 0.4887

Epoch 00019: val_mDice did not improve from 0.49681
Epoch 20/300
 - 3s - loss: 3900.5139 - acc: 0.9195 - mDice: 0.5807 - val_loss: 5496.3082 - val_acc: 0.8989 - val_mDice: 0.4669

Epoch 00020: val_mDice did not improve from 0.49681
Epoch 21/300
 - 3s - loss: 3774.8284 - acc: 0.9212 - mDice: 0.5909 - val_loss: 4501.8839 - val_acc: 0.9201 - val_mDice: 0.5185

Epoch 00021: val_mDice improved from 0.49681 to 0.51849, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 3s - loss: 3730.3778 - acc: 0.9219 - mDice: 0.5942 - val_loss: 4535.2136 - val_acc: 0.9214 - val_mDice: 0.5155

Epoch 00022: val_mDice did not improve from 0.51849
Epoch 23/300
 - 3s - loss: 3674.5293 - acc: 0.9226 - mDice: 0.5989 - val_loss: 4962.7476 - val_acc: 0.9259 - val_mDice: 0.4868

Epoch 00023: val_mDice did not improve from 0.51849
Epoch 24/300
 - 3s - loss: 3614.6415 - acc: 0.9233 - mDice: 0.6039 - val_loss: 4771.2662 - val_acc: 0.9265 - val_mDice: 0.5000

Epoch 00024: val_mDice did not improve from 0.51849
Epoch 25/300
 - 3s - loss: 3546.5824 - acc: 0.9242 - mDice: 0.6094 - val_loss: 4708.8134 - val_acc: 0.9275 - val_mDice: 0.5038

Epoch 00025: val_mDice did not improve from 0.51849
Epoch 26/300
 - 3s - loss: 3474.2781 - acc: 0.9251 - mDice: 0.6156 - val_loss: 5656.7950 - val_acc: 0.9244 - val_mDice: 0.4522

Epoch 00026: val_mDice did not improve from 0.51849
Epoch 27/300
 - 3s - loss: 3484.6508 - acc: 0.9254 - mDice: 0.6153 - val_loss: 4477.2239 - val_acc: 0.9261 - val_mDice: 0.5187

Epoch 00027: val_mDice improved from 0.51849 to 0.51868, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 3s - loss: 3400.4033 - acc: 0.9263 - mDice: 0.6218 - val_loss: 4546.7042 - val_acc: 0.9245 - val_mDice: 0.5148

Epoch 00028: val_mDice did not improve from 0.51868
Epoch 29/300
 - 3s - loss: 3331.3849 - acc: 0.9272 - mDice: 0.6276 - val_loss: 4367.4380 - val_acc: 0.9218 - val_mDice: 0.5294

Epoch 00029: val_mDice improved from 0.51868 to 0.52937, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 4s - loss: 3294.9318 - acc: 0.9275 - mDice: 0.6306 - val_loss: 4561.6828 - val_acc: 0.9129 - val_mDice: 0.5170

Epoch 00030: val_mDice did not improve from 0.52937
Epoch 31/300
 - 4s - loss: 3286.2712 - acc: 0.9280 - mDice: 0.6318 - val_loss: 4434.2664 - val_acc: 0.9298 - val_mDice: 0.5244

Epoch 00031: val_mDice did not improve from 0.52937
Epoch 32/300
 - 4s - loss: 3228.5165 - acc: 0.9286 - mDice: 0.6366 - val_loss: 4189.5388 - val_acc: 0.9265 - val_mDice: 0.5405

Epoch 00032: val_mDice improved from 0.52937 to 0.54053, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 3s - loss: 3211.2204 - acc: 0.9288 - mDice: 0.6382 - val_loss: 4400.6440 - val_acc: 0.9267 - val_mDice: 0.5269

Epoch 00033: val_mDice did not improve from 0.54053
Epoch 34/300
 - 3s - loss: 3168.1175 - acc: 0.9294 - mDice: 0.6417 - val_loss: 4507.7018 - val_acc: 0.9274 - val_mDice: 0.5180

Epoch 00034: val_mDice did not improve from 0.54053
Epoch 35/300
 - 3s - loss: 3169.1769 - acc: 0.9296 - mDice: 0.6421 - val_loss: 4298.4139 - val_acc: 0.9283 - val_mDice: 0.5332

Epoch 00035: val_mDice did not improve from 0.54053
Epoch 36/300
 - 3s - loss: 3110.4795 - acc: 0.9305 - mDice: 0.6473 - val_loss: 4405.4231 - val_acc: 0.9181 - val_mDice: 0.5288

Epoch 00036: val_mDice did not improve from 0.54053
Epoch 37/300
 - 3s - loss: 3076.1643 - acc: 0.9306 - mDice: 0.6500 - val_loss: 4517.5928 - val_acc: 0.9143 - val_mDice: 0.5207

Epoch 00037: val_mDice did not improve from 0.54053
Epoch 38/300
 - 3s - loss: 3049.2726 - acc: 0.9312 - mDice: 0.6528 - val_loss: 4310.8660 - val_acc: 0.9226 - val_mDice: 0.5346

Epoch 00038: val_mDice did not improve from 0.54053
Epoch 39/300
 - 3s - loss: 3067.4888 - acc: 0.9310 - mDice: 0.6512 - val_loss: 4515.8588 - val_acc: 0.9143 - val_mDice: 0.5194

Epoch 00039: val_mDice did not improve from 0.54053
Epoch 40/300
 - 3s - loss: 3003.2608 - acc: 0.9318 - mDice: 0.6568 - val_loss: 4261.4716 - val_acc: 0.9206 - val_mDice: 0.5378

Epoch 00040: val_mDice did not improve from 0.54053
Epoch 41/300
 - 3s - loss: 2959.9108 - acc: 0.9321 - mDice: 0.6605 - val_loss: 4592.7960 - val_acc: 0.9117 - val_mDice: 0.5154

Epoch 00041: val_mDice did not improve from 0.54053
Epoch 42/300
 - 3s - loss: 2953.7816 - acc: 0.9322 - mDice: 0.6610 - val_loss: 4567.5096 - val_acc: 0.9137 - val_mDice: 0.5176

Epoch 00042: val_mDice did not improve from 0.54053
Epoch 43/300
 - 3s - loss: 2953.3823 - acc: 0.9325 - mDice: 0.6615 - val_loss: 4403.2164 - val_acc: 0.9171 - val_mDice: 0.5278

Epoch 00043: val_mDice did not improve from 0.54053
Epoch 44/300
 - 3s - loss: 2943.2110 - acc: 0.9324 - mDice: 0.6623 - val_loss: 4454.3097 - val_acc: 0.9249 - val_mDice: 0.5248

Epoch 00044: val_mDice did not improve from 0.54053
Epoch 45/300
 - 3s - loss: 2924.2641 - acc: 0.9327 - mDice: 0.6641 - val_loss: 4468.3394 - val_acc: 0.9306 - val_mDice: 0.5227

Epoch 00045: val_mDice did not improve from 0.54053
Epoch 46/300
 - 3s - loss: 2907.1346 - acc: 0.9330 - mDice: 0.6655 - val_loss: 4212.8327 - val_acc: 0.9261 - val_mDice: 0.5410

Epoch 00046: val_mDice improved from 0.54053 to 0.54099, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 3s - loss: 2871.4593 - acc: 0.9333 - mDice: 0.6689 - val_loss: 4546.5271 - val_acc: 0.9162 - val_mDice: 0.5192

Epoch 00047: val_mDice did not improve from 0.54099
Epoch 48/300
 - 3s - loss: 2855.7141 - acc: 0.9334 - mDice: 0.6703 - val_loss: 4460.1814 - val_acc: 0.9178 - val_mDice: 0.5246

Epoch 00048: val_mDice did not improve from 0.54099
Epoch 49/300
 - 3s - loss: 2824.5703 - acc: 0.9340 - mDice: 0.6734 - val_loss: 4181.3532 - val_acc: 0.9222 - val_mDice: 0.5421

Epoch 00049: val_mDice improved from 0.54099 to 0.54213, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 50/300
 - 3s - loss: 2810.2465 - acc: 0.9338 - mDice: 0.6745 - val_loss: 4395.2128 - val_acc: 0.9284 - val_mDice: 0.5283

Epoch 00050: val_mDice did not improve from 0.54213
Epoch 51/300
 - 3s - loss: 2824.8924 - acc: 0.9339 - mDice: 0.6735 - val_loss: 4328.1281 - val_acc: 0.9262 - val_mDice: 0.5326

Epoch 00051: val_mDice did not improve from 0.54213
Epoch 52/300
 - 3s - loss: 2807.7655 - acc: 0.9341 - mDice: 0.6750 - val_loss: 4548.9222 - val_acc: 0.9182 - val_mDice: 0.5186

Epoch 00052: val_mDice did not improve from 0.54213
Epoch 53/300
 - 3s - loss: 2774.6581 - acc: 0.9345 - mDice: 0.6781 - val_loss: 4246.6117 - val_acc: 0.9306 - val_mDice: 0.5375

Epoch 00053: val_mDice did not improve from 0.54213
Epoch 54/300
 - 3s - loss: 2761.5822 - acc: 0.9348 - mDice: 0.6793 - val_loss: 4451.4903 - val_acc: 0.9179 - val_mDice: 0.5252

Epoch 00054: val_mDice did not improve from 0.54213
Epoch 55/300
 - 3s - loss: 2781.5233 - acc: 0.9346 - mDice: 0.6774 - val_loss: 4427.3592 - val_acc: 0.9237 - val_mDice: 0.5274

Epoch 00055: val_mDice did not improve from 0.54213
Epoch 56/300
 - 4s - loss: 2730.3301 - acc: 0.9351 - mDice: 0.6820 - val_loss: 4352.6053 - val_acc: 0.9190 - val_mDice: 0.5330

Epoch 00056: val_mDice did not improve from 0.54213
Epoch 57/300
 - 4s - loss: 2740.3754 - acc: 0.9350 - mDice: 0.6813 - val_loss: 4177.2929 - val_acc: 0.9294 - val_mDice: 0.5440

Epoch 00057: val_mDice improved from 0.54213 to 0.54404, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 58/300
 - 5s - loss: 2725.9032 - acc: 0.9352 - mDice: 0.6825 - val_loss: 4399.8789 - val_acc: 0.9316 - val_mDice: 0.5301

Epoch 00058: val_mDice did not improve from 0.54404
Epoch 59/300
 - 3s - loss: 2722.3166 - acc: 0.9354 - mDice: 0.6830 - val_loss: 4111.6226 - val_acc: 0.9301 - val_mDice: 0.5472

Epoch 00059: val_mDice improved from 0.54404 to 0.54717, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 60/300
 - 3s - loss: 2701.5149 - acc: 0.9357 - mDice: 0.6852 - val_loss: 4228.5345 - val_acc: 0.9267 - val_mDice: 0.5400

Epoch 00060: val_mDice did not improve from 0.54717
Epoch 61/300
 - 3s - loss: 2661.6105 - acc: 0.9361 - mDice: 0.6886 - val_loss: 4317.3782 - val_acc: 0.9302 - val_mDice: 0.5330

Epoch 00061: val_mDice did not improve from 0.54717
Epoch 62/300
 - 3s - loss: 2681.9803 - acc: 0.9360 - mDice: 0.6870 - val_loss: 4346.1209 - val_acc: 0.9240 - val_mDice: 0.5312

Epoch 00062: val_mDice did not improve from 0.54717
Epoch 63/300
 - 3s - loss: 2648.7737 - acc: 0.9361 - mDice: 0.6898 - val_loss: 4202.1735 - val_acc: 0.9316 - val_mDice: 0.5434

Epoch 00063: val_mDice did not improve from 0.54717
Epoch 64/300
 - 3s - loss: 2675.8284 - acc: 0.9357 - mDice: 0.6878 - val_loss: 4325.9652 - val_acc: 0.9303 - val_mDice: 0.5357

Epoch 00064: val_mDice did not improve from 0.54717
Epoch 65/300
 - 3s - loss: 2651.0264 - acc: 0.9362 - mDice: 0.6898 - val_loss: 4291.3905 - val_acc: 0.9300 - val_mDice: 0.5349

Epoch 00065: val_mDice did not improve from 0.54717
Epoch 66/300
 - 3s - loss: 2637.8209 - acc: 0.9361 - mDice: 0.6909 - val_loss: 4351.4853 - val_acc: 0.9281 - val_mDice: 0.5310

Epoch 00066: val_mDice did not improve from 0.54717
Epoch 67/300
 - 3s - loss: 2603.5587 - acc: 0.9368 - mDice: 0.6944 - val_loss: 4319.2829 - val_acc: 0.9198 - val_mDice: 0.5332

Epoch 00067: val_mDice did not improve from 0.54717
Epoch 68/300
 - 3s - loss: 2611.5111 - acc: 0.9365 - mDice: 0.6936 - val_loss: 4345.4376 - val_acc: 0.9237 - val_mDice: 0.5315

Epoch 00068: val_mDice did not improve from 0.54717
Epoch 69/300
 - 3s - loss: 2584.2481 - acc: 0.9367 - mDice: 0.6964 - val_loss: 4215.1854 - val_acc: 0.9283 - val_mDice: 0.5412

Epoch 00069: val_mDice did not improve from 0.54717
Epoch 70/300
 - 3s - loss: 2567.6246 - acc: 0.9366 - mDice: 0.6977 - val_loss: 4389.0992 - val_acc: 0.9238 - val_mDice: 0.5299

Epoch 00070: val_mDice did not improve from 0.54717
Epoch 71/300
 - 3s - loss: 2589.2646 - acc: 0.9368 - mDice: 0.6960 - val_loss: 4364.0906 - val_acc: 0.9295 - val_mDice: 0.5297

Epoch 00071: val_mDice did not improve from 0.54717
Epoch 72/300
 - 3s - loss: 2571.4869 - acc: 0.9369 - mDice: 0.6976 - val_loss: 4185.3986 - val_acc: 0.9301 - val_mDice: 0.5422

Epoch 00072: val_mDice did not improve from 0.54717
Epoch 73/300
 - 3s - loss: 2550.9945 - acc: 0.9370 - mDice: 0.6994 - val_loss: 4265.7746 - val_acc: 0.9321 - val_mDice: 0.5368

Epoch 00073: val_mDice did not improve from 0.54717
Epoch 74/300
 - 4s - loss: 2546.4348 - acc: 0.9372 - mDice: 0.6999 - val_loss: 4173.6430 - val_acc: 0.9308 - val_mDice: 0.5423

Epoch 00074: val_mDice did not improve from 0.54717
Epoch 75/300
 - 3s - loss: 2549.1225 - acc: 0.9371 - mDice: 0.6998 - val_loss: 4204.0848 - val_acc: 0.9276 - val_mDice: 0.5409

Epoch 00075: val_mDice did not improve from 0.54717
Epoch 76/300
 - 4s - loss: 2527.8059 - acc: 0.9374 - mDice: 0.7017 - val_loss: 4241.9906 - val_acc: 0.9306 - val_mDice: 0.5387

Epoch 00076: val_mDice did not improve from 0.54717
Epoch 77/300
 - 4s - loss: 2532.2146 - acc: 0.9372 - mDice: 0.7014 - val_loss: 4395.0215 - val_acc: 0.9303 - val_mDice: 0.5279

Epoch 00077: val_mDice did not improve from 0.54717
Epoch 78/300
 - 3s - loss: 2517.2227 - acc: 0.9373 - mDice: 0.7030 - val_loss: 4308.8069 - val_acc: 0.9321 - val_mDice: 0.5344

Epoch 00078: val_mDice did not improve from 0.54717
Epoch 79/300
 - 3s - loss: 2522.3050 - acc: 0.9375 - mDice: 0.7024 - val_loss: 4269.7762 - val_acc: 0.9314 - val_mDice: 0.5380

Epoch 00079: val_mDice did not improve from 0.54717
Epoch 80/300
 - 3s - loss: 2510.3211 - acc: 0.9375 - mDice: 0.7035 - val_loss: 4373.9774 - val_acc: 0.9245 - val_mDice: 0.5291

Epoch 00080: val_mDice did not improve from 0.54717
Epoch 81/300
 - 3s - loss: 2540.7217 - acc: 0.9377 - mDice: 0.7039 - val_loss: 4370.1557 - val_acc: 0.9291 - val_mDice: 0.5283

Epoch 00081: val_mDice did not improve from 0.54717
Epoch 82/300
 - 3s - loss: 2499.1137 - acc: 0.9377 - mDice: 0.7046 - val_loss: 4293.3081 - val_acc: 0.9297 - val_mDice: 0.5342

Epoch 00082: val_mDice did not improve from 0.54717
Epoch 83/300
 - 3s - loss: 2463.4132 - acc: 0.9379 - mDice: 0.7079 - val_loss: 4332.1050 - val_acc: 0.9250 - val_mDice: 0.5323

Epoch 00083: val_mDice did not improve from 0.54717
Epoch 84/300
 - 3s - loss: 2469.9705 - acc: 0.9379 - mDice: 0.7075 - val_loss: 4329.1324 - val_acc: 0.9261 - val_mDice: 0.5326

Epoch 00084: val_mDice did not improve from 0.54717
Epoch 85/300
 - 3s - loss: 2477.1077 - acc: 0.9379 - mDice: 0.7068 - val_loss: 4579.9791 - val_acc: 0.9295 - val_mDice: 0.5139

Epoch 00085: val_mDice did not improve from 0.54717
Epoch 86/300
 - 3s - loss: 2465.2127 - acc: 0.9379 - mDice: 0.7078 - val_loss: 4491.5317 - val_acc: 0.9297 - val_mDice: 0.5219

Epoch 00086: val_mDice did not improve from 0.54717
Epoch 87/300
 - 3s - loss: 2455.6311 - acc: 0.9382 - mDice: 0.7090 - val_loss: 4638.1370 - val_acc: 0.9185 - val_mDice: 0.5119

Epoch 00087: val_mDice did not improve from 0.54717
Epoch 88/300
 - 3s - loss: 2433.3988 - acc: 0.9384 - mDice: 0.7109 - val_loss: 5079.4846 - val_acc: 0.9038 - val_mDice: 0.4825

Epoch 00088: val_mDice did not improve from 0.54717
Epoch 89/300
 - 3s - loss: 2456.3307 - acc: 0.9379 - mDice: 0.7090 - val_loss: 4343.5874 - val_acc: 0.9283 - val_mDice: 0.5302

Epoch 00089: val_mDice did not improve from 0.54717
Restoring model weights from the end of the best epoch
Epoch 00089: early stopping
{'val_loss': [21688.42043832632, 15495.438955453727, 12659.027231069711, 8737.559598482572, 7579.268629807692, 9165.1337890625, 6578.47500375601, 9117.067410982572, 6613.23481633113, 5734.0444899338945, 7455.173621544471, 5924.486065204327, 6837.083899864783, 8255.060096153846, 5199.166475736178, 4841.442861703726, 4853.0386962890625, 5024.8838454026445, 5001.075307992788, 5496.308218149038, 4501.883920522837, 4535.213641826923, 4962.747586763822, 4771.2661696213945, 4708.8133544921875, 5656.79496882512, 4477.223858173077, 4546.704204852765, 4367.438025841346, 4561.682833158053, 4434.266394981971, 4189.538771409255, 4400.643977238582, 4507.701772836538, 4298.41392164964, 4405.423123873197, 4517.592810997596, 4310.866004356971, 4515.85883976863, 4261.471613957332, 4592.79603928786, 4567.509605994592, 4403.21644944411, 4454.3096923828125, 4468.339421198918, 4212.832735501803, 4546.527108999399, 4460.181434044471, 4181.353233924279, 4395.212848369892, 4328.128145658053, 4548.922189565806, 4246.611684945913, 4451.49032827524, 4427.359173114483, 4352.605309119592, 4177.292903019832, 4399.87890625, 4111.622600848858, 4228.534489558293, 4317.378169133113, 4346.120943509615, 4202.173490084135, 4325.965181790865, 4291.39053109976, 4351.485290527344, 4319.282921424279, 4345.437561035156, 4215.185443584735, 4389.099219689002, 4364.090557391827, 4185.398629995493, 4265.77455491286, 4173.64297250601, 4204.084791917067, 4241.990586500901, 4395.021456204928, 4308.806917630709, 4269.7762451171875, 4373.977407602163, 4370.155719463642, 4293.308133638822, 4332.10498046875, 4329.132427509015, 4579.979088416467, 4491.531728891226, 4638.136972280649, 5079.484633225661, 4343.587369478666], 'val_acc': [0.6590413336570446, 0.8120229335931631, 0.8806537756553063, 0.9011286565890679, 0.8817002154313601, 0.8749261842324183, 0.9009678868147043, 0.9017665363275088, 0.9068456796499399, 0.8994232668326452, 0.906460885818188, 0.90754945232318, 0.9086775756799258, 0.9110155197290274, 0.8994048146101145, 0.9098346623090597, 0.9207099974155426, 0.9041413687742673, 0.9038909902939429, 0.8989172279834747, 0.9201195858992063, 0.9214163720607758, 0.9259472970779126, 0.9265008156116192, 0.9275076756110558, 0.9243895732439481, 0.9260633037640498, 0.9244818228941697, 0.9217827434723194, 0.912886958855849, 0.9297929131067716, 0.9265350699424744, 0.9267248373765212, 0.9273864512260144, 0.9283274343380561, 0.9181268719526438, 0.9143208104830521, 0.9225840339293847, 0.9142996966838837, 0.9205940251167004, 0.9116507676931528, 0.9136776626110077, 0.9170515147539285, 0.9248640216313876, 0.9305704671602982, 0.9261080897771395, 0.9162212266371801, 0.9178290642224826, 0.9221517764605008, 0.9284064769744873, 0.9261977076530457, 0.9182454806107742, 0.9305731447843405, 0.9179213276276221, 0.9236805118047274, 0.9190283211377951, 0.9293817488046793, 0.9315510323414435, 0.930135564162181, 0.9266985127559075, 0.9301698551728175, 0.9239888878969046, 0.9316168840114887, 0.9303253384736868, 0.9300143283147079, 0.928140266583516, 0.9198427888063284, 0.9237306049236884, 0.9283010684526883, 0.923833422935926, 0.9295267393955817, 0.9300828942885766, 0.9321414507352389, 0.9307971848891332, 0.9276447341992304, 0.9306100079646478, 0.9302963866637304, 0.9321098052538358, 0.9313770280434535, 0.9244607090950012, 0.9291313726168412, 0.9297243883976569, 0.9250405912215893, 0.9260711853320782, 0.9294687211513519, 0.9297481179237366, 0.9185196321744186, 0.9037512724216168, 0.92826941380134], 'val_mDice': [0.10578591663103837, 0.18530546759183592, 0.23492752760648727, 0.3046983079268382, 0.3527917495140663, 0.3240800230548932, 0.403021477162838, 0.3386188991940938, 0.4071890918108133, 0.440983031804745, 0.38913607224822044, 0.433217267290904, 0.4112795634338489, 0.39782390284996766, 0.47261861654428333, 0.4968116065630546, 0.4952167347073555, 0.4864331598465259, 0.48871897906064987, 0.46693132473872256, 0.5184922487689898, 0.5154935843669451, 0.48680943709153396, 0.5000189307790536, 0.5037531331181526, 0.45217043820482034, 0.5186762024576848, 0.5148298809161553, 0.5293662204192235, 0.5169767410709307, 0.5244258475991396, 0.5405303274209683, 0.5269232733318439, 0.5180129692531549, 0.5332311644003942, 0.5287633492396429, 0.5206625748139161, 0.534607293514105, 0.5193879845050665, 0.5377945091861945, 0.515441469848156, 0.5176175786898687, 0.527773152750272, 0.5247991835841765, 0.5226762372140701, 0.5409884922779523, 0.519234051498083, 0.5246056696543326, 0.5421320801744094, 0.5282684415578842, 0.5325867963524965, 0.5186298558345208, 0.5374585000368265, 0.5251566022634506, 0.5273964863557082, 0.5329512862058786, 0.5440411667984265, 0.5300800075324682, 0.5471695592770209, 0.5400107328135234, 0.5330166103175054, 0.5312161755103332, 0.5433866765636665, 0.5357214418741373, 0.5349390529669248, 0.5309726727696565, 0.5332375019788742, 0.5315175526417218, 0.5412226178898261, 0.5298548478346604, 0.5297450721263885, 0.5422190410586504, 0.5368259818508074, 0.5423072587985259, 0.5408718998615558, 0.5386946645493691, 0.5279433114024309, 0.5343785661344345, 0.5380129458812567, 0.5291413447031608, 0.5282660229847982, 0.5342285741980259, 0.5323080672667577, 0.532557436479972, 0.5138770797504828, 0.521859809756279, 0.511914468728579, 0.4824541491957811, 0.5301621324167802], 'loss': [29351.533313679247, 21387.96488981427, 15177.526404038916, 11225.522479363208, 8522.966612617925, 7352.473135318396, 6707.355325950766, 6213.215633752211, 5716.932911998821, 5370.081585578198, 5098.067438089623, 4905.748367021669, 4696.983992666568, 4566.285042240935, 4372.228844984523, 4266.589459113355, 4173.513122558594, 4045.96951927329, 4058.8491360646376, 3900.5139275316924, 3774.8283795050856, 3730.3778214364684, 3674.5292669332252, 3614.641491008255, 3546.582428554319, 3474.278072717055, 3484.650751077904, 3400.40332376732, 3331.3848876953125, 3294.9318398529626, 3286.2711515606575, 3228.5165416789505, 3211.2203737654777, 3168.1175041918486, 3169.1769374631485, 3110.4794622457252, 3076.1643457952537, 3049.272555369251, 3067.488761470003, 3003.2608435288917, 2959.9108437592126, 2953.78159433041, 2953.382274699661, 2943.210995080336, 2924.264139427329, 2907.134596338812, 2871.459294157208, 2855.71414472472, 2824.5702733453713, 2810.2465221477005, 2824.892405383992, 2807.7654937168336, 2774.6581006320016, 2761.582199384581, 2781.523325794148, 2730.330058547686, 2740.3754272460938, 2725.903213213075, 2722.3166354197374, 2701.5148568783166, 2661.6104874520934, 2681.980302918632, 2648.7737415241745, 2675.8283875663324, 2651.026421313016, 2637.820949338517, 2603.55873770084, 2611.511102640404, 2584.248075665168, 2567.624590028007, 2589.2646064038545, 2571.4869476894164, 2550.99449186505, 2546.4348409400795, 2549.122533258402, 2527.805858684036, 2532.2145523934996, 2517.222729377027, 2522.3050341336234, 2510.3210518315154, 2540.7216739294663, 2499.1136900703864, 2463.41316309515, 2469.970466469819, 2477.1076591059846, 2465.2126741229363, 2455.6311265477593, 2433.3988025593308, 2456.3306694750518], 'acc': [0.27147558247143366, 0.7521990557324212, 0.8568268215881204, 0.8838345110416412, 0.8882731657545522, 0.8899295397524564, 0.8925621501117382, 0.8943655443079067, 0.8966975344239541, 0.8993944081495393, 0.9016011666576818, 0.9039699272164758, 0.9059698668853292, 0.9088144111183455, 0.9115743791719653, 0.9137535255472615, 0.9156730360579941, 0.9176461347993815, 0.9179331277901271, 0.9195421152519729, 0.9211848400673777, 0.9218705996589841, 0.9225806073760087, 0.923329269267478, 0.924229805761913, 0.9251278835647511, 0.9254045902558092, 0.92629858935779, 0.9272006142814204, 0.9275393247042062, 0.928021879972152, 0.928641825633229, 0.9288153462814834, 0.9294255971908569, 0.9295512780828296, 0.930510255244543, 0.9305786588844264, 0.9311598097940661, 0.931005226834765, 0.9318272094681578, 0.9320851030214777, 0.932193527244172, 0.9324849067993883, 0.9324095848034013, 0.9326820986450843, 0.9329949465562712, 0.9333498840624431, 0.9334089129038576, 0.9340438519446355, 0.9338371677781051, 0.9339262542297255, 0.9341007496388454, 0.9345068869725713, 0.9347581885895639, 0.9345897053772548, 0.9351016836908629, 0.9350206067539611, 0.9352145726388356, 0.9353565376884533, 0.935669519428937, 0.936106949763478, 0.9359779054263853, 0.936053289557403, 0.9357441230764929, 0.9361653285768797, 0.9361145167418246, 0.9367565720711114, 0.9364896889002818, 0.936743640674735, 0.9366294019064814, 0.9368046077917207, 0.936899906340635, 0.9370498932757467, 0.9372050582237963, 0.9370534490301924, 0.9374042462627843, 0.9371688565555608, 0.9373472931812394, 0.9374568113740885, 0.9375076240526056, 0.9376746269891847, 0.937699001633896, 0.9378708435117074, 0.9379426659840457, 0.9379173222015489, 0.9378652153712399, 0.938233603284044, 0.9383905096998755, 0.9379001951442575], 'mDice': [0.04405897057105629, 0.10382372154942099, 0.18971758624011614, 0.2604027212650146, 0.32423903301077067, 0.3694455433847769, 0.40050392162125065, 0.42674962656115584, 0.4545052951236941, 0.4764444506112135, 0.4937003789083013, 0.5068738272167602, 0.5211109869041533, 0.531444068506079, 0.5444385549932156, 0.5531516898915453, 0.5598679643194631, 0.5693586859500633, 0.5693883850889386, 0.5806898553416414, 0.5908848674229856, 0.594155343917181, 0.5988934492727496, 0.6038764872640934, 0.6093812891334858, 0.6156299600623688, 0.6152715736402655, 0.6217693180408118, 0.6276374428339724, 0.6306484619963844, 0.6317956562874452, 0.636630264655599, 0.6382105662575308, 0.6417111335497983, 0.6420553849553162, 0.6472809216323888, 0.6500454775567325, 0.6528251027723528, 0.6512103044199493, 0.6568220766647807, 0.6605356377813051, 0.660957063706416, 0.6614748065201741, 0.6623359876421263, 0.6640867188854037, 0.6655319386495734, 0.6688562041183688, 0.6702866759502663, 0.6733544755656764, 0.6744573054448614, 0.6734657861151785, 0.6750145368980911, 0.678105611846132, 0.6792828946743371, 0.6773670819008125, 0.6820196793326792, 0.6812501296682177, 0.682507833219924, 0.6830277170212764, 0.6851735919151666, 0.6885770101029918, 0.6870165950847122, 0.689832368830465, 0.6878181993961334, 0.689797283624703, 0.6908594946253974, 0.6944033306724621, 0.6936038063382203, 0.6963651860659977, 0.6976876486584825, 0.6960383324690584, 0.6975713779903808, 0.6994458363865906, 0.6999085385282084, 0.6997816270252444, 0.701721874329279, 0.7013848761342606, 0.7029873776548313, 0.7023751887510408, 0.7034843381283418, 0.7038921463601994, 0.7045882209291998, 0.7078881840098579, 0.707532563299503, 0.7067746368219268, 0.7077863868677391, 0.7090374942658082, 0.7109240560599093, 0.709041768368685]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.16s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.74s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.42s/it]
predicting train subjects:   0%|          | 0/114 [00:00<?, ?it/s]predicting train subjects:   1%|          | 1/114 [00:02<03:55,  2.08s/it]predicting train subjects:   2%|▏         | 2/114 [00:03<03:34,  1.92s/it]predicting train subjects:   3%|▎         | 3/114 [00:05<03:26,  1.86s/it]predicting train subjects:   4%|▎         | 4/114 [00:06<03:16,  1.79s/it]predicting train subjects:   4%|▍         | 5/114 [00:08<03:18,  1.83s/it]predicting train subjects:   5%|▌         | 6/114 [00:10<03:08,  1.74s/it]predicting train subjects:   6%|▌         | 7/114 [00:12<03:01,  1.70s/it]predicting train subjects:   7%|▋         | 8/114 [00:13<02:51,  1.62s/it]predicting train subjects:   8%|▊         | 9/114 [00:15<03:01,  1.73s/it]predicting train subjects:   9%|▉         | 10/114 [00:17<03:09,  1.82s/it]predicting train subjects:  10%|▉         | 11/114 [00:19<03:09,  1.84s/it]predicting train subjects:  11%|█         | 12/114 [00:20<02:58,  1.75s/it]predicting train subjects:  11%|█▏        | 13/114 [00:22<02:54,  1.73s/it]predicting train subjects:  12%|█▏        | 14/114 [00:24<02:52,  1.72s/it]predicting train subjects:  13%|█▎        | 15/114 [00:26<03:05,  1.87s/it]predicting train subjects:  14%|█▍        | 16/114 [00:28<03:17,  2.01s/it]predicting train subjects:  15%|█▍        | 17/114 [00:30<03:17,  2.04s/it]predicting train subjects:  16%|█▌        | 18/114 [00:32<03:05,  1.93s/it]predicting train subjects:  17%|█▋        | 19/114 [00:34<02:56,  1.85s/it]predicting train subjects:  18%|█▊        | 20/114 [00:36<03:00,  1.92s/it]predicting train subjects:  18%|█▊        | 21/114 [00:38<02:59,  1.93s/it]predicting train subjects:  19%|█▉        | 22/114 [00:40<02:51,  1.86s/it]predicting train subjects:  20%|██        | 23/114 [00:41<02:43,  1.80s/it]predicting train subjects:  21%|██        | 24/114 [00:43<02:37,  1.75s/it]predicting train subjects:  22%|██▏       | 25/114 [00:45<02:41,  1.82s/it]predicting train subjects:  23%|██▎       | 26/114 [00:47<02:43,  1.86s/it]predicting train subjects:  24%|██▎       | 27/114 [00:49<02:41,  1.86s/it]predicting train subjects:  25%|██▍       | 28/114 [00:50<02:28,  1.73s/it]predicting train subjects:  25%|██▌       | 29/114 [00:52<02:22,  1.68s/it]predicting train subjects:  26%|██▋       | 30/114 [00:54<02:29,  1.78s/it]predicting train subjects:  27%|██▋       | 31/114 [00:56<02:36,  1.88s/it]predicting train subjects:  28%|██▊       | 32/114 [00:58<02:35,  1.90s/it]predicting train subjects:  29%|██▉       | 33/114 [00:59<02:25,  1.80s/it]predicting train subjects:  30%|██▉       | 34/114 [01:01<02:18,  1.73s/it]predicting train subjects:  31%|███       | 35/114 [01:02<02:10,  1.65s/it]predicting train subjects:  32%|███▏      | 36/114 [01:04<02:16,  1.75s/it]predicting train subjects:  32%|███▏      | 37/114 [01:07<02:30,  1.95s/it]predicting train subjects:  33%|███▎      | 38/114 [01:09<02:36,  2.05s/it]predicting train subjects:  34%|███▍      | 39/114 [01:11<02:30,  2.01s/it]predicting train subjects:  35%|███▌      | 40/114 [01:13<02:22,  1.92s/it]predicting train subjects:  36%|███▌      | 41/114 [01:15<02:36,  2.14s/it]predicting train subjects:  37%|███▋      | 42/114 [01:17<02:33,  2.13s/it]predicting train subjects:  38%|███▊      | 43/114 [01:19<02:21,  2.00s/it]predicting train subjects:  39%|███▊      | 44/114 [01:21<02:17,  1.97s/it]predicting train subjects:  39%|███▉      | 45/114 [01:22<02:06,  1.84s/it]predicting train subjects:  40%|████      | 46/114 [01:25<02:11,  1.93s/it]predicting train subjects:  41%|████      | 47/114 [01:27<02:13,  2.00s/it]predicting train subjects:  42%|████▏     | 48/114 [01:29<02:12,  2.01s/it]predicting train subjects:  43%|████▎     | 49/114 [01:31<02:05,  1.93s/it]predicting train subjects:  44%|████▍     | 50/114 [01:32<01:55,  1.81s/it]predicting train subjects:  45%|████▍     | 51/114 [01:34<01:56,  1.85s/it]predicting train subjects:  46%|████▌     | 52/114 [01:36<01:50,  1.79s/it]predicting train subjects:  46%|████▋     | 53/114 [01:37<01:48,  1.77s/it]predicting train subjects:  47%|████▋     | 54/114 [01:39<01:40,  1.68s/it]predicting train subjects:  48%|████▊     | 55/114 [01:41<01:46,  1.80s/it]predicting train subjects:  49%|████▉     | 56/114 [01:43<01:50,  1.90s/it]predicting train subjects:  50%|█████     | 57/114 [01:45<01:49,  1.92s/it]predicting train subjects:  51%|█████     | 58/114 [01:47<01:49,  1.96s/it]predicting train subjects:  52%|█████▏    | 59/114 [01:49<01:41,  1.85s/it]predicting train subjects:  53%|█████▎    | 60/114 [01:50<01:36,  1.79s/it]predicting train subjects:  54%|█████▎    | 61/114 [01:52<01:37,  1.84s/it]predicting train subjects:  54%|█████▍    | 62/114 [01:54<01:33,  1.79s/it]predicting train subjects:  55%|█████▌    | 63/114 [01:56<01:36,  1.88s/it]predicting train subjects:  56%|█████▌    | 64/114 [01:58<01:30,  1.80s/it]predicting train subjects:  57%|█████▋    | 65/114 [02:00<01:32,  1.89s/it]predicting train subjects:  58%|█████▊    | 66/114 [02:02<01:35,  2.00s/it]predicting train subjects:  59%|█████▉    | 67/114 [02:04<01:32,  1.97s/it]predicting train subjects:  60%|█████▉    | 68/114 [02:06<01:29,  1.95s/it]predicting train subjects:  61%|██████    | 69/114 [02:07<01:21,  1.80s/it]predicting train subjects:  61%|██████▏   | 70/114 [02:09<01:16,  1.74s/it]predicting train subjects:  62%|██████▏   | 71/114 [02:10<01:12,  1.68s/it]predicting train subjects:  63%|██████▎   | 72/114 [02:12<01:09,  1.66s/it]predicting train subjects:  64%|██████▍   | 73/114 [02:14<01:13,  1.79s/it]predicting train subjects:  65%|██████▍   | 74/114 [02:16<01:09,  1.73s/it]predicting train subjects:  66%|██████▌   | 75/114 [02:18<01:12,  1.85s/it]predicting train subjects:  67%|██████▋   | 76/114 [02:20<01:14,  1.97s/it]predicting train subjects:  68%|██████▊   | 77/114 [02:22<01:15,  2.03s/it]predicting train subjects:  68%|██████▊   | 78/114 [02:24<01:08,  1.90s/it]predicting train subjects:  69%|██████▉   | 79/114 [02:26<01:05,  1.87s/it]predicting train subjects:  70%|███████   | 80/114 [02:27<01:00,  1.77s/it]predicting train subjects:  71%|███████   | 81/114 [02:29<00:57,  1.74s/it]predicting train subjects:  72%|███████▏  | 82/114 [02:31<00:59,  1.85s/it]predicting train subjects:  73%|███████▎  | 83/114 [02:33<01:00,  1.95s/it]predicting train subjects:  74%|███████▎  | 84/114 [02:35<00:58,  1.96s/it]predicting train subjects:  75%|███████▍  | 85/114 [02:37<00:53,  1.83s/it]predicting train subjects:  75%|███████▌  | 86/114 [02:38<00:49,  1.77s/it]predicting train subjects:  76%|███████▋  | 87/114 [02:41<00:51,  1.90s/it]predicting train subjects:  77%|███████▋  | 88/114 [02:42<00:49,  1.92s/it]predicting train subjects:  78%|███████▊  | 89/114 [02:44<00:45,  1.83s/it]predicting train subjects:  79%|███████▉  | 90/114 [02:46<00:43,  1.81s/it]predicting train subjects:  80%|███████▉  | 91/114 [02:47<00:39,  1.72s/it]predicting train subjects:  81%|████████  | 92/114 [02:49<00:36,  1.65s/it]predicting train subjects:  82%|████████▏ | 93/114 [02:51<00:36,  1.75s/it]predicting train subjects:  82%|████████▏ | 94/114 [02:53<00:36,  1.85s/it]predicting train subjects:  83%|████████▎ | 95/114 [02:54<00:32,  1.74s/it]predicting train subjects:  84%|████████▍ | 96/114 [02:56<00:30,  1.68s/it]predicting train subjects:  85%|████████▌ | 97/114 [02:58<00:30,  1.78s/it]predicting train subjects:  86%|████████▌ | 98/114 [03:00<00:28,  1.77s/it]predicting train subjects:  87%|████████▋ | 99/114 [03:01<00:25,  1.69s/it]predicting train subjects:  88%|████████▊ | 100/114 [03:03<00:23,  1.68s/it]predicting train subjects:  89%|████████▊ | 101/114 [03:05<00:22,  1.72s/it]predicting train subjects:  89%|████████▉ | 102/114 [03:06<00:20,  1.68s/it]predicting train subjects:  90%|█████████ | 103/114 [03:08<00:17,  1.62s/it]predicting train subjects:  91%|█████████ | 104/114 [03:10<00:17,  1.76s/it]predicting train subjects:  92%|█████████▏| 105/114 [03:12<00:16,  1.87s/it]predicting train subjects:  93%|█████████▎| 106/114 [03:14<00:14,  1.83s/it]predicting train subjects:  94%|█████████▍| 107/114 [03:15<00:12,  1.81s/it]predicting train subjects:  95%|█████████▍| 108/114 [03:17<00:11,  1.85s/it]predicting train subjects:  96%|█████████▌| 109/114 [03:19<00:08,  1.77s/it]predicting train subjects:  96%|█████████▋| 110/114 [03:21<00:06,  1.72s/it]predicting train subjects:  97%|█████████▋| 111/114 [03:22<00:05,  1.70s/it]predicting train subjects:  98%|█████████▊| 112/114 [03:25<00:03,  1.87s/it]predicting train subjects:  99%|█████████▉| 113/114 [03:27<00:01,  1.98s/it]predicting train subjects: 100%|██████████| 114/114 [03:29<00:00,  1.92s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a’: File exists
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:13,  1.53s/it]Loading train:   1%|          | 2/285 [00:02<06:42,  1.42s/it]Loading train:   1%|          | 3/285 [00:04<06:38,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:05<06:14,  1.33s/it]Loading train:   2%|▏         | 5/285 [00:06<06:23,  1.37s/it]Loading train:   2%|▏         | 6/285 [00:07<06:06,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:28,  1.40s/it]Loading train:   3%|▎         | 8/285 [00:10<06:14,  1.35s/it]Loading train:   3%|▎         | 9/285 [00:12<06:26,  1.40s/it]Loading train:   4%|▎         | 10/285 [00:13<05:52,  1.28s/it]Loading train:   4%|▍         | 11/285 [00:14<05:08,  1.13s/it]Loading train:   4%|▍         | 12/285 [00:14<04:53,  1.08s/it]Loading train:   5%|▍         | 13/285 [00:15<04:24,  1.03it/s]Loading train:   5%|▍         | 14/285 [00:16<04:18,  1.05it/s]Loading train:   5%|▌         | 15/285 [00:17<04:41,  1.04s/it]Loading train:   6%|▌         | 16/285 [00:18<04:45,  1.06s/it]Loading train:   6%|▌         | 17/285 [00:19<04:34,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:20<04:33,  1.02s/it]Loading train:   7%|▋         | 19/285 [00:21<04:34,  1.03s/it]Loading train:   7%|▋         | 20/285 [00:23<04:52,  1.10s/it]Loading train:   7%|▋         | 21/285 [00:24<04:53,  1.11s/it]Loading train:   8%|▊         | 22/285 [00:25<04:31,  1.03s/it]Loading train:   8%|▊         | 23/285 [00:26<04:19,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:26<04:00,  1.09it/s]Loading train:   9%|▉         | 25/285 [00:27<04:01,  1.08it/s]Loading train:   9%|▉         | 26/285 [00:28<04:02,  1.07it/s]Loading train:   9%|▉         | 27/285 [00:29<03:53,  1.10it/s]Loading train:  10%|▉         | 28/285 [00:30<03:56,  1.09it/s]Loading train:  10%|█         | 29/285 [00:31<03:54,  1.09it/s]Loading train:  11%|█         | 30/285 [00:32<04:20,  1.02s/it]Loading train:  11%|█         | 31/285 [00:33<04:19,  1.02s/it]Loading train:  11%|█         | 32/285 [00:34<04:09,  1.02it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:08,  1.01it/s]Loading train:  12%|█▏        | 34/285 [00:36<04:05,  1.02it/s]Loading train:  12%|█▏        | 35/285 [00:37<04:10,  1.00s/it]Loading train:  13%|█▎        | 36/285 [00:38<04:07,  1.00it/s]Loading train:  13%|█▎        | 37/285 [00:39<04:08,  1.00s/it]Loading train:  13%|█▎        | 38/285 [00:40<04:06,  1.00it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:51,  1.06it/s]Loading train:  14%|█▍        | 40/285 [00:42<03:46,  1.08it/s]Loading train:  14%|█▍        | 41/285 [00:43<03:44,  1.09it/s]Loading train:  15%|█▍        | 42/285 [00:44<03:35,  1.13it/s]Loading train:  15%|█▌        | 43/285 [00:45<04:07,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:46<04:03,  1.01s/it]Loading train:  16%|█▌        | 45/285 [00:47<03:55,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:48<03:53,  1.02it/s]Loading train:  16%|█▋        | 47/285 [00:49<03:48,  1.04it/s]Loading train:  17%|█▋        | 48/285 [00:50<03:44,  1.05it/s]Loading train:  17%|█▋        | 49/285 [00:51<03:44,  1.05it/s]Loading train:  18%|█▊        | 50/285 [00:52<03:50,  1.02it/s]Loading train:  18%|█▊        | 51/285 [00:53<03:49,  1.02it/s]Loading train:  18%|█▊        | 52/285 [00:54<03:47,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:42,  1.04it/s]Loading train:  19%|█▉        | 54/285 [00:56<03:50,  1.00it/s]Loading train:  19%|█▉        | 55/285 [00:56<03:34,  1.07it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:37,  1.05it/s]Loading train:  20%|██        | 57/285 [00:58<03:27,  1.10it/s]Loading train:  20%|██        | 58/285 [00:59<03:36,  1.05it/s]Loading train:  21%|██        | 59/285 [01:00<03:40,  1.02it/s]Loading train:  21%|██        | 60/285 [01:01<03:51,  1.03s/it]Loading train:  21%|██▏       | 61/285 [01:02<03:35,  1.04it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:33,  1.04it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:48,  1.03s/it]Loading train:  22%|██▏       | 64/285 [01:06<04:05,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:31,  1.24s/it]Loading train:  23%|██▎       | 66/285 [01:09<04:37,  1.27s/it]Loading train:  24%|██▎       | 67/285 [01:10<04:29,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:11<04:06,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:47,  1.05s/it]Loading train:  25%|██▍       | 70/285 [01:13<03:49,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:14<03:43,  1.04s/it]Loading train:  25%|██▌       | 72/285 [01:15<03:40,  1.03s/it]Loading train:  26%|██▌       | 73/285 [01:16<03:39,  1.03s/it]Loading train:  26%|██▌       | 74/285 [01:17<03:34,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:18<03:30,  1.00s/it]Loading train:  27%|██▋       | 76/285 [01:18<03:26,  1.01it/s]Loading train:  27%|██▋       | 77/285 [01:19<03:17,  1.05it/s]Loading train:  27%|██▋       | 78/285 [01:20<03:20,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:22<03:35,  1.05s/it]Loading train:  28%|██▊       | 80/285 [01:23<03:28,  1.01s/it]Loading train:  28%|██▊       | 81/285 [01:24<03:29,  1.03s/it]Loading train:  29%|██▉       | 82/285 [01:24<03:16,  1.03it/s]Loading train:  29%|██▉       | 83/285 [01:25<03:06,  1.08it/s]Loading train:  29%|██▉       | 84/285 [01:26<03:01,  1.11it/s]Loading train:  30%|██▉       | 85/285 [01:27<03:03,  1.09it/s]Loading train:  30%|███       | 86/285 [01:28<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:29<03:09,  1.05it/s]Loading train:  31%|███       | 88/285 [01:30<03:00,  1.09it/s]Loading train:  31%|███       | 89/285 [01:31<02:54,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:32<03:10,  1.03it/s]Loading train:  32%|███▏      | 91/285 [01:33<03:02,  1.06it/s]Loading train:  32%|███▏      | 92/285 [01:34<03:01,  1.06it/s]Loading train:  33%|███▎      | 93/285 [01:34<02:53,  1.11it/s]Loading train:  33%|███▎      | 94/285 [01:35<02:52,  1.11it/s]Loading train:  33%|███▎      | 95/285 [01:36<02:57,  1.07it/s]Loading train:  34%|███▎      | 96/285 [01:37<02:54,  1.08it/s]Loading train:  34%|███▍      | 97/285 [01:38<03:01,  1.04it/s]Loading train:  34%|███▍      | 98/285 [01:39<02:56,  1.06it/s]Loading train:  35%|███▍      | 99/285 [01:40<02:55,  1.06it/s]Loading train:  35%|███▌      | 100/285 [01:41<02:56,  1.05it/s]Loading train:  35%|███▌      | 101/285 [01:42<02:51,  1.08it/s]Loading train:  36%|███▌      | 102/285 [01:43<02:55,  1.04it/s]Loading train:  36%|███▌      | 103/285 [01:44<02:48,  1.08it/s]Loading train:  36%|███▋      | 104/285 [01:45<02:52,  1.05it/s]Loading train:  37%|███▋      | 105/285 [01:46<03:03,  1.02s/it]Loading train:  37%|███▋      | 106/285 [01:47<02:53,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:48<02:58,  1.00s/it]Loading train:  38%|███▊      | 108/285 [01:49<02:54,  1.01it/s]Loading train:  38%|███▊      | 109/285 [01:50<02:47,  1.05it/s]Loading train:  39%|███▊      | 110/285 [01:51<02:43,  1.07it/s]Loading train:  39%|███▉      | 111/285 [01:51<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:52<02:30,  1.15it/s]Loading train:  40%|███▉      | 113/285 [01:53<02:36,  1.10it/s]Loading train:  40%|████      | 114/285 [01:54<02:34,  1.10it/s]Loading train:  40%|████      | 115/285 [01:55<02:30,  1.13it/s]Loading train:  41%|████      | 116/285 [01:56<02:34,  1.09it/s]Loading train:  41%|████      | 117/285 [01:57<02:28,  1.13it/s]Loading train:  41%|████▏     | 118/285 [01:58<02:27,  1.13it/s]Loading train:  42%|████▏     | 119/285 [01:59<02:38,  1.04it/s]Loading train:  42%|████▏     | 120/285 [02:00<02:36,  1.06it/s]Loading train:  42%|████▏     | 121/285 [02:01<02:58,  1.09s/it]Loading train:  43%|████▎     | 122/285 [02:02<02:58,  1.10s/it]Loading train:  43%|████▎     | 123/285 [02:04<03:05,  1.14s/it]Loading train:  44%|████▎     | 124/285 [02:05<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:05<02:42,  1.01s/it]Loading train:  44%|████▍     | 126/285 [02:06<02:29,  1.07it/s]Loading train:  45%|████▍     | 127/285 [02:07<02:19,  1.13it/s]Loading train:  45%|████▍     | 128/285 [02:08<02:14,  1.17it/s]Loading train:  45%|████▌     | 129/285 [02:08<02:05,  1.25it/s]Loading train:  46%|████▌     | 130/285 [02:09<02:00,  1.29it/s]Loading train:  46%|████▌     | 131/285 [02:10<01:57,  1.31it/s]Loading train:  46%|████▋     | 132/285 [02:11<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:11<01:57,  1.29it/s]Loading train:  47%|████▋     | 134/285 [02:12<01:51,  1.35it/s]Loading train:  47%|████▋     | 135/285 [02:13<01:50,  1.35it/s]Loading train:  48%|████▊     | 136/285 [02:13<01:48,  1.38it/s]Loading train:  48%|████▊     | 137/285 [02:15<02:01,  1.22it/s]Loading train:  48%|████▊     | 138/285 [02:15<02:00,  1.22it/s]Loading train:  49%|████▉     | 139/285 [02:16<02:05,  1.16it/s]Loading train:  49%|████▉     | 140/285 [02:17<02:07,  1.14it/s]Loading train:  49%|████▉     | 141/285 [02:18<02:01,  1.19it/s]Loading train:  50%|████▉     | 142/285 [02:19<02:01,  1.18it/s]Loading train:  50%|█████     | 143/285 [02:20<02:00,  1.18it/s]Loading train:  51%|█████     | 144/285 [02:21<01:59,  1.18it/s]Loading train:  51%|█████     | 145/285 [02:21<02:00,  1.17it/s]Loading train:  51%|█████     | 146/285 [02:22<02:00,  1.16it/s]Loading train:  52%|█████▏    | 147/285 [02:23<01:54,  1.20it/s]Loading train:  52%|█████▏    | 148/285 [02:24<01:52,  1.22it/s]Loading train:  52%|█████▏    | 149/285 [02:25<01:47,  1.26it/s]Loading train:  53%|█████▎    | 150/285 [02:25<01:49,  1.24it/s]Loading train:  53%|█████▎    | 151/285 [02:26<01:53,  1.18it/s]Loading train:  53%|█████▎    | 152/285 [02:27<01:53,  1.17it/s]Loading train:  54%|█████▎    | 153/285 [02:28<01:55,  1.15it/s]Loading train:  54%|█████▍    | 154/285 [02:29<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:30<01:48,  1.20it/s]Loading train:  55%|█████▍    | 156/285 [02:31<01:54,  1.13it/s]Loading train:  55%|█████▌    | 157/285 [02:32<01:49,  1.17it/s]Loading train:  55%|█████▌    | 158/285 [02:32<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:33<01:44,  1.21it/s]Loading train:  56%|█████▌    | 160/285 [02:34<01:38,  1.27it/s]Loading train:  56%|█████▋    | 161/285 [02:35<01:38,  1.26it/s]Loading train:  57%|█████▋    | 162/285 [02:35<01:34,  1.30it/s]Loading train:  57%|█████▋    | 163/285 [02:36<01:35,  1.28it/s]Loading train:  58%|█████▊    | 164/285 [02:37<01:32,  1.30it/s]Loading train:  58%|█████▊    | 165/285 [02:38<01:35,  1.25it/s]Loading train:  58%|█████▊    | 166/285 [02:39<01:44,  1.14it/s]Loading train:  59%|█████▊    | 167/285 [02:40<01:41,  1.16it/s]Loading train:  59%|█████▉    | 168/285 [02:40<01:35,  1.23it/s]Loading train:  59%|█████▉    | 169/285 [02:41<01:31,  1.27it/s]Loading train:  60%|█████▉    | 170/285 [02:42<01:31,  1.26it/s]Loading train:  60%|██████    | 171/285 [02:43<01:29,  1.28it/s]Loading train:  60%|██████    | 172/285 [02:43<01:26,  1.31it/s]Loading train:  61%|██████    | 173/285 [02:44<01:25,  1.30it/s]Loading train:  61%|██████    | 174/285 [02:45<01:23,  1.34it/s]Loading train:  61%|██████▏   | 175/285 [02:46<01:23,  1.31it/s]Loading train:  62%|██████▏   | 176/285 [02:46<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:47<01:25,  1.26it/s]Loading train:  62%|██████▏   | 178/285 [02:48<01:24,  1.27it/s]Loading train:  63%|██████▎   | 179/285 [02:49<01:24,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [02:50<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [02:51<01:30,  1.15it/s]Loading train:  64%|██████▍   | 182/285 [02:52<01:26,  1.19it/s]Loading train:  64%|██████▍   | 183/285 [02:52<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [02:53<01:22,  1.22it/s]Loading train:  65%|██████▍   | 185/285 [02:54<01:21,  1.23it/s]Loading train:  65%|██████▌   | 186/285 [02:55<01:25,  1.16it/s]Loading train:  66%|██████▌   | 187/285 [02:56<01:25,  1.14it/s]Loading train:  66%|██████▌   | 188/285 [02:57<01:27,  1.11it/s]Loading train:  66%|██████▋   | 189/285 [02:58<01:26,  1.11it/s]Loading train:  67%|██████▋   | 190/285 [02:59<01:23,  1.14it/s]Loading train:  67%|██████▋   | 191/285 [03:00<01:26,  1.09it/s]Loading train:  67%|██████▋   | 192/285 [03:00<01:22,  1.12it/s]Loading train:  68%|██████▊   | 193/285 [03:01<01:16,  1.20it/s]Loading train:  68%|██████▊   | 194/285 [03:02<01:14,  1.22it/s]Loading train:  68%|██████▊   | 195/285 [03:02<01:08,  1.31it/s]Loading train:  69%|██████▉   | 196/285 [03:03<01:11,  1.24it/s]Loading train:  69%|██████▉   | 197/285 [03:04<01:12,  1.21it/s]Loading train:  69%|██████▉   | 198/285 [03:05<01:16,  1.14it/s]Loading train:  70%|██████▉   | 199/285 [03:06<01:13,  1.17it/s]Loading train:  70%|███████   | 200/285 [03:07<01:09,  1.23it/s]Loading train:  71%|███████   | 201/285 [03:08<01:12,  1.15it/s]Loading train:  71%|███████   | 202/285 [03:09<01:09,  1.19it/s]Loading train:  71%|███████   | 203/285 [03:10<01:12,  1.13it/s]Loading train:  72%|███████▏  | 204/285 [03:10<01:09,  1.17it/s]Loading train:  72%|███████▏  | 205/285 [03:11<01:05,  1.21it/s]Loading train:  72%|███████▏  | 206/285 [03:12<01:02,  1.26it/s]Loading train:  73%|███████▎  | 207/285 [03:13<01:04,  1.22it/s]Loading train:  73%|███████▎  | 208/285 [03:14<01:09,  1.11it/s]Loading train:  73%|███████▎  | 209/285 [03:15<01:09,  1.09it/s]Loading train:  74%|███████▎  | 210/285 [03:16<01:05,  1.14it/s]Loading train:  74%|███████▍  | 211/285 [03:16<01:03,  1.17it/s]Loading train:  74%|███████▍  | 212/285 [03:17<01:00,  1.21it/s]Loading train:  75%|███████▍  | 213/285 [03:18<00:57,  1.24it/s]Loading train:  75%|███████▌  | 214/285 [03:19<00:55,  1.29it/s]Loading train:  75%|███████▌  | 215/285 [03:20<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:20<00:54,  1.27it/s]Loading train:  76%|███████▌  | 217/285 [03:21<00:56,  1.21it/s]Loading train:  76%|███████▋  | 218/285 [03:22<01:00,  1.11it/s]Loading train:  77%|███████▋  | 219/285 [03:23<01:01,  1.08it/s]Loading train:  77%|███████▋  | 220/285 [03:24<00:55,  1.17it/s]Loading train:  78%|███████▊  | 221/285 [03:25<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:26<00:53,  1.17it/s]Loading train:  78%|███████▊  | 223/285 [03:26<00:51,  1.19it/s]Loading train:  79%|███████▊  | 224/285 [03:27<00:49,  1.22it/s]Loading train:  79%|███████▉  | 225/285 [03:28<00:49,  1.20it/s]Loading train:  79%|███████▉  | 226/285 [03:29<00:51,  1.14it/s]Loading train:  80%|███████▉  | 227/285 [03:30<00:56,  1.03it/s]Loading train:  80%|████████  | 228/285 [03:31<00:55,  1.03it/s]Loading train:  80%|████████  | 229/285 [03:32<00:51,  1.08it/s]Loading train:  81%|████████  | 230/285 [03:33<00:46,  1.19it/s]Loading train:  81%|████████  | 231/285 [03:33<00:42,  1.27it/s]Loading train:  81%|████████▏ | 232/285 [03:34<00:42,  1.26it/s]Loading train:  82%|████████▏ | 233/285 [03:35<00:39,  1.33it/s]Loading train:  82%|████████▏ | 234/285 [03:36<00:41,  1.23it/s]Loading train:  82%|████████▏ | 235/285 [03:36<00:38,  1.30it/s]Loading train:  83%|████████▎ | 236/285 [03:37<00:39,  1.25it/s]Loading train:  83%|████████▎ | 237/285 [03:38<00:39,  1.21it/s]Loading train:  84%|████████▎ | 238/285 [03:39<00:39,  1.20it/s]Loading train:  84%|████████▍ | 239/285 [03:40<00:37,  1.23it/s]Loading train:  84%|████████▍ | 240/285 [03:40<00:35,  1.27it/s]Loading train:  85%|████████▍ | 241/285 [03:41<00:34,  1.29it/s]Loading train:  85%|████████▍ | 242/285 [03:42<00:34,  1.26it/s]Loading train:  85%|████████▌ | 243/285 [03:43<00:33,  1.24it/s]Loading train:  86%|████████▌ | 244/285 [03:44<00:34,  1.19it/s]Loading train:  86%|████████▌ | 245/285 [03:45<00:32,  1.25it/s]Loading train:  86%|████████▋ | 246/285 [03:45<00:32,  1.21it/s]Loading train:  87%|████████▋ | 247/285 [03:46<00:32,  1.17it/s]Loading train:  87%|████████▋ | 248/285 [03:47<00:33,  1.11it/s]Loading train:  87%|████████▋ | 249/285 [03:48<00:31,  1.16it/s]Loading train:  88%|████████▊ | 250/285 [03:49<00:29,  1.19it/s]Loading train:  88%|████████▊ | 251/285 [03:50<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:50<00:25,  1.27it/s]Loading train:  89%|████████▉ | 253/285 [03:51<00:25,  1.26it/s]Loading train:  89%|████████▉ | 254/285 [03:52<00:24,  1.24it/s]Loading train:  89%|████████▉ | 255/285 [03:53<00:24,  1.24it/s]Loading train:  90%|████████▉ | 256/285 [03:53<00:22,  1.31it/s]Loading train:  90%|█████████ | 257/285 [03:54<00:20,  1.33it/s]Loading train:  91%|█████████ | 258/285 [03:55<00:21,  1.26it/s]Loading train:  91%|█████████ | 259/285 [03:56<00:20,  1.28it/s]Loading train:  91%|█████████ | 260/285 [03:57<00:19,  1.26it/s]Loading train:  92%|█████████▏| 261/285 [03:57<00:18,  1.28it/s]Loading train:  92%|█████████▏| 262/285 [03:58<00:17,  1.31it/s]Loading train:  92%|█████████▏| 263/285 [03:59<00:17,  1.27it/s]Loading train:  93%|█████████▎| 264/285 [04:00<00:17,  1.17it/s]Loading train:  93%|█████████▎| 265/285 [04:01<00:17,  1.16it/s]Loading train:  93%|█████████▎| 266/285 [04:02<00:15,  1.23it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:13,  1.29it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [04:04<00:13,  1.16it/s]Loading train:  95%|█████████▍| 270/285 [04:05<00:12,  1.18it/s]Loading train:  95%|█████████▌| 271/285 [04:06<00:11,  1.21it/s]Loading train:  95%|█████████▌| 272/285 [04:07<00:11,  1.18it/s]Loading train:  96%|█████████▌| 273/285 [04:07<00:09,  1.23it/s]Loading train:  96%|█████████▌| 274/285 [04:08<00:09,  1.18it/s]Loading train:  96%|█████████▋| 275/285 [04:09<00:08,  1.17it/s]Loading train:  97%|█████████▋| 276/285 [04:10<00:07,  1.13it/s]Loading train:  97%|█████████▋| 277/285 [04:11<00:07,  1.08it/s]Loading train:  98%|█████████▊| 278/285 [04:12<00:06,  1.09it/s]Loading train:  98%|█████████▊| 279/285 [04:13<00:05,  1.13it/s]Loading train:  98%|█████████▊| 280/285 [04:14<00:04,  1.18it/s]Loading train:  99%|█████████▊| 281/285 [04:15<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [04:16<00:02,  1.10it/s]Loading train:  99%|█████████▉| 283/285 [04:17<00:01,  1.08it/s]Loading train: 100%|█████████▉| 284/285 [04:17<00:00,  1.11it/s]Loading train: 100%|██████████| 285/285 [04:18<00:00,  1.11it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:03, 87.33it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:02, 90.68it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:02, 88.46it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:02, 107.69it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:01, 134.80it/s]concatenating: train:  42%|████▏     | 119/285 [00:00<00:01, 162.96it/s]concatenating: train:  54%|█████▍    | 154/285 [00:00<00:00, 193.86it/s]concatenating: train:  66%|██████▋   | 189/285 [00:00<00:00, 223.75it/s]concatenating: train:  79%|███████▊  | 224/285 [00:00<00:00, 249.89it/s]concatenating: train:  91%|█████████ | 258/285 [00:01<00:00, 270.43it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 183.27it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.53s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.45s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.39s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 32.26it/s]2019-07-07 22:18:21.356235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-07 22:18:21.356350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-07 22:18:21.356367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-07 22:18:21.356377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-07 22:18:21.379383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/45 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/45 [00:00<00:08,  4.90it/s]loading the weights for Res Unet:   7%|▋         | 3/45 [00:00<00:07,  5.78it/s]loading the weights for Res Unet:   9%|▉         | 4/45 [00:00<00:07,  5.42it/s]loading the weights for Res Unet:  20%|██        | 9/45 [00:01<00:07,  5.02it/s]loading the weights for Res Unet:  22%|██▏       | 10/45 [00:02<00:14,  2.34it/s]loading the weights for Res Unet:  27%|██▋       | 12/45 [00:03<00:12,  2.54it/s]loading the weights for Res Unet:  29%|██▉       | 13/45 [00:03<00:10,  2.95it/s]loading the weights for Res Unet:  40%|████      | 18/45 [00:03<00:06,  4.02it/s]loading the weights for Res Unet:  44%|████▍     | 20/45 [00:03<00:05,  4.93it/s]loading the weights for Res Unet:  49%|████▉     | 22/45 [00:04<00:04,  4.66it/s]loading the weights for Res Unet:  58%|█████▊    | 26/45 [00:04<00:03,  6.02it/s]loading the weights for Res Unet:  62%|██████▏   | 28/45 [00:04<00:02,  6.70it/s]loading the weights for Res Unet:  67%|██████▋   | 30/45 [00:05<00:02,  7.43it/s]loading the weights for Res Unet:  71%|███████   | 32/45 [00:07<00:05,  2.40it/s]loading the weights for Res Unet:  80%|████████  | 36/45 [00:07<00:03,  2.95it/s]loading the weights for Res Unet:  84%|████████▍ | 38/45 [00:08<00:01,  3.75it/s]loading the weights for Res Unet:  87%|████████▋ | 39/45 [00:08<00:01,  3.95it/s]loading the weights for Res Unet:  91%|█████████ | 41/45 [00:08<00:00,  4.78it/s]loading the weights for Res Unet:  93%|█████████▎| 42/45 [00:08<00:00,  4.61it/s]loading the weights for Res Unet: 100%|██████████| 45/45 [00:08<00:00,  5.16it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 11)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 40, 11)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 40, 20)   2000        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 40, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 40, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 40, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 40, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 40, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 31)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 31)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 20, 31)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 20, 40)   11200       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 20, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 20, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 20, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 20, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 20, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 71)   0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 20, 71)   0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 20)   5700        dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 51)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 40, 20)   9200        concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 40, 20)   80          conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 40, 20)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 40, 20)   3620        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 40, 20)   80          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 40, 20)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 71)   0           concatenate_4[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 40, 71)   0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 10)   2850        dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 21)   0           conv2d_transpose_2[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 80, 10)   1900        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 80, 10)   40          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 80, 10)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 80, 10)   910         activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 80, 10)   40          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 80, 10)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 31)   0           concatenate_6[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 80, 31)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 13)   416         dropout_5[0][0]                  
==================================================================================================
Total params: 57,666
Trainable params: 13,106
Non-trainable params: 44,560
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 17099.3187 - acc: 0.5370 - mDice: 0.0713 - val_loss: 11219.4973 - val_acc: 0.8319 - val_mDice: 0.1279

Epoch 00001: val_mDice improved from -inf to 0.12786, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 7s - loss: 10249.1321 - acc: 0.8524 - mDice: 0.1531 - val_loss: 8177.7312 - val_acc: 0.9020 - val_mDice: 0.2031

Epoch 00002: val_mDice improved from 0.12786 to 0.20311, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 7s - loss: 7400.0785 - acc: 0.8684 - mDice: 0.2327 - val_loss: 8733.1968 - val_acc: 0.9040 - val_mDice: 0.1974

Epoch 00003: val_mDice did not improve from 0.20311
Epoch 4/300
 - 7s - loss: 6222.5977 - acc: 0.8737 - mDice: 0.2884 - val_loss: 5282.8835 - val_acc: 0.9063 - val_mDice: 0.3288

Epoch 00004: val_mDice improved from 0.20311 to 0.32877, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 7s - loss: 5540.0544 - acc: 0.8780 - mDice: 0.3285 - val_loss: 4335.3735 - val_acc: 0.9126 - val_mDice: 0.4016

Epoch 00005: val_mDice improved from 0.32877 to 0.40156, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 7s - loss: 5038.0091 - acc: 0.8823 - mDice: 0.3624 - val_loss: 4235.7284 - val_acc: 0.9143 - val_mDice: 0.4073

Epoch 00006: val_mDice improved from 0.40156 to 0.40729, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 7s - loss: 4651.0391 - acc: 0.8865 - mDice: 0.3907 - val_loss: 4222.2443 - val_acc: 0.9096 - val_mDice: 0.4053

Epoch 00007: val_mDice did not improve from 0.40729
Epoch 8/300
 - 7s - loss: 4389.4774 - acc: 0.8900 - mDice: 0.4119 - val_loss: 4130.5012 - val_acc: 0.9031 - val_mDice: 0.4115

Epoch 00008: val_mDice improved from 0.40729 to 0.41145, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 6s - loss: 4176.6127 - acc: 0.8923 - mDice: 0.4296 - val_loss: 3592.0436 - val_acc: 0.9267 - val_mDice: 0.4624

Epoch 00009: val_mDice improved from 0.41145 to 0.46239, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 6s - loss: 4027.6382 - acc: 0.8944 - mDice: 0.4430 - val_loss: 3515.4639 - val_acc: 0.9292 - val_mDice: 0.4678

Epoch 00010: val_mDice improved from 0.46239 to 0.46780, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 7s - loss: 3866.9784 - acc: 0.8966 - mDice: 0.4575 - val_loss: 3681.9666 - val_acc: 0.9295 - val_mDice: 0.4481

Epoch 00011: val_mDice did not improve from 0.46780
Epoch 12/300
 - 7s - loss: 3739.0954 - acc: 0.8985 - mDice: 0.4694 - val_loss: 3392.8871 - val_acc: 0.9308 - val_mDice: 0.4786

Epoch 00012: val_mDice improved from 0.46780 to 0.47862, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 7s - loss: 3629.1517 - acc: 0.9001 - mDice: 0.4800 - val_loss: 3174.6134 - val_acc: 0.9292 - val_mDice: 0.4978

Epoch 00013: val_mDice improved from 0.47862 to 0.49776, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 7s - loss: 3521.2741 - acc: 0.9017 - mDice: 0.4901 - val_loss: 3526.2271 - val_acc: 0.9316 - val_mDice: 0.4650

Epoch 00014: val_mDice did not improve from 0.49776
Epoch 15/300
 - 7s - loss: 3415.9472 - acc: 0.9034 - mDice: 0.5002 - val_loss: 3480.1493 - val_acc: 0.9316 - val_mDice: 0.4679

Epoch 00015: val_mDice did not improve from 0.49776
Epoch 16/300
 - 7s - loss: 3317.6482 - acc: 0.9045 - mDice: 0.5103 - val_loss: 3190.6057 - val_acc: 0.9340 - val_mDice: 0.4952

Epoch 00016: val_mDice did not improve from 0.49776
Epoch 17/300
 - 6s - loss: 3257.0735 - acc: 0.9059 - mDice: 0.5167 - val_loss: 3164.6905 - val_acc: 0.9300 - val_mDice: 0.4990

Epoch 00017: val_mDice improved from 0.49776 to 0.49903, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 7s - loss: 3192.8314 - acc: 0.9069 - mDice: 0.5232 - val_loss: 3427.4271 - val_acc: 0.9201 - val_mDice: 0.4750

Epoch 00018: val_mDice did not improve from 0.49903
Epoch 19/300
 - 7s - loss: 3151.3509 - acc: 0.9082 - mDice: 0.5278 - val_loss: 3064.0520 - val_acc: 0.9356 - val_mDice: 0.5082

Epoch 00019: val_mDice improved from 0.49903 to 0.50824, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 7s - loss: 3070.9671 - acc: 0.9090 - mDice: 0.5362 - val_loss: 3170.4306 - val_acc: 0.9261 - val_mDice: 0.5007

Epoch 00020: val_mDice did not improve from 0.50824
Epoch 21/300
 - 7s - loss: 3041.7977 - acc: 0.9097 - mDice: 0.5393 - val_loss: 3235.9928 - val_acc: 0.9273 - val_mDice: 0.4936

Epoch 00021: val_mDice did not improve from 0.50824
Epoch 22/300
 - 7s - loss: 2980.3119 - acc: 0.9107 - mDice: 0.5461 - val_loss: 3676.0395 - val_acc: 0.9322 - val_mDice: 0.4460

Epoch 00022: val_mDice did not improve from 0.50824
Epoch 23/300
 - 7s - loss: 2948.4253 - acc: 0.9113 - mDice: 0.5496 - val_loss: 3400.5061 - val_acc: 0.9227 - val_mDice: 0.4816

Epoch 00023: val_mDice did not improve from 0.50824
Epoch 24/300
 - 7s - loss: 2907.4106 - acc: 0.9122 - mDice: 0.5543 - val_loss: 3691.4214 - val_acc: 0.9318 - val_mDice: 0.4428

Epoch 00024: val_mDice did not improve from 0.50824
Epoch 25/300
 - 7s - loss: 2871.5667 - acc: 0.9126 - mDice: 0.5580 - val_loss: 2958.1301 - val_acc: 0.9386 - val_mDice: 0.5186

Epoch 00025: val_mDice improved from 0.50824 to 0.51864, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 8s - loss: 2824.8903 - acc: 0.9140 - mDice: 0.5634 - val_loss: 2939.5908 - val_acc: 0.9325 - val_mDice: 0.5227

Epoch 00026: val_mDice improved from 0.51864 to 0.52274, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 7s - loss: 2782.7922 - acc: 0.9147 - mDice: 0.5682 - val_loss: 2874.2497 - val_acc: 0.9388 - val_mDice: 0.5302

Epoch 00027: val_mDice improved from 0.52274 to 0.53023, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 7s - loss: 2762.3079 - acc: 0.9154 - mDice: 0.5706 - val_loss: 3125.9785 - val_acc: 0.9261 - val_mDice: 0.5050

Epoch 00028: val_mDice did not improve from 0.53023
Epoch 29/300
 - 7s - loss: 2734.7986 - acc: 0.9156 - mDice: 0.5739 - val_loss: 2900.4424 - val_acc: 0.9403 - val_mDice: 0.5281

Epoch 00029: val_mDice did not improve from 0.53023
Epoch 30/300
 - 8s - loss: 2721.2656 - acc: 0.9162 - mDice: 0.5754 - val_loss: 2939.4579 - val_acc: 0.9287 - val_mDice: 0.5217

Epoch 00030: val_mDice did not improve from 0.53023
Epoch 31/300
 - 7s - loss: 2677.6692 - acc: 0.9172 - mDice: 0.5806 - val_loss: 2822.7926 - val_acc: 0.9358 - val_mDice: 0.5346

Epoch 00031: val_mDice improved from 0.53023 to 0.53460, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 7s - loss: 2652.5183 - acc: 0.9176 - mDice: 0.5834 - val_loss: 3016.2582 - val_acc: 0.9355 - val_mDice: 0.5207

Epoch 00032: val_mDice did not improve from 0.53460
Epoch 33/300
 - 7s - loss: 2635.1334 - acc: 0.9179 - mDice: 0.5855 - val_loss: 2679.0344 - val_acc: 0.9359 - val_mDice: 0.5482

Epoch 00033: val_mDice improved from 0.53460 to 0.54823, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 7s - loss: 2612.5366 - acc: 0.9186 - mDice: 0.5882 - val_loss: 3001.1135 - val_acc: 0.9298 - val_mDice: 0.5188

Epoch 00034: val_mDice did not improve from 0.54823
Epoch 35/300
 - 7s - loss: 2600.2969 - acc: 0.9187 - mDice: 0.5896 - val_loss: 2946.8500 - val_acc: 0.9315 - val_mDice: 0.5269

Epoch 00035: val_mDice did not improve from 0.54823
Epoch 36/300
 - 7s - loss: 2561.8479 - acc: 0.9197 - mDice: 0.5944 - val_loss: 2940.1971 - val_acc: 0.9266 - val_mDice: 0.5233

Epoch 00036: val_mDice did not improve from 0.54823
Epoch 37/300
 - 8s - loss: 2537.9405 - acc: 0.9199 - mDice: 0.5972 - val_loss: 2686.2786 - val_acc: 0.9418 - val_mDice: 0.5489

Epoch 00037: val_mDice improved from 0.54823 to 0.54887, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 38/300
 - 8s - loss: 2516.4900 - acc: 0.9204 - mDice: 0.5999 - val_loss: 2822.6142 - val_acc: 0.9323 - val_mDice: 0.5355

Epoch 00038: val_mDice did not improve from 0.54887
Epoch 39/300
 - 7s - loss: 2518.0789 - acc: 0.9206 - mDice: 0.5995 - val_loss: 3410.6241 - val_acc: 0.9083 - val_mDice: 0.4807

Epoch 00039: val_mDice did not improve from 0.54887
Epoch 40/300
 - 7s - loss: 2500.4954 - acc: 0.9207 - mDice: 0.6017 - val_loss: 3005.0856 - val_acc: 0.9415 - val_mDice: 0.5156

Epoch 00040: val_mDice did not improve from 0.54887
Epoch 41/300
 - 7s - loss: 2476.0140 - acc: 0.9209 - mDice: 0.6046 - val_loss: 2924.9552 - val_acc: 0.9288 - val_mDice: 0.5234

Epoch 00041: val_mDice did not improve from 0.54887
Epoch 42/300
 - 7s - loss: 2463.4505 - acc: 0.9215 - mDice: 0.6063 - val_loss: 2858.9838 - val_acc: 0.9360 - val_mDice: 0.5322

Epoch 00042: val_mDice did not improve from 0.54887
Epoch 43/300
 - 8s - loss: 2459.7849 - acc: 0.9214 - mDice: 0.6067 - val_loss: 3011.7142 - val_acc: 0.9242 - val_mDice: 0.5154

Epoch 00043: val_mDice did not improve from 0.54887
Epoch 44/300
 - 8s - loss: 2444.7165 - acc: 0.9217 - mDice: 0.6084 - val_loss: 2769.4168 - val_acc: 0.9436 - val_mDice: 0.5383

Epoch 00044: val_mDice did not improve from 0.54887
Epoch 45/300
 - 7s - loss: 2424.6262 - acc: 0.9223 - mDice: 0.6108 - val_loss: 2654.6138 - val_acc: 0.9398 - val_mDice: 0.5515

Epoch 00045: val_mDice improved from 0.54887 to 0.55153, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 8s - loss: 2411.7053 - acc: 0.9222 - mDice: 0.6125 - val_loss: 2891.1298 - val_acc: 0.9415 - val_mDice: 0.5240

Epoch 00046: val_mDice did not improve from 0.55153
Epoch 47/300
 - 8s - loss: 2404.9462 - acc: 0.9226 - mDice: 0.6134 - val_loss: 2814.7474 - val_acc: 0.9417 - val_mDice: 0.5319

Epoch 00047: val_mDice did not improve from 0.55153
Epoch 48/300
 - 7s - loss: 2398.0716 - acc: 0.9225 - mDice: 0.6142 - val_loss: 3230.6514 - val_acc: 0.9185 - val_mDice: 0.4928

Epoch 00048: val_mDice did not improve from 0.55153
Epoch 49/300
 - 8s - loss: 2398.2785 - acc: 0.9228 - mDice: 0.6143 - val_loss: 2533.0638 - val_acc: 0.9413 - val_mDice: 0.5633

Epoch 00049: val_mDice improved from 0.55153 to 0.56334, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_FCN_ResUnet_TL_NL3_LS_MyJoint_US1_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 50/300
 - 8s - loss: 2376.3840 - acc: 0.9232 - mDice: 0.6169 - val_loss: 3036.0258 - val_acc: 0.9189 - val_mDice: 0.5131

Epoch 00050: val_mDice did not improve from 0.56334
Epoch 51/300
 - 7s - loss: 2372.9431 - acc: 0.9233 - mDice: 0.6174 - val_loss: 2565.2236 - val_acc: 0.9422 - val_mDice: 0.5595

Epoch 00051: val_mDice did not improve from 0.56334
Epoch 52/300
 - 7s - loss: 2359.7992 - acc: 0.9233 - mDice: 0.6190 - val_loss: 2626.5900 - val_acc: 0.9386 - val_mDice: 0.5536

Epoch 00052: val_mDice did not improve from 0.56334
Epoch 53/300
 - 7s - loss: 2350.8410 - acc: 0.9238 - mDice: 0.6201 - val_loss: 2613.1931 - val_acc: 0.9425 - val_mDice: 0.5544

Epoch 00053: val_mDice did not improve from 0.56334
Epoch 54/300
 - 7s - loss: 2345.8710 - acc: 0.9236 - mDice: 0.6207 - val_loss: 2815.6299 - val_acc: 0.9396 - val_mDice: 0.5355

Epoch 00054: val_mDice did not improve from 0.56334
Epoch 55/300
 - 8s - loss: 2340.4747 - acc: 0.9241 - mDice: 0.6214 - val_loss: 2637.7289 - val_acc: 0.9427 - val_mDice: 0.5524

Epoch 00055: val_mDice did not improve from 0.56334
Epoch 56/300
 - 8s - loss: 2335.0122 - acc: 0.9241 - mDice: 0.6221 - val_loss: 2739.5001 - val_acc: 0.9378 - val_mDice: 0.5421

Epoch 00056: val_mDice did not improve from 0.56334
Epoch 57/300
 - 8s - loss: 2330.6403 - acc: 0.9244 - mDice: 0.6227 - val_loss: 5200.6722 - val_acc: 0.9292 - val_mDice: 0.3764

Epoch 00057: val_mDice did not improve from 0.56334
Epoch 58/300
 - 7s - loss: 2317.2780 - acc: 0.9244 - mDice: 0.6245 - val_loss: 2855.7819 - val_acc: 0.9323 - val_mDice: 0.5296

Epoch 00058: val_mDice did not improve from 0.56334
Epoch 59/300
 - 7s - loss: 2309.5687 - acc: 0.9248 - mDice: 0.6253 - val_loss: 3811.1248 - val_acc: 0.9320 - val_mDice: 0.4347

Epoch 00059: val_mDice did not improve from 0.56334
Epoch 60/300
 - 8s - loss: 2304.6647 - acc: 0.9248 - mDice: 0.6259 - val_loss: 2799.2033 - val_acc: 0.9356 - val_mDice: 0.5382

Epoch 00060: val_mDice did not improve from 0.56334
Epoch 61/300
 - 8s - loss: 2294.0970 - acc: 0.9250 - mDice: 0.6272 - val_loss: 2839.6874 - val_acc: 0.9376 - val_mDice: 0.5320

Epoch 00061: val_mDice did not improve from 0.56334
Epoch 62/300
 - 8s - loss: 2287.8014 - acc: 0.9249 - mDice: 0.6280 - val_loss: 2770.5733 - val_acc: 0.9338 - val_mDice: 0.5378

Epoch 00062: val_mDice did not improve from 0.56334
Epoch 63/300
 - 8s - loss: 2295.3976 - acc: 0.9249 - mDice: 0.6272 - val_loss: 2631.7119 - val_acc: 0.9397 - val_mDice: 0.5530

Epoch 00063: val_mDice did not improve from 0.56334
Epoch 64/300
 - 8s - loss: 2279.6175 - acc: 0.9251 - mDice: 0.6291 - val_loss: 2774.6053 - val_acc: 0.9408 - val_mDice: 0.5382

Epoch 00064: val_mDice did not improve from 0.56334
Epoch 65/300
 - 8s - loss: 2279.0226 - acc: 0.9254 - mDice: 0.6291 - val_loss: 2831.7802 - val_acc: 0.9365 - val_mDice: 0.5324

Epoch 00065: val_mDice did not improve from 0.56334
Epoch 66/300
 - 9s - loss: 2277.1126 - acc: 0.9253 - mDice: 0.6294 - val_loss: 3043.5989 - val_acc: 0.9389 - val_mDice: 0.5101

Epoch 00066: val_mDice did not improve from 0.56334
Epoch 67/300
 - 8s - loss: 2262.5514 - acc: 0.9258 - mDice: 0.6312 - val_loss: 2839.7810 - val_acc: 0.9346 - val_mDice: 0.5305

Epoch 00067: val_mDice did not improve from 0.56334
Epoch 68/300
 - 8s - loss: 2263.1574 - acc: 0.9255 - mDice: 0.6312 - val_loss: 2859.2003 - val_acc: 0.9417 - val_mDice: 0.5253

Epoch 00068: val_mDice did not improve from 0.56334
Epoch 69/300
 - 8s - loss: 2261.2583 - acc: 0.9256 - mDice: 0.6314 - val_loss: 2695.6337 - val_acc: 0.9383 - val_mDice: 0.5466

Epoch 00069: val_mDice did not improve from 0.56334
Epoch 70/300
 - 8s - loss: 2251.2874 - acc: 0.9257 - mDice: 0.6327 - val_loss: 2668.0203 - val_acc: 0.9419 - val_mDice: 0.5495

Epoch 00070: val_mDice did not improve from 0.56334
Epoch 71/300
 - 8s - loss: 2250.4180 - acc: 0.9258 - mDice: 0.6328 - val_loss: 2749.5839 - val_acc: 0.9396 - val_mDice: 0.5401

Epoch 00071: val_mDice did not improve from 0.56334
Epoch 72/300
 - 8s - loss: 2238.2384 - acc: 0.9262 - mDice: 0.6343 - val_loss: 2847.3508 - val_acc: 0.9344 - val_mDice: 0.5293

Epoch 00072: val_mDice did not improve from 0.56334
Epoch 73/300
 - 8s - loss: 2235.3093 - acc: 0.9264 - mDice: 0.6347 - val_loss: 2897.0957 - val_acc: 0.9300 - val_mDice: 0.5252

Epoch 00073: val_mDice did not improve from 0.56334
Epoch 74/300
 - 8s - loss: 2242.1375 - acc: 0.9262 - mDice: 0.6338 - val_loss: 2629.9832 - val_acc: 0.9429 - val_mDice: 0.5526

Epoch 00074: val_mDice did not improve from 0.56334
Epoch 75/300
 - 8s - loss: 2226.2633 - acc: 0.9264 - mDice: 0.6359 - val_loss: 2659.3828 - val_acc: 0.9436 - val_mDice: 0.5496

Epoch 00075: val_mDice did not improve from 0.56334
Epoch 76/300
 - 8s - loss: 2233.8269 - acc: 0.9265 - mDice: 0.6351 - val_loss: 2675.4386 - val_acc: 0.9401 - val_mDice: 0.5493

Epoch 00076: val_mDice did not improve from 0.56334
Epoch 77/300
 - 8s - loss: 2222.9344 - acc: 0.9265 - mDice: 0.6362 - val_loss: 2609.3795 - val_acc: 0.9387 - val_mDice: 0.5573

Epoch 00077: val_mDice did not improve from 0.56334
Epoch 78/300
 - 8s - loss: 2224.0045 - acc: 0.9269 - mDice: 0.6362 - val_loss: 2667.2596 - val_acc: 0.9413 - val_mDice: 0.5532

Epoch 00078: val_mDice did not improve from 0.56334
Epoch 79/300
 - 9s - loss: 2220.9336 - acc: 0.9269 - mDice: 0.6366 - val_loss: 3483.1015 - val_acc: 0.9341 - val_mDice: 0.4591

Epoch 00079: val_mDice did not improve from 0.56334
Restoring model weights from the end of the best epoch
Epoch 00079: early stopping
{'val_loss': [11219.497256324405, 8177.731236049107, 8733.196800595239, 5282.883486793155, 4335.3735119047615, 4235.728410993303, 4222.244256882441, 4130.501174200149, 3592.0435849144346, 3515.4639485677085, 3681.966622488839, 3392.8871140252977, 3174.6134207589284, 3526.2270856584823, 3480.1493094308034, 3190.605666387649, 3164.69045875186, 3427.427071707589, 3064.0519670758927, 3170.4305826822915, 3235.9927746000744, 3676.039544968378, 3400.506109328497, 3691.421404157366, 2958.130144391741, 2939.5907679966517, 2874.2496628534227, 3125.978515625, 2900.44241187686, 2939.4578857421875, 2822.7925734747023, 3016.2582484654017, 2679.0343569800966, 3001.1135370163693, 2946.8500395275296, 2940.197062174479, 2686.278628394717, 2822.6142229352677, 3410.6240583147323, 3005.085638137091, 2924.9552176339284, 2858.9837530226932, 3011.7141927083335, 2769.416811988467, 2654.61375499907, 2891.1297694614955, 2814.747392926897, 3230.6514253162204, 2533.0637555803573, 3036.025814964658, 2565.2236444382443, 2626.5899512881324, 2613.1930716378347, 2815.6298944382443, 2637.7288832891554, 2739.5000988188244, 5200.672247023809, 2855.7818632579983, 3811.124750046503, 2799.2033168247767, 2839.6873982747397, 2770.5733322870165, 2631.711908249628, 2774.605271112351, 2831.7802138555617, 3043.598932175409, 2839.780991327195, 2859.2003479003906, 2695.6336553664432, 2668.020266578311, 2749.5839422316776, 2847.350844610305, 2897.0957234700522, 2629.983218238467, 2659.382825578962, 2675.4385753813244, 2609.3795078822545, 2667.259608677455, 3483.1014556884766], 'val_acc': [0.8319253949891954, 0.9020421504974365, 0.9040086808658782, 0.9062683213324774, 0.9125846993355524, 0.9142742724645705, 0.9096383055051168, 0.9030609074093047, 0.9267147268567767, 0.9292262168157668, 0.9295467109907241, 0.9308470544360933, 0.9291780903225854, 0.9316460745675224, 0.9315545019649324, 0.9339857924552191, 0.9300366356259301, 0.9200892618724278, 0.9356227176530021, 0.9261309476125807, 0.9272595927828834, 0.9321634570757548, 0.9227495505696252, 0.9318246529215858, 0.9385554024151394, 0.932536624726795, 0.9387797684896559, 0.9260783053579784, 0.9403067798841567, 0.9286744395891825, 0.9357737842060271, 0.9355448484420776, 0.9359203548658461, 0.9297893558229718, 0.931549935113816, 0.9265545038949876, 0.9418017126265026, 0.9322527278037298, 0.9082554834229606, 0.9415499142238072, 0.928766009353456, 0.9359501060985383, 0.9242192960920788, 0.9436126521655491, 0.9398420140856788, 0.9414537719317845, 0.9416918499129159, 0.9185256617409843, 0.9413324055217561, 0.9188576170376369, 0.9422000816890171, 0.9386103522209894, 0.9424793748628526, 0.9396131208964756, 0.9426946100734529, 0.9377609973862058, 0.9291712301118034, 0.9322733510108221, 0.9319688706170945, 0.9356181224187216, 0.9375938744772048, 0.9338370135852269, 0.9397115281649998, 0.9407508884157453, 0.9365407313619342, 0.9389148524829319, 0.9346108152752831, 0.9416506602650597, 0.9382554945491609, 0.9418681150390988, 0.9395901901381356, 0.9343681307066054, 0.929963387194134, 0.9429395794868469, 0.9436492863155547, 0.9401030313400995, 0.9387065087045942, 0.9413072523616609, 0.93412089631671], 'val_mDice': [0.12786001658865384, 0.20310540704390623, 0.1974196145076045, 0.3287735607120253, 0.4015628464874767, 0.40729040439639774, 0.40532326875698, 0.41145347005554606, 0.4623877035365218, 0.46779660720910343, 0.44808243144126164, 0.4786194690636226, 0.4977640367689587, 0.46498744438091916, 0.46791999804831685, 0.4951888093990939, 0.4990278769816671, 0.4749932413299878, 0.5082422423930395, 0.5007122765694346, 0.4936186477896713, 0.4460166882546175, 0.4816165360666457, 0.4428029376126471, 0.5186397566327027, 0.5227436533286458, 0.5302267853348028, 0.5049671961792878, 0.5280720133866582, 0.5216788131566275, 0.5346026637014889, 0.5206759543645949, 0.5482313714566684, 0.5187781314764704, 0.526923109732923, 0.5233371286165147, 0.5488736029891741, 0.5355417323963982, 0.48067405110313777, 0.5156300527354082, 0.5233854151197842, 0.5322404459473633, 0.5154418468120552, 0.5383486080737341, 0.5515309795737267, 0.5239975691906044, 0.5318680332884902, 0.4928342378920033, 0.5633375265059017, 0.5130953934221041, 0.5594963083664576, 0.5535657624048846, 0.5544209748151756, 0.5355494574067139, 0.5524392752420335, 0.5421477343354907, 0.376391808193277, 0.5295921386707396, 0.4347467763083322, 0.5381881472255502, 0.5320204530088675, 0.5377516538969108, 0.5530102785144534, 0.5382378576766877, 0.5323961611304965, 0.5101256512460255, 0.5305425671949273, 0.5252654453118643, 0.5465685388162023, 0.5494809509033248, 0.5401230374617236, 0.529296085061062, 0.5251573882997036, 0.5525734860982213, 0.5496338655551275, 0.549305089882442, 0.5572538466325828, 0.553180583708343, 0.45910976294960293], 'loss': [17099.318705229118, 10249.13208511438, 7400.078548892514, 6222.597694469046, 5540.054424861733, 5038.009141176634, 4651.0390876342, 4389.477393811301, 4176.612687913444, 4027.6381939957314, 3866.978447094298, 3739.095412010721, 3629.151680235369, 3521.2741134405273, 3415.9471504030507, 3317.6481577290583, 3257.073450368334, 3192.831358368879, 3151.3509087284015, 3070.9671091227165, 3041.7977491900574, 2980.311905110206, 2948.4253330940405, 2907.41059534541, 2871.5666987292448, 2824.8902829583726, 2782.7921800350487, 2762.30793362425, 2734.7986214032676, 2721.2655824507183, 2677.6692341675252, 2652.5183070403245, 2635.133400800303, 2612.5365594584796, 2600.296939223999, 2561.847896860541, 2537.9404754373913, 2516.489974113657, 2518.0788852154046, 2500.4954161385663, 2476.013970637795, 2463.4504783075854, 2459.7849110974175, 2444.716536613657, 2424.6261972868997, 2411.705343916808, 2404.9462149307315, 2398.0716266326876, 2398.278541178103, 2376.3839881121826, 2372.943056117231, 2359.7991912059297, 2350.841021739106, 2345.8710155233334, 2340.474654348273, 2335.0122424262277, 2330.640262907494, 2317.277984907431, 2309.568699086772, 2304.6647289093, 2294.096982874667, 2287.8014077458142, 2295.397617955646, 2279.6174532447403, 2279.0225549554098, 2277.112601496982, 2262.5513581128303, 2263.1574469103575, 2261.258305440961, 2251.2873717308594, 2250.41802028923, 2238.2384030849735, 2235.309262606825, 2242.137491861979, 2226.263299757055, 2233.8268698903207, 2222.9343640849797, 2224.0045005749803, 2220.933630862952], 'acc': [0.5370237288020906, 0.8523659999370116, 0.8684252459855353, 0.8736999892122097, 0.8779715318222002, 0.882333168352365, 0.8865126250037022, 0.8899936375416656, 0.8923372149191681, 0.8943545500828118, 0.8965909600096997, 0.898525716919694, 0.900132286771543, 0.9016817439055199, 0.9034213892108608, 0.9044938056896894, 0.9058724599282636, 0.9069416103552411, 0.9081866326809205, 0.9090154668442288, 0.9096884224969619, 0.9107222831821497, 0.9113011357640401, 0.9122117414556304, 0.9126445921556279, 0.9139790351114591, 0.9147015816218044, 0.9154030342126872, 0.9155564579472781, 0.9161541512390771, 0.9171707007796267, 0.9175882835550898, 0.9179003343017708, 0.9186409323896221, 0.9187082650000956, 0.9196859804311193, 0.9199363487245307, 0.9204414298200231, 0.9205537179152079, 0.9207358746163666, 0.920942564460614, 0.9214776703243612, 0.9214423588987534, 0.921726446448665, 0.9222649083170606, 0.9222453327245144, 0.9226238461549235, 0.9225038608099101, 0.9227620874017517, 0.9231912312375251, 0.9232529576674624, 0.9232871575532035, 0.9237544240003748, 0.9235656150554402, 0.9240590632364013, 0.9240741265033835, 0.9243675008062823, 0.9244405865577321, 0.9247843381961877, 0.9247505085326262, 0.9249800722539735, 0.9249479520842591, 0.9248874994838355, 0.9251117120249689, 0.9253550619088043, 0.9253351825014897, 0.9257722706470228, 0.9255314469912022, 0.9256175494570941, 0.9256556932696814, 0.9258076986964093, 0.926152962686378, 0.9264059754173627, 0.9261714066640017, 0.9264006637552467, 0.9265466279116628, 0.9265447519798602, 0.9268631534193071, 0.9268999734388189], 'mDice': [0.07128105507971454, 0.15305357306178696, 0.2326606410028205, 0.28835477019657124, 0.3285321789151422, 0.36240034053866654, 0.39067276576844534, 0.41190640385012556, 0.42958725528931235, 0.4429891707064307, 0.45750418341594185, 0.4694040347000572, 0.47996657102558915, 0.4901277937019448, 0.5002245924388694, 0.5102748519794684, 0.5166583975340007, 0.5232131147812115, 0.5278279897172441, 0.5361845056652587, 0.5393187772660029, 0.5460664232457009, 0.5495531305380587, 0.5543340770569016, 0.5580128000056971, 0.5633637753437543, 0.5681539428746606, 0.5706028844525595, 0.5738782051190122, 0.5754389655091341, 0.5805947654206376, 0.5833546181209565, 0.585459941208466, 0.5882002132831108, 0.5895954351768067, 0.5943784367401568, 0.5971765785013202, 0.5999320774770597, 0.5995144159411888, 0.601676394559295, 0.6046095268331513, 0.6062782194105582, 0.6067253762480149, 0.6083985352323122, 0.6108252460703308, 0.6124762919497485, 0.613397336268163, 0.6142128501780487, 0.61426457924169, 0.6168956883454199, 0.6174348555871556, 0.6189995050683104, 0.620123039051267, 0.6206944038671681, 0.6214470448626336, 0.6221068178341066, 0.6227302784769894, 0.6244662455425847, 0.6253119451084508, 0.6258977281925465, 0.6272109451380359, 0.6279883712892108, 0.6271753520066508, 0.6290680262103392, 0.6291263968999248, 0.6293985454108137, 0.6312145963095737, 0.6311577934508198, 0.6313807029863854, 0.6326525824847239, 0.6327902324424444, 0.6342762544800005, 0.6346916273101254, 0.6338097873693811, 0.6359008449291893, 0.6351069097737713, 0.6362291706626485, 0.6361908472777102, 0.6366380145836134]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.46s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:05<00:02,  2.99s/it]predicting test subjects: 100%|██████████| 3/3 [00:07<00:00,  2.73s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<11:27,  2.42s/it]predicting train subjects:   1%|          | 2/285 [00:04<10:27,  2.22s/it]predicting train subjects:   1%|          | 3/285 [00:06<10:27,  2.23s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<10:11,  2.18s/it]predicting train subjects:   2%|▏         | 5/285 [00:11<10:59,  2.35s/it]predicting train subjects:   2%|▏         | 6/285 [00:13<10:19,  2.22s/it]predicting train subjects:   2%|▏         | 7/285 [00:15<10:38,  2.30s/it]predicting train subjects:   3%|▎         | 8/285 [00:17<10:19,  2.23s/it]predicting train subjects:   3%|▎         | 9/285 [00:20<10:41,  2.32s/it]predicting train subjects:   4%|▎         | 10/285 [00:23<11:40,  2.55s/it]predicting train subjects:   4%|▍         | 11/285 [00:25<11:41,  2.56s/it]predicting train subjects:   4%|▍         | 12/285 [00:28<11:52,  2.61s/it]predicting train subjects:   5%|▍         | 13/285 [00:30<11:00,  2.43s/it]predicting train subjects:   5%|▍         | 14/285 [00:32<10:49,  2.40s/it]predicting train subjects:   5%|▌         | 15/285 [00:35<10:44,  2.39s/it]predicting train subjects:   6%|▌         | 16/285 [00:37<10:48,  2.41s/it]predicting train subjects:   6%|▌         | 17/285 [00:39<10:20,  2.32s/it]predicting train subjects:   6%|▋         | 18/285 [00:42<10:36,  2.38s/it]predicting train subjects:   7%|▋         | 19/285 [00:44<09:55,  2.24s/it]predicting train subjects:   7%|▋         | 20/285 [00:47<10:36,  2.40s/it]predicting train subjects:   7%|▋         | 21/285 [00:49<10:43,  2.44s/it]predicting train subjects:   8%|▊         | 22/285 [00:51<10:14,  2.34s/it]predicting train subjects:   8%|▊         | 23/285 [00:54<10:25,  2.39s/it]predicting train subjects:   8%|▊         | 24/285 [00:56<10:05,  2.32s/it]predicting train subjects:   9%|▉         | 25/285 [00:58<10:22,  2.39s/it]predicting train subjects:   9%|▉         | 26/285 [01:01<10:47,  2.50s/it]predicting train subjects:   9%|▉         | 27/285 [01:03<10:01,  2.33s/it]predicting train subjects:  10%|▉         | 28/285 [01:06<10:37,  2.48s/it]predicting train subjects:  10%|█         | 29/285 [01:08<10:16,  2.41s/it]predicting train subjects:  11%|█         | 30/285 [01:11<10:50,  2.55s/it]predicting train subjects:  11%|█         | 31/285 [01:14<11:01,  2.60s/it]predicting train subjects:  11%|█         | 32/285 [01:16<10:33,  2.50s/it]predicting train subjects:  12%|█▏        | 33/285 [01:19<10:23,  2.47s/it]predicting train subjects:  12%|█▏        | 34/285 [01:21<10:21,  2.47s/it]predicting train subjects:  12%|█▏        | 35/285 [01:23<10:16,  2.46s/it]predicting train subjects:  13%|█▎        | 36/285 [01:26<10:10,  2.45s/it]predicting train subjects:  13%|█▎        | 37/285 [01:28<10:11,  2.47s/it]predicting train subjects:  13%|█▎        | 38/285 [01:31<09:52,  2.40s/it]predicting train subjects:  14%|█▎        | 39/285 [01:33<09:29,  2.32s/it]predicting train subjects:  14%|█▍        | 40/285 [01:35<09:42,  2.38s/it]predicting train subjects:  14%|█▍        | 41/285 [01:38<09:37,  2.37s/it]predicting train subjects:  15%|█▍        | 42/285 [01:39<09:03,  2.24s/it]predicting train subjects:  15%|█▌        | 43/285 [01:42<09:09,  2.27s/it]predicting train subjects:  15%|█▌        | 44/285 [01:45<10:15,  2.55s/it]predicting train subjects:  16%|█▌        | 45/285 [01:47<09:47,  2.45s/it]predicting train subjects:  16%|█▌        | 46/285 [01:50<09:54,  2.49s/it]predicting train subjects:  16%|█▋        | 47/285 [01:52<09:31,  2.40s/it]predicting train subjects:  17%|█▋        | 48/285 [01:54<09:19,  2.36s/it]predicting train subjects:  17%|█▋        | 49/285 [01:57<09:48,  2.49s/it]predicting train subjects:  18%|█▊        | 50/285 [01:59<09:38,  2.46s/it]predicting train subjects:  18%|█▊        | 51/285 [02:02<09:59,  2.56s/it]predicting train subjects:  18%|█▊        | 52/285 [02:04<09:12,  2.37s/it]predicting train subjects:  19%|█▊        | 53/285 [02:06<09:03,  2.34s/it]predicting train subjects:  19%|█▉        | 54/285 [02:10<10:05,  2.62s/it]predicting train subjects:  19%|█▉        | 55/285 [02:12<09:31,  2.49s/it]predicting train subjects:  20%|█▉        | 56/285 [02:14<09:32,  2.50s/it]predicting train subjects:  20%|██        | 57/285 [02:17<09:06,  2.39s/it]predicting train subjects:  20%|██        | 58/285 [02:19<09:14,  2.44s/it]predicting train subjects:  21%|██        | 59/285 [02:22<09:07,  2.42s/it]predicting train subjects:  21%|██        | 60/285 [02:25<09:42,  2.59s/it]predicting train subjects:  21%|██▏       | 61/285 [02:27<08:58,  2.41s/it]predicting train subjects:  22%|██▏       | 62/285 [02:29<08:47,  2.36s/it]predicting train subjects:  22%|██▏       | 63/285 [02:31<08:57,  2.42s/it]predicting train subjects:  22%|██▏       | 64/285 [02:34<09:07,  2.48s/it]predicting train subjects:  23%|██▎       | 65/285 [02:37<09:18,  2.54s/it]predicting train subjects:  23%|██▎       | 66/285 [02:39<09:24,  2.58s/it]predicting train subjects:  24%|██▎       | 67/285 [02:42<09:09,  2.52s/it]predicting train subjects:  24%|██▍       | 68/285 [02:44<08:50,  2.45s/it]predicting train subjects:  24%|██▍       | 69/285 [02:46<08:45,  2.43s/it]predicting train subjects:  25%|██▍       | 70/285 [02:49<08:50,  2.47s/it]predicting train subjects:  25%|██▍       | 71/285 [02:52<09:09,  2.57s/it]predicting train subjects:  25%|██▌       | 72/285 [02:54<08:53,  2.51s/it]predicting train subjects:  26%|██▌       | 73/285 [02:56<08:34,  2.43s/it]predicting train subjects:  26%|██▌       | 74/285 [02:59<08:49,  2.51s/it]predicting train subjects:  26%|██▋       | 75/285 [03:02<09:00,  2.57s/it]predicting train subjects:  27%|██▋       | 76/285 [03:04<08:53,  2.55s/it]predicting train subjects:  27%|██▋       | 77/285 [03:06<08:27,  2.44s/it]predicting train subjects:  27%|██▋       | 78/285 [03:08<07:56,  2.30s/it]predicting train subjects:  28%|██▊       | 79/285 [03:11<08:00,  2.33s/it]predicting train subjects:  28%|██▊       | 80/285 [03:13<07:58,  2.33s/it]predicting train subjects:  28%|██▊       | 81/285 [03:15<07:48,  2.30s/it]predicting train subjects:  29%|██▉       | 82/285 [03:18<08:10,  2.41s/it]predicting train subjects:  29%|██▉       | 83/285 [03:20<08:00,  2.38s/it]predicting train subjects:  29%|██▉       | 84/285 [03:23<07:55,  2.36s/it]predicting train subjects:  30%|██▉       | 85/285 [03:25<07:44,  2.32s/it]predicting train subjects:  30%|███       | 86/285 [03:27<07:59,  2.41s/it]predicting train subjects:  31%|███       | 87/285 [03:30<07:54,  2.39s/it]predicting train subjects:  31%|███       | 88/285 [03:32<07:36,  2.32s/it]predicting train subjects:  31%|███       | 89/285 [03:34<07:42,  2.36s/it]predicting train subjects:  32%|███▏      | 90/285 [03:37<08:12,  2.53s/it]predicting train subjects:  32%|███▏      | 91/285 [03:40<07:54,  2.45s/it]predicting train subjects:  32%|███▏      | 92/285 [03:42<07:55,  2.46s/it]predicting train subjects:  33%|███▎      | 93/285 [03:44<07:45,  2.43s/it]predicting train subjects:  33%|███▎      | 94/285 [03:47<08:10,  2.57s/it]predicting train subjects:  33%|███▎      | 95/285 [03:50<08:15,  2.61s/it]predicting train subjects:  34%|███▎      | 96/285 [03:53<08:09,  2.59s/it]predicting train subjects:  34%|███▍      | 97/285 [03:55<08:06,  2.59s/it]predicting train subjects:  34%|███▍      | 98/285 [03:58<08:13,  2.64s/it]predicting train subjects:  35%|███▍      | 99/285 [04:01<08:13,  2.65s/it]predicting train subjects:  35%|███▌      | 100/285 [04:03<08:00,  2.60s/it]predicting train subjects:  35%|███▌      | 101/285 [04:05<07:38,  2.49s/it]predicting train subjects:  36%|███▌      | 102/285 [04:08<07:51,  2.58s/it]predicting train subjects:  36%|███▌      | 103/285 [04:11<07:46,  2.56s/it]predicting train subjects:  36%|███▋      | 104/285 [04:14<07:59,  2.65s/it]predicting train subjects:  37%|███▋      | 105/285 [04:16<07:53,  2.63s/it]predicting train subjects:  37%|███▋      | 106/285 [04:18<07:37,  2.56s/it]predicting train subjects:  38%|███▊      | 107/285 [04:21<07:26,  2.51s/it]predicting train subjects:  38%|███▊      | 108/285 [04:23<07:18,  2.48s/it]predicting train subjects:  38%|███▊      | 109/285 [04:26<07:40,  2.62s/it]predicting train subjects:  39%|███▊      | 110/285 [04:29<07:48,  2.68s/it]predicting train subjects:  39%|███▉      | 111/285 [04:32<07:48,  2.69s/it]predicting train subjects:  39%|███▉      | 112/285 [04:34<07:42,  2.67s/it]predicting train subjects:  40%|███▉      | 113/285 [04:37<07:59,  2.79s/it]predicting train subjects:  40%|████      | 114/285 [04:40<07:48,  2.74s/it]predicting train subjects:  40%|████      | 115/285 [04:43<07:34,  2.67s/it]predicting train subjects:  41%|████      | 116/285 [04:45<07:26,  2.64s/it]predicting train subjects:  41%|████      | 117/285 [04:47<06:59,  2.49s/it]predicting train subjects:  41%|████▏     | 118/285 [04:50<07:04,  2.54s/it]predicting train subjects:  42%|████▏     | 119/285 [04:53<07:26,  2.69s/it]predicting train subjects:  42%|████▏     | 120/285 [04:55<07:03,  2.57s/it]predicting train subjects:  42%|████▏     | 121/285 [04:58<06:56,  2.54s/it]predicting train subjects:  43%|████▎     | 122/285 [05:00<06:35,  2.43s/it]predicting train subjects:  43%|████▎     | 123/285 [05:02<06:16,  2.32s/it]predicting train subjects:  44%|████▎     | 124/285 [05:05<06:33,  2.44s/it]predicting train subjects:  44%|████▍     | 125/285 [05:07<06:28,  2.43s/it]predicting train subjects:  44%|████▍     | 126/285 [05:09<06:05,  2.30s/it]predicting train subjects:  45%|████▍     | 127/285 [05:11<05:54,  2.24s/it]predicting train subjects:  45%|████▍     | 128/285 [05:14<06:16,  2.40s/it]predicting train subjects:  45%|████▌     | 129/285 [05:16<06:11,  2.38s/it]predicting train subjects:  46%|████▌     | 130/285 [05:19<05:59,  2.32s/it]predicting train subjects:  46%|████▌     | 131/285 [05:21<05:53,  2.29s/it]predicting train subjects:  46%|████▋     | 132/285 [05:23<05:56,  2.33s/it]predicting train subjects:  47%|████▋     | 133/285 [05:25<05:46,  2.28s/it]predicting train subjects:  47%|████▋     | 134/285 [05:27<05:23,  2.14s/it]predicting train subjects:  47%|████▋     | 135/285 [05:29<05:22,  2.15s/it]predicting train subjects:  48%|████▊     | 136/285 [05:32<05:48,  2.34s/it]predicting train subjects:  48%|████▊     | 137/285 [05:35<06:06,  2.48s/it]predicting train subjects:  48%|████▊     | 138/285 [05:37<05:58,  2.44s/it]predicting train subjects:  49%|████▉     | 139/285 [05:39<05:43,  2.35s/it]predicting train subjects:  49%|████▉     | 140/285 [05:42<05:46,  2.39s/it]predicting train subjects:  49%|████▉     | 141/285 [05:44<05:30,  2.30s/it]predicting train subjects:  50%|████▉     | 142/285 [05:46<05:24,  2.27s/it]predicting train subjects:  50%|█████     | 143/285 [05:48<05:03,  2.14s/it]predicting train subjects:  51%|█████     | 144/285 [05:51<05:26,  2.32s/it]predicting train subjects:  51%|█████     | 145/285 [05:53<05:16,  2.26s/it]predicting train subjects:  51%|█████     | 146/285 [05:55<05:14,  2.26s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:57<04:53,  2.13s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:59<04:49,  2.11s/it]predicting train subjects:  52%|█████▏    | 149/285 [06:02<05:13,  2.31s/it]predicting train subjects:  53%|█████▎    | 150/285 [06:04<05:17,  2.35s/it]predicting train subjects:  53%|█████▎    | 151/285 [06:06<05:04,  2.27s/it]predicting train subjects:  53%|█████▎    | 152/285 [06:08<04:49,  2.18s/it]predicting train subjects:  54%|█████▎    | 153/285 [06:10<04:37,  2.10s/it]predicting train subjects:  54%|█████▍    | 154/285 [06:13<04:45,  2.18s/it]predicting train subjects:  54%|█████▍    | 155/285 [06:15<04:41,  2.17s/it]predicting train subjects:  55%|█████▍    | 156/285 [06:17<04:56,  2.30s/it]predicting train subjects:  55%|█████▌    | 157/285 [06:20<05:00,  2.35s/it]predicting train subjects:  55%|█████▌    | 158/285 [06:22<04:59,  2.36s/it]predicting train subjects:  56%|█████▌    | 159/285 [06:24<04:37,  2.20s/it]predicting train subjects:  56%|█████▌    | 160/285 [06:26<04:41,  2.25s/it]predicting train subjects:  56%|█████▋    | 161/285 [06:28<04:33,  2.21s/it]predicting train subjects:  57%|█████▋    | 162/285 [06:30<04:15,  2.08s/it]predicting train subjects:  57%|█████▋    | 163/285 [06:32<04:12,  2.07s/it]predicting train subjects:  58%|█████▊    | 164/285 [06:35<04:17,  2.13s/it]predicting train subjects:  58%|█████▊    | 165/285 [06:37<04:23,  2.19s/it]predicting train subjects:  58%|█████▊    | 166/285 [06:40<04:47,  2.41s/it]predicting train subjects:  59%|█████▊    | 167/285 [06:42<04:42,  2.39s/it]predicting train subjects:  59%|█████▉    | 168/285 [06:44<04:21,  2.24s/it]predicting train subjects:  59%|█████▉    | 169/285 [06:46<04:16,  2.21s/it]predicting train subjects:  60%|█████▉    | 170/285 [06:48<04:10,  2.18s/it]predicting train subjects:  60%|██████    | 171/285 [06:50<04:05,  2.16s/it]predicting train subjects:  60%|██████    | 172/285 [06:53<04:12,  2.23s/it]predicting train subjects:  61%|██████    | 173/285 [06:55<04:18,  2.30s/it]predicting train subjects:  61%|██████    | 174/285 [06:58<04:13,  2.29s/it]predicting train subjects:  61%|██████▏   | 175/285 [07:00<04:07,  2.25s/it]predicting train subjects:  62%|██████▏   | 176/285 [07:03<04:30,  2.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [07:05<04:22,  2.43s/it]predicting train subjects:  62%|██████▏   | 178/285 [07:07<03:55,  2.20s/it]predicting train subjects:  63%|██████▎   | 179/285 [07:09<03:52,  2.20s/it]predicting train subjects:  63%|██████▎   | 180/285 [07:11<03:53,  2.22s/it]predicting train subjects:  64%|██████▎   | 181/285 [07:13<03:54,  2.25s/it]predicting train subjects:  64%|██████▍   | 182/285 [07:16<03:51,  2.25s/it]predicting train subjects:  64%|██████▍   | 183/285 [07:18<03:48,  2.24s/it]predicting train subjects:  65%|██████▍   | 184/285 [07:20<03:41,  2.20s/it]predicting train subjects:  65%|██████▍   | 185/285 [07:22<03:30,  2.10s/it]predicting train subjects:  65%|██████▌   | 186/285 [07:24<03:39,  2.22s/it]predicting train subjects:  66%|██████▌   | 187/285 [07:27<03:50,  2.35s/it]predicting train subjects:  66%|██████▌   | 188/285 [07:30<03:54,  2.42s/it]predicting train subjects:  66%|██████▋   | 189/285 [07:32<03:38,  2.28s/it]predicting train subjects:  67%|██████▋   | 190/285 [07:34<03:27,  2.19s/it]predicting train subjects:  67%|██████▋   | 191/285 [07:36<03:25,  2.19s/it]predicting train subjects:  67%|██████▋   | 192/285 [07:38<03:15,  2.10s/it]predicting train subjects:  68%|██████▊   | 193/285 [07:39<02:57,  1.93s/it]predicting train subjects:  68%|██████▊   | 194/285 [07:41<02:48,  1.86s/it]predicting train subjects:  68%|██████▊   | 195/285 [07:43<02:45,  1.83s/it]predicting train subjects:  69%|██████▉   | 196/285 [07:45<03:03,  2.06s/it]predicting train subjects:  69%|██████▉   | 197/285 [07:48<03:06,  2.12s/it]predicting train subjects:  69%|██████▉   | 198/285 [07:50<03:15,  2.25s/it]predicting train subjects:  70%|██████▉   | 199/285 [07:52<02:55,  2.04s/it]predicting train subjects:  70%|███████   | 200/285 [07:53<02:44,  1.94s/it]predicting train subjects:  71%|███████   | 201/285 [07:56<02:50,  2.03s/it]predicting train subjects:  71%|███████   | 202/285 [07:58<02:50,  2.05s/it]predicting train subjects:  71%|███████   | 203/285 [08:00<02:50,  2.08s/it]predicting train subjects:  72%|███████▏  | 204/285 [08:02<02:43,  2.02s/it]predicting train subjects:  72%|███████▏  | 205/285 [08:04<02:40,  2.00s/it]predicting train subjects:  72%|███████▏  | 206/285 [08:06<02:41,  2.05s/it]predicting train subjects:  73%|███████▎  | 207/285 [08:08<02:44,  2.10s/it]predicting train subjects:  73%|███████▎  | 208/285 [08:11<02:59,  2.33s/it]predicting train subjects:  73%|███████▎  | 209/285 [08:13<02:53,  2.28s/it]predicting train subjects:  74%|███████▎  | 210/285 [08:15<02:36,  2.08s/it]predicting train subjects:  74%|███████▍  | 211/285 [08:16<02:27,  1.99s/it]predicting train subjects:  74%|███████▍  | 212/285 [08:19<02:29,  2.05s/it]predicting train subjects:  75%|███████▍  | 213/285 [08:21<02:26,  2.04s/it]predicting train subjects:  75%|███████▌  | 214/285 [08:22<02:18,  1.95s/it]predicting train subjects:  75%|███████▌  | 215/285 [08:24<02:16,  1.95s/it]predicting train subjects:  76%|███████▌  | 216/285 [08:26<02:03,  1.78s/it]predicting train subjects:  76%|███████▌  | 217/285 [08:28<02:04,  1.83s/it]predicting train subjects:  76%|███████▋  | 218/285 [08:30<02:05,  1.88s/it]predicting train subjects:  77%|███████▋  | 219/285 [08:32<02:06,  1.92s/it]predicting train subjects:  77%|███████▋  | 220/285 [08:33<01:56,  1.79s/it]predicting train subjects:  78%|███████▊  | 221/285 [08:35<01:57,  1.83s/it]predicting train subjects:  78%|███████▊  | 222/285 [08:37<01:58,  1.89s/it]predicting train subjects:  78%|███████▊  | 223/285 [08:39<01:52,  1.81s/it]predicting train subjects:  79%|███████▊  | 224/285 [08:41<01:51,  1.84s/it]predicting train subjects:  79%|███████▉  | 225/285 [08:42<01:48,  1.80s/it]predicting train subjects:  79%|███████▉  | 226/285 [08:45<01:52,  1.91s/it]predicting train subjects:  80%|███████▉  | 227/285 [08:47<01:57,  2.02s/it]predicting train subjects:  80%|████████  | 228/285 [08:49<01:56,  2.04s/it]predicting train subjects:  80%|████████  | 229/285 [08:51<01:49,  1.96s/it]predicting train subjects:  81%|████████  | 230/285 [08:52<01:39,  1.80s/it]predicting train subjects:  81%|████████  | 231/285 [08:54<01:31,  1.70s/it]predicting train subjects:  81%|████████▏ | 232/285 [08:55<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [08:57<01:25,  1.65s/it]predicting train subjects:  82%|████████▏ | 234/285 [08:59<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [09:00<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [09:02<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [09:04<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [09:06<01:27,  1.87s/it]predicting train subjects:  84%|████████▍ | 239/285 [09:08<01:23,  1.82s/it]predicting train subjects:  84%|████████▍ | 240/285 [09:09<01:16,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [09:11<01:14,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [09:12<01:08,  1.60s/it]predicting train subjects:  85%|████████▌ | 243/285 [09:14<01:06,  1.58s/it]predicting train subjects:  86%|████████▌ | 244/285 [09:16<01:10,  1.72s/it]predicting train subjects:  86%|████████▌ | 245/285 [09:17<01:05,  1.63s/it]predicting train subjects:  86%|████████▋ | 246/285 [09:19<01:07,  1.73s/it]predicting train subjects:  87%|████████▋ | 247/285 [09:21<01:07,  1.77s/it]predicting train subjects:  87%|████████▋ | 248/285 [09:23<01:04,  1.74s/it]predicting train subjects:  87%|████████▋ | 249/285 [09:24<01:01,  1.69s/it]predicting train subjects:  88%|████████▊ | 250/285 [09:26<00:56,  1.63s/it]predicting train subjects:  88%|████████▊ | 251/285 [09:27<00:53,  1.58s/it]predicting train subjects:  88%|████████▊ | 252/285 [09:29<00:50,  1.54s/it]predicting train subjects:  89%|████████▉ | 253/285 [09:31<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [09:33<00:53,  1.73s/it]predicting train subjects:  89%|████████▉ | 255/285 [09:34<00:52,  1.75s/it]predicting train subjects:  90%|████████▉ | 256/285 [09:36<00:48,  1.67s/it]predicting train subjects:  90%|█████████ | 257/285 [09:37<00:45,  1.64s/it]predicting train subjects:  91%|█████████ | 258/285 [09:39<00:47,  1.75s/it]predicting train subjects:  91%|█████████ | 259/285 [09:41<00:45,  1.75s/it]predicting train subjects:  91%|█████████ | 260/285 [09:43<00:41,  1.66s/it]predicting train subjects:  92%|█████████▏| 261/285 [09:44<00:40,  1.67s/it]predicting train subjects:  92%|█████████▏| 262/285 [09:46<00:36,  1.60s/it]predicting train subjects:  92%|█████████▏| 263/285 [09:47<00:34,  1.58s/it]predicting train subjects:  93%|█████████▎| 264/285 [09:49<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [09:51<00:34,  1.75s/it]predicting train subjects:  93%|█████████▎| 266/285 [09:53<00:31,  1.67s/it]predicting train subjects:  94%|█████████▎| 267/285 [09:54<00:28,  1.60s/it]predicting train subjects:  94%|█████████▍| 268/285 [09:56<00:29,  1.71s/it]predicting train subjects:  94%|█████████▍| 269/285 [09:58<00:27,  1.73s/it]predicting train subjects:  95%|█████████▍| 270/285 [09:59<00:24,  1.63s/it]predicting train subjects:  95%|█████████▌| 271/285 [10:01<00:22,  1.61s/it]predicting train subjects:  95%|█████████▌| 272/285 [10:02<00:21,  1.66s/it]predicting train subjects:  96%|█████████▌| 273/285 [10:04<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [10:06<00:17,  1.60s/it]predicting train subjects:  96%|█████████▋| 275/285 [10:07<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [10:09<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [10:11<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [10:12<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [10:14<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [10:15<00:07,  1.60s/it]predicting train subjects:  99%|█████████▊| 281/285 [10:17<00:06,  1.59s/it]predicting train subjects:  99%|█████████▉| 282/285 [10:18<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [10:20<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [10:22<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [10:24<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:15,  1.75s/it]Loading train:   1%|          | 2/285 [00:03<07:49,  1.66s/it]Loading train:   1%|          | 3/285 [00:04<07:42,  1.64s/it]Loading train:   1%|▏         | 4/285 [00:06<08:08,  1.74s/it]Loading train:   2%|▏         | 5/285 [00:08<08:25,  1.81s/it]Loading train:   2%|▏         | 6/285 [00:10<08:12,  1.76s/it]Loading train:   2%|▏         | 7/285 [00:12<08:27,  1.82s/it]Loading train:   3%|▎         | 8/285 [00:13<08:09,  1.77s/it]Loading train:   3%|▎         | 9/285 [00:16<08:45,  1.90s/it]Loading train:   4%|▎         | 10/285 [00:17<08:06,  1.77s/it]Loading train:   4%|▍         | 11/285 [00:19<07:37,  1.67s/it]Loading train:   4%|▍         | 12/285 [00:20<07:26,  1.63s/it]Loading train:   5%|▍         | 13/285 [00:21<06:46,  1.49s/it]Loading train:   5%|▍         | 14/285 [00:23<07:01,  1.56s/it]Loading train:   5%|▌         | 15/285 [00:25<07:09,  1.59s/it]Loading train:   6%|▌         | 16/285 [00:26<07:05,  1.58s/it]Loading train:   6%|▌         | 17/285 [00:28<06:39,  1.49s/it]Loading train:   6%|▋         | 18/285 [00:29<07:00,  1.57s/it]Loading train:   7%|▋         | 19/285 [00:31<06:46,  1.53s/it]Loading train:   7%|▋         | 20/285 [00:32<06:41,  1.52s/it]Loading train:   7%|▋         | 21/285 [00:34<06:27,  1.47s/it]Loading train:   8%|▊         | 22/285 [00:35<06:18,  1.44s/it]Loading train:   8%|▊         | 23/285 [00:36<06:10,  1.41s/it]Loading train:   8%|▊         | 24/285 [00:38<05:56,  1.37s/it]Loading train:   9%|▉         | 25/285 [00:39<06:26,  1.48s/it]Loading train:   9%|▉         | 26/285 [00:41<06:24,  1.49s/it]Loading train:   9%|▉         | 27/285 [00:42<06:27,  1.50s/it]Loading train:  10%|▉         | 28/285 [00:44<06:26,  1.50s/it]Loading train:  10%|█         | 29/285 [00:45<06:27,  1.52s/it]Loading train:  11%|█         | 30/285 [00:47<06:55,  1.63s/it]Loading train:  11%|█         | 31/285 [00:49<06:59,  1.65s/it]Loading train:  11%|█         | 32/285 [00:50<06:20,  1.50s/it]Loading train:  12%|█▏        | 33/285 [00:51<06:05,  1.45s/it]Loading train:  12%|█▏        | 34/285 [00:53<06:02,  1.44s/it]Loading train:  12%|█▏        | 35/285 [00:54<06:10,  1.48s/it]Loading train:  13%|█▎        | 36/285 [00:56<05:57,  1.44s/it]Loading train:  13%|█▎        | 37/285 [00:57<06:01,  1.46s/it]Loading train:  13%|█▎        | 38/285 [00:59<05:48,  1.41s/it]Loading train:  14%|█▎        | 39/285 [01:00<05:47,  1.41s/it]Loading train:  14%|█▍        | 40/285 [01:01<05:49,  1.43s/it]Loading train:  14%|█▍        | 41/285 [01:03<05:30,  1.35s/it]Loading train:  15%|█▍        | 42/285 [01:04<05:27,  1.35s/it]Loading train:  15%|█▌        | 43/285 [01:05<05:25,  1.34s/it]Loading train:  15%|█▌        | 44/285 [01:07<05:34,  1.39s/it]Loading train:  16%|█▌        | 45/285 [01:08<05:30,  1.38s/it]Loading train:  16%|█▌        | 46/285 [01:10<05:35,  1.40s/it]Loading train:  16%|█▋        | 47/285 [01:11<05:01,  1.27s/it]Loading train:  17%|█▋        | 48/285 [01:12<05:25,  1.37s/it]Loading train:  17%|█▋        | 49/285 [01:14<05:52,  1.50s/it]Loading train:  18%|█▊        | 50/285 [01:15<05:46,  1.48s/it]Loading train:  18%|█▊        | 51/285 [01:17<06:11,  1.59s/it]Loading train:  18%|█▊        | 52/285 [01:19<05:49,  1.50s/it]Loading train:  19%|█▊        | 53/285 [01:20<05:53,  1.52s/it]Loading train:  19%|█▉        | 54/285 [01:22<06:09,  1.60s/it]Loading train:  19%|█▉        | 55/285 [01:23<05:54,  1.54s/it]Loading train:  20%|█▉        | 56/285 [01:25<05:49,  1.52s/it]Loading train:  20%|██        | 57/285 [01:26<05:44,  1.51s/it]Loading train:  20%|██        | 58/285 [01:28<05:23,  1.43s/it]Loading train:  21%|██        | 59/285 [01:29<05:35,  1.49s/it]Loading train:  21%|██        | 60/285 [01:31<05:26,  1.45s/it]Loading train:  21%|██▏       | 61/285 [01:32<05:04,  1.36s/it]Loading train:  22%|██▏       | 62/285 [01:33<05:15,  1.42s/it]Loading train:  22%|██▏       | 63/285 [01:34<05:00,  1.35s/it]Loading train:  22%|██▏       | 64/285 [01:36<05:36,  1.52s/it]Loading train:  23%|██▎       | 65/285 [01:38<05:58,  1.63s/it]Loading train:  23%|██▎       | 66/285 [01:40<06:04,  1.66s/it]Loading train:  24%|██▎       | 67/285 [01:41<05:47,  1.60s/it]Loading train:  24%|██▍       | 68/285 [01:43<05:27,  1.51s/it]Loading train:  24%|██▍       | 69/285 [01:44<05:18,  1.48s/it]Loading train:  25%|██▍       | 70/285 [01:45<05:08,  1.43s/it]Loading train:  25%|██▍       | 71/285 [01:47<05:24,  1.52s/it]Loading train:  25%|██▌       | 72/285 [01:49<05:15,  1.48s/it]Loading train:  26%|██▌       | 73/285 [01:50<05:19,  1.51s/it]Loading train:  26%|██▌       | 74/285 [01:52<05:12,  1.48s/it]Loading train:  26%|██▋       | 75/285 [01:53<05:25,  1.55s/it]Loading train:  27%|██▋       | 76/285 [01:55<05:23,  1.55s/it]Loading train:  27%|██▋       | 77/285 [01:56<05:08,  1.49s/it]Loading train:  27%|██▋       | 78/285 [01:57<04:56,  1.43s/it]Loading train:  28%|██▊       | 79/285 [01:59<04:57,  1.44s/it]Loading train:  28%|██▊       | 80/285 [02:00<04:54,  1.44s/it]Loading train:  28%|██▊       | 81/285 [02:02<04:37,  1.36s/it]Loading train:  29%|██▉       | 82/285 [02:03<04:42,  1.39s/it]Loading train:  29%|██▉       | 83/285 [02:04<04:29,  1.33s/it]Loading train:  29%|██▉       | 84/285 [02:06<05:11,  1.55s/it]Loading train:  30%|██▉       | 85/285 [02:08<05:26,  1.63s/it]Loading train:  30%|███       | 86/285 [02:10<05:35,  1.69s/it]Loading train:  31%|███       | 87/285 [02:11<05:26,  1.65s/it]Loading train:  31%|███       | 88/285 [02:13<05:36,  1.71s/it]Loading train:  31%|███       | 89/285 [02:15<05:45,  1.76s/it]Loading train:  32%|███▏      | 90/285 [02:17<05:21,  1.65s/it]Loading train:  32%|███▏      | 91/285 [02:18<05:18,  1.64s/it]Loading train:  32%|███▏      | 92/285 [02:20<05:33,  1.73s/it]Loading train:  33%|███▎      | 93/285 [02:22<05:34,  1.74s/it]Loading train:  33%|███▎      | 94/285 [02:23<05:12,  1.64s/it]Loading train:  33%|███▎      | 95/285 [02:25<05:25,  1.71s/it]Loading train:  34%|███▎      | 96/285 [02:27<05:29,  1.74s/it]Loading train:  34%|███▍      | 97/285 [02:29<05:23,  1.72s/it]Loading train:  34%|███▍      | 98/285 [02:30<05:18,  1.70s/it]Loading train:  35%|███▍      | 99/285 [02:32<05:08,  1.66s/it]Loading train:  35%|███▌      | 100/285 [02:34<05:18,  1.72s/it]Loading train:  35%|███▌      | 101/285 [02:35<04:54,  1.60s/it]Loading train:  36%|███▌      | 102/285 [02:37<04:55,  1.62s/it]Loading train:  36%|███▌      | 103/285 [02:38<04:32,  1.50s/it]Loading train:  36%|███▋      | 104/285 [02:40<04:39,  1.54s/it]Loading train:  37%|███▋      | 105/285 [02:41<04:38,  1.55s/it]Loading train:  37%|███▋      | 106/285 [02:42<04:23,  1.47s/it]Loading train:  38%|███▊      | 107/285 [02:44<04:23,  1.48s/it]Loading train:  38%|███▊      | 108/285 [02:45<04:18,  1.46s/it]Loading train:  38%|███▊      | 109/285 [02:47<04:32,  1.55s/it]Loading train:  39%|███▊      | 110/285 [02:49<04:34,  1.57s/it]Loading train:  39%|███▉      | 111/285 [02:50<04:37,  1.60s/it]Loading train:  39%|███▉      | 112/285 [02:52<04:31,  1.57s/it]Loading train:  40%|███▉      | 113/285 [02:53<04:28,  1.56s/it]Loading train:  40%|████      | 114/285 [02:55<04:20,  1.52s/it]Loading train:  40%|████      | 115/285 [02:56<04:16,  1.51s/it]Loading train:  41%|████      | 116/285 [02:58<04:19,  1.54s/it]Loading train:  41%|████      | 117/285 [02:59<04:10,  1.49s/it]Loading train:  41%|████▏     | 118/285 [03:01<04:01,  1.45s/it]Loading train:  42%|████▏     | 119/285 [03:02<03:55,  1.42s/it]Loading train:  42%|████▏     | 120/285 [03:03<03:48,  1.38s/it]Loading train:  42%|████▏     | 121/285 [03:05<04:04,  1.49s/it]Loading train:  43%|████▎     | 122/285 [03:07<04:05,  1.51s/it]Loading train:  43%|████▎     | 123/285 [03:08<04:01,  1.49s/it]Loading train:  44%|████▎     | 124/285 [03:09<03:52,  1.45s/it]Loading train:  44%|████▍     | 125/285 [03:11<03:43,  1.40s/it]Loading train:  44%|████▍     | 126/285 [03:12<03:26,  1.30s/it]Loading train:  45%|████▍     | 127/285 [03:13<03:33,  1.35s/it]Loading train:  45%|████▍     | 128/285 [03:14<03:17,  1.26s/it]Loading train:  45%|████▌     | 129/285 [03:15<03:05,  1.19s/it]Loading train:  46%|████▌     | 130/285 [03:17<03:12,  1.24s/it]Loading train:  46%|████▌     | 131/285 [03:18<03:18,  1.29s/it]Loading train:  46%|████▋     | 132/285 [03:19<03:12,  1.26s/it]Loading train:  47%|████▋     | 133/285 [03:21<03:13,  1.27s/it]Loading train:  47%|████▋     | 134/285 [03:22<03:22,  1.34s/it]Loading train:  47%|████▋     | 135/285 [03:23<03:13,  1.29s/it]Loading train:  48%|████▊     | 136/285 [03:24<03:09,  1.27s/it]Loading train:  48%|████▊     | 137/285 [03:26<03:17,  1.33s/it]Loading train:  48%|████▊     | 138/285 [03:27<03:17,  1.35s/it]Loading train:  49%|████▉     | 139/285 [03:28<03:10,  1.30s/it]Loading train:  49%|████▉     | 140/285 [03:30<03:10,  1.31s/it]Loading train:  49%|████▉     | 141/285 [03:31<02:59,  1.25s/it]Loading train:  50%|████▉     | 142/285 [03:32<03:04,  1.29s/it]Loading train:  50%|█████     | 143/285 [03:34<03:00,  1.27s/it]Loading train:  51%|█████     | 144/285 [03:35<03:03,  1.30s/it]Loading train:  51%|█████     | 145/285 [03:36<03:06,  1.33s/it]Loading train:  51%|█████     | 146/285 [03:38<03:00,  1.30s/it]Loading train:  52%|█████▏    | 147/285 [03:39<02:58,  1.29s/it]Loading train:  52%|█████▏    | 148/285 [03:40<02:54,  1.28s/it]Loading train:  52%|█████▏    | 149/285 [03:41<02:51,  1.26s/it]Loading train:  53%|█████▎    | 150/285 [03:42<02:42,  1.20s/it]Loading train:  53%|█████▎    | 151/285 [03:44<02:48,  1.26s/it]Loading train:  53%|█████▎    | 152/285 [03:45<02:48,  1.27s/it]Loading train:  54%|█████▎    | 153/285 [03:46<02:52,  1.30s/it]Loading train:  54%|█████▍    | 154/285 [03:48<02:51,  1.31s/it]Loading train:  54%|█████▍    | 155/285 [03:49<02:38,  1.22s/it]Loading train:  55%|█████▍    | 156/285 [03:50<02:32,  1.18s/it]Loading train:  55%|█████▌    | 157/285 [03:51<02:38,  1.24s/it]Loading train:  55%|█████▌    | 158/285 [03:52<02:38,  1.25s/it]Loading train:  56%|█████▌    | 159/285 [03:54<02:31,  1.20s/it]Loading train:  56%|█████▌    | 160/285 [03:55<02:45,  1.33s/it]Loading train:  56%|█████▋    | 161/285 [03:57<02:50,  1.37s/it]Loading train:  57%|█████▋    | 162/285 [03:58<02:46,  1.36s/it]Loading train:  57%|█████▋    | 163/285 [03:59<02:44,  1.35s/it]Loading train:  58%|█████▊    | 164/285 [04:00<02:36,  1.29s/it]Loading train:  58%|█████▊    | 165/285 [04:02<02:41,  1.35s/it]Loading train:  58%|█████▊    | 166/285 [04:03<02:41,  1.36s/it]Loading train:  59%|█████▊    | 167/285 [04:05<02:37,  1.34s/it]Loading train:  59%|█████▉    | 168/285 [04:06<02:38,  1.35s/it]Loading train:  59%|█████▉    | 169/285 [04:07<02:32,  1.32s/it]Loading train:  60%|█████▉    | 170/285 [04:09<02:33,  1.33s/it]Loading train:  60%|██████    | 171/285 [04:10<02:32,  1.34s/it]Loading train:  60%|██████    | 172/285 [04:11<02:30,  1.33s/it]Loading train:  61%|██████    | 173/285 [04:13<02:28,  1.33s/it]Loading train:  61%|██████    | 174/285 [04:14<02:23,  1.29s/it]Loading train:  61%|██████▏   | 175/285 [04:15<02:15,  1.23s/it]Loading train:  62%|██████▏   | 176/285 [04:16<02:22,  1.30s/it]Loading train:  62%|██████▏   | 177/285 [04:18<02:20,  1.30s/it]Loading train:  62%|██████▏   | 178/285 [04:19<02:27,  1.38s/it]Loading train:  63%|██████▎   | 179/285 [04:21<02:24,  1.36s/it]Loading train:  63%|██████▎   | 180/285 [04:22<02:20,  1.34s/it]Loading train:  64%|██████▎   | 181/285 [04:23<02:19,  1.34s/it]Loading train:  64%|██████▍   | 182/285 [04:24<02:14,  1.31s/it]Loading train:  64%|██████▍   | 183/285 [04:26<02:15,  1.33s/it]Loading train:  65%|██████▍   | 184/285 [04:27<02:07,  1.26s/it]Loading train:  65%|██████▍   | 185/285 [04:28<02:10,  1.30s/it]Loading train:  65%|██████▌   | 186/285 [04:30<02:13,  1.34s/it]Loading train:  66%|██████▌   | 187/285 [04:31<02:12,  1.35s/it]Loading train:  66%|██████▌   | 188/285 [04:32<02:07,  1.32s/it]Loading train:  66%|██████▋   | 189/285 [04:33<01:59,  1.24s/it]Loading train:  67%|██████▋   | 190/285 [04:35<01:58,  1.24s/it]Loading train:  67%|██████▋   | 191/285 [04:36<01:51,  1.19s/it]Loading train:  67%|██████▋   | 192/285 [04:37<01:50,  1.18s/it]Loading train:  68%|██████▊   | 193/285 [04:38<01:48,  1.18s/it]Loading train:  68%|██████▊   | 194/285 [04:40<02:03,  1.36s/it]Loading train:  68%|██████▊   | 195/285 [04:42<02:19,  1.55s/it]Loading train:  69%|██████▉   | 196/285 [04:44<02:27,  1.66s/it]Loading train:  69%|██████▉   | 197/285 [04:45<02:24,  1.64s/it]Loading train:  69%|██████▉   | 198/285 [04:47<02:23,  1.65s/it]Loading train:  70%|██████▉   | 199/285 [04:48<02:16,  1.59s/it]Loading train:  70%|███████   | 200/285 [04:50<02:06,  1.49s/it]Loading train:  71%|███████   | 201/285 [04:51<02:07,  1.52s/it]Loading train:  71%|███████   | 202/285 [04:53<01:59,  1.44s/it]Loading train:  71%|███████   | 203/285 [04:54<02:02,  1.50s/it]Loading train:  72%|███████▏  | 204/285 [04:56<02:07,  1.58s/it]Loading train:  72%|███████▏  | 205/285 [04:57<02:03,  1.54s/it]Loading train:  72%|███████▏  | 206/285 [04:59<01:54,  1.44s/it]Loading train:  73%|███████▎  | 207/285 [05:01<02:07,  1.63s/it]Loading train:  73%|███████▎  | 208/285 [05:03<02:15,  1.76s/it]Loading train:  73%|███████▎  | 209/285 [05:05<02:14,  1.77s/it]Loading train:  74%|███████▎  | 210/285 [05:06<02:06,  1.69s/it]Loading train:  74%|███████▍  | 211/285 [05:07<01:57,  1.59s/it]Loading train:  74%|███████▍  | 212/285 [05:09<01:51,  1.53s/it]Loading train:  75%|███████▍  | 213/285 [05:11<01:56,  1.62s/it]Loading train:  75%|███████▌  | 214/285 [05:12<01:48,  1.53s/it]